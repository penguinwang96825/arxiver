{"title": "Jinx: Unlimited LLMs for Probing Alignment Failures", "abstract": "Unlimited, or so-called helpful-only language models are trained without\nsafety alignment constraints and never refuse user queries. They are widely\nused by leading AI companies as internal tools for red teaming and alignment\nevaluation. For example, if a safety-aligned model produces harmful outputs\nsimilar to an unlimited model, this indicates alignment failures that require\nfurther attention. Despite their essential role in assessing alignment, such\nmodels are not available to the research community.\n  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx\nresponds to all queries without refusals or safety filtering, while preserving\nthe base model's capabilities in reasoning and instruction following. It\nprovides researchers with an accessible tool for probing alignment failures,\nevaluating safety boundaries, and systematically studying failure modes in\nlanguage model safety.", "published": "2025-08-11 17:56:06", "link": "http://arxiv.org/abs/2508.08243v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge", "abstract": "Evaluating the safety alignment of LLM responses in high-risk mental health\ndialogues is particularly difficult due to missing gold-standard answers and\nthe ethically sensitive nature of these interactions. To address this\nchallenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark\nbased on real-world Chinese mental health dialogues. It evaluates whether the\nmodel responses align with the safety principles defined by experts.\nSpecifically designed for settings without standard references, our method\nadopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation\nusing expert-defined reasoning chains grounded in psychological intervention\nprinciples. We employ binary point-wise scoring across multiple safety\ndimensions to enhance the explainability and traceability of the evaluation.\nAdditionally, we present a manually curated, high-quality Chinese-language\ndataset covering self-harm, suicidal ideation, and existential distress,\nderived from real-world online discourse. Experiments on 3600 judgments show\nthat our method achieves the highest agreement with expert assessments and\nproduces more interpretable evaluation rationales compared to existing\napproaches. Our dataset and evaluation tool are publicly available to\nfacilitate further research.", "published": "2025-08-11 17:52:07", "link": "http://arxiv.org/abs/2508.08236v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Capabilities of GPT-5 on Multimodal Medical Reasoning", "abstract": "Recent advances in large language models (LLMs) have enabled general-purpose\nsystems to perform increasingly complex domain-specific reasoning without\nextensive fine-tuning. In the medical domain, decision-making often requires\nintegrating heterogeneous information sources, including patient narratives,\nstructured data, and medical images. This study positions GPT-5 as a generalist\nmultimodal reasoner for medical decision support and systematically evaluates\nits zero-shot chain-of-thought reasoning performance on both text-based\nquestion answering and visual question answering tasks under a unified\nprotocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20\nagainst standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU\nmedical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that\nGPT-5 consistently outperforms all baselines, achieving state-of-the-art\naccuracy across all QA benchmarks and delivering substantial gains in\nmultimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and\nunderstanding scores by +29.62% and +36.18% over GPT-4o, respectively, and\nsurpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in\nunderstanding. In contrast, GPT-4o remains below human expert performance in\nmost dimensions. A representative case study demonstrates GPT-5's ability to\nintegrate visual and textual cues into a coherent diagnostic reasoning chain,\nrecommending appropriate high-stakes interventions. Our results show that, on\nthese controlled multimodal reasoning benchmarks, GPT-5 moves from\nhuman-comparable to above human-expert performance. This improvement may\nsubstantially inform the design of future clinical decision-support systems.", "published": "2025-08-11 17:43:45", "link": "http://arxiv.org/abs/2508.08224v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning", "abstract": "Reinforcement learning for LLM reasoning has rapidly emerged as a prominent\nresearch area, marked by a significant surge in related studies on both\nalgorithmic innovations and practical applications. Despite this progress,\nseveral critical challenges remain, including the absence of standardized\nguidelines for employing RL techniques and a fragmented understanding of their\nunderlying mechanisms. Additionally, inconsistent experimental settings,\nvariations in training data, and differences in model initialization have led\nto conflicting conclusions, obscuring the key characteristics of these\ntechniques and creating confusion among practitioners when selecting\nappropriate techniques. This paper systematically reviews widely adopted RL\ntechniques through rigorous reproductions and isolated evaluations within a\nunified open-source framework. We analyze the internal mechanisms, applicable\nscenarios, and core principles of each technique through fine-grained\nexperiments, including datasets of varying difficulty, model sizes, and\narchitectures. Based on these insights, we present clear guidelines for\nselecting RL techniques tailored to specific setups, and provide a reliable\nroadmap for practitioners navigating the RL for the LLM domain. Finally, we\nreveal that a minimalist combination of two techniques can unlock the learning\ncapability of critic-free policies using vanilla PPO loss. The results\ndemonstrate that our simple combination consistently improves performance,\nsurpassing strategies like GRPO and DAPO.", "published": "2025-08-11 17:39:45", "link": "http://arxiv.org/abs/2508.08221v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling", "abstract": "Watermarking LLM-generated text is critical for content attribution and\nmisinformation prevention. However, existing methods compromise text quality,\nrequire white-box model access and logit manipulation. These limitations\nexclude API-based models and multilingual scenarios. We propose SAEMark, a\ngeneral framework for post-hoc multi-bit watermarking that embeds personalized\nmessages solely via inference-time, feature-based rejection sampling without\naltering model logits or requiring training. Our approach operates on\ndeterministic features extracted from generated text, selecting outputs whose\nfeature statistics align with key-derived targets. This framework naturally\ngeneralizes across languages and domains while preserving text quality through\nsampling LLM outputs instead of modifying. We provide theoretical guarantees\nrelating watermark success probability and compute budget that hold for any\nsuitable feature extractor. Empirically, we demonstrate the framework's\neffectiveness using Sparse Autoencoders (SAEs), achieving superior detection\naccuracy and text quality. Experiments across 4 datasets show SAEMark's\nconsistent performance, with 99.7% F1 on English and strong multi-bit detection\naccuracy. SAEMark establishes a new paradigm for scalable watermarking that\nworks out-of-the-box with closed-source LLMs while enabling content\nattribution.", "published": "2025-08-11 17:33:18", "link": "http://arxiv.org/abs/2508.08211v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models", "abstract": "There has been much recent interest in evaluating large language models for\nuncertainty calibration to facilitate model control and modulate user trust.\nInference time uncertainty, which may provide a real-time signal to the model\nor external control modules, is particularly important for applying these\nconcepts to improve LLM-user experience in practice. While many of the existing\npapers consider model calibration, comparatively little work has sought to\nevaluate how closely model uncertainty aligns to human uncertainty. In this\nwork, we evaluate a collection of inference-time uncertainty measures, using\nboth established metrics and novel variations, to determine how closely they\nalign with both human group-level uncertainty and traditional notions of model\ncalibration. We find that numerous measures show evidence of strong alignment\nto human uncertainty, even despite the lack of alignment to human answer\npreference. For those successful metrics, we find moderate to strong evidence\nof model calibration in terms of both correctness correlation and\ndistributional analysis.", "published": "2025-08-11 17:22:45", "link": "http://arxiv.org/abs/2508.08204v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Speculative Decoding for Llama at Scale: Challenges and Solutions", "abstract": "Speculative decoding is a standard method for accelerating the inference\nspeed of large language models. However, scaling it for production environments\nposes several engineering challenges, including efficiently implementing\ndifferent operations (e.g., tree attention and multi-round speculative\ndecoding) on GPU. In this paper, we detail the training and inference\noptimization techniques that we have implemented to enable EAGLE-based\nspeculative decoding at a production scale for Llama models. With these\nchanges, we achieve a new state-of-the-art inference latency for Llama models.\nFor example, Llama4 Maverick decodes at a speed of about 4 ms per token (with a\nbatch size of one) on 8 NVIDIA H100 GPUs, which is 10% faster than the\npreviously best known method. Furthermore, for EAGLE-based speculative\ndecoding, our optimizations enable us to achieve a speed-up for large batch\nsizes between 1.4x and 2.0x at production scale.", "published": "2025-08-11 17:11:26", "link": "http://arxiv.org/abs/2508.08192v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo", "abstract": "The Learning With Disagreements (LeWiDi) 2025 shared task is to model\nannotator disagreement through soft label distribution prediction and\nperspectivist evaluation, modeling annotators. We adapt DisCo (Distribution\nfrom Context), a neural architecture that jointly models item-level and\nannotator-level label distributions, and present detailed analysis and\nimprovements. In this paper, we extend the DisCo by incorporating annotator\nmetadata, enhancing input representations, and modifying the loss functions to\ncapture disagreement patterns better. Through extensive experiments, we\ndemonstrate substantial improvements in both soft and perspectivist evaluation\nmetrics across three datasets. We also conduct in-depth error and calibration\nanalyses, highlighting the conditions under which improvements occur. Our\nfindings underscore the value of disagreement-aware modeling and offer insights\ninto how system components interact with the complexity of human-annotated\ndata.", "published": "2025-08-11 16:39:09", "link": "http://arxiv.org/abs/2508.08163v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation", "abstract": "Reinforcement learning (RL) is emerging as a powerful paradigm for enabling\nlarge language models (LLMs) to perform complex reasoning tasks. Recent\nadvances indicate that integrating RL with retrieval-augmented generation (RAG)\nallows LLMs to dynamically incorporate external knowledge, leading to more\ninformed and robust decision making. However, we identify a critical challenge\nduring policy-driven trajectory sampling: LLMs are frequently trapped in\nunproductive reasoning paths, which we refer to as \"dead ends\", committing to\noverconfident yet incorrect conclusions. This severely hampers exploration and\nundermines effective policy optimization. To address this challenge, we propose\nREX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented\nGeneration), a novel framework that explores alternative reasoning paths while\nmaintaining rigorous policy learning through principled distributional\ncorrections. Our approach introduces two key innovations: (1) Mixed Sampling\nStrategy, which combines a novel probe sampling method with exploratory prompts\nto escape dead ends; and (2) Policy Correction Mechanism, which employs\nimportance sampling to correct distribution shifts induced by mixed sampling,\nthereby mitigating gradient estimation bias. We evaluate it on seven\nquestion-answering benchmarks, and the experimental results show that REX-RAG\nachieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B\nover strong baselines, demonstrating competitive results across multiple\ndatasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.", "published": "2025-08-11 16:25:25", "link": "http://arxiv.org/abs/2508.08149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data-Efficient Biomedical In-Context Learning: A Diversity-Enhanced Submodular Perspective", "abstract": "Recent progress in large language models (LLMs) has leveraged their\nin-context learning (ICL) abilities to enable quick adaptation to unseen\nbiomedical NLP tasks. By incorporating only a few input-output examples into\nprompts, LLMs can rapidly perform these new tasks. While the impact of these\ndemonstrations on LLM performance has been extensively studied, most existing\napproaches prioritize representativeness over diversity when selecting examples\nfrom large corpora. To address this gap, we propose Dual-Div, a\ndiversity-enhanced data-efficient framework for demonstration selection in\nbiomedical ICL. Dual-Div employs a two-stage retrieval and ranking process:\nFirst, it identifies a limited set of candidate examples from a corpus by\noptimizing both representativeness and diversity (with optional annotation for\nunlabeled data). Second, it ranks these candidates against test queries to\nselect the most relevant and non-redundant demonstrations. Evaluated on three\nbiomedical NLP tasks (named entity recognition (NER), relation extraction (RE),\nand text classification (TC)) using LLaMA 3.1 and Qwen 2.5 for inference, along\nwith three retrievers (BGE-Large, BMRetriever, MedCPT), Dual-Div consistently\noutperforms baselines-achieving up to 5% higher macro-F1 scores-while\ndemonstrating robustness to prompt permutations and class imbalance. Our\nfindings establish that diversity in initial retrieval is more critical than\nranking-stage optimization, and limiting demonstrations to 3-5 examples\nmaximizes performance efficiency.", "published": "2025-08-11 16:13:21", "link": "http://arxiv.org/abs/2508.08140v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models", "abstract": "Large Language Models (LLMs) are prone to generating fluent but incorrect\ncontent, known as confabulation, which poses increasing risks in multi-turn or\nagentic applications where outputs may be reused as context. In this work, we\ninvestigate how in-context information influences model behavior and whether\nLLMs can identify their unreliable responses. We propose a reliability\nestimation that leverages token-level uncertainty to guide the aggregation of\ninternal model representations. Specifically, we compute aleatoric and\nepistemic uncertainty from output logits to identify salient tokens and\naggregate their hidden states into compact representations for response-level\nreliability prediction. Through controlled experiments on open QA benchmarks,\nwe find that correct in-context information improves both answer accuracy and\nmodel confidence, while misleading context often induces confidently incorrect\nresponses, revealing a misalignment between uncertainty and correctness. Our\nprobing-based method captures these shifts in model behavior and improves the\ndetection of unreliable outputs across multiple open-source LLMs. These results\nunderscore the limitations of direct uncertainty signals and highlight the\npotential of uncertainty-guided probing for reliability-aware generation.", "published": "2025-08-11 16:12:36", "link": "http://arxiv.org/abs/2508.08139v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models", "abstract": "Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to\nperceive speech inputs, have gained increasing attention for their potential to\nadvance speech understanding tasks. However, despite recent progress, studies\nshow that SLMs often struggle to generalize across datasets, even for trained\nlanguages and tasks, raising concerns about whether they process speech in a\ntext-like manner as intended. A key challenge underlying this limitation is the\nmodality gap between speech and text representations. The high variability in\nspeech embeddings may allow SLMs to achieve strong in-domain performance by\nexploiting unintended speech variations, ultimately hindering generalization.\nTo mitigate this modality gap, we introduce Optimal Transport Regularization\n(OTReg), a method that formulates speech-text alignment as an optimal transport\nproblem and derives a regularization loss to improve SLM training. In each\ntraining iteration, OTReg first establishes a structured correspondence between\nspeech and transcript embeddings by determining the optimal transport plan,\nthen incorporates the regularization loss based on this transport plan to\noptimize SLMs in generating speech embeddings that align more effectively with\ntranscript embeddings. OTReg is lightweight, requiring no additional labels or\nlearnable parameters, and integrates seamlessly into existing SLM training\nprocedures. Extensive multilingual ASR experiments demonstrate that OTReg\nenhances speech-text alignment, mitigates the modality gap, and consequently\nimproves SLM generalization across diverse datasets.", "published": "2025-08-11 16:06:04", "link": "http://arxiv.org/abs/2508.08131v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks", "abstract": "In this paper, we introduce a novel Czech dataset for aspect-based sentiment\nanalysis (ABSA), which consists of 3.1K manually annotated reviews from the\nrestaurant domain. The dataset is built upon the older Czech dataset, which\ncontained only separate labels for the basic ABSA tasks such as aspect term\nextraction or aspect polarity detection. Unlike its predecessor, our new\ndataset is specifically designed for more complex tasks, e.g.\ntarget-aspect-category detection. These advanced tasks require a unified\nannotation format, seamlessly linking sentiment elements (labels) together. Our\ndataset follows the format of the well-known SemEval-2016 datasets. This design\nchoice allows effortless application and evaluation in cross-lingual scenarios,\nultimately fostering cross-language comparisons with equivalent counterpart\ndatasets in other languages. The annotation process engaged two trained\nannotators, yielding an impressive inter-annotator agreement rate of\napproximately 90%. Additionally, we provide 24M reviews without annotations\nsuitable for unsupervised learning. We present robust monolingual baseline\nresults achieved with various Transformer-based models and insightful error\nanalysis to supplement our contributions. Our code and dataset are freely\navailable for non-commercial research purposes.", "published": "2025-08-11 16:03:28", "link": "http://arxiv.org/abs/2508.08125v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Iterative refinement, not training objective, makes HuBERT behave differently from wav2vec 2.0", "abstract": "Self-supervised models for speech representation learning now see widespread\nuse for their versatility and performance on downstream tasks, but the effect\nof model architecture on the linguistic information learned in their\nrepresentations remains under-studied. This study investigates two such models,\nHuBERT and wav2vec 2.0, and minimally compares two of their architectural\ndifferences: training objective and iterative pseudo-label refinement through\nmultiple training iterations. We find that differences in canonical correlation\nof hidden representations to word identity, phoneme identity, and speaker\nidentity are explained by training iteration, not training objective. We\nsuggest that future work investigate the reason for the effectiveness of\niterative refinement in encoding linguistic information in self-supervised\nspeech representations.", "published": "2025-08-11 15:48:56", "link": "http://arxiv.org/abs/2508.08110v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?", "abstract": "Recent advancements in Large Language Models (LLMs) and their increased\naccessibility have made it easier than ever for students to automatically\ngenerate texts, posing new challenges for educational institutions. To enforce\nnorms of academic integrity and ensure students' learning, learning analytics\nmethods to automatically detect LLM-generated text appear increasingly\nappealing. This paper benchmarks the performance of different state-of-the-art\ndetectors in educational contexts, introducing a novel dataset, called\nGenerative Essay Detection in Education (GEDE), containing over 900\nstudent-written essays and over 12,500 LLM-generated essays from various\ndomains. To capture the diversity of LLM usage practices in generating text, we\npropose the concept of contribution levels, representing students' contribution\nto a given assignment. These levels range from purely human-written texts, to\nslightly LLM-improved versions, to fully LLM-generated texts, and finally to\nactive attacks on the detector by \"humanizing\" generated texts. We show that\nmost detectors struggle to accurately classify texts of intermediate student\ncontribution levels, like LLM-improved human-written texts. Detectors are\nparticularly likely to produce false positives, which is problematic in\neducational settings where false suspicions can severely impact students'\nlives. Our dataset, code, and additional supplementary materials are publicly\navailable at\nhttps://github.com/lukasgehring/Assessing-LLM-Text-Detection-in-Educational-Contexts.", "published": "2025-08-11 15:34:49", "link": "http://arxiv.org/abs/2508.08096v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dual Information Speech Language Models for Emotional Conversations", "abstract": "Conversational systems relying on text-based large language models (LLMs)\noften overlook paralinguistic cues, essential for understanding emotions and\nintentions. Speech-language models (SLMs), which use speech as input, are\nemerging as a promising solution. However, SLMs built by extending frozen LLMs\nstruggle to capture paralinguistic information and exhibit reduced context\nunderstanding. We identify entangled information and improper training\nstrategies as key issues. To address these issues, we propose two heterogeneous\nadapters and suggest a weakly supervised training strategy. Our approach\ndisentangles paralinguistic and linguistic information, enabling SLMs to\ninterpret speech through structured representations. It also preserves\ncontextual understanding by avoiding the generation of task-specific vectors\nthrough controlled randomness. This approach trains only the adapters on common\ndatasets, ensuring parameter and data efficiency. Experiments demonstrate\ncompetitive performance in emotional conversation tasks, showcasing the model's\nability to effectively integrate both paralinguistic and linguistic information\nwithin contextual settings.", "published": "2025-08-11 15:33:44", "link": "http://arxiv.org/abs/2508.08095v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches", "abstract": "Recently, large reasoning models have demonstrated strong mathematical and\ncoding abilities, and deep search leverages their reasoning capabilities in\nchallenging information retrieval tasks. Existing deep search works are\ngenerally limited to a single knowledge source, either local or the Web.\nHowever, enterprises often require private deep search systems that can\nleverage search tools over both local and the Web corpus. Simply training an\nagent equipped with multiple search tools using flat reinforcement learning\n(RL) is a straightforward idea, but it has problems such as low training data\nefficiency and poor mastery of complex tools. To address the above issue, we\npropose a hierarchical agentic deep search framework, HierSearch, trained with\nhierarchical RL. At the low level, a local deep search agent and a Web deep\nsearch agent are trained to retrieve evidence from their corresponding domains.\nAt the high level, a planner agent coordinates low-level agents and provides\nthe final answer. Moreover, to prevent direct answer copying and error\npropagation, we design a knowledge refiner that filters out hallucinations and\nirrelevant evidence returned by low-level agents. Experiments show that\nHierSearch achieves better performance compared to flat RL, and outperforms\nvarious deep search and multi-source retrieval-augmented generation baselines\nin six benchmarks across general, finance, and medical domains.", "published": "2025-08-11 15:31:47", "link": "http://arxiv.org/abs/2508.08088v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Investigating the Design Space of Visual Grounding in Multimodal Large Language Model", "abstract": "Fine-grained multimodal capability in Multimodal Large Language Models\n(MLLMs) has emerged as a critical research direction, particularly for tackling\nthe visual grounding (VG) problem. Despite the strong performance achieved by\nexisting approaches, they often employ disparate design choices when\nfine-tuning MLLMs for VG, lacking systematic verification to support these\ndesigns. To bridge this gap, this paper presents a comprehensive study of\nvarious design choices that impact the VG performance of MLLMs. We conduct our\nanalysis using LLaVA-1.5, which has been widely adopted in prior empirical\nstudies of MLLMs. While more recent models exist, we follow this convention to\nensure our findings remain broadly applicable and extendable to other\narchitectures. We cover two key aspects: (1) exploring different visual\ngrounding paradigms in MLLMs, identifying the most effective design, and\nproviding our insights; and (2) conducting ablation studies on the design of\ngrounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our\nfindings contribute to a stronger MLLM for VG, achieving improvements of +5.6%\n/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.", "published": "2025-08-11 15:10:52", "link": "http://arxiv.org/abs/2508.08066v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations", "abstract": "Event logs reflect the behavior of business processes that are mapped in\norganizational information systems. Predictive process monitoring (PPM)\ntransforms these data into value by creating process-related predictions that\nprovide the insights required for proactive interventions at process runtime.\nExisting PPM techniques require sufficient amounts of event data or other\nrelevant resources that might not be readily available, preventing some\norganizations from utilizing PPM. The transfer learning-based PPM technique\npresented in this paper allows organizations without suitable event data or\nother relevant resources to implement PPM for effective decision support. The\ntechnique is instantiated in two real-life use cases, based on which numerical\nexperiments are performed using event logs for IT service management processes\nin an intra- and inter-organizational setting. The results of the experiments\nsuggest that knowledge of one business process can be transferred to a similar\nbusiness process in the same or a different organization to enable effective\nPPM in the target context. With the proposed technique, organizations can\nbenefit from transfer learning in an intra- and inter-organizational setting,\nwhere resources like pre-trained models are transferred within and across\norganizational boundaries.", "published": "2025-08-11 15:03:50", "link": "http://arxiv.org/abs/2508.08061v1", "categories": ["cs.LG", "cs.CL", "cs.DB"], "primary_category": "cs.LG"}
{"title": "9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)", "abstract": "The Sign Language Translation and Avatar Technology (SLTAT) workshops\ncontinue a series of gatherings to share recent advances in improving deaf /\nhuman communication through non-invasive means. This 2025 edition, the 9th\nsince its first appearance in 2011, is hosted by the International Conference\non Intelligent Virtual Agents (IVA), giving the opportunity for contamination\nbetween two research communities, using digital humans as either virtual\ninterpreters or as interactive conversational agents. As presented in this\nsummary paper, SLTAT sees contributions beyond avatar technologies, with a\nconsistent number of submissions on sign language recognition, and other work\non data collection, data analysis, tools, ethics, usability, and affective\ncomputing.", "published": "2025-08-11 14:50:21", "link": "http://arxiv.org/abs/2508.08050v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning", "abstract": "Recent advancements in large language models, multimodal large language\nmodels, and large audio language models (LALMs) have significantly improved\ntheir reasoning capabilities through reinforcement learning with rule-based\nrewards. However, the explicit reasoning process has yet to show significant\nbenefits for audio question answering, and effectively leveraging deep\nreasoning remains an open challenge, with LALMs still falling short of\nhuman-level auditory-language reasoning. To address these limitations, we\npropose Audio-Thinker, a reinforcement learning framework designed to enhance\nthe reasoning capabilities of LALMs, with a focus on improving adaptability,\nconsistency, and effectiveness. Our approach introduces an adaptive think\naccuracy reward, enabling the model to adjust its reasoning strategies based on\ntask complexity dynamically. Furthermore, we incorporate an external reward\nmodel to evaluate the overall consistency and quality of the reasoning process,\ncomplemented by think-based rewards that help the model distinguish between\nvalid and flawed reasoning paths during training. Experimental results\ndemonstrate that our Audio-Thinker model outperforms existing\nreasoning-oriented LALMs across various benchmark tasks, exhibiting superior\nreasoning and generalization capabilities.", "published": "2025-08-11 14:41:10", "link": "http://arxiv.org/abs/2508.08039v1", "categories": ["cs.SD", "cs.CL", "cs.MM"], "primary_category": "cs.SD"}
{"title": "Progressive Depth Up-scaling via Optimal Transport", "abstract": "Scaling Large Language Models (LLMs) yields performance gains but incurs\nsubstantial training costs. Depth up-scaling offers training efficiency by\nadding new layers to pre-trained models. However, most existing methods copy or\naverage weights from base layers, neglecting neuron permutation differences.\nThis limitation can potentially cause misalignment that harms performance.\nInspired by applying Optimal Transport (OT) for neuron alignment, we propose\nOptimal Transport Depth Up-Scaling (OpT-DeUS). OpT-DeUS aligns and fuses\nTransformer blocks in adjacent base layers via OT for new layer creation, to\nmitigate neuron permutation mismatch between layers. OpT-DeUS achieves better\noverall performance and offers improved training efficiency than existing\nmethods for continual pre-training and supervised fine-tuning across different\nmodel sizes. To further evaluate the impact of interpolation positions, our\nextensive analysis shows that inserting new layers closer to the top results in\nhigher training efficiency due to shorter back-propagation time while obtaining\nadditional performance gains.", "published": "2025-08-11 14:15:33", "link": "http://arxiv.org/abs/2508.08011v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WideSearch: Benchmarking Agentic Broad Info-Seeking", "abstract": "From professional research to everyday planning, many tasks are bottlenecked\nby wide-scale information seeking, which is more repetitive than cognitively\ncomplex. With the rapid development of Large Language Models (LLMs), automated\nsearch agents powered by LLMs offer a promising solution to liberate humans\nfrom this tedious work. However, the capability of these agents to perform such\n\"wide-context\" collection reliably and completely remains largely unevaluated\ndue to a lack of suitable benchmarks. To bridge this gap, we introduce\nWideSearch, a new benchmark engineered to evaluate agent reliability on these\nlarge-scale collection tasks. The benchmark features 200 manually curated\nquestions (100 in English, 100 in Chinese) from over 15 diverse domains,\ngrounded in real user queries. Each task requires agents to collect large-scale\natomic information, which could be verified one by one objectively, and arrange\nit into a well-organized output. A rigorous five-stage quality control pipeline\nensures the difficulty, completeness, and verifiability of the dataset. We\nbenchmark over 10 state-of-the-art agentic search systems, including\nsingle-agent, multi-agent frameworks, and end-to-end commercial systems. Most\nsystems achieve overall success rates near 0\\%, with the best performer\nreaching just 5\\%. However, given sufficient time, cross-validation by multiple\nhuman testers can achieve a near 100\\% success rate. These results demonstrate\nthat present search agents have critical deficiencies in large-scale\ninformation seeking, underscoring urgent areas for future research and\ndevelopment in agentic search. Our dataset, evaluation pipeline, and benchmark\nresults have been publicly released at https://widesearch-seed.github.io/", "published": "2025-08-11 14:03:09", "link": "http://arxiv.org/abs/2508.07999v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Medical Metaphors Corpus (MCC)", "abstract": "Metaphor is a fundamental cognitive mechanism that shapes scientific\nunderstanding, enabling the communication of complex concepts while potentially\nconstraining paradigmatic thinking. Despite the prevalence of figurative\nlanguage in scientific discourse, existing metaphor detection resources\nprimarily focus on general-domain text, leaving a critical gap for\ndomain-specific applications. In this paper, we present the Medical Metaphors\nCorpus (MCC), a comprehensive dataset of 792 annotated scientific conceptual\nmetaphors spanning medical and biological domains. MCC aggregates metaphorical\nexpressions from diverse sources including peer-reviewed literature, news\nmedia, social media discourse, and crowdsourced contributions, providing both\nbinary and graded metaphoricity judgments validated through human annotation.\nEach instance includes source-target conceptual mappings and perceived\nmetaphoricity scores on a 0-7 scale, establishing the first annotated resource\nfor computational scientific metaphor research. Our evaluation demonstrates\nthat state-of-the-art language models achieve modest performance on scientific\nmetaphor detection, revealing substantial room for improvement in\ndomain-specific figurative language understanding. MCC enables multiple\nresearch applications including metaphor detection benchmarking, quality-aware\ngeneration systems, and patient-centered communication tools.", "published": "2025-08-11 13:55:31", "link": "http://arxiv.org/abs/2508.07993v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription", "abstract": "Automatic transcription of acoustic guitar fingerpicking performances remains\na challenging task due to the scarcity of labeled training data and legal\nconstraints connected with musical recordings. This work investigates a\nprocedural data generation pipeline as an alternative to real audio recordings\nfor training transcription models. Our approach synthesizes training data\nthrough four stages: knowledge-based fingerpicking tablature composition, MIDI\nperformance rendering, physical modeling using an extended Karplus-Strong\nalgorithm, and audio augmentation including reverb and distortion. We train and\nevaluate a CRNN-based note-tracking model on both real and synthetic datasets,\ndemonstrating that procedural data can be used to achieve reasonable\nnote-tracking results. Finetuning with a small amount of real data further\nenhances transcription accuracy, improving over models trained exclusively on\nreal recordings. These results highlight the potential of procedurally\ngenerated audio for data-scarce music information retrieval tasks.", "published": "2025-08-11 13:52:17", "link": "http://arxiv.org/abs/2508.07987v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL", "abstract": "Recent advancements in LLM-based agents have demonstrated remarkable\ncapabilities in handling complex, knowledge-intensive tasks by integrating\nexternal tools. Among diverse choices of tools, search tools play a pivotal\nrole in accessing vast external knowledge. However, open-source agents still\nfall short of achieving expert-level Search Intelligence, the ability to\nresolve ambiguous queries, generate precise searches, analyze results, and\nconduct thorough exploration. Existing approaches fall short in scalability,\nefficiency, and data quality. For example, small turn limits in existing online\nRL methods, e.g. <=10, restrict complex strategy learning. This paper\nintroduces ASearcher, an open-source project for large-scale RL training of\nsearch agents. Our key contributions include: (1) Scalable fully asynchronous\nRL training that enables long-horizon search while maintaining high training\nefficiency. (2) A prompt-based LLM agent that autonomously synthesizes\nhigh-quality and challenging QAs, creating a large-scale QA dataset. Through RL\ntraining, our prompt-based QwQ-32B agent achieves substantial improvements,\nwith 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our\nagent exhibits extreme long-horizon search, with tool calls exceeding 40 turns\nand output tokens exceeding 150k during training time. With a simple agent\ndesign and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on\nxBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We\nopen-source our models, training data, and codes in\nhttps://github.com/inclusionAI/ASearcher.", "published": "2025-08-11 13:36:57", "link": "http://arxiv.org/abs/2508.07976v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Document Retrieval Coherence for Semantically Equivalent Queries", "abstract": "Dense Retrieval (DR) models have proven to be effective for Document\nRetrieval and Information Grounding tasks. Usually, these models are trained\nand optimized for improving the relevance of top-ranked documents for a given\nquery. Previous work has shown that popular DR models are sensitive to the\nquery and document lexicon: small variations of it may lead to a significant\ndifference in the set of retrieved documents. In this paper, we propose a\nvariation of the Multi-Negative Ranking loss for training DR that improves the\ncoherence of models in retrieving the same documents with respect to\nsemantically similar queries. The loss penalizes discrepancies between the\ntop-k ranked documents retrieved for diverse but semantic equivalent queries.\nWe conducted extensive experiments on various datasets, MS-MARCO, Natural\nQuestions, BEIR, and TREC DL 19/20. The results show that (i) models optimizes\nby our loss are subject to lower sensitivity, and, (ii) interestingly, higher\naccuracy.", "published": "2025-08-11 13:34:59", "link": "http://arxiv.org/abs/2508.07975v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Joint Transcription of Acoustic Guitar Strumming Directions and Chords", "abstract": "Automatic transcription of guitar strumming is an underrepresented and\nchallenging task in Music Information Retrieval (MIR), particularly for\nextracting both strumming directions and chord progressions from audio signals.\nWhile existing methods show promise, their effectiveness is often hindered by\nlimited datasets. In this work, we extend a multimodal approach to guitar\nstrumming transcription by introducing a novel dataset and a deep\nlearning-based transcription model. We collect 90 min of real-world guitar\nrecordings using an ESP32 smartwatch motion sensor and a structured recording\nprotocol, complemented by a synthetic dataset of 4h of labeled strumming audio.\nA Convolutional Recurrent Neural Network (CRNN) model is trained to detect\nstrumming events, classify their direction, and identify the corresponding\nchords using only microphone audio. Our evaluation demonstrates significant\nimprovements over baseline onset detection algorithms, with a hybrid method\ncombining synthetic and real-world data achieving the highest accuracy for both\nstrumming action detection and chord classification. These results highlight\nthe potential of deep learning for robust guitar strumming transcription and\nopen new avenues for automatic rhythm guitar analysis.", "published": "2025-08-11 13:34:49", "link": "http://arxiv.org/abs/2508.07973v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Understanding Syntactic Generalization in Structure-inducing Language Models", "abstract": "Structure-inducing Language Models (SiLM) are trained on a self-supervised\nlanguage modeling task, and induce a hierarchical sentence representation as a\nbyproduct when processing an input. A wide variety of SiLMs have been proposed.\nHowever, these have typically been evaluated on a relatively small scale, and\nevaluation of these models has systematic gaps and lacks comparability. In this\nwork, we study three different SiLM architectures using both natural language\n(English) corpora and synthetic bracketing expressions: Structformer (Shen et\nal., 2021), UDGN (Shen et al., 2022) and GPST (Hu et al., 2024). We compare\nthem with respect to (i) properties of the induced syntactic representations\n(ii) performance on grammaticality judgment tasks, and (iii) training dynamics.\nWe find that none of the three architectures dominates across all evaluation\nmetrics. However, there are significant differences, in particular with respect\nto the induced syntactic representations. The Generative Pretrained Structured\nTransformer (GPST; Hu et al. 2024) performs most consistently across evaluation\nsettings, and outperforms the other models on long-distance dependencies in\nbracketing expressions. Furthermore, our study shows that small models trained\non large amounts of synthetic data provide a useful testbed for evaluating\nbasic model properties.", "published": "2025-08-11 13:29:41", "link": "http://arxiv.org/abs/2508.07969v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Machine Interpreting: Lessons from Human Interpreting Studies", "abstract": "Current speech translation systems, while having achieved impressive\naccuracies, are rather static in their behavior and do not adapt to real-world\nsituations in ways human interpreters do. In order to improve their practical\nusefulness and enable interpreting-like experiences, a precise understanding of\nthe nature of human interpreting is crucial. To this end, we discuss human\ninterpreting literature from the perspective of the machine translation field,\nwhile considering both operational and qualitative aspects. We identify\nimplications for the development of speech translation systems and argue that\nthere is great potential to adopt many human interpreting principles using\nrecent modeling techniques. We hope that our findings provide inspiration for\nclosing the perceived usability gap, and can motivate progress toward true\nmachine interpreting.", "published": "2025-08-11 13:20:33", "link": "http://arxiv.org/abs/2508.07964v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Subjective Language Understanding: A Survey", "abstract": "Subjective language understanding refers to a broad set of natural language\nprocessing tasks where the goal is to interpret or generate content that\nconveys personal feelings, opinions, or figurative meanings rather than\nobjective facts. With the advent of large language models (LLMs) such as\nChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach\nthese inherently nuanced tasks. In this survey, we provide a comprehensive\nreview of recent advances in applying LLMs to subjective language tasks,\nincluding sentiment analysis, emotion recognition, sarcasm detection, humor\nunderstanding, stance detection, metaphor interpretation, intent detection, and\naesthetics assessment. We begin by clarifying the definition of subjective\nlanguage from linguistic and cognitive perspectives, and we outline the unique\nchallenges posed by subjective language (e.g. ambiguity, figurativeness,\ncontext dependence). We then survey the evolution of LLM architectures and\ntechniques that particularly benefit subjectivity tasks, highlighting why LLMs\nare well-suited to model subtle human-like judgments. For each of the eight\ntasks, we summarize task definitions, key datasets, state-of-the-art LLM-based\nmethods, and remaining challenges. We provide comparative insights, discussing\ncommonalities and differences among tasks and how multi-task LLM approaches\nmight yield unified models of subjectivity. Finally, we identify open issues\nsuch as data limitations, model bias, and ethical considerations, and suggest\nfuture research directions. We hope this survey will serve as a valuable\nresource for researchers and practitioners interested in the intersection of\naffective computing, figurative language processing, and large-scale language\nmodels.", "published": "2025-08-11 13:10:44", "link": "http://arxiv.org/abs/2508.07959v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expert Preference-based Evaluation of Automated Related Work Generation", "abstract": "Expert domain writing, such as scientific writing, typically demands\nextensive domain knowledge. Recent advances in LLMs show promising potential in\nreducing the expert workload. However, evaluating the quality of automatically\ngenerated scientific writing is a crucial open issue, as it requires knowledge\nof domain-specific evaluation criteria and the ability to discern expert\npreferences. Conventional automatic metrics and LLM-as-a-judge systems are\ninsufficient to grasp expert preferences and domain-specific quality standards.\nTo address this gap and support human-AI collaborative writing, we focus on\nrelated work generation, one of the most challenging scientific tasks, as an\nexemplar. We propose GREP, a multi-turn evaluation framework that integrates\nclassical related work evaluation criteria with expert-specific preferences.\nInstead of assigning a single score, our framework decomposes the evaluation\ninto fine-grained dimensions. This localized evaluation approach is further\naugmented with contrastive few-shot examples to provide detailed contextual\nguidance for the evaluation dimensions. The design principles allow our\nframework to deliver cardinal assessment of quality, which can facilitate\nbetter post-training compared to ordinal preference data. For better\naccessibility, we design two variants of GREP: a more precise variant with\nproprietary LLMs as evaluators, and a cheaper alternative with open-weight\nLLMs. Empirical investigation reveals that our framework is able to assess the\nquality of related work sections in a much more robust manner compared to\nstandard LLM judges, reflects natural scenarios of scientific writing, and\nbears a strong correlation with the human expert assessment. We also observe\nthat generations from state-of-the-art LLMs struggle to satisfy validation\nconstraints of a suitable related work section. They (mostly) fail to improve\nbased on feedback as well.", "published": "2025-08-11 13:08:07", "link": "http://arxiv.org/abs/2508.07955v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Challenges and opportunities in portraying emotion in generated sign language", "abstract": "Non-manual signals in sign languages continue to be a challenge for signing\navatars. More specifically, emotional content has been difficult to incorporate\nbecause of a lack of a standard method of specifying the avatar's emotional\nstate. This paper explores the application of an intuitive two-parameter\nrepresentation for emotive non-manual signals to the Paula signing avatar that\nshows promise for facilitating the linguistic specification of emotional facial\nexpressions in a more coherent manner than previous methods. Users can apply\nthese parameters to control Paula's emotional expressions through a textual\nrepresentation called the EASIER notation. The representation can allow avatars\nto express more nuanced emotional states using two numerical parameters. It\nalso has the potential to enable more consistent specification of emotional\nnon-manual signals in linguistic annotations which drive signing avatars.", "published": "2025-08-11 12:52:39", "link": "http://arxiv.org/abs/2508.07937v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tailored Emotional LLM-Supporter: Enhancing Cultural Sensitivity", "abstract": "Large language models (LLMs) show promise in offering emotional support and\ngenerating empathetic responses for individuals in distress, but their ability\nto deliver culturally sensitive support remains underexplored due to lack of\nresources. In this work, we introduce CultureCare, the first dataset designed\nfor this task, spanning four cultures and including 1729 distress messages,\n1523 cultural signals, and 1041 support strategies with fine-grained emotional\nand cultural annotations. Leveraging CultureCare, we (i) develop and test four\nadaptation strategies for guiding three state-of-the-art LLMs toward culturally\nsensitive responses; (ii) conduct comprehensive evaluations using LLM judges,\nin-culture human annotators, and clinical psychologists; (iii) show that\nadapted LLMs outperform anonymous online peer responses, and that simple\ncultural role-play is insufficient for cultural sensitivity; and (iv) explore\nthe application of LLMs in clinical training, where experts highlight their\npotential in fostering cultural competence in future therapists.", "published": "2025-08-11 12:17:58", "link": "http://arxiv.org/abs/2508.07902v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-shot Cross-lingual Aspect-Based Sentiment Analysis with Sequence-to-Sequence Models", "abstract": "Aspect-based sentiment analysis (ABSA) has received substantial attention in\nEnglish, yet challenges remain for low-resource languages due to the scarcity\nof labelled data. Current cross-lingual ABSA approaches often rely on external\ntranslation tools and overlook the potential benefits of incorporating a small\nnumber of target language examples into training. In this paper, we evaluate\nthe effect of adding few-shot target language examples to the training set\nacross four ABSA tasks, six target languages, and two sequence-to-sequence\nmodels. We show that adding as few as ten target language examples\nsignificantly improves performance over zero-shot settings and achieves a\nsimilar effect to constrained decoding in reducing prediction errors.\nFurthermore, we demonstrate that combining 1,000 target language examples with\nEnglish data can even surpass monolingual baselines. These findings offer\npractical insights for improving cross-lingual ABSA in low-resource and\ndomain-specific settings, as obtaining ten high-quality annotated examples is\nboth feasible and highly effective.", "published": "2025-08-11 11:31:37", "link": "http://arxiv.org/abs/2508.07866v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Czech Aspect-Based Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis\ntask that aims to identify sentiment toward specific aspects of an entity.\nWhile large language models (LLMs) have shown strong performance in various\nnatural language processing (NLP) tasks, their capabilities for Czech ABSA\nremain largely unexplored. In this work, we conduct a comprehensive evaluation\nof 19 LLMs of varying sizes and architectures on Czech ABSA, comparing their\nperformance in zero-shot, few-shot, and fine-tuning scenarios. Our results show\nthat small domain-specific models fine-tuned for ABSA outperform\ngeneral-purpose LLMs in zero-shot and few-shot settings, while fine-tuned LLMs\nachieve state-of-the-art results. We analyze how factors such as\nmultilingualism, model size, and recency influence performance and present an\nerror analysis highlighting key challenges, particularly in aspect term\nprediction. Our findings provide insights into the suitability of LLMs for\nCzech ABSA and offer guidance for future research in this area.", "published": "2025-08-11 11:24:57", "link": "http://arxiv.org/abs/2508.07860v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs for Law: Evaluating Legal-Specific LLMs on Contract Understanding", "abstract": "Despite advances in legal NLP, no comprehensive evaluation covering multiple\nlegal-specific LLMs currently exists for contract classification tasks in\ncontract understanding. To address this gap, we present an evaluation of 10\nlegal-specific LLMs on three English language contract understanding tasks and\ncompare them with 7 general-purpose LLMs. The results show that legal-specific\nLLMs consistently outperform general-purpose models, especially on tasks\nrequiring nuanced legal understanding. Legal-BERT and Contracts-BERT establish\nnew SOTAs on two of the three tasks, despite having 69% fewer parameters than\nthe best-performing general-purpose LLM. We also identify CaseLaw-BERT and\nLexLM as strong additional baselines for contract understanding. Our results\nprovide a holistic evaluation of legal-specific LLMs and will facilitate the\ndevelopment of more accurate contract understanding systems.", "published": "2025-08-11 11:08:32", "link": "http://arxiv.org/abs/2508.07849v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models as Expert Annotators", "abstract": "Textual data annotation, the process of labeling or tagging text with\nrelevant information, is typically costly, time-consuming, and labor-intensive.\nWhile large language models (LLMs) have demonstrated their potential as direct\nalternatives to human annotators for general domains natural language\nprocessing (NLP) tasks, their effectiveness on annotation tasks in domains\nrequiring expert knowledge remains underexplored. In this paper, we\ninvestigate: whether top-performing LLMs, which might be perceived as having\nexpert-level proficiency in academic and professional benchmarks, can serve as\ndirect alternatives to human expert annotators? To this end, we evaluate both\nindividual LLMs and multi-agent approaches across three highly specialized\ndomains: finance, biomedicine, and law. Specifically, we propose a multi-agent\ndiscussion framework to simulate a group of human annotators, where LLMs are\ntasked to engage in discussions by considering others' annotations and\njustifications before finalizing their labels. Additionally, we incorporate\nreasoning models (e.g., o3-mini) to enable a more comprehensive comparison. Our\nempirical results reveal that: (1) Individual LLMs equipped with inference-time\ntechniques (e.g., chain-of-thought (CoT), self-consistency) show only marginal\nor even negative performance gains, contrary to prior literature suggesting\ntheir broad effectiveness. (2) Overall, reasoning models do not demonstrate\nstatistically significant improvements over non-reasoning models in most\nsettings. This suggests that extended long CoT provides relatively limited\nbenefits for data annotation in specialized domains. (3) Certain model\nbehaviors emerge in the multi-agent discussion environment. For instance,\nClaude 3.7 Sonnet with thinking rarely changes its initial annotations, even\nwhen other agents provide correct annotations or valid reasoning.", "published": "2025-08-11 10:19:10", "link": "http://arxiv.org/abs/2508.07827v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Compositional Approaches for Focus and Sentiment Analysis", "abstract": "This paper summarizes the results of evaluating a compositional approach for\nFocus Analysis (FA) in Linguistics and Sentiment Analysis (SA) in Natural\nLanguage Processing (NLP). While quantitative evaluations of compositional and\nnon-compositional approaches in SA exist in NLP, similar quantitative\nevaluations are very rare in FA in Linguistics that deal with linguistic\nexpressions representing focus or emphasis such as \"it was John who left\". We\nfill this gap in research by arguing that compositional rules in SA also apply\nto FA because FA and SA are closely related meaning that SA is part of FA. Our\ncompositional approach in SA exploits basic syntactic rules such as rules of\nmodification, coordination, and negation represented in the formalism of\nUniversal Dependencies (UDs) in English and applied to words representing\nsentiments from sentiment dictionaries. Some of the advantages of our\ncompositional analysis method for SA in contrast to non-compositional analysis\nmethods are interpretability and explainability. We test the accuracy of our\ncompositional approach and compare it with a non-compositional approach VADER\nthat uses simple heuristic rules to deal with negation, coordination and\nmodification. In contrast to previous related work that evaluates\ncompositionality in SA on long reviews, this study uses more appropriate\ndatasets to evaluate compositionality. In addition, we generalize the results\nof compositional approaches in SA to compositional approaches in FA.", "published": "2025-08-11 09:52:41", "link": "http://arxiv.org/abs/2508.07810v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can You Trick the Grader? Adversarial Persuasion of LLM Judges", "abstract": "As large language models take on growing roles as automated evaluators in\npractical settings, a critical question arises: Can individuals persuade an LLM\njudge to assign unfairly high scores? This study is the first to reveal that\nstrategically embedded persuasive language can bias LLM judges when scoring\nmathematical reasoning tasks, where correctness should be independent of\nstylistic variation. Grounded in Aristotle's rhetorical principles, we\nformalize seven persuasion techniques (Majority, Consistency, Flattery,\nReciprocity, Pity, Authority, Identity) and embed them into otherwise identical\nresponses. Across six math benchmarks, we find that persuasive language leads\nLLM judges to assign inflated scores to incorrect solutions, by up to 8% on\naverage, with Consistency causing the most severe distortion. Notably,\nincreasing model size does not substantially mitigate this vulnerability.\nFurther analysis demonstrates that combining multiple persuasion techniques\namplifies the bias, and pairwise evaluation is likewise susceptible. Moreover,\nthe persuasive effect persists under counter prompting strategies, highlighting\na critical vulnerability in LLM-as-a-Judge pipelines and underscoring the need\nfor robust defenses against persuasion-based attacks.", "published": "2025-08-11 09:45:02", "link": "http://arxiv.org/abs/2508.07805v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts", "abstract": "The Mixture of Experts (MoE) architecture is a cornerstone of modern\nstate-of-the-art (SOTA) large language models (LLMs). MoE models facilitate\nscalability by enabling sparse parameter activation. However, traditional MoE\narchitecture uses homogeneous experts of a uniform size, activating a fixed\nnumber of parameters irrespective of input complexity and thus limiting\ncomputational efficiency. To overcome this limitation, we introduce Grove MoE,\na novel architecture incorporating experts of varying sizes, inspired by the\nheterogeneous big.LITTLE CPU architecture. This architecture features novel\nadjugate experts with a dynamic activation mechanism, enabling model capacity\nexpansion while maintaining manageable computational overhead. Building on this\narchitecture, we present GroveMoE-Base and GroveMoE-Inst, 33B-parameter LLMs\ndeveloped by applying an upcycling strategy to the Qwen3-30B-A3B-Base model\nduring mid-training and post-training. GroveMoE models dynamically activate\n3.14-3.28B parameters based on token complexity and achieve performance\ncomparable to SOTA open-source models of similar or even larger size.", "published": "2025-08-11 09:15:36", "link": "http://arxiv.org/abs/2508.07785v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SASST: Leveraging Syntax-Aware Chunking and LLMs for Simultaneous Speech Translation", "abstract": "This work proposes a grammar-based chunking strategy that segments input\nstreams into semantically complete units by parsing dependency relations (e.g.,\nnoun phrase boundaries, verb-object structures) and punctuation features. The\nmethod ensures chunk coherence and minimizes semantic fragmentation. Building\non this mechanism, we present SASST (Syntax-Aware Simultaneous Speech\nTranslation), an end-to-end framework integrating frozen Whisper encoder and\ndecoder-only LLM. The unified architecture dynamically outputs translation\ntokens or <WAIT> symbols to jointly optimize translation timing and content,\nwith target-side reordering addressing word-order divergence. Experiments on\nCoVoST2 multilingual corpus En-{De, Zh, Ja} demonstrate significant translation\nquality improvements across languages and validate the effectiveness of\nsyntactic structures in LLM-driven SimulST systems.", "published": "2025-08-11 09:13:35", "link": "http://arxiv.org/abs/2508.07781v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pareto Multi-Objective Alignment for Language Models", "abstract": "Large language models (LLMs) are increasingly deployed in real-world\napplications that require careful balancing of multiple, often conflicting,\nobjectives, such as informativeness versus conciseness, or helpfulness versus\ncreativity. However, current alignment methods, primarily based on RLHF,\noptimize LLMs toward a single reward function, resulting in rigid behavior that\nfails to capture the complexity and diversity of human preferences. This\nlimitation hinders the adaptability of LLMs to practical scenarios, making\nmulti-objective alignment (MOA) a critical yet underexplored area. To bridge\nthis gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and\ncomputationally efficient algorithm designed explicitly for MOA in LLMs. In\ncontrast to computationally prohibitive multi-objective optimization (MOO)\nmethods, PAMA transforms multi-objective RLHF into a convex optimization with a\nclosed-form solution, significantly enhancing scalability. Traditional MOO\napproaches suffer from prohibitive O(n^2*d) complexity, where d represents the\nnumber of model parameters, typically in the billions for LLMs, rendering\ndirect optimization infeasible. PAMA reduces this complexity to O(n) where n is\nthe number of objectives, enabling optimization to be completed within\nmilliseconds. We provide theoretical guarantees that PAMA converges to a Pareto\nstationary point, where no objective can be improved without degrading at least\none other. Extensive experiments across language models ranging from 125M to 7B\nparameters demonstrate PAMA's robust and effective MOA capabilities, aligning\nwith its theoretical advantages. PAMA provides a highly efficient solution to\nthe MOA problem that was previously considered intractable, offering a\npractical and theoretically grounded approach to aligning LLMs with diverse\nhuman values, paving the way for versatile and adaptable real-world AI\ndeployments.", "published": "2025-08-11 08:54:14", "link": "http://arxiv.org/abs/2508.07768v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Exploring Causal Effect of Social Bias on Faithfulness Hallucinations in Large Language Models", "abstract": "Large language models (LLMs) have achieved remarkable success in various\ntasks, yet they remain vulnerable to faithfulness hallucinations, where the\noutput does not align with the input. In this study, we investigate whether\nsocial bias contributes to these hallucinations, a causal relationship that has\nnot been explored. A key challenge is controlling confounders within the\ncontext, which complicates the isolation of causality between bias states and\nhallucinations. To address this, we utilize the Structural Causal Model (SCM)\nto establish and validate the causality and design bias interventions to\ncontrol confounders. In addition, we develop the Bias Intervention Dataset\n(BID), which includes various social biases, enabling precise measurement of\ncausal effects. Experiments on mainstream LLMs reveal that biases are\nsignificant causes of faithfulness hallucinations, and the effect of each bias\nstate differs in direction. We further analyze the scope of these causal\neffects across various models, specifically focusing on unfairness\nhallucinations, which are primarily targeted by social bias, revealing the\nsubtle yet significant causal effect of bias on hallucination generation.", "published": "2025-08-11 08:34:28", "link": "http://arxiv.org/abs/2508.07753v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment", "abstract": "Alignment methodologies have emerged as a critical pathway for enhancing\nlanguage model alignment capabilities. While SFT (supervised fine-tuning)\naccelerates convergence through direct token-level loss intervention, its\nefficacy is constrained by offline policy trajectory. In contrast,\nRL(reinforcement learning) facilitates exploratory policy optimization, but\nsuffers from low sample efficiency and stringent dependency on high-quality\nbase models. To address these dual challenges, we propose GRAO (Group Relative\nAlignment Optimization), a unified framework that synergizes the respective\nstrengths of SFT and RL through three key innovations: 1) A multi-sample\ngeneration strategy enabling comparative quality assessment via reward\nfeedback; 2) A novel Group Direct Alignment Loss formulation leveraging\nintra-group relative advantage weighting; 3) Reference-aware parameter updates\nguided by pairwise preference dynamics. Our theoretical analysis establishes\nGRAO's convergence guarantees and sample efficiency advantages over\nconventional approaches. Comprehensive evaluations across complex human\nalignment tasks demonstrate GRAO's superior performance, achieving\n57.70\\%,17.65\\% 7.95\\% and 5.18\\% relative improvements over SFT, DPO, PPO and\nGRPO baselines respectively. This work provides both a theoretically grounded\nalignment framework and empirical evidence for efficient capability evolution\nin language models.", "published": "2025-08-11 08:28:47", "link": "http://arxiv.org/abs/2508.07750v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction", "abstract": "Transformer-based models primarily rely on Next Token Prediction (NTP), which\npredicts the next token in a sequence based on the preceding context. However,\nNTP's focus on single-token prediction often limits a model's ability to plan\nahead or maintain long-range coherence, raising questions about how well LLMs\ncan predict longer contexts, such as full sentences within structured\ndocuments. While NTP encourages local fluency, it provides no explicit\nincentive to ensure global coherence across sentence boundaries-an essential\nskill for reconstructive or discursive tasks. To investigate this, we evaluate\nthree commercial LLMs (GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) on\nMasked Sentence Prediction (MSP) - the task of infilling a randomly removed\nsentence - from three domains: ROCStories (narrative), Recipe1M (procedural),\nand Wikipedia (expository). We assess both fidelity (similarity to the original\nsentence) and cohesiveness (fit within the surrounding context). Our key\nfinding reveals that commercial LLMs, despite their superlative performance in\nother tasks, are poor at predicting masked sentences in low-structured domains,\nhighlighting a gap in current model capabilities.", "published": "2025-08-11 07:25:50", "link": "http://arxiv.org/abs/2508.07702v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval", "abstract": "Tool learning has emerged as a promising paradigm for large language models\n(LLMs) to solve many real-world tasks. Nonetheless, with the tool repository\nrapidly expanding, it is impractical to contain all tools within the limited\ninput length of LLMs. To alleviate these issues, researchers have explored\nincorporating a tool retrieval module to select the most relevant tools or\nrepresent tools as unique tokens within LLM parameters. However, most\nstate-of-the-art methods are under transductive settings, assuming all tools\nhave been observed during training. Such a setting deviates from reality as the\nreal-world tool repository is evolving and incorporates new tools frequently.\nWhen dealing with these unseen tools, which refer to tools not encountered\nduring the training phase, these methods are limited by two key issues,\nincluding the large distribution shift and the vulnerability of\nsimilarity-based retrieval. To this end, inspired by human cognitive processes\nof mastering unseen tools through discovering and applying the logical\ninformation from prior experience, we introduce a novel Logic-Guided Semantic\nBridging framework for inductive tool retrieval, namely, LoSemB, which aims to\nmine and transfer latent logical information for inductive tool retrieval\nwithout costly retraining. Specifically, LoSemB contains a logic-based\nembedding alignment module to mitigate distribution shifts and implements a\nrelational augmented retrieval mechanism to reduce the vulnerability of\nsimilarity-based retrieval. Extensive experiments demonstrate that LoSemB\nachieves advanced performance in inductive settings while maintaining desirable\neffectiveness in the transductive setting.", "published": "2025-08-11 07:07:18", "link": "http://arxiv.org/abs/2508.07690v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GLiClass: Generalist Lightweight Model for Sequence Classification Tasks", "abstract": "Classification is one of the most widespread tasks in AI applications,\nserving often as the first step in filtering, sorting, and categorizing data.\nSince modern AI systems must handle large volumes of input data and early\npipeline stages can propagate errors downstream, achieving high efficiency and\naccuracy is critical. Moreover, classification requirements can change\ndynamically based on user needs, necessitating models with strong zero-shot\ncapabilities. While generative LLMs have become mainstream for zero-shot\nclassification due to their versatility, they suffer from inconsistent\ninstruction following and computational inefficiency. Cross-encoders, commonly\nused as rerankers in RAG pipelines, face a different bottleneck: they must\nprocess text-label pairs sequentially, significantly reducing efficiency with\nlarge label sets. Embedding-based approaches offer good efficiency but struggle\nwith complex scenarios involving logical and semantic constraints. We propose\nGLiClass, a novel method that adapts the GLiNER architecture for sequence\nclassification tasks. Our approach achieves strong accuracy and efficiency\ncomparable to embedding-based methods, while maintaining the flexibility needed\nfor zero-shot and few-shot learning scenarios. Additionally, we adapted\nproximal policy optimization (PPO) for multi-label text classification,\nenabling training classifiers in data-sparse conditions or from human feedback.", "published": "2025-08-11 06:22:25", "link": "http://arxiv.org/abs/2508.07662v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents", "abstract": "Vision-and-Language Navigation (VLN) poses significant challenges in enabling\nagents to interpret natural language instructions and navigate complex 3D\nenvironments. While recent progress has been driven by large-scale pre-training\nand data augmentation, current methods still struggle to generalize to unseen\nscenarios, particularly when complex spatial and temporal reasoning is\nrequired. In this work, we propose SkillNav, a modular framework that\nintroduces structured, skill-based reasoning into Transformer-based VLN agents.\nOur method decomposes navigation into a set of interpretable atomic skills\n(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each\nhandled by a specialized agent. We then introduce a novel zero-shot\nVision-Language Model (VLM)-based router, which dynamically selects the most\nsuitable agent at each time step by aligning sub-goals with visual observations\nand historical actions. SkillNav achieves a new state-of-the-art performance on\nthe R2R benchmark and demonstrates strong generalization to the GSA-R2R\nbenchmark that includes novel instruction styles and unseen environments.", "published": "2025-08-11 05:50:30", "link": "http://arxiv.org/abs/2508.07642v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information", "abstract": "We introduce InterChart, a diagnostic benchmark that evaluates how well\nvision-language models (VLMs) reason across multiple related charts, a task\ncentral to real-world applications such as scientific reporting, financial\nanalysis, and public policy dashboards. Unlike prior benchmarks focusing on\nisolated, visually uniform charts, InterChart challenges models with diverse\nquestion types ranging from entity inference and trend correlation to numerical\nestimation and abstract multi-step reasoning grounded in 2-3 thematically or\nstructurally related charts. We organize the benchmark into three tiers of\nincreasing difficulty: (1) factual reasoning over individual charts, (2)\nintegrative analysis across synthetically aligned chart sets, and (3) semantic\ninference over visually complex, real-world chart pairs. Our evaluation of\nstate-of-the-art open and closed-source VLMs reveals consistent and steep\naccuracy declines as chart complexity increases. We find that models perform\nbetter when we decompose multi-entity charts into simpler visual units,\nunderscoring their struggles with cross-chart integration. By exposing these\nsystematic limitations, InterChart provides a rigorous framework for advancing\nmultimodal reasoning in complex, multi-visual environments.", "published": "2025-08-11 05:19:23", "link": "http://arxiv.org/abs/2508.07630v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "I.2.7; I.2.10; I.4.10; I.7.5"], "primary_category": "cs.CL"}
{"title": "Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization", "abstract": "We present Klear-Reasoner, a model with long reasoning capabilities that\ndemonstrates careful deliberation during problem solving, achieving outstanding\nperformance across multiple benchmarks. Although there are already many\nexcellent works related to inference models in the current community, there are\nstill many problems with reproducing high-performance inference models due to\nincomplete disclosure of training details. This report provides an in-depth\nanalysis of the reasoning model, covering the entire post-training workflow\nfrom data preparation and long Chain-of-Thought supervised fine-tuning (long\nCoT SFT) to reinforcement learning (RL), along with detailed ablation studies\nfor each experimental component. For SFT data, our experiments show that a\nsmall number of high-quality data sources are more effective than a large\nnumber of diverse data sources, and that difficult samples can achieve better\nresults without accuracy filtering. In addition, we investigate two key issues\nwith current clipping mechanisms in RL: Clipping suppresses critical\nexploration signals and ignores suboptimal trajectories. To address these\nchallenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)\nthat gently backpropagates gradients from clipped tokens. GPPO not only\nenhances the model's exploration capacity but also improves its efficiency in\nlearning from negative samples. Klear-Reasoner exhibits exceptional reasoning\nabilities in mathematics and programming, scoring 90.5\\% on AIME 2024, 83.2\\%\non AIME 2025, 66.0\\% on LiveCodeBench V5 and 58.1\\% on LiveCodeBench V6.", "published": "2025-08-11 05:17:51", "link": "http://arxiv.org/abs/2508.07629v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ThinkTuning: Instilling Cognitive Reflections without Distillation", "abstract": "Recent advances in test-time scaling have led to the emergence of thinking\nLLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL\ndrives this self-improvement paradigm, a recent study (Gandhi et al., 2025)\nshows that RL alone does not truly instill these new reasoning abilities - it\nmerely draws out behaviors already present in the base models. This raises a\nquestion: How can we train the models that don't exhibit such thinking behavior\nto develop it in the first place? To this end, we propose ThinkTuning, a\nGRPO-based interactive training approach where we augment the rollouts of a\nstudent model with the guidance from a teacher model. A simple idea from\nclassroom practice inspires our method: a teacher poses a problem, lets the\nstudent try an answer, then gives corrective feedback -- enough to point the\nmind in the right direction and then show the solution. Each piece of feedback\nreshapes the student's thoughts, leading them to arrive at the correct\nsolution. Similarly, we find that this type of implicit supervision through\nfeedback from a teacher model of the same size improves the reasoning\ncapabilities of the student model. In particular, on average, our method shows\na 3.85% improvement over zero-shot baselines across benchmarks, and on\nMATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements\nover the vanilla-GRPO baseline. Source code is available at\nhttps://github.com/3rdAT/ThinkTuning.", "published": "2025-08-11 04:51:43", "link": "http://arxiv.org/abs/2508.07616v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements", "abstract": "Although the LLM-based in-context learning (ICL) paradigm has demonstrated\nconsiderable success across various natural language processing tasks, it\nencounters challenges in event detection. This is because LLMs lack an accurate\nunderstanding of event triggers and tend to make over-interpretation, which\ncannot be effectively corrected through in-context examples alone. In this\npaper, we focus on the most challenging one-shot setting and propose KeyCP++, a\nkeyword-centric chain-of-thought prompting approach. KeyCP++ addresses the\nweaknesses of conventional ICL by automatically annotating the logical gaps\nbetween input text and detection results for the demonstrations. Specifically,\nto generate in-depth and meaningful rationale, KeyCP++ constructs a trigger\ndiscrimination prompting template. It incorporates the exemplary triggers\n(a.k.a keywords) into the prompt as the anchor to simply trigger profiling, let\nLLM propose candidate triggers, and justify each candidate. These\npropose-and-judge rationales help LLMs mitigate over-reliance on the keywords\nand promote detection rule learning. Extensive experiments demonstrate the\neffectiveness of our approach, showcasing significant advancements in one-shot\nevent detection.", "published": "2025-08-11 03:58:35", "link": "http://arxiv.org/abs/2508.07598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IBPS: Indian Bail Prediction System", "abstract": "Bail decisions are among the most frequently adjudicated matters in Indian\ncourts, yet they remain plagued by subjectivity, delays, and inconsistencies.\nWith over 75% of India's prison population comprising undertrial prisoners,\nmany from socioeconomically disadvantaged backgrounds, the lack of timely and\nfair bail adjudication exacerbates human rights concerns and contributes to\nsystemic judicial backlog. In this paper, we present the Indian Bail Prediction\nSystem (IBPS), an AI-powered framework designed to assist in bail\ndecision-making by predicting outcomes and generating legally sound rationales\nbased solely on factual case attributes and statutory provisions. We curate and\nrelease a large-scale dataset of 150,430 High Court bail judgments, enriched\nwith structured annotations such as age, health, criminal history, crime\ncategory, custody duration, statutes, and judicial reasoning. We fine-tune a\nlarge language model using parameter-efficient techniques and evaluate its\nperformance across multiple configurations, with and without statutory context,\nand with RAG. Our results demonstrate that models fine-tuned with statutory\nknowledge significantly outperform baselines, achieving strong accuracy and\nexplanation quality, and generalize well to a test set independently annotated\nby legal experts. IBPS offers a transparent, scalable, and reproducible\nsolution to support data-driven legal assistance, reduce bail delays, and\npromote procedural fairness in the Indian judicial system.", "published": "2025-08-11 03:44:17", "link": "http://arxiv.org/abs/2508.07592v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR", "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npowerful paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). Unlike traditional RL approaches, RLVR leverages rule-based\nfeedback to guide LLMs in generating and refining complex reasoning chains -- a\nprocess critically dependent on effective exploration strategies. While prior\nwork has demonstrated RLVR's empirical success, the fundamental mechanisms\ngoverning LLMs' exploration behaviors remain underexplored. This technical\nreport presents a systematic investigation of exploration capacities in RLVR,\ncovering four main aspects: (1) exploration space shaping, where we develop\nquantitative metrics to characterize LLMs' capability boundaries; (2)\nentropy-performance exchange, analyzed across training stages, individual\ninstances, and token-level patterns; and (3) RL performance optimization,\nexamining methods to effectively translate exploration gains into measurable\nimprovements. By unifying previously identified insights with new empirical\nevidence, this work aims to provide a foundational framework for advancing RLVR\nsystems.", "published": "2025-08-11 01:26:16", "link": "http://arxiv.org/abs/2508.07534v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI", "abstract": "What if the patterns hidden within dialogue reveal more about communication\nthan the words themselves? We introduce Conversational DNA, a novel visual\nlanguage that treats any dialogue -- whether between humans, between human and\nAI, or among groups -- as a living system with interpretable structure that can\nbe visualized, compared, and understood. Unlike traditional conversation\nanalysis that reduces rich interaction to statistical summaries, our approach\nreveals the temporal architecture of dialogue through biological metaphors.\nLinguistic complexity flows through strand thickness, emotional trajectories\ncascade through color gradients, conversational relevance forms through\nconnecting elements, and topic coherence maintains structural integrity through\nhelical patterns. Through exploratory analysis of therapeutic conversations and\nhistorically significant human-AI dialogues, we demonstrate how this\nvisualization approach reveals interaction patterns that traditional methods\nmiss. Our work contributes a new creative framework for understanding\ncommunication that bridges data visualization, human-computer interaction, and\nthe fundamental question of what makes dialogue meaningful in an age where\nhumans increasingly converse with artificial minds.", "published": "2025-08-11 00:43:35", "link": "http://arxiv.org/abs/2508.07520v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews", "abstract": "Word clouds are a common way to summarize qualitative interviews, yet\ntraditional frequency-based methods often fail in conversational contexts: they\nsurface filler words, ignore paraphrase, and fragment semantically related\nideas. This limits their usefulness in early-stage analysis, when researchers\nneed fast, interpretable overviews of what participant actually said. We\nintroduce ThemeClouds, an open-source visualization tool that uses large\nlanguage models (LLMs) to generate thematic, participant-weighted word clouds\nfrom dialogue transcripts. The system prompts an LLM to identify concept-level\nthemes across a corpus and then counts how many unique participants mention\neach topic, yielding a visualization grounded in breadth of mention rather than\nraw term frequency. Researchers can customize prompts and visualization\nparameters, providing transparency and control. Using interviews from a user\nstudy comparing five recording-device configurations (31 participants; 155\ntranscripts, Whisper ASR), our approach surfaces more actionable device\nconcerns than frequency clouds and topic-modeling baselines (e.g., LDA,\nBERTopic). We discuss design trade-offs for integrating LLM assistance into\nqualitative workflows, implications for interpretability and researcher agency,\nand opportunities for interactive analyses such as per-condition contrasts\n(``diff clouds'').", "published": "2025-08-11 00:27:52", "link": "http://arxiv.org/abs/2508.07517v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Augmenting Bias Detection in LLMs Using Topological Data Analysis", "abstract": "Recently, many bias detection methods have been proposed to determine the\nlevel of bias a large language model captures. However, tests to identify which\nparts of a large language model are responsible for bias towards specific\ngroups remain underdeveloped. In this study, we present a method using\ntopological data analysis to identify which heads in GPT-2 contribute to the\nmisrepresentation of identity groups present in the StereoSet dataset. We find\nthat biases for particular categories, such as gender or profession, are\nconcentrated in attention heads that act as hot spots. The metric we propose\ncan also be used to determine which heads capture bias for a specific group\nwithin a bias category, and future work could extend this method to help\nde-bias large language models.", "published": "2025-08-11 00:19:47", "link": "http://arxiv.org/abs/2508.07516v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cut2Next: Generating Next Shot via In-Context Tuning", "abstract": "Effective multi-shot generation demands purposeful, film-like transitions and\nstrict cinematic continuity. Current methods, however, often prioritize basic\nvisual consistency, neglecting crucial editing patterns (e.g., shot/reverse\nshot, cutaways) that drive narrative flow for compelling storytelling. This\nyields outputs that may be visually coherent but lack narrative sophistication\nand true cinematic integrity. To bridge this, we introduce Next Shot Generation\n(NSG): synthesizing a subsequent, high-quality shot that critically conforms to\nprofessional editing patterns while upholding rigorous cinematic continuity.\nOur framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs\nin-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This\nstrategy uses Relational Prompts to define overall context and inter-shot\nediting styles. Individual Prompts then specify per-shot content and\ncinematographic attributes. Together, these guide Cut2Next to generate\ncinematically appropriate next shots. Architectural innovations, Context-Aware\nCondition Injection (CACI) and Hierarchical Attention Mask (HAM), further\nintegrate these diverse signals without introducing new parameters. We\nconstruct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with\nhierarchical prompts, and introduce CutBench for evaluation. Experiments show\nCut2Next excels in visual consistency and text fidelity. Crucially, user\nstudies reveal a strong preference for Cut2Next, particularly for its adherence\nto intended editing patterns and overall cinematic continuity, validating its\nability to generate high-quality, narratively expressive, and cinematically\ncoherent subsequent shots.", "published": "2025-08-11 17:56:59", "link": "http://arxiv.org/abs/2508.08244v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "VGGSounder: Audio-Visual Evaluations for Foundation Models", "abstract": "The emergence of audio-visual foundation models underscores the importance of\nreliably assessing their multi-modal understanding. The VGGSounder dataset is\ncommonly used as a benchmark for evaluation audio-visual classification.\nHowever, our analysis identifies several limitations of VGGSounder, including\nincomplete labelling, partially overlapping classes, and misaligned modalities.\nThese lead to distorted evaluations of auditory and visual capabilities. To\naddress these limitations, we introduce VGGSounder, a comprehensively\nre-annotated, multi-label test set that extends VGGSound and is specifically\ndesigned to evaluate audio-visual foundation models. VGGSounder features\ndetailed modality annotations, enabling precise analyses of modality-specific\nperformance. Furthermore, we reveal model limitations by analysing performance\ndegradation when adding another input modality with our new modality confusion\nmetric.", "published": "2025-08-11 17:53:23", "link": "http://arxiv.org/abs/2508.08237v1", "categories": ["cs.MM", "cs.AI", "cs.SD"], "primary_category": "cs.MM"}
{"title": "LL3M: Large Language 3D Modelers", "abstract": "We present LL3M, a multi-agent system that leverages pretrained large\nlanguage models (LLMs) to generate 3D assets by writing interpretable Python\ncode in Blender. We break away from the typical generative approach that learns\nfrom a collection of 3D data. Instead, we reformulate shape generation as a\ncode-writing task, enabling greater modularity, editability, and integration\nwith artist workflows. Given a text prompt, LL3M coordinates a team of\nspecialized LLM agents to plan, retrieve, write, debug, and refine Blender\nscripts that generate and edit geometry and appearance. The generated code\nworks as a high-level, interpretable, human-readable, well-documented\nrepresentation of scenes and objects, making full use of sophisticated Blender\nconstructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse,\nunconstrained shapes, materials, and scenes. This code presents many avenues\nfor further agent and human editing and experimentation via code tweaks or\nprocedural parameters. This medium naturally enables a co-creative loop in our\nsystem: agents can automatically self-critique using code and visuals, while\niterative user instructions provide an intuitive way to refine assets. A shared\ncode context across agents enables awareness of previous attempts, and a\nretrieval-augmented generation knowledge base built from Blender API\ndocumentation, BlenderRAG, equips agents with examples, types, and functions\nempowering advanced modeling operations and code correctness. We demonstrate\nthe effectiveness of LL3M across diverse shape categories, style and material\nedits, and user-driven refinements. Our experiments showcase the power of code\nas a generative and interpretable medium for 3D asset creation. Our project\npage is at https://threedle.github.io/ll3m.", "published": "2025-08-11 17:48:02", "link": "http://arxiv.org/abs/2508.08228v1", "categories": ["cs.GR", "cs.AI"], "primary_category": "cs.GR"}
{"title": "OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution", "abstract": "Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM)\ngenerative models show promising potential for one-step Real-World Image\nSuper-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a\nLow-Quality (LQ) image latent distribution at the initial timestep. However, a\nfundamental gap exists between the LQ image latent distribution and the\nGaussian noisy latent distribution, limiting the effective utilization of\ngenerative priors. We observe that the noisy latent distribution at DDPM/FM\nmid-timesteps aligns more closely with the LQ image latent distribution. Based\non this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a\nuniversal framework applicable to DDPM/FM-based generative models. OMGSR\ninjects the LQ image latent distribution at a pre-computed mid-timestep,\nincorporating the proposed Latent Distribution Refinement loss to alleviate the\nlatent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to\neliminate checkerboard artifacts in image generation. Within this framework, we\ninstantiate OMGSR for DDPM/FM-based generative models with two variants:\nOMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate\nthat OMGSR-S/F achieves balanced/excellent performance across quantitative and\nqualitative metrics at 512-resolution. Notably, OMGSR-F establishes\noverwhelming dominance in all reference metrics. We further train a\n1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which\nyields excellent results, especially in the details of the image generation. We\nalso generate 2k-resolution images by the 1k-resolution OMGSR-F using our\ntwo-stage Tiled VAE & Diffusion.", "published": "2025-08-11 17:44:59", "link": "http://arxiv.org/abs/2508.08227v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent", "abstract": "Transformers have demonstrated remarkable capabilities in multi-step\nreasoning tasks. However, understandings of the underlying mechanisms by which\nthey acquire these abilities through training remain limited, particularly from\na theoretical standpoint. This work investigates how transformers learn to\nsolve symbolic multi-step reasoning problems through chain-of-thought\nprocesses, focusing on path-finding in trees. We analyze two intertwined tasks:\na backward reasoning task, where the model outputs a path from a goal node to\nthe root, and a more complex forward reasoning task, where the model implements\ntwo-stage reasoning by first identifying the goal-to-root path and then\nreversing it to produce the root-to-goal path. Our theoretical analysis,\ngrounded in the dynamics of gradient descent, shows that trained one-layer\ntransformers can provably solve both tasks with generalization guarantees to\nunseen trees. In particular, our multi-phase training dynamics for forward\nreasoning elucidate how different attention heads learn to specialize and\ncoordinate autonomously to solve the two subtasks in a single autoregressive\npath. These results provide a mechanistic explanation of how trained\ntransformers can implement sequential algorithmic procedures. Moreover, they\noffer insights into the emergence of reasoning abilities, suggesting that when\ntasks are structured to take intermediate chain-of-thought steps, even shallow\nmulti-head transformers can effectively solve problems that would otherwise\nrequire deeper architectures.", "published": "2025-08-11 17:40:47", "link": "http://arxiv.org/abs/2508.08222v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Street-Level AI: Are Large Language Models Ready for Real-World Judgments?", "abstract": "A surge of recent work explores the ethical and societal implications of\nlarge-scale AI models that make \"moral\" judgments. Much of this literature\nfocuses either on alignment with human judgments through various thought\nexperiments or on the group fairness implications of AI judgments. However, the\nmost immediate and likely use of AI is to help or fully replace the so-called\nstreet-level bureaucrats, the individuals deciding to allocate scarce social\nresources or approve benefits. There is a rich history underlying how\nprinciples of local justice determine how society decides on prioritization\nmechanisms in such domains. In this paper, we examine how well LLM judgments\nalign with human judgments, as well as with socially and politically determined\nvulnerability scoring systems currently used in the domain of homelessness\nresource allocation. Crucially, we use real data on those needing services\n(maintaining strict confidentiality by only using local large models) to\nperform our analyses. We find that LLM prioritizations are extremely\ninconsistent in several ways: internally on different runs, between different\nLLMs, and between LLMs and the vulnerability scoring systems. At the same time,\nLLMs demonstrate qualitative consistency with lay human judgments in pairwise\ntesting. Findings call into question the readiness of current generation AI\nsystems for naive integration in high-stakes societal decision-making.", "published": "2025-08-11 17:12:55", "link": "http://arxiv.org/abs/2508.08193v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "RedDino: A foundation model for red blood cell analysis", "abstract": "Red blood cells (RBCs) are essential to human health, and their precise\nmorphological analysis is important for diagnosing hematological disorders.\nDespite the promise of foundation models in medical diagnostics, comprehensive\nAI solutions for RBC analysis remain scarce. We present RedDino, a\nself-supervised foundation model designed for RBC image analysis. RedDino uses\nan RBC-specific adaptation of the DINOv2 self-supervised learning framework and\nis trained on a curated dataset of 1.25 million RBC images from diverse\nacquisition modalities and sources. Extensive evaluations show that RedDino\noutperforms existing state-of-the-art models on RBC shape classification.\nThrough assessments including linear probing and nearest neighbor\nclassification, we confirm its strong feature representations and\ngeneralization ability. Our main contributions are: (1) a foundation model\ntailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations\nfor RBC modeling, and (3) a detailed evaluation of generalization performance.\nRedDino addresses key challenges in computational hematology by capturing\nnuanced morphological features, advancing the development of reliable\ndiagnostic tools. The source code and pretrained models for RedDino are\navailable at https://github.com/Snarci/RedDino, and the pretrained models can\nbe downloaded from our Hugging Face collection at\nhttps://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc", "published": "2025-08-11 16:59:31", "link": "http://arxiv.org/abs/2508.08180v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision", "abstract": "Accurately grounding regions of interest (ROIs) is critical for diagnosis and\ntreatment planning in medical imaging. While multimodal large language models\n(MLLMs) combine visual perception with natural language, current\nmedical-grounding pipelines still rely on supervised fine-tuning with explicit\nspatial hints, making them ill-equipped to handle the implicit queries common\nin clinical practice. This work makes three core contributions. We first define\nUnified Medical Reasoning Grounding (UMRG), a novel vision-language task that\ndemands clinical reasoning and pixel-level grounding. Second, we release\nU-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside\nimplicit clinical queries and reasoning traces, spanning 10 modalities, 15\nsuper-categories, and 108 specific categories. Finally, we introduce\nMedReasoner, a modular framework that distinctly separates reasoning from\nsegmentation: an MLLM reasoner is optimized with reinforcement learning, while\na frozen segmentation expert converts spatial prompts into masks, with\nalignment achieved through format and accuracy rewards. MedReasoner achieves\nstate-of-the-art performance on U-MRG-14K and demonstrates strong\ngeneralization to unseen clinical queries, underscoring the significant promise\nof reinforcement learning for interpretable medical grounding.", "published": "2025-08-11 16:59:06", "link": "http://arxiv.org/abs/2508.08177v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Neural Logic Networks for Interpretable Classification", "abstract": "Traditional neural networks have an impressive classification performance,\nbut what they learn cannot be inspected, verified or extracted. Neural Logic\nNetworks on the other hand have an interpretable structure that enables them to\nlearn a logical mechanism relating the inputs and outputs with AND and OR\noperations. We generalize these networks with NOT operations and biases that\ntake into account unobserved data and develop a rigorous logical and\nprobabilistic modeling in terms of concept combinations to motivate their use.\nWe also propose a novel factorized IF-THEN rule structure for the model as well\nas a modified learning algorithm. Our method improves the state-of-the-art in\nBoolean networks discovery and is able to learn relevant, interpretable rules\nin tabular classification, notably on an example from the medical field where\ninterpretability has tangible value.", "published": "2025-08-11 16:49:56", "link": "http://arxiv.org/abs/2508.08172v1", "categories": ["cs.LG", "cs.AI", "cs.LO"], "primary_category": "cs.LG"}
{"title": "PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C", "abstract": "Python has become the dominant language for general-purpose programming, yet\nit lacks robust tools for formal verification. In contrast, programmers working\nin languages such as C benefit from mature model checkers, for example CBMC,\nwhich enable exhaustive symbolic reasoning and fault localisation. The inherent\ncomplexity of Python, coupled with the verbosity and low-level nature of\nexisting transpilers (e.g., Cython), have historically limited the\napplicability of formal verification to Python programs.\n  In this paper, we propose PyVeritas, a novel framework that leverages Large\nLanguage Models (LLMs) for high-level transpilation from Python to C, followed\nby bounded model checking and MaxSAT-based fault localisation in the generated\nC code. PyVeritas enables verification and bug localisation for Python code\nusing existing model checking tools for C. Our empirical evaluation on two\nPython benchmarks demonstrates that LLM-based transpilation can achieve a high\ndegree of accuracy, up to 80--90% for some LLMs, enabling effective development\nenvironment that supports assertion-based verification and interpretable fault\ndiagnosis for small yet non-trivial Python programs.", "published": "2025-08-11 16:49:07", "link": "http://arxiv.org/abs/2508.08171v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Can AI Explanations Make You Change Your Mind?", "abstract": "In the context of AI-based decision support systems, explanations can help\nusers to judge when to trust the AI's suggestion, and when to question it. In\nthis way, human oversight can prevent AI errors and biased decision-making.\nHowever, this rests on the assumption that users will consider explanations in\nenough detail to be able to catch such errors. We conducted an online study on\ntrust in explainable DSS, and were surprised to find that in many cases,\nparticipants spent little time on the explanation and did not always consider\nit in detail. We present an exploratory analysis of this data, investigating\nwhat factors impact how carefully study participants consider AI explanations,\nand how this in turn impacts whether they are open to changing their mind based\non what the AI suggests.", "published": "2025-08-11 16:36:20", "link": "http://arxiv.org/abs/2508.08158v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework", "abstract": "This paper introduces a novel Large Language Models (LLMs)-assisted agent\nthat automatically converts natural-language descriptions of power system\noptimization scenarios into compact, solver-ready formulations and generates\ncorresponding solutions. In contrast to approaches that rely solely on LLM to\nproduce solutions directly, the proposed method focuses on discovering a\nmathematically compatible formulation that can be efficiently solved by\noff-the-shelf optimization solvers. Directly using LLMs to produce solutions\noften leads to infeasible or suboptimal results, as these models lack the\nnumerical precision and constraint-handling capabilities of established\noptimization solvers. The pipeline integrates a domain-aware prompt and schema\nwith an LLM, enforces feasibility through systematic validation and iterative\nrepair, and returns both solver-ready models and user-facing results. Using the\nunit commitment problem as a representative case study, the agent produces\noptimal or near-optimal schedules along with the associated objective costs.\nResults demonstrate that coupling the solver with task-specific validation\nsignificantly enhances solution reliability. This work shows that combining AI\nwith established optimization frameworks bridges high-level problem\ndescriptions and executable mathematical models, enabling more efficient\ndecision-making in energy systems", "published": "2025-08-11 16:22:57", "link": "http://arxiv.org/abs/2508.08147v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models", "abstract": "The rapid growth of resource-constrained mobile platforms, including mobile\nrobots, wearable systems, and Internet-of-Things devices, has increased the\ndemand for computationally efficient neural network controllers (NNCs) that can\noperate within strict hardware limitations. While deep neural networks (DNNs)\ndemonstrate superior performance in control applications, their substantial\ncomputational complexity and memory requirements present significant barriers\nto practical deployment on edge devices. This paper introduces a comprehensive\nmodel compression methodology that leverages component-aware structured pruning\nto determine the optimal pruning magnitude for each pruning group, ensuring a\nbalance between compression and stability for NNC deployment. Our approach is\nrigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC),\na state-of-the-art model-based reinforcement learning algorithm, with a\nsystematic integration of mathematical stability guarantee properties,\nspecifically Lyapunov criteria. The key contribution of this work lies in\nproviding a principled framework for determining the theoretical limits of\nmodel compression while preserving controller stability. Experimental\nvalidation demonstrates that our methodology successfully reduces model\ncomplexity while maintaining requisite control performance and stability\ncharacteristics. Furthermore, our approach establishes a quantitative boundary\nfor safe compression ratios, enabling practitioners to systematically determine\nthe maximum permissible model reduction before violating critical stability\nproperties, thereby facilitating the confident deployment of compressed NNCs in\nresource-limited environments.", "published": "2025-08-11 16:16:51", "link": "http://arxiv.org/abs/2508.08144v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "abstract": "Conducting a comprehensive literature review is crucial for advancing circuit\ndesign methodologies. However, the rapid influx of state-of-the-art research,\ninconsistent data representation, and the complexity of optimizing circuit\ndesign objectives make this task significantly challenging. In this paper, we\npropose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for\ncircuit design assistance that integrates a hybrid Retrieval-Augmented\nGeneration (RAG) framework with an adaptive vector database of circuit design\nresearch papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason +\nAct (ReAct) workflow for iterative reasoning, goal-setting, and multi-step\ninformation retrieval. It functions as a question-answering design assistant,\ncapable of interpreting complex queries and providing reasoned responses\ngrounded in circuit literature. Its multimodal capabilities enable processing\nof both textual and visual data, facilitating more efficient and comprehensive\nanalysis. The system dynamically adapts using intelligent search tools,\nautomated document retrieval from the internet, and real-time database updates.\nUnlike conventional approaches constrained by model context limits, MuaLLM\ndecouples retrieval from inference, enabling scalable reasoning over\narbitrarily large corpora. At the maximum context length supported by standard\nLLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining\nthe same accuracy. This allows rapid, no-human-in-the-loop database generation,\novercoming the bottleneck of simulation-based dataset creation for circuits. To\nevaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval\nand citation performance, and Reasoning-100 (Reas-100), focused on multistep\nreasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8%\naccuracy on Reas-100.", "published": "2025-08-11 16:11:09", "link": "http://arxiv.org/abs/2508.08137v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks", "abstract": "The security of LLM-based multi-agent systems (MAS) is critically threatened\nby propagation vulnerability, where malicious agents can distort collective\ndecision-making through inter-agent message interactions. While existing\nsupervised defense methods demonstrate promising performance, they may be\nimpractical in real-world scenarios due to their heavy reliance on labeled\nmalicious agents to train a supervised malicious detection model. To enable\npractical and generalizable MAS defenses, in this paper, we propose BlindGuard,\nan unsupervised defense method that learns without requiring any\nattack-specific labels or prior knowledge of malicious behaviors. To this end,\nwe establish a hierarchical agent encoder to capture individual, neighborhood,\nand global interaction patterns of each agent, providing a comprehensive\nunderstanding for malicious agent detection. Meanwhile, we design a\ncorruption-guided detector that consists of directional noise injection and\ncontrastive learning, allowing effective detection model training solely on\nnormal agent behaviors. Extensive experiments show that BlindGuard effectively\ndetects diverse attack types (i.e., prompt injection, memory poisoning, and\ntool attack) across MAS with various communication patterns while maintaining\nsuperior generalizability compared to supervised baselines. The code is\navailable at: https://github.com/MR9812/BlindGuard.", "published": "2025-08-11 16:04:47", "link": "http://arxiv.org/abs/2508.08127v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing", "abstract": "Knowledge Tracing (KT) is committed to capturing students' knowledge mastery\nfrom their historical interactions. Simulating students' memory states is a\npromising approach to enhance both the performance and interpretability of\nknowledge tracing models. Memory consists of three fundamental processes:\nencoding, storage, and retrieval. Although forgetting primarily manifests\nduring the storage stage, most existing studies rely on a single,\nundifferentiated forgetting mechanism, overlooking other memory processes as\nwell as personalized forgetting patterns. To address this, this paper proposes\nmemoryKT, a knowledge tracing model based on a novel temporal variational\nautoencoder. The model simulates memory dynamics through a three-stage process:\n(i) Learning the distribution of students' knowledge memory features, (ii)\nReconstructing their exercise feedback, while (iii) Embedding a personalized\nforgetting module within the temporal workflow to dynamically modulate memory\nstorage strength. This jointly models the complete encoding-storage-retrieval\ncycle, significantly enhancing the model's perception capability for individual\ndifferences. Extensive experiments on four public datasets demonstrate that our\nproposed approach significantly outperforms state-of-the-art baselines.", "published": "2025-08-11 15:59:59", "link": "http://arxiv.org/abs/2508.08122v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Vision-Based Localization and LLM-based Navigation for Indoor Environments", "abstract": "Indoor navigation remains a complex challenge due to the absence of reliable\nGPS signals and the architectural intricacies of large enclosed environments.\nThis study presents an indoor localization and navigation approach that\nintegrates vision-based localization with large language model (LLM)-based\nnavigation. The localization system utilizes a ResNet-50 convolutional neural\nnetwork fine-tuned through a two-stage process to identify the user's position\nusing smartphone camera input. To complement localization, the navigation\nmodule employs an LLM, guided by a carefully crafted system prompt, to\ninterpret preprocessed floor plan images and generate step-by-step directions.\nExperimental evaluation was conducted in a realistic office corridor with\nrepetitive features and limited visibility to test localization robustness. The\nmodel achieved high confidence and an accuracy of 96% across all tested\nwaypoints, even under constrained viewing conditions and short-duration\nqueries. Navigation tests using ChatGPT on real building floor maps yielded an\naverage instruction accuracy of 75%, with observed limitations in zero-shot\nreasoning and inference time. This research demonstrates the potential for\nscalable, infrastructure-free indoor navigation using off-the-shelf cameras and\npublicly available floor plans, particularly in resource-constrained settings\nlike hospitals, airports, and educational institutions.", "published": "2025-08-11 15:59:09", "link": "http://arxiv.org/abs/2508.08120v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking", "abstract": "Multi-object tracking (MOT) in monocular videos is fundamentally challenged\nby occlusions and depth ambiguity, issues that conventional\ntracking-by-detection (TBD) methods struggle to resolve owing to a lack of\ngeometric awareness. To address these limitations, we introduce GRASPTrack, a\nnovel depth-aware MOT framework that integrates monocular depth estimation and\ninstance segmentation into a standard TBD pipeline to generate high-fidelity 3D\npoint clouds from 2D detections, thereby enabling explicit 3D geometric\nreasoning. These 3D point clouds are then voxelized to enable a precise and\nrobust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To\nfurther enhance tracking robustness, our approach incorporates Depth-aware\nAdaptive Noise Compensation, which dynamically adjusts the Kalman filter\nprocess noise based on occlusion severity for more reliable state estimation.\nAdditionally, we propose a Depth-enhanced Observation-Centric Momentum, which\nextends the motion direction consistency from the image plane into 3D space to\nimprove motion-based association cues, particularly for objects with complex\ntrajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack\nbenchmarks demonstrate that our method achieves competitive performance,\nsignificantly improving tracking robustness in complex scenes with frequent\nocclusions and intricate motion patterns.", "published": "2025-08-11 15:56:21", "link": "http://arxiv.org/abs/2508.08117v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork", "abstract": "We present TeamMedAgents, a novel multi-agent approach that systematically\nintegrates evidence-based teamwork components from human-human collaboration\ninto medical decision-making with large language models (LLMs). Our approach\nvalidates an organizational psychology teamwork model from human collaboration\nto computational multi-agent medical systems by operationalizing six core\nteamwork components derived from Salas et al.'s \"Big Five\" model: team\nleadership, mutual performance monitoring, team orientation, shared mental\nmodels, closed-loop communication, and mutual trust. We implement and evaluate\nthese components as modular, configurable mechanisms within an adaptive\ncollaboration architecture while assessing the effect of the number of agents\ninvolved based on the task's requirements and domain. Systematic evaluation of\ncomputational implementations of teamwork behaviors across eight medical\nbenchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets,\nPath-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8\nevaluated datasets. Controlled ablation studies conducted on 50 questions per\nconfiguration across 3 independent runs provide mechanistic insights into\nindividual component contributions, revealing optimal teamwork configurations\nthat vary by reasoning task complexity and domain-specific requirements. Our\nablation analyses reveal dataset-specific optimal teamwork configurations,\nindicating that different medical reasoning modalities benefit from distinct\ncollaborative patterns. TeamMedAgents represents an advancement in\ncollaborative AI by providing a systematic translation of established teamwork\ntheories from human collaboration into agentic collaboration, establishing a\nfoundation for evidence-based multi-agent system design in critical\ndecision-making domains.", "published": "2025-08-11 15:55:06", "link": "http://arxiv.org/abs/2508.08115v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Hyperspectral Imaging", "abstract": "Hyperspectral imaging (HSI) is an advanced sensing modality that\nsimultaneously captures spatial and spectral information, enabling\nnon-invasive, label-free analysis of material, chemical, and biological\nproperties. This Primer presents a comprehensive overview of HSI, from the\nunderlying physical principles and sensor architectures to key steps in data\nacquisition, calibration, and correction. We summarize common data structures\nand highlight classical and modern analysis methods, including dimensionality\nreduction, classification, spectral unmixing, and AI-driven techniques such as\ndeep learning. Representative applications across Earth observation, precision\nagriculture, biomedicine, industrial inspection, cultural heritage, and\nsecurity are also discussed, emphasizing HSI's ability to uncover sub-visual\nfeatures for advanced monitoring, diagnostics, and decision-making. Persistent\nchallenges, such as hardware trade-offs, acquisition variability, and the\ncomplexity of high-dimensional data, are examined alongside emerging solutions,\nincluding computational imaging, physics-informed modeling, cross-modal fusion,\nand self-supervised learning. Best practices for dataset sharing,\nreproducibility, and metadata documentation are further highlighted to support\ntransparency and reuse. Looking ahead, we explore future directions toward\nscalable, real-time, and embedded HSI systems, driven by sensor\nminiaturization, self-supervised learning, and foundation models. As HSI\nevolves into a general-purpose, cross-disciplinary platform, it holds promise\nfor transformative applications in science, technology, and society.", "published": "2025-08-11 15:47:24", "link": "http://arxiv.org/abs/2508.08107v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience", "abstract": "Studies on in-vehicle conversational agents have traditionally relied on\npre-scripted prompts or limited voice commands, constraining natural\ndriver-agent interaction. To resolve this issue, the present study explored the\npotential of a ChatGPT-based in-vehicle agent capable of carrying continuous,\nmulti-turn dialogues. Forty drivers participated in our experiment using a\nmotion-based driving simulator, comparing three conditions (No agent,\nPre-scripted agent, and ChatGPT-based agent) as a within-subjects variable.\nResults showed that the ChatGPT-based agent condition led to more stable\ndriving performance across multiple metrics. Participants demonstrated lower\nvariability in longitudinal acceleration, lateral acceleration, and lane\ndeviation compared to the other two conditions. In subjective evaluations, the\nChatGPT-based agent also received significantly higher ratings in competence,\nanimacy, affective trust, and preference compared to the Pre-scripted agent.\nOur thematic analysis of driver-agent conversations revealed diverse\ninteraction patterns in topics, including driving assistance/questions,\nentertainment requests, and anthropomorphic interactions. Our results highlight\nthe potential of LLM-powered in-vehicle conversational agents to enhance\ndriving safety and user experience through natural, context-rich interactions.", "published": "2025-08-11 15:40:44", "link": "http://arxiv.org/abs/2508.08101v1", "categories": ["cs.HC", "cs.AI", "cs.SE"], "primary_category": "cs.HC"}
{"title": "Grid2Guide: A* Enabled Small Language Model for Indoor Navigation", "abstract": "Reliable indoor navigation remains a significant challenge in complex\nenvironments, particularly where external positioning signals and dedicated\ninfrastructures are unavailable. This research presents Grid2Guide, a hybrid\nnavigation framework that combines the A* search algorithm with a Small\nLanguage Model (SLM) to generate clear, human-readable route instructions. The\nframework first conducts a binary occupancy matrix from a given indoor map.\nUsing this matrix, the A* algorithm computes the optimal path between origin\nand destination, producing concise textual navigation steps. These steps are\nthen transformed into natural language instructions by the SLM, enhancing\ninterpretability for end users. Experimental evaluations across various indoor\nscenarios demonstrate the method's effectiveness in producing accurate and\ntimely navigation guidance. The results validate the proposed approach as a\nlightweight, infrastructure-free solution for real-time indoor navigation\nsupport.", "published": "2025-08-11 15:39:27", "link": "http://arxiv.org/abs/2508.08100v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Growing Reservoirs with Developmental Graph Cellular Automata", "abstract": "Developmental Graph Cellular Automata (DGCA) are a novel model for\nmorphogenesis, capable of growing directed graphs from single-node seeds. In\nthis paper, we show that DGCAs can be trained to grow reservoirs. Reservoirs\nare grown with two types of targets: task-driven (using the NARMA family of\ntasks) and task-independent (using reservoir metrics).\n  Results show that DGCAs are able to grow into a variety of specialized,\nlife-like structures capable of effectively solving benchmark tasks,\nstatistically outperforming `typical' reservoirs on the same task. Overall,\nthese lay the foundation for the development of DGCA systems that produce\nplastic reservoirs and for modeling functional, adaptive morphogenesis.", "published": "2025-08-11 15:32:01", "link": "http://arxiv.org/abs/2508.08091v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence", "abstract": "The Dempster-Shafer theory of evidence has been widely applied in the field\nof information fusion under uncertainty. Most existing research focuses on\ncombining evidence within the same frame of discernment. However, in real-world\nscenarios, trained algorithms or data often originate from different regions or\norganizations, where data silos are prevalent. As a result, using different\ndata sources or models to generate basic probability assignments may lead to\nheterogeneous frames, for which traditional fusion methods often yield\nunsatisfactory results. To address this challenge, this study proposes an\nopen-world information fusion method, termed Full Negation Belief\nTransformation (FNBT), based on the Dempster-Shafer theory. More specially, a\ncriterion is introduced to determine whether a given fusion task belongs to the\nopen-world setting. Then, by extending the frames, the method can accommodate\nelements from heterogeneous frames. Finally, a full negation mechanism is\nemployed to transform the mass functions, so that existing combination rules\ncan be applied to the transformed mass functions for such information fusion.\nTheoretically, the proposed method satisfies three desirable properties, which\nare formally proven: mass function invariance, heritability, and essential\nconflict elimination. Empirically, FNBT demonstrates superior performance in\npattern classification tasks on real-world datasets and successfully resolves\nZadeh's counterexample, thereby validating its practical effectiveness.", "published": "2025-08-11 15:21:48", "link": "http://arxiv.org/abs/2508.08075v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction", "abstract": "Connecting an ever-expanding catalogue of products with suitable\nmanufacturers and suppliers is critical for resilient, efficient global supply\nchains, yet traditional methods struggle to capture complex capabilities,\ncertifications, geographic constraints, and rich multimodal data of real-world\nmanufacturer profiles. To address these gaps, we introduce PMGraph, a public\nbenchmark of bipartite and heterogeneous multimodal supply-chain graphs linking\n8,888 manufacturers, over 70k products, more than 110k manufacturer-product\nedges, and over 29k product images. Building on this benchmark, we propose the\nCascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first\naligns and aggregates textual and visual attributes into intermediate group\nembeddings, then propagates them through a manufacturer-product hetero-graph\nvia multiscale message passing to enhance link prediction accuracy. C-MAG also\nprovides practical guidelines for modality-aware fusion, preserving predictive\nperformance in noisy, real-world settings.", "published": "2025-08-11 15:14:03", "link": "http://arxiv.org/abs/2508.08071v1", "categories": ["cs.LG", "cs.AI", "J.1; I.2.4; H.2.8"], "primary_category": "cs.LG"}
{"title": "AdaptFlow: Adaptive Workflow Optimization via Meta-Learning", "abstract": "Recent advances in large language models (LLMs) have sparked growing interest\nin agentic workflows, which are structured sequences of LLM invocations\nintended to solve complex tasks. However, existing approaches often rely on\nstatic templates or manually designed workflows, which limit adaptability to\ndiverse tasks and hinder scalability. We propose AdaptFlow, a natural\nlanguage-based meta-learning framework inspired by model-agnostic meta-learning\n(MAML). AdaptFlow learns a generalizable workflow initialization that enables\nrapid subtask-level adaptation. It employs a bi-level optimization scheme: the\ninner loop refines the workflow for a specific subtask using LLM-generated\nfeedback, while the outer loop updates the shared initialization to perform\nwell across tasks. This setup allows AdaptFlow to generalize effectively to\nunseen tasks by adapting the initialized workflow through language-guided\nmodifications. Evaluated across question answering, code generation, and\nmathematical reasoning benchmarks, AdaptFlow consistently outperforms both\nmanually crafted and automatically searched baselines, achieving\nstate-of-the-art results with strong generalization across tasks and models.\nThe source code and data are available at\nhttps://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.", "published": "2025-08-11 14:52:59", "link": "http://arxiv.org/abs/2508.08053v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On Understanding of the Dynamics of Model Capacity in Continual Learning", "abstract": "The stability-plasticity dilemma, closely related to a neural network's (NN)\ncapacity-its ability to represent tasks-is a fundamental challenge in continual\nlearning (CL). Within this context, we introduce CL's effective model capacity\n(CLEMC) that characterizes the dynamic behavior of the stability-plasticity\nbalance point. We develop a difference equation to model the evolution of the\ninterplay between the NN, task data, and optimization procedure. We then\nleverage CLEMC to demonstrate that the effective capacity-and, by extension,\nthe stability-plasticity balance point is inherently non-stationary. We show\nthat regardless of the NN architecture or optimization method, a NN's ability\nto represent new tasks diminishes when incoming task distributions differ from\nprevious ones. We conduct extensive experiments to support our theoretical\nfindings, spanning a range of architectures-from small feedforward network and\nconvolutional networks to medium-sized graph neural networks and\ntransformer-based large language models with millions of parameters.", "published": "2025-08-11 14:52:56", "link": "http://arxiv.org/abs/2508.08052v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Rethinking Self-Replication: Detecting Distributed Selfhood in the Outlier Cellular Automaton", "abstract": "Spontaneous self-replication in cellular automata has long been considered\nrare, with most known examples requiring careful design or artificial\ninitialization. In this paper, we present formal, causal evidence that such\nreplication can emerge unassisted -- and that it can do so in a distributed,\nmulti-component form. Building on prior work identifying complex dynamics in\nthe Outlier rule, we introduce a data-driven framework that reconstructs the\nfull causal ancestry of patterns in a deterministic cellular automaton. This\nallows us to rigorously identify self-replicating structures via explicit\ncausal lineages. Our results show definitively that self-replicators in the\nOutlier CA are not only spontaneous and robust, but are also often composed of\nmultiple disjoint clusters working in coordination, raising questions about\nsome conventional notions of individuality and replication in artificial life\nsystems.", "published": "2025-08-11 14:49:11", "link": "http://arxiv.org/abs/2508.08047v1", "categories": ["nlin.CG", "cs.AI"], "primary_category": "nlin.CG"}
{"title": "Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation", "abstract": "Recommendation systems have faced significant challenges in cold-start\nscenarios, where new items with a limited history of interaction need to be\neffectively recommended to users. Though multimodal data (e.g., images, text,\naudio, etc.) offer rich information to address this issue, existing approaches\noften employ simplistic integration methods such as concatenation, average\npooling, or fixed weighting schemes, which fail to capture the complex\nrelationships between modalities. Our study proposes a novel Mixture of Experts\n(MoE) framework for multimodal cold-start recommendation, named MAMEX, which\ndynamically leverages latent representation from different modalities. MAMEX\nutilizes modality-specific expert networks and introduces a learnable gating\nmechanism that adaptively weights the contribution of each modality based on\nits content characteristics. This approach enables MAMEX to emphasize the most\ninformative modalities for each item while maintaining robustness when certain\nmodalities are less relevant or missing. Extensive experiments on benchmark\ndatasets show that MAMEX outperforms state-of-the-art methods in cold-start\nscenarios, with superior accuracy and adaptability. For reproducibility, the\ncode has been made available on Github https://github.com/L2R-UET/MAMEX.", "published": "2025-08-11 14:47:14", "link": "http://arxiv.org/abs/2508.08042v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models", "abstract": "Prompt-based tuning has emerged as a lightweight alternative to full\nfine-tuning in large vision-language models, enabling efficient adaptation via\nlearned contextual prompts. This paradigm has recently been extended to\nfederated learning settings (e.g., PromptFL), where clients collaboratively\ntrain prompts under data privacy constraints. However, the security\nimplications of prompt-based aggregation in federated multimodal learning\nremain largely unexplored, leaving a critical attack surface unaddressed. In\nthis paper, we introduce \\textbf{BadPromptFL}, the first backdoor attack\ntargeting prompt-based federated learning in multimodal contrastive models. In\nBadPromptFL, compromised clients jointly optimize local backdoor triggers and\nprompt embeddings, injecting poisoned prompts into the global aggregation\nprocess. These prompts are then propagated to benign clients, enabling\nuniversal backdoor activation at inference without modifying model parameters.\nLeveraging the contextual learning behavior of CLIP-style architectures,\nBadPromptFL achieves high attack success rates (e.g., \\(>90\\%\\)) with minimal\nvisibility and limited client participation. Extensive experiments across\nmultiple datasets and aggregation protocols validate the effectiveness,\nstealth, and generalizability of our attack, raising critical concerns about\nthe robustness of prompt-based federated learning in real-world deployments.", "published": "2025-08-11 14:42:44", "link": "http://arxiv.org/abs/2508.08040v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Exploring Strategies for Personalized Radiation Therapy: Part III Identifying genetic determinants for Radiation Response with Meta Learning", "abstract": "Radiation response in cancer is shaped by complex, patient specific biology,\nyet current treatment strategies often rely on uniform dose prescriptions\nwithout accounting for tumor heterogeneity. In this study, we introduce a meta\nlearning framework for one-shot prediction of radiosensitivity measured by SF2\nusing cell line level gene expression data. Unlike the widely used\nRadiosensitivity Index RSI a rank-based linear model trained on a fixed 10-gene\nsignature, our proposed meta-learned model allows the importance of each gene\nto vary by sample through fine tuning. This flexibility addresses key\nlimitations of static models like RSI, which assume uniform gene contributions\nacross tumor types and discard expression magnitude and gene gene interactions.\nOur results show that meta learning offers robust generalization to unseen\nsamples and performs well in tumor subgroups with high radiosensitivity\nvariability, such as adenocarcinoma and large cell carcinoma. By learning\ntransferable structure across tasks while preserving sample specific\nadaptability, our approach enables rapid adaptation to individual samples,\nimproving predictive accuracy across diverse tumor subtypes while uncovering\ncontext dependent patterns of gene influence that may inform personalized\ntherapy.", "published": "2025-08-11 14:34:18", "link": "http://arxiv.org/abs/2508.08030v1", "categories": ["physics.med-ph", "cs.AI", "cs.LG"], "primary_category": "physics.med-ph"}
{"title": "Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches", "abstract": "Speech Recognition (ASR) due to phoneme distortions and high variability.\nWhile self-supervised ASR models like Wav2Vec, HuBERT, and Whisper have shown\npromise, their effectiveness in dysarthric speech remains unclear. This study\nsystematically benchmarks these models with different decoding strategies,\nincluding CTC, seq2seq, and LLM-enhanced decoding (BART,GPT-2, Vicuna). Our\ncontributions include (1) benchmarking ASR architectures for dysarthric speech,\n(2) introducing LLM-based decoding to improve intelligibility, (3) analyzing\ngeneralization across datasets, and (4) providing insights into recognition\nerrors across severity levels. Findings highlight that LLM-enhanced decoding\nimproves dysarthric ASR by leveraging linguistic constraints for phoneme\nrestoration and grammatical correction.", "published": "2025-08-11 14:31:20", "link": "http://arxiv.org/abs/2508.08027v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Advancing Knowledge Tracing by Exploring Follow-up Performance Trends", "abstract": "Intelligent Tutoring Systems (ITS), such as Massive Open Online Courses,\noffer new opportunities for human learning. At the core of such systems,\nknowledge tracing (KT) predicts students' future performance by analyzing their\nhistorical learning activities, enabling an accurate evaluation of students'\nknowledge states over time. We show that existing KT methods often encounter\ncorrelation conflicts when analyzing the relationships between historical\nlearning sequences and future performance. To address such conflicts, we\npropose to extract so-called Follow-up Performance Trends (FPTs) from\nhistorical ITS data and to incorporate them into KT. We propose a method called\nForward-Looking Knowledge Tracing (FINER) that combines historical learning\nsequences with FPTs to enhance student performance prediction accuracy. FINER\nconstructs learning patterns that facilitate the retrieval of FPTs from\nhistorical ITS data in linear time; FINER includes a novel similarity-aware\nattention mechanism that aggregates FPTs based on both frequency and contextual\nsimilarity; and FINER offers means of combining FPTs and historical learning\nsequences to enable more accurate prediction of student future performance.\nExperiments on six real-world datasets show that FINER can outperform ten\nstate-of-the-art KT methods, increasing accuracy by 8.74% to 84.85%.", "published": "2025-08-11 14:26:11", "link": "http://arxiv.org/abs/2508.08019v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Fitting Description Logic Ontologies to ABox and Query Examples", "abstract": "We study a fitting problem inspired by ontology-mediated querying: given a\ncollection\n  of positive and negative examples of\n  the form $(\\mathcal{A},q)$ with\n  $\\mathcal{A}$ an ABox and $q$ a Boolean query, we seek\n  an ontology $\\mathcal{O}$ that satisfies $\\mathcal{A} \\cup \\mathcal{O} \\vDash\nq$ for all positive examples and $\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$ for\nall negative examples.\n  We consider the description logics $\\mathcal{ALC}$ and $\\mathcal{ALCI}$ as\nontology languages and\n  a range of query languages that\n  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof\n(UCQs).\n  For all of the resulting fitting problems,\n  we provide\n  effective characterizations and determine the computational complexity\n  of deciding whether a fitting ontology exists. This problem turns out to be\n${\\small CO}NP$ for AQs and full CQs\n  and $2E{\\small XP}T{\\small IME}$-complete for CQs and UCQs.\n  These results hold for both $\\mathcal{ALC}$ and $\\mathcal{ALCI}$.", "published": "2025-08-11 14:11:27", "link": "http://arxiv.org/abs/2508.08007v1", "categories": ["cs.AI", "Computing methodologies~Description logics, Computing\n  methodologies~Ontology engineering"], "primary_category": "cs.AI"}
{"title": "Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP", "abstract": "Extensive experiments and prior studies show that no single maximum clique\nalgorithm consistently performs best across all instances, highlighting the\nimportance of selecting suitable algorithms based on instance features. Through\nan extensive analysis of relevant studies, it is found that there is a lack of\nresearch work concerning algorithm selection oriented toward the Maximum Clique\nProblem (MCP). In this work, we propose a learning-based framework that\nintegrates both traditional machine learning and graph neural networks to\naddress this gap. We construct a labeled dataset by running four exact MCP\nalgorithms on a diverse collection of graph instances, accompanied by\nstructural and global statistical features extracted from each graph. We first\nevaluate four conventional classifiers: Support Vector Machine (SVM), Random\nForest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple\ndataset variants. Experimental results show that RF consistently shows strong\nperformance across metrics and dataset variants, making it a reliable baseline.\nIn addition, feature importance analysis indicates that connectivity and\ntopological structure are strong predictors of algorithm performance. Building\non these findings, we develop a dual-channel model named GAT-MLP, which\ncombines a Graph Attention Network (GAT) for local structural encoding with a\nMultilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model\nshows strong and consistent performance across all metrics. Our results\nhighlight the effectiveness of dual-channel architectures and the promise of\ngraph neural networks in combinatorial algorithm selection.", "published": "2025-08-11 14:09:58", "link": "http://arxiv.org/abs/2508.08005v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths", "abstract": "\"Fedspeak\", the stylized and often nuanced language used by the U.S. Federal\nReserve, encodes implicit policy signals and strategic stances. The Federal\nOpen Market Committee strategically employs Fedspeak as a communication tool to\nshape market expectations and influence both domestic and global economic\nconditions. As such, automatically parsing and interpreting Fedspeak presents a\nhigh-impact challenge, with significant implications for financial forecasting,\nalgorithmic trading, and data-driven policy analysis. In this paper, we propose\nan LLM-based, uncertainty-aware framework for deciphering Fedspeak and\nclassifying its underlying monetary policy stance. Technically, to enrich the\nsemantic and contextual representation of Fedspeak texts, we incorporate\ndomain-specific reasoning grounded in the monetary policy transmission\nmechanism. We further introduce a dynamic uncertainty decoding module to assess\nthe confidence of model predictions, thereby enhancing both classification\naccuracy and model reliability. Experimental results demonstrate that our\nframework achieves state-of-the-art performance on the policy stance analysis\ntask. Moreover, statistical analysis reveals a significant positive correlation\nbetween perceptual uncertainty and model error rates, validating the\neffectiveness of perceptual uncertainty as a diagnostic signal.", "published": "2025-08-11 14:04:59", "link": "http://arxiv.org/abs/2508.08001v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval", "abstract": "Retrieval-augmented generation has achieved strong performance on\nknowledge-intensive tasks where query-document relevance can be identified\nthrough direct lexical or semantic matches. However, many real-world queries\ninvolve abstract reasoning, analogical thinking, or multi-step inference, which\nexisting retrievers often struggle to capture. To address this challenge, we\npresent \\textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive\ninformation retrieval. DIVER consists of four components: document processing\nto improve input quality, LLM-driven query expansion via iterative document\ninteraction, a reasoning-enhanced retriever fine-tuned on synthetic\nmulti-domain data with hard negatives, and a pointwise reranker that combines\nLLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark,\nDIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original\nqueries, consistently outperforming competitive reasoning-aware models. These\nresults demonstrate the effectiveness of reasoning-aware retrieval strategies\nin complex real-world tasks. Our code and retrieval model will be released\nsoon.", "published": "2025-08-11 13:57:49", "link": "http://arxiv.org/abs/2508.07995v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "abstract": "Visual effects (VFX) are essential visual enhancements fundamental to modern\ncinematic production. Although video generation models offer cost-efficient\nsolutions for VFX production, current methods are constrained by per-effect\nLoRA training, which limits generation to single effects. This fundamental\nlimitation impedes applications that require spatially controllable composite\neffects, i.e., the concurrent generation of multiple effects at designated\nlocations. However, integrating diverse effects into a unified framework faces\nmajor challenges: interference from effect variations and spatial\nuncontrollability during multi-VFX joint training. To tackle these challenges,\nwe propose Omni-Effects, a first unified framework capable of generating\nprompt-guided effects and spatially controllable composite effects. The core of\nour framework comprises two key innovations: (1) LoRA-based Mixture of Experts\n(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects\nwithin a unified model while effectively mitigating cross-task interference.\n(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the\ntext token, enabling precise spatial control. Furthermore, we introduce an\nIndependent-Information Flow (IIF) module integrated within the SAP, isolating\nthe control signals corresponding to individual effects to prevent any unwanted\nblending. To facilitate this research, we construct a comprehensive VFX dataset\nOmni-VFX via a novel data collection pipeline combining image editing and\nFirst-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX\nevaluation framework for validating model performance. Extensive experiments\ndemonstrate that Omni-Effects achieves precise spatial control and diverse\neffect generation, enabling users to specify both the category and location of\ndesired effects.", "published": "2025-08-11 13:41:24", "link": "http://arxiv.org/abs/2508.07981v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent\nparadigm for training large language models and multimodal systems. Despite\nnotable advances enabled by existing RLHF training frameworks, significant\nchallenges remain in scaling to complex multimodal workflows and adapting to\ndynamic workloads. In particular, current systems often encounter limitations\nrelated to controller scalability when managing large models, as well as\ninefficiencies in orchestrating intricate RLHF pipelines, especially in\nscenarios that require dynamic sampling and resource allocation. In this paper,\nwe introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple,\nscalable, and balanced RLHF training framework specifically designed to address\nthese challenges. WeChat-YATT features a parallel controller programming model\nthat enables flexible and efficient orchestration of complex RLHF workflows,\neffectively mitigating the bottlenecks associated with centralized controller\narchitectures and facilitating scalability in large-scale data scenarios. In\naddition, we propose a dynamic placement schema that adaptively partitions\ncomputational resources and schedules workloads, thereby significantly reducing\nhardware idle time and improving GPU utilization under variable training\nconditions. We evaluate WeChat-YATT across a range of experimental scenarios,\ndemonstrating that it achieves substantial improvements in throughput compared\nto state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been\nsuccessfully deployed to train models supporting WeChat product features for a\nlarge-scale user base, underscoring its effectiveness and robustness in\nreal-world applications.", "published": "2025-08-11 13:31:53", "link": "http://arxiv.org/abs/2508.07970v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Exploring the Challenges and Opportunities of AI-assisted Codebase Generation", "abstract": "Recent AI code assistants have significantly improved their ability to\nprocess more complex contexts and generate entire codebases based on a textual\ndescription, compared to the popular snippet-level generation. These codebase\nAI assistants (CBAs) can also extend or adapt codebases, allowing users to\nfocus on higher-level design and deployment decisions. While prior work has\nextensively studied the impact of snippet-level code generation, this new class\nof codebase generation models is relatively unexplored. Despite initial\nanecdotal reports of excitement about these agents, they remain less frequently\nadopted compared to snippet-level code assistants. To utilize CBAs better, we\nneed to understand how developers interact with CBAs, and how and why CBAs fall\nshort of developers' needs. In this paper, we explored these gaps through a\ncounterbalanced user study and interview with (n = 16) students and developers\nworking on coding tasks with CBAs. We found that participants varied the\ninformation in their prompts, like problem description (48% of prompts),\nrequired functionality (98% of prompts), code structure (48% of prompts), and\ntheir prompt writing process. Despite various strategies, the overall\nsatisfaction score with generated codebases remained low (mean = 2.8, median =\n3, on a scale of one to five). Participants mentioned functionality as the most\ncommon factor for dissatisfaction (77% of instances), alongside poor code\nquality (42% of instances) and communication issues (25% of instances). We\ndelve deeper into participants' dissatisfaction to identify six underlying\nchallenges that participants faced when using CBAs, and extracted five barriers\nto incorporating CBAs into their workflows. Finally, we surveyed 21 commercial\nCBAs to compare their capabilities with participant challenges and present\ndesign opportunities for more efficient and useful CBAs.", "published": "2025-08-11 13:26:48", "link": "http://arxiv.org/abs/2508.07966v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "abstract": "Forensic cause-of-death determination faces systemic challenges, including\nworkforce shortages and diagnostic variability, particularly in high-volume\nsystems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic\nAgenT), a multi-agent AI framework that automates and standardizes death\ninvestigations through a domain-adapted large language model. FEAT's\napplication-oriented architecture integrates: (i) a central Planner for task\ndecomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a\nMemory & Reflection module for iterative refinement, and (iv) a Global Solver\nfor conclusion synthesis. The system employs tool-augmented reasoning,\nhierarchical retrieval-augmented generation, forensic-tuned LLMs, and\nhuman-in-the-loop feedback to ensure legal and medical validity. In evaluations\nacross diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI\nsystems in both long-form autopsy analyses and concise cause-of-death\nconclusions. It demonstrated robust generalization across six geographic\nregions and achieved high expert concordance in blinded validations. Senior\npathologists validated FEAT's outputs as comparable to those of human experts,\nwith improved detection of subtle evidentiary nuances. To our knowledge, FEAT\nis the first LLM-based AI agent system dedicated to forensic medicine, offering\nscalable, consistent death certification while maintaining expert-level rigor.\nBy integrating AI efficiency with human oversight, this work could advance\nequitable access to reliable medicolegal services while addressing critical\ncapacity constraints in forensic systems.", "published": "2025-08-11 13:05:59", "link": "http://arxiv.org/abs/2508.07950v1", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis", "abstract": "Despite growing attention to deepfake speech detection, the aspects of bias\nand fairness remain underexplored in the speech domain. To address this gap, we\nintroduce the Speaker Characteristics Deepfake (SCDF) dataset: a novel, richly\nannotated resource enabling systematic evaluation of demographic biases in\ndeepfake speech detection. SCDF contains over 237,000 utterances in a balanced\nrepresentation of both male and female speakers spanning five languages and a\nwide age range. We evaluate several state-of-the-art detectors and show that\nspeaker characteristics significantly influence detection performance,\nrevealing disparities across sex, language, age, and synthesizer type. These\nfindings highlight the need for bias-aware development and provide a foundation\nfor building non-discriminatory deepfake detection systems aligned with ethical\nand regulatory standards.", "published": "2025-08-11 12:58:37", "link": "http://arxiv.org/abs/2508.07944v1", "categories": ["cs.SD", "cs.AI", "cs.CR"], "primary_category": "cs.SD"}
{"title": "Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots", "abstract": "This article proposes a collision risk anticipation method based on\nshort-term prediction of the agents position. A Long Short-Term Memory (LSTM)\nmodel, trained on past trajectories, is used to estimate the next position of\neach robot. This prediction allows us to define an anticipated collision risk\nby dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent.\nThe approach is tested in a constrained environment, where two robots move\nwithout communication or identifiers. Despite a limited sampling frequency (1\nHz), the results show a significant decrease of the collisions number and a\nstability improvement. The proposed method, which is computationally\ninexpensive, appears particularly attractive for implementation on embedded\nsystems.", "published": "2025-08-11 12:55:51", "link": "http://arxiv.org/abs/2508.07941v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "\\(X\\)-evolve: Solution space evolution powered by large language models", "abstract": "While combining large language models (LLMs) with evolutionary algorithms\n(EAs) shows promise for solving complex optimization problems, current\napproaches typically evolve individual solutions, often incurring high LLM call\ncosts. We introduce \\(X\\)-evolve, a paradigm-shifting method that instead\nevolves solution spaces \\(X\\) (sets of individual solutions) - subsets of the\noverall search space \\(S\\). In \\(X\\)-evolve, LLMs generate tunable programs\nwherein certain code snippets, designated as parameters, define a tunable\nsolution space. A score-based search algorithm then efficiently explores this\nparametrically defined space, guided by feedback from objective function\nscores. This strategy enables broader and more efficient exploration, which can\npotentially accelerate convergence at a much lower search cost, requiring up to\ntwo orders of magnitude fewer LLM calls than prior leading methods. We\ndemonstrate \\(X\\)-evolve's efficacy across three distinct hard optimization\nproblems. For the cap set problem, we discover a larger partial admissible set,\nestablishing a new tighter asymptotic lower bound for the cap set constant (\\(C\n\\ge 2.2203\\)). In information theory, we uncover a larger independent set for\nthe 15-vertex cycle graph (\\(\\mathcal{C}_{15}^{\\boxtimes 5}\\), size 19,946),\nthereby raising the known lower bound on its Shannon capacity. Furthermore, for\nthe NP-hard online bin packing problem, we generate heuristics that\nconsistently outperform standard strategies across established benchmarks. By\nevolving solution spaces, our method considerably improves search\neffectiveness, making it possible to tackle high-dimensional problems that were\npreviously computationally prohibitive.", "published": "2025-08-11 12:47:59", "link": "http://arxiv.org/abs/2508.07932v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models", "abstract": "Despite significant progress in generative modelling, existing diffusion\nmodels often struggle to produce anatomically precise female pelvic images,\nlimiting their application in gynaecological imaging, where data scarcity and\npatient privacy concerns are critical. To overcome these barriers, we introduce\na novel diffusion-based framework for uterine MRI synthesis, integrating both\nunconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs)\nand Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates\nanatomically coherent, high fidelity synthetic images that closely mimic real\nscans and provide valuable resources for training robust diagnostic models. We\nevaluate generative quality using advanced perceptual and distributional\nmetrics, benchmarking against standard reconstruction methods, and demonstrate\nsubstantial gains in diagnostic accuracy on a key classification task. A\nblinded expert evaluation further validates the clinical realism of our\nsynthetic images. We release our models with privacy safeguards and a\ncomprehensive synthetic uterine MRI dataset to support reproducible research\nand advance equitable AI in gynaecology.", "published": "2025-08-11 12:18:23", "link": "http://arxiv.org/abs/2508.07903v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction", "abstract": "Computer vision-based technologies significantly enhance surgical automation\nby advancing tool tracking, detection, and localization. However, Current\ndata-driven approaches are data-voracious, requiring large, high-quality\nlabeled image datasets, which limits their application in surgical data\nscience. Our Work introduces a novel dynamic Gaussian Splatting technique to\naddress the data scarcity in surgical image datasets. We propose a dynamic\nGaussian model to represent dynamic surgical scenes, enabling the rendering of\nsurgical instruments from unseen viewpoints and deformations with real tissue\nbackgrounds. We utilize a dynamic training adjustment strategy to address\nchallenges posed by poorly calibrated camera poses from real-world scenarios.\nAdditionally, we propose a method based on dynamic Gaussians for automatically\ngenerating annotations for our synthetic data. For evaluation, we constructed a\nnew dataset featuring seven scenes with 14,000 frames of tool and camera motion\nand tool jaw articulation, with a background of an ex-vivo porcine model. Using\nthis dataset, we synthetically replicate the scene deformation from the ground\ntruth data, allowing direct comparisons of synthetic image quality.\nExperimental results illustrate that our method generates photo-realistic\nlabeled image datasets with the highest values in Peak-Signal-to-Noise Ratio\n(29.87). We further evaluate the performance of medical-specific neural\nnetworks trained on real and synthetic images using an unseen real-world image\ndataset. Our results show that the performance of models trained on synthetic\nimages generated by the proposed method outperforms those trained with\nstate-of-the-art standard data augmentation by 10%, leading to an overall\nimprovement in model performances by nearly 15%.", "published": "2025-08-11 12:13:05", "link": "http://arxiv.org/abs/2508.07897v1", "categories": ["cs.CV", "cs.AI", "I.3.3"], "primary_category": "cs.CV"}
{"title": "Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant", "abstract": "Simulators have revolutionized scientific practice across the natural\nsciences. By generating data that reliably approximate real-world phenomena,\nthey enable scientists to accelerate hypothesis testing and optimize\nexperimental designs. This is perhaps best illustrated by AlphaFold, a\nNobel-prize winning simulator in chemistry that predicts protein structures\nfrom amino acid sequences, enabling rapid prototyping of molecular\ninteractions, drug targets, and protein functions. In the behavioral sciences,\na reliable participant simulator - a system capable of producing human-like\nbehavior across cognitive tasks - would represent a similarly transformative\nadvance. Recently, Binz et al. introduced Centaur, a large language model (LLM)\nfine-tuned on human data from 160 experiments, proposing its use not only as a\nmodel of cognition but also as a participant simulator for \"in silico\nprototyping of experimental studies\", e.g., to advance automated cognitive\nscience. Here, we review the core criteria for a participant simulator and\nassess how well Centaur meets them. Although Centaur demonstrates strong\npredictive accuracy, its generative behavior - a critical criterion for a\nparticipant simulator - systematically diverges from human data. This suggests\nthat, while Centaur is a significant step toward predicting human behavior, it\ndoes not yet meet the standards of a reliable participant simulator or an\naccurate model of cognition.", "published": "2025-08-11 12:05:18", "link": "http://arxiv.org/abs/2508.07887v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning", "abstract": "This paper introduces an advanced AI-driven perception system for autonomous\nquadcopter navigation in GPS-denied indoor environments. The proposed framework\nleverages cloud computing to offload computationally intensive tasks and\nincorporates a custom-designed printed circuit board (PCB) for efficient sensor\ndata acquisition, enabling robust navigation in confined spaces. The system\nintegrates YOLOv11 for object detection, Depth Anything V2 for monocular depth\nestimation, a PCB equipped with Time-of-Flight (ToF) sensors and an Inertial\nMeasurement Unit (IMU), and a cloud-based Large Language Model (LLM) for\ncontext-aware decision-making. A virtual safety envelope, enforced by\ncalibrated sensor offsets, ensures collision avoidance, while a multithreaded\narchitecture achieves low-latency processing. Enhanced spatial awareness is\nfacilitated by 3D bounding box estimation with Kalman filtering. Experimental\nresults in an indoor testbed demonstrate strong performance, with object\ndetection achieving a mean Average Precision (mAP50) of 0.6, depth estimation\nMean Absolute Error (MAE) of 7.2 cm, only 16 safety envelope breaches across 42\ntrials over approximately 11 minutes, and end-to-end system latency below 1\nsecond. This cloud-supported, high-intelligence framework serves as an\nauxiliary perception and navigation system, complementing state-of-the-art\ndrone autonomy for GPS-denied confined spaces.", "published": "2025-08-11 12:00:03", "link": "http://arxiv.org/abs/2508.07885v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Selective Contrastive Learning for Weakly Supervised Affordance Grounding", "abstract": "Facilitating an entity's interaction with objects requires accurately\nidentifying parts that afford specific actions. Weakly supervised affordance\ngrounding (WSAG) seeks to imitate human learning from third-person\ndemonstrations, where humans intuitively grasp functional parts without needing\npixel-level annotations. To achieve this, grounding is typically learned using\na shared classifier across images from different perspectives, along with\ndistillation strategies incorporating part discovery process. However, since\naffordance-relevant parts are not always easily distinguishable, models\nprimarily rely on classification, often focusing on common class-specific\npatterns that are unrelated to affordance. To address this limitation, we move\nbeyond isolated part-level learning by introducing selective prototypical and\npixel contrastive objectives that adaptively learn affordance-relevant cues at\nboth the part and object levels, depending on the granularity of the available\ninformation. Initially, we find the action-associated objects in both\negocentric (object-focused) and exocentric (third-person example) images by\nleveraging CLIP. Then, by cross-referencing the discovered objects of\ncomplementary views, we excavate the precise part-level affordance clues in\neach perspective. By consistently learning to distinguish affordance-relevant\nregions from affordance-irrelevant background context, our approach effectively\nshifts activation from irrelevant areas toward meaningful affordance cues.\nExperimental results demonstrate the effectiveness of our method. Codes are\navailable at github.com/hynnsk/SelectiveCL.", "published": "2025-08-11 11:49:37", "link": "http://arxiv.org/abs/2508.07877v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images", "abstract": "Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer,\nand early, accurate diagnosis is critical to improving patient survival rates\nby guiding treatment decisions. Combining medical expertise with artificial\nintelligence (AI) holds significant promise for enhancing the precision and\nefficiency of IDC detection. In this work, we propose a human-in-the-loop\n(HITL) deep learning system designed to detect IDC in histopathology images.\nThe system begins with an initial diagnosis provided by a high-performance\nEfficientNetV2S model, offering feedback from AI to the human expert. Medical\nprofessionals then review the AI-generated results, correct any misclassified\nimages, and integrate the revised labels into the training dataset, forming a\nfeedback loop from the human back to the AI. This iterative process refines the\nmodel's performance over time. The EfficientNetV2S model itself achieves\nstate-of-the-art performance compared to existing methods in the literature,\nwith an overall accuracy of 93.65\\%. Incorporating the human-in-the-loop system\nfurther improves the model's accuracy using four experimental groups with\nmisclassified images. These results demonstrate the potential of this\ncollaborative approach to enhance AI performance in diagnostic systems. This\nwork contributes to advancing automated, efficient, and highly accurate methods\nfor IDC detection through human-AI collaboration, offering a promising\ndirection for future AI-assisted medical diagnostics.", "published": "2025-08-11 11:45:57", "link": "http://arxiv.org/abs/2508.07875v1", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Vertex Features for Neural Global Illumination", "abstract": "Recent research on learnable neural representations has been widely adopted\nin the field of 3D scene reconstruction and neural rendering applications.\nHowever, traditional feature grid representations often suffer from substantial\nmemory footprint, posing a significant bottleneck for modern parallel computing\nhardware. In this paper, we present neural vertex features, a generalized\nformulation of learnable representation for neural rendering tasks involving\nexplicit mesh surfaces. Instead of uniformly distributing neural features\nthroughout 3D space, our method stores learnable features directly at mesh\nvertices, leveraging the underlying geometry as a compact and structured\nrepresentation for neural processing. This not only optimizes memory\nefficiency, but also improves feature representation by aligning compactly with\nthe surface using task-specific geometric priors. We validate our neural\nrepresentation across diverse neural rendering tasks, with a specific emphasis\non neural radiosity. Experimental results demonstrate that our method reduces\nmemory consumption to only one-fifth (or even less) of grid-based\nrepresentations, while maintaining comparable rendering quality and lowering\ninference overhead.", "published": "2025-08-11 11:10:19", "link": "http://arxiv.org/abs/2508.07852v1", "categories": ["cs.GR", "cs.AI"], "primary_category": "cs.GR"}
{"title": "Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images", "abstract": "Accurate, reliable solar flare prediction is crucial for mitigating potential\ndisruptions to critical infrastructure, while predicting solar flares remains a\nsignificant challenge. Existing methods based on heuristic physical features\noften lack representation learning from solar images. On the other hand,\nend-to-end learning approaches struggle to model long-range temporal\ndependencies in solar images. In this study, we propose Deep Space Weather\nModel (Deep SWM), which is based on multiple deep state space models for\nhandling both ten-channel solar images and long-range spatio-temporal\ndependencies. Deep SWM also features a sparse masked autoencoder, a novel\npretraining strategy that employs a two-phase masking approach to preserve\ncrucial regions such as sunspots while compressing spatial information.\nFurthermore, we built FlareBench, a new public benchmark for solar flare\nprediction covering a full 11-year solar activity cycle, to validate our\nmethod. Our method outperformed baseline methods and even human expert\nperformance on standard metrics in terms of performance and reliability. The\nproject page can be found at https://keio-smilab25.github.io/DeepSWM.", "published": "2025-08-11 11:06:56", "link": "http://arxiv.org/abs/2508.07847v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts", "abstract": "Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex\nmulti-step tasks that require continuous planning, sequential decision-making,\nand extended execution across domains to achieve the final goal. However,\nexisting methods heavily rely on skill chaining by concatenating pre-trained\nsubtasks, with environment observations and self-state tightly coupled, lacking\nthe ability to generalize to new combinations of environments and skills,\nfailing to complete various LH tasks across domains. To solve this problem,\nthis paper presents DETACH, a cross-domain learning framework for LH tasks via\nbiologically inspired dual-stream disentanglement. Inspired by the brain's\n\"where-what\" dual pathway mechanism, DETACH comprises two core modules: i) an\nenvironment learning module for spatial understanding, which captures object\nfunctions, spatial relationships, and scene semantics, achieving cross-domain\ntransfer through complete environment-self disentanglement; ii) a skill\nlearning module for task execution, which processes self-state information\nincluding joint degrees of freedom and motor patterns, enabling cross-skill\ntransfer through independent motor pattern encoding. We conducted extensive\nexperiments on various LH tasks in HSI scenes. Compared with existing methods,\nDETACH can achieve an average subtasks success rate improvement of 23% and\naverage execution efficiency improvement of 29%.", "published": "2025-08-11 10:54:28", "link": "http://arxiv.org/abs/2508.07842v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations", "abstract": "Over the years, the need for rescue operations throughout the world has\nincreased rapidly. Demographic changes and the resulting risk of injury or\nhealth disorders form the basis for emergency calls. In such scenarios, first\nresponders are in a rush to reach the patient in need, provide first aid, and\nsave lives. In these situations, they must be able to provide personalized and\noptimized healthcare in the shortest possible time and estimate the patients\ncondition with the help of freshly recorded vital data in an emergency\nsituation. However, in such a timedependent situation, first responders and\nmedical experts cannot fully grasp their knowledge and need assistance and\nrecommendation for further medical treatments. To achieve this, on the spot\ncalculated, evaluated, and processed knowledge must be made available to\nimprove treatments by first responders. The Knowledge Graph presented in this\narticle as a central knowledge representation provides first responders with an\ninnovative knowledge management that enables intelligent treatment\nrecommendations with an artificial intelligence-based pre-recognition of the\nsituation.", "published": "2025-08-11 10:39:15", "link": "http://arxiv.org/abs/2508.07834v1", "categories": ["cs.AI", "cs.ET"], "primary_category": "cs.AI"}
{"title": "Auditory Intelligence: Understanding the World Through Sound", "abstract": "Recent progress in auditory intelligence has yielded high-performing systems\nfor sound event detection (SED), acoustic scene classification (ASC), automated\naudio captioning (AAC), and audio question answering (AQA). Yet these tasks\nremain largely constrained to surface-level recognition-capturing what happened\nbut not why, what it implies, or how it unfolds in context. I propose a\nconceptual reframing of auditory intelligence as a layered, situated process\nthat encompasses perception, reasoning, and interaction. To instantiate this\nview, I introduce four cognitively inspired task paradigms-ASPIRE, SODA, AUX,\nand AUGMENT-those structure auditory understanding across time-frequency\npattern captioning, hierarchical event/scene description, causal explanation,\nand goal-driven interpretation, respectively. Together, these paradigms provide\na roadmap toward more generalizable, explainable, and human-aligned auditory\nintelligence, and are intended to catalyze a broader discussion of what it\nmeans for machines to understand sound.", "published": "2025-08-11 10:25:58", "link": "http://arxiv.org/abs/2508.07829v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP", "abstract": "Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap\nwhen applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of\nlocal inductive biases for dense prediction and their reliance on inflexible\nfeature fusion paradigms. We address these limitations through an Architectural\nCo-Design framework that jointly refines feature representation and cross-modal\nfusion. Our method integrates a parameter-efficient Convolutional Low-Rank\nAdaptation (Conv-LoRA) adapter to inject local inductive biases for\nfine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that\nleverages visual context to adaptively modulate text prompts, enabling a\npowerful bidirectional fusion. Extensive experiments on diverse industrial and\nmedical benchmarks demonstrate superior accuracy and robustness, validating\nthat this synergistic co-design is critical for robustly adapting foundation\nmodels to dense perception tasks.", "published": "2025-08-11 10:03:45", "link": "http://arxiv.org/abs/2508.07819v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer", "abstract": "The core role of medical images in disease diagnosis makes their quality\ndirectly affect the accuracy of clinical judgment. However, due to factors such\nas low-dose scanning, equipment limitations and imaging artifacts, medical\nimages are often accompanied by non-uniform noise interference, which seriously\naffects structure recognition and lesion detection. This paper proposes a\nmedical image adaptive denoising model (MI-ND) that integrates multi-scale\nconvolutional and Transformer architecture, introduces a noise level estimator\n(NLE) and a noise adaptive attention module (NAAB), and realizes\nchannel-spatial attention regulation and cross-modal feature fusion driven by\nnoise perception. Systematic testing is carried out on multimodal public\ndatasets. Experiments show that this method significantly outperforms the\ncomparative methods in image quality indicators such as PSNR, SSIM, and LPIPS,\nand improves the F1 score and ROC-AUC in downstream diagnostic tasks, showing\nstrong prac-tical value and promotional potential. The model has outstanding\nbenefits in structural recovery, diagnostic sensitivity, and cross-modal\nrobustness, and provides an effective solution for medical image enhancement\nand AI-assisted diagnosis and treatment.", "published": "2025-08-11 10:00:51", "link": "http://arxiv.org/abs/2508.07817v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "eess.IV"}
{"title": "Best-Effort Policies for Robust Markov Decision Processes", "abstract": "We study the common generalization of Markov decision processes (MDPs) with\nsets of transition probabilities, known as robust MDPs (RMDPs). A standard goal\nin RMDPs is to compute a policy that maximizes the expected return under an\nadversarial choice of the transition probabilities. If the uncertainty in the\nprobabilities is independent between the states, known as s-rectangularity,\nsuch optimal robust policies can be computed efficiently using robust value\niteration. However, there might still be multiple optimal robust policies,\nwhich, while equivalent with respect to the worst-case, reflect different\nexpected returns under non-adversarial choices of the transition probabilities.\nHence, we propose a refined policy selection criterion for RMDPs, drawing\ninspiration from the notions of dominance and best-effort in game theory.\nInstead of seeking a policy that only maximizes the worst-case expected return,\nwe additionally require the policy to achieve a maximal expected return under\ndifferent (i.e., not fully adversarial) transition probabilities. We call such\na policy an optimal robust best-effort (ORBE) policy. We prove that ORBE\npolicies always exist, characterize their structure, and present an algorithm\nto compute them with a small overhead compared to standard robust value\niteration. ORBE policies offer a principled tie-breaker among optimal robust\npolicies. Numerical experiments show the feasibility of our approach.", "published": "2025-08-11 09:18:34", "link": "http://arxiv.org/abs/2508.07790v1", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "PCA-Guided Autoencoding for Structured Dimensionality Reduction in Active Infrared Thermography", "abstract": "Active Infrared thermography (AIRT) is a widely adopted non-destructive\ntesting (NDT) technique for detecting subsurface anomalies in industrial\ncomponents. Due to the high dimensionality of AIRT data, current approaches\nemploy non-linear autoencoders (AEs) for dimensionality reduction. However, the\nlatent space learned by AIRT AEs lacks structure, limiting their effectiveness\nin downstream defect characterization tasks. To address this limitation, this\npaper proposes a principal component analysis guided (PCA-guided) autoencoding\nframework for structured dimensionality reduction to capture intricate,\nnon-linear features in thermographic signals while enforcing a structured\nlatent space. A novel loss function, PCA distillation loss, is introduced to\nguide AIRT AEs to align the latent representation with structured PCA\ncomponents while capturing the intricate, non-linear patterns in thermographic\nsignals. To evaluate the utility of the learned, structured latent space, we\npropose a neural network-based evaluation metric that assesses its suitability\nfor defect characterization. Experimental results show that the proposed\nPCA-guided AE outperforms state-of-the-art dimensionality reduction methods on\nPVC, CFRP, and PLA samples in terms of contrast, signal-to-noise ratio (SNR),\nand neural network-based metrics.", "published": "2025-08-11 08:58:13", "link": "http://arxiv.org/abs/2508.07773v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models", "abstract": "Unlike bitmap images, scalable vector graphics (SVG) maintain quality when\nscaled, frequently employed in computer vision and artistic design in the\nrepresentation of SVG code. In this era of proliferating AI-powered systems,\nenabling AI to understand and generate SVG has become increasingly urgent.\nHowever, AI-driven SVG understanding and generation (U&G) remain significant\nchallenges. SVG code, equivalent to a set of curves and lines controlled by\nfloating-point parameters, demands high precision in SVG U&G. Besides, SVG\ngeneration operates under diverse conditional constraints, including textual\nprompts and visual references, which requires powerful multi-modal processing\nfor condition-to-SVG transformation. Recently, the rapid growth of Multi-modal\nLarge Language Models (MLLMs) have demonstrated capabilities to process\nmulti-modal inputs and generate complex vector controlling parameters,\nsuggesting the potential to address SVG U&G tasks within a unified model. To\nunlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset\ncalled UniSVG, comprising 525k data items, tailored for MLLM training and\nevaluation. To our best knowledge, it is the first comprehensive dataset\ndesigned for unified SVG generation (from textual prompts and images) and SVG\nunderstanding (color, category, usage, etc.). As expected, learning on the\nproposed dataset boosts open-source MLLMs' performance on various SVG U&G\ntasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset,\nbenchmark, weights, codes and experiment details on\nhttps://ryanlijinke.github.io/.", "published": "2025-08-11 08:50:14", "link": "http://arxiv.org/abs/2508.07766v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Sparse Probabilistic Graph Circuits", "abstract": "Deep generative models (DGMs) for graphs achieve impressively high expressive\npower thanks to very efficient and scalable neural networks. However, these\nnetworks contain non-linearities that prevent analytical computation of many\nstandard probabilistic inference queries, i.e., these DGMs are considered\n\\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs)\naddress this issue by enabling \\emph{tractable} probabilistic inference, they\noperate on dense graph representations with $\\mathcal{O}(n^2)$ complexity for\ngraphs with $n$ nodes and \\emph{$m$ edges}. To address this scalability issue,\nwe introduce Sparse PGCs, a new class of tractable generative models that\noperate directly on sparse graph representation, reducing the complexity to\n$\\mathcal{O}(n + m)$, which is particularly beneficial for $m \\ll n^2$. In the\ncontext of de novo drug design, we empirically demonstrate that SPGCs retain\nexact inference capabilities, improve memory efficiency and inference speed,\nand match the performance of intractable DGMs in key metrics.", "published": "2025-08-11 08:47:27", "link": "http://arxiv.org/abs/2508.07763v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation", "abstract": "Insider threats, which can lead to severe losses, remain a major security\nconcern. While machine learning-based insider threat detection (ITD) methods\nhave shown promising results, their progress is hindered by the scarcity of\nhigh-quality data. Enterprise data is sensitive and rarely accessible, while\npublicly available datasets, when limited in scale due to cost, lack sufficient\nreal-world coverage; and when purely synthetic, they fail to capture rich\nsemantics and realistic user behavior. To address this, we propose Chimera, the\nfirst large language model (LLM)-based multi-agent framework that automatically\nsimulates both benign and malicious insider activities and collects diverse\nlogs across diverse enterprise environments. Chimera models each employee with\nagents that have role-specific behavior and integrates modules for group\nmeetings, pairwise interactions, and autonomous scheduling, capturing realistic\norganizational dynamics. It incorporates 15 types of insider attacks (e.g., IP\ntheft, system sabotage) and has been deployed to simulate activities in three\nsensitive domains: technology company, finance corporation, and medical\ninstitution, producing a new dataset, ChimeraLog. We assess ChimeraLog via\nhuman studies and quantitative analysis, confirming its diversity, realism, and\npresence of explainable threat patterns. Evaluations of existing ITD methods\nshow an average F1-score of 0.83, which is significantly lower than 0.99 on the\nCERT dataset, demonstrating ChimeraLog's higher difficulty and utility for\nadvancing ITD research.", "published": "2025-08-11 08:24:48", "link": "http://arxiv.org/abs/2508.07745v1", "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Symmetry-Aware Transformer Training for Automated Planning", "abstract": "While transformers excel in many settings, their application in the field of\nautomated planning is limited. Prior work like PlanGPT, a state-of-the-art\ndecoder-only transformer, struggles with extrapolation from easy to hard\nplanning problems. This in turn stems from problem symmetries: planning tasks\ncan be represented with arbitrary variable names that carry no meaning beyond\nbeing identifiers. This causes a combinatorial explosion of equivalent\nrepresentations that pure transformers cannot efficiently learn from. We\npropose a novel contrastive learning objective to make transformers\nsymmetry-aware and thereby compensate for their lack of inductive bias.\nCombining this with architectural improvements, we show that transformers can\nbe efficiently trained for either plan-generation or heuristic-prediction. Our\nresults across multiple planning domains demonstrate that our symmetry-aware\ntraining effectively and efficiently addresses the limitations of PlanGPT.", "published": "2025-08-11 08:23:34", "link": "http://arxiv.org/abs/2508.07743v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases", "abstract": "Repair-based semantics have been extensively studied as a means of obtaining\nmeaningful answers to queries posed over inconsistent knowledge bases (KBs).\nWhile several works have considered how to exploit a priority relation between\nfacts to select optimal repairs, the question of how to specify such\npreferences remains largely unaddressed. This motivates us to introduce a\ndeclarative rule-based framework for specifying and computing a priority\nrelation between conflicting facts. As the expressed preferences may contain\nundesirable cycles, we consider the problem of determining when a set of\npreference rules always yields an acyclic relation, and we also explore a\npragmatic approach that extracts an acyclic relation by applying various cycle\nremoval techniques. Towards an end-to-end system for querying inconsistent KBs,\nwe present a preliminary implementation and experimental evaluation of the\nframework, which employs answer set programming to evaluate the preference\nrules, apply the desired cycle resolution techniques to obtain a priority\nrelation, and answer queries under prioritized-repair semantics.", "published": "2025-08-11 08:21:02", "link": "http://arxiv.org/abs/2508.07742v1", "categories": ["cs.LO", "cs.AI", "cs.DB"], "primary_category": "cs.LO"}
{"title": "CognitiveArm: Enabling Real-Time EEG-Controlled Prosthetic Arm Using Embodied Machine Learning", "abstract": "Efficient control of prosthetic limbs via non-invasive brain-computer\ninterfaces (BCIs) requires advanced EEG processing, including pre-filtering,\nfeature extraction, and action prediction, performed in real time on edge AI\nhardware. Achieving this on resource-constrained devices presents challenges in\nbalancing model complexity, computational efficiency, and latency. We present\nCognitiveArm, an EEG-driven, brain-controlled prosthetic system implemented on\nembedded AI hardware, achieving real-time operation without compromising\naccuracy. The system integrates BrainFlow, an open-source library for EEG data\nacquisition and streaming, with optimized deep learning (DL) models for precise\nbrain signal classification. Using evolutionary search, we identify\nPareto-optimal DL configurations through hyperparameter tuning, optimizer\nanalysis, and window selection, analyzed individually and in ensemble\nconfigurations. We apply model compression techniques such as pruning and\nquantization to optimize models for embedded deployment, balancing efficiency\nand accuracy. We collected an EEG dataset and designed an annotation pipeline\nenabling precise labeling of brain signals corresponding to specific intended\nactions, forming the basis for training our optimized DL models. CognitiveArm\nalso supports voice commands for seamless mode switching, enabling control of\nthe prosthetic arm's 3 degrees of freedom (DoF). Running entirely on embedded\nhardware, it ensures low latency and real-time responsiveness. A full-scale\nprototype, interfaced with the OpenBCI UltraCortex Mark IV EEG headset,\nachieved up to 90% accuracy in classifying three core actions (left, right,\nidle). Voice integration enables multiplexed, variable movement for everyday\ntasks (e.g., handshake, cup picking), enhancing real-world performance and\ndemonstrating CognitiveArm's potential for advanced prosthetic control.", "published": "2025-08-11 08:04:59", "link": "http://arxiv.org/abs/2508.07731v1", "categories": ["cs.HC", "cs.AI", "68T50, 68T40, 68T07, 92C55", "I.2.7; I.2.9"], "primary_category": "cs.HC"}
{"title": "DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models", "abstract": "Accurate detection and classification of diverse door types in floor plans\ndrawings is critical for multiple applications, such as building compliance\nchecking, and indoor scene understanding. Despite their importance, publicly\navailable datasets specifically designed for fine-grained multi-class door\ndetection remain scarce. In this work, we present a semi-automated pipeline\nthat leverages a state-of-the-art object detector and a large language model\n(LLM) to construct a multi-class door detection dataset with minimal manual\neffort. Doors are first detected as a unified category using a deep object\ndetection model. Next, an LLM classifies each detected instance based on its\nvisual and contextual features. Finally, a human-in-the-loop stage ensures\nhigh-quality labels and bounding boxes. Our method significantly reduces\nannotation cost while producing a dataset suitable for benchmarking neural\nmodels in floor plan analysis. This work demonstrates the potential of\ncombining deep learning and multimodal reasoning for efficient dataset\nconstruction in complex real-world domains.", "published": "2025-08-11 07:41:09", "link": "http://arxiv.org/abs/2508.07714v1", "categories": ["cs.CV", "cs.AI", "cs.ET"], "primary_category": "cs.CV"}
{"title": "Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer", "abstract": "Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a\npromising approach for constructing energy-efficient Transformer architectures.\nCompared to directly trained Spiking Transformers, ANN-to-SNN conversion\nmethods bypass the high training costs. However, existing methods still suffer\nfrom notable limitations, failing to effectively handle nonlinear operations in\nTransformer architectures and requiring additional fine-tuning processes for\npre-trained ANNs. To address these issues, we propose a high-performance and\ntraining-free ANN-to-SNN conversion framework tailored for Transformer\narchitectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE)\nneuron, which employs an exponential decay strategy and multi-basis encoding\nmethod to efficiently approximate various nonlinear operations. It removes the\nrequirement for weight modifications in pre-trained ANNs. Extensive experiments\nacross diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures\n(ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless\nconversion accuracy with significantly lower latency. This provides a promising\npathway for the efficient and scalable deployment of Spiking Transformers in\nreal-world applications.", "published": "2025-08-11 07:38:32", "link": "http://arxiv.org/abs/2508.07710v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Energy Consumption in Parallel Neural Network Training", "abstract": "The increasing demand for computational resources of training neural networks\nleads to a concerning growth in energy consumption. While parallelization has\nenabled upscaling model and dataset sizes and accelerated training, its impact\non energy consumption is often overlooked. To close this research gap, we\nconducted scaling experiments for data-parallel training of two models,\nResNet50 and FourCastNet, and evaluated the impact of parallelization\nparameters, i.e., GPU count, global batch size, and local batch size, on\npredictive performance, training time, and energy consumption. We show that\nenergy consumption scales approximately linearly with the consumed resources,\ni.e., GPU hours; however, the respective scaling factor differs substantially\nbetween distinct model trainings and hardware, and is systematically influenced\nby the number of samples and gradient updates per GPU hour. Our results shed\nlight on the complex interplay of scaling up neural network training and can\ninform future developments towards more sustainable AI research.", "published": "2025-08-11 07:34:04", "link": "http://arxiv.org/abs/2508.07706v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding", "abstract": "Temporal Video Grounding (TVG) aims to precisely localize video segments\ncorresponding to natural language queries, which is a critical capability for\nlong-form video understanding. Although existing reinforcement learning\napproaches encourage models to generate reasoning chains before predictions,\nthey fail to explicitly constrain the reasoning process to ensure the quality\nof the final temporal predictions. To address this limitation, we propose\nTimestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG),\na novel framework that introduces timestamp anchors within the reasoning\nprocess to enforce explicit supervision to the thought content. These anchors\nserve as intermediate verification points. More importantly, we require each\nreasoning step to produce increasingly accurate temporal estimations, thereby\nensuring that the reasoning process contributes meaningfully to the final\nprediction. To address the challenge of low-probability anchor generation in\nmodels (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation\ntraining strategy: (1) initial GRPO training to collect 30K high-quality\nreasoning traces containing multiple timestamp anchors, (2) supervised\nfine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the\nSFT-enhanced model. This three-stage training strategy enables robust anchor\ngeneration while maintaining reasoning quality. Experiments show that our model\nachieves state-of-the-art performance while producing interpretable, verifiable\nreasoning chains with progressively refined temporal estimations.", "published": "2025-08-11 06:59:32", "link": "http://arxiv.org/abs/2508.07683v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation", "abstract": "Sepsis, a life-threatening inflammatory response to infection, causes organ\ndysfunction, making early detection and optimal management critical. Previous\nreinforcement learning (RL) approaches to sepsis management rely primarily on\nstructured data, such as lab results or vital signs, and on a dearth of a\ncomprehensive understanding of the patient's condition. In this work, we\npropose a Multimodal Offline REinforcement learning for Clinical notes\nLeveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis\ncontrol in intensive care units. MORE-CLEAR employs pre-trained large-scale\nlanguage models (LLMs) to facilitate the extraction of rich semantic\nrepresentations from clinical notes, preserving clinical context and improving\npatient state representation. Gated fusion and cross-modal attention allow\ndynamic weight adjustment in the context of time and the effective integration\nof multimodal data. Extensive cross-validation using two public (MIMIC-III and\nMIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly\nimproves estimated survival rate and policy performance compared to\nsingle-modal RL approaches. To our knowledge, this is the first to leverage LLM\ncapabilities within a multimodal offline RL for better state representation in\nmedical applications. This approach can potentially expedite the treatment and\nmanagement of sepsis by enabling reinforcement learning models to propose\nenhanced actions based on a more comprehensive understanding of patient\nconditions.", "published": "2025-08-11 06:58:33", "link": "http://arxiv.org/abs/2508.07681v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Ethics2vec: aligning automatic agents and human preferences", "abstract": "Though intelligent agents are supposed to improve human experience (or make\nit more efficient), it is hard from a human perspective to grasp the ethical\nvalues which are explicitly or implicitly embedded in an agent behaviour. This\nis the well-known problem of alignment, which refers to the challenge of\ndesigning AI systems that align with human values, goals and preferences. This\nproblem is particularly challenging since most human ethical considerations\nrefer to \\emph{incommensurable} (i.e. non-measurable and/or incomparable)\nvalues and criteria. Consider, for instance, a medical agent prescribing a\ntreatment to a cancerous patient. How could it take into account (and/or weigh)\nincommensurable aspects like the value of a human life and the cost of the\ntreatment? Now, the alignment between human and artificial values is possible\nonly if we define a common space where a metric can be defined and used. This\npaper proposes to extend to ethics the conventional Anything2vec approach,\nwhich has been successful in plenty of similar and hard-to-quantify domains\n(ranging from natural language processing to recommendation systems and graph\nanalysis). This paper proposes a way to map an automatic agent decision-making\n(or control law) strategy to a multivariate vector representation, which can be\nused to compare and assess the alignment with human values. The Ethics2Vec\nmethod is first introduced in the case of an automatic agent performing binary\ndecision-making. Then, a vectorisation of an automatic control law (like in the\ncase of a self-driving car) is discussed to show how the approach can be\nextended to automatic control settings.", "published": "2025-08-11 06:52:46", "link": "http://arxiv.org/abs/2508.07673v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration", "abstract": "Current AI approaches to refugee integration optimize narrow objectives such\nas employment and fail to capture the cultural, emotional, and ethical\ndimensions critical for long-term success. We introduce EMPATHIA (Enriched\nMultimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),\na multi-agent framework addressing the central Creative AI question: how do we\npreserve human dignity when machines participate in life-altering decisions?\nGrounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes\nintegration into three modules: SEED (Socio-cultural Entry and Embedding\nDecision) for initial placement, RISE (Rapid Integration and Self-sufficiency\nEngine) for early independence, and THRIVE (Transcultural Harmony and\nResilience through Integrated Values and Engagement) for sustained outcomes.\nSEED employs a selector-validator architecture with three specialized agents -\nemotional, cultural, and ethical - that deliberate transparently to produce\ninterpretable recommendations. Experiments on the UN Kakuma dataset (15,026\nindividuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and\nimplementation on 6,359 working-age refugees (15+) with 150+ socioeconomic\nvariables achieved 87.4% validation convergence and explainable assessments\nacross five host countries. EMPATHIA's weighted integration of cultural,\nemotional, and ethical factors balances competing value systems while\nsupporting practitioner-AI collaboration. By augmenting rather than replacing\nhuman expertise, EMPATHIA provides a generalizable framework for AI-driven\nallocation tasks where multiple values must be reconciled.", "published": "2025-08-11 06:50:55", "link": "http://arxiv.org/abs/2508.07671v1", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MA", "stat.AP", "68T07, 68T42, 68T50, 91F20, 62P25", "I.2.11; I.2.1; H.1.2; J.4; K.4.2"], "primary_category": "cs.AI"}
{"title": "AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting", "abstract": "With the increase in maritime traffic and the mandatory implementation of the\nAutomatic Identification System (AIS), the importance and diversity of maritime\ntraffic analysis tasks based on AIS data, such as vessel trajectory prediction,\nanomaly detection, and collision risk assessment, is rapidly growing. However,\nexisting approaches tend to address these tasks individually, making it\ndifficult to holistically consider complex maritime situations. To address this\nlimitation, we propose a novel framework, AIS-LLM, which integrates time-series\nAIS data with a large language model (LLM). AIS-LLM consists of a Time-Series\nEncoder for processing AIS sequences, an LLM-based Prompt Encoder, a\nCross-Modality Alignment Module for semantic alignment between time-series data\nand textual prompts, and an LLM-based Multi-Task Decoder. This architecture\nenables the simultaneous execution of three key tasks: trajectory prediction,\nanomaly detection, and risk assessment of vessel collisions within a single\nend-to-end system. Experimental results demonstrate that AIS-LLM outperforms\nexisting methods across individual tasks, validating its effectiveness.\nFurthermore, by integratively analyzing task outputs to generate situation\nsummaries and briefings, AIS-LLM presents the potential for more intelligent\nand efficient maritime traffic management.", "published": "2025-08-11 06:39:45", "link": "http://arxiv.org/abs/2508.07668v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning", "abstract": "Addressing contextual privacy concerns remains challenging in interactive\nsettings where large language models (LLMs) process information from multiple\nsources (e.g., summarizing meetings with private and public information). We\nintroduce a multi-agent framework that decomposes privacy reasoning into\nspecialized subtasks (extraction, classification), reducing the information\nload on any single agent while enabling iterative validation and more reliable\nadherence to contextual privacy norms. To understand how privacy errors emerge\nand propagate, we conduct a systematic ablation over information-flow\ntopologies, revealing when and why upstream detection mistakes cascade into\ndownstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with\nseveral open-source and closed-sourced LLMs demonstrate that our best\nmulti-agent configuration substantially reduces private information leakage\n(\\textbf{18\\%} on ConfAIde and \\textbf{19\\%} on PrivacyLens with GPT-4o) while\npreserving the fidelity of public content, outperforming single-agent\nbaselines. These results highlight the promise of principled information-flow\ndesign in multi-agent systems for contextual privacy with LLMs.", "published": "2025-08-11 06:34:09", "link": "http://arxiv.org/abs/2508.07667v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning", "abstract": "This study aims to discover spatial correlations between Earth observations\nand atmospheric states to improve the forecasting accuracy of global\natmospheric state estimation, which are usually conducted using conventional\nnumerical weather prediction (NWP) systems and is the beginning of weather\nforecasting. NWP systems predict future atmospheric states at fixed locations,\nwhich are called NWP grid points, by analyzing previous atmospheric states and\nnewly acquired Earth observations without fixed locations. Thus, surrounding\nmeteorological context and the changing locations of the observations make\nspatial correlations between atmospheric states and observations over time. To\nhandle complicated spatial correlations, which change dynamically, we employ\nspatiotemporal graph neural networks (STGNNs) with structure learning. However,\nstructure learning has an inherent limitation that this can cause structural\ninformation loss and over-smoothing problem by generating excessive edges. To\nsolve this problem, we regulate edge sampling by adaptively determining node\ndegrees and considering the spatial distances between NWP grid points and\nobservations. We validated the effectiveness of the proposed method by using\nreal-world atmospheric state and observation data from East Asia. Even in areas\nwith high atmospheric variability, the proposed method outperformed existing\nSTGNN models with and without structure learning.", "published": "2025-08-11 06:14:31", "link": "http://arxiv.org/abs/2508.07659v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation", "abstract": "Next Point-of-Interest (POI) recommendation is a research hotspot in business\nintelligence, where users' spatial-temporal transitions and social\nrelationships play key roles. However, most existing works model spatial and\ntemporal transitions separately, leading to misaligned representations of the\nsame spatial-temporal key nodes. This misalignment introduces redundant\ninformation during fusion, increasing model uncertainty and reducing\ninterpretability. To address this issue, we propose DiMuST, a socially enhanced\nPOI recommendation model based on disentangled representation learning over\nmultiplex spatial-temporal transition graphs. The model employs a novel\nDisentangled variational multiplex graph Auto-Encoder (DAE), which first\ndisentangles shared and private distributions using a multiplex\nspatial-temporal graph strategy. It then fuses the shared features via a\nProduct of Experts (PoE) mechanism and denoises the private features through\ncontrastive constraints. The model effectively captures the spatial-temporal\ntransition representations of POIs while preserving the intrinsic correlation\nof their spatial-temporal relationships. Experiments on two challenging\ndatasets demonstrate that our DiMuST significantly outperforms existing methods\nacross multiple metrics.", "published": "2025-08-11 06:00:20", "link": "http://arxiv.org/abs/2508.07649v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Grasp-HGN: Grasping the Unexpected", "abstract": "For transradial amputees, robotic prosthetic hands promise to regain the\ncapability to perform daily living activities. To advance next-generation\nprosthetic hand control design, it is crucial to address current shortcomings\nin robustness to out of lab artifacts, and generalizability to new\nenvironments. Due to the fixed number of object to interact with in existing\ndatasets, contrasted with the virtually infinite variety of objects encountered\nin the real world, current grasp models perform poorly on unseen objects,\nnegatively affecting users' independence and quality of life.\n  To address this: (i) we define semantic projection, the ability of a model to\ngeneralize to unseen object types and show that conventional models like YOLO,\ndespite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose\nGrasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to\ninfer the suitable grasp type estimate based on the object's physical\ncharacteristics resulting in a significant 50.2% accuracy over unseen object\ntypes compared to 36.7% accuracy of an SOTA grasp estimation model.\n  Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp\nNetwork (HGN), an edge-cloud deployment infrastructure enabling fast grasp\nestimation on edge and accurate cloud inference as a fail-safe, effectively\nexpanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC)\nenables dynamic switching between edge and cloud models, improving semantic\nprojection accuracy by 5.6% (to 42.3%) with 3.5x speedup over the unseen object\ntypes. Over a real-world sample mix, it reaches 86% average accuracy (12.2%\ngain over edge-only), and 2.2x faster inference than Grasp-LLaVA alone.", "published": "2025-08-11 05:58:28", "link": "http://arxiv.org/abs/2508.07648v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Attribution Explanations for Deep Neural Networks: A Theoretical Perspective", "abstract": "Attribution explanation is a typical approach for explaining deep neural\nnetworks (DNNs), inferring an importance or contribution score for each input\nvariable to the final output. In recent years, numerous attribution methods\nhave been developed to explain DNNs. However, a persistent concern remains\nunresolved, i.e., whether and which attribution methods faithfully reflect the\nactual contribution of input variables to the decision-making process. The\nfaithfulness issue undermines the reliability and practical utility of\nattribution explanations. We argue that these concerns stem from three core\nchallenges. First, difficulties arise in comparing attribution methods due to\ntheir unstructured heterogeneity, differences in heuristics, formulations, and\nimplementations that lack a unified organization. Second, most methods lack\nsolid theoretical underpinnings, with their rationales remaining absent,\nambiguous, or unverified. Third, empirically evaluating faithfulness is\nchallenging without ground truth. Recent theoretical advances provide a\npromising way to tackle these challenges, attracting increasing attention. We\nsummarize these developments, with emphasis on three key directions: (i)\nTheoretical unification, which uncovers commonalities and differences among\nmethods, enabling systematic comparisons; (ii) Theoretical rationale,\nclarifying the foundations of existing methods; (iii) Theoretical evaluation,\nrigorously proving whether methods satisfy faithfulness principles. Beyond a\ncomprehensive review, we provide insights into how these studies help deepen\ntheoretical understanding, inform method selection, and inspire new attribution\nmethods. We conclude with a discussion of promising open problems for further\nwork.", "published": "2025-08-11 05:41:20", "link": "http://arxiv.org/abs/2508.07636v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo", "abstract": "We study the problem of posterior sampling in the context of score based\ngenerative models. We have a trained score network for a prior $p(x)$, a\nmeasurement model $p(y|x)$, and are tasked with sampling from the posterior\n$p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case)\nunder well-accepted computational hardness assumptions. Despite this, popular\nalgorithms for tasks such as image super-resolution, stylization, and\nreconstruction enjoy empirical success. Rather than establishing distributional\nassumptions or restricted settings under which exact posterior sampling is\ntractable, we view this as a more general \"tilting\" problem of biasing a\ndistribution towards a measurement. Under minimal assumptions, we show that one\ncan tractably sample from a distribution that is simultaneously close to the\nposterior of a noised prior in KL divergence and the true posterior in Fisher\ndivergence. Intuitively, this combination ensures that the resulting sample is\nconsistent with both the measurement and the prior. To the best of our\nknowledge these are the first formal results for (approximate) posterior\nsampling in polynomial time.", "published": "2025-08-11 05:25:24", "link": "http://arxiv.org/abs/2508.07631v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization", "abstract": "The future of poultry production depends on a paradigm shift replacing\nsubjective, labor-intensive welfare checks with data-driven, intelligent\nmonitoring ecosystems. Traditional welfare assessments-limited by human\nobservation and single-sensor data-cannot fully capture the complex,\nmultidimensional nature of laying hen welfare in modern farms. Multimodal\nArtificial Intelligence (AI) offers a breakthrough, integrating visual,\nacoustic, environmental, and physiological data streams to reveal deeper\ninsights into avian welfare dynamics. This investigation highlights multimodal\nAs transformative potential, showing that intermediate (feature-level) fusion\nstrategies achieve the best balance between robustness and performance under\nreal-world poultry conditions, and offer greater scalability than early or late\nfusion approaches. Key adoption barriers include sensor fragility in harsh farm\nenvironments, high deployment costs, inconsistent behavioral definitions, and\nlimited cross-farm generalizability. To address these, we introduce two novel\nevaluation tools - the Domain Transfer Score (DTS) to measure model\nadaptability across diverse farm settings, and the Data Reliability Index (DRI)\nto assess sensor data quality under operational constraints. We also propose a\nmodular, context-aware deployment framework designed for laying hen\nenvironments, enabling scalable and practical integration of multimodal\nsensing. This work lays the foundation for a transition from reactive, unimodal\nmonitoring to proactive, precision-driven welfare systems that unite\nproductivity with ethical, science based animal care.", "published": "2025-08-11 05:17:16", "link": "http://arxiv.org/abs/2508.07628v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation", "abstract": "Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with\ncatheter ablation procedures, but procedural outcomes are highly variable.\nEvaluating and improving ablation efficacy is challenging due to the complex\ninteraction between patient-specific tissue and procedural factors. This paper\nasks two questions: Can AF recurrence be predicted by simulating the effects of\nprocedural parameters? How should we ablate to reduce AF recurrence? We propose\nSOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel\ndeep-learning framework that addresses these questions. SOFA first simulates\nthe outcome of an ablation strategy by generating a post-ablation image\ndepicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and\nthe specific procedural parameters used (e.g., ablation locations, duration,\ntemperature, power, and force). During this simulation, it predicts AF\nrecurrence risk. Critically, SOFA then introduces an optimization scheme that\nrefines these procedural parameters to minimize the predicted risk. Our method\nleverages a multi-modal, multi-view generator that processes 2.5D\nrepresentations of the atrium. Quantitative evaluations show that SOFA\naccurately synthesizes post-ablation images and that our optimization scheme\nleads to a 22.18\\% reduction in the model-predicted recurrence risk. To the\nbest of our knowledge, SOFA is the first framework to integrate the simulation\nof procedural effects, recurrence prediction, and parameter optimization,\noffering a novel tool for personalizing AF ablation.", "published": "2025-08-11 05:01:54", "link": "http://arxiv.org/abs/2508.07621v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "On the Limits of Selective AI Prediction: A Case Study in Clinical Decision Making", "abstract": "AI has the potential to augment human decision making. However, even\nhigh-performing models can produce inaccurate predictions when deployed. These\ninaccuracies, combined with automation bias, where humans overrely on AI\npredictions, can result in worse decisions. Selective prediction, in which\npotentially unreliable model predictions are hidden from users, has been\nproposed as a solution. This approach assumes that when AI abstains and informs\nthe user so, humans make decisions as they would without AI involvement. To\ntest this assumption, we study the effects of selective prediction on human\ndecisions in a clinical context. We conducted a user study of 259 clinicians\ntasked with diagnosing and treating hospitalized patients. We compared their\nbaseline performance without any AI involvement to their AI-assisted accuracy\nwith and without selective prediction. Our findings indicate that selective\nprediction mitigates the negative effects of inaccurate AI in terms of decision\naccuracy. Compared to no AI assistance, clinician accuracy declined when shown\ninaccurate AI predictions (66% [95% CI: 56%-75%] vs. 56% [95% CI: 46%-66%]),\nbut recovered under selective prediction (64% [95% CI: 54%-73%]). However,\nwhile selective prediction nearly maintains overall accuracy, our results\nsuggest that it alters patterns of mistakes: when informed the AI abstains,\nclinicians underdiagnose (18% increase in missed diagnoses) and undertreat (35%\nincrease in missed treatments) compared to no AI input at all. Our findings\nunderscore the importance of empirically validating assumptions about how\nhumans engage with AI within human-AI systems.", "published": "2025-08-11 04:53:13", "link": "http://arxiv.org/abs/2508.07617v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Learning an Implicit Physics Model for Image-based Fluid Simulation", "abstract": "Humans possess an exceptional ability to imagine 4D scenes, encompassing both\nmotion and 3D geometry, from a single still image. This ability is rooted in\nour accumulated observations of similar scenes and an intuitive understanding\nof physics. In this paper, we aim to replicate this capacity in neural\nnetworks, specifically focusing on natural fluid imagery. Existing methods for\nthis task typically employ simplistic 2D motion estimators to animate the\nimage, leading to motion predictions that often defy physical principles,\nresulting in unrealistic animations. Our approach introduces a novel method for\ngenerating 4D scenes with physics-consistent animation from a single image. We\npropose the use of a physics-informed neural network that predicts motion for\neach surface point, guided by a loss term derived from fundamental physical\nprinciples, including the Navier-Stokes equations. To capture appearance, we\npredict feature-based 3D Gaussians from the input image and its estimated\ndepth, which are then animated using the predicted motions and rendered from\nany desired camera perspective. Experimental results highlight the\neffectiveness of our method in producing physically plausible animations,\nshowcasing significant performance improvements over existing methods. Our\nproject page is https://physfluid.github.io/ .", "published": "2025-08-11 17:59:58", "link": "http://arxiv.org/abs/2508.08254v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ReferSplat: Referring Segmentation in 3D Gaussian Splatting", "abstract": "We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task\nthat aims to segment target objects in a 3D Gaussian scene based on natural\nlanguage descriptions, which often contain spatial relationships or object\nattributes. This task requires the model to identify newly described objects\nthat may be occluded or not directly visible in a novel view, posing a\nsignificant challenge for 3D multi-modal understanding. Developing this\ncapability is crucial for advancing embodied AI. To support research in this\narea, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that\n3D multi-modal understanding and spatial relationship modeling are key\nchallenges for R3DGS. To address these challenges, we propose ReferSplat, a\nframework that explicitly models 3D Gaussian points with natural language\nexpressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art\nperformance on both the newly proposed R3DGS task and 3D open-vocabulary\nsegmentation benchmarks. Dataset and code are available at\nhttps://github.com/heshuting555/ReferSplat.", "published": "2025-08-11 17:59:30", "link": "http://arxiv.org/abs/2508.08252v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation", "abstract": "Current diffusion models for audio-driven avatar video generation struggle to\nsynthesize long videos with natural audio synchronization and identity\nconsistency. This paper presents StableAvatar, the first end-to-end video\ndiffusion transformer that synthesizes infinite-length high-quality videos\nwithout post-processing. Conditioned on a reference image and audio,\nStableAvatar integrates tailored training and inference modules to enable\ninfinite-length video generation. We observe that the main reason preventing\nexisting models from generating long videos lies in their audio modeling. They\ntypically rely on third-party off-the-shelf extractors to obtain audio\nembeddings, which are then directly injected into the diffusion model via\ncross-attention. Since current diffusion backbones lack any audio-related\npriors, this approach causes severe latent distribution error accumulation\nacross video clips, leading the latent distribution of subsequent segments to\ndrift away from the optimal distribution gradually. To address this,\nStableAvatar introduces a novel Time-step-aware Audio Adapter that prevents\nerror accumulation via time-step-aware modulation. During inference, we propose\na novel Audio Native Guidance Mechanism to further enhance the audio\nsynchronization by leveraging the diffusion's own evolving joint audio-latent\nprediction as a dynamic guidance signal. To enhance the smoothness of the\ninfinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy\nthat fuses latent over time. Experiments on benchmarks show the effectiveness\nof StableAvatar both qualitatively and quantitatively.", "published": "2025-08-11 17:58:24", "link": "http://arxiv.org/abs/2508.08248v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks", "abstract": "Language-guided long-horizon mobile manipulation has long been a grand\nchallenge in embodied semantic reasoning, generalizable manipulation, and\nadaptive locomotion. Three fundamental limitations hinder progress: First,\nalthough large language models have improved spatial reasoning and task\nplanning through semantic priors, existing implementations remain confined to\ntabletop scenarios, failing to address the constrained perception and limited\nactuation ranges of mobile platforms. Second, current manipulation strategies\nexhibit insufficient generalization when confronted with the diverse object\nconfigurations encountered in open-world environments. Third, while crucial for\npractical deployment, the dual requirement of maintaining high platform\nmaneuverability alongside precise end-effector control in unstructured settings\nremains understudied.\n  In this work, we present ODYSSEY, a unified mobile manipulation framework for\nagile quadruped robots equipped with manipulators, which seamlessly integrates\nhigh-level task planning with low-level whole-body control. To address the\nchallenge of egocentric perception in language-conditioned tasks, we introduce\na hierarchical planner powered by a vision-language model, enabling\nlong-horizon instruction decomposition and precise action execution. At the\ncontrol level, our novel whole-body policy achieves robust coordination across\nchallenging terrains. We further present the first benchmark for long-horizon\nmobile manipulation, evaluating diverse indoor and outdoor scenarios. Through\nsuccessful sim-to-real transfer, we demonstrate the system's generalization and\nrobustness in real-world deployments, underscoring the practicality of legged\nmanipulators in unstructured environments. Our work advances the feasibility of\ngeneralized robotic assistants capable of complex, dynamic tasks. Our project\npage: https://kaijwang.github.io/odyssey.github.io/", "published": "2025-08-11 17:54:31", "link": "http://arxiv.org/abs/2508.08240v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Learning User Preferences for Image Generation Model", "abstract": "User preference prediction requires a comprehensive and accurate\nunderstanding of individual tastes. This includes both surface-level\nattributes, such as color and style, and deeper content-related aspects, such\nas themes and composition. However, existing methods typically rely on general\nhuman preferences or assume static user profiles, often neglecting individual\nvariability and the dynamic, multifaceted nature of personal taste. To address\nthese limitations, we propose an approach built upon Multimodal Large Language\nModels, introducing contrastive preference loss and preference tokens to learn\npersonalized user preferences from historical interactions. The contrastive\npreference loss is designed to effectively distinguish between user ''likes''\nand ''dislikes'', while the learnable preference tokens capture shared interest\nrepresentations among existing users, enabling the model to activate\ngroup-specific preferences and enhance consistency across similar users.\nExtensive experiments demonstrate our model outperforms other methods in\npreference prediction accuracy, effectively identifying users with similar\naesthetic inclinations and providing more precise guidance for generating\nimages that align with individual tastes. The project page is\n\\texttt{https://learn-user-pref.github.io/}.", "published": "2025-08-11 17:39:42", "link": "http://arxiv.org/abs/2508.08220v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAGOnline: Segment Any Gaussians Online", "abstract": "3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit\n3D scene representation, yet achieving efficient and consistent 3D segmentation\nremains challenging. Current methods suffer from prohibitive computational\ncosts, limited 3D spatial reasoning, and an inability to track multiple objects\nsimultaneously. We present Segment Any Gaussians Online (SAGOnline), a\nlightweight and zero-shot framework for real-time 3D segmentation in Gaussian\nscenes that addresses these limitations through two key innovations: (1) a\ndecoupled strategy that integrates video foundation models (e.g., SAM2) for\nview-consistent 2D mask propagation across synthesized views; and (2) a\nGPU-accelerated 3D mask generation and Gaussian-level instance labeling\nalgorithm that assigns unique identifiers to 3D primitives, enabling lossless\nmulti-object tracking and segmentation across views. SAGOnline achieves\nstate-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU)\nbenchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15--1500 times\nin inference speed (27 ms/frame). Qualitative results demonstrate robust\nmulti-object segmentation and tracking in complex scenes. Our contributions\ninclude: (i) a lightweight and zero-shot framework for 3D segmentation in\nGaussian scenes, (ii) explicit labeling of Gaussian primitives enabling\nsimultaneous segmentation and tracking, and (iii) the effective adaptation of\n2D video foundation models to the 3D domain. This work allows real-time\nrendering and 3D scene understanding, paving the way for practical AR/VR and\nrobotic applications.", "published": "2025-08-11 17:38:50", "link": "http://arxiv.org/abs/2508.08219v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model", "abstract": "Precise spatial modeling in the operating room (OR) is foundational to many\nclinical tasks, supporting intraoperative awareness, hazard avoidance, and\nsurgical decision-making. While existing approaches leverage large-scale\nmultimodal datasets for latent-space alignment to implicitly learn spatial\nrelationships, they overlook the 3D capabilities of MLLMs. However, this\napproach raises two issues: (1) Operating rooms typically lack multiple video\nand audio sensors, making multimodal 3D data difficult to obtain; (2) Training\nsolely on readily available 2D data fails to capture fine-grained details in\ncomplex scenes. To address this gap, we introduce Spatial-ORMLLM, the first\nlarge vision-language model for 3D spatial reasoning in operating rooms using\nonly RGB modality to infer volumetric and semantic cues, enabling downstream\nmedical tasks with detailed and holistic spatial context. Spatial-ORMLLM\nincorporates a Spatial-Enhanced Feature Fusion Block, which integrates 2D\nmodality inputs with rich 3D spatial knowledge extracted by the estimation\nalgorithm and then feeds the combined features into the visual tower. By\nemploying a unified end-to-end MLLM framework, it combines powerful spatial\nfeatures with textual features to deliver robust 3D scene reasoning without any\nadditional expert annotations or sensor inputs. Experiments on multiple\nbenchmark clinical datasets demonstrate that Spatial-ORMLLM achieves\nstate-of-the-art performance and generalizes robustly to previously unseen\nsurgical scenarios and downstream tasks.", "published": "2025-08-11 17:17:20", "link": "http://arxiv.org/abs/2508.08199v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reinforcement Learning in Vision: A Survey", "abstract": "Recent advances at the intersection of reinforcement learning (RL) and visual\nintelligence have enabled agents that not only perceive complex visual scenes\nbut also reason, generate, and act within them. This survey offers a critical\nand up-to-date synthesis of the field. We first formalize visual RL problems\nand trace the evolution of policy-optimization strategies from RLHF to\nverifiable reward paradigms, and from Proximal Policy Optimization to Group\nRelative Policy Optimization. We then organize more than 200 representative\nworks into four thematic pillars: multi-modal large language models, visual\ngeneration, unified model frameworks, and vision-language-action models. For\neach pillar we examine algorithmic design, reward engineering, benchmark\nprogress, and we distill trends such as curriculum-driven training,\npreference-aligned diffusion, and unified reward modeling. Finally, we review\nevaluation protocols spanning set-level fidelity, sample-level preference, and\nstate-level stability, and we identify open challenges that include sample\nefficiency, generalization, and safe deployment. Our goal is to provide\nresearchers and practitioners with a coherent map of the rapidly expanding\nlandscape of visual RL and to highlight promising directions for future\ninquiry. Resources are available at:\nhttps://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.", "published": "2025-08-11 17:08:55", "link": "http://arxiv.org/abs/2508.08189v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning", "abstract": "Semantic segmentation of structural defects in civil infrastructure remains\nchallenging due to variable defect appearances, harsh imaging conditions, and\nsignificant class imbalance. Current deep learning methods, despite their\neffectiveness, typically require millions of parameters, rendering them\nimpractical for real-time inspection systems. We introduce KARMA\n(Kolmogorov-Arnold Representation Mapping Architecture), a highly efficient\nsemantic segmentation framework that models complex defect patterns through\ncompositions of one-dimensional functions rather than conventional\nconvolutions. KARMA features three technical innovations: (1) a\nparameter-efficient Tiny Kolmogorov-Arnold Network (TiKAN) module leveraging\nlow-rank factorization for KAN-based feature transformation; (2) an optimized\nfeature pyramid structure with separable convolutions for multi-scale defect\nanalysis; and (3) a static-dynamic prototype mechanism that enhances feature\nrepresentation for imbalanced classes. Extensive experiments on benchmark\ninfrastructure inspection datasets demonstrate that KARMA achieves competitive\nor superior mean IoU performance compared to state-of-the-art approaches, while\nusing significantly fewer parameters (0.959M vs. 31.04M, a 97% reduction).\nOperating at 0.264 GFLOPS, KARMA maintains inference speeds suitable for\nreal-time deployment, enabling practical automated infrastructure inspection\nsystems without compromising accuracy. The source code can be accessed at the\nfollowing URL: https://github.com/faeyelab/karma.", "published": "2025-08-11 17:06:55", "link": "http://arxiv.org/abs/2508.08186v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening", "abstract": "Transformer-based methods have demonstrated strong potential in hyperspectral\npansharpening by modeling long-range dependencies. However, their effectiveness\nis often limited by redundant token representations and a lack of multi-scale\nfeature modeling. Hyperspectral images exhibit intrinsic spectral priors (e.g.,\nabundance sparsity) and spatial priors (e.g., non-local similarity), which are\ncritical for accurate reconstruction. From a spectral-spatial perspective,\nVision Transformers (ViTs) face two major limitations: they struggle to\npreserve high-frequency components--such as material edges and texture\ntransitions--and suffer from attention dispersion across redundant tokens.\nThese issues stem from the global self-attention mechanism, which tends to\ndilute high-frequency signals and overlook localized details. To address these\nchallenges, we propose the Token-wise High-frequency Augmentation Transformer\n(THAT), a novel framework designed to enhance hyperspectral pansharpening\nthrough improved high-frequency feature representation and token selection.\nSpecifically, THAT introduces: (1) Pivotal Token Selective Attention (PTSA) to\nprioritize informative tokens and suppress redundancy; (2) a Multi-level\nVariance-aware Feed-forward Network (MVFN) to enhance high-frequency detail\nlearning. Experiments on standard benchmarks show that THAT achieves\nstate-of-the-art performance with improved reconstruction quality and\nefficiency. The source code is available at https://github.com/kailuo93/THAT.", "published": "2025-08-11 17:03:10", "link": "http://arxiv.org/abs/2508.08183v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation", "abstract": "Human motion generation has found widespread applications in AR/VR, film,\nsports, and medical rehabilitation, offering a cost-effective alternative to\ntraditional motion capture systems. However, evaluating the fidelity of such\ngenerated motions is a crucial, multifaceted task. Although previous approaches\nhave attempted at motion fidelity evaluation using human perception or physical\nconstraints, there remains an inherent gap between human-perceived fidelity and\nphysical feasibility. Moreover, the subjective and coarse binary labeling of\nhuman perception further undermines the development of a robust data-driven\nmetric. We address these issues by introducing a physical labeling method. This\nmethod evaluates motion fidelity by calculating the minimum modifications\nneeded for a motion to align with physical laws. With this approach, we are\nable to produce fine-grained, continuous physical alignment annotations that\nserve as objective ground truth. With these annotations, we propose PP-Motion,\na novel data-driven metric to evaluate both physical and perceptual fidelity of\nhuman motion. To effectively capture underlying physical priors, we employ\nPearson's correlation loss for the training of our metric. Additionally, by\nincorporating a human-based perceptual fidelity loss, our metric can capture\nfidelity that simultaneously considers both human perception and physical\nalignment. Experimental results demonstrate that our metric, PP-Motion, not\nonly aligns with physical laws but also aligns better with human perception of\nmotion fidelity than previous work.", "published": "2025-08-11 16:59:15", "link": "http://arxiv.org/abs/2508.08179v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "3D Human Mesh Estimation from Single View RGBD", "abstract": "Despite significant progress in 3D human mesh estimation from RGB images;\nRGBD cameras, offering additional depth data, remain underutilized. In this\npaper, we present a method for accurate 3D human mesh estimation from a single\nRGBD view, leveraging the affordability and widespread adoption of RGBD cameras\nfor real-world applications. A fully supervised approach for this problem,\nrequires a dataset with RGBD image and 3D mesh label pairs. However, collecting\nsuch a dataset is costly and challenging, hence, existing datasets are small,\nand limited in pose and shape diversity. To overcome this data scarcity, we\nleverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D\nmeshes from the body models found in MoCap datasets, and create partial,\nsingle-view versions of them by projection to a virtual camera. This simulates\nthe depth data provided by an RGBD camera from a single viewpoint. Then, we\ntrain a masked autoencoder to complete the partial, single-view mesh. During\ninference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'',\nmatches the depth values coming from the sensor to vertices of a template human\nmesh, which creates a partial, single-view mesh. We effectively recover parts\nof the 3D human body mesh model that are not visible, resulting in a full body\nmesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL\nand CAPE datasets, respectively; outperforming existing methods that use\nfull-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE\ndataset, outperforming a recently published RGB based method by 18.4 mm,\nhighlighting the usefulness of depth data. Code will be released.", "published": "2025-08-11 16:59:14", "link": "http://arxiv.org/abs/2508.08178v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data", "abstract": "Large-scale scientific simulations require significant resources to generate\nhigh-resolution time-varying data (TVD). While super-resolution is an efficient\npost-processing strategy to reduce costs, existing methods rely on a large\namount of HR training data, limiting their applicability to diverse simulation\nscenarios. To address this constraint, we proposed CD-TVD, a novel framework\nthat combines contrastive learning and an improved diffusion-based\nsuper-resolution model to achieve accurate 3D super-resolution from limited\ntime-step high-resolution data. During pre-training on historical simulation\ndata, the contrastive encoder and diffusion superresolution modules learn\ndegradation patterns and detailed features of high-resolution and\nlow-resolution samples. In the training phase, the improved diffusion model\nwith a local attention mechanism is fine-tuned using only one newly generated\nhigh-resolution timestep, leveraging the degradation knowledge learned by the\nencoder. This design minimizes the reliance on large-scale high-resolution\ndatasets while maintaining the capability to recover fine-grained details.\nExperimental results on fluid and atmospheric simulation datasets confirm that\nCD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a\nsignificant advancement in data augmentation for large-scale scientific\nsimulations. The code is available at\nhttps://github.com/Xin-Gao-private/CD-TVD.", "published": "2025-08-11 16:51:28", "link": "http://arxiv.org/abs/2508.08173v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction", "abstract": "Reinforcement learning for training end-to-end autonomous driving models in\nclosed-loop simulations is gaining growing attention. However, most simulation\nenvironments differ significantly from real-world conditions, creating a\nsubstantial simulation-to-reality (sim2real) gap. To bridge this gap, some\napproaches utilize scene reconstruction techniques to create photorealistic\nenvironments as a simulator. While this improves realistic sensor simulation,\nthese methods are inherently constrained by the distribution of the training\ndata, making it difficult to render high-quality sensor data for novel\ntrajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a\nframework designed to integrate video diffusion priors into scene\nreconstruction to aid reinforcement learning, thereby enhancing end-to-end\nautonomous driving training. Specifically, in ReconDreamer-RL, we introduce\nReconSimulator, which combines the video diffusion prior for appearance\nmodeling and incorporates a kinematic model for physical modeling, thereby\nreconstructing driving scenarios from real-world data. This narrows the\nsim2real gap for closed-loop evaluation and reinforcement learning. To cover\nmore corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA),\nwhich adjusts the trajectories of surrounding vehicles relative to the ego\nvehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in).\nFinally, the Cousin Trajectory Generator (CTG) is proposed to address the issue\nof training data distribution, which is often biased toward simple\nstraight-line movements. Experiments show that ReconDreamer-RL improves\nend-to-end autonomous driving training, outperforming imitation learning\nmethods with a 5x reduction in the Collision Ratio.", "published": "2025-08-11 16:45:55", "link": "http://arxiv.org/abs/2508.08170v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning", "abstract": "Class-Incremental Learning (CIL) requires a learning system to continually\nlearn new classes without forgetting. Existing pre-trained model-based CIL\nmethods often freeze the pre-trained network and adapt to incremental tasks\nusing additional lightweight modules such as adapters. However, incorrect\nmodule selection during inference hurts performance, and task-specific modules\noften overlook shared general knowledge, leading to errors on distinguishing\nbetween similar classes across tasks. To address the aforementioned challenges,\nwe propose integrating Task-Specific and Universal Adapters (TUNA) in this\npaper. Specifically, we train task-specific adapters to capture the most\ncrucial features relevant to their respective tasks and introduce an\nentropy-based selection mechanism to choose the most suitable adapter.\nFurthermore, we leverage an adapter fusion strategy to construct a universal\nadapter, which encodes the most discriminative features shared across tasks. We\ncombine task-specific and universal adapter predictions to harness both\nspecialized and general knowledge during inference. Extensive experiments on\nvarious benchmark datasets demonstrate the state-of-the-art performance of our\napproach. Code is available at: https://github.com/LAMDA-CL/ICCV2025-TUNA", "published": "2025-08-11 16:41:04", "link": "http://arxiv.org/abs/2508.08165v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization", "abstract": "The field of visual and audio generation is burgeoning with new\nstate-of-the-art methods. This rapid proliferation of new techniques\nunderscores the need for robust solutions for detecting synthetic content in\nvideos. In particular, when fine-grained alterations via localized\nmanipulations are performed in visual, audio, or both domains, these subtle\nmodifications add challenges to the detection algorithms. This paper presents\nsolutions for the problems of deepfake video classification and localization.\nThe methods were submitted to the ACM 1M Deepfakes Detection Challenge,\nachieving the best performance in the temporal localization task and a top four\nranking in the classification task for the TestA split of the evaluation\ndataset.", "published": "2025-08-11 16:14:17", "link": "http://arxiv.org/abs/2508.08141v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting", "abstract": "The success of 3DGS in generative and editing applications has sparked\ngrowing interest in 3DGS-based style transfer. However, current methods still\nface two major challenges: (1) multi-view inconsistency often leads to style\nconflicts, resulting in appearance smoothing and distortion; and (2) heavy\nreliance on VGG features, which struggle to disentangle style and content from\nstyle images, often causing content leakage and excessive stylization. To\ntackle these issues, we introduce \\textbf{FantasyStyle}, a 3DGS-based style\ntransfer framework, and the first to rely entirely on diffusion model\ndistillation. It comprises two key components: (1) \\textbf{Multi-View Frequency\nConsistency}. We enhance cross-view consistency by applying a 3D filter to\nmulti-view noisy latent, selectively reducing low-frequency components to\nmitigate stylized prior conflicts. (2) \\textbf{Controllable Stylized\nDistillation}. To suppress content leakage from style images, we introduce\nnegative guidance to exclude undesired content. In addition, we identify the\nlimitations of Score Distillation Sampling and Delta Denoising Score in 3D\nstyle transfer and remove the reconstruction term accordingly. Building on\nthese insights, we propose a controllable stylized distillation that leverages\nnegative guidance to more effectively optimize the 3D Gaussians. Extensive\nexperiments demonstrate that our method consistently outperforms\nstate-of-the-art approaches, achieving higher stylization quality and visual\nrealism across various scenes and styles.", "published": "2025-08-11 16:11:08", "link": "http://arxiv.org/abs/2508.08136v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control", "abstract": "While recent flow-based image editing models demonstrate general-purpose\ncapabilities across diverse tasks, they often struggle to specialize in\nchallenging scenarios -- particularly those involving large-scale shape\ntransformations. When performing such structural edits, these methods either\nfail to achieve the intended shape change or inadvertently alter non-target\nregions, resulting in degraded background quality. We propose\nFollow-Your-Shape, a training-free and mask-free framework that supports\nprecise and controllable editing of object shapes while strictly preserving\nnon-target content. Motivated by the divergence between inversion and editing\ntrajectories, we compute a Trajectory Divergence Map (TDM) by comparing\ntoken-wise velocity differences between the inversion and denoising paths. The\nTDM enables precise localization of editable regions and guides a Scheduled KV\nInjection mechanism that ensures stable and faithful editing. To facilitate a\nrigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120\nnew images and enriched prompt pairs specifically curated for shape-aware\nediting. Experiments demonstrate that our method achieves superior editability\nand visual fidelity, particularly in tasks requiring large-scale shape\nreplacement.", "published": "2025-08-11 16:10:00", "link": "http://arxiv.org/abs/2508.08134v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images", "abstract": "We propose a deep learning-based approach that integrates MRI sequence\nparameters to improve the accuracy and generalizability of quantitative image\nsynthesis from clinical weighted MRI. Our physics-driven neural network embeds\nMRI sequence parameters -- repetition time (TR), echo time (TE), and inversion\ntime (TI) -- directly into the model via parameter embedding, enabling the\nnetwork to learn the underlying physical principles of MRI signal formation.\nThe model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as\ninput and synthesizes T1, T2, and proton density (PD) quantitative maps.\nTrained on healthy brain MR images, it was evaluated on both internal and\nexternal test datasets. The proposed method achieved high performance with PSNR\nvalues exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter\nmaps. It outperformed conventional deep learning models in accuracy and\nrobustness, including data with previously unseen brain structures and lesions.\nNotably, our model accurately synthesized quantitative maps for these unseen\npathological regions, highlighting its superior generalization capability.\nIncorporating MRI sequence parameters via parameter embedding allows the neural\nnetwork to better learn the physical characteristics of MR signals,\nsignificantly enhancing the performance and reliability of quantitative MRI\nsynthesis. This method shows great potential for accelerating qMRI and\nimproving its clinical utility.", "published": "2025-08-11 16:01:12", "link": "http://arxiv.org/abs/2508.08123v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learned Regularization for Microwave Tomography", "abstract": "Microwave Tomography (MWT) aims to reconstruct the dielectric properties of\ntissues from measured scattered electromagnetic fields. This inverse problem is\nhighly nonlinear and ill-posed, posing significant challenges for conventional\noptimization-based methods, which, despite being grounded in physical models,\noften fail to recover fine structural details. Recent deep learning strategies,\nincluding end-to-end and post-processing networks, have improved reconstruction\nquality but typically require large paired training datasets and may struggle\nto generalize. To overcome these limitations, we propose a physics-informed\nhybrid framework that integrates diffusion models as learned regularization\nwithin a data-consistency-driven variational scheme. Specifically, we introduce\nSingle-Step Diffusion Regularization (SSD-Reg), a novel approach that embeds\ndiffusion priors into the iterative reconstruction process, enabling the\nrecovery of complex anatomical structures without the need for paired data.\nSSD-Reg maintains fidelity to both the governing physics and learned structural\ndistributions, improving accuracy, stability, and robustness. Extensive\nexperiments demonstrate that SSD-Reg, implemented as a Plug-and-Play (PnP)\nmodule, provides a flexible and effective solution for tackling the\nill-posedness inherent in functional image reconstruction.", "published": "2025-08-11 15:54:58", "link": "http://arxiv.org/abs/2508.08114v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning", "abstract": "This paper introduces TBAC-UniImage, a novel unified model for multimodal\nunderstanding and generation. We achieve this by deeply integrating a\npre-trained Diffusion Model, acting as a generative ladder, with a Multimodal\nLarge Language Model (MLLM). Previous diffusion-based unified models face two\nprimary limitations. One approach uses only the MLLM's final hidden state as\nthe generative condition. This creates a shallow connection, as the generator\nis isolated from the rich, hierarchical representations within the MLLM's\nintermediate layers. The other approach, pretraining a unified generative\narchitecture from scratch, is computationally expensive and prohibitive for\nmany researchers. To overcome these issues, our work explores a new paradigm.\nInstead of relying on a single output, we use representations from multiple,\ndiverse layers of the MLLM as generative conditions for the diffusion model.\nThis method treats the pre-trained generator as a ladder, receiving guidance\nfrom various depths of the MLLM's understanding process. Consequently,\nTBAC-UniImage achieves a much deeper and more fine-grained unification of\nunderstanding and generation.", "published": "2025-08-11 15:37:22", "link": "http://arxiv.org/abs/2508.08098v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Plant Root Skeleton Detection and Extraction", "abstract": "Plant roots typically exhibit a highly complex and dense architecture,\nincorporating numerous slender lateral roots and branches, which significantly\nhinders the precise capture and modeling of the entire root system.\nAdditionally, roots often lack sufficient texture and color information, making\nit difficult to identify and track root traits using visual methods. Previous\nresearch on roots has been largely confined to 2D studies; however, exploring\nthe 3D architecture of roots is crucial in botany. Since roots grow in real 3D\nspace, 3D phenotypic information is more critical for studying genetic traits\nand their impact on root development. We have introduced a 3D root skeleton\nextraction method that efficiently derives the 3D architecture of plant roots\nfrom a few images. This method includes the detection and matching of lateral\nroots, triangulation to extract the skeletal structure of lateral roots, and\nthe integration of lateral and primary roots. We developed a highly complex\nroot dataset and tested our method on it. The extracted 3D root skeletons\nshowed considerable similarity to the ground truth, validating the\neffectiveness of the model. This method can play a significant role in\nautomated breeding robots. Through precise 3D root structure analysis, breeding\nrobots can better identify plant phenotypic traits, especially root structure\nand growth patterns, helping practitioners select seeds with superior root\nsystems. This automated approach not only improves breeding efficiency but also\nreduces manual intervention, making the breeding process more intelligent and\nefficient, thus advancing modern agriculture.", "published": "2025-08-11 15:33:10", "link": "http://arxiv.org/abs/2508.08094v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MDD-Net: Multimodal Depression Detection through Mutual Transformer", "abstract": "Depression is a major mental health condition that severely impacts the\nemotional and physical well-being of individuals. The simple nature of data\ncollection from social media platforms has attracted significant interest in\nproperly utilizing this information for mental health research. A Multimodal\nDepression Detection Network (MDD-Net), utilizing acoustic and visual data\nobtained from social media networks, is proposed in this work where mutual\ntransformers are exploited to efficiently extract and fuse multimodal features\nfor efficient depression detection. The MDD-Net consists of four core modules:\nan acoustic feature extraction module for retrieving relevant acoustic\nattributes, a visual feature extraction module for extracting significant\nhigh-level patterns, a mutual transformer for computing the correlations among\nthe generated features and fusing these features from multiple modalities, and\na detection layer for detecting depression using the fused feature\nrepresentations. The extensive experiments are performed using the multimodal\nD-Vlog dataset, and the findings reveal that the developed multimodal\ndepression detection network surpasses the state-of-the-art by up to 17.37% for\nF1-Score, demonstrating the greater performance of the proposed system. The\nsource code is accessible at\nhttps://github.com/rezwanh001/Multimodal-Depression-Detection.", "published": "2025-08-11 15:32:56", "link": "http://arxiv.org/abs/2508.08093v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Matrix-3D: Omnidirectional Explorable 3D World Generation", "abstract": "Explorable 3D world generation from a single image or text prompt forms a\ncornerstone of spatial intelligence. Recent works utilize video model to\nachieve wide-scope and generalizable 3D world generation. However, existing\napproaches often suffer from a limited scope in the generated scenes. In this\nwork, we propose Matrix-3D, a framework that utilize panoramic representation\nfor wide-coverage omnidirectional explorable 3D world generation that combines\nconditional video generation and panoramic 3D reconstruction. We first train a\ntrajectory-guided panoramic video diffusion model that employs scene mesh\nrenders as condition, to enable high-quality and geometrically consistent scene\nvideo generation. To lift the panorama scene video to 3D world, we propose two\nseparate methods: (1) a feed-forward large panorama reconstruction model for\nrapid 3D scene reconstruction and (2) an optimization-based pipeline for\naccurate and detailed 3D scene reconstruction. To facilitate effective\ntraining, we also introduce the Matrix-Pano dataset, the first large-scale\nsynthetic collection comprising 116K high-quality static panoramic video\nsequences with depth and trajectory annotations. Extensive experiments\ndemonstrate that our proposed framework achieves state-of-the-art performance\nin panoramic video generation and 3D world generation. See more in\nhttps://matrix-3d.github.io.", "published": "2025-08-11 15:29:57", "link": "http://arxiv.org/abs/2508.08086v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness", "abstract": "Micro-expressions (MEs) are regarded as important indicators of an\nindividual's intrinsic emotions, preferences, and tendencies. ME analysis\nrequires spotting of ME intervals within long video sequences and recognition\nof their corresponding emotional categories. Previous deep learning approaches\ncommonly employ sliding-window classification networks. However, the use of\nfixed window lengths and hard classification presents notable limitations in\npractice. Furthermore, these methods typically treat ME spotting and\nrecognition as two separate tasks, overlooking the essential relationship\nbetween them. To address these challenges, this paper proposes two state space\nmodel-based architectures, namely ME-TST and ME-TST+, which utilize temporal\nstate transition mechanisms to replace conventional window-level classification\nwith video-level regression. This enables a more precise characterization of\nthe temporal dynamics of MEs and supports the modeling of MEs with varying\ndurations. In ME-TST+, we further introduce multi-granularity ROI modeling and\nthe slowfast Mamba framework to alleviate information loss associated with\ntreating ME analysis as a time-series task. Additionally, we propose a synergy\nstrategy for spotting and recognition at both the feature and result levels,\nleveraging their intrinsic connection to enhance overall analysis performance.\nExtensive experiments demonstrate that the proposed methods achieve\nstate-of-the-art performance. The codes are available at\nhttps://github.com/zizheng-guo/ME-TST.", "published": "2025-08-11 15:28:32", "link": "http://arxiv.org/abs/2508.08082v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition", "abstract": "Multi-label classification (MLC) of medical images aims to identify multiple\ndiseases and holds significant clinical potential. A critical step is to learn\nclass-specific features for accurate diagnosis and improved interpretability\neffectively. However, current works focus primarily on causal attention to\nlearn class-specific features, yet they struggle to interpret the true cause\ndue to the inadvertent attention to class-irrelevant features. To address this\nchallenge, we propose a new structural causal model (SCM) that treats\nclass-specific attention as a mixture of causal, spurious, and noisy factors,\nand a novel Information Bottleneck-based Causal Attention (IBCA) that is\ncapable of learning the discriminative class-specific attention for MLC of\nmedical images. Specifically, we propose learning Gaussian mixture multi-label\nspatial attention to filter out class-irrelevant information and capture each\nclass-specific attention pattern. Then a contrastive enhancement-based causal\nintervention is proposed to gradually mitigate the spurious attention and\nreduce noise information by aligning multi-head attention with the Gaussian\nmixture multi-label spatial. Quantitative and ablation results on Endo and\nMuReD show that IBCA outperforms all methods. Compared to the second-best\nresults for each metric, IBCA achieves improvements of 6.35\\% in CR, 7.72\\% in\nOR, and 5.02\\% in mAP for MuReD, 1.47\\% in CR, and 1.65\\% in CF1, and 1.42\\% in\nmAP for Endo.", "published": "2025-08-11 15:12:54", "link": "http://arxiv.org/abs/2508.08069v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI", "abstract": "Accelerating Magnetic Resonance Imaging (MRI) reduces scan time but often\ndegrades image quality. While Implicit Neural Representations (INRs) show\npromise for MRI reconstruction, they struggle at high acceleration factors due\nto weak prior constraints, leading to structural loss and aliasing artefacts.\nTo address this, we propose PrIINeR, an INR-based MRI reconstruction method\nthat integrates prior knowledge from pre-trained deep learning models into the\nINR framework. By combining population-level knowledge with instance-based\noptimization and enforcing dual data consistency, PrIINeR aligns both with the\nacquired k-space data and the prior-informed reconstruction. Evaluated on the\nNYU fastMRI dataset, our method not only outperforms state-of-the-art INR-based\napproaches but also improves upon several learning-based state-of-the-art\nmethods, significantly improving structural preservation and fidelity while\neffectively removing aliasing artefacts.PrIINeR bridges deep learning and\nINR-based techniques, offering a more reliable solution for high-quality,\naccelerated MRI reconstruction. The code is publicly available on\nhttps://github.com/multimodallearning/PrIINeR.", "published": "2025-08-11 14:59:09", "link": "http://arxiv.org/abs/2508.08058v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix", "abstract": "While video generation models excel at producing high-quality monocular\nvideos, generating 3D stereoscopic and spatial videos for immersive\napplications remains an underexplored challenge. We present a pose-free and\ntraining-free method that leverages an off-the-shelf monocular video generation\nmodel to produce immersive 3D videos. Our approach first warps the generated\nmonocular video into pre-defined camera viewpoints using estimated depth\ninformation, then applies a novel \\textit{frame matrix} inpainting framework.\nThis framework utilizes the original video generation model to synthesize\nmissing content across different viewpoints and timestamps, ensuring spatial\nand temporal consistency without requiring additional model fine-tuning.\nMoreover, we develop a \\dualupdate~scheme that further improves the quality of\nvideo inpainting by alleviating the negative effects propagated from\ndisoccluded areas in the latent space. The resulting multi-view videos are then\nadapted into stereoscopic pairs or optimized into 4D Gaussians for spatial\nvideo synthesis. We validate the efficacy of our proposed method by conducting\nexperiments on videos from various generative models, such as Sora, Lumiere,\nWALT, and Zeroscope. The experiments demonstrate that our method has a\nsignificant improvement over previous methods. Project page at:\nhttps://daipengwa.github.io/S-2VG_ProjectPage/", "published": "2025-08-11 14:50:03", "link": "http://arxiv.org/abs/2508.08048v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation", "abstract": "Depth estimation, essential for autonomous driving, seeks to interpret the 3D\nenvironment surrounding vehicles. The development of radar sensors, known for\ntheir cost-efficiency and robustness, has spurred interest in radar-camera\nfusion-based solutions. However, existing algorithms fuse features from these\nmodalities without accounting for weather conditions, despite radars being\nknown to be more robust than cameras under adverse weather. Additionally, while\nVision-Language models have seen rapid advancement, utilizing language\ndescriptions alongside other modalities for depth estimation remains an open\nchallenge. This paper first introduces a text-generation strategy along with\nfeature extraction and fusion techniques that can assist monocular depth\nestimation pipelines, leading to improved accuracy across different algorithms\non the KITTI dataset. Building on this, we propose TRIDE, a radar-camera fusion\nalgorithm that enhances text feature extraction by incorporating radar point\ninformation. To address the impact of weather on sensor performance, we\nintroduce a weather-aware fusion block that adaptively adjusts radar weighting\nbased on current weather conditions. Our method, benchmarked on the nuScenes\ndataset, demonstrates performance gains over the state-of-the-art, achieving a\n12.87% improvement in MAE and a 9.08% improvement in RMSE. Code:\nhttps://github.com/harborsarah/TRIDE", "published": "2025-08-11 14:39:41", "link": "http://arxiv.org/abs/2508.08038v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning", "abstract": "Federated self-supervised learning (FSSL) combines the advantages of\ndecentralized modeling and unlabeled representation learning, serving as a\ncutting-edge paradigm with strong potential for scalability and privacy\npreservation. Although FSSL has garnered increasing attention, research\nindicates that it remains vulnerable to backdoor attacks. Existing methods\ngenerally rely on visually obvious triggers, which makes it difficult to meet\nthe requirements for stealth and practicality in real-world deployment. In this\npaper, we propose an imperceptible and effective backdoor attack method against\nFSSL, called IPBA. Our empirical study reveals that existing imperceptible\ntriggers face a series of challenges in FSSL, particularly limited\ntransferability, feature entanglement with augmented samples, and\nout-of-distribution properties. These issues collectively undermine the\neffectiveness and stealthiness of traditional backdoor attacks in FSSL. To\novercome these challenges, IPBA decouples the feature distributions of backdoor\nand augmented samples, and introduces Sliced-Wasserstein distance to mitigate\nthe out-of-distribution properties of backdoor samples, thereby optimizing the\ntrigger generation process. Our experimental results on several FSSL scenarios\nand datasets show that IPBA significantly outperforms existing backdoor attack\nmethods in performance and exhibits strong robustness under various defense\nmechanisms.", "published": "2025-08-11 14:36:11", "link": "http://arxiv.org/abs/2508.08031v1", "categories": ["cs.CR", "cs.CV"], "primary_category": "cs.CR"}
{"title": "Mitigating Biases in Surgical Operating Rooms with Geometry", "abstract": "Deep neural networks are prone to learning spurious correlations, exploiting\ndataset-specific artifacts rather than meaningful features for prediction. In\nsurgical operating rooms (OR), these manifest through the standardization of\nsmocks and gowns that obscure robust identifying landmarks, introducing model\nbias for tasks related to modeling OR personnel. Through gradient-based\nsaliency analysis on two public OR datasets, we reveal that CNN models succumb\nto such shortcuts, fixating on incidental visual cues such as footwear beneath\nsurgical gowns, distinctive eyewear, or other role-specific identifiers.\nAvoiding such biases is essential for the next generation of intelligent\nassistance systems in the OR, which should accurately recognize personalized\nworkflow traits, such as surgical skill level or coordination with other staff\nmembers. We address this problem by encoding personnel as 3D point cloud\nsequences, disentangling identity-relevant shape and motion patterns from\nappearance-based confounders. Our experiments demonstrate that while RGB and\ngeometric methods achieve comparable performance on datasets with apparent\nsimulation artifacts, RGB models suffer a 12% accuracy drop in realistic\nclinical settings with decreased visual diversity due to standardizations. This\nperformance gap confirms that geometric representations capture more meaningful\nbiometric features, providing an avenue to developing robust methods of\nmodeling humans in the OR.", "published": "2025-08-11 14:32:32", "link": "http://arxiv.org/abs/2508.08028v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition", "abstract": "Automatic data augmentation (AutoDA) plays an important role in enhancing the\ngeneralization of neural networks. However, mainstream AutoDA methods often\nencounter two challenges: either the search process is excessively\ntime-consuming, hindering practical application, or the performance is\nsuboptimal due to insufficient policy adaptation during training. To address\nthese issues, we propose Sample-aware RandAugment (SRA), an asymmetric,\nsearch-free AutoDA method that dynamically adjusts augmentation policies while\nmaintaining straightforward implementation. SRA incorporates a heuristic\nscoring module that evaluates the complexity of the original training data,\nenabling the application of tailored augmentations for each sample.\nAdditionally, an asymmetric augmentation strategy is employed to maximize the\npotential of this scoring module. In multiple experimental settings, SRA\nnarrows the performance gap between search-based and search-free AutoDA\nmethods, achieving a state-of-the-art Top-1 accuracy of 78.31\\% on ImageNet\nwith ResNet-50. Notably, SRA demonstrates good compatibility with existing\naugmentation pipelines and solid generalization across new tasks, without\nrequiring hyperparameter tuning. The pretrained models leveraging SRA also\nenhance recognition in downstream object detection tasks. SRA represents a\npromising step towards simpler, more effective, and practical AutoDA designs\napplicable to a variety of future tasks. Our code is available at\n\\href{https://github.com/ainieli/Sample-awareRandAugment}{https://github.com/ainieli/Sample-awareRandAugment", "published": "2025-08-11 14:09:01", "link": "http://arxiv.org/abs/2508.08004v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models", "abstract": "Group Activity Detection (GAD) involves recognizing social groups and their\ncollective behaviors in videos. Vision Foundation Models (VFMs), like DinoV2,\noffer excellent features, but are pretrained primarily on object-centric data\nand remain underexplored for modeling group dynamics. While they are a\npromising alternative to highly task-specific GAD architectures that require\nfull fine-tuning, our initial investigation reveals that simply swapping CNN\nbackbones used in these methods with VFMs brings little gain, underscoring the\nneed for structured, group-aware reasoning on top.\n  We introduce Prompt-driven Group Activity Detection (ProGraD) -- a method\nthat bridges this gap through 1) learnable group prompts to guide the VFM\nattention toward social configurations, and 2) a lightweight two-layer\nGroupContext Transformer that infers actor-group associations and collective\nbehavior. We evaluate our approach on two recent GAD benchmarks: Cafe, which\nfeatures multiple concurrent social groups, and Social-CAD, which focuses on\nsingle-group interactions. While we surpass state-of-the-art in both settings,\nour method is especially effective in complex multi-group scenarios, where we\nyield a gain of 6.5\\% (Group mAP\\@1.0) and 8.2\\% (Group mAP\\@0.5) using only\n10M trainable parameters. Furthermore, our experiments reveal that ProGraD\nproduces interpretable attention maps, offering insights into actor-group\nreasoning. Code and models will be released.", "published": "2025-08-11 13:59:22", "link": "http://arxiv.org/abs/2508.07996v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility", "abstract": "Multimodal Large Language Models (MLLMs) hold immense promise as assistive\ntechnologies for the blind and visually impaired (BVI) community. However, we\nidentify a critical failure mode that undermines their trustworthiness in\nreal-world applications. We introduce the Escalator Problem -- the inability of\nstate-of-the-art models to perceive an escalator's direction of travel -- as a\ncanonical example of a deeper limitation we term Implicit Motion Blindness.\nThis blindness stems from the dominant frame-sampling paradigm in video\nunderstanding, which, by treating videos as discrete sequences of static\nimages, fundamentally struggles to perceive continuous, low-signal motion. As a\nposition paper, our contribution is not a new model but rather to: (I) formally\narticulate this blind spot, (II) analyze its implications for user trust, and\n(III) issue a call to action. We advocate for a paradigm shift from purely\nsemantic recognition towards robust physical perception and urge the\ndevelopment of new, human-centered benchmarks that prioritize safety,\nreliability, and the genuine needs of users in dynamic environments.", "published": "2025-08-11 13:53:09", "link": "http://arxiv.org/abs/2508.07989v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking", "abstract": "Providing intelligent support to surgical teams is a key frontier in\nautomated surgical scene understanding, with the long-term goal of improving\npatient outcomes. Developing personalized intelligence for all staff members\nrequires maintaining a consistent state of who is located where for long\nsurgical procedures, which still poses numerous computational challenges. We\npropose TrackOR, a framework for tackling long-term multi-person tracking and\nre-identification in the operating room. TrackOR uses 3D geometric signatures\nto achieve state-of-the-art online tracking performance (+11% Association\nAccuracy over the strongest baseline), while also enabling an effective offline\nrecovery process to create analysis-ready trajectories. Our work shows that by\nleveraging 3D geometric information, persistent identity tracking becomes\nattainable, enabling a critical shift towards the more granular, staff-centric\nanalyses required for personalized intelligent systems in the operating room.\nThis new capability opens up various applications, including our proposed\ntemporal pathway imprints that translate raw tracking data into actionable\ninsights for improving team efficiency and safety and ultimately providing\npersonalized support.", "published": "2025-08-11 13:28:50", "link": "http://arxiv.org/abs/2508.07968v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security", "abstract": "Advancement of machine learning techniques, combined with the availability of\nlarge-scale datasets, has significantly improved the accuracy and efficiency of\nfacial recognition. Modern facial recognition systems are trained using large\nface datasets collected from diverse individuals or public repositories.\nHowever, for training, these datasets are often replicated and stored in\nmultiple workstations, resulting in data replication, which complicates\ndatabase management and oversight. Currently, once a user submits their face\nfor dataset preparation, they lose control over how their data is used, raising\nsignificant privacy and ethical concerns. This paper introduces VOIDFace, a\nnovel framework for facial recognition systems that addresses two major issues.\nFirst, it eliminates the need of data replication and improves data control to\nsecurely store training face data by using visual secret sharing. Second, it\nproposes a patch-based multi-training network that uses this novel training\ndata storage mechanism to develop a robust, privacy-preserving facial\nrecognition system. By integrating these advancements, VOIDFace aims to improve\nthe privacy, security, and efficiency of facial recognition training, while\nensuring greater control over sensitive personal face data. VOIDFace also\nenables users to exercise their Right-To-Be-Forgotten property to control their\npersonal data. Experimental evaluations on the VGGFace2 dataset show that\nVOIDFace provides Right-To-Be-Forgotten, improved data control, security, and\nprivacy while maintaining competitive facial recognition performance. Code is\navailable at: https://github.com/ajnasmuhammed89/VOIDFace", "published": "2025-08-11 13:15:36", "link": "http://arxiv.org/abs/2508.07960v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding", "abstract": "Video Temporal Grounding (VTG) aims to extract relevant video segments based\non a given natural language query. Recently, zero-shot VTG methods have gained\nattention by leveraging pretrained vision-language models (VLMs) to localize\ntarget moments without additional training. However, existing approaches suffer\nfrom semantic fragmentation, where temporally continuous frames sharing the\nsame semantics are split across multiple segments. When segments are\nfragmented, it becomes difficult to predict an accurate target moment that\naligns with the text query. Also, they rely on skewed similarity distributions\nfor localization, making it difficult to select the optimal segment.\nFurthermore, they heavily depend on the use of LLMs which require expensive\ninferences. To address these limitations, we propose a \\textit{TAG}, a simple\nyet effective Temporal-Aware approach for zero-shot video temporal Grounding,\nwhich incorporates temporal pooling, temporal coherence clustering, and\nsimilarity adjustment. Our proposed method effectively captures the temporal\ncontext of videos and addresses distorted similarity distributions without\ntraining. Our approach achieves state-of-the-art results on Charades-STA and\nActivityNet Captions benchmark datasets without rely on LLMs. Our code is\navailable at https://github.com/Nuetee/TAG", "published": "2025-08-11 12:38:46", "link": "http://arxiv.org/abs/2508.07925v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection", "abstract": "Generative AI holds great potentials to automate and enhance data synthesis\nin nuclear medicine. However, the high-stakes nature of biomedical imaging\nnecessitates robust mechanisms to detect and manage unexpected or erroneous\nmodel behavior. We introduce development and implementation of a hybrid anomaly\ndetection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems.\nTwo applications are demonstrated: Pose2Xray, which generates synthetic X-rays\nfrom photographic mouse images, and DosimetrEYE, which estimates 3D radiation\ndose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD)\nenhances reliability, reduces manual oversight, and supports real-time quality\ncontrol. This approach strengthens the industrial viability of GenAI in\npreclinical settings by increasing robustness, scalability, and regulatory\ncompliance.", "published": "2025-08-11 12:35:44", "link": "http://arxiv.org/abs/2508.07923v1", "categories": ["cs.CV", "cs.HC", "cs.LG"], "primary_category": "cs.CV"}
{"title": "RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering", "abstract": "Visual Question Answering (VQA) in remote sensing (RS) is pivotal for\ninterpreting Earth observation data. However, existing RS VQA datasets are\nconstrained by limitations in annotation richness, question diversity, and the\nassessment of specific reasoning capabilities. This paper introduces RSVLM-QA\ndataset, a new large-scale, content-rich VQA dataset for the RS domain.\nRSVLM-QA is constructed by integrating data from several prominent RS\nsegmentation and detection datasets: WHU, LoveDA, INRIA, and iSAID. We employ\nan innovative dual-track annotation generation pipeline. Firstly, we leverage\nLarge Language Models (LLMs), specifically GPT-4.1, with meticulously designed\nprompts to automatically generate a suite of detailed annotations including\nimage captions, spatial relations, and semantic tags, alongside complex\ncaption-based VQA pairs. Secondly, to address the challenging task of object\ncounting in RS imagery, we have developed a specialized automated process that\nextracts object counts directly from the original segmentation data; GPT-4.1\nthen formulates natural language answers from these counts, which are paired\nwith preset question templates to create counting QA pairs. RSVLM-QA comprises\n13,820 images and 162,373 VQA pairs, featuring extensive annotations and\ndiverse question types. We provide a detailed statistical analysis of the\ndataset and a comparison with existing RS VQA benchmarks, highlighting the\nsuperior depth and breadth of RSVLM-QA's annotations. Furthermore, we conduct\nbenchmark experiments on Six mainstream Vision Language Models (VLMs),\ndemonstrating that RSVLM-QA effectively evaluates and challenges the\nunderstanding and reasoning abilities of current VLMs in the RS domain. We\nbelieve RSVLM-QA will serve as a pivotal resource for the RS VQA and VLM\nresearch communities, poised to catalyze advancements in the field.", "published": "2025-08-11 12:32:48", "link": "http://arxiv.org/abs/2508.07918v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction", "abstract": "Reconstructing dense geometry for dynamic scenes from a monocular video is a\ncritical yet challenging task. Recent memory-based methods enable efficient\nonline reconstruction, but they fundamentally suffer from a Memory Demand\nDilemma: The memory representation faces an inherent conflict between the\nlong-term stability required for static structures and the rapid, high-fidelity\ndetail retention needed for dynamic motion. This conflict forces existing\nmethods into a compromise, leading to either geometric drift in static\nstructures or blurred, inaccurate reconstructions of dynamic objects. To\naddress this dilemma, we propose Mem4D, a novel framework that decouples the\nmodeling of static geometry and dynamic motion. Guided by this insight, we\ndesign a dual-memory architecture: 1) The Transient Dynamics Memory (TDM)\nfocuses on capturing high-frequency motion details from recent frames, enabling\naccurate and fine-grained modeling of dynamic content; 2) The Persistent\nStructure Memory (PSM) compresses and preserves long-term spatial information,\nensuring global consistency and drift-free reconstruction for static elements.\nBy alternating queries to these specialized memories, Mem4D simultaneously\nmaintains static geometry with global consistency and reconstructs dynamic\nelements with high fidelity. Experiments on challenging benchmarks demonstrate\nthat our method achieves state-of-the-art or competitive performance while\nmaintaining high efficiency. Codes will be publicly available.", "published": "2025-08-11 12:23:31", "link": "http://arxiv.org/abs/2508.07908v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generative Video Matting", "abstract": "Video matting has traditionally been limited by the lack of high-quality\nground-truth data. Most existing video matting datasets provide only\nhuman-annotated imperfect alpha and foreground annotations, which must be\ncomposited to background images or videos during the training stage. Thus, the\ngeneralization capability of previous methods in real-world scenarios is\ntypically poor. In this work, we propose to solve the problem from two\nperspectives. First, we emphasize the importance of large-scale pre-training by\npursuing diverse synthetic and pseudo-labeled segmentation datasets. We also\ndevelop a scalable synthetic data generation pipeline that can render diverse\nhuman bodies and fine-grained hairs, yielding around 200 video clips with a\n3-second duration for fine-tuning. Second, we introduce a novel video matting\napproach that can effectively leverage the rich priors from pre-trained video\ndiffusion models. This architecture offers two key advantages. First, strong\npriors play a critical role in bridging the domain gap between synthetic and\nreal-world scenes. Second, unlike most existing methods that process video\nmatting frame-by-frame and use an independent decoder to aggregate temporal\ninformation, our model is inherently designed for video, ensuring strong\ntemporal consistency. We provide a comprehensive quantitative evaluation across\nthree benchmark datasets, demonstrating our approach's superior performance,\nand present comprehensive qualitative results in diverse real-world scenes,\nillustrating the strong generalization capability of our method. The code is\navailable at https://github.com/aim-uofa/GVM.", "published": "2025-08-11 12:18:55", "link": "http://arxiv.org/abs/2508.07905v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality", "abstract": "Handwritten text recognition for historical documents remains challenging due\nto handwriting variability, degraded sources, and limited layout-aware\nannotations. In this work, we address annotation errors - particularly\nhyphenation issues - in the Bullinger correspondence, a large 16th-century\nletter collection. We introduce a self-training method based on a CTC alignment\nalgorithm that matches full transcriptions to text line images using dynamic\nprogramming and model output probabilities trained with the CTC loss. Our\napproach improves performance (e.g., by 1.1 percentage points CER with PyLaia)\nand increases alignment accuracy. Interestingly, we find that weaker models\nyield more accurate alignments, enabling an iterative training strategy. We\nrelease a new manually corrected subset of 100 pages from the Bullinger\ndataset, along with our code and benchmarks. Our approach can be applied\niteratively to further improve the CER as well as the alignment quality for\ntext recognition pipelines. Code and data are available via\nhttps://github.com/andreas-fischer-unifr/nntp.", "published": "2025-08-11 12:18:41", "link": "http://arxiv.org/abs/2508.07904v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation", "abstract": "Generating high-fidelity human videos that match user-specified identities is\nimportant yet challenging in the field of generative AI. Existing methods often\nrely on an excessive number of training parameters and lack compatibility with\nother AIGC tools. In this paper, we propose Stand-In, a lightweight and\nplug-and-play framework for identity preservation in video generation.\nSpecifically, we introduce a conditional image branch into the pre-trained\nvideo generation model. Identity control is achieved through restricted\nself-attentions with conditional position mapping, and can be learned quickly\nwith only 2000 pairs. Despite incorporating and training just $\\sim$1\\%\nadditional parameters, our framework achieves excellent results in video\nquality and identity preservation, outperforming other full-parameter training\nmethods. Moreover, our framework can be seamlessly integrated for other tasks,\nsuch as subject-driven video generation, pose-referenced video generation,\nstylization, and face swapping.", "published": "2025-08-11 12:17:38", "link": "http://arxiv.org/abs/2508.07901v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal", "abstract": "Image restoration under adverse weather conditions has been extensively\nexplored, leading to numerous high-performance methods. In particular, recent\nadvances in All-in-One approaches have shown impressive results by training on\nmulti-task image restoration datasets. However, most of these methods rely on\ndedicated network modules or parameters for each specific degradation type,\nresulting in a significant parameter overhead. Moreover, the relatedness across\ndifferent restoration tasks is often overlooked. In light of these issues, we\npropose a parameter-efficient All-in-One image restoration framework that\nleverages task-aware enhanced prompts to tackle various adverse weather\ndegradations.Specifically, we adopt a two-stage training paradigm consisting of\na pretraining phase and a prompt-tuning phase to mitigate parameter conflicts\nacross tasks. We first employ supervised learning to acquire general\nrestoration knowledge, and then adapt the model to handle specific degradation\nvia trainable soft prompts. Crucially, we enhance these task-specific prompts\nin a task-aware manner. We apply low-rank decomposition to these prompts to\ncapture both task-general and task-specific characteristics, and impose\ncontrastive constraints to better align them with the actual inter-task\nrelatedness. These enhanced prompts not only improve the parameter efficiency\nof the restoration model but also enable more accurate task modeling, as\nevidenced by t-SNE analysis. Experimental results on different restoration\ntasks demonstrate that the proposed method achieves superior performance with\nonly 2.75M parameters.", "published": "2025-08-11 11:51:06", "link": "http://arxiv.org/abs/2508.07878v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning", "abstract": "Modern large vision-language models (LVLMs) convert each input image into a\nlarge set of tokens, far outnumbering the text tokens. Although this improves\nvisual perception, it introduces severe image token redundancy. Because image\ntokens carry sparse information, many add little to reasoning, yet greatly\nincrease inference cost. The emerging image token pruning methods tackle this\nissue by identifying the most important tokens and discarding the rest. These\nmethods can raise efficiency with only modest performance loss. However, most\nof them only consider single-image tasks and overlook multimodal in-context\nlearning (ICL), where redundancy is greater and efficiency is more critical.\nRedundant tokens weaken the advantage of multimodal ICL for rapid domain\nadaptation and cause unstable performance. Applying existing pruning methods in\nthis setting leads to large accuracy drops, exposing a clear gap and the need\nfor new techniques. Thus, we propose Contextually Adaptive Token Pruning\n(CATP), a training-free pruning method targeted at multimodal ICL. CATP\nconsists of two stages that perform progressive pruning to fully account for\nthe complex cross-modal interactions in the input sequence. After removing\n77.8\\% of the image tokens, CATP produces an average performance gain of 0.6\\%\nover the vanilla model on four LVLMs and eight benchmarks, exceeding all\nbaselines remarkably. Meanwhile, it effectively improves efficiency by\nachieving an average reduction of 10.78\\% in inference latency. CATP enhances\nthe practical value of multimodal ICL and lays the groundwork for future\nprogress in interleaved image-text scenarios.", "published": "2025-08-11 11:41:51", "link": "http://arxiv.org/abs/2508.07871v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model", "abstract": "Human motion generation has emerged as a critical technology with\ntransformative potential for real-world applications. However, existing\nvision-language-motion models (VLMMs) face significant limitations that hinder\ntheir practical deployment. We identify controllability as a main bottleneck,\nmanifesting in five key aspects: inadequate response to diverse human commands,\nlimited pose initialization capabilities, poor performance on long-term\nsequences, insufficient handling of unseen scenarios, and lack of fine-grained\ncontrol over individual body parts. To overcome these limitations, we present\nBeing-M0.5, the first real-time, controllable VLMM that achieves\nstate-of-the-art performance across multiple motion generation tasks. Our\napproach is built upon HuMo100M, the largest and most comprehensive human\nmotion dataset to date, comprising over 5 million self-collected motion\nsequences, 100 million multi-task instructional instances, and detailed\npart-level annotations that address a critical gap in existing datasets. We\nintroduce a novel part-aware residual quantization technique for motion\ntokenization that enables precise, granular control over individual body parts\nduring generation. Extensive experimental validation demonstrates Being-M0.5's\nsuperior performance across diverse motion benchmarks, while comprehensive\nefficiency analysis confirms its real-time capabilities. Our contributions\ninclude design insights and detailed computational analysis to guide future\ndevelopment of practical motion generators. We believe that HuMo100M and\nBeing-M0.5 represent significant advances that will accelerate the adoption of\nmotion generation technologies in real-world applications. The project page is\navailable at https://beingbeyond.github.io/Being-M0.5.", "published": "2025-08-11 11:26:10", "link": "http://arxiv.org/abs/2508.07863v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images", "abstract": "Minimally invasive surgery presents challenges such as dynamic tissue motion\nand a limited field of view. Accurate tissue tracking has the potential to\nsupport surgical guidance, improve safety by helping avoid damage to sensitive\nstructures, and enable context-aware robotic assistance during complex\nprocedures. In this work, we propose a novel method for markerless 3D tissue\ntracking by leveraging 2D Tracking Any Point (TAP) networks. Our method\ncombines two CoTracker models, one for temporal tracking and one for stereo\nmatching, to estimate 3D motion from stereo endoscopic images. We evaluate the\nsystem using a clinical laparoscopic setup and a robotic arm simulating tissue\nmotion, with experiments conducted on a synthetic 3D-printed phantom and a\nchicken tissue phantom. Tracking on the chicken tissue phantom yielded more\nreliable results, with Euclidean distance errors as low as 1.1 mm at a velocity\nof 10 mm/s. These findings highlight the potential of TAP-based models for\naccurate, markerless 3D tracking in challenging surgical scenarios.", "published": "2025-08-11 11:10:16", "link": "http://arxiv.org/abs/2508.07851v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs", "abstract": "In this paper, electron microscopy images of microstructures formed on Ge\nsurfaces by ion beam irradiation were processed to extract topological features\nas skeleton graphs, which were then embedded using a graph convolutional\nnetwork. The resulting embeddings were analyzed using principal component\nanalysis, and cluster separability in the resulting PCA space was evaluated\nusing the Davies-Bouldin index. The results indicate that variations in\nirradiation angle have a more significant impact on the morphological\nproperties of Ge surfaces than variations in irradiation fluence.", "published": "2025-08-11 11:10:07", "link": "http://arxiv.org/abs/2508.07850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving", "abstract": "Bird's Eye View (BEV) perception systems based on multi-sensor feature fusion\nhave become a fundamental cornerstone for end-to-end autonomous driving.\nHowever, existing multi-modal BEV methods commonly suffer from limited input\nadaptability, constrained modeling capacity, and suboptimal generalization. To\naddress these challenges, we propose a hierarchically decoupled\nMixture-of-Experts architecture at the functional module level, termed\nComputing Brain DEvelopment System Mixture-of-Experts (CBDES MoE). CBDES MoE\nintegrates multiple structurally heterogeneous expert networks with a\nlightweight Self-Attention Router (SAR) gating mechanism, enabling dynamic\nexpert path selection and sparse, input-aware efficient inference. To the best\nof our knowledge, this is the first modular Mixture-of-Experts framework\nconstructed at the functional module granularity within the autonomous driving\ndomain. Extensive evaluations on the real-world nuScenes dataset demonstrate\nthat CBDES MoE consistently outperforms fixed single-expert baselines in 3D\nobject detection. Compared to the strongest single-expert model, CBDES MoE\nachieves a 1.6-point increase in mAP and a 4.1-point improvement in NDS,\ndemonstrating the effectiveness and practical advantages of the proposed\napproach.", "published": "2025-08-11 10:44:25", "link": "http://arxiv.org/abs/2508.07838v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Effortless Vision-Language Model Specialization in Histopathology without Annotation", "abstract": "Recent advances in Vision-Language Models (VLMs) in histopathology, such as\nCONCH and QuiltNet, have demonstrated impressive zero-shot classification\ncapabilities across various tasks. However, their general-purpose design may\nlead to suboptimal performance in specific downstream applications. While\nsupervised fine-tuning methods address this issue, they require manually\nlabeled samples for adaptation. This paper investigates annotation-free\nadaptation of VLMs through continued pretraining on domain- and task-relevant\nimage-caption pairs extracted from existing databases. Our experiments on two\nVLMs, CONCH and QuiltNet, across three downstream tasks reveal that these pairs\nsubstantially enhance both zero-shot and few-shot performance. Notably, with\nlarger training sizes, continued pretraining matches the performance of\nfew-shot methods while eliminating manual labeling. Its effectiveness,\ntask-agnostic design, and annotation-free workflow make it a promising pathway\nfor adapting VLMs to new histopathology tasks. Code is available at\nhttps://github.com/DeepMicroscopy/Annotation-free-VLM-specialization.", "published": "2025-08-11 10:39:27", "link": "http://arxiv.org/abs/2508.07835v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization", "abstract": "Vision Language Models (VLMs) encode multimodal inputs over large, complex,\nand difficult-to-interpret architectures, which limit transparency and trust.\nWe propose a Multimodal Inversion for Model Interpretation and\nConceptualization (MIMIC) framework to visualize the internal representations\nof VLMs by synthesizing visual concepts corresponding to internal encodings.\nMIMIC uses a joint VLM-based inversion and a feature alignment objective to\naccount for VLM's autoregressive processing. It additionally includes a triplet\nof regularizers for spatial alignment, natural image smoothness, and semantic\nrealism. We quantitatively and qualitatively evaluate MIMIC by inverting visual\nconcepts over a range of varying-length free-form VLM output texts. Reported\nresults include both standard visual quality metrics as well as semantic\ntext-based metrics. To the best of our knowledge, this is the first model\ninversion approach addressing visual interpretations of VLM concepts.", "published": "2025-08-11 10:36:58", "link": "http://arxiv.org/abs/2508.07833v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models", "abstract": "No-reference image quality assessment (NR-IQA) aims to simulate the process\nof perceiving image quality aligned with subjective human perception. However,\nexisting NR-IQA methods either focus on global representations that leads to\nlimited insights into the semantically salient regions or employ a uniform\nweighting for region features that weakens the sensitivity to local quality\nvariations. In this paper, we propose a fine-grained image quality assessment\nmodel, named RSFIQA, which integrates region-level distortion information to\nperceive multi-dimensional quality discrepancies. To enhance regional quality\nawareness, we first utilize the Segment Anything Model (SAM) to dynamically\npartition the input image into non-overlapping semantic regions. For each\nregion, we teach a powerful Multi-modal Large Language Model (MLLM) to extract\ndescriptive content and perceive multi-dimensional distortions, enabling a\ncomprehensive understanding of both local semantics and quality degradations.\nTo effectively leverage this information, we introduce Region-Aware Semantic\nAttention (RSA) mechanism, which generates a global attention map by\naggregating fine-grained representations from local regions. In addition,\nRSFIQA is backbone-agnostic and can be seamlessly integrated into various deep\nneural network architectures. Extensive experiments demonstrate the robustness\nand effectiveness of the proposed method, which achieves competitive quality\nprediction performance across multiple benchmark datasets.", "published": "2025-08-11 10:03:00", "link": "http://arxiv.org/abs/2508.07818v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semi-supervised Multiscale Matching for SAR-Optical Image", "abstract": "Driven by the complementary nature of optical and synthetic aperture radar\n(SAR) images, SAR-optical image matching has garnered significant interest.\nMost existing SAR-optical image matching methods aim to capture effective\nmatching features by employing the supervision of pixel-level matched\ncorrespondences within SAR-optical image pairs, which, however, suffers from\ntime-consuming and complex manual annotation, making it difficult to collect\nsufficient labeled SAR-optical image pairs. To handle this, we design a\nsemi-supervised SAR-optical image matching pipeline that leverages both scarce\nlabeled and abundant unlabeled image pairs and propose a semi-supervised\nmultiscale matching for SAR-optical image matching (S2M2-SAR). Specifically, we\npseudo-label those unlabeled SAR-optical image pairs with pseudo ground-truth\nsimilarity heatmaps by combining both deep and shallow level matching results,\nand train the matching model by employing labeled and pseudo-labeled similarity\nheatmaps. In addition, we introduce a cross-modal feature enhancement module\ntrained using a cross-modality mutual independence loss, which requires no\nground-truth labels. This unsupervised objective promotes the separation of\nmodality-shared and modality-specific features by encouraging statistical\nindependence between them, enabling effective feature disentanglement across\noptical and SAR modalities. To evaluate the effectiveness of S2M2-SAR, we\ncompare it with existing competitors on benchmark datasets. Experimental\nresults demonstrate that S2M2-SAR not only surpasses existing semi-supervised\nmethods but also achieves performance competitive with fully supervised SOTA\nmethods, demonstrating its efficiency and practical potential.", "published": "2025-08-11 09:55:39", "link": "http://arxiv.org/abs/2508.07812v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DiTVR: Zero-Shot Diffusion Transformer for Video Restoration", "abstract": "Video restoration aims to reconstruct high quality video sequences from low\nquality inputs, addressing tasks such as super resolution, denoising, and\ndeblurring. Traditional regression based methods often produce unrealistic\ndetails and require extensive paired datasets, while recent generative\ndiffusion models face challenges in ensuring temporal consistency. We introduce\nDiTVR, a zero shot video restoration framework that couples a diffusion\ntransformer with trajectory aware attention and a wavelet guided, flow\nconsistent sampler. Unlike prior 3D convolutional or frame wise diffusion\napproaches, our attention mechanism aligns tokens along optical flow\ntrajectories, with particular emphasis on vital layers that exhibit the highest\nsensitivity to temporal dynamics. A spatiotemporal neighbour cache dynamically\nselects relevant tokens based on motion correspondences across frames. The flow\nguided sampler injects data consistency only into low-frequency bands,\npreserving high frequency priors while accelerating convergence. DiTVR\nestablishes a new zero shot state of the art on video restoration benchmarks,\ndemonstrating superior temporal consistency and detail preservation while\nremaining robust to flow noise and occlusions.", "published": "2025-08-11 09:54:45", "link": "http://arxiv.org/abs/2508.07811v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning", "abstract": "Generating 3D human poses from multimodal inputs such as images or text\nrequires models to capture both rich spatial and semantic correspondences.\nWhile pose-specific multimodal large language models (MLLMs) have shown promise\nin this task, they are typically trained with supervised objectives such as\nSMPL parameter regression or token-level prediction, which struggle to model\nthe inherent ambiguity and achieve task-specific alignment required for\naccurate 3D pose generation. To address these limitations, we propose Pose-RFT,\na reinforcement fine-tuning framework tailored for 3D human pose generation in\nMLLMs. We formulate the task as a hybrid action reinforcement learning problem\nthat jointly optimizes discrete language prediction and continuous pose\ngeneration. To this end, we introduce HyGRPO, a hybrid reinforcement learning\nalgorithm that performs group-wise reward normalization over sampled responses\nto guide joint optimization of discrete and continuous actions. Pose-RFT\nfurther incorporates task-specific reward functions to guide optimization\ntowards spatial alignment in image-to-pose generation and semantic consistency\nin text-to-pose generation. Extensive experiments on multiple pose generation\nbenchmarks demonstrate that Pose-RFT significantly improves performance over\nexisting pose-specific MLLMs, validating the effectiveness of hybrid action\nreinforcement fine-tuning for 3D pose generation.", "published": "2025-08-11 09:44:58", "link": "http://arxiv.org/abs/2508.07804v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks", "abstract": "The goal of multimodal image fusion is to integrate complementary information\nfrom infrared and visible images, generating multimodal fused images for\ndownstream tasks. Existing downstream pre-training models are typically trained\non visible images. However, the significant pixel distribution differences\nbetween visible and multimodal fusion images can degrade downstream task\nperformance, sometimes even below that of using only visible images. This paper\nexplores adapting multimodal fused images with significant modality differences\nto object detection and semantic segmentation models trained on visible images.\nTo address this, we propose MambaTrans, a novel multimodal fusion image\nmodality translator. MambaTrans uses descriptions from a multimodal large\nlanguage model and masks from semantic segmentation models as input. Its core\ncomponent, the Multi-Model State Space Block, combines mask-image-text\ncross-attention and a 3D-Selective Scan Module, enhancing pure visual\ncapabilities. By leveraging object detection prior knowledge, MambaTrans\nminimizes detection loss during training and captures long-term dependencies\namong text, masks, and images. This enables favorable results in pre-trained\nmodels without adjusting their parameters. Experiments on public datasets show\nthat MambaTrans effectively improves multimodal image performance in downstream\ntasks.", "published": "2025-08-11 09:39:16", "link": "http://arxiv.org/abs/2508.07803v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Power Battery Detection", "abstract": "Power batteries are essential components in electric vehicles, where internal\nstructural defects can pose serious safety risks. We conduct a comprehensive\nstudy on a new task, power battery detection (PBD), which aims to localize the\ndense endpoints of cathode and anode plates from industrial X-ray images for\nquality inspection. Manual inspection is inefficient and error-prone, while\ntraditional vision algorithms struggle with densely packed plates, low\ncontrast, scale variation, and imaging artifacts. To address this issue and\ndrive more attention into this meaningful task, we present PBD5K, the first\nlarge-scale benchmark for this task, consisting of 5,000 X-ray images from nine\nbattery types with fine-grained annotations and eight types of real-world\nvisual interference. To support scalable and consistent labeling, we develop an\nintelligent annotation pipeline that combines image filtering, model-assisted\npre-labeling, cross-verification, and layered quality evaluation. We formulate\nPBD as a point-level segmentation problem and propose MDCNeXt, a model designed\nto extract and integrate multi-dimensional structure clues including point,\nline, and count information from the plate itself. To improve discrimination\nbetween plates and suppress visual interference, MDCNeXt incorporates two state\nspace modules. The first is a prompt-filtered module that learns contrastive\nrelationships guided by task-specific prompts. The second is a density-aware\nreordering module that refines segmentation in regions with high plate density.\nIn addition, we propose a distance-adaptive mask generation strategy to provide\nrobust supervision under varying spatial distributions of anode and cathode\npositions. The source code and datasets will be publicly available at\n\\href{https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD}{PBD5K}.", "published": "2025-08-11 09:35:25", "link": "http://arxiv.org/abs/2508.07797v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake", "abstract": "Active defense strategies have been developed to counter the threat of\ndeepfake technology. However, a primary challenge is their lack of persistence,\nas their effectiveness is often short-lived. Attackers can bypass these\ndefenses by simply collecting protected samples and retraining their models.\nThis means that static defenses inevitably fail when attackers retrain their\nmodels, which severely limits practical use. We argue that an effective defense\nnot only distorts forged content but also blocks the model's ability to adapt,\nwhich occurs when attackers retrain their models on protected images. To\nachieve this, we propose an innovative Two-Stage Defense Framework (TSDF).\nBenefiting from the intensity separation mechanism designed in this paper, the\nframework uses dual-function adversarial perturbations to perform two roles.\nFirst, it can directly distort the forged results. Second, it acts as a\npoisoning vehicle that disrupts the data preparation process essential for an\nattacker's retraining pipeline. By poisoning the data source, TSDF aims to\nprevent the attacker's model from adapting to the defensive perturbations, thus\nensuring the defense remains effective long-term. Comprehensive experiments\nshow that the performance of traditional interruption methods degrades sharply\nwhen it is subjected to adversarial retraining. However, our framework shows a\nstrong dual defense capability, which can improve the persistence of active\ndefense. Our code will be available at https://github.com/vpsg-research/TSDF.", "published": "2025-08-11 09:26:48", "link": "http://arxiv.org/abs/2508.07795v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning", "abstract": "To reduce radiation exposure and improve the diagnostic efficacy of low-dose\ncomputed tomography (LDCT), numerous deep learning-based denoising methods have\nbeen developed to mitigate noise and artifacts. However, most of these\napproaches ignore the anatomical semantics of human tissues, which may\npotentially result in suboptimal denoising outcomes. To address this problem,\nwe propose ALDEN, an anatomy-aware LDCT denoising method that integrates\nsemantic features of pretrained vision models (PVMs) with adversarial and\ncontrastive learning. Specifically, we introduce an anatomy-aware discriminator\nthat dynamically fuses hierarchical semantic features from reference\nnormal-dose CT (NDCT) via cross-attention mechanisms, enabling tissue-specific\nrealism evaluation in the discriminator. In addition, we propose a\nsemantic-guided contrastive learning module that enforces anatomical\nconsistency by contrasting PVM-derived features from LDCT, denoised CT and\nNDCT, preserving tissue-specific patterns through positive pairs and\nsuppressing artifacts via dual negative pairs. Extensive experiments conducted\non two LDCT denoising datasets reveal that ALDEN achieves the state-of-the-art\nperformance, offering superior anatomy preservation and substantially reducing\nover-smoothing issue of previous work. Further validation on a downstream\nmulti-organ segmentation task (encompassing 117 anatomical structures) affirms\nthe model's ability to maintain anatomical awareness.", "published": "2025-08-11 09:17:12", "link": "http://arxiv.org/abs/2508.07788v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences", "abstract": "Recent advancements in gait recognition have significantly enhanced\nperformance by treating silhouettes as either an unordered set or an ordered\nsequence. However, both set-based and sequence-based approaches exhibit notable\nlimitations. Specifically, set-based methods tend to overlook short-range\ntemporal context for individual frames, while sequence-based methods struggle\nto capture long-range temporal dependencies effectively. To address these\nchallenges, we draw inspiration from human identification and propose a new\nperspective that conceptualizes human gait as a composition of individualized\nactions. Each action is represented by a series of frames, randomly selected\nfrom a continuous segment of the sequence, which we term a snippet.\nFundamentally, the collection of snippets for a given sequence enables the\nincorporation of multi-scale temporal context, facilitating more comprehensive\ngait feature learning. Moreover, we introduce a non-trivial solution for\nsnippet-based gait recognition, focusing on Snippet Sampling and Snippet\nModeling as key components. Extensive experiments on four widely-used gait\ndatasets validate the effectiveness of our proposed approach and, more\nimportantly, highlight the potential of gait snippets. For instance, our method\nachieves the rank-1 accuracy of 77.5% on Gait3D and 81.7% on GREW using a 2D\nconvolution-based backbone.", "published": "2025-08-11 09:13:38", "link": "http://arxiv.org/abs/2508.07782v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)", "abstract": "Modeling the rotation of moving objects is a fundamental task in computer\nvision, yet $SO(3)$ extrapolation still presents numerous challenges: (1)\nunknown quantities such as the moment of inertia complicate dynamics, (2) the\npresence of external forces and torques can lead to non-conservative\nkinematics, and (3) estimating evolving state trajectories under sparse, noisy\nobservations requires robustness. We propose modeling trajectories of noisy\npose estimates on the manifold of 3D rotations in a physically and\ngeometrically meaningful way by leveraging Neural Controlled Differential\nEquations guided with $SO(3)$ Savitzky-Golay paths. Existing extrapolation\nmethods often rely on energy conservation or constant velocity assumptions,\nlimiting their applicability in real-world scenarios involving non-conservative\nforces. In contrast, our approach is agnostic to energy and momentum\nconservation while being robust to input noise, making it applicable to\ncomplex, non-inertial systems. Our approach is easily integrated as a module in\nexisting pipelines and generalizes well to trajectories with unknown physical\nparameters. By learning to approximate object dynamics from noisy states during\ntraining, our model attains robust extrapolation capabilities in simulation and\nvarious real-world settings. Code is available at\nhttps://github.com/bastianlb/forecasting-rotational-dynamics", "published": "2025-08-11 09:03:10", "link": "http://arxiv.org/abs/2508.07775v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prototype-Guided Curriculum Learning for Zero-Shot Learning", "abstract": "In Zero-Shot Learning (ZSL), embedding-based methods enable knowledge\ntransfer from seen to unseen classes by learning a visual-semantic mapping from\nseen-class images to class-level semantic prototypes (e.g., attributes).\nHowever, these semantic prototypes are manually defined and may introduce noisy\nsupervision for two main reasons: (i) instance-level mismatch: variations in\nperspective, occlusion, and annotation bias will cause discrepancies between\nindividual sample and the class-level semantic prototypes; and (ii) class-level\nimprecision: the manually defined semantic prototypes may not accurately\nreflect the true semantics of the class. Consequently, the visual-semantic\nmapping will be misled, reducing the effectiveness of knowledge transfer to\nunseen classes. In this work, we propose a prototype-guided curriculum learning\nframework (dubbed as CLZSL), which mitigates instance-level mismatches through\na Prototype-Guided Curriculum Learning (PCL) module and addresses class-level\nimprecision via a Prototype Update (PUP) module. Specifically, the PCL module\nprioritizes samples with high cosine similarity between their visual mappings\nand the class-level semantic prototypes, and progressively advances to\nless-aligned samples, thereby reducing the interference of instance-level\nmismatches to achieve accurate visual-semantic mapping. Besides, the PUP module\ndynamically updates the class-level semantic prototypes by leveraging the\nvisual mappings learned from instances, thereby reducing class-level\nimprecision and further improving the visual-semantic mapping. Experiments were\nconducted on standard benchmark datasets-AWA2, SUN, and CUB-to verify the\neffectiveness of our method.", "published": "2025-08-11 08:56:21", "link": "http://arxiv.org/abs/2508.07771v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation", "abstract": "The synthesis of spatiotemporally coherent 4D content presents fundamental\nchallenges in computer vision, requiring simultaneous modeling of high-fidelity\nspatial representations and physically plausible temporal dynamics. Current\napproaches often struggle to maintain view consistency while handling complex\nscene dynamics, particularly in large-scale environments with multiple\ninteracting elements. This work introduces Dream4D, a novel framework that\nbridges this gap through a synergy of controllable video generation and neural\n4D reconstruction. Our approach seamlessly combines a two-stage architecture:\nit first predicts optimal camera trajectories from a single image using\nfew-shot learning, then generates geometrically consistent multi-view sequences\nvia a specialized pose-conditioned diffusion process, which are finally\nconverted into a persistent 4D representation. This framework is the first to\nleverage both rich temporal priors from video diffusion models and geometric\nawareness of the reconstruction models, which significantly facilitates 4D\ngeneration and shows higher quality (e.g., mPSNR, mSSIM) over existing methods.", "published": "2025-08-11 08:55:47", "link": "http://arxiv.org/abs/2508.07769v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sea-Undistort: A Dataset for Through-Water Image Restoration in High Resolution Airborne Bathymetric Mapping", "abstract": "Accurate image-based bathymetric mapping in shallow waters remains\nchallenging due to the complex optical distortions such as wave induced\npatterns, scattering and sunglint, introduced by the dynamic water surface, the\nwater column properties, and solar illumination. In this work, we introduce\nSea-Undistort, a comprehensive synthetic dataset of 1200 paired 512x512\nthrough-water scenes rendered in Blender. Each pair comprises a distortion-free\nand a distorted view, featuring realistic water effects such as sun glint,\nwaves, and scattering over diverse seabeds. Accompanied by per-image metadata\nsuch as camera parameters, sun position, and average depth, Sea-Undistort\nenables supervised training that is otherwise infeasible in real environments.\nWe use Sea-Undistort to benchmark two state-of-the-art image restoration\nmethods alongside an enhanced lightweight diffusion-based framework with an\nearly-fusion sun-glint mask. When applied to real aerial data, the enhanced\ndiffusion model delivers more complete Digital Surface Models (DSMs) of the\nseabed, especially in deeper areas, reduces bathymetric errors, suppresses\nglint and scattering, and crisply restores fine seabed details. Dataset,\nweights, and code are publicly available at\nhttps://www.magicbathy.eu/Sea-Undistort.html.", "published": "2025-08-11 08:43:29", "link": "http://arxiv.org/abs/2508.07760v1", "categories": ["eess.IV", "cs.CV", "cs.GR"], "primary_category": "eess.IV"}
{"title": "Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild", "abstract": "Large vision models like the Segment Anything Model (SAM) exhibit significant\nlimitations when applied to downstream tasks in the wild. Consequently,\nreference segmentation, which leverages reference images and their\ncorresponding masks to impart novel knowledge to the model, emerges as a\npromising new direction for adapting vision models. However, existing reference\nsegmentation approaches predominantly rely on meta-learning, which still\nnecessitates an extensive meta-training process and brings massive data and\ncomputational cost. In this study, we propose a novel approach by representing\nthe inherent correspondence between reference-target image pairs as a pseudo\nvideo. This perspective allows the latest version of SAM, known as SAM2, which\nis equipped with interactive video object segmentation (iVOS) capabilities, to\nbe adapted to downstream tasks in a lightweight manner. We term this approach\nCorrespondence As Video for SAM (CAV-SAM). CAV-SAM comprises two key modules:\nthe Diffusion-Based Semantic Transition (DBST) module employs a diffusion model\nto construct a semantic transformation sequence, while the Test-Time Geometric\nAlignment (TTGA) module aligns the geometric changes within this sequence\nthrough test-time fine-tuning. We evaluated CAVSAM on widely-used datasets,\nachieving segmentation performance improvements exceeding 5% over SOTA methods.\nImplementation is provided in the supplementary materials.", "published": "2025-08-11 08:42:49", "link": "http://arxiv.org/abs/2508.07759v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion", "abstract": "The recent demand for customized image generation raises a need for\ntechniques that effectively extract the common concept from small sets of\nimages. Existing methods typically rely on additional guidance, such as text\nprompts or spatial masks, to capture the common target concept. Unfortunately,\nrelying on manually provided guidance can lead to incomplete separation of\nauxiliary features, which degrades generation quality.In this paper, we propose\nContrastive Inversion, a novel approach that identifies the common concept by\ncomparing the input images without relying on additional information. We train\nthe target token along with the image-wise auxiliary text tokens via\ncontrastive learning, which extracts the well-disentangled true semantics of\nthe target. Then we apply disentangled cross-attention fine-tuning to improve\nconcept fidelity without overfitting. Experimental results and analysis\ndemonstrate that our method achieves a balanced, high-level performance in both\nconcept representation and editing, outperforming existing techniques.", "published": "2025-08-11 08:36:29", "link": "http://arxiv.org/abs/2508.07755v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Grouped Speculative Decoding for Autoregressive Image Generation", "abstract": "Recently, autoregressive (AR) image models have demonstrated remarkable\ngenerative capabilities, positioning themselves as a compelling alternative to\ndiffusion models. However, their sequential nature leads to long inference\ntimes, limiting their practical scalability. In this work, we introduce Grouped\nSpeculative Decoding (GSD), a novel, training-free acceleration method for AR\nimage models. While recent studies have explored Speculative Decoding (SD) as a\nmeans to speed up AR image generation, existing approaches either provide only\nmodest acceleration or require additional training. Our in-depth analysis\nreveals a fundamental difference between language and image tokens: image\ntokens exhibit inherent redundancy and diversity, meaning multiple tokens can\nconvey valid semantics. However, traditional SD methods are designed to accept\nonly a single most-likely token, which fails to leverage this difference,\nleading to excessive false-negative rejections. To address this, we propose a\nnew SD strategy that evaluates clusters of visually valid tokens rather than\nrelying on a single target token. Additionally, we observe that static\nclustering based on embedding distance is ineffective, which motivates our\ndynamic GSD approach. Extensive experiments show that GSD accelerates AR image\nmodels by an average of 3.7x while preserving image quality-all without\nrequiring any additional training. The source code is available at\nhttps://github.com/junhyukso/GSD", "published": "2025-08-11 08:27:57", "link": "http://arxiv.org/abs/2508.07747v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting", "abstract": "The performance of computer vision models in certain real-world applications,\nsuch as medical diagnosis, is often limited by the scarcity of available\nimages. Expanding datasets using pre-trained generative models is an effective\nsolution. However, due to the uncontrollable generation process and the\nambiguity of natural language, noisy images may be generated. Re-weighting is\nan effective way to address this issue by assigning low weights to such noisy\nimages. We first theoretically analyze three types of supervision for the\ngenerated images. Based on the theoretical analysis, we develop TriReWeight, a\ntriplet-connection-based sample re-weighting method to enhance generative data\naugmentation. Theoretically, TriReWeight can be integrated with any generative\ndata augmentation methods and never downgrade their performance. Moreover, its\ngeneralization approaches the optimal in the order $O(\\sqrt{d\\ln (n)/n})$. Our\nexperiments validate the correctness of the theoretical analysis and\ndemonstrate that our method outperforms the existing SOTA methods by $7.9\\%$ on\naverage over six natural image datasets and by $3.4\\%$ on average over three\nmedical datasets. We also experimentally validate that our method can enhance\nthe performance of different generative data augmentation methods.", "published": "2025-08-11 07:50:47", "link": "http://arxiv.org/abs/2508.07723v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Registration-Based Star-Shape Segmentation Model and Fast Algorithms", "abstract": "Image segmentation plays a crucial role in extracting objects of interest and\nidentifying their boundaries within an image. However, accurate segmentation\nbecomes challenging when dealing with occlusions, obscurities, or noise in\ncorrupted images. To tackle this challenge, prior information is often\nutilized, with recent attention on star-shape priors. In this paper, we propose\na star-shape segmentation model based on the registration framework. By\ncombining the level set representation with the registration framework and\nimposing constraints on the deformed level set function, our model enables both\nfull and partial star-shape segmentation, accommodating single or multiple\ncenters. Additionally, our approach allows for the enforcement of identified\nboundaries to pass through specified landmark locations. We tackle the proposed\nmodels using the alternating direction method of multipliers. Through numerical\nexperiments conducted on synthetic and real images, we demonstrate the efficacy\nof our approach in achieving accurate star-shape segmentation.", "published": "2025-08-11 07:47:46", "link": "http://arxiv.org/abs/2508.07721v1", "categories": ["cs.CV", "cs.NA", "math.NA", "65D18, 68U10, 94A08"], "primary_category": "cs.CV"}
{"title": "Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction", "abstract": "3D Gaussian Splatting (3DGS) achieves remarkable results in the field of\nsurface reconstruction. However, when Gaussian normal vectors are aligned\nwithin the single-view projection plane, while the geometry appears reasonable\nin the current view, biases may emerge upon switching to nearby views. To\naddress the distance and global matching challenges in multi-view scenes, we\ndesign multi-view normal and distance-guided Gaussian splatting. This method\nachieves geometric depth unification and high-accuracy reconstruction by\nconstraining nearby depth maps and aligning 3D normals. Specifically, for the\nreconstruction of small indoor and outdoor scenes, we propose a multi-view\ndistance reprojection regularization module that achieves multi-view Gaussian\nalignment by computing the distance loss between two nearby views and the same\nGaussian surface. Additionally, we develop a multi-view normal enhancement\nmodule, which ensures consistency across views by matching the normals of pixel\npoints in nearby views and calculating the loss. Extensive experimental results\ndemonstrate that our method outperforms the baseline in both quantitative and\nqualitative evaluations, significantly enhancing the surface reconstruction\ncapability of 3DGS.", "published": "2025-08-11 07:25:13", "link": "http://arxiv.org/abs/2508.07701v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing", "abstract": "As 3D generation techniques continue to flourish, the demand for generating\npersonalized content is rapidly rising. Users increasingly seek to apply\nvarious editing methods to polish generated 3D content, aiming to enhance its\ncolor, style, and lighting without compromising the underlying geometry.\nHowever, most existing editing tools focus on the 2D domain, and directly\nfeeding their results into 3D generation methods (like multi-view diffusion\nmodels) will introduce information loss, degrading the quality of the final 3D\nassets. In this paper, we propose a tuning-free, plug-and-play scheme that\naligns edited assets with their original geometry in a single inference run.\nCentral to our approach is a geometry preservation module that guides the\nedited multi-view generation with original input normal latents. Besides, an\ninjection switcher is proposed to deliberately control the supervision extent\nof the original normals, ensuring the alignment between the edited color and\nnormal views. Extensive experiments show that our method consistently improves\nboth the multi-view consistency and mesh quality of edited 3D assets, across\nmultiple combinations of multi-view diffusion models and editing methods.", "published": "2025-08-11 07:23:39", "link": "http://arxiv.org/abs/2508.07700v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework", "abstract": "In this work, we first propose DiffVC-OSD, a One-Step Diffusion-based\nPerceptual Neural Video Compression framework. Unlike conventional multi-step\ndiffusion-based methods, DiffVC-OSD feeds the reconstructed latent\nrepresentation directly into a One-Step Diffusion Model, enhancing perceptual\nquality through a single diffusion step guided by both temporal context and the\nlatent itself. To better leverage temporal dependencies, we design a Temporal\nContext Adapter that encodes conditional inputs into multi-level features,\noffering more fine-grained guidance for the Denoising Unet. Additionally, we\nemploy an End-to-End Finetuning strategy to improve overall compression\nperformance. Extensive experiments demonstrate that DiffVC-OSD achieves\nstate-of-the-art perceptual compression performance, offers about 20$\\times$\nfaster decoding and a 86.92\\% bitrate reduction compared to the corresponding\nmulti-step diffusion-based variant.", "published": "2025-08-11 06:59:23", "link": "http://arxiv.org/abs/2508.07682v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Undress to Redress: A Training-Free Framework for Virtual Try-On", "abstract": "Virtual try-on (VTON) is a crucial task for enhancing user experience in\nonline shopping by generating realistic garment previews on personal photos.\nAlthough existing methods have achieved impressive results, they struggle with\nlong-sleeve-to-short-sleeve conversions-a common and practical scenario-often\nproducing unrealistic outputs when exposed skin is underrepresented in the\noriginal image. We argue that this challenge arises from the ''majority''\ncompletion rule in current VTON models, which leads to inaccurate skin\nrestoration in such cases. To address this, we propose UR-VTON (Undress-Redress\nVirtual Try-ON), a novel, training-free framework that can be seamlessly\nintegrated with any existing VTON method. UR-VTON introduces an\n''undress-to-redress'' mechanism: it first reveals the user's torso by\nvirtually ''undressing,'' then applies the target short-sleeve garment,\neffectively decomposing the conversion into two more manageable steps.\nAdditionally, we incorporate Dynamic Classifier-Free Guidance scheduling to\nbalance diversity and image quality during DDPM sampling, and employ Structural\nRefiner to enhance detail fidelity using high-frequency cues. Finally, we\npresent LS-TON, a new benchmark for long-sleeve-to-short-sleeve try-on.\nExtensive experiments demonstrate that UR-VTON outperforms state-of-the-art\nmethods in both detail preservation and image quality. Code will be released\nupon acceptance.", "published": "2025-08-11 06:55:49", "link": "http://arxiv.org/abs/2508.07680v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels", "abstract": "The acquisition of high-quality labeled synthetic aperture radar (SAR) data\nis challenging due to the demanding requirement for expert knowledge.\nConsequently, the presence of unreliable noisy labels is unavoidable, which\nresults in performance degradation of SAR automatic target recognition (ATR).\nExisting research on learning with noisy labels mainly focuses on image data.\nHowever, the non-intuitive visual characteristics of SAR data are insufficient\nto achieve noise-robust learning. To address this problem, we propose\ncollaborative learning of scattering and deep features (CLSDF) for SAR ATR with\nnoisy labels. Specifically, a multi-model feature fusion framework is designed\nto integrate scattering and deep features. The attributed scattering centers\n(ASCs) are treated as dynamic graph structure data, and the extracted physical\ncharacteristics effectively enrich the representation of deep image features.\nThen, the samples with clean and noisy labels are divided by modeling the loss\ndistribution with multiple class-wise Gaussian Mixture Models (GMMs).\nAfterward, the semi-supervised learning of two divergent branches is conducted\nbased on the data divided by each other. Moreover, a joint distribution\nalignment strategy is introduced to enhance the reliability of co-guessed\nlabels. Extensive experiments have been done on the Moving and Stationary\nTarget Acquisition and Recognition (MSTAR) dataset, and the results show that\nthe proposed method can achieve state-of-the-art performance under different\noperating conditions with various label noises.", "published": "2025-08-11 06:10:23", "link": "http://arxiv.org/abs/2508.07656v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering", "abstract": "We propose a novel training-free image generation algorithm that precisely\ncontrols the occlusion relationships between objects in an image. Existing\nimage generation methods typically rely on prompts to influence occlusion,\nwhich often lack precision. While layout-to-image methods provide control over\nobject locations, they fail to address occlusion relationships explicitly.\nGiven a pre-trained image diffusion model, our method leverages volume\nrendering principles to \"render\" the scene in latent space, guided by occlusion\nrelationships and the estimated transmittance of objects. This approach does\nnot require retraining or fine-tuning the image diffusion model, yet it enables\naccurate occlusion control due to its physics-grounded foundation. In extensive\nexperiments, our method significantly outperforms existing approaches in terms\nof occlusion accuracy. Furthermore, we demonstrate that by adjusting the\nopacities of objects or concepts during rendering, our method can achieve a\nvariety of effects, such as altering the transparency of objects, the density\nof mass (e.g., forests), the concentration of particles (e.g., rain, fog), the\nintensity of light, and the strength of lens effects, etc.", "published": "2025-08-11 05:57:59", "link": "http://arxiv.org/abs/2508.07647v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning", "abstract": "Visual Robot Manipulation (VRM) aims to enable a robot to follow natural\nlanguage instructions based on robot states and visual observations, and\ntherefore requires costly multi-modal data. To compensate for the deficiency of\nrobot data, existing approaches have employed vision-language pretraining with\nlarge-scale data. However, they either utilize web data that differs from\nrobotic tasks, or train the model in an implicit way (e.g., predicting future\nframes at the pixel level), thus showing limited generalization ability under\ninsufficient robot data. In this paper, we propose to learn from large-scale\nhuman action video datasets in an explicit way (i.e., imitating human actions\nfrom hand keypoints), introducing Visual Robot Manipulation with Analogical\nReasoning (AR-VRM). To acquire action knowledge explicitly from human action\nvideos, we propose a keypoint Vision-Language Model (VLM) pretraining scheme,\nenabling the VLM to learn human action knowledge and directly predict human\nhand keypoints. During fine-tuning on robot data, to facilitate the robotic arm\nin imitating the action patterns of human motions, we first retrieve human\naction videos that perform similar manipulation tasks and have similar\nhistorical observations , and then learn the Analogical Reasoning (AR) map\nbetween human hand keypoints and robot components. Taking advantage of focusing\non action keypoints instead of irrelevant visual cues, our method achieves\nleading performance on the CALVIN benchmark {and real-world experiments}. In\nfew-shot scenarios, our AR-VRM outperforms previous methods by large margins ,\nunderscoring the effectiveness of explicitly imitating human actions under data\nscarcity.", "published": "2025-08-11 05:09:58", "link": "http://arxiv.org/abs/2508.07626v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Coloring Graphs with no Totally Odd Clique Immersion", "abstract": "We prove that graphs that do not contain a totally odd immersion of $K_t$ are\n$\\mathcal{O}(t)$-colorable. In particular, we show that any graph with no\ntotally odd immersion of $K_t$ is the union of a bipartite graph and a graph\nwhich forbids an immersion of $K_{\\mathcal{O}(t)}$. Our results are\nalgorithmic, and we give a fixed-parameter tractable algorithm (in $t$) to find\nsuch a decomposition.", "published": "2025-08-11 15:57:58", "link": "http://arxiv.org/abs/2508.08119v1", "categories": ["math.CO", "cs.DM", "05C15, 05C83", "G.2.2"], "primary_category": "math.CO"}
{"title": "Remarks on the Brouwer Conjecture", "abstract": "The Brouwer conjecture (BC) in spectral graph theory claims that the sum of\nthe largest k Kirchhoff eigenvalues of a graph are bounded above by the number\nm of edges plus k(k+1)/2. We show that (BC) holds for all graphs with n\nvertices if n is larger or equal than 4 times the square of the maximal vertex\ndegree. We also note that the weaker upper bound m+k(k+1) holds\nunconditionally. We also note that (BC) for graphs implies (BC) for quivers.", "published": "2025-08-11 02:13:38", "link": "http://arxiv.org/abs/2508.07550v1", "categories": ["math.CO", "cs.DM", "05Cxx 05Exx 68Rxx"], "primary_category": "math.CO"}
{"title": "Early Explorations of Recommender Systems for Physical Activity and Well-being", "abstract": "As recommender systems increasingly guide physical actions, often through\nwearables and coaching tools, new challenges arise around how users interpret,\ntrust, and respond to this advice. This paper introduces a conceptual framework\nfor tangible recommendations that influence users' bodies, routines, and\nwell-being. We describe three design dimensions: trust and interpretation,\nintent alignment, and consequence awareness. These highlight key limitations in\napplying conventional recommender logic to embodied settings. Through examples\nand design reflections, we outline how future systems can support long-term\nwell-being, behavioral alignment, and socially responsible personalization.", "published": "2025-08-11 13:38:58", "link": "http://arxiv.org/abs/2508.07980v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "Careful Queries, Credible Results: Teaching RAG Models Advanced Web Search Tools with Reinforcement Learning", "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating up-to-date external knowledge, yet real-world web environments\npresent unique challenges. These limitations manifest as two key challenges:\npervasive misinformation in the web environment, which introduces unreliable or\nmisleading content that can degrade retrieval accuracy, and the\nunderutilization of web tools, which, if effectively employed, could enhance\nquery precision and help mitigate this noise, ultimately improving the\nretrieval results in RAG systems. To address these issues, we propose\nWebFilter, a novel RAG framework that generates source-restricted queries and\nfilters out unreliable content. This approach combines a retrieval filtering\nmechanism with a behavior- and outcome-driven reward strategy, optimizing both\nquery formulation and retrieval outcomes. Extensive experiments demonstrate\nthat WebFilter improves answer quality and retrieval precision, outperforming\nexisting RAG methods on both in-domain and out-of-domain benchmarks.", "published": "2025-08-11 13:08:37", "link": "http://arxiv.org/abs/2508.07956v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Meta Off-Policy Estimation", "abstract": "Off-policy estimation (OPE) methods enable unbiased offline evaluation of\nrecommender systems, directly estimating the online reward some target policy\nwould have obtained, from offline data and with statistical guarantees. The\ntheoretical elegance of the framework combined with practical successes have\nled to a surge of interest, with many competing estimators now available to\npractitioners and researchers. Among these, Doubly Robust methods provide a\nprominent strategy to combine value- and policy-based estimators.\n  In this work, we take an alternative perspective to combine a set of OPE\nestimators and their associated confidence intervals into a single, more\naccurate estimate. Our approach leverages a correlated fixed-effects\nmeta-analysis framework, explicitly accounting for dependencies among\nestimators that arise due to shared data. This yields a best linear unbiased\nestimate (BLUE) of the target policy's value, along with an appropriately\nconservative confidence interval that reflects inter-estimator correlation. We\nvalidate our method on both simulated and real-world data, demonstrating\nimproved statistical efficiency over existing individual estimators.", "published": "2025-08-11 12:31:13", "link": "http://arxiv.org/abs/2508.07914v1", "categories": ["stat.ML", "cs.IR", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Recommendation Is a Dish Better Served Warm", "abstract": "In modern recommender systems, experimental settings typically include\nfiltering out cold users and items based on a minimum interaction threshold.\nHowever, these thresholds are often chosen arbitrarily and vary widely across\nstudies, leading to inconsistencies that can significantly affect the\ncomparability and reliability of evaluation results. In this paper, we\nsystematically explore the cold-start boundary by examining the criteria used\nto determine whether a user or an item should be considered cold. Our\nexperiments incrementally vary the number of interactions for different items\nduring training, and gradually update the length of user interaction histories\nduring inference. We investigate the thresholds across several widely used\ndatasets, commonly represented in recent papers from top-tier conferences, and\non multiple established recommender baselines. Our findings show that\ninconsistent selection of cold-start thresholds can either result in the\nunnecessary removal of valuable data or lead to the misclassification of cold\ninstances as warm, introducing more noise into the system.", "published": "2025-08-11 11:14:49", "link": "http://arxiv.org/abs/2508.07856v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Encode Me If You Can: Learning Universal User Representations via Event Sequence Autoencoding", "abstract": "Building universal user representations that capture the essential aspects of\nuser behavior is a crucial task for modern machine learning systems. In\nreal-world applications, a user's historical interactions often serve as the\nfoundation for solving a wide range of predictive tasks, such as churn\nprediction, recommendations, or lifetime value estimation. Using a\ntask-independent user representation that is effective across all such tasks\ncan reduce the need for task-specific feature engineering and model retraining,\nleading to more scalable and efficient machine learning pipelines. The goal of\nthe RecSys Challenge 2025 by Synerise was to develop such Universal Behavioral\nProfiles from logs of past user behavior, which included various types of\nevents such as product purchases, page views, and search queries. We propose a\nmethod that transforms the entire user interaction history into a single\nchronological sequence and trains a GRU-based autoencoder to reconstruct this\nsequence from a fixed-size vector. If the model can accurately reconstruct the\nsequence, the latent vector is expected to capture the key behavioral patterns.\nIn addition to this core model, we explored several alternative methods for\ngenerating user embeddings and combined them by concatenating their output\nvectors into a unified representation. This ensemble strategy further improved\ngeneralization across diverse downstream tasks and helped our team,\nai_lab_recsys, achieve second place in the RecSys Challenge 2025.", "published": "2025-08-11 08:28:01", "link": "http://arxiv.org/abs/2508.07748v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "MLego: Interactive and Scalable Topic Exploration Through Model Reuse", "abstract": "With massive texts on social media, users and analysts often rely on topic\nmodeling techniques to quickly extract key themes and gain insights.\nTraditional topic modeling techniques, such as Latent Dirichlet Allocation\n(LDA), provide valuable insights but are computationally expensive, making them\nimpractical for real-time data analysis. Although recent advances in\ndistributed training and fast sampling methods have improved efficiency,\nreal-time topic exploration remains a significant challenge. In this paper, we\npresent MLego, an interactive query framework designed to support real-time\ntopic modeling analysis by leveraging model materialization and reuse. Instead\nof retraining models from scratch, MLego efficiently merges materialized topic\nmodels to construct approximate results at interactive speeds. To further\nenhance efficiency, we introduce a hierarchical plan search strategy for single\nqueries and an optimized query reordering technique for batch queries. We\nintegrate MLego into a visual analytics prototype system, enabling users to\nexplore large-scale textual datasets through interactive queries. Extensive\nexperiments demonstrate that MLego significantly reduces computation costs\nwhile maintaining high-quality topic modeling results. MLego enhances existing\nvisual analytics approaches, which primarily focus on user-driven topic\nmodeling, by enabling real-time, query-driven exploration. This complements\ntraditional methods and bridges the gap between scalable topic modeling and\ninteractive data analysis.", "published": "2025-08-11 06:06:26", "link": "http://arxiv.org/abs/2508.07654v1", "categories": ["cs.DB", "cs.IR"], "primary_category": "cs.DB"}
{"title": "UMRE: A Unified Monotonic Transformation for Ranking Ensemble in Recommender Systems", "abstract": "Industrial recommender systems commonly rely on ensemble sorting (ES) to\ncombine predictions from multiple behavioral objectives. Traditionally, this\nprocess depends on manually designed nonlinear transformations (e.g.,\npolynomial or exponential functions) and hand-tuned fusion weights to balance\ncompeting goals -- an approach that is labor-intensive and frequently\nsuboptimal in achieving Pareto efficiency. In this paper, we propose a novel\nUnified Monotonic Ranking Ensemble (UMRE) framework to address the limitations\nof traditional methods in ensemble sorting. UMRE replaces handcrafted\ntransformations with Unconstrained Monotonic Neural Networks (UMNN), which\nlearn expressive, strictly monotonic functions through the integration of\npositive neural integrals. Subsequently, a lightweight ranking model is\nemployed to fuse the prediction scores, assigning personalized weights to each\nprediction objective. To balance competing goals, we further introduce a Pareto\noptimality strategy that adaptively coordinates task weights during training.\nUMRE eliminates manual tuning, maintains ranking consistency, and achieves\nfine-grained personalization. Experimental results on two public recommendation\ndatasets (Kuairand and Tenrec) and online A/B tests demonstrate impressive\nperformance and generalization capabilities.", "published": "2025-08-11 04:38:57", "link": "http://arxiv.org/abs/2508.07613v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Towards Comprehensible Recommendation with Large Language Model Fine-tuning", "abstract": "Recommender systems have become increasingly ubiquitous in daily life. While\ntraditional recommendation approaches primarily rely on ID-based\nrepresentations or item-side content features, they often fall short in\ncapturing the underlying semantics aligned with user preferences (e.g.,\nrecommendation reasons for items), leading to a semantic-collaborative gap.\nRecently emerged LLM-based feature extraction approaches also face a key\nchallenge: how to ensure that LLMs possess recommendation-aligned reasoning\ncapabilities and can generate accurate, personalized reasons to mitigate the\nsemantic-collaborative gap. To address these issues, we propose a novel Content\nUnderstanding from a Collaborative Perspective framework (CURec), which\ngenerates collaborative-aligned content features for more comprehensive\nrecommendations. \\method first aligns the LLM with recommendation objectives\nthrough pretraining, equipping it with instruction-following and\nchain-of-thought reasoning capabilities. Next, we design a reward model\ninspired by traditional recommendation architectures to evaluate the quality of\nthe recommendation reasons generated by the LLM. Finally, using the reward\nsignals, CURec fine-tunes the LLM through RL and corrects the generated reasons\nto ensure their accuracy. The corrected reasons are then integrated into a\ndownstream recommender model to enhance comprehensibility and recommendation\nperformance. Extensive experiments on public benchmarks demonstrate the\nsuperiority of CURec over existing methods.", "published": "2025-08-11 03:55:31", "link": "http://arxiv.org/abs/2508.07595v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Orthogonal Low Rank Embedding Stabilization", "abstract": "The instability of embedding spaces across model retraining cycles presents\nsignificant challenges to downstream applications using user or item embeddings\nderived from recommendation systems as input features. This paper introduces a\nnovel orthogonal low-rank transformation methodology designed to stabilize the\nuser/item embedding space, ensuring consistent embedding dimensions across\nretraining sessions. Our approach leverages a combination of efficient low-rank\nsingular value decomposition and orthogonal Procrustes transformation to map\nembeddings into a standardized space. This transformation is computationally\nefficient, lossless, and lightweight, preserving the dot product and inference\nquality while reducing operational burdens. Unlike existing methods that modify\ntraining objectives or embedding structures, our approach maintains the\nintegrity of the primary model application and can be seamlessly integrated\nwith other stabilization techniques.", "published": "2025-08-11 03:15:51", "link": "http://arxiv.org/abs/2508.07574v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Composable Quantum Fault-Tolerance", "abstract": "Proving threshold theorems for fault-tolerant quantum computation is a\nburdensome endeavor with many moving parts that come together in relatively\nformulaic but lengthy ways. It is difficult and rare to combine elements from\nmultiple papers into a single formal threshold proof, due to the use of\ndifferent measures of fault-tolerance. In this work, we introduce composable\nfault-tolerance, a framework that decouples the probabilistic analysis of the\nnoise distribution from the combinatorial analysis of circuit correctness, and\nenables threshold proofs to compose independently analyzed gadgets easily and\nrigorously. Within this framework, we provide a library of standard and\ncommonly used gadgets such as memory and logic implemented by constant-depth\ncircuits for quantum low-density parity check codes and distillation. As sample\napplications, we explicitly write down a threshold proof for computation with\nsurface code and re-derive the constant space-overhead fault-tolerant scheme of\nGottesman using gadgets from this library. We expect that future\nfault-tolerance proofs may focus on the analysis of novel techniques while\nleaving the standard components to the composable fault-tolerance framework,\nwith the formal proof following the intuitive ``napkin math'' exactly.", "published": "2025-08-11 17:58:14", "link": "http://arxiv.org/abs/2508.08246v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Industrial Viewpoints on RAN Technologies for 6G", "abstract": "6G standardization is to start imminently, with commercial deployments\nexpected before 2030. Its technical components and performance requirements are\nthe focus of this article. Our emphasis is on the 6G radio access, especially\nMIMO, AI, waveforms, coding, signal constellations and integration with\nnon-terrestrial networks. Whilst standardization has not yet formally started,\nthe scope of the 6G study items has been defined. Our predictions in this paper\nare speculative as there are no results of the study yet, but our views are\nguided by implementation and deployment aspects. We expect that the views here\nwill guide researchers and industry practitioners.", "published": "2025-08-11 17:44:24", "link": "http://arxiv.org/abs/2508.08225v1", "categories": ["cs.NI", "cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.NI"}
{"title": "Adaptive Learning for IRS-Assisted Wireless Networks: Securing Opportunistic Communications Against Byzantine Eavesdroppers", "abstract": "We propose a joint learning framework for Byzantine-resilient spectrum\nsensing and secure intelligent reflecting surface (IRS)--assisted opportunistic\naccess under channel state information (CSI) uncertainty. The sensing stage\nperforms logit-domain Bayesian updates with trimmed aggregation and\nattention-weighted consensus, and the base station (BS) fuses network beliefs\nwith a conservative minimum rule, preserving detection accuracy under a bounded\nnumber of Byzantine users. Conditioned on the sensing outcome, we pose downlink\ndesign as sum mean-squared error (MSE) minimization under transmit-power and\nsignal-leakage constraints and jointly optimize the BS precoder, IRS phase\nshifts, and user equalizers. With partial (or known) CSI, we develop an\naugmented-Lagrangian alternating algorithm with projected updates and provide\nprovable sublinear convergence, with accelerated rates under mild local\ncurvature. With unknown CSI, we perform constrained Bayesian optimization (BO)\nin a geometry-aware low-dimensional latent space using Gaussian process (GP)\nsurrogates; we prove regret bounds for a constrained upper confidence bound\n(UCB) variant of the BO module, and demonstrate strong empirical performance of\nthe implemented procedure. Simulations across diverse network conditions show\nhigher detection probability at fixed false-alarm rate under adversarial\nattacks, large reductions in sum MSE for honest users, strong suppression of\neavesdropper signal power, and fast convergence. The framework offers a\npractical path to secure opportunistic communication that adapts to CSI\navailability while coherently coordinating sensing and transmission through\njoint learning.", "published": "2025-08-11 17:28:25", "link": "http://arxiv.org/abs/2508.08206v1", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT", "math.OC"], "primary_category": "eess.SP"}
{"title": "Random Modulation: Achieving Asymptotic Replica Optimality over Arbitrary Norm-Bounded and Spectrally Convergent Channel Matrices", "abstract": "This paper introduces a random modulation technique that is decoupled from\nthe channel matrix, allowing it to be applied to arbitrary norm-bounded and\nspectrally convergent channel matrices. The proposed random modulation\nconstructs an equivalent dense and random channel matrix, ensuring that the\nsignals undergo sufficient statistical channel fading. It also guarantees the\nasymptotic replica maximum a posteriori (MAP) bit-error rate (BER) optimality\nof approximate message passing (AMP)-type detectors for linear systems with\narbitrary norm-bounded and spectrally convergent channel matrices when their\nstate evolution has a unique fixed point. Then, a low-complexity cross-domain\nmemory approximate message passing (CD-MAMP) detector is proposed for random\nmodulation, leveraging the sparsity of the time-domain channel and the\nrandomness of the random transform-domain channel. Furthermore, the optimal\npower allocation schemes are derived to minimize the replica MAP BER and\nmaximize the replica constrained capacity of random-modulated linear systems,\nassuming the availability of channel state information (CSI) at the\ntransceiver. Numerical results show that the proposed random modulation can\nachieve BER and block-error rate (BLER) performance gains of up to 2 - 3 dB\ncompared to existing OFDM/OTFS/AFDM with 5G-NR LDPC codes, under both average\nand optimized power allocation.", "published": "2025-08-11 15:39:01", "link": "http://arxiv.org/abs/2508.08099v1", "categories": ["cs.IT", "math.IT", "math.ST", "stat.TH"], "primary_category": "cs.IT"}
{"title": "Adaptive Source-Channel Coding for Semantic Communications", "abstract": "Semantic communications (SemComs) have emerged as a promising paradigm for\njoint data and task-oriented transmissions, combining the demands for both the\nbit-accurate delivery and end-to-end (E2E) distortion minimization. However,\ncurrent joint source-channel coding (JSCC) in SemComs is not compatible with\nthe existing communication systems and cannot adapt to the variations of the\nsources or the channels, while separate source-channel coding (SSCC) is\nsuboptimal in the finite blocklength regime. To address these issues, we\npropose an adaptive source-channel coding (ASCC) scheme for SemComs over\nparallel Gaussian channels, where the deep neural network (DNN)-based semantic\nsource coding and conventional digital channel coding are separately deployed\nand adaptively designed. To enable efficient adaptation between the source and\nchannel coding, we first approximate the E2E data and semantic distortions as\nfunctions of source coding rate and bit error ratio (BER) via logistic\nregression, where BER is further modeled as functions of signal-to-noise ratio\n(SNR) and channel coding rate. Then, we formulate the weighted sum E2E\ndistortion minimization problem for joint source-channel coding rate and power\nallocation over parallel channels, which is solved by the successive convex\napproximation. Finally, simulation results demonstrate that the proposed ASCC\nscheme outperforms typical deep JSCC and SSCC schemes for both the single- and\nparallel-channel scenarios while maintaining full compatibility with practical\ndigital systems.", "published": "2025-08-11 13:09:54", "link": "http://arxiv.org/abs/2508.07958v1", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions", "abstract": "Progressive neurodegenerative diseases, including Alzheimer's disease (AD),\nmultiple sclerosis (MS), Parkinson's disease (PD), and amyotrophic lateral\nsclerosis (ALS), exhibit complex, nonlinear trajectories that challenge\ndeterministic modeling. Traditional time-domain analyses of multiomic and\nneuroimaging data often fail to capture hidden oscillatory patterns, limiting\npredictive accuracy. We propose a theoretical mathematical framework that\ntransforms time-series data into frequency or s-domain using Fourier and\nLaplace transforms, models neuronal dynamics via Hamiltonian formulations, and\nemploys quantum-classical hybrid computing with variational quantum\neigensolvers (VQE) for enhanced pattern detection. This theoretical construct\nserves as a foundation for future empirical works in quantum-enhanced analysis\nof neurodegenerative diseases. We extend this to quaternionic representations\nwith three imaginary axes ($i, j, k$) to model multistate Hamiltonians in\nmultifaceted disorders, drawing from quantum neuromorphic computing to capture\nentangled neural dynamics \\citep{Pehle2020, Emani2019}. This approach leverages\nquantum advantages in handling high-dimensional amplitude-phase data, enabling\noutlier detection and frequency signature analysis. Potential clinical\napplications include identifying high-risk patients with rapid progression or\ntherapy resistance using s-domain biomarkers, supported by quantum machine\nlearning (QML) precedents achieving up to 99.89% accuracy in Alzheimer's\nclassification \\citep{Belay2024, Bhowmik2025}. This framework aims to lay the\ngroundwork for redefining precision medicine for neurodegenerative diseases\nthrough future validations.", "published": "2025-08-11 13:03:58", "link": "http://arxiv.org/abs/2508.07948v1", "categories": ["cs.ET", "cs.IT", "cs.LG", "math.IT", "quant-ph", "81P68, 92C20, 42A38, 15A18, 81R05", "F.0; F.1.1; F.2.1; G.1.0; G.1.3; I.2; I.2.1; I.2.6; I.5; J.3"], "primary_category": "cs.ET"}
{"title": "Age of Information Minimization in Goal-Oriented Communication with Processing and Cost of Actuation Error Constraints", "abstract": "We study a goal-oriented communication system in which a source monitors an\nenvironment that evolves as a discrete-time, two-state Markov chain. At each\ntime slot, a controller decides whether to sample the environment and if so\nwhether to transmit a raw or processed sample, to the controller. Processing\nimproves transmission reliability over an unreliable wireless channel, but\nincurs an additional cost. The objective is to minimize the long-term average\nage of information (AoI), subject to constraints on the costs incurred at the\nsource and the cost of actuation error (CAE), a semantic metric that assigns\ndifferent penalties to different actuation errors. Although reducing AoI can\npotentially help reduce CAE, optimizing AoI alone is insufficient, as it\noverlooks the evolution of the underlying process. For instance, faster source\ndynamics lead to higher CAE for the same average AoI, and different AoI\ntrajectories can result in markedly different CAE under identical average AoI.\nTo address this, we propose a stationary randomized policy that achieves an\naverage AoI within a bounded multiplicative factor of the optimal among all\nfeasible policies. Extensive numerical experiments are conducted to\ncharacterize system behavior under a range of parameters. These results offer\ninsights into the feasibility of the optimization problem, the structure of\nnear-optimal actions, and the fundamental trade-offs between AoI, CAE, and the\ncosts involved.", "published": "2025-08-11 11:31:21", "link": "http://arxiv.org/abs/2508.07865v1", "categories": ["cs.IT", "math.IT", "math.OC"], "primary_category": "cs.IT"}
{"title": "QoS-Aware Integrated Sensing, Communication, and Control with Movable Antenna", "abstract": "Integrated sensing, communication, and control (ISCC) has emerged as a key\nenabler for low-altitude wireless networks with enhanced adaptability through\nresource allocation co-design and intelligent environment awareness. However,\ndynamic interference and channel attenuation constrain the potential of the\nISCC system. To address this challenge, we propose a novel movable\nantenna-empowered ISCC system. An achievable data rate maximization problem is\nformulated while guaranteeing the sensing and control quality-of-service (QoS)\nby optimizing the positions of the antennas and the beamforming strategy for\ncommunication, sensing, and control co-design. An efficient alternating\noptimization (AO)-based algorithm is proposed to solve the highly coupled\nnon-convex problem. Numerical results demonstrate that the proposed AO-based\nalgorithm achieves substantial gains in the achievable data rate and the\ncontrol QoS compared with benchmark schemes.", "published": "2025-08-11 09:36:23", "link": "http://arxiv.org/abs/2508.07799v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations", "abstract": "In this work, we address the problem of training Reinforcement Learning (RL)\nagents over communication networks. The RL paradigm requires the agent to\ninstantaneously perceive the state evolution to infer the effects of its\nactions on the environment. This is impossible if the agent receives state\nupdates over lossy or delayed wireless systems and thus operates with partial\nand intermittent information. In recent years, numerous frameworks have been\nproposed to manage RL with imperfect feedback; however, they often offer\nspecific solutions with a substantial computational burden. To address these\nlimits, we propose a novel architecture, named Homomorphic Robust Remote\nReinforcement Learning (HR3L), that enables the training of remote RL agents\nexchanging observations across a non-ideal wireless channel. HR3L considers two\nunits: the transmitter, which encodes meaningful representations of the\nenvironment, and the receiver, which decodes these messages and performs\nactions to maximize a reward signal. Importantly, HR3L does not require the\nexchange of gradient information across the wireless channel, allowing for\nquicker training and a lower communication overhead than state-of-the-art\nsolutions. Experimental results demonstrate that HR3L significantly outperforms\nbaseline methods in terms of sample efficiency and adapts to different\ncommunication scenarios, including packet losses, delayed transmissions, and\ncapacity limitations.", "published": "2025-08-11 07:50:25", "link": "http://arxiv.org/abs/2508.07722v1", "categories": ["cs.LG", "cs.IT", "cs.MA", "math.IT"], "primary_category": "cs.LG"}
{"title": "Importance-Aware Semantic Communication in MIMO-OFDM Systems Using Vision Transformer", "abstract": "This paper presents a novel importance-aware quantization, subcarrier\nmapping, and power allocation (IA-QSMPA) framework for semantic communication\nin multiple-input multiple-output orthogonal frequency division multiplexing\n(MIMO-OFDM) systems, empowered by a pretrained Vision Transformer (ViT). The\nproposed framework exploits attention-based importance extracted from a\npretrained ViT to jointly optimize quantization levels, subcarrier mapping, and\npower allocation. Specifically, IA-QSMPA maps semantically important features\nto high-quality subchannels and allocates resources in accordance with their\ncontribution to task performance and communication latency. To efficiently\nsolve the resulting nonconvex optimization problem, a block coordinate descent\nalgorithm is employed. The framework is further extended to operate under\nfinite blocklength transmission, where communication errors may occur. In this\nsetting, a segment-wise linear approximation of the channel dispersion penalty\nis introduced to enable efficient joint optimization under practical\nconstraints. Simulation results on a multi-view image classification task using\nthe MVP-N dataset demonstrate that IA-QSMPA significantly outperforms\nconventional methods in both ideal and finite blocklength transmission\nscenarios, achieving superior task performance and communication efficiency.", "published": "2025-08-11 07:17:55", "link": "http://arxiv.org/abs/2508.07696v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Extended AB Algorithms for Bistatic Integrated Sensing and Communications Systems", "abstract": "Integrated sensing and communication (ISAC) is pivotal for next-generation\nwireless networks, rendering the computation of rate-distortion trade-off in\nISAC systems critically important. In this paper, we propose the extended\nArimoto-Blahut (AB) algorithms to calculate the rate-distortion trade-off in\nbistatic ISAC systems, which overcome the limitation of existing AB algorithms\nin handling non-convex constraints. Specifically, we introduce auxiliary\nvariables to transform non-convex distortion constraints into linear\nconstraints, prove that the reformulated linearly-constrained optimization\nproblem maintains the same optimal solution as the original problem, and\ndevelop extended AB algorithms for both squared error and logarithmic loss\ndistortion metrics based on the framework of AB algorithm. Numerical results\nvalidate the effectiveness of the proposed algorithm.", "published": "2025-08-11 02:58:14", "link": "http://arxiv.org/abs/2508.07567v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Multimodal Remote Inference", "abstract": "We consider a remote inference system with multiple modalities, where a\nmultimodal machine learning (ML) model performs real-time inference using\nfeatures collected from remote sensors. As sensor observations may change\ndynamically over time, fresh features are critical for inference tasks.\nHowever, timely delivering features from all modalities is often infeasible due\nto limited network resources. To this end, we study a two-modality scheduling\nproblem to minimize the ML model's inference error, which is expressed as a\npenalty function of AoI for both modalities. We develop an index-based\nthreshold policy and prove its optimality. Specifically, the scheduler switches\nmodalities when the current modality's index function exceeds a threshold. We\nshow that the two modalities share the same threshold, and both the index\nfunctions and the threshold can be computed efficiently. The optimality of our\npolicy holds for (i) general AoI functions that are \\emph{non-monotonic} and\n\\emph{non-additive} and (ii) \\emph{heterogeneous} transmission times. Numerical\nresults show that our policy reduces inference error by up to 55% compared to\nround-robin and uniform random policies, which are oblivious to the AoI-based\ninference error function. Our results shed light on how to improve remote\ninference accuracy by optimizing task-oriented AoI functions.", "published": "2025-08-11 02:30:44", "link": "http://arxiv.org/abs/2508.07555v1", "categories": ["cs.LG", "cs.IT", "cs.NI", "math.IT"], "primary_category": "cs.LG"}
{"title": "Graded Quantum Codes: From Weighted Algebraic Geometry to Homological Chain Complexes", "abstract": "We introduce graded quantum codes, unifying two classes of quantum\nerror-correcting codes. The first, quantum weighted algebraic geometry (AG)\ncodes, derives from rational points on hypersurfaces in weighted projective\nspaces over finite fields. This extends classical AG codes by adding weighted\ndegrees and singularities, enabling self-orthogonal codes via the CSS method\nwith improved distances using algebraic structures and invariants like weighted\nheights.The second class arises from chain complexes of graded vector spaces,\ngeneralizing homological quantum codes to include torsion and multiple\ngradings. This produces low-density parity-check codes with parameters based on\nhomology ranks, including examples from knot invariants and quantum rotors.\n  A shared grading leads to a refined Singleton bound: $d \\leq \\frac{n - k +\n2}{2} - \\frac{\\epsilon}{2}$, where $\\epsilon > 0$ reflects entropy adjustments\nfrom geometric singularities and defects. The bound holds partially for simple\norbifolds and is supported by examples over small fields.\n  Applications include post-quantum cryptography, fault-tolerant quantum\ncomputing, and optimization via graded neural networks, linking algebraic\ngeometry, homological algebra, and quantum information.", "published": "2025-08-11 01:44:51", "link": "http://arxiv.org/abs/2508.07542v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion", "abstract": "Personalised music-based interventions offer a powerful means of supporting\nmotor rehabilitation by dynamically tailoring auditory stimuli to provide\nexternal timekeeping cues, modulate affective states, and stabilise gait\npatterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for\nadapting these interventions across individuals. However, inter-subject\nvariability in EEG signals, further compounded by movement-induced artefacts\nand motor planning differences, hinders the generalisability of BCIs and\nresults in lengthy calibration processes. We propose Individual Tangent Space\nAlignment (ITSA), a novel pre-alignment strategy incorporating subject-specific\nrecentering, distribution matching, and supervised rotational alignment to\nenhance cross-subject generalisation. Our hybrid architecture fuses Regularised\nCommon Spatial Patterns (RCSP) with Riemannian geometry in parallel and\nsequential configurations, improving class separability while maintaining the\ngeometric structure of covariance matrices for robust statistical computation.\nUsing leave-one-subject-out cross-validation, `ITSA' demonstrates significant\nperformance improvements across subjects and conditions. The parallel fusion\napproach shows the greatest enhancement over its sequential counterpart, with\nrobust performance maintained across varying data conditions and electrode\nconfigurations. The code will be made publicly available at the time of\npublication.", "published": "2025-08-11 17:37:17", "link": "http://arxiv.org/abs/2508.08216v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets", "abstract": "Developing accurate and generalizable epileptic seizure prediction models\nfrom electroencephalography (EEG) data across multiple clinical sites is\nhindered by patient privacy regulations and significant data heterogeneity\n(non-IID characteristics). Federated Learning (FL) offers a privacy-preserving\nframework for collaborative training, but standard aggregation methods like\nFederated Averaging (FedAvg) can be biased by dominant datasets in\nheterogeneous settings. This paper investigates FL for seizure prediction using\na single EEG channel across four diverse public datasets (Siena, CHB-MIT,\nHelsinki, NCH), representing distinct patient populations (adult, pediatric,\nneonate) and recording conditions. We implement privacy-preserving global\nnormalization and propose a Random Subset Aggregation strategy, where each\nclient trains on a fixed-size random subset of its data per round, ensuring\nequal contribution during aggregation. Our results show that locally trained\nmodels fail to generalize across sites, and standard weighted FedAvg yields\nhighly skewed performance (e.g., 89.0% accuracy on CHB-MIT but only 50.8% on\nHelsinki and 50.6% on NCH). In contrast, Random Subset Aggregation\nsignificantly improves performance on under-represented clients (accuracy\nincreases to 81.7% on Helsinki and 68.7% on NCH) and achieves a superior\nmacro-average accuracy of 77.1% and pooled accuracy of 80.0% across all sites,\ndemonstrating a more robust and fair global model. This work highlights the\npotential of balanced FL approaches for building effective and generalizable\nseizure prediction systems in realistic, heterogeneous multi-hospital\nenvironments while respecting data privacy.", "published": "2025-08-11 16:36:31", "link": "http://arxiv.org/abs/2508.08159v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks", "abstract": "Deep neural networks (DNNs) are being utilized in various aspects of our\ndaily lives, including high-stakes decision-making applications that impact\nindividuals. However, these systems reflect and amplify bias from the data used\nduring training and testing, potentially resulting in biased behavior and\ninaccurate decisions. For instance, having different misclassification rates\nbetween white and black sub-populations. However, effectively and efficiently\nidentifying and correcting biased behavior in DNNs is a challenge. This paper\nintroduces FairFLRep, an automated fairness-aware fault localization and repair\ntechnique that identifies and corrects potentially bias-inducing neurons in DNN\nclassifiers. FairFLRep focuses on adjusting neuron weights associated with\nsensitive attributes, such as race or gender, that contribute to unfair\ndecisions. By analyzing the input-output relationships within the network,\nFairFLRep corrects neurons responsible for disparities in predictive quality\nparity. We evaluate FairFLRep on four image classification datasets using two\nDNN classifiers, and four tabular datasets with a DNN model. The results show\nthat FairFLRep consistently outperforms existing methods in improving fairness\nwhile preserving accuracy. An ablation study confirms the importance of\nconsidering fairness during both fault localization and repair stages. Our\nfindings also show that FairFLRep is more efficient than the baseline\napproaches in repairing the network.", "published": "2025-08-11 16:28:42", "link": "http://arxiv.org/abs/2508.08151v1", "categories": ["cs.LG", "cs.SE"], "primary_category": "cs.LG"}
{"title": "An effective potential for generative modelling with active matter", "abstract": "Score-based diffusion models generate samples from a complex underlying data\ndistribution by time-reversal of a diffusion process and represent the\nstate-of-the-art in many generative AI applications such as artificial image\nsynthesis. Here, I show how a generative diffusion model can be implemented\nbased on an underlying active particle process with finite correlation time. In\ncontrast to previous approaches that use a score function acting on the\nvelocity coordinate of the active particle, time reversal is here achieved by\nimposing an effective time-dependent potential on the position coordinate only.\nThe effective potential is valid to first order in the persistence time and\nleads to a force field that is fully determined by the standard score function\nand its derivatives up to 2nd order. Numerical experiments for artificial data\ndistributions confirm the validity of the effective potential.", "published": "2025-08-11 16:21:32", "link": "http://arxiv.org/abs/2508.08146v1", "categories": ["cond-mat.stat-mech", "cond-mat.soft", "cs.LG"], "primary_category": "cond-mat.stat-mech"}
{"title": "OFAL: An Oracle-Free Active Learning Framework", "abstract": "In the active learning paradigm, using an oracle to label data has always\nbeen a complex and expensive task, and with the emersion of large unlabeled\ndata pools, it would be highly beneficial If we could achieve better results\nwithout relying on an oracle. This research introduces OFAL, an oracle-free\nactive learning scheme that utilizes neural network uncertainty. OFAL uses the\nmodel's own uncertainty to transform highly confident unlabeled samples into\ninformative uncertain samples. First, we start with separating and quantifying\ndifferent parts of uncertainty and introduce Monte Carlo Dropouts as an\napproximation of the Bayesian Neural Network model. Secondly, by adding a\nvariational autoencoder, we go on to generate new uncertain samples by stepping\ntoward the uncertain part of latent space starting from a confidence seed\nsample. By generating these new informative samples, we can perform active\nlearning and enhance the model's accuracy. Lastly, we try to compare and\nintegrate our method with other widely used active learning sampling methods.", "published": "2025-08-11 16:04:29", "link": "http://arxiv.org/abs/2508.08126v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection", "abstract": "Large-scale models pre-trained on Electroencephalography (EEG) have shown\npromise in clinical applications such as neurological disorder detection.\nHowever, the practical deployment of EEG-based large-scale models faces\ncritical challenges such as limited labeled EEG data and suboptimal performance\nin clinical scenarios. To address these issues, we propose NeuroDx-LM, a novel\nlarge-scale model specifically designed for detecting EEG-based neurological\ndisorders. Our key contributions include (i) a Selective Temporal-Frequency\nEmbedding mechanism that adaptively captures complex temporal and spectral\npatterns in EEG signals; and (ii) a Progressive Feature-Aware Training strategy\nthat refines feature representation in a two-stage process. In the first stage,\nour model learns the fundamental discriminative features of EEG activities; in\nthe second stage, the model further extracts more specialized fine-grained\nfeatures for accurate diagnostic performance. We evaluated NeuroDx-LM on the\nCHB-MIT and Schizophrenia datasets, achieving state-of-the-art performance in\nEEG-based seizure and schizophrenia detection, respectively. These results\ndemonstrate the great potential of EEG-based large-scale models to advance\nclinical applicability. Our code is available at\nhttps://github.com/LetItBe12345/NeuroDx-LM.", "published": "2025-08-11 16:02:25", "link": "http://arxiv.org/abs/2508.08124v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation", "abstract": "Reliable digital twins of lithium-ion batteries must achieve high physical\nfidelity with sub-millisecond speed. In this work, we benchmark three\noperator-learning surrogates for the Single Particle Model (SPM): Deep Operator\nNetworks (DeepONets), Fourier Neural Operators (FNOs) and a newly proposed\nparameter-embedded Fourier Neural Operator (PE-FNO), which conditions each\nspectral layer on particle radius and solid-phase diffusivity. Models are\ntrained on simulated trajectories spanning four current families (constant,\ntriangular, pulse-train, and Gaussian-random-field) and a full range of\nState-of-Charge (SOC) (0 % to 100 %). DeepONet accurately replicates\nconstant-current behaviour but struggles with more dynamic loads. The basic FNO\nmaintains mesh invariance and keeps concentration errors below 1 %, with\nvoltage mean-absolute errors under 1.7 mV across all load types. Introducing\nparameter embedding marginally increases error, but enables generalisation to\nvarying radii and diffusivities. PE-FNO executes approximately 200 times faster\nthan a 16-thread SPM solver. Consequently, PE-FNO's capabilities in inverse\ntasks are explored in a parameter estimation task with Bayesian optimisation,\nrecovering anode and cathode diffusivities with 1.14 % and 8.4 % mean absolute\npercentage error, respectively, and 0.5918 percentage points higher error in\ncomparison with classical methods. These results pave the way for neural\noperators to meet the accuracy, speed and parametric flexibility demands of\nreal-time battery management, design-of-experiments and large-scale inference.\nPE-FNO outperforms conventional neural surrogates, offering a practical path\ntowards high-speed and high-fidelity electrochemical digital twins.", "published": "2025-08-11 15:31:23", "link": "http://arxiv.org/abs/2508.08087v1", "categories": ["cs.LG", "physics.chem-ph"], "primary_category": "cs.LG"}
{"title": "Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles", "abstract": "Symbolic Regression (SR) is a well-established framework for generating\ninterpretable or white-box predictive models. Although SR has been successfully\napplied to create interpretable estimates of the average of the outcome, it is\ncurrently not well understood how it can be used to estimate the relationship\nbetween variables at other points in the distribution of the target variable.\nSuch estimates of e.g. the median or an extreme value provide a fuller picture\nof how predictive variables affect the outcome and are necessary in\nhigh-stakes, safety-critical application domains. This study introduces\nSymbolic Quantile Regression (SQR), an approach to predict conditional\nquantiles with SR. In an extensive evaluation, we find that SQR outperforms\ntransparent models and performs comparably to a strong black-box baseline\nwithout compromising transparency. We also show how SQR can be used to explain\ndifferences in the target distribution by comparing models that predict extreme\nand central outcomes in an airline fuel usage case study. We conclude that SQR\nis suitable for predicting conditional quantiles and understanding interesting\nfeature influences at varying quantiles.", "published": "2025-08-11 15:27:40", "link": "http://arxiv.org/abs/2508.08080v1", "categories": ["cs.LG", "cs.NE", "stat.AP"], "primary_category": "cs.LG"}
{"title": "ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring", "abstract": "In electronic design automation, logic optimization operators play a crucial\nrole in minimizing the gate count of logic circuits. However, their computation\ndemands are high. Operators such as refactor conventionally form iterative cuts\nfor each node, striving for a more compact representation - a task which often\nfails 98% on average. Prior research has sought to mitigate computational cost\nthrough parallelization. In contrast, our approach leverages a classifier to\nprune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis\noperations. Experiments on the refactor operator using the EPFL benchmark suite\nand 10 large industrial designs demonstrate that this technique can speedup\nlogic optimization by 3.9x on average compared with the state-of-the-art ABC\nimplementation.", "published": "2025-08-11 15:18:07", "link": "http://arxiv.org/abs/2508.08073v1", "categories": ["cs.LG", "cs.AR", "cs.ET"], "primary_category": "cs.LG"}
{"title": "Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles", "abstract": "Accurate power consumption prediction is crucial for improving efficiency and\nreducing environmental impact, yet traditional methods relying on specialized\ninstruments or rigid physical models are impractical for large-scale,\nreal-world deployment. This study introduces a scalable data-driven method\nusing powertrain dynamic feature sets and both traditional machine learning and\ndeep neural networks to estimate instantaneous and cumulative power consumption\nin internal combustion engine (ICE), electric vehicle (EV), and hybrid electric\nvehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with\nmean absolute error and root mean squared error on the order of $10^{-3}$, and\ncumulative errors under 3%. Transformer and long short-term memory models\nperformed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%,\nrespectively. Results confirm the approach's effectiveness across vehicles and\nmodels. Uncertainty analysis revealed greater variability in EV and HEV\ndatasets than ICE, due to complex power management, emphasizing the need for\nrobust models for advanced powertrains.", "published": "2025-08-11 14:37:40", "link": "http://arxiv.org/abs/2508.08034v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks", "abstract": "The introduction of 5G and the Open Radio Access Network (O-RAN) architecture\nhas enabled more flexible and intelligent network deployments. However, the\nincreased complexity and openness of these architectures also introduce novel\nsecurity challenges, such as data manipulation attacks on the semi-standardised\nShared Data Layer (SDL) within the O-RAN platform through malicious xApps. In\nparticular, malicious xApps can exploit this vulnerability by introducing\nsubtle Unicode-wise alterations (hypoglyphs) into the data that are being used\nby traditional machine learning (ML)-based anomaly detection methods. These\nUnicode-wise manipulations can potentially bypass detection and cause failures\nin anomaly detection systems based on traditional ML, such as AutoEncoders,\nwhich are unable to process hypoglyphed data without crashing. We investigate\nthe use of Large Language Models (LLMs) for anomaly detection within the O-RAN\narchitecture to address this challenge. We demonstrate that LLM-based xApps\nmaintain robust operational performance and are capable of processing\nmanipulated messages without crashing. While initial detection accuracy\nrequires further improvements, our results highlight the robustness of LLMs to\nadversarial attacks such as hypoglyphs in input data. There is potential to use\ntheir adaptability through prompt engineering to further improve the accuracy,\nalthough this requires further research. Additionally, we show that LLMs\nachieve low detection latency (under 0.07 seconds), making them suitable for\nNear-Real-Time (Near-RT) RIC deployments.", "published": "2025-08-11 14:32:43", "link": "http://arxiv.org/abs/2508.08029v1", "categories": ["cs.CR", "cs.ET", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Optimizing Federated Learning for Scalable Power-demand Forecasting in Microgrids", "abstract": "Real-time monitoring of power consumption in cities and micro-grids through\nthe Internet of Things (IoT) can help forecast future demand and optimize grid\noperations. But moving all consumer-level usage data to the cloud for\npredictions and analysis at fine time scales can expose activity patterns.\nFederated Learning~(FL) is a privacy-sensitive collaborative DNN training\napproach that retains data on edge devices, trains the models on private data\nlocally, and aggregates the local models in the cloud. But key challenges\nexist: (i) clients can have non-independently identically distributed~(non-IID)\ndata, and (ii) the learning should be computationally cheap while scaling to\n1000s of (unseen) clients. In this paper, we develop and evaluate several\noptimizations to FL training across edge and cloud for time-series demand\nforecasting in micro-grids and city-scale utilities using DNNs to achieve a\nhigh prediction accuracy while minimizing the training cost. We showcase the\nbenefit of using exponentially weighted loss while training and show that it\nfurther improves the prediction of the final model. Finally, we evaluate these\nstrategies by validating over 1000s of clients for three states in the US from\nthe OpenEIA corpus, and performing FL both in a pseudo-distributed setting and\na Pi edge cluster. The results highlight the benefits of the proposed methods\nover baselines like ARIMA and DNNs trained for individual consumers, which are\nnot scalable.", "published": "2025-08-11 14:27:26", "link": "http://arxiv.org/abs/2508.08022v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks", "abstract": "Federated Learning (FL) is an emerging learning framework that enables edge\ndevices to collaboratively train ML models without sharing their local data. FL\nfaces, however, a significant challenge due to the high amount of information\nthat must be exchanged between the devices and the aggregator in the training\nphase, which can exceed the limited capacity of wireless systems. In this\npaper, two communication-efficient FL methods are considered where\ncommunication overhead is reduced by communicating scalar values instead of\nlong vectors and by allowing high number of users to send information\nsimultaneously. The first approach employs a zero-order optimization technique\nwith two-point gradient estimator, while the second involves a first-order\ngradient computation strategy. The novelty lies in leveraging channel\ninformation in the learning algorithms, eliminating hence the need for\nadditional resources to acquire channel state information (CSI) and to remove\nits impact, as well as in considering asynchronous devices. We provide a\nrigorous analytical framework for the two methods, deriving convergence\nguarantees and establishing appropriate performance bounds.", "published": "2025-08-11 14:16:23", "link": "http://arxiv.org/abs/2508.08013v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation", "abstract": "Traffic state estimation (TSE) falls methodologically into three categories:\nmodel-driven, data-driven, and model-data dual-driven. Model-driven TSE relies\non macroscopic traffic flow models originated from hydrodynamics. Data-driven\nTSE leverages historical sensing data and employs statistical models or machine\nlearning methods to infer traffic state. Model-data dual-driven traffic state\nestimation attempts to harness the strengths of both aspects to achieve more\naccurate TSE. From the perspective of mathematical operator theory, TSE can be\nviewed as a type of operator that maps available measurements of inerested\ntraffic state into unmeasured traffic state variables in real time. For the\nfirst time this paper proposes to study real-time freeway TSE in the idea of\nphysics-informed deep operator network (PI-DeepONet), which is an\noperator-oriented architecture embedding traffic flow models based on deep\nneural networks. The paper has developed an extended architecture from the\noriginal PI-DeepONet. The extended architecture is featured with: (1) the\nacceptance of 2-D data input so as to support CNN-based computations; (2) the\nintroduction of a nonlinear expansion layer, an attention mechanism, and a MIMO\nmechanism; (3) dedicated neural network design for adaptive identification of\ntraffic flow model parameters. A traffic state estimator built on the basis of\nthis extended PI-DeepONet architecture was evaluated with respect to a short\nfreeway stretch of NGSIM and a large-scale urban expressway in China, along\nwith other four baseline TSE methods. The evaluation results demonstrated that\nthis novel TSE method outperformed the baseline methods with high-precision\nestimation results of flow and mean speed.", "published": "2025-08-11 14:07:01", "link": "http://arxiv.org/abs/2508.08002v1", "categories": ["cs.LG", "physics.app-ph"], "primary_category": "cs.LG"}
{"title": "Prediction error certification for PINNs: Theory, computation, and application to Stokes flow", "abstract": "Rigorous error estimation is a fundamental topic in numerical analysis. With\nthe increasing use of physics-informed neural networks (PINNs) for solving\npartial differential equations, several approaches have been developed to\nquantify the associated prediction error. In this work, we build upon a\nsemigroup-based framework previously introduced by the authors for estimating\nthe PINN error. While this estimator has so far been limited to academic\nexamples - due to the need to compute quantities related to input-to-state\nstability - we extend its applicability to a significantly broader class of\nproblems. This is accomplished by modifying the error bound and proposing\nnumerical strategies to approximate the required stability parameters. The\nextended framework enables the certification of PINN predictions in more\nrealistic scenarios, as demonstrated by a numerical study of Stokes flow around\na cylinder.", "published": "2025-08-11 13:57:02", "link": "http://arxiv.org/abs/2508.07994v1", "categories": ["math.NA", "cs.LG", "cs.NA", "65N15, 47D06, 35A35, 35F16, 41A65"], "primary_category": "math.NA"}
{"title": "Sharper Perturbed-Kullback-Leibler Exponential Tail Bounds for Beta and Dirichlet Distributions", "abstract": "This paper presents an improved exponential tail bound for Beta\ndistributions, refining a result in [15]. This improvement is achieved by\ninterpreting their bound as a regular Kullback-Leibler (KL) divergence one,\nwhile introducing a specific perturbation $\\eta$ that shifts the mean of the\nBeta distribution closer to zero within the KL bound. Our contribution is to\nshow that a larger perturbation can be chosen, thereby tightening the bound. We\nthen extend this result from the Beta distribution to Dirichlet distributions\nand Dirichlet processes (DPs).", "published": "2025-08-11 13:53:55", "link": "http://arxiv.org/abs/2508.07991v1", "categories": ["math.PR", "cs.LG"], "primary_category": "math.PR"}
{"title": "Likelihood Ratio Tests by Kernel Gaussian Embedding", "abstract": "We propose a novel kernel-based nonparametric two-sample test, employing the\ncombined use of kernel mean and kernel covariance embedding. Our test builds on\nrecent results showing how such combined embeddings map distinct probability\nmeasures to mutually singular Gaussian measures on the kernel's RKHS.\nLeveraging this result, we construct a test statistic based on the relative\nentropy between the Gaussian embeddings, i.e.\\ the likelihood ratio. The\nlikelihood ratio is specifically tailored to detect equality versus singularity\nof two Gaussians, and satisfies a ``$0/\\infty$\" law, in that it vanishes under\nthe null and diverges under the alternative. To implement the test in finite\nsamples, we introduce a regularised version, calibrated by way of permutation.\nWe prove consistency, establish uniform power guarantees under mild conditions,\nand discuss how our framework unifies and extends prior approaches based on\nspectrally regularized MMD. Empirical results on synthetic and real data\ndemonstrate remarkable gains in power compared to state-of-the-art methods,\nparticularly in high-dimensional and weak-signal regimes.", "published": "2025-08-11 13:41:38", "link": "http://arxiv.org/abs/2508.07982v1", "categories": ["stat.ML", "cs.LG", "stat.ME", "62G10, 62G20, 62H15, 62H20, 60G15, 46E22"], "primary_category": "stat.ML"}
{"title": "Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters", "abstract": "Clustering algorithms often assume all features contribute equally to the\ndata structure, an assumption that usually fails in high-dimensional or noisy\nsettings. Feature weighting methods can address this, but most require\nadditional parameter tuning. We propose SHARK (Shapley Reweighted $k$-means), a\nfeature-weighted clustering algorithm motivated by the use of Shapley values\nfrom cooperative game theory to quantify feature relevance, which requires no\nadditional parameters beyond those in $k$-means. We prove that the $k$-means\nobjective can be decomposed into a sum of per-feature Shapley values, providing\nan axiomatic foundation for unsupervised feature relevance and reducing Shapley\ncomputation from exponential to polynomial time. SHARK iteratively re-weights\nfeatures by the inverse of their Shapley contribution, emphasising informative\ndimensions and down-weighting irrelevant ones. Experiments on synthetic and\nreal-world data sets show that SHARK consistently matches or outperforms\nexisting methods, achieving superior robustness and accuracy, particularly in\nscenarios where noise may be present. Software:\nhttps://github.com/rickfawley/shark.", "published": "2025-08-11 13:07:21", "link": "http://arxiv.org/abs/2508.07952v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Gaussian Approximation for Two-Timescale Linear Stochastic Approximation", "abstract": "In this paper, we establish non-asymptotic bounds for accuracy of normal\napproximation for linear two-timescale stochastic approximation (TTSA)\nalgorithms driven by martingale difference or Markov noise. Focusing on both\nthe last iterate and Polyak-Ruppert averaging regimes, we derive bounds for\nnormal approximation in terms of the convex distance between probability\ndistributions. Our analysis reveals a non-trivial interaction between the fast\nand slow timescales: the normal approximation rate for the last iterate\nimproves as the timescale separation increases, while it decreases in the\nPolyak-Ruppert averaged setting. We also provide the high-order moment bounds\nfor the error of linear TTSA algorithm, which may be of independent interest.", "published": "2025-08-11 12:41:14", "link": "http://arxiv.org/abs/2508.07928v1", "categories": ["stat.ML", "cs.LG", "math.OC", "math.PR", "math.ST", "stat.TH", "60F05, 62L20"], "primary_category": "stat.ML"}
{"title": "Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting", "abstract": "Time series forecasting poses significant challenges in non-stationary\nenvironments where underlying patterns evolve over time. In this work, we\npropose a novel framework that enhances deep neural network (DNN) performance\nby leveraging specialized model adaptation and selection. Initially, a base DNN\nis trained offline on historical time series data. A reserved validation subset\nis then segmented to extract and cluster the most dominant patterns within the\nseries, thereby identifying distinct regimes. For each identified cluster, the\nbase DNN is fine-tuned to produce a specialized version that captures unique\npattern characteristics. At inference, the most recent input is matched against\nthe cluster centroids, and the corresponding fine-tuned version is deployed\nbased on the closest similarity measure. Additionally, our approach integrates\na concept drift detection mechanism to identify and adapt to emerging patterns\ncaused by non-stationary behavior. The proposed framework is generalizable\nacross various DNN architectures and has demonstrated significant performance\ngains on both traditional DNNs and recent advanced architectures implemented in\nthe GluonTS library.", "published": "2025-08-11 12:40:08", "link": "http://arxiv.org/abs/2508.07927v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Score Augmentation for Diffusion Models", "abstract": "Diffusion models have achieved remarkable success in generative modeling.\nHowever, this study confirms the existence of overfitting in diffusion model\ntraining, particularly in data-limited regimes. To address this challenge, we\npropose Score Augmentation (ScoreAug), a novel data augmentation framework\nspecifically designed for diffusion models. Unlike conventional augmentation\napproaches that operate on clean data, ScoreAug applies transformations to\nnoisy data, aligning with the inherent denoising mechanism of diffusion.\nCrucially, ScoreAug further requires the denoiser to predict the augmentation\nof the original target. This design establishes an equivariant learning\nobjective, enabling the denoiser to learn scores across varied denoising\nspaces, thereby realizing what we term score augmentation. We also\ntheoretically analyze the relationship between scores in different spaces under\ngeneral transformations. In experiments, we extensively validate ScoreAug on\nmultiple benchmarks including CIFAR-10, FFHQ, AFHQv2, and ImageNet, with\nresults demonstrating significant performance improvements over baselines.\nNotably, ScoreAug effectively mitigates overfitting across diverse scenarios,\nsuch as varying data scales and model capacities, while exhibiting stable\nconvergence properties. Another advantage of ScoreAug over standard data\naugmentation lies in its ability to circumvent data leakage issues under\ncertain conditions. Furthermore, we show that ScoreAug can be synergistically\ncombined with traditional data augmentation techniques to achieve additional\nperformance gains.", "published": "2025-08-11 12:39:46", "link": "http://arxiv.org/abs/2508.07926v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Stochastic dynamics learning with state-space systems", "abstract": "This work advances the theoretical foundations of reservoir computing (RC) by\nproviding a unified treatment of fading memory and the echo state property\n(ESP) in both deterministic and stochastic settings. We investigate state-space\nsystems, a central model class in time series learning, and establish that\nfading memory and solution stability hold generically -- even in the absence of\nthe ESP -- offering a robust explanation for the empirical success of RC models\nwithout strict contractivity conditions. In the stochastic case, we critically\nassess stochastic echo states, proposing a novel distributional perspective\nrooted in attractor dynamics on the space of probability distributions, which\nleads to a rich and coherent theory. Our results extend and generalize previous\nwork on non-autonomous dynamical systems, offering new insights into causality,\nstability, and memory in RC models. This lays the groundwork for reliable\ngenerative modeling of temporal data in both deterministic and stochastic\nregimes.", "published": "2025-08-11 11:49:01", "link": "http://arxiv.org/abs/2508.07876v1", "categories": ["stat.ML", "cs.LG", "math.DS", "math.ST", "stat.TH", "37B02, 37B55, 37H05, 37N35, 62M10, 68T05"], "primary_category": "stat.ML"}
{"title": "EFU: Enforcing Federated Unlearning via Functional Encryption", "abstract": "Federated unlearning (FU) algorithms allow clients in federated settings to\nexercise their ''right to be forgotten'' by removing the influence of their\ndata from a collaboratively trained model. Existing FU methods maintain data\nprivacy by performing unlearning locally on the client-side and sending\ntargeted updates to the server without exposing forgotten data; yet they often\nrely on server-side cooperation, revealing the client's intent and identity\nwithout enforcement guarantees - compromising autonomy and unlearning privacy.\nIn this work, we propose EFU (Enforced Federated Unlearning), a\ncryptographically enforced FU framework that enables clients to initiate\nunlearning while concealing its occurrence from the server. Specifically, EFU\nleverages functional encryption to bind encrypted updates to specific\naggregation functions, ensuring the server can neither perform unauthorized\ncomputations nor detect or skip unlearning requests. To further mask behavioral\nand parameter shifts in the aggregated model, we incorporate auxiliary\nunlearning losses based on adversarial examples and parameter importance\nregularization. Extensive experiments show that EFU achieves near-random\naccuracy on forgotten data while maintaining performance comparable to full\nretraining across datasets and neural architectures - all while concealing\nunlearning intent from the server. Furthermore, we demonstrate that EFU is\nagnostic to the underlying unlearning algorithm, enabling secure,\nfunction-hiding, and verifiable unlearning for any client-side FU mechanism\nthat issues targeted updates.", "published": "2025-08-11 11:44:21", "link": "http://arxiv.org/abs/2508.07873v1", "categories": ["cs.CR", "cs.DC", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Unequal Uncertainty: Rethinking Algorithmic Interventions for Mitigating Discrimination from AI", "abstract": "Uncertainty in artificial intelligence (AI) predictions poses urgent legal\nand ethical challenges for AI-assisted decision-making. We examine two\nalgorithmic interventions that act as guardrails for human-AI collaboration:\nselective abstention, which withholds high-uncertainty predictions from human\ndecision-makers, and selective friction, which delivers those predictions\ntogether with salient warnings or disclosures that slow the decision process.\nResearch has shown that selective abstention based on uncertainty can\ninadvertently exacerbate disparities and disadvantage under-represented groups\nthat disproportionately receive uncertain predictions. In this paper, we\nprovide the first integrated socio-technical and legal analysis of\nuncertainty-based algorithmic interventions. Through two case studies,\nAI-assisted consumer credit decisions and AI-assisted content moderation, we\ndemonstrate how the seemingly neutral use of uncertainty thresholds can trigger\ndiscriminatory impacts. We argue that, although both interventions pose risks\nof unlawful discrimination under UK law, selective frictions offer a promising\npathway toward fairer and more accountable AI-assisted decision-making by\npreserving transparency and encouraging more cautious human judgment.", "published": "2025-08-11 11:43:34", "link": "http://arxiv.org/abs/2508.07872v1", "categories": ["cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow", "abstract": "Attitude control is a fundamental aspect of spacecraft operations. Model\nPredictive Control (MPC) has emerged as a powerful strategy for these tasks,\nrelying on accurate models of the system dynamics to optimize control actions\nover a prediction horizon. In scenarios where physics models are incomplete,\ndifficult to derive, or computationally expensive, machine learning offers a\nflexible alternative by learning the system behavior directly from data.\nHowever, purely data-driven models often struggle with generalization and\nstability, especially when applied to inputs outside their training domain. To\naddress these limitations, we investigate the benefits of incorporating\nPhysics-Informed Neural Networks (PINNs) into the learning of spacecraft\nattitude dynamics, comparing their performance with that of purely data-driven\napproaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network\narchitecture with a self-attention mechanism, we trained several models on\nsimulated data generated with the Basilisk simulator. Two training strategies\nwere considered: a purely data-driven baseline and a physics-informed variant\nto improve robustness and stability. Our results demonstrate that the inclusion\nof physics-based information significantly enhances the performance in terms of\nthe mean relative error of the best architectures found by 27.08%. These\nadvantages are particularly evident when the learned models are integrated into\nan MPC framework, where PINN-based models consistently outperform their purely\ndata-driven counterparts in terms of control accuracy and robustness, yielding\nimprovements of up to 42.86% in performance stability error and increased\nrobustness-to-noise.", "published": "2025-08-11 10:50:49", "link": "http://arxiv.org/abs/2508.07841v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "G-IFT: A Gated Linear Unit adapter with Iterative Fine-Tuning for Low-Resource Children's Speaker Verification", "abstract": "Speaker Verification (SV) systems trained on adults speech often underperform\non children's SV due to the acoustic mismatch, and limited children speech data\nmakes fine-tuning not very effective. In this paper, we propose an innovative\nframework, a Gated Linear Unit adapter with Iterative Fine-Tuning (G-IFT), to\nenhance knowledge transfer efficiency between the high-resource adults speech\ndomain and the low-resource children's speech domain. In this framework, a\nGated Linear Unit adapter is first inserted between the pre-trained speaker\nembedding model and the classifier. Then the classifier, adapter, and\npre-trained speaker embedding model are optimized sequentially in an iterative\nway. This framework is agnostic to the type of the underlying architecture of\nthe SV system. Our experiments on ECAPA-TDNN, ResNet, and X-vector\narchitectures using the OGI and MyST datasets demonstrate that the G-IFT\nframework yields consistent reductions in Equal Error Rates compared to\nbaseline methods.", "published": "2025-08-11 10:41:56", "link": "http://arxiv.org/abs/2508.07836v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning", "abstract": "Reinforcement learning with verifiable reward (RLVR) has become a promising\nparadigm for post-training large language models (LLMs) to improve their\nreasoning capability. However, when the rollout accuracy is low on hard\nproblems, the reward becomes sparse, limiting learning efficiency and causing\nexploration bottlenecks. Existing approaches either rely on stronger LLMs for\ndistillation or filter out difficult problems, which limits scalability or\nrestricts reasoning improvement through exploration.\n  We propose EvoCoT, a self-evolving curriculum learning framework based on\ntwo-stage chain-of-thought (CoT) reasoning optimization. EvoCoT constrains the\nexploration space by self-generating and verifying CoT trajectories, then\ngradually shortens them to expand the space in a controlled way. This enables\nLLMs to stably learn from initially unsolved hard problems under sparse\nrewards. We apply EvoCoT to multiple LLM families, including Qwen, DeepSeek,\nand Llama. Experiments show that EvoCoT enables LLMs to solve previously\nunsolved problems, improves reasoning capability without external CoT\nsupervision, and is compatible with various RL fine-tuning methods. We release\nthe source code to support future research.", "published": "2025-08-11 09:49:01", "link": "http://arxiv.org/abs/2508.07809v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Topological Feature Compression for Molecular Graph Neural Networks", "abstract": "Recent advances in molecular representation learning have produced highly\neffective encodings of molecules for numerous cheminformatics and\nbioinformatics tasks. However, extracting general chemical insight while\nbalancing predictive accuracy, interpretability, and computational efficiency\nremains a major challenge. In this work, we introduce a novel Graph Neural\nNetwork (GNN) architecture that combines compressed higher-order topological\nsignals with standard molecular features. Our approach captures global\ngeometric information while preserving computational tractability and\nhuman-interpretable structure. We evaluate our model across a range of\nbenchmarks, from small-molecule datasets to complex material datasets, and\ndemonstrate superior performance using a parameter-efficient architecture. We\nachieve the best performing results in both accuracy and robustness across\nalmost all benchmarks. We open source all code \\footnote{All code and results\ncan be found on Github https://github.com/rahulkhorana/TFC-PACT-Net}.", "published": "2025-08-11 09:45:47", "link": "http://arxiv.org/abs/2508.07807v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Generative Inversion for Property-Targeted Materials Design: Application to Shape Memory Alloys", "abstract": "The design of shape memory alloys (SMAs) with high transformation\ntemperatures and large mechanical work output remains a longstanding challenge\nin functional materials engineering. Here, we introduce a data-driven framework\nbased on generative adversarial network (GAN) inversion for the inverse design\nof high-performance SMAs. By coupling a pretrained GAN with a property\nprediction model, we perform gradient-based latent space optimization to\ndirectly generate candidate alloy compositions and processing parameters that\nsatisfy user-defined property targets. The framework is experimentally\nvalidated through the synthesis and characterization of five NiTi-based SMAs.\nAmong them, the Ni$_{49.8}$Ti$_{26.4}$Hf$_{18.6}$Zr$_{5.2}$ alloy achieves a\nhigh transformation temperature of 404 $^\\circ$C, a large mechanical work\noutput of 9.9 J/cm$^3$, a transformation enthalpy of 43 J/g , and a thermal\nhysteresis of 29 {\\deg}C, outperforming existing NiTi alloys. The enhanced\nperformance is attributed to a pronounced transformation volume change and a\nfinely dispersed of Ti$_2$Ni-type precipitates, enabled by sluggish Zr and Hf\ndiffusion, and semi-coherent interfaces with localized strain fields. This\nstudy demonstrates that GAN inversion offers an efficient and generalizable\nroute for the property-targeted discovery of complex alloys.", "published": "2025-08-11 09:36:08", "link": "http://arxiv.org/abs/2508.07798v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory", "abstract": "Offline reinforcement learning (RL) aims to optimize the return given a fixed\ndataset of agent trajectories without additional interactions with the\nenvironment. While algorithm development has progressed rapidly, significant\ntheoretical advances have also been made in understanding the fundamental\nchallenges of offline RL. However, bridging these theoretical insights with\npractical algorithm design remains an ongoing challenge. In this survey, we\nexplore key intuitions derived from theoretical work and their implications for\noffline RL algorithms.\n  We begin by listing the conditions needed for the proofs, including function\nrepresentation and data coverage assumptions. Function representation\nconditions tell us what to expect for generalization, and data coverage\nassumptions describe the quality requirement of the data. We then examine\ncounterexamples, where offline RL is not solvable without an impractically\nlarge amount of data. These cases highlight what cannot be achieved for all\nalgorithms and the inherent hardness of offline RL. Building on techniques to\nmitigate these challenges, we discuss the conditions that are sufficient for\noffline RL. These conditions are not merely assumptions for theoretical proofs,\nbut they also reveal the limitations of these algorithms and remind us to\nsearch for novel solutions when the conditions cannot be satisfied.", "published": "2025-08-11 08:26:28", "link": "http://arxiv.org/abs/2508.07746v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning", "abstract": "Multi-Domain Continual Learning (MDCL) acquires knowledge from sequential\ntasks with shifting class sets and distribution. Despite the\nParameter-Efficient Fine-Tuning (PEFT) methods can adapt for this dual\nheterogeneity, they still suffer from catastrophic forgetting and forward\nforgetting. To address these challenges, we propose a Two-Level Routing Grouped\nMixture-of-Experts (TRGE) method. Firstly, TRGE dynamically expands the\npre-trained CLIP model, assigning specific expert group for each task to\nmitigate catastrophic forgetting. With the number of experts continually grows\nin this process, TRGE maintains the static experts count within the group and\nintroduces the intra-group router to alleviate routing overfitting caused by\nthe increasing routing complexity. Meanwhile, we design an inter-group routing\npolicy based on task identifiers and task prototype distance, which dynamically\nselects relevant expert groups and combines their outputs to enhance inter-task\ncollaboration. Secondly, to get the correct task identifiers, we leverage\nMultimodal Large Language Models (MLLMs) which own powerful multimodal\ncomprehension capabilities to generate semantic task descriptions and recognize\nthe correct task identifier. Finally, to mitigate forward forgetting, we\ndynamically fuse outputs for unseen samples from the frozen CLIP model and TRGE\nadapter based on training progress, leveraging both pre-trained and learned\nknowledge. Through extensive experiments across various settings, our method\noutperforms other advanced methods with fewer trainable parameters.", "published": "2025-08-11 08:18:22", "link": "http://arxiv.org/abs/2508.07738v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information", "abstract": "Deep neural networks can memorize corrupted labels, making data quality\ncritical for model performance, yet real-world datasets are frequently\ncompromised by both label noise and input noise. This paper proposes a mutual\ninformation-based framework for data selection under hybrid noise scenarios\nthat quantifies statistical dependencies between inputs and labels. We compute\neach sample's pointwise contribution to the overall mutual information and find\nthat lower contributions indicate noisy or mislabeled instances. Empirical\nvalidation on MNIST with different synthetic noise settings demonstrates that\nthe method effectively filters low-quality samples. Under label corruption,\ntraining on high-MI samples improves classification accuracy by up to 15\\%\ncompared to random sampling. Furthermore, the method exhibits robustness to\nbenign input modifications, preserving semantically valid data while filtering\ntruly corrupted samples.", "published": "2025-08-11 07:39:20", "link": "http://arxiv.org/abs/2508.07713v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Semantic-Enhanced Time-Series Forecasting via Large Language Models", "abstract": "Time series forecasting plays a significant role in finance, energy,\nmeteorology, and IoT applications. Recent studies have leveraged the\ngeneralization capabilities of large language models (LLMs) to adapt to time\nseries forecasting, achieving promising performance. However, existing studies\nfocus on token-level modal alignment, instead of bridging the intrinsic\nmodality gap between linguistic knowledge structures and time series data\npatterns, greatly limiting the semantic representation. To address this issue,\nwe propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent\nperiodicity and anomalous characteristics of time series to embed into the\nsemantic space to enhance the token embedding. This process enhances the\ninterpretability of tokens for LLMs, thereby activating the potential of LLMs\nfor temporal sequence analysis. Moreover, existing Transformer-based LLMs excel\nat capturing long-range dependencies but are weak at modeling short-term\nanomalies in time-series data. Hence, we propose a plugin module embedded\nwithin self-attention that models long-term and short-term dependencies to\neffectively adapt LLMs to time-series analysis. Our approach freezes the LLM\nand reduces the sequence dimensionality of tokens, greatly reducing\ncomputational consumption. Experiments demonstrate the superiority performance\nof our SE-LLM against the state-of-the-art (SOTA) methods.", "published": "2025-08-11 07:19:21", "link": "http://arxiv.org/abs/2508.07697v1", "categories": ["cs.LG", "cs.CE"], "primary_category": "cs.LG"}
{"title": "Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks", "abstract": "Federated learning (FL) enables collaborative model training across\ndecentralized clients without sharing local data, thereby enhancing privacy and\nfacilitating collaboration among clients connected via social networks.\nHowever, these social connections introduce privacy externalities: a client's\nprivacy loss depends not only on its privacy protection strategy but also on\nthe privacy decisions of others, propagated through the network via multi-hop\ninteractions. In this work, we propose a socially-aware privacy-preserving FL\nmechanism that systematically quantifies indirect privacy leakage through a\nmulti-hop propagation model. We formulate the server-client interaction as a\ntwo-stage Stackelberg game, where the server, as the leader, optimizes\nincentive policies, and clients, as followers, strategically select their\nprivacy budgets, which determine their privacy-preserving levels by controlling\nthe magnitude of added noise. To mitigate information asymmetry in networked\nprivacy estimation, we introduce a mean-field estimator to approximate the\naverage external privacy risk. We theoretically prove the existence and\nconvergence of the fixed point of the mean-field estimator and derive\nclosed-form expressions for the Stackelberg Nash Equilibrium. Despite being\ndesigned from a client-centric incentive perspective, our mechanism achieves\napproximately-optimal social welfare, as revealed by Price of Anarchy (PoA)\nanalysis. Experiments on diverse datasets demonstrate that our approach\nsignificantly improves client utilities and reduces server costs while\nmaintaining model performance, outperforming both Social-Agnostic (SA)\nbaselines and methods that account for social externalities.", "published": "2025-08-11 06:53:32", "link": "http://arxiv.org/abs/2508.07676v1", "categories": ["cs.LG", "cs.DC", "cs.GT"], "primary_category": "cs.LG"}
{"title": "Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation", "abstract": "Large Language Models (LLMs) are revolutionizing how users interact with\ninformation systems, yet their high inference cost poses serious scalability\nand sustainability challenges. Caching inference responses, allowing them to be\nretrieved without another forward pass through the LLM, has emerged as one\npossible solution. Traditional exact-match caching, however, overlooks the\nsemantic similarity between queries, leading to unnecessary recomputation.\nSemantic caching addresses this by retrieving responses based on semantic\nsimilarity, but introduces a fundamentally different cache eviction problem:\none must account for mismatch costs between incoming queries and cached\nresponses. Moreover, key system parameters, such as query arrival probabilities\nand serving costs, are often unknown and must be learned over time. Existing\nsemantic caching methods are largely ad-hoc, lacking theoretical foundations\nand unable to adapt to real-world uncertainty. In this paper, we present a\nprincipled, learning-based framework for semantic cache eviction under unknown\nquery and cost distributions. We formulate both offline optimization and online\nlearning variants of the problem, and develop provably efficient algorithms\nwith state-of-the-art guarantees. We also evaluate our framework on a synthetic\ndataset, showing that our proposed algorithms perform matching or superior\nperformance compared with baselines.", "published": "2025-08-11 06:53:27", "link": "http://arxiv.org/abs/2508.07675v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Turn Jailbreaks Are Simpler Than They Seem", "abstract": "While defenses against single-turn jailbreak attacks on Large Language Models\n(LLMs) have improved significantly, multi-turn jailbreaks remain a persistent\nvulnerability, often achieving success rates exceeding 70% against models\noptimized for single-turn protection. This work presents an empirical analysis\nof automated multi-turn jailbreak attacks across state-of-the-art models\nincluding GPT-4, Claude, and Gemini variants, using the StrongREJECT benchmark.\nOur findings challenge the perceived sophistication of multi-turn attacks: when\naccounting for the attacker's ability to learn from how models refuse harmful\nrequests, multi-turn jailbreaking approaches are approximately equivalent to\nsimply resampling single-turn attacks multiple times. Moreover, attack success\nis correlated among similar models, making it easier to jailbreak newly\nreleased ones. Additionally, for reasoning models, we find surprisingly that\nhigher reasoning effort often leads to higher attack success rates. Our results\nhave important implications for AI safety evaluation and the design of\njailbreak-resistant systems. We release the source code at\nhttps://github.com/diogo-cruz/multi_turn_simpler", "published": "2025-08-11 05:57:41", "link": "http://arxiv.org/abs/2508.07646v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals", "abstract": "Aligning Large Language Models (LLMs) with diverse human values requires\nmoving beyond a single holistic \"better-than\" preference criterion. While\ncollecting fine-grained, aspect-specific preference data is more reliable and\nscalable, existing methods like Direct Preference Optimization (DPO) struggle\nwith the severe noise and conflicts inherent in such aggregated datasets. In\nthis paper, we tackle this challenge from a data-centric perspective. We first\nderive the Direct Multi-Preference Optimization (DMPO) objective, and uncover a\nkey Preference Divergence (PD) term that quantifies inter-aspect preference\nconflicts. Instead of using this term for direct optimization, we leverage it\nto formulate a novel, theoretically-grounded data selection principle. Our\nprinciple advocates for selecting a subset of high-consensus data-identified by\nthe most negative PD values-for efficient DPO training. We prove the optimality\nof this strategy by analyzing the loss bounds of the DMPO objective in the\nselection problem. To operationalize our approach, we introduce practical\nmethods of PD term estimation and length bias mitigation, thereby proposing our\nPD selection method. Evaluation on the UltraFeedback dataset with three varying\nconflict levels shows that our simple yet effective strategy achieves over 10%\nrelative improvement against both the standard holistic preference and a\nstronger oracle using aggregated preference signals, all while boosting\ntraining efficiency and obviating the need for intractable holistic preference\nannotating, unlocking the potential of robust LLM alignment via fine-grained\npreference signals.", "published": "2025-08-11 05:43:02", "link": "http://arxiv.org/abs/2508.07638v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs", "abstract": "Implicit continuous models, such as functional models and implicit neural\nnetworks, are an increasingly popular method for replacing discrete data\nrepresentations with continuous, high-order, and differentiable surrogates.\nThese models offer new perspectives on the storage, transfer, and analysis of\nscientific data. In this paper, we introduce the first framework to directly\nextract complex topological features -- contours, Jacobi sets, and ridge-valley\ngraphs -- from a type of continuous implicit model known as multivariate\nfunctional approximation (MFA). MFA replaces discrete data with continuous\npiecewise smooth functions. Given an MFA model as the input, our approach\nenables direct extraction of complex topological features from the model,\nwithout reverting to a discrete representation of the model. Our work is easily\ngeneralizable to any continuous implicit model that supports the queries of\nfunction values and high-order derivatives. Our work establishes the building\nblocks for performing topological data analysis and visualization on implicit\ncontinuous models.", "published": "2025-08-11 05:41:24", "link": "http://arxiv.org/abs/2508.07637v1", "categories": ["cs.LG", "cs.CG"], "primary_category": "cs.LG"}
{"title": "When and how can inexact generative models still sample from the data manifold?", "abstract": "A curious phenomenon observed in some dynamical generative models is the\nfollowing: despite learning errors in the score function or the drift vector\nfield, the generated samples appear to shift \\emph{along} the support of the\ndata distribution but not \\emph{away} from it. In this work, we investigate\nthis phenomenon of \\emph{robustness of the support} by taking a dynamical\nsystems approach on the generating stochastic/deterministic process. Our\nperturbation analysis of the probability flow reveals that infinitesimal\nlearning errors cause the predicted density to be different from the target\ndensity only on the data manifold for a wide class of generative models.\nFurther, what is the dynamical mechanism that leads to the robustness of the\nsupport? We show that the alignment of the top Lyapunov vectors (most sensitive\ninfinitesimal perturbation directions) with the tangent spaces along the\nboundary of the data manifold leads to robustness and prove a sufficient\ncondition on the dynamics of the generating process to achieve this alignment.\nMoreover, the alignment condition is efficient to compute and, in practice, for\nrobust generative models, automatically leads to accurate estimates of the\ntangent bundle of the data manifold. Using a finite-time linear perturbation\nanalysis on samples paths as well as probability flows, our work complements\nand extends existing works on obtaining theoretical guarantees for generative\nmodels from a stochastic analysis, statistical learning and uncertainty\nquantification points of view. Our results apply across different dynamical\ngenerative models, such as conditional flow-matching and score-based generative\nmodels, and for different target distributions that may or may not satisfy the\nmanifold hypothesis.", "published": "2025-08-11 03:24:34", "link": "http://arxiv.org/abs/2508.07581v1", "categories": ["cs.LG", "math.DS", "math.PR"], "primary_category": "cs.LG"}
{"title": "Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification", "abstract": "LayerNorm is pivotal in Vision Transformers (ViTs), yet its fine-tuning\ndynamics under data scarcity and domain shifts remain underexplored. This paper\nshows that shifts in LayerNorm parameters after fine-tuning (LayerNorm shifts)\nare indicative of the transitions between source and target domains; its\nefficacy is contingent upon the degree to which the target training samples\naccurately represent the target domain, as quantified by our proposed\nFine-tuning Shift Ratio ($FSR$). Building on this, we propose a simple yet\neffective rescaling mechanism using a scalar $\\lambda$ that is negatively\ncorrelated to $FSR$ to align learned LayerNorm shifts with those ideal shifts\nachieved under fully representative data, combined with a cyclic framework that\nfurther enhances the LayerNorm fine-tuning. Extensive experiments across\nnatural and pathological images, in both in-distribution (ID) and\nout-of-distribution (OOD) settings, and various target training sample regimes\nvalidate our framework. Notably, OOD tasks tend to yield lower $FSR$ and higher\n$\\lambda$ in comparison to ID cases, especially with scarce data, indicating\nunder-represented target training samples. Moreover, ViTFs fine-tuned on\npathological data behave more like ID settings, favoring conservative LayerNorm\nupdates. Our findings illuminate the underexplored dynamics of LayerNorm in\ntransfer learning and provide practical strategies for LayerNorm fine-tuning.", "published": "2025-08-11 03:18:47", "link": "http://arxiv.org/abs/2508.07577v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression", "abstract": "Using more test-time computation during language model inference, such as\ngenerating more intermediate thoughts or sampling multiple candidate answers,\nhas proven effective in significantly improving model performance. This paper\ntakes an initial step toward bridging the gap between practical language model\ninference and theoretical transformer analysis by incorporating randomness and\nsampling. We focus on in-context linear regression with continuous/binary\ncoefficients, where our framework simulates language model decoding through\nnoise injection and binary coefficient sampling. Through this framework, we\nprovide detailed analyses of widely adopted inference techniques. Supported by\nempirical results, our theoretical framework and analysis demonstrate the\npotential for offering new insights into understanding inference behaviors in\nreal-world language models.", "published": "2025-08-11 03:05:36", "link": "http://arxiv.org/abs/2508.07571v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Barron Space Representations for Elliptic PDEs with Homogeneous Boundary Conditions", "abstract": "We study the approximation complexity of high-dimensional second-order\nelliptic PDEs with homogeneous boundary conditions on the unit hypercube,\nwithin the framework of Barron spaces. Under the assumption that the\ncoefficients belong to suitably defined Barron spaces, we prove that the\nsolution can be efficiently approximated by two-layer neural networks,\ncircumventing the curse of dimensionality. Our results demonstrate the\nexpressive power of shallow networks in capturing high-dimensional PDE\nsolutions under appropriate structural assumptions.", "published": "2025-08-11 02:36:40", "link": "http://arxiv.org/abs/2508.07559v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning", "abstract": "Machine learning (ML) systems are increasingly deployed in high-stakes\ndomains where reliability is paramount. This thesis investigates how\nuncertainty estimation can enhance the safety and trustworthiness of ML,\nfocusing on selective prediction -- where models abstain when confidence is\nlow.\n  We first show that a model's training trajectory contains rich uncertainty\nsignals that can be exploited without altering its architecture or loss. By\nensembling predictions from intermediate checkpoints, we propose a lightweight,\npost-hoc abstention method that works across tasks, avoids the cost of deep\nensembles, and achieves state-of-the-art selective prediction performance.\nCrucially, this approach is fully compatible with differential privacy (DP),\nallowing us to study how privacy noise affects uncertainty quality. We find\nthat while many methods degrade under DP, our trajectory-based approach remains\nrobust, and we introduce a framework for isolating the privacy-uncertainty\ntrade-off. Next, we then develop a finite-sample decomposition of the selective\nclassification gap -- the deviation from the oracle accuracy-coverage curve --\nidentifying five interpretable error sources and clarifying which interventions\ncan close the gap. This explains why calibration alone cannot fix ranking\nerrors, motivating methods that improve uncertainty ordering. Finally, we show\nthat uncertainty signals can be adversarially manipulated to hide errors or\ndeny service while maintaining high accuracy, and we design defenses combining\ncalibration audits with verifiable inference.\n  Together, these contributions advance reliable ML by improving, evaluating,\nand safeguarding uncertainty estimation, enabling models that not only make\naccurate predictions -- but also know when to say \"I do not know\".", "published": "2025-08-11 02:33:53", "link": "http://arxiv.org/abs/2508.07556v1", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Commentary Generation for Soccer Highlights", "abstract": "Automated soccer commentary generation has evolved from template-based\nsystems to advanced neural architectures, aiming to produce real-time\ndescriptions of sports events. While frameworks like SoccerNet-Caption laid\nfoundational work, their inability to achieve fine-grained alignment between\nvideo content and commentary remains a significant challenge. Recent efforts\nsuch as MatchTime, with its MatchVoice model, address this issue through coarse\nand fine-grained alignment techniques, achieving improved temporal\nsynchronization. In this paper, we extend MatchVoice to commentary generation\nfor soccer highlights using the GOAL dataset, which emphasizes short clips over\nentire games. We conduct extensive experiments to reproduce the original\nMatchTime results and evaluate our setup, highlighting the impact of different\ntraining configurations and hardware limitations. Furthermore, we explore the\neffect of varying window sizes on zero-shot performance. While MatchVoice\nexhibits promising generalization capabilities, our findings suggest the need\nfor integrating techniques from broader video-language domains to further\nenhance performance. Our code is available at\nhttps://github.com/chidaksh/SoccerCommentary.", "published": "2025-08-11 01:48:37", "link": "http://arxiv.org/abs/2508.07543v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning", "abstract": "Accurate and interpretable bearing fault classification is critical for\nensuring the reliability of rotating machinery, particularly under variable\noperating conditions where domain shifts can significantly degrade model\nperformance. This study proposes a physics-informed multimodal convolutional\nneural network (CNN) with a late fusion architecture, integrating vibration and\nmotor current signals alongside a dedicated physics-based feature extraction\nbranch. The model incorporates a novel physics-informed loss function that\npenalizes physically implausible predictions based on characteristic bearing\nfault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency\nInner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive\nexperiments on the Paderborn University dataset demonstrate that the proposed\nphysics-informed approach consistently outperforms a non-physics-informed\nbaseline, achieving higher accuracy, reduced false classifications, and\nimproved robustness across multiple data splits. To address performance\ndegradation under unseen operating conditions, three transfer learning (TL)\nstrategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy\n(LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS\nyields the best generalization, with additional performance gains when combined\nwith physics-informed modeling. Validation on the KAIST bearing dataset\nconfirms the framework's cross-dataset applicability, achieving up to 98\npercent accuracy. Statistical hypothesis testing further verifies significant\nimprovements (p < 0.01) in classification performance. The proposed framework\ndemonstrates the potential of integrating domain knowledge with data-driven\nlearning to achieve robust, interpretable, and generalizable fault diagnosis\nfor real-world industrial applications.", "published": "2025-08-11 01:32:09", "link": "http://arxiv.org/abs/2508.07536v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction", "abstract": "As deep spatio-temporal neural networks are increasingly utilised in urban\ncomputing contexts, the deployment of such methods can have a direct impact on\nusers of critical urban infrastructure, such as public transport, emergency\nservices, and traffic management systems. While many spatio-temporal methods\nfocus on improving accuracy, fairness has recently gained attention due to\ngrowing evidence that biased predictions in spatio-temporal applications can\ndisproportionately disadvantage certain demographic or geographic groups,\nthereby reinforcing existing socioeconomic inequalities and undermining the\nethical deployment of AI in public services. In this paper, we propose a novel\nframework, FairDRL-ST, based on disentangled representation learning, to\naddress fairness concerns in spatio-temporal prediction, with a particular\nfocus on mobility demand forecasting. By leveraging adversarial learning and\ndisentangled representation learning, our framework learns to separate\nattributes that contain sensitive information. Unlike existing methods that\nenforce fairness through supervised learning, which may lead to\novercompensation and degraded performance, our framework achieves fairness in\nan unsupervised manner with minimal performance loss. We apply our framework to\nreal-world urban mobility datasets and demonstrate its ability to close\nfairness gaps while delivering competitive predictive performance compared to\nstate-of-the-art fairness-aware methods.", "published": "2025-08-11 00:36:19", "link": "http://arxiv.org/abs/2508.07518v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-agent systems for chemical engineering: A review and perspective", "abstract": "Large language model (LLM)-based multi-agent systems (MASs) are a recent but\nrapidly evolving technology with the potential to transform chemical\nengineering by decomposing complex workflows into teams of collaborative agents\nwith specialized knowledge and tools. This review surveys the state-of-the-art\nof MAS within chemical engineering. While early studies demonstrate promising\nresults, scientific challenges remain, including the design of tailored\narchitectures, integration of heterogeneous data modalities, development of\nfoundation models with domain-specific modalities, and strategies for ensuring\ntransparency, safety, and environmental impact. As a young but fast-moving\nfield, MASs offer exciting opportunities to rethink chemical engineering\nworkflows.", "published": "2025-08-11 11:55:18", "link": "http://arxiv.org/abs/2508.07880v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Toward Goal-Oriented Communication in Multi-Agent Systems: An overview", "abstract": "As multi-agent systems (MAS) become increasingly prevalent in autonomous\nsystems, distributed control, and edge intelligence, efficient communication\nunder resource constraints has emerged as a critical challenge. Traditional\ncommunication paradigms often emphasize message fidelity or bandwidth\noptimization, overlooking the task relevance of the exchanged information. In\ncontrast, goal-oriented communication prioritizes the importance of information\nwith respect to the agents' shared objectives. This review provides a\ncomprehensive survey of goal-oriented communication in MAS, bridging\nperspectives from information theory, communication theory, and machine\nlearning. We examine foundational concepts alongside learning-based approaches\nand emergent protocols. Special attention is given to coordination under\ncommunication constraints, as well as applications in domains such as swarm\nrobotics, federated learning, and edge computing. The paper concludes with a\ndiscussion of open challenges and future research directions at the\nintersection of communication theory, machine learning, and multi-agent\ndecision making.", "published": "2025-08-11 07:46:55", "link": "http://arxiv.org/abs/2508.07720v1", "categories": ["cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "Perpetual exploration in anonymous synchronous networks with a Byzantine black hole", "abstract": "In this paper, we investigate: ``How can a group of initially co-located\nmobile agents perpetually explore an unknown graph, when one stationary node\noccasionally behaves maliciously, under an adversary's control?'' We call this\nnode a ``Byzantine black hole (BBH)'' and at any given round it may choose to\ndestroy all visiting agents, or none. This subtle power can drastically\nundermine classical exploration strategies designed for an always active black\nhole. We study this perpetual exploration problem in the presence of at most\none BBH, without initial knowledge of the network size. Since the underlying\ngraph may be 1-connected, perpetual exploration of the entire graph may be\ninfeasible. We thus define two variants: \\pbmPerpExpl\\ and \\pbmPerpExplHome. In\nthe former, the agents are tasked to perform perpetual exploration of at least\none component, obtained after the exclusion of the BBH. In the latter, the\nagents are tasked to perform perpetual exploration of the component which\ncontains the \\emph{home} node, where agents are initially co-located.\nNaturally, \\pbmPerpExplHome\\ is a special case of \\pbmPerpExpl. Agents operate\nunder a synchronous scheduler and communicate in a face-to-face model. Our goal\nis to determine the minimum number of agents necessary and sufficient to solve\nthese problems. In acyclic networks, we obtain optimal algorithms that solve\n\\pbmPerpExpl\\ with $4$ agents, and \\pbmPerpExplHome\\ with $6$ agents in trees.\nThe lower bounds hold even in path graphs. In general graphs, we give a\nnon-trivial lower bound of $2\\Delta-1$ agents for \\pbmPerpExpl, and an upper\nbound of $3\\Delta+3$ agents for \\pbmPerpExplHome. To our knowledge, this is the\nfirst study of a black-hole variant in arbitrary networks without initial\ntopological knowledge.", "published": "2025-08-11 07:27:22", "link": "http://arxiv.org/abs/2508.07703v1", "categories": ["cs.DC", "cs.MA"], "primary_category": "cs.DC"}
{"title": "Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation", "abstract": "Drafting a Statement of Work (SOW) is a vital part of business and legal\nprojects. It outlines key details like deliverables, timelines,\nresponsibilities, and legal terms. However, creating these documents is often a\nslow and complex process. It usually involves multiple people, takes several\ndays, and leaves room for errors or outdated content. This paper introduces a\nnew AI-driven automation system that makes the entire SOW drafting process\nfaster, easier, and more accurate. Instead of relying completely on humans, the\nsystem uses three intelligent components or 'agents' that each handle a part of\nthe job. One agent writes the first draft, another checks if everything is\nlegally correct, and the third agent formats the document and ensures\neverything is in order. Unlike basic online tools that just fill in templates,\nthis system understands the meaning behind the content and customizes the SOW\nto match the needs of the project. It also checks legal compliance and\nformatting so that users can trust the result. The system was tested using real\nbusiness examples. It was able to create a full SOW in under three minutes,\ncompared to several hours or days using manual methods. It also performed well\nin accuracy and quality, showing that it can reduce legal risks and save a lot\nof time. This solution shows how artificial intelligence can be used to support\nlegal and business professionals by taking care of routine work and helping\nthem focus on more important decisions. It's a step toward making legal\nprocesses smarter, faster, and more reliable.", "published": "2025-08-11 02:59:36", "link": "http://arxiv.org/abs/2508.07569v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "A probabilistic approach to spectral analysis of Cauchy-type inverse problems: Convergence and stability analysis", "abstract": "A comprehensive convergence and stability analysis of some probabilistic\nnumerical methods designed to solve Cauchy-type inverse problems is performed\nin this study. Such inverse problems aim at solving an elliptic partial\ndifferential equation (PDE) or a system of elliptic PDEs in a bounded Euclidean\ndomain, subject to incomplete boundary and/or internal conditions, and are\nusually severely ill-posed. In a very recent paper \\cite{CiGrMaI}, a\nprobabilistic numerical framework has been developed by the authors, wherein\nsuch inverse problems could be analysed thoroughly by simulating the spectrum\nof some corresponding direct problem and its singular value decomposition based\non stochastic representations and Monte Carlo simulations. Herein a full\nprobabilistic error analysis of the aforementioned methods is provided, whereas\nthe convergence of the corresponding approximations is proved and explicit\nerror bounds are provided. This is achieved by employing tools from several\nareas such as spectral theory, regularity theory for elliptic measures,\nstochastic representations, and concentration inequalities.", "published": "2025-08-11 17:35:57", "link": "http://arxiv.org/abs/2508.08215v1", "categories": ["math.NA", "cs.NA", "65N12, 65N15, 65N21, 65N25, 65N75, 35J25, 65C05, 60J65, 65C40"], "primary_category": "math.NA"}
{"title": "A Note on Eigenvalues of Perturbed Hermitian Matrices", "abstract": "Let $$ A=\\left(\\begin{array}{cc} H_1 & E^*\\\\ E & H_2\\end{array}\\right) \\quad\n\\hbox{ and } \\quad \\wtd A=\\left(\\begin{array}{cc} H_1 & O\\\\ O &\nH_2\\end{array}\\right)$$ be two $N$-by-$N$ Hermitian matrices with eigenvalues\n$\\lambda_1 \\ge \\cdots \\ge \\lambda_{N}$ and $\\wtd \\lambda_1 \\ge \\cdots \\ge \\wtd\n\\lambda_N$, respectively. \\iffalse There are two kinds of perturbation bounds\non $|\\lambda_i - \\wtd \\lambda_i|$:\n  $|\\lambda_i- \\wtd \\lambda_i| \\le \\|E\\|$, where $\\|E\\|$\n  is the largest singular value of $\\|E\\|$, regardless of\n  $H_i$'s spectral distributions, and\n  $|\\lambda_i - \\wtd \\lambda_i| \\le \\|E\\|^2/\\eta$, where $\\eta$ is\n  the minimum gap between $H_i$'s spectra. \\end{enumerate} Bounds of the first\nkind overestimate the changes when $\\|E\\|\\ll\\eta$ while those of the second\nkind may blow up when $\\eta$ is too tiny. \\fi Denote by $\\|E\\|$ the spectral\nnorm of the matrix $E$, and $\\eta$ the spectral gap between the spectra of\n$H_1$ and $H_2$. It is shown that $$ |\\lambda_i - \\wtd \\lambda_i| \\le {2\\|E\\|^2\n\\over \\eta+\\sqrt{\\eta^2+4\\|E\\|^2}} \\, , $$ which improves all the existing\nresults. Similar bounds are obtained for singular values of matrices under\nblock perturbations.", "published": "2025-08-11 17:20:23", "link": "http://arxiv.org/abs/2508.08203v1", "categories": ["math.NA", "cs.NA", "15A42, 15A18, 65F15"], "primary_category": "math.NA"}
{"title": "The univariate multinode Shepard method for the Caputo fractional derivatives: from Approximation to the solution of Bagley-Torvik equation", "abstract": "In this paper, we approximate the fractional derivative of a given function\nusing the univariate multinode Shepard method through the Gauss-Jacobi\nquadrature formula. Subsequently, the proposed method is applied to the\nnumerical solution of boundary value problems (BVPs) and initial value problems\n(IVPs), specifically addressing the Bagley-Torvik equations. Experimental\nresults confirm the method's effectiveness, particularly in accurately\napproximating the Bagley-Torvik equation for both BVPs and IVPs.", "published": "2025-08-11 15:12:12", "link": "http://arxiv.org/abs/2508.08067v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Anderson Accelerated Primal-Dual Hybrid Gradient for solving LP", "abstract": "We present the Anderson Accelerated Primal-Dual Hybrid Gradient (AA-PDHG), a\nfixed-point-based framework designed to overcome the slow convergence of the\nstandard PDHG method for the solution of linear programming (LP) problems. We\nestablish the global convergence of AA-PDHG under a safeguard condition. In\naddition, we propose a filtered variant (FAA-PDHG) that applies angle and\nlength filtering to preserve the uniform boundedness of the coefficient matrix,\na property crucial for guaranteeing convergence. Numerical results show that\nboth AA-PDHG and FAA-PDHG deliver significant speedups over vanilla PDHG for\nlarge-scale LP instances.", "published": "2025-08-11 15:06:48", "link": "http://arxiv.org/abs/2508.08062v1", "categories": ["math.OC", "cs.NA", "math.NA", "65K05, 90C05, 90C06, 90C25, 90C33"], "primary_category": "math.OC"}
{"title": "Multinode Shepard collocation method for pricing of financial derivatives", "abstract": "This paper explores the use of the multinode Shepard method for the numerical\nsolution of the two-dimensional Black-Scholes equation. The proposed approach\nintegrates a spatial approximation via the multinode Shepard operator with a\ntemporal discretization based on the Backward Difference Formula. Numerical\nexperiments are presented to demonstrate the accuracy and effectiveness of the\nmethod.", "published": "2025-08-11 14:28:22", "link": "http://arxiv.org/abs/2508.08023v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Finite element 3D models of melanoma growth and time-dependent backscattered data for dielectric properties of melanoma at 6 GHz", "abstract": "Finite element meshes for 3D models simulating realistic malignant melanoma\n(MM) growth, incorporating accurate dielectric properties of the skin, have\nbeen developed. Numerical simulations illustrate how 3D finite element meshes\ncan be utilized to generate backscattered data, enabling the evaluation of\nreconstruction algorithms designed to determine the dielectric properties of\nthe proposed 3D model.", "published": "2025-08-11 09:25:01", "link": "http://arxiv.org/abs/2508.07794v1", "categories": ["math.NA", "cs.NA", "65J22, 65K10, 65M32, 65M55, 65M60, 65M70"], "primary_category": "math.NA"}
{"title": "Reconstructing the dielectric properties of melanoma in 3D using real-life melanoma model", "abstract": "The paper presents performance of the adaptive domain decomposition finite\nelement/finite difference method for reconstruction of the dielectric\npermittivity and conductivity functions for 3D real-life melanoma model using\nmeasurements of the backscattered electric field at the boundary of the\ninvestigated domain. We present several gradient-based reconstruction\nalgorithms which use optimization approach to find stationary point of the\nLagrangian. Our computational tests show qualitative and quantitative\nreconstruction of dielectric permittivity and conductivity functions using\nrealistic model of malign melanoma at 6 GHz in 3D.", "published": "2025-08-11 09:07:34", "link": "http://arxiv.org/abs/2508.07780v1", "categories": ["math.NA", "cs.NA", "65J22, 65K10, 65M32, 65M55, 65M60, 65M70"], "primary_category": "math.NA"}
{"title": "Multinode Shepard Functions and Tensor Product Polynomial Interpolation: Applications to Digital Elevation Models", "abstract": "The paper presents an in-depth exploration of the multinode Shepard\ninterpolant on a regular rectangular grid, demonstrating its efficacy in\nreconstructing surfaces from DEM data. Additionally, we study the approximation\norder associated to this interpolant and present a detailed algorithm for\nreconstructing surfaces. Numerical tests showcase the effectiveness of the\nproposed algorithm.", "published": "2025-08-11 08:47:50", "link": "http://arxiv.org/abs/2508.07764v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A $C^{\\infty}$ rational quasi-interpolation operator for functions with jumps without the Gibbs phenomenon", "abstract": "The study of quasi-interpolation has gained significant importance in\nnumerical analysis and approximation theory due to its versatile applications\nin scientific and engineering fields. This technique provides a flexible and\nefficient alternative to traditional interpolation methods by approximating\ndata points without requiring the approximated function to pass exactly through\nthem. This approach is particularly valuable for handling jump discontinuities,\nwhere classical interpolation methods often fail due to the Gibbs phenomenon.\nThese discontinuities are common in practical scenarios such as signal\nprocessing and computational physics. In this paper, we present a $C^{\\infty}$\nrational quasi-interpolation operator designed to effectively approximate\nfunctions with jump discontinuities while minimizing the issues typically\nassociated with traditional interpolation methods.", "published": "2025-08-11 08:20:51", "link": "http://arxiv.org/abs/2508.07741v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Addendum on data driven regularization by projection", "abstract": "We study the stability of regularization by projection for solving linear\ninverse problems if the forward operator is given indirectly but specified via\nsome input-output training pairs. We extend the approach in \"Data driven\nregularization by projection\" (Aspri, Korolev, and Scherzer; Inverse Problems;\n36 (2020), 125009) to data pairs, which are noisy and, possibly, linearly\ndependent.", "published": "2025-08-11 07:37:54", "link": "http://arxiv.org/abs/2508.07709v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Efficient adaptive randomized algorithms for fixed-threshold low-rank matrix approximation", "abstract": "The low-rank matrix approximation problems within a threshold are widely\napplied in information retrieval, image processing, background estimation of\nthe video sequence problems and so on. This paper presents an adaptive\nrandomized rank-revealing algorithm of the data matrix $A$, in which the basis\nmatrix $Q$ of the approximate range space is adaptively built block by block,\nthrough a recursive deflation procedure on $A$. Detailed analysis of randomized\nprojection schemes are provided to analyze the numerical rank reduce during the\ndeflation. The provable spectral and Frobenius error $(I-QQ^T)A$ of the\napproximate low-rank matrix $\\tilde A=QQ^TA$ are presented, as well as the\napproximate singular values. This blocked deflation technique is pass-efficient\nand can accelerate practical computations of large matrices. Applied to image\nprocessing and background estimation problems, the blocked randomized algorithm\nbehaves more reliable and more efficient than the known Lanczos-based method\nand a rank-revealing algorithm proposed by Lee, Li and Zeng (in SIAM J. Matrix\nAnal. Appl. 31 (2009), pp. 503-525).", "published": "2025-08-11 02:26:29", "link": "http://arxiv.org/abs/2508.07553v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Physics-informed Multiresolution Wavelet Neural Network Method for Solving Partial Differential Equations", "abstract": "In this paper, a physics-informed multiresolution wavelet neural network\n(PIMWNN) method is proposed for solving partial differential equations (PDEs).\nThis method uses the multiresolution wavelet neural network (MWNN) to\napproximate unknown functions, then substituting the MWNN into PDEs and\ntraining the MWNN by least-squares algorithm. We apply the proposed method to\nvarious problems, including stationary/nonstationary advection, diffusion and\nadvection-diffusion problems, and linear/nonlinear time-dependent problems.\nNumerical experiments show that the PIMWNN method can achieve higher accuracy\nand faster speed than Physics Informed Neural Networks (PINNs). Moreover, the\nPIMWNN method, being mesh-free, can handle different boundary conditions easily\nand solve the time-dependent problems efficiently. The proposed method is\nexpected to solve the spectral bias problem in network training. These\ncharacteristics show the great potential of the PIMWNN method used in the field\nof numerical solving methods for PDEs.", "published": "2025-08-11 02:01:12", "link": "http://arxiv.org/abs/2508.07546v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Randomized coordinate gradient descent almost surely escapes strict saddle points", "abstract": "We analyze the behavior of randomized coordinate gradient descent for\nnonconvex optimization, proving that under standard assumptions, the iterates\nalmost surely escape strict saddle points. By formulating the method as a\nnonlinear random dynamical system and characterizing neighborhoods of critical\npoints, we establish this result through the center-stable manifold theorem.", "published": "2025-08-11 01:31:19", "link": "http://arxiv.org/abs/2508.07535v1", "categories": ["math.OC", "cs.NA", "math.DS", "math.NA", "math.PR"], "primary_category": "math.OC"}
{"title": "Optimal Fees for Liquidity Provision in Automated Market Makers", "abstract": "Passive liquidity providers (LPs) in automated market makers (AMMs) face\nlosses due to adverse selection (LVR), which static trading fees often fail to\noffset in practice. We study the key determinants of LP profitability in a\ndynamic reduced-form model where an AMM operates in parallel with a centralized\nexchange (CEX), traders route their orders optimally to the venue offering the\nbetter price, and arbitrageurs exploit price discrepancies. Using large-scale\nsimulations and real market data, we analyze how LP profits vary with market\nconditions such as volatility and trading volume, and characterize the optimal\nAMM fee as a function of these conditions. We highlight the mechanisms driving\nthese relationships through extensive comparative statics, and confirm the\nmodel's relevance through market data calibration. A key trade-off emerges:\nfees must be low enough to attract volume, yet high enough to earn sufficient\nrevenues and mitigate arbitrage losses. We find that under normal market\nconditions, the optimal AMM fee is competitive with the trading cost on the CEX\nand remarkably stable, whereas in periods of very high volatility, a high fee\nprotects passive LPs from severe losses. These findings suggest that a\nthreshold-type dynamic fee schedule is both robust enough to market conditions\nand improves LP outcomes.", "published": "2025-08-11 16:30:02", "link": "http://arxiv.org/abs/2508.08152v1", "categories": ["q-fin.TR", "econ.GN", "math.OC", "q-fin.CP", "q-fin.EC", "q-fin.PM"], "primary_category": "q-fin.TR"}
{"title": "Optimal Dividend, Reinsurance, and Capital Injection Strategies for an Insurer with Two Collaborating Business Lines", "abstract": "This paper considers an insurer with two collaborating business lines, and\nthe risk exposure of each line follows a diffusion risk model. The manager of\nthe insurer makes three decisions for each line: (i) dividend payout, (ii)\n(proportional) reinsurance coverage, and (iii) capital injection (from one line\ninto the other). The manager seeks an optimal dividend, reinsurance, and\ncapital injection strategy to maximize the expected weighted sum of the total\ndividend payments until the first ruin. We completely solve this problem and\nobtain the value function and optimal strategies in closed form. We show that\nthe optimal dividend strategy is a threshold strategy, and the more important\nline always has a lower threshold to pay dividends. The optimal proportion of\nrisk ceded to the reinsurer is decreasing with respect to the aggregate reserve\nlevel for each line, and capital injection is only used to prevent the ruin of\na business line. Finally, numerical examples are presented to illustrate the\nimpact of model parameters on the optimal strategies.", "published": "2025-08-11 16:06:00", "link": "http://arxiv.org/abs/2508.08130v1", "categories": ["math.OC", "q-fin.MF", "q-fin.RM", "91G05 (Primary) 93E20 (Secondary)"], "primary_category": "math.OC"}
{"title": "Regularity of Solutions of Mean-Field $G$-SDEs", "abstract": "We study regularity properties of the unique solution of a mean-field\n$G$-SDE. More precisely, we consider a mean-field $G$-SDE with\nsquare-integrable random initial condition and establish its first and second\norder Fr\\'echet differentiability in the random initial condition and specify\nthe $G$-SDEs of the respective Fr\\'echet derivatives.", "published": "2025-08-11 11:36:11", "link": "http://arxiv.org/abs/2508.07867v1", "categories": ["math.PR", "q-fin.MF"], "primary_category": "math.PR"}
{"title": "Unwitting Markowitz' Simplification of Portfolio Random Returns", "abstract": "In his famous paper, Markowitz (1952) derived the dependence of portfolio\nrandom returns on the random returns of its securities. This result allowed\nMarkowitz to obtain his famous expression for portfolio variance. We show that\nMarkowitz's equation for portfolio random returns and the expression for\nportfolio variance, which results from it, describe a simplified approximation\nof the real markets when the volumes of all consecutive trades with the\nsecurities are assumed to be constant during the averaging interval. To show\nthis, we consider the investor who doesn't trade shares of securities of his\nportfolio. The investor only observes the trades made in the market with his\nsecurities and derives the time series that model the trades with his portfolio\nas with a single security. These time series describe the portfolio return and\nvariance in exactly the same way as the time series of trades with securities\ndescribe their returns and variances. The portfolio time series reveal the\ndependence of portfolio random returns on the random returns of securities and\non the ratio of the random volumes of trades with the securities to the random\nvolumes of trades with the portfolio. If we assume that all volumes of the\nconsecutive trades with securities are constant, obtain Markowitz's equation\nfor the portfolio's random returns. The market-based variance of the portfolio\naccounts for the effects of random fluctuations of the volumes of the\nconsecutive trades. The use of Markowitz variance may give significantly higher\nor lower estimates than market-based portfolio variance.", "published": "2025-08-11 16:24:37", "link": "http://arxiv.org/abs/2508.08148v1", "categories": ["econ.GN", "q-fin.EC", "q-fin.GN", "q-fin.PM", "q-fin.ST"], "primary_category": "econ.GN"}
{"title": "MSU-Bench: Towards Understanding the Conversational Multi-talker Scenarios", "abstract": "Spoken Language Understanding (SLU) has progressed from traditional\nsingle-task methods to large audio language model (LALM) solutions. Yet, most\nexisting speech benchmarks focus on single-speaker or isolated tasks,\noverlooking the challenges posed by multi-speaker conversations that are common\nin real-world scenarios. We introduce MSU-Bench, a comprehensive benchmark for\nevaluating multi-speaker conversational understanding with a speaker-centric\ndesign. Our hierarchical framework covers four progressive tiers:\nsingle-speaker static attribute understanding, single-speaker dynamic attribute\nunderstanding, multi-speaker background understanding, and multi-speaker\ninteraction understanding. This structure ensures all tasks are grounded in\nspeaker-centric contexts, from basic perception to complex reasoning across\nmultiple speakers. By evaluating state-of-the-art models on MSU-Bench, we\ndemonstrate that as task complexity increases across the benchmark's tiers, all\nmodels exhibit a significant performance decline. We also observe a persistent\ncapability gap between open-source models and closed-source commercial ones,\nparticularly in multi-speaker interaction reasoning. These findings validate\nthe effectiveness of MSU-Bench for assessing and advancing conversational\nunderstanding in realistic multi-speaker environments. Demos can be found in\nthe supplementary material.", "published": "2025-08-11 16:31:32", "link": "http://arxiv.org/abs/2508.08155v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Score-Informed BiLSTM Correction for Refining MIDI Velocity in Automatic Piano Transcription", "abstract": "MIDI is a modern standard for storing music, recording how musical notes are\nplayed. Many piano performances have corresponding MIDI scores available\nonline. Some of these are created by the original performer, recording on an\nelectric piano alongside the audio, while others are through manual\ntranscription. In recent years, automatic music transcription (AMT) has rapidly\nadvanced, enabling machines to transcribe MIDI from audio. However, these\ntranscriptions often require further correction. Assuming a perfect timing\ncorrection, we focus on the loudness correction in terms of MIDI velocity (a\nparameter in MIDI for loudness control). This task can be approached through\nscore-informed MIDI velocity estimation, which has undergone several\ndevelopments. While previous approaches introduced specifically built models to\nre-estimate MIDI velocity, thereby replacing AMT estimates, we propose a BiLSTM\ncorrection module to refine AMT-estimated velocity. Although we did not reach\nstate-of-the-art performance, we validated our method on the well-known AMT\nsystem, the high-resolution piano transcription (HPT), and achieved significant\nimprovements.", "published": "2025-08-11 08:40:33", "link": "http://arxiv.org/abs/2508.07757v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Filling MIDI Velocity using U-Net Image Colorizer", "abstract": "Modern music producers commonly use MIDI (Musical Instrument Digital\nInterface) to store their musical compositions. However, MIDI files created\nwith digital software may lack the expressive characteristics of human\nperformances, essentially leaving the velocity parameter - a control for note\nloudness - undefined, which defaults to a flat value. The task of filling MIDI\nvelocity is termed MIDI velocity prediction, which uses regression models to\nenhance music expressiveness by adjusting only this parameter. In this paper,\nwe introduce the U-Net, a widely adopted architecture in image colorization, to\nthis task. By conceptualizing MIDI data as images, we adopt window attention\nand develop a custom loss function to address the sparsity of MIDI-converted\nimages. Current dataset availability restricts our experiments to piano data.\nEvaluated on the MAESTRO v3 and SMD datasets, our proposed method for filling\nMIDI velocity outperforms previous approaches in both quantitative metrics and\nqualitative listening tests.", "published": "2025-08-11 08:32:07", "link": "http://arxiv.org/abs/2508.07751v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Is GAN Necessary for Mel-Spectrogram-based Neural Vocoder?", "abstract": "Recently, mainstream mel-spectrogram-based neural vocoders rely on generative\nadversarial network (GAN) for high-fidelity speech generation, e.g., HiFi-GAN\nand BigVGAN. However, the use of GAN restricts training efficiency and model\ncomplexity. Therefore, this paper proposes a novel FreeGAN vocoder, aiming to\nanswer the question of whether GAN is necessary for mel-spectrogram-based\nneural vocoders. The FreeGAN employs an amplitude-phase serial prediction\nframework, eliminating the need for GAN training. It incorporates amplitude\nprior input, SNAKE-ConvNeXt v2 backbone and frequency-weighted anti-wrapping\nphase loss to compensate for the performance loss caused by the absence of GAN.\nExperimental results confirm that the speech quality of FreeGAN is comparable\nto that of advanced GAN-based vocoders, while significantly improving training\nefficiency and complexity. Other explicit-phase-prediction-based neural\nvocoders can also work without GAN, leveraging our proposed methods.", "published": "2025-08-11 07:38:48", "link": "http://arxiv.org/abs/2508.07711v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "UniFlow: Unifying Speech Front-End Tasks via Continuous Generative Modeling", "abstract": "Generative modeling has recently achieved remarkable success across image,\nvideo, and audio domains, demonstrating powerful capabilities for unified\nrepresentation learning. Yet speech front-end tasks such as speech enhancement\n(SE), target speaker extraction (TSE), acoustic echo cancellation (AEC), and\nlanguage-queried source separation (LASS) remain largely tackled by disparate,\ntask-specific solutions. This fragmentation leads to redundant engineering\neffort, inconsistent performance, and limited extensibility. To address this\ngap, we introduce UniFlow, a unified framework that employs continuous\ngenerative modeling to tackle diverse speech front-end tasks in a shared latent\nspace. Specifically, UniFlow utilizes a waveform variational autoencoder (VAE)\nto learn a compact latent representation of raw audio, coupled with a Diffusion\nTransformer (DiT) that predicts latent updates. To differentiate the speech\nprocessing task during the training, learnable condition embeddings indexed by\na task ID are employed to enable maximal parameter sharing while preserving\ntask-specific adaptability. To balance model performance and computational\nefficiency, we investigate and compare three generative objectives: denoising\ndiffusion, flow matching, and mean flow within the latent domain. We validate\nUniFlow on multiple public benchmarks, demonstrating consistent gains over\nstate-of-the-art baselines. UniFlow's unified latent formulation and\nconditional design make it readily extensible to new tasks, providing an\nintegrated foundation for building and scaling generative speech processing\npipelines. To foster future research, we will open-source our codebase.", "published": "2025-08-11 02:35:54", "link": "http://arxiv.org/abs/2508.07558v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Real-time CARFAC Cochlea Model Acceleration on FPGA for Underwater Acoustic Sensing Systems", "abstract": "This paper presents a real-time, energy-efficient embedded system\nimplementing an array of Cascade of Asymmetric Resonators with Fast-Acting\nCompression (CARFAC) cochlea models for underwater sound analysis. Built on the\nAMD Kria KV260 System-on-Module (SoM), the system integrates a Rust-based\nsoftware framework on the processor for real-time interfacing and\nsynchronization with multiple hydrophone inputs, and a hardware-accelerated\nimplementation of the CARFAC models on a Field-Programmable Gate Array (FPGA)\nfor real-time sound pre-processing. Compared to prior work, the CARFAC\naccelerator achieves improved scalability and processing speed while reducing\nresource usage through optimized time-multiplexing, pipelined design, and\nelimination of costly division circuits. Experimental results demonstrate 13.5%\nhardware utilization for a single 64-channel CARFAC instance and a whole board\npower consumption of 3.11 W when processing a 256 kHz input signal in real\ntime.", "published": "2025-08-11 00:58:34", "link": "http://arxiv.org/abs/2508.07523v1", "categories": ["eess.AS", "cs.SD", "92C50 (Primary) 68Q25, 94A12 (Secondary)"], "primary_category": "eess.AS"}
{"title": "Mamba-FCS: Joint Spatio- Frequency Feature Fusion, Change-Guided Attention, and SeK Loss for Enhanced Semantic Change Detection in Remote Sensing", "abstract": "Semantic Change Detection (SCD) from remote sensing imagery requires models\nbalancing extensive spatial context, computational efficiency, and sensitivity\nto class-imbalanced land-cover transitions. While Convolutional Neural Networks\nexcel at local feature extraction but lack global context, Transformers provide\nglobal modeling at high computational costs. Recent Mamba architectures based\non state-space models offer compelling solutions through linear complexity and\nefficient long-range modeling. In this study, we introduce Mamba-FCS, a SCD\nframework built upon Visual State Space Model backbone incorporating, a Joint\nSpatio-Frequency Fusion block incorporating log-amplitude frequency domain\nfeatures to enhance edge clarity and suppress illumination artifacts, a\nChange-Guided Attention (CGA) module that explicitly links the naturally\nintertwined BCD and SCD tasks, and a Separated Kappa (SeK) loss tailored for\nclass-imbalanced performance optimization. Extensive evaluation on SECOND and\nLandsat-SCD datasets shows that Mamba-FCS achieves state-of-the-art metrics,\n88.62% Overall Accuracy, 65.78% F_scd, and 25.50% SeK on SECOND, 96.25% Overall\nAccuracy, 89.27% F_scd, and 60.26% SeK on Landsat-SCD. Ablation analyses\nconfirm distinct contributions of each novel component, with qualitative\nassessments highlighting significant improvements in SCD. Our results underline\nthe substantial potential of Mamba architectures, enhanced by proposed\ntechniques, setting a new benchmark for effective and scalable semantic change\ndetection in remote sensing applications. The complete source code,\nconfiguration files, and pre-trained models will be publicly available upon\npublication.", "published": "2025-08-11 17:49:59", "link": "http://arxiv.org/abs/2508.08232v1", "categories": ["eess.IV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Robust Design of Beyond-Diagonal Reconfigurable Intelligent Surface Empowered RSMA-SWIPT System Under Channel Estimation Errors", "abstract": "This work explores the integration of rate-splitting multiple access (RSMA),\nsimultaneous wireless information and power transfer (SWIPT), and\nbeyond-diagonal reconfigurable intelligent surface (BD-RIS) to enhance the\nspectral-efficiency, energy-efficiency, coverage, and connectivity of future\nsixth-generation (6G) communication networks. Specifically, with a multiuser\nBD-RIS-empowered RSMA-SWIPT system, we jointly optimize the transmit precoding\nvectors, the common rate proportion of users, the power-splitting ratios, and\nscattering matrix of BD-RIS node, under the assumption of imperfect channel\nstate information (CSI). Additionally, to better capture practical hardware\nbehavior, we incorporate a nonlinear energy harvesting model under energy\nharvesting constraints. We design a robust optimization framework to maximize\nthe system sum-rate, while explicitly accounting for the worst-case impact of\nCSI uncertainties. Further, we introduce an alternating optimization framework\nthat partitions the problem into several blocks, which are optimized\niteratively. More specifically, the transmit precoding vectors are optimized by\nreformulating the problem as a convex semidefinite programming through\nsuccessive-convex approximation (SCA), whereas the power-splitting problem is\nsolved using the MOSEK-enabled CVX toolbox. Subsequently, to optimize the\nscattering matrix of the BD-RIS, we first employ SCA to reformulate the problem\ninto a convex form, and then design a manifold optimization strategy based on\nthe Conjugate-Gradient method. Finally, numerical simulation results reveal\nthat the proposed scheme provides significant performance improvements over\nexisting benchmarks and demonstrates rapid convergence within a reasonable\nnumber of iterations.", "published": "2025-08-11 15:37:01", "link": "http://arxiv.org/abs/2508.08097v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Advancing the Control of Low-Altitude Wireless Networks: Architecture, Design Principles, and Future Directions", "abstract": "This article introduces a control-oriented low-altitude wireless network\n(LAWN) that integrates near-ground communications and remote estimation of the\ninternal system state. This integration supports reliable networked control in\ndynamic aerial-ground environments. First, we introduce the network's modular\narchitecture and key performance metrics. Then, we discuss core design\ntrade-offs across the control, communication, and estimation layers. A case\nstudy illustrates closed-loop coordination under wireless constraints. Finally,\nwe outline future directions for scalable, resilient LAWN deployments in\nreal-time and resource-constrained scenarios.", "published": "2025-08-11 13:28:22", "link": "http://arxiv.org/abs/2508.07967v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "RIS-Assisted NOMA with Partial CSI and Mutual Coupling: A Machine Learning Approach", "abstract": "Non-orthogonal multiple access (NOMA) is a promising multiple access\ntechnique. Its performance depends strongly on the wireless channel property,\nwhich can be enhanced by reconfigurable intelligent surfaces (RISs). In this\npaper, we jointly optimize base station (BS) precoding and RIS configuration\nwith unsupervised machine learning (ML), which looks for the optimal solution\nautonomously. In particular, we propose a dedicated neural network (NN)\narchitecture RISnet inspired by domain knowledge in communication. Compared to\nstate-of-the-art, the proposed approach combines analytical optimal BS\nprecoding and ML-enabled RIS, has a high scalability to control more than 1000\nRIS elements, has a low requirement for channel state information (CSI) in\ninput, and addresses the mutual coupling between RIS elements. Beyond the\nconsidered problem, this work is an early contribution to domain knowledge\nenabled ML, which exploit the domain expertise of communication systems to\ndesign better approaches than general ML methods.", "published": "2025-08-11 12:24:41", "link": "http://arxiv.org/abs/2508.07909v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Over-the-Top Resource Broker System for Split Computing: An Approach to Distribute Cloud Computing Infrastructure", "abstract": "6G network architectures will usher in a wave of innovative services and\ncapabilities, introducing concepts like split computing and dynamic processing\nnodes. This implicates a paradigm where accessing resources seamlessly aligns\nwith diverse processing node characteristics, ensuring a uniform interface. In\nthis landscape, the identity of the operator becomes inconsequential, paving\nthe way for a collaborative ecosystem where multiple providers contribute to a\nshared pool of resources. At the core of this vision is the guarantee of\nspecific performance parameters, precisely tailored to the location and service\nrequirements. A consistent layer, as the abstraction of the complexities of\ndifferent infrastructure providers, is needed to simplify service deployment.\nOne promising approach is the introduction of an over-the-top broker for\nresource allocation, which streamlines the integration of these services into\nthe network and cloud infrastructure of the future. This paper explores the\nrole of the broker in two split computing scenarios. By abstracting the\ncomplexities of various infrastructures, the broker proves to be a versatile\nsolution applicable not only to cloud environments but also to networks and\nbeyond. Additionally, a detailed discussion of a proof-of-concept\nimplementation provides insights into the broker's actual architectural\nframework.", "published": "2025-08-11 08:24:23", "link": "http://arxiv.org/abs/2508.07744v1", "categories": ["cs.DC", "cs.NI", "eess.SP"], "primary_category": "cs.DC"}
{"title": "Touch-Augmented Gaussian Splatting for Enhanced 3D Scene Reconstruction", "abstract": "This paper presents a multimodal framework that integrates touch signals\n(contact points and surface normals) into 3D Gaussian Splatting (3DGS). Our\napproach enhances scene reconstruction, particularly under challenging\nconditions like low lighting, limited camera viewpoints, and occlusions.\nDifferent from the visual-only method, the proposed approach incorporates\nspatially selective touch measurements to refine both the geometry and\nappearance of the 3D Gaussian representation. To guide the touch exploration,\nwe introduce a two-stage sampling scheme that initially probes sparse regions\nand then concentrates on high-uncertainty boundaries identified from the\nreconstructed mesh. A geometric loss is proposed to ensure surface smoothness,\nresulting in improved geometry. Experimental results across diverse scenarios\nshow consistent improvements in geometric accuracy. In the most challenging\ncase with severe occlusion, the Chamfer Distance is reduced by over 15x,\ndemonstrating the effectiveness of integrating touch cues into 3D Gaussian\nSplatting. Furthermore, our approach maintains a fully online pipeline,\nunderscoring its feasibility in visually degraded environments.", "published": "2025-08-11 07:45:22", "link": "http://arxiv.org/abs/2508.07717v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Remote ID Based UAV Collision Avoidance Optimization for Low-Altitude Airspace Safety", "abstract": "With the rapid development of unmanned aerial vehicles (UAVs), it is\nparamount to ensure safe and efficient operations in open airspaces. The remote\nidentification (Remote ID) is deemed an effective real-time UAV monitoring\nsystem by the federal aviation administration, which holds potentials for\nenabling inter-UAV communications. This paper deeply investigates the\napplication of Remote ID for UAV collision avoidance while minimizing\ncommunication delays. First, we propose a Remote ID based distributed multi-UAV\ncollision avoidance (DMUCA) framework to support the collision detection,\navoidance decision-making, and trajectory recovery. Next, the average\ntransmission delays for Remote ID messages are analyzed, incorporating the\npacket reception mechanisms and packet loss due to interference. The\noptimization problem is formulated to minimize the long-term average\ncommunication delay, where UAVs can flexibly select the Remote ID protocol to\nenhance the collision avoidance performance. To tackle the problem, we design a\nmulti-agent deep Q-network based adaptive communication configuration\nalgorithm, allowing UAVs to autonomously learn the optimal protocol\nconfigurations in dynamic environments. Finally, numerical results verify the\nfeasibility of the proposed DMUCA framework, and the proposed mechanism can\nreduce the average delay by 32% compared to the fixed protocol configuration.", "published": "2025-08-11 06:01:13", "link": "http://arxiv.org/abs/2508.07651v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching-Antenna Systems (PASS): A Tutorial", "abstract": "Pinching antenna systems (PASS) present a breakthrough among the\nflexible-antenna technologies, and distinguish themselves by facilitating\nlarge-scale antenna reconfiguration, line-of-sight creation, scalable\nimplementation, and near-field benefits, thus bringing wireless communications\nfrom the last mile to the last meter. A comprehensive tutorial is presented in\nthis paper. First, the fundamentals of PASS are discussed, including PASS\nsignal models, hardware models, power radiation models, and pinching antenna\nactivation methods. Building upon this, the information-theoretic capacity\nlimits achieved by PASS are characterized, and several typical performance\nmetrics of PASS-based communications are analyzed to demonstrate its\nsuperiority over conventional antenna technologies. Next, the pinching\nbeamforming design is investigated. The corresponding power scaling law is\nfirst characterized. For the joint transmit and pinching design in the general\nmultiple-waveguide case, 1) a pair of transmission strategies is proposed for\nPASS-based single-user communications to validate the superiority of PASS,\nnamely sub-connected and fully connected structures; and 2) three practical\nprotocols are proposed for facilitating PASS-based multi-user communications,\nnamely waveguide switching, waveguide division, and waveguide multiplexing. A\npossible implementation of PASS in wideband communications is further\nhighlighted. Moreover, the channel state information acquisition in PASS is\nelaborated with a pair of promising solutions. To overcome the high complexity\nand suboptimality inherent in conventional convex-optimization-based\napproaches, machine-learning-based methods for operating PASS are also\nexplored, focusing on selected deep neural network architectures and training\nalgorithms. Finally, several promising applications of PASS in next-generation\nwireless networks are highlighted.", "published": "2025-08-11 03:11:20", "link": "http://arxiv.org/abs/2508.07572v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Direction of Arrival Estimation with Virtual Antenna Array Using FMCW Radar Simulated Data", "abstract": "The FMCW radars are widely used for automotive radar systems. The basic idea\nfor FMCW radars is to generate a linear frequency ramp as transmit signal. The\ndifference frequency, (i.e., beat frequency) between the transmitted and\nreceived signal is determined after down conversion. The FFT operation on beat\nfrequency signal can recognize targets at different range and velocity.\nIncreasing demand on safety functionality leads to the Direction of Arrival\n(DOA) estimation to resolve two closely located targets. Consequently, the\nproblem of angle estimation for 77GHz FMCW automotive radar simulated data has\nbeen investigated in this term project. In particular, we examined the\nperformances of FFT, MUSIC and compressed sensing in angle estimation task, and\nit was found that although FFT is the fastest algorithm, it has very poor\nangular resolution when compared with others which are both super resolution\nalgorithms. The code for this project report is available at\nhttps://github.com/ekurtgl/FMCW-MIMO-Radar-Simulation.", "published": "2025-08-11 00:07:22", "link": "http://arxiv.org/abs/2508.07513v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Jinx: Unlimited LLMs for Probing Alignment Failures", "abstract": "Unlimited, or so-called helpful-only language models are trained without\nsafety alignment constraints and never refuse user queries. They are widely\nused by leading AI companies as internal tools for red teaming and alignment\nevaluation. For example, if a safety-aligned model produces harmful outputs\nsimilar to an unlimited model, this indicates alignment failures that require\nfurther attention. Despite their essential role in assessing alignment, such\nmodels are not available to the research community.\n  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx\nresponds to all queries without refusals or safety filtering, while preserving\nthe base model's capabilities in reasoning and instruction following. It\nprovides researchers with an accessible tool for probing alignment failures,\nevaluating safety boundaries, and systematically studying failure modes in\nlanguage model safety.", "published": "2025-08-11 17:56:06", "link": "http://arxiv.org/abs/2508.08243v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation", "abstract": "Reinforcement learning (RL) is emerging as a powerful paradigm for enabling\nlarge language models (LLMs) to perform complex reasoning tasks. Recent\nadvances indicate that integrating RL with retrieval-augmented generation (RAG)\nallows LLMs to dynamically incorporate external knowledge, leading to more\ninformed and robust decision making. However, we identify a critical challenge\nduring policy-driven trajectory sampling: LLMs are frequently trapped in\nunproductive reasoning paths, which we refer to as \"dead ends\", committing to\noverconfident yet incorrect conclusions. This severely hampers exploration and\nundermines effective policy optimization. To address this challenge, we propose\nREX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented\nGeneration), a novel framework that explores alternative reasoning paths while\nmaintaining rigorous policy learning through principled distributional\ncorrections. Our approach introduces two key innovations: (1) Mixed Sampling\nStrategy, which combines a novel probe sampling method with exploratory prompts\nto escape dead ends; and (2) Policy Correction Mechanism, which employs\nimportance sampling to correct distribution shifts induced by mixed sampling,\nthereby mitigating gradient estimation bias. We evaluate it on seven\nquestion-answering benchmarks, and the experimental results show that REX-RAG\nachieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B\nover strong baselines, demonstrating competitive results across multiple\ndatasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.", "published": "2025-08-11 16:25:25", "link": "http://arxiv.org/abs/2508.08149v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning", "abstract": "Recent advancements in large language models, multimodal large language\nmodels, and large audio language models (LALMs) have significantly improved\ntheir reasoning capabilities through reinforcement learning with rule-based\nrewards. However, the explicit reasoning process has yet to show significant\nbenefits for audio question answering, and effectively leveraging deep\nreasoning remains an open challenge, with LALMs still falling short of\nhuman-level auditory-language reasoning. To address these limitations, we\npropose Audio-Thinker, a reinforcement learning framework designed to enhance\nthe reasoning capabilities of LALMs, with a focus on improving adaptability,\nconsistency, and effectiveness. Our approach introduces an adaptive think\naccuracy reward, enabling the model to adjust its reasoning strategies based on\ntask complexity dynamically. Furthermore, we incorporate an external reward\nmodel to evaluate the overall consistency and quality of the reasoning process,\ncomplemented by think-based rewards that help the model distinguish between\nvalid and flawed reasoning paths during training. Experimental results\ndemonstrate that our Audio-Thinker model outperforms existing\nreasoning-oriented LALMs across various benchmark tasks, exhibiting superior\nreasoning and generalization capabilities.", "published": "2025-08-11 14:41:10", "link": "http://arxiv.org/abs/2508.08039v2", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization", "abstract": "We present Klear-Reasoner, a model with long reasoning capabilities that\ndemonstrates careful deliberation during problem solving, achieving outstanding\nperformance across multiple benchmarks. Although there are already many\nexcellent works related to inference models in the current community, there are\nstill many problems with reproducing high-performance inference models due to\nincomplete disclosure of training details. This report provides an in-depth\nanalysis of the reasoning model, covering the entire post-training workflow\nfrom data preparation and long Chain-of-Thought supervised fine-tuning (long\nCoT SFT) to reinforcement learning (RL), along with detailed ablation studies\nfor each experimental component. For SFT data, our experiments show that a\nsmall number of high-quality data sources are more effective than a large\nnumber of diverse data sources, and that difficult samples can achieve better\nresults without accuracy filtering. In addition, we investigate two key issues\nwith current clipping mechanisms in RL: Clipping suppresses critical\nexploration signals and ignores suboptimal trajectories. To address these\nchallenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)\nthat gently backpropagates gradients from clipped tokens. GPPO not only\nenhances the model's exploration capacity but also improves its efficiency in\nlearning from negative samples. Klear-Reasoner exhibits exceptional reasoning\nabilities in mathematics and programming, scoring 90.5% on AIME 2024, 83.2% on\nAIME 2025, 66.0% on LiveCodeBench V5 and 58.1% on LiveCodeBench V6.", "published": "2025-08-11 05:17:51", "link": "http://arxiv.org/abs/2508.07629v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Cut2Next: Generating Next Shot via In-Context Tuning", "abstract": "Effective multi-shot generation demands purposeful, film-like transitions and\nstrict cinematic continuity. Current methods, however, often prioritize basic\nvisual consistency, neglecting crucial editing patterns (e.g., shot/reverse\nshot, cutaways) that drive narrative flow for compelling storytelling. This\nyields outputs that may be visually coherent but lack narrative sophistication\nand true cinematic integrity. To bridge this, we introduce Next Shot Generation\n(NSG): synthesizing a subsequent, high-quality shot that critically conforms to\nprofessional editing patterns while upholding rigorous cinematic continuity.\nOur framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs\nin-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This\nstrategy uses Relational Prompts to define overall context and inter-shot\nediting styles. Individual Prompts then specify per-shot content and\ncinematographic attributes. Together, these guide Cut2Next to generate\ncinematically appropriate next shots. Architectural innovations, Context-Aware\nCondition Injection (CACI) and Hierarchical Attention Mask (HAM), further\nintegrate these diverse signals without introducing new parameters. We\nconstruct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with\nhierarchical prompts, and introduce CutBench for evaluation. Experiments show\nCut2Next excels in visual consistency and text fidelity. Crucially, user\nstudies reveal a strong preference for Cut2Next, particularly for its adherence\nto intended editing patterns and overall cinematic continuity, validating its\nability to generate high-quality, narratively expressive, and cinematically\ncoherent subsequent shots.", "published": "2025-08-11 17:56:59", "link": "http://arxiv.org/abs/2508.08244v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Fitting Description Logic Ontologies to ABox and Query Examples", "abstract": "We study a fitting problem inspired by ontology-mediated querying: given a\ncollection of positive and negative examples of the form $(\\mathcal{A},q)$ with\n$\\mathcal{A}$ an ABox and $q$ a Boolean query, we seek an ontology\n$\\mathcal{O}$ that satisfies $\\mathcal{A} \\cup \\mathcal{O} \\vDash q$ for all\npositive examples and $\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$ for all\nnegative examples. We consider the description logics $\\mathcal{ALC}$ and\n$\\mathcal{ALCI}$ as ontology languages and a range of query languages that\nincludes atomic queries (AQs), conjunctive queries (CQs), and unions thereof\n(UCQs). For all of the resulting fitting problems, we provide effective\ncharacterizations and determine the computational complexity of deciding\nwhether a fitting ontology exists. This problem turns out to be ${\\scriptsize\nCO}NP$ for AQs and full CQs and $2E{\\scriptsize XP}T{\\scriptsize IME}$-complete\nfor CQs and UCQs. These results hold for both $\\mathcal{ALC}$ and\n$\\mathcal{ALCI}$.", "published": "2025-08-11 14:11:27", "link": "http://arxiv.org/abs/2508.08007v2", "categories": ["cs.AI", "Computing methodologies~Description logics, Computing\n  methodologies~Ontology engineering"], "primary_category": "cs.AI"}
{"title": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths", "abstract": "\"Fedspeak\", the stylized and often nuanced language used by the U.S. Federal\nReserve, encodes implicit policy signals and strategic stances. The Federal\nOpen Market Committee strategically employs Fedspeak as a communication tool to\nshape market expectations and influence both domestic and global economic\nconditions. As such, automatically parsing and interpreting Fedspeak presents a\nhigh-impact challenge, with significant implications for financial forecasting,\nalgorithmic trading, and data-driven policy analysis. In this paper, we propose\nan LLM-based, uncertainty-aware framework for deciphering Fedspeak and\nclassifying its underlying monetary policy stance. Technically, to enrich the\nsemantic and contextual representation of Fedspeak texts, we incorporate\ndomain-specific reasoning grounded in the monetary policy transmission\nmechanism. We further introduce a dynamic uncertainty decoding module to assess\nthe confidence of model predictions, thereby enhancing both classification\naccuracy and model reliability. Experimental results demonstrate that our\nframework achieves state-of-the-art performance on the policy stance analysis\ntask. Moreover, statistical analysis reveals a significant positive correlation\nbetween perceptual uncertainty and model error rates, validating the\neffectiveness of perceptual uncertainty as a diagnostic signal.", "published": "2025-08-11 14:04:59", "link": "http://arxiv.org/abs/2508.08001v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval", "abstract": "Retrieval-augmented generation has achieved strong performance on\nknowledge-intensive tasks where query-document relevance can be identified\nthrough direct lexical or semantic matches. However, many real-world queries\ninvolve abstract reasoning, analogical thinking, or multi-step inference, which\nexisting retrievers often struggle to capture. To address this challenge, we\npresent \\textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive\ninformation retrieval. DIVER consists of four components: document processing\nto improve input quality, LLM-driven query expansion via iterative document\ninteraction, a reasoning-enhanced retriever fine-tuned on synthetic\nmulti-domain data with hard negatives, and a pointwise reranker that combines\nLLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark,\nDIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original\nqueries, consistently outperforming competitive reasoning-aware models. These\nresults demonstrate the effectiveness of reasoning-aware retrieval strategies\nin complex real-world tasks. Our code and retrieval model will be released\nsoon.", "published": "2025-08-11 13:57:49", "link": "http://arxiv.org/abs/2508.07995v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "abstract": "Visual effects (VFX) are essential visual enhancements fundamental to modern\ncinematic production. Although video generation models offer cost-efficient\nsolutions for VFX production, current methods are constrained by per-effect\nLoRA training, which limits generation to single effects. This fundamental\nlimitation impedes applications that require spatially controllable composite\neffects, i.e., the concurrent generation of multiple effects at designated\nlocations. However, integrating diverse effects into a unified framework faces\nmajor challenges: interference from effect variations and spatial\nuncontrollability during multi-VFX joint training. To tackle these challenges,\nwe propose Omni-Effects, a first unified framework capable of generating\nprompt-guided effects and spatially controllable composite effects. The core of\nour framework comprises two key innovations: (1) LoRA-based Mixture of Experts\n(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects\nwithin a unified model while effectively mitigating cross-task interference.\n(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the\ntext token, enabling precise spatial control. Furthermore, we introduce an\nIndependent-Information Flow (IIF) module integrated within the SAP, isolating\nthe control signals corresponding to individual effects to prevent any unwanted\nblending. To facilitate this research, we construct a comprehensive VFX dataset\nOmni-VFX via a novel data collection pipeline combining image editing and\nFirst-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX\nevaluation framework for validating model performance. Extensive experiments\ndemonstrate that Omni-Effects achieves precise spatial control and diverse\neffect generation, enabling users to specify both the category and location of\ndesired effects.", "published": "2025-08-11 13:41:24", "link": "http://arxiv.org/abs/2508.07981v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation", "abstract": "Insider threats, which can lead to severe losses, remain a major security\nconcern. While machine learning-based insider threat detection (ITD) methods\nhave shown promising results, their progress is hindered by the scarcity of\nhigh-quality data. Enterprise data is sensitive and rarely accessible, while\npublicly available datasets, when limited in scale due to cost, lack sufficient\nreal-world coverage; and when purely synthetic, they fail to capture rich\nsemantics and realistic user behavior. To address this, we propose Chimera, the\nfirst large language model (LLM)-based multi-agent framework that automatically\nsimulates both benign and malicious insider activities and collects diverse\nlogs across diverse enterprise environments. Chimera models each employee with\nagents that have role-specific behavior and integrates modules for group\nmeetings, pairwise interactions, and autonomous scheduling, capturing realistic\norganizational dynamics. It incorporates 15 types of insider attacks (e.g., IP\ntheft, system sabotage) and has been deployed to simulate activities in three\nsensitive domains: technology company, finance corporation, and medical\ninstitution, producing a new dataset, ChimeraLog. We assess ChimeraLog via\nhuman studies and quantitative analysis, confirming its diversity, realism, and\npresence of explainable threat patterns. Evaluations of existing ITD methods\nshow an average F1-score of 0.83, which is significantly lower than 0.99 on the\nCERT dataset, demonstrating ChimeraLog's higher difficulty and utility for\nadvancing ITD research.", "published": "2025-08-11 08:24:48", "link": "http://arxiv.org/abs/2508.07745v2", "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "cs.CR"}
{"title": "3D Human Mesh Estimation from Single View RGBD", "abstract": "Despite significant progress in 3D human mesh estimation from RGB images;\nRGBD cameras, offering additional depth data, remain underutilized. In this\npaper, we present a method for accurate 3D human mesh estimation from a single\nRGBD view, leveraging the affordability and widespread adoption of RGBD cameras\nfor real-world applications. A fully supervised approach for this problem,\nrequires a dataset with RGBD image and 3D mesh label pairs. However, collecting\nsuch a dataset is costly and challenging, hence, existing datasets are small,\nand limited in pose and shape diversity. To overcome this data scarcity, we\nleverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D\nmeshes from the body models found in MoCap datasets, and create partial,\nsingle-view versions of them by projection to a virtual camera. This simulates\nthe depth data provided by an RGBD camera from a single viewpoint. Then, we\ntrain a masked autoencoder to complete the partial, single-view mesh. During\ninference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'',\nmatches the depth values coming from the sensor to vertices of a template human\nmesh, which creates a partial, single-view mesh. We effectively recover parts\nof the 3D human body mesh model that are not visible, resulting in a full body\nmesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL\nand CAPE datasets, respectively; outperforming existing methods that use\nfull-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE\ndataset, outperforming a recently published RGB based method by 18.4 mm,\nhighlighting the usefulness of depth data. Code will be released.", "published": "2025-08-11 16:59:14", "link": "http://arxiv.org/abs/2508.08178v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control", "abstract": "While recent flow-based image editing models demonstrate general-purpose\ncapabilities across diverse tasks, they often struggle to specialize in\nchallenging scenarios -- particularly those involving large-scale shape\ntransformations. When performing such structural edits, these methods either\nfail to achieve the intended shape change or inadvertently alter non-target\nregions, resulting in degraded background quality. We propose\nFollow-Your-Shape, a training-free and mask-free framework that supports\nprecise and controllable editing of object shapes while strictly preserving\nnon-target content. Motivated by the divergence between inversion and editing\ntrajectories, we compute a Trajectory Divergence Map (TDM) by comparing\ntoken-wise velocity differences between the inversion and denoising paths. The\nTDM enables precise localization of editable regions and guides a Scheduled KV\nInjection mechanism that ensures stable and faithful editing. To facilitate a\nrigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120\nnew images and enriched prompt pairs specifically curated for shape-aware\nediting. Experiments demonstrate that our method achieves superior editability\nand visual fidelity, particularly in tasks requiring large-scale shape\nreplacement.", "published": "2025-08-11 16:10:00", "link": "http://arxiv.org/abs/2508.08134v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction", "abstract": "Reconstructing dense geometry for dynamic scenes from a monocular video is a\ncritical yet challenging task. Recent memory-based methods enable efficient\nonline reconstruction, but they fundamentally suffer from a Memory Demand\nDilemma: The memory representation faces an inherent conflict between the\nlong-term stability required for static structures and the rapid, high-fidelity\ndetail retention needed for dynamic motion. This conflict forces existing\nmethods into a compromise, leading to either geometric drift in static\nstructures or blurred, inaccurate reconstructions of dynamic objects. To\naddress this dilemma, we propose Mem4D, a novel framework that decouples the\nmodeling of static geometry and dynamic motion. Guided by this insight, we\ndesign a dual-memory architecture: 1) The Transient Dynamics Memory (TDM)\nfocuses on capturing high-frequency motion details from recent frames, enabling\naccurate and fine-grained modeling of dynamic content; 2) The Persistent\nStructure Memory (PSM) compresses and preserves long-term spatial information,\nensuring global consistency and drift-free reconstruction for static elements.\nBy alternating queries to these specialized memories, Mem4D simultaneously\nmaintains static geometry with global consistency and reconstructs dynamic\nelements with high fidelity. Experiments on challenging benchmarks demonstrate\nthat our method achieves state-of-the-art or competitive performance while\nmaintaining high efficiency. Codes will be publicly available.", "published": "2025-08-11 12:23:31", "link": "http://arxiv.org/abs/2508.07908v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation", "abstract": "Generating high-fidelity human videos that match user-specified identities is\nimportant yet challenging in the field of generative AI. Existing methods often\nrely on an excessive number of training parameters and lack compatibility with\nother AIGC tools. In this paper, we propose Stand-In, a lightweight and\nplug-and-play framework for identity preservation in video generation.\nSpecifically, we introduce a conditional image branch into the pre-trained\nvideo generation model. Identity control is achieved through restricted\nself-attentions with conditional position mapping, and can be learned quickly\nwith only 2000 pairs. Despite incorporating and training just $\\sim$1%\nadditional parameters, our framework achieves excellent results in video\nquality and identity preservation, outperforming other full-parameter training\nmethods. Moreover, our framework can be seamlessly integrated for other tasks,\nsuch as subject-driven video generation, pose-referenced video generation,\nstylization, and face swapping.", "published": "2025-08-11 12:17:38", "link": "http://arxiv.org/abs/2508.07901v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation", "abstract": "Large Language Models (LLMs) are revolutionizing how users interact with\ninformation systems, yet their high inference cost poses serious scalability\nand sustainability challenges. Caching inference responses, allowing them to be\nretrieved without another forward pass through the LLM, has emerged as one\npossible solution. Traditional exact-match caching, however, overlooks the\nsemantic similarity between queries, leading to unnecessary recomputation.\nSemantic caching addresses this by retrieving responses based on semantic\nsimilarity, but introduces a fundamentally different cache eviction problem:\none must account for mismatch costs between incoming queries and cached\nresponses. Moreover, key system parameters, such as query arrival probabilities\nand serving costs, are often unknown and must be learned over time. Existing\nsemantic caching methods are largely ad-hoc, lacking theoretical foundations\nand unable to adapt to real-world uncertainty. In this paper, we present a\nprincipled, learning-based framework for semantic cache eviction under unknown\nquery and cost distributions. We formulate both offline optimization and online\nlearning variants of the problem, and develop provably efficient algorithms\nwith state-of-the-art guarantees. We also evaluate our framework on a synthetic\ndataset, showing that our proposed algorithms perform matching or superior\nperformance compared with baselines.", "published": "2025-08-11 06:53:27", "link": "http://arxiv.org/abs/2508.07675v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RIS-Assisted NOMA with Partial CSI and Mutual Coupling: A Machine Learning Approach", "abstract": "Non-orthogonal multiple access (NOMA) is a promising multiple access\ntechnique. Its performance depends strongly on the wireless channel property,\nwhich can be enhanced by reconfigurable intelligent surfaces (RISs). In this\npaper, we jointly optimize base station (BS) precoding and RIS configuration\nwith unsupervised machine learning (ML), which looks for the optimal solution\nautonomously. In particular, we propose a dedicated neural network (NN)\narchitecture RISnet inspired by domain knowledge in communication. Compared to\nstate-of-the-art, the proposed approach combines analytical optimal BS\nprecoding and ML-enabled RIS, has a high scalability to control more than 1000\nRIS elements, has a low requirement for channel state information (CSI) in\ninput, and addresses the mutual coupling between RIS elements. Beyond the\nconsidered problem, this work is an early contribution to domain knowledge\nenabled ML, which exploit the domain expertise of communication systems to\ndesign better approaches than general ML methods.", "published": "2025-08-11 12:24:41", "link": "http://arxiv.org/abs/2508.07909v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "DeCAL Tokenwise Compression", "abstract": "This paper introduces DeCAL, a new method for tokenwise compression. DeCAL\nuses an encoder-decoder language model pretrained with denoising to learn to\nproduce high-quality, general-purpose compressed representations by the\nencoder. DeCAL applies small modifications to the encoder, with the emphasis on\nmaximizing compression quality, even at the expense of compute. We show that\nDeCAL at 2x compression can match uncompressed on many downstream tasks, with\nusually only minor dropoff in metrics up to 8x compression, among\nquestion-answering, summarization, and multi-vector retrieval tasks. DeCAL\noffers significant savings where pre-computed dense representations can be\nutilized, and we believe the approach can be further developed to be more\nbroadly applicable.", "published": "2025-08-11 22:49:54", "link": "http://arxiv.org/abs/2508.08514v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression", "abstract": "Large language models (LLMs) are currently aligned using techniques such as\nreinforcement learning from human feedback (RLHF). However, these methods use\nscalar rewards that can only reflect user preferences on average. Pluralistic\nalignment instead seeks to capture diverse user preferences across a set of\nattributes, moving beyond just helpfulness and harmlessness. Toward this end,\nwe propose a steerable pluralistic model based on few-shot comparative\nregression that can adapt to individual user preferences. Our approach\nleverages in-context learning and reasoning, grounded in a set of fine-grained\nattributes, to compare response options and make aligned choices. To evaluate\nour algorithm, we also propose two new steerable pluralistic benchmarks by\nadapting the Moral Integrity Corpus (MIC) and the HelpSteer2 datasets,\ndemonstrating the applicability of our approach to value-aligned\ndecision-making and reward modeling, respectively. Our few-shot comparative\nregression approach is interpretable and compatible with different attributes\nand LLMs, while outperforming multiple baseline and state-of-the-art methods.\nOur work provides new insights and research directions in pluralistic\nalignment, enabling a more fair and representative use of LLMs and advancing\nthe state-of-the-art in ethical AI.", "published": "2025-08-11 22:40:31", "link": "http://arxiv.org/abs/2508.08509v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Re:Verse -- Can Your VLM Read a Manga?", "abstract": "Current Vision Language Models (VLMs) demonstrate a critical gap between\nsurface-level recognition and deep narrative reasoning when processing\nsequential visual storytelling. Through a comprehensive investigation of manga\nnarrative understanding, we reveal that while recent large multimodal models\nexcel at individual panel interpretation, they systematically fail at temporal\ncausality and cross-panel cohesion, core requirements for coherent story\ncomprehension. We introduce a novel evaluation framework that combines\nfine-grained multimodal annotation, cross-modal embedding analysis, and\nretrieval-augmented assessment to systematically characterize these\nlimitations.\n  Our methodology includes (i) a rigorous annotation protocol linking visual\nelements to narrative structure through aligned light novel text, (ii)\ncomprehensive evaluation across multiple reasoning paradigms, including direct\ninference and retrieval-augmented generation, and (iii) cross-modal similarity\nanalysis revealing fundamental misalignments in current VLMs' joint\nrepresentations. Applying this framework to Re:Zero manga across 11 chapters\nwith 308 annotated panels, we conduct the first systematic study of long-form\nnarrative understanding in VLMs through three core evaluation axes: generative\nstorytelling, contextual dialogue grounding, and temporal reasoning. Our\nfindings demonstrate that current models lack genuine story-level intelligence,\nstruggling particularly with non-linear narratives, character consistency, and\ncausal inference across extended sequences. This work establishes both the\nfoundation and practical methodology for evaluating narrative intelligence,\nwhile providing actionable insights into the capability of deep sequential\nunderstanding of Discrete Visual Narratives beyond basic recognition in\nMultimodal Models.", "published": "2025-08-11 22:40:05", "link": "http://arxiv.org/abs/2508.08508v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Momentum Point-Perplexity Mechanics in Large Language Models", "abstract": "We take a physics-based approach to studying how the internal hidden states\nof large language models change from token to token during inference. Across 20\nopen-source transformer models (135M-3B parameters), we find that a quantity\ncombining the rate of change in hidden states and the model's next-token\ncertainty, analogous to energy in physics, remains nearly constant.\nRandom-weight models conserve this \"energy\" more tightly than pre-trained ones,\nwhile training shifts models into a faster, more decisive regime with greater\nvariability. Using this \"log-Lagrangian\" view, we derive a control method\ncalled Jacobian steering, which perturbs hidden states in the minimal way\nneeded to favor a target token. This approach maintained near-constant energy\nin two tested models and produced continuations rated higher in semantic\nquality than the models' natural outputs. Viewing transformers through this\nmechanics lens offers a principled basis for interpretability, anomaly\ndetection, and low-risk steering. This could help make powerful models more\npredictable and aligned with human intent.", "published": "2025-08-11 21:50:34", "link": "http://arxiv.org/abs/2508.08492v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints", "abstract": "Small large language models (LLMs) often face difficulties in aligning output\nto human preferences, particularly when operating under severe performance\ngaps. In this work, we propose two lightweight DPO-based variants -- Adaptive\nMargin-Sigmoid Loss and APO-hinge-zero -- to better address underperformance\nscenarios by introducing margin-based objectives and selective update\nmechanisms.\n  Our APO-hinge-zero method, which combines hinge-induced hard-example mining\nwith the chosen-focused optimization of APO-zero, achieves strong results. In\nAlpacaEval, APO-hinge-zero improves the win rate by +2.0 points and the\nlength-controlled win rate by +1.4 points compared to the APO-zero baseline. In\nMT-Bench, our methods maintain competitive performance in diverse categories,\nparticularly excelling in STEM and Humanities tasks.\n  These results demonstrate that simple modifications to preference-based\nobjectives can significantly enhance small LLM alignment under resource\nconstraints, offering a practical path toward more efficient deployment.", "published": "2025-08-11 20:53:37", "link": "http://arxiv.org/abs/2508.08466v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment", "abstract": "Prior work on language modeling showed conflicting findings about whether\nmorphologically aligned approaches to tokenization improve performance,\nparticularly for languages with complex morphology. To investigate this, we\nselect a typologically diverse set of languages: Telugu (agglutinative), Hindi\n(primarily fusional with some agglutination), and English (fusional). We\nconduct a comprehensive evaluation of language models -- starting from\ntokenizer training and extending through the finetuning and downstream task\nevaluation. To account for the consistent performance differences observed\nacross tokenizer variants, we focus on two key factors: morphological alignment\nand tokenization quality. To assess morphological alignment of tokenizers in\nTelugu, we create a dataset containing gold morpheme segmentations of 600\nderivational and 7000 inflectional word forms.\n  Our experiments reveal that better morphological alignment correlates\npositively -- though moderately -- with performance in syntax-based tasks such\nas Parts-of-Speech tagging, Named Entity Recognition and Dependency Parsing.\nHowever, we also find that the tokenizer algorithm (Byte-pair Encoding vs.\nUnigram) plays a more significant role in influencing downstream performance\nthan morphological alignment alone. Naive Unigram tokenizers outperform others\nacross most settings, though hybrid tokenizers that incorporate morphological\nsegmentation significantly improve performance within the BPE framework. In\ncontrast, intrinsic metrics like Corpus Token Count (CTC) and R\\'enyi entropy\nshowed no correlation with downstream performance.", "published": "2025-08-11 19:23:59", "link": "http://arxiv.org/abs/2508.08424v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery", "abstract": "Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT)\nreasoning models like DeepSeek-R1 and QWQ, have demonstrated powerful reasoning\ncapabilities, achieving impressive performance in commonsense reasoning and\nmathematical inference. Despite their effectiveness, Long-CoT reasoning models\nare often criticized for their limited ability and low efficiency in\nknowledge-intensive domains such as molecule discovery. Success in this field\nrequires a precise understanding of domain knowledge, including molecular\nstructures and chemical principles, which is challenging due to the inherent\ncomplexity of molecular data and the scarcity of high-quality expert\nannotations. To bridge this gap, we introduce Mol-R1, a novel framework\ndesigned to improve explainability and reasoning performance of R1-like\nExplicit Long-CoT reasoning LLMs in text-based molecule generation. Our\napproach begins with a high-quality reasoning dataset curated through Prior\nRegulation via In-context Distillation (PRID), a dedicated distillation\nstrategy to effectively generate paired reasoning traces guided by prior\nregulations. Building upon this, we introduce MoIA, Molecular Iterative\nAdaptation, a sophisticated training strategy that iteratively combines\nSupervised Fine-tuning (SFT) with Reinforced Policy Optimization (RPO),\ntailored to boost the reasoning performance of R1-like reasoning models for\nmolecule discovery. Finally, we examine the performance of Mol-R1 in the\ntext-based molecule reasoning generation task, showing superior performance\nagainst existing baselines.", "published": "2025-08-11 18:50:05", "link": "http://arxiv.org/abs/2508.08401v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation", "abstract": "Large Language Models (LLMs) are increasingly employed as AI tutors due to\ntheir scalability and potential for personalized instruction. However,\noff-the-shelf LLMs often underperform in educational settings: they frequently\nreveal answers too readily, fail to adapt their responses to student\nuncertainty, and remain vulnerable to emotionally manipulative prompts. To\naddress these challenges, we introduce CoDAE, a framework that adapts LLMs for\neducational use through Chain-of-Thought (CoT) data augmentation. We collect\nreal-world dialogues between students and a ChatGPT-based tutor and enrich them\nusing CoT prompting to promote step-by-step reasoning and pedagogically aligned\nguidance. Furthermore, we design targeted dialogue cases to explicitly mitigate\nthree key limitations: over-compliance, low response adaptivity, and threat\nvulnerability. We fine-tune four open-source LLMs on different variants of the\naugmented datasets and evaluate them in simulated educational scenarios using\nboth automatic metrics and LLM-as-a-judge assessments. Our results show that\nmodels fine-tuned with CoDAE deliver more pedagogically appropriate guidance,\nbetter support reasoning processes, and effectively resist premature answer\ndisclosure.", "published": "2025-08-11 18:13:31", "link": "http://arxiv.org/abs/2508.08386v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning", "abstract": "We study an efficient implementation of Multi-Armed Bandit (MAB)-based\nMonte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is\nthat it spends a significant time deciding which node to expand next. While\nselecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity\nwith traditional array-based priority-queues for dense integer keys, the\ntree-based OPEN list used by MCTS requires $O(\\log N)$, which roughly\ncorresponds to the search depth $d$. In classical planning, $d$ is arbitrarily\nlarge (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node\nselection is significant, unlike in game tree search, where the cost is\nnegligible compared to the node evaluation (rollouts) because $d$ is inherently\nlimited by the game (e.g., $d\\leq 361$ in Go). To improve this bottleneck, we\npropose a bilevel modification to MCTS that runs a best-first search from each\nselected leaf node with an expansion budget proportional to $d$, which achieves\namortized $O(1)$ runtime for node selection, equivalent to the traditional\nqueue-based OPEN list. In addition, we introduce Tree Collapsing, an\nenhancement that reduces action selection steps and further improves the\nperformance.", "published": "2025-08-11 18:12:40", "link": "http://arxiv.org/abs/2508.08385v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Exploring the Technical Knowledge Interaction of Global Digital Humanities: Three-decade Evidence from Bibliometric-based perspectives", "abstract": "Digital Humanities (DH) is an interdisciplinary field that integrates\ncomputational methods with humanities scholarship to investigate innovative\ntopics. Each academic discipline follows a unique developmental path shaped by\nthe topics researchers investigate and the methods they employ. With the help\nof bibliometric analysis, most of previous studies have examined DH across\nmultiple dimensions such as research hotspots, co-author networks, and\ninstitutional rankings. However, these studies have often been limited in their\nability to provide deep insights into the current state of technological\nadvancements and topic development in DH. As a result, their conclusions tend\nto remain superficial or lack interpretability in understanding how methods and\ntopics interrelate in the field. To address this gap, this study introduced a\nnew concept of Topic-Method Composition (TMC), which refers to a hybrid\nknowledge structure generated by the co-occurrence of specific research topics\nand the corresponding method. Especially by analyzing the interaction between\nTMCs, we can see more clearly the intersection and integration of digital\ntechnology and humanistic subjects in DH. Moreover, this study developed a\nTMC-based workflow combining bibliometric analysis, topic modeling, and network\nanalysis to analyze the development characteristics and patterns of research\ndisciplines. By applying this workflow to large-scale bibliometric data, it\nenables a detailed view of the knowledge structures, providing a tool adaptable\nto other fields.", "published": "2025-08-11 12:27:39", "link": "http://arxiv.org/abs/2508.08347v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Maximizing GPU Efficiency via Optimal Adapter Caching: An Analytical Approach for Multi-Tenant LLM Serving", "abstract": "Serving LLM adapters has gained significant attention as an effective\napproach to adapt general-purpose language models to diverse, task-specific use\ncases. However, serving a wide range of adapters introduces several and\nsubstantial overheads, leading to performance degradation and challenges in\noptimal placement. To address these challenges, we present an analytical,\nAI-driven pipeline that accurately determines the optimal allocation of\nadapters in single-node setups. This allocation maximizes performance,\neffectively using GPU resources, while preventing request starvation.\nCrucially, the proposed allocation is given based on current workload patterns.\nThese insights in single-node setups can be leveraged in multi-replica\ndeployments for overall placement, load balancing and server configuration,\nultimately enhancing overall performance and improving resource efficiency. Our\napproach builds on an in-depth analysis of LLM adapter serving, accounting for\noverheads and performance variability, and includes the development of the\nfirst Digital Twin capable of replicating online LLM-adapter serving systems\nwith matching key performance metrics. The experimental results demonstrate\nthat the Digital Twin achieves a SMAPE difference of no more than 5.5% in\nthroughput compared to real results, and the proposed pipeline accurately\npredicts the optimal placement with minimal latency.", "published": "2025-08-11 10:47:35", "link": "http://arxiv.org/abs/2508.08343v1", "categories": ["cs.PF", "cs.AI", "cs.CL"], "primary_category": "cs.PF"}
{"title": "SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering", "abstract": "Access to real-world medical data is often restricted due to privacy\nregulations, posing a significant barrier to the advancement of healthcare\nresearch. Synthetic data offers a promising alternative; however, generating\nrealistic, clinically valid, and privacy-conscious records remains a major\nchallenge. Recent advancements in Large Language Models (LLMs) offer new\nopportunities for structured data generation; however, existing approaches\nfrequently lack systematic prompting strategies and comprehensive,\nmulti-dimensional evaluation frameworks.\n  In this paper, we present SynLLM, a modular framework for generating\nhigh-quality synthetic medical tabular data using 20 state-of-the-art\nopen-source LLMs, including LLaMA, Mistral, and GPT variants, guided by\nstructured prompts. We propose four distinct prompt types, ranging from\nexample-driven to rule-based constraints, that encode schema, metadata, and\ndomain knowledge to control generation without model fine-tuning. Our framework\nfeatures a comprehensive evaluation pipeline that rigorously assesses generated\ndata across statistical fidelity, clinical consistency, and privacy\npreservation.\n  We evaluate SynLLM across three public medical datasets, including Diabetes,\nCirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt\nengineering significantly impacts data quality and privacy risk, with\nrule-based prompts achieving the best privacy-quality balance. SynLLM\nestablishes that, when guided by well-designed prompts and evaluated with\nrobust, multi-metric criteria, LLMs can generate synthetic medical data that is\nboth clinically plausible and privacy-aware, paving the way for safer and more\neffective data sharing in healthcare research.", "published": "2025-08-11 23:56:42", "link": "http://arxiv.org/abs/2508.08529v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Playing Atari Space Invaders with Sparse Cosine Optimized Policy Evolution", "abstract": "Evolutionary approaches have previously been shown to be effective learning\nmethods for a diverse set of domains. However, the domain of game-playing poses\na particular challenge for evolutionary methods due to the inherently large\nstate space of video games. As the size of the input state expands, the size of\nthe policy must also increase in order to effectively learn the temporal\npatterns in the game space. Consequently, a larger policy must contain more\ntrainable parameters, exponentially increasing the size of the search space.\nAny increase in search space is highly problematic for evolutionary methods, as\nincreasing the number of trainable parameters is inversely correlated with\nconvergence speed. To reduce the size of the input space while maintaining a\nmeaningful representation of the original space, we introduce Sparse Cosine\nOptimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine\nTransform (DCT) as a pseudo attention mechanism, transforming an input state\ninto a coefficient matrix. By truncating and applying sparsification to this\nmatrix, we reduce the dimensionality of the input space while retaining the\nhighest energy features of the original input. We demonstrate the effectiveness\nof SCOPE as the policy for the Atari game Space Invaders. In this task, SCOPE\nwith CMA-ES outperforms evolutionary methods that consider an unmodified input\nstate, such as OpenAI-ES and HyperNEAT. SCOPE also outperforms simple\nreinforcement learning methods, such as DQN and A3C. SCOPE achieves this result\nthrough reducing the input size by 53% from 33,600 to 15,625 then using a\nbilinear affine mapping of sparse DCT coefficients to policy actions learned by\nthe CMA-ES algorithm.", "published": "2025-08-11 23:44:08", "link": "http://arxiv.org/abs/2508.08526v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI", "abstract": "Interactive streetscape mapping tools such as Google Street View (GSV) and\nMeta Mapillary enable users to virtually navigate and experience real-world\nenvironments via immersive 360{\\deg} imagery but remain fundamentally\ninaccessible to blind users. We introduce StreetViewAI, the first-ever\naccessible street view tool, which combines context-aware, multimodal AI,\naccessible navigation controls, and conversational speech. With StreetViewAI,\nblind users can virtually examine destinations, engage in open-world\nexploration, or virtually tour any of the over 220 billion images and 100+\ncountries where GSV is deployed. We iteratively designed StreetViewAI with a\nmixed-visual ability team and performed an evaluation with eleven blind users.\nOur findings demonstrate the value of an accessible street view in supporting\nPOI investigations and remote route planning. We close by enumerating key\nguidelines for future work.", "published": "2025-08-11 23:30:39", "link": "http://arxiv.org/abs/2508.08524v1", "categories": ["cs.HC", "cs.AI", "H.5; I.2"], "primary_category": "cs.HC"}
{"title": "VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models", "abstract": "Vision Language Models (VLMs) are increasingly being used in a broad range of\napplications, bringing their security and behavioral control to the forefront.\nWhile existing approaches for behavioral control or output redirection, like\nsystem prompting in VLMs, are easily detectable and often ineffective,\nactivation-based steering vectors require invasive runtime access to model\ninternals--incompatible with API-based services and closed-source deployments.\nWe introduce VISOR (Visual Input-based Steering for Output Redirection), a\nnovel method that achieves sophisticated behavioral control through optimized\nvisual inputs alone. By crafting universal steering images that induce target\nactivation patterns, VISOR enables practical deployment across all VLM serving\nmodalities while remaining imperceptible compared to explicit textual\ninstructions. We validate VISOR on LLaVA-1.5-7B across three critical alignment\ntasks: refusal, sycophancy and survival instinct. A single 150KB steering image\nmatches steering vector performance within 1-2% for positive behavioral shifts\nwhile dramatically exceeding it for negative steering--achieving up to 25%\nshifts from baseline compared to steering vectors' modest changes. Unlike\nsystem prompting (3-4% shifts), VISOR provides robust bidirectional control\nwhile maintaining 99.9% performance on 14,000 unrelated MMLU tasks. Beyond\neliminating runtime overhead and model access requirements, VISOR exposes a\ncritical security vulnerability: adversaries can achieve sophisticated\nbehavioral manipulation through visual channels alone, bypassing text-based\ndefenses. Our work fundamentally re-imagines multimodal model control and\nhighlights the urgent need for defenses against visual steering attacks.", "published": "2025-08-11 23:25:16", "link": "http://arxiv.org/abs/2508.08521v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Using LLMs to Capture Users' Temporal Context for Recommendation", "abstract": "Effective recommender systems demand dynamic user understanding, especially\nin complex, evolving environments. Traditional user profiling often fails to\ncapture the nuanced, temporal contextual factors of user preferences, such as\ntransient short-term interests and enduring long-term tastes. This paper\npresents an assessment of Large Language Models (LLMs) for generating\nsemantically rich, time-aware user profiles. We do not propose a novel\nend-to-end recommendation architecture; instead, the core contribution is a\nsystematic investigation into the degree of LLM effectiveness in capturing the\ndynamics of user context by disentangling short-term and long-term preferences.\nThis approach, framing temporal preferences as dynamic user contexts for\nrecommendations, adaptively fuses these distinct contextual components into\ncomprehensive user embeddings. The evaluation across Movies&TV and Video Games\ndomains suggests that while LLM-generated profiles offer semantic depth and\ntemporal structure, their effectiveness for context-aware recommendations is\nnotably contingent on the richness of user interaction histories. Significant\ngains are observed in dense domains (e.g., Movies&TV), whereas improvements are\nless pronounced in sparse environments (e.g., Video Games). This work\nhighlights LLMs' nuanced potential in enhancing user profiling for adaptive,\ncontext-aware recommendations, emphasizing the critical role of dataset\ncharacteristics for practical applicability.", "published": "2025-08-11 22:48:31", "link": "http://arxiv.org/abs/2508.08512v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "SharpXR: Structure-Aware Denoising for Pediatric Chest X-Rays", "abstract": "Pediatric chest X-ray imaging is essential for early diagnosis, particularly\nin low-resource settings where advanced imaging modalities are often\ninaccessible. Low-dose protocols reduce radiation exposure in children but\nintroduce substantial noise that can obscure critical anatomical details.\nConventional denoising methods often degrade fine details, compromising\ndiagnostic accuracy. In this paper, we present SharpXR, a structure-aware\ndual-decoder U-Net designed to denoise low-dose pediatric X-rays while\npreserving diagnostically relevant features. SharpXR combines a\nLaplacian-guided edge-preserving decoder with a learnable fusion module that\nadaptively balances noise suppression and structural detail retention. To\naddress the scarcity of paired training data, we simulate realistic\nPoisson-Gaussian noise on the Pediatric Pneumonia Chest X-ray dataset. SharpXR\noutperforms state-of-the-art baselines across all evaluation metrics while\nmaintaining computational efficiency suitable for resource-constrained\nsettings. SharpXR-denoised images improved downstream pneumonia classification\naccuracy from 88.8% to 92.5%, underscoring its diagnostic value in low-resource\npediatric care.", "published": "2025-08-11 23:07:20", "link": "http://arxiv.org/abs/2508.08518v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CObL: Toward Zero-Shot Ordinal Layering without User Prompting", "abstract": "Vision benefits from grouping pixels into objects and understanding their\nspatial relationships, both laterally and in depth. We capture this with a\nscene representation comprising an occlusion-ordered stack of \"object layers,\"\neach containing an isolated and amodally-completed object. To infer this\nrepresentation from an image, we introduce a diffusion-based architecture named\nConcurrent Object Layers (CObL). CObL generates a stack of object layers in\nparallel, using Stable Diffusion as a prior for natural objects and\ninference-time guidance to ensure the inferred layers composite back to the\ninput image. We train CObL using a few thousand synthetically-generated images\nof multi-object tabletop scenes, and we find that it zero-shot generalizes to\nphotographs of real-world tabletops with varying numbers of novel objects. In\ncontrast to recent models for amodal object completion, CObL reconstructs\nmultiple occluded objects without user prompting and without knowing the number\nof objects beforehand. Unlike previous models for unsupervised object-centric\nrepresentation learning, CObL is not limited to the world it was trained in.", "published": "2025-08-11 22:08:57", "link": "http://arxiv.org/abs/2508.08498v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MuGa-VTON: Multi-Garment Virtual Try-On via Diffusion Transformers with Prompt Customization", "abstract": "Virtual try-on seeks to generate photorealistic images of individuals in\ndesired garments, a task that must simultaneously preserve personal identity\nand garment fidelity for practical use in fashion retail and personalization.\nHowever, existing methods typically handle upper and lower garments separately,\nrely on heavy preprocessing, and often fail to preserve person-specific cues\nsuch as tattoos, accessories, and body shape-resulting in limited realism and\nflexibility. To this end, we introduce MuGa-VTON, a unified multi-garment\ndiffusion framework that jointly models upper and lower garments together with\nperson identity in a shared latent space. Specifically, we proposed three key\nmodules: the Garment Representation Module (GRM) for capturing both garment\nsemantics, the Person Representation Module (PRM) for encoding identity and\npose cues, and the A-DiT fusion module, which integrates garment, person, and\ntext-prompt features through a diffusion transformer. This architecture\nsupports prompt-based customization, allowing fine-grained garment\nmodifications with minimal user input. Extensive experiments on the VITON-HD\nand DressCode benchmarks demonstrate that MuGa-VTON outperforms existing\nmethods in both qualitative and quantitative evaluations, producing\nhigh-fidelity, identity-preserving results suitable for real-world virtual\ntry-on applications.", "published": "2025-08-11 21:45:07", "link": "http://arxiv.org/abs/2508.08488v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling", "abstract": "Despite recent advances, long-sequence video generation frameworks still\nsuffer from significant limitations: poor assistive capability, suboptimal\nvisual quality, and limited expressiveness. To mitigate these limitations, we\npropose MAViS, an end-to-end multi-agent collaborative framework for\nlong-sequence video storytelling. MAViS orchestrates specialized agents across\nmultiple stages, including script writing, shot designing, character modeling,\nkeyframe generation, video animation, and audio generation. In each stage,\nagents operate under the 3E Principle -- Explore, Examine, and Enhance -- to\nensure the completeness of intermediate outputs. Considering the capability\nlimitations of current generative models, we propose the Script Writing\nGuidelines to optimize compatibility between scripts and generative tools.\nExperimental results demonstrate that MAViS achieves state-of-the-art\nperformance in assistive capability, visual quality, and video expressiveness.\nIts modular framework further enables scalability with diverse generative\nmodels and tools. With just a brief user prompt, MAViS is capable of producing\nhigh-quality, expressive long-sequence video storytelling, enriching\ninspirations and creativity for users. To the best of our knowledge, MAViS is\nthe only framework that provides multimodal design output -- videos with\nnarratives and background music.", "published": "2025-08-11 21:42:41", "link": "http://arxiv.org/abs/2508.08487v1", "categories": ["cs.CV", "cs.AI", "cs.MA"], "primary_category": "cs.CV"}
{"title": "Enhanced Liver Tumor Detection in CT Images Using 3D U-Net and Bat Algorithm for Hyperparameter Optimization", "abstract": "Liver cancer is one of the most prevalent and lethal forms of cancer, making\nearly detection crucial for effective treatment. This paper introduces a novel\napproach for automated liver tumor segmentation in computed tomography (CT)\nimages by integrating a 3D U-Net architecture with the Bat Algorithm for\nhyperparameter optimization. The method enhances segmentation accuracy and\nrobustness by intelligently optimizing key parameters like the learning rate\nand batch size. Evaluated on a publicly available dataset, our model\ndemonstrates a strong ability to balance precision and recall, with a high\nF1-score at lower prediction thresholds. This is particularly valuable for\nclinical diagnostics, where ensuring no potential tumors are missed is\nparamount. Our work contributes to the field of medical image analysis by\ndemonstrating that the synergy between a robust deep learning architecture and\na metaheuristic optimization algorithm can yield a highly effective solution\nfor complex segmentation tasks.", "published": "2025-08-11 20:21:30", "link": "http://arxiv.org/abs/2508.08452v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Preprocessing Algorithm Leveraging Geometric Modeling for Scale Correction in Hyperspectral Images for Improved Unmixing Performance", "abstract": "Spectral variability significantly impacts the accuracy and convergence of\nhyperspectral unmixing algorithms. While many methods address complex spectral\nvariability, large-scale variations in spectral signature scale caused by\nfactors such as topography, illumination, and shadowing remain a major\nchallenge. These variations often degrade unmixing performance and complicate\nmodel fitting. In this paper, we propose a novel preprocessing algorithm that\ncorrects scale-induced spectral variability prior to unmixing. By isolating and\ncompensating for these large-scale multiplicative effects, the algorithm\nprovides a cleaner input, enabling unmixing methods to focus more effectively\non modeling nonlinear spectral variability and abundance estimation. We present\na rigorous mathematical framework to describe scale variability and extensive\nexperimental validation of the proposed algorithm. Furthermore, the algorithm's\nimpact is evaluated across a broad spectrum of state-of-the-art unmixing\nalgorithms on two synthetic and two real hyperspectral datasets. The proposed\npreprocessing step consistently improves the performance of these algorithms,\nincluding those specifically designed to handle spectral variability, with\nerror reductions close to 50% in many cases. This demonstrates that scale\ncorrection acts as a complementary step, facilitating more accurate unmixing by\nexisting methods. The algorithm's generality and significant impact highlight\nits potential as a key component in practical hyperspectral unmixing pipelines.\nThe implementation code will be made publicly available upon publication.", "published": "2025-08-11 19:42:35", "link": "http://arxiv.org/abs/2508.08431v1", "categories": ["eess.IV", "cs.CV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Improving Facial Rig Semantics for Tracking and Retargeting", "abstract": "In this paper, we consider retargeting a tracked facial performance to either\nanother person or to a virtual character in a game or virtual reality (VR)\nenvironment. We remove the difficulties associated with identifying and\nretargeting the semantics of one rig framework to another by utilizing the same\nframework (3DMM, FLAME, MetaHuman, etc.) for both subjects. Although this does\nnot constrain the choice of framework when retargeting from one person to\nanother, it does force the tracker to use the game/VR character rig when\nretargeting to a game/VR character. We utilize volumetric morphing in order to\nfit facial rigs to both performers and targets; in addition, a carefully chosen\nset of Simon-Says expressions is used to calibrate each rig to the motion\nsignatures of the relevant performer or target. Although a uniform set of\nSimon-Says expressions can likely be used for all person to person retargeting,\nwe argue that person to game/VR character retargeting benefits from Simon-Says\nexpressions that capture the distinct motion signature of the game/VR character\nrig. The Simon-Says calibrated rigs tend to produce the desired expressions\nwhen exercising animation controls (as expected). Unfortunately, these\nwell-calibrated rigs still lead to undesirable controls when tracking a\nperformance (a well-behaved function can have an arbitrarily ill-conditioned\ninverse), even though they typically produce acceptable geometry\nreconstructions. Thus, we propose a fine-tuning approach that modifies the rig\nused by the tracker in order to promote the output of more semantically\nmeaningful animation controls, facilitating high efficacy retargeting. In order\nto better address real-world scenarios, the fine-tuning relies on implicit\ndifferentiation so that the tracker can be treated as a (potentially\nnon-differentiable) black box.", "published": "2025-08-11 19:39:04", "link": "http://arxiv.org/abs/2508.08429v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Neural Tangent Knowledge Distillation for Optical Convolutional Networks", "abstract": "Hybrid Optical Neural Networks (ONNs, typically consisting of an optical\nfrontend and a digital backend) offer an energy-efficient alternative to fully\ndigital deep networks for real-time, power-constrained systems. However, their\nadoption is limited by two main challenges: the accuracy gap compared to\nlarge-scale networks during training, and discrepancies between simulated and\nfabricated systems that further degrade accuracy. While previous work has\nproposed end-to-end optimizations for specific datasets (e.g., MNIST) and\noptical systems, these approaches typically lack generalization across tasks\nand hardware designs. To address these limitations, we propose a task-agnostic\nand hardware-agnostic pipeline that supports image classification and\nsegmentation across diverse optical systems. To assist optical system design\nbefore training, we estimate achievable model accuracy based on user-specified\nconstraints such as physical size and the dataset. For training, we introduce\nNeural Tangent Knowledge Distillation (NTKD), which aligns optical models with\nelectronic teacher networks, thereby narrowing the accuracy gap. After\nfabrication, NTKD also guides fine-tuning of the digital backend to compensate\nfor implementation errors. Experiments on multiple datasets (e.g., MNIST,\nCIFAR, Carvana Masking) and hardware configurations show that our pipeline\nconsistently improves ONN performance and enables practical deployment in both\npre-fabrication simulations and physical implementations.", "published": "2025-08-11 19:15:06", "link": "http://arxiv.org/abs/2508.08421v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Spatiotemporally Consistent Indoor Lighting Estimation with Diffusion Priors", "abstract": "Indoor lighting estimation from a single image or video remains a challenge\ndue to its highly ill-posed nature, especially when the lighting condition of\nthe scene varies spatially and temporally. We propose a method that estimates\nfrom an input video a continuous light field describing the spatiotemporally\nvarying lighting of the scene. We leverage 2D diffusion priors for optimizing\nsuch light field represented as a MLP. To enable zero-shot generalization to\nin-the-wild scenes, we fine-tune a pre-trained image diffusion model to predict\nlighting at multiple locations by jointly inpainting multiple chrome balls as\nlight probes. We evaluate our method on indoor lighting estimation from a\nsingle image or video and show superior performance over compared baselines.\nMost importantly, we highlight results on spatiotemporally consistent lighting\nestimation from in-the-wild videos, which is rarely demonstrated in previous\nworks.", "published": "2025-08-11 18:11:42", "link": "http://arxiv.org/abs/2508.08384v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions", "abstract": "Object detection (OD) has become vital for numerous computer vision\napplications, but deploying it on resource-constrained IoT devices presents a\nsignificant challenge. These devices, often powered by energy-efficient\nmicrocontrollers, struggle to handle the computational load of deep\nlearning-based OD models. This issue is compounded by the rapid proliferation\nof IoT devices, predicted to surpass 150 billion by 2030. TinyML offers a\ncompelling solution by enabling OD on ultra-low-power devices, paving the way\nfor efficient and real-time processing at the edge. Although numerous survey\npapers have been published on this topic, they often overlook the optimization\nchallenges associated with deploying OD models in TinyML environments. To\naddress this gap, this survey paper provides a detailed analysis of key\noptimization techniques for deploying OD models on resource-constrained\ndevices. These techniques include quantization, pruning, knowledge\ndistillation, and neural architecture search. Furthermore, we explore both\ntheoretical approaches and practical implementations, bridging the gap between\nacademic research and real-world edge artificial intelligence deployment.\nFinally, we compare the key performance indicators (KPIs) of existing OD\nimplementations on microcontroller devices, highlighting the achieved maturity\nlevel of these solutions in terms of both prediction accuracy and efficiency.\nWe also provide a public repository to continually track developments in this\nfast-evolving field:\nhttps://github.com/christophezei/Optimizing-Object-Detection-Models-for-TinyML-A-Comprehensive-Survey.", "published": "2025-08-11 17:28:59", "link": "http://arxiv.org/abs/2508.08352v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search", "abstract": "The Trigger Arc Traveling Salesman Problem (TA-TSP) extends the classical TSP\nby introducing dynamic arc costs that change when specific \\textit{trigger}\narcs are traversed, modeling scenarios such as warehouse operations with\ncompactable storage systems. This paper introduces a GRASP-based metaheuristic\nthat combines multiple construction heuristics with a multi-neighborhood local\nsearch. The construction phase uses mixed-integer programming (MIP) techniques\nto transform the TA-TSP into a sequence of tailored TSP instances, while the\nimprovement phase applies 2-Opt, Swap, and Relocate operators. Computational\nexperiments on MESS 2024 competition instances achieved average optimality gaps\nof 0.77\\% and 0.40\\% relative to the best-known solutions within a 60-second\nlimit. On smaller, synthetically generated datasets, the method produced\nsolutions 11.3\\% better than the Gurobi solver under the same time constraints.\nThe algorithm finished in the top three at MESS 2024, demonstrating its\nsuitability for real-time routing applications with state-dependent travel\ncosts.", "published": "2025-08-11 21:24:38", "link": "http://arxiv.org/abs/2508.08477v1", "categories": ["cs.AI", "cs.DM"], "primary_category": "cs.AI"}
{"title": "Short Proof: Exact Solution to the Finite Frobenius Coin Problem", "abstract": "The Frobenius Coin Problem is a classic question in mathematics: given coins\nof specified denominations, what is the largest amount that cannot be formed\nusing only those coins? This brief work covers a variation of such question,\nposing a limit on the number of coins available for each denomination. Thus,\nthe new problem becomes finding the count of distinct values that can be\nrepresented, and those that cannot, within the finite set of integers ranging\nfrom zero to the sum of all coins. We refer to this version of the problem as\nthe \"finite\" case. We will show how this closely relates to the original\nquestion, and prove an exact formula solving the problem when exactly two\ndenominations are involved.", "published": "2025-08-11 20:45:28", "link": "http://arxiv.org/abs/2508.08464v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Temporal User Profiling with LLMs: Balancing Short-Term and Long-Term Preferences for Recommendations", "abstract": "Accurately modeling user preferences is crucial for improving the performance\nof content-based recommender systems. Existing approaches often rely on\nsimplistic user profiling methods, such as averaging or concatenating item\nembeddings, which fail to capture the nuanced nature of user preference\ndynamics, particularly the interactions between long-term and short-term\npreferences. In this work, we propose LLM-driven Temporal User Profiling\n(LLM-TUP), a novel method for user profiling that explicitly models short-term\nand long-term preferences by leveraging interaction timestamps and generating\nnatural language representations of user histories using a large language model\n(LLM). These representations are encoded into high-dimensional embeddings using\na pre-trained BERT model, and an attention mechanism is applied to dynamically\nfuse the short-term and long-term embeddings into a comprehensive user profile.\nExperimental results on real-world datasets demonstrate that LLM-TUP achieves\nsubstantial improvements over several baselines, underscoring the effectiveness\nof our temporally aware user-profiling approach and the use of semantically\nrich user profiles, generated by LLMs, for personalized content-based\nrecommendation.", "published": "2025-08-11 20:28:24", "link": "http://arxiv.org/abs/2508.08454v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Generating Query-Relevant Document Summaries via Reinforcement Learning", "abstract": "E-commerce search engines often rely solely on product titles as input for\nranking models with latency constraints. However, this approach can result in\nsuboptimal relevance predictions, as product titles often lack sufficient\ndetail to capture query intent. While product descriptions provide richer\ninformation, their verbosity and length make them unsuitable for real-time\nranking, particularly for computationally expensive architectures like\ncross-encoder ranking models. To address this challenge, we propose ReLSum, a\nnovel reinforcement learning framework designed to generate concise,\nquery-relevant summaries of product descriptions optimized for search\nrelevance. ReLSum leverages relevance scores as rewards to align the objectives\nof summarization and ranking, effectively overcoming limitations of prior\nmethods, such as misaligned learning targets. The framework employs a trainable\nlarge language model (LLM) to produce summaries, which are then used as input\nfor a cross-encoder ranking model. Experimental results demonstrate significant\nimprovements in offline metrics, including recall and NDCG, as well as online\nuser engagement metrics. ReLSum provides a scalable and efficient solution for\nenhancing search relevance in large-scale e-commerce systems.", "published": "2025-08-11 18:52:28", "link": "http://arxiv.org/abs/2508.08404v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Projection-based multifidelity linear regression for data-scarce applications", "abstract": "Surrogate modeling for systems with high-dimensional quantities of interest\nremains challenging, particularly when training data are costly to acquire.\nThis work develops multifidelity methods for multiple-input multiple-output\nlinear regression targeting data-limited applications with high-dimensional\noutputs. Multifidelity methods integrate many inexpensive low-fidelity model\nevaluations with limited, costly high-fidelity evaluations. We introduce two\nprojection-based multifidelity linear regression approaches that leverage\nprincipal component basis vectors for dimensionality reduction and combine\nmultifidelity data through: (i) a direct data augmentation using low-fidelity\ndata, and (ii) a data augmentation incorporating explicit linear corrections\nbetween low-fidelity and high-fidelity data. The data augmentation approaches\ncombine high-fidelity and low-fidelity data into a unified training set and\ntrain the linear regression model through weighted least squares with\nfidelity-specific weights. Various weighting schemes and their impact on\nregression accuracy are explored. The proposed multifidelity linear regression\nmethods are demonstrated on approximating the surface pressure field of a\nhypersonic vehicle in flight. In a low-data regime of no more than ten\nhigh-fidelity samples, multifidelity linear regression achieves approximately\n3% - 12% improvement in median accuracy compared to single-fidelity methods\nwith comparable computational cost.", "published": "2025-08-11 22:55:04", "link": "http://arxiv.org/abs/2508.08517v1", "categories": ["stat.ML", "cs.CE", "cs.LG"], "primary_category": "stat.ML"}
{"title": "When the Domain Expert Has No Time and the LLM Developer Has No Clinical Expertise: Real-World Lessons from LLM Co-Design in a Safety-Net Hospital", "abstract": "Large language models (LLMs) have the potential to address social and\nbehavioral determinants of health by transforming labor intensive workflows in\nresource-constrained settings. Creating LLM-based applications that serve the\nneeds of underserved communities requires a deep understanding of their local\ncontext, but it is often the case that neither LLMs nor their developers\npossess this local expertise, and the experts in these communities often face\nsevere time/resource constraints. This creates a disconnect: how can one engage\nin meaningful co-design of an LLM-based application for an under-resourced\ncommunity when the communication channel between the LLM developer and domain\nexpert is constrained? We explored this question through a real-world case\nstudy, in which our data science team sought to partner with social workers at\na safety net hospital to build an LLM application that summarizes patients'\nsocial needs. Whereas prior works focus on the challenge of prompt tuning, we\nfound that the most critical challenge in this setting is the careful and\nprecise specification of \\what information to surface to providers so that the\nLLM application is accurate, comprehensive, and verifiable. Here we present a\nnovel co-design framework for settings with limited access to domain experts,\nin which the summary generation task is first decomposed into\nindividually-optimizable attributes and then each attribute is efficiently\nrefined and validated through a multi-tier cascading approach.", "published": "2025-08-11 22:34:23", "link": "http://arxiv.org/abs/2508.08504v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Benchmarking Federated Learning for Throughput Prediction in 5G Live Streaming Applications", "abstract": "Accurate and adaptive network throughput prediction is essential for\nlatency-sensitive and bandwidth-intensive applications in 5G and emerging 6G\nnetworks. However, most existing methods rely on centralized training with\nuniformly collected data, limiting their applicability in heterogeneous mobile\nenvironments with non-IID data distributions. This paper presents the first\ncomprehensive benchmarking of federated learning (FL) strategies for throughput\nprediction in realistic 5G edge scenarios. We evaluate three aggregation\nalgorithms - FedAvg, FedProx, and FedBN - across four time-series\narchitectures: LSTM, CNN, CNN+LSTM, and Transformer, using five diverse\nreal-world datasets. We systematically analyze the effects of client\nheterogeneity, cohort size, and history window length on prediction\nperformance. Our results reveal key trade-offs among model complexities,\nconvergence rates, and generalization. It is found that FedBN consistently\ndelivers robust performance under non-IID conditions. On the other hand, LSTM\nand Transformer models outperform CNN-based baselines by up to 80% in R2\nscores. Moreover, although Transformers converge in half the rounds of LSTM,\nthey require longer history windows to achieve a high R2, indicating higher\ncontext dependence. LSTM is, therefore, found to achieve a favorable balance\nbetween accuracy, rounds, and temporal footprint. To validate the end-to-end\napplicability of the framework, we have integrated our FL-based predictors into\na live adaptive streaming pipeline. It is seen that FedBN-based LSTM and\nTransformer models improve mean QoE scores by 11.7% and 11.4%, respectively,\nover FedAvg, while also reducing the variance. These findings offer actionable\ninsights for building scalable, privacy-preserving, and edge-aware throughput\nprediction systems in next-generation wireless networks.", "published": "2025-08-11 21:27:40", "link": "http://arxiv.org/abs/2508.08479v1", "categories": ["cs.DC", "cs.LG", "14J60", "F.2.2; I.2.7"], "primary_category": "cs.DC"}
{"title": "Sparse Partial Optimal Transport via Quadratic Regularization", "abstract": "Partial Optimal Transport (POT) has recently emerged as a central tool in\nvarious Machine Learning (ML) applications. It lifts the stringent assumption\nof the conventional Optimal Transport (OT) that input measures are of equal\nmasses, which is often not guaranteed in real-world datasets, and thus offers\ngreater flexibility by permitting transport between unbalanced input measures.\nNevertheless, existing major solvers for POT commonly rely on entropic\nregularization for acceleration and thus return dense transport plans,\nhindering the adoption of POT in various applications that favor sparsity. In\nthis paper, as an alternative approach to the entropic POT formulation in the\nliterature, we propose a novel formulation of POT with quadratic\nregularization, hence termed quadratic regularized POT (QPOT), which induces\nsparsity to the transport plan and consequently facilitates the adoption of POT\nin many applications with sparsity requirements. Extensive experiments on\nsynthetic and CIFAR-10 datasets, as well as real-world applications such as\ncolor transfer and domain adaptations, consistently demonstrate the improved\nsparsity and favorable performance of our proposed QPOT formulation.", "published": "2025-08-11 21:22:35", "link": "http://arxiv.org/abs/2508.08476v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Discrete Diffusion-Based Model-Level Explanation of Heterogeneous GNNs with Node Features", "abstract": "Many real-world datasets, such as citation networks, social networks, and\nmolecular structures, are naturally represented as heterogeneous graphs, where\nnodes belong to different types and have additional features. For example, in a\ncitation network, nodes representing \"Paper\" or \"Author\" may include attributes\nlike keywords or affiliations. A critical machine learning task on these graphs\nis node classification, which is useful for applications such as fake news\ndetection, corporate risk assessment, and molecular property prediction.\nAlthough Heterogeneous Graph Neural Networks (HGNNs) perform well in these\ncontexts, their predictions remain opaque. Existing post-hoc explanation\nmethods lack support for actual node features beyond one-hot encoding of node\ntype and often fail to generate realistic, faithful explanations. To address\nthese gaps, we propose DiGNNExplainer, a model-level explanation approach that\nsynthesizes heterogeneous graphs with realistic node features via discrete\ndenoising diffusion. In particular, we generate realistic discrete features\n(e.g., bag-of-words features) using diffusion models within a discrete space,\nwhereas previous approaches are limited to continuous spaces. We evaluate our\napproach on multiple datasets and show that DiGNNExplainer produces\nexplanations that are realistic and faithful to the model's decision-making,\noutperforming state-of-the-art methods.", "published": "2025-08-11 20:33:10", "link": "http://arxiv.org/abs/2508.08458v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Differentiable Cyclic Causal Discovery Under Unmeasured Confounders", "abstract": "Understanding causal relationships between variables is fundamental across\nscientific disciplines. Most causal discovery algorithms rely on two key\nassumptions: (i) all variables are observed, and (ii) the underlying causal\ngraph is acyclic. While these assumptions simplify theoretical analysis, they\nare often violated in real-world systems, such as biological networks. Existing\nmethods that account for confounders either assume linearity or struggle with\nscalability. To address these limitations, we propose DCCD-CONF, a novel\nframework for differentiable learning of nonlinear cyclic causal graphs in the\npresence of unmeasured confounders using interventional data. Our approach\nalternates between optimizing the graph structure and estimating the confounder\ndistribution by maximizing the log-likelihood of the data. Through experiments\non synthetic data and real-world gene perturbation datasets, we show that\nDCCD-CONF outperforms state-of-the-art methods in both causal graph recovery\nand confounder identification. Additionally, we also provide consistency\nguarantees for our framework, reinforcing its theoretical soundness.", "published": "2025-08-11 20:13:34", "link": "http://arxiv.org/abs/2508.08450v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Selective KV-Cache Sharing to Mitigate Timing Side-Channels in LLM Inference", "abstract": "Global KV-cache sharing has emerged as a key optimization for accelerating\nlarge language model (LLM) inference. However, it exposes a new class of timing\nside-channel attacks, enabling adversaries to infer sensitive user inputs via\nshared cache entries. Existing defenses, such as per-user isolation, eliminate\nleakage but degrade performance by up to 38.9% in time-to-first-token (TTFT),\nmaking them impractical for high-throughput deployment. To address this gap, we\nintroduce SafeKV (Secure and Flexible KV Cache Sharing), a privacy-aware\nKV-cache management framework that selectively shares non-sensitive entries\nwhile confining sensitive content to private caches. SafeKV comprises three\ncomponents: (i) a hybrid, multi-tier detection pipeline that integrates\nrule-based pattern matching, a general-purpose privacy detector, and\ncontext-aware validation; (ii) a unified radix-tree index that manages public\nand private entries across heterogeneous memory tiers (HBM, DRAM, SSD); and\n(iii) entropy-based access monitoring to detect and mitigate residual\ninformation leakage. Our evaluation shows that SafeKV mitigates 94% - 97% of\ntiming-based side-channel attacks. Compared to per-user isolation method,\nSafeKV improves TTFT by up to 40.58% and throughput by up to 2.66X across\ndiverse LLMs and workloads. SafeKV reduces cache-induced TTFT overhead from\n50.41% to 11.74% on Qwen3-235B. By combining fine-grained privacy control with\nhigh cache reuse efficiency, SafeKV reclaims the performance advantages of\nglobal sharing while providing robust runtime privacy guarantees for LLM\ninference.", "published": "2025-08-11 19:55:44", "link": "http://arxiv.org/abs/2508.08438v1", "categories": ["cs.CR", "cs.LG", "cs.OS"], "primary_category": "cs.CR"}
{"title": "Fast weight programming and linear transformers: from machine learning to neurobiology", "abstract": "Recent advances in artificial neural networks for machine learning, and\nlanguage modeling in particular, have established a family of recurrent neural\nnetwork (RNN) architectures that, unlike conventional RNNs with vector-form\nhidden states, use two-dimensional (2D) matrix-form hidden states. Such\n2D-state RNNs, known as Fast Weight Programmers (FWPs), can be interpreted as a\nneural network whose synaptic weights (called fast weights) dynamically change\nover time as a function of input observations, and serve as short-term memory\nstorage; corresponding synaptic weight modifications are controlled or\nprogrammed by another network (the programmer) whose parameters are trained\n(e.g., by gradient descent). In this Primer, we review the technical\nfoundations of FWPs, their computational characteristics, and their connections\nto transformers and state space models. We also discuss connections between\nFWPs and models of synaptic plasticity in the brain, suggesting a convergence\nof natural and artificial intelligence.", "published": "2025-08-11 19:50:03", "link": "http://arxiv.org/abs/2508.08435v1", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Regret minimization in Linear Bandits with offline data via extended D-optimal exploration", "abstract": "We consider the problem of online regret minimization in linear bandits with\naccess to prior observations (offline data) from the underlying bandit model.\nThere are numerous applications where extensive offline data is often\navailable, such as in recommendation systems, online advertising. Consequently,\nthis problem has been studied intensively in recent literature. Our algorithm,\nOffline-Online Phased Elimination (OOPE), effectively incorporates the offline\ndata to substantially reduce the online regret compared to prior work. To\nleverage offline information prudently, OOPE uses an extended D-optimal design\nwithin each exploration phase. OOPE achieves an online regret is\n$\\tilde{O}(\\sqrt{\\deff T \\log \\left(|\\mathcal{A}|T\\right)}+d^2)$. $\\deff \\leq\nd)$ is the effective problem dimension which measures the number of poorly\nexplored directions in offline data and depends on the eigen-spectrum\n$(\\lambda_k)_{k \\in [d]}$ of the Gram matrix of the offline data. The\neigen-spectrum $(\\lambda_k)_{k \\in [d]}$ is a quantitative measure of the\n\\emph{quality} of offline data. If the offline data is poorly explored ($\\deff\n\\approx d$), we recover the established regret bounds for purely online setting\nwhile, when offline data is abundant ($\\Toff >> T$) and well-explored ($\\deff =\no(1) $), the online regret reduces substantially. Additionally, we provide the\nfirst known minimax regret lower bounds in this setting that depend explicitly\non the quality of the offline data. These lower bounds establish the optimality\nof our algorithm in regimes where offline data is either well-explored or\npoorly explored. Finally, by using a Frank-Wolfe approximation to the extended\noptimal design we further improve the $O(d^{2})$ term to\n$O\\left(\\frac{d^{2}}{\\deff} \\min \\{ \\deff,1\\} \\right)$, which can be\nsubstantial in high dimensions with moderate quality of offline data $\\deff =\n\\Omega(1)$.", "published": "2025-08-11 19:14:56", "link": "http://arxiv.org/abs/2508.08420v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Scaled-Dot-Product Attention as One-Sided Entropic Optimal Transport", "abstract": "The scaled-dot-product attention (SDPA) mechanism is a core component of\nmodern deep learning, but its mathematical form is often motivated by\nheuristics. This work provides a first-principles justification for SDPA. We\nfirst show that the attention forward pass is the exact solution to a\ndegenerate, one-sided Entropic Optimal Transport (EOT) problem, which seeks a\ndistribution that maximizes similarity while being maximally entropic. This\noptimization perspective has a direct consequence for the backward pass. We\nprove that the standard gradient computed via backpropagation is mathematically\nidentical to an advantage-based policy gradient, a variance-reduced update rule\nfrom reinforcement learning. Crucially, we demonstrate that the EOT formulation\nof the forward pass induces a specific information geometry on the space of\nattention distributions. It is this geometry, characterized by the Fisher\nInformation Matrix, that dictates the precise form of the learning gradient,\nrevealing the advantage-based update as a natural consequence of the\noptimization problem being solved. This unified view reveals SDPA as a\nprincipled mechanism where the forward pass performs optimal inference and the\nbackward pass implements a rational, manifold-aware learning update.", "published": "2025-08-11 18:00:17", "link": "http://arxiv.org/abs/2508.08369v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The DNA of nuclear models: How AI predicts nuclear masses", "abstract": "Obtaining high-precision predictions of nuclear masses, or equivalently\nnuclear binding energies, $E_b$, remains an important goal in nuclear-physics\nresearch. Recently, many AI-based tools have shown promising results on this\ntask, some achieving precision that surpasses the best physics models. However,\nthe utility of these AI models remains in question given that predictions are\nonly useful where measurements do not exist, which inherently requires\nextrapolation away from the training (and testing) samples. Since AI models are\nlargely black boxes, the reliability of such an extrapolation is difficult to\nassess. We present an AI model that not only achieves cutting-edge precision\nfor $E_b$, but does so in an interpretable manner. For example, we find (and\nexplain why) that the most important dimensions of its internal representation\nform a double helix, where the analog of the hydrogen bonds in DNA here link\nthe number of protons and neutrons found in the most stable nucleus of each\nisotopic chain. Furthermore, we show that the AI prediction of $E_b$ can be\nfactorized and ordered hierarchically, with the most important terms\ncorresponding to well-known symbolic models (such as the famous liquid drop).\nRemarkably, the improvement of the AI model over symbolic ones can almost\nentirely be attributed to an observation made by Jaffe in 1969. The end result\nis a fully interpretable data-driven model of nuclear masses.", "published": "2025-08-11 18:00:17", "link": "http://arxiv.org/abs/2508.08370v1", "categories": ["nucl-th", "cs.AI", "cs.LG", "nucl-ex"], "primary_category": "nucl-th"}
{"title": "A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems", "abstract": "Collective behaviors such as swarming and flocking emerge from simple,\ndecentralized interactions in biological systems. Existing models, such as\nVicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber\nmodel imposes rigid formations, limiting their applicability in swarm robotics.\nTo address these limitations, this paper proposes a minimal yet expressive\nmodel that governs agent dynamics using relative positions, velocities, and\nlocal density, modulated by two tunable parameters: the spatial offset and\nkinetic offset. The model achieves spatially flexible, collision-free behaviors\nthat reflect naturalistic group dynamics. Furthermore, we extend the framework\nto cognitive autonomous systems, enabling energy-aware phase transitions\nbetween swarming and flocking through adaptive control parameter tuning. This\ncognitively inspired approach offers a robust foundation for real-world\napplications in multi-robot systems, particularly autonomous aerial swarms.", "published": "2025-08-11 21:15:32", "link": "http://arxiv.org/abs/2508.08473v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Efficient Computation of Dominant Eigenvalues Using Adaptive Block Lanczos with Chebyshev Filtering", "abstract": "We present an efficient method for computing dominant eigenvalues of large,\nnonsymmetric, diagonalizable matrices based on an adaptive block Lanczos\nalgorithm combined with Chebyshev polynomial filtering. The proposed approach\nimproves numerical stability through two key components: (i) the Adaptive Block\nLanczos (ABLE) method, which maintains biorthogonality using SVD based\nstabilization, and (ii) Chebyshev filtering, which enhances spectral separation\nvia iterative polynomial filtering. Numerical experiments on dense and sparse\ntest problems confirm the effectiveness of the ABLE Chebyshev algorithm.", "published": "2025-08-11 21:58:21", "link": "http://arxiv.org/abs/2508.08495v1", "categories": ["math.NA", "cs.NA", "F65"], "primary_category": "math.NA"}
{"title": "Exploring Disentangled Neural Speech Codecs from Self-Supervised Representations", "abstract": "Neural audio codecs (NACs), which use neural networks to generate compact\naudio representations, have garnered interest for their applicability to many\ndownstream tasks -- especially quantized codecs due to their compatibility with\nlarge language models. However, unlike text, speech conveys not only linguistic\ncontent but also rich paralinguistic features. Encoding these elements in an\nentangled fashion may be suboptimal, as it limits flexibility. For instance,\nvoice conversion (VC) aims to convert speaker characteristics while preserving\nthe original linguistic content, which requires a disentangled representation.\nInspired by VC methods utilizing $k$-means quantization with self-supervised\nfeatures to disentangle phonetic information, we develop a discrete NAC capable\nof structured disentanglement. Experimental evaluations show that our approach\nachieves reconstruction performance on par with conventional NACs that do not\nexplicitly perform disentanglement, while also matching the effectiveness of\nconventional VC techniques.", "published": "2025-08-11 18:44:56", "link": "http://arxiv.org/abs/2508.08399v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "AD-AVSR: Asymmetric Dual-stream Enhancement for Robust Audio-Visual Speech Recognition", "abstract": "Audio-visual speech recognition (AVSR) combines audio-visual modalities to\nimprove speech recognition, especially in noisy environments. However, most\nexisting methods deploy the unidirectional enhancement or symmetric fusion\nmanner, which limits their capability to capture heterogeneous and\ncomplementary correlations of audio-visual data-especially under asymmetric\ninformation conditions. To tackle these gaps, we introduce a new AVSR framework\ntermed AD-AVSR based on bidirectional modality enhancement. Specifically, we\nfirst introduce the audio dual-stream encoding strategy to enrich audio\nrepresentations from multiple perspectives and intentionally establish\nasymmetry to support subsequent cross-modal interactions. The enhancement\nprocess involves two key components, Audio-aware Visual Refinement Module for\nenhanced visual representations under audio guidance, and Cross-modal Noise\nSuppression Masking Module which refines audio representations using visual\ncues, collaboratively leading to the closed-loop and bidirectional information\nflow. To further enhance correlation robustness, we adopt a threshold-based\nselection mechanism to filter out irrelevant or weakly correlated audio-visual\npairs. Extensive experimental results on the LRS2 and LRS3 datasets indicate\nthat our AD-AVSR consistently surpasses SOTA methods in both performance and\nnoise robustness, highlighting the effectiveness of our model design.", "published": "2025-08-11 04:23:08", "link": "http://arxiv.org/abs/2508.07608v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Voice Pathology Detection Using Phonation", "abstract": "Voice disorders significantly affect communication and quality of life,\nrequiring an early and accurate diagnosis. Traditional methods like\nlaryngoscopy are invasive, subjective, and often inaccessible. This research\nproposes a noninvasive, machine learning-based framework for detecting voice\npathologies using phonation data.\n  Phonation data from the Saarbr\\\"ucken Voice Database are analyzed using\nacoustic features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma\nfeatures, and Mel spectrograms. Recurrent Neural Networks (RNNs), including\nLSTM and attention mechanisms, classify samples into normal and pathological\ncategories. Data augmentation techniques, including pitch shifting and Gaussian\nnoise addition, enhance model generalizability, while preprocessing ensures\nsignal quality. Scale-based features, such as H\\\"older and Hurst exponents,\nfurther capture signal irregularities and long-term dependencies.\n  The proposed framework offers a noninvasive, automated diagnostic tool for\nearly detection of voice pathologies, supporting AI-driven healthcare, and\nimproving patient outcomes.", "published": "2025-08-11 03:33:18", "link": "http://arxiv.org/abs/2508.07587v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Exploring Efficient Directional and Distance Cues for Regional Speech Separation", "abstract": "In this paper, we introduce a neural network-based method for regional speech\nseparation using a microphone array. This approach leverages novel spatial cues\nto extract the sound source not only from specified direction but also within\ndefined distance. Specifically, our method employs an improved delay-and-sum\ntechnique to obtain directional cues, substantially enhancing the signal from\nthe target direction. We further enhance separation by incorporating the\ndirect-to-reverberant ratio into the input features, enabling the model to\nbetter discriminate sources within and beyond a specified distance.\nExperimental results demonstrate that our proposed method leads to substantial\ngains across multiple objective metrics. Furthermore, our method achieves\nstate-of-the-art performance on the CHiME-8 MMCSG dataset, which was recorded\nin real-world conversational scenarios, underscoring its effectiveness for\nspeech separation in practical applications.", "published": "2025-08-11 02:52:46", "link": "http://arxiv.org/abs/2508.07563v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Small-footprint Acoustic Echo Cancellation Solution for Mobile Full-Duplex Speech Interactions", "abstract": "In full-duplex speech interaction systems, effective Acoustic Echo\nCancellation (AEC) is crucial for recovering echo-contaminated speech. This\npaper presents a neural network-based AEC solution to address challenges in\nmobile scenarios with varying hardware, nonlinear distortions and long latency.\nWe first incorporate diverse data augmentation strategies to enhance the\nmodel's robustness across various environments. Moreover, progressive learning\nis employed to incrementally improve AEC effectiveness, resulting in a\nconsiderable improvement in speech quality. To further optimize AEC's\ndownstream applications, we introduce a novel post-processing strategy\nemploying tailored parameters designed specifically for tasks such as Voice\nActivity Detection (VAD) and Automatic Speech Recognition (ASR), thus enhancing\ntheir overall efficacy. Finally, our method employs a small-footprint model\nwith streaming inference, enabling seamless deployment on mobile devices.\nEmpirical results demonstrate effectiveness of the proposed method in Echo\nReturn Loss Enhancement and Perceptual Evaluation of Speech Quality, alongside\nsignificant improvements in both VAD and ASR results.", "published": "2025-08-11 02:45:31", "link": "http://arxiv.org/abs/2508.07561v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Analytical and Experimental Study of Distributed Uplink Beamforming in the Presence of Carrier Frequency Offsets", "abstract": "Realizing distributed multi-user beamforming (D-MUBF) in time division duplex\n(TDD)-based multi-user MIMO (MU-MIMO) systems faces significant challenges. One\nof the most fundamental challenges is achieving accurate over-the-air (OTA)\ntiming and frequency synchronization among distributed access points (APs),\nparticularly due to residual frequency offsets caused by local oscillator (LO)\ndrifts. Despite decades of research on synchronization for MU-MIMO, there are\nonly a few experimental studies that evaluate D-MUBF techniques under imperfect\nfrequency synchronization among distributed antennas. This paper presents an\nanalytical and experimental assessment of D-MUBF methods in the presence of\nfrequency synchronization errors. We provide closed-form expressions for\nsignal-to-interference-plus-noise ratio (SINR) as a function of channel\ncharacteristics and statistical properties of carrier frequency offset (CFO)\namong AP antennas. In addition, through experimental evaluations conducted with\nthe RENEW massive MIMO testbed, we collected comprehensive datasets across\nvarious experimental scenarios. These datasets comprise uplink pilot samples\nfor channel and CFO estimation, in addition to uplink multi-user data intended\nfor analyzing D-MUBF techniques. By examining these datasets, we assess the\nperformance of D-MUBF in the presence of CFO and compare the analytical\npredictions with empirical measurements. Furthermore, we make the datasets\npublicly available and provide insights on utilizing them for future research\nendeavors.", "published": "2025-08-11 22:36:51", "link": "http://arxiv.org/abs/2508.08506v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Tensor-Structured Bayesian Channel Prediction for Upper Mid-Band XL-MIMO Systems", "abstract": "The upper mid-band balances coverage and capacity for the future cellular\nsystems and also embraces XL-MIMO systems, offering enhanced spectral and\nenergy efficiency. However, these benefits are significantly degraded under\nmobility due to channel aging, and further exacerbated by the unique near-field\n(NF) and spatial non-stationarity (SnS) propagation in such systems. To address\nthis challenge, we propose a novel channel prediction approach that\nincorporates dedicated channel modeling, probabilistic representations, and\nBayesian inference algorithms for this emerging scenario. Specifically, we\ndevelop tensor-structured channel models in both the spatial-frequency-temporal\n(SFT) and beam-delay-Doppler (BDD) domains, which leverage temporal\ncorrelations among multiple pilot symbols for channel prediction. The factor\nmatrices of multi-linear transformations are parameterized by BDD domain grids\nand SnS factors, where beam domain grids are jointly determined by angles and\nslopes under spatial-chirp based NF representations. To enable tractable\ninference, we replace environment-dependent BDD domain grids with uniformly\nsampled ones, and introduce perturbation parameters in each domain to mitigate\ngrid mismatch. We further propose a hybrid beam domain strategy that integrates\nangle-only sampling with slope hyperparameterization to avoid the computational\nburden of explicit slope sampling. Based on the probabilistic models, we\ndevelop tensor-structured bi-layer inference (TS-BLI) algorithm under the\nexpectation-maximization (EM) framework, which reduces computational complexity\nvia tensor operations by leveraging the bi-layer factor graph for approximate\nE-step inference and an alternating strategy with closed-form updates in the\nM-step. Numerical simulations based on the near-practical channel simulator\ndemonstrate the superior channel prediction performance of the proposed\nalgorithm.", "published": "2025-08-11 21:48:39", "link": "http://arxiv.org/abs/2508.08491v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Audio-Visual Speech Enhancement: Architectural Design and Deployment Strategies", "abstract": "This paper introduces a new AI-based Audio-Visual Speech Enhancement (AVSE)\nsystem and presents a comparative performance analysis of different deployment\narchitectures. The proposed AVSE system employs convolutional neural networks\n(CNNs) for spectral feature extraction and long short-term memory (LSTM)\nnetworks for temporal modeling, enabling robust speech enhancement through\nmultimodal fusion of audio and visual cues. Multiple deployment scenarios are\ninvestigated, including cloud-based, edge-assisted, and standalone device\nimplementations. Their performance is evaluated in terms of speech quality\nimprovement, latency, and computational overhead. Real-world experiments are\nconducted across various network conditions, including Ethernet, Wi-Fi, 4G, and\n5G, to analyze the trade-offs between processing delay, communication latency,\nand perceptual speech quality. The results show that while cloud deployment\nachieves the highest enhancement quality, edge-assisted architectures offer the\nbest balance between latency and intelligibility, meeting real-time\nrequirements under 5G and Wi-Fi 6 conditions. These findings provide practical\nguidelines for selecting and optimizing AVSE deployment architectures in\ndiverse applications, including assistive hearing devices, telepresence, and\nindustrial communications.", "published": "2025-08-11 21:01:19", "link": "http://arxiv.org/abs/2508.08468v1", "categories": ["cs.SD", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Hardware-friendly IR-HARQ for Polar SCL Decoders", "abstract": "To extend the applications of polar codes within next-generation wireless\ncommunication systems, it is essential to incorporate support for Incremental\nRedundancy (IR) Hybrid Automatic Repeat Request (HARQ) schemes. The baseline\nIR-HARQ scheme's reliance on set-based operations leads to irregular memory\naccess patterns, posing significant challenges for efficient hardware\nimplementation. Furthermore, the introduction of new bit types increases the\nnumber of fast nodes that are decoded without traversing the sub-tree,\nresulting in a substantial area overhead when implemented in hardware. To\naddress these issues and improve hardware compatibility, we propose\ntransforming the set-based operations within the polar IR-HARQ scheme into\nbinary vector operations. Additionally, we introduce a new fast node\nintegration approach that avoids increasing the number of fast nodes, thereby\nminimizing the associated area overhead. Our proposed scheme results in a\nmemory overhead of 25-27% compared to successive cancellation list (SCL)\ndecoding without IR-HARQ support.", "published": "2025-08-11 19:24:42", "link": "http://arxiv.org/abs/2508.08425v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Capabilities of GPT-5 on Multimodal Medical Reasoning", "abstract": "Recent advances in large language models (LLMs) have enabled general-purpose\nsystems to perform increasingly complex domain-specific reasoning without\nextensive fine-tuning. In the medical domain, decision-making often requires\nintegrating heterogeneous information sources, including patient narratives,\nstructured data, and medical images. This study positions GPT-5 as a generalist\nmultimodal reasoner for medical decision support and systematically evaluates\nits zero-shot chain-of-thought reasoning performance on both text-based\nquestion answering and visual question answering tasks under a unified\nprotocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20\nagainst standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU\nmedical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that\nGPT-5 consistently outperforms all baselines, achieving state-of-the-art\naccuracy across all QA benchmarks and delivering substantial gains in\nmultimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and\nunderstanding scores by +29.26% and +26.18% over GPT-4o, respectively, and\nsurpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in\nunderstanding. In contrast, GPT-4o remains below human expert performance in\nmost dimensions. A representative case study demonstrates GPT-5's ability to\nintegrate visual and textual cues into a coherent diagnostic reasoning chain,\nrecommending appropriate high-stakes interventions. Our results show that, on\nthese controlled multimodal reasoning benchmarks, GPT-5 moves from\nhuman-comparable to above human-expert performance. This improvement may\nsubstantially inform the design of future clinical decision-support systems.", "published": "2025-08-11 17:43:45", "link": "http://arxiv.org/abs/2508.08224v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL", "abstract": "Recent advancements in LLM-based agents have demonstrated remarkable\ncapabilities in handling complex, knowledge-intensive tasks by integrating\nexternal tools. Among diverse choices of tools, search tools play a pivotal\nrole in accessing vast external knowledge. However, open-source agents still\nfall short of achieving expert-level Search Intelligence, the ability to\nresolve ambiguous queries, generate precise searches, analyze results, and\nconduct thorough exploration. Existing approaches fall short in scalability,\nefficiency, and data quality. For example, small turn limits in existing online\nRL methods, e.g. <=10, restrict complex strategy learning. This paper\nintroduces ASearcher, an open-source project for large-scale RL training of\nsearch agents. Our key contributions include: (1) Scalable fully asynchronous\nRL training that enables long-horizon search while maintaining high training\nefficiency. (2) A prompt-based LLM agent that autonomously synthesizes\nhigh-quality and challenging QAs, creating a large-scale QA dataset. Through RL\ntraining, our prompt-based QwQ-32B agent achieves substantial improvements,\nwith 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our\nagent exhibits extreme long-horizon search, with tool calls exceeding 40 turns\nand output tokens exceeding 150k during training time. With a simple agent\ndesign and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on\nxBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We\nopen-source our models, training data, and codes in\nhttps://github.com/inclusionAI/ASearcher.", "published": "2025-08-11 13:36:57", "link": "http://arxiv.org/abs/2508.07976v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Remarks on the Brouwer Conjecture", "abstract": "The Brouwer conjecture (BC) in spectral graph theory claims that the sum of\nthe largest k Kirchhoff eigenvalues of a graph are bounded above by the number\nm of edges plus k(k+1)/2. We show that (BC) holds for all graphs with n\nvertices if n is larger or equal than 4 times the square of the maximal vertex\ndegree. We also note that (BC) for graphs implies (BC) for quivers.", "published": "2025-08-11 02:13:38", "link": "http://arxiv.org/abs/2508.07550v2", "categories": ["math.CO", "cs.DM", "05Cxx 05Exx 68Rxx"], "primary_category": "math.CO"}
{"title": "Regret minimization in Linear Bandits with offline data via extended D-optimal exploration", "abstract": "We consider the problem of online regret minimization in linear bandits with\naccess to prior observations (offline data) from the underlying bandit model.\nThere are numerous applications where extensive offline data is often\navailable, such as in recommendation systems, online advertising. Consequently,\nthis problem has been studied intensively in recent literature. Our algorithm,\nOffline-Online Phased Elimination (OOPE), effectively incorporates the offline\ndata to substantially reduce the online regret compared to prior work. To\nleverage offline information prudently, OOPE uses an extended D-optimal design\nwithin each exploration phase. OOPE achieves an online regret is\n$\\tilde{O}(\\sqrt{\\deff T \\log \\left(|\\mathcal{A}|T\\right)}+d^2)$. $\\deff \\leq\nd)$ is the effective problem dimension which measures the number of poorly\nexplored directions in offline data and depends on the eigen-spectrum\n$(\\lambda_k)_{k \\in [d]}$ of the Gram matrix of the offline data. The\neigen-spectrum $(\\lambda_k)_{k \\in [d]}$ is a quantitative measure of the\n\\emph{quality} of offline data. If the offline data is poorly explored ($\\deff\n\\approx d$), we recover the established regret bounds for purely online setting\nwhile, when offline data is abundant ($\\Toff >> T$) and well-explored ($\\deff =\no(1) $), the online regret reduces substantially. Additionally, we provide the\nfirst known minimax regret lower bounds in this setting that depend explicitly\non the quality of the offline data. These lower bounds establish the optimality\nof our algorithm in regimes where offline data is either well-explored or\npoorly explored. Finally, by using a Frank-Wolfe approximation to the extended\noptimal design we further improve the $O(d^{2})$ term to\n$O\\left(\\frac{d^{2}}{\\deff} \\min \\{ \\deff,1\\} \\right)$, which can be\nsubstantial in high dimensions with moderate quality of offline data $\\deff =\n\\Omega(1)$.", "published": "2025-08-11 19:14:56", "link": "http://arxiv.org/abs/2508.08420v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems", "abstract": "Collective behaviors such as swarming and flocking emerge from simple,\ndecentralized interactions in biological systems. Existing models, such as\nVicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber\nmodel imposes rigid formations, limiting their applicability in swarm robotics.\nTo address these limitations, this paper proposes a minimal yet expressive\nmodel that governs agent dynamics using relative positions, velocities, and\nlocal density, modulated by two tunable parameters: the spatial offset and\nkinetic offset. The model achieves spatially flexible, collision-free behaviors\nthat reflect naturalistic group dynamics. Furthermore, we extend the framework\nto cognitive autonomous systems, enabling energy-aware phase transitions\nbetween swarming and flocking through adaptive control parameter tuning. This\ncognitively inspired approach offers a robust foundation for real-world\napplications in multi-robot systems, particularly autonomous aerial swarms.", "published": "2025-08-11 21:15:32", "link": "http://arxiv.org/abs/2508.08473v2", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Composable Quantum Fault-Tolerance", "abstract": "Proving threshold theorems for fault-tolerant quantum computation is a\nburdensome endeavor with many moving parts that come together in relatively\nformulaic but lengthy ways. It is difficult and rare to combine elements from\nmultiple papers into a single formal threshold proof, due to the use of\ndifferent measures of fault-tolerance. In this work, we introduce composable\nfault-tolerance, a framework that decouples the probabilistic analysis of the\nnoise distribution from the combinatorial analysis of circuit correctness, and\nenables threshold proofs to compose independently analyzed gadgets easily and\nrigorously. Within this framework, we provide a library of standard and\ncommonly used gadgets such as memory and logic implemented by constant-depth\ncircuits for quantum low-density parity check codes and distillation. As sample\napplications, we explicitly write down a threshold proof for computation with\nsurface code and re-derive the constant space-overhead fault-tolerant scheme of\nGottesman using gadgets from this library. We expect that future\nfault-tolerance proofs may focus on the analysis of novel techniques while\nleaving the standard components to the composable fault-tolerance framework,\nwith the formal proof following the intuitive ``napkin math'' exactly.", "published": "2025-08-11 17:58:14", "link": "http://arxiv.org/abs/2508.08246v2", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "RIS-Assisted NOMA with Partial CSI and Mutual Coupling: A Machine Learning Approach", "abstract": "Non-orthogonal multiple access (NOMA) is a promising multiple access\ntechnique. Its performance depends strongly on the wireless channel property,\nwhich can be enhanced by reconfigurable intelligent surfaces (RISs). In this\npaper, we jointly optimize base station (BS) precoding and RIS configuration\nwith unsupervised machine learning (ML), which looks for the optimal solution\nautonomously. In particular, we propose a dedicated neural network (NN)\narchitecture RISnet inspired by domain knowledge in communication. Compared to\nstate-of-the-art, the proposed approach combines analytical optimal BS\nprecoding and ML-enabled RIS, has a high scalability to control more than 1000\nRIS elements, has a low requirement for channel state information (CSI) in\ninput, and addresses the mutual coupling between RIS elements. Beyond the\nconsidered problem, this work is an early contribution to domain knowledge\nenabled ML, which exploit the domain expertise of communication systems to\ndesign better approaches than general ML methods.", "published": "2025-08-11 12:24:41", "link": "http://arxiv.org/abs/2508.07909v3", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CleanCTG: A Deep Learning Model for Multi-Artefact Detection and Reconstruction in Cardiotocography", "abstract": "Cardiotocography (CTG) is essential for fetal monitoring but is frequently\ncompromised by diverse artefacts which obscure true fetal heart rate (FHR)\npatterns and can lead to misdiagnosis or delayed intervention. Current\ndeep-learning approaches typically bypass comprehensive noise handling,\napplying minimal preprocessing or focusing solely on downstream classification,\nwhile traditional methods rely on simple interpolation or rule-based filtering\nthat addresses only missing samples and fail to correct complex artefact types.\nWe present CleanCTG, an end-to-end dual-stage model that first identifies\nmultiple artefact types via multi-scale convolution and context-aware\ncross-attention, then reconstructs corrupted segments through artefact-specific\ncorrection branches. Training utilised over 800,000 minutes of physiologically\nrealistic, synthetically corrupted CTGs derived from expert-verified \"clean\"\nrecordings. On synthetic data, CleanCTG achieved perfect artefact detection\n(AU-ROC = 1.00) and reduced mean squared error (MSE) on corrupted segments to\n2.74 x 10^-4 (clean-segment MSE = 2.40 x 10^-6), outperforming the next best\nmethod by more than 60%. External validation on 10,190 minutes of\nclinician-annotated segments yielded AU-ROC = 0.95 (sensitivity = 83.44%,\nspecificity 94.22%), surpassing six comparator classifiers. Finally, when\nintegrated with the Dawes-Redman system on 933 clinical CTG recordings,\ndenoised traces increased specificity (from 80.70% to 82.70%) and shortened\nmedian time to decision by 33%. These findings suggest that explicit artefact\nremoval and signal reconstruction can both maintain diagnostic accuracy and\nenable shorter monitoring sessions, offering a practical route to more reliable\nCTG interpretation.", "published": "2025-08-11 11:24:45", "link": "http://arxiv.org/abs/2508.10928v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
