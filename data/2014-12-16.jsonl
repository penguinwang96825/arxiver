{"title": "Rehabilitation of Count-based Models for Word Vector Representations", "abstract": "Recent works on word representations mostly rely on predictive models.\nDistributed word representations (aka word embeddings) are trained to optimally\npredict the contexts in which the corresponding words tend to appear. Such\nmodels have succeeded in capturing word similarties as well as semantic and\nsyntactic regularities. Instead, we aim at reviving interest in a model based\non counts. We present a systematic study of the use of the Hellinger distance\nto extract semantic representations from the word co-occurence statistics of\nlarge text corpora. We show that this distance gives good performance on word\nsimilarity and analogy tasks, with a proper type and size of context, and a\ndimensionality reduction based on a stochastic low-rank approximation. Besides\nbeing both simple and intuitive, this method also provides an encoding function\nwhich can be used to infer unseen words or phrases. This becomes a clear\nadvantage compared to predictive models which must train these new words.", "published": "2014-12-16 09:43:56", "link": "http://arxiv.org/abs/1412.4930v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Application of Topic Models to Judgments from Public Procurement Domain", "abstract": "In this work, automatic analysis of themes contained in a large corpora of\njudgments from public procurement domain is performed. The employed technique\nis unsupervised latent Dirichlet allocation (LDA). In addition, it is proposed,\nto use LDA in conjunction with recently developed method of unsupervised\nkeyword extraction. Such an approach improves the interpretability of the\nautomatically obtained topics and allows for better computational performance.\nThe described analysis illustrates a potential of the method in detecting\nrecurring themes and discovering temporal trends in lodged contract appeals.\nThese results may be in future applied to improve information retrieval from\nrepositories of legal texts or as auxiliary material for legal analyses carried\nout by human experts.", "published": "2014-12-16 22:00:52", "link": "http://arxiv.org/abs/1412.5212v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling laws in human speech, decreasing emergence of new words and a\n  generalized model", "abstract": "Human language, as a typical complex system, its organization and evolution\nis an attractive topic for both physical and cultural researchers. In this\npaper, we present the first exhaustive analysis of the text organization of\nhuman speech. Two important results are that: (i) the construction and\norganization of spoken language can be characterized as Zipf's law and Heaps'\nlaw, as observed in written texts; (ii) word frequency vs. rank distribution\nand the growth of distinct words with the increase of text length shows\nsignificant differences between book and speech. In speech word frequency\ndistribution are more concentrated on higher frequency words, and the emergence\nof new words decreases much rapidly when the content length grows. Based on\nthese observations, a new generalized model is proposed to explain these\ncomplex dynamical behaviors and the differences between speech and book.", "published": "2014-12-16 00:34:37", "link": "http://arxiv.org/abs/1412.4846v2", "categories": ["cs.CL", "physics.data-an"], "primary_category": "cs.CL"}
