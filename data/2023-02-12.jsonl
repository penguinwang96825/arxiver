{"title": "Discourse Structure Extraction from Pre-Trained and Fine-Tuned Language\n  Models in Dialogues", "abstract": "Discourse processing suffers from data sparsity, especially for dialogues. As\na result, we explore approaches to build discourse structures for dialogues,\nbased on attention matrices from Pre-trained Language Models (PLMs). We\ninvestigate multiple tasks for fine-tuning and show that the dialogue-tailored\nSentence Ordering task performs best. To locate and exploit discourse\ninformation in PLMs, we propose an unsupervised and a semi-supervised method.\nOur proposals achieve encouraging results on the STAC corpus, with F1 scores of\n57.2 and 59.3 for unsupervised and semi-supervised methods, respectively. When\nrestricted to projective trees, our scores improved to 63.3 and 68.1.", "published": "2023-02-12 11:26:10", "link": "http://arxiv.org/abs/2302.05895v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating the Effect of Relative Positional Embeddings on\n  AMR-to-Text Generation with Structural Adapters", "abstract": "Text generation from Abstract Meaning Representation (AMR) has substantially\nbenefited from the popularized Pretrained Language Models (PLMs). Myriad\napproaches have linearized the input graph as a sequence of tokens to fit the\nPLM tokenization requirements. Nevertheless, this transformation jeopardizes\nthe structural integrity of the graph and is therefore detrimental to its\nresulting representation. To overcome this issue, Ribeiro et al. have recently\nproposed StructAdapt, a structure-aware adapter which injects the input graph\nconnectivity within PLMs using Graph Neural Networks (GNNs). In this paper, we\ninvestigate the influence of Relative Position Embeddings (RPE) on AMR-to-Text,\nand, in parallel, we examine the robustness of StructAdapt. Through ablation\nstudies, graph attack and link prediction, we reveal that RPE might be\npartially encoding input graphs. We suggest further research regarding the role\nof RPE will provide valuable insights for Graph-to-Text generation.", "published": "2023-02-12 12:43:36", "link": "http://arxiv.org/abs/2302.05900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Extended Sequence Tagging Vocabulary for Grammatical Error Correction", "abstract": "We extend a current sequence-tagging approach to Grammatical Error Correction\n(GEC) by introducing specialised tags for spelling correction and morphological\ninflection using the SymSpell and LemmInflect algorithms. Our approach improves\ngeneralisation: the proposed new tagset allows a smaller number of tags to\ncorrect a larger range of errors. Our results show a performance improvement\nboth overall and in the targeted error categories. We further show that\nensembles trained with our new tagset outperform those trained with the\nbaseline tagset on the public BEA benchmark.", "published": "2023-02-12 13:31:53", "link": "http://arxiv.org/abs/2302.05913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stabilized In-Context Learning with Pre-trained Language Models for Few\n  Shot Dialogue State Tracking", "abstract": "Prompt-based methods with large pre-trained language models (PLMs) have shown\nimpressive unaided performance across many NLP tasks. These models improve even\nfurther with the addition of a few labeled in-context exemplars to guide output\ngeneration. However, for more complex tasks such as dialogue state tracking\n(DST), designing prompts that reliably convey the desired intent is nontrivial,\nleading to unstable results. Furthermore, building in-context exemplars for\ndialogue tasks is difficult because conversational contexts are long while\nmodel input lengths are relatively short. To overcome these issues we first\nadapt a meta-learning scheme to the dialogue domain which stabilizes the\nability of the model to perform well under various prompts. We additionally\ndesign a novel training method to improve upon vanilla retrieval mechanisms to\nfind ideal in-context examples. Finally, we introduce a saliency model to limit\ndialogue text length, allowing us to include more exemplars per query. In\neffect, we are able to achieve highly competitive results for few-shot DST on\nMultiWOZ.", "published": "2023-02-12 15:05:10", "link": "http://arxiv.org/abs/2302.05932v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing the Effectiveness of the Underlying Reasoning Tasks in\n  Multi-hop Question Answering", "abstract": "To explain the predicted answers and evaluate the reasoning abilities of\nmodels, several studies have utilized underlying reasoning (UR) tasks in\nmulti-hop question answering (QA) datasets. However, it remains an open\nquestion as to how effective UR tasks are for the QA task when training models\non both tasks in an end-to-end manner. In this study, we address this question\nby analyzing the effectiveness of UR tasks (including both sentence-level and\nentity-level tasks) in three aspects: (1) QA performance, (2) reasoning\nshortcuts, and (3) robustness. While the previous models have not been\nexplicitly trained on an entity-level reasoning prediction task, we build a\nmulti-task model that performs three tasks together: sentence-level supporting\nfacts prediction, entity-level reasoning prediction, and answer prediction.\nExperimental results on 2WikiMultiHopQA and HotpotQA-small datasets reveal that\n(1) UR tasks can improve QA performance. Using four debiased datasets that are\nnewly created, we demonstrate that (2) UR tasks are helpful in preventing\nreasoning shortcuts in the multi-hop QA task. However, we find that (3) UR\ntasks do not contribute to improving the robustness of the model on adversarial\nquestions, such as sub-questions and inverted questions. We encourage future\nstudies to investigate the effectiveness of entity-level reasoning in the form\nof natural language questions (e.g., sub-question forms).", "published": "2023-02-12 17:32:55", "link": "http://arxiv.org/abs/2302.05963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL", "abstract": "One of the recent best attempts at Text-to-SQL is the pre-trained language\nmodel. Due to the structural property of the SQL queries, the seq2seq model\ntakes the responsibility of parsing both the schema items (i.e., tables and\ncolumns) and the skeleton (i.e., SQL keywords). Such coupled targets increase\nthe difficulty of parsing the correct SQL queries especially when they involve\nmany schema items and logic operators. This paper proposes a ranking-enhanced\nencoding and skeleton-aware decoding framework to decouple the schema linking\nand the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its\nencoder is injected by the most relevant schema items instead of the whole\nunordered ones, which could alleviate the schema linking effort during SQL\nparsing, and its decoder first generates the skeleton and then the actual SQL\nquery, which could implicitly constrain the SQL parsing. We evaluate our\nproposed framework on Spider and its three robustness variants: Spider-DK,\nSpider-Syn, and Spider-Realistic. The experimental results show that our\nframework delivers promising performance and robustness. Our code is available\nat https://github.com/RUCKBReasoning/RESDSQL.", "published": "2023-02-12 17:41:16", "link": "http://arxiv.org/abs/2302.05965v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer models: an introduction and catalog", "abstract": "In the past few years we have seen the meteoric appearance of dozens of\nfoundation models of the Transformer family, all of which have memorable and\nsometimes funny, but not self-explanatory, names. The goal of this paper is to\noffer a somewhat comprehensive but simple catalog and classification of the\nmost popular Transformer models. The paper also includes an introduction to the\nmost important aspects and innovations in Transformer models. Our catalog will\ninclude models that are trained using self-supervised learning (e.g., BERT or\nGPT3) as well as those that are further trained using a human-in-the-loop (e.g.\nthe InstructGPT model used by ChatGPT).", "published": "2023-02-12 01:26:49", "link": "http://arxiv.org/abs/2302.07730v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AIDA: Legal Judgment Predictions for Non-Professional Fact Descriptions\n  via Partial-and-Imbalanced Domain Adaptation", "abstract": "In this paper, we study the problem of legal domain adaptation problem from\nan imbalanced source domain to a partial target domain. The task aims to\nimprove legal judgment predictions for non-professional fact descriptions. We\nformulate this task as a partial-and-imbalanced domain adaptation problem.\nThough deep domain adaptation has achieved cutting-edge performance in many\nunsupervised domain adaptation tasks. However, due to the negative transfer of\nsamples in non-shared classes, it is hard for current domain adaptation model\nto solve the partial-and-imbalanced transfer problem. In this work, we explore\nlarge-scale non-shared but related classes data in the source domain with a\nhierarchy weighting adaptation to tackle this limitation. We propose to embed a\nnovel pArtial Imbalanced Domain Adaptation technique (AIDA) in the deep\nlearning model, which can jointly borrow sibling knowledge from non-shared\nclasses to shared classes in the source domain and further transfer the shared\nclasses knowledge from the source domain to the target domain. Experimental\nresults show that our model outperforms the state-of-the-art algorithms.", "published": "2023-02-12 07:04:55", "link": "http://arxiv.org/abs/2302.07728v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "\"Why is this misleading?\": Detecting News Headline Hallucinations with\n  Explanations", "abstract": "Automatic headline generation enables users to comprehend ongoing news events\npromptly and has recently become an important task in web mining and natural\nlanguage processing. With the growing need for news headline generation, we\nargue that the hallucination issue, namely the generated headlines being not\nsupported by the original news stories, is a critical challenge for the\ndeployment of this feature in web-scale systems Meanwhile, due to the\ninfrequency of hallucination cases and the requirement of careful reading for\nraters to reach the correct consensus, it is difficult to acquire a large\ndataset for training a model to detect such hallucinations through human\ncuration. In this work, we present a new framework named ExHalder to address\nthis challenge for headline hallucination detection. ExHalder adapts the\nknowledge from public natural language inference datasets into the news domain\nand learns to generate natural language sentences to explain the hallucination\ndetection results. To evaluate the model performance, we carefully collect a\ndataset with more than six thousand labeled <article, headline> pairs.\nExtensive experiments on this dataset and another six public ones demonstrate\nthat ExHalder can identify hallucinated headlines accurately and justifies its\npredictions with human-readable natural language explanations.", "published": "2023-02-12 04:21:49", "link": "http://arxiv.org/abs/2302.05852v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Position Matters! Empirical Study of Order Effect in Knowledge-grounded\n  Dialogue", "abstract": "With the power of large pretrained language models, various research works\nhave integrated knowledge into dialogue systems. The traditional techniques\ntreat knowledge as part of the input sequence for the dialogue system,\nprepending a set of knowledge statements in front of dialogue history. However,\nsuch a mechanism forces knowledge sets to be concatenated in an ordered manner,\nmaking models implicitly pay imbalanced attention to the sets during training.\nIn this paper, we first investigate how the order of the knowledge set can\ninfluence autoregressive dialogue systems' responses. We conduct experiments on\ntwo commonly used dialogue datasets with two types of transformer-based models\nand find that models view the input knowledge unequally. To this end, we\npropose a simple and novel technique to alleviate the order effect by modifying\nthe position embeddings of knowledge input in these models. With the proposed\nposition embedding method, the experimental results show that each knowledge\nstatement is uniformly considered to generate responses.", "published": "2023-02-12 10:13:00", "link": "http://arxiv.org/abs/2302.05888v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TextDefense: Adversarial Text Detection based on Word Importance Entropy", "abstract": "Currently, natural language processing (NLP) models are wildly used in\nvarious scenarios. However, NLP models, like all deep models, are vulnerable to\nadversarially generated text. Numerous works have been working on mitigating\nthe vulnerability from adversarial attacks. Nevertheless, there is no\ncomprehensive defense in existing works where each work targets a specific\nattack category or suffers from the limitation of computation overhead,\nirresistible to adaptive attack, etc.\n  In this paper, we exhaustively investigate the adversarial attack algorithms\nin NLP, and our empirical studies have discovered that the attack algorithms\nmainly disrupt the importance distribution of words in a text. A well-trained\nmodel can distinguish subtle importance distribution differences between clean\nand adversarial texts. Based on this intuition, we propose TextDefense, a new\nadversarial example detection framework that utilizes the target model's\ncapability to defend against adversarial attacks while requiring no prior\nknowledge. TextDefense differs from previous approaches, where it utilizes the\ntarget model for detection and thus is attack type agnostic. Our extensive\nexperiments show that TextDefense can be applied to different architectures,\ndatasets, and attack methods and outperforms existing methods. We also discover\nthat the leading factor influencing the performance of TextDefense is the\ntarget model's generalizability. By analyzing the property of the target model\nand the property of the adversarial example, we provide our insights into the\nadversarial attacks in NLP and the principles of our defense method.", "published": "2023-02-12 11:12:44", "link": "http://arxiv.org/abs/2302.05892v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Entanglement as a Method to Reduce Uncertainty", "abstract": "In physics, entanglement 'reduces' the entropy of an entity, because the (von\nNeumann) entropy of, e.g., a composite bipartite entity in a pure entangled\nstate is systematically lower than the entropy of the component sub-entities.\nWe show here that this 'genuinely non-classical reduction of entropy as a\nresult of composition' also holds whenever two concepts combine in human\ncognition and, more generally, it is valid in human culture. We exploit these\nresults and make a 'new hypothesis' on the nature of entanglement, namely, the\nproduction of entanglement in the preparation of a composite entity can be seen\nas a 'dynamical process of collaboration between its sub-entities to reduce\nuncertainty', because the composite entity is in a pure state while its\nsub-entities are in a non-pure, or density, state, as a result of the\npreparation. We identify within the nature of this entanglement a mechanism of\ncontextual updating and illustrate the mechanism in the example we analyze. Our\nhypothesis naturally explains the 'non-classical nature' of some quantum\nlogical connectives, as due to Bell-type correlations.", "published": "2023-02-12 12:18:01", "link": "http://arxiv.org/abs/2302.05898v1", "categories": ["q-bio.NC", "cs.CL", "quant-ph"], "primary_category": "q-bio.NC"}
{"title": "MarioGPT: Open-Ended Text2Level Generation through Large Language Models", "abstract": "Procedural Content Generation (PCG) is a technique to generate complex and\ndiverse environments in an automated way. However, while generating content\nwith PCG methods is often straightforward, generating meaningful content that\nreflects specific intentions and constraints remains challenging. Furthermore,\nmany PCG algorithms lack the ability to generate content in an open-ended\nmanner. Recently, Large Language Models (LLMs) have shown to be incredibly\neffective in many diverse domains. These trained LLMs can be fine-tuned,\nre-using information and accelerating training for new tasks. Here, we\nintroduce MarioGPT, a fine-tuned GPT2 model trained to generate tile-based game\nlevels, in our case Super Mario Bros levels. MarioGPT can not only generate\ndiverse levels, but can be text-prompted for controllable level generation,\naddressing one of the key challenges of current PCG techniques. As far as we\nknow, MarioGPT is the first text-to-level model and combined with novelty\nsearch it enables the generation of diverse levels with varying play-style\ndynamics (i.e. player paths) and the open-ended discovery of an increasingly\ndiverse range of content. Code available at\nhttps://github.com/shyamsn97/mario-gpt.", "published": "2023-02-12 19:12:24", "link": "http://arxiv.org/abs/2302.05981v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Team Triple-Check at Factify 2: Parameter-Efficient Large Foundation\n  Models with Feature Representations for Multi-Modal Fact Verification", "abstract": "Multi-modal fact verification has become an important but challenging issue\non social media due to the mismatch between the text and images in the\nmisinformation of news content, which has been addressed by considering\ncross-modalities to identify the veracity of the news in recent years. In this\npaper, we propose the Pre-CoFactv2 framework with new parameter-efficient\nfoundation models for modeling fine-grained text and input embeddings with\nlightening parameters, multi-modal multi-type fusion for not only capturing\nrelations for the same and different modalities but also for different types\n(i.e., claim and document), and feature representations for explicitly\nproviding metadata for each sample. In addition, we introduce a unified\nensemble method to boost model performance by adjusting the importance of each\ntrained model with not only the weights but also the powers. Extensive\nexperiments show that Pre-CoFactv2 outperforms Pre-CoFact by a large margin and\nachieved new state-of-the-art results at the Factify challenge at AAAI 2023. We\nfurther illustrate model variations to verify the relative contributions of\ndifferent components. Our team won the first prize (F1-score: 81.82%) and we\nmade our code publicly available at\nhttps://github.com/wwweiwei/Pre-CoFactv2-AAAI-2023.", "published": "2023-02-12 18:08:54", "link": "http://arxiv.org/abs/2302.07740v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LiT Tuned Models for Efficient Species Detection", "abstract": "Recent advances in training vision-language models have demonstrated\nunprecedented robustness and transfer learning effectiveness; however, standard\ncomputer vision datasets are image-only, and therefore not well adapted to such\ntraining methods. Our paper introduces a simple methodology for adapting any\nfine-grained image classification dataset for distributed vision-language\npretraining. We implement this methodology on the challenging iNaturalist-2021\ndataset, comprised of approximately 2.7 million images of macro-organisms\nacross 10,000 classes, and achieve a new state-of-the art model in terms of\nzero-shot classification accuracy. Somewhat surprisingly, our model (trained\nusing a new method called locked-image text tuning) uses a pre-trained, frozen\nvision representation, proving that language alignment alone can attain strong\ntransfer learning performance, even on fractious, long-tailed datasets. Our\napproach opens the door for utilizing high quality vision-language pretrained\nmodels in agriculturally relevant applications involving species detection.", "published": "2023-02-12 20:36:55", "link": "http://arxiv.org/abs/2302.10281v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Academic Writing with GPT-3.5: Reflections on Practices, Efficacy and\n  Transparency", "abstract": "The debate around the use of GPT 3.5 has been a popular topic among academics\nsince the release of ChatGPT. Whilst some have argued for the advantages of GPT\n3.5 in enhancing academic writing, others have raised concerns such as\nplagiarism, the spread of false information, and ecological issues. The need\nfor finding ways to use GPT 3.5 models transparently has been voiced, and\nsuggestions have been made on social media as to how to use GPT 3.5 models in a\nsmart way. Nevertheless, to date, there is a lack of literature which clearly\noutlines how to use GPT 3.5 models in academic writing, how effective they are,\nand how to use them transparently. To address this, I conducted a personal\nexperience experiment with GPT 3.5, specifically by using OpenAI text davinci\n003 model, for writing this article. I identified five ways of using GPT 3.5:\nChunk Stylist, Bullet to Paragraph, Talk Textualizer, Research Buddy, and\nPolisher. I reflected on their efficacy, and commented on their potential\nimpact on writing ethics. Additionally, I provided a comprehensive document\nwhich shows the prompts I used, results I got from GPT 3.5, the final edits and\nvisually compares those by showing the differences in percentages.", "published": "2023-02-12 22:05:08", "link": "http://arxiv.org/abs/2304.11079v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ASR Bundestag: A Large-Scale political debate dataset in German", "abstract": "We present ASR Bundestag, a dataset for automatic speech recognition in\nGerman, consisting of 610 hours of aligned audio-transcript pairs for\nsupervised training as well as 1,038 hours of unlabeled audio snippets for\nself-supervised learning, based on raw audio data and transcriptions from\nplenary sessions and committee meetings of the German parliament. In addition,\nwe discuss utilized approaches for the automated creation of speech datasets\nand assess the quality of the resulting dataset based on evaluations and\nfinetuning of a pre-trained state of the art model. We make the dataset\npublicly available, including all subsets.", "published": "2023-02-12 21:45:18", "link": "http://arxiv.org/abs/2302.06008v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SemanticAC: Semantics-Assisted Framework for Audio Classification", "abstract": "In this paper, we propose SemanticAC, a semantics-assisted framework for\nAudio Classification to better leverage the semantic information. Unlike\nconventional audio classification methods that treat class labels as discrete\nvectors, we employ a language model to extract abundant semantics from labels\nand optimize the semantic consistency between audio signals and their labels.\nWe verify that simple textual information from labels and advanced pretraining\nmodels enable more abundant semantic supervision for better performance.\nSpecifically, we design a text encoder to capture the semantic information from\nthe text extension of labels. Then we map the audio signals to align with the\nsemantics of corresponding class labels via an audio encoder and a similarity\ncalculation module so as to enforce the semantic consistency. Extensive\nexperiments on two audio datasets, ESC-50 and US8K demonstrate that our\nproposed method consistently outperforms the compared audio classification\nmethods.", "published": "2023-02-12 15:30:28", "link": "http://arxiv.org/abs/2302.05940v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
