{"title": "Incremental Few-shot Text Classification with Multi-round New Classes:\n  Formulation, Dataset and System", "abstract": "Text classification is usually studied by labeling natural language texts\nwith relevant categories from a predefined set. In the real world, new classes\nmight keep challenging the existing system with limited labeled data. The\nsystem should be intelligent enough to recognize upcoming new classes with a\nfew examples. In this work, we define a new task in the NLP domain, incremental\nfew-shot text classification, where the system incrementally handles multiple\nrounds of new classes. For each round, there is a batch of new classes with a\nfew labeled examples per class. Two major challenges exist in this new task:\n(i) For the learning process, the system should incrementally learn new classes\nround by round without re-training on the examples of preceding classes; (ii)\nFor the performance, the system should perform well on new classes without much\nloss on preceding classes. In addition to formulating the new task, we also\nrelease two benchmark datasets in the incremental few-shot setting: intent\nclassification and relation classification. Moreover, we propose two entailment\napproaches, ENTAILMENT and HYBRID, which show promise for solving this novel\nproblem.", "published": "2021-04-24 04:41:15", "link": "http://arxiv.org/abs/2104.11882v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Coverage for Non-Autoregressive Neural Machine Translation", "abstract": "Non-Autoregressive Neural Machine Translation (NAT) has achieved significant\ninference speedup by generating all tokens simultaneously. Despite its high\nefficiency, NAT usually suffers from two kinds of translation errors:\nover-translation (e.g. repeated tokens) and under-translation (e.g. missing\ntranslations), which eventually limits the translation quality. In this paper,\nwe argue that these issues of NAT can be addressed through coverage modeling,\nwhich has been proved to be useful in autoregressive decoding. We propose a\nnovel Coverage-NAT to model the coverage information directly by a token-level\ncoverage iterative refinement mechanism and a sentence-level coverage\nagreement, which can remind the model if a source token has been translated or\nnot and improve the semantics consistency between the translation and the\nsource, respectively. Experimental results on WMT14 En-De and WMT16 En-Ro\ntranslation tasks show that our method can alleviate those errors and achieve\nstrong improvements over the baseline system.", "published": "2021-04-24 07:33:23", "link": "http://arxiv.org/abs/2104.11897v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extract then Distill: Efficient and Effective Task-Agnostic BERT\n  Distillation", "abstract": "Task-agnostic knowledge distillation, a teacher-student framework, has been\nproved effective for BERT compression. Although achieving promising results on\nNLP tasks, it requires enormous computational resources. In this paper, we\npropose Extract Then Distill (ETD), a generic and flexible strategy to reuse\nthe teacher's parameters for efficient and effective task-agnostic\ndistillation, which can be applied to students of any size. Specifically, we\nintroduce two variants of ETD, ETD-Rand and ETD-Impt, which extract the\nteacher's parameters in a random manner and by following an importance metric\nrespectively. In this way, the student has already acquired some knowledge at\nthe beginning of the distillation process, which makes the distillation process\nconverge faster. We demonstrate the effectiveness of ETD on the GLUE benchmark\nand SQuAD. The experimental results show that: (1) compared with the baseline\nwithout an ETD strategy, ETD can save 70\\% of computation cost. Moreover, it\nachieves better results than the baseline when using the same computing\nresource. (2) ETD is generic and has been proven effective for different\ndistillation methods (e.g., TinyBERT and MiniLM) and students of different\nsizes. The source code will be publicly available upon publication.", "published": "2021-04-24 11:23:39", "link": "http://arxiv.org/abs/2104.11928v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vietnamese Complaint Detection on E-Commerce Websites", "abstract": "Customer product reviews play a role in improving the quality of products and\nservices for business organizations or their brands. Complaining is an attitude\nthat expresses dissatisfaction with an event or a product not meeting customer\nexpectations. In this paper, we build a Open-domain Complaint Detection dataset\n(UIT-ViOCD), including 5,485 human-annotated reviews on four categories about\nproduct reviews on e-commerce sites. After the data collection phase, we\nproceed to the annotation task and achieve the inter-annotator agreement Am of\n87%. Then, we present an extensive methodology for the research purposes and\nachieve 92.16% by F1-score for identifying complaints. With the results, in the\nfuture, we aim to build a system for open-domain complaint detection in\nE-commerce websites.", "published": "2021-04-24 15:19:06", "link": "http://arxiv.org/abs/2104.11969v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language ID Prediction from Speech Using Self-Attentive Pooling and\n  1D-Convolutions", "abstract": "This memo describes NTR-TSU submission for SIGTYP 2021 Shared Task on\npredicting language IDs from speech.\n  Spoken Language Identification (LID) is an important step in a multilingual\nAutomated Speech Recognition (ASR) system pipeline. For many low-resource and\nendangered languages, only single-speaker recordings may be available,\ndemanding a need for domain and speaker-invariant language ID systems. In this\nmemo, we show that a convolutional neural network with a Self-Attentive Pooling\nlayer shows promising results for the language identification task.", "published": "2021-04-24 16:41:17", "link": "http://arxiv.org/abs/2104.11985v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "A Multi-Size Neural Network with Attention Mechanism for Answer\n  Selection", "abstract": "Semantic matching is of central significance to the answer selection task\nwhich aims to select correct answers for a given question from a candidate\nanswer pool. A useful method is to employ neural networks with attention to\ngenerate sentences representations in a way that information from pair\nsentences can mutually influence the computation of representations. In this\nwork, an effective architecture,multi-size neural network with attention\nmechanism (AM-MSNN),is introduced into the answer selection task. This\narchitecture captures more levels of language granularities in parallel,\nbecause of the various sizes of filters comparing with single-layer CNN and\nmulti-layer CNNs. Meanwhile it extends the sentence representations by\nattention mechanism, thus containing more information for different types of\nquestions. The empirical study on three various benchmark tasks of answer\nselection demonstrates the efficacy of the proposed model in all the benchmarks\nand its superiority over competitors. The experimental results show that (1)\nmulti-size neural network (MSNN) is a more useful method to capture abstract\nfeatures on different levels of granularities than single/multi-layer CNNs; (2)\nthe attention mechanism (AM) is a better strategy to derive more informative\nrepresentations; (3) AM-MSNN is a better architecture for the answer selection\ntask for the moment.", "published": "2021-04-24 02:13:26", "link": "http://arxiv.org/abs/2105.03278v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ask & Explore: Grounded Question Answering for Curiosity-Driven\n  Exploration", "abstract": "In many real-world scenarios where extrinsic rewards to the agent are\nextremely sparse, curiosity has emerged as a useful concept providing intrinsic\nrewards that enable the agent to explore its environment and acquire\ninformation to achieve its goals. Despite their strong performance on many\nsparse-reward tasks, existing curiosity approaches rely on an overly holistic\nview of state transitions, and do not allow for a structured understanding of\nspecific aspects of the environment. In this paper, we formulate curiosity\nbased on grounded question answering by encouraging the agent to ask questions\nabout the environment and be curious when the answers to these questions\nchange. We show that natural language questions encourage the agent to uncover\nspecific knowledge about their environment such as the physical properties of\nobjects as well as their spatial relationships with other objects, which serve\nas valuable curiosity rewards to solve sparse-reward tasks more efficiently.", "published": "2021-04-24 07:56:31", "link": "http://arxiv.org/abs/2104.11902v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MusCaps: Generating Captions for Music Audio", "abstract": "Content-based music information retrieval has seen rapid progress with the\nadoption of deep learning. Current approaches to high-level music description\ntypically make use of classification models, such as in auto-tagging or genre\nand mood classification. In this work, we propose to address music description\nvia audio captioning, defined as the task of generating a natural language\ndescription of music audio content in a human-like manner. To this end, we\npresent the first music audio captioning model, MusCaps, consisting of an\nencoder-decoder with temporal attention. Our method combines convolutional and\nrecurrent neural network architectures to jointly process audio-text inputs\nthrough a multimodal encoder and leverages pre-training on audio data to obtain\nrepresentations that effectively capture and summarise musical features in the\ninput. Evaluation of the generated captions through automatic metrics shows\nthat our method outperforms a baseline designed for non-music audio captioning.\nThrough an ablation study, we unveil that this performance boost can be mainly\nattributed to pre-training of the audio encoder, while other design choices -\nmodality fusion, decoding strategy and the use of attention - contribute only\nmarginally. Our model represents a shift away from classification-based music\ndescription and combines tasks requiring both auditory and linguistic\nunderstanding to bridge the semantic gap in music information retrieval.", "published": "2021-04-24 16:34:47", "link": "http://arxiv.org/abs/2104.11984v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Music Embedding: A Tool for Incorporating Music Theory into\n  Computational Music Applications", "abstract": "Advancements in the digital technologies have enabled researchers to develop\na variety of Computational Music applications. Such applications are required\nto capture, process, and generate data related to music. Therefore, it is\nimportant to digitally represent music in a music theoretic and concise manner.\nExisting approaches for representing music are ineffective in terms of\nutilizing music theory. In this paper, we address the disjoint of music theory\nand computational music by developing an opensource representation tool based\non music theory. Through the wide range of use cases, we run an analysis on the\nclassical music pieces to show the usefulness of the developed music embedding.", "published": "2021-04-24 04:32:45", "link": "http://arxiv.org/abs/2104.11880v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Aligned Contrastive Predictive Coding", "abstract": "We investigate the possibility of forcing a self-supervised model trained\nusing a contrastive predictive loss to extract slowly varying latent\nrepresentations. Rather than producing individual predictions for each of the\nfuture representations, the model emits a sequence of predictions shorter than\nthat of the upcoming representations to which they will be aligned. In this\nway, the prediction network solves a simpler task of predicting the next\nsymbols, but not their exact timing, while the encoding network is trained to\nproduce piece-wise constant latent codes. We evaluate the model on a speech\ncoding task and demonstrate that the proposed Aligned Contrastive Predictive\nCoding (ACPC) leads to higher linear phone prediction accuracy and lower ABX\nerror rates, while being slightly faster to train due to the reduced number of\nprediction heads.", "published": "2021-04-24 13:07:22", "link": "http://arxiv.org/abs/2104.11946v3", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
