{"title": "Building a Neural Semantic Parser from a Domain Ontology", "abstract": "Semantic parsing is the task of converting natural language utterances into\nmachine interpretable meaning representations which can be executed against a\nreal-world environment such as a database. Scaling semantic parsing to\narbitrary domains faces two interrelated challenges: obtaining broad coverage\ntraining data effectively and cheaply; and developing a model that generalizes\nto compositional utterances and complex intentions. We address these challenges\nwith a framework which allows to elicit training data from a domain ontology\nand bootstrap a neural parser which recursively builds derivations of logical\nforms. In our framework meaning representations are described by sequences of\nnatural language templates, where each template corresponds to a decomposed\nfragment of the underlying meaning representation. Although artificial,\ntemplates can be understood and paraphrased by humans to create natural\nutterances, resulting in parallel triples of utterances, meaning\nrepresentations, and their decompositions. These allow us to train a neural\nsemantic parser which learns to compose rules in deriving meaning\nrepresentations. We crowdsource training data on six domains, covering both\nsingle-turn utterances which exhibit rich compositionality, and sequential\nutterances where a complex task is procedurally performed in steps. We then\ndevelop neural semantic parsers which perform such compositional tasks. In\ngeneral, our approach allows to deploy neural semantic parsers quickly and\ncheaply from a given domain ontology.", "published": "2018-12-25 05:30:18", "link": "http://arxiv.org/abs/1812.10037v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence to Sequence Learning for Query Expansion", "abstract": "Using sequence to sequence algorithms for query expansion has not been\nexplored yet in Information Retrieval literature nor in Question-Answering's.\nWe tried to fill this gap in the literature with a custom Query Expansion\nengine trained and tested on open datasets. Starting from open datasets, we\nbuilt a Query Expansion training set using sentence-embeddings-based Keyword\nExtraction. We therefore assessed the ability of the Sequence to Sequence\nneural networks to capture expanding relations in the words embeddings' space.", "published": "2018-12-25 15:24:04", "link": "http://arxiv.org/abs/1812.10119v1", "categories": ["cs.IR", "cs.CL", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Deep Representation Learning for Clustering of Health Tweets", "abstract": "Twitter has been a prominent social media platform for mining\npopulation-level health data and accurate clustering of health-related tweets\ninto topics is important for extracting relevant health insights. In this work,\nwe propose deep convolutional autoencoders for learning compact representations\nof health-related tweets, further to be employed in clustering. We compare our\nmethod to several conventional tweet representation methods including\nbag-of-words, term frequency-inverse document frequency, Latent Dirichlet\nAllocation and Non-negative Matrix Factorization with 3 different clustering\nalgorithms. Our results show that the clustering performance using proposed\nrepresentation learning scheme significantly outperforms that of conventional\nmethods for all experiments of different number of clusters. In addition, we\npropose a constraint on the learned representations during the neural network\ntraining in order to further enhance the clustering performance. All in all,\nthis study introduces utilization of deep neural network-based architectures,\ni.e., deep convolutional autoencoders, for learning informative representations\nof health-related tweets.", "published": "2018-12-25 00:31:22", "link": "http://arxiv.org/abs/1901.00439v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Noise Flooding for Detecting Audio Adversarial Examples Against\n  Automatic Speech Recognition", "abstract": "Neural models enjoy widespread use across a variety of tasks and have grown\nto become crucial components of many industrial systems. Despite their\neffectiveness and extensive popularity, they are not without their exploitable\nflaws. Initially applied to computer vision systems, the generation of\nadversarial examples is a process in which seemingly imperceptible\nperturbations are made to an image, with the purpose of inducing a deep\nlearning based classifier to misclassify the image. Due to recent trends in\nspeech processing, this has become a noticeable issue in speech recognition\nmodels. In late 2017, an attack was shown to be quite effective against the\nSpeech Commands classification model. Limited-vocabulary speech classifiers,\nsuch as the Speech Commands model, are used quite frequently in a variety of\napplications, particularly in managing automated attendants in telephony\ncontexts. As such, adversarial examples produced by this attack could have\nreal-world consequences. While previous work in defending against these\nadversarial examples has investigated using audio preprocessing to reduce or\ndistort adversarial noise, this work explores the idea of flooding particular\nfrequency bands of an audio signal with random noise in order to detect\nadversarial examples. This technique of flooding, which does not require\nretraining or modifying the model, is inspired by work done in computer vision\nand builds on the idea that speech classifiers are relatively robust to natural\nnoise. A combined defense incorporating 5 different frequency bands for\nflooding the signal with noise outperformed other existing defenses in the\naudio space, detecting adversarial examples with 91.8% precision and 93.5%\nrecall.", "published": "2018-12-25 08:02:01", "link": "http://arxiv.org/abs/1812.10061v1", "categories": ["cs.SD", "cs.CL", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multimodal deep learning for short-term stock volatility prediction", "abstract": "Stock market volatility forecasting is a task relevant to assessing market\nrisk. We investigate the interaction between news and prices for the\none-day-ahead volatility prediction using state-of-the-art deep learning\napproaches. The proposed models are trained either end-to-end or using sentence\nencoders transfered from other tasks. We evaluate a broad range of stock market\nsectors, namely Consumer Staples, Energy, Utilities, Heathcare, and Financials.\nOur experimental results show that adding news improves the volatility\nforecasting as compared to the mainstream models that rely only on price data.\nIn particular, our model outperforms the widely-recognized GARCH(1,1) model for\nall sectors in terms of coefficient of determination $R^2$, $MSE$ and $MAE$,\nachieving the best performance when training from both news and price data.", "published": "2018-12-25 14:35:08", "link": "http://arxiv.org/abs/1812.10479v1", "categories": ["q-fin.ST", "cs.CL", "cs.LG", "q-fin.RM", "stat.ML"], "primary_category": "q-fin.ST"}
{"title": "Tensor-Train Long Short-Term Memory for Monaural Speech Enhancement", "abstract": "In recent years, Long Short-Term Memory (LSTM) has become a popular choice\nfor speech separation and speech enhancement task. The capability of LSTM\nnetwork can be enhanced by widening and adding more layers. However, this would\nintroduce millions of parameters in the network and also increase the\nrequirement of computational resources. These limitations hinders the efficient\nimplementation of RNN models in low-end devices such as mobile phones and\nembedded systems with limited memory. To overcome these issues, we proposed to\nuse an efficient alternative approach of reducing parameters by representing\nthe weight matrix parameters of LSTM based on Tensor-Train (TT) format. We\ncalled this Tensor-Train factorized LSTM as TT-LSTM model. Based on this\nTT-LSTM units, we proposed a deep TensorNet model for single-channel speech\nenhancement task. Experimental results in various test conditions and in terms\nof standard speech quality and intelligibility metrics, demonstrated that the\nproposed deep TT-LSTM based speech enhancement framework can achieve\ncompetitive performances with the state-of-the-art uncompressed RNN model, even\nthough the proposed model architecture is orders of magnitude less complex.", "published": "2018-12-25 12:21:42", "link": "http://arxiv.org/abs/1812.10095v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
