{"title": "Generating realistic patient data", "abstract": "Developing algorithms for real-life problems that perform well in practice\nhighly depends on the availability of realistic data for testing. Obtaining\nreal-life data for optimization problems in health care, however, is often\ndifficult. This is especially true for any patient related optimization\nproblems, e.g., for patient-to-room assignment, due to data privacy policies.\nFurthermore, obtained real-life data usually cannot be published which\nprohibits reproducibility of results by other researchers. Therefore, often\nartificially generated instances are used. In this paper, we present\ncombinatorial insights about the feasibility of instances for the\npatient-to-room assignment problem (PRA). We use these insights to develop a\nconfigurable instance generator for PRA with an easy-to-use graphical user\ninterface. Configurability is in this case especially important as we observed\nin an extensive analysis of real-life data that, e.g., the probability\ndistribution for patients' age and length of stay depends on the respective\nward.", "published": "2025-07-04 09:29:30", "link": "http://arxiv.org/abs/2507.03423v1", "categories": ["math.OC", "cs.DM", "cs.LG"], "primary_category": "math.OC"}
{"title": "Efficient and Effective Query Context-Aware Learning-to-Rank Model for Sequential Recommendation", "abstract": "Modern sequential recommender systems commonly use transformer-based models\nfor next-item prediction. While these models demonstrate a strong balance\nbetween efficiency and quality, integrating interleaving features - such as the\nquery context (e.g., browse category) under which next-item interactions occur\n- poses challenges. Effectively capturing query context is crucial for refining\nranking relevance and enhancing user engagement, as it provides valuable\nsignals about user intent within a session. Unlike an item's features, query\ncontext is not temporally aligned with the item sequence, making its\nincorporation into transformers challenging and error-prone. This paper\nanalyzes different strategies for incorporating query context into transformers\ntrained with a causal language modeling procedure as a case study. We propose a\nnew method that effectively fuses the item sequence with query context within\nthe attention mechanism. Through extensive offline and online experiments on a\nlarge-scale online platform and open datasets, we present evidence that our\nproposed method is an effective approach for integrating query context to\nimprove model ranking quality in terms of relevance and diversity.", "published": "2025-07-04 19:50:01", "link": "http://arxiv.org/abs/2507.03789v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Ranking-based Fusion Algorithms for Extreme Multi-label Text Classification (XMTC)", "abstract": "In the context of Extreme Multi-label Text Classification (XMTC), where\nlabels are assigned to text instances from a large label space, the long-tail\ndistribution of labels presents a significant challenge. Labels can be broadly\ncategorized into frequent, high-coverage \\textbf{head labels} and infrequent,\nlow-coverage \\textbf{tail labels}, complicating the task of balancing\neffectiveness across all labels. To address this, combining predictions from\nmultiple retrieval methods, such as sparse retrievers (e.g., BM25) and dense\nretrievers (e.g., fine-tuned BERT), offers a promising solution. The fusion of\n\\textit{sparse} and \\textit{dense} retrievers is motivated by the complementary\nranking characteristics of these methods. Sparse retrievers compute relevance\nscores based on high-dimensional, bag-of-words representations, while dense\nretrievers utilize approximate nearest neighbor (ANN) algorithms on dense text\nand label embeddings within a shared embedding space. Rank-based fusion\nalgorithms leverage these differences by combining the precise matching\ncapabilities of sparse retrievers with the semantic richness of dense\nretrievers, thereby producing a final ranking that improves the effectiveness\nacross both head and tail labels.", "published": "2025-07-04 18:17:52", "link": "http://arxiv.org/abs/2507.03761v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Agent-Based Detection and Resolution of Incompleteness and Ambiguity in Interactions with Large Language Models", "abstract": "Many of us now treat LLMs as modern-day oracles asking it almost any kind of\nquestion. However, consulting an LLM does not have to be a single turn\nactivity. But long multi-turn interactions can get tedious if it is simply to\nclarify contextual information that can be arrived at through reasoning. In\nthis paper, we examine the use of agent-based architecture to bolster LLM-based\nQuestion-Answering systems with additional reasoning capabilities. We examine\nthe automatic resolution of potential incompleteness or ambiguities in\nquestions by transducers implemented using LLM-based agents. We focus on\nseveral benchmark datasets that are known to contain questions with these\ndeficiencies to varying degrees. We equip different LLMs (GPT-3.5-Turbo and\nLlama-4-Scout) with agents that act as specialists in detecting and resolving\ndeficiencies of incompleteness and ambiguity. The agents are implemented as\nzero-shot ReAct agents. Rather than producing an answer in a single step, the\nmodel now decides between 3 actions a) classify b) resolve c) answer. Action a)\ndecides if the question is incomplete, ambiguous, or normal. Action b)\ndetermines if any deficiencies identified can be resolved. Action c) answers\nthe resolved form of the question. We compare the use of LLMs with and without\nthe use of agents with these components. Our results show benefits of agents\nwith transducer 1) A shortening of the length of interactions with human 2) An\nimprovement in the answer quality and 3) Explainable resolution of deficiencies\nin the question. On the negative side we find while it may result in additional\nLLM invocations and in some cases, increased latency. But on tested datasets,\nthe benefits outweigh the costs except when questions already have sufficient\ncontext. Suggesting the agent-based approach could be a useful mechanism to\nharness the power of LLMs to develop more robust QA systems.", "published": "2025-07-04 17:28:33", "link": "http://arxiv.org/abs/2507.03726v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "I.2"], "primary_category": "cs.AI"}
{"title": "GENPLUGIN: A Plug-and-Play Framework for Long-Tail Generative Recommendation with Exposure Bias Mitigation", "abstract": "Generative recommendation (GenRec) offers LLM integration, reduced embedding\ncosts, and eliminates per-candidate scoring, attracting great attention.\nDespite its promising performance, this study reveals that it suffers from\ngeneration exposure bias and poor long-tail item generalization, two critical\nlimitations overlooked by prior works on GenRec. To address these, we propose\nGENPLUGIN, a plug-and-play framework featuring a dual-encoder, shared-decoder\narchitecture. During pre-training, it aligns language and ID views via\ncontrastive learning, harmonizing item representations across two complementary\nviews. Besides, GENPLUGIN uses a novel training strategy that probabilistically\nsubstitutes ground-truth item ID tokens with predictions from the\nlanguage-semantics encoder, alleviating exposure bias. To improve long-tail\ngenerative recommendation, we propose a retrieval-based data augmentation\nmechanism. It fine-tunes the decoder of GENPLUGIN to endow GENPLUGIN with the\nability to use relevant users w.r.t. contexts or collaborative information to\naugment the generation of item ID tokens in long-tail recommendation scenarios.\nWe have plugged GENPLUGIN into several representative GenRec models and the\nextensive experiments demonstrate that GENPLUGIN can notably mitigate\ngeneration exposure bias during item ID generation while significantly\nimproving the quality of long-tail item recommendation.", "published": "2025-07-04 13:25:51", "link": "http://arxiv.org/abs/2507.03568v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Multistakeholder Approach to Value-Driven Co-Design of Recommender System Evaluation Metrics in Digital Archives", "abstract": "This paper presents the first multistakeholder approach for translating\ndiverse stakeholder values into an evaluation metric setup for Recommender\nSystems (RecSys) in digital archives. While commercial platforms mainly rely on\nengagement metrics, cultural heritage domains require frameworks that balance\ncompeting priorities among archivists, platform owners, researchers, and other\nstakeholders. To address this challenge, we conducted high-profile focus groups\n(5 groups x 5 persons) with upstream, provider, system, consumer, and\ndownstream stakeholders, identifying value priorities across critical\ndimensions: visibility/representation, expertise adaptation, and\ntransparency/trust. Our analysis shows that stakeholder concerns naturally\nalign with four sequential research funnel stages: discovery, interaction,\nintegration, and impact. The resulting framework addresses domain-specific\nchallenges including collection representation imbalances, non-linear research\npatterns, and tensions between specialized expertise and broader accessibility.\nWe propose tailored metrics for each stage in this research journey, such as\nresearch path quality for discovery, contextual appropriateness for\ninteraction, metadata-weighted relevance for integration, and cross-stakeholder\nvalue alignment for impact assessment. Our contributions extend beyond digital\narchives to the broader RecSys community, offering transferable evaluation\napproaches for domains where value emerges through sustained engagement rather\nthan immediate consumption.", "published": "2025-07-04 13:09:08", "link": "http://arxiv.org/abs/2507.03556v1", "categories": ["cs.IR", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Exploring the Effect of Context-Awareness and Popularity Calibration on Popularity Bias in POI Recommendations", "abstract": "Point-of-interest (POI) recommender systems help users discover relevant\nlocations, but their effectiveness is often compromised by popularity bias,\nwhich disadvantages less popular, yet potentially meaningful places. This paper\naddresses this challenge by evaluating the effectiveness of context-aware\nmodels and calibrated popularity techniques as strategies for mitigating\npopularity bias. Using four real-world POI datasets (Brightkite, Foursquare,\nGowalla, and Yelp), we analyze the individual and combined effects of these\napproaches on recommendation accuracy and popularity bias. Our results reveal\nthat context-aware models cannot be considered a uniform solution, as the\nmodels studied exhibit divergent impacts on accuracy and bias. In contrast,\ncalibration techniques can effectively align recommendation popularity with\nuser preferences, provided there is a careful balance between accuracy and bias\nmitigation. Notably, the combination of calibration and context-awareness\nyields recommendations that balance accuracy and close alignment with the\nusers' popularity profiles, i.e., popularity calibration.", "published": "2025-07-04 11:56:11", "link": "http://arxiv.org/abs/2507.03503v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Explainable Information Retrieval in the Audit Domain", "abstract": "Conversational agents such as Microsoft Copilot and Google Gemini assist\nusers with complex search tasks but often generate misleading or fabricated\nreferences. This undermines trust, particularly in high-stakes domains such as\nmedicine and finance. Explainable information retrieval (XIR) aims to address\nthis by making search results more transparent and interpretable. While most\nXIR research is domain-agnostic, this paper focuses on auditing -- a critical\nyet underexplored area. We argue that XIR systems can support auditors in\ncompleting their complex task. We outline key challenges and future research\ndirections to advance XIR in this domain.", "published": "2025-07-04 11:07:20", "link": "http://arxiv.org/abs/2507.03479v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Modeling Item-Level Dynamic Variability with Residual Diffusion for Bundle Recommendation", "abstract": "Existing solutions for bundle recommendation(BR) have achieved remarkable\neffectiveness for predicting the user's preference for prebuilt bundles.\nHowever, bundle-item(B-I) affiliation will vary dynamically in real scenarios.\nFor example, a bundle themed as 'casual outfit', may add 'hat' or remove\n'watch' due to factors such as seasonal variations, changes in user pes or\ninventory adjustments. Our empirical study demonstrates that the performance of\nmainstream BR models will fluctuate or even decline regarding item-level\nvariability. This paper makes the first attempt to referencaddress the above\nproblem and proposes a novel Residual Diffusion for Bundle\nRecommendation(RDiffBR) as a model-agnostic generative framework which can\nassist a BR model in adapting this scenario. During the initial training of the\nBR model, RDiffBR employs a residual diffusion model to process the item-level\nbundle embeddings which are generated by BR model to represent bundle theme via\na forward-reverse process. In the inference stage, RDiffBR reverses item-level\nbundle embeddings obtained by the well-trained bundle model under B-I\nvariability scenarios to generate the effective item-level bundle embeddings.\nIn particular, the residual connection in our residual approximator\nsignificantly enhances item-level bundle embeddings generation ability of BR\nmodels. Experiments on six BR models and four public datasets from different\ndomains show that RDiffBR improves the performance of Recall and NDCG of\nbackbone BR models by up to 23%, while only increased training time about\n4%.Codes and datasets are available at\nhttps://anonymous.4open.science/r/RDiffBR.", "published": "2025-07-04 03:56:04", "link": "http://arxiv.org/abs/2507.03280v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "On the Distribution of Age of Information in Time-varying Updating Systems", "abstract": "Age of Information (AoI) is a crucial metric for quantifying information\nfreshness in real-time systems where the sampling rate of data packets is\ntime-varying. Evaluating AoI under such conditions is challenging, as system\nstates become temporally correlated and traditional stationary analysis is\ninapplicable. We investigate an $M_{t}/G/1/1$ queueing system with a\ntime-varying sampling rate and probabilistic preemption, proposing a novel\nanalytical framework based on multi-dimensional partial differential equations\n(PDEs) to capture the time evolution of the system's status distribution. To\nsolve the PDEs, we develop a decomposition technique that breaks the\nhigh-dimensional PDE into lower-dimensional subsystems. Solving these\nsubsystems allows us to derive the Aol distribution at arbitrary time\ninstances. We show AoI does not exhibit a memoryless property, even with\nnegligible processing times, due to its dependence on the historical sampling\nprocess. Our framework extends to the stationary setting, where we derive a\nclosed-form expression for the Laplace-Stieltjes Transform (LST) of the\nsteady-state AoI. Numerical experiments reveal AoI exhibits a non-trivial lag\nin response to sampling rate changes. Our results also show that no single\npreemption probability or processing time distribution can minimize Aol\nviolation probability across all thresholds in either time-varying or\nstationary scenarios. Finally, we formulate an optimization problem and propose\na heuristic method to find sampling rates that reduce costs while satisfying\nAoI constraints.", "published": "2025-07-04 20:42:09", "link": "http://arxiv.org/abs/2507.03799v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "You May Use the Same Channel Knowledge Map for Environment-Aware NLoS Sensing and Communication", "abstract": "As one of the key usage scenarios for the sixth generation (6G) wireless\nnetworks, integrated sensing and communication (ISAC) provides an efficient\nframework to achieve simultaneous wireless sensing and communication. However,\ntraditional wireless sensing techniques mainly rely on the line-of-sight (LoS)\nassumptions, i.e., the sensing targets are directly visible to both the sensing\ntransmitter and receiver. This hinders ISAC systems to be applied in complex\nenvironments such as the urban low-altitude airspace, which usually suffers\nfrom signal blockage and non-line-of-sight (NLoS) multi-path propagation. To\naddress this challenge, in this paper, we propose a novel approach to enable\nenvironment-aware NLoS ISAC by leveraging the new technique called channel\nknowledge map (CKM), which was originally proposed for environment-aware\nwireless communications. One major novelty of our proposed method is that the\nsame CKM built for wireless communication can be directly used to enable NLoS\nwireless sensing, thus enjoying the benefits of ``killing two birds with one\nstone''. To this end, the sensing targets are treated as virtual user equipment\n(UE), and the wireless communication channel priors are transformed into the\nsensing channel priors, allowing one single CKM to serve dual purposes. We\nillustrate our proposed framework by a specific CKM called \\emph{channel\nangle-delay map} (CADM). Specifically, the proposed framework utilizes CADM to\nderive angle-delay priors of the sensing channel by exploiting the relationship\nbetween communication and sensing angle-delay distributions, enabling sensing\ntarget localization in the challenging NLoS environment. Extensive simulation\nresults demonstrate significant performance improvements over classic\ngeometry-based sensing methods, which is further validated by Cram\\'er-Rao\nLower Bound (CRLB) analysis.", "published": "2025-07-04 13:57:13", "link": "http://arxiv.org/abs/2507.03589v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "From Street Form to Spatial Justice: Explaining Urban Exercise Inequality via a Triadic SHAP-Informed Framework", "abstract": "Urban streets are essential public spaces that facilitate everyday physical\nactivity and promote health equity. Drawing on Henri Lefebvre's spatial triad,\nthis study proposes a conceptual and methodological framework to quantify\nstreet-level exercise deprivation through the dimensions of conceived (planning\nand structure), perceived (visual and sensory), and lived (practice and\nexperiential) urban spaces. We integrate multi-source spatial data-including\nstreet networks, street-view imagery, and social media-using explainable\nmachine learning (SHAP analysis) to classify streets by their dominant\ndeprivation modes, forming a novel typology of spatial inequity. Results\nhighlight significant differences across urban contexts: older city cores\npredominantly experience infrastructural constraints (conceived space), whereas\nnew development areas suffer from experiential disengagement (lived space).\nFurthermore, by identifying spatial mismatches between population distribution\nand exercise intensity, our study reveals localized clusters of latent\ndeprivation. Simulation experiments demonstrate that targeted improvements\nacross spatial dimensions can yield up to 14% increases in exercise\nsupportiveness. This research not only operationalizes Lefebvre's spatial\ntheory at the street scale but also provides actionable insights and\nintervention guidelines, contributing to the broader goals of spatial justice\nand urban health equity.", "published": "2025-07-04 13:28:30", "link": "http://arxiv.org/abs/2507.03570v1", "categories": ["cs.CY", "cs.IT", "cs.LG", "math.IT", "62H30, 91D10, 68T05", "I.2.6; I.5.2; H.2.8; J.4"], "primary_category": "cs.CY"}
{"title": "Affine Frequency Division Multiplexing Over Wideband Doubly-Dispersive Channels With Time-Scaling Effects", "abstract": "The recently proposed affine frequency division multiplexing (AFDM)\nmodulation has been considered as a promising technology for narrowband\ndoubly-dispersive channels. However, the time-scaling effects, i.e., pulse\nwidening and pulse shortening phenomena, in extreme wideband doubly-dispersive\nchannels have not been considered in the literatures. In this paper, we\ninvestigate such wideband transmission and develop an efficient transmission\nstructure with chirp-periodic prefix (CPP) and chirp-periodic suffix (CPS) for\nAFDM system. We derive the input-output relationship of AFDM system under\ntime-scaled wideband doubly-dispersive channels and demonstrate the sparsity in\ndiscrete affine Fourier (DAF) domain equivalent channels. We further optimize\nthe AFDM chirp parameters to accommodate the time-scaling characteristics in\nwideband doubly-dispersive channels and verify the superiority of the derived\nchirp parameters by pairwise error probability (PEP) analysis. We also develop\nan efficient cross domain distributed orthogonal approximate message passing\n(CD-D-OAMP) algorithm for AFDM symbol detection and analyze its corresponding\nstate evolution. By analyzing the detection complexity of CD-D-OAMP detector\nand evaluating the error performance of AFDM systems based on simulations, we\ndemonstrate that the AFDM system with our optimized chirp parameters\noutperforms the existing competitive modulation schemes in time-scaled wideband\ndoubly-dispersive channels. Moreover, our proposed CD-D-OAMP detector can\nachieve the desirable trade-off between the complexity and performance, while\nsupporting parallel computing to significantly reduce the computational\nlatency.", "published": "2025-07-04 12:39:56", "link": "http://arxiv.org/abs/2507.03537v1", "categories": ["cs.PF", "cs.IT", "math.IT"], "primary_category": "cs.PF"}
{"title": "Short Blocklength Error Correction Codes for Continuous-Variable Quantum Key Distribution", "abstract": "We introduce a two-step error correction scheme for reconciliation in\ncontinuous-variable quantum key distribution systems. Using this scheme, it is\npossible to use error correction codes with small blocklengths (1000 bits),\nincreasing secret key rates at a distance of 140km by up to 7.3 times.", "published": "2025-07-04 12:28:29", "link": "http://arxiv.org/abs/2507.03529v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Early Termination of Low-Density Parity-Check Codes for Continuous-Variable Quantum Key Distribution", "abstract": "We analyse the impact of log a-posteriori early termination on the decoding\nthroughput of reconciliation for continuous-variable quantum key distribution.\nIncreases in decoded secret key rate throughput of up to 182% are reported in\nboth simulations and experiments.", "published": "2025-07-04 12:06:39", "link": "http://arxiv.org/abs/2507.03509v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Near-Field Codebook-Based 3D Spherical Channel Estimation for UCA XL-MIMO Systems", "abstract": "Extremely large-scale multiple input multiple output (XL-MIMO), a key\ntechnology for 6G communications, faces challenges in near-field channel\nestimation due to spherical wavefronts and the need for three-dimensional (3D)\nspatial characterization, particularly with uniform circular arrays (UCAs).\nThis letter proposes a spherical-domain simultaneous orthogonal matching\npursuit (S-SOMP) based scheme tailored for near-field 3D channel estimation in\nUCA-equipped XL-MIMO systems. We establish a sparse channel representation\nbased on the near-field spherical wave model. Then, a novel spherical-domain\ntransform matrix codebook is designed via joint discrete sampling of distance,\nazimuth, and elevation parameters, leveraging analytical approximations to\nensure low correlation between steering vectors. This structured codebook\nenables accurate sparse signal recovery using the S-SOMP algorithm for\nefficient joint estimation of channel path gains, spatial angles, and\ndistances. Simulation results demonstrate significant channel estimation\naccuracy improvements compared to existing benchmarks.", "published": "2025-07-04 12:03:28", "link": "http://arxiv.org/abs/2507.03507v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Class-Based Expurgation Attains Csisz\u00e1r's Expurgated Source-Channel Exponent", "abstract": "This paper studies expurgated error exponents for joint source-channel coding\nfor discrete memoryless sources and channels. We consider a partition of the\nsource messages into classes, where the codeword distributions depend on the\nclass. We show that two carefully chosen classes suffice to achieve Csisz\\'ar's\nexpurgated exponent.", "published": "2025-07-04 11:17:18", "link": "http://arxiv.org/abs/2507.03481v1", "categories": ["cs.IT", "math.IT", "math.PR"], "primary_category": "cs.IT"}
{"title": "Learning Variable Node Selection for Improved Multi-Round Belief Propagation Decoding", "abstract": "Error correction at short blocklengths remains a challenge for low-density\nparity-check (LDPC) codes, as belief propagation (BP) decoding is suboptimal\ncompared to maximum-likelihood decoding (MLD). While BP rarely makes errors, it\noften fails to converge due to a small number of problematic, erroneous\nvariable nodes (VNs). Multi-round BP (MRBP) decoding improves performance by\nidentifying and perturbing these VNs, enabling BP to succeed in subsequent\ndecoding attempts. However, existing heuristic approaches for VN identification\nmay require a large number of decoding rounds to approach ML performance. In\nthis work, we draw a connection between identifying candidate VNs to perturb in\nMRBP and estimating channel output errors, a problem previously addressed by\nsyndrome-based neural decoders (SBND). Leveraging this insight, we propose an\nSBND-inspired neural network architecture that learns to predict which VNs MRBP\nneeds to focus on. Experimental results demonstrate that the proposed learning\napproach outperforms expert rules from the literature, requiring fewer MRBP\ndecoding attempts to reach near-MLD performance. This makes it a promising lead\nfor improving the decoding of short LDPC codes.", "published": "2025-07-04 10:38:40", "link": "http://arxiv.org/abs/2507.03461v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Movable-Antenna-Enhanced Physical-Layer Service Integration: Performance Analysis and Optimization", "abstract": "Movable antennas (MAs) have drawn increasing attention in wireless\ncommunications due to their capability to create favorable channel conditions\nvia local movement within a confined region. In this letter, we investigate its\napplication in physical-layer service integration (PHY-SI), where a multi-MA\nbase station (BS) simultaneously transmits both confidential and multicast\nmessages to two users. The multicast message is intended for both users, while\nthe confidential message is intended only for one user and must remain\nperfectly secure from the other. Our goal is to jointly optimize the secrecy\nand multicast beamforming, as well as the MAs' positions at the BS to maximize\nthe secrecy rate for one user while satisfying the multicast rate requirement\nfor both users. To gain insights, we first conduct performance analysis of this\nMA-enhanced PHY-SI system in two special cases, revealing its unique\ncharacteristics compared to conventional PHY-SI with fixed-position antennas\n(FPAs). To address the secrecy rate maximization problem, we propose a\ntwo-layer optimization framework that integrates the semidefinite relaxation\n(SDR) technique and a discrete sampling algorithm. Numerical results\ndemonstrate that MAs can greatly enhance the achievable secrecy rate region for\nPHY-SI compared to FPAs.", "published": "2025-07-04 10:07:09", "link": "http://arxiv.org/abs/2507.03449v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Set Shaping Theory and the Foundations of Redundancy-Free Testable Codes", "abstract": "To render a sequence testable, namely capable of identifying and detecting\nerrors, it is necessary to apply a transformation that increases its length by\nintroducing statistical dependence among symbols, as commonly exemplified by\nthe addition of parity bits. However, since the decoder does not have prior\nknowledge of the original symbols, it must treat the artificially introduced\nsymbols as if they were independent. Consequently, these additional symbols\nmust be transmitted, even though their conditional probability, under ideal and\nerror free conditions, would be zero. This sequence extension implies that not\nall symbol combinations of the new length are practically realizable: if an\nerror modifies a sequence, making it inadmissible such an error becomes\ndetectable. Recent developments in Set Shaping Theory have revealed a\nsurprising result: it is always possible to transform a sequence into a longer\nversion by carefully selecting which longer sequences are allowed, in such a\nway that the overall set of sequences becomes more structured and less complex\nthan the original. This means that even though the sequence is extended and\ndependencies are introduced between symbols, the total amount of information\ncontained in the new set does not increase proportionally on the contrary, it\ncan be slightly reduced. In other words, one can construct a new set of longer\nsequences where each one corresponds uniquely to an original sequence, but the\nentire set is designed in such a way that it can be treated as if the symbols\nwere independent, making encoding simpler. This allows sequence to become\ntestable capable of detecting errors without adding visible redundancy or\nincreasing the informational content.", "published": "2025-07-04 10:00:10", "link": "http://arxiv.org/abs/2507.03444v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Specific Absorption Rate-Aware Multiuser MIMO Assisted by Fluid Antenna System", "abstract": "With the development of the upcoming sixth-generation (6G) wireless networks,\nthere is a pressing need for innovative technologies capable of satisfying\nheightened performance indicators. Fluid antenna system (FAS) is proposed\nrecently as a promising technique to achieve higher data rates and more\ndiversity gains by dynamically changing the positions of the antennas to form a\nmore desirable channel. However, worries regarding the possibly harmful effects\nof electromagnetic (EM) radiation emitted by devices have arisen as a result of\nthe rapid evolution of advanced techniques in wireless communication systems.\nSpecific absorption rate (SAR) is a widely adopted metric to quantify EM\nradiation worldwide. In this paper, we investigate the SAR-aware multiuser\nmultiple-input multiple-output (MIMO) communications assisted by FAS. In\nparticular, a two-layer iterative algorithm is proposed to minimize the SAR\nvalue under signal-to-interference-plus-noise ratio (SINR) and FAS constraints.\nMoreover, the minimum weighted SINR maximization problem under SAR and FAS\nconstraints is studied by finding its relationship with the SAR minimization\nproblem. Simulation results verify that the proposed SAR-aware FAS design\noutperforms the adaptive backoff and fixed-position antenna designs.", "published": "2025-07-04 07:34:34", "link": "http://arxiv.org/abs/2507.03351v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Function-Correcting Codes with Homogeneous Distance", "abstract": "Function-correcting codes are designed to reduce redundancy of codes when\nprotecting function values of information against errors. As generalizations of\nHamming weights and Lee weights over $ \\mathbb{Z}_{4} $, homogeneous weights\nare used in codes over finite rings. In this paper, we introduce\nfunction-correcting codes with homogeneous distance denoted by FCCHDs, which\nextend function-correcting codes with Hamming distance. We first define $ D\n$-homogeneous distance codes. We use $ D $-homogenous distance codes to\ncharacterize connections between the optimal redundancy of FCCHDs and lengths\nof these codes for some matrices $ D $. By these connections, we obtain several\nbounds of the optimal redundancy of FCCHDs for some functions. In addition, we\nalso construct FCCHDs for homogeneous weight functions and homogeneous weight\ndistribution functions. Specially, redundancies of some codes we construct in\nthis paper reach the optimal redundancy bounds.", "published": "2025-07-04 06:39:53", "link": "http://arxiv.org/abs/2507.03332v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Spectrahedral relaxations of Eulerian rigidly convex sets", "abstract": "We study a generalization of Eulerian polynomials to the multivariate setting\nintroduced by Br\\\"and\\'en. Although initially these polynomials were introduced\nusing the language of hyperbolic and stable polynomials, we manage to translate\nsome restrictions of these polynomials to our real zero setting. Once we are in\nthis setting, we focus our attention on the rigidly convex sets (RCSs) defined\nby these polynomials. In particular, we study the corresponding rigidly convex\nsets looking at spectrahedral relaxations constructed through the use of monic\nsymmetric linear matrix polynomials (MSLMPs) of small size and depending\npolynomially (actually just cubically) on the coefficients of the corresponding\npolynomials. We analyze how good are the obtained spectrahedral approximations\nto these rigidly convex sets. We do this analysis by measuring the behavior\nalong the diagonal, where we precisely recover the original univariate Eulerian\npolynomials. Thus we conclude that, measuring through the diagonal, our\nrelaxation-based spectrahedral method for approximation of the rigidly convex\nsets defined by multivariate Eulerian polynomials is highly accurate. In\nparticular, we see that this relaxation-based spectrahedral method for\napproximation of the rigidly convex sets defined by multivariate Eulerian\npolynomials provides bounds for the extreme roots of the corresponding\nunivariate Eulerian polynomials that are better than these already found in the\nliterature. All in all, this tells us that, at least close to the diagonal, the\nglobal outer approximation to the rigidly convex sets provided by this\nrelaxation-based spectrahedral method is itself highly accurate.", "published": "2025-07-04 20:42:31", "link": "http://arxiv.org/abs/2507.03800v1", "categories": ["math.CO", "cs.NA", "math.AG", "math.NA", "math.OC", "05A05, 05A15, 05A20 (Primary), 06A07, 65H04, 41A10, 41A45, 41A60,\n  90C23 (Secondary)", "G.2.1; G.1.2; G.1.3; G.1.5; G.1.6"], "primary_category": "math.CO"}
{"title": "Efficient Quantum Access Model for Sparse Structured Matrices using Linear Combination of Things", "abstract": "We develop a novel approach for Linear combination of unitaries (LCU) type\ndecomposition for structured sparse matrices. Such matrices frequently arise\nduring numerical solution of partial differential equations which are\nubiquitous in science and engineering. LCU is a versatile quantum algorithmic\nprimitive that plays an important role in context of both variational quantum\nalgorithms (VQA) and fully fault-tolerant ones, and has been applied to a\ndiverse range of problems. Conventionally, Pauli basis is used for LCU\ndecomposition, which however in worst case can result in number of LCU terms\nthat scale quadratically with respect to the matrix size. We show that by using\nan alternate basis one can better exploit the sparsity and underlying structure\nof matrix leading to number of tensor product terms which scale only\nlogarithmically with respect to the matrix size. We develop numerical and\nsemi-analytical approaches for computing sigma basis decomposition for an\narbitrary matrix. Given this new basis is comprised of non-unitary operators,\nwe employ the concept of unitary completion to design efficient quantum\ncircuits for evaluation of the expectation values of operators composed of\ntensor product of elements from sigma basis which can be used for cost function\nevaluation in VQAs. We also develop an approach for block encoding of arbitrary\noperator given its decomposition in sigma basis which could be used in variety\nof fully fault-tolerant algorithms. We compare our approach with other related\nconcepts in the literature including unitary dilation and provide numerical\nillustrations on several PDE examples.", "published": "2025-07-04 17:05:07", "link": "http://arxiv.org/abs/2507.03714v1", "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "quant-ph"}
{"title": "Adjoint-based A Posteriori Error Analysis for Semi-explicit Index-1 and Hessenberg Index-2 Differential-Algebraic Equations", "abstract": "In this work we develop and analyze adjoint-based analyses for \\textit{a\nposteriori} error estimation for the temporal discretization of\ndifferential-algebraic equations (DAEs) of special type: semi-explicit index-1\nand Hessenberg index-2. Our technique quantifies the error in a Quantity of\nInterest (QoI), which is defined as a bounded linear functional of the solution\nof a DAE. We derive representations for errors various trypes of QoIs\n(depending on the entire time interval, final time, algebraic variables,\ndifferential variables etc.). We form two analyses: one that defines the\nadjoint to the DAE system, and one that first converts the DAE to an ODE system\nand then applies classical \\textit{a posteriori} analysis techniques. A number\nof examples are presented, including nonlinear and non-autonomous DAEs, as well\nas discretized partial differential-algebraic equations (PDAEs). Numerical\nresults indicate a high degree of accuracy in the error estimation.", "published": "2025-07-04 16:57:49", "link": "http://arxiv.org/abs/2507.03712v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Noise-robust multi-fidelity surrogate modelling for parametric partial differential equations", "abstract": "We address the challenge of constructing noise-robust surrogate models for\nquantities of interest (QoIs) arising from parametric partial differential\nequations (PDEs), using multi-fidelity collocation techniques; specifically,\nthe Multi-Index Stochastic Collocation (MISC). In practical scenarios, the PDE\nevaluations used to build a response surface are often corrupted by numerical\nnoise, especially for the low-fidelity models. This noise, which may originate\nfrom loose solver tolerances, coarse discretisations, or transient effects, can\nlead to overfitting in MISC, degrading surrogate quality through nonphysical\noscillations and loss of convergence, thereby limiting its utility in\ndownstream tasks like uncertainty quantification, optimisation, and control. To\ncorrect this behaviour, we propose an improved version of MISC that can\nautomatically detect the presence of solver noise during the surrogate model\nconstruction and then ignore the exhausted fidelities. Our approach monitors\nthe spectral decay of the surrogate at each iteration, identifying stagnation\nin the coefficient spectrum that signals the onset of noise. Once detected, the\nalgorithm selectively halts the use of noisy fidelities, focusing computational\nresources on those fidelities that still provide meaningful information. The\neffectiveness of this approach is numerically validated on two challenging test\ncases: a parabolic advection--diffusion PDE with uncertain coefficients, and a\nparametric turbulent incompressible Navier--Stokes problem. The results\nshowcase the accuracy and robustness of the resulting multi-fidelity surrogate\nand its capability to extract relevant information, even from under-resolved\nmeshes not suitable for reliable single-fidelity computations.", "published": "2025-07-04 16:18:57", "link": "http://arxiv.org/abs/2507.03691v1", "categories": ["math.NA", "cs.CE", "cs.NA"], "primary_category": "math.NA"}
{"title": "Bilinear Quadratic Output Systems and Balanced Truncation", "abstract": "Dynamical systems with quadratic outputs have recently attracted significant\nattention. In this paper, we consider bilinear dynamical systems, a special\nclass of weakly nonlinear systems, with a quadratic output. We develop various\nprimal-dual formulations for these systems and define the corresponding system\nGramians. Conditions for the existence and uniqueness of these Gramians are\nestablished, and the generalized Lyapunov equations they satisfy are derived.\nUsing these Gramians and their truncated versions, which are computationally\nmore efficient, we construct a balanced truncation framework for bilinear\nsystems with quadratic outputs. The proposed approach is demonstrated through\ntwo numerical examples.", "published": "2025-07-04 16:04:15", "link": "http://arxiv.org/abs/2507.03684v1", "categories": ["math.NA", "cs.NA", "93A15, 93B05, 93B07, 93C10, 93C15"], "primary_category": "math.NA"}
{"title": "PINN-DG: Residual neural network methods trained with Finite Elements", "abstract": "Over the past few years, neural network methods have evolved in various\ndirections for approximating partial differential equations (PDEs). A promising\nnew development is the integration of neural networks with classical numerical\ntechniques such as finite elements and finite differences. In this paper, we\nintroduce a new class of Physics-Informed Neural Networks (PINNs) trained using\ndiscontinuous Galerkin finite element methods. Unlike standard\ncollocation-based PINNs that rely on pointwise gradient evaluations and Monte\nCarlo quadrature, our approach computes the loss functional using finite\nelement interpolation and integration. This avoids costly pointwise derivative\ncomputations, particularly advantageous for elliptic PDEs requiring\nsecond-order derivatives, and inherits key stability and accuracy benefits from\nthe finite element framework. We present a convergence analysis based on\nvariational arguments and support our theoretical findings with numerical\nexperiments that demonstrate improved efficiency and robustness.", "published": "2025-07-04 12:16:57", "link": "http://arxiv.org/abs/2507.03521v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "65M15 (Primary), 65M12 (Secondary)"], "primary_category": "math.NA"}
{"title": "Elliptic interface problem approximated by CutFEM: I. Conservative flux recovery and numerical validation of adaptive mesh refinement", "abstract": "We study an elliptic interface problem with discontinuous diffusion\ncoefficients on unfitted meshes using the CutFEM method. Our main contribution\nis the reconstruction of conservative fluxes from the CutFEM solution and their\nuse in a posteriori error estimation. We introduce a hybrid mixed formulation\nwith locally computable Lagrange multipliers and reconstruct the flux in the\nimmersed Raviart-Thomas space. Based on this, we propose a new a posteriori\nerror estimator that includes both volume and interface terms. We state its\nrobust reliability and local efficiency, and validate the approach through\nnumerical experiments.", "published": "2025-07-04 11:31:57", "link": "http://arxiv.org/abs/2507.03492v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Generalized UGK scheme in the diffusive", "abstract": "The unified gas kinetic scheme (UGKS) was initially designed to address\nmultiscale challenges in rarefied gas dynamics and then extended to radiative\ntransfert theory, as described by BGK like relaxation models. In this work, we\nextend its application to linear kinetic models with non isotropic scattering\ncollision operators, as well as Fokker-Planck models . These problems typically\nexhibit a fully diffusive nature in the optically thick limit (corresponding to\na small Knudsen number). It still leads to an asymptotic preserving (AP)\nproperty not only in this diffusive regime but also in the free transport\nlimit. A series of numerical experiments confirm the effectiveness of the\napproach.", "published": "2025-07-04 08:34:33", "link": "http://arxiv.org/abs/2507.03385v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On the non-convexity issue in the radial Calder\u00f3n problem", "abstract": "A classical approach to the Calder\\'on problem is to estimate the unknown\nconductivity by solving a nonlinear least-squares problem. It is generally\nbelieved that it leads to a nonconvex optimization problem which is riddled\nwith bad local minimums. This has motivated the development of reconstruction\nmethods based on convex optimization, one recent contribution being the\nnonlinear convex semidefinite programming approach of Harrach (2023). In this\nwork, we investigate the computational viability of this convex approach in a\nsimple setting where the conductivities are piecewise constant and radial. We\nimplement this convex reconstruction method and compare it extensively to the\nleast squares approach. Our experiments suggest that this convex programming\napproach only allows to accurately estimate the unknown for problems with a\nvery small size. Moreover, surprisingly, it is consistently outperformed by\nNewton-type least squares solvers, which are also faster and require less\nmeasurements. We revisit the issue of nonconvexity in this piecewise constant\nradial setting and prove that, contrary to previous claims, there are no local\nminimums in the case of two scalar unknowns with no measurement noise. We also\nprovide a partial proof of this result in the general setting which holds under\na numerically verifiable assumption.", "published": "2025-07-04 08:23:43", "link": "http://arxiv.org/abs/2507.03379v1", "categories": ["math.NA", "cs.NA", "math.AP", "math.OC"], "primary_category": "math.NA"}
{"title": "Structured Backward Errors of Sparse Generalized Saddle Point Problems with Hermitian Block Matrices", "abstract": "In this paper, we derive the structured backward error (BE) for a class of\ngeneralized saddle point problems (GSPP) by preserving the sparsity pattern and\nHermitian structures of the block matrices. Additionally, we construct the\noptimal backward perturbation matrices for which the structured BE is achieved.\nOur analysis also examines the structured BE in cases where the sparsity\npattern is not maintained. Through numerical experiments, we demonstrate the\nreliability of the derived structured BEs and the corresponding optimal\nbackward perturbations. Additionally, the derived structured BEs are used to\nassess the strong backward stability of numerical methods for solving the GSPP.", "published": "2025-07-04 06:45:00", "link": "http://arxiv.org/abs/2507.03335v1", "categories": ["math.NA", "cs.NA", "15A12, 65F20, 65F35, 65F99"], "primary_category": "math.NA"}
{"title": "Real-time prediction of plasma instabilities with sparse-grid-accelerated optimized dynamic mode decomposition", "abstract": "Parametric data-driven reduced-order models (ROMs) that embed dependencies in\na large number of input parameters are crucial for enabling many-query tasks in\nlarge-scale problems. These tasks, including design optimization, control, and\nuncertainty quantification, are essential for developing digital twins in\nreal-world applications. However, standard training data generation methods are\ncomputationally prohibitive due to the curse of dimensionality, as their cost\nscales exponentially with the number of inputs.This paper investigates\nefficient training of parametric data-driven ROMs using sparse grid\ninterpolation with (L)-Leja points, specifically targeting scenarios with\nhigher-dimensional input parameter spaces. (L)-Leja points are nested and\nexhibit slow growth, resulting in sparse grids with low cardinality in\nlow-to-medium dimensional settings, making them ideal for large-scale,\ncomputationally expensive problems. Focusing on gyrokinetic simulations of\nplasma micro-instabilities in fusion experiments as a representative real-world\napplication, we construct parametric ROMs for the full 5D gyrokinetic\ndistribution function via optimized dynamic mode decomposition (optDMD) and\nsparse grids based on (L)-Leja points. We perform detailed experiments in two\nscenarios: First, the Cyclone Base Case benchmark assesses optDMD ROM\nprediction capabilities beyond training time horizons and across variations in\nthe binormal wave number. Second, for a real-world electron temperature\ngradient driven micro-instability simulation featuring six input parameters, we\ndemonstrate that an accurate parametric optDMD ROM can be constructed at a cost\nof only $28$ high-fidelity gyrokinetic simulations thanks to sparse grids. In\nthe broader context of fusion research, these results demonstrate the potential\nof sparse grid-based parametric ROMs to enable otherwise intractable many-query\ntasks.", "published": "2025-07-04 01:34:54", "link": "http://arxiv.org/abs/2507.03245v1", "categories": ["physics.comp-ph", "cs.CE", "cs.NA", "math.NA", "physics.plasm-ph"], "primary_category": "physics.comp-ph"}
{"title": "Perpetual American Standard and Lookback Options in Insider Models with Progressively Enlarged Filtrations", "abstract": "We derive closed-form solutions to the optimal stopping problems related to\nthe pricing of perpetual American standard and lookback put and call options in\nthe extensions of the Black-Merton-Scholes model with progressively enlarged\nfiltrations. More specifically, the information available to the insider is\nmodelled by Brownian filtrations progressively enlarged with the times of\neither the global maximum or minimum of the underlying risky asset price over\nthe infinite time interval, which is not a stopping time in the filtration\ngenerated by the underlying risky asset. We show that the optimal exercise\ntimes are the first times at which the asset price process reaches either lower\nor upper stochastic boundaries depending on the current values of its running\nmaximum or minimum given the occurrence of times of either the global maximum\nor minimum, respectively. The proof is based on the reduction of the original\nproblems into the necessarily three-dimensional optimal stopping problems and\nthe equivalent free-boundary problems. We apply either the normal-reflection or\nthe normal-entrance conditions as well as the smooth-fit conditions for the\nvalue functions to characterise the candidate boundaries as either the maximal\nor minimal solutions to the associated first-order nonlinear ordinary\ndifferential equations and the transcendental arithmetic equations,\nrespectively.", "published": "2025-07-04 10:47:50", "link": "http://arxiv.org/abs/2507.03470v1", "categories": ["q-fin.MF", "q-fin.PR", "91B25, 60G40, 60G44"], "primary_category": "q-fin.MF"}
{"title": "IMPACT: Importance-Aware Activation Space Reconstruction", "abstract": "Large language models (LLMs) achieve strong performance across many domains\nbut are difficult to deploy in resource-constrained settings due to their size.\nLow-rank weight matrix compression is a popular strategy for reducing model\nsize, typically by minimizing weight reconstruction error under the assumption\nthat weights are low-rank. However, this assumption often does not hold in\nLLMs. Instead, LLM activations exhibit stronger low-rank structure-prompting a\nshift toward minimizing activation reconstruction error.\n  We show that this shift alone is insufficient: activation dimensions\ncontribute unequally to model performance, and uniform reconstruction can harm\nperformance. We propose IMPACT, a principled framework for importance-aware\nactivation reconstruction that links model compression decisions to their\nimpact on model behavior. IMPACT formulates an optimization problem that\nconsiders both activation structure and gradient sensitivity, and derives a\nclosed-form solution where the optimal reconstruction bases are the\neigenvectors of an importance-weighted activation covariance matrix. This\nenables low-rank approximations explicitly optimized to preserve accuracy.\nExperiments across diverse models and tasks show that IMPACT achieves up to\n48.6% greater model size reduction with accuracy comparable to state-of-the-art\nbaselines.", "published": "2025-07-04 22:26:33", "link": "http://arxiv.org/abs/2507.03828v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Skewed Score: A statistical framework to assess autograders", "abstract": "The evaluation of large language model (LLM) outputs is increasingly\nperformed by other LLMs, a setup commonly known as \"LLM-as-a-judge\", or\nautograders. While autograders offer a scalable alternative to human\nevaluation, they have shown mixed reliability and may exhibit systematic\nbiases, depending on response type, scoring methodology, domain specificity,\nand other factors. In this paper we propose a statistical framework based on\nBayesian generalised linear models (GLMs) that enables researchers to\nsimultaneously assess their autograders while also addressing their primary\nresearch questions (e.g., LLM evaluation). Our approach models evaluation\noutcomes (e.g., scores or pairwise preferences) as a function of properties of\nthe grader (e.g., human vs. autograder) and the evaluated item (e.g., response\nlength or the LLM that generated it), allowing for explicit quantification of\nscoring differences and potential biases within a unified framework. In\naddition, our method can be used to augment traditional reliability metrics\nsuch as inter-rater agreement, by providing uncertainty estimates and\nclarifying the source of disagreement. Overall, this approach contributes to\nmore robust and interpretable use of autograders in LLM evaluation, enabling\nboth performance analysis and bias detection.", "published": "2025-07-04 18:45:10", "link": "http://arxiv.org/abs/2507.03772v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sequential Regression Learning with Randomized Algorithms", "abstract": "This paper presents ``randomized SINDy\", a sequential machine learning\nalgorithm designed for dynamic data that has a time-dependent structure. It\nemploys a probabilistic approach, with its PAC learning property rigorously\nproven through the mathematical theory of functional analysis. The algorithm\ndynamically predicts using a learned probability distribution of predictors,\nupdating weights via gradient descent and a proximal algorithm to maintain a\nvalid probability density. Inspired by SINDy (Brunton et al. 2016), it\nincorporates feature augmentation and Tikhonov regularization. For multivariate\nnormal weights, the proximal step is omitted to focus on parameter estimation.\nThe algorithm's effectiveness is demonstrated through experimental results in\nregression and binary classification using real-world data.", "published": "2025-07-04 18:14:36", "link": "http://arxiv.org/abs/2507.03759v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Implicit Regularisation in Diffusion Models: An Algorithm-Dependent Generalisation Analysis", "abstract": "The success of denoising diffusion models raises important questions\nregarding their generalisation behaviour, particularly in high-dimensional\nsettings. Notably, it has been shown that when training and sampling are\nperformed perfectly, these models memorise training data -- implying that some\nform of regularisation is essential for generalisation. Existing theoretical\nanalyses primarily rely on algorithm-independent techniques such as uniform\nconvergence, heavily utilising model structure to obtain generalisation bounds.\nIn this work, we instead leverage the algorithmic aspects that promote\ngeneralisation in diffusion models, developing a general theory of\nalgorithm-dependent generalisation for this setting. Borrowing from the\nframework of algorithmic stability, we introduce the notion of score stability,\nwhich quantifies the sensitivity of score-matching algorithms to dataset\nperturbations. We derive generalisation bounds in terms of score stability, and\napply our framework to several fundamental learning settings, identifying\nsources of regularisation. In particular, we consider denoising score matching\nwith early stopping (denoising regularisation), sampler-wide coarse\ndiscretisation (sampler regularisation) and optimising with SGD (optimisation\nregularisation). By grounding our analysis in algorithmic properties rather\nthan model structure, we identify multiple sources of implicit regularisation\nunique to diffusion models that have so far been overlooked in the literature.", "published": "2025-07-04 18:07:06", "link": "http://arxiv.org/abs/2507.03756v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Determination of Particle-Size Distributions from Light-Scattering Measurement Using Constrained Gaussian Process Regression", "abstract": "In this work, we propose a novel methodology for robustly estimating particle\nsize distributions from optical scattering measurements using constrained\nGaussian process regression. The estimation of particle size distributions is\ncommonly formulated as a Fredholm integral equation of the first kind, an\nill-posed inverse problem characterized by instability due to measurement noise\nand limited data. To address this, we use a Gaussian process prior to\nregularize the solution and integrate a normalization constraint into the\nGaussian process via two approaches: by constraining the Gaussian process using\na pseudo-measurement and by using Lagrange multipliers in the equivalent\noptimization problem. To improve computational efficiency, we employ a spectral\nexpansion of the covariance kernel using eigenfunctions of the Laplace\noperator, resulting in a computationally tractable low-rank representation\nwithout sacrificing accuracy. Additionally, we investigate two complementary\nstrategies for hyperparameter estimation: a data-driven approach based on\nmaximizing the unconstrained log marginal likelihood, and an alternative\napproach where the physical constraints are taken into account. Numerical\nexperiments demonstrate that the proposed constrained Gaussian process\nregression framework accurately reconstructs particle size distributions,\nproducing numerically stable, smooth, and physically interpretable results.\nThis methodology provides a principled and efficient solution for addressing\ninverse scattering problems and related ill-posed integral equations.", "published": "2025-07-04 17:56:16", "link": "http://arxiv.org/abs/2507.03736v1", "categories": ["stat.ML", "cs.LG", "physics.optics", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Robust estimation of heterogeneous treatment effects in randomized trials leveraging external data", "abstract": "Randomized trials are typically designed to detect average treatment effects\nbut often lack the statistical power to uncover effect heterogeneity over\npatient characteristics, limiting their value for personalized decision-making.\nTo address this, we propose the QR-learner, a model-agnostic learner that\nestimates conditional average treatment effects (CATE) within the trial\npopulation by leveraging external data from other trials or observational\nstudies. The proposed method is robust: it has the potential to reduce the CATE\nprediction mean squared error while maintaining consistency, even when the\nexternal data is not aligned with the trial. Moreover, we introduce a procedure\nthat combines the QR-learner with a trial-only CATE learner and show that it\nasymptotically matches or exceeds the trial-only learner in terms of mean\nsquared error. We examine the performance of our approach in simulation studies\nand apply the methods to a real-world dataset, demonstrating improvements in\nboth CATE estimation and statistical power for detecting heterogeneous effects.", "published": "2025-07-04 16:01:05", "link": "http://arxiv.org/abs/2507.03681v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Disentangling Doubt in Deep Causal AI", "abstract": "Accurate individual treatment-effect estimation in high-stakes applications\ndemands both reliable point predictions and interpretable uncertainty\nquantification. We propose a factorized Monte Carlo Dropout framework for deep\ntwin-network models that splits total predictive variance into representation\nuncertainty (sigma_rep) in the shared encoder and prediction uncertainty\n(sigma_pred) in the outcome heads. Across three synthetic covariate-shift\nregimes, our intervals are well-calibrated (ECE < 0.03) and satisfy sigma_rep^2\n+ sigma_pred^2 ~ sigma_tot^2. Additionally, we observe a crossover: head\nuncertainty leads on in-distribution data, but representation uncertainty\ndominates under shift. Finally, on a real-world twins cohort with induced\nmultivariate shifts, only sigma_rep spikes on out-of-distribution samples\n(delta sigma ~ 0.0002) and becomes the primary error predictor (rho_rep <=\n0.89), while sigma_pred remains flat. This module-level decomposition offers a\npractical diagnostic for detecting and interpreting uncertainty sources in deep\ncausal-effect models.", "published": "2025-07-04 14:48:51", "link": "http://arxiv.org/abs/2507.03622v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Degrees of Freedom for Linear Attention: Distilling Softmax Attention with Optimal Feature Efficiency", "abstract": "Linear attention has attracted interest as a computationally efficient\napproximation to softmax attention, especially for long sequences. Recent\nstudies have explored distilling softmax attention in pre-trained Transformers\ninto linear attention. However, a critical challenge remains: how to choose the\nfeature dimension that governs the approximation quality. Existing methods fix\nthis dimension uniformly across all attention layers, overlooking the diverse\nroles and complexities of them. In this paper, we propose a principled method\nto automatically determine the feature dimension in linear attention using the\nconcept of statistical degrees of freedom, which represent the effective\ndimensionality of the inputs. We provide a theoretical bound on the\napproximation error and show that the dimension chosen by our method achieves\nsmaller error under a fixed computational budget. Furthermore, we introduce an\nefficient layerwise training strategy to learn nonlinear features tailored to\neach layer. Experiments on multiple pre-trained transformers demonstrate that\nour method improves the performance of distilled models compared to baselines\nwithout increasing the inference cost. Our findings also provide insight into\nhow the complexity of the attention mechanism evolves across layers.", "published": "2025-07-04 06:59:17", "link": "http://arxiv.org/abs/2507.03340v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Conformal Information Pursuit for Interactively Guiding Large Language Models", "abstract": "A significant use case of instruction-finetuned Large Language Models (LLMs)\nis to solve question-answering tasks interactively. In this setting, an LLM\nagent is tasked with making a prediction by sequentially querying relevant\ninformation from the user, as opposed to a single-turn conversation. This paper\nexplores sequential querying strategies that aim to minimize the expected\nnumber of queries. One such strategy is Information Pursuit (IP), a greedy\nalgorithm that at each iteration selects the query that maximizes information\ngain or equivalently minimizes uncertainty. However, obtaining accurate\nestimates of mutual information or conditional entropy for LLMs is very\ndifficult in practice due to over- or under-confident LLM probabilities, which\nleads to suboptimal query selection and predictive performance. To better\nestimate the uncertainty at each iteration, we propose Conformal Information\nPursuit (C-IP), an alternative approach to sequential information gain based on\nconformal prediction sets. More specifically, C-IP leverages a relationship\nbetween prediction sets and conditional entropy at each iteration to estimate\nuncertainty based on the average size of conformal prediction sets. In contrast\nto conditional entropy, we find that conformal prediction sets are a\ndistribution-free and robust method of measuring uncertainty. Experiments with\n20 Questions show that C-IP obtains better predictive performance and shorter\nquery-answer chains compared to previous approaches to IP and uncertainty-based\nchain-of-thought methods. Furthermore, extending to an interactive medical\nsetting between a doctor and a patient on the MediQ dataset, C-IP achieves\ncompetitive performance with direct single-turn prediction while offering\ngreater interpretability.", "published": "2025-07-04 03:55:39", "link": "http://arxiv.org/abs/2507.03279v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "LILI clustering algorithm: Limit Inferior Leaf Interval Integrated into Causal Forest for Causal Interference", "abstract": "Causal forest methods are powerful tools in causal inference. Similar to\ntraditional random forest in machine learning, causal forest independently\nconsiders each causal tree. However, this independence consideration increases\nthe likelihood that classification errors in one tree are repeated in others,\npotentially leading to significant bias in causal e ect estimation. In this\npaper, we propose a novel approach that establishes connections between causal\ntrees through the Limit Inferior Leaf Interval (LILI) clustering algorithm.\nLILIs are constructed based on the leaves of all causal trees, emphasizing the\nsimilarity of dataset confounders. When two instances with di erent treatments\nare grouped into the same leaf across a su cient number of causal trees, they\nare treated as counterfactual outcomes of each other. Through this clustering\nmechanism, LILI clustering reduces bias present in traditional causal tree\nmethods and enhances the prediction accuracy for the average treatment e ect\n(ATE). By integrating LILIs into a causal forest, we develop an e cient causal\ninference method. Moreover, we explore several key properties of LILI by\nrelating it to the concepts of limit inferior and limit superior in the set\ntheory. Theoretical analysis rigorously proves the convergence of the estimated\nATE using LILI clustering. Empirically, extensive comparative experiments\ndemonstrate the superior performance of LILI clustering.", "published": "2025-07-04 03:04:00", "link": "http://arxiv.org/abs/2507.03271v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Assessing the Viability of Wave Field Synthesis in VR-Based Cognitive Research", "abstract": "This paper investigates the viability of Wave Field Synthesis (WFS) for\nenhancing auditory immersion in VR-based cognitive research. While Virtual\nReality (VR) offers significant advantages for studying human perception and\nbehavior, auditory cues are often underutilized. WFS, an advanced audio\nrendering technique, can create highly realistic and spatially accurate\nsoundscapes, potentially increasing ecological validity. This study evaluates\nWFS by implementing a sample experiment where participants localize static and\nmoving sound sources in both a WFS-rendered environment and a conventional\nstereo headphone setup. The research explores the impact of virtual\nenvironments, sound types, and durations on localization accuracy and search\nbehavior. Findings indicate that while stereo setups can achieve higher\naccuracy, WFS provides a more natural and intuitive auditory experience,\nparticularly for directional cues. The study also highlights limitations of\ncurrent WFS systems, such as the lack of height localization, occlusion\nsimulation, and user-dependent optimization, which affect performance,\nespecially for centrally located sound sources. Despite these challenges, WFS\nshows promise for specialized auditory perception research, particularly for\ncomplex soundscapes where directional information is paramount.", "published": "2025-07-04 20:30:51", "link": "http://arxiv.org/abs/2507.03797v1", "categories": ["cs.HC", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Improving Low-Resource Dialect Classification Using Retrieval-based Voice Conversion", "abstract": "Deep learning models for dialect identification are often limited by the\nscarcity of dialectal data. To address this challenge, we propose to use\nRetrieval-based Voice Conversion (RVC) as an effective data augmentation method\nfor a low-resource German dialect classification task. By converting audio\nsamples to a uniform target speaker, RVC minimizes speaker-related variability,\nenabling models to focus on dialect-specific linguistic and phonetic features.\nOur experiments demonstrate that RVC enhances classification performance when\nutilized as a standalone augmentation method. Furthermore, combining RVC with\nother augmentation methods such as frequency masking and segment removal leads\nto additional performance gains, highlighting its potential for improving\ndialect classification in low-resource scenarios.", "published": "2025-07-04 15:14:49", "link": "http://arxiv.org/abs/2507.03641v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MusGO: A Community-Driven Framework For Assessing Openness in Music-Generative AI", "abstract": "Since 2023, generative AI has rapidly advanced in the music domain. Despite\nsignificant technological advancements, music-generative models raise critical\nethical challenges, including a lack of transparency and accountability, along\nwith risks such as the replication of artists' works, which highlights the\nimportance of fostering openness. With upcoming regulations such as the EU AI\nAct encouraging open models, many generative models are being released labelled\nas 'open'. However, the definition of an open model remains widely debated. In\nthis article, we adapt a recently proposed evidence-based framework for\nassessing openness in LLMs to the music domain. Using feedback from a survey of\n110 participants from the Music Information Retrieval (MIR) community, we\nrefine the framework into MusGO (Music-Generative Open AI), which comprises 13\nopenness categories: 8 essential and 5 desirable. We evaluate 16\nstate-of-the-art generative models and provide an openness leaderboard that is\nfully open to public scrutiny and community contributions. Through this work,\nwe aim to clarify the concept of openness in music-generative AI and promote\nits transparent and responsible development.", "published": "2025-07-04 14:12:19", "link": "http://arxiv.org/abs/2507.03599v1", "categories": ["cs.SD", "cs.AI", "cs.CY", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RECA-PD: A Robust Explainable Cross-Attention Method for Speech-based Parkinson's Disease Classification", "abstract": "Parkinson's Disease (PD) affects over 10 million people globally, with speech\nimpairments often preceding motor symptoms by years, making speech a valuable\nmodality for early, non-invasive detection. While recent deep-learning models\nachieve high accuracy, they typically lack the explainability required for\nclinical use. To address this, we propose RECA-PD, a novel, robust, and\nexplainable cross-attention architecture that combines interpretable speech\nfeatures with self-supervised representations. RECA-PD matches state-of-the-art\nperformance in Speech-based PD detection while providing explanations that are\nmore consistent and more clinically meaningful. Additionally, we demonstrate\nthat performance degradation in certain speech tasks (e.g., monologue) can be\nmitigated by segmenting long recordings. Our findings indicate that performance\nand explainability are not necessarily mutually exclusive. Future work will\nenhance the usability of explanations for non-experts and explore severity\nestimation to increase the real-world clinical relevance.", "published": "2025-07-04 14:05:47", "link": "http://arxiv.org/abs/2507.03594v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "OMAR-RQ: Open Music Audio Representation Model Trained with Multi-Feature Masked Token Prediction", "abstract": "Developing open-source foundation models is essential for advancing research\nin music audio understanding and ensuring access to powerful, multipurpose\nrepresentations for music information retrieval. We present OMAR-RQ, a model\ntrained with self-supervision via masked token classification methodologies\nusing a large-scale dataset with over 330,000 hours of music audio. We\nexperiment with different input features and quantization options, and achieve\nstate-of-the-art performance in music tagging, pitch estimation, chord\nrecognition, beat tracking, segmentation, and difficulty estimation among open\nself-supervised models. We open-source our training and evaluation pipelines\nand model weights, available at https://github.com/mtg/omar-rq.", "published": "2025-07-04 11:19:47", "link": "http://arxiv.org/abs/2507.03482v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust Localization of Partially Fake Speech: Metrics, Models, and Out-of-Domain Evaluation", "abstract": "Partial audio deepfake localization pose unique challenges and remain\nunderexplored compared to full-utterance spoofing detection. While recent\nmethods report strong in-domain performance, their real-world utility remains\nunclear. In this analysis, we critically examine the limitations of current\nevaluation practices, particularly the widespread use of Equal Error Rate\n(EER), which often obscures generalization and deployment readiness. We propose\nreframing the localization task as a sequential anomaly detection problem and\nadvocate for the use of threshold-dependent metrics such as accuracy,\nprecision, recall, and F1-score, which better reflect real-world behavior.\nSpecifically, we analyze the performance of the open-source Coarse-to-Fine\nProposal Refinement Framework (CFPRF), which achieves a 20-ms EER of 7.61% on\nthe in-domain PartialSpoof evaluation set, but 43.25% and 27.59% on the\nLlamaPartialSpoof and Half-Truth out-of-domain test sets. Interestingly, our\nreproduced version of the same model performs worse on in-domain data (9.84%)\nbut better on the out-of-domain sets (41.72% and 14.98%, respectively). This\nhighlights the risks of over-optimizing for in-domain EER, which can lead to\nmodels that perform poorly in real-world scenarios. It also suggests that while\ndeep learning models can be effective on in-domain data, they generalize poorly\nto out-of-domain scenarios, failing to detect novel synthetic samples and\nmisclassifying unfamiliar bona fide audio. Finally, we observe that adding more\nbona fide or fully synthetic utterances to the training data often degrades\nperformance, whereas adding partially fake utterances improves it.", "published": "2025-07-04 10:46:11", "link": "http://arxiv.org/abs/2507.03468v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Direction Estimation of Sound Sources Using Microphone Arrays and Signal Strength", "abstract": "Sound-tracking refers to the process of determining the direction from which\na sound originates, making it a fundamental component of sound source\nlocalization. This capability is essential in a variety of applications,\nincluding security systems, acoustic monitoring, and speaker tracking, where\naccurately identifying the direction of a sound source enables real-time\nresponses, efficient resource allocation, and improved situational awareness.\nWhile sound-tracking is closely related to localization, it specifically\nfocuses on identifying the direction of the sound source rather than estimating\nits exact position in space. Despite its utility, sound-tracking systems face\nseveral challenges, such as maintaining directional accuracy and precision,\nalong with the need for sophisticated hardware configurations and complex\nsignal processing algorithms. This paper presents a sound-tracking method using\nthree electret microphones. We estimate the direction of a sound source using a\nlightweight method that analyzes signals from three strategically placed\nmicrophones. By comparing the average power of the received signals, the system\ninfers the most probable direction of the sound. The results indicate that the\npower level from each microphone effectively determines the sound source\ndirection. Our system employs a straightforward and cost-effective hardware\ndesign, ensuring simplicity and affordability in implementation. It achieves a\nlocalization error of less than 6 degrees and a precision of 98%. Additionally,\nits effortless integration with various systems makes it versatile and\nadaptable. Consequently, this technique presents a robust and reliable solution\nfor sound-tracking and localization, with potential applications spanning\ndiverse domains such as security systems, smart homes, and acoustic monitoring.", "published": "2025-07-04 10:40:16", "link": "http://arxiv.org/abs/2507.03466v1", "categories": ["cs.SD", "cs.SY", "eess.AS", "eess.SY"], "primary_category": "cs.SD"}
{"title": "MaskBeat: Loopable Drum Beat Generation", "abstract": "We present MaskBeat, a transformer-based approach for loopable drum pattern\ngeneration. Rather than predicting drum hits sequentially, our method uses\nbidirectional attention with iterative refinement, allowing instruments to be\ngenerated in parallel while maintaining musical coherence. Additionally, we\nintroduce custom loss functions that capture drum-specific musical\nrelationships. Our experiments show that MaskBeat generates higher quality and\nmore musically coherent drum patterns than baseline approaches.", "published": "2025-07-04 08:57:24", "link": "http://arxiv.org/abs/2507.03395v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speaker-agnostic Emotion Vector for Cross-speaker Emotion Intensity Control", "abstract": "Cross-speaker emotion intensity control aims to generate emotional speech of\na target speaker with desired emotion intensities using only their neutral\nspeech. A recently proposed method, emotion arithmetic, achieves emotion\nintensity control using a single-speaker emotion vector. Although this prior\nmethod has shown promising results in the same-speaker setting, it lost speaker\nconsistency in the cross-speaker setting due to mismatches between the emotion\nvector of the source and target speakers. To overcome this limitation, we\npropose a speaker-agnostic emotion vector designed to capture shared emotional\nexpressions across multiple speakers. This speaker-agnostic emotion vector is\napplicable to arbitrary speakers. Experimental results demonstrate that the\nproposed method succeeds in cross-speaker emotion intensity control while\nmaintaining speaker consistency, speech quality, and controllability, even in\nthe unseen speaker case.", "published": "2025-07-04 08:28:57", "link": "http://arxiv.org/abs/2507.03382v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Eigenvoice Synthesis based on Model Editing for Speaker Generation", "abstract": "Speaker generation task aims to create unseen speaker voice without reference\nspeech. The key to the task is defining a speaker space that represents diverse\nspeakers to determine the generated speaker trait. However, the effective way\nto define this speaker space remains unclear. Eigenvoice synthesis is one of\nthe promising approaches in the traditional parametric synthesis framework,\nsuch as HMM-based methods, which define a low-dimensional speaker space using\npre-stored speaker features. This study proposes a novel DNN-based eigenvoice\nsynthesis method via model editing. Unlike prior methods, our method defines a\nspeaker space in the DNN model parameter space. By directly sampling new DNN\nmodel parameters in this space, we can create diverse speaker voices.\nExperimental results showed the capability of our method to generate diverse\nspeakers' speech. Moreover, we discovered a gender-dominant axis in the created\nspeaker space, indicating the potential to control speaker attributes.", "published": "2025-07-04 08:19:47", "link": "http://arxiv.org/abs/2507.03377v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SHNU Multilingual Conversational Speech Recognition System for INTERSPEECH 2025 MLC-SLM Challenge", "abstract": "This paper describes SHNU multilingual conversational speech recognition\nsystem (SHNU-mASR, team name-\"maybe\"), submitted to Track 1 of the INTERSPEECH\n2025 MLC-SLM Challenge. Our system integrates a parallel-speech-encoder\narchitecture with a large language model (LLM) to form a unified multilingual\nASR framework. The parallel-speech-encoder consists of two pre-trained\nencoders, the Whisper-large-v3 encoder and mHuBERT-147 encoder. Their output\nembeddings are concatenated and fed into the LLM, enabling the model to\nleverage complementary acoustic and linguistic knowledge and achieve\ncompetitive performance. Moreover, we adopt a tri-stage training strategy to\njointly update the low-rank adaptation modules and projector parameters of both\nthe speech encoders and the LLM. In addition, we incorporate an additional\nlanguage-aware prompt at the LLM input to enhance language-specific text\ngeneration. The SHNU-mASR system achieves an overall character/word error rate\n(CER/WER) of 11.76% on the blind evaluation set of the challenge, outperforming\nthe official MLC-SLM baseline by 8.41 absolute CER/WER, without increasing the\nbaseline training data.", "published": "2025-07-04 07:10:33", "link": "http://arxiv.org/abs/2507.03343v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Event2Audio: Event-Based Optical Vibration Sensing", "abstract": "Small vibrations observed in video can unveil information beyond what is\nvisual, such as sound and material properties. It is possible to passively\nrecord these vibrations when they are visually perceptible, or actively amplify\ntheir visual contribution with a laser beam when they are not perceptible. In\nthis paper, we improve upon the active sensing approach by leveraging\nevent-based cameras, which are designed to efficiently capture fast motion. We\ndemonstrate our method experimentally by recovering audio from vibrations, even\nfor multiple simultaneous sources, and in the presence of environmental\ndistortions. Our approach matches the state-of-the-art reconstruction quality\nat much faster speeds, approaching real-time processing.", "published": "2025-07-04 03:19:18", "link": "http://arxiv.org/abs/2507.03273v1", "categories": ["eess.IV", "cs.CV", "eess.AS"], "primary_category": "eess.IV"}
{"title": "Toward Efficient Speech Emotion Recognition via Spectral Learning and Attention", "abstract": "Speech Emotion Recognition (SER) traditionally relies on auditory data\nanalysis for emotion classification. Several studies have adopted different\nmethods for SER. However, existing SER methods often struggle to capture subtle\nemotional variations and generalize across diverse datasets. In this article,\nwe use Mel-Frequency Cepstral Coefficients (MFCCs) as spectral features to\nbridge the gap between computational emotion processing and human auditory\nperception. To further improve robustness and feature diversity, we propose a\nnovel 1D-CNN-based SER framework that integrates data augmentation techniques.\nMFCC features extracted from the augmented data are processed using a 1D\nConvolutional Neural Network (CNN) architecture enhanced with channel and\nspatial attention mechanisms. These attention modules allow the model to\nhighlight key emotional patterns, enhancing its ability to capture subtle\nvariations in speech signals. The proposed method delivers cutting-edge\nperformance, achieving the accuracy of 97.49% for SAVEE, 99.23% for RAVDESS,\n89.31% for CREMA-D, 99.82% for TESS, 99.53% for EMO-DB, and 96.39% for EMOVO.\nExperimental results show new benchmarks in SER, demonstrating the\neffectiveness of our approach in recognizing emotional expressions with high\nprecision. Our evaluation demonstrates that the integration of advanced Deep\nLearning (DL) methods substantially enhances generalization across diverse\ndatasets, underscoring their potential to advance SER for real-world deployment\nin assistive technologies and human-computer interaction.", "published": "2025-07-04 01:55:49", "link": "http://arxiv.org/abs/2507.03251v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SHAP-AAD: DeepSHAP-Guided Channel Reduction for EEG Auditory Attention Detection", "abstract": "Electroencephalography (EEG)-based auditory attention detection (AAD) offers\na non-invasive way to enhance hearing aids, but conventional methods rely on\ntoo many electrodes, limiting wearability and comfort. This paper presents\nSHAP-AAD, a two-stage framework that combines DeepSHAP-based channel selection\nwith a lightweight temporal convolutional network (TCN) for efficient AAD using\nfewer channels.DeepSHAP, an explainable AI technique, is applied to a\nConvolutional Neural Network (CNN) trained on topographic alpha-power maps to\nrank channel importance, and the top-k EEG channels are used to train a compact\nTCN. Experiments on the DTU dataset show that using 32 channels yields\ncomparable accuracy to the full 64-channel setup (79.21% vs. 81.06%) on\naverage. In some cases, even 8 channels can deliver satisfactory accuracy.\nThese results demonstrate the effectiveness of SHAP-AAD in reducing complexity\nwhile preserving high detection performance.", "published": "2025-07-04 21:24:40", "link": "http://arxiv.org/abs/2507.03814v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Improving SAGIN Resilience to Jamming with Reconfigurable Intelligent Surfaces", "abstract": "This study investigates the anti-jamming space-air-ground integrated network\n(SAGIN) scenario wherein a reconfigurable intelligent surface (RIS) is deployed\non a fixed Unmanned Aerial Vehicle (UAV) to counteract malevolent jamming\nattacks. In contrast to existing research, in this paper, we consider that a\nLow Earth Orbit (LEO) satellite is sending the signal to the user on the ground\nin the presence of jamming from a Geostationary Equatorial Orbit (GEO)\nsatellite side. We aim to maximize the signal-to-jamming plus noise ratio\n(SJNR) by optimizing the RIS beamforming and transmit power of the LEO\nsatellite. Assuming the availability of global channel state information (CSI)\nat the RIS, we propose alternating optimization (AO) and semidefinite\nrelaxation (SDR) techniques to address the complexity. Simulation results show\nthat the optimization schemes lead to considerable performance improvements.\nThe results also indicate that, given the high jamming power and the relatively\nsmall number of RIS elements, deploying the RIS on UAVs near the user is more\neffective in mitigating the impact of jamming interferers.", "published": "2025-07-04 17:35:43", "link": "http://arxiv.org/abs/2507.03729v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance Analysis of Data Detection in the THz-Band under Channel-Correlated Noise", "abstract": "We present a comprehensive symbol error rate (SER) analysis framework for\nlink-level terahertz (THz)-band communication systems under linear zero-forcing\n(ZF) data detection. First, we derive the mismatched SER for indoor THz systems\nunder independent channel and noise assumptions, calculating the probability\ndensity function of the ratio of Gaussian noise to $\\alpha$-$\\mu$ channels\nresulting from ZF filtering. Next, we derive the precise SER under correlated\nchannel and noise conditions, modeling dependencies using the copula method.\nFinally, we evaluate the SER for THz channels with correlated distortion noise\nfrom hardware impairments. Simulations demonstrate that the proposed framework\ncorrects for multi-dB SERs resulting from the channel-noise independence\nassumption.", "published": "2025-07-04 16:36:56", "link": "http://arxiv.org/abs/2507.03702v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multipath-Enhanced Measurement of Antenna Patterns: Experiment", "abstract": "In a companion paper we presented the theory for an antenna pattern measuring\ntechnique that uses (rather than mitigates) the properties of a multipath\nenvironment. Here we use measurements in a typical home garage to\nexperimentally demonstrate the feasibility of the technique. A half-wavelength\nelectric dipole with different orientations was used as both the calibration\nand test antennas. For simplicity, we limited the modeling of the antenna\npattern to using only the three $l=1$ vector spherical harmonics. Three methods\nwere used to analyze the measurements: a matrix inversion method using only 3\nsense antennas, a least-square-error technique, and a least-square-error\ntechnique with a constant power constraint imposed. The two least-square-error\ntechniques used the measurements from 10 sense antennas. The constrained\nleast-square-error technique was found to give the best results.", "published": "2025-07-04 15:23:24", "link": "http://arxiv.org/abs/2507.03647v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multipath-Enhanced Measurement of Antenna Patterns: Theory", "abstract": "Traditional antenna pattern measurements involve minimizing the impact of\nmultipath propagation in the measurement environment. In contrast, this work\nintroduces a measurement approach that uses rather than mitigates multipath\npropagation. This is referred to as the Multipath-Enhanced Antenna Pattern\n(MEAP) Measurement technique. In this respect the approach has some kinship\nwith Multiple-Input Multiple-Output (MIMO) systems. The advantage in the case\nof MIMO systems is increased capacity; in the MEAP approach the advantage is\nelimination of the need for creating an anechoic environment. The approach uses\nmeasurements with reference antennas to calibrate the multipath channel matrix,\nand vector spherical harmonics for efficient pattern representation. After\npresenting the mathematical details of the method, numerical calculations\nillustrating the approach are presented. Experimental results are described in\na companion paper.", "published": "2025-07-04 15:09:34", "link": "http://arxiv.org/abs/2507.03639v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Implicit Neural Representation of Beamforming for Continuous Aperture Array (CAPA) System", "abstract": "In this paper, a learning-based approach for optimizing downlink beamforming\nin continuous aperture array (CAPA) systems is proposed, where a MIMO scenario\nthat both the base station (BS) and the user are equipped with CAPA is\nconsidered. As the beamforming in the CAPA system is a function that maps a\ncoordinate on the aperture to the beamforming weight at the coordinate, a DNN\ncalled BeaINR is proposed to parameterize this function, which is called\nimplicit neural representation (INR). We further find that the optimal\nbeamforming function lies in the subspace of channel function, i.e., it can be\nexpressed as a weighted integral of channel function. Based on this finding, we\npropose another DNN called CoefINR to learn the weighting coefficient with INR,\nwhich has lower complexity than learning the beamforming function with BeaINR.\nSimulation results show that the proposed INR-based methods outperform\nnumerical baselines in both spectral efficiency (SE) and inference time, with\nCoefINR offering additional training efficiency.", "published": "2025-07-04 14:31:36", "link": "http://arxiv.org/abs/2507.03609v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "UWB TDoA Error Correction using Transformers: Patching and Positional Encoding Strategies", "abstract": "Despite their high accuracy, UWB-based localization systems suffer\ninaccuracies when deployed in industrial locations with many obstacles due to\nmultipath effects and non-line-of-sight (NLOS) conditions. In such\nenvironments, current error mitigation approaches for time difference of\narrival (TDoA) localization typically exclude NLOS links. However, this\nexclusion approach leads to geometric dilution of precision problems and this\napproach is infeasible when the majority of links are NLOS. To address these\nlimitations, we propose a transformer-based TDoA position correction method\nthat uses raw channel impulse responses (CIRs) from all available anchor nodes\nto compute position corrections. We introduce different CIR ordering, patching\nand positional encoding strategies for the transformer, and analyze each\nproposed technique's scalability and performance gains. Based on experiments on\nreal-world UWB measurements, our approach can provide accuracies of up to 0.39\nm in a complex environment consisting of (almost) only NLOS signals, which is\nan improvement of 73.6 % compared to the TDoA baseline.", "published": "2025-07-04 12:19:54", "link": "http://arxiv.org/abs/2507.03523v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "A Hybrid Game-Theory and Deep Learning Framework for Predicting Tourist Arrivals via Big Data Analytics and Opinion Leader Detection", "abstract": "In the era of Industry 5.0, data-driven decision-making has become\nindispensable for optimizing systems across Industrial Engineering. This paper\naddresses the value of big data analytics by proposing a novel non-linear\nhybrid approach for forecasting international tourist arrivals in two different\ncontexts: (i) arrivals to Hong Kong from five major source nations\n(pre-COVID-19), and (ii) arrivals to Sanya in Hainan province, China\n(post-COVID-19). The method integrates multiple sources of Internet big data\nand employs an innovative game theory-based algorithm to identify opinion\nleaders on social media platforms. Subsequently, nonstationary attributes in\ntourism demand data are managed through Empirical Wavelet Transform (EWT),\nensuring refined time-frequency analysis. Finally, a memory-aware Stacked\nBi-directional Long Short-Term Memory (Stacked BiLSTM) network is used to\ngenerate accurate demand forecasts. Experimental results demonstrate that this\napproach outperforms existing state-of-the-art techniques and remains robust\nunder dynamic and volatile conditions, highlighting its applicability to\nbroader Industrial Engineering domains, such as logistics, supply chain\nmanagement, and production planning, where forecasting and resource allocation\nare key challenges. By merging advanced Deep Learning (DL), time-frequency\nanalysis, and social media insights, the proposed framework showcases how\nlarge-scale data can elevate the quality and efficiency of decision-making\nprocesses.", "published": "2025-07-04 09:17:17", "link": "http://arxiv.org/abs/2507.03411v1", "categories": ["cs.LG", "cs.GT", "eess.SP"], "primary_category": "cs.LG"}
{"title": "AoI-Energy-Spectrum Optimization in Post-Disaster Powered Communication Intelligent Network via Hierarchical Heterogeneous Graph Neural Network", "abstract": "This paper designs a post-disaster powered communication intelligent network\n(PDPCIN) to address communication disruptions caused by ground base station\n(GBS) failures within the post-disaster area. PDPCIN employs unmanned aerial\nvehicles (UAVs) to provide wireless data collection (WDC) and wireless energy\ntransmission (WET) for affected areas and leverages low earth orbit satellites\n(LEO SATs) to relay UAV data to the nearest survival GBS. To ensure basic\npost-disaster communication while co-optimizing age of information (AoI),\nenergy efficiency, and spectrum efficiency, intelligent synchronization-UAV\n(IS-UAV) architecture, AoI-based four thresholds updating (AFTU) mechanism, and\nDynamic multi-LEO access (DMLA) strategy are proposed. However, three key\nchallenges remain: time-varying task-resource imbalances, complex topology\ncaused by multi-device scheduling, and nonlinear coupling in multidimensional\nmetric optimization, making system optimization NP-hard. Therefore, this paper\nproposes a hierarchical heterogeneous graph neural networks (HHGNN) framework.\nIt models heterogeneous device nodes and their communication relations as a\nhierarchical heterogeneous graph structure, integrating our defined graph\nsensing, exchange, and mask layer to handle the network's input, feature\npropagation, and output. To search appropriate number of single-LEO SATs, we\npropose single-LEO SAT density optimization (S-LSDO) algorithm. Finally, we\ncompare the proposed scheme with state-of-the-art benchmarks to validate its\nsuperior collaborative optimization of AoI, energy efficiency, and spectrum\nefficiency. Based on this, we derive the expressions for the expected values of\nAoI and stagnant AoI proportion.", "published": "2025-07-04 09:09:03", "link": "http://arxiv.org/abs/2507.03401v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Evaluation of an Uncertainty-Aware Late Fusion Algorithm for Multi-Source Bird's Eye View Detections Under Controlled Noise", "abstract": "Reliable multi-source fusion is crucial for robust perception in autonomous\nsystems. However, evaluating fusion performance independently of detection\nerrors remains challenging. This work introduces a systematic evaluation\nframework that injects controlled noise into ground-truth bounding boxes to\nisolate the fusion process. We then propose Unified Kalman Fusion (UniKF), a\nlate-fusion algorithm based on Kalman filtering to merge Bird's Eye View (BEV)\ndetections while handling synchronization issues. Experiments show that UniKF\noutperforms baseline methods across various noise levels, achieving up to 3x\nlower object's positioning and orientation errors and 2x lower dimension\nestimation errors, while maintaining nearperfect precision and recall between\n99.5% and 100%.", "published": "2025-07-04 08:26:16", "link": "http://arxiv.org/abs/2507.03381v1", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Adaptive Gate-Aware Mamba Networks for Magnetic Resonance Fingerprinting", "abstract": "Magnetic Resonance Fingerprinting (MRF) enables fast quantitative imaging by\nmatching signal evolutions to a predefined dictionary. However, conventional\ndictionary matching suffers from exponential growth in computational cost and\nmemory usage as the number of parameters increases, limiting its scalability to\nmulti-parametric mapping. To address this, recent work has explored deep\nlearning-based approaches as alternatives to DM. We propose GAST-Mamba, an\nend-to-end framework that combines a dual Mamba-based encoder with a Gate-Aware\nSpatial-Temporal (GAST) processor. Built on structured state-space models, our\narchitecture efficiently captures long-range spatial dependencies with linear\ncomplexity. On 5 times accelerated simulated MRF data (200 frames), GAST-Mamba\nachieved a T1 PSNR of 33.12~dB, outperforming SCQ (31.69~dB). For T2 mapping,\nit reached a PSNR of 30.62~dB and SSIM of 0.9124. In vivo experiments further\ndemonstrated improved anatomical detail and reduced artifacts. Ablation studies\nconfirmed that each component contributes to performance, with the GAST module\nbeing particularly important under strong undersampling. These results\ndemonstrate the effectiveness of GAST-Mamba for accurate and robust\nreconstruction from highly undersampled MRF acquisitions, offering a scalable\nalternative to traditional DM-based methods.", "published": "2025-07-04 08:04:01", "link": "http://arxiv.org/abs/2507.03369v1", "categories": ["eess.IV", "cs.LG", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Enhancing Satellite Quantum Key Distribution with Dual Band Reconfigurable Intelligent Surfaces", "abstract": "This paper presents a novel system architecture for hybrid satellite\ncommunications, integrating quantum key distribution (QKD) and classical radio\nfrequency (RF) data transmission using a dual-band reconfigurable intelligent\nsurface (RIS). The motivation is to address the growing need for global,\nsecure, and reliable communications by leveraging the security of quantum\noptical links and the robustness of classical RF channels within a unified\nframework. By employing a frequency-selective RIS, the system independently\noptimizes both quantum (850 nm) and classical (S-band) channels in real time,\ndynamically adapting to environmental fluctuations such as atmospheric\nturbulence and rain attenuation. The joint optimization of the quantum bit\nerror rate (QBER) and the classical signal-to noise ratio (SNR) is formulated\nas a quadratic unconstrained binary optimization (QUBO) problem, enabling\nefficient adaptive phase control utilizing both quantum and classical\ncomputational methods. Comprehensive theoretical modeling and simulations,\nbenchmarked against experimental data from the Micius satellite, demonstrate\nsubstantial performance gains. Notably, the RIS assisted system reduces QBER\nfrom approximately 2.5% to 0.7%, increases the secure key rate (SKR) to over\n30,000 bits per second, and enhances classical RF SNR by about 3 dB at high\nelevation angles. These results illustrate the practical potential of hybrid\nRIS-assisted satellite links to deliver robust, efficient, and secure global\ncommunications.", "published": "2025-07-04 01:35:03", "link": "http://arxiv.org/abs/2507.03246v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Movable-Antenna-Enhanced Physical-Layer Service Integration: Performance Analysis and Optimization", "abstract": "Movable antennas (MAs) have drawn increasing attention in wireless\ncommunications due to their capability to create favorable channel conditions\nvia local movement within a confined region. In this letter, we investigate its\napplication in physical-layer service integration (PHY-SI), where a multi-MA\nbase station (BS) simultaneously transmits both confidential and multicast\nmessages to two users. The multicast message is intended for both users, while\nthe confidential message is intended only for one user and must remain\nperfectly secure from the other. Our goal is to jointly optimize the secrecy\nand multicast beamforming, as well as the MAs' positions at the BS to maximize\nthe secrecy rate for one user while satisfying the multicast rate requirement\nfor both users. To gain insights, we first conduct performance analysis of this\nMA-enhanced PHY-SI system in two special cases, revealing its unique\ncharacteristics compared to conventional PHY-SI with fixed-position antennas\n(FPAs). To address the secrecy rate maximization problem, we propose a\ntwo-layer optimization framework that integrates the semidefinite relaxation\n(SDR) technique and a discrete sampling algorithm. Numerical results\ndemonstrate that MAs can greatly enhance the achievable secrecy rate region for\nPHY-SI compared to FPAs.", "published": "2025-07-04 10:07:09", "link": "http://arxiv.org/abs/2507.03449v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "SHNU Multilingual Conversational Speech Recognition System for INTERSPEECH 2025 MLC-SLM Challenge", "abstract": "This paper describes SHNU multilingual conversational speech recognition\nsystem (SHNU-mASR, team name-\"maybe\"), submitted to Track 1 of the INTERSPEECH\n2025 MLC-SLM Challenge. Our system integrates a parallel-speech-encoder\narchitecture with a large language model (LLM) to form a unified multilingual\nASR framework. The parallel-speech-encoder consists of two pre-trained\nencoders, the Whisper-large-v3 encoder and mHuBERT-147 encoder. Their output\nembeddings are concatenated and fed into the LLM, enabling the model to\nleverage complementary acoustic and linguistic knowledge and achieve\ncompetitive performance. Moreover, we adopt a tri-stage training strategy to\njointly update the low-rank adaptation modules and projector parameters of both\nthe speech encoders and the LLM. In addition, we incorporate an additional\nlanguage-aware prompt at the LLM input to enhance language-specific text\ngeneration. The SHNU-mASR system achieves an overall character/word error rate\n(CER/WER) of 11.76% on the blind evaluation set of the challenge, outperforming\nthe official MLC-SLM baseline by 8.41 absolute CER/WER, without increasing the\nbaseline training data.", "published": "2025-07-04 07:10:33", "link": "http://arxiv.org/abs/2507.03343v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion", "abstract": "Student dropout in distance learning remains a critical challenge, with\nprofound societal and economic consequences. While classical machine learning\nmodels leverage structured socio-demographic and behavioral data, they often\nfail to capture the nuanced emotional and contextual factors embedded in\nunstructured student interactions. This paper introduces a transformative AI\nframework that redefines dropout prediction through three synergistic\ninnovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment\nanalysis, prompt engineering to decode academic stressors, and cross-modal\nattention fusion to dynamically align textual, behavioral, and\nsocio-demographic insights. By grounding sentiment analysis in a curated\nknowledge base of pedagogical content, our RAG-enhanced BERT model interprets\nstudent comments with unprecedented contextual relevance, while optimized\nprompts isolate indicators of academic distress (e.g., \"isolation,\" \"workload\nanxiety\"). A cross-modal attention layer then fuses these insights with\ntemporal engagement patterns, creating holistic risk profiles. Evaluated on a\nlongitudinal dataset of 4 423 students, the framework achieves 89% accuracy and\nan F1-score of 0.88, outperforming conventional models by 7% and reducing false\nnegatives by 21%. Beyond prediction, the system generates interpretable\ninterventions by retrieving contextually aligned strategies (e.g., mentorship\nprograms for isolated learners). This work bridges the gap between predictive\nanalytics and actionable pedagogy, offering a scalable solution to mitigate\ndropout risks in global education systems", "published": "2025-07-04 21:41:43", "link": "http://arxiv.org/abs/2507.05285v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "I.2.7; I.2.1; K.3.1"], "primary_category": "cs.CL"}
{"title": "Exploring LLM Capabilities in Extracting DCAT-Compatible Metadata for Data Cataloging", "abstract": "Efficient data exploration is crucial as data becomes increasingly important\nfor accelerating processes, improving forecasts and developing new business\nmodels. Data consumers often spend 25-98 % of their time searching for suitable\ndata due to the exponential growth, heterogeneity and distribution of data.\nData catalogs can support and accelerate data exploration by using metadata to\nanswer user queries. However, as metadata creation and maintenance is often a\nmanual process, it is time-consuming and requires expertise. This study\ninvestigates whether LLMs can automate metadata maintenance of text-based data\nand generate high-quality DCAT-compatible metadata. We tested zero-shot and\nfew-shot prompting strategies with LLMs from different vendors for generating\nmetadata such as titles and keywords, along with a fine-tuned model for\nclassification. Our results show that LLMs can generate metadata comparable to\nhuman-created content, particularly on tasks that require advanced semantic\nunderstanding. Larger models outperformed smaller ones, and fine-tuning\nsignificantly improves classification accuracy, while few-shot prompting yields\nbetter results in most cases. Although LLMs offer a faster and reliable way to\ncreate metadata, a successful application requires careful consideration of\ntask-specific criteria and domain context.", "published": "2025-07-04 10:49:37", "link": "http://arxiv.org/abs/2507.05282v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "PINN-DG: Residual neural network methods trained with Finite Elements", "abstract": "Over the past few years, neural network methods have evolved in various\ndirections for approximating partial differential equations (PDEs). A promising\nnew development is the integration of neural networks with classical numerical\ntechniques such as finite elements and finite differences. In this paper, we\nintroduce a new class of Physics-Informed Neural Networks (PINNs) trained using\ndiscontinuous Galerkin finite element methods. Unlike standard\ncollocation-based PINNs that rely on pointwise gradient evaluations and Monte\nCarlo quadrature, our approach computes the loss functional using finite\nelement interpolation and integration. This avoids costly pointwise derivative\ncomputations, particularly advantageous for elliptic PDEs requiring\nsecond-order derivatives, and inherits key stability and accuracy benefits from\nthe finite element framework. We present a convergence analysis based on\nvariational arguments and support our theoretical findings with numerical\nexperiments that demonstrate improved efficiency and robustness.", "published": "2025-07-04 12:16:57", "link": "http://arxiv.org/abs/2507.03521v2", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "65M15 (Primary), 65M12 (Secondary)"], "primary_category": "math.NA"}
{"title": "Skewed Score: A statistical framework to assess autograders", "abstract": "The evaluation of large language model (LLM) outputs is increasingly\nperformed by other LLMs, a setup commonly known as \"LLM-as-a-judge\", or\nautograders. While autograders offer a scalable alternative to human\nevaluation, they have shown mixed reliability and may exhibit systematic\nbiases, depending on response type, scoring methodology, domain specificity, or\nother factors. Here we propose a statistical framework based on Bayesian\ngeneralised linear models (GLMs) that enables researchers to simultaneously\nassess their autograders while addressing their primary research questions\n(e.g., LLM evaluation). Our approach models evaluation outcomes (e.g., scores\nor pairwise preferences) as a function of properties of the grader (e.g., human\nvs. autograder) and the evaluated item (e.g., response length or the LLM that\ngenerated it), allowing for explicit quantification of scoring differences and\npotential biases within a unified framework. In addition, our method can be\nused to augment traditional metrics such as inter-rater agreement, by providing\nuncertainty estimates and clarifying sources of disagreement. Overall, this\napproach contributes to more robust and interpretable use of autograders in LLM\nevaluation, enabling both performance analysis and bias detection.", "published": "2025-07-04 18:45:10", "link": "http://arxiv.org/abs/2507.03772v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation", "abstract": "Recently, pre-trained models with phonetic supervision have demonstrated\ntheir advantages for crosslingual speech recognition in data efficiency and\ninformation sharing across languages. However, a limitation is that a\npronunciation lexicon is needed for such phoneme-based crosslingual speech\nrecognition. In this study, we aim to eliminate the need for pronunciation\nlexicons and propose a latent variable model based method, with phonemes being\ntreated as discrete latent variables. The new method consists of a\nspeech-to-phoneme (S2P) model and a phoneme-to-grapheme (P2G) model, and a\ngrapheme-to-phoneme (G2P) model is introduced as an auxiliary inference model.\nTo jointly train the three models, we utilize the joint stochastic\napproximation (JSA) algorithm, which is a stochastic extension of the EM\n(expectation-maximization) algorithm and has demonstrated superior performance\nparticularly in estimating discrete latent variable models. Based on the\nWhistle multilingual pre-trained S2P model, crosslingual experiments are\nconducted in Polish (130 h) and Indonesian (20 h). With only 10 minutes of\nphoneme supervision, the new method, JSA-SPG, achieves 5\\% error rate\nreductions compared to the best crosslingual fine-tuning approach using subword\nor full phoneme supervision. Furthermore, it is found that in language domain\nadaptation (i.e., utilizing cross-domain text-only data), JSA-SPG outperforms\nthe standard practice of language model fusion via the auxiliary support of the\nG2P model by 9% error rate reductions. To facilitate reproducibility and\nencourage further exploration in this field, we open-source the JSA-SPG\ntraining code and complete pipeline.", "published": "2025-07-04 12:23:22", "link": "http://arxiv.org/abs/2507.06249v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Elliptic interface problem approximated by CutFEM: I. Conservative flux recovery and numerical validation of adaptive mesh refinement", "abstract": "We study an elliptic interface problem with discontinuous diffusion\ncoefficients on unfitted meshes using the CutFEM method. Our main contribution\nis the reconstruction of conservative fluxes from the CutFEM solution and their\nuse in a posteriori error estimation. We introduce a hybrid mixed formulation\nwith locally computable Lagrange multipliers and reconstruct the flux in the\nimmersed Raviart-Thomas space. Based on this, we propose a new a posteriori\nerror estimator that includes both volume and interface terms. We state its\nrobust reliability and local efficiency, and validate the approach through\nnumerical experiments.", "published": "2025-07-04 11:31:57", "link": "http://arxiv.org/abs/2507.03492v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Toward Efficient Speech Emotion Recognition via Spectral Learning and Attention", "abstract": "Speech Emotion Recognition (SER) traditionally relies on auditory data\nanalysis for emotion classification. Several studies have adopted different\nmethods for SER. However, existing SER methods often struggle to capture subtle\nemotional variations and generalize across diverse datasets. In this article,\nwe use Mel-Frequency Cepstral Coefficients (MFCCs) as spectral features to\nbridge the gap between computational emotion processing and human auditory\nperception. To further improve robustness and feature diversity, we propose a\nnovel 1D-CNN-based SER framework that integrates data augmentation techniques.\nMFCC features extracted from the augmented data are processed using a 1D\nConvolutional Neural Network (CNN) architecture enhanced with channel and\nspatial attention mechanisms. These attention modules allow the model to\nhighlight key emotional patterns, enhancing its ability to capture subtle\nvariations in speech signals. The proposed method delivers cutting-edge\nperformance, achieving the accuracy of 97.49% for SAVEE, 99.23% for RAVDESS,\n89.31% for CREMA-D, 99.82% for TESS, 99.53% for EMO-DB, and 96.39% for EMOVO.\nExperimental results show new benchmarks in SER, demonstrating the\neffectiveness of our approach in recognizing emotional expressions with high\nprecision. Our evaluation demonstrates that the integration of advanced Deep\nLearning (DL) methods substantially enhances generalization across diverse\ndatasets, underscoring their potential to advance SER for real-world deployment\nin assistive technologies and human-computer interaction.", "published": "2025-07-04 01:55:49", "link": "http://arxiv.org/abs/2507.03251v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
