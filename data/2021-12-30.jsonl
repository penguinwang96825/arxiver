{"title": "QEMind: Alibaba's Submission to the WMT21 Quality Estimation Shared Task", "abstract": "Quality Estimation, as a crucial step of quality control for machine\ntranslation, has been explored for years. The goal is to investigate automatic\nmethods for estimating the quality of machine translation results without\nreference translations. In this year's WMT QE shared task, we utilize the\nlarge-scale XLM-Roberta pre-trained model and additionally propose several\nuseful features to evaluate the uncertainty of the translations to build our QE\nsystem, named \\textit{QEMind}. The system has been applied to the\nsentence-level scoring task of Direct Assessment and the binary score\nprediction task of Critical Error Detection. In this paper, we present our\nsubmissions to the WMT 2021 QE shared task and an extensive set of experimental\nresults have shown us that our multilingual systems outperform the best system\nin the Direct Assessment QE task of WMT 2020.", "published": "2021-12-30 02:27:29", "link": "http://arxiv.org/abs/2112.14890v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "YACLC: A Chinese Learner Corpus with Multidimensional Annotation", "abstract": "Learner corpus collects language data produced by L2 learners, that is second\nor foreign-language learners. This resource is of great relevance for second\nlanguage acquisition research, foreign-language teaching, and automatic\ngrammatical error correction. However, there is little focus on learner corpus\nfor Chinese as Foreign Language (CFL) learners. Therefore, we propose to\nconstruct a large-scale, multidimensional annotated Chinese learner corpus. To\nconstruct the corpus, we first obtain a large number of topic-rich texts\ngenerated by CFL learners. Then we design an annotation scheme including a\nsentence acceptability score as well as grammatical error and fluency-based\ncorrections. We build a crowdsourcing platform to perform the annotation\neffectively (https://yaclc.wenmind.net). We name the corpus YACLC (Yet Another\nChinese Learner Corpus) and release it as part of the CUGE benchmark\n(http://cuge.baai.ac.cn). By analyzing the original sentences and annotations\nin the corpus, we found that YACLC has a considerable size and very high\nannotation quality. We hope this corpus can further enhance the studies on\nChinese International Education and Chinese automatic grammatical error\ncorrection.", "published": "2021-12-30 13:07:08", "link": "http://arxiv.org/abs/2112.15043v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KIND: an Italian Multi-Domain Dataset for Named Entity Recognition", "abstract": "In this paper we present KIND, an Italian dataset for Named-entity\nrecognition. It contains more than one million tokens with annotation covering\nthree classes: person, location, and organization. The dataset (around 600K\ntokens) mostly contains manual gold annotations in three different domains\n(news, literature, and political discourses) and a semi-automatically annotated\npart. The multi-domain feature is the main strength of the present work,\noffering a resource which covers different styles and language uses, as well as\nthe largest Italian NER dataset with manual gold annotations. It represents an\nimportant resource for the training of NER systems in Italian. Texts and\nannotations are freely downloadable from the Github repository.", "published": "2021-12-30 15:41:52", "link": "http://arxiv.org/abs/2112.15099v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Utilizing Wordnets for Cognate Detection among Indian Languages", "abstract": "Automatic Cognate Detection (ACD) is a challenging task which has been\nutilized to help NLP applications like Machine Translation, Information\nRetrieval and Computational Phylogenetics. Unidentified cognate pairs can pose\na challenge to these applications and result in a degradation of performance.\nIn this paper, we detect cognate word pairs among ten Indian languages with\nHindi and use deep learning methodologies to predict whether a word pair is\ncognate or not. We identify IndoWordnet as a potential resource to detect\ncognate word pairs based on orthographic similarity-based methods and train\nneural network models using the data obtained from it. We identify parallel\ncorpora as another potential resource and perform the same experiments for\nthem. We also validate the contribution of Wordnets through further\nexperimentation and report improved performance of up to 26%. We discuss the\nnuances of cognate detection among closely related Indian languages and release\nthe lists of detected cognates as a dataset. We also observe the behaviour of,\nto an extent, unrelated Indian language pairs and release the lists of detected\ncognates among them as well.", "published": "2021-12-30 16:46:28", "link": "http://arxiv.org/abs/2112.15124v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Mixed-Precision Quantization Search of BERT", "abstract": "Pre-trained language models such as BERT have shown remarkable effectiveness\nin various natural language processing tasks. However, these models usually\ncontain millions of parameters, which prevents them from practical deployment\non resource-constrained devices. Knowledge distillation, Weight pruning, and\nQuantization are known to be the main directions in model compression. However,\ncompact models obtained through knowledge distillation may suffer from\nsignificant accuracy drop even for a relatively small compression ratio. On the\nother hand, there are only a few quantization attempts that are specifically\ndesigned for natural language processing tasks. They suffer from a small\ncompression ratio or a large error rate since manual setting on\nhyper-parameters is required and fine-grained subgroup-wise quantization is not\nsupported. In this paper, we proposed an automatic mixed-precision quantization\nframework designed for BERT that can simultaneously conduct quantization and\npruning in a subgroup-wise level. Specifically, our proposed method leverages\nDifferentiable Neural Architecture Search to assign scale and precision for\nparameters in each sub-group automatically, and at the same time pruning out\nredundant groups of parameters. Extensive evaluations on BERT downstream tasks\nreveal that our proposed method outperforms baselines by providing the same\nperformance with much smaller model size. We also show the feasibility of\nobtaining the extremely light-weight model by combining our solution with\northogonal methods such as DistilBERT.", "published": "2021-12-30 06:32:47", "link": "http://arxiv.org/abs/2112.14938v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Does QA-based intermediate training help fine-tuning language models for\n  text classification?", "abstract": "Fine-tuning pre-trained language models for downstream tasks has become a\nnorm for NLP. Recently it is found that intermediate training based on\nhigh-level inference tasks such as Question Answering (QA) can improve the\nperformance of some language models for target tasks. However it is not clear\nif intermediate training generally benefits various language models. In this\npaper, using the SQuAD-2.0 QA task for intermediate training for target text\nclassification tasks, we experimented on eight tasks for single-sequence\nclassification and eight tasks for sequence-pair classification using two base\nand two compact language models. Our experiments show that QA-based\nintermediate training generates varying transfer performance across different\nlanguage models, except for similar QA tasks.", "published": "2021-12-30 13:30:25", "link": "http://arxiv.org/abs/2112.15051v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TextRGNN: Residual Graph Neural Networks for Text Classification", "abstract": "Recently, text classification model based on graph neural network (GNN) has\nattracted more and more attention. Most of these models adopt a similar network\nparadigm, that is, using pre-training node embedding initialization and\ntwo-layer graph convolution. In this work, we propose TextRGNN, an improved GNN\nstructure that introduces residual connection to deepen the convolution network\ndepth. Our structure can obtain a wider node receptive field and effectively\nsuppress the over-smoothing of node features. In addition, we integrate the\nprobabilistic language model into the initialization of graph node embedding,\nso that the non-graph semantic information of can be better extracted. The\nexperimental results show that our model is general and efficient. It can\nsignificantly improve the classification accuracy whether in corpus level or\ntext level, and achieve SOTA performance on a wide range of text classification\ndatasets.", "published": "2021-12-30 13:48:58", "link": "http://arxiv.org/abs/2112.15060v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RheFrameDetect: A Text Classification System for Automatic Detection of\n  Rhetorical Frames in AI from Open Sources", "abstract": "Rhetorical Frames in AI can be thought of as expressions that describe AI\ndevelopment as a competition between two or more actors, such as governments or\ncompanies. Examples of such Frames include robotic arms race, AI rivalry,\ntechnological supremacy, cyberwarfare dominance and 5G race. Detection of\nRhetorical Frames from open sources can help us track the attitudes of\ngovernments or companies towards AI, specifically whether attitudes are\nbecoming more cooperative or competitive over time. Given the rapidly\nincreasing volumes of open sources (online news media, twitter, blogs), it is\ndifficult for subject matter experts to identify Rhetorical Frames in (near)\nreal-time. Moreover, these sources are in general unstructured (noisy) and\ntherefore, detecting Frames from these sources will require state-of-the-art\ntext classification techniques. In this paper, we develop RheFrameDetect, a\ntext classification system for (near) real-time capture of Rhetorical Frames\nfrom open sources. Given an input document, RheFrameDetect employs text\nclassification techniques at multiple levels (document level and paragraph\nlevel) to identify all occurrences of Frames used in the discussion of AI. We\nperformed extensive evaluation of the text classification techniques used in\nRheFrameDetect against human annotated Frames from multiple news sources. To\nfurther demonstrate the effectiveness of RheFrameDetect, we show multiple case\nstudies depicting the Frames identified by RheFrameDetect compared against\nhuman annotated Frames.", "published": "2021-12-30 05:39:42", "link": "http://arxiv.org/abs/2112.14933v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Matters: Radiology Report Generation with General and Specific\n  Knowledge", "abstract": "Automatic radiology report generation is critical in clinics which can\nrelieve experienced radiologists from the heavy workload and remind\ninexperienced radiologists of misdiagnosis or missed diagnose. Existing\napproaches mainly formulate radiology report generation as an image captioning\ntask and adopt the encoder-decoder framework. However, in the medical domain,\nsuch pure data-driven approaches suffer from the following problems: 1) visual\nand textual bias problem; 2) lack of expert knowledge. In this paper, we\npropose a knowledge-enhanced radiology report generation approach introduces\ntwo types of medical knowledge: 1) General knowledge, which is input\nindependent and provides the broad knowledge for report generation; 2) Specific\nknowledge, which is input dependent and provides the fine-grained knowledge for\nreport generation. To fully utilize both the general and specific knowledge, we\nalso propose a knowledge-enhanced multi-head attention mechanism. By merging\nthe visual features of the radiology image with general knowledge and specific\nknowledge, the proposed model can improve the quality of generated reports.\nExperimental results on two publicly available datasets IU-Xray and MIMIC-CXR\nshow that the proposed knowledge enhanced approach outperforms state-of-the-art\nimage captioning based methods. Ablation studies also demonstrate that both\ngeneral and specific knowledge can help to improve the performance of radiology\nreport generation.", "published": "2021-12-30 10:36:04", "link": "http://arxiv.org/abs/2112.15009v2", "categories": ["eess.IV", "cs.CL", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Radiology Report Generation with a Learned Knowledge Base and\n  Multi-modal Alignment", "abstract": "In clinics, a radiology report is crucial for guiding a patient's treatment.\nHowever, writing radiology reports is a heavy burden for radiologists. To this\nend, we present an automatic, multi-modal approach for report generation from a\nchest x-ray. Our approach, motivated by the observation that the descriptions\nin radiology reports are highly correlated with specific information of the\nx-ray images, features two distinct modules: (i) Learned knowledge base: To\nabsorb the knowledge embedded in the radiology reports, we build a knowledge\nbase that can automatically distil and restore medical knowledge from textual\nembedding without manual labour; (ii) Multi-modal alignment: to promote the\nsemantic alignment among reports, disease labels, and images, we explicitly\nutilize textual embedding to guide the learning of the visual feature space. We\nevaluate the performance of the proposed model using metrics from both natural\nlanguage generation and clinic efficacy on the public IU-Xray and MIMIC-CXR\ndatasets. Our ablation study shows that each module contributes to improving\nthe quality of generated reports. Furthermore, with the assistance of both\nmodules, our approach outperforms state-of-the-art methods over almost all the\nmetrics.", "published": "2021-12-30 10:43:56", "link": "http://arxiv.org/abs/2112.15011v2", "categories": ["eess.IV", "cs.CL", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Feature extraction with mel scale separation method on noise audio\n  recordings", "abstract": "This paper focuses on improving the accuracy of noise audio recordings.\nHigh-quality audio recording, extraction using the mel frequency cepstral\ncoefficients (MFCC) method produces high accuracy. While the low-quality is\nbecause of noise, the accuracy is low. Improved accuracy by investigating the\neffect of bandwidth on the mel scale. The proposed improvement uses the mel\nscale separation methods into two frequency channels (MFCC dual channel). For\nthe comparison method using the mel scale bandwidth without separation (MFCC\nsingle-channel). Feature analysis using k-mean clustering. The data uses a\nnoise variance of up to -16 dB. Testing on the MFCC single channel method for\n-16 dB noise has an accuracy of 47.5%, while the MFCC dual-channel method has\nan accuracy better of 76.25%. The next test used adaptive noise-canceling (ANC)\nto reduce noise before extraction. The result is that the MFCC single-channel\nmethod has an accuracy of 82.5% and the MFCC dual-channel method has an\naccuracy better of 83.75%. High-quality audio recording testing for the MFCC\nsingle-channel method has an accuracy of 92.5% and the MFCC dual-channel method\nhas an accuracy better of 97.5%. The test results show the effect of mel scale\nbandwidth to increase accuracy. The MFCC dual-channel method has higher\naccuracy.", "published": "2021-12-30 05:24:08", "link": "http://arxiv.org/abs/2112.14930v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio-to-symbolic Arrangement via Cross-modal Music Representation\n  Learning", "abstract": "Could we automatically derive the score of a piano accompaniment based on the\naudio of a pop song? This is the audio-to-symbolic arrangement problem we\ntackle in this paper. A good arrangement model should not only consider the\naudio content but also have prior knowledge of piano composition (so that the\ngeneration \"sounds like\" the audio and meanwhile maintains musicality). To this\nend, we contribute a cross-modal representation-learning model, which 1)\nextracts chord and melodic information from the audio, and 2) learns texture\nrepresentation from both audio and a corrupted ground truth arrangement. We\nfurther introduce a tailored training strategy that gradually shifts the source\nof texture information from corrupted score to audio. In the end, the\nscore-based texture posterior is reduced to a standard normal distribution, and\nonly audio is needed for inference. Experiments show that our model captures\nmajor audio information and outperforms baselines in generation quality.", "published": "2021-12-30 16:05:30", "link": "http://arxiv.org/abs/2112.15110v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
