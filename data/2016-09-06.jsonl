{"title": "Attention-Based Recurrent Neural Network Models for Joint Intent\n  Detection and Slot Filling", "abstract": "Attention-based encoder-decoder neural network models have recently shown\npromising results in machine translation and speech recognition. In this work,\nwe propose an attention-based neural network model for joint intent detection\nand slot filling, both of which are critical steps for many speech\nunderstanding and dialog systems. Unlike in machine translation and speech\nrecognition, alignment is explicit in slot filling. We explore different\nstrategies in incorporating this alignment information to the encoder-decoder\nframework. Learning from the attention mechanism in encoder-decoder model, we\nfurther propose introducing attention to the alignment-based RNN models. Such\nattentions provide additional information to the intent classification and slot\nlabel prediction. Our independent task models achieve state-of-the-art intent\ndetection error rate and slot filling F1 score on the benchmark ATIS task. Our\njoint training model further obtains 0.56% absolute (23.8% relative) error\nreduction on intent detection and 0.23% absolute gain on slot filling over the\nindependent task models.", "published": "2016-09-06 09:29:12", "link": "http://arxiv.org/abs/1609.01454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Online Spoken Language Understanding and Language Modeling with\n  Recurrent Neural Networks", "abstract": "Speaker intent detection and semantic slot filling are two critical tasks in\nspoken language understanding (SLU) for dialogue systems. In this paper, we\ndescribe a recurrent neural network (RNN) model that jointly performs intent\ndetection, slot filling, and language modeling. The neural network model keeps\nupdating the intent estimation as word in the transcribed utterance arrives and\nuses it as contextual features in the joint model. Evaluation of the language\nmodel and online SLU model is made on the ATIS benchmarking data set. On\nlanguage modeling task, our joint model achieves 11.8% relative reduction on\nperplexity comparing to the independent training language model. On SLU tasks,\nour joint model outperforms the independent task training model by 22.3% on\nintent detection error rate, with slight degradation on slot filling F1 score.\nThe joint model also shows advantageous performance in the realistic ASR\nsettings with noisy speech input.", "published": "2016-09-06 09:45:51", "link": "http://arxiv.org/abs/1609.01462v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatically extracting, ranking and visually summarizing the\n  treatments for a disease", "abstract": "Clinicians are expected to have up-to-date and broad knowledge of disease\ntreatment options for a patient. Online health knowledge resources contain a\nwealth of information. However, because of the time investment needed to\ndisseminate and rank pertinent information, there is a need to summarize the\ninformation in a more concise format. Our aim of the study is to provide\nclinicians with a concise overview of popular treatments for a given disease\nusing information automatically computed from Medline abstracts. We analyzed\nthe treatments of two disorders - Atrial Fibrillation and Congestive Heart\nFailure. We calculated the precision, recall, and f-scores of our two ranking\nmethods to measure the accuracy of the results. For Atrial Fibrillation\ndisorder, maximum f-score for the New Treatments weighing method is 0.611,\nwhich occurs at 60 treatments. For Congestive Heart Failure disorder, maximum\nf-score for the New Treatments weighing method is 0.503, which occurs at 80\ntreatments.", "published": "2016-09-06 14:30:18", "link": "http://arxiv.org/abs/1609.01574v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Using Natural Language Processing to Screen Patients with Active Heart\n  Failure: An Exploration for Hospital-wide Surveillance", "abstract": "In this paper, we proposed two different approaches, a rule-based approach\nand a machine-learning based approach, to identify active heart failure cases\nautomatically by analyzing electronic health records (EHR). For the rule-based\napproach, we extracted cardiovascular data elements from clinical notes and\nmatched patients to different colors according their heart failure condition by\nusing rules provided by experts in heart failure. It achieved 69.4% accuracy\nand 0.729 F1-Score. For the machine learning approach, with bigram of clinical\nnotes as features, we tried four different models while SVM with linear kernel\nachieved the best performance with 87.5% accuracy and 0.86 F1-Score. Also, from\nthe classification comparison between the four different models, we believe\nthat linear models fit better for this problem. Once we combine the\nmachine-learning and rule-based algorithms, we will enable hospital-wide\nsurveillance of active heart failure through increased accuracy and\ninterpretability of the outputs.", "published": "2016-09-06 14:46:41", "link": "http://arxiv.org/abs/1609.01580v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Bootstrap Machine Learning Approach to Identify Rare Disease Patients\n  from Electronic Health Records", "abstract": "Rare diseases are very difficult to identify among large number of other\npossible diagnoses. Better availability of patient data and improvement in\nmachine learning algorithms empower us to tackle this problem computationally.\nIn this paper, we target one such rare disease - cardiac amyloidosis. We aim to\nautomate the process of identifying potential cardiac amyloidosis patients with\nthe help of machine learning algorithms and also learn most predictive factors.\nWith the help of experienced cardiologists, we prepared a gold standard with 73\npositive (cardiac amyloidosis) and 197 negative instances. We achieved high\naverage cross-validation F1 score of 0.98 using an ensemble machine learning\nclassifier. Some of the predictive variables were: Age and Diagnosis of cardiac\narrest, chest pain, congestive heart failure, hypertension, prim open angle\nglaucoma, and shoulder arthritis. Further studies are needed to validate the\naccuracy of the system across an entire health system and its generalizability\nfor other diseases.", "published": "2016-09-06 14:54:58", "link": "http://arxiv.org/abs/1609.01586v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CRTS: A type system for representing clinical recommendations", "abstract": "Background: Clinical guidelines and recommendations are the driving wheels of\nthe evidence-based medicine (EBM) paradigm, but these are available primarily\nas unstructured text and are generally highly heterogeneous in nature. This\nsignificantly reduces the dissemination and automatic application of these\nrecommendations at the point of care. A comprehensive structured representation\nof these recommendations is highly beneficial in this regard. Objective: The\nobjective of this paper to present Clinical Recommendation Type System (CRTS),\na common type system that can effectively represent a clinical recommendation\nin a structured form. Methods: CRTS is built by analyzing 125 recommendations\nand 195 research articles corresponding to 6 different diseases available from\nUpToDate, a publicly available clinical knowledge system, and from the National\nGuideline Clearinghouse, a public resource for evidence-based clinical practice\nguidelines. Results: We show that CRTS not only covers the recommendations but\nalso is flexible to be extended to represent information from primary\nliterature. We also describe how our developed type system can be applied for\nclinical decision support, medical knowledge summarization, and citation\nretrieval. Conclusion: We showed that our proposed type system is precise and\ncomprehensive in representing a large sample of recommendations available for\nvarious disorders. CRTS can now be used to build interoperable information\nextraction systems that automatically extract clinical recommendations and\nrelated data elements from clinical evidence resources, guidelines, systematic\nreviews and primary publications.\n  Keywords: guidelines and recommendations, type system, clinical decision\nsupport, evidence-based medicine, information storage and retrieval", "published": "2016-09-06 15:02:03", "link": "http://arxiv.org/abs/1609.01592v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "An Information Extraction Approach to Prescreen Heart Failure Patients\n  for Clinical Trials", "abstract": "To reduce the large amount of time spent screening, identifying, and\nrecruiting patients into clinical trials, we need prescreening systems that are\nable to automate the data extraction and decision-making tasks that are\ntypically relegated to clinical research study coordinators. However, a major\nobstacle is the vast amount of patient data available as unstructured free-form\ntext in electronic health records. Here we propose an information\nextraction-based approach that first automatically converts unstructured text\ninto a structured form. The structured data are then compared against a list of\neligibility criteria using a rule-based system to determine which patients\nqualify for enrollment in a heart failure clinical trial. We show that we can\nachieve highly accurate results, with recall and precision values of 0.95 and\n0.86, respectively. Our system allowed us to significantly reduce the time\nneeded for prescreening patients from a few weeks to a few minutes. Our\nopen-source information extraction modules are available for researchers and\ncould be tested and validated in other cardiovascular trials. An approach such\nas the one we demonstrate here may decrease costs and expedite clinical trials,\nand could enhance the reproducibility of trials across institutions and\npopulations.", "published": "2016-09-06 15:05:25", "link": "http://arxiv.org/abs/1609.01594v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Hybrid Citation Retrieval Algorithm for Evidence-based Clinical\n  Knowledge Summarization: Combining Concept Extraction, Vector Similarity and\n  Query Expansion for High Precision", "abstract": "Novel information retrieval methods to identify citations relevant to a\nclinical topic can overcome the knowledge gap existing between the primary\nliterature (MEDLINE) and online clinical knowledge resources such as UpToDate.\nSearching the MEDLINE database directly or with query expansion methods returns\na large number of citations that are not relevant to the query. The current\nstudy presents a citation retrieval system that retrieves citations for\nevidence-based clinical knowledge summarization. This approach combines query\nexpansion, concept-based screening algorithm, and concept-based vector\nsimilarity. We also propose an information extraction framework for automated\nconcept (Population, Intervention, Comparison, and Disease) extraction. We\nevaluated our proposed system on all topics (as queries) available from\nUpToDate for two diseases, heart failure (HF) and atrial fibrillation (AFib).\nThe system achieved an overall F-score of 41.2% on HF topics and 42.4% on AFib\ntopics on a gold standard of citations available in UpToDate. This is\nsignificantly high when compared to a query-expansion based baseline (F-score\nof 1.3% on HF and 2.2% on AFib) and a system that uses query expansion with\ndisease hyponyms and journal names, concept-based screening, and term-based\nvector similarity system (F-score of 37.5% on HF and 39.5% on AFib). Evaluating\nthe system with top K relevant citations, where K is the number of citations in\nthe gold standard achieved a much higher overall F-score of 69.9% on HF topics\nand 75.1% on AFib topics. In addition, the system retrieved up to 18 new\nrelevant citations per topic when tested on ten HF and six AFib clinical\ntopics.", "published": "2016-09-06 15:10:39", "link": "http://arxiv.org/abs/1609.01597v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
