{"title": "Robust Elicitable Functionals", "abstract": "Elicitable functionals and (strictly) consistent scoring functions are of\ninterest due to their utility of determining (uniquely) optimal forecasts, and\nthus the ability to effectively backtest predictions. However, in practice,\nassuming that a distribution is correctly specified is too strong a belief to\nreliably hold. To remediate this, we incorporate a notion of statistical\nrobustness into the framework of elicitable functionals, meaning that our\nrobust functional accounts for \"small\" misspecifications of a baseline\ndistribution. Specifically, we propose a robustified version of elicitable\nfunctionals by using the Kullback-Leibler divergence to quantify potential\nmisspecifications from a baseline distribution. We show that the robust\nelicitable functionals admit unique solutions lying at the boundary of the\nuncertainty region, and provide conditions for existence and uniqueness. Since\nevery elicitable functional possesses infinitely many scoring functions, we\npropose the class of b-homogeneous strictly consistent scoring functions, for\nwhich the robust functionals maintain desirable statistical properties. We show\nthe applicability of the robust elicitable functional in several examples: in a\nreinsurance setting and in robust regression problems.", "published": "2024-09-06 17:15:56", "link": "http://arxiv.org/abs/2409.04412v2", "categories": ["stat.ME", "q-fin.MF", "q-fin.RM"], "primary_category": "stat.ME"}
{"title": "Ergodicity and Law-of-large numbers for the Volterra Cox-Ingersoll-Ross process", "abstract": "We study the Volterra Volterra Cox-Ingersoll-Ross process on $\\mathbb{R}_+$\nand its stationary version. Based on a fine asymptotic analysis of the\ncorresponding Volterra Riccati equation combined with the affine transformation\nformula, we first show that the finite-dimensional distributions of this\nprocess are asymptotically independent. Afterwards, we prove a law-of-large\nnumbers in $L^p$(\\Omega)$ with $p \\geq 2$ and show that the stationary process\nis ergodic. As an application, we prove the consistency of the method of\nmoments and study the maximum-likelihood estimation for continuous and discrete\nhigh-frequency observations.", "published": "2024-09-06 15:08:19", "link": "http://arxiv.org/abs/2409.04496v1", "categories": ["math.PR", "q-fin.MF"], "primary_category": "math.PR"}
{"title": "Optimal post-retirement investment under longevity risk in collective funds", "abstract": "We study the optimal investment problem for a homogeneous collective of $n$\nindividuals investing in a Black-Scholes model subject to longevity risk with\nEpstein--Zin preferences. %and with preferences given by power utility. We\ncompute analytic formulae for the optimal investment strategy, consumption is\nin discrete-time and there is no systematic longevity risk. We develop a\nstylised model of systematic longevity risk in continuous time which allows us\nto also obtain an analytic solution to the optimal investment problem in this\ncase. We numerically solve the same problem using a continuous-time version of\nthe Cairns--Blake--Dowd model. We apply our results to estimate the potential\nbenefits of pooling longevity risk over purchasing an insurance product such as\nan annuity, and to estimate the benefits of optimal longevity risk pooling in a\nsmall heterogeneous fund.", "published": "2024-09-06 13:19:51", "link": "http://arxiv.org/abs/2409.15325v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "On The Role of Prompt Construction In Enhancing Efficacy and Efficiency\n  of LLM-Based Tabular Data Generation", "abstract": "LLM-based data generation for real-world tabular data can be challenged by\nthe lack of sufficient semantic context in feature names used to describe\ncolumns. We hypothesize that enriching prompts with domain-specific insights\ncan improve both the quality and efficiency of data generation. To test this\nhypothesis, we explore three prompt construction protocols: Expert-guided,\nLLM-guided, and Novel-Mapping. Through empirical studies with the recently\nproposed GReaT framework, we find that context-enriched prompts lead to\nsignificantly improved data generation quality and training efficiency.", "published": "2024-09-06 00:02:09", "link": "http://arxiv.org/abs/2409.03946v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Margin Prototypical Network for Few-shot Relation Classification\n  with Fine-grained Features", "abstract": "Relation classification (RC) plays a pivotal role in both natural language\nunderstanding and knowledge graph completion. It is generally formulated as a\ntask to recognize the relationship between two entities of interest appearing\nin a free-text sentence. Conventional approaches on RC, regardless of feature\nengineering or deep learning based, can obtain promising performance on\ncategorizing common types of relation leaving a large proportion of\nunrecognizable long-tail relations due to insufficient labeled instances for\ntraining. In this paper, we consider few-shot learning is of great practical\nsignificance to RC and thus improve a modern framework of metric learning for\nfew-shot RC. Specifically, we adopt the large-margin ProtoNet with fine-grained\nfeatures, expecting they can generalize well on long-tail relations. Extensive\nexperiments were conducted by FewRel, a large-scale supervised few-shot RC\ndataset, to evaluate our framework: LM-ProtoNet (FGF). The results demonstrate\nthat it can achieve substantial improvements over many baseline approaches.", "published": "2024-09-06 03:28:38", "link": "http://arxiv.org/abs/2409.04009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Safer Online Spaces: Simulating and Assessing Intervention\n  Strategies for Eating Disorder Discussions", "abstract": "Eating disorders are complex mental health conditions that affect millions of\npeople around the world. Effective interventions on social media platforms are\ncrucial, yet testing strategies in situ can be risky. We present a novel\nLLM-driven experimental testbed for simulating and assessing intervention\nstrategies in ED-related discussions. Our framework generates synthetic\nconversations across multiple platforms, models, and ED-related topics,\nallowing for controlled experimentation with diverse intervention approaches.\nWe analyze the impact of various intervention strategies on conversation\ndynamics across four dimensions: intervention type, generative model, social\nmedia platform, and ED-related community/topic. We employ cognitive domain\nanalysis metrics, including sentiment, emotions, etc., to evaluate the\neffectiveness of interventions. Our findings reveal that civility-focused\ninterventions consistently improve positive sentiment and emotional tone across\nall dimensions, while insight-resetting approaches tend to increase negative\nemotions. We also uncover significant biases in LLM-generated conversations,\nwith cognitive metrics varying notably between models (Claude-3 Haiku $>$\nMistral $>$ GPT-3.5-turbo $>$ LLaMA3) and even between versions of the same\nmodel. These variations highlight the importance of model selection in\nsimulating realistic discussions related to ED. Our work provides valuable\ninformation on the complex dynamics of ED-related discussions and the\neffectiveness of various intervention strategies.", "published": "2024-09-06 06:27:35", "link": "http://arxiv.org/abs/2409.04043v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Harmonized Chain of Thought", "abstract": "Chain-of-thought (CoT) prompting has demonstrated the capacity of large\nlanguage models to perform complex reasoning through intermediate steps. While\neffective, current CoT methods face challenges: Zero-shot-CoT can lead to\nreasoning errors, and Few-shot-CoT requires labor-intensive manual\ndemonstrations. Auto-CoT attempts to address these issues by automatically\ngenerating diverse demonstrations, but this diversity can lead to inconsistent\nreasoning patterns. We propose ECHO (Self-Harmonized Chain of Thought), a novel\nmethod that unifies diverse solution paths into a consistent and effective\nreasoning pattern. ECHO employs an iterative process to refine and harmonize\nautomatically generated demonstrations, mitigating the limitations of existing\napproaches. Our comprehensive experiments across arithmetic, commonsense, and\nsymbolic reasoning tasks demonstrate that ECHO outperforms Auto-CoT by an\naverage of 2.8%. These findings suggest that ECHO represents a significant step\ntowards more robust and generalizable automated reasoning in large language\nmodels.", "published": "2024-09-06 06:57:04", "link": "http://arxiv.org/abs/2409.04057v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-based Personality Profiling: Reinforcement Learning for Relevance\n  Filtering", "abstract": "Author profiling is the task of inferring characteristics about individuals\nby analyzing content they share. Supervised machine learning still dominates\nautomatic systems that perform this task, despite the popularity of prompting\nlarge language models to address natural language understanding tasks. One\nreason is that the classification instances consist of large amounts of posts,\npotentially a whole user profile, which may exceed the input length of\nTransformers. Even if a model can use a large context window, the entirety of\nposts makes the application of API-accessed black box systems costly and slow,\nnext to issues which come with such \"needle-in-the-haystack\" tasks. To mitigate\nthis limitation, we propose a new method for author profiling which aims at\ndistinguishing relevant from irrelevant content first, followed by the actual\nuser profiling only with relevant data. To circumvent the need for\nrelevance-annotated data, we optimize this relevance filter via reinforcement\nlearning with a reward function that utilizes the zero-shot capabilities of\nlarge language models. We evaluate our method for Big Five personality trait\nprediction on two Twitter corpora. On publicly available real-world data with a\nskewed label distribution, our method shows similar efficacy to using all posts\nin a user profile, but with a substantially shorter context. An evaluation on a\nversion of these data balanced with artificial posts shows that the filtering\nto relevant posts leads to a significantly improved accuracy of the\npredictions.", "published": "2024-09-06 08:43:10", "link": "http://arxiv.org/abs/2409.04122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Coin Has Two Sides: A Novel Detector-Corrector Framework for Chinese\n  Spelling Correction", "abstract": "Chinese Spelling Correction (CSC) stands as a foundational Natural Language\nProcessing (NLP) task, which primarily focuses on the correction of erroneous\ncharacters in Chinese texts. Certain existing methodologies opt to disentangle\nthe error correction process, employing an additional error detector to\npinpoint error positions. However, owing to the inherent performance\nlimitations of error detector, precision and recall are like two sides of the\ncoin which can not be both facing up simultaneously. Furthermore, it is also\nworth investigating how the error position information can be judiciously\napplied to assist the error correction. In this paper, we introduce a novel\napproach based on error detector-corrector framework. Our detector is designed\nto yield two error detection results, each characterized by high precision and\nrecall. Given that the occurrence of errors is context-dependent and detection\noutcomes may be less precise, we incorporate the error detection results into\nthe CSC task using an innovative feature fusion strategy and a selective\nmasking strategy. Empirical experiments conducted on mainstream CSC datasets\nsubstantiate the efficacy of our proposed method.", "published": "2024-09-06 09:26:45", "link": "http://arxiv.org/abs/2409.04150v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question\n  Answering", "abstract": "Advancements in natural language processing have revolutionized the way we\ncan interact with digital information systems, such as databases, making them\nmore accessible. However, challenges persist, especially when accuracy is\ncritical, as in the biomedical domain. A key issue is the hallucination\nproblem, where models generate information unsupported by the underlying data,\npotentially leading to dangerous misinformation. This paper presents a novel\napproach designed to bridge this gap by combining Large Language Models (LLM)\nand Knowledge Graphs (KG) to improve the accuracy and reliability of\nquestion-answering systems, on the example of a biomedical KG. Built on the\nLangChain framework, our method incorporates a query checker that ensures the\nsyntactical and semantic validity of LLM-generated queries, which are then used\nto extract information from a Knowledge Graph, substantially reducing errors\nlike hallucinations. We evaluated the overall performance using a new benchmark\ndataset of 50 biomedical questions, testing several LLMs, including GPT-4 Turbo\nand llama3:70b. Our results indicate that while GPT-4 Turbo outperforms other\nmodels in generating accurate queries, open-source models like llama3:70b show\npromise with appropriate prompt engineering. To make this approach accessible,\na user-friendly web-based interface has been developed, allowing users to input\nnatural language queries, view generated and corrected Cypher queries, and\nverify the resulting paths for accuracy. Overall, this hybrid approach\neffectively addresses common issues such as data gaps and hallucinations,\noffering a reliable and intuitive solution for question answering systems. The\nsource code for generating the results of this paper and for the user-interface\ncan be found in our Git repository: https://git.zib.de/lpusch/cyphergenkg-gui", "published": "2024-09-06 10:49:46", "link": "http://arxiv.org/abs/2409.04181v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Language Data Initiative: Advancing Low-Resource Machine\n  Translation for Karakalpak", "abstract": "This study presents several contributions for the Karakalpak language: a\nFLORES+ devtest dataset translated to Karakalpak, parallel corpora for\nUzbek-Karakalpak, Russian-Karakalpak and English-Karakalpak of 100,000 pairs\neach and open-sourced fine-tuned neural models for translation across these\nlanguages. Our experiments compare different model variants and training\napproaches, demonstrating improvements over existing baselines. This work,\nconducted as part of the Open Language Data Initiative (OLDI) shared task, aims\nto advance machine translation capabilities for Karakalpak and contribute to\nexpanding linguistic diversity in NLP technologies.", "published": "2024-09-06 13:25:18", "link": "http://arxiv.org/abs/2409.04269v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Customizing Large Language Model Generation Style using\n  Parameter-Efficient Finetuning", "abstract": "One-size-fits-all large language models (LLMs) are increasingly being used to\nhelp people with their writing. However, the style these models are trained to\nwrite in may not suit all users or use cases. LLMs would be more useful as\nwriting assistants if their idiolect could be customized to match each user. In\nthis paper, we explore whether parameter-efficient finetuning (PEFT) with\nLow-Rank Adaptation can effectively guide the style of LLM generations. We use\nthis method to customize LLaMA-2 to ten different authors and show that the\ngenerated text has lexical, syntactic, and surface alignment with the target\nauthor but struggles with content memorization. Our findings highlight the\npotential of PEFT to support efficient, user-level customization of LLMs.", "published": "2024-09-06 19:25:18", "link": "http://arxiv.org/abs/2409.04574v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Paper Copilot: A Self-Evolving and Efficient LLM System for Personalized\n  Academic Assistance", "abstract": "As scientific research proliferates, researchers face the daunting task of\nnavigating and reading vast amounts of literature. Existing solutions, such as\ndocument QA, fail to provide personalized and up-to-date information\nefficiently. We present Paper Copilot, a self-evolving, efficient LLM system\ndesigned to assist researchers, based on thought-retrieval, user profile and\nhigh performance optimization. Specifically, Paper Copilot can offer\npersonalized research services, maintaining a real-time updated database.\nQuantitative evaluation demonstrates that Paper Copilot saves 69.92\\% of time\nafter efficient deployment. This paper details the design and implementation of\nPaper Copilot, highlighting its contributions to personalized academic support\nand its potential to streamline the research process.", "published": "2024-09-06 20:04:04", "link": "http://arxiv.org/abs/2409.04593v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer\n  Training", "abstract": "Language models can largely benefit from efficient tokenization. However,\nthey still mostly utilize the classical BPE algorithm, a simple and reliable\nmethod. This has been shown to cause such issues as under-trained tokens and\nsub-optimal compression that may affect the downstream performance. We\nintroduce Picky BPE, a modified BPE algorithm that carries out vocabulary\nrefinement during tokenizer training. Our method improves vocabulary\nefficiency, eliminates under-trained tokens, and does not compromise text\ncompression. Our experiments show that our method does not reduce the\ndownstream performance, and in several cases improves it.", "published": "2024-09-06 20:12:34", "link": "http://arxiv.org/abs/2409.04599v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparse Rewards Can Self-Train Dialogue Agents", "abstract": "Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM)\nagents, especially in multi-turn dialogue tasks, have been primarily driven by\nsupervised fine-tuning and high-quality human feedback. However, as base LLM\nmodels continue to improve, acquiring meaningful human feedback has become\nincreasingly challenging and costly. In certain domains, base LLM agents may\neventually exceed human capabilities, making traditional feedback-driven\nmethods impractical. In this paper, we introduce a novel self-improvement\nparadigm that empowers LLM agents to autonomously enhance their performance\nwithout external human feedback. Our method, Juxtaposed Outcomes for Simulation\nHarvesting (JOSH), is a self-alignment algorithm that leverages a sparse reward\nsimulation environment to extract ideal behaviors and further train the LLM on\nits own outputs. We present ToolWOZ, a sparse reward tool-calling simulation\nenvironment derived from MultiWOZ. We demonstrate that models trained with\nJOSH, both small and frontier, significantly improve tool-based interactions\nwhile preserving general model capabilities across diverse benchmarks. Our code\nand data are publicly available on GitHub at\nhttps://github.com/asappresearch/josh-llm-simulation-training", "published": "2024-09-06 21:00:57", "link": "http://arxiv.org/abs/2409.04617v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decolonising Data Systems: Using Jyutping or Pinyin as tonal\n  representations of Chinese names for data linkage", "abstract": "Data linkage is increasingly used in health research and policy making and is\nrelied on for understanding health inequalities. However, linked data is only\nas useful as the underlying data quality, and differential linkage rates may\ninduce selection bias in the linked data. A mechanism that selectively\ncompromises data quality is name romanisation. Converting text of a different\nwriting system into Latin based writing, or romanisation, has long been the\nstandard process of representing names in character-based writing systems such\nas Chinese, Vietnamese, and other languages such as Swahili. Unstandardised\nromanisation of Chinese characters, due in part to problems of preserving the\ncorrect name orders the lack of proper phonetic representation of a tonal\nlanguage, has resulted in poor linkage rates for Chinese immigrants. This\nopinion piece aims to suggests that the use of standardised romanisation\nsystems for Cantonese (Jyutping) or Mandarin (Pinyin) Chinese, which\nincorporate tonal information, could improve linkage rates and accuracy for\nindividuals with Chinese names. We used 771 Chinese and English names scraped\nfrom openly available sources, and compared the utility of Jyutping, Pinyin and\nthe Hong Kong Government Romanisation system (HKG-romanisation) for\nrepresenting Chinese names. We demonstrate that both Jyutping and Pinyin result\nin fewer errors compared with the HKG-romanisation system. We suggest that\ncollecting and preserving people's names in their original writing systems is\nethically and socially pertinent. This may inform development of\nlanguage-specific pre-processing and linkage paradigms that result in more\ninclusive research data which better represents the targeted populations.", "published": "2024-09-06 12:01:01", "link": "http://arxiv.org/abs/2409.13706v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Programming Language Ensemble for Code Generation in Large\n  Language Model", "abstract": "Large language models (LLMs) have significantly improved code generation,\nparticularly in one-pass code generation. However, most existing approaches\nfocus solely on generating code in a single programming language, overlooking\nthe potential of leveraging the multi-language capabilities of LLMs. LLMs have\nvarying patterns of errors across different languages, suggesting that a more\nrobust approach could be developed by leveraging these multi-language outputs.\nIn this study, we propose Multi-Programming Language Ensemble (MPLE), a novel\nensemble-based method that utilizes code generation across multiple programming\nlanguages to enhance overall performance. By treating each language-specific\ncode generation process as an individual \"weak expert\" and effectively\nintegrating their outputs, our method mitigates language-specific errors and\nbiases. This multi-language ensemble strategy leverages the complementary\nstrengths of different programming languages, enabling the model to produce\nmore accurate and robust code. Our approach can be seamlessly integrated with\ncommonly used techniques such as the reflection algorithm and Monte Carlo tree\nsearch to improve code generation quality further. Experimental results show\nthat our framework consistently enhances baseline performance by up to 17.92%\non existing benchmarks (HumanEval and HumanEval-plus), with a standout result\nof 96.25% accuracy on the HumanEval benchmark, achieving new state-of-the-art\nresults across various LLM models. The code will be released at\nhttps://github.com/NinjaTech-AI/MPLE", "published": "2024-09-06 08:31:18", "link": "http://arxiv.org/abs/2409.04114v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Calculation to Adjudication: Examining LLM judges on Mathematical\n  Reasoning Tasks", "abstract": "To reduce the need for human annotations, large language models (LLMs) have\nbeen proposed as judges of the quality of other candidate models. LLM judges\nare typically evaluated by measuring the correlation with human judgments on\ngeneration tasks such as summarization or machine translation. In contrast, we\nstudy LLM judges on mathematical reasoning tasks. These tasks require\nmulti-step reasoning, and the correctness of their solutions is verifiable,\nenabling a more objective evaluation. We perform a detailed performance\nanalysis and find that the used judges are mostly unable to improve task\nperformance but are able to pick the better model. Our analysis uncovers a\nstrong correlation between judgment performance and the candidate model task\nperformance. We observe that judges tend to choose the model of higher quality\neven if its answer is incorrect. Further, we show that it is possible to use\nstatistics, such as the task performances of the individual models, to predict\njudgment performance. In an ablation, we either swap or mask the candidate\nanswers and observe that judges often keep the original judgment, providing\nevidence that judges incorporate writing style in their judgments. In summary,\nwe find that regularities in the judgments are quantifiable using statistical\nmeasures and provide various angles on exploiting them.", "published": "2024-09-06 10:09:41", "link": "http://arxiv.org/abs/2409.04168v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GALLa: Graph Aligned Large Language Models for Improved Source Code\n  Understanding", "abstract": "Programming languages possess rich semantic information such as data flow\nthat is represented by graphs and not available from the surface form of source\ncode. Recent code language models have scaled to billions of parameters, but\nmodel source code solely as text tokens while ignoring any other structural\ninformation. Conversely, models that do encode structural information of code\nmake modifications to the Transformer architecture, limiting their scale and\ncompatibility with pretrained LLMs. In this work, we take the best of both\nworlds with GALLa - Graph Aligned Large Language Model. GALLa utilizes graph\nneural networks and cross-modal alignment technologies to inject the structural\ninformation of code into LLMs as an auxiliary task during finetuning. This\nframework is both model-agnostic and task-agnostic, as it can be applied to any\ncode LLM for any code downstream task, and requires the structural graph data\nonly at training time from a corpus unrelated to the finetuning data, while\nincurring no cost at inference time over the baseline LLM. Experiments on five\ncode tasks with four different baseline LLMs ranging in size from 350M to 8B\nvalidate the effectiveness of GALLa, demonstrating consistent improvement over\nthe baseline, even for powerful models such as LLaMA3.", "published": "2024-09-06 10:57:34", "link": "http://arxiv.org/abs/2409.04183v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Residual Stream Analysis with Multi-Layer SAEs", "abstract": "Sparse autoencoders (SAEs) are a promising approach to interpreting the\ninternal representations of transformer language models. However, SAEs are\nusually trained separately on each transformer layer, making it difficult to\nuse them to study how information flows across layers. To solve this problem,\nwe introduce the multi-layer SAE (MLSAE): a single SAE trained on the residual\nstream activation vectors from every transformer layer. Given that the residual\nstream is understood to preserve information across layers, we expected MLSAE\nlatents to 'switch on' at a token position and remain active at later layers.\nInterestingly, we find that individual latents are often active at a single\nlayer for a given token or prompt, but the layer at which an individual latent\nis active may differ for different tokens or prompts. We quantify these\nphenomena by defining a distribution over layers and considering its variance.\nWe find that the variance of the distributions of latent activations over\nlayers is about two orders of magnitude greater when aggregating over tokens\ncompared with a single token. For larger underlying models, the degree to which\nlatents are active at multiple layers increases, which is consistent with the\nfact that the residual stream activation vectors at adjacent layers become more\nsimilar. Finally, we relax the assumption that the residual stream basis is the\nsame at every layer by applying pre-trained tuned-lens transformations, but our\nfindings remain qualitatively similar. Our results represent a new approach to\nunderstanding how representations change as they flow through transformers. We\nrelease our code to train and analyze MLSAEs at\nhttps://github.com/tim-lawson/mlsae.", "published": "2024-09-06 11:01:55", "link": "http://arxiv.org/abs/2409.04185v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Fast Forwarding Low-Rank Training", "abstract": "Parameter efficient finetuning methods like low-rank adaptation (LoRA) aim to\nreduce the computational costs of finetuning pretrained Language Models (LMs).\nEnabled by these low-rank settings, we propose an even more efficient\noptimization strategy: Fast Forward, a simple and effective approach to\naccelerate large segments of training. In a Fast Forward stage, we repeat the\nmost recent optimizer step until the loss stops improving on a tiny validation\nset. By alternating between regular optimization steps and Fast Forward stages,\nFast Forward provides up to an 87\\% reduction in FLOPs and up to an 81\\%\nreduction in train time over standard SGD with Adam. We validate Fast Forward\nby finetuning various models on different tasks and demonstrate that it speeds\nup training without compromising model performance. Additionally, we analyze\nwhen and how to apply Fast Forward.", "published": "2024-09-06 11:53:37", "link": "http://arxiv.org/abs/2409.04206v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An overview of domain-specific foundation model: key technologies,\n  applications and challenges", "abstract": "The impressive performance of ChatGPT and other foundation-model-based\nproducts in human language understanding has prompted both academia and\nindustry to explore how these models can be tailored for specific industries\nand application scenarios. This process, known as the customization of\ndomain-specific foundation models, addresses the limitations of general-purpose\nmodels, which may not fully capture the unique patterns and requirements of\ndomain-specific data. Despite its importance, there is a notable lack of\ncomprehensive overview papers on building domain-specific foundation models,\nwhile numerous resources exist for general-purpose models. To bridge this gap,\nthis article provides a timely and thorough overview of the methodology for\ncustomizing domain-specific foundation models. It introduces basic concepts,\noutlines the general architecture, and surveys key methods for constructing\ndomain-specific models. Furthermore, the article discusses various domains that\ncan benefit from these specialized models and highlights the challenges ahead.\nThrough this overview, we aim to offer valuable guidance and reference for\nresearchers and practitioners from diverse fields to develop their own\ncustomized foundation models.", "published": "2024-09-06 13:24:22", "link": "http://arxiv.org/abs/2409.04267v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Using Large Language Models to Generate Authentic Multi-agent Knowledge\n  Work Datasets", "abstract": "Current publicly available knowledge work data collections lack diversity,\nextensive annotations, and contextual information about the users and their\ndocuments. These issues hinder objective and comparable data-driven evaluations\nand optimizations of knowledge work assistance systems. Due to the considerable\nresources needed to collect such data in real-life settings and the necessity\nof data censorship, collecting such a dataset appears nearly impossible. For\nthis reason, we propose a configurable, multi-agent knowledge work dataset\ngenerator. This system simulates collaborative knowledge work among agents\nproducing Large Language Model-generated documents and accompanying data\ntraces. Additionally, the generator captures all background information, given\nin its configuration or created during the simulation process, in a knowledge\ngraph. Finally, the resulting dataset can be utilized and shared without\nprivacy or confidentiality concerns.\n  This paper introduces our approach's design and vision and focuses on\ngenerating authentic knowledge work documents using Large Language Models. Our\nstudy involving human raters who assessed 53% of the generated and 74% of the\nreal documents as realistic demonstrates the potential of our approach.\nFurthermore, we analyze the authenticity criteria mentioned in the\nparticipants' comments and elaborate on potential improvements for identified\ncommon issues.", "published": "2024-09-06 13:53:28", "link": "http://arxiv.org/abs/2409.04286v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Learning vs Retrieval: The Role of In-Context Examples in Regression\n  with Large Language Models", "abstract": "Generative Large Language Models (LLMs) are capable of being in-context\nlearners. However, the underlying mechanism of in-context learning (ICL) is\nstill a major research question, and experimental research results about how\nmodels exploit ICL are not always consistent. In this work, we propose a\nframework for evaluating in-context learning mechanisms, which we claim are a\ncombination of retrieving internal knowledge and learning from in-context\nexamples by focusing on regression tasks. First, we show that LLMs can solve\nreal-world regression problems and then design experiments to measure the\nextent to which the LLM retrieves its internal knowledge versus learning from\nin-context examples. We argue that this process lies on a spectrum between\nthese two extremes. We provide an in-depth analysis of the degrees to which\nthese mechanisms are triggered depending on various factors, such as prior\nknowledge about the tasks and the type and richness of the information provided\nby the in-context examples. We employ three LLMs and utilize multiple datasets\nto corroborate the robustness of our findings. Our results shed light on how to\nengineer prompts to leverage meta-learning from in-context examples and foster\nknowledge retrieval depending on the problem being addressed.", "published": "2024-09-06 14:46:37", "link": "http://arxiv.org/abs/2409.04318v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Chain-of-Translation Prompting (CoTR): A Novel Prompting Technique for\n  Low Resource Languages", "abstract": "This paper introduces Chain of Translation Prompting (CoTR), a novel strategy\ndesigned to enhance the performance of language models in low-resource\nlanguages. CoTR restructures prompts to first translate the input context from\na low-resource language into a higher-resource language, such as English. The\nspecified task like generation, classification, or any other NLP function is\nthen performed on the translated text, with the option to translate the output\nback to the original language if needed. All these steps are specified in a\nsingle prompt. We demonstrate the effectiveness of this method through a case\nstudy on the low-resource Indic language Marathi. The CoTR strategy is applied\nto various tasks, including sentiment analysis, hate speech classification,\nsubject classification and text generation, and its efficacy is showcased by\ncomparing it with regular prompting methods. Our results underscore the\npotential of translation-based prompting strategies to significantly improve\nmultilingual LLM performance in low-resource languages, offering valuable\ninsights for future research and applications. We specifically see the highest\naccuracy improvements with the hate speech detection task. The technique also\nhas the potential to enhance the quality of synthetic data generation for\nunderrepresented languages using LLMs.", "published": "2024-09-06 17:15:17", "link": "http://arxiv.org/abs/2409.04512v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Does Code Pretraining Affect Language Model Task Performance?", "abstract": "Large language models are increasingly trained on corpora containing both\nnatural language and non-linguistic data like source code. Aside from aiding\nprogramming-related tasks, anecdotal evidence suggests that including code in\npretraining corpora may improve performance on other, unrelated tasks, yet to\ndate no work has been able to establish a causal connection by controlling\nbetween language and code data. Here we do just this. We pretrain language\nmodels on datasets which interleave natural language and code in two different\nsettings: additive, in which the total volume of data seen during pretraining\nis held constant; and competitive, in which the volume of language data is held\nconstant. We study how the pretraining mixture affects performance on (a) a\ndiverse collection of tasks included in the BigBench benchmark, and (b)\ncompositionality, measured by generalization accuracy on semantic parsing and\nsyntactic transformations. We find that pretraining on higher proportions of\ncode improves performance on compositional tasks involving structured output\n(like semantic parsing), and mathematics. Conversely, increase code mixture can\nharm performance on other tasks, including on tasks that requires sensitivity\nto linguistic structure such as syntax or morphology, and tasks measuring\nreal-world knowledge.", "published": "2024-09-06 18:33:38", "link": "http://arxiv.org/abs/2409.04556v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Column Vocabulary Association (CVA): semantic interpretation of dataless\n  tables", "abstract": "Traditional Semantic Table Interpretation (STI) methods rely primarily on the\nunderlying table data to create semantic annotations. This year's SemTab\nchallenge introduced the ``Metadata to KG'' track, which focuses on performing\nSTI by using only metadata information, without access to the underlying data.\nIn response to this new challenge, we introduce a new term: Column Vocabulary\nAssociation (CVA). This term refers to the task of semantic annotation of\ncolumn headers solely based on metadata information. In this study, we evaluate\nthe performance of various methods in executing the CVA task, including a Large\nLanguage Models (LLMs) and Retrieval Augmented Generation (RAG) approach, as\nwell as a more traditional similarity approach with SemanticBERT. Our\nmethodology uses a zero-shot setting, with no pretraining or examples passed to\nthe Large Language Models (LLMs), as we aim to avoid a domain-specific setting.\n  We investigate a total of 7 different LLMs, of which three commercial GPT\nmodels (i.e. gpt-3.5-turbo-0.125, gpt-4o and gpt-4-turbo) and four open source\nmodels (i.e. llama3-80b, llama3-7b, gemma-7b and mixtral-8x7b). We integrate\nthis models with RAG systems, and we explore how variations in temperature\nsettings affect performances. Moreover, we continue our investigation by\nperforming the CVA task utilizing SemanticBERT, analyzing how various metadata\ninformation influence its performance.\n  Initial findings indicate that LLMs generally perform well at temperatures\nbelow 1.0, achieving an accuracy of 100\\% in certain cases. Nevertheless, our\ninvestigation also reveal that the nature of the data significantly influences\nCVA task outcomes. In fact, in cases where the input data and glossary are\nrelated (for example by being created by the same organizations) traditional\nmethods appear to surpass the performance of LLMs.", "published": "2024-09-06 14:58:30", "link": "http://arxiv.org/abs/2409.13709v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "You can remove GPT2's LayerNorm by fine-tuning", "abstract": "The LayerNorm (LN) layer in GPT-style transformer models has long been a\nhindrance to mechanistic interpretability. LN is a crucial component required\nto stabilize the training of large language models, and LN or the similar\nRMSNorm have been used in practically all large language models based on the\ntransformer architecture. The non-linear nature of the LN layers is a hindrance\nfor mechanistic interpretability as it hinders interpretation of the residual\nstream, and makes it difficult to decompose the model into circuits. Some\nresearchers have gone so far as to name \"reasons interpretability researchers\nhate layer norm.\"\n  In this paper we show that it is possible to remove the LN layers from a\npre-trained GPT2-small model by fine-tuning on a fraction (500M tokens) of the\ntraining data. We demonstrate that this LN-free model achieves similar\nperformance to the original model on the OpenWebText and ThePile datasets\n(-0.05 cross-entropy loss), and the Hellaswag benchmark (-0.5% accuracy). We\nprovide our implementation at https://github.com/ApolloResearch/gpt2_noLN, and\nfine-tuned GPT2-small models at\nhttps://huggingface.co/apollo-research/gpt2_noLN.\n  Our work not only provides a simplified model for mechanistic\ninterpretability research, but also provides evidence that the LN layers, at\ninference time, do not play a crucial role in transformer models.", "published": "2024-09-06 16:17:06", "link": "http://arxiv.org/abs/2409.13710v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Medical Concept Normalization in a Low-Resource Setting", "abstract": "In the field of biomedical natural language processing, medical concept\nnormalization is a crucial task for accurately mapping mentions of concepts to\na large knowledge base. However, this task becomes even more challenging in\nlow-resource settings, where limited data and resources are available. In this\nthesis, I explore the challenges of medical concept normalization in a\nlow-resource setting. Specifically, I investigate the shortcomings of current\nmedical concept normalization methods applied to German lay texts. Since there\nis no suitable dataset available, a dataset consisting of posts from a German\nmedical online forum is annotated with concepts from the Unified Medical\nLanguage System. The experiments demonstrate that multilingual\nTransformer-based models are able to outperform string similarity methods. The\nuse of contextual information to improve the normalization of lay mentions is\nalso examined, but led to inferior results. Based on the results of the best\nperforming model, I present a systematic error analysis and lay out potential\nimprovements to mitigate frequent errors.", "published": "2024-09-06 10:19:32", "link": "http://arxiv.org/abs/2409.14579v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Refining Wikidata Taxonomy using Large Language Models", "abstract": "Due to its collaborative nature, Wikidata is known to have a complex\ntaxonomy, with recurrent issues like the ambiguity between instances and\nclasses, the inaccuracy of some taxonomic paths, the presence of cycles, and\nthe high level of redundancy across classes. Manual efforts to clean up this\ntaxonomy are time-consuming and prone to errors or subjective decisions. We\npresent WiKC, a new version of Wikidata taxonomy cleaned automatically using a\ncombination of Large Language Models (LLMs) and graph mining techniques.\nOperations on the taxonomy, such as cutting links or merging classes, are\nperformed with the help of zero-shot prompting on an open-source LLM. The\nquality of the refined taxonomy is evaluated from both intrinsic and extrinsic\nperspectives, on a task of entity typing for the latter, showing the practical\ninterest of WiKC.", "published": "2024-09-06 06:53:45", "link": "http://arxiv.org/abs/2409.04056v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "AnyMatch -- Efficient Zero-Shot Entity Matching with a Small Language\n  Model", "abstract": "Entity matching (EM) is the problem of determining whether two records refer\nto same real-world entity, which is crucial in data integration, e.g., for\nproduct catalogs or address databases. A major drawback of many EM approaches\nis their dependence on labelled examples. We thus focus on the challenging\nsetting of zero-shot entity matching where no labelled examples are available\nfor an unseen target dataset. Recently, large language models (LLMs) have shown\npromising results for zero-shot EM, but their low throughput and high\ndeployment cost limit their applicability and scalability.\n  We revisit the zero-shot EM problem with AnyMatch, a small language model\nfine-tuned in a transfer learning setup. We propose several novel data\nselection techniques to generate fine-tuning data for our model, e.g., by\nselecting difficult pairs to match via an AutoML filter, by generating\nadditional attribute-level examples, and by controlling label imbalance in the\ndata.\n  We conduct an extensive evaluation of the prediction quality and deployment\ncost of our model, in a comparison to thirteen baselines on nine benchmark\ndatasets. We find that AnyMatch provides competitive prediction quality despite\nits small parameter size: it achieves the second-highest F1 score overall, and\noutperforms several other approaches that employ models with hundreds of\nbillions of parameters. Furthermore, our approach exhibits major cost benefits:\nthe average prediction quality of AnyMatch is within 4.4% of the\nstate-of-the-art method MatchGPT with the proprietary trillion-parameter model\nGPT-4, yet AnyMatch requires four orders of magnitude less parameters and\nincurs a 3,899 times lower inference cost (in dollars per 1,000 tokens).", "published": "2024-09-06 07:29:01", "link": "http://arxiv.org/abs/2409.04073v2", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "UI-JEPA: Towards Active Perception of User Intent through Onscreen User\n  Activity", "abstract": "Generating user intent from a sequence of user interface (UI) actions is a\ncore challenge in comprehensive UI understanding. Recent advancements in\nmultimodal large language models (MLLMs) have led to substantial progress in\nthis area, but their demands for extensive model parameters, computing power,\nand high latency makes them impractical for scenarios requiring lightweight,\non-device solutions with low latency or heightened privacy. Additionally, the\nlack of high-quality datasets has hindered the development of such lightweight\nmodels. To address these challenges, we propose UI-JEPA, a novel framework that\nemploys masking strategies to learn abstract UI embeddings from unlabeled data\nthrough self-supervised learning, combined with an LLM decoder fine-tuned for\nuser intent prediction. We also introduce two new UI-grounded multimodal\ndatasets, \"Intent in the Wild\" (IIW) and \"Intent in the Tame\" (IIT), designed\nfor few-shot and zero-shot UI understanding tasks. IIW consists of 1.7K videos\nacross 219 intent categories, while IIT contains 914 videos across 10\ncategories. We establish the first baselines for these datasets, showing that\nrepresentations learned using a JEPA-style objective, combined with an LLM\ndecoder, can achieve user intent predictions that match the performance of\nstate-of-the-art large MLLMs, but with significantly reduced annotation and\ndeployment resources. Measured by intent similarity scores, UI-JEPA outperforms\nGPT-4 Turbo and Claude 3.5 Sonnet by 10.0% and 7.2% respectively, averaged\nacross two datasets. Notably, UI-JEPA accomplishes the performance with a 50.5x\nreduction in computational cost and a 6.6x improvement in latency in the IIW\ndataset. These results underscore the effectiveness of UI-JEPA, highlighting\nits potential for lightweight, high-performance UI understanding.", "published": "2024-09-06 07:44:44", "link": "http://arxiv.org/abs/2409.04081v3", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Structure and dynamics of growing networks of Reddit threads", "abstract": "Millions of people use online social networks to reinforce their sense of\nbelonging, for example by giving and asking for feedback as a form of social\nvalidation and self-recognition. It is common to observe disagreement among\npeople beliefs and points of view when expressing this feedback. Modeling and\nanalyzing such interactions is crucial to understand social phenomena that\nhappen when people face different opinions while expressing and discussing\ntheir values. In this work, we study a Reddit community in which people\nparticipate to judge or be judged with respect to some behavior, as it\nrepresents a valuable source to study how users express judgments online. We\nmodel threads of this community as complex networks of user interactions\ngrowing in time, and we analyze the evolution of their structural properties.\nWe show that the evolution of Reddit networks differ from other real social\nnetworks, despite falling in the same category. This happens because their\nglobal clustering coefficient is extremely small and the average shortest path\nlength increases over time. Such properties reveal how users discuss in\nthreads, i.e. with mostly one other user and often by a single message. We\nstrengthen such result by analyzing the role that disagreement and reciprocity\nplay in such conversations. We also show that Reddit thread's evolution over\ntime is governed by two subgraphs growing at different speeds. We discover\nthat, in the studied community, the difference of such speed is higher than in\nother communities because of the user guidelines enforcing specific user\ninteractions. Finally, we interpret the obtained results on user behavior\ndrawing back to Social Judgment Theory.", "published": "2024-09-06 07:53:33", "link": "http://arxiv.org/abs/2409.04085v1", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "Confidence-Aware Document OCR Error Detection", "abstract": "Optical Character Recognition (OCR) continues to face accuracy challenges\nthat impact subsequent applications. To address these errors, we explore the\nutility of OCR confidence scores for enhancing post-OCR error detection. Our\nstudy involves analyzing the correlation between confidence scores and error\nrates across different OCR systems. We develop ConfBERT, a BERT-based model\nthat incorporates OCR confidence scores into token embeddings and offers an\noptional pre-training phase for noise adjustment. Our experimental results\ndemonstrate that integrating OCR confidence scores can enhance error detection\ncapabilities. This work underscores the importance of OCR confidence scores in\nimproving detection accuracy and reveals substantial disparities in performance\nbetween commercial and open-source OCR technologies.", "published": "2024-09-06 08:35:28", "link": "http://arxiv.org/abs/2409.04117v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language\n  Models for Text-to-Code Generation", "abstract": "In recent years, large language models (LLMs) have emerged as powerful tools\nwith potential applications in various fields, including software engineering.\nWithin the scope of this research, we evaluate five different state-of-the-art\nLLMs - Bard, BingChat, ChatGPT, Llama2, and Code Llama - concerning their\ncapabilities for text-to-code generation. In an empirical study, we feed\nprompts with textual descriptions of coding problems sourced from the\nprogramming website LeetCode to the models with the task of creating solutions\nin Python. Subsequently, the quality of the generated outputs is assessed using\nthe testing functionalities of LeetCode. The results indicate large differences\nin performance between the investigated models. ChatGPT can handle these\ntypical programming challenges by far the most effectively, surpassing even\ncode-specialized models like Code Llama. To gain further insights, we measure\nthe runtime as well as the memory usage of the generated outputs and compared\nthem to the other code submissions on Leetcode. A detailed error analysis,\nencompassing a comparison of the differences concerning correct indentation and\nform of the generated code as well as an assignment of the incorrectly solved\ntasks to certain error categories allows us to obtain a more nuanced picture of\nthe results and potential for improvement. The results also show a clear\npattern of increasingly incorrect produced code when the models are facing a\nlot of context in the form of longer prompts.", "published": "2024-09-06 10:03:49", "link": "http://arxiv.org/abs/2409.04164v1", "categories": ["cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "AGR: Age Group fairness Reward for Bias Mitigation in LLMs", "abstract": "LLMs can exhibit age biases, resulting in unequal treatment of individuals\nacross age groups. While much research has addressed racial and gender biases,\nage bias remains little explored. The scarcity of instruction-tuning and\npreference datasets for age bias hampers its detection and measurement, and\nexisting fine-tuning methods seldom address age-related fairness. In this\npaper, we construct age bias preference datasets and instruction-tuning\ndatasets for RLHF. We introduce ARG, an age fairness reward to reduce\ndifferences in the response quality of LLMs across different age groups.\nExtensive experiments demonstrate that this reward significantly improves\nresponse accuracy and reduces performance disparities across age groups. Our\nsource code and datasets are available at the anonymous\n\\href{https://anonymous.4open.science/r/FairRLHF-D445/readme.md}{link}.", "published": "2024-09-06 15:18:12", "link": "http://arxiv.org/abs/2409.04340v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Empirical Bayesian image restoration by Langevin sampling with a\n  denoising diffusion implicit prior", "abstract": "Score-based diffusion methods provide a powerful strategy to solve image\nrestoration tasks by flexibly combining a pre-trained foundational prior model\nwith a likelihood function specified during test time. Such methods are\npredominantly derived from two stochastic processes: reversing\nOrnstein-Uhlenbeck, which underpins the celebrated denoising diffusion\nprobabilistic models (DDPM) and denoising diffusion implicit models (DDIM), and\nthe Langevin diffusion process. The solutions delivered by DDPM and DDIM are\noften remarkably realistic, but they are not always consistent with\nmeasurements because of likelihood intractability issues and the associated\nrequired approximations. Alternatively, using a Langevin process circumvents\nthe intractable likelihood issue, but usually leads to restoration results of\ninferior quality and longer computing times. This paper presents a novel and\nhighly computationally efficient image restoration method that carefully embeds\na foundational DDPM denoiser within an empirical Bayesian Langevin algorithm,\nwhich jointly calibrates key model hyper-parameters as it estimates the model's\nposterior mean. Extensive experimental results on three canonical tasks (image\ndeblurring, super-resolution, and inpainting) demonstrate that the proposed\napproach improves on state-of-the-art strategies both in image estimation\naccuracy and computing time.", "published": "2024-09-06 16:20:24", "link": "http://arxiv.org/abs/2409.04384v1", "categories": ["cs.CV", "cs.CL", "eess.IV"], "primary_category": "cs.CV"}
{"title": "RLPF: Reinforcement Learning from Prediction Feedback for User\n  Summarization with LLMs", "abstract": "LLM-powered personalization agent systems employ Large Language Models (LLMs)\nto predict users' behavior from their past activities. However, their\neffectiveness often hinges on the ability to effectively leverage extensive,\nlong user historical data due to its inherent noise and length of such data.\nExisting pretrained LLMs may generate summaries that are concise but lack the\nnecessary context for downstream tasks, hindering their utility in\npersonalization systems. To address these challenges, we introduce\nReinforcement Learning from Prediction Feedback (RLPF). RLPF fine-tunes LLMs to\ngenerate concise, human-readable user summaries that are optimized for\ndownstream task performance. By maximizing the usefulness of the generated\nsummaries, RLPF effectively distills extensive user history data while\npreserving essential information for downstream tasks. Our empirical evaluation\ndemonstrates significant improvements in both extrinsic downstream task utility\nand intrinsic summary quality, surpassing baseline methods by up to 22% on\ndownstream task performance and achieving an up to 84.59% win rate on\nFactuality, Abstractiveness, and Readability. RLPF also achieves a remarkable\n74% reduction in context length while improving performance on 16 out of 19\nunseen tasks and/or datasets, showcasing its generalizability. This approach\noffers a promising solution for enhancing LLM personalization by effectively\ntransforming long, noisy user histories into informative and human-readable\nrepresentations.", "published": "2024-09-06 17:30:45", "link": "http://arxiv.org/abs/2409.04421v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OPAL: Outlier-Preserved Microscaling Quantization Accelerator for\n  Generative Large Language Models", "abstract": "To overcome the burden on the memory size and bandwidth due to\never-increasing size of large language models (LLMs), aggressive weight\nquantization has been recently studied, while lacking research on quantizing\nactivations. In this paper, we present a hardware-software co-design method\nthat results in an energy-efficient LLM accelerator, named OPAL, for generation\ntasks. First of all, a novel activation quantization method that leverages the\nmicroscaling data format while preserving several outliers per sub-tensor block\n(e.g., four out of 128 elements) is proposed. Second, on top of preserving\noutliers, mixed precision is utilized that sets 5-bit for inputs to sensitive\nlayers in the decoder block of an LLM, while keeping inputs to less sensitive\nlayers to 3-bit. Finally, we present the OPAL hardware architecture that\nconsists of FP units for handling outliers and vectorized INT multipliers for\ndominant non-outlier related operations. In addition, OPAL uses log2-based\napproximation on softmax operations that only requires shift and subtraction to\nmaximize power efficiency. As a result, we are able to improve the energy\nefficiency by 1.6~2.2x, and reduce the area by 2.4~3.1x with negligible\naccuracy loss, i.e., <1 perplexity increase.", "published": "2024-09-06 02:33:20", "link": "http://arxiv.org/abs/2409.05902v3", "categories": ["cs.LG", "cs.AR", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Programming Refusal with Conditional Activation Steering", "abstract": "LLMs have shown remarkable capabilities, but precisely controlling their\nresponse behavior remains challenging. Existing activation steering methods\nalter LLM behavior indiscriminately, limiting their practical applicability in\nsettings where selective responses are essential, such as content moderation or\ndomain-specific assistants. In this paper, we propose Conditional Activation\nSteering (CAST), which analyzes LLM activation patterns during inference to\nselectively apply or withhold activation steering based on the input context.\nOur method is based on the observation that different categories of prompts\nactivate distinct patterns in the model's hidden states. Using CAST, one can\nsystematically control LLM behavior with rules like \"if input is about hate\nspeech or adult content, then refuse\" or \"if input is not about legal advice,\nthen refuse.\" This allows for selective modification of responses to specific\ncontent while maintaining normal responses to other content, all without\nrequiring weight optimization. We release an open-source implementation of our\nframework at github.com/IBM/activation-steering .", "published": "2024-09-06 15:47:40", "link": "http://arxiv.org/abs/2409.05907v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Retrieval Augmented Generation-Based Incident Resolution Recommendation\n  System for IT Support", "abstract": "Clients wishing to implement generative AI in the domain of IT Support and\nAIOps face two critical issues: domain coverage and model size constraints due\nto model choice limitations. Clients might choose to not use larger proprietary\nmodels such as GPT-4 due to cost and privacy concerns and so are limited to\nsmaller models with potentially less domain coverage that do not generalize to\nthe client's domain. Retrieval augmented generation is a common solution that\naddresses both of these issues: a retrieval system first retrieves the\nnecessary domain knowledge which a smaller generative model leverages as\ncontext for generation. We present a system developed for a client in the IT\nSupport domain for support case solution recommendation that combines retrieval\naugmented generation (RAG) for answer generation with an encoder-only model for\nclassification and a generative large language model for query generation. We\ncover architecture details, data collection and annotation, development journey\nand preliminary validations, expected final deployment process and evaluation\nplans, and finally lessons learned.", "published": "2024-09-06 13:06:29", "link": "http://arxiv.org/abs/2409.13707v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Towards Safe Multilingual Frontier AI", "abstract": "Linguistically inclusive LLMs -- which maintain good performance regardless\nof the language with which they are prompted -- are necessary for the diffusion\nof AI benefits around the world. Multilingual jailbreaks that rely on language\ntranslation to evade safety measures undermine the safe and inclusive\ndeployment of AI systems. We provide policy recommendations to enhance the\nmultilingual capabilities of AI while mitigating the risks of multilingual\njailbreaks. We examine how a language's level of resourcing relates to how\nvulnerable LLMs are to multilingual jailbreaks in that language. We do this by\ntesting five advanced AI models across 24 official languages of the EU.\nBuilding on prior research, we propose policy actions that align with the EU\nlegal landscape and institutional framework to address multilingual jailbreaks,\nwhile promoting linguistic inclusivity. These include mandatory assessments of\nmultilingual capabilities and vulnerabilities, public opinion research, and\nstate support for multilingual AI development. The measures aim to improve AI\nsafety and functionality through EU policy initiatives, guiding the\nimplementation of the EU AI Act and informing regulatory efforts of the\nEuropean AI Office.", "published": "2024-09-06 14:26:18", "link": "http://arxiv.org/abs/2409.13708v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with\n  100+ NLP Researchers", "abstract": "Recent advancements in large language models (LLMs) have sparked optimism\nabout their potential to accelerate scientific discovery, with a growing number\nof works proposing research agents that autonomously generate and validate new\nideas. Despite this, no evaluations have shown that LLM systems can take the\nvery first step of producing novel, expert-level ideas, let alone perform the\nentire research process. We address this by establishing an experimental design\nthat evaluates research idea generation while controlling for confounders and\nperforms the first head-to-head comparison between expert NLP researchers and\nan LLM ideation agent. By recruiting over 100 NLP researchers to write novel\nideas and blind reviews of both LLM and human ideas, we obtain the first\nstatistically significant conclusion on current LLM capabilities for research\nideation: we find LLM-generated ideas are judged as more novel (p < 0.05) than\nhuman expert ideas while being judged slightly weaker on feasibility. Studying\nour agent baselines closely, we identify open problems in building and\nevaluating research agents, including failures of LLM self-evaluation and their\nlack of diversity in generation. Finally, we acknowledge that human judgements\nof novelty can be difficult, even by experts, and propose an end-to-end study\ndesign which recruits researchers to execute these ideas into full projects,\nenabling us to study whether these novelty and feasibility judgements result in\nmeaningful differences in research outcome.", "published": "2024-09-06 08:25:03", "link": "http://arxiv.org/abs/2409.04109v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "3D Data Long-Term Preservation in Cultural Heritage", "abstract": "The report explores the challenges and strategies for preserving 3D digital\ndata in cultural heritage. It discusses the issue of technological\nobsolescence, emphasising the need for ustainable storage solutions and ongoing\ndata management strategies. Key topics include understanding technological\nobsolescence, the lifecycle of digital content, digital continuity, data\nmanagement plans (DMP), FAIR principles, and the use of public repositories.\nThe report also covers the importance of metadata in long-term digital\npreservation, including types of metadata and strategies for building valuable\nmetadata. It examines the evolving standards and interoperability in 3D format\npreservation and the importance of managing metadata and paradata. The document\nprovides a comprehensive overview of the challenges and solutions for\npreserving 3D cultural heritage data in the long term.", "published": "2024-09-06 16:32:46", "link": "http://arxiv.org/abs/2409.04507v2", "categories": ["cs.IT", "cs.CG", "cs.CL", "cs.DL", "cs.GR", "math.IT", "E.1; I.4; H.1.1; H.3.2"], "primary_category": "cs.IT"}
{"title": "Low-Complexity Own Voice Reconstruction for Hearables with an In-Ear\n  Microphone", "abstract": "Hearable devices, equipped with one or more microphones, are commonly used\nfor speech communication. Here, we consider the scenario where a hearable is\nused to capture the user's own voice in a noisy environment. In this scenario,\nown voice reconstruction (OVR) is essential for enhancing the quality and\nintelligibility of the recorded noisy own voice signals. In previous work, we\ndeveloped a deep learning-based OVR system, aiming to reduce the amount of\ndevice-specific recordings for training by using data augmentation with\nphoneme-dependent models of own voice transfer characteristics. Given the\nlimited computational resources available on hearables, in this paper we\npropose low-complexity variants of an OVR system based on the FT-JNF\narchitecture and investigate the required amount of device-specific recordings\nfor effective data augmentation and fine-tuning. Simulation results show that\nthe proposed OVR system considerably improves speech quality, even under\nconstraints of low complexity and a limited amount of device-specific\nrecordings.", "published": "2024-09-06 08:59:42", "link": "http://arxiv.org/abs/2409.04136v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "NPU-NTU System for Voice Privacy 2024 Challenge", "abstract": "Speaker anonymization is an effective privacy protection solution that\nconceals the speaker's identity while preserving the linguistic content and\nparalinguistic information of the original speech. To establish a fair\nbenchmark and facilitate comparison of speaker anonymization systems, the\nVoicePrivacy Challenge (VPC) was held in 2020 and 2022, with a new edition\nplanned for 2024. In this paper, we describe our proposed speaker anonymization\nsystem for VPC 2024. Our system employs a disentangled neural codec\narchitecture and a serial disentanglement strategy to gradually disentangle the\nglobal speaker identity and time-variant linguistic content and paralinguistic\ninformation. We introduce multiple distillation methods to disentangle\nlinguistic content, speaker identity, and emotion. These methods include\nsemantic distillation, supervised speaker distillation, and frame-level emotion\ndistillation. Based on these distillations, we anonymize the original speaker\nidentity using a weighted sum of a set of candidate speaker identities and a\nrandomly generated speaker identity. Our system achieves the best trade-off of\nprivacy protection and emotion preservation in VPC 2024.", "published": "2024-09-06 10:32:42", "link": "http://arxiv.org/abs/2409.04173v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Development of the Listening in Spatialized Noise-Sentences (LiSN-S)\n  Test in Brazilian Portuguese: Presentation Software, Speech Stimuli, and\n  Sentence Equivalence", "abstract": "The Listening in Spatialized Noise Sentences (LiSN-S) is a test to evaluate\nauditory spatial processing currently only available in the English language.\nIt produces a three-dimensional auditory environment under headphones and uses\na simple repetition response protocol to determine speech reception thresholds\n(SRTs) for sentences presented in competing speech under various conditions. In\norder to develop the LiSN-S test in Brazilian Portuguese, it was necessary to\nprepare a speech database recorded by professional voice actresses and to\ndevise presentation software. These sentences were presented to 35 adults (aged\nbetween 19 and 40 years) and 24 children (aged between 8 and 10 years), all\nwith normal hearing-verified through tone and speech audiometry and\ntympanometry-and good performance at school. We used a logistic curve\ndescribing word error rate versus presentation level, fitted for each sentence,\nto select a set of 120 sentences for the test. Furthermore, all selected\nsentences were adjusted in amplitude for equal intelligibility. The framework\nof LiSN-S in Brazilian Portuguese is ready for normative data analysis. After\nits conclusion, we believe it will contribute to diagnosing and rehabilitating\nBrazilian children with complaints related to hearing difficulties in noisy\nenvironments", "published": "2024-09-06 03:57:30", "link": "http://arxiv.org/abs/2409.04014v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Investigating Neural Audio Codecs for Speech Language Model-Based Speech\n  Generation", "abstract": "Neural audio codec tokens serve as the fundamental building blocks for speech\nlanguage model (SLM)-based speech generation. However, there is no systematic\nunderstanding on how the codec system affects the speech generation performance\nof the SLM. In this work, we examine codec tokens within SLM framework for\nspeech generation to provide insights for effective codec design. We retrain\nexisting high-performing neural codec models on the same data set and loss\nfunctions to compare their performance in a uniform setting. We integrate codec\ntokens into two SLM systems: masked-based parallel speech generation system and\nan auto-regressive (AR) plus non-auto-regressive (NAR) model-based system. Our\nfindings indicate that better speech reconstruction in codec systems does not\nguarantee improved speech generation in SLM. A high-quality codec decoder is\ncrucial for natural speech production in SLM, while speech intelligibility\ndepends more on quantization mechanism.", "published": "2024-09-06 04:06:50", "link": "http://arxiv.org/abs/2409.04016v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "WaveTransfer: A Flexible End-to-end Multi-instrument Timbre Transfer\n  with Diffusion", "abstract": "As diffusion-based deep generative models gain prevalence, researchers are\nactively investigating their potential applications across various domains,\nincluding music synthesis and style alteration. Within this work, we are\ninterested in timbre transfer, a process that involves seamlessly altering the\ninstrumental characteristics of musical pieces while preserving essential\nmusical elements. This paper introduces WaveTransfer, an end-to-end diffusion\nmodel designed for timbre transfer. We specifically employ the bilateral\ndenoising diffusion model (BDDM) for noise scheduling search. Our model is\ncapable of conducting timbre transfer between audio mixtures as well as\nindividual instruments. Notably, it exhibits versatility in that it\naccommodates multiple types of timbre transfer between unique instrument pairs\nin a single model, eliminating the need for separate model training for each\npairing. Furthermore, unlike recent works limited to 16 kHz, WaveTransfer can\nbe trained at various sampling rates, including the industry-standard 44.1 kHz,\na feature of particular interest to the music community.", "published": "2024-09-06 06:55:11", "link": "http://arxiv.org/abs/2409.15321v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Searching for Effective Preprocessing Method and CNN-based Architecture\n  with Efficient Channel Attention on Speech Emotion Recognition", "abstract": "Speech emotion recognition (SER) classifies human emotions in speech with a\ncomputer model. Recently, performance in SER has steadily increased as deep\nlearning techniques have adapted. However, unlike many domains that use speech\ndata, data for training in the SER model is insufficient. This causes\noverfitting of training of the neural network, resulting in performance\ndegradation. In fact, successful emotion recognition requires an effective\npreprocessing method and a model structure that efficiently uses the number of\nweight parameters. In this study, we propose using eight dataset versions with\ndifferent frequency-time resolutions to search for an effective emotional\nspeech preprocessing method. We propose a 6-layer convolutional neural network\n(CNN) model with efficient channel attention (ECA) to pursue an efficient model\nstructure. In particular, the well-positioned ECA blocks can improve channel\nfeature representation with only a few parameters. With the interactive\nemotional dyadic motion capture (IEMOCAP) dataset, increasing the frequency\nresolution in preprocessing emotional speech can improve emotion recognition\nperformance. Also, ECA after the deep convolution layer can effectively\nincrease channel feature representation. Consequently, the best result (79.37UA\n79.68WA) can be obtained, exceeding the performance of previous SER models.\nFurthermore, to compensate for the lack of emotional speech data, we experiment\nwith multiple preprocessing data methods that augment trainable data\npreprocessed with all different settings from one sample. In the experiment, we\ncan achieve the highest result (80.28UA 80.46WA).", "published": "2024-09-06 03:17:25", "link": "http://arxiv.org/abs/2409.04007v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SLiCK: Exploiting Subsequences for Length-Constrained Keyword Spotting", "abstract": "User-defined keyword spotting on a resource-constrained edge device is\nchallenging. However, keywords are often bounded by a maximum keyword length,\nwhich has been largely under-leveraged in prior works. Our analysis of\nkeyword-length distribution shows that user-defined keyword spotting can be\ntreated as a length-constrained problem, eliminating the need for aggregation\nover variable text length. This leads to our proposed method for efficient\nkeyword spotting, SLiCK (exploiting Subsequences for Length-Constrained Keyword\nspotting). We further introduce a subsequence-level matching scheme to learn\naudio-text relations at a finer granularity, thus distinguishing\nsimilar-sounding keywords more effectively through enhanced context. In SLiCK,\nthe model is trained with a multi-task learning approach using two modules:\nMatcher (utterance-level matching task, novel subsequence-level matching task)\nand Encoder (phoneme recognition task). The proposed method improves the\nbaseline results on Libriphrase hard dataset, increasing AUC from $88.52$ to\n$94.9$ and reducing EER from $18.82$ to $11.1$.", "published": "2024-09-06 01:08:29", "link": "http://arxiv.org/abs/2409.09067v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
