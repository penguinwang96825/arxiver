{"title": "Mask-then-Fill: A Flexible and Effective Data Augmentation Framework for\n  Event Extraction", "abstract": "We present Mask-then-Fill, a flexible and effective data augmentation\nframework for event extraction. Our approach allows for more flexible\nmanipulation of text and thus can generate more diverse data while keeping the\noriginal event structure unchanged as much as possible. Specifically, it first\nrandomly masks out an adjunct sentence fragment and then infills a\nvariable-length text span with a fine-tuned infilling model. The main advantage\nlies in that it can replace a fragment of arbitrary length in the text with\nanother fragment of variable length, compared to the existing methods which can\nonly replace a single word or a fixed-length fragment. On trigger and argument\nextraction tasks, the proposed framework is more effective than baseline\nmethods and it demonstrates particularly strong results in the low-resource\nsetting. Our further analysis shows that it achieves a good balance between\ndiversity and distributional similarity.", "published": "2023-01-06 09:19:23", "link": "http://arxiv.org/abs/2301.02427v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OPD@NL4Opt: An ensemble approach for the NER task of the optimization\n  problem", "abstract": "In this paper, we present an ensemble approach for the NL4Opt competition\nsubtask 1(NER task). For this task, we first fine tune the pretrained language\nmodels based on the competition dataset. Then we adopt differential learning\nrates and adversarial training strategies to enhance the model generalization\nand robustness. Additionally, we use a model ensemble method for the final\nprediction, which achieves a micro-averaged F1 score of 93.3% and attains the\nsecond prize in the NER task.", "published": "2023-01-06 11:07:55", "link": "http://arxiv.org/abs/2301.02459v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Causal Categorization of Mental Health Posts using Transformers", "abstract": "With recent developments in digitization of clinical psychology, NLP research\ncommunity has revolutionized the field of mental health detection on social\nmedia. Existing research in mental health analysis revolves around the\ncross-sectional studies to classify users' intent on social media. For in-depth\nanalysis, we investigate existing classifiers to solve the problem of causal\ncategorization which suggests the inefficiency of learning based methods due to\nlimited training samples. To handle this challenge, we use transformer models\nand demonstrate the efficacy of a pre-trained transfer learning on \"CAMS\"\ndataset. The experimental result improves the accuracy and depicts the\nimportance of identifying cause-and-effect relationships in the underlying\ntext.", "published": "2023-01-06 16:37:48", "link": "http://arxiv.org/abs/2301.02589v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "You Truly Understand What I Need: Intellectual and Friendly Dialogue\n  Agents grounding Knowledge and Persona", "abstract": "To build a conversational agent that interacts fluently with humans, previous\nstudies blend knowledge or personal profile into the pre-trained language\nmodel. However, the model that considers knowledge and persona at the same time\nis still limited, leading to hallucination and a passive way of using personas.\nWe propose an effective dialogue agent that grounds external knowledge and\npersona simultaneously. The agent selects the proper knowledge and persona to\nuse for generating the answers with our candidate scoring implemented with a\npoly-encoder. Then, our model generates the utterance with lesser hallucination\nand more engagingness utilizing retrieval augmented generation with\nknowledge-persona enhanced query. We conduct experiments on the\npersona-knowledge chat and achieve state-of-the-art performance in grounding\nand generation tasks on the automatic metrics. Moreover, we validate the\nanswers from the models regarding hallucination and engagingness through human\nevaluation and qualitative results. We show our retriever's effectiveness in\nextracting relevant documents compared to the other previous retrievers, along\nwith the comparison of multiple candidate scoring methods. Code is available at\nhttps://github.com/dlawjddn803/INFO", "published": "2023-01-06 06:47:21", "link": "http://arxiv.org/abs/2301.02401v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Topics as Entity Clusters: Entity-based Topics from Large Language\n  Models and Graph Neural Networks", "abstract": "Topic models aim to reveal latent structures within a corpus of text,\ntypically through the use of term-frequency statistics over bag-of-words\nrepresentations from documents. In recent years, conceptual entities --\ninterpretable, language-independent features linked to external knowledge\nresources -- have been used in place of word-level tokens, as words typically\nrequire extensive language processing with a minimal assurance of\ninterpretability. However, current literature is limited when it comes to\nexploring purely entity-driven neural topic modeling. For instance, despite the\nadvantages of using entities for eliciting thematic structure, it is unclear\nwhether current techniques are compatible with these sparsely organised,\ninformation-dense conceptual units. In this work, we explore entity-based\nneural topic modeling and propose a novel topic clustering approach using\nbimodal vector representations of entities. Concretely, we extract these latent\nrepresentations from large language models and graph neural networks trained on\na knowledge base of symbolic relations, in order to derive the most salient\naspects of these conceptual units. Analysis of coherency metrics confirms that\nour approach is better suited to working with entities in comparison to\nstate-of-the-art models, particularly when using graph-based embeddings trained\non a knowledge base.", "published": "2023-01-06 10:54:54", "link": "http://arxiv.org/abs/2301.02458v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SAIDS: A Novel Approach for Sentiment Analysis Informed of Dialect and\n  Sarcasm", "abstract": "Sentiment analysis becomes an essential part of every social network, as it\nenables decision-makers to know more about users' opinions in almost all life\naspects. Despite its importance, there are multiple issues it encounters like\nthe sentiment of the sarcastic text which is one of the main challenges of\nsentiment analysis. This paper tackles this challenge by introducing a novel\nsystem (SAIDS) that predicts the sentiment, sarcasm and dialect of Arabic\ntweets. SAIDS uses its prediction of sarcasm and dialect as known information\nto predict the sentiment. It uses MARBERT as a language model to generate\nsentence embedding, then passes it to the sarcasm and dialect models, and then\nthe outputs of the three models are concatenated and passed to the sentiment\nanalysis model. Multiple system design setups were experimented with and\nreported. SAIDS was applied to the ArSarcasm-v2 dataset where it outperforms\nthe state-of-the-art model for the sentiment analysis task. By training all\ntasks together, SAIDS achieves results of 75.98 FPN, 59.09 F1-score and 71.13\nF1-score for sentiment analysis, sarcasm detection, and dialect identification\nrespectively. The system design can be used to enhance the performance of any\ntask which is dependent on other tasks.", "published": "2023-01-06 14:19:46", "link": "http://arxiv.org/abs/2301.02521v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Witscript 3: A Hybrid AI System for Improvising Jokes in a Conversation", "abstract": "Previous papers presented Witscript and Witscript 2, AI systems for\nimprovising jokes in a conversation. Witscript generates jokes that rely on\nwordplay, whereas the jokes generated by Witscript 2 rely on common sense. This\npaper extends that earlier work by presenting Witscript 3, which generates joke\ncandidates using three joke production mechanisms and then selects the best\ncandidate to output. Like Witscript and Witscript 2, Witscript 3 is based on\nhumor algorithms created by an expert comedy writer. Human evaluators judged\nWitscript 3's responses to input sentences to be jokes 44% of the time. This is\nevidence that Witscript 3 represents another step toward giving a chatbot a\nhumanlike sense of humor.", "published": "2023-01-06 19:25:46", "link": "http://arxiv.org/abs/2301.02695v1", "categories": ["cs.CL", "cs.AI", "I.2.7; J.5"], "primary_category": "cs.CL"}
{"title": "Facilitating Contrastive Learning of Discourse Relational Senses by\n  Exploiting the Hierarchy of Sense Relations", "abstract": "Implicit discourse relation recognition is a challenging task that involves\nidentifying the sense or senses that hold between two adjacent spans of text,\nin the absence of an explicit connective between them. In both PDTB-2 and\nPDTB-3, discourse relational senses are organized into a three-level hierarchy\nranging from four broad top-level senses, to more specific senses below them.\nMost previous work on implicit discourse relation recognition have used the\nsense hierarchy simply to indicate what sense labels were available. Here we do\nmore -- incorporating the sense hierarchy into the recognition process itself\nand using it to select the negative examples used in contrastive learning. With\nno additional effort, the approach achieves state-of-the-art performance on the\ntask.", "published": "2023-01-06 21:55:48", "link": "http://arxiv.org/abs/2301.02724v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generative Antibody Design for Complementary Chain Pairing Sequences\n  through Encoder-Decoder Language Model", "abstract": "Current protein language models (pLMs) predominantly focus on single-chain\nprotein sequences and often have not accounted for constraints on generative\ndesign imposed by protein-protein interactions. To address this gap, we present\npaired Antibody T5 (pAbT5), an encoder-decoder model to generate complementary\nheavy or light chain from its pairing partner. We show that our model respects\nconservation in framework regions and variability in hypervariable domains,\ndemonstrated by agreement with sequence alignment and variable-length CDR\nloops. We also show that our model captures chain pairing preferences through\nthe recovery of ground-truth chain type and gene families. Our results showcase\nthe potential of pAbT5 in generative antibody design, incorporating biological\nconstraints from chain pairing preferences.", "published": "2023-01-06 23:34:52", "link": "http://arxiv.org/abs/2301.02748v4", "categories": ["q-bio.BM", "cs.CE", "cs.CL"], "primary_category": "q-bio.BM"}
{"title": "\"No, to the Right\" -- Online Language Corrections for Robotic\n  Manipulation via Shared Autonomy", "abstract": "Systems for language-guided human-robot interaction must satisfy two key\ndesiderata for broad adoption: adaptivity and learning efficiency.\nUnfortunately, existing instruction-following agents cannot adapt, lacking the\nability to incorporate online natural language supervision, and even if they\ncould, require hundreds of demonstrations to learn even simple policies. In\nthis work, we address these problems by presenting Language-Informed Latent\nActions with Corrections (LILAC), a framework for incorporating and adapting to\nnatural language corrections - \"to the right,\" or \"no, towards the book\" -\nonline, during execution. We explore rich manipulation domains within a shared\nautonomy paradigm. Instead of discrete turn-taking between a human and robot,\nLILAC splits agency between the human and robot: language is an input to a\nlearned model that produces a meaningful, low-dimensional control space that\nthe human can use to guide the robot. Each real-time correction refines the\nhuman's control space, enabling precise, extended behaviors - with the added\nbenefit of requiring only a handful of demonstrations to learn. We evaluate our\napproach via a user study where users work with a Franka Emika Panda\nmanipulator to complete complex manipulation tasks. Compared to existing\nlearned baselines covering both open-loop instruction following and single-turn\nshared autonomy, we show that our corrections-aware approach obtains higher\ntask completion rates, and is subjectively preferred by users because of its\nreliability, precision, and ease of use.", "published": "2023-01-06 15:03:27", "link": "http://arxiv.org/abs/2301.02555v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Multi-Genre Music Transformer -- Composing Full Length Musical Piece", "abstract": "In the task of generating music, the art factor plays a big role and is a\ngreat challenge for AI. Previous work involving adversarial training to produce\nnew music pieces and modeling the compatibility of variety in music (beats,\ntempo, musical stems) demonstrated great examples of learning this task. Though\nthis was limited to generating mashups or learning features from tempo and key\ndistributions to produce similar patterns. Compound Word Transformer was able\nto represent music generation task as a sequence generation challenge involving\nmusical events defined by compound words. These musical events give a more\naccurate description of notes progression, chord change, harmony and the art\nfactor. The objective of the project is to implement a Multi-Genre Transformer\nwhich learns to produce music pieces through more adaptive learning process\ninvolving more challenging task where genres or form of the composition is also\nconsidered. We built a multi-genre compound word dataset, implemented a linear\ntransformer which was trained on this dataset. We call this Multi-Genre\nTransformer, which was able to generate full length new musical pieces which is\ndiverse and comparable to original tracks. The model trains 2-5 times faster\nthan other models discussed.", "published": "2023-01-06 05:27:55", "link": "http://arxiv.org/abs/2301.02385v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multimodal Lyrics-Rhythm Matching", "abstract": "Despite the recent increase in research on artificial intelligence for music,\nprominent correlations between key components of lyrics and rhythm such as\nkeywords, stressed syllables, and strong beats are not frequently studied. This\nis likely due to challenges such as audio misalignment, inaccuracies in\nsyllabic identification, and most importantly, the need for cross-disciplinary\nknowledge. To address this lack of research, we propose a novel multimodal\nlyrics-rhythm matching approach in this paper that specifically matches key\ncomponents of lyrics and music with each other without any language\nlimitations. We use audio instead of sheet music with readily available\nmetadata, which creates more challenges yet increases the application\nflexibility of our method. Furthermore, our approach creatively generates\nseveral patterns involving various multimodalities, including music strong\nbeats, lyrical syllables, auditory changes in a singer's pronunciation, and\nespecially lyrical keywords, which are utilized for matching key lyrical\nelements with key rhythmic elements. This advantageous approach not only\nprovides a unique way to study auditory lyrics-rhythm correlations including\nefficient rhythm-based audio alignment algorithms, but also bridges\ncomputational linguistics with music as well as music cognition. Our\nexperimental results reveal an 0.81 probability of matching on average, and\naround 30% of the songs have a probability of 0.9 or higher of keywords landing\non strong beats, including 12% of the songs with a perfect landing. Also, the\nsimilarity metrics are used to evaluate the correlation between lyrics and\nrhythm. It shows that nearly 50% of the songs have 0.70 similarity or higher.\nIn conclusion, our approach contributes significantly to the lyrics-rhythm\nrelationship by computationally unveiling insightful correlations.", "published": "2023-01-06 22:24:53", "link": "http://arxiv.org/abs/2301.02732v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Using External Off-Policy Speech-To-Text Mappings in Contextual\n  End-To-End Automated Speech Recognition", "abstract": "Despite improvements to the generalization performance of automated speech\nrecognition (ASR) models, specializing ASR models for downstream tasks remains\na challenging task, primarily due to reduced data availability (necessitating\nincreased data collection), and rapidly shifting data distributions (requiring\nmore frequent model fine-tuning). In this work, we investigate the potential of\nleveraging external knowledge, particularly through off-policy key-value stores\ngenerated with text-to-speech methods, to allow for flexible post-training\nadaptation to new data distributions. In our approach, audio embeddings\ncaptured from text-to-speech, along with semantic text embeddings, are used to\nbias ASR via an approximate k-nearest-neighbor (KNN) based attentive fusion\nstep. Our experiments on LibiriSpeech and in-house voice assistant/search\ndatasets show that the proposed approach can reduce domain adaptation time by\nup to 1K GPU-hours while providing up to 3% WER improvement compared to a\nfine-tuning baseline, suggesting a promising approach for adapting production\nASR systems in challenging zero and few-shot scenarios.", "published": "2023-01-06 22:32:50", "link": "http://arxiv.org/abs/2301.02736v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
