{"title": "Enhancing Dialogue Summarization with Topic-Aware Global- and Local-\n  Level Centrality", "abstract": "Dialogue summarization aims to condense a given dialogue into a simple and\nfocused summary text. Typically, both the roles' viewpoints and conversational\ntopics change in the dialogue stream. Thus how to effectively handle the\nshifting topics and select the most salient utterance becomes one of the major\nchallenges of this task. In this paper, we propose a novel topic-aware\nGlobal-Local Centrality (GLC) model to help select the salient context from all\nsub-topics. The centralities are constructed at both the global and local\nlevels. The global one aims to identify vital sub-topics in the dialogue and\nthe local one aims to select the most important context in each sub-topic.\nSpecifically, the GLC collects sub-topic based on the utterance\nrepresentations. And each utterance is aligned with one sub-topic. Based on the\nsub-topics, the GLC calculates global- and local-level centralities. Finally,\nwe combine the two to guide the model to capture both salient context and\nsub-topics when generating summaries. Experimental results show that our model\noutperforms strong baselines on three public dialogue summarization datasets:\nCSDS, MC, and SAMSUM. Further analysis demonstrates that our GLC can exactly\nidentify vital contents from\nsub-topics.~\\footnote{\\url{https://github.com/xnliang98/bart-glc}}", "published": "2023-01-29 06:41:55", "link": "http://arxiv.org/abs/2301.12376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syrupy Mouthfeel and Hints of Chocolate -- Predicting Coffee Review\n  Scores using Text Based Sentiment", "abstract": "This paper uses textual data contained in certified (q-graded) coffee reviews\nto predict corresponding scores on a scale from 0-100. By transforming this\nhighly specialized and standardized textual data in a predictor space, we\nconstruct regression models which accurately capture the patterns in\ncorresponding coffee bean scores.", "published": "2023-01-29 10:55:36", "link": "http://arxiv.org/abs/2301.12417v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Producing Usable Taxonomies Cheaply and Rapidly at Pinterest Using\n  Discovered Dynamic $\u03bc$-Topics", "abstract": "Creating a taxonomy of interests is expensive and human-effort intensive: not\nonly do we need to identify nodes and interconnect them, in order to use the\ntaxonomy, we must also connect the nodes to relevant entities such as users,\npins, and queries. Connecting to entities is challenging because of ambiguities\ninherent to language but also because individual interests are dynamic and\nevolve. Here, we offer an alternative approach that begins with bottom-up\ndiscovery of $\\mu$-topics called pincepts. The discovery process itself\nconnects these $\\mu$-topics dynamically with relevant queries, pins, and users\nat high precision, automatically adapting to shifting interests. Pincepts cover\nall areas of user interest and automatically adjust to the specificity of user\ninterests and are thus suitable for the creation of various kinds of\ntaxonomies. Human experts associate taxonomy nodes with $\\mu$-topics (on\naverage, 3 $\\mu$-topics per node), and the $\\mu$-topics offer a high-level data\nlayer that allows quick definition, immediate inspection, and easy\nmodification. Even more powerfully, $\\mu$-topics allow easy exploration of\nnearby semantic space, enabling curators to spot and fill gaps. Curators'\ndomain knowledge is heavily leveraged and we thus don't need untrained\nmechanical Turks, allowing further cost reduction. These $\\mu$-topics thus\noffer a satisfactory \"symbolic\" stratum over which to define taxonomies. We\nhave successfully applied this technique for very rapidly iterating on and\nlaunching the home decor and fashion styles taxonomy for style-based\npersonalization, prominently featured at the top of Pinterest search results,\nat 94% precision, improving search success rate by 34.8% as well as boosting\nlong clicks and pin saves.", "published": "2023-01-29 19:27:08", "link": "http://arxiv.org/abs/2301.12520v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Discerning Several Thousand Judgments: GPT-3 Rates the Article +\n  Adjective + Numeral + Noun Construction", "abstract": "Knowledge of syntax includes knowledge of rare, idiosyncratic constructions.\nLLMs must overcome frequency biases in order to master such constructions. In\nthis study, I prompt GPT-3 to give acceptability judgments on the\nEnglish-language Article + Adjective + Numeral + Noun construction (e.g., \"a\nlovely five days\"). I validate the prompt using the CoLA corpus of\nacceptability judgments and then zero in on the AANN construction. I compare\nGPT- 3's judgments to crowdsourced human judgments on a subset of sentences.\nGPT-3's judgments are broadly similar to human judgments and generally align\nwith proposed constraints in the literature but, in some cases, GPT-3's\njudgments and human judgments diverge from the literature and from each other.", "published": "2023-01-29 22:29:55", "link": "http://arxiv.org/abs/2301.12564v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Schema-Guided Semantic Accuracy: Faithfulness in Task-Oriented Dialogue\n  Response Generation", "abstract": "Ensuring that generated utterances are faithful to dialogue actions is\ncrucial for Task-Oriented Dialogue Response Generation. Slot Error Rate (SER)\nonly partially measures generation quality in that it solely assesses\nutterances generated from non-categorical slots whose values are expected to be\nreproduced exactly. Utterances generated from categorical slots, which are more\nvariable, are not assessed by SER. We propose Schema-Guided Semantic Accuracy\n(SGSAcc) to evaluate utterances generated from both categorical and\nnon-categorical slots by recognizing textual entailment. We show that SGSAcc\ncan be applied to evaluate utterances generated from a wide range of dialogue\nactions in the Schema Guided Dialogue (SGD) dataset with good agreement with\nhuman judgment. We also identify a previously overlooked weakness in generating\nfaithful utterances from categorical slots in unseen domains. We show that\nprefix tuning applied to T5 generation can address this problem. We further\nbuild an ensemble of prefix-tuning and fine-tuning models that achieves the\nlowest SER reported and high SGSAcc on the SGD dataset.", "published": "2023-01-29 22:32:48", "link": "http://arxiv.org/abs/2301.12568v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic Analysis using Paninian System of Sounds and Finite State\n  Machines", "abstract": "The study of spoken languages comprises phonology, morphology, and grammar.\nAnalysis of a language can be based on its syntax, semantics, and pragmatics.\nThe languages can be classified as root languages, inflectional languages, and\nstem languages. All these factors lead to the formation of vocabulary which has\ncommonality/similarity as well as distinct and subtle differences across\nlanguages. In this paper, we make use of Paninian system of sounds to construct\na phonetic map and then words are represented as state transitions on the\nphonetic map. Each group of related words that cut across languages is\nrepresented by a m-language (morphological language). Morphological Finite\nAutomata (MFA) are defined that accept the words belonging to a given\nm-language. This exercise can enable us to better understand the\ninter-relationships between words in spoken languages in both language-agnostic\nand language-cognizant manner. Based on our study and analysis, we propose an\nEcosystem Model for Linguistic Development with Sanskrit at the core, in place\nof the widely accepted family tree model.", "published": "2023-01-29 15:22:10", "link": "http://arxiv.org/abs/2301.12463v2", "categories": ["cs.CL", "cs.FL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Biomedical Knowledge Graph Construction:\n  Information extraction from EMR notes", "abstract": "The automatic construction of knowledge graphs (KGs) is an important research\narea in medicine, with far-reaching applications spanning drug discovery and\nclinical trial design. These applications hinge on the accurate identification\nof interactions among medical and biological entities. In this study, we\npropose an end-to-end machine learning solution based on large language models\n(LLMs) that utilize electronic medical record notes to construct KGs. The\nentities used in the KG construction process are diseases, factors, treatments,\nas well as manifestations that coexist with the patient while experiencing the\ndisease. Given the critical need for high-quality performance in medical\napplications, we embark on a comprehensive assessment of 12 LLMs of various\narchitectures, evaluating their performance and safety attributes. To gauge the\nquantitative efficacy of our approach by assessing both precision and recall,\nwe manually annotate a dataset provided by the Macula and Retina Institute. We\nalso assess the qualitative performance of LLMs, such as the ability to\ngenerate structured outputs or the tendency to hallucinate. The results\nillustrate that in contrast to encoder-only and encoder-decoder, decoder-only\nLLMs require further investigation. Additionally, we provide guided prompt\ndesign to utilize such LLMs. The application of the proposed methodology is\ndemonstrated on age-related macular degeneration.", "published": "2023-01-29 15:52:33", "link": "http://arxiv.org/abs/2301.12473v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Cross-lingual Information Retrieval on Low-Resource Languages\n  via Optimal Transport Distillation", "abstract": "Benefiting from transformer-based pre-trained language models, neural ranking\nmodels have made significant progress. More recently, the advent of\nmultilingual pre-trained language models provides great support for designing\nneural cross-lingual retrieval models. However, due to unbalanced pre-training\ndata in different languages, multilingual language models have already shown a\nperformance gap between high and low-resource languages in many downstream\ntasks. And cross-lingual retrieval models built on such pre-trained models can\ninherit language bias, leading to suboptimal result for low-resource languages.\nMoreover, unlike the English-to-English retrieval task, where large-scale\ntraining collections for document ranking such as MS MARCO are available, the\nlack of cross-lingual retrieval data for low-resource language makes it more\nchallenging for training cross-lingual retrieval models. In this work, we\npropose OPTICAL: Optimal Transport distillation for low-resource Cross-lingual\ninformation retrieval. To transfer a model from high to low resource languages,\nOPTICAL forms the cross-lingual token alignment task as an optimal transport\nproblem to learn from a well-trained monolingual retrieval model. By separating\nthe cross-lingual knowledge from knowledge of query document matching, OPTICAL\nonly needs bitext data for distillation training, which is more feasible for\nlow-resource languages. Experimental results show that, with minimal training\ndata, OPTICAL significantly outperforms strong baselines on low-resource\nlanguages, including neural machine translation.", "published": "2023-01-29 22:30:36", "link": "http://arxiv.org/abs/2301.12566v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Unifying Molecular and Textual Representations via Multi-task Language\n  Modelling", "abstract": "The recent advances in neural language models have also been successfully\napplied to the field of chemistry, offering generative solutions for classical\nproblems in molecular design and synthesis planning. These new methods have the\npotential to fuel a new era of data-driven automation in scientific discovery.\nHowever, specialized models are still typically required for each task, leading\nto the need for problem-specific fine-tuning and neglecting task\ninterrelations. The main obstacle in this field is the lack of a unified\nrepresentation between natural language and chemical representations,\ncomplicating and limiting human-machine interaction. Here, we propose the first\nmulti-domain, multi-task language model that can solve a wide range of tasks in\nboth the chemical and natural language domains. Our model can handle chemical\nand natural language concurrently, without requiring expensive pre-training on\nsingle domains or task-specific models. Interestingly, sharing weights across\ndomains remarkably improves our model when benchmarked against state-of-the-art\nbaselines on single-domain and cross-domain tasks. In particular, sharing\ninformation across domains and tasks gives rise to large improvements in\ncross-domain tasks, the magnitude of which increase with scale, as measured by\nmore than a dozen of relevant metrics. Our work suggests that such models can\nrobustly and efficiently accelerate discovery in physical sciences by\nsuperseding problem-specific fine-tuning and enhancing human-model\ninteractions.", "published": "2023-01-29 23:56:45", "link": "http://arxiv.org/abs/2301.12586v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Physarum Inspired Bicycle Lane Network Design in a Congested Mega City", "abstract": "Mobility is a key factor in urban life and transport network plays a vital\nrole in mobility. Worse transport network having less mobility is one of the\nkey reasons to decline the living standard in any unplanned mega city.\nTransport mobility enhancement in an unplanned mega city is always challenging\ndue to various constraints including complex design and high cost involvement.\nThe aim of this thesis is to enhance transport mobility in a megacity\nintroducing a bicycle lane. To design the bicycle lane natural Physarum,\nbrainless single celled multi-nucleated protist, is studied and modified for\nbetter optimization. Recently Physarum inspired techniques are drawn\nsignificant attention to the construction of effective networks. Exiting\nPhysarum inspired models effectively and efficiently solves different problems\nincluding transport network design and modification and implication for bicycle\nlane is the unique contribution of this study. Central area of Dhaka, the\ncapital city of Bangladesh, is considered to analyze and design the bicycle\nlane network bypassing primary roads.", "published": "2023-01-29 16:55:49", "link": "http://arxiv.org/abs/2301.13609v1", "categories": ["physics.soc-ph", "cs.CL"], "primary_category": "physics.soc-ph"}
{"title": "Progressive Prompts: Continual Learning for Language Models", "abstract": "We introduce Progressive Prompts - a simple and efficient approach for\ncontinual learning in language models. Our method allows forward transfer and\nresists catastrophic forgetting, without relying on data replay or a large\nnumber of task-specific parameters. Progressive Prompts learns a new soft\nprompt for each task and sequentially concatenates it with the previously\nlearned prompts, while keeping the base model frozen. Experiments on standard\ncontinual learning benchmarks show that our approach outperforms\nstate-of-the-art methods, with an improvement >20% in average test accuracy\nover the previous best-preforming method on T5 model. We also explore a more\nchallenging continual learning setup with longer sequences of tasks and show\nthat Progressive Prompts significantly outperforms prior methods.", "published": "2023-01-29 00:17:38", "link": "http://arxiv.org/abs/2301.12314v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Time out of Mind: Generating Rate of Speech conditioned on emotion and\n  speaker", "abstract": "Voice synthesis has seen significant improvements in the past decade\nresulting in highly intelligible voices. Further investigations have resulted\nin models that can produce variable speech, including conditional emotional\nexpression. The problem lies, however, in a focus on phrase-level modifications\nand prosodic vocal features. Using the CREMA-D dataset we have trained a GAN\nconditioned on emotion to generate worth lengths for a given input text. These\nword lengths are relative to neutral speech and can be provided, through speech\nsynthesis markup language (SSML) to a text-to-speech (TTS) system to generate\nmore expressive speech. Additionally, a generative model is also trained using\nimplicit maximum likelihood estimation (IMLE) and a comparative analysis with\nGANs is included. We were able to achieve better performances on objective\nmeasures for neutral speech, and better time alignment for happy speech when\ncompared to an out-of-box model. However, further investigation of subjective\nevaluation is required.", "published": "2023-01-29 02:58:01", "link": "http://arxiv.org/abs/2301.12331v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Achieving Timestamp Prediction While Recognizing with Non-Autoregressive\n  End-to-End ASR Model", "abstract": "Conventional ASR systems use frame-level phoneme posterior to conduct\nforce-alignment~(FA) and provide timestamps, while end-to-end ASR systems\nespecially AED based ones are short of such ability. This paper proposes to\nperform timestamp prediction~(TP) while recognizing by utilizing continuous\nintegrate-and-fire~(CIF) mechanism in non-autoregressive ASR model -\nParaformer. Foucing on the fire place bias issue of CIF, we conduct\npost-processing strategies including fire-delay and silence insertion. Besides,\nwe propose to use scaled-CIF to smooth the weights of CIF output, which is\nproved beneficial for both ASR and TP task. Accumulated averaging shift~(AAS)\nand diarization error rate~(DER) are adopted to measure the quality of\ntimestamps and we compare these metrics of proposed system and conventional\nhybrid force-alignment system. The experiment results over manually-marked\ntimestamps testset show that the proposed optimization methods significantly\nimprove the accuracy of CIF timestamps, reducing 66.7\\% and 82.1\\% of AAS and\nDER respectively. Comparing to Kaldi force-alignment trained with the same\ndata, optimized CIF timestamps achieved 12.3\\% relative AAS reduction.", "published": "2023-01-29 03:47:59", "link": "http://arxiv.org/abs/2301.12343v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Vicarious Offense and Noise Audit of Offensive Speech Classifiers:\n  Unifying Human and Machine Disagreement on What is Offensive", "abstract": "Offensive speech detection is a key component of content moderation. However,\nwhat is offensive can be highly subjective. This paper investigates how machine\nand human moderators disagree on what is offensive when it comes to real-world\nsocial web political discourse. We show that (1) there is extensive\ndisagreement among the moderators (humans and machines); and (2) human and\nlarge-language-model classifiers are unable to predict how other human raters\nwill respond, based on their political leanings. For (1), we conduct a noise\naudit at an unprecedented scale that combines both machine and human responses.\nFor (2), we introduce a first-of-its-kind dataset of vicarious offense. Our\nnoise audit reveals that moderation outcomes vary wildly across different\nmachine moderators. Our experiments with human moderators suggest that\npolitical leanings combined with sensitive issues affect both first-person and\nvicarious offense. The dataset is available through\nhttps://github.com/Homan-Lab/voiced.", "published": "2023-01-29 20:39:21", "link": "http://arxiv.org/abs/2301.12534v4", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NeuralKalman: A Learnable Kalman Filter for Acoustic Echo Cancellation", "abstract": "The robustness of the Kalman filter to double talk and its rapid convergence\nmake it a popular approach for addressing acoustic echo cancellation (AEC)\nchallenges. However, the inability to model nonlinearity and the need to tune\ncontrol parameters cast limitations on such adaptive filtering algorithms. In\nthis paper, we integrate the frequency domain Kalman filter (FDKF) and deep\nneural networks (DNNs) into a hybrid method, called NeuralKalman, to leverage\nthe advantages of deep learning and adaptive filtering algorithms.\nSpecifically, we employ a DNN to estimate nonlinearly distorted far-end\nsignals, a transition factor, and the nonlinear transition function in the\nstate equation of the FDKF algorithm. Experimental results show that the\nproposed NeuralKalman improves the performance of FDKF significantly and\noutperforms strong baseline methods.", "published": "2023-01-29 05:41:30", "link": "http://arxiv.org/abs/2301.12363v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Artistic Curve Steganography Carried by Musical Audio", "abstract": "In this work, we create artistic closed loop curves that trace out images and\n3D shapes, which we then hide in musical audio as a form of steganography. We\nuse traveling salesperson art to create artistic plane loops to trace out image\ncontours, and we use Hamiltonian cycles on triangle meshes to create artistic\nspace loops that fill out 3D surfaces. Our embedding scheme is designed to\nfaithfully preserve the geometry of these loops after lossy compression, while\nkeeping their presence undetectable to the audio listener. To accomplish this,\nwe hide each dimension of the curve in a different frequency, and we perturb a\nsliding window sum of the magnitude of that frequency to best match the target\ncurve at that dimension, while hiding scale information in that frequency's\nphase. In the process, we exploit geometric properties of the curves to help to\nmore effectively hide and recover them. Our scheme is simple and encoding\nhappens efficiently with a nonnegative least squares framework, while decoding\nis trivial. We validate our technique quantitatively on large datasets of\nimages and audio, and we show results of a crowd sourced listening test that\nvalidate that the hidden information is indeed unobtrusive.", "published": "2023-01-29 04:15:57", "link": "http://arxiv.org/abs/2301.12354v1", "categories": ["cs.SD", "cs.IR", "cs.MM", "eess.AS", "I.3.8; E.4; I.5.4"], "primary_category": "cs.SD"}
{"title": "Composer's Assistant: An Interactive Transformer for Multi-Track MIDI\n  Infilling", "abstract": "We introduce Composer's Assistant, a system for interactive human-computer\ncomposition in the REAPER digital audio workstation. We consider the task of\nmulti-track MIDI infilling when arbitrary track-measures have been deleted from\na contiguous slice of measures from a MIDI file, and we train a T5-like model\nto accomplish this task. Composer's Assistant consists of this model together\nwith scripts that enable interaction with the model in REAPER. We conduct\nobjective and subjective tests of our model. We release our complete system,\nconsisting of source code, pretrained models, and REAPER scripts. Our models\nwere trained only on permissively-licensed MIDI files.", "published": "2023-01-29 19:45:10", "link": "http://arxiv.org/abs/2301.12525v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AudioLDM: Text-to-Audio Generation with Latent Diffusion Models", "abstract": "Text-to-audio (TTA) system has recently gained attention for its ability to\nsynthesize general audio based on text descriptions. However, previous studies\nin TTA have limited generation quality with high computational costs. In this\nstudy, we propose AudioLDM, a TTA system that is built on a latent space to\nlearn the continuous audio representations from contrastive language-audio\npretraining (CLAP) latents. The pretrained CLAP models enable us to train LDMs\nwith audio embedding while providing text embedding as a condition during\nsampling. By learning the latent representations of audio signals and their\ncompositions without modeling the cross-modal relationship, AudioLDM is\nadvantageous in both generation quality and computational efficiency. Trained\non AudioCaps with a single GPU, AudioLDM achieves state-of-the-art TTA\nperformance measured by both objective and subjective metrics (e.g., frechet\ndistance). Moreover, AudioLDM is the first TTA system that enables various\ntext-guided audio manipulations (e.g., style transfer) in a zero-shot fashion.\nOur implementation and demos are available at https://audioldm.github.io.", "published": "2023-01-29 17:48:17", "link": "http://arxiv.org/abs/2301.12503v3", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
