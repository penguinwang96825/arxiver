{"title": "Reducing Gender Bias in Word-Level Language Models with a\n  Gender-Equalizing Loss Function", "abstract": "Gender bias exists in natural language datasets which neural language models\ntend to learn, resulting in biased text generation. In this research, we\npropose a debiasing approach based on the loss function modification. We\nintroduce a new term to the loss function which attempts to equalize the\nprobabilities of male and female words in the output. Using an array of bias\nevaluation metrics, we provide empirical evidence that our approach\nsuccessfully mitigates gender bias in language models without increasing\nperplexity. In comparison to existing debiasing strategies, data augmentation,\nand word embedding debiasing, our method performs better in several aspects,\nespecially in reducing gender bias in occupation words. Finally, we introduce a\ncombination of data augmentation and our approach, and show that it outperforms\nexisting strategies in all bias evaluation metrics.", "published": "2019-05-30 00:43:02", "link": "http://arxiv.org/abs/1905.12801v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple but Effective Method to Incorporate Multi-turn Context with\n  BERT for Conversational Machine Comprehension", "abstract": "Conversational machine comprehension (CMC) requires understanding the context\nof multi-turn dialogue. Using BERT, a pre-training language model, has been\nsuccessful for single-turn machine comprehension, while modeling multiple turns\nof question answering with BERT has not been established because BERT has a\nlimit on the number and the length of input sequences. In this paper, we\npropose a simple but effective method with BERT for CMC. Our method uses BERT\nto encode a paragraph independently conditioned with each question and each\nanswer in a multi-turn context. Then, the method predicts an answer on the\nbasis of the paragraph representations encoded with BERT. The experiments with\nrepresentative CMC datasets, QuAC and CoQA, show that our method outperformed\nrecently published methods (+0.8 F1 on QuAC and +2.1 F1 on CoQA). In addition,\nwe conducted a detailed analysis of the effects of the number and types of\ndialogue history on the accuracy of CMC, and we found that the gold answer\nhistory, which may not be given in an actual conversation, contributed to the\nmodel performance most on both datasets.", "published": "2019-05-30 04:28:19", "link": "http://arxiv.org/abs/1905.12848v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controllable Unsupervised Text Attribute Transfer via Editing Entangled\n  Latent Representation", "abstract": "Unsupervised text attribute transfer automatically transforms a text to alter\na specific attribute (e.g. sentiment) without using any parallel data, while\nsimultaneously preserving its attribute-independent content. The dominant\napproaches are trying to model the content-independent attribute separately,\ne.g., learning different attributes' representations or using multiple\nattribute-specific decoders. However, it may lead to inflexibility from the\nperspective of controlling the degree of transfer or transferring over multiple\naspects at the same time. To address the above problems, we propose a more\nflexible unsupervised text attribute transfer framework which replaces the\nprocess of modeling attribute with minimal editing of latent representations\nbased on an attribute classifier. Specifically, we first propose a\nTransformer-based autoencoder to learn an entangled latent representation for a\ndiscrete text, then we transform the attribute transfer task to an optimization\nproblem and propose the Fast-Gradient-Iterative-Modification algorithm to edit\nthe latent representation until conforming to the target attribute. Extensive\nexperimental results demonstrate that our model achieves very competitive\nperformance on three public data sets. Furthermore, we also show that our model\ncan not only control the degree of transfer freely but also allow to transfer\nover multiple aspects at the same time.", "published": "2019-05-30 09:32:03", "link": "http://arxiv.org/abs/1905.12926v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unbabel's Submission to the WMT2019 APE Shared Task: BERT-based\n  Encoder-Decoder for Automatic Post-Editing", "abstract": "This paper describes Unbabel's submission to the WMT2019 APE Shared Task for\nthe English-German language pair. Following the recent rise of large, powerful,\npre-trained models, we adapt the BERT pretrained model to perform Automatic\nPost-Editing in an encoder-decoder framework. Analogously to dual-encoder\narchitectures we develop a BERT-based encoder-decoder (BED) model in which a\nsingle pretrained BERT encoder receives both the source src and machine\ntranslation tgt strings. Furthermore, we explore a conservativeness factor to\nconstrain the APE system to perform fewer edits. As the official results show,\nwhen trained on a weighted combination of in-domain and artificial training\ndata, our BED system with the conservativeness penalty improves significantly\nthe translations of a strong Neural Machine Translation system by $-0.78$ and\n$+1.23$ in terms of TER and BLEU, respectively. Finally, our submission\nachieves a new state-of-the-art, ex-aequo, in English-German APE of NMT.", "published": "2019-05-30 14:17:39", "link": "http://arxiv.org/abs/1905.13068v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MathQA: Towards Interpretable Math Word Problem Solving with\n  Operation-Based Formalisms", "abstract": "We introduce a large-scale dataset of math word problems and an interpretable\nneural math problem solver that learns to map problems to operation programs.\nDue to annotation challenges, current datasets in this domain have been either\nrelatively small in scale or did not offer precise operational annotations over\ndiverse problem types. We introduce a new representation language to model\nprecise operation programs corresponding to each math problem that aim to\nimprove both the performance and the interpretability of the learned models.\nUsing this representation language, our new dataset, MathQA, significantly\nenhances the AQuA dataset with fully-specified operational programs. We\nadditionally introduce a neural sequence-to-program model enhanced with\nautomatic problem categorization. Our experiments show improvements over\ncompetitive baselines in our MathQA as well as the AQuA dataset. The results\nare still significantly lower than human performance indicating that the\ndataset poses new challenges for future research. Our dataset is available at:\nhttps://math-qa.github.io/math-QA/", "published": "2019-05-30 21:28:12", "link": "http://arxiv.org/abs/1905.13319v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing The Factual Accuracy of Generated Text", "abstract": "We propose a model-based metric to estimate the factual accuracy of generated\ntext that is complementary to typical scoring schemes like ROUGE\n(Recall-Oriented Understudy for Gisting Evaluation) and BLEU (Bilingual\nEvaluation Understudy). We introduce and release a new large-scale dataset\nbased on Wikipedia and Wikidata to train relation classifiers and end-to-end\nfact extraction models. The end-to-end models are shown to be able to extract\ncomplete sets of facts from datasets with full pages of text. We then analyse\nmultiple models that estimate factual accuracy on a Wikipedia text\nsummarization task, and show their efficacy compared to ROUGE and other\nmodel-free variants by conducting a human evaluation study.", "published": "2019-05-30 21:37:45", "link": "http://arxiv.org/abs/1905.13322v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Lightweight Recurrent Network for Sequence Modeling", "abstract": "Recurrent networks have achieved great success on various sequential tasks\nwith the assistance of complex recurrent units, but suffer from severe\ncomputational inefficiency due to weak parallelization. One direction to\nalleviate this issue is to shift heavy computations outside the recurrence. In\nthis paper, we propose a lightweight recurrent network, or LRN. LRN uses input\nand forget gates to handle long-range dependencies as well as gradient\nvanishing and explosion, with all parameter related calculations factored\noutside the recurrence. The recurrence in LRN only manipulates the weight\nassigned to each token, tightly connecting LRN with self-attention networks. We\napply LRN as a drop-in replacement of existing recurrent units in several\nneural sequential models. Extensive experiments on six NLP tasks show that LRN\nyields the best running efficiency with little or no loss in model performance.", "published": "2019-05-30 21:40:46", "link": "http://arxiv.org/abs/1905.13324v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grammar-based Neural Text-to-SQL Generation", "abstract": "The sequence-to-sequence paradigm employed by neural text-to-SQL models\ntypically performs token-level decoding and does not consider generating SQL\nhierarchically from a grammar. Grammar-based decoding has shown significant\nimprovements for other semantic parsing tasks, but SQL and other general\nprogramming languages have complexities not present in logical formalisms that\nmake writing hierarchical grammars difficult. We introduce techniques to handle\nthese complexities, showing how to construct a schema-dependent grammar with\nminimal over-generation. We analyze these techniques on ATIS and Spider, two\nchallenging text-to-SQL datasets, demonstrating that they yield 14--18\\%\nrelative reductions in error.", "published": "2019-05-30 21:43:57", "link": "http://arxiv.org/abs/1905.13326v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiaBLa: A Corpus of Bilingual Spontaneous Written Dialogues for Machine\n  Translation", "abstract": "We present a new English-French test set for the evaluation of Machine\nTranslation (MT) for informal, written bilingual dialogue. The test set\ncontains 144 spontaneous dialogues (5,700+ sentences) between native English\nand French speakers, mediated by one of two neural MT systems in a range of\nrole-play settings. The dialogues are accompanied by fine-grained\nsentence-level judgments of MT quality, produced by the dialogue participants\nthemselves, as well as by manually normalised versions and reference\ntranslations produced a posteriori. The motivation for the corpus is two-fold:\nto provide (i) a unique resource for evaluating MT models, and (ii) a corpus\nfor the analysis of MT-mediated communication. We provide a preliminary\nanalysis of the corpus to confirm that the participants' judgments reveal\nperceptible differences in MT quality between the two MT systems used.", "published": "2019-05-30 23:41:35", "link": "http://arxiv.org/abs/1905.13354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantically Conditioned Dialog Response Generation via Hierarchical\n  Disentangled Self-Attention", "abstract": "Semantically controlled neural response generation on limited-domain has\nachieved great performance. However, moving towards multi-domain large-scale\nscenarios are shown to be difficult because the possible combinations of\nsemantic inputs grow exponentially with the number of domains. To alleviate\nsuch scalability issue, we exploit the structure of dialog acts to build a\nmulti-layer hierarchical graph, where each act is represented as a root-to-leaf\nroute on the graph. Then, we incorporate such graph structure prior as an\ninductive bias to build a hierarchical disentangled self-attention network,\nwhere we disentangle attention heads to model designated nodes on the dialog\nact graph. By activating different (disentangled) heads at each layer,\ncombinatorially many dialog act semantics can be modeled to control the neural\nresponse generation. On the large-scale Multi-Domain-WOZ dataset, our model can\nyield a significant improvement over the baselines on various automatic and\nhuman evaluation metrics.", "published": "2019-05-30 05:57:27", "link": "http://arxiv.org/abs/1905.12866v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "M-GWAP: An Online and Multimodal Game With A Purpose in WordPress for\n  Mental States Annotation", "abstract": "M-GWAP is a multimodal game with a purpose of that leverages on the wisdom of\ncrowds phenomenon for the annotation of multimedia data in terms of mental\nstates. This game with a purpose is developed in WordPress to allow users\nimplementing the game without programming skills. The game adopts motivational\nstrategies for the player to remain engaged, such as a score system, text\nmotivators while playing, a ranking system to foster competition and mechanics\nfor identify building. The current version of the game was deployed after alpha\nand beta testing helped refining the game accordingly.", "published": "2019-05-30 07:07:52", "link": "http://arxiv.org/abs/1905.12884v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A Compare-Aggregate Model with Latent Clustering for Answer Selection", "abstract": "In this paper, we propose a novel method for a sentence-level\nanswer-selection task that is a fundamental problem in natural language\nprocessing. First, we explore the effect of additional information by adopting\na pretrained language model to compute the vector representation of the input\ntext and by applying transfer learning from a large-scale corpus. Second, we\nenhance the compare-aggregate model by proposing a novel latent clustering\nmethod to compute additional information within the target corpus and by\nchanging the objective function from listwise to pointwise. To evaluate the\nperformance of the proposed approaches, experiments are performed with the\nWikiQA and TREC-QA datasets. The empirical results demonstrate the superiority\nof our proposed approach, which achieve state-of-the-art performance for both\ndatasets.", "published": "2019-05-30 07:44:34", "link": "http://arxiv.org/abs/1905.12897v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interactive-predictive neural multimodal systems", "abstract": "Despite the advances achieved by neural models in sequence to sequence\nlearning, exploited in a variety of tasks, they still make errors. In many use\ncases, these are corrected by a human expert in a posterior revision process.\nThe interactive-predictive framework aims to minimize the human effort spent on\nthis process by considering partial corrections for iteratively refining the\nhypothesis. In this work, we generalize the interactive-predictive approach,\ntypically applied in to machine translation field, to tackle other multimodal\nproblems namely, image and video captioning. We study the application of this\nframework to multimodal neural sequence to sequence models. We show that,\nfollowing this framework, we approximately halve the effort spent for\ncorrecting the outputs generated by the automatic systems. Moreover, we deploy\nour systems in a publicly accessible demonstration, that allows to better\nunderstand the behavior of the interactive-predictive framework.", "published": "2019-05-30 11:47:04", "link": "http://arxiv.org/abs/1905.12980v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Hierarchical Transformers for Multi-Document Summarization", "abstract": "In this paper, we develop a neural summarization model which can effectively\nprocess multiple input documents and distill Transformer architecture with the\nability to encode documents in a hierarchical manner. We represent\ncross-document relationships via an attention mechanism which allows to share\ninformation as opposed to simply concatenating text spans and processing them\nas a flat sequence. Our model learns latent dependencies among textual units,\nbut can also take advantage of explicit graph representations focusing on\nsimilarity or discourse relations. Empirical results on the WikiSum dataset\ndemonstrate that the proposed architecture brings substantial improvements over\nseveral strong baselines.", "published": "2019-05-30 16:49:11", "link": "http://arxiv.org/abs/1905.13164v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interpretable Adversarial Training for Text", "abstract": "Generating high-quality and interpretable adversarial examples in the text\ndomain is a much more daunting task than it is in the image domain. This is due\npartly to the discrete nature of text, partly to the problem of ensuring that\nthe adversarial examples are still probable and interpretable, and partly to\nthe problem of maintaining label invariance under input perturbations. In order\nto address some of these challenges, we introduce sparse projected gradient\ndescent (SPGD), a new approach to crafting interpretable adversarial examples\nfor text. SPGD imposes a directional regularization constraint on input\nperturbations by projecting them onto the directions to nearby word embeddings\nwith highest cosine similarities. This constraint ensures that perturbations\nmove each word embedding in an interpretable direction (i.e., towards another\nnearby word embedding). Moreover, SPGD imposes a sparsity constraint on\nperturbations at the sentence level by ignoring word-embedding perturbations\nwhose norms are below a certain threshold. This constraint ensures that our\nmethod changes only a few words per sequence, leading to higher quality\nadversarial examples. Our experiments with the IMDB movie review dataset show\nthat the proposed SPGD method improves adversarial example interpretability and\nlikelihood (evaluated by average per-word perplexity) compared to\nstate-of-the-art methods, while suffering little to no loss in training\nperformance.", "published": "2019-05-30 05:55:58", "link": "http://arxiv.org/abs/1905.12864v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Lattice-based lightly-supervised acoustic model training", "abstract": "In the broadcast domain there is an abundance of related text data and\npartial transcriptions, such as closed captions and subtitles. This text data\ncan be used for lightly supervised training, in which text matching the audio\nis selected using an existing speech recognition model. Current approaches to\nlight supervision typically filter the data based on matching error rates\nbetween the transcriptions and biased decoding hypotheses. In contrast,\nsemi-supervised training does not require matching text data, instead\ngenerating a hypothesis using a background language model. State-of-the-art\nsemi-supervised training uses lattice-based supervision with the lattice-free\nMMI (LF-MMI) objective function. We propose a technique to combine inaccurate\ntranscriptions with the lattices generated for semi-supervised training, thus\npreserving uncertainty in the lattice where appropriate. We demonstrate that\nthis combined approach reduces the expected error rates over the lattices, and\nreduces the word error rate (WER) on a broadcast task.", "published": "2019-05-30 16:12:26", "link": "http://arxiv.org/abs/1905.13150v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Grounding Language Attributes to Objects using Bayesian Eigenobjects", "abstract": "We develop a system to disambiguate object instances within the same class\nbased on simple physical descriptions. The system takes as input a natural\nlanguage phrase and a depth image containing a segmented object and predicts\nhow similar the observed object is to the object described by the phrase. Our\nsystem is designed to learn from only a small amount of human-labeled language\ndata and generalize to viewpoints not represented in the language-annotated\ndepth image training set. By decoupling 3D shape representation from language\nrepresentation, this method is able to ground language to novel objects using a\nsmall amount of language-annotated depth-data and a larger corpus of unlabeled\n3D object meshes, even when these objects are partially observed from unusual\nviewpoints. Our system is able to disambiguate between novel objects, observed\nvia depth images, based on natural language descriptions. Our method also\nenables view-point transfer; trained on human-annotated data on a small set of\ndepth images captured from frontal viewpoints, our system successfully\npredicted object attributes from rear views despite having no such depth images\nin its training set. Finally, we demonstrate our approach on a Baxter robot,\nenabling it to pick specific objects based on human-provided natural language\ndescriptions.", "published": "2019-05-30 16:15:36", "link": "http://arxiv.org/abs/1905.13153v2", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Threshold-Based Retrieval and Textual Entailment Detection on Legal Bar\n  Exam Questions", "abstract": "Getting an overview over the legal domain has become challenging, especially\nin a broad, international context. Legal question answering systems have the\npotential to alleviate this task by automatically retrieving relevant legal\ntexts for a specific statement and checking whether the meaning of the\nstatement can be inferred from the found documents. We investigate a\ncombination of the BM25 scoring method of Elasticsearch with word embeddings\ntrained on English translations of the German and Japanese civil law. For this,\nwe define criteria which select a dynamic number of relevant documents\naccording to threshold scores. Exploiting two deep learning classifiers and\ntheir respective prediction bias with a threshold-based answer inclusion\ncriterion has shown to be beneficial for the textual entailment task, when\ncompared to the baseline.", "published": "2019-05-30 23:17:26", "link": "http://arxiv.org/abs/1905.13350v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Speaker Anonymization Using X-vector and Neural Waveform Models", "abstract": "The social media revolution has produced a plethora of web services to which\nusers can easily upload and share multimedia documents. Despite the popularity\nand convenience of such services, the sharing of such inherently personal data,\nincluding speech data, raises obvious security and privacy concerns. In\nparticular, a user's speech data may be acquired and used with speech synthesis\nsystems to produce high-quality speech utterances which reflect the same user's\nspeaker identity. These utterances may then be used to attack speaker\nverification systems. One solution to mitigate these concerns involves the\nconcealing of speaker identities before the sharing of speech data. For this\npurpose, we present a new approach to speaker anonymization. The idea is to\nextract linguistic and speaker identity features from an utterance and then to\nuse these with neural acoustic and waveform models to synthesize anonymized\nspeech. The original speaker identity, in the form of timbre, is suppressed and\nreplaced with that of an anonymous pseudo identity. The approach exploits\nstate-of-the-art x-vector speaker representations. These are used to derive\nanonymized pseudo speaker identities through the combination of multiple,\nrandom speaker x-vectors. Experimental results show that the proposed approach\nis effective in concealing speaker identities. It increases the equal error\nrate of a speaker verification system while maintaining high quality,\nanonymized speech.", "published": "2019-05-30 01:33:31", "link": "http://arxiv.org/abs/1905.13561v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Musical Composition Style Transfer via Disentangled Timbre\n  Representations", "abstract": "Music creation involves not only composing the different parts (e.g., melody,\nchords) of a musical work but also arranging/selecting the instruments to play\nthe different parts. While the former has received increasing attention, the\nlatter has not been much investigated. This paper presents, to the best of our\nknowledge, the first deep learning models for rearranging music of arbitrary\ngenres. Specifically, we build encoders and decoders that take a piece of\npolyphonic musical audio as input and predict as output its musical score. We\ninvestigate disentanglement techniques such as adversarial training to separate\nlatent factors that are related to the musical content (pitch) of different\nparts of the piece, and that are related to the instrumentation (timbre) of the\nparts per short-time segment. By disentangling pitch and timbre, our models\nhave an idea of how each piece was composed and arranged. Moreover, the models\ncan realize \"composition style transfer\" by rearranging a musical piece without\nmuch affecting its pitch content. We validate the effectiveness of the models\nby experiments on instrument activity detection and composition style transfer.\nTo facilitate follow-up research, we open source our code at\nhttps://github.com/biboamy/instrument-disentangle.", "published": "2019-05-30 06:30:37", "link": "http://arxiv.org/abs/1905.13567v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Music Classification Model based on Metric Learning and Feature\n  Extraction from MP3 Audio Files", "abstract": "The development of models for learning music similarity and feature\nextraction from audio media files is an increasingly important task for the\nentertainment industry. This work proposes a novel music classification model\nbased on metric learning and feature extraction from MP3 audio files. The\nmetric learning process considers the learning of a set of parameterized\ndistances employing a structured prediction approach from a set of MP3 audio\nfiles containing several music genres. The main objective of this work is to\nmake possible learning a personalized metric for each customer. To extract the\nacoustic information we use the Mel-Frequency Cepstral Coefficient (MFCC) and\nmake a dimensionality reduction with the use of Principal Components Analysis.\nWe attest the model validity performing a set of experiments and comparing the\ntraining and testing results with baseline algorithms, such as K-means and Soft\nMargin Linear Support Vector Machine (SVM). Experiments show promising results\nand encourage the future development of an online version of the learning\nmodel.", "published": "2019-05-30 00:52:57", "link": "http://arxiv.org/abs/1905.12804v2", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
