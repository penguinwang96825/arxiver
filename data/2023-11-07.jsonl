{"title": "GNAT: A General Narrative Alignment Tool", "abstract": "Algorithmic sequence alignment identifies similar segments shared between\npairs of documents, and is fundamental to many NLP tasks. But it is difficult\nto recognize similarities between distant versions of narratives such as\ntranslations and retellings, particularly for summaries and abridgements which\nare much shorter than the original novels.\n  We develop a general approach to narrative alignment coupling the\nSmith-Waterman algorithm from bioinformatics with modern text similarity\nmetrics. We show that the background of alignment scores fits a Gumbel\ndistribution, enabling us to define rigorous p-values on the significance of\nany alignment. We apply and evaluate our general narrative alignment tool\n(GNAT) on four distinct problem domains differing greatly in both the relative\nand absolute length of documents, namely summary-to-book alignment, translated\nbook alignment, short story alignment, and plagiarism detection --\ndemonstrating the power and performance of our methods.", "published": "2023-11-07 00:24:14", "link": "http://arxiv.org/abs/2311.03627v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Principles from Clinical Research for NLP Model Generalization", "abstract": "The NLP community typically relies on performance of a model on a held-out\ntest set to assess generalization. Performance drops observed in datasets\noutside of official test sets are generally attributed to \"out-of-distribution\"\neffects. Here, we explore the foundations of generalizability and study the\nfactors that affect it, articulating lessons from clinical studies. In clinical\nresearch, generalizability is an act of reasoning that depends on (a) internal\nvalidity of experiments to ensure controlled measurement of cause and effect,\nand (b) external validity or transportability of the results to the wider\npopulation. We demonstrate how learning spurious correlations, such as the\ndistance between entities in relation extraction tasks, can affect a model's\ninternal validity and in turn adversely impact generalization. We, therefore,\npresent the need to ensure internal validity when building machine learning\nmodels in NLP. Our recommendations also apply to generative large language\nmodels, as they are known to be sensitive to even minor semantic preserving\nalterations. We also propose adapting the idea of matching in randomized\ncontrolled trials and observational studies to NLP evaluation to measure\ncausation.", "published": "2023-11-07 02:17:25", "link": "http://arxiv.org/abs/2311.03663v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation\n  with Weighted Prefix-to-Prefix Training", "abstract": "Simultaneous machine translation (SiMT) is a challenging task that requires\nstarting translation before the full source sentence is available.\nPrefix-to-prefix framework is often applied to SiMT, which learns to predict\ntarget tokens using only a partial source prefix. However, due to the word\norder difference between languages, misaligned prefix pairs would make SiMT\nmodels suffer from serious hallucination problems, i.e. target outputs that are\nunfaithful to source inputs. Such problems can not only produce target tokens\nthat are not supported by the source prefix, but also hinder generating the\ncorrect translation by receiving more source words. In this work, we propose a\nConfidence-Based Simultaneous Machine Translation (CBSiMT) framework, which\nuses model confidence to perceive hallucination tokens and mitigates their\nnegative impact with weighted prefix-to-prefix training. Specifically,\ntoken-level and sentence-level weights are calculated based on model confidence\nand acted on the loss function. We explicitly quantify the faithfulness of the\ngenerated target tokens using the token-level weight, and employ the\nsentence-level weight to alleviate the disturbance of sentence pairs with\nserious word order differences on the model. Experimental results on MuST-C\nEnglish-to-Chinese and WMT15 German-to-English SiMT tasks demonstrate that our\nmethod can consistently improve translation quality at most latency regimes,\nwith up to 2 BLEU scores improvement at low latency.", "published": "2023-11-07 02:44:45", "link": "http://arxiv.org/abs/2311.03672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine\n  Translation of Lecture Transcripts", "abstract": "Lecture transcript translation helps learners understand online courses,\nhowever, building a high-quality lecture machine translation system lacks\npublicly available parallel corpora. To address this, we examine a framework\nfor parallel corpus mining, which provides a quick and effective way to mine a\nparallel corpus from publicly available lectures on Coursera. To create the\nparallel corpora, we propose a dynamic programming based sentence alignment\nalgorithm which leverages the cosine similarity of machine-translated\nsentences. The sentence alignment F1 score reaches 96%, which is higher than\nusing the BERTScore, LASER, or sentBERT methods. For both English--Japanese and\nEnglish--Chinese lecture translations, we extracted parallel corpora of\napproximately 50,000 lines and created development and test sets through manual\nfiltering for benchmarking translation performance. Through machine translation\nexperiments, we show that the mined corpora enhance the quality of lecture\ntranscript translation when used in conjunction with out-of-domain parallel\ncorpora via multistage fine-tuning. Furthermore, this study also suggests\nguidelines for gathering and cleaning corpora, mining parallel sentences,\ncleaning noise in the mined data, and creating high-quality evaluation splits.\nFor the sake of reproducibility, we have released the corpora as well as the\ncode to create them. The dataset is available at\nhttps://github.com/shyyhs/CourseraParallelCorpusMining.", "published": "2023-11-07 03:50:25", "link": "http://arxiv.org/abs/2311.03696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Large Language Models Attribution", "abstract": "Open-domain generative systems have gained significant attention in the field\nof conversational AI (e.g., generative search engines). This paper presents a\ncomprehensive review of the attribution mechanisms employed by these systems,\nparticularly large language models. Though attribution or citation improve the\nfactuality and verifiability, issues like ambiguous knowledge reservoirs,\ninherent biases, and the drawbacks of excessive attribution can hinder the\neffectiveness of these systems. The aim of this survey is to provide valuable\ninsights for researchers, aiding in the refinement of attribution methodologies\nto enhance the reliability and veracity of responses generated by open-domain\ngenerative systems. We believe that this field is still in its early stages;\nhence, we maintain a repository to keep track of ongoing studies at\nhttps://github.com/HITsz-TMG/awesome-llm-attributions.", "published": "2023-11-07 05:20:09", "link": "http://arxiv.org/abs/2311.03731v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Structured Information for Explainable Multi-hop Question\n  Answering and Reasoning", "abstract": "Neural models, including large language models (LLMs), achieve superior\nperformance on multi-hop question-answering. To elicit reasoning capabilities\nfrom LLMs, recent works propose using the chain-of-thought (CoT) mechanism to\ngenerate both the reasoning chain and the answer, which enhances the model's\ncapabilities in conducting multi-hop reasoning. However, several challenges\nstill remain: such as struggling with inaccurate reasoning, hallucinations, and\nlack of interpretability. On the other hand, information extraction (IE)\nidentifies entities, relations, and events grounded to the text. The extracted\nstructured information can be easily interpreted by humans and machines\n(Grishman, 2019). In this work, we investigate constructing and leveraging\nextracted semantic structures (graphs) for multi-hop question answering,\nespecially the reasoning process. Empirical results and human evaluations show\nthat our framework: generates more faithful reasoning chains and substantially\nimproves the QA performance on two benchmark datasets. Moreover, the extracted\nstructures themselves naturally provide grounded explanations that are\npreferred by humans, as compared to the generated reasoning chains and\nsaliency-based explanations.", "published": "2023-11-07 05:32:39", "link": "http://arxiv.org/abs/2311.03734v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse\n  Finetuning", "abstract": "Unified Sequence Labeling that articulates different sequence labeling\nproblems such as Named Entity Recognition, Relation Extraction, Semantic Role\nLabeling, etc. in a generalized sequence-to-sequence format opens up the\nopportunity to make the maximum utilization of large language model knowledge\ntoward structured prediction. Unfortunately, this requires formatting them into\nspecialized augmented format unknown to the base pretrained language model\n(PLMs) necessitating finetuning to the target format. This significantly bounds\nits usefulness in data-limited settings where finetuning large models cannot\nproperly generalize to the target format. To address this challenge and\nleverage PLM knowledge effectively, we propose FISH-DIP, a sample-aware dynamic\nsparse finetuning strategy that selectively focuses on a fraction of\nparameters, informed by feedback from highly regressing examples, during the\nfine-tuning process. By leveraging the dynamism of sparsity, our approach\nmitigates the impact of well-learned samples and prioritizes underperforming\ninstances for improvement in generalization. Across five tasks of sequence\nlabeling, we demonstrate that FISH-DIP can smoothly optimize the model in low\nresource settings offering upto 40% performance improvements over full\nfine-tuning depending on target evaluation settings. Also, compared to\nin-context learning and other parameter-efficient fine-tuning approaches,\nFISH-DIP performs comparably or better, notably in extreme low-resource\nsettings.", "published": "2023-11-07 06:19:37", "link": "http://arxiv.org/abs/2311.03748v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Which is better? Exploring Prompting Strategy For LLM-based Metrics", "abstract": "This paper describes the DSBA submissions to the Prompting Large Language\nModels as Explainable Metrics shared task, where systems were submitted to two\ntracks: small and large summarization tracks. With advanced Large Language\nModels (LLMs) such as GPT-4, evaluating the quality of Natural Language\nGeneration (NLG) has become increasingly paramount. Traditional\nsimilarity-based metrics such as BLEU and ROUGE have shown to misalign with\nhuman evaluation and are ill-suited for open-ended generation tasks. To address\nthis issue, we explore the potential capability of LLM-based metrics,\nespecially leveraging open-source LLMs. In this study, wide range of prompts\nand prompting techniques are systematically analyzed with three approaches:\nprompting strategy, score aggregation, and explainability. Our research focuses\non formulating effective prompt templates, determining the granularity of NLG\nquality scores and assessing the impact of in-context examples on LLM-based\nevaluation. Furthermore, three aggregation strategies are compared to identify\nthe most reliable method for aggregating NLG quality scores. To examine\nexplainability, we devise a strategy that generates rationales for the scores\nand analyzes the characteristics of the explanation produced by the open-source\nLLMs. Extensive experiments provide insights regarding evaluation capabilities\nof open-source LLMs and suggest effective prompting strategies.", "published": "2023-11-07 06:36:39", "link": "http://arxiv.org/abs/2311.03754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for\n  Bias Evaluation in Machine Translation", "abstract": "Neural Machine Translation (NMT) models are state-of-the-art for machine\ntranslation. However, these models are known to have various social biases,\nespecially gender bias. Most of the work on evaluating gender bias in NMT has\nfocused primarily on English as the source language. For source languages\ndifferent from English, most of the studies use gender-neutral sentences to\nevaluate gender bias. However, practically, many sentences that we encounter do\nhave gender information. Therefore, it makes more sense to evaluate for bias\nusing such sentences. This allows us to determine if NMT models can identify\nthe correct gender based on the grammatical gender cues in the source sentence\nrather than relying on biased correlations with, say, occupation terms. To\ndemonstrate our point, in this work, we use Hindi as the source language and\nconstruct two sets of gender-specific sentences: OTSC-Hindi and WinoMT-Hindi\nthat we use to evaluate different Hindi-English (HI-EN) NMT systems\nautomatically for gender bias. Our work highlights the importance of\nconsidering the nature of language when designing such extrinsic bias\nevaluation datasets.", "published": "2023-11-07 07:09:59", "link": "http://arxiv.org/abs/2311.03767v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Representation Projection: Can We Transfer Factual Knowledge\n  across Languages in Multilingual Language Models?", "abstract": "Multilingual pretrained language models serve as repositories of multilingual\nfactual knowledge. Nevertheless, a substantial performance gap of factual\nknowledge probing exists between high-resource languages and low-resource\nlanguages, suggesting limited implicit factual knowledge transfer across\nlanguages in multilingual pretrained language models. This paper investigates\nthe feasibility of explicitly transferring relatively rich factual knowledge\nfrom English to non-English languages. To accomplish this, we propose two\nparameter-free $\\textbf{L}$anguage $\\textbf{R}$epresentation\n$\\textbf{P}$rojection modules (LRP2). The first module converts non-English\nrepresentations into English-like equivalents, while the second module reverts\nEnglish-like representations back into representations of the corresponding\nnon-English language. Experimental results on the mLAMA dataset demonstrate\nthat LRP2 significantly improves factual knowledge retrieval accuracy and\nfacilitates knowledge transferability across diverse non-English languages. We\nfurther investigate the working mechanism of LRP2 from the perspectives of\nrepresentation space and cross-lingual knowledge neuron.", "published": "2023-11-07 08:16:16", "link": "http://arxiv.org/abs/2311.03788v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Character-Level Bangla Text-to-IPA Transcription Using Transformer\n  Architecture with Sequence Alignment", "abstract": "The International Phonetic Alphabet (IPA) is indispensable in language\nlearning and understanding, aiding users in accurate pronunciation and\ncomprehension. Additionally, it plays a pivotal role in speech therapy,\nlinguistic research, accurate transliteration, and the development of\ntext-to-speech systems, making it an essential tool across diverse fields.\nBangla being 7th as one of the widely used languages, gives rise to the need\nfor IPA in its domain. Its IPA mapping is too diverse to be captured manually\ngiving the need for Artificial Intelligence and Machine Learning in this field.\nIn this study, we have utilized a transformer-based sequence-to-sequence model\nat the letter and symbol level to get the IPA of each Bangla word as the\nvariation of IPA in association of different words is almost null. Our\ntransformer model only consisted of 8.5 million parameters with only a single\ndecoder and encoder layer. Additionally, to handle the punctuation marks and\nthe occurrence of foreign languages in the text, we have utilized manual\nmapping as the model won't be able to learn to separate them from Bangla words\nwhile decreasing our required computational resources. Finally, maintaining the\nrelative position of the sentence component IPAs and generation of the combined\nIPA has led us to achieve the top position with a word error rate of 0.10582 in\nthe public ranking of DataVerse Challenge - ITVerse 2023\n(https://www.kaggle.com/competitions/dataverse_2023/).", "published": "2023-11-07 08:20:06", "link": "http://arxiv.org/abs/2311.03792v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Noisy Pair Corrector for Dense Retrieval", "abstract": "Most dense retrieval models contain an implicit assumption: the training\nquery-document pairs are exactly matched. Since it is expensive to annotate the\ncorpus manually, training pairs in real-world applications are usually\ncollected automatically, which inevitably introduces mismatched-pair noise. In\nthis paper, we explore an interesting and challenging problem in dense\nretrieval, how to train an effective model with mismatched-pair noise. To solve\nthis problem, we propose a novel approach called Noisy Pair Corrector (NPC),\nwhich consists of a detection module and a correction module. The detection\nmodule estimates noise pairs by calculating the perplexity between annotated\npositive and easy negative documents. The correction module utilizes an\nexponential moving average (EMA) model to provide a soft supervised signal,\naiding in mitigating the effects of noise. We conduct experiments on\ntext-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks\nStaQC and SO-DS. Experimental results show that NPC achieves excellent\nperformance in handling both synthetic and realistic noise.", "published": "2023-11-07 08:27:14", "link": "http://arxiv.org/abs/2311.03798v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversations in Galician: a Large Language Model for an\n  Underrepresented Language", "abstract": "The recent proliferation of Large Conversation Language Models has\nhighlighted the economic significance of widespread access to this type of AI\ntechnologies in the current information age. Nevertheless, prevailing models\nhave primarily been trained on corpora consisting of documents written in\npopular languages. The dearth of such cutting-edge tools for low-resource\nlanguages further exacerbates their underrepresentation in the current economic\nlandscape, thereby impacting their native speakers. This paper introduces two\nnovel resources designed to enhance Natural Language Processing (NLP) for the\nGalician language. We present a Galician adaptation of the Alpaca dataset,\ncomprising 52,000 instructions and demonstrations. This dataset proves\ninvaluable for enhancing language models by fine-tuning them to more accurately\nadhere to provided instructions. Additionally, as a demonstration of the\ndataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician,\na language not originally supported by the model, by following the Alpaca\nformat. This work contributes to the research on multilingual models tailored\nfor low-resource settings, a crucial endeavor in ensuring the inclusion of all\nlinguistic communities in the development of Large Language Models. Another\nnoteworthy aspect of this research is the exploration of how knowledge of a\nclosely related language, in this case, Portuguese, can assist in generating\ncoherent text when training resources are scarce. Both the Galician Alpaca\ndataset and Cabuxa-7B are publicly accessible on our Huggingface Hub, and we\nhave made the source code available to facilitate replication of this\nexperiment and encourage further advancements for underrepresented languages.", "published": "2023-11-07 08:52:28", "link": "http://arxiv.org/abs/2311.03812v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparse Contrastive Learning of Sentence Embeddings", "abstract": "Recently, SimCSE has shown the feasibility of contrastive learning in\ntraining sentence embeddings and illustrates its expressiveness in spanning an\naligned and uniform embedding space. However, prior studies have shown that\ndense models could contain harmful parameters that affect the model\nperformance, and it is no wonder that SimCSE can as well be invented with such\nparameters. Driven by this, parameter sparsification is applied, where\nalignment and uniformity scores are used to measure the contribution of each\nparameter to the overall quality of sentence embeddings. Drawing from a\npreliminary study, we consider parameters with minimal contributions to be\ndetrimental, as their sparsification results in improved model performance. To\ndiscuss the ubiquity of detrimental parameters and remove them, more\nexperiments on the standard semantic textual similarity (STS) tasks and\ntransfer learning tasks are conducted, and the results show that the proposed\nsparsified SimCSE (SparseCSE) has excellent performance in comparison with\nSimCSE. Furthermore, through in-depth analysis, we establish the validity and\nstability of our sparsification method, showcasing that the embedding space\ngenerated by SparseCSE exhibits improved alignment compared to that produced by\nSimCSE. Importantly, the uniformity yet remains uncompromised.", "published": "2023-11-07 10:54:45", "link": "http://arxiv.org/abs/2311.03881v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "iACOS: Advancing Implicit Sentiment Extraction with Informative and\n  Adaptive Negative Examples", "abstract": "Aspect-based sentiment analysis (ABSA) have been extensively studied, but\nlittle light has been shed on the quadruple extraction consisting of four\nfundamental elements: aspects, categories, opinions and sentiments, especially\nwith implicit aspects and opinions. In this paper, we propose a new method\niACOS for extracting Implicit Aspects with Categories and Opinions with\nSentiments. First, iACOS appends two implicit tokens at the end of a text to\ncapture the context-aware representation of all tokens including implicit\naspects and opinions. Second, iACOS develops a sequence labeling model over the\ncontext-aware token representation to co-extract explicit and implicit aspects\nand opinions. Third, iACOS devises a multi-label classifier with a specialized\nmulti-head attention for discovering aspect-opinion pairs and predicting their\ncategories and sentiments simultaneously. Fourth, iACOS leverages informative\nand adaptive negative examples to jointly train the multi-label classifier and\nthe other two classifiers on categories and sentiments by multi-task learning.\nFinally, the experimental results show that iACOS significantly outperforms\nother quadruple extraction baselines according to the F1 score on two public\nbenchmark datasets.", "published": "2023-11-07 11:19:06", "link": "http://arxiv.org/abs/2311.03896v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Korean NLP Tasks with Linguistically Informed Subword\n  Tokenization and Sub-character Decomposition", "abstract": "We introduce a morpheme-aware subword tokenization method that utilizes\nsub-character decomposition to address the challenges of applying Byte Pair\nEncoding (BPE) to Korean, a language characterized by its rich morphology and\nunique writing system. Our approach balances linguistic accuracy with\ncomputational efficiency in Pre-trained Language Models (PLMs). Our evaluations\nshow that this technique achieves good performances overall, notably improving\nresults in the syntactic task of NIKL-CoLA. This suggests that integrating\nmorpheme type information can enhance language models' syntactic and semantic\ncapabilities, indicating that adopting more linguistic insights can further\nimprove performance beyond standard morphological analysis.", "published": "2023-11-07 12:08:21", "link": "http://arxiv.org/abs/2311.03928v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Factoring Hate Speech: A New Annotation Framework to Study Hate Speech\n  in Social Media", "abstract": "In this work we propose a novel annotation scheme which factors hate speech\ninto five separate discursive categories. To evaluate our scheme, we construct\na corpus of over 2.9M Twitter posts containing hateful expressions directed at\nJews, and annotate a sample dataset of 1,050 tweets. We present a statistical\nanalysis of the annotated dataset as well as discuss annotation examples, and\nconclude by discussing promising directions for future work.", "published": "2023-11-07 13:08:55", "link": "http://arxiv.org/abs/2311.03969v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals", "abstract": "In many domains of argumentation, people's arguments are driven by so-called\nattitude roots, i.e., underlying beliefs and world views, and their\ncorresponding attitude themes. Given the strength of these latent drivers of\narguments, recent work in psychology suggests that instead of directly\ncountering surface-level reasoning (e.g., falsifying given premises), one\nshould follow an argumentation style inspired by the Jiu-Jitsu 'soft' combat\nsystem (Hornsey and Fielding, 2017): first, identify an arguer's attitude roots\nand themes, and then choose a prototypical rebuttal that is aligned with those\ndrivers instead of invalidating those. In this work, we are the first to\nexplore Jiu-Jitsu argumentation for peer review by proposing the novel task of\nattitude and theme-guided rebuttal generation. To this end, we enrich an\nexisting dataset for discourse structure in peer reviews with attitude roots,\nattitude themes, and canonical rebuttals. To facilitate this process, we recast\nestablished annotation concepts from the domain of peer reviews (e.g., aspects\na review sentence is relating to) and train domain-specific models. We then\npropose strong rebuttal generation strategies, which we benchmark on our novel\ndataset for the task of end-to-end attitude and theme-guided rebuttal\ngeneration and two subtasks.", "published": "2023-11-07 13:54:01", "link": "http://arxiv.org/abs/2311.03998v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Film Adaptation through Narrative Alignment", "abstract": "Novels are often adapted into feature films, but the differences between the\ntwo media usually require dropping sections of the source text from the movie\nscript. Here we study this screen adaptation process by constructing narrative\nalignments using the Smith-Waterman local alignment algorithm coupled with\nSBERT embedding distance to quantify text similarity between scenes and book\nunits. We use these alignments to perform an automated analysis of 40\nadaptations, revealing insights into the screenwriting process concerning (i)\nfaithfulness of adaptation, (ii) importance of dialog, (iii) preservation of\nnarrative order, and (iv) gender representation issues reflective of the\nBechdel test.", "published": "2023-11-07 14:18:03", "link": "http://arxiv.org/abs/2311.04020v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment", "abstract": "Alignment with human preference is a desired property of large language\nmodels (LLMs). Currently, the main alignment approach is based on reinforcement\nlearning from human feedback (RLHF). Despite the effectiveness of RLHF, it is\nintricate to implement and train, thus recent studies explore how to develop\nalternative alignment approaches based on supervised fine-tuning (SFT). A major\nlimitation of SFT is that it essentially does imitation learning, which cannot\nfully understand what are the expected behaviors. To address this issue, we\npropose an improved alignment approach named FIGA. Different from prior\nmethods, we incorporate fine-grained (i.e., token or phrase level) quality\nsignals that are derived by contrasting good and bad responses. Our approach\nhas made two major contributions. Firstly, we curate a refined alignment\ndataset that pairs initial responses and the corresponding revised ones.\nSecondly, we devise a new loss function can leverage fine-grained quality\nsignals to instruct the learning of LLMs for alignment. Extensive experiments\nhave demonstrated the effectiveness of our approaches by comparing a number of\ncompetitive baselines.", "published": "2023-11-07 15:36:40", "link": "http://arxiv.org/abs/2311.04072v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do LLMs exhibit human-like response biases? A case study in survey\n  design", "abstract": "As large language models (LLMs) become more capable, there is growing\nexcitement about the possibility of using LLMs as proxies for humans in\nreal-world tasks where subjective labels are desired, such as in surveys and\nopinion polling. One widely-cited barrier to the adoption of LLMs as proxies\nfor humans in subjective tasks is their sensitivity to prompt wording - but\ninterestingly, humans also display sensitivities to instruction changes in the\nform of response biases. We investigate the extent to which LLMs reflect human\nresponse biases, if at all. We look to survey design, where human response\nbiases caused by changes in the wordings of \"prompts\" have been extensively\nexplored in social psychology literature. Drawing from these works, we design a\ndataset and framework to evaluate whether LLMs exhibit human-like response\nbiases in survey questionnaires. Our comprehensive evaluation of nine models\nshows that popular open and commercial LLMs generally fail to reflect\nhuman-like behavior, particularly in models that have undergone RLHF.\nFurthermore, even if a model shows a significant change in the same direction\nas humans, we find that they are sensitive to perturbations that do not elicit\nsignificant changes in humans. These results highlight the pitfalls of using\nLLMs as human proxies, and underscore the need for finer-grained\ncharacterizations of model behavior. Our code, dataset, and collected samples\nare available at https://github.com/lindiatjuatja/BiasMonkey", "published": "2023-11-07 15:40:43", "link": "http://arxiv.org/abs/2311.04076v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personality Style Recognition via Machine Learning: Identifying\n  Anaclitic and Introjective Personality Styles from Patients' Speech", "abstract": "In disentangling the heterogeneity observed in psychopathology, personality\nof the patients is considered crucial. While it has been demonstrated that\npersonality traits are reflected in the language used by a patient, we\nhypothesize that this enables automatic inference of the personality type\ndirectly from speech utterances, potentially more accurately than through a\ntraditional questionnaire-based approach explicitly designed for personality\nclassification. To validate this hypothesis, we adopt natural language\nprocessing (NLP) and standard machine learning tools for classification. We\ntest this on a dataset of recorded clinical diagnostic interviews (CDI) on a\nsample of 79 patients diagnosed with major depressive disorder (MDD) -- a\ncondition for which differentiated treatment based on personality styles has\nbeen advocated -- and classified into anaclitic and introjective personality\nstyles. We start by analyzing the interviews to see which linguistic features\nare associated with each style, in order to gain a better understanding of the\nstyles. Then, we develop automatic classifiers based on (a) standardized\nquestionnaire responses; (b) basic text features, i.e., TF-IDF scores of words\nand word sequences; (c) more advanced text features, using LIWC (linguistic\ninquiry and word count) and context-aware features using BERT (bidirectional\nencoder representations from transformers); (d) audio features. We find that\nautomated classification with language-derived features (i.e., based on LIWC)\nsignificantly outperforms questionnaire-based classification models.\nFurthermore, the best performance is achieved by combining LIWC with the\nquestionnaire features. This suggests that more work should be put into\ndeveloping linguistically based automated techniques for characterizing\npersonality, however questionnaires still to some extent complement such\nmethods.", "published": "2023-11-07 15:56:19", "link": "http://arxiv.org/abs/2311.04088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modelling Sentiment Analysis: LLMs and data augmentation techniques", "abstract": "This paper provides different approaches for a binary sentiment\nclassification on a small training dataset. LLMs that provided state-of-the-art\nresults in sentiment analysis and similar domains are being used, such as BERT,\nRoBERTa and XLNet.", "published": "2023-11-07 17:12:39", "link": "http://arxiv.org/abs/2311.04139v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What is Lost in Knowledge Distillation?", "abstract": "Deep neural networks (DNNs) have improved NLP tasks significantly, but\ntraining and maintaining such networks could be costly. Model compression\ntechniques, such as, knowledge distillation (KD), have been proposed to address\nthe issue; however, the compression process could be lossy. Motivated by this,\nour work investigates how a distilled student model differs from its teacher,\nif the distillation process causes any information losses, and if the loss\nfollows a specific pattern. Our experiments aim to shed light on the type of\ntasks might be less or more sensitive to KD by reporting data points on the\ncontribution of different factors, such as the number of layers or attention\nheads. Results such as ours could be utilized when determining effective and\nefficient configurations to achieve optimal information transfers between\nlarger (teacher) and smaller (student) models.", "published": "2023-11-07 17:13:40", "link": "http://arxiv.org/abs/2311.04142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Black-Box Prompt Optimization: Aligning Large Language Models without\n  Model Training", "abstract": "Large language models (LLMs) have shown impressive success in various\napplications. However, these models are often not well aligned with human\nintents, which calls for additional treatments on them; that is, the alignment\nproblem. To make LLMs better follow user instructions, existing alignment\nmethods primarily focus on further training them. However, the extra training\nof LLMs is usually expensive in terms of GPU computing; even worse, some LLMs\nare not accessible for user-demanded training, such as GPTs. In this work, we\ntake a different perspective -- Black-Box Prompt Optimization (BPO) -- to\nperform alignments. The idea is to optimize user prompts to suit LLMs' input\nunderstanding, so as to best realize users' intents without updating LLMs'\nparameters. BPO leverages human preferences to optimize prompts, thus making it\nsuperior to LLM (e.g., ChatGPT) as a prompt engineer. Moreover, BPO is\nmodel-agnostic, and the empirical results demonstrate that the BPO-aligned\nChatGPT yields a 22% increase in the win rate against its original version and\n10% for GPT-4. Notably, the BPO-aligned LLMs can outperform the same models\naligned by PPO and DPO, and it also brings additional performance gains when\ncombining BPO with PPO or DPO. Code and datasets are released at\nhttps://github.com/thu-coai/BPO.", "published": "2023-11-07 17:31:50", "link": "http://arxiv.org/abs/2311.04155v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions\n  for Collocations in Spanish", "abstract": "In natural language processing (NLP), lexical function is a concept to\nunambiguously represent semantic and syntactic features of words and phrases in\ntext first crafted in the Meaning-Text Theory. Hierarchical classification of\nlexical functions involves organizing these features into a tree-like hierarchy\nof categories or labels. This is a challenging task as it requires a good\nunderstanding of the context and the relationships among words and phrases in\ntext. It also needs large amounts of labeled data to train language models\neffectively. In this paper, we present a dataset of most frequent Spanish\nverb-noun collocations and sentences where they occur, each collocation is\nassigned to one of 37 lexical functions defined as classes for a hierarchical\nclassification task. Each class represents a relation between the noun and the\nverb in a collocation involving their semantic and syntactic features. We\ncombine the classes in a tree-based structure, and introduce classification\nobjectives for each level of the structure. The dataset was created by\ndependency tree parsing and matching of the phrases in Spanish news. We provide\nbaselines and data splits for each objective.", "published": "2023-11-07 18:32:34", "link": "http://arxiv.org/abs/2311.04189v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aspect-based Meeting Transcript Summarization: A Two-Stage Approach with\n  Weak Supervision on Sentence Classification", "abstract": "Aspect-based meeting transcript summarization aims to produce multiple\nsummaries, each focusing on one aspect of content in a meeting transcript. It\nis challenging as sentences related to different aspects can mingle together,\nand those relevant to a specific aspect can be scattered throughout the long\ntranscript of a meeting. The traditional summarization methods produce one\nsummary mixing information of all aspects, which cannot deal with the above\nchallenges of aspect-based meeting transcript summarization. In this paper, we\npropose a two-stage method for aspect-based meeting transcript summarization.\nTo select the input content related to specific aspects, we train a sentence\nclassifier on a dataset constructed from the AMI corpus with pseudo-labeling.\nThen we merge the sentences selected for a specific aspect as the input for the\nsummarizer to produce the aspect-based summary. Experimental results on the AMI\ncorpus outperform many strong baselines, which verifies the effectiveness of\nour proposed method.", "published": "2023-11-07 19:06:31", "link": "http://arxiv.org/abs/2311.04292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Formal Aspects of Language Modeling", "abstract": "Large language models have become one of the most commonly deployed NLP\ninventions. In the past half-decade, their integration into core natural\nlanguage processing tools has dramatically increased the performance of such\ntools, and they have entered the public discourse surrounding artificial\nintelligence. Consequently, it is important for both developers and researchers\nalike to understand the mathematical foundations of large language models, as\nwell as how to implement them. These notes are the accompaniment to the\ntheoretical portion of the ETH Z\\\"urich course on large language models,\ncovering what constitutes a language model from a formal, theoretical\nperspective.", "published": "2023-11-07 20:21:42", "link": "http://arxiv.org/abs/2311.04329v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncovering Intermediate Variables in Transformers using Circuit Probing", "abstract": "Neural network models have achieved high performance on a wide variety of\ncomplex tasks, but the algorithms that they implement are notoriously difficult\nto interpret. It is often necessary to hypothesize intermediate variables\ninvolved in a network's computation in order to understand these algorithms.\nFor example, does a language model depend on particular syntactic properties\nwhen generating a sentence? Yet, existing analysis tools make it difficult to\ntest hypotheses of this type. We propose a new analysis technique - circuit\nprobing - that automatically uncovers low-level circuits that compute\nhypothesized intermediate variables. This enables causal analysis through\ntargeted ablation at the level of model parameters. We apply this method to\nmodels trained on simple arithmetic tasks, demonstrating its effectiveness at\n(1) deciphering the algorithms that models have learned, (2) revealing modular\nstructure within a model, and (3) tracking the development of circuits over\ntraining. Across these three experiments we demonstrate that circuit probing\ncombines and extends the capabilities of existing methods, providing one\nunified approach for a variety of analyses. Finally, we demonstrate circuit\nprobing on a real-world use case: uncovering circuits that are responsible for\nsubject-verb agreement and reflexive anaphora in GPT2-Small and Medium.", "published": "2023-11-07 21:27:17", "link": "http://arxiv.org/abs/2311.04354v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating multiple large language models in pediatric ophthalmology", "abstract": "IMPORTANCE The response effectiveness of different large language models\n(LLMs) and various individuals, including medical students, graduate students,\nand practicing physicians, in pediatric ophthalmology consultations, has not\nbeen clearly established yet. OBJECTIVE Design a 100-question exam based on\npediatric ophthalmology to evaluate the performance of LLMs in highly\nspecialized scenarios and compare them with the performance of medical students\nand physicians at different levels. DESIGN, SETTING, AND PARTICIPANTS This\nsurvey study assessed three LLMs, namely ChatGPT (GPT-3.5), GPT-4, and PaLM2,\nwere assessed alongside three human cohorts: medical students, postgraduate\nstudents, and attending physicians, in their ability to answer questions\nrelated to pediatric ophthalmology. It was conducted by administering\nquestionnaires in the form of test papers through the LLM network interface,\nwith the valuable participation of volunteers. MAIN OUTCOMES AND MEASURES Mean\nscores of LLM and humans on 100 multiple-choice questions, as well as the\nanswer stability, correlation, and response confidence of each LLM. RESULTS\nGPT-4 performed comparably to attending physicians, while ChatGPT (GPT-3.5) and\nPaLM2 outperformed medical students but slightly trailed behind postgraduate\nstudents. Furthermore, GPT-4 exhibited greater stability and confidence when\nresponding to inquiries compared to ChatGPT (GPT-3.5) and PaLM2. CONCLUSIONS\nAND RELEVANCE Our results underscore the potential for LLMs to provide medical\nassistance in pediatric ophthalmology and suggest significant capacity to guide\nthe education of medical students.", "published": "2023-11-07 22:23:51", "link": "http://arxiv.org/abs/2311.04368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Innovation and Word Usage Patterns in Machine Learning", "abstract": "In this study, we delve into the dynamic landscape of machine learning\nresearch evolution. Initially, through the utilization of Latent Dirichlet\nAllocation, we discern pivotal themes and fundamental concepts that have\nemerged within the realm of machine learning. Subsequently, we undertake a\ncomprehensive analysis to track the evolutionary trajectories of these\nidentified themes. To quantify the novelty and divergence of research\ncontributions, we employ the Kullback-Leibler Divergence metric. This\nstatistical measure serves as a proxy for ``surprise'', indicating the extent\nof differentiation between the content of academic papers and the subsequent\ndevelopments in research. By amalgamating these insights, we gain the ability\nto ascertain the pivotal roles played by prominent researchers and the\nsignificance of specific academic venues (periodicals and conferences) within\nthe machine learning domain.", "published": "2023-11-07 00:41:15", "link": "http://arxiv.org/abs/2311.03633v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning to Learn for Few-shot Continual Active Learning", "abstract": "Continual learning strives to ensure stability in solving previously seen\ntasks while demonstrating plasticity in a novel domain. Recent advances in\ncontinual learning are mostly confined to a supervised learning setting,\nespecially in NLP domain. In this work, we consider a few-shot continual active\nlearning setting where labeled data are inadequate, and unlabeled data are\nabundant but with a limited annotation budget. We exploit meta-learning and\npropose a method, called Meta-Continual Active Learning. This method\nsequentially queries the most informative examples from a pool of unlabeled\ndata for annotation to enhance task-specific performance and tackle continual\nlearning problems through meta-objective. Specifically, we employ meta-learning\nand experience replay to address inter-task confusion and catastrophic\nforgetting. We further incorporate textual augmentations to avoid memory\nover-fitting caused by experience replay and sample queries, thereby ensuring\ngeneralization. We conduct extensive experiments on benchmark text\nclassification datasets from diverse domains to validate the feasibility and\neffectiveness of meta-continual active learning. We also analyze the impact of\ndifferent active learning strategies on various meta continual learning models.\nThe experimental results demonstrate that introducing randomness into sample\nselection is the best default strategy for maintaining generalization in\nmeta-continual learning framework.", "published": "2023-11-07 05:22:11", "link": "http://arxiv.org/abs/2311.03732v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Multilingual Mathematical Autoformalization", "abstract": "Autoformalization is the task of translating natural language materials into\nmachine-verifiable formalisations. Progress in autoformalization research is\nhindered by the lack of a sizeable dataset consisting of informal-formal pairs\nexpressing the same essence. Existing methods tend to circumvent this challenge\nby manually curating small corpora or using few-shot learning with large\nlanguage models. But these methods suffer from data scarcity and formal\nlanguage acquisition difficulty. In this work, we create $\\texttt{MMA}$, a\nlarge, flexible, multilingual, and multi-domain dataset of informal-formal\npairs, by using a language model to translate in the reverse direction, that\nis, from formal mathematical statements into corresponding informal ones.\nExperiments show that language models fine-tuned on $\\texttt{MMA}$ produce\n$16-18\\%$ of statements acceptable with minimal corrections on the\n$\\texttt{miniF2F}$ and $\\texttt{ProofNet}$ benchmarks, up from $0\\%$ with the\nbase model. We demonstrate that fine-tuning on multilingual formal data results\nin more capable autoformalization models even when deployed on monolingual\ntasks.", "published": "2023-11-07 06:42:15", "link": "http://arxiv.org/abs/2311.03755v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OLaLa: Ontology Matching with Large Language Models", "abstract": "Ontology (and more generally: Knowledge Graph) Matching is a challenging task\nwhere information in natural language is one of the most important signals to\nprocess. With the rise of Large Language Models, it is possible to incorporate\nthis knowledge in a better way into the matching pipeline. A number of\ndecisions still need to be taken, e.g., how to generate a prompt that is useful\nto the model, how information in the KG can be formulated in prompts, which\nLarge Language Model to choose, how to provide existing correspondences to the\nmodel, how to generate candidates, etc. In this paper, we present a prototype\nthat explores these questions by applying zero-shot and few-shot prompting with\nmultiple open Large Language Models to different tasks of the Ontology\nAlignment Evaluation Initiative (OAEI). We show that with only a handful of\nexamples and a well-designed prompt, it is possible to achieve results that are\nen par with supervised matching systems which use a much larger portion of the\nground truth.", "published": "2023-11-07 09:34:20", "link": "http://arxiv.org/abs/2311.03837v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "An Expectation-Realization Model for Metaphor Detection", "abstract": "We propose a metaphor detection architecture that is structured around two\nmain modules: an expectation component that estimates representations of\nliteral word expectations given a context, and a realization component that\ncomputes representations of actual word meanings in context. The overall\narchitecture is trained to learn expectation-realization (ER) patterns that\ncharacterize metaphorical uses of words. When evaluated on three metaphor\ndatasets for within distribution, out of distribution, and novel metaphor\ngeneralization, the proposed method is shown to obtain results that are\ncompetitive or better than state-of-the art. Further increases in metaphor\ndetection accuracy are obtained through ensembling of ER models.", "published": "2023-11-07 13:03:54", "link": "http://arxiv.org/abs/2311.03963v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PrivLM-Bench: A Multi-level Privacy Evaluation Benchmark for Language\n  Models", "abstract": "The rapid development of language models (LMs) brings unprecedented\naccessibility and usage for both models and users. On the one hand, powerful\nLMs achieve state-of-the-art performance over numerous downstream NLP tasks. On\nthe other hand, more and more attention is paid to unrestricted model accesses\nthat may bring malicious privacy risks of data leakage. To address these\nissues, many recent works propose privacy-preserving language models (PPLMs)\nwith differential privacy (DP). Unfortunately, different DP implementations\nmake it challenging for a fair comparison among existing PPLMs. In this paper,\nwe present PrivLM-Bench, a multi-perspective privacy evaluation benchmark to\nempirically and intuitively quantify the privacy leakage of LMs. Instead of\nonly reporting DP parameters, PrivLM-Bench sheds light on the neglected\ninference data privacy during actual usage. PrivLM-Bench first clearly defines\nmulti-faceted privacy objectives. Then, PrivLM-Bench constructs a unified\npipeline to perform private fine-tuning. Lastly, PrivLM-Bench performs existing\nprivacy attacks on LMs with pre-defined privacy objectives as the empirical\nevaluation results. The empirical attack results are used to fairly and\nintuitively evaluate the privacy leakage of various PPLMs. We conduct extensive\nexperiments on three datasets of GLUE for mainstream LMs.", "published": "2023-11-07 14:55:52", "link": "http://arxiv.org/abs/2311.04044v3", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning Fine-tuning of Language Models is Biased Towards\n  More Extractable Features", "abstract": "Many capable large language models (LLMs) are developed via self-supervised\npre-training followed by a reinforcement-learning fine-tuning phase, often\nbased on human or AI feedback. During this stage, models may be guided by their\ninductive biases to rely on simpler features which may be easier to extract, at\na cost to robustness and generalisation. We investigate whether principles\ngoverning inductive biases in the supervised fine-tuning of LLMs also apply\nwhen the fine-tuning process uses reinforcement learning. Following Lovering et\nal (2021), we test two hypotheses: that features more $\\textit{extractable}$\nafter pre-training are more likely to be utilised by the final policy, and that\nthe evidence for/against a feature predicts whether it will be utilised.\nThrough controlled experiments on synthetic and natural language tasks, we find\nstatistically significant correlations which constitute strong evidence for\nthese hypotheses.", "published": "2023-11-07 15:00:39", "link": "http://arxiv.org/abs/2311.04046v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "KPI Extraction from Maintenance Work Orders -- A Comparison of Expert\n  Labeling, Text Classification and AI-Assisted Tagging for Computing Failure\n  Rates of Wind Turbines", "abstract": "Maintenance work orders are commonly used to document information about wind\nturbine operation and maintenance. This includes details about proactive and\nreactive wind turbine downtimes, such as preventative and corrective\nmaintenance. However, the information contained in maintenance work orders is\noften unstructured and difficult to analyze, presenting challenges for\ndecision-makers wishing to use it for optimizing operation and maintenance. To\naddress this issue, this work compares three different approaches to calculate\nreliability by performance indicators from maintenance work orders. The first\napproach involves manual labeling of the maintenance work orders by domain\nexperts, using the schema defined in an industrial guideline to assign the\nlabel accordingly. The second approach involves the development of a model that\nautomatically labels the maintenance work orders using text classification\nmethods. Through this method, we are able to achieve macro average and weighted\naverage F1-Scores of 0.75 and 0.85 respectively. The third technique uses an\nAI-assisted tagging tool to tag and structure the raw maintenance information,\ntogether with a novel rule-based approach for extracting relevant maintenance\nwork orders for failure rate calculation. In our experiments the AI-assisted\ntool leads to a 88% drop in tagging time in comparison to the other two\napproaches, while expert labeling and text classification are more accurate in\nKPI extraction. Overall, our findings make extracting maintenance information\nfrom maintenance work orders more efficient, enable the assessment of\nreliability key performance indicators and therefore support the optimization\nof wind turbine operation and maintenance.", "published": "2023-11-07 15:25:52", "link": "http://arxiv.org/abs/2311.04064v2", "categories": ["cs.CL", "cs.LG", "I.2.7; I.7"], "primary_category": "cs.CL"}
{"title": "Perturbed examples reveal invariances shared by language models", "abstract": "The rapid growth in natural language processing (NLP) research has led to\nnumerous new models, outpacing our understanding of how they compare to\nestablished ones. One major reason for this difficulty is saturating\nbenchmarks, which may not well reflect differences in model performance in the\nwild. In this work, we introduce a novel framework to compare two NLP models by\nrevealing their shared invariance to interpretable input perturbations\ntargeting a specific linguistic capability. Via experiments on models from the\nsame and different architecture families, this framework offers insights about\nhow changes in models (e.g., distillation, size increase) affect linguistic\ncapabilities. Furthermore, our framework enables evaluation of invariances\nbetween commercial black-box models (e.g., InstructGPT family) and models that\nare better understood (e.g., GPT-2). Across experiments, we observe that large\nlanguage models share many invariances encoded by models of various sizes,\nwhereas the invariances by large models are only shared by other large models.\nPossessing a wide variety of invariances may be key to the recent successes of\nlarge language models, and our framework can shed light on the types of\ninvariances retained or emerging in new models. We make the code publicly\navailable.", "published": "2023-11-07 17:48:35", "link": "http://arxiv.org/abs/2311.04166v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for\n  Retrieval Augmented Generation", "abstract": "Large Language Models (LLMs) are smart but forgetful. Recent studies, (e.g.,\n(Bubeck et al., 2023)) on modern LLMs have shown that they are capable of\nperforming amazing tasks typically necessitating human-level intelligence.\nHowever, unlike humans, frozen LLMs do not improve over time; they neither\nacquire new knowledge nor learn from their successes or failures. Some\napproaches to improving the intelligence of LLMs include fine-tuning models\nbased on problem-solving performance (Zelikman et al., 2022), and building\nbigger and more sophisticated models (Bubeck et al., 2023). However, these\nmethods have the drawback of requiring substantial data and computational\nresources to retrain existing models. In this paper, we explore the use of\nRetrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to\nimprove problem-solving performance. We propose ARM-RAG (Auxiliary Rationale\nMemory for Retrieval Augmented Generation), a system that learns from its\nsuccesses without incurring high training costs. We demonstrate that the\nstorage and subsequent retrieval of reasoning chains have a positive influence\non performance in grade-school math problems.", "published": "2023-11-07 18:03:23", "link": "http://arxiv.org/abs/2311.04177v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures\n  for Image Captioning Models", "abstract": "Image captioning studies heavily rely on automatic evaluation metrics such as\nBLEU and METEOR. However, such n-gram-based metrics have been shown to\ncorrelate poorly with human evaluation, leading to the proposal of alternative\nmetrics such as SPICE for English; however, no equivalent metrics have been\nestablished for other languages. Therefore, in this study, we propose an\nautomatic evaluation metric called JaSPICE, which evaluates Japanese captions\nbased on scene graphs. The proposed method generates a scene graph from\ndependencies and the predicate-argument structure, and extends the graph using\nsynonyms. We conducted experiments employing 10 image captioning models trained\non STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which\ncontains 103,170 human evaluations. The results showed that our metric\noutperformed the baseline metrics for the correlation coefficient with the\nhuman evaluation.", "published": "2023-11-07 18:33:34", "link": "http://arxiv.org/abs/2311.04192v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "JPAVE: A Generation and Classification-based Model for Joint Product\n  Attribute Prediction and Value Extraction", "abstract": "Product attribute value extraction is an important task in e-Commerce which\ncan help several downstream applications such as product search and\nrecommendation. Most previous models handle this task using sequence labeling\nor question answering method which rely on the sequential position information\nof values in the product text and are vulnerable to data discrepancy between\ntraining and testing. This limits their generalization ability to real-world\nscenario in which each product can have multiple descriptions across various\nshopping platforms with different composition of text and style. They also have\nlimited zero-shot ability to new values. In this paper, we propose a multi-task\nlearning model with value generation/classification and attribute prediction\ncalled JPAVE to predict values without the necessity of position information of\nvalues in the text. Furthermore, the copy mechanism in value generator and the\nvalue attention module in value classifier help our model address the data\ndiscrepancy issue by only focusing on the relevant part of input text and\nignoring other information which causes the discrepancy issue such as sentence\nstructure in the text. Besides, two variants of our model are designed for\nopen-world and closed-world scenarios. In addition, copy mechanism introduced\nin the first variant based on value generation can improve its zero-shot\nability for identifying unseen values. Experimental results on a public dataset\ndemonstrate the superiority of our model compared with strong baselines and its\ngeneralization ability of predicting new values.", "published": "2023-11-07 18:36:16", "link": "http://arxiv.org/abs/2311.04196v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary\n  Case Study", "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive performance\nacross various vision and language tasks, yet their potential applications in\nrecommendation tasks with visual assistance remain unexplored. To bridge this\ngap, we present a preliminary case study investigating the recommendation\ncapabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a\nseries of qualitative test samples spanning multiple domains and employ these\nsamples to assess the quality of GPT-4V's responses within recommendation\nscenarios. Evaluation results on these test samples prove that GPT-4V has\nremarkable zero-shot recommendation abilities across diverse domains, thanks to\nits robust visual-text comprehension capabilities and extensive general\nknowledge. However, we have also identified some limitations in using GPT-4V\nfor recommendations, including a tendency to provide similar responses when\ngiven similar inputs. This report concludes with an in-depth discussion of the\nchallenges and research opportunities associated with utilizing GPT-4V in\nrecommendation scenarios. Our objective is to explore the potential of\nextending LMMs from vision and language tasks to recommendation tasks. We hope\nto inspire further research into next-generation multimodal generative\nrecommendation models, which can enhance user experiences by offering greater\ndiversity and interactivity. All images and prompts used in this report will be\naccessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.", "published": "2023-11-07 18:39:10", "link": "http://arxiv.org/abs/2311.04199v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with\n  Modality Collaboration", "abstract": "Multi-modal Large Language Models (MLLMs) have demonstrated impressive\ninstruction abilities across various open-ended tasks. However, previous\nmethods primarily focus on enhancing multi-modal capabilities. In this work, we\nintroduce a versatile multi-modal large language model, mPLUG-Owl2, which\neffectively leverages modality collaboration to improve performance in both\ntext and multi-modal tasks. mPLUG-Owl2 utilizes a modularized network design,\nwith the language decoder acting as a universal interface for managing\ndifferent modalities. Specifically, mPLUG-Owl2 incorporates shared functional\nmodules to facilitate modality collaboration and introduces a modality-adaptive\nmodule that preserves modality-specific features. Extensive experiments reveal\nthat mPLUG-Owl2 is capable of generalizing both text tasks and multi-modal\ntasks and achieving state-of-the-art performances with a single generic model.\nNotably, mPLUG-Owl2 is the first MLLM model that demonstrates the modality\ncollaboration phenomenon in both pure-text and multi-modal scenarios, setting a\npioneering path in the development of future multi-modal foundation models.", "published": "2023-11-07 14:21:29", "link": "http://arxiv.org/abs/2311.04257v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "CRAB: Assessing the Strength of Causal Relationships Between Real-world\n  Events", "abstract": "Understanding narratives requires reasoning about the cause-and-effect\nrelationships between events mentioned in the text. While existing foundation\nmodels yield impressive results in many NLP tasks requiring reasoning, it is\nunclear whether they understand the complexity of the underlying network of\ncausal relationships of events in narratives. In this work, we present CRAB, a\nnew Causal Reasoning Assessment Benchmark designed to evaluate causal\nunderstanding of events in real-world narratives. CRAB contains fine-grained,\ncontextual causality annotations for ~2.7K pairs of real-world events that\ndescribe various newsworthy event timelines (e.g., the acquisition of Twitter\nby Elon Musk). Using CRAB, we measure the performance of several large language\nmodels, demonstrating that most systems achieve poor performance on the task.\nMotivated by classical causal principles, we also analyze the causal structures\nof groups of events in CRAB, and find that models perform worse on causal\nreasoning when events are derived from complex causal structures compared to\nsimple linear causal chains. We make our dataset and code available to the\nresearch community.", "published": "2023-11-07 19:00:44", "link": "http://arxiv.org/abs/2311.04284v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic\n  Representations", "abstract": "We introduce sub-sentence encoder, a contrastively-learned contextual\nembedding model for fine-grained semantic representation of text. In contrast\nto the standard practice with sentence embeddings, where the meaning of an\nentire sequence of text is encoded into a fixed-length vector, the sub-sentence\nencoder learns to produce distinct contextual embeddings corresponding to\ndifferent atomic propositions, i.e. atomic units of meaning expressed within a\ntext sequence. The sub-sentence embeddings are contrastively learned to\nrecognize (inferred) semantic equivalence between propositions across different\ntext sequences. Our experiments show the effectiveness of sub-sentence encoders\nin applications, such as retrieving supporting facts for fine-grained text\nattribution or recognizing the conditional semantic similarity between texts.\nIn practice, we demonstrate that sub-sentence encoders keep the same level of\ninference cost and space complexity compared to sentence encoders.", "published": "2023-11-07 20:38:30", "link": "http://arxiv.org/abs/2311.04335v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Taxonomy of Rater Disagreements: Surveying Challenges & Opportunities\n  from the Perspective of Annotating Online Toxicity", "abstract": "Toxicity is an increasingly common and severe issue in online spaces.\nConsequently, a rich line of machine learning research over the past decade has\nfocused on computationally detecting and mitigating online toxicity. These\nefforts crucially rely on human-annotated datasets that identify toxic content\nof various kinds in social media texts. However, such annotations historically\nyield low inter-rater agreement, which was often dealt with by taking the\nmajority vote or other such approaches to arrive at a single ground truth\nlabel. Recent research has pointed out the importance of accounting for the\nsubjective nature of this task when building and utilizing these datasets, and\nthis has triggered work on analyzing and better understanding rater\ndisagreements, and how they could be effectively incorporated into the machine\nlearning developmental pipeline. While these efforts are filling an important\ngap, there is a lack of a broader framework about the root causes of rater\ndisagreement, and therefore, we situate this work within that broader\nlandscape. In this survey paper, we analyze a broad set of literature on the\nreasons behind rater disagreements focusing on online toxicity, and propose a\ndetailed taxonomy for the same. Further, we summarize and discuss the potential\nsolutions targeting each reason for disagreement. We also discuss several open\nissues, which could promote the future development of online toxicity research.", "published": "2023-11-07 21:00:51", "link": "http://arxiv.org/abs/2311.04345v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating the Effectiveness of Retrieval-Augmented Large Language\n  Models in Scientific Document Reasoning", "abstract": "Despite the dramatic progress in Large Language Model (LLM) development, LLMs\noften provide seemingly plausible but not factual information, often referred\nto as hallucinations. Retrieval-augmented LLMs provide a non-parametric\napproach to solve these issues by retrieving relevant information from external\ndata sources and augment the training process. These models help to trace\nevidence from an externally provided knowledge base allowing the model\npredictions to be better interpreted and verified. In this work, we critically\nevaluate these models in their ability to perform in scientific document\nreasoning tasks. To this end, we tuned multiple such model variants with\nscience-focused instructions and evaluated them on a scientific document\nreasoning benchmark for the usefulness of the retrieved document passages. Our\nfindings suggest that models justify predictions in science tasks with\nfabricated evidence and leveraging scientific corpus as pretraining data does\nnot alleviate the risk of evidence fabrication.", "published": "2023-11-07 21:09:57", "link": "http://arxiv.org/abs/2311.04348v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Syntax-Guided Transformers: Elevating Compositional Generalization and\n  Grounding in Multimodal Environments", "abstract": "Compositional generalization, the ability of intelligent models to\nextrapolate understanding of components to novel compositions, is a fundamental\nyet challenging facet in AI research, especially within multimodal\nenvironments. In this work, we address this challenge by exploiting the\nsyntactic structure of language to boost compositional generalization. This\npaper elevates the importance of syntactic grounding, particularly through\nattention masking techniques derived from text input parsing. We introduce and\nevaluate the merits of using syntactic information in the multimodal grounding\nproblem. Our results on grounded compositional generalization underscore the\npositive impact of dependency parsing across diverse tasks when utilized with\nWeight Sharing across the Transformer encoder. The results push the\nstate-of-the-art in multimodal grounding and parameter-efficient modeling and\nprovide insights for future research.", "published": "2023-11-07 21:59:16", "link": "http://arxiv.org/abs/2311.04364v1", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models in Ophthalmology", "abstract": "Purpose: The performance of three different large language models (LLMS)\n(GPT-3.5, GPT-4, and PaLM2) in answering ophthalmology professional questions\nwas evaluated and compared with that of three different professional\npopulations (medical undergraduates, medical masters, and attending\nphysicians). Methods: A 100-item ophthalmology single-choice test was\nadministered to three different LLMs (GPT-3.5, GPT-4, and PaLM2) and three\ndifferent professional levels (medical undergraduates, medical masters, and\nattending physicians), respectively. The performance of LLM was comprehensively\nevaluated and compared with the human group in terms of average score,\nstability, and confidence. Results: Each LLM outperformed undergraduates in\ngeneral, with GPT-3.5 and PaLM2 being slightly below the master's level, while\nGPT-4 showed a level comparable to that of attending physicians. In addition,\nGPT-4 showed significantly higher answer stability and confidence than GPT-3.5\nand PaLM2. Conclusion: Our study shows that LLM represented by GPT-4 performs\nbetter in the field of ophthalmology. With further improvements, LLM will bring\nunexpected benefits in medical education and clinical decision making in the\nnear future.", "published": "2023-11-07 16:19:45", "link": "http://arxiv.org/abs/2311.04933v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompt Cache: Modular Attention Reuse for Low-Latency Inference", "abstract": "We present Prompt Cache, an approach for accelerating inference for large\nlanguage models (LLM) by reusing attention states across different LLM prompts.\nMany input prompts have overlapping text segments, such as system messages,\nprompt templates, and documents provided for context. Our key insight is that\nby precomputing and storing the attention states of these frequently occurring\ntext segments on the inference server, we can efficiently reuse them when these\nsegments appear in user prompts. Prompt Cache employs a schema to explicitly\ndefine such reusable text segments, called prompt modules. The schema ensures\npositional accuracy during attention state reuse and provides users with an\ninterface to access cached states in their prompt. Using a prototype\nimplementation, we evaluate Prompt Cache across several LLMs. We show that\nPrompt Cache significantly reduce latency in time-to-first-token, especially\nfor longer prompts such as document-based question answering and\nrecommendations. The improvements range from 8x for GPU-based inference to 60x\nfor CPU-based inference, all while maintaining output accuracy and without the\nneed for model parameter modifications.", "published": "2023-11-07 18:17:05", "link": "http://arxiv.org/abs/2311.04934v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Linear Representation Hypothesis and the Geometry of Large Language\n  Models", "abstract": "Informally, the 'linear representation hypothesis' is the idea that\nhigh-level concepts are represented linearly as directions in some\nrepresentation space. In this paper, we address two closely related questions:\nWhat does \"linear representation\" actually mean? And, how do we make sense of\ngeometric notions (e.g., cosine similarity or projection) in the representation\nspace? To answer these, we use the language of counterfactuals to give two\nformalizations of \"linear representation\", one in the output (word)\nrepresentation space, and one in the input (sentence) space. We then prove\nthese connect to linear probing and model steering, respectively. To make sense\nof geometric notions, we use the formalization to identify a particular\n(non-Euclidean) inner product that respects language structure in a sense we\nmake precise. Using this causal inner product, we show how to unify all notions\nof linear representation. In particular, this allows the construction of probes\nand steering vectors using counterfactual pairs. Experiments with LLaMA-2\ndemonstrate the existence of linear representations of concepts, the connection\nto interpretation and control, and the fundamental role of the choice of inner\nproduct.", "published": "2023-11-07 01:59:11", "link": "http://arxiv.org/abs/2311.03658v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and\n  Inference of Large Language Models", "abstract": "Large Language Models (LLMs) have seen great advance in both academia and\nindustry, and their popularity results in numerous open-source frameworks and\ntechniques in accelerating LLM pre-training, fine-tuning, and inference.\nTraining and deploying LLMs are expensive as it requires considerable computing\nresources and memory, hence many efficient approaches have been developed for\nimproving system pipelines as well as operators. However, the runtime\nperformance can vary significantly across hardware and software stacks, which\nmakes it difficult to choose the best configuration. In this work, we aim to\nbenchmark the performance from both macro and micro perspectives. First, we\nbenchmark the end-to-end performance of pre-training, fine-tuning, and serving\nLLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and\n70B) on three 8-GPU platforms with and without individual optimization\ntechniques, including ZeRO, quantization, recomputation, FlashAttention. Then,\nwe dive deeper to provide a detailed runtime analysis of the sub-modules,\nincluding computing and communication operators in LLMs. For end users, our\nbenchmark and findings help better understand different optimization\ntechniques, training and inference frameworks, together with hardware platforms\nin choosing configurations for deploying LLMs. For researchers, our in-depth\nmodule-wise analyses discover potential opportunities for future work to\nfurther optimize the runtime performance of LLMs.", "published": "2023-11-07 03:25:56", "link": "http://arxiv.org/abs/2311.03687v2", "categories": ["cs.PF", "cs.CL", "cs.LG"], "primary_category": "cs.PF"}
{"title": "LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media\n  Generators", "abstract": "Recent advancements in text-to-image generation have revolutionized numerous\nfields, including art and cinema, by automating the generation of high-quality,\ncontext-aware images and video. However, the utility of these technologies is\noften limited by the inadequacy of text prompts in guiding the generator to\nproduce artistically coherent and subject-relevant images. In this paper, We\ndescribe the techniques that can be used to make Large Language Models (LLMs)\nact as Art Directors that enhance image and video generation. We describe our\nunified system for this called \"LaDi\". We explore how LaDi integrates multiple\ntechniques for augmenting the capabilities of text-to-image generators (T2Is)\nand text-to-video generators (T2Vs), with a focus on constrained decoding,\nintelligent prompting, fine-tuning, and retrieval. LaDi and these techniques\nare being used today in apps and platforms developed by Plai Labs.", "published": "2023-11-07 04:44:40", "link": "http://arxiv.org/abs/2311.03716v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DynaSemble: Dynamic Ensembling of Textual and Structure-Based Models for\n  Knowledge Graph Completion", "abstract": "We consider two popular approaches to Knowledge Graph Completion (KGC):\ntextual models that rely on textual entity descriptions, and structure-based\nmodels that exploit the connectivity structure of the Knowledge Graph (KG).\nPreliminary experiments show that these approaches have complementary\nstrengths: structure-based models perform exceptionally well when the gold\nanswer is easily reachable from the query head in the KG, while textual models\nexploit descriptions to give good performance even when the gold answer is not\neasily reachable. In response, we propose DynaSemble, a novel method for\nlearning query-dependent ensemble weights to combine these approaches by using\nthe distributions of scores assigned by the models in the ensemble to all\ncandidate entities. DynaSemble achieves state-of-the-art results on three\nstandard KGC datasets, with up to 6.8 pt MRR and 8.3 pt Hits@1 gains over the\nbest baseline model for the WN18RR dataset.", "published": "2023-11-07 07:53:06", "link": "http://arxiv.org/abs/2311.03780v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Rethinking and Improving Multi-task Learning for End-to-end Speech\n  Translation", "abstract": "Significant improvements in end-to-end speech translation (ST) have been\nachieved through the application of multi-task learning. However, the extent to\nwhich auxiliary tasks are highly consistent with the ST task, and how much this\napproach truly helps, have not been thoroughly studied. In this paper, we\ninvestigate the consistency between different tasks, considering different\ntimes and modules. We find that the textual encoder primarily facilitates\ncross-modal conversion, but the presence of noise in speech impedes the\nconsistency between text and speech representations. Furthermore, we propose an\nimproved multi-task learning (IMTL) approach for the ST task, which bridges the\nmodal gap by mitigating the difference in length and representation. We conduct\nexperiments on the MuST-C dataset. The results demonstrate that our method\nattains state-of-the-art results. Moreover, when additional data is used, we\nachieve the new SOTA result on MuST-C English to Spanish task with 20.8% of the\ntraining time required by the current SOTA method.", "published": "2023-11-07 08:48:46", "link": "http://arxiv.org/abs/2311.03810v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Aspects of human memory and Large Language Models", "abstract": "Large Language Models (LLMs) are huge artificial neural networks which\nprimarily serve to generate text, but also provide a very sophisticated\nprobabilistic model of language use. Since generating a semantically consistent\ntext requires a form of effective memory, we investigate the memory properties\nof LLMs and find surprising similarities with key characteristics of human\nmemory. We argue that the human-like memory properties of the Large Language\nModel do not follow automatically from the LLM architecture but are rather\nlearned from the statistics of the training textual data. These results\nstrongly suggest that the biological features of human memory leave an imprint\non the way that we structure our textual narratives.", "published": "2023-11-07 09:39:12", "link": "http://arxiv.org/abs/2311.03839v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "An Analysis of Dialogue Repair in Voice Assistants", "abstract": "Spoken dialogue systems have transformed human-machine interaction by\nproviding real-time responses to queries. However, misunderstandings between\nthe user and system persist. This study explores the significance of\ninteractional language in dialogue repair between virtual assistants and users\nby analyzing interactions with Google Assistant and Siri, focusing on their\nutilization and response to the other-initiated repair strategy \"huh?\"\nprevalent in human-human interaction. Findings reveal several\nassistant-generated strategies but an inability to replicate human-like repair\nstrategies such as \"huh?\". English and Spanish user acceptability surveys show\ndifferences in users' repair strategy preferences and assistant usage, with\nboth similarities and disparities among the two surveyed languages. These\nresults shed light on inequalities between interactional language in\nhuman-human interaction and human-machine interaction, underscoring the need\nfor further research on the impact of interactional language in human-machine\ninteraction in English and beyond.", "published": "2023-11-07 12:50:11", "link": "http://arxiv.org/abs/2311.03952v2", "categories": ["cs.CL", "cs.HC", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Unveiling Safety Vulnerabilities of Large Language Models", "abstract": "As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability.", "published": "2023-11-07 16:50:33", "link": "http://arxiv.org/abs/2311.04124v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards Interpretable Sequence Continuation: Analyzing Shared Circuits\n  in Large Language Models", "abstract": "While transformer models exhibit strong capabilities on linguistic tasks,\ntheir complex architectures make them difficult to interpret. Recent work has\naimed to reverse engineer transformer models into human-readable\nrepresentations called circuits that implement algorithmic functions. We extend\nthis research by analyzing and comparing circuits for similar sequence\ncontinuation tasks, which include increasing sequences of Arabic numerals,\nnumber words, and months. By applying circuit interpretability analysis, we\nidentify a key sub-circuit in both GPT-2 Small and Llama-2-7B responsible for\ndetecting sequence members and for predicting the next member in a sequence.\nOur analysis reveals that semantically related sequences rely on shared circuit\nsubgraphs with analogous roles. Additionally, we show that this sub-circuit has\neffects on various math-related prompts, such as on intervaled circuits,\nSpanish number word and months continuation, and natural language word\nproblems. Overall, documenting shared computational structures enables better\nmodel behavior predictions, identification of errors, and safer editing\nprocedures. This mechanistic understanding of transformers is a critical step\ntowards building more robust, aligned, and interpretable language models.", "published": "2023-11-07 16:58:51", "link": "http://arxiv.org/abs/2311.04131v6", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rephrase and Respond: Let Large Language Models Ask Better Questions for\n  Themselves", "abstract": "Misunderstandings arise not only in interpersonal communication but also\nbetween humans and Large Language Models (LLMs). Such discrepancies can make\nLLMs interpret seemingly unambiguous questions in unexpected ways, yielding\nincorrect responses. While it is widely acknowledged that the quality of a\nprompt, such as a question, significantly impacts the quality of the response\nprovided by LLMs, a systematic method for crafting questions that LLMs can\nbetter comprehend is still underdeveloped. In this paper, we present a method\nnamed `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand\nquestions posed by humans and provide responses in a single prompt. This\napproach serves as a simple yet effective prompting method for improving\nperformance. We also introduce a two-step variant of RaR, where a rephrasing\nLLM first rephrases the question and then passes the original and rephrased\nquestions together to a different responding LLM. This facilitates the\neffective utilization of rephrased questions generated by one LLM with another.\nOur experiments demonstrate that our methods significantly improve the\nperformance of different models across a wide range to tasks. We further\nprovide a comprehensive comparison between RaR and the popular Chain-of-Thought\n(CoT) methods, both theoretically and empirically. We show that RaR is\ncomplementary to CoT and can be combined with CoT to achieve even better\nperformance. Our work not only contributes to enhancing LLM performance\nefficiently and effectively but also sheds light on a fair evaluation of LLM\ncapabilities. Data and codes are available at\nhttps://github.com/uclaml/Rephrase-and-Respond.", "published": "2023-11-07 18:43:34", "link": "http://arxiv.org/abs/2311.04205v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unifying Structure and Language Semantic for Efficient Contrastive\n  Knowledge Graph Completion with Structured Entity Anchors", "abstract": "The goal of knowledge graph completion (KGC) is to predict missing links in a\nKG using trained facts that are already known. In recent, pre-trained language\nmodel (PLM) based methods that utilize both textual and structural information\nare emerging, but their performances lag behind state-of-the-art (SOTA)\nstructure-based methods or some methods lose their inductive inference\ncapabilities in the process of fusing structure embedding to text encoder. In\nthis paper, we propose a novel method to effectively unify structure\ninformation and language semantics without losing the power of inductive\nreasoning. We adopt entity anchors and these anchors and textual description of\nKG elements are fed together into the PLM-based encoder to learn unified\nrepresentations. In addition, the proposed method utilizes additional random\nnegative samples which can be reused in the each mini-batch during contrastive\nlearning to learn a generalized entity representations. We verify the\neffectiveness of the our proposed method through various experiments and\nanalysis. The experimental results on standard benchmark widely used in link\nprediction task show that the proposed model outperforms existing the SOTA KGC\nmodels. Especially, our method show the largest performance improvement on\nFB15K-237, which is competitive to the SOTA of structure-based KGC methods.", "published": "2023-11-07 11:17:55", "link": "http://arxiv.org/abs/2311.04250v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Fully Automated Task Management for Generation, Execution, and\n  Evaluation: A Framework for Fetch-and-Carry Tasks with Natural Language\n  Instructions in Continuous Space", "abstract": "This paper aims to develop a framework that enables a robot to execute tasks\nbased on visual information, in response to natural language instructions for\nFetch-and-Carry with Object Grounding (FCOG) tasks. Although there have been\nmany frameworks, they usually rely on manually given instruction sentences.\nTherefore, evaluations have only been conducted with fixed tasks. Furthermore,\nmany multimodal language understanding models for the benchmarks only consider\ndiscrete actions. To address the limitations, we propose a framework for the\nfull automation of the generation, execution, and evaluation of FCOG tasks. In\naddition, we introduce an approach to solving the FCOG tasks by dividing them\ninto four distinct subtasks.", "published": "2023-11-07 15:38:09", "link": "http://arxiv.org/abs/2311.04260v1", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Watermarks in the Sand: Impossibility of Strong Watermarking for\n  Generative Models", "abstract": "Watermarking generative models consists of planting a statistical signal\n(watermark) in a model's output so that it can be later verified that the\noutput was generated by the given model. A strong watermarking scheme satisfies\nthe property that a computationally bounded attacker cannot erase the watermark\nwithout causing significant quality degradation. In this paper, we study the\n(im)possibility of strong watermarking schemes. We prove that, under\nwell-specified and natural assumptions, strong watermarking is impossible to\nachieve. This holds even in the private detection algorithm setting, where the\nwatermark insertion and detection algorithms share a secret key, unknown to the\nattacker. To prove this result, we introduce a generic efficient watermark\nattack; the attacker is not required to know the private key of the scheme or\neven which scheme is used. Our attack is based on two assumptions: (1) The\nattacker has access to a \"quality oracle\" that can evaluate whether a candidate\noutput is a high-quality response to a prompt, and (2) The attacker has access\nto a \"perturbation oracle\" which can modify an output with a nontrivial\nprobability of maintaining quality, and which induces an efficiently mixing\nrandom walk on high-quality outputs. We argue that both assumptions can be\nsatisfied in practice by an attacker with weaker computational capabilities\nthan the watermarked model itself, to which the attacker has only black-box\naccess. Furthermore, our assumptions will likely only be easier to satisfy over\ntime as models grow in capabilities and modalities. We demonstrate the\nfeasibility of our attack by instantiating it to attack three existing\nwatermarking schemes for large language models: Kirchenbauer et al. (2023),\nKuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully\nremoves the watermarks planted by all three schemes, with only minor quality\ndegradation.", "published": "2023-11-07 22:52:54", "link": "http://arxiv.org/abs/2311.04378v4", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "A comparative analysis between Conformer-Transducer, Whisper, and\n  wav2vec2 for improving the child speech recognition", "abstract": "Automatic Speech Recognition (ASR) systems have progressed significantly in\ntheir performance on adult speech data; however, transcribing child speech\nremains challenging due to the acoustic differences in the characteristics of\nchild and adult voices. This work aims to explore the potential of adapting\nstate-of-the-art Conformer-transducer models to child speech to improve child\nspeech recognition performance. Furthermore, the results are compared with\nthose of self-supervised wav2vec2 models and semi-supervised multi-domain\nWhisper models that were previously finetuned on the same data. We demonstrate\nthat finetuning Conformer-transducer models on child speech yields significant\nimprovements in ASR performance on child speech, compared to the non-finetuned\nmodels. We also show Whisper and wav2vec2 adaptation on different child speech\ndatasets. Our detailed comparative analysis shows that wav2vec2 provides the\nmost consistent performance improvements among the three methods studied.", "published": "2023-11-07 19:32:48", "link": "http://arxiv.org/abs/2311.04936v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MatNexus: A Comprehensive Text Mining and Analysis Suite for Materials\n  Discover", "abstract": "MatNexus is a specialized software for the automated collection, processing,\nand analysis of text from scientific articles. Through an integrated suite of\nmodules, the MatNexus facilitates the retrieval of scientific articles,\nprocesses textual data for insights, generates vector representations suitable\nfor machine learning, and offers visualization capabilities for word\nembeddings. With the vast volume of scientific publications, MatNexus stands\nout as an end-to-end tool for researchers aiming to gain insights from\nscientific literature in material science, making the exploration of materials,\nsuch as the electrocatalyst examples we show here, efficient and insightful.", "published": "2023-11-07 14:14:36", "link": "http://arxiv.org/abs/2311.06303v1", "categories": ["cond-mat.mtrl-sci", "cs.CL", "physics.chem-ph", "H.4; H.5; I.5; I.7; J.2"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Input Reconstruction Attack against Vertical Federated Large Language\n  Models", "abstract": "Recently, large language models (LLMs) have drawn extensive attention from\nacademia and the public, due to the advent of the ChatGPT. While LLMs show\ntheir astonishing ability in text generation for various tasks, privacy\nconcerns limit their usage in real-life businesses. More specifically, either\nthe user's inputs (the user sends the query to the model-hosting server) or the\nmodel (the user downloads the complete model) itself will be revealed during\nthe usage. Vertical federated learning (VFL) is a promising solution to this\nkind of problem. It protects both the user's input and the knowledge of the\nmodel by splitting the model into a bottom part and a top part, which is\nmaintained by the user and the model provider, respectively. However, in this\npaper, we demonstrate that in LLMs, VFL fails to protect the user input since\nit is simple and cheap to reconstruct the input from the intermediate\nembeddings. Experiments show that even with a commercial GPU, the input\nsentence can be reconstructed in only one second. We also discuss several\npossible solutions to enhance the privacy of vertical federated LLMs.", "published": "2023-11-07 09:39:22", "link": "http://arxiv.org/abs/2311.07585v2", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Benefits and Harms of Large Language Models in Digital Mental Health", "abstract": "The past decade has been transformative for mental health research and\npractice. The ability to harness large repositories of data, whether from\nelectronic health records (EHR), mobile devices, or social media, has revealed\na potential for valuable insights into patient experiences, promising early,\nproactive interventions, as well as personalized treatment plans. Recent\ndevelopments in generative artificial intelligence, particularly large language\nmodels (LLMs), show promise in leading digital mental health to uncharted\nterritory. Patients are arriving at doctors' appointments with information\nsourced from chatbots, state-of-the-art LLMs are being incorporated in medical\nsoftware and EHR systems, and chatbots from an ever-increasing number of\nstartups promise to serve as AI companions, friends, and partners. This article\npresents contemporary perspectives on the opportunities and risks posed by LLMs\nin the design, development, and implementation of digital mental health tools.\nWe adopt an ecological framework and draw on the affordances offered by LLMs to\ndiscuss four application areas -- care-seeking behaviors from individuals in\nneed of care, community care provision, institutional and medical care\nprovision, and larger care ecologies at the societal level. We engage in a\nthoughtful consideration of whether and how LLM-based technologies could or\nshould be employed for enhancing mental health. The benefits and harms our\narticle surfaces could serve to help shape future research, advocacy, and\nregulatory efforts focused on creating more responsible, user-friendly,\nequitable, and secure LLM-based tools for mental health treatment and\nintervention.", "published": "2023-11-07 14:11:10", "link": "http://arxiv.org/abs/2311.14693v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "COOL: A Constraint Object-Oriented Logic Programming Language and its\n  Neural-Symbolic Compilation System", "abstract": "This paper explores the integration of neural networks with logic\nprogramming, addressing the longstanding challenges of combining the\ngeneralization and learning capabilities of neural networks with the precision\nof symbolic logic. Traditional attempts at this integration have been hampered\nby difficulties in initial data acquisition, the reliability of undertrained\nnetworks, and the complexity of reusing and augmenting trained models. To\novercome these issues, we introduce the COOL (Constraint Object-Oriented Logic)\nprogramming language, an innovative approach that seamlessly combines logical\nreasoning with neural network technologies. COOL is engineered to autonomously\nhandle data collection, mitigating the need for user-supplied initial data. It\nincorporates user prompts into the coding process to reduce the risks of\nundertraining and enhances the interaction among models throughout their\nlifecycle to promote the reuse and augmentation of networks. Furthermore, the\nfoundational principles and algorithms in COOL's design and its compilation\nsystem could provide valuable insights for future developments in programming\nlanguages and neural network architectures.", "published": "2023-11-07 06:29:59", "link": "http://arxiv.org/abs/2311.03753v1", "categories": ["cs.AI", "cs.CL", "cs.DC", "cs.FL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Fine-tuning convergence model in Bengali speech recognition", "abstract": "Research on speech recognition has attracted considerable interest due to the\ndifficult task of segmenting uninterrupted speech. Among various languages,\nBengali features distinct rhythmic patterns and tones, making it particularly\ndifficult to recognize and lacking an efficient commercial recognition method.\nIn order to improve the automatic speech recognition model for Bengali, our\nteam has chosen to utilize the wave2vec 2.0 pre-trained model, which has\nundergone convergence for fine-tuning. Regarding Word Error Rate (WER), the\nlearning rate and dropout parameters were fine-tuned, and after the model\ntraining was stable, attempts were made to enlarge the training set ratio,\nwhich improved the model's performance. Consequently, there was a notable\nenhancement in the WER from 0.508 to 0.437 on the test set of the publicly\nlisted official dataset. Afterwards, the training and validation sets were\nmerged, creating a comprehensive dataset that was used as the training set,\nachieving a remarkable WER of 0.436.", "published": "2023-11-07 16:47:19", "link": "http://arxiv.org/abs/2311.04122v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Soundbay: Deep Learning Framework for Marine Mammals and Bioacoustic\n  Research", "abstract": "This paper presents Soundbay, an open-source Python framework that allows\nbio-acoustics and machine learning researchers to implement and utilize deep\nlearning-based algorithms for acoustic audio analysis. Soundbay provides an\neasy and intuitive platform for applying existing models on one's data or\ncreating new models effortlessly. One of the main advantages of the framework\nis the capability to compare baselines on different benchmarks, a crucial part\nof emerging research and development related to the usage of deep-learning\nalgorithms for animal call analysis. We demonstrate this by providing a\nbenchmark for cetacean call detection on multiple datasets. The framework is\npublicly accessible via https://github.com/deep-voice/soundbay", "published": "2023-11-07 20:55:26", "link": "http://arxiv.org/abs/2311.04343v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring Latent Spaces of Tonal Music using Variational Autoencoders", "abstract": "Variational Autoencoders (VAEs) have proven to be effective models for\nproducing latent representations of cognitive and semantic value. We assess the\ndegree to which VAEs trained on a prototypical tonal music corpus of 371 Bach's\nchorales define latent spaces representative of the circle of fifths and the\nhierarchical relation of each key component pitch as drawn in music cognition.\nIn detail, we compare the latent space of different VAE corpus encodings --\nPiano roll, MIDI, ABC, Tonnetz, DFT of pitch, and pitch class distributions --\nin providing a pitch space for key relations that align with cognitive\ndistances. We evaluate the model performance of these encodings using objective\nmetrics to capture accuracy, mean square error (MSE), KL-divergence, and\ncomputational cost. The ABC encoding performs the best in reconstructing the\noriginal data, while the Pitch DFT seems to capture more information from the\nlatent space. Furthermore, an objective evaluation of 12 major or minor\ntranspositions per piece is adopted to quantify the alignment of 1) intra- and\ninter-segment distances per key and 2) the key distances to cognitive pitch\nspaces. Our results show that Pitch DFT VAE latent spaces align best with\ncognitive spaces and provide a common-tone space where overlapping objects\nwithin a key are fuzzy clusters, which impose a well-defined order of\nstructural significance or stability -- i.e., a tonal hierarchy. Tonal\nhierarchies of different keys can be used to measure key distances and the\nrelationships of their in-key components at multiple hierarchies (e.g., notes\nand chords). The implementation of our VAE and the encodings framework are made\navailable online.", "published": "2023-11-07 00:15:29", "link": "http://arxiv.org/abs/2311.03621v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Are Words Enough? On the semantic conditioning of affective music\n  generation", "abstract": "Music has been commonly recognized as a means of expressing emotions. In this\nsense, an intense debate emerges from the need to verbalize musical emotions.\nThis concern seems highly relevant today, considering the exponential growth of\nnatural language processing using deep learning models where it is possible to\nprompt semantic propositions to generate music automatically. This scoping\nreview aims to analyze and discuss the possibilities of music generation\nconditioned by emotions. To address this topic, we propose a historical\nperspective that encompasses the different disciplines and methods contributing\nto this topic. In detail, we review two main paradigms adopted in automatic\nmusic generation: rules-based and machine-learning models. Of note are the deep\nlearning architectures that aim to generate high-fidelity music from textual\ndescriptions. These models raise fundamental questions about the expressivity\nof music, including whether emotions can be represented with words or expressed\nthrough them. We conclude that overcoming the limitation and ambiguity of\nlanguage to express emotions through music, some of the use of deep learning\nwith natural language has the potential to impact the creative industries by\nproviding powerful tools to prompt and generate new musical works.", "published": "2023-11-07 00:19:09", "link": "http://arxiv.org/abs/2311.03624v1", "categories": ["cs.MM", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Improved Child Text-to-Speech Synthesis through Fastpitch-based Transfer\n  Learning", "abstract": "Speech synthesis technology has witnessed significant advancements in recent\nyears, enabling the creation of natural and expressive synthetic speech. One\narea of particular interest is the generation of synthetic child speech, which\npresents unique challenges due to children's distinct vocal characteristics and\ndevelopmental stages. This paper presents a novel approach that leverages the\nFastpitch text-to-speech (TTS) model for generating high-quality synthetic\nchild speech. This study uses the transfer learning training pipeline. The\napproach involved finetuning a multi-speaker TTS model to work with child\nspeech. We use the cleaned version of the publicly available MyST dataset (55\nhours) for our finetuning experiments. We also release a prototype dataset of\nsynthetic speech samples generated from this research together with model code\nto support further research. By using a pretrained MOSNet, we conducted an\nobjective assessment that showed a significant correlation between real and\nsynthetic child voices. Additionally, to validate the intelligibility of the\ngenerated speech, we employed an automatic speech recognition (ASR) model to\ncompare the word error rates (WER) of real and synthetic child voices. The\nspeaker similarity between the real and generated speech is also measured using\na pretrained speaker encoder.", "published": "2023-11-07 19:31:44", "link": "http://arxiv.org/abs/2311.04313v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "InstrumentGen: Generating Sample-Based Musical Instruments From Text", "abstract": "We introduce the text-to-instrument task, which aims at generating\nsample-based musical instruments based on textual prompts. Accordingly, we\npropose InstrumentGen, a model that extends a text-prompted generative audio\nframework to condition on instrument family, source type, pitch (across an\n88-key spectrum), velocity, and a joint text/audio embedding. Furthermore, we\npresent a differentiable loss function to evaluate the intra-instrument timbral\nconsistency of sample-based instruments. Our results establish a foundational\ntext-to-instrument baseline, extending research in the domain of automatic\nsample-based instrument generation.", "published": "2023-11-07 20:45:59", "link": "http://arxiv.org/abs/2311.04339v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Can CLIP Help Sound Source Localization?", "abstract": "Large-scale pre-trained image-text models demonstrate remarkable versatility\nacross diverse tasks, benefiting from their robust representational\ncapabilities and effective multimodal alignment. We extend the application of\nthese models, specifically CLIP, to the domain of sound source localization.\nUnlike conventional approaches, we employ the pre-trained CLIP model without\nexplicit text input, relying solely on the audio-visual correspondence. To this\nend, we introduce a framework that translates audio signals into tokens\ncompatible with CLIP's text encoder, yielding audio-driven embeddings. By\ndirectly using these embeddings, our method generates audio-grounded masks for\nthe provided audio, extracts audio-grounded image features from the highlighted\nregions, and aligns them with the audio-driven embeddings using the\naudio-visual correspondence objective. Our findings suggest that utilizing\npre-trained image-text models enable our model to generate more complete and\ncompact localization maps for the sounding objects. Extensive experiments show\nthat our method outperforms state-of-the-art approaches by a significant\nmargin.", "published": "2023-11-07 15:26:57", "link": "http://arxiv.org/abs/2311.04066v1", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Proceedings of the 5th International Workshop on Reading Music Systems", "abstract": "The International Workshop on Reading Music Systems (WoRMS) is a workshop\nthat tries to connect researchers who develop systems for reading music, such\nas in the field of Optical Music Recognition, with other researchers and\npractitioners that could benefit from such systems, like librarians or\nmusicologists. The relevant topics of interest for the workshop include, but\nare not limited to: Music reading systems; Optical music recognition; Datasets\nand performance evaluation; Image processing on music scores; Writer\nidentification; Authoring, editing, storing and presentation systems for music\nscores; Multi-modal systems; Novel input-methods for music to produce written\nmusic; Web-based Music Information Retrieval services; Applications and\nprojects; Use-cases related to written music.\n  These are the proceedings of the 5th International Workshop on Reading Music\nSystems, held in Milan, Italy on Nov. 4th 2023.", "published": "2023-11-07 16:00:42", "link": "http://arxiv.org/abs/2311.04091v1", "categories": ["cs.CV", "cs.IR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
