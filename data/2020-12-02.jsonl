{"title": "Automatic Extraction of Ranked SNP-Phenotype Associations from\n  Literature through Detecting Neural Candidates, Negation and Modality Markers", "abstract": "Genome-wide association (GWA) constitutes a prominent portion of studies\nwhich have been conducted on personalized medicine and pharmacogenomics.\nRecently, very few methods have been developed for extracting mutation-diseases\nassociations. However, there is no available method for extracting the\nassociation of SNP-phenotype from text which considers degree of confidence in\nassociations. In this study, first a relation extraction method relying on\nlinguistic-based negation detection and neutral candidates is proposed. The\nexperiments show that negation cues and scope as well as detecting neutral\ncandidates can be employed for implementing a superior relation extraction\nmethod which outperforms the kernel-based counterparts due to a uniform innate\npolarity of sentences and small number of complex sentences in the corpus.\nMoreover, a modality based approach is proposed to estimate the confidence\nlevel of the extracted association which can be used to assess the reliability\nof the reported association. Keywords: SNP, Phenotype, Biomedical Relation\nExtraction, Negation Detection.", "published": "2020-12-02 00:03:07", "link": "http://arxiv.org/abs/2012.00902v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Can We Know When Language Models Know? On the Calibration of\n  Language Models for Question Answering", "abstract": "Recent works have shown that language models (LM) capture different types of\nknowledge regarding facts or common sense. However, because no model is\nperfect, they still fail to provide appropriate answers in many cases. In this\npaper, we ask the question \"how can we know when language models know, with\nconfidence, the answer to a particular query?\" We examine this question from\nthe point of view of calibration, the property of a probabilistic model's\npredicted probabilities actually being well correlated with the probabilities\nof correctness. We examine three strong generative models -- T5, BART, and\nGPT-2 -- and study whether their probabilities on QA tasks are well calibrated,\nfinding the answer is a relatively emphatic no. We then examine methods to\ncalibrate such models to make their confidence scores correlate better with the\nlikelihood of correctness through fine-tuning, post-hoc probability\nmodification, or adjustment of the predicted outputs or inputs. Experiments on\na diverse range of datasets demonstrate the effectiveness of our methods. We\nalso perform analysis to study the strengths and limitations of these methods,\nshedding light on further improvements that may be made in methods for\ncalibrating LMs. We have released the code at\nhttps://github.com/jzbjyb/lm-calibration.", "published": "2020-12-02 03:53:13", "link": "http://arxiv.org/abs/2012.00955v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interactive Teaching for Conversational AI", "abstract": "Current conversational AI systems aim to understand a set of pre-designed\nrequests and execute related actions, which limits them to evolve naturally and\nadapt based on human interactions. Motivated by how children learn their first\nlanguage interacting with adults, this paper describes a new Teachable AI\nsystem that is capable of learning new language nuggets called concepts,\ndirectly from end users using live interactive teaching sessions. The proposed\nsetup uses three models to: a) Identify gaps in understanding automatically\nduring live conversational interactions, b) Learn the respective\ninterpretations of such unknown concepts from live interactions with users, and\nc) Manage a classroom sub-dialogue specifically tailored for interactive\nteaching sessions. We propose state-of-the-art transformer based neural\narchitectures of models, fine-tuned on top of pre-trained models, and show\naccuracy improvements on the respective components. We demonstrate that this\nmethod is very promising in leading way to build more adaptive and personalized\nlanguage understanding models.", "published": "2020-12-02 04:08:49", "link": "http://arxiv.org/abs/2012.00958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meta-KD: A Meta Knowledge Distillation Framework for Language Model\n  Compression across Domains", "abstract": "Pre-trained language models have been applied to various NLP tasks with\nconsiderable performance gains. However, the large model sizes, together with\nthe long inference time, limit the deployment of such models in real-time\napplications. One line of model compression approaches considers knowledge\ndistillation to distill large teacher models into small student models. Most of\nthese studies focus on single-domain only, which ignores the transferable\nknowledge from other domains. We notice that training a teacher with\ntransferable knowledge digested across domains can achieve better\ngeneralization capability to help knowledge distillation. Hence we propose a\nMeta-Knowledge Distillation (Meta-KD) framework to build a meta-teacher model\nthat captures transferable knowledge across domains and passes such knowledge\nto students. Specifically, we explicitly force the meta-teacher to capture\ntransferable knowledge at both instance-level and feature-level from multiple\ndomains, and then propose a meta-distillation algorithm to learn single-domain\nstudent models with guidance from the meta-teacher. Experiments on public\nmulti-domain NLP tasks show the effectiveness and superiority of the proposed\nMeta-KD framework. Further, we also demonstrate the capability of Meta-KD in\nthe settings where the training data is scarce.", "published": "2020-12-02 15:18:37", "link": "http://arxiv.org/abs/2012.01266v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Supertagging the Long Tail with Tree-Structured Decoding of Complex\n  Categories", "abstract": "Although current CCG supertaggers achieve high accuracy on the standard WSJ\ntest set, few systems make use of the categories' internal structure that will\ndrive the syntactic derivation during parsing. The tagset is traditionally\ntruncated, discarding the many rare and complex category types in the long\ntail. However, supertags are themselves trees. Rather than give up on rare\ntags, we investigate constructive models that account for their internal\nstructure, including novel methods for tree-structured prediction. Our best\ntagger is capable of recovering a sizeable fraction of the long-tail supertags\nand even generates CCG categories that have never been seen in training, while\napproximating the prior state of the art in overall tag accuracy with fewer\nparameters. We further investigate how well different approaches generalize to\nout-of-domain evaluation sets.", "published": "2020-12-02 15:51:36", "link": "http://arxiv.org/abs/2012.01285v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Computational Approach to Measuring the Semantic Divergence of\n  Cognates", "abstract": "Meaning is the foundation stone of intercultural communication. Languages are\ncontinuously changing, and words shift their meanings for various reasons.\nSemantic divergence in related languages is a key concern of historical\nlinguistics. In this paper we investigate semantic divergence across languages\nby measuring the semantic similarity of cognate sets in multiple languages. The\nmethod that we propose is based on cross-lingual word embeddings. In this paper\nwe implement and evaluate our method on English and five Romance languages, but\nit can be extended easily to any language pair, requiring only large\nmonolingual corpora for the involved languages and a small bilingual dictionary\nfor the pair. This language-agnostic method facilitates a quantitative analysis\nof cognates divergence -- by computing degrees of semantic similarity between\ncognate pairs -- and provides insights for identifying false friends. As a\nsecond contribution, we formulate a straightforward method for detecting false\nfriends, and introduce the notion of \"soft false friend\" and \"hard false\nfriend\", as well as a measure of the degree of \"falseness\" of a false friends\npair. Additionally, we propose an algorithm that can output suggestions for\ncorrecting false friends, which could result in a very helpful tool for\nlanguage learning or translation.", "published": "2020-12-02 15:52:38", "link": "http://arxiv.org/abs/2012.01288v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Stylistic Variation across Different Political Regimes", "abstract": "In this article we propose a stylistic analysis of texts written across two\ndifferent periods, which differ not only temporally, but politically and\nculturally: communism and democracy in Romania. We aim to analyze the stylistic\nvariation between texts written during these two periods, and determine at what\nlevels the variation is more apparent (if any): at the stylistic level, at the\ntopic level etc. We take a look at the stylistic profile of these texts\ncomparatively, by performing clustering and classification experiments on the\ntexts, using traditional authorship attribution methods and features. To\nconfirm the stylistic variation is indeed an effect of the change in political\nand cultural environment, and not merely reflective of a natural change in the\nauthor's style with time, we look at various stylistic metrics over time and\nshow that the change in style between the two periods is statistically\nsignificant. We also perform an analysis of the variation in topic between the\ntwo epochs, to compare with the variation at the style level. These analyses\nshow that texts from the two periods can indeed be distinguished, both from the\npoint of view of style and from that of semantic content (topic).", "published": "2020-12-02 16:16:46", "link": "http://arxiv.org/abs/2012.01305v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TAN-NTM: Topic Attention Networks for Neural Topic Modeling", "abstract": "Topic models have been widely used to learn text representations and gain\ninsight into document corpora. To perform topic discovery, most existing neural\nmodels either take document bag-of-words (BoW) or sequence of tokens as input\nfollowed by variational inference and BoW reconstruction to learn topic-word\ndistribution. However, leveraging topic-word distribution for learning better\nfeatures during document encoding has not been explored much. To this end, we\ndevelop a framework TAN-NTM, which processes document as a sequence of tokens\nthrough a LSTM whose contextual outputs are attended in a topic-aware manner.\nWe propose a novel attention mechanism which factors in topic-word distribution\nto enable the model to attend on relevant words that convey topic related cues.\nThe output of topic attention module is then used to carry out variational\ninference. We perform extensive ablations and experiments resulting in ~9-15\npercentage improvement over score of existing SOTA topic models in NPMI\ncoherence on several benchmark datasets - 20Newsgroups, Yelp Review Polarity\nand AGNews. Further, we show that our method learns better latent\ndocument-topic features compared to existing topic models through improvement\non two downstream tasks: document classification and topic guided keyphrase\ngeneration.", "published": "2020-12-02 20:58:04", "link": "http://arxiv.org/abs/2012.01524v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting BERT to improve aspect-based sentiment analysis performance\n  on Persian language", "abstract": "Aspect-based sentiment analysis (ABSA) is a more detailed task in sentiment\nanalysis, by identifying opinion polarity toward a certain aspect in a text.\nThis method is attracting more attention from the community, due to the fact\nthat it provides more thorough and useful information. However, there are few\nlanguage-specific researches on Persian language. The present research aims to\nimprove the ABSA on the Persian Pars-ABSA dataset. This research shows the\npotential of using pre-trained BERT model and taking advantage of using\nsentence-pair input on an ABSA task. The results indicate that employing\nPars-BERT pre-trained model along with natural language inference auxiliary\nsentence (NLI-M) could boost the ABSA task accuracy up to 91% which is 5.5%\n(absolute) higher than state-of-the-art studies on Pars-ABSA dataset.", "published": "2020-12-02 16:47:20", "link": "http://arxiv.org/abs/2012.07510v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Extracting COVID-19 Diagnoses and Symptoms From Clinical Text: A New\n  Annotated Corpus and Neural Event Extraction Framework", "abstract": "Coronavirus disease 2019 (COVID-19) is a global pandemic. Although much has\nbeen learned about the novel coronavirus since its emergence, there are many\nopen questions related to tracking its spread, describing symptomology,\npredicting the severity of infection, and forecasting healthcare utilization.\nFree-text clinical notes contain critical information for resolving these\nquestions. Data-driven, automatic information extraction models are needed to\nuse this text-encoded information in large-scale studies. This work presents a\nnew clinical corpus, referred to as the COVID-19 Annotated Clinical Text (CACT)\nCorpus, which comprises 1,472 notes with detailed annotations characterizing\nCOVID-19 diagnoses, testing, and clinical presentation. We introduce a\nspan-based event extraction model that jointly extracts all annotated\nphenomena, achieving high performance in identifying COVID-19 and symptom\nevents with associated assertion values (0.83-0.97 F1 for events and 0.73-0.79\nF1 for assertions). In a secondary use application, we explored the prediction\nof COVID-19 test results using structured patient data (e.g. vital signs and\nlaboratory results) and automatically extracted symptom information. The\nautomatically extracted symptoms improve prediction performance, beyond\nstructured data alone.", "published": "2020-12-02 05:25:02", "link": "http://arxiv.org/abs/2012.00974v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Classification of Multimodal Hate Speech -- The Winning Solution of\n  Hateful Memes Challenge", "abstract": "Hateful Memes is a new challenge set for multimodal classification, focusing\non detecting hate speech in multimodal memes. Difficult examples are added to\nthe dataset to make it hard to rely on unimodal signals, which means only\nmultimodal models can succeed. According to Kiela,the state-of-the-art methods\nperform poorly compared to humans (64.73% vs. 84.7% accuracy) on Hateful Memes.\nI propose a new model that combined multimodal with rules, which achieve the\nfirst ranking of accuracy and AUROC of 86.8% and 0.923 respectively. These\nrules are extracted from training set, and focus on improving the\nclassification accuracy of difficult samples.", "published": "2020-12-02 07:38:26", "link": "http://arxiv.org/abs/2012.01002v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Biomedical Knowledge Graph Refinement with Embedding and Logic Rules", "abstract": "Currently, there is a rapidly increasing need for high-quality biomedical\nknowledge graphs (BioKG) that provide direct and precise biomedical knowledge.\nIn the context of COVID-19, this issue is even more necessary to be\nhighlighted. However, most BioKG construction inevitably includes numerous\nconflicts and noises deriving from incorrect knowledge descriptions in\nliterature and defective information extraction techniques. Many studies have\ndemonstrated that reasoning upon the knowledge graph is effective in\neliminating such conflicts and noises. This paper proposes a method BioGRER to\nimprove the BioKG's quality, which comprehensively combines the knowledge graph\nembedding and logic rules that support and negate triplets in the BioKG. In the\nproposed model, the BioKG refinement problem is formulated as the probability\nestimation for triplets in the BioKG. We employ the variational EM algorithm to\noptimize knowledge graph embedding and logic rule inference alternately. In\nthis way, our model could combine efforts from both the knowledge graph\nembedding and logic rules, leading to better results than using them alone. We\nevaluate our model over a COVID-19 knowledge graph and obtain competitive\nresults.", "published": "2020-12-02 08:55:07", "link": "http://arxiv.org/abs/2012.01031v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Generating Descriptions for Sequential Images with Local-Object\n  Attention and Global Semantic Context Modelling", "abstract": "In this paper, we propose an end-to-end CNN-LSTM model for generating\ndescriptions for sequential images with a local-object attention mechanism. To\ngenerate coherent descriptions, we capture global semantic context using a\nmulti-layer perceptron, which learns the dependencies between sequential\nimages. A paralleled LSTM network is exploited for decoding the sequence\ndescriptions. Experimental results show that our model outperforms the baseline\nacross three different evaluation metrics on the datasets published by\nMicrosoft.", "published": "2020-12-02 16:07:32", "link": "http://arxiv.org/abs/2012.01295v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Learning from others' mistakes: Avoiding dataset biases without modeling\n  them", "abstract": "State-of-the-art natural language processing (NLP) models often learn to\nmodel dataset biases and surface form correlations instead of features that\ntarget the intended underlying task. Previous work has demonstrated effective\nmethods to circumvent these issues when knowledge of the bias is available. We\nconsider cases where the bias issues may not be explicitly identified, and show\na method for training models that learn to ignore these problematic\ncorrelations. Our approach relies on the observation that models with limited\ncapacity primarily learn to exploit biases in the dataset. We can leverage the\nerrors of such limited capacity models to train a more robust model in a\nproduct of experts, thus bypassing the need to hand-craft a biased model. We\nshow the effectiveness of this method to retain improvements in\nout-of-distribution settings even if no particular bias is targeted by the\nbiased model.", "published": "2020-12-02 16:10:54", "link": "http://arxiv.org/abs/2012.01300v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ArCorona: Analyzing Arabic Tweets in the Early Days of Coronavirus\n  (COVID-19) Pandemic", "abstract": "Over the past few months, there were huge numbers of circulating tweets and\ndiscussions about Coronavirus (COVID-19) in the Arab region. It is important\nfor policy makers and many people to identify types of shared tweets to better\nunderstand public behavior, topics of interest, requests from governments,\nsources of tweets, etc. It is also crucial to prevent spreading of rumors and\nmisinformation about the virus or bad cures. To this end, we present the\nlargest manually annotated dataset of Arabic tweets related to COVID-19. We\ndescribe annotation guidelines, analyze our dataset and build effective machine\nlearning and transformer based models for classification.", "published": "2020-12-02 19:05:25", "link": "http://arxiv.org/abs/2012.01462v3", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "SChME at SemEval-2020 Task 1: A Model Ensemble for Detecting Lexical\n  Semantic Change", "abstract": "This paper describes SChME (Semantic Change Detection with Model Ensemble), a\nmethod usedin SemEval-2020 Task 1 on unsupervised detection of lexical semantic\nchange. SChME usesa model ensemble combining signals of distributional models\n(word embeddings) and wordfrequency models where each model casts a vote\nindicating the probability that a word sufferedsemantic change according to\nthat feature. More specifically, we combine cosine distance of wordvectors\ncombined with a neighborhood-based metric we named Mapped Neighborhood\nDistance(MAP), and a word frequency differential metric as input signals to our\nmodel. Additionally,we explore alignment-based methods to investigate the\nimportance of the landmarks used in thisprocess. Our results show evidence that\nthe number of landmarks used for alignment has a directimpact on the predictive\nperformance of the model. Moreover, we show that languages that sufferless\nsemantic change tend to benefit from using a large number of landmarks, whereas\nlanguageswith more semantic change benefit from a more careful choice of\nlandmark number for alignment.", "published": "2020-12-02 23:56:34", "link": "http://arxiv.org/abs/2012.01603v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Extending NLP Techniques from the Categorical to the Latent Space: KL\n  Divergence, Zipf's Law, and Similarity Search", "abstract": "Despite the recent successes of deep learning in natural language processing\n(NLP), there remains widespread usage of and demand for techniques that do not\nrely on machine learning. The advantage of these techniques is their\ninterpretability and low cost when compared to frequently opaque and expensive\nmachine learning models. Although they may not be be as performant in all\ncases, they are often sufficient for common and relatively simple problems. In\nthis paper, we aim to modernize these older methods while retaining their\nadvantages by extending approaches from categorical or bag-of-words\nrepresentations to word embeddings representations in the latent space. First,\nwe show that entropy and Kullback-Leibler divergence can be efficiently\nestimated using word embeddings and use this estimation to compare text across\nseveral categories. Next, we recast the heavy-tailed distribution known as\nZipf's law that is frequently observed in the categorical space to the latent\nspace. Finally, we look to improve the Jaccard similarity measure for sentence\nsuggestion by introducing a new method of identifying similar sentences based\non the set cover problem. We compare the performance of this algorithm against\nseveral baselines including Word Mover's Distance and the Levenshtein distance.", "published": "2020-12-02 17:35:49", "link": "http://arxiv.org/abs/2012.01941v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Fairness in Classifying Medical Conversations into SOAP Sections", "abstract": "As machine learning algorithms are more widely deployed in healthcare, the\nquestion of algorithmic fairness becomes more critical to examine. Our work\nseeks to identify and understand disparities in a deployed model that\nclassifies doctor-patient conversations into sections of a medical SOAP note.\nWe employ several metrics to measure disparities in the classifier performance,\nand find small differences in a portion of the disadvantaged groups. A deeper\nanalysis of the language in these conversations and further stratifying the\ngroups suggests these differences are related to and often attributable to the\ntype of medical appointment (e.g., psychiatric vs. internist). Our findings\nstress the importance of understanding the disparities that may exist in the\ndata itself and how that affects a model's ability to equally distribute\nbenefits.", "published": "2020-12-02 14:55:22", "link": "http://arxiv.org/abs/2012.07749v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "End-to-End QA on COVID-19: Domain Adaptation with Synthetic Training", "abstract": "End-to-end question answering (QA) requires both information retrieval (IR)\nover a large document collection and machine reading comprehension (MRC) on the\nretrieved passages. Recent work has successfully trained neural IR systems\nusing only supervised question answering (QA) examples from open-domain\ndatasets. However, despite impressive performance on Wikipedia, neural IR lags\nbehind traditional term matching approaches such as BM25 in more specific and\nspecialized target domains such as COVID-19. Furthermore, given little or no\nlabeled data, effective adaptation of QA systems can also be challenging in\nsuch target domains. In this work, we explore the application of synthetically\ngenerated QA examples to improve performance on closed-domain retrieval and\nMRC. We combine our neural IR and MRC systems and show significant improvements\nin end-to-end QA on the CORD-19 collection over a state-of-the-art open-domain\nQA baseline.", "published": "2020-12-02 18:59:59", "link": "http://arxiv.org/abs/2012.01414v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Linguistic Classification using Instance-Based Learning", "abstract": "Traditionally linguists have organized languages of the world as language\nfamilies modelled as trees. In this work we take a contrarian approach and\nquestion the tree-based model that is rather restrictive. For example, the\naffinity that Sanskrit independently has with languages across Indo-European\nlanguages is better illustrated using a network model. We can say the same\nabout inter-relationship between languages in India, where the\ninter-relationships are better discovered than assumed. To enable such a\ndiscovery, in this paper we have made use of instance-based learning techniques\nto assign language labels to words. We vocalize each word and then classify it\nby making use of our custom linguistic distance metric of the word relative to\ntraining sets containing language labels. We construct the training sets by\nmaking use of word clusters and assigning a language and category label to that\ncluster. Further, we make use of clustering coefficients as a quality metric\nfor our research. We believe our work has the potential to usher in a new era\nin linguistics. We have limited this work for important languages in India.\nThis work can be further strengthened by applying Adaboost for classification\ncoupled with structural equivalence concepts of social network analysis.", "published": "2020-12-02 04:12:10", "link": "http://arxiv.org/abs/2012.07512v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Speaker Recognition Based on Deep Learning: An Overview", "abstract": "Speaker recognition is a task of identifying persons from their voices.\nRecently, deep learning has dramatically revolutionized speaker recognition.\nHowever, there is lack of comprehensive reviews on the exciting progress.\n  In this paper, we review several major subtasks of speaker recognition,\nincluding speaker verification, identification, diarization, and robust speaker\nrecognition, with a focus on deep-learning-based methods. Because the major\nadvantage of deep learning over conventional methods is its representation\nability, which is able to produce highly abstract embedding features from\nutterances, we first pay close attention to deep-learning-based speaker feature\nextraction, including the inputs, network structures, temporal pooling\nstrategies, and objective functions respectively, which are the fundamental\ncomponents of many speaker recognition subtasks. Then, we make an overview of\nspeaker diarization, with an emphasis of recent supervised, end-to-end, and\nonline diarization. Finally, we survey robust speaker recognition from the\nperspectives of domain adaptation and speech enhancement, which are two major\napproaches of dealing with domain mismatch and noise problems. Popular and\nrecently released corpora are listed at the end of the paper.", "published": "2020-12-02 02:24:45", "link": "http://arxiv.org/abs/2012.00931v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "The Third DIHARD Diarization Challenge", "abstract": "DIHARD III was the third in a series of speaker diarization challenges\nintended to improve the robustness of diarization systems to variability in\nrecording equipment, noise conditions, and conversational domain. Speaker\ndiarization was evaluated under two speech activity conditions (diarization\nfrom a reference speech activity vs. diarization from scratch) and 11 diverse\ndomains. The domains span a range of recording conditions and interaction\ntypes, including read audio-books, meeting speech, clinical interviews, web\nvideos, and, for the first time, conversational telephone speech. A total of 30\norganizations (forming 21teams) from industry and academia submitted 499 valid\nsystem outputs. The evaluation results indicate that speaker diarization has\nimproved markedly since DIHARD I, particularly for two-party interactions, but\nthat for many domains (e.g., web video) the problem remains far from solved.", "published": "2020-12-02 19:33:44", "link": "http://arxiv.org/abs/2012.01477v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Joint gender and age estimation based on speech signals using x-vectors\n  and transfer learning", "abstract": "In this paper we extend the x-vector framework for the task of speaker's age\nestimation and gender classification. In particular, we replace the baseline\nmultilayer-TDNN architecture with QuartzNet, a convolutional architecture that\nhas gained success in the field of speech recognition. We further propose a\ntwo-staged transfer learning scheme, utilizing large scale speech datasets:\nVoxCeleb and Common Voice, and usage of multitask learning to allow for joint\nage estimation and gender classification with a single system. We train and\nevaluate the performance on the TIMIT dataset. The proposed transfer learning\nscheme yields consecutive performance improvements in terms of both age\nestimation error and gender classification accuracy and the best performing\nsystem achieves new state-of-the-art results on the task of age estimation on\nthe TIMIT TEST dataset with MAE of 5.12 and 5.29 years and RMSE of 7.24 and\n8.12 years for male and female speakers respectively while maintaining a gender\nclassification accuracy of 99.6%.", "published": "2020-12-02 21:46:01", "link": "http://arxiv.org/abs/2012.01551v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sequence Generation using Deep Recurrent Networks and Embeddings: A\n  study case in music", "abstract": "Automatic generation of sequences has been a highly explored field in the\nlast years. In particular, natural language processing and automatic music\ncomposition have gained importance due to the recent advances in machine\nlearning and Neural Networks with intrinsic memory mechanisms such as Recurrent\nNeural Networks. This paper evaluates different types of memory mechanisms\n(memory cells) and analyses their performance in the field of music\ncomposition. The proposed approach considers music theory concepts such as\ntransposition, and uses data transformations (embeddings) to introduce semantic\nmeaning and improve the quality of the generated melodies. A set of\nquantitative metrics is presented to evaluate the performance of the proposed\narchitecture automatically, measuring the tonality of the musical compositions.", "published": "2020-12-02 14:19:19", "link": "http://arxiv.org/abs/2012.01231v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Study of Few-Shot Audio Classification", "abstract": "Advances in deep learning have resulted in state-of-the-art performance for\nmany audio classification tasks but, unlike humans, these systems traditionally\nrequire large amounts of data to make accurate predictions. Not every person or\norganization has access to those resources, and the organizations that do, like\nour field at large, do not reflect the demographics of our country. Enabling\npeople to use machine learning without significant resource hurdles is\nimportant, because machine learning is an increasingly useful tool for solving\nproblems, and can solve a broader set of problems when put in the hands of a\nbroader set of people. Few-shot learning is a type of machine learning designed\nto enable the model to generalize to new classes with very few examples. In\nthis research, we address two audio classification tasks (speaker\nidentification and activity classification) with the Prototypical Network\nfew-shot learning algorithm, and assess performance of various encoder\narchitectures. Our encoders include recurrent neural networks, as well as one-\nand two-dimensional convolutional neural networks. We evaluate our model for\nspeaker identification on the VoxCeleb dataset and ICSI Meeting Corpus,\nobtaining 5-shot 5-way accuracies of 93.5% and 54.0%, respectively. We also\nevaluate for activity classification from audio using few-shot subsets of the\nKinetics~600 dataset and AudioSet, both drawn from Youtube videos, obtaining\n51.5% and 35.2% accuracy, respectively.", "published": "2020-12-02 22:19:16", "link": "http://arxiv.org/abs/2012.01573v1", "categories": ["eess.AS", "cs.NE", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Enhancement of Spatial Clustering-Based Time-Frequency Masks using LSTM\n  Neural Networks", "abstract": "Recent works have shown that Deep Recurrent Neural Networks using the LSTM\narchitecture can achieve strong single-channel speech enhancement by estimating\ntime-frequency masks. However, these models do not naturally generalize to\nmulti-channel inputs from varying microphone configurations. In contrast,\nspatial clustering techniques can achieve such generalization but lack a strong\nsignal model. Our work proposes a combination of the two approaches. By using\nLSTMs to enhance spatial clustering based time-frequency masks, we achieve both\nthe signal modeling performance of multiple single-channel LSTM-DNN speech\nenhancers and the signal separation performance and generality of multi-channel\nspatial clustering. We compare our proposed system to several baselines on the\nCHiME-3 dataset. We evaluate the quality of the audio from each system using\nSDR from the BSS\\_eval toolkit and PESQ. We evaluate the intelligibility of the\noutput of each system using word error rate from a Kaldi automatic speech\nrecognizer.", "published": "2020-12-02 22:29:29", "link": "http://arxiv.org/abs/2012.01576v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "COVID-19 Cough Classification using Machine Learning and Global\n  Smartphone Recordings", "abstract": "We present a machine learning based COVID-19 cough classifier which can\ndiscriminate COVID-19 positive coughs from both COVID-19 negative and healthy\ncoughs recorded on a smartphone. This type of screening is non-contact, easy to\napply, and can reduce the workload in testing centres as well as limit\ntransmission by recommending early self-isolation to those who have a cough\nsuggestive of COVID-19. The datasets used in this study include subjects from\nall six continents and contain both forced and natural coughs, indicating that\nthe approach is widely applicable. The publicly available Coswara dataset\ncontains 92 COVID-19 positive and 1079 healthy subjects, while the second\nsmaller dataset was collected mostly in South Africa and contains 18 COVID-19\npositive and 26 COVID-19 negative subjects who have undergone a SARS-CoV\nlaboratory test. Both datasets indicate that COVID-19 positive coughs are\n15\\%-20\\% shorter than non-COVID coughs. Dataset skew was addressed by applying\nthe synthetic minority oversampling technique (SMOTE). A leave-$p$-out\ncross-validation scheme was used to train and evaluate seven machine learning\nclassifiers: LR, KNN, SVM, MLP, CNN, LSTM and Resnet50. Our results show that\nalthough all classifiers were able to identify COVID-19 coughs, the best\nperformance was exhibited by the Resnet50 classifier, which was best able to\ndiscriminate between the COVID-19 positive and the healthy coughs with an area\nunder the ROC curve (AUC) of 0.98. An LSTM classifier was best able to\ndiscriminate between the COVID-19 positive and COVID-19 negative coughs, with\nan AUC of 0.94 after selecting the best 13 features from a sequential forward\nselection (SFS). Since this type of cough audio classification is\ncost-effective and easy to deploy, it is potentially a useful and viable means\nof non-contact COVID-19 screening.", "published": "2020-12-02 13:35:42", "link": "http://arxiv.org/abs/2012.01926v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improved MVDR Beamforming Using LSTM Speech Models to Clean Spatial\n  Clustering Masks", "abstract": "Spatial clustering techniques can achieve significant multi-channel noise\nreduction across relatively arbitrary microphone configurations, but have\ndifficulty incorporating a detailed speech/noise model. In contrast, LSTM\nneural networks have successfully been trained to recognize speech from noise\non single-channel inputs, but have difficulty taking full advantage of the\ninformation in multi-channel recordings. This paper integrates these two\napproaches, training LSTM speech models to clean the masks generated by the\nModel-based EM Source Separation and Localization (MESSL) spatial clustering\nmethod. By doing so, it attains both the spatial separation performance and\ngenerality of multi-channel spatial clustering and the signal modeling\nperformance of multiple parallel single-channel LSTM speech enhancers. Our\nexperiments show that when our system is applied to the CHiME-3 dataset of\nnoisy tablet recordings, it increases speech quality as measured by the\nPerceptual Evaluation of Speech Quality (PESQ) algorithm and reduces the word\nerror rate of the baseline CHiME-3 speech recognizer, as compared to the\ndefault BeamformIt beamformer.", "published": "2020-12-02 22:35:00", "link": "http://arxiv.org/abs/2012.02191v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Combining Spatial Clustering with LSTM Speech Models for Multichannel\n  Speech Enhancement", "abstract": "Recurrent neural networks using the LSTM architecture can achieve significant\nsingle-channel noise reduction. It is not obvious, however, how to apply them\nto multi-channel inputs in a way that can generalize to new microphone\nconfigurations. In contrast, spatial clustering techniques can achieve such\ngeneralization, but lack a strong signal model. This paper combines the two\napproaches to attain both the spatial separation performance and generality of\nmultichannel spatial clustering and the signal modeling performance of multiple\nparallel single-channel LSTM speech enhancers. The system is compared to\nseveral baselines on the CHiME3 dataset in terms of speech quality predicted by\nthe PESQ algorithm and word error rate of a recognizer trained on mis-matched\nconditions, in order to focus on generalization. Our experiments show that by\ncombining the LSTM models with the spatial clustering, we reduce word error\nrate by 4.6\\% absolute (17.2\\% relative) on the development set and 11.2\\%\nabsolute (25.5\\% relative) on test set compared with spatial clustering system,\nand reduce by 10.75\\% (32.72\\% relative) on development set and 6.12\\% absolute\n(15.76\\% relative) on test data compared with LSTM model.", "published": "2020-12-02 22:37:50", "link": "http://arxiv.org/abs/2012.03388v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
