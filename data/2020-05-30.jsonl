{"title": "Topic Detection and Summarization of User Reviews", "abstract": "A massive amount of reviews are generated daily from various platforms. It is\nimpossible for people to read through tons of reviews and to obtain useful\ninformation. Automatic summarizing customer reviews thus is important for\nidentifying and extracting the essential information to help users to obtain\nthe gist of the data. However, as customer reviews are typically short,\ninformal, and multifaceted, it is extremely challenging to generate topic-wise\nsummarization.While there are several studies aims to solve this issue, they\nare heuristic methods that are developed only utilizing customer reviews.\nUnlike existing method, we propose an effective new summarization method by\nanalyzing both reviews and summaries.To do that, we first segment reviews and\nsummaries into individual sentiments. As the sentiments are typically short, we\ncombine sentiments talking about the same aspect into a single document and\napply topic modeling method to identify hidden topics among customer reviews\nand summaries. Sentiment analysis is employed to distinguish positive and\nnegative opinions among each detected topic. A classifier is also introduced to\ndistinguish the writing pattern of summaries and that of customer reviews.\nFinally, sentiments are selected to generate the summarization based on their\ntopic relevance, sentiment analysis score and the writing pattern. To test our\nmethod, a new dataset comprising product reviews and summaries about 1028\nproducts are collected from Amazon and CNET. Experimental results show the\neffectiveness of our method compared with other methods.", "published": "2020-05-30 02:19:08", "link": "http://arxiv.org/abs/2006.00148v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "User Memory Reasoning for Conversational Recommendation", "abstract": "We study a conversational recommendation model which dynamically manages\nusers' past (offline) preferences and current (online) requests through a\nstructured and cumulative user memory knowledge graph, to allow for natural\ninteractions and accurate recommendations. For this study, we create a new\nMemory Graph (MG) <--> Conversational Recommendation parallel corpus called\nMGConvRex with 7K+ human-to-human role-playing dialogs, grounded on a\nlarge-scale user memory bootstrapped from real-world user scenarios. MGConvRex\ncaptures human-level reasoning over user memory and has disjoint\ntraining/testing sets of users for zero-shot (cold-start) reasoning for\nrecommendation. We propose a simple yet expandable formulation for constructing\nand updating the MG, and a reasoning model that predicts optimal dialog\npolicies and recommendation items in unconstrained graph space. The prediction\nof our proposed model inherits the graph structure, providing a natural way to\nexplain the model's recommendation. Experiments are conducted for both offline\nmetrics and online simulation, showing competitive results.", "published": "2020-05-30 05:29:23", "link": "http://arxiv.org/abs/2006.00184v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Corpus Creation for Sentiment Analysis in Code-Mixed Tamil-English Text", "abstract": "Understanding the sentiment of a comment from a video or an image is an\nessential task in many applications. Sentiment analysis of a text can be useful\nfor various decision-making processes. One such application is to analyse the\npopular sentiments of videos on social media based on viewer comments. However,\ncomments from social media do not follow strict rules of grammar, and they\ncontain mixing of more than one language, often written in non-native scripts.\nNon-availability of annotated code-mixed data for a low-resourced language like\nTamil also adds difficulty to this problem. To overcome this, we created a gold\nstandard Tamil-English code-switched, sentiment-annotated corpus containing\n15,744 comment posts from YouTube. In this paper, we describe the process of\ncreating the corpus and assigning polarities. We present inter-annotator\nagreement and show the results of sentiment analysis trained on this corpus as\na benchmark.", "published": "2020-05-30 07:17:27", "link": "http://arxiv.org/abs/2006.00206v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Sentiment Analysis Dataset for Code-Mixed Malayalam-English", "abstract": "There is an increasing demand for sentiment analysis of text from social\nmedia which are mostly code-mixed. Systems trained on monolingual data fail for\ncode-mixed data due to the complexity of mixing at different levels of the\ntext. However, very few resources are available for code-mixed data to create\nmodels specific for this data. Although much research in multilingual and\ncross-lingual sentiment analysis has used semi-supervised or unsupervised\nmethods, supervised methods still performs better. Only a few datasets for\npopular languages such as English-Spanish, English-Hindi, and English-Chinese\nare available. There are no resources available for Malayalam-English\ncode-mixed data. This paper presents a new gold standard corpus for sentiment\nanalysis of code-mixed text in Malayalam-English annotated by voluntary\nannotators. This gold standard corpus obtained a Krippendorff's alpha above 0.8\nfor the dataset. We use this new corpus to provide the benchmark for sentiment\nanalysis in Malayalam-English code-mixed texts.", "published": "2020-05-30 07:32:37", "link": "http://arxiv.org/abs/2006.00210v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Masking for Improved Stability in Spoken Language Translation", "abstract": "For spoken language translation (SLT) in live scenarios such as conferences,\nlectures and meetings, it is desirable to show the translation to the user as\nquickly as possible, avoiding an annoying lag between speaker and translated\ncaptions. In other words, we would like low-latency, online SLT. If we assume a\npipeline of automatic speech recognition (ASR) and machine translation (MT)\nthen a viable approach to online SLT is to pair an online ASR system, with a a\nretranslation strategy, where the MT system re-translates every update received\nfrom ASR. However this can result in annoying \"flicker\" as the MT system\nupdates its translation. A possible solution is to add a fixed delay, or \"mask\"\nto the the output of the MT system, but a fixed global mask introduces\nundesirable latency to the output. We show how this mask can be set\ndynamically, improving the latency-flicker trade-off without sacrificing\ntranslation quality.", "published": "2020-05-30 12:23:10", "link": "http://arxiv.org/abs/2006.00249v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Augmentation with Unsupervised Machine Translation Improves the\n  Structural Similarity of Cross-lingual Word Embeddings", "abstract": "Unsupervised cross-lingual word embedding (CLWE) methods learn a linear\ntransformation matrix that maps two monolingual embedding spaces that are\nseparately trained with monolingual corpora. This method relies on the\nassumption that the two embedding spaces are structurally similar, which does\nnot necessarily hold true in general. In this paper, we argue that using a\npseudo-parallel corpus generated by an unsupervised machine translation model\nfacilitates the structural similarity of the two embedding spaces and improves\nthe quality of CLWEs in the unsupervised mapping method. We show that our\napproach outperforms other alternative approaches given the same amount of\ndata, and, through detailed analysis, we show that data augmentation with the\npseudo data from unsupervised machine translation is especially effective for\nmapping-based CLWEs because (1) the pseudo data makes the source and target\ncorpora (partially) parallel; (2) the pseudo data contains information on the\noriginal language that helps to learn similar embedding spaces between the\nsource and target languages.", "published": "2020-05-30 13:28:03", "link": "http://arxiv.org/abs/2006.00262v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic Features for Readability Assessment", "abstract": "Readability assessment aims to automatically classify text by the level\nappropriate for learning readers. Traditional approaches to this task utilize a\nvariety of linguistically motivated features paired with simple machine\nlearning models. More recent methods have improved performance by discarding\nthese features and utilizing deep learning models. However, it is unknown\nwhether augmenting deep learning models with linguistically motivated features\nwould improve performance further. This paper combines these two approaches\nwith the goal of improving overall model performance and addressing this\nquestion. Evaluating on two large readability corpora, we find that, given\nsufficient training data, augmenting deep learning models with linguistically\nmotivated features does not improve state-of-the-art performance. Our results\nprovide preliminary evidence for the hypothesis that the state-of-the-art deep\nlearning models represent linguistic features of the text related to\nreadability. Future research on the nature of representations formed in these\nmodels can shed light on the learned features and their relations to\nlinguistically motivated ones hypothesized in traditional approaches.", "published": "2020-05-30 22:14:46", "link": "http://arxiv.org/abs/2006.00377v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Filterbank Learning for Keyword Spotting", "abstract": "Despite their great performance over the years, handcrafted speech features\nare not necessarily optimal for any particular speech application.\nConsequently, with greater or lesser success, optimal filterbank learning has\nbeen studied for different speech processing tasks. In this paper, we fill in a\ngap by exploring filterbank learning for keyword spotting (KWS). Two approaches\nare examined: filterbank matrix learning in the power spectral domain and\nparameter learning of a psychoacoustically-motivated gammachirp filterbank.\nFilterbank parameters are optimized jointly with a modern deep residual neural\nnetwork-based KWS back-end. Our experimental results reveal that, in general,\nthere are no statistically significant differences, in terms of KWS accuracy,\nbetween using a learned filterbank and handcrafted speech features. Thus, while\nwe conclude that the latter are still a wise choice when using modern KWS\nback-ends, we also hypothesize that this could be a symptom of information\nredundancy, which opens up new research possibilities in the field of\nsmall-footprint KWS.", "published": "2020-05-30 08:11:58", "link": "http://arxiv.org/abs/2006.00217v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
