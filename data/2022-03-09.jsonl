{"title": "On the Evaluation of Answer-Agnostic Paragraph-level Multi-Question\n  Generation", "abstract": "We study the task of predicting a set of salient questions from a given\nparagraph without any prior knowledge of the precise answer. We make two main\ncontributions. First, we propose a new method to evaluate a set of predicted\nquestions against the set of references by using the Hungarian algorithm to\nassign predicted questions to references before scoring the assigned pairs. We\nshow that our proposed evaluation strategy has better theoretical and practical\nproperties compared to prior methods because it can properly account for the\ncoverage of references. Second, we compare different strategies to utilize a\npre-trained seq2seq model to generate and select a set of questions related to\na given paragraph. The code is available.", "published": "2022-03-09 00:55:54", "link": "http://arxiv.org/abs/2203.04464v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Onception: Active Learning with Expert Advice for Real World Machine\n  Translation", "abstract": "Active learning can play an important role in low-resource settings (i.e.,\nwhere annotated data is scarce), by selecting which instances may be more\nworthy to annotate. Most active learning approaches for Machine Translation\nassume the existence of a pool of sentences in a source language, and rely on\nhuman annotators to provide translations or post-edits, which can still be\ncostly. In this article, we assume a real world human-in-the-loop scenario in\nwhich: (i) the source sentences may not be readily available, but instead\narrive in a stream; (ii) the automatic translations receive feedback in the\nform of a rating, instead of a correct/edited translation, since the\nhuman-in-the-loop might be a user looking for a translation, but not be able to\nprovide one. To tackle the challenge of deciding whether each incoming pair\nsource-translations is worthy to query for human feedback, we resort to a\nnumber of stream-based active learning query strategies. Moreover, since we not\nknow in advance which query strategy will be the most adequate for a certain\nlanguage pair and set of Machine Translation models, we propose to dynamically\ncombine multiple strategies using prediction with expert advice. Our\nexperiments show that using active learning allows to converge to the best\nMachine Translation systems with fewer human interactions. Furthermore,\ncombining multiple strategies using prediction with expert advice often\noutperforms several individual active learning strategies with even fewer\ninteractions.", "published": "2022-03-09 03:32:42", "link": "http://arxiv.org/abs/2203.04507v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Slangvolution: A Causal Analysis of Semantic Change and Frequency\n  Dynamics in Slang", "abstract": "Languages are continuously undergoing changes, and the mechanisms that\nunderlie these changes are still a matter of debate. In this work, we approach\nlanguage evolution through the lens of causality in order to model not only how\nvarious distributional factors associate with language change, but how they\ncausally affect it. In particular, we study slang, which is an informal\nlanguage that is typically restricted to a specific group or social setting. We\nanalyze the semantic change and frequency shift of slang words and compare them\nto those of standard, nonslang words. With causal discovery and causal\ninference techniques, we measure the effect that word type (slang/nonslang) has\non both semantic change and frequency shift, as well as its relationship to\nfrequency, polysemy and part of speech. Our analysis provides some new insights\nin the study of language change, e.g., we show that slang words undergo less\nsemantic change but tend to have larger frequency shifts over time.", "published": "2022-03-09 11:34:43", "link": "http://arxiv.org/abs/2203.04651v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nested Named Entity Recognition as Latent Lexicalized Constituency\n  Parsing", "abstract": "Nested named entity recognition (NER) has been receiving increasing\nattention. Recently, (Fu et al, 2021) adapt a span-based constituency parser to\ntackle nested NER. They treat nested entities as partially-observed\nconstituency trees and propose the masked inside algorithm for partial\nmarginalization. However, their method cannot leverage entity heads, which have\nbeen shown useful in entity mention detection and entity typing. In this work,\nwe resort to more expressive structures, lexicalized constituency trees in\nwhich constituents are annotated by headwords, to model nested entities. We\nleverage the Eisner-Satta algorithm to perform partial marginalization and\ninference efficiently. In addition, we propose to use (1) a two-stage strategy\n(2) a head regularization loss and (3) a head-aware labeling loss in order to\nenhance the performance. We make a thorough ablation study to investigate the\nfunctionality of each component. Experimentally, our method achieves the\nstate-of-the-art performance on ACE2004, ACE2005 and NNE, and competitive\nperformance on GENIA, and meanwhile has a fast inference speed.", "published": "2022-03-09 12:02:59", "link": "http://arxiv.org/abs/2203.04665v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Diversity: Visible to Humans, Exploitable by Machines", "abstract": "The Universal Knowledge Core (UKC) is a large multilingual lexical database\nwith a focus on language diversity and covering over a thousand languages. The\naim of the database, as well as its tools and data catalogue, is to make the\nsomewhat abstract notion of diversity visually understandable for humans and\nformally exploitable by machines. The UKC website lets users explore millions\nof individual words and their meanings, but also phenomena of cross-lingual\nconvergence and divergence, such as shared interlingual meanings, lexicon\nsimilarities, cognate clusters, or lexical gaps. The UKC LiveLanguage\nCatalogue, in turn, provides access to the underlying lexical data in a\ncomputer-processable form, ready to be reused in cross-lingual applications.", "published": "2022-03-09 14:04:16", "link": "http://arxiv.org/abs/2203.04723v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One-Shot Learning from a Demonstration with Hierarchical Latent Language", "abstract": "Humans have the capability, aided by the expressive compositionality of their\nlanguage, to learn quickly by demonstration. They are able to describe unseen\ntask-performing procedures and generalize their execution to other contexts. In\nthis work, we introduce DescribeWorld, an environment designed to test this\nsort of generalization skill in grounded agents, where tasks are linguistically\nand procedurally composed of elementary concepts. The agent observes a single\ntask demonstration in a Minecraft-like grid world, and is then asked to carry\nout the same task in a new map. To enable such a level of generalization, we\npropose a neural agent infused with hierarchical latent language--both at the\nlevel of task inference and subtask planning. Our agent first generates a\ntextual description of the demonstrated unseen task, then leverages this\ndescription to replicate it. Through multiple evaluation scenarios and a suite\nof generalization tests, we find that agents that perform text-based inference\nare better equipped for the challenge under a random split of tasks.", "published": "2022-03-09 15:36:43", "link": "http://arxiv.org/abs/2203.04806v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neuro-symbolic Natural Logic with Introspective Revision for Natural\n  Language Inference", "abstract": "We introduce a neuro-symbolic natural logic framework based on reinforcement\nlearning with introspective revision. The model samples and rewards specific\nreasoning paths through policy gradient, in which the introspective revision\nalgorithm modifies intermediate symbolic reasoning steps to discover\nreward-earning operations as well as leverages external knowledge to alleviate\nspurious reasoning and training inefficiency. The framework is supported by\nproperly designed local relation models to avoid input entangling, which helps\nensure the interpretability of the proof paths. The proposed model has built-in\ninterpretability and shows superior capability in monotonicity inference,\nsystematic generalization, and interpretability, compared to previous models on\nthe existing datasets.", "published": "2022-03-09 16:31:58", "link": "http://arxiv.org/abs/2203.04857v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PET: An Annotated Dataset for Process Extraction from Natural Language\n  Text", "abstract": "Process extraction from text is an important task of process discovery, for\nwhich various approaches have been developed in recent years. However, in\ncontrast to other information extraction tasks, there is a lack of\ngold-standard corpora of business process descriptions that are carefully\nannotated with all the entities and relationships of interest. Due to this, it\nis currently hard to compare the results obtained by extraction approaches in\nan objective manner, whereas the lack of annotated texts also prevents the\napplication of data-driven information extraction methodologies, typical of the\nnatural language processing field. Therefore, to bridge this gap, we present\nthe PET dataset, a first corpus of business process descriptions annotated with\nactivities, gateways, actors, and flow information. We present our new\nresource, including a variety of baselines to benchmark the difficulty and\nchallenges of business process extraction from text. PET can be accessed via\nhuggingface.co/datasets/patriziobellan/PET", "published": "2022-03-09 16:33:59", "link": "http://arxiv.org/abs/2203.04860v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Alignment of Distributional Word Embeddings", "abstract": "Cross-domain alignment play a key roles in tasks ranging from machine\ntranslation to transfer learning. Recently, purely unsupervised methods\noperating on monolingual embeddings have successfully been used to infer a\nbilingual lexicon without relying on supervision. However, current state-of-the\nart methods only focus on point vectors although distributional embeddings have\nproven to embed richer semantic information when representing words. In this\npaper, we propose stochastic optimization approach for aligning probabilistic\nembeddings. Finally, we evaluate our method on the problem of unsupervised word\ntranslation, by aligning word embeddings trained on monolingual data. We show\nthat the proposed approach achieves good performance on the bilingual lexicon\ninduction task across several language pairs and performs better than the\npoint-vector based approach.", "published": "2022-03-09 16:39:06", "link": "http://arxiv.org/abs/2203.04863v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Networks and Unsupervised Ranking of Sentences", "abstract": "We construct a contextual network to represent a document with syntactic and\nsemantic relations between word-sentence pairs, based on which we devise an\nunsupervised algorithm called CNATAR (Contextual Network And Text Analysis\nRank) to score sentences, and rank them through a bi-objective 0-1 knapsack\nmaximization problem over topic analysis and sentence scores. We show that\nCNATAR outperforms the combined ranking of the three human judges provided on\nthe SummBank dataset under both ROUGE and BLEU metrics, which in term\nsignificantly outperforms each individual judge's ranking. Moreover, CNATAR\nproduces so far the highest ROUGE scores over DUC-02, and outperforms previous\nsupervised algorithms on the CNN/DailyMail and NYT datasets. We also compare\nthe performance of CNATAR and the latest supervised neural-network\nsummarization models and compute oracle results.", "published": "2022-03-09 00:47:20", "link": "http://arxiv.org/abs/2203.04459v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Boilerplate Detection via Semantic Classification of TextBlocks", "abstract": "We present a hierarchical neural network model called SemText to detect HTML\nboilerplate based on a novel semantic representation of HTML tags, class names,\nand text blocks. We train SemText on three published datasets of news webpages\nand fine-tune it using a small number of development data in CleanEval and\nGoogleTrends-2017. We show that SemText achieves the state-of-the-art accuracy\non these datasets. We then demonstrate the robustness of SemText by showing\nthat it also detects boilerplate effectively on out-of-domain community-based\nquestion-answer webpages.", "published": "2022-03-09 01:01:49", "link": "http://arxiv.org/abs/2203.04467v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PALI-NLP at SemEval-2022 Task 4: Discriminative Fine-tuning of\n  Transformers for Patronizing and Condescending Language Detection", "abstract": "Patronizing and condescending language (PCL) has a large harmful impact and\nis difficult to detect, both for human judges and existing NLP systems. At\nSemEval-2022 Task 4, we propose a novel Transformer-based model and its\nensembles to accurately understand such language context for PCL detection. To\nfacilitate comprehension of the subtle and subjective nature of PCL, two\nfine-tuning strategies are applied to capture discriminative features from\ndiverse linguistic behaviour and categorical distribution. The system achieves\nremarkable results on the official ranking, including 1st in Subtask 1 and 5th\nin Subtask 2. Extensive experiments on the task demonstrate the effectiveness\nof our system and its strategies.", "published": "2022-03-09 10:05:10", "link": "http://arxiv.org/abs/2203.04616v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LEBP -- Language Expectation & Binding Policy: A Two-Stream Framework\n  for Embodied Vision-and-Language Interaction Task Learning Agents", "abstract": "People always desire an embodied agent that can perform a task by\nunderstanding language instruction. Moreover, they also want to monitor and\nexpect agents to understand commands the way they expected. But, how to build\nsuch an embodied agent is still unclear. Recently, people can explore this\nproblem with the Vision-and-Language Interaction benchmark ALFRED, which\nrequires an agent to perform complicated daily household tasks following\nnatural language instructions in unseen scenes. In this paper, we propose LEBP\n-- Language Expectation and Binding Policy Module to tackle the ALFRED. The\nLEBP contains a two-stream process: 1) It first conducts a language expectation\nmodule to generate an expectation describing how to perform tasks by\nunderstanding the language instruction. The expectation consists of a sequence\nof sub-steps for the task (e.g., Pick an apple). The expectation allows people\nto access and check the understanding results of instructions before the agent\ntakes actual actions, in case the task might go wrong. 2) Then, it uses the\nbinding policy module to bind sub-steps in expectation to actual actions to\nspecific scenarios. Actual actions include navigation and object manipulation.\nExperimental results suggest our approach achieves comparable performance to\ncurrently published SOTA methods and can avoid large decay from seen scenarios\nto unseen scenarios.", "published": "2022-03-09 10:47:10", "link": "http://arxiv.org/abs/2203.04637v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ASET: Ad-hoc Structured Exploration of Text Collections [Extended\n  Abstract]", "abstract": "In this paper, we propose a new system called ASET that allows users to\nperform structured explorations of text collections in an ad-hoc manner. The\nmain idea of ASET is to use a new two-phase approach that first extracts a\nsuperset of information nuggets from the texts using existing extractors such\nas named entity recognizers and then matches the extractions to a structured\ntable definition as requested by the user based on embeddings. In our\nevaluation, we show that ASET is thus able to extract structured data from\nreal-world text collections in high quality without the need to design\nextraction pipelines upfront.", "published": "2022-03-09 12:02:17", "link": "http://arxiv.org/abs/2203.04663v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Enhance Topics Analysis based on Keywords Properties", "abstract": "Topic Modelling is one of the most prevalent text analysis technique used to\nexplore and retrieve collection of documents. The evaluation of the topic model\nalgorithms is still a very challenging tasks due to the absence of\ngold-standard list of topics to compare against for every corpus. In this work,\nwe present a specificity score based on keywords properties that is able to\nselect the most informative topics. This approach helps the user to focus on\nthe most informative topics. In the experiments, we show that we are able to\ncompress the state-of-the-art topic modelling results of different factors with\nan information loss that is much lower than the solution based on the recent\ncoherence score presented in literature.", "published": "2022-03-09 15:10:12", "link": "http://arxiv.org/abs/2203.04786v1", "categories": ["cs.IR", "cs.CL", "H.5; I.7"], "primary_category": "cs.IR"}
{"title": "Efficient Sub-structured Knowledge Distillation", "abstract": "Structured prediction models aim at solving a type of problem where the\noutput is a complex structure, rather than a single variable. Performing\nknowledge distillation for such models is not trivial due to their\nexponentially large output space. In this work, we propose an approach that is\nmuch simpler in its formulation and far more efficient for training than\nexisting approaches. Specifically, we transfer the knowledge from a teacher\nmodel to its student model by locally matching their predictions on all\nsub-structures, instead of the whole output space. In this manner, we avoid\nadopting some time-consuming techniques like dynamic programming (DP) for\ndecoding output structures, which permits parallel computation and makes the\ntraining process even faster in practice. Besides, it encourages the student\nmodel to better mimic the internal behavior of the teacher model. Experiments\non two structured prediction tasks demonstrate that our approach outperforms\nprevious methods and halves the time cost for one training epoch.", "published": "2022-03-09 15:56:49", "link": "http://arxiv.org/abs/2203.04825v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Automatic Language Identification for Celtic Texts", "abstract": "Language identification is an important Natural Language Processing task. It\nhas been thoroughly researched in the literature. However, some issues are\nstill open. This work addresses the identification of the related low-resource\nlanguages on the example of the Celtic language family.\n  This work's main goals were: (1) to collect the dataset of three Celtic\nlanguages; (2) to prepare a method to identify the languages from the Celtic\nfamily, i.e. to train a successful classification model; (3) to evaluate the\ninfluence of different feature extraction methods, and explore the\napplicability of the unsupervised models as a feature extraction technique; (4)\nto experiment with the unsupervised feature extraction on a reduced annotated\nset.\n  We collected a new dataset including Irish, Scottish, Welsh and English\nrecords. We tested supervised models such as SVM and neural networks with\ntraditional statistical features alongside the output of clustering,\nautoencoder, and topic modelling methods. The analysis showed that the\nunsupervised features could serve as a valuable extension to the n-gram feature\nvectors. It led to an improvement in performance for more entangled classes.\nThe best model achieved a 98\\% F1 score and 97\\% MCC. The dense neural network\nconsistently outperformed the SVM model.\n  The low-resource languages are also challenging due to the scarcity of\navailable annotated training data. This work evaluated the performance of the\nclassifiers using the unsupervised feature extraction on the reduced labelled\ndataset to handle this issue. The results uncovered that the unsupervised\nfeature vectors are more robust to the labelled set reduction. Therefore, they\nproved to help achieve comparable classification performance with much less\nlabelled data.", "published": "2022-03-09 16:04:13", "link": "http://arxiv.org/abs/2203.04831v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLX-GPT: A Model for Natural Language Explanations in Vision and\n  Vision-Language Tasks", "abstract": "Natural language explanation (NLE) models aim at explaining the\ndecision-making process of a black box system via generating natural language\nsentences which are human-friendly, high-level and fine-grained. Current NLE\nmodels explain the decision-making process of a vision or vision-language model\n(a.k.a., task model), e.g., a VQA model, via a language model (a.k.a.,\nexplanation model), e.g., GPT. Other than the additional memory resources and\ninference time required by the task model, the task and explanation models are\ncompletely independent, which disassociates the explanation from the reasoning\nprocess made to predict the answer. We introduce NLX-GPT, a general, compact\nand faithful language model that can simultaneously predict an answer and\nexplain it. We first conduct pre-training on large scale data of image-caption\npairs for general understanding of images, and then formulate the answer as a\ntext prediction task along with the explanation. Without region proposals nor a\ntask model, our resulting overall framework attains better evaluation scores,\ncontains much less parameters and is 15$\\times$ faster than the current SoA\nmodel. We then address the problem of evaluating the explanations which can be\nin many times generic, data-biased and can come in several forms. We therefore\ndesign 2 new evaluation measures: (1) explain-predict and (2) retrieval-based\nattack, a self-evaluation framework that requires no labels. Code is at:\nhttps://github.com/fawazsammani/nlxgpt.", "published": "2022-03-09 22:57:15", "link": "http://arxiv.org/abs/2203.05081v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Weibo Dataset for the 2022 Russo-Ukrainian Crisis", "abstract": "Online social networks such as Twitter and Weibo play an important role in\nhow people stay informed and exchange reactions. Each crisis encompasses a new\nopportunity to study the portability of models for various tasks (e.g.,\ninformation extraction, complex event understanding, misinformation detection,\netc.), due to differences in domain, entities, and event types. We present the\nRussia-Ukraine Crisis Weibo (RUW) dataset, with over 3.5M user posts and\ncomments in the first release. Our data is available at\nhttps://github.com/yrf1/RussiaUkraine_weibo_dataset.", "published": "2022-03-09 19:06:04", "link": "http://arxiv.org/abs/2203.05967v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Sequential Multi-task Learning with Task Dependency for Appeal Judgment\n  Prediction", "abstract": "Legal Judgment Prediction (LJP) aims to automatically predict judgment\nresults, such as charges, relevant law articles, and the term of penalty. It\nplays a vital role in legal assistant systems and has become a popular research\ntopic in recent years. This paper concerns a worthwhile but not well-studied\nLJP task, Appeal judgment Prediction (AJP), which predicts the judgment of an\nappellate court on an appeal case based on the textual description of case\nfacts and grounds of appeal. There are two significant challenges in practice\nto solve the AJP task. One is how to model the appeal judgment procedure\nappropriately. The other is how to improve the interpretability of the\nprediction results. We propose a Sequential Multi-task Learning Framework with\nTask Dependency for Appeal Judgement Prediction (SMAJudge) to address these\nchallenges. SMAJudge utilizes two sequential components to model the complete\nproceeding from the lower court to the appellate court and employs an attention\nmechanism to make the prediction more explainable, which handles the challenges\nof AJP effectively. Experimental results obtained with a dataset consisting of\nmore than 30K appeal judgment documents have revealed the effectiveness and\nsuperiority of SMAJudge.", "published": "2022-03-09 08:51:13", "link": "http://arxiv.org/abs/2204.07046v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mapping global dynamics of benchmark creation and saturation in\n  artificial intelligence", "abstract": "Benchmarks are crucial to measuring and steering progress in artificial\nintelligence (AI). However, recent studies raised concerns over the state of AI\nbenchmarking, reporting issues such as benchmark overfitting, benchmark\nsaturation and increasing centralization of benchmark dataset creation. To\nfacilitate monitoring of the health of the AI benchmarking ecosystem, we\nintroduce methodologies for creating condensed maps of the global dynamics of\nbenchmark creation and saturation. We curated data for 3765 benchmarks covering\nthe entire domains of computer vision and natural language processing, and show\nthat a large fraction of benchmarks quickly trended towards near-saturation,\nthat many benchmarks fail to find widespread utilization, and that benchmark\nperformance gains for different AI tasks were prone to unforeseen bursts. We\nanalyze attributes associated with benchmark popularity, and conclude that\nfuture benchmarks should emphasize versatility, breadth and real-world utility.", "published": "2022-03-09 09:16:49", "link": "http://arxiv.org/abs/2203.04592v4", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Memory Efficient Continual Learning with Transformers", "abstract": "In many real-world scenarios, data to train machine learning models becomes\navailable over time. Unfortunately, these models struggle to continually learn\nnew concepts without forgetting what has been learnt in the past. This\nphenomenon is known as catastrophic forgetting and it is difficult to prevent\ndue to practical constraints. For instance, the amount of data that can be\nstored or the computational resources that can be used might be limited.\nMoreover, applications increasingly rely on large pre-trained neural networks,\nsuch as pre-trained Transformers, since the resources or data might not be\navailable in sufficiently large quantities to practitioners to train the model\nfrom scratch. In this paper, we devise a method to incrementally train a model\non a sequence of tasks using pre-trained Transformers and extending them with\nAdapters. Different than the existing approaches, our method is able to scale\nto a large number of tasks without significant overhead and allows sharing\ninformation across tasks. On both image and text classification tasks, we\nempirically demonstrate that our method maintains a good predictive performance\nwithout retraining the model or increasing the number of model parameters over\ntime. The resulting model is also significantly faster at inference time\ncompared to Adapter-based state-of-the-art methods.", "published": "2022-03-09 10:57:59", "link": "http://arxiv.org/abs/2203.04640v2", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Pretrained Domain-Specific Language Model for General Information\n  Retrieval Tasks in the AEC Domain", "abstract": "As an essential task for the architecture, engineering, and construction\n(AEC) industry, information retrieval (IR) from unstructured textual data based\non natural language processing (NLP) is gaining increasing attention. Although\nvarious deep learning (DL) models for IR tasks have been investigated in the\nAEC domain, it is still unclear how domain corpora and domain-specific\npretrained DL models can improve performance in various IR tasks. To this end,\nthis work systematically explores the impacts of domain corpora and various\ntransfer learning techniques on the performance of DL models for IR tasks and\nproposes a pretrained domain-specific language model for the AEC domain. First,\nboth in-domain and close-domain corpora are developed. Then, two types of\npretrained models, including traditional wording embedding models and\nBERT-based models, are pretrained based on various domain corpora and transfer\nlearning strategies. Finally, several widely used DL models for IR tasks are\nfurther trained and tested based on various configurations and pretrained\nmodels. The result shows that domain corpora have opposite effects on\ntraditional word embedding models for text classification and named entity\nrecognition tasks but can further improve the performance of BERT-based models\nin all tasks. Meanwhile, BERT-based models dramatically outperform traditional\nmethods in all IR tasks, with maximum improvements of 5.4% and 10.1% in the F1\nscore, respectively. This research contributes to the body of knowledge in two\nways: 1) demonstrating the advantages of domain corpora and pretrained DL\nmodels and 2) opening the first domain-specific dataset and pretrained language\nmodel for the AEC domain, to the best of our knowledge. Thus, this work sheds\nlight on the adoption and application of pretrained models in the AEC domain.", "published": "2022-03-09 14:10:55", "link": "http://arxiv.org/abs/2203.04729v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rethinking Task Sampling for Few-shot Vision-Language Transfer Learning", "abstract": "Despite achieving state-of-the-art zero-shot performance, existing\nvision-language models still fall short of few-shot transfer ability on\ndomain-specific problems. Classical fine-tuning often fails to prevent highly\nexpressive models from exploiting spurious correlations. Although\nmodel-agnostic meta-learning (MAML) presents as a natural alternative for\nfew-shot transfer learning, the expensive computation due to implicit\nsecond-order optimization limits its use on large-scale vision-language models\nsuch as CLIP. While much literature has been devoted to exploring alternative\noptimization strategies, we identify another essential aspect towards effective\nfew-shot transfer learning, task sampling, which is previously only be viewed\nas part of data pre-processing in MAML. To show the impact of task sampling, we\npropose a simple algorithm, Model-Agnostic Multitask Fine-tuning (MAMF), which\ndifferentiates classical fine-tuning only on uniformly sampling multiple tasks.\nDespite its simplicity, we show that MAMF consistently outperforms classical\nfine-tuning on five few-shot vision-language classification tasks. We further\nshow that the effectiveness of the bi-level optimization in MAML is highly\nsensitive to the zero-shot performance of a task in the context of few-shot\nvision-language classification. The goal of this paper is to provide new\ninsights on what makes few-shot learning work, and encourage more research into\ninvestigating better task sampling strategies.", "published": "2022-03-09 17:26:53", "link": "http://arxiv.org/abs/2203.04904v3", "categories": ["cs.MM", "cs.CL", "cs.CV"], "primary_category": "cs.MM"}
{"title": "KPE: Keypoint Pose Encoding for Transformer-based Image Generation", "abstract": "Transformers have recently been shown to generate high quality images from\ntext input. However, the existing method of pose conditioning using skeleton\nimage tokens is computationally inefficient and generate low quality images.\nTherefore we propose a new method; Keypoint Pose Encoding (KPE); KPE is 10\ntimes more memory efficient and over 73% faster at generating high quality\nimages from text input conditioned on the pose. The pose constraint improves\nthe image quality and reduces errors on body extremities such as arms and legs.\nThe additional benefits include invariance to changes in the target image\ndomain and image resolution, making it easily scalable to higher resolution\nimages. We demonstrate the versatility of KPE by generating photorealistic\nmultiperson images derived from the DeepFashion dataset. We also introduce a\nevaluation method People Count Error (PCE) that is effective in detecting error\nin generated human images.", "published": "2022-03-09 17:38:03", "link": "http://arxiv.org/abs/2203.04907v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DUAL: Discrete Spoken Unit Adaptive Learning for Textless Spoken\n  Question Answering", "abstract": "Spoken Question Answering (SQA) is to find the answer from a spoken document\ngiven a question, which is crucial for personal assistants when replying to the\nqueries from the users. Existing SQA methods all rely on Automatic Speech\nRecognition (ASR) transcripts. Not only does ASR need to be trained with\nmassive annotated data that are time and cost-prohibitive to collect for\nlow-resourced languages, but more importantly, very often the answers to the\nquestions include name entities or out-of-vocabulary words that cannot be\nrecognized correctly. Also, ASR aims to minimize recognition errors equally\nover all words, including many function words irrelevant to the SQA task.\nTherefore, SQA without ASR transcripts (textless) is always highly desired,\nalthough known to be very difficult.\n  This work proposes Discrete Spoken Unit Adaptive Learning (DUAL), leveraging\nunlabeled data for pre-training and fine-tuned by the SQA downstream task. The\ntime intervals of spoken answers can be directly predicted from spoken\ndocuments. We also release a new SQA benchmark corpus, NMSQA, for data with\nmore realistic scenarios. We empirically showed that DUAL yields results\ncomparable to those obtained by cascading ASR and text QA model and robust to\nreal-world data. Our code and model will be open-sourced.", "published": "2022-03-09 17:46:22", "link": "http://arxiv.org/abs/2203.04911v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word\n  Speech Recognition", "abstract": "Language model fusion helps smart assistants recognize words which are rare\nin acoustic data but abundant in text-only corpora (typed search logs).\nHowever, such corpora have properties that hinder downstream performance,\nincluding being (1) too large, (2) beset with domain-mismatched content, and\n(3) heavy-headed rather than heavy-tailed (excessively many duplicate search\nqueries such as \"weather\"). We show that three simple strategies for selecting\nlanguage modeling data can dramatically improve rare-word recognition without\nharming overall performance. First, to address the heavy-headedness, we\ndownsample the data according to a soft log function, which tunably reduces\nhigh frequency (head) sentences. Second, to encourage rare-word exposure, we\nexplicitly filter for words rare in the acoustic data. Finally, we tackle\ndomain-mismatch via perplexity-based contrastive selection, filtering for\nexamples matched to the target domain. We down-select a large corpus of web\nsearch queries by a factor of 53x and achieve better LM perplexities than\nwithout down-selection. When shallow-fused with a state-of-the-art, production\nspeech engine, our LM achieves WER reductions of up to 24% relative on\nrare-word sentences (without changing overall WER) compared to a baseline LM\ntrained on the raw corpus. These gains are further validated through favorable\nside-by-side evaluations on live voice search traffic.", "published": "2022-03-09 19:20:03", "link": "http://arxiv.org/abs/2203.05008v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "HealthPrompt: A Zero-shot Learning Paradigm for Clinical Natural\n  Language Processing", "abstract": "Deep learning algorithms are dependent on the availability of large-scale\nannotated clinical text datasets. The lack of such publicly available datasets\nis the biggest bottleneck for the development of clinical Natural Language\nProcessing(NLP) systems. Zero-Shot Learning(ZSL) refers to the use of deep\nlearning models to classify instances from new classes of which no training\ndata have been seen before. Prompt-based learning is an emerging ZSL technique\nwhere we define task-based templates for NLP tasks. We developed a novel\nprompt-based clinical NLP framework called HealthPrompt and applied the\nparadigm of prompt-based learning on clinical texts. In this technique, rather\nthan fine-tuning a Pre-trained Language Model(PLM), the task definitions are\ntuned by defining a prompt template. We performed an in-depth analysis of\nHealthPrompt on six different PLMs in a no-data setting. Our experiments prove\nthat prompts effectively capture the context of clinical texts and perform\nremarkably well without any training data.", "published": "2022-03-09 21:44:28", "link": "http://arxiv.org/abs/2203.05061v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Language Adaptive Cross-lingual Speech Representation Learning with\n  Sparse Sharing Sub-networks", "abstract": "Unsupervised cross-lingual speech representation learning (XLSR) has recently\nshown promising results in speech recognition by leveraging vast amounts of\nunlabeled data across multiple languages. However, standard XLSR model suffers\nfrom language interference problem due to the lack of language specific\nmodeling ability. In this work, we investigate language adaptive training on\nXLSR models. More importantly, we propose a novel language adaptive\npre-training approach based on sparse sharing sub-networks. It makes room for\nlanguage specific modeling by pruning out unimportant parameters for each\nlanguage, without requiring any manually designed language specific component.\nAfter pruning, each language only maintains a sparse sub-network, while the\nsub-networks are partially shared with each other. Experimental results on a\ndownstream multilingual speech recognition task show that our proposed method\nsignificantly outperforms baseline XLSR models on both high resource and low\nresource languages. Besides, our proposed method consistently outperforms other\nadaptation methods and requires fewer parameters.", "published": "2022-03-09 09:01:32", "link": "http://arxiv.org/abs/2203.04583v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A practical framework for multi-domain speech recognition and an\n  instance sampling method to neural language modeling", "abstract": "Automatic speech recognition (ASR) systems used on smart phones or vehicles\nare usually required to process speech queries from very different domains. In\nsuch situations, a vanilla ASR system usually fails to perform well on every\ndomain. This paper proposes a multi-domain ASR framework for Tencent Map, a\nnavigation app used on smart phones and in-vehicle infotainment systems. The\nproposed framework consists of three core parts: a basic ASR module to generate\nn-best lists of a speech query, a text classification module to determine which\ndomain the speech query belongs to, and a reranking module to rescore n-best\nlists using domain-specific language models. In addition, an instance sampling\nbased method to training neural network language models (NNLMs) is proposed to\naddress the data imbalance problem in multi-domain ASR. In experiments, the\nproposed framework was evaluated on navigation domain and music domain, since\nnavigating and playing music are two main features of Tencent Map. Compared to\na general ASR system, the proposed framework achieves a relative 13% $\\sim$ 22%\ncharacter error rate reduction on several test sets collected from Tencent Map\nand our in-car voice assistant.", "published": "2022-03-09 14:33:42", "link": "http://arxiv.org/abs/2203.04767v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An Environmental Feature Representation in I-vector Space for Room\n  Verification and Metadata Estimation", "abstract": "This paper investigates the application of environmental feature\nrepresentations for room verification tasks and acoustic meta-data estimation.\nAudio recordings contain both speaker and non-speaker information. We refer to\nthe non-speaker-related information, including channel and other environmental\nfactors, as e-vectors. I-vectors, commonly used in speaker identification, are\nextracted in the total variability space and capture both speaker and\nchannel-environment information without discrimination. Accordingly, e-vectors\ncan be extracted from i-vectors using methods such as linear discriminant\nanalysis. In this paper, we first demonstrate that e-vectors can be\nsuccessfully applied to room verification tasks with a low equal error rate.\nSecond, we propose two methods for estimating metadata information --\nsignal-to-noise (SNR) and reverberation (T60) -- from these e-vectors. When\ncomparing our system to contemporary global SNR estimation methods, in terms of\naccuracy, we perform favorably even with low dimensional i-vectors. Lastly, we\nshow that room verification tasks can be improved if e-vectors are augmented\nwith the extracted metadata information.", "published": "2022-03-09 16:55:45", "link": "http://arxiv.org/abs/2203.04880v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An error correction scheme for improved air-tissue boundary in real-time\n  MRI video for speech production", "abstract": "The best performance in Air-tissue boundary (ATB) segmentation of real-time\nMagnetic Resonance Imaging (rtMRI) videos in speech production is known to be\nachieved by a 3-dimensional convolutional neural network (3D-CNN) model.\nHowever, the evaluation of this model, as well as other ATB segmentation\ntechniques reported in the literature, is done using Dynamic Time Warping (DTW)\ndistance between the entire original and predicted contours. Such an evaluation\nmeasure may not capture local errors in the predicted contour. Careful analysis\nof predicted contours reveals errors in regions like the velum part of contour1\n(ATB comprising of upper lip, hard palate, and velum) and tongue base section\nof contour2 (ATB covering jawline, lower lip, tongue base, and epiglottis),\nwhich are not captured in a global evaluation metric like DTW distance. In this\nwork, we automatically detect such errors and propose a correction scheme for\nthe same. We also propose two new evaluation metrics for ATB segmentation\nseparately in contour1 and contour2 to explicitly capture two types of errors\nin these contours. The proposed detection and correction strategies result in\nan improvement of these two evaluation metrics by 61.8% and 61.4% for contour1\nand by 67.8% and 28.4% for contour2. Traditional DTW distance, on the other\nhand, improves by 44.6% for contour1 and 4.0% for contour2.", "published": "2022-03-09 03:17:24", "link": "http://arxiv.org/abs/2203.06004v1", "categories": ["cs.CV", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Speaker Identification Experiments Under Gender De-Identification", "abstract": "The present work is based on the COST Action IC1206 for De-identification in\nmultimedia content. It was performed to test four algorithms of voice\nmodifications on a speech gender recognizer to find the degree of modification\nof pitch when the speech recognizer have the probability of success equal to\nthe probability of failure. The purpose of this analysis is to assess the\nintensity of the speech tone modification, the quality, the reversibility and\nnot-reversibility of the changes made. Keywords DeIdentification; Speech\nAlgorithms", "published": "2022-03-09 10:47:23", "link": "http://arxiv.org/abs/2203.04638v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust Federated Learning Against Adversarial Attacks for Speech Emotion\n  Recognition", "abstract": "Due to the development of machine learning and speech processing, speech\nemotion recognition has been a popular research topic in recent years. However,\nthe speech data cannot be protected when it is uploaded and processed on\nservers in the internet-of-things applications of speech emotion recognition.\nFurthermore, deep neural networks have proven to be vulnerable to\nhuman-indistinguishable adversarial perturbations. The adversarial attacks\ngenerated from the perturbations may result in deep neural networks wrongly\npredicting the emotional states. We propose a novel federated adversarial\nlearning framework for protecting both data and deep neural networks. The\nproposed framework consists of i) federated learning for data privacy, and ii)\nadversarial training at the training stage and randomisation at the testing\nstage for model robustness. The experiments show that our proposed framework\ncan effectively protect the speech data locally and improve the model\nrobustness against a series of adversarial attacks.", "published": "2022-03-09 13:19:26", "link": "http://arxiv.org/abs/2203.04696v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Convolutional Neural Network for Roadway Incident Surveillance\n  Using Audio Data", "abstract": "Crash events identification and prediction plays a vital role in\nunderstanding safety conditions for transportation systems. While existing\nsystems use traffic parameters correlated with crash data to classify and train\nthese models, we propose the use of a novel sensory unit that can also\naccurately identify crash events: microphone. Audio events can be collected and\nanalyzed to classify events such as crash. In this paper, we have demonstrated\nthe use of a deep Convolutional Neural Network (CNN) for road event\nclassification. Important audio parameters such as Mel Frequency Cepstral\nCoefficients (MFCC), log Mel-filterbank energy spectrum and Fourier Spectrum\nwere used as feature set. Additionally, the dataset was augmented with more\nsample data by the use of audio augmentation techniques such as time and pitch\nshifting. Together with the feature extraction this data augmentation can\nachieve reasonable accuracy. Four events such as crash, tire skid, horn and\nsiren sounds can be accurately identified giving indication of a road hazard\nthat can be useful for traffic operators or paramedics. The proposed\nmethodology can reach accuracy up to 94%. Such audio systems can be implemented\nas a part of an Internet of Things (IoT) platform that can complement\nvideo-based sensors without complete coverage.", "published": "2022-03-09 13:42:56", "link": "http://arxiv.org/abs/2203.06059v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
