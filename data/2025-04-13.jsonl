{"title": "Integrated GARCH-GRU in Financial Volatility Forecasting", "abstract": "In this study, we propose a novel integrated Generalized Autoregressive\nConditional Heteroskedasticity-Gated Recurrent Unit (GARCH-GRU) model for\nfinancial volatility modeling and forecasting. The model embeds the GARCH(1,1)\nformulation directly into the GRU cell architecture, yielding a unified\nrecurrent unit that jointly captures both traditional econometric properties\nand complex temporal dynamics. This hybrid structure leverages the strengths of\nGARCH in modeling key stylized facts of financial volatility, such as\nclustering and persistence, while utilizing the GRU's capacity to learn\nnonlinear dependencies from sequential data. Compared to the GARCH-LSTM\ncounterpart, the GARCH-GRU model demonstrates superior computational\nefficiency, requiring significantly less training time, while maintaining and\nimproving forecasting accuracy. Empirical evaluation across multiple financial\ndatasets confirms the model's robust outperformance in terms of mean squared\nerror (MSE) and mean absolute error (MAE) relative to a range of benchmarks,\nincluding standard neural networks, alternative hybrid architectures, and\nclassical GARCH-type models. As an application, we compute Value-at-Risk (VaR)\nusing the model's volatility forecasts and observe lower violation ratios,\nfurther validating the predictive reliability of the proposed framework in\npractical risk management settings.", "published": "2025-04-13 00:04:15", "link": "http://arxiv.org/abs/2504.09380v1", "categories": ["q-fin.ST", "q-fin.RM"], "primary_category": "q-fin.ST"}
{"title": "Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, but their\ndevelopment has primarily focused on English and other high-resource languages,\nleaving many languages underserved. We present our latest Hindi-English\nbi-lingual LLM \\textbf{Mantra-14B} with ~3\\% average improvement in benchmark\nscores over both languages, outperforming models twice its size. Using a\ncurated dataset composed of English and Hindi instruction data of 485K samples,\nwe instruction tuned models such as Qwen-2.5-14B-Instruct and Phi-4 to improve\nperformance over both English and Hindi. Our experiments encompassing seven\ndifferent LLMs of varying parameter sizes and over 140 training attempts with\nvarying English-Hindi training data ratios demonstrated that it is possible to\nsignificantly improve multilingual performance without compromising native\nperformance. Further, our approach avoids resource-intensive techniques like\nvocabulary expansion or architectural modifications, thus keeping the model\nsize small. Our results indicate that modest fine-tuning with culturally and\nlocally informed data can bridge performance gaps without incurring significant\ncomputational overhead. We release our training code, datasets, and models\nunder mit and apache licenses to aid further research towards under-represented\nand low-resource languages.", "published": "2025-04-13 23:10:13", "link": "http://arxiv.org/abs/2504.09753v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can LLM feedback enhance review quality? A randomized study of 20K reviews at ICLR 2025", "abstract": "Peer review at AI conferences is stressed by rapidly rising submission\nvolumes, leading to deteriorating review quality and increased author\ndissatisfaction. To address these issues, we developed Review Feedback Agent, a\nsystem leveraging multiple large language models (LLMs) to improve review\nclarity and actionability by providing automated feedback on vague comments,\ncontent misunderstandings, and unprofessional remarks to reviewers. Implemented\nat ICLR 2025 as a large randomized control study, our system provided optional\nfeedback to more than 20,000 randomly selected reviews. To ensure high-quality\nfeedback for reviewers at this scale, we also developed a suite of automated\nreliability tests powered by LLMs that acted as guardrails to ensure feedback\nquality, with feedback only being sent to reviewers if it passed all the tests.\nThe results show that 27% of reviewers who received feedback updated their\nreviews, and over 12,000 feedback suggestions from the agent were incorporated\nby those reviewers. This suggests that many reviewers found the AI-generated\nfeedback sufficiently helpful to merit updating their reviews. Incorporating AI\nfeedback led to significantly longer reviews (an average increase of 80 words\namong those who updated after receiving feedback) and more informative reviews,\nas evaluated by blinded researchers. Moreover, reviewers who were selected to\nreceive AI feedback were also more engaged during paper rebuttals, as seen in\nlonger author-reviewer discussions. This work demonstrates that carefully\ndesigned LLM-generated review feedback can enhance peer review quality by\nmaking reviews more specific and actionable while increasing engagement between\nreviewers and authors. The Review Feedback Agent is publicly available at\nhttps://github.com/zou-group/review_feedback_agent.", "published": "2025-04-13 22:01:25", "link": "http://arxiv.org/abs/2504.09737v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "AgentA/B: Automated and Scalable Web A/BTesting with Interactive LLM Agents", "abstract": "A/B testing experiment is a widely adopted method for evaluating UI/UX design\ndecisions in modern web applications. Yet, traditional A/B testing remains\nconstrained by its dependence on the large-scale and live traffic of human\nparticipants, and the long time of waiting for the testing result. Through\nformative interviews with six experienced industry practitioners, we identified\ncritical bottlenecks in current A/B testing workflows. In response, we present\nAgentA/B, a novel system that leverages Large Language Model-based autonomous\nagents (LLM Agents) to automatically simulate user interaction behaviors with\nreal webpages. AgentA/B enables scalable deployment of LLM agents with diverse\npersonas, each capable of navigating the dynamic webpage and interactively\nexecuting multi-step interactions like search, clicking, filtering, and\npurchasing. In a demonstrative controlled experiment, we employ AgentA/B to\nsimulate a between-subject A/B testing with 1,000 LLM agents Amazon.com, and\ncompare agent behaviors with real human shopping behaviors at a scale. Our\nfindings suggest AgentA/B can emulate human-like behavior patterns.", "published": "2025-04-13 21:10:56", "link": "http://arxiv.org/abs/2504.09723v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Evaluating the Quality of Benchmark Datasets for Low-Resource Languages: A Case Study on Turkish", "abstract": "The reliance on translated or adapted datasets from English or multilingual\nresources introduces challenges regarding linguistic and cultural suitability.\nThis study addresses the need for robust and culturally appropriate benchmarks\nby evaluating the quality of 17 commonly used Turkish benchmark datasets. Using\na comprehensive framework that assesses six criteria, both human and LLM-judge\nannotators provide detailed evaluations to identify dataset strengths and\nshortcomings.\n  Our results reveal that 70% of the benchmark datasets fail to meet our\nheuristic quality standards. The correctness of the usage of technical terms is\nthe strongest criterion, but 85% of the criteria are not satisfied in the\nexamined datasets. Although LLM judges demonstrate potential, they are less\neffective than human annotators, particularly in understanding cultural common\nsense knowledge and interpreting fluent, unambiguous text. GPT-4o has stronger\nlabeling capabilities for grammatical and technical tasks, while Llama3.3-70B\nexcels at correctness and cultural knowledge evaluation. Our findings emphasize\nthe urgent need for more rigorous quality control in creating and adapting\ndatasets for low-resource languages.", "published": "2025-04-13 20:45:49", "link": "http://arxiv.org/abs/2504.09714v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DUMP: Automated Distribution-Level Curriculum Learning for RL-based LLM Post-training", "abstract": "Recent advances in reinforcement learning (RL)-based post-training have led\nto notable improvements in large language models (LLMs), particularly in\nenhancing their reasoning capabilities to handle complex tasks. However, most\nexisting methods treat the training data as a unified whole, overlooking the\nfact that modern LLM training often involves a mixture of data from diverse\ndistributions-varying in both source and difficulty. This heterogeneity\nintroduces a key challenge: how to adaptively schedule training across\ndistributions to optimize learning efficiency. In this paper, we present a\nprincipled curriculum learning framework grounded in the notion of\ndistribution-level learnability. Our core insight is that the magnitude of\npolicy advantages reflects how much a model can still benefit from further\ntraining on a given distribution. Based on this, we propose a\ndistribution-level curriculum learning framework for RL-based LLM\npost-training, which leverages the Upper Confidence Bound (UCB) principle to\ndynamically adjust sampling probabilities for different distrubutions. This\napproach prioritizes distributions with either high average advantage\n(exploitation) or low sample count (exploration), yielding an adaptive and\ntheoretically grounded training schedule. We instantiate our curriculum\nlearning framework with GRPO as the underlying RL algorithm and demonstrate its\neffectiveness on logic reasoning datasets with multiple difficulties and\nsources. Our experiments show that our framework significantly improves\nconvergence speed and final performance, highlighting the value of\ndistribution-aware curriculum strategies in LLM post-training. Code:\nhttps://github.com/ZhentingWang/DUMP.", "published": "2025-04-13 20:10:27", "link": "http://arxiv.org/abs/2504.09710v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GRPO-LEAD: A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models", "abstract": "Recent advances in R1-like reasoning models leveraging Group Relative Policy\nOptimization (GRPO) have significantly improved the performance of language\nmodels on mathematical reasoning tasks. However, current GRPO implementations\nencounter critical challenges, including reward sparsity due to binary accuracy\nmetrics, limited incentives for conciseness, and insufficient focus on complex\nreasoning tasks. To address these issues, we propose GRPO-LEAD, a suite of\nnovel enhancements tailored for mathematical reasoning. Specifically, GRPO-LEAD\nintroduces (1) a length-dependent accuracy reward to encourage concise and\nprecise solutions, (2) an explicit penalty mechanism for incorrect answers to\nsharpen decision boundaries, and (3) a difficulty-aware advantage reweighting\nstrategy that amplifies learning signals for challenging problems. Furthermore,\nwe systematically examine the impact of model scale and supervised fine-tuning\n(SFT) strategies, demonstrating that larger-scale base models and carefully\ncurated datasets significantly enhance reinforcement learning effectiveness.\nExtensive empirical evaluations and ablation studies confirm that GRPO-LEAD\nsubstantially mitigates previous shortcomings, resulting in language models\nthat produce more concise, accurate, and robust reasoning across diverse\nmathematical tasks.", "published": "2025-04-13 19:07:45", "link": "http://arxiv.org/abs/2504.09696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety", "abstract": "The rise of LLM-driven AI characters raises safety concerns, particularly for\nvulnerable human users with psychological disorders. To address these risks, we\npropose EmoAgent, a multi-agent AI framework designed to evaluate and mitigate\nmental health hazards in human-AI interactions. EmoAgent comprises two\ncomponents: EmoEval simulates virtual users, including those portraying\nmentally vulnerable individuals, to assess mental health changes before and\nafter interactions with AI characters. It uses clinically proven psychological\nand psychiatric assessment tools (PHQ-9, PDI, PANSS) to evaluate mental risks\ninduced by LLM. EmoGuard serves as an intermediary, monitoring users' mental\nstatus, predicting potential harm, and providing corrective feedback to\nmitigate risks. Experiments conducted in popular character-based chatbots show\nthat emotionally engaging dialogues can lead to psychological deterioration in\nvulnerable users, with mental state deterioration in more than 34.4% of the\nsimulations. EmoGuard significantly reduces these deterioration rates,\nunderscoring its role in ensuring safer AI-human interactions. Our code is\navailable at: https://github.com/1akaman/EmoAgent", "published": "2025-04-13 18:47:22", "link": "http://arxiv.org/abs/2504.09689v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Domain-Adaptive Continued Pre-Training of Small Language Models", "abstract": "Continued pre-training of small language models offers a promising path for\ndomain adaptation with limited computational resources. I've investigated this\napproach within educational domains, evaluating it as a resource-efficient\nalternative to training models from scratch. Using a 125M parameter model, I\ndemonstrate significant performance improvements through incremental training\non 400 million tokens, followed by further training to reach 1 billion tokens.\nMy approach includes comprehensive data preprocessing, memory-optimized\ntraining configurations, and benchmark-based evaluation. Results show notable\ngains in knowledge-intensive tasks (MMLU +8.1%) and contextual understanding\n(HellaSwag +7.6%), while revealing educational domain specialization\ntrade-offs. I analyze token efficiency, catastrophic forgetting mitigation\nstrategies, and scaling patterns. My findings suggest that thoughtful\npreprocessing and training methodologies enable meaningful improvements in\nlanguage model capabilities even with constrained computational resources,\nopening pathways for domain-specific adaptation of smaller language models.", "published": "2025-04-13 18:40:32", "link": "http://arxiv.org/abs/2504.09687v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CLEAR-KGQA: Clarification-Enhanced Ambiguity Resolution for Knowledge Graph Question Answering", "abstract": "This study addresses the challenge of ambiguity in knowledge graph question\nanswering (KGQA). While recent KGQA systems have made significant progress,\nparticularly with the integration of large language models (LLMs), they\ntypically assume user queries are unambiguous, which is an assumption that\nrarely holds in real-world applications. To address these limitations, we\npropose a novel framework that dynamically handles both entity ambiguity (e.g.,\ndistinguishing between entities with similar names) and intent ambiguity (e.g.,\nclarifying different interpretations of user queries) through interactive\nclarification. Our approach employs a Bayesian inference mechanism to quantify\nquery ambiguity and guide LLMs in determining when and how to request\nclarification from users within a multi-turn dialogue framework. We further\ndevelop a two-agent interaction framework where an LLM-based user simulator\nenables iterative refinement of logical forms through simulated user feedback.\nExperimental results on the WebQSP and CWQ dataset demonstrate that our method\nsignificantly improves performance by effectively resolving semantic\nambiguities. Additionally, we contribute a refined dataset of disambiguated\nqueries, derived from interaction histories, to facilitate future research in\nthis direction.", "published": "2025-04-13 17:34:35", "link": "http://arxiv.org/abs/2504.09665v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Myanmar XNLI: Building a Dataset and Exploring Low-resource Approaches to Natural Language Inference with Myanmar", "abstract": "Despite dramatic recent progress in NLP, it is still a major challenge to\napply Large Language Models (LLM) to low-resource languages. This is made\nvisible in benchmarks such as Cross-Lingual Natural Language Inference (XNLI),\na key task that demonstrates cross-lingual capabilities of NLP systems across a\nset of 15 languages. In this paper, we extend the XNLI task for one additional\nlow-resource language, Myanmar, as a proxy challenge for broader low-resource\nlanguages, and make three core contributions. First, we build a dataset called\nMyanmar XNLI (myXNLI) using community crowd-sourced methods, as an extension to\nthe existing XNLI corpus. This involves a two-stage process of community-based\nconstruction followed by expert verification; through an analysis, we\ndemonstrate and quantify the value of the expert verification stage in the\ncontext of community-based construction for low-resource languages. We make the\nmyXNLI dataset available to the community for future research. Second, we carry\nout evaluations of recent multilingual language models on the myXNLI benchmark,\nas well as explore data-augmentation methods to improve model performance. Our\ndata-augmentation methods improve model accuracy by up to 2 percentage points\nfor Myanmar, while uplifting other languages at the same time. Third, we\ninvestigate how well these data-augmentation methods generalise to other\nlow-resource languages in the XNLI dataset.", "published": "2025-04-13 16:36:59", "link": "http://arxiv.org/abs/2504.09645v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Iterative Self-Training for Code Generation via Reinforced Re-Ranking", "abstract": "Generating high-quality code that solves complex programming tasks is\nchallenging, especially with current decoder-based models that produce highly\nstochastic outputs. In code generation, even minor errors can easily break the\nentire solution. Leveraging multiple sampled solutions can significantly\nimprove the overall output quality.\n  One effective way to enhance code generation is by pairing a code generation\nmodel with a reranker model, which selects the best solution from the generated\nsamples. We propose a novel iterative self-training approach for self-training\nreranker models using Proximal Policy Optimization (PPO), aimed at improving\nboth reranking accuracy and the overall code generation process. Unlike\ntraditional PPO approaches, where the focus is on optimizing a generative model\nwith a reward model, our approach emphasizes the development of a robust\nreward/reranking model. This model improves the quality of generated code\nthrough reranking and addresses problems and errors that the reward model might\noverlook during PPO alignment with the reranker. Our method iteratively refines\nthe training dataset by re-evaluating outputs, identifying high-scoring\nnegative examples, and incorporating them into the training loop, that boosting\nmodel performance.\n  Our evaluation on the MultiPL-E dataset demonstrates that our 13.4B parameter\nmodel outperforms a 33B model in code generation quality while being three\ntimes faster. Moreover, it achieves performance comparable to GPT-4 and\nsurpasses it in one programming language.", "published": "2025-04-13 16:34:17", "link": "http://arxiv.org/abs/2504.09643v1", "categories": ["cs.CL", "cs.IR", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Leveraging Reasoning Model Answers to Enhance Non-Reasoning Model Capability", "abstract": "Recent advancements in large language models (LLMs), such as DeepSeek-R1 and\nOpenAI-o1, have demonstrated the significant effectiveness of test-time\nscaling, achieving substantial performance gains across various benchmarks.\nThese advanced models utilize deliberate \"thinking\" steps to systematically\nenhance answer quality. In this paper, we propose leveraging these high-quality\noutputs generated by reasoning-intensive models to improve less computationally\ndemanding, non-reasoning models. We explore and compare methodologies for\nutilizing the answers produced by reasoning models to train and improve\nnon-reasoning models. Through straightforward Supervised Fine-Tuning (SFT)\nexperiments on established benchmarks, we demonstrate consistent improvements\nacross various benchmarks, underscoring the potential of this approach for\nadvancing the ability of models to answer questions directly.", "published": "2025-04-13 16:26:56", "link": "http://arxiv.org/abs/2504.09639v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference", "abstract": "We propose the Metropolis-Hastings Captioning Game (MHCG), a method to fuse\nknowledge of multiple vision-language models (VLMs) by learning from each\nother. Although existing methods that combine multiple models suffer from\ninference costs and architectural constraints, MHCG avoids these problems by\nperforming decentralized Bayesian inference through a process resembling a\nlanguage game. The knowledge fusion process establishes communication between\ntwo VLM agents alternately captioning images and learning from each other. We\nconduct two image-captioning experiments with two VLMs, each pre-trained on a\ndifferent dataset. The first experiment demonstrates that MHCG achieves\nconsistent improvement in reference-free evaluation metrics. The second\nexperiment investigates how MHCG contributes to sharing VLMs' category-level\nvocabulary by observing the occurrence of the vocabulary in the generated\ncaptions.", "published": "2025-04-13 15:28:09", "link": "http://arxiv.org/abs/2504.09620v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Fine-tuning an Large Language Model for Automating Computational Fluid Dynamics Simulations", "abstract": "Configuring computational fluid dynamics (CFD) simulations typically demands\nextensive domain expertise, limiting broader access. Although large language\nmodels (LLMs) have advanced scientific computing, their use in automating CFD\nworkflows is underdeveloped. We introduce a novel approach centered on\ndomain-specific LLM adaptation. By fine-tuning Qwen2.5-7B-Instruct on NL2FOAM,\nour custom dataset of 28716 natural language-to-OpenFOAM configuration pairs\nwith chain-of-thought (CoT) annotations, we enable direct translation from\nnatural language descriptions to executable CFD setups. A multi-agent framework\norchestrates the process, autonomously verifying inputs, generating\nconfigurations, running simulations, and correcting errors. Evaluation on a\nbenchmark of 21 diverse flow cases demonstrates state-of-the-art performance,\nachieving 88.7% solution accuracy and 82.6% first-attempt success rate. This\nsignificantly outperforms larger general-purpose models like\nQwen2.5-72B-Instruct, DeepSeek-R1, and Llama3.3-70B-Instruct, while also\nrequiring fewer correction iterations and maintaining high computational\nefficiency. The results highlight the critical role of domain-specific\nadaptation in deploying LLM assistants for complex engineering workflows.", "published": "2025-04-13 14:35:30", "link": "http://arxiv.org/abs/2504.09602v1", "categories": ["physics.flu-dyn", "cs.AI", "cs.CL"], "primary_category": "physics.flu-dyn"}
{"title": "Short-Path Prompting in LLMs: Analyzing Reasoning Instability and Solutions for Robust Performance", "abstract": "Recent years have witnessed significant progress in large language models'\n(LLMs) reasoning, which is largely due to the chain-of-thought (CoT)\napproaches, allowing models to generate intermediate reasoning steps before\nreaching the final answer. Building on these advances, state-of-the-art LLMs\nare instruction-tuned to provide long and detailed CoT pathways when responding\nto reasoning-related questions. However, human beings are naturally cognitive\nmisers and will prompt language models to give rather short responses, thus\nraising a significant conflict with CoT reasoning. In this paper, we delve into\nhow LLMs' reasoning performance changes when users provide short-path prompts.\nThe results and analysis reveal that language models can reason effectively and\nrobustly without explicit CoT prompts, while under short-path prompting, LLMs'\nreasoning ability drops significantly and becomes unstable, even on\ngrade-school problems. To address this issue, we propose two approaches: an\ninstruction-guided approach and a fine-tuning approach, both designed to\neffectively manage the conflict. Experimental results show that both methods\nachieve high accuracy, providing insights into the trade-off between\ninstruction adherence and reasoning accuracy in current models.", "published": "2025-04-13 14:12:14", "link": "http://arxiv.org/abs/2504.09586v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reduction of Supervision for Biomedical Knowledge Discovery", "abstract": "Knowledge discovery is hindered by the increasing volume of publications and\nthe scarcity of extensive annotated data. To tackle the challenge of\ninformation overload, it is essential to employ automated methods for knowledge\nextraction and processing. Finding the right balance between the level of\nsupervision and the effectiveness of models poses a significant challenge.\nWhile supervised techniques generally result in better performance, they have\nthe major drawback of demanding labeled data. This requirement is\nlabor-intensive and time-consuming and hinders scalability when exploring new\ndomains. In this context, our study addresses the challenge of identifying\nsemantic relationships between biomedical entities (e.g., diseases, proteins)\nin unstructured text while minimizing dependency on supervision. We introduce a\nsuite of unsupervised algorithms based on dependency trees and attention\nmechanisms and employ a range of pointwise binary classification methods.\nTransitioning from weakly supervised to fully unsupervised settings, we assess\nthe methods' ability to learn from data with noisy labels. The evaluation on\nbiomedical benchmark datasets explores the effectiveness of the methods. Our\napproach tackles a central issue in knowledge discovery: balancing performance\nwith minimal supervision. By gradually decreasing supervision, we assess the\nrobustness of pointwise binary classification techniques in handling noisy\nlabels, revealing their capability to shift from weakly supervised to entirely\nunsupervised scenarios. Comprehensive benchmarking offers insights into the\neffectiveness of these techniques, suggesting an encouraging direction toward\nadaptable knowledge discovery systems, representing progress in creating\ndata-efficient methodologies for extracting useful insights when annotated data\nis limited.", "published": "2025-04-13 14:05:40", "link": "http://arxiv.org/abs/2504.09582v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "LLMs Can Achieve High-quality Simultaneous Machine Translation as Efficiently as Offline", "abstract": "When the complete source sentence is provided, Large Language Models (LLMs)\nperform excellently in offline machine translation even with a simple prompt\n\"Translate the following sentence from [src lang] into [tgt lang]:\". However,\nin many real scenarios, the source tokens arrive in a streaming manner and\nsimultaneous machine translation (SiMT) is required, then the efficiency and\nperformance of decoder-only LLMs are significantly limited by their\nauto-regressive nature. To enable LLMs to achieve high-quality SiMT as\nefficiently as offline translation, we propose a novel paradigm that includes\nconstructing supervised fine-tuning (SFT) data for SiMT, along with new\ntraining and inference strategies. To replicate the token input/output stream\nin SiMT, the source and target tokens are rearranged into an interleaved\nsequence, separated by special tokens according to varying latency\nrequirements. This enables powerful LLMs to learn read and write operations\nadaptively, based on varying latency prompts, while still maintaining efficient\nauto-regressive decoding. Experimental results show that, even with limited SFT\ndata, our approach achieves state-of-the-art performance across various SiMT\nbenchmarks, and preserves the original abilities of offline translation.\nMoreover, our approach generalizes well to document-level SiMT setting without\nrequiring specific fine-tuning, even beyond the offline translation model.", "published": "2025-04-13 13:45:53", "link": "http://arxiv.org/abs/2504.09570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution", "abstract": "Chain-of-Thought (CoT) prompting enhances the reasoning of large language\nmodels (LLMs) by decomposing problems into sequential steps, mimicking human\nlogic and reducing errors. However, complex tasks with vast solution spaces and\nvague constraints often exceed the capacity of a single reasoning chain.\nInspired by Minimal Free Resolution (MFR) in commutative algebra and algebraic\ngeometry, we propose Syzygy of Thoughts (SoT)-a novel framework that extends\nCoT by introducing auxiliary, interrelated reasoning paths. SoT captures deeper\nlogical dependencies, enabling more robust and structured problem-solving. MFR\ndecomposes a module into a sequence of free modules with minimal rank,\nproviding a structured analytical approach to complex systems. This method\nintroduces the concepts of \"Module\", \"Betti numbers\",\"Freeness\", \"Mapping\",\n\"Exactness\" and \"Minimality\", enabling the systematic decomposition of the\noriginal complex problem into logically complete minimal subproblems while\npreserving key problem features and reducing reasoning length. We tested SoT\nacross diverse datasets (e.g., GSM8K, MATH) and models (e.g., GPT-4o-mini,\nQwen2.5), achieving inference accuracy that matches or surpasses mainstream\nCoTs standards. Additionally, by aligning the sampling process with algebraic\nconstraints, our approach enhances the scalability of inference time in LLMs,\nensuring both transparent reasoning and high performance. Our code will be\npublicly available at https://github.com/dlMARiA/Syzygy-of-thoughts.", "published": "2025-04-13 13:35:41", "link": "http://arxiv.org/abs/2504.09566v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How new data permeates LLM knowledge and how to dilute it", "abstract": "Large language models learn and continually learn through the accumulation of\ngradient-based updates, but how individual pieces of new information affect\nexisting knowledge, leading to both beneficial generalization and problematic\nhallucination, remains poorly understood. We demonstrate that when learning new\ninformation, LLMs exhibit a \"priming\" effect: learning a new fact can cause the\nmodel to inappropriately apply that knowledge in unrelated contexts. To\nsystematically study this phenomenon, we introduce \"Outlandish,\" a carefully\ncurated dataset of 1320 diverse text samples designed to probe how new\nknowledge permeates through an LLM's existing knowledge base. Using this\ndataset, we show that the degree of priming after learning new information can\nbe predicted by measuring the token probability of key words before learning.\nThis relationship holds robustly across different model architectures (PALM-2,\nGemma, Llama), sizes, and training stages. Finally, we develop two novel\ntechniques to modulate how new knowledge affects existing model behavior: (1) a\n``stepping-stone'' text augmentation strategy and (2) an ``ignore-k'' update\npruning method. These approaches reduce undesirable priming effects by 50-95\\%\nwhile preserving the model's ability to learn new information. Our findings\nprovide both empirical insights into how LLMs learn and practical tools for\nimproving the specificity of knowledge insertion in language models. Further\nmaterials: https://sunchipsster1.github.io/projects/outlandish/", "published": "2025-04-13 11:25:04", "link": "http://arxiv.org/abs/2504.09522v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs", "abstract": "When applying pre-trained large language models (LLMs) to address anomaly\ndetection tasks, the multivariate time series (MTS) modality of anomaly\ndetection does not align with the text modality of LLMs. Existing methods\nsimply transform the MTS data into multiple univariate time series sequences,\nwhich can cause many problems. This paper introduces MADLLM, a novel\nmultivariate anomaly detection method via pre-trained LLMs. We design a new\ntriple encoding technique to align the MTS modality with the text modality of\nLLMs. Specifically, this technique integrates the traditional patch embedding\nmethod with two novel embedding approaches: Skip Embedding, which alters the\norder of patch processing in traditional methods to help LLMs retain knowledge\nof previous features, and Feature Embedding, which leverages contrastive\nlearning to allow the model to better understand the correlations between\ndifferent features. Experimental results demonstrate that our method\noutperforms state-of-the-art methods in various public anomaly detection\ndatasets.", "published": "2025-04-13 10:07:52", "link": "http://arxiv.org/abs/2504.09504v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Kongzi: A Historical Large Language Model with Fact Enhancement", "abstract": "The capabilities of the latest large language models (LLMs) have been\nextended from pure natural language understanding to complex reasoning tasks.\nHowever, current reasoning models often exhibit factual inaccuracies in longer\nreasoning chains, which poses challenges for historical reasoning and limits\nthe potential of LLMs in complex, knowledge-intensive tasks. Historical studies\nrequire not only the accurate presentation of factual information but also the\nability to establish cross-temporal correlations and derive coherent\nconclusions from fragmentary and often ambiguous sources. To address these\nchallenges, we propose Kongzi, a large language model specifically designed for\nhistorical analysis. Through the integration of curated, high-quality\nhistorical data and a novel fact-reinforcement learning strategy, Kongzi\ndemonstrates strong factual alignment and sophisticated reasoning depth.\nExtensive experiments on tasks such as historical question answering and\nnarrative generation demonstrate that Kongzi outperforms existing models in\nboth factual accuracy and reasoning depth. By effectively addressing the unique\nchallenges inherent in historical texts, Kongzi sets a new standard for the\ndevelopment of accurate and reliable LLMs in professional domains.", "published": "2025-04-13 09:01:05", "link": "http://arxiv.org/abs/2504.09488v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HalluShift: Measuring Distribution Shifts towards Hallucination Detection in LLMs", "abstract": "Large Language Models (LLMs) have recently garnered widespread attention due\nto their adeptness at generating innovative responses to the given prompts\nacross a multitude of domains. However, LLMs often suffer from the inherent\nlimitation of hallucinations and generate incorrect information while\nmaintaining well-structured and coherent responses. In this work, we\nhypothesize that hallucinations stem from the internal dynamics of LLMs. Our\nobservations indicate that, during passage generation, LLMs tend to deviate\nfrom factual accuracy in subtle parts of responses, eventually shifting toward\nmisinformation. This phenomenon bears a resemblance to human cognition, where\nindividuals may hallucinate while maintaining logical coherence, embedding\nuncertainty within minor segments of their speech. To investigate this further,\nwe introduce an innovative approach, HalluShift, designed to analyze the\ndistribution shifts in the internal state space and token probabilities of the\nLLM-generated responses. Our method attains superior performance compared to\nexisting baselines across various benchmark datasets. Our codebase is available\nat https://github.com/sharanya-dasgupta001/hallushift.", "published": "2025-04-13 08:35:22", "link": "http://arxiv.org/abs/2504.09482v1", "categories": ["cs.CL", "cs.AI", "cs.ET"], "primary_category": "cs.CL"}
{"title": "Draw with Thought: Unleashing Multimodal Reasoning for Scientific Diagram Generation", "abstract": "Scientific diagrams are vital tools for communicating structured knowledge\nacross disciplines. However, they are often published as static raster images,\nlosing symbolic semantics and limiting reuse. While Multimodal Large Language\nModels (MLLMs) offer a pathway to bridging vision and structure, existing\nmethods lack semantic control and structural interpretability, especially on\ncomplex diagrams. We propose Draw with Thought (DwT), a training-free framework\nthat guides MLLMs to reconstruct diagrams into editable mxGraph XML code\nthrough cognitively-grounded Chain-of-Thought reasoning. DwT enables\ninterpretable and controllable outputs without model fine-tuning by dividing\nthe task into two stages: Coarse-to-Fine Planning, which handles perceptual\nstructuring and semantic specification, and Structure-Aware Code Generation,\nenhanced by format-guided refinement. To support evaluation, we release\nPlot2XML, a benchmark of 247 real-world scientific diagrams with gold-standard\nXML annotations. Extensive experiments across eight MLLMs show that our\napproach yields high-fidelity, semantically aligned, and structurally valid\nreconstructions, with human evaluations confirming strong alignment in both\naccuracy and visual aesthetics, offering a scalable solution for converting\nstatic visuals into executable representations and advancing machine\nunderstanding of scientific graphics.", "published": "2025-04-13 08:22:09", "link": "http://arxiv.org/abs/2504.09479v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender", "abstract": "Despite extensive efforts in safety alignment, large language models (LLMs)\nremain vulnerable to jailbreak attacks. Activation steering offers a\ntraining-free defense method but relies on fixed steering coefficients,\nresulting in suboptimal protection and increased false rejections of benign\ninputs. To address this, we propose AdaSteer, an adaptive activation steering\nmethod that dynamically adjusts model behavior based on input characteristics.\nWe identify two key properties: Rejection Law (R-Law), which shows that\nstronger steering is needed for jailbreak inputs opposing the rejection\ndirection, and Harmfulness Law (H-Law), which differentiates adversarial and\nbenign inputs. AdaSteer steers input representations along both the Rejection\nDirection (RD) and Harmfulness Direction (HD), with adaptive coefficients\nlearned via logistic regression, ensuring robust jailbreak defense while\npreserving benign input handling. Experiments on LLaMA-3.1, Gemma-2, and\nQwen2.5 show that AdaSteer outperforms baseline methods across multiple\njailbreak attacks with minimal impact on utility. Our results highlight the\npotential of interpretable model internals for real-time, flexible safety\nenforcement in LLMs.", "published": "2025-04-13 07:39:17", "link": "http://arxiv.org/abs/2504.09466v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "BabyVLM: Data-Efficient Pretraining of VLMs Inspired by Infant Learning", "abstract": "Human infants rapidly develop visual reasoning skills from minimal input,\nsuggesting that developmentally inspired pretraining could significantly\nenhance the efficiency of vision-language models (VLMs). Although recent\nefforts have leveraged infant-inspired datasets like SAYCam, existing\nevaluation benchmarks remain misaligned--they are either too simplistic,\nnarrowly scoped, or tailored for large-scale pretrained models. Additionally,\ntraining exclusively on infant data overlooks the broader, diverse input from\nwhich infants naturally learn. To address these limitations, we propose\nBabyVLM, a novel framework comprising comprehensive in-domain evaluation\nbenchmarks and a synthetic training dataset created via child-directed\ntransformations of existing datasets. We demonstrate that VLMs trained with our\nsynthetic dataset achieve superior performance on BabyVLM tasks compared to\nmodels trained solely on SAYCam or general-purpose data of the SAYCam size.\nBabyVLM thus provides a robust, developmentally aligned evaluation tool and\nillustrates how compact models trained on carefully curated data can generalize\neffectively, opening pathways toward data-efficient vision-language learning\nparadigms.", "published": "2025-04-13 04:17:12", "link": "http://arxiv.org/abs/2504.09426v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ClinicalGPT-R1: Pushing reasoning capability of generalist disease diagnosis with large language model", "abstract": "Recent advances in reasoning with large language models (LLMs)has shown\nremarkable reasoning capabilities in domains such as mathematics and coding,\nyet their application to clinical diagnosis remains underexplored. Here, we\nintroduce ClinicalGPT-R1, a reasoning enhanced generalist large language model\nfor disease diagnosis. Trained on a dataset of 20,000 real-world clinical\nrecords, ClinicalGPT-R1 leverages diverse training strategies to enhance\ndiagnostic reasoning. To benchmark performance, we curated MedBench-Hard, a\nchallenging dataset spanning seven major medical specialties and representative\ndiseases. Experimental results demonstrate that ClinicalGPT-R1 outperforms\nGPT-4o in Chinese diagnostic tasks and achieves comparable performance to GPT-4\nin English settings. This comparative study effectively validates the superior\nperformance of ClinicalGPT-R1 in disease diagnosis tasks. Resources are\navailable at https://github.com/medfound/medfound.", "published": "2025-04-13 04:00:40", "link": "http://arxiv.org/abs/2504.09421v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SaRO: Enhancing LLM Safety through Reasoning-based Alignment", "abstract": "Current safety alignment techniques for large language models (LLMs) face two\nkey challenges: (1) under-generalization, which leaves models vulnerable to\nnovel jailbreak attacks, and (2) over-alignment, which leads to the excessive\nrefusal of benign instructions. Our preliminary investigation reveals semantic\noverlap between jailbreak/harmful queries and normal prompts in embedding\nspace, suggesting that more effective safety alignment requires a deeper\nsemantic understanding. This motivates us to incorporate safety-policy-driven\nreasoning into the alignment process. To this end, we propose the\nSafety-oriented Reasoning Optimization Framework (SaRO), which consists of two\nstages: (1) Reasoning-style Warmup (RW) that enables LLMs to internalize\nlong-chain reasoning through supervised fine-tuning, and (2) Safety-oriented\nReasoning Process Optimization (SRPO) that promotes safety reflection via\ndirect preference optimization (DPO). Extensive experiments demonstrate the\nsuperiority of SaRO over traditional alignment methods.", "published": "2025-04-13 03:36:06", "link": "http://arxiv.org/abs/2504.09420v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UXAgent: A System for Simulating Usability Testing of Web Design with LLM Agents", "abstract": "Usability testing is a fundamental research method that user experience (UX)\nresearchers use to evaluate and iterate a web design, but\\textbf{ how to\nevaluate and iterate the usability testing study design } itself? Recent\nadvances in Large Language Model-simulated Agent (\\textbf{LLM Agent}) research\ninspired us to design \\textbf{UXAgent} to support UX researchers in evaluating\nand reiterating their usability testing study design before they conduct the\nreal human-subject study. Our system features a Persona Generator module, an\nLLM Agent module, and a Universal Browser Connector module to automatically\ngenerate thousands of simulated users to interactively test the target website.\nThe system also provides an Agent Interview Interface and a Video Replay\nInterface so that the UX researchers can easily review and analyze the\ngenerated qualitative and quantitative log data. Through a heuristic\nevaluation, five UX researcher participants praised the innovation of our\nsystem but also expressed concerns about the future of LLM Agent usage in UX\nstudies.", "published": "2025-04-13 02:34:22", "link": "http://arxiv.org/abs/2504.09407v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Question Tokens Deserve More Attention: Enhancing Large Language Models without Training through Step-by-Step Reading and Question Attention Recalibration", "abstract": "Large Language Models (LLMs) often struggle with tasks that require a deep\nunderstanding of complex questions, especially when faced with long-range\ndependencies or multi-step reasoning. This work investigates the limitations of\ncurrent LLMs in question comprehension and identifies three insights: (1)\nrepeating question tokens improves comprehension by increasing attention to\nquestion regions, (2) increased backward dependencies negatively affect\nperformance due to unidirectional attentional constraints, and (3)\nrecalibrating attentional mechanisms to prioritize question-relevant regions\nimproves performance.\n  Based on these findings, we first propose a family of prompt-based strategies\n- Step-by-Step Reading (SSR), SSR+, and SSR++ - that guide LLMs to\nincrementally process question tokens and align their reasoning with the input\nstructure. These methods significantly improve performance, with SSR++\nachieving state-of-the-art results on several benchmarks: 96.66% on GSM8K,\n94.61% on ASDiv, and 76.28% on AQuA. Second, we introduce a training-free\nattention recalibration mechanism that dynamically adjusts attention\ndistributions during inference to emphasize question-relevant regions. This\nmethod improves the accuracy of LLaMA 3.1-8B on AQuA by 5.17% without changing\nmodel parameters or input prompts.\n  Taken together, our results highlight the importance of structured prompt\ndesign and attention optimization in improving LLM comprehension, providing\nlightweight yet effective tools for improving performance in various NLP tasks.", "published": "2025-04-13 02:10:18", "link": "http://arxiv.org/abs/2504.09402v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Composable NLP Workflows for BERT-based Ranking and QA System", "abstract": "There has been a lot of progress towards building NLP models that scale to\nmultiple tasks. However, real-world systems contain multiple components and it\nis tedious to handle cross-task interaction with varying levels of text\ngranularity. In this work, we built an end-to-end Ranking and\nQuestion-Answering (QA) system using Forte, a toolkit that makes composable NLP\npipelines. We utilized state-of-the-art deep learning models such as BERT,\nRoBERTa in our pipeline, evaluated the performance on MS-MARCO and Covid-19\ndatasets using metrics such as BLUE, MRR, F1 and compared the results of\nranking and QA systems with their corresponding benchmark results. The modular\nnature of our pipeline and low latency of reranker makes it easy to build\ncomplex NLP applications easily.", "published": "2025-04-13 01:48:13", "link": "http://arxiv.org/abs/2504.09398v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluation Under Imperfect Benchmarks and Ratings: A Case Study in Text Simplification", "abstract": "Despite the successes of language models, their evaluation remains a daunting\nchallenge for new and existing tasks. We consider the task of text\nsimplification, commonly used to improve information accessibility, where\nevaluation faces two major challenges. First, the data in existing benchmarks\nmight not reflect the capabilities of current language models on the task,\noften containing disfluent, incoherent, or simplistic examples. Second,\nexisting human ratings associated with the benchmarks often contain a high\ndegree of disagreement, resulting in inconsistent ratings; nevertheless,\nexisting metrics still have to show higher correlations with these imperfect\nratings. As a result, evaluation for the task is not reliable and does not\nreflect expected trends (e.g., more powerful models being assigned higher\nscores). We address these challenges for the task of text simplification\nthrough three contributions. First, we introduce SynthSimpliEval, a synthetic\nbenchmark for text simplification featuring simplified sentences generated by\nmodels of varying sizes. Through a pilot study, we show that human ratings on\nour benchmark exhibit high inter-annotator agreement and reflect the expected\ntrend: larger models produce higher-quality simplifications. Second, we show\nthat auto-evaluation with a panel of LLM judges (LLMs-as-a-jury) often suffices\nto obtain consistent ratings for the evaluation of text simplification. Third,\nwe demonstrate that existing learnable metrics for text simplification benefit\nfrom training on our LLMs-as-a-jury-rated synthetic data, closing the gap with\npure LLMs-as-a-jury for evaluation. Overall, through our case study on text\nsimplification, we show that a reliable evaluation requires higher quality test\ndata, which could be obtained through synthetic data and LLMs-as-a-jury\nratings.", "published": "2025-04-13 01:36:47", "link": "http://arxiv.org/abs/2504.09394v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Memorization: Mapping the Originality-Quality Frontier of Language Models", "abstract": "As large language models (LLMs) are increasingly used for ideation and\nscientific discovery, it is important to evaluate their ability to generate\nnovel output. Prior work evaluates novelty as the originality with respect to\ntraining data, but original outputs can be low quality. In contrast, non-expert\njudges may favor high-quality but memorized outputs, limiting the reliability\nof human preference as a metric. We propose a new novelty metric for LLM\ngenerations that balances originality and quality -- the harmonic mean of the\nfraction of \\ngrams unseen during training and a task-specific quality score.\nWe evaluate the novelty of generations from two families of open-data models\n(OLMo and Pythia) on three creative tasks: story completion, poetry writing,\nand creative tool use. We find that LLM generated text is less novel than human\nwritten text. To elicit more novel outputs, we experiment with various\ninference-time methods, which reveals a trade-off between originality and\nquality. While these methods can boost novelty, they do so by increasing\noriginality at the expense of quality. In contrast, increasing model size or\napplying post-training reliably shifts the Pareto frontier, highlighting that\nstarting with a stronger base model is a more effective way to improve novelty.", "published": "2025-04-13 00:48:58", "link": "http://arxiv.org/abs/2504.09389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Language Models' Sensitivity to Suspicious Coincidences", "abstract": "Humans are sensitive to suspicious coincidences when generalizing inductively\nover data, as they make assumptions as to how the data was sampled. This\nresults in smaller, more specific hypotheses being favored over more general\nones. For instance, when provided the set {Austin, Dallas, Houston}, one is\nmore likely to think that this is sampled from \"Texas Cities\" over \"US Cities\"\neven though both are compatible. Suspicious coincidence is strongly connected\nto pragmatic reasoning, and can serve as a testbed to analyze systems on their\nsensitivity towards the communicative goals of the task (i.e., figuring out the\ntrue category underlying the data). In this paper, we analyze whether\nsuspicious coincidence effects are reflected in language models' (LMs)\nbehavior. We do so in the context of two domains: 1) the number game, where\nhumans made judgments of whether a number (e.g., 4) fits a list of given\nnumbers (e.g., 16, 32, 2); and 2) by extending the number game setup to\nprominent cities. For both domains, the data is compatible with multiple\nhypotheses and we study which hypothesis is most consistent with the models'\nbehavior. On analyzing five models, we do not find strong evidence for\nsuspicious coincidences in LMs' zero-shot behavior. However, when provided\naccess to the hypotheses space via chain-of-thought or explicit prompting, LMs\nstart to show an effect resembling suspicious coincidences, sometimes even\nshowing effects consistent with humans. Our study suggests that inductive\nreasoning behavior in LMs can be enhanced with explicit access to the\nhypothesis landscape.", "published": "2025-04-13 00:43:06", "link": "http://arxiv.org/abs/2504.09387v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can you map it to English? The Role of Cross-Lingual Alignment in Multilingual Performance of LLMs", "abstract": "Large language models (LLMs) pre-trained predominantly on English text\nexhibit surprising multilingual capabilities, yet the mechanisms driving\ncross-lingual generalization remain poorly understood. This work investigates\nhow the alignment of representations for text written in different languages\ncorrelates with LLM performance on natural language understanding tasks and\ntranslation tasks, both at the language and the instance level. For this\npurpose, we introduce cross-lingual alignment metrics such as the\nDiscriminative Alignment Index (DALI) to quantify the alignment at an instance\nlevel for discriminative tasks. Through experiments on three natural language\nunderstanding tasks (Belebele, XStoryCloze, XCOPA), and machine translation, we\nfind that while cross-lingual alignment metrics strongly correlate with task\naccuracy at the language level, the sample-level alignment often fails to\ndistinguish correct from incorrect predictions, exposing alignment as a\nnecessary but insufficient condition for success.", "published": "2025-04-13 00:01:22", "link": "http://arxiv.org/abs/2504.09378v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Detection of Intro and Credits in Video using CLIP and Multihead Attention", "abstract": "Detecting transitions between intro/credits and main content in videos is a\ncrucial task for content segmentation, indexing, and recommendation systems.\nManual annotation of such transitions is labor-intensive and error-prone, while\nheuristic-based methods often fail to generalize across diverse video styles.\nIn this work, we introduce a deep learning-based approach that formulates the\nproblem as a sequence-to-sequence classification task, where each second of a\nvideo is labeled as either \"intro\" or \"film.\" Our method extracts frames at a\nfixed rate of 1 FPS, encodes them using CLIP (Contrastive Language-Image\nPretraining), and processes the resulting feature representations with a\nmultihead attention model incorporating learned positional encoding. The system\nachieves an F1-score of 91.0%, Precision of 89.0%, and Recall of 97.0% on the\ntest set, and is optimized for real-time inference, achieving 11.5 FPS on CPU\nand 107 FPS on high-end GPUs. This approach has practical applications in\nautomated content indexing, highlight detection, and video summarization.\nFuture work will explore multimodal learning, incorporating audio features and\nsubtitles to further enhance detection accuracy.", "published": "2025-04-13 22:08:18", "link": "http://arxiv.org/abs/2504.09738v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "68T07", "I.2.10; I.4.8; I.5.1"], "primary_category": "cs.CV"}
{"title": "Dynamik: Syntactically-Driven Dynamic Font Sizing for Emphasis of Key Information", "abstract": "In today's globalized world, there are increasing opportunities for\nindividuals to communicate using a common non-native language (lingua franca).\nNon-native speakers often have opportunities to listen to foreign languages,\nbut may not comprehend them as fully as native speakers do. To aid real-time\ncomprehension, live transcription of subtitles is frequently used in everyday\nlife (e.g., during Zoom conversations, watching YouTube videos, or on social\nnetworking sites). However, simultaneously reading subtitles while listening\ncan increase cognitive load. In this study, we propose Dynamik, a system that\nreduces cognitive load during reading by decreasing the size of less important\nwords and enlarging important ones, thereby enhancing sentence contrast. Our\nresults indicate that Dynamik can reduce certain aspects of cognitive load,\nspecifically, participants' perceived performance and effort among individuals\nwith low proficiency in English, as well as enhance the users' sense of\ncomprehension, especially among people with low English ability. We further\ndiscuss our methods' applicability to other languages and potential\nimprovements and further research directions.", "published": "2025-04-13 21:46:11", "link": "http://arxiv.org/abs/2504.09734v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Adapting Robot's Explanation for Failures Based on Observed Human Behavior in Human-Robot Collaboration", "abstract": "This work aims to interpret human behavior to anticipate potential user\nconfusion when a robot provides explanations for failure, allowing the robot to\nadapt its explanations for more natural and efficient collaboration. Using a\ndataset that included facial emotion detection, eye gaze estimation, and\ngestures from 55 participants in a user study, we analyzed how human behavior\nchanged in response to different types of failures and varying explanation\nlevels. Our goal is to assess whether human collaborators are ready to accept\nless detailed explanations without inducing confusion. We formulate a\ndata-driven predictor to predict human confusion during robot failure\nexplanations. We also propose and evaluate a mechanism, based on the predictor,\nto adapt the explanation level according to observed human behavior. The\npromising results from this evaluation indicate the potential of this research\nin adapting a robot's explanations for failures to enhance the collaborative\nexperience.", "published": "2025-04-13 20:49:43", "link": "http://arxiv.org/abs/2504.09717v1", "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "cs.RO"}
{"title": "The Rate-Immediacy Barrier in Explicit Tree Code Constructions", "abstract": "Since the introduction of tree codes by Schulman (STOC 1993), explicit\nconstruction of such codes has remained a notorious challenge. While the\nconstruction of asymptotically-good explicit tree codes continues to be\nelusive, a work by Cohen, Haeupler and Schulman (STOC 2018), as well as the\nstate-of-the-art construction by Ben Yaacov, Cohen, and Yankovitz (STOC 2022)\nhave achieved codes with rate $\\Omega(1/\\log\\log n)$, exponentially improving\nupon the original construction of Evans, Klugerman and Schulman from 1994. All\nof these constructions rely, at least in part, on increasingly sophisticated\nmethods of combining (block) error-correcting codes.\n  In this work, we identify a fundamental barrier to constructing tree codes\nusing current techniques. We introduce a key property, which we call immediacy,\nthat, while not required by the original definition of tree codes, is shared by\nall known constructions and inherently arises from recursive combinations of\nerror-correcting codes. Our main technical contribution is the proof of a\nrate-immediacy tradeoff, which, in particular, implies that any tree code with\nconstant distance and non-trivial immediacy must necessarily have vanishing\nrate. By applying our rate-immediacy tradeoff to existing constructions, we\nestablish that their known rate analyses are essentially optimal. More broadly,\nour work highlights the need for fundamentally new ideas--beyond the recursive\nuse of error-correcting codes--to achieve substantial progress in explicitly\nconstructing asymptotically-good tree codes.", "published": "2025-04-13 00:47:48", "link": "http://arxiv.org/abs/2504.09388v1", "categories": ["cs.IT", "cs.CC", "cs.DM", "math.IT"], "primary_category": "cs.IT"}
{"title": "Outage Probability Analysis for OTFS with Finite Blocklength", "abstract": "Orthogonal time frequency space (OTFS) modulation is widely acknowledged as a\nprospective waveform for future wireless communication networks.To provide\ninsights for the practical system design, this paper analyzes the outage\nprobability of OTFS modulation with finite blocklength.To begin with, we\npresent the system model and formulate the analysis of outage probability for\nOTFS with finite blocklength as an equivalent problem of calculating the outage\nprobability with finite blocklength over parallel additive white Gaussian noise\n(AWGN) channels.Subsequently, we apply the equivalent noise approach to derive\na lower bound on the outage probability of OTFS with finite blocklength under\nboth average power allocation and water-filling power allocation strategies,\nrespectively.Finally, the lower bounds of the outage probability are determined\nusing the Monte-Carlo method for the two power allocation strategies.The impact\nof the number of resolvable paths and coding rates on the outage probability is\nanalyzed, and the simulation results are compared with the theoretical lower\nbounds.", "published": "2025-04-13 15:53:46", "link": "http://arxiv.org/abs/2504.09628v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Slow Thinking for Sequential Recommendation", "abstract": "To develop effective sequential recommender systems, numerous methods have\nbeen proposed to model historical user behaviors. Despite the effectiveness,\nthese methods share the same fast thinking paradigm. That is, for making\nrecommendations, these methods typically encodes user historical interactions\nto obtain user representations and directly match these representations with\ncandidate item representations. However, due to the limited capacity of\ntraditional lightweight recommendation models, this one-step inference paradigm\noften leads to suboptimal performance. To tackle this issue, we present a novel\nslow thinking recommendation model, named STREAM-Rec. Our approach is capable\nof analyzing historical user behavior, generating a multi-step, deliberative\nreasoning process, and ultimately delivering personalized recommendations. In\nparticular, we focus on two key challenges: (1) identifying the suitable\nreasoning patterns in recommender systems, and (2) exploring how to effectively\nstimulate the reasoning capabilities of traditional recommenders. To this end,\nwe introduce a three-stage training framework. In the first stage, the model is\npretrained on large-scale user behavior data to learn behavior patterns and\ncapture long-range dependencies. In the second stage, we design an iterative\ninference algorithm to annotate suitable reasoning traces by progressively\nrefining the model predictions. This annotated data is then used to fine-tune\nthe model. Finally, in the third stage, we apply reinforcement learning to\nfurther enhance the model generalization ability. Extensive experiments\nvalidate the effectiveness of our proposed method.", "published": "2025-04-13 15:53:30", "link": "http://arxiv.org/abs/2504.09627v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Revisiting Self-Attentive Sequential Recommendation", "abstract": "Recommender systems are ubiquitous in on-line services to drive businesses.\nAnd many sequential recommender models were deployed in these systems to\nenhance personalization. The approach of using the transformer decoder as the\nsequential recommender was proposed years ago and is still a strong baseline in\nrecent works. But this kind of sequential recommender model did not scale up\nwell, compared to language models. Quite some details in the classical\nself-attentive sequential recommender model could be revisited, and some new\nexperiments may lead to new findings, without changing the general model\nstructure which was the focus of many previous works. In this paper, we show\nthe details and propose new experiment methodologies for future research on\nsequential recommendation, in hope to motivate further exploration to new\nfindings in this area.", "published": "2025-04-13 14:30:57", "link": "http://arxiv.org/abs/2504.09596v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "HD-RAG: Retrieval-Augmented Generation for Hybrid Documents Containing Text and Hierarchical Tables", "abstract": "With the rapid advancement of large language models (LLMs),\nRetrieval-Augmented Generation (RAG) effectively combines LLMs generative\ncapabilities with external retrieval-based information. The Hybrid Document RAG\ntask aims to integrate textual and hierarchical tabular data for more\ncomprehensive retrieval and generation in complex scenarios. However, there is\nno existing dataset specifically designed for this task that includes both text\nand tabular data. Additionally, existing methods struggle to retrieve relevant\ntabular data and integrate it with text. Semantic similarity-based retrieval\nlacks accuracy, while table-specific methods fail to handle complex\nhierarchical structures effectively. Furthermore, the QA task requires complex\nreasoning and calculations, further complicating the challenge. In this paper,\nwe propose a new large-scale dataset, DocRAGLib, specifically designed for the\nquestion answering (QA) task scenario under Hybrid Document RAG. To tackle\nthese challenges, we introduce HD-RAG, a novel framework that incorporates a\nrow-and-column level (RCL) table representation, employs a two-stage process\ncombining ensemble and LLM-based retrieval, and integrates RECAP, which is\ndesigned for multi-step reasoning and complex calculations in Document-QA\ntasks. We conduct comprehensive experiments with DocRAGLib, showing that HD-RAG\noutperforms existing baselines in both retrieval accuracy and QA performance,\ndemonstrating its effectiveness.", "published": "2025-04-13 13:02:33", "link": "http://arxiv.org/abs/2504.09554v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences", "abstract": "Due to the convenience of mobile devices, the online games have become an\nimportant part for user entertainments in reality, creating a demand for friend\nrecommendation in online games. However, none of existing approaches can\neffectively incorporate the multi-modal user features (\\emph{e.g.}, images and\ntexts) with the structural information in the friendship graph, due to the\nfollowing limitations: (1) some of them ignore the high-order structural\nproximity between users, (2) some fail to learn the pairwise relevance between\nusers at modality-specific level, and (3) some cannot capture both the local\nand global user preferences on different modalities. By addressing these\nissues, in this paper, we propose an end-to-end model \\textsc{FROG} that better\nmodels the user preferences on potential friends. Comprehensive experiments on\nboth offline evaluation and online deployment at \\kw{Tencent} have demonstrated\nthe superiority of \\textsc{FROG} over existing approaches.", "published": "2025-04-13 04:27:10", "link": "http://arxiv.org/abs/2504.09428v1", "categories": ["cs.SI", "cs.AI", "cs.IR"], "primary_category": "cs.SI"}
{"title": "SegOTA: Accelerating Over-the-Air Federated Learning with Segmented Transmission", "abstract": "Federated learning (FL) with over-the-air computation efficiently utilizes\nthe communication resources, but it can still experience significant latency\nwhen each device transmits a large number of model parameters to the server.\nThis paper proposes the Segmented Over-The-Air (SegOTA) method for FL, which\nreduces latency by partitioning devices into groups and letting each group\ntransmit only one segment of the model parameters in each communication round.\nConsidering a multi-antenna server, we model the SegOTA transmission and\nreception process to establish an upper bound on the expected model learning\noptimality gap. We minimize this upper bound, by formulating the per-round\nonline optimization of device grouping and joint transmit-receive beamforming,\nfor which we derive efficient closed-form solutions. Simulation results show\nthat our proposed SegOTA substantially outperforms the conventional full-model\nOTA approach and other common alternatives.", "published": "2025-04-13 22:44:23", "link": "http://arxiv.org/abs/2504.09745v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series Sensing Signals", "abstract": "Standard multimodal self-supervised learning (SSL) algorithms regard\ncross-modal synchronization as implicit supervisory labels during pretraining,\nthus posing high requirements on the scale and quality of multimodal samples.\nThese constraints significantly limit the performance of sensing intelligence\nin IoT applications, as the heterogeneity and the non-interpretability of\ntime-series signals result in abundant unimodal data but scarce high-quality\nmultimodal pairs. This paper proposes InfoMAE, a cross-modal alignment\nframework that tackles the challenge of multimodal pair efficiency under the\nSSL setting by facilitating efficient cross-modal alignment of pretrained\nunimodal representations. InfoMAE achieves \\textit{efficient cross-modal\nalignment} with \\textit{limited data pairs} through a novel information\ntheory-inspired formulation that simultaneously addresses distribution-level\nand instance-level alignment. Extensive experiments on two real-world IoT\napplications are performed to evaluate InfoMAE's pairing efficiency to bridge\npretrained unimodal models into a cohesive joint multimodal model. InfoMAE\nenhances downstream multimodal tasks by over 60% with significantly improved\nmultimodal pairing efficiency. It also improves unimodal task accuracy by an\naverage of 22%.", "published": "2025-04-13 20:03:29", "link": "http://arxiv.org/abs/2504.09707v1", "categories": ["cs.AI", "cs.IT", "cs.LG", "cs.MM", "math.IT"], "primary_category": "cs.AI"}
{"title": "On Stochastic Performance Analysis of Secure Integrated Sensing and Communication Networks", "abstract": "This paper analyzes the stochastic security performance of a multiple-input\nmultiple-output (MIMO) integrated sensing and communication (ISAC) system in a\ndownlink scenario. A base station (BS) transmits a multi-functional signal to\nsimultaneously communicate with a user, sense a target angular location, and\ncounteract eavesdropping threats. The system includes a passive single-antenna\ncommunication eavesdropper and a multi-antenna sensing eavesdropper attempting\nto infer the target location. The BS-user and BS-eavesdroppers channels follow\nRayleigh fading, while the target azimuth angle is uniformly distributed. To\nevaluate the performance, we derive exact expressions for the secrecy ergodic\nrate and the ergodic Cramer-Rao lower bound (CRB) for target localization at\nboth the BS and the sensing eavesdropper. This involves computing the\nprobability density functions (PDFs) of the signal-to-noise ratio (SNR) and\nCRB, leveraging the central limit theorem for tractability. Numerical results\nvalidate our findings.", "published": "2025-04-13 17:54:53", "link": "http://arxiv.org/abs/2504.09674v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nnumerous tasks, yet principled explanations for their underlying mechanisms and\nseveral phenomena, such as scaling laws, hallucinations, and related behaviors,\nremain elusive. In this work, we revisit the classical relationship between\ncompression and prediction, grounded in Kolmogorov complexity and Shannon\ninformation theory, to provide deeper insights into LLM behaviors. By\nleveraging the Kolmogorov Structure Function and interpreting LLM compression\nas a two-part coding process, we offer a detailed view of how LLMs acquire and\nstore information across increasing model and data scales -- from pervasive\nsyntactic patterns to progressively rarer knowledge elements. Motivated by this\ntheoretical perspective and natural assumptions inspired by Heap's and Zipf's\nlaws, we introduce a simplified yet representative hierarchical data-generation\nframework called the Syntax-Knowledge model. Under the Bayesian setting, we\nshow that prediction and compression within this model naturally lead to\ndiverse learning and scaling behaviors of LLMs. In particular, our theoretical\nanalysis offers intuitive and principled explanations for both data and model\nscaling laws, the dynamics of knowledge acquisition during training and\nfine-tuning, factual knowledge hallucinations in LLMs. The experimental results\nvalidate our theoretical predictions.", "published": "2025-04-13 14:31:52", "link": "http://arxiv.org/abs/2504.09597v1", "categories": ["cs.AI", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.AI"}
{"title": "Bounds and Optimal Constructions of Generalized Merge-Convertible Codes for Code Conversion into LRCs", "abstract": "Error-correcting codes are essential for ensuring fault tolerance in modern\ndistributed data storage systems. However, in practice, factors such as the\nfailure rates of storage devices can vary significantly over time, resulting in\nchanges to the optimal code parameters. To reduce storage costs while\nmaintaining efficiency, Maturana and Rashmi introduced a theoretical framework\nknown as code conversion, which enables dynamic adjustment of code parameters\naccording to device performance. In this paper, we focus exclusively on the\nbounds and constructions of generalized merge-convertible codes. First, we\nestablish a new lower bound on the access cost when the final code is an\n$(r,\\delta)$-LRC. This bound unifies and generalizes all previously known\nbounds for merge conversion where the initial and final codes are either an LRC\nor an MDS code. We then construct a family of access-optimal MDS convertible\ncodes by leveraging subgroups of the automorphism group of a rational function\nfield. It is worth noting that our construction is also per-symbol read\naccess-optimal. Next, we further extend our MDS-based construction to design\naccess-optimal convertible codes for the conversion between $(r,\\delta)$-LRCs.\nFinally, using the parity-check matrix approach, we present a construction of\naccess-optimal convertible codes that enable merge conversion from MDS codes to\nan $(r,\\delta)$-LRC. To the best of our knowledge, this is the first explicit\noptimal construction of code conversion between MDS codes and LRCs. All of our\nconstructions are over finite fields whose sizes grow linearly with the code\nlength.", "published": "2025-04-13 14:01:10", "link": "http://arxiv.org/abs/2504.09580v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Dynamical symmetries in the fluctuation-driven regime: an application of Noether's theorem to noisy dynamical systems", "abstract": "Noether's theorem provides a powerful link between continuous symmetries and\nconserved quantities for systems governed by some variational principle.\nPerhaps unfortunately, most dynamical systems of interest in neuroscience and\nartificial intelligence cannot be described by any such principle. On the other\nhand, nonequilibrium physics provides a variational principle that describes\nhow fairly generic noisy dynamical systems are most likely to transition\nbetween two states; in this work, we exploit this principle to apply Noether's\ntheorem, and hence learn about how the continuous symmetries of dynamical\nsystems constrain their most likely trajectories. We identify analogues of the\nconservation of energy, momentum, and angular momentum, and briefly discuss\nexamples of each in the context of models of decision-making, recurrent neural\nnetworks, and diffusion generative models.", "published": "2025-04-13 23:56:31", "link": "http://arxiv.org/abs/2504.09761v1", "categories": ["cs.LG", "cond-mat.stat-mech"], "primary_category": "cs.LG"}
{"title": "Enhancing Classifier Evaluation: A Fairer Benchmarking Strategy Based on Ability and Robustness", "abstract": "Benchmarking is a fundamental practice in machine learning (ML) for comparing\nthe performance of classification algorithms. However, traditional evaluation\nmethods often overlook a critical aspect: the joint consideration of dataset\ncomplexity and an algorithm's ability to generalize. Without this dual\nperspective, assessments may favor models that perform well on easy instances\nwhile failing to capture their true robustness. To address this limitation,\nthis study introduces a novel evaluation methodology that combines Item\nResponse Theory (IRT) with the Glicko-2 rating system, originally developed to\nmeasure player strength in competitive games. IRT assesses classifier ability\nbased on performance over difficult instances, while Glicko-2 updates\nperformance metrics - such as rating, deviation, and volatility - via simulated\ntournaments between classifiers. This combined approach provides a fairer and\nmore nuanced measure of algorithm capability. A case study using the\nOpenML-CC18 benchmark showed that only 15% of the datasets are truly\nchallenging and that a reduced subset with 50% of the original datasets offers\ncomparable evaluation power. Among the algorithms tested, Random Forest\nachieved the highest ability score. The results highlight the importance of\nimproving benchmark design by focusing on dataset quality and adopting\nevaluation strategies that reflect both difficulty and classifier proficiency.", "published": "2025-04-13 23:54:08", "link": "http://arxiv.org/abs/2504.09759v1", "categories": ["cs.LG", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Integrating Large Language Models for Automated Structural Analysis", "abstract": "Automated analysis for engineering structures offers considerable potential\nfor boosting efficiency by minimizing repetitive tasks. Although AI-driven\nmethods are increasingly common, no systematic framework yet leverages Large\nLanguage Models (LLMs) for automatic structural analysis. To address this gap,\nwe propose a novel framework that integrates LLMs with structural analysis\nsoftware. LLMs serve as the core engine: they parse structural descriptions\nfrom text and translate them into executable Python scripts. Moreover, the\nframework integrates the generative capabilities of LLMs with code-based finite\nelement (FE) tools like OpenSeesPy. It employs domain-specific prompt design\nand in-context learning strategies to enhance the LLM's problem-solving\ncapabilities and generative stability, enabling fully automated structural\nanalysis from descriptive text to model outputs. In our experiments, we\nintroduce a well-curated small-scale benchmark dataset of 20 structural\nanalysis word problems (SAWPs) with ground-truth solutions and evaluate the\nperformance of different LLMs within our framework in solving these SAWPs. The\nrole of system instructions, crafted by structural engineers, is also\ninvestigated to understand their impact on LLM-driven structural analysis.\nAdditionally, the generative stability of our framework is examined. Through\nmultiple validation experiments on the benchmark, our results demonstrate that\nthe proposed framework can substantially increase the level of automation in\nsolving SAWPs compared to traditional methods. Quantitatively, the framework,\nbuilt on GPT-4o, achieved 100% accuracy, surpassing GPT-4 (85%), Gemini 1.5 Pro\n(80%), and Llama-3.3 (30%) on the test examples. Furthermore, integrating\ndomain-specific instructions enhanced performance by 30% on problems with\nasymmetrical structural configurations.", "published": "2025-04-13 23:10:33", "link": "http://arxiv.org/abs/2504.09754v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Stochastic generative methods for stable and accurate closure modeling of chaotic dynamical systems", "abstract": "Traditional deterministic subgrid-scale (SGS) models are often dissipative\nand unstable, especially in regions of chaotic and turbulent flow. Ongoing work\nin climate science and ocean modeling motivates the use of stochastic SGS\nmodels for chaotic dynamics. Further, developing stochastic generative models\nof underlying dynamics is a rapidly expanding field. In this work, we aim to\nincorporate stochastic integration toward closure modeling for chaotic\ndynamical systems. Further, we want to explore the potential stabilizing effect\nthat stochastic models could have on linearized chaotic systems. We propose\nparametric and generative approaches for closure modeling using stochastic\ndifferential equations (SDEs). We derive and implement a quadratic diffusion\nmodel based on the fluctuations, demonstrating increased accuracy from bridging\ntheoretical models with generative approaches. Results are demonstrated on the\nLorenz-63 dynamical system.", "published": "2025-04-13 22:59:42", "link": "http://arxiv.org/abs/2504.09750v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Epsilon-Neighborhood Decision-Boundary Governed Estimation (EDGE) of 2D Black Box Classifier Functions", "abstract": "Accurately estimating decision boundaries in black box systems is critical\nwhen ensuring safety, quality, and feasibility in real-world applications.\nHowever, existing methods iteratively refine boundary estimates by sampling in\nregions of uncertainty, without providing guarantees on the closeness to the\ndecision boundary and also result in unnecessary exploration that is especially\ndisadvantageous when evaluations are costly. This paper presents the\nEpsilon-Neighborhood Decision-Boundary Governed Estimation (EDGE), a sample\nefficient and function-agnostic algorithm that leverages the intermediate value\ntheorem to estimate the location of the decision boundary of a black box binary\nclassifier within a user-specified epsilon-neighborhood. Evaluations are\nconducted on three nonlinear test functions and a case study of an electric\ngrid stability problem with uncertain renewable power injection. The EDGE\nalgorithm demonstrates superior sample efficiency and better boundary\napproximation than adaptive sampling techniques and grid-based searches.", "published": "2025-04-13 21:40:46", "link": "http://arxiv.org/abs/2504.09733v1", "categories": ["cs.CG", "cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.CG"}
{"title": "Preconditioned Gradient Descent for Over-Parameterized Nonconvex Matrix Factorization", "abstract": "In practical instances of nonconvex matrix factorization, the rank of the\ntrue solution $r^{\\star}$ is often unknown, so the rank $r$ of the model can be\noverspecified as $r>r^{\\star}$. This over-parameterized regime of matrix\nfactorization significantly slows down the convergence of local search\nalgorithms, from a linear rate with $r=r^{\\star}$ to a sublinear rate when\n$r>r^{\\star}$. We propose an inexpensive preconditioner for the matrix sensing\nvariant of nonconvex matrix factorization that restores the convergence rate of\ngradient descent back to linear, even in the over-parameterized case, while\nalso making it agnostic to possible ill-conditioning in the ground truth.\nClassical gradient descent in a neighborhood of the solution slows down due to\nthe need for the model matrix factor to become singular. Our key result is that\nthis singularity can be corrected by $\\ell_{2}$ regularization with a specific\nrange of values for the damping parameter. In fact, a good damping parameter\ncan be inexpensively estimated from the current iterate. The resulting\nalgorithm, which we call preconditioned gradient descent or PrecGD, is stable\nunder noise, and converges linearly to an information theoretically optimal\nerror bound. Our numerical experiments find that PrecGD works equally well in\nrestoring the linear convergence of other variants of nonconvex matrix\nfactorization in the over-parameterized regime.", "published": "2025-04-13 20:06:49", "link": "http://arxiv.org/abs/2504.09708v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "Transformer-Based Representation Learning for Robust Gene Expression Modeling and Cancer Prognosis", "abstract": "Transformer-based models have achieved remarkable success in natural language\nand vision tasks, but their application to gene expression analysis remains\nlimited due to data sparsity, high dimensionality, and missing values. We\npresent GexBERT, a transformer-based autoencoder framework for robust\nrepresentation learning of gene expression data. GexBERT learns context-aware\ngene embeddings by pretraining on large-scale transcriptomic profiles with a\nmasking and restoration objective that captures co-expression relationships\namong thousands of genes. We evaluate GexBERT across three critical tasks in\ncancer research: pan-cancer classification, cancer-specific survival\nprediction, and missing value imputation. GexBERT achieves state-of-the-art\nclassification accuracy from limited gene subsets, improves survival prediction\nby restoring expression of prognostic anchor genes, and outperforms\nconventional imputation methods under high missingness. Furthermore, its\nattention-based interpretability reveals biologically meaningful gene patterns\nacross cancer types. These findings demonstrate the utility of GexBERT as a\nscalable and effective tool for gene expression modeling, with translational\npotential in settings where gene coverage is limited or incomplete.", "published": "2025-04-13 19:49:59", "link": "http://arxiv.org/abs/2504.09704v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow", "abstract": "Recent prompt-based image editing models have demonstrated impressive\nprompt-following capability at structural editing tasks. However, existing\nmodels still fail to perform local edits, follow detailed editing prompts, or\nmaintain global image quality beyond a single editing step. To address these\nchallenges, we introduce SPICE, a training-free workflow that accepts arbitrary\nresolutions and aspect ratios, accurately follows user requirements, and\nimproves image quality consistently during more than 100 editing steps. By\nsynergizing the strengths of a base diffusion model and a Canny edge ControlNet\nmodel, SPICE robustly handles free-form editing instructions from the user.\nSPICE outperforms state-of-the-art baselines on a challenging realistic\nimage-editing dataset consisting of semantic editing (object addition, removal,\nreplacement, and background change), stylistic editing (texture changes), and\nstructural editing (action change) tasks. Not only does SPICE achieve the\nhighest quantitative performance according to standard evaluation metrics, but\nit is also consistently preferred by users over existing image-editing methods.\nWe release the workflow implementation for popular diffusion model Web UIs to\nsupport further research and artistic exploration.", "published": "2025-04-13 19:13:04", "link": "http://arxiv.org/abs/2504.09697v1", "categories": ["cs.GR", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Dominated Actions in Imperfect-Information Games", "abstract": "Dominance is a fundamental concept in game theory. In strategic-form games\ndominated strategies can be identified in polynomial time. As a consequence,\niterative removal of dominated strategies can be performed efficiently as a\npreprocessing step for reducing the size of a game before computing a Nash\nequilibrium. For imperfect-information games in extensive form, we could\nconvert the game to strategic form and then iteratively remove dominated\nstrategies in the same way; however, this conversion may cause an exponential\nblowup in game size. In this paper we define and study the concept of dominated\nactions in imperfect-information games. Our main result is a polynomial-time\nalgorithm for determining whether an action is dominated (strictly or weakly)\nby any mixed strategy in n-player games, which can be extended to an algorithm\nfor iteratively removing dominated actions. This allows us to efficiently\nreduce the size of the game tree as a preprocessing step for Nash equilibrium\ncomputation. We explore the role of dominated actions empirically in the \"All\nIn or Fold\" No-Limit Texas Hold'em poker variant.", "published": "2025-04-13 20:48:44", "link": "http://arxiv.org/abs/2504.09716v1", "categories": ["cs.GT", "cs.AI", "cs.MA", "econ.TH"], "primary_category": "cs.GT"}
{"title": "AgentDynEx: Nudging the Mechanics and Dynamics of Multi-Agent Simulations", "abstract": "Multi-agent large language model simulations have the potential to model\ncomplex human behaviors and interactions. If the mechanics are set up properly,\nunanticipated and valuable social dynamics can surface. However, it is\nchallenging to consistently enforce simulation mechanics while still allowing\nfor notable and emergent dynamics. We present AgentDynEx, an AI system that\nhelps set up simulations from user-specified mechanics and dynamics. AgentDynEx\nuses LLMs to guide users through a Configuration Matrix to identify core\nmechanics and define milestones to track dynamics. It also introduces a method\ncalled \\textit{nudging}, where the system dynamically reflects on simulation\nprogress and gently intervenes if it begins to deviate from intended outcomes.\nA technical evaluation found that nudging enables simulations to have more\ncomplex mechanics and maintain its notable dynamics compared to simulations\nwithout nudging. We discuss the importance of nudging as a technique for\nbalancing mechanics and dynamics of multi-agent simulations.", "published": "2025-04-13 17:26:35", "link": "http://arxiv.org/abs/2504.09662v1", "categories": ["cs.MA", "cs.AI", "cs.HC"], "primary_category": "cs.MA"}
{"title": "Unification of Consensus-Based Multi-Objective Optimization and Multi-Robot Path Planning", "abstract": "Multi-agent systems seeking consensus may also have other objective functions\nto optimize, requiring the research of multi-objective optimization in\nconsensus. Several recent publications have explored this domain using various\nmethods such as weighted-sum optimization and penalization methods. This paper\nreviews the state of the art for consensus-based multi-objective optimization,\nposes a multi-agent lunar rover exploration problem seeking consensus and\nmaximization of explored area, and achieves optimal edge weights and steering\nangles by applying SQP algorithms.", "published": "2025-04-13 13:56:54", "link": "http://arxiv.org/abs/2504.09577v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Level-set topology optimisation with unfitted finite elements and automatic shape differentiation", "abstract": "In this paper we develop automatic shape differentiation techniques for\nunfitted discretisations and link these to recent advances in shape calculus\nfor unfitted methods. We extend existing analytic shape calculus results to the\ncase where the domain boundary intersects with the boundary of the background\ndomain. We further show that we can recover these analytic derivatives to\nmachine precision regardless of the mesh size using the developed automatic\nshape differentiation techniques. In addition, we show that we can also recover\nthe symmetric shape Hessian. We implement these techniques for both serial and\ndistributed computing frameworks in the Julia package GridapTopOpt and the\nwider Gridap ecosystem. As part of this implementation we propose a novel\ngraph-based approach for isolated volume detection. We demonstrate the\napplicability of the unfitted automatic shape differentiation framework and our\nimplementation by considering the three-dimensional minimum compliance topology\noptimisation of a linear elastic wheel and of a linear elastic structure in a\nfluid-structure interaction problem with Stokes flow. The implementation is\ngeneral and allows GridapTopOpt to solve a wide range of problems without\nanalytic calculation of shape derivatives and avoiding issues that arise when\nmaterial properties are smoothed at the domain boundary. The software is open\nsource and available at https://github.com/zjwegert/GridapTopOpt.jl.", "published": "2025-04-13 22:55:35", "link": "http://arxiv.org/abs/2504.09748v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Analysis and structure-preserving approximation of a Cahn-Hilliard-Forchheimer system with solution-dependent mass and volume source", "abstract": "We analyze a coupled Cahn-Hilliard-Forchheimer system featuring\nconcentration-dependent mobility, mass source and convective transport. The\nvelocity field is governed by a generalized quasi-incompressible Forchheimer\nequation with solution-dependent volume source. We impose Dirichlet boundary\nconditions for the pressure to accommodate the source term. Our contributions\ninclude a novel well-posedness result for the generalized Forchheimer subsystem\nvia the Browder-Minty theorem, and existence of weak solutions for the full\ncoupled system established through energy estimates at the Galerkin level\ncombined with compactness techniques such as Aubin-Lions' lemma and Minty's\ntrick. Furthermore, we develop a structure-preserving discretization using\nRaviart-Thomas elements for the velocity that maintains exact mass balance and\ndiscrete energy-dissipation balance, with well-posedness demonstrated through\nrelative energy estimates and inf-sup stability. Lastly, we validate our model\nthrough numerical experiments, demonstrating optimal convergence rates,\nstructure preservation, and the role of the Forchheimer nonlinearity in\ngoverning phase-field evolution dynamics.", "published": "2025-04-13 22:08:43", "link": "http://arxiv.org/abs/2504.09739v1", "categories": ["math.NA", "cs.NA", "math.AP", "35A01, 35A02, 35D30, 35Q92"], "primary_category": "math.NA"}
{"title": "Optimal convergence rates for the finite element approximation of the Sobolev constant", "abstract": "We establish optimal convergence rates for the P1 finite element\napproximation of the Sobolev constant in arbitrary dimensions N\\geq 2 and for\nLebesgue exponents 1<p<N. Our analysis relies on a refined study of the Sobolev\ndeficit in suitable quasi-norms, which have been introduced and utilized in the\ncontext of finite element approximations of the p- Laplacian. The proof further\ninvolves sharp estimates for the finite element approximation of Sobolev\nminimizers.", "published": "2025-04-13 16:22:05", "link": "http://arxiv.org/abs/2504.09637v1", "categories": ["math.NA", "cs.NA", "math.CA"], "primary_category": "math.NA"}
{"title": "Hybrid discontinuous Galerkin discretizations for the damped time-harmonic Galbrun's equation", "abstract": "In this article, we consider the damped time-harmonic Galbrun's equation\nwhich models solar and stellar oscillations. We introduce and analyze hybrid\ndiscontinuous Galerkin discretizations, which are stable and convergent for any\npolynomial degree greater or equal than one and are computationally more\nefficient than discontinuous Galerkin discretizations. Additionally, the\nmethods are stable with respect to the drastic changes in the magnitude of the\ncoefficients occurring in stars. The analysis is based on the concept of\ndiscrete approximation schemes and weak T-compatibility, which exploits the\nweakly T-coercive structure of the equation.", "published": "2025-04-13 12:34:11", "link": "http://arxiv.org/abs/2504.09547v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Super-Exponential Approximation of the Riemann-Liouville Fractional Integral via Shifted Gegenbauer Pseudospectral Methods", "abstract": "This paper introduces a shifted Gegenbauer pseudospectral (SGPS) method for\nhigh-precision approximation of the left Riemann-Liouville fractional integral\n(RLFI). By using precomputable fractional-order shifted Gegenbauer integration\nmatrices (FSGIMs), the method achieves super-exponential convergence for smooth\nfunctions, delivering near machine-precision accuracy with minimal\ncomputational cost. Tunable shifted Gegenbauer (SG) parameters enable flexible\noptimization across diverse problems, while rigorous error analysis confirms\nrapid error decay under optimal settings. Numerical experiments demonstrate\nthat the SGPS method outperforms MATLAB's integral, MATHEMATICA's NIntegrate,\nand existing techniques by up to two orders of magnitude in accuracy, with\nsuperior efficiency for varying fractional orders 0 < \\alpha < 1. Its\nadaptability and precision make the SGPS method a transformative tool for\nfractional calculus, ideal for modeling complex systems with memory and\nnon-local behavior.", "published": "2025-04-13 11:26:12", "link": "http://arxiv.org/abs/2504.09526v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Hybrid Radial Kernels for Solving Weakly Singular Fredholm Integral Equations: Balancing Accuracy and Stability in Meshless Methods", "abstract": "Over the past few decades, kernel-based approximation methods had achieved\nastonishing success in solving different problems in the field of science and\nengineering. However, when employing the direct or standard method of\nperforming computations using infinitely smooth kernels, a conflict arises\nbetween the accuracy that can be theoretically attained and the numerical\nstability. In other words, when the shape parameter tends to zero, the\noperational matrix for the standard bases with infinitely smooth kernels become\nseverely ill-conditioned. This conflict can be managed applying hybrid kernels.\nThe hybrid kernels extend the approximation space and provide high flexibility\nto strike the best possible balance between accuracy and stability. In the\ncurrent study, an innovative approach using hybrid radial kernels (HRKs) is\nprovided to solve weakly singular Fredholm integral equations (WSFIEs) of the\nsecond kind in a meshless scheme. The approach employs hybrid kernels built on\ndispersed nodes as a basis within the discrete collocation technique. This\nmethod transforms the problem being studied into a linear system of algebraic\nequations. Also, the particle swarm optimization (PSO) algorithm is utilized to\ncalculate the optimal parameters for the hybrid kernels, which is based on\nminimizing the maximum absolute error (MAE). We also study the error estimate\nof the suggested scheme. Lastly, we assess the accuracy and validity of the\nhybrid technique by carrying out various numerical experiments. The numerical\nfindings show that the estimates obtained from hybrid kernels are significantly\nmore accurate in solving WSFIEs compared to pure kernels. Additionally, it was\nrevealed that the hybrid bases remain stable across various values of the shape\nparameters.", "published": "2025-04-13 09:17:22", "link": "http://arxiv.org/abs/2504.09492v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The Whitney method of fundamental solutions with Lusin wavelets", "abstract": "We establish the theoretical foundation for a variant of the method of\nfundamental solutions (MFS), where the source points $\\{q_j\\}_{j=1}^\\infty$\naccumulate towards the domain in a Whitney fashion, meaning that their\nseparation is proportional to the distance to the domain. We prove that the\nnormalized Lusin wavelets $\\psi_j(w) = b_j(w-q_j)^{-2}$ constitute a\ngeneralized basis, known as a frame, for the Hardy subspace of $L_2$-traces of\nholomorphic functions on the domain. Consequently, our method, where $\\psi_j$\nare used as basis functions in the MFS, enables a numerically stable\napproximation of solutions to Laplace boundary value problems, even when the\nsolutions lack analytic continuation across the boundary. Despite the source\npoints accumulating towards the domain, our computations show no loss of\naccuracy near the boundary, in contrast to the boundary integral equation\nmethod.", "published": "2025-04-13 07:04:24", "link": "http://arxiv.org/abs/2504.09458v1", "categories": ["math.NA", "cs.NA", "math.AP", "math.CA", "42B37, 42C40, 65N12, 65N80"], "primary_category": "math.NA"}
{"title": "Stong order 1 adaptive approximation of jump-diffusion SDEs with discontinuous drift", "abstract": "We present an adaptive approximation scheme for jump-diffusion SDEs with\ndiscontinuous drift and (possibly) degenerate diffusion. This\ntransformation-based doubly-adaptive quasi-Milstein scheme is the first scheme\nthat has strong convergence rate $1$ in $L^p$ for $p\\in[1,\\infty)$ with respect\nto the average computational cost for these SDEs. To obtain our result, we\nprove that under slightly stronger assumptions which are still weaker than\nthose in existing literature, a related doubly-adaptive quasi-Milstein scheme\nhas convergence order $1$. This scheme is doubly-adaptive in the sense that it\nis jump-adapted, i.e.~all jump times of the Poisson noise are grid points, and\nit includes an adaptive stepsize strategy to account for the discontinuities of\nthe drift.", "published": "2025-04-13 06:22:52", "link": "http://arxiv.org/abs/2504.09452v1", "categories": ["math.NA", "cs.NA", "math.PR", "60H10, 65C30, 65C20"], "primary_category": "math.NA"}
{"title": "Heterogeneous multiscale methods for fourth-order singular perturbations", "abstract": "We develop a numerical homogenization method for fourth-order singular\nperturbation problems within the framework of heterogeneous multiscale method.\nThese problems arise from heterogeneous strain gradient elasticity and\nelasticity models for architectured materials. We establish an error estimate\nfor the homogenized solution applicable to general media and derive an explicit\nconvergence for the locally periodic media with the fine-scale $\\varepsilon$.\nFor cell problems of size $\\delta=\\mathbb{N}\\varepsilon$, the classical\nresonance error $\\mathcal{O}(\\varepsilon/\\delta)$ can be eliminated due to the\ndominance of the higher-order operator. Despite the occurrence of boundary\nlayer effects, discretization errors do not necessarily deteriorate for general\nboundary conditions. Numerical simulations corroborate these theoretical\nfindings.", "published": "2025-04-13 02:46:38", "link": "http://arxiv.org/abs/2504.09410v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Integrated GARCH-GRU in Financial Volatility Forecasting", "abstract": "In this study, we propose a novel integrated Generalized Autoregressive\nConditional Heteroskedasticity-Gated Recurrent Unit (GARCH-GRU) model for\nfinancial volatility modeling and forecasting. The model embeds the GARCH(1,1)\nformulation directly into the GRU cell architecture, yielding a unified\nrecurrent unit that jointly captures both traditional econometric properties\nand complex temporal dynamics. This hybrid structure leverages the strengths of\nGARCH in modeling key stylized facts of financial volatility, such as\nclustering and persistence, while utilizing the GRU's capacity to learn\nnonlinear dependencies from sequential data. Compared to the GARCH-LSTM\ncounterpart, the GARCH-GRU model demonstrates superior computational\nefficiency, requiring significantly less training time, while maintaining and\nimproving forecasting accuracy. Empirical evaluation across multiple financial\ndatasets confirms the model's robust outperformance in terms of mean squared\nerror (MSE) and mean absolute error (MAE) relative to a range of benchmarks,\nincluding standard neural networks, alternative hybrid architectures, and\nclassical GARCH-type models. As an application, we compute Value-at-Risk (VaR)\nusing the model's volatility forecasts and observe lower violation ratios,\nfurther validating the predictive reliability of the proposed framework in\npractical risk management settings.", "published": "2025-04-13 00:04:15", "link": "http://arxiv.org/abs/2504.09380v1", "categories": ["q-fin.ST", "q-fin.RM"], "primary_category": "q-fin.ST"}
{"title": "Modeling Discrete Coating Degradation Events via Hawkes Processes", "abstract": "Forecasting the degradation of coated materials has long been a topic of\ncritical interest in engineering, as it has enormous implications for both\nsystem maintenance and sustainable material use. Material degradation is\naffected by many factors, including the history of corrosion and\ncharacteristics of the environment, which can be measured by high-frequency\nsensors. However, the high volume of data produced by such sensors can inhibit\nefficient modeling and prediction. To alleviate this issue, we propose novel\nmetrics for representing material degradation, taking the form of discrete\ndegradation events. These events maintain the statistical properties of\ncontinuous sensor readings, such as correlation with time to coating failure\nand coefficient of variation at failure, but are composed of orders of\nmagnitude fewer measurements. To forecast future degradation of the coating\nsystem, a marked Hawkes process models the events. We use the forecast of\ndegradation to predict a future time of failure, exhibiting superior\nperformance to the approach based on direct modeling of galvanic corrosion\nusing continuous sensor measurements. While such maintenance is typically done\non a regular basis, degradation models can enable informed condition-based\nmaintenance, reducing unnecessary excess maintenance and preventing unexpected\nfailures.", "published": "2025-04-13 19:57:10", "link": "http://arxiv.org/abs/2504.09706v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Ordinary Least Squares as an Attention Mechanism", "abstract": "I show that ordinary least squares (OLS) predictions can be rewritten as the\noutput of a restricted attention module, akin to those forming the backbone of\nlarge language models. This connection offers an alternative perspective on\nattention beyond the conventional information retrieval framework, making it\nmore accessible to researchers and analysts with a background in traditional\nstatistics. It falls into place when OLS is framed as a similarity-based method\nin a transformed regressor space, distinct from the standard view based on\npartial correlations. In fact, the OLS solution can be recast as the outcome of\nan alternative problem: minimizing squared prediction errors by optimizing the\nembedding space in which training and test vectors are compared via inner\nproducts. Rather than estimating coefficients directly, we equivalently learn\noptimal encoding and decoding operations for predictors. From this vantage\npoint, OLS maps naturally onto the query-key-value structure of attention\nmechanisms. Building on this foundation, I discuss key elements of\nTransformer-style attention and draw connections to classic ideas from time\nseries econometrics.", "published": "2025-04-13 17:26:44", "link": "http://arxiv.org/abs/2504.09663v1", "categories": ["cs.LG", "econ.EM", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Quantization Error Propagation: Revisiting Layer-Wise Post-Training Quantization", "abstract": "Layer-wise post-training quantization has emerged as a widely used technique\nfor compressing large language models (LLMs) without retraining. However,\nrecent progress in this line of research is saturating, underscoring the need\nto revisit its core limitation and explore further improvements. This study\nidentifies a critical bottleneck in existing layer-wise PTQ methods: the\naccumulation of quantization errors across layers significantly degrades\nperformance, particularly in low-bit regimes. To address this, we propose\nQuantization Error Propagation (QEP), a lightweight and general framework that\nenhances layer-wise PTQ by explicitly propagating the quantization error which\nenable compensating for accumulated quantization errors. Additionally, we\nintroduce a tunable propagation mechanism that allows for control over both\npropagation strength and computational overhead, making the framework adaptable\nto various architectures and resource constraints. Empirical evaluation on\nLLaMA2 models (7B, 13B, 70B) demonstrate that incorporating QEP into standard\nlayer-wise PTQ pipelines outperforms standard PTQ methods. Notably, QEP yields\nsubstantial performance improvements under extreme low-bit quantization\nsettings.", "published": "2025-04-13 15:56:00", "link": "http://arxiv.org/abs/2504.09629v1", "categories": ["cs.LG", "stat.AP", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Conditional Independence Test Based on Transport Maps", "abstract": "Testing conditional independence between two random vectors given a third is\na fundamental and challenging problem in statistics, particularly in\nmultivariate nonparametric settings due to the complexity of conditional\nstructures. We propose a novel framework for testing conditional independence\nusing transport maps. At the population level, we show that two well-defined\ntransport maps can transform the conditional independence test into an\nunconditional independence test, this substantially simplifies the problem.\nThese transport maps are estimated from data using conditional continuous\nnormalizing flow models. Within this framework, we derive a test statistic and\nprove its consistency under both the null and alternative hypotheses. A\npermutation-based procedure is employed to evaluate the significance of the\ntest. We validate the proposed method through extensive simulations and\nreal-data analysis. Our numerical studies demonstrate the practical\neffectiveness of the proposed method for conditional independence testing.", "published": "2025-04-13 13:38:25", "link": "http://arxiv.org/abs/2504.09567v1", "categories": ["stat.ML", "cs.LG", "stat.ME", "62G05, 62G08, 68T07"], "primary_category": "stat.ML"}
{"title": "Optimal sparse phase retrieval via a quasi-Bayesian approach", "abstract": "This paper addresses the problem of sparse phase retrieval, a fundamental\ninverse problem in applied mathematics, physics, and engineering, where a\nsignal need to be reconstructed using only the magnitude of its transformation\nwhile phase information remains inaccessible. Leveraging the inherent sparsity\nof many real-world signals, we introduce a novel sparse quasi-Bayesian approach\nand provide the first theoretical guarantees for such an approach.\nSpecifically, we employ a scaled Student distribution as a continuous shrinkage\nprior to enforce sparsity and analyze the method using the PAC-Bayesian\ninequality framework. Our results establish that the proposed Bayesian\nestimator achieves minimax-optimal convergence rates under sub-exponential\nnoise, matching those of state-of-the-art frequentist methods. To ensure\ncomputational feasibility, we develop an efficient Langevin Monte Carlo\nsampling algorithm. Through numerical experiments, we demonstrate that our\nmethod performs comparably to existing frequentist techniques, highlighting its\npotential as a principled alternative for sparse phase retrieval in noisy\nsettings.", "published": "2025-04-13 10:21:35", "link": "http://arxiv.org/abs/2504.09509v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "aweSOM: a CPU/GPU-accelerated Self-organizing Map and Statistically Combined Ensemble Framework for Machine-learning Clustering Analysis", "abstract": "We introduce aweSOM, an open-source Python package for machine learning (ML)\nclustering and classification, using a Self-organizing Maps (SOM) algorithm\nthat incorporates CPU/GPU acceleration to accommodate large ($N > 10^6$, where\n$N$ is the number of data points), multidimensional datasets. aweSOM consists\nof two main modules, one that handles the initialization and training of the\nSOM, and another that stacks the results of multiple SOM realizations to obtain\nmore statistically robust clusters. Existing Python-based SOM implementations\n(e.g., POPSOM, Yuan (2018); MiniSom, Vettigli (2018); sklearn-som) primarily\nserve as proof-of-concept demonstrations, optimized for smaller datasets, but\nlacking scalability for large, multidimensional data. aweSOM provides a\nsolution for this gap in capability, with good performance scaling up to $\\sim\n10^8$ individual points, and capable of utilizing multiple features per point.\nWe compare the code performance against the legacy implementations it is based\non, and find a 10-100x speed up, as well as significantly improved memory\nefficiency, due to several built-in optimizations.", "published": "2025-04-13 06:17:35", "link": "http://arxiv.org/abs/2504.09449v1", "categories": ["cs.LG", "astro-ph.IM", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Constants of motion network revisited", "abstract": "Discovering constants of motion is meaningful in helping understand the\ndynamical systems, but inevitably needs proficient mathematical skills and keen\nanalytical capabilities. With the prevalence of deep learning, methods\nemploying neural networks, such as Constant Of Motion nETwork (COMET), are\npromising in handling this scientific problem. Although the COMET method can\nproduce better predictions on dynamics by exploiting the discovered constants\nof motion, there is still plenty of room to sharpen it. In this paper, we\npropose a novel neural network architecture, built using the\nsingular-value-decomposition (SVD) technique, and a two-phase training\nalgorithm to improve the performance of COMET. Extensive experiments show that\nour approach not only retains the advantages of COMET, such as applying to\nnon-Hamiltonian systems and indicating the number of constants of motion, but\nalso can be more lightweight and noise-robust than COMET.", "published": "2025-04-13 04:57:34", "link": "http://arxiv.org/abs/2504.09434v1", "categories": ["cs.LG", "physics.class-ph", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Adaptive Insurance Reserving with CVaR-Constrained Reinforcement Learning under Macroeconomic Regimes", "abstract": "This paper proposes a reinforcement learning (RL) framework for insurance\nreserving that integrates tail-risk sensitivity, macroeconomic regime modeling,\nand regulatory compliance. The reserving problem is formulated as a\nfinite-horizon Markov Decision Process (MDP), in which reserve adjustments are\noptimized using Proximal Policy Optimization (PPO) subject to Conditional\nValue-at-Risk (CVaR) constraints. To enhance policy robustness across varying\neconomic conditions, the agent is trained using a regime-aware curriculum that\nprogressively increases volatility exposure.\n  The reward structure penalizes reserve shortfall, capital inefficiency, and\nsolvency floor violations, with design elements informed by Solvency II and Own\nRisk and Solvency Assessment (ORSA) frameworks. Empirical evaluations on two\nindustry datasets--Workers' Compensation, and Other Liability--demonstrate that\nthe RL-CVaR agent achieves superior performance relative to classical reserving\nmethods across multiple criteria, including tail-risk control (CVaR$_{0.95}$),\ncapital efficiency, and regulatory violation rate. The framework also\naccommodates fixed-shock stress testing and regime-stratified analysis,\nproviding a principled and extensible approach to reserving under uncertainty.", "published": "2025-04-13 01:43:25", "link": "http://arxiv.org/abs/2504.09396v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "FSSUAVL: A Discriminative Framework using Vision Models for Federated Self-Supervised Audio and Image Understanding", "abstract": "Recent studies have demonstrated that vision models can effectively learn\nmultimodal audio-image representations when paired. However, the challenge of\nenabling deep models to learn representations from unpaired modalities remains\nunresolved. This issue is especially pertinent in scenarios like Federated\nLearning (FL), where data is often decentralized, heterogeneous, and lacks a\nreliable guarantee of paired data. Previous attempts tackled this issue through\nthe use of auxiliary pretrained encoders or generative models on local clients,\nwhich invariably raise computational cost with increasing number modalities.\nUnlike these approaches, in this paper, we aim to address the task of unpaired\naudio and image recognition using \\texttt{FSSUAVL}, a single deep model\npretrained in FL with self-supervised contrastive learning (SSL). Instead of\naligning the audio and image modalities, \\texttt{FSSUAVL} jointly discriminates\nthem by projecting them into a common embedding space using contrastive SSL.\nThis extends the utility of \\texttt{FSSUAVL} to paired and unpaired audio and\nimage recognition tasks. Our experiments with CNN and ViT demonstrate that\n\\texttt{FSSUAVL} significantly improves performance across various image- and\naudio-based downstream tasks compared to using separate deep models for each\nmodality. Additionally, \\texttt{FSSUAVL}'s capacity to learn multimodal feature\nrepresentations allows for integrating auxiliary information, if available, to\nenhance recognition accuracy.", "published": "2025-04-13 11:04:43", "link": "http://arxiv.org/abs/2504.09516v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DiTSE: High-Fidelity Generative Speech Enhancement via Latent Diffusion Transformers", "abstract": "Real-world speech recordings suffer from degradations such as background\nnoise and reverberation. Speech enhancement aims to mitigate these issues by\ngenerating clean high-fidelity signals. While recent generative approaches for\nspeech enhancement have shown promising results, they still face two major\nchallenges: (1) content hallucination, where plausible phonemes generated\ndiffer from the original utterance; and (2) inconsistency, failing to preserve\nspeaker's identity and paralinguistic features from the input speech. In this\nwork, we introduce DiTSE (Diffusion Transformer for Speech Enhancement), which\naddresses quality issues of degraded speech in full bandwidth. Our approach\nemploys a latent diffusion transformer model together with robust conditioning\nfeatures, effectively addressing these challenges while remaining\ncomputationally efficient. Experimental results from both subjective and\nobjective evaluations demonstrate that DiTSE achieves state-of-the-art audio\nquality that, for the first time, matches real studio-quality audio from the\nDAPS dataset. Furthermore, DiTSE significantly improves the preservation of\nspeaker identity and content fidelity, reducing hallucinations across datasets\ncompared to state-of-the-art enhancers. Audio samples are available at:\nhttp://hguimaraes.me/DiTSE", "published": "2025-04-13 00:04:48", "link": "http://arxiv.org/abs/2504.09381v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Accelerating Ray Tracing-Based Wireless Channels Generation for Real-Time Network Digital Twins", "abstract": "Ray tracing (RT) simulation is a widely used approach to enable modeling\nwireless channels in applications such as network digital twins. However, the\ncomputational cost to execute RT is proportional to factors such as the level\nof detail used in the adopted 3D scenario. This work proposes RT pre-processing\nalgorithms that aim at simplifying the 3D scene without distorting the channel.\nIt also proposes a post-processing method that augments a set of RT results to\nachieve an improved time resolution. These methods enable using RT in\napplications that use a detailed and photorealistic 3D scenario, while\ngenerating consistent wireless channels over time. Our simulation results with\ndifferent 3D scenarios demonstrate that it is possible to reduce the simulation\ntime by more than 50% without compromising the accuracy of the RT parameters.", "published": "2025-04-13 23:02:36", "link": "http://arxiv.org/abs/2504.09751v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Enhanced Filterless Multi-Color VLC via QCT", "abstract": "Color shift keying (CSK) in visible light communication (VLC) often suffers\nfrom filter-induced crosstalk and reduced brightness. This paper proposes using\nquartered composite transform (QCT) with multi-color light-emitting diodes\n(LEDs) to improve both illumination and communication. The proposd DC-biased\nQCT scheme eliminates receiver optical filters, thereby removing crosstalk and\nsignificantly increasing signal-to-noise ratio (SNR). Simulations demonstrate\nQCT maintains high illumination quality (CRI 79.72, CCT 3462 K) while achieving\nover double the average illuminance compared to CSK under the same power\nbudget. QCT also shows better bit error rate (BER) performance in\nlow-to-moderate SNR regimes and has ability to convert multi-tap\nfrequency-selective channel into an equivalent single-tap flat-fading channel\nto mitigate inter-symbol interference (ISI), proving a promising technique for\nbrighter, high-performance, filter-less VLC.", "published": "2025-04-13 22:41:54", "link": "http://arxiv.org/abs/2504.09743v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Quantum Manifold Optimization: A Design Framework for Future Communications Systems", "abstract": "Inspired by recent developments in various areas of science relevant to\nquantum computing, we introduce quantum manifold optimization (QMO) as a\npromising framework for solving constrained optimization problems in\nnext-generation wireless communication systems. We begin by showing how\nclassical wireless design problems - such as pilot design in cell-free\n(CF)-massive MIMO (mMIMO), beamformer optimization in gigantic multiple input\nmultiple output (MIMO), and reconfigurable intelligent surface (RIS) phase\ntuning - naturally reside on structured manifolds like the Stiefel,\nGrassmannian, and oblique manifolds, with the latter novelly formulated in this\nwork. Then, we demonstrate how these problems can be reformulated as\ntrace-based quantum expectation values over variationally-encoded quantum\nstates. While theoretical in scope, the work lays a foundation for a new class\nof quantum optimization algorithms with broad application to the design of\nfuture beyond-sixth-generation (B6G) systems.", "published": "2025-04-13 17:36:21", "link": "http://arxiv.org/abs/2504.09667v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Millimeter-Wave Joint Radar and Communications With an RIS-Integrated Array", "abstract": "In the context of the joint radar and communications (JRC) framework,\nreconfigurable intelligent surfaces (RISs) emerged as a promising technology\nfor their ability to shape the propagation environment by adjusting their\nphase-shift coefficients. However, achieving perfect synchronization and\neffective collaboration between access points (APs) and RISs is crucial to\nsuccessful operation. This paper investigates the performance of a bistatic JRC\nnetwork operating in the millimeter-wave (mmWave) frequency band, where the\nreceiving AP is equipped with an RIS-integrated array. This system\nsimultaneously serves multiple UEs while estimating the position of a target\nwith limited prior knowledge of its position. To achieve this, we optimize both\nthe power allocation of the transmitted waveform and the RIS phase-shift matrix\nto minimize the position error bound (PEB) of the target. At the same time, we\nensure that the UEs achieve an acceptable level of spectral efficiency. The\nnumerical results show that an RIS-integrated array, even with a small number\nof receiving antennas, can achieve high localization accuracy. Additionally,\noptimized phase-shifts significantly improve the localization accuracy in\ncomparison to a random phase-shift configuration.", "published": "2025-04-13 16:20:53", "link": "http://arxiv.org/abs/2504.09636v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Hybrid Transmitting and Reflecting Beyond Diagonal Reconfigurable Intelligent Surface with Independent Beam Control and Power Splitting", "abstract": "A hybrid transmitting and reflecting beyond diagonal reconfigurable\nintelligent surface (BD-RIS) design is proposed. Operating in the same\naperture, frequency band and polarization, the proposed BD-RIS features\nindependent beam steering control of its reflected and transmitted waves. In\naddition it provides a hybrid mode with both reflected and transmitted waves\nusing tunable power splitting between beams. The BD-RIS comprises two phase\nreconfigurable antenna arrays interconnected by an array of tunable two-port\npower splitters. The two-port power splitter in each BD-RIS cell is built upon\na varactor in parallel with a bias inductor to exert tunable impedance\nvariations on transmission lines. Provided with variable reverse DC voltages,\nthe two-port power splitter can control the power ratio of S11 over S21 from\n-20 dB to 20 dB, thus allowing tunable power splitting. Each antenna is 2-bit\nphase reconfigurable with 200 MHz bandwidth at 2.4 GHz so that each cell of\nBD-RIS can also achieve independent reflection and transmission phase control.\nTo characterize and optimize the electromagnetic response of the proposed\nBD-RIS design, a Th\\'evenin equivalent model and corresponding analytical\nmethod is provided. A BD-RIS with 4 by 4 cells was also prototyped and tested.\nExperiments show that in reflection and transmission mode, the fabricated\nBD-RIS can realize beam steering in reflection and transmission space,\nrespectively. It is also verified that when operating in hybrid mode, the\nBD-RIS enables independent beam steering of the reflected and transmitted\nwaves. This work helps fill the gap between realizing practical hardware design\nand establishing an accurate physical model for the hybrid transmitting and\nreflecting BD-RIS, enabling hybrid transmitting and reflecting BD-RIS assisted\nwireless communications.", "published": "2025-04-13 15:22:49", "link": "http://arxiv.org/abs/2504.09618v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "PLS-Assisted Offloading for Edge Computing-Enabled Post-Quantum Security in Resource-Constrained Devices", "abstract": "With the advent of post-quantum cryptography (PQC) standards, it has become\nimperative for resource-constrained devices (RCDs) in the Internet of Things\n(IoT) to adopt these quantum-resistant protocols. However, the high\ncomputational overhead and the large key sizes associated with PQC make direct\ndeployment on such devices impractical. To address this challenge, we propose\nan edge computing-enabled PQC framework that leverages a physical-layer\nsecurity (PLS)-assisted offloading strategy, allowing devices to either offload\nintensive cryptographic tasks to a post-quantum edge server (PQES) or perform\nthem locally. Furthermore, to ensure data confidentiality within the edge\ndomain, our framework integrates two PLS techniques: offloading RCDs employ\nwiretap coding to secure data transmission, while non-offloading RCDs serve as\nfriendly jammers by broadcasting artificial noise to disrupt potential\neavesdroppers. Accordingly, we co-design the computation offloading and PLS\nstrategy by jointly optimizing the device transmit power, PQES computation\nresource allocation, and offloading decisions to minimize overall latency under\nresource constraints. Numerical results demonstrate significant latency\nreductions compared to baseline schemes, confirming the scalability and\nefficiency of our approach for secure PQC operations in IoT networks.", "published": "2025-04-13 05:14:17", "link": "http://arxiv.org/abs/2504.09437v1", "categories": ["cs.CR", "eess.SP"], "primary_category": "cs.CR"}
{"title": "Deep Mismatch Channel Estimation in IRS based 6G Communication", "abstract": "We propose a channel estimation protocol to determine the uplink channel\nstate information (CSI) at the base station for an intelligent reflecting\nsurface (IRS) based wireless communication. More specifically, we develop a\nchannel estimation scheme in a multi-user system with high estimation accuracy\nand low computational complexity. One of the state-of-the-art approaches to\nchannel estimation is the deep learning-based approach. However, the\ndata-driven model often experiences high computational complexity and, thus, is\nslow to channel estimation. Inspired by the success of utilizing domain\nknowledge to build effective data-driven models, the proposed scheme uses the\nhigh channel correlation property to train a shallow deep learning model. More\nspecifically, utilizing the one coherent channel estimation, the model predicts\nthe subsequent channel coherence CSI. We evaluate the performance of the\nproposed scheme in terms of normalized mean square error (NMSE) and spectral\nefficiency (SE) via simulation. The proposed scheme can estimate the CSI with\nreasonable success of lower NMSE, higher SE, and lower estimation time than\nexisting schemes.", "published": "2025-04-13 03:02:45", "link": "http://arxiv.org/abs/2504.09412v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Wavefront Estimation From a Single Measurement: Uniqueness and Algorithms", "abstract": "Wavefront estimation is an essential component of adaptive optics where the\ngoal is to recover the underlying phase from its Fourier magnitude. While this\nmay sound identical to classical phase retrieval, wavefront estimation faces\nmore strict requirements regarding uniqueness as adaptive optics systems need a\nunique phase to compensate for the distorted wavefront. Existing real-time\nwavefront estimation methodologies are dominated by sensing via specialized\noptical hardware due to their high speed, but they often have a low spatial\nresolution. A computational method that can perform both fast and accurate\nwavefront estimation with a single measurement can improve resolution and bring\nnew applications such as real-time passive wavefront estimation, opening the\ndoor to a new generation of medical and defense applications.\n  In this paper, we tackle the wavefront estimation problem by observing that\nthe non-uniqueness is related to the geometry of the pupil shape. By analyzing\nthe source of ambiguities and breaking the symmetry, we present a joint\noptics-algorithm approach by co-designing the shape of the pupil and the\nreconstruction neural network. Using our proposed lightweight neural network,\nwe demonstrate wavefront estimation of a phase of size $128\\times 128$ at\n$5,200$ frames per second on a CPU computer, achieving an average Strehl ratio\nup to $0.98$ in the noiseless case. We additionally test our method on real\nmeasurements using a spatial light modulator. Code is available at\nhttps://pages.github.itap.purdue.edu/StanleyChanGroup/wavefront-estimation/.", "published": "2025-04-13 01:38:51", "link": "http://arxiv.org/abs/2504.09395v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "ClinicalGPT-R1: Pushing reasoning capability of generalist disease diagnosis with large language model", "abstract": "Recent advances in reasoning with large language models (LLMs)has shown\nremarkable reasoning capabilities in domains such as mathematics and coding,\nyet their application to clinical diagnosis remains underexplored. Here, we\nintroduce ClinicalGPT-R1, a reasoning enhanced generalist large language model\nfor disease diagnosis. Trained on a dataset of 20,000 real-world clinical\nrecords, ClinicalGPT-R1 leverages diverse training strategies to enhance\ndiagnostic reasoning. To benchmark performance, we curated MedBench-Hard, a\nchallenging dataset spanning seven major medical specialties and representative\ndiseases. Experimental results demonstrate that ClinicalGPT-R1 outperforms\nGPT-4o in Chinese diagnostic tasks and achieves comparable performance to GPT-4\nin English settings. This comparative study effectively validates the superior\nperformance of ClinicalGPT-R1 in disease diagnosis tasks. Resources are\navailable at https://github.com/medfound/medfound.", "published": "2025-04-13 04:00:40", "link": "http://arxiv.org/abs/2504.09421v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can you map it to English? The Role of Cross-Lingual Alignment in Multilingual Performance of LLMs", "abstract": "Large language models (LLMs) pre-trained predominantly on English text\nexhibit surprising multilingual capabilities, yet the mechanisms driving\ncross-lingual generalization remain poorly understood. This work investigates\nhow the alignment of representations for text written in different languages\ncorrelates with LLM performance on natural language understanding tasks and\ntranslation tasks, both at the language and the instance level. For this\npurpose, we introduce cross-lingual alignment metrics such as the\nDiscriminative Alignment Index (DALI) to quantify the alignment at an instance\nlevel for discriminative tasks. Through experiments on three natural language\nunderstanding tasks (Belebele, XStoryCloze, XCOPA), and machine translation, we\nfind that while cross-lingual alignment metrics strongly correlate with task\naccuracy at the language level, the sample-level alignment often fails to\ndistinguish correct from incorrect predictions, exposing alignment as a\nnecessary but insufficient condition for success.", "published": "2025-04-13 00:01:22", "link": "http://arxiv.org/abs/2504.09378v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Textual Embeddings from Contrastive Learning with Generative Recommender for Enhanced Personalization", "abstract": "Recent advances in recommender systems have highlighted the complementary\nstrengths of generative modeling and pretrained language models. We propose a\nhybrid framework that augments the Hierarchical Sequential Transduction Unit\n(HSTU) generative recommender with BLaIR -- a contrastive text embedding model.\nThis integration enriches item representations with semantic signals from\ntextual metadata while preserving HSTU's powerful sequence modeling\ncapabilities.\n  We evaluate our method on two domains from the Amazon Reviews 2023 dataset,\ncomparing it against the original HSTU and a variant that incorporates\nembeddings from OpenAI's state-of-the-art text-embedding-3-large model. While\nthe OpenAI embedding model is likely trained on a substantially larger corpus\nwith significantly more parameters, our lightweight BLaIR-enhanced approach --\npretrained on domain-specific data -- consistently achieves better performance,\nhighlighting the effectiveness of contrastive text embeddings in\ncompute-efficient settings.", "published": "2025-04-13 15:23:00", "link": "http://arxiv.org/abs/2504.10545v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation", "abstract": "The burgeoning presence of Large Language Models (LLM) is propelling the\ndevelopment of personalized recommender systems. Most existing LLM-based\nmethods fail to sufficiently explore the multi-view graph structure\ncorrelations inherent in recommendation scenarios. To this end, we propose a\nnovel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation\n(HeLLM), designed to equip LLMs with the capability to capture intricate\nhigher-order semantic correlations by fusing graph-level contextual signals\nwith sequence-level behavioral patterns. In the recommender pre-training phase,\nwe design a user hypergraph to uncover shared interest preferences among users\nand an item hypergraph to capture correlations within multimodal similarities\namong items. The hypergraph convolution and synergistic contrastive learning\nmechanism are introduced to enhance the distinguishability of learned\nrepresentations. In the LLM fine-tuning phase, we inject the learned\ngraph-structured embeddings directly into the LLM's architecture and integrate\nsequential features capturing each user's chronological behavior. This process\nenables hypergraphs to leverage graph-structured information as global context,\nenhancing the LLM's ability to perceive complex relational patterns and\nintegrate multimodal information, while also modeling local temporal dynamics.\nExtensive experiments demonstrate the superiority of our proposed method over\nstate-of-the-art baselines, confirming the advantages of fusing\nhypergraph-based context with sequential user behavior in LLMs for\nrecommendation.", "published": "2025-04-13 09:12:35", "link": "http://arxiv.org/abs/2504.10541v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Distilling Transitional Pattern to Large Language Models for Multimodal Session-based Recommendation", "abstract": "Session-based recommendation (SBR) predicts the next item based on anonymous\nsessions. Traditional SBR explores user intents based on ID collaborations or\nauxiliary content. To further alleviate data sparsity and cold-start issues,\nrecent Multimodal SBR (MSBR) methods utilize simplistic pre-trained models for\nmodality learning but have limitations in semantic richness. Considering\nsemantic reasoning abilities of Large Language Models (LLM), we focus on the\nLLM-enhanced MSBR scenario in this paper, which leverages LLM cognition for\ncomprehensive multimodal representation generation, to enhance downstream MSBR.\nTackling this problem faces two challenges: i) how to obtain LLM cognition on\nboth transitional patterns and inherent multimodal knowledge, ii) how to align\nboth features into one unified LLM, minimize discrepancy while maximizing\nrepresentation utility. To this end, we propose a multimodal LLM-enhanced\nframework TPAD, which extends a distillation paradigm to decouple and align\ntransitional patterns for promoting MSBR. TPAD establishes parallel\nKnowledge-MLLM and Transfer-MLLM, where the former interprets item\nknowledge-reflected features and the latter extracts transition-aware features\nunderneath sessions. A transitional pattern alignment module harnessing mutual\ninformation estimation theory unites two MLLMs, alleviating distribution\ndiscrepancy and distilling transitional patterns into modal representations.\nExtensive experiments on real-world datasets demonstrate the effectiveness of\nour framework.", "published": "2025-04-13 07:49:08", "link": "http://arxiv.org/abs/2504.10538v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "AB-Cache: Training-Free Acceleration of Diffusion Models via Adams-Bashforth Cached Feature Reuse", "abstract": "Diffusion models have demonstrated remarkable success in generative tasks,\nyet their iterative denoising process results in slow inference, limiting their\npracticality. While existing acceleration methods exploit the well-known\nU-shaped similarity pattern between adjacent steps through caching mechanisms,\nthey lack theoretical foundation and rely on simplistic computation reuse,\noften leading to performance degradation. In this work, we provide a\ntheoretical understanding by analyzing the denoising process through the\nsecond-order Adams-Bashforth method, revealing a linear relationship between\nthe outputs of consecutive steps. This analysis explains why the outputs of\nadjacent steps exhibit a U-shaped pattern. Furthermore, extending\nAdams-Bashforth method to higher order, we propose a novel caching-based\nacceleration approach for diffusion models, instead of directly reusing cached\nresults, with a truncation error bound of only \\(O(h^k)\\) where $h$ is the step\nsize. Extensive validation across diverse image and video diffusion models\n(including HunyuanVideo and FLUX.1-dev) with various schedulers demonstrates\nour method's effectiveness in achieving nearly $3\\times$ speedup while\nmaintaining original performance levels, offering a practical real-time\nsolution without compromising generation quality.", "published": "2025-04-13 08:29:58", "link": "http://arxiv.org/abs/2504.10540v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Imaging Transformer for MRI Denoising: a Scalable Model Architecture that enables SNR << 1 Imaging", "abstract": "Purpose: To propose a flexible and scalable imaging transformer (IT)\narchitecture with three attention modules for multi-dimensional imaging data\nand apply it to MRI denoising with very low input SNR.\n  Methods: Three independent attention modules were developed: spatial local,\nspatial global, and frame attentions. They capture long-range signal\ncorrelation and bring back the locality of information in images. An\nattention-cell-block design processes 5D tensors ([B, C, F, H, W]) for 2D,\n2D+T, and 3D image data. A High Resolution (HRNet) backbone was built to hold\nIT blocks. Training dataset consists of 206,677 cine series and test datasets\nhad 7,267 series. Ten input SNR levels from 0.05 to 8.0 were tested. IT models\nwere compared to seven convolutional and transformer baselines. To test\nscalability, four IT models 27m to 218m parameters were trained. Two senior\ncardiologists reviewed IT model outputs from which the EF was measured and\ncompared against the ground-truth.\n  Results: IT models significantly outperformed other models over the tested\nSNR levels. The performance gap was most prominent at low SNR levels. The\nIT-218m model had the highest SSIM and PSNR, restoring good image quality and\nanatomical details even at SNR 0.2. Two experts agreed at this SNR or above,\nthe IT model output gave the same clinical interpretation as the ground-truth.\nThe model produced images that had accurate EF measurements compared to\nground-truth values.\n  Conclusions: Imaging transformer model offers strong performance,\nscalability, and versatility for MR denoising. It recovers image quality\nsuitable for confident clinical reading and accurate EF measurement, even at\nvery low input SNR of 0.2.", "published": "2025-04-13 02:36:15", "link": "http://arxiv.org/abs/2504.10534v1", "categories": ["eess.IV", "eess.SP", "physics.med-ph"], "primary_category": "eess.IV"}
{"title": "Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nnumerous tasks, yet principled explanations for their underlying mechanisms and\nseveral phenomena, such as scaling laws, hallucinations, and related behaviors,\nremain elusive. In this work, we revisit the classical relationship between\ncompression and prediction, grounded in Kolmogorov complexity and Shannon\ninformation theory, to provide deeper insights into LLM behaviors. By\nleveraging the Kolmogorov Structure Function and interpreting LLM compression\nas a two-part coding process, we offer a detailed view of how LLMs acquire and\nstore information across increasing model and data scales -- from pervasive\nsyntactic patterns to progressively rarer knowledge elements. Motivated by this\ntheoretical perspective and natural assumptions inspired by Heap's and Zipf's\nlaws, we introduce a simplified yet representative hierarchical data-generation\nframework called the Syntax-Knowledge model. Under the Bayesian setting, we\nshow that prediction and compression within this model naturally lead to\ndiverse learning and scaling behaviors of LLMs. In particular, our theoretical\nanalysis offers intuitive and principled explanations for both data and model\nscaling laws, the dynamics of knowledge acquisition during training and\nfine-tuning, factual knowledge hallucinations in LLMs. The experimental results\nvalidate our theoretical predictions.", "published": "2025-04-13 14:31:52", "link": "http://arxiv.org/abs/2504.09597v2", "categories": ["cs.AI", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.AI"}
