{"title": "Political Leanings in Web3 Betting: Decoding the Interplay of Political and Profitable Motives", "abstract": "Harnessing the transparent blockchain user behavior data, we construct the\nPolitical Betting Leaning Score (PBLS) to measure political leanings based on\nbetting within Web3 prediction markets. Focusing on Polymarket and starting\nfrom the 2024 U.S. Presidential Election, we synthesize behaviors over 15,000\naddresses across 4,500 events and 8,500 markets, capturing the intensity and\ndirection of their political leanings by the PBLS. We validate the PBLS through\ninternal consistency checks and external comparisons. We uncover relationships\nbetween our PBLS and betting behaviors through over 800 features capturing\nvarious behavioral aspects. A case study of the 2022 U.S. Senate election\nfurther demonstrates the ability of our measurement while decoding the dynamic\ninteraction between political and profitable motives. Our findings contribute\nto understanding decision-making in decentralized markets, enhancing the\nanalysis of behaviors within Web3 prediction environments. The insights of this\nstudy reveal the potential of blockchain in enabling innovative,\nmultidisciplinary studies and could inform the development of more effective\nonline prediction markets, improve the accuracy of forecast, and help the\ndesign and optimization of platform mechanisms. The data and code for the paper\nare accessible at the following link: https://github.com/anonymous.", "published": "2024-07-20 11:17:19", "link": "http://arxiv.org/abs/2407.14844v1", "categories": ["cs.CY", "cs.HC", "cs.SI", "q-fin.TR"], "primary_category": "cs.CY"}
{"title": "Automatic Real-word Error Correction in Persian Text", "abstract": "Automatic spelling correction stands as a pivotal challenge within the ambit\nof natural language processing (NLP), demanding nuanced solutions. Traditional\nspelling correction techniques are typically only capable of detecting and\ncorrecting non-word errors, such as typos and misspellings. However,\ncontext-sensitive errors, also known as real-word errors, are more challenging\nto detect because they are valid words that are used incorrectly in a given\ncontext. The Persian language, characterized by its rich morphology and complex\nsyntax, presents formidable challenges to automatic spelling correction\nsystems. Furthermore, the limited availability of Persian language resources\nmakes it difficult to train effective spelling correction models. This paper\nintroduces a cutting-edge approach for precise and efficient real-word error\ncorrection in Persian text. Our methodology adopts a structured, multi-tiered\napproach, employing semantic analysis, feature selection, and advanced\nclassifiers to enhance error detection and correction efficacy. The innovative\narchitecture discovers and stores semantic similarities between words and\nphrases in Persian text. The classifiers accurately identify real-word errors,\nwhile the semantic ranking algorithm determines the most probable corrections\nfor real-word errors, taking into account specific spelling correction and\ncontext properties such as context, semantic similarity, and edit-distance\nmeasures. Evaluations have demonstrated that our proposed method surpasses\nprevious Persian real-word error correction models. Our method achieves an\nimpressive F-measure of 96.6% in the detection phase and an accuracy of 99.1%\nin the correction phase. These results clearly indicate that our approach is a\nhighly promising solution for automatic real-word error correction in Persian\ntext.", "published": "2024-07-20 07:50:52", "link": "http://arxiv.org/abs/2407.14795v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Style Transfer: An Introductory Overview", "abstract": "Text Style Transfer (TST) is a pivotal task in natural language generation to\nmanipulate text style attributes while preserving style-independent content.\nThe attributes targeted in TST can vary widely, including politeness,\nauthorship, mitigation of offensive language, modification of feelings, and\nadjustment of text formality. TST has become a widely researched topic with\nsubstantial advancements in recent years. This paper provides an introductory\noverview of TST, addressing its challenges, existing approaches, datasets,\nevaluation measures, subtasks, and applications. This fundamental overview\nimproves understanding of the background and fundamentals of text style\ntransfer.", "published": "2024-07-20 09:54:55", "link": "http://arxiv.org/abs/2407.14822v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of AI-Debater 2023: The Challenges of Argument Generation Tasks", "abstract": "In this paper we present the results of the AI-Debater 2023 Challenge held by\nthe Chinese Conference on Affect Computing (CCAC 2023), and introduce the\nrelated datasets. We organize two tracks to handle the argumentative generation\ntasks in different scenarios, namely, Counter-Argument Generation (Track 1) and\nClaim-based Argument Generation (Track 2). Each track is equipped with its\ndistinct dataset and baseline model respectively. In total, 32 competing teams\nregister for the challenge, from which we received 11 successful submissions.\nIn this paper, we will present the results of the challenge and a summary of\nthe systems, highlighting commonalities and innovations among participating\nsystems. Datasets and baseline models of the AI-Debater 2023 Challenge have\nbeen already released and can be accessed through the official website of the\nchallenge.", "published": "2024-07-20 10:13:54", "link": "http://arxiv.org/abs/2407.14829v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Seal: Advancing Speech Language Models to be Few-Shot Learners", "abstract": "Existing auto-regressive language models have demonstrated a remarkable\ncapability to perform a new task with just a few examples in prompt, without\nrequiring any additional training. In order to extend this capability to a\nmulti-modal setting (i.e. speech and language), this paper introduces the Seal\nmodel, an abbreviation for speech language model. It incorporates a novel\nalignment method, in which Kullback-Leibler divergence loss is performed to\ntrain a projector that bridges a frozen speech encoder with a frozen language\nmodel decoder. The resulting Seal model exhibits robust performance as a\nfew-shot learner on two speech understanding tasks. Additionally, consistency\nexperiments are conducted to validate its robustness on different pre-trained\nlanguage models.", "published": "2024-07-20 13:28:12", "link": "http://arxiv.org/abs/2407.14875v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modular Sentence Encoders: Separating Language Specialization from\n  Cross-Lingual Alignment", "abstract": "Multilingual sentence encoders are commonly obtained by training multilingual\nlanguage models to map sentences from different languages into a shared\nsemantic space. As such, they are subject to curse of multilinguality, a loss\nof monolingual representational accuracy due to parameter sharing. Another\nlimitation of multilingual sentence encoders is the trade-off between\nmonolingual and cross-lingual performance. Training for cross-lingual alignment\nof sentence embeddings distorts the optimal monolingual structure of semantic\nspaces of individual languages, harming the utility of sentence embeddings in\nmonolingual tasks. In this work, we address both issues by modular training of\nsentence encoders, i.e., by separating monolingual specialization from\ncross-lingual alignment. We first efficiently train language-specific sentence\nencoders to avoid negative interference between languages (i.e., the curse). We\nthen align all non-English monolingual encoders to the English encoder by\ntraining a cross-lingual alignment adapter on top of each, preventing\ninterference with monolingual specialization from the first step. In both\nsteps, we resort to contrastive learning on machine-translated paraphrase data.\nMonolingual and cross-lingual evaluations on semantic text\nsimilarity/relatedness and multiple-choice QA render our modular solution more\neffective than multilingual sentence encoders, especially benefiting\nlow-resource languages.", "published": "2024-07-20 13:56:39", "link": "http://arxiv.org/abs/2407.14878v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Economy Watchers Survey Provides Datasets and Tasks for Japanese\n  Financial Domain", "abstract": "Natural language processing (NLP) tasks in English and general domains are\nwidely available and are often used to evaluate pre-trained language models. In\ncontrast, fewer tasks are available for languages other than English and in the\nfinancial domain. Particularly, tasks in the Japanese and financial domains are\nlimited. We develop two large datasets using data published by a Japanese\ncentral government agency. The datasets provide three Japanese financial NLP\ntasks, including 3- and 12-class classifications for categorizing sentences,\nalong with a 5-class classification task for sentiment analysis. Our datasets\nare designed to be comprehensive and updated by leveraging an automatic update\nframework that ensures that the latest task datasets are publicly always\navailable.", "published": "2024-07-20 02:35:14", "link": "http://arxiv.org/abs/2407.14727v2", "categories": ["cs.CL", "cs.CE"], "primary_category": "cs.CL"}
{"title": "I Need Help! Evaluating LLM's Ability to Ask for Users' Support: A Case\n  Study on Text-to-SQL Generation", "abstract": "This study explores the proactive ability of LLMs to seek user support. We\npropose metrics to evaluate the trade-off between performance improvements and\nuser burden, and investigate whether LLMs can determine when to request help\nunder varying information availability. Our experiments show that without\nexternal feedback, many LLMs struggle to recognize their need for user support.\nThe findings highlight the importance of external signals and provide insights\nfor future research on improving support-seeking strategies. Source code:\nhttps://github.com/appier-research/i-need-help", "published": "2024-07-20 06:12:29", "link": "http://arxiv.org/abs/2407.14767v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PERCORE: A Deep Learning-Based Framework for Persian Spelling Correction\n  with Phonetic Analysis", "abstract": "This research introduces a state-of-the-art Persian spelling correction\nsystem that seamlessly integrates deep learning techniques with phonetic\nanalysis, significantly enhancing the accuracy and efficiency of natural\nlanguage processing (NLP) for Persian. Utilizing a fine-tuned language\nrepresentation model, our methodology effectively combines deep contextual\nanalysis with phonetic insights, adeptly correcting both non-word and real-word\nspelling errors. This strategy proves particularly effective in tackling the\nunique complexities of Persian spelling, including its elaborate morphology and\nthe challenge of homophony. A thorough evaluation on a wide-ranging dataset\nconfirms our system's superior performance compared to existing methods, with\nimpressive F1-Scores of 0.890 for detecting real-word errors and 0.905 for\ncorrecting them. Additionally, the system demonstrates a strong capability in\nnon-word error correction, achieving an F1-Score of 0.891. These results\nillustrate the significant benefits of incorporating phonetic insights into\ndeep learning models for spelling correction. Our contributions not only\nadvance Persian language processing by providing a versatile solution for a\nvariety of NLP applications but also pave the way for future research in the\nfield, emphasizing the critical role of phonetic analysis in developing\neffective spelling correction system.", "published": "2024-07-20 07:41:04", "link": "http://arxiv.org/abs/2407.14789v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?", "abstract": "Solving grid puzzles involves a significant amount of logical reasoning.\nHence, it is a good domain to evaluate the reasoning capability of a model\nwhich can then guide us to improve the reasoning ability of models. However,\nmost existing works evaluate only the final predicted answer of a puzzle,\nwithout delving into an in-depth analysis of the LLMs' reasoning chains (such\nas where they falter) or providing any finer metrics to evaluate them. Since\nLLMs may rely on simple heuristics or artifacts to predict the final answer, it\nis crucial to evaluate the generated reasoning chain beyond overall correctness\nmeasures, for accurately evaluating the reasoning abilities of LLMs. To this\nend, we first develop GridPuzzle, an evaluation dataset comprising 274\ngrid-based puzzles with different complexities. Second, we propose a new error\ntaxonomy derived from manual analysis of reasoning chains from LLMs including\nGPT-4, Claude-3, Gemini, Mistral, and Llama-2. Then, we develop an LLM-based\nframework for large-scale subjective evaluation (i.e., identifying errors) and\nan objective metric, PuzzleEval, to evaluate the correctness of reasoning\nchains. Evaluating reasoning chains from LLMs leads to several interesting\nfindings. We further show that existing prompting methods used for enhancing\nmodels' reasoning abilities do not improve performance on GridPuzzle. This\nhighlights the importance of understanding fine-grained errors and presents a\nchallenge for future research to enhance LLMs' puzzle-solving abilities by\ndeveloping methods that address these errors. Data and source code are\navailable at https://github.com/Mihir3009/GridPuzzle.", "published": "2024-07-20 07:43:07", "link": "http://arxiv.org/abs/2407.14790v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding the Relationship between Prompts and Response Uncertainty\n  in Large Language Models", "abstract": "Large language models (LLMs) are widely used in decision-making, but their\nreliability, especially in critical tasks like healthcare, is not\nwell-established. Therefore, understanding how LLMs reason and make decisions\nis crucial for their safe deployment. This paper investigates how the\nuncertainty of responses generated by LLMs relates to the information provided\nin the input prompt. Leveraging the insight that LLMs learn to infer latent\nconcepts during pretraining, we propose a prompt-response concept model that\nexplains how LLMs generate responses and helps understand the relationship\nbetween prompts and response uncertainty. We show that the uncertainty\ndecreases as the prompt's informativeness increases, similar to epistemic\nuncertainty. Our detailed experimental results on real-world datasets validate\nour proposed model.", "published": "2024-07-20 11:19:58", "link": "http://arxiv.org/abs/2407.14845v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Falcon2-11B Technical Report", "abstract": "We introduce Falcon2-11B, a foundation model trained on over five trillion\ntokens, and its multimodal counterpart, Falcon2-11B-vlm, which is a\nvision-to-text model. We report our findings during the training of the\nFalcon2-11B which follows a multi-stage approach where the early stages are\ndistinguished by their context length and a final stage where we use a curated,\nhigh-quality dataset. Additionally, we report the effect of doubling the batch\nsize mid-training and how training loss spikes are affected by the learning\nrate. The downstream performance of the foundation model is evaluated on\nestablished benchmarks, including multilingual and code datasets. The\nfoundation model shows strong generalization across all the tasks which makes\nit suitable for downstream finetuning use cases. For the vision language model,\nwe report the performance on several benchmarks and show that our model\nachieves a higher average score compared to open-source models of similar size.\nThe model weights and code of both Falcon2-11B and Falcon2-11B-vlm are made\navailable under a permissive license.", "published": "2024-07-20 14:23:15", "link": "http://arxiv.org/abs/2407.14885v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Operationalizing a Threat Model for Red-Teaming Large Language Models\n  (LLMs)", "abstract": "Creating secure and resilient applications with large language models (LLM)\nrequires anticipating, adjusting to, and countering unforeseen threats.\nRed-teaming has emerged as a critical technique for identifying vulnerabilities\nin real-world LLM implementations. This paper presents a detailed threat model\nand provides a systematization of knowledge (SoK) of red-teaming attacks on\nLLMs. We develop a taxonomy of attacks based on the stages of the LLM\ndevelopment and deployment process and extract various insights from previous\nresearch. In addition, we compile methods for defense and practical red-teaming\nstrategies for practitioners. By delineating prominent attack motifs and\nshedding light on various entry points, this paper provides a framework for\nimproving the security and robustness of LLM-based systems.", "published": "2024-07-20 17:05:04", "link": "http://arxiv.org/abs/2407.14937v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Improving Citation Text Generation: Overcoming Limitations in Length\n  Control", "abstract": "A key challenge in citation text generation is that the length of generated\ntext often differs from the length of the target, lowering the quality of the\ngeneration. While prior works have investigated length-controlled generation,\ntheir effectiveness depends on knowing the appropriate generation length. In\nthis work, we present an in-depth study of the limitations of predicting\nscientific citation text length and explore the use of heuristic estimates of\ndesired length.", "published": "2024-07-20 22:10:37", "link": "http://arxiv.org/abs/2407.14997v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Hard Prompts Made Interpretable: Sparse Entropy Regularization for\n  Prompt Tuning with RL", "abstract": "With the advent of foundation models, prompt tuning has positioned itself as\nan important technique for directing model behaviors and eliciting desired\nresponses. Prompt tuning regards selecting appropriate keywords included into\nthe input, thereby adapting to the downstream task without adjusting or\nfine-tuning the model parameters. There is a wide range of work in prompt\ntuning, from approaches that directly harness the backpropagated gradient\nsignals from the model, to those employing black-box optimization such as\nreinforcement learning (RL) methods. Our primary focus is on RLPrompt, which\naims to find optimal prompt tokens leveraging soft Q-learning. While the\nresults show promise, we have observed that the prompts frequently appear\nunnatural, which impedes their interpretability. We address this limitation by\nusing sparse Tsallis entropy regularization, a principled approach to filtering\nout unlikely tokens from consideration. We extensively evaluate our approach\nacross various tasks, including few-shot text classification, unsupervised text\nstyle transfer, and textual inversion from images. The results indicate a\nnotable improvement over baselines, highlighting the efficacy of our approach\nin addressing the challenges of prompt tuning. Moreover, we show that the\nprompts discovered using our method are more natural and interpretable compared\nto those from other baselines.", "published": "2024-07-20 03:10:19", "link": "http://arxiv.org/abs/2407.14733v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "On the Design and Analysis of LLM-Based Algorithms", "abstract": "We initiate a formal investigation into the design and analysis of LLM-based\nalgorithms, i.e. algorithms that contain one or multiple calls of large\nlanguage models (LLMs) as sub-routines and critically rely on the capabilities\nof LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt\nengineering to complicated LLM-powered agent systems and compound AI systems,\nhave achieved remarkable empirical success, the design and optimization of them\nhave mostly relied on heuristics and trial-and-errors, which is largely due to\na lack of formal and analytical study for these algorithms. To fill this gap,\nwe start by identifying the computational-graph representation of LLM-based\nalgorithms, the design principle of task decomposition, and some key\nabstractions, which then facilitate our formal analysis for the accuracy and\nefficiency of LLM-based algorithms, despite the black-box nature of LLMs.\nThrough extensive analytical and empirical investigation in a series of case\nstudies, we demonstrate that the proposed framework is broadly applicable to a\nwide range of scenarios and diverse patterns of LLM-based algorithms, such as\nparallel, hierarchical and recursive task decomposition. Our proposed framework\nholds promise for advancing LLM-based algorithms, by revealing the reasons\nbehind curious empirical phenomena, guiding the choices of hyperparameters,\npredicting the empirical performance of algorithms, and inspiring new algorithm\ndesign. To promote further study of LLM-based algorithms, we release our source\ncode at\nhttps://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.", "published": "2024-07-20 07:39:07", "link": "http://arxiv.org/abs/2407.14788v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large-vocabulary forensic pathological analyses via prototypical\n  cross-modal contrastive learning", "abstract": "Forensic pathology is critical in determining the cause and manner of death\nthrough post-mortem examinations, both macroscopic and microscopic. The field,\nhowever, grapples with issues such as outcome variability, laborious processes,\nand a scarcity of trained professionals. This paper presents SongCi, an\ninnovative visual-language model (VLM) designed specifically for forensic\npathology. SongCi utilizes advanced prototypical cross-modal self-supervised\ncontrastive learning to enhance the accuracy, efficiency, and generalizability\nof forensic analyses. It was pre-trained and evaluated on a comprehensive\nmulti-center dataset, which includes over 16 million high-resolution image\npatches, 2,228 vision-language pairs of post-mortem whole slide images (WSIs),\nand corresponding gross key findings, along with 471 distinct diagnostic\noutcomes. Our findings indicate that SongCi surpasses existing multi-modal AI\nmodels in many forensic pathology tasks, performs comparably to experienced\nforensic pathologists and significantly better than less experienced ones, and\nprovides detailed multi-modal explainability, offering critical assistance in\nforensic investigations. To the best of our knowledge, SongCi is the first VLM\nspecifically developed for forensic pathological analysis and the first\nlarge-vocabulary computational pathology (CPath) model that directly processes\ngigapixel WSIs in forensic science.", "published": "2024-07-20 15:34:52", "link": "http://arxiv.org/abs/2407.14904v1", "categories": ["eess.IV", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Improving Context-Aware Preference Modeling for Language Models", "abstract": "While finetuning language models from pairwise preferences has proven\nremarkably effective, the underspecified nature of natural language presents\ncritical challenges. Direct preference feedback is uninterpretable, difficult\nto provide where multidimensional criteria may apply, and often inconsistent,\neither because it is based on incomplete instructions or provided by diverse\nprincipals. To address these challenges, we consider the two-step preference\nmodeling procedure that first resolves the under-specification by selecting a\ncontext, and then evaluates preference with respect to the chosen context. We\ndecompose reward modeling error according to these two steps, which suggests\nthat supervising context in addition to context-specific preference may be a\nviable approach to aligning models with diverse human preferences. For this to\nwork, the ability of models to evaluate context-specific preference is\ncritical. To this end, we contribute context-conditioned preference datasets\nand accompanying experiments that investigate the ability of language models to\nevaluate context-specific preference. We use our datasets to (1) show that\nexisting preference models benefit from, but fail to fully consider, added\ncontext, (2) finetune a context-aware reward model with context-specific\nperformance exceeding that of GPT-4 and Llama 3 70B on tested datasets, and (3)\ninvestigate the value of context-aware preference modeling.", "published": "2024-07-20 16:05:17", "link": "http://arxiv.org/abs/2407.14916v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Consent in Crisis: The Rapid Decline of the AI Data Commons", "abstract": "General-purpose artificial intelligence (AI) systems are built on massive\nswathes of public web data, assembled into corpora such as C4, RefinedWeb, and\nDolma. To our knowledge, we conduct the first, large-scale, longitudinal audit\nof the consent protocols for the web domains underlying AI training corpora.\nOur audit of 14,000 web domains provides an expansive view of crawlable web\ndata and how codified data use preferences are changing over time. We observe a\nproliferation of AI-specific clauses to limit use, acute differences in\nrestrictions on AI developers, as well as general inconsistencies between\nwebsites' expressed intentions in their Terms of Service and their robots.txt.\nWe diagnose these as symptoms of ineffective web protocols, not designed to\ncope with the widespread re-purposing of the internet for AI. Our longitudinal\nanalyses show that in a single year (2023-2024) there has been a rapid\ncrescendo of data restrictions from web sources, rendering ~5%+ of all tokens\nin C4, or 28%+ of the most actively maintained, critical sources in C4, fully\nrestricted from use. For Terms of Service crawling restrictions, a full 45% of\nC4 is now restricted. If respected or enforced, these restrictions are rapidly\nbiasing the diversity, freshness, and scaling laws for general-purpose AI\nsystems. We hope to illustrate the emerging crises in data consent, for both\ndevelopers and creators. The foreclosure of much of the open web will impact\nnot only commercial AI, but also non-commercial AI and academic research.", "published": "2024-07-20 16:50:18", "link": "http://arxiv.org/abs/2407.14933v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Conversational Rubert for Detecting Competitive Interruptions in\n  ASR-Transcribed Dialogues", "abstract": "Interruption in a dialogue occurs when the listener begins their speech\nbefore the current speaker finishes speaking. Interruptions can be broadly\ndivided into two groups: cooperative (when the listener wants to support the\nspeaker), and competitive (when the listener tries to take control of the\nconversation against the speaker's will). A system that automatically\nclassifies interruptions can be used in call centers, specifically in the tasks\nof customer satisfaction monitoring and agent monitoring. In this study, we\ndeveloped a text-based interruption classification model by preparing an\nin-house dataset consisting of ASR-transcribed customer support telephone\ndialogues in Russian. We fine-tuned Conversational RuBERT on our dataset and\noptimized hyperparameters, and the model performed well. With further\nimprovements, the proposed model can be applied to automatic monitoring\nsystems.", "published": "2024-07-20 17:25:53", "link": "http://arxiv.org/abs/2407.14940v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Recent Advances in Generative AI and Large Language Models: Current\n  Status, Challenges, and Perspectives", "abstract": "The emergence of Generative Artificial Intelligence (AI) and Large Language\nModels (LLMs) has marked a new era of Natural Language Processing (NLP),\nintroducing unprecedented capabilities that are revolutionizing various\ndomains. This paper explores the current state of these cutting-edge\ntechnologies, demonstrating their remarkable advancements and wide-ranging\napplications. Our paper contributes to providing a holistic perspective on the\ntechnical foundations, practical applications, and emerging challenges within\nthe evolving landscape of Generative AI and LLMs. We believe that understanding\nthe generative capabilities of AI systems and the specific context of LLMs is\ncrucial for researchers, practitioners, and policymakers to collaboratively\nshape the responsible and ethical integration of these technologies into\nvarious domains. Furthermore, we identify and address main research gaps,\nproviding valuable insights to guide future research endeavors within the AI\nresearch community.", "published": "2024-07-20 18:48:35", "link": "http://arxiv.org/abs/2407.14962v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sim-CLIP: Unsupervised Siamese Adversarial Fine-Tuning for Robust and\n  Semantically-Rich Vision-Language Models", "abstract": "Vision-language models (VLMs) have achieved significant strides in recent\ntimes specially in multimodal tasks, yet they remain susceptible to adversarial\nattacks on their vision components. To address this, we propose Sim-CLIP, an\nunsupervised adversarial fine-tuning method that enhances the robustness of the\nwidely-used CLIP vision encoder against such attacks while maintaining semantic\nrichness and specificity. By employing a Siamese architecture with cosine\nsimilarity loss, Sim-CLIP learns semantically meaningful and attack-resilient\nvisual representations without requiring large batch sizes or momentum\nencoders. Our results demonstrate that VLMs enhanced with Sim-CLIP's fine-tuned\nCLIP encoder exhibit significantly enhanced robustness against adversarial\nattacks, while preserving semantic meaning of the perturbed images. Notably,\nSim-CLIP does not require additional training or fine-tuning of the VLM itself;\nreplacing the original vision encoder with our fine-tuned Sim-CLIP suffices to\nprovide robustness. This work underscores the significance of reinforcing\nfoundational models like CLIP to safeguard the reliability of downstream VLM\napplications, paving the way for more secure and effective multimodal systems.", "published": "2024-07-20 19:53:52", "link": "http://arxiv.org/abs/2407.14971v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Generalization v.s. Memorization: Tracing Language Models' Capabilities\n  Back to Pretraining Data", "abstract": "The impressive capabilities of large language models (LLMs) have sparked\ndebate over whether these models genuinely generalize to unseen tasks or\npredominantly rely on memorizing vast amounts of pretraining data. To explore\nthis issue, we introduce an extended concept of memorization, distributional\nmemorization, which measures the correlation between the LLM output\nprobabilities and the pretraining data frequency. To effectively capture\ntask-specific pretraining data frequency, we propose a novel task-gram language\nmodel, which is built by counting the co-occurrence of semantically related\n$n$-gram pairs from task inputs and outputs in the pretraining corpus. Using\nthe Pythia models trained on the Pile dataset, we evaluate four distinct tasks:\nmachine translation, factual question answering, world knowledge understanding,\nand math reasoning. Our findings reveal varying levels of memorization, with\nthe strongest effect observed in factual question answering. Furthermore, while\nmodel performance improves across all tasks as LLM size increases, only factual\nquestion answering shows an increase in memorization, whereas machine\ntranslation and reasoning tasks exhibit greater generalization, producing more\nnovel outputs. This study demonstrates that memorization plays a larger role in\nsimpler, knowledge-intensive tasks, while generalization is the key for harder,\nreasoning-based tasks, providing a scalable method for analyzing large\npretraining corpora in greater depth.", "published": "2024-07-20 21:24:40", "link": "http://arxiv.org/abs/2407.14985v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mapping the Technological Future: A Topic, Sentiment, and Emotion\n  Analysis in Social Media Discourse", "abstract": "People worldwide are currently confronted with a number of technological\nchallenges, which act as a potent source of uncertainty. The uncertainty\narising from the volatility and unpredictability of technology (such as AI) and\nits potential consequences is widely discussed on social media. This study uses\nBERTopic modelling along with sentiment and emotion analysis on 1.5 million\ntweets from 2021 to 2023 to identify anticipated tech-driven futures and\ncapture the emotions communicated by 400 key opinion leaders (KOLs). Findings\nindicate positive sentiment significantly outweighs negative, with a prevailing\ndominance of positive anticipatory emotions. Specifically, the 'Hope' score is\napproximately 10.33\\% higher than the median 'Anxiety' score. KOLs emphasize\n'Optimism' and benefits over 'Pessimism' and challenges. The study emphasizes\nthe important role KOLs play in shaping future visions through anticipatory\ndiscourse and emotional tone during times of technological uncertainty.", "published": "2024-07-20 18:15:30", "link": "http://arxiv.org/abs/2407.17522v1", "categories": ["cs.AI", "cs.CL", "cs.SI", "stat.AP", "J.4"], "primary_category": "cs.AI"}
{"title": "Mapping Patient Trajectories: Understanding and Visualizing Sepsis\n  Prognostic Pathways from Patients Clinical Narratives", "abstract": "In recent years, healthcare professionals are increasingly emphasizing on\npersonalized and evidence-based patient care through the exploration of\nprognostic pathways. To study this, structured clinical variables from\nElectronic Health Records (EHRs) data have traditionally been employed by many\nresearchers. Presently, Natural Language Processing models have received great\nattention in clinical research which expanded the possibilities of using\nclinical narratives. In this paper, we propose a systematic methodology for\ndeveloping sepsis prognostic pathways derived from clinical notes, focusing on\ndiverse patient subgroups identified by exploring comorbidities associated with\nsepsis and generating explanations of these subgroups using SHAP. The extracted\nprognostic pathways of these subgroups provide valuable insights into the\ndynamic trajectories of sepsis severity over time. Visualizing these pathways\nsheds light on the likelihood and direction of disease progression across\nvarious contexts and reveals patterns and pivotal factors or biomarkers\ninfluencing the transition between sepsis stages, whether toward deterioration\nor improvement. This empowers healthcare providers to implement more\npersonalized and effective healthcare strategies for individual patients.", "published": "2024-07-20 14:45:55", "link": "http://arxiv.org/abs/2407.21039v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation\n  for Industrial Knowledge Base", "abstract": "This paper introduces Golden-Retriever, designed to efficiently navigate vast\nindustrial knowledge bases, overcoming challenges in traditional LLM\nfine-tuning and RAG frameworks with domain-specific jargon and context\ninterpretation. Golden-Retriever incorporates a reflection-based question\naugmentation step before document retrieval, which involves identifying jargon,\nclarifying its meaning based on context, and augmenting the question\naccordingly. Specifically, our method extracts and lists all jargon and\nabbreviations in the input question, determines the context against a\npre-defined list, and queries a jargon dictionary for extended definitions and\ndescriptions. This comprehensive augmentation ensures the RAG framework\nretrieves the most relevant documents by providing clear context and resolving\nambiguities, significantly improving retrieval accuracy. Evaluations using\nthree open-source LLMs on a domain-specific question-answer dataset demonstrate\nGolden-Retriever's superior performance, providing a robust solution for\nefficiently integrating and querying industrial knowledge bases.", "published": "2024-07-20 06:10:46", "link": "http://arxiv.org/abs/2408.00798v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Multi-label audio classification with a noisy zero-shot teacher", "abstract": "We propose a novel training scheme using self-label correction and data\naugmentation methods designed to deal with noisy labels and improve real-world\naccuracy on a polyphonic audio content detection task. The augmentation method\nreduces label noise by mixing multiple audio clips and joining their labels,\nwhile being compatible with multiple active labels. We additionally show that\nperformance can be improved by a self-label correction method using the same\npretrained model. Finally, we show that it is feasible to use a strong\nzero-shot model such as CLAP to generate labels for unlabeled data and improve\nthe results using the proposed training and label enhancement methods. The\nresulting model performs similar to CLAP while being an efficient mobile device\nfriendly architecture and can be quickly adapted to unlabeled sound classes.", "published": "2024-07-20 00:34:15", "link": "http://arxiv.org/abs/2407.14712v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Towards Realistic Emotional Voice Conversion using Controllable\n  Emotional Intensity", "abstract": "Realistic emotional voice conversion (EVC) aims to enhance emotional\ndiversity of converted audios, making the synthesized voices more authentic and\nnatural. To this end, we propose Emotional Intensity-aware Network (EINet),\ndynamically adjusting intonation and rhythm by incorporating controllable\nemotional intensity. To better capture nuances in emotional intensity, we go\nbeyond mere distance measurements among acoustic features. Instead, an emotion\nevaluator is utilized to precisely quantify speaker's emotional state. By\nemploying an intensity mapper, intensity pseudo-labels are obtained to bridge\nthe gap between emotional speech intensity modeling and run-time conversion. To\nensure high speech quality while retaining controllability, an emotion renderer\nis used for combining linguistic features smoothly with manipulated emotional\nfeatures at frame level. Furthermore, we employ a duration predictor to\nfacilitate adaptive prediction of rhythm changes condition on specifying\nintensity value. Experimental results show EINet's superior performance in\nnaturalness and diversity of emotional expression compared to state-of-the-art\nEVC methods.", "published": "2024-07-20 08:13:58", "link": "http://arxiv.org/abs/2407.14800v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
