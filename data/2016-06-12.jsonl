{"title": "External Lexical Information for Multilingual Part-of-Speech Tagging", "abstract": "Morphosyntactic lexicons and word vector representations have both proven\nuseful for improving the accuracy of statistical part-of-speech taggers. Here\nwe compare the performances of four systems on datasets covering 16 languages,\ntwo of these systems being feature-based (MEMMs and CRFs) and two of them being\nneural-based (bi-LSTMs). We show that, on average, all four approaches perform\nsimilarly and reach state-of-the-art results. Yet better performances are\nobtained with our feature-based models on lexically richer datasets (e.g. for\nmorphologically rich languages), whereas neural-based results are higher on\ndatasets with less lexical variability (e.g. for English). These conclusions\nhold in particular for the MEMM models relying on our system MElt, which\nbenefited from newly designed features. This shows that, under certain\nconditions, feature-based approaches enriched with morphosyntactic lexicons are\ncompetitive with respect to neural methods.", "published": "2016-06-12 08:06:55", "link": "http://arxiv.org/abs/1606.03676v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Reinforcement Learning with a Combinatorial Action Space for\n  Predicting Popular Reddit Threads", "abstract": "We introduce an online popularity prediction and tracking task as a benchmark\ntask for reinforcement learning with a combinatorial, natural language action\nspace. A specified number of discussion threads predicted to be popular are\nrecommended, chosen from a fixed window of recent comments to track. Novel deep\nreinforcement learning architectures are studied for effective modeling of the\nvalue function associated with actions comprised of interdependent sub-actions.\nThe proposed model, which represents dependence between sub-actions through a\nbi-directional LSTM, gives the best performance across different experimental\nconfigurations and domains, and it also generalizes well with varying numbers\nof recommendation requests.", "published": "2016-06-12 05:38:20", "link": "http://arxiv.org/abs/1606.03667v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Belief Tracker: Data-Driven Dialogue State Tracking", "abstract": "One of the core components of modern spoken dialogue systems is the belief\ntracker, which estimates the user's goal at every step of the dialogue.\nHowever, most current approaches have difficulty scaling to larger, more\ncomplex dialogue domains. This is due to their dependency on either: a) Spoken\nLanguage Understanding models that require large amounts of annotated training\ndata; or b) hand-crafted lexicons for capturing some of the linguistic\nvariation in users' language. We propose a novel Neural Belief Tracking (NBT)\nframework which overcomes these problems by building on recent advances in\nrepresentation learning. NBT models reason over pre-trained word vectors,\nlearning to compose them into distributed representations of user utterances\nand dialogue context. Our evaluation on two datasets shows that this approach\nsurpasses past limitations, matching the performance of state-of-the-art models\nwhich rely on hand-crafted semantic lexicons and outperforming them when such\nlexicons are not provided.", "published": "2016-06-12 22:59:14", "link": "http://arxiv.org/abs/1606.03777v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Retrieving and Ranking Similar Questions from Question-Answer Archives\n  Using Topic Modelling and Topic Distribution Regression", "abstract": "Presented herein is a novel model for similar question ranking within\ncollaborative question answer platforms. The presented approach integrates a\nregression stage to relate topics derived from questions to those derived from\nquestion-answer pairs. This helps to avoid problems caused by the differences\nin vocabulary used within questions and answers, and the tendency for questions\nto be shorter than answers. The performance of the model is shown to outperform\ntranslation methods and topic modelling (without regression) on several\nreal-world datasets.", "published": "2016-06-12 23:50:19", "link": "http://arxiv.org/abs/1606.03783v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
