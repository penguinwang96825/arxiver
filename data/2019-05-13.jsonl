{"title": "Towards Content Transfer through Grounded Text Generation", "abstract": "Recent work in neural generation has attracted significant interest in\ncontrolling the form of text, such as style, persona, and politeness. However,\nthere has been less work on controlling neural text generation for content.\nThis paper introduces the notion of Content Transfer for long-form text\ngeneration, where the task is to generate a next sentence in a document that\nboth fits its context and is grounded in a content-rich external textual source\nsuch as a news story. Our experiments on Wikipedia data show significant\nimprovements against competitive baselines. As another contribution of this\npaper, we release a benchmark dataset of 640k Wikipedia referenced sentences\npaired with the source articles to encourage exploration of this new task.", "published": "2019-05-13 21:36:43", "link": "http://arxiv.org/abs/1905.05293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modelling Instance-Level Annotator Reliability for Natural Language\n  Labelling Tasks", "abstract": "When constructing models that learn from noisy labels produced by multiple\nannotators, it is important to accurately estimate the reliability of\nannotators. Annotators may provide labels of inconsistent quality due to their\nvarying expertise and reliability in a domain. Previous studies have mostly\nfocused on estimating each annotator's overall reliability on the entire\nannotation task. However, in practice, the reliability of an annotator may\ndepend on each specific instance. Only a limited number of studies have\ninvestigated modelling per-instance reliability and these only considered\nbinary labels. In this paper, we propose an unsupervised model which can handle\nboth binary and multi-class labels. It can automatically estimate the\nper-instance reliability of each annotator and the correct label for each\ninstance. We specify our model as a probabilistic model which incorporates\nneural networks to model the dependency between latent variables and instances.\nFor evaluation, the proposed method is applied to both synthetic and real data,\nincluding two labelling tasks: text classification and textual entailment.\nExperimental results demonstrate our novel method can not only accurately\nestimate the reliability of annotators across different instances, but also\nachieve superior performance in predicting the correct labels and detecting the\nleast reliable annotators compared to state-of-the-art baselines.", "published": "2019-05-13 11:40:09", "link": "http://arxiv.org/abs/1905.04981v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Review of Keyphrase Extraction", "abstract": "Keyphrase extraction is a textual information processing task concerned with\nthe automatic extraction of representative and characteristic phrases from a\ndocument that express all the key aspects of its content. Keyphrases constitute\na succinct conceptual summary of a document, which is very useful in digital\ninformation management systems for semantic indexing, faceted search, document\nclustering and classification. This article introduces keyphrase extraction,\nprovides a well-structured review of the existing work, offers interesting\ninsights on the different evaluation approaches, highlights open issues and\npresents a comparative experimental study of popular unsupervised techniques on\nfive datasets.", "published": "2019-05-13 14:01:08", "link": "http://arxiv.org/abs/1905.05044v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Transfer Learning for Scientific Data Chain Extraction in Small Chemical\n  Corpus with BERT-CRF Model", "abstract": "Computational chemistry develops fast in recent years due to the rapid growth\nand breakthroughs in AI. Thanks for the progress in natural language\nprocessing, researchers can extract more fine-grained knowledge in publications\nto stimulate the development in computational chemistry. While the works and\ncorpora in chemical entity extraction have been restricted in the biomedicine\nor life science field instead of the chemistry field, we build a new corpus in\nchemical bond field annotated for 7 types of entities: compound, solvent,\nmethod, bond, reaction, pKa and pKa value. This paper presents a novel BERT-CRF\nmodel to build scientific chemical data chains by extracting 7 chemical\nentities and relations from publications. And we propose a joint model to\nextract the entities and relations simultaneously. Experimental results on our\nChemical Special Corpus demonstrate that we achieve state-of-art and\ncompetitive NER performance.", "published": "2019-05-13 03:18:38", "link": "http://arxiv.org/abs/1905.05615v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Challenges in Building Intelligent Open-domain Dialog Systems", "abstract": "There is a resurgent interest in developing intelligent open-domain dialog\nsystems due to the availability of large amounts of conversational data and the\nrecent progress on neural approaches to conversational AI. Unlike traditional\ntask-oriented bots, an open-domain dialog system aims to establish long-term\nconnections with users by satisfying the human need for communication,\naffection, and social belonging. This paper reviews the recent works on neural\napproaches that are devoted to addressing three challenges in developing such\nsystems: semantics, consistency, and interactiveness. Semantics requires a\ndialog system to not only understand the content of the dialog but also\nidentify user's social needs during the conversation. Consistency requires the\nsystem to demonstrate a consistent personality to win users trust and gain\ntheir long-term confidence. Interactiveness refers to the system's ability to\ngenerate interpersonal responses to achieve particular social goals such as\nentertainment, conforming, and task completion. The works we select to present\nhere is based on our unique views and are by no means complete. Nevertheless,\nwe hope that the discussion will inspire new research in developing more\nintelligent dialog systems.", "published": "2019-05-13 02:46:28", "link": "http://arxiv.org/abs/1905.05709v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classifying Norm Conflicts using Learned Semantic Representations", "abstract": "While most social norms are informal, they are often formalized by companies\nin contracts to regulate trades of goods and services. When poorly written,\ncontracts may contain normative conflicts resulting from opposing deontic\nmeanings or contradict specifications. As contracts tend to be long and contain\nmany norms, manually identifying such conflicts requires human-effort, which is\ntime-consuming and error-prone. Automating such task benefits contract makers\nincreasing productivity and making conflict identification more reliable. To\naddress this problem, we introduce an approach to detect and classify norm\nconflicts in contracts by converting them into latent representations that\npreserve both syntactic and semantic information and training a model to\nclassify norm conflicts in four conflict types. Our results reach the new state\nof the art when compared to a previous approach.", "published": "2019-05-13 19:43:54", "link": "http://arxiv.org/abs/1906.02121v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Synchronous Bidirectional Neural Machine Translation", "abstract": "Existing approaches to neural machine translation (NMT) generate the target\nlanguage sequence token by token from left to right. However, this kind of\nunidirectional decoding framework cannot make full use of the target-side\nfuture contexts which can be produced in a right-to-left decoding direction,\nand thus suffers from the issue of unbalanced outputs. In this paper, we\nintroduce a synchronous bidirectional neural machine translation (SB-NMT) that\npredicts its outputs using left-to-right and right-to-left decoding\nsimultaneously and interactively, in order to leverage both of the history and\nfuture information at the same time. Specifically, we first propose a new\nalgorithm that enables synchronous bidirectional decoding in a single model.\nThen, we present an interactive decoding model in which left-to-right\n(right-to-left) generation does not only depend on its previously generated\noutputs, but also relies on future contexts predicted by right-to-left\n(left-to-right) decoding. We extensively evaluate the proposed SB-NMT model on\nlarge-scale NIST Chinese-English, WMT14 English-German, and WMT18\nRussian-English translation tasks. Experimental results demonstrate that our\nmodel achieves significant improvements over the strong Transformer model by\n3.92, 1.49 and 1.04 BLEU points respectively, and obtains the state-of-the-art\nperformance on Chinese-English and English-German translation tasks.", "published": "2019-05-13 03:34:14", "link": "http://arxiv.org/abs/1905.04847v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Quantifying and Alleviating the Language Prior Problem in Visual\n  Question Answering", "abstract": "Benefiting from the advancement of computer vision, natural language\nprocessing and information retrieval techniques, visual question answering\n(VQA), which aims to answer questions about an image or a video, has received\nlots of attentions over the past few years. Although some progress has been\nachieved so far, several studies have pointed out that current VQA models are\nheavily affected by the \\emph{language prior problem}, which means they tend to\nanswer questions based on the co-occurrence patterns of question keywords\n(e.g., how many) and answers (e.g., 2) instead of understanding images and\nquestions. Existing methods attempt to solve this problem by either balancing\nthe biased datasets or forcing models to better understand images. However,\nonly marginal effects and even performance deterioration are observed for the\nfirst and second solution, respectively. In addition, another important issue\nis the lack of measurement to quantitatively measure the extent of the language\nprior effect, which severely hinders the advancement of related techniques.\n  In this paper, we make contributions to solve the above problems from two\nperspectives. Firstly, we design a metric to quantitatively measure the\nlanguage prior effect of VQA models. The proposed metric has been demonstrated\nto be effective in our empirical studies. Secondly, we propose a regularization\nmethod (i.e., score regularization module) to enhance current VQA models by\nalleviating the language prior problem as well as boosting the backbone model\nperformance. The proposed score regularization module adopts a pair-wise\nlearning strategy, which makes the VQA models answer the question based on the\nreasoning of the image (upon this question) instead of basing on\nquestion-answer patterns observed in the biased training set. The score\nregularization module is flexible to be integrated into various VQA models.", "published": "2019-05-13 06:31:33", "link": "http://arxiv.org/abs/1905.04877v1", "categories": ["cs.CV", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Learning to Exploit Long-term Relational Dependencies in Knowledge\n  Graphs", "abstract": "We study the problem of knowledge graph (KG) embedding. A widely-established\nassumption to this problem is that similar entities are likely to have similar\nrelational roles. However, existing related methods derive KG embeddings mainly\nbased on triple-level learning, which lack the capability of capturing\nlong-term relational dependencies of entities. Moreover, triple-level learning\nis insufficient for the propagation of semantic information among entities,\nespecially for the case of cross-KG embedding. In this paper, we propose\nrecurrent skipping networks (RSNs), which employ a skipping mechanism to bridge\nthe gaps between entities. RSNs integrate recurrent neural networks (RNNs) with\nresidual learning to efficiently capture the long-term relational dependencies\nwithin and between KGs. We design an end-to-end framework to support RSNs on\ndifferent tasks. Our experimental results showed that RSNs outperformed\nstate-of-the-art embedding-based methods for entity alignment and achieved\ncompetitive performance for KG completion.", "published": "2019-05-13 08:53:31", "link": "http://arxiv.org/abs/1905.04914v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Almost Unsupervised Text to Speech and Automatic Speech Recognition", "abstract": "Text to speech (TTS) and automatic speech recognition (ASR) are two dual\ntasks in speech processing and both achieve impressive performance thanks to\nthe recent advance in deep learning and large amount of aligned speech and text\ndata. However, the lack of aligned data poses a major practical problem for TTS\nand ASR on low-resource languages. In this paper, by leveraging the dual nature\nof the two tasks, we propose an almost unsupervised learning method that only\nleverages few hundreds of paired data and extra unpaired data for TTS and ASR.\nOur method consists of the following components: (1) a denoising auto-encoder,\nwhich reconstructs speech and text sequences respectively to develop the\ncapability of language modeling both in speech and text domain; (2) dual\ntransformation, where the TTS model transforms the text $y$ into speech\n$\\hat{x}$, and the ASR model leverages the transformed pair $(\\hat{x},y)$ for\ntraining, and vice versa, to boost the accuracy of the two tasks; (3)\nbidirectional sequence modeling, which addresses error propagation especially\nin the long speech and text sequence when training with few paired data; (4) a\nunified model structure, which combines all the above components for TTS and\nASR based on Transformer model. Our method achieves 99.84% in terms of word\nlevel intelligible rate and 2.68 MOS for TTS, and 11.7% PER for ASR on LJSpeech\ndataset, by leveraging only 200 paired speech and text data (about 20 minutes\naudio), together with extra unpaired speech and text data.", "published": "2019-05-13 13:20:57", "link": "http://arxiv.org/abs/1905.06791v3", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MetricGAN: Generative Adversarial Networks based Black-box Metric Scores\n  Optimization for Speech Enhancement", "abstract": "Adversarial loss in a conditional generative adversarial network (GAN) is not\ndesigned to directly optimize evaluation metrics of a target task, and thus,\nmay not always guide the generator in a GAN to generate data with improved\nmetric scores. To overcome this issue, we propose a novel MetricGAN approach\nwith an aim to optimize the generator with respect to one or multiple\nevaluation metrics. Moreover, based on MetricGAN, the metric scores of the\ngenerated data can also be arbitrarily specified by users. We tested the\nproposed MetricGAN on a speech enhancement task, which is particularly suitable\nto verify the proposed approach because there are multiple metrics measuring\ndifferent aspects of speech signals. Moreover, these metrics are generally\ncomplex and could not be fully optimized by Lp or conventional adversarial\nlosses.", "published": "2019-05-13 06:21:59", "link": "http://arxiv.org/abs/1905.04874v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
