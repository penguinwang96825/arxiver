{"title": "Cutwidth Bounds via Vertex Partitions", "abstract": "We study the cutwidth measure on graphs and ways to bound the cutwidth of a\ngraph by partitioning its vertices. We consider bounds expressed as a function\nof two quantities: on the one hand, the maximal cutwidth y of the subgraphs\ninduced by the classes of the partition, and on the other hand, the cutwidth x\nof the quotient multigraph obtained by merging each class to a single vertex.\nWe consider in particular the decomposition of directed graphs into strongly\nconnected components (SCCs): in this case, y is the maximal cutwidth of an SCC,\nand x is the cutwidth of the directed acyclic condensation multigraph.\n  We show that the cutwidth of a graph is always in O(x + y), specifically it\ncan be upper bounded by 1.5x + y. We also show a lower bound justifying that\nthe constant 1.5 cannot be improved in general", "published": "2025-04-02 10:23:58", "link": "http://arxiv.org/abs/2504.01574v2", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "Vertex-Based Localization of Erd\u0151s-Gallai Theorems for Paths and Cycles", "abstract": "For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. The Erd\\H{o}s-Gallai theorem for paths states that\nin a simple $P_k$-free graph, $m \\leq \\frac{n(k-1)}{2}$, where $P_k$ denotes a\npath with length $k$ (that is, with $k$ edges). In this paper, we generalize\nthis result as follows: For each $v \\in V(G)$, let $p(v)$ be the length of the\nlongest path that contains $v$. We show that \\[m \\leq \\sum_{v \\in V(G)}\n\\frac{p(v)}{2}\\] The Erd\\H{o}s-Gallai theorem for cycles states that in a\nsimple graph $G$ with circumference (that is, the length of the longest cycle)\nat most $k$, we have $m \\leq \\frac{k(n-1)}{2}$. We strengthen this result as\nfollows: For each $v \\in V(G)$, let $c(v)$ be the length of the longest cycle\nthat contains $v$, or $2$ if $v$ is not part of any cycle. We prove that \\[m\n\\leq \\left( \\sum_{v \\in V(G)} \\frac{c(v)}{2} \\right) - \\frac{c(u)}{2}\\] where\n$c(u)$ denotes the circumference of $G$. \\newline Furthermore, we characterize\nthe class of extremal graphs that attain equality in these bounds.", "published": "2025-04-02 08:52:28", "link": "http://arxiv.org/abs/2504.01501v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Achieving Unanimous Consensus in Decision Making Using Multi-Agents", "abstract": "Blockchain consensus mechanisms have relied on algorithms such as\nProof-of-Work (PoW) and Proof-of-Stake (PoS) to ensure network functionality\nand integrity. However, these approaches struggle with adaptability for\ndecision-making where the opinions of each matter rather than reaching an\nagreement based on honest majority or weighted consensus. This paper introduces\na novel deliberation-based consensus mechanism where Large Language Models\n(LLMs) act as rational agents engaging in structured discussions to reach a\nunanimous consensus. By leveraging graded consensus and a multi-round\ndeliberation process, our approach ensures both unanimous consensus for\ndefinitive problems and graded confidence for prioritized decisions and\npolicies. We provide a formalization of our system and use it to show that the\nproperties of blockchains: consistency, agreement, liveness, and determinism\nare maintained. Moreover, experimental results demonstrate our system's\nfeasibility, showcasing how our deliberation method's convergence, block\nproperties, and accuracy enable decision-making on blockchain networks. We also\naddress key challenges with this novel approach such as degeneration of\nthoughts, hallucinations, malicious models and nodes, resource consumption, and\nscalability.", "published": "2025-04-02 21:02:54", "link": "http://arxiv.org/abs/2504.02128v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Self-Resource Allocation in Multi-Agent LLM Systems", "abstract": "With the development of LLMs as agents, there is a growing interest in\nconnecting multiple agents into multi-agent systems to solve tasks\nconcurrently, focusing on their role in task assignment and coordination. This\npaper explores how LLMs can effectively allocate computational tasks among\nmultiple agents, considering factors such as cost, efficiency, and performance.\nIn this work, we address key questions, including the effectiveness of LLMs as\norchestrators and planners, comparing their effectiveness in task assignment\nand coordination. Our experiments demonstrate that LLMs can achieve high\nvalidity and accuracy in resource allocation tasks. We find that the planner\nmethod outperforms the orchestrator method in handling concurrent actions,\nresulting in improved efficiency and better utilization of agents.\nAdditionally, we show that providing explicit information about worker\ncapabilities enhances the allocation strategies of planners, particularly when\ndealing with suboptimal workers.", "published": "2025-04-02 18:15:41", "link": "http://arxiv.org/abs/2504.02051v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Distributed Multi-agent Coordination over Cellular Sheaves", "abstract": "Techniques for coordination of multi-agent systems are vast and varied, often\nutilizing purpose-built solvers or controllers with tight coupling to the types\nof systems involved or the coordination goal. In this paper, we introduce a\ngeneral unified framework for heterogeneous multi-agent coordination using the\nlanguage of cellular sheaves and nonlinear sheaf Laplacians, which are\ngeneralizations of graphs and graph Laplacians. Specifically, we introduce the\nconcept of a nonlinear homological program encompassing a choice of cellular\nsheaf on an undirected graph, nonlinear edge potential functions, and\nconstrained convex node objectives, which constitutes a standard form for a\nwide class of coordination problems. We use the alternating direction method of\nmultipliers to derive a distributed optimization algorithm for solving these\nnonlinear homological programs. To demonstrate the applicability of this\nframework, we show how heterogeneous coordination goals including combinations\nof consensus, formation, and flocking can be formulated as nonlinear\nhomological programs and provide numerical simulations showing the efficacy of\nour distributed solution algorithm.", "published": "2025-04-02 18:13:22", "link": "http://arxiv.org/abs/2504.02049v2", "categories": ["math.OC", "cs.MA", "math.AT", "93A16, 93B45, 55N30"], "primary_category": "math.OC"}
{"title": "Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective Pruning", "abstract": "The Internet of Drones (IoD), where drones collaborate in data collection and\nanalysis, has become essential for applications such as surveillance and\nenvironmental monitoring. Federated learning (FL) enables drones to train\nmachine learning models in a decentralized manner while preserving data\nprivacy. However, FL in IoD networks is susceptible to attacks like data\npoisoning and model inversion. Federated unlearning (FU) mitigates these risks\nby eliminating adversarial data contributions, preventing their influence on\nthe model. This paper proposes sky of unlearning (SoUL), a federated unlearning\nframework that efficiently removes the influence of unlearned data while\nmaintaining model performance. A selective pruning algorithm is designed to\nidentify and remove neurons influential in unlearning but minimally impact the\noverall performance of the model. Simulations demonstrate that SoUL outperforms\nexisting unlearning methods, achieves accuracy comparable to full retraining,\nand reduces computation and communication overhead, making it a scalable and\nefficient solution for resource-constrained IoD networks.", "published": "2025-04-02 13:07:30", "link": "http://arxiv.org/abs/2504.01705v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Anticipating Degradation: A Predictive Approach to Fault Tolerance in Robot Swarms", "abstract": "An active approach to fault tolerance is essential for robot swarms to\nachieve long-term autonomy. Previous efforts have focused on responding to\nspontaneous electro-mechanical faults and failures. However, many faults occur\ngradually over time. Waiting until such faults have manifested as failures\nbefore addressing them is both inefficient and unsustainable in a variety of\nscenarios. This work argues that the principles of predictive maintenance, in\nwhich potential faults are resolved before they hinder the operation of the\nswarm, offer a promising means of achieving long-term fault tolerance. This is\na novel approach to swarm fault tolerance, which is shown to give a comparable\nor improved performance when tested against a reactive approach in almost all\ncases tested.", "published": "2025-04-02 10:59:10", "link": "http://arxiv.org/abs/2504.01594v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Jointly Exchangeable Collective Risk Models: Interaction, Structure, and Limit Theorems", "abstract": "We introduce a framework for systemic risk modeling in insurance portfolios\nusing jointly exchangeable arrays, extending classical collective risk models\nto account for interactions. We establish central limit theorems that\nasymptotically characterize total portfolio losses, providing a theoretical\nfoundation for approximations in large portfolios and over long time horizons.\nThese approximations are validated through simulation-based numerical\nexperiments. Additionally, we analyze the impact of dependence on portfolio\nloss distributions, with a particular focus on tail behavior.", "published": "2025-04-02 09:53:16", "link": "http://arxiv.org/abs/2504.06287v1", "categories": ["q-fin.RM", "math.PR", "q-fin.MF", "91G45, 60F05"], "primary_category": "q-fin.RM"}
{"title": "Aligned Better, Listen Better for Audio-Visual Large Language Models", "abstract": "Audio is essential for multimodal video understanding. On the one hand, video\ninherently contains audio, which supplies complementary information to vision.\nBesides, video large language models (Video-LLMs) can encounter many\naudio-centric settings. However, existing Video-LLMs and Audio-Visual Large\nLanguage Models (AV-LLMs) exhibit deficiencies in exploiting audio information,\nleading to weak understanding and hallucinations. To solve the issues, we delve\ninto the model architecture and dataset. (1) From the architectural\nperspective, we propose a fine-grained AV-LLM, namely Dolphin. The concurrent\nalignment of audio and visual modalities in both temporal and spatial\ndimensions ensures a comprehensive and accurate understanding of videos.\nSpecifically, we devise an audio-visual multi-scale adapter for multi-scale\ninformation aggregation, which achieves spatial alignment. For temporal\nalignment, we propose audio-visual interleaved merging. (2) From the dataset\nperspective, we curate an audio-visual caption and instruction-tuning dataset,\ncalled AVU. It comprises 5.2 million diverse, open-ended data tuples (video,\naudio, question, answer) and introduces a novel data partitioning strategy.\nExtensive experiments show our model not only achieves remarkable performance\nin audio-visual understanding, but also mitigates potential hallucinations.", "published": "2025-04-02 18:47:09", "link": "http://arxiv.org/abs/2504.02061v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Leveraging Embedding Techniques in Multimodal Machine Learning for Mental Illness Assessment", "abstract": "The increasing global prevalence of mental disorders, such as depression and\nPTSD, requires objective and scalable diagnostic tools. Traditional clinical\nassessments often face limitations in accessibility, objectivity, and\nconsistency. This paper investigates the potential of multimodal machine\nlearning to address these challenges, leveraging the complementary information\navailable in text, audio, and video data. Our approach involves a comprehensive\nanalysis of various data preprocessing techniques, including novel chunking and\nutterance-based formatting strategies. We systematically evaluate a range of\nstate-of-the-art embedding models for each modality and employ Convolutional\nNeural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature\nextraction. We explore data-level, feature-level, and decision-level fusion\ntechniques, including a novel integration of Large Language Model (LLM)\npredictions. We also investigate the impact of replacing Multilayer Perceptron\nclassifiers with Support Vector Machines. We extend our analysis to severity\nprediction using PHQ-8 and PCL-C scores and multi-class classification\n(considering co-occurring conditions). Our results demonstrate that\nutterance-based chunking significantly improves performance, particularly for\ntext and audio modalities. Decision-level fusion, incorporating LLM\npredictions, achieves the highest accuracy, with a balanced accuracy of 94.8%\nfor depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM\narchitectures with utterance-level chunking, coupled with the integration of\nexternal LLM, provides a powerful and nuanced approach to the detection and\nassessment of mental health conditions. Our findings highlight the potential of\nMMML for developing more accurate, accessible, and personalized mental\nhealthcare tools.", "published": "2025-04-02 14:19:06", "link": "http://arxiv.org/abs/2504.01767v1", "categories": ["eess.AS", "cs.AI", "cs.CV"], "primary_category": "eess.AS"}
{"title": "Token Pruning in Audio Transformers: Optimizing Performance and Decoding Patch Importance", "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance across\nvarious computer vision tasks, but their high computational cost remains a\nchallenge. Token pruning has been proposed to reduce this cost by selectively\nremoving less important tokens. While effective in vision tasks by discarding\nnon-object regions, applying this technique to audio tasks presents unique\nchallenges, as distinguishing relevant from irrelevant regions in\ntime-frequency representations is less straightforward. In this study, for the\nfirst time, we applied token pruning to ViT-based audio classification models\nusing Mel-spectrograms and analyzed the trade-offs between model performance\nand computational cost: TopK token pruning can reduce MAC operations of\nAudioMAE and AST by 30-40%, with less than a 1% drop in classification\naccuracy. Our analysis reveals that while high-intensity tokens contribute\nsignificantly to model accuracy, low-intensity tokens remain important. In\nparticular, they play a more critical role in general audio classification\ntasks than in speech-specific tasks.", "published": "2025-04-02 12:44:38", "link": "http://arxiv.org/abs/2504.01690v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Chain of Correction for Full-text Speech Recognition with Large Language Models", "abstract": "Full-text error correction with Large Language Models (LLMs) for Automatic\nSpeech Recognition (ASR) has gained increased attention due to its potential to\ncorrect errors across long contexts and address a broader spectrum of error\ntypes, including punctuation restoration and inverse text normalization.\nNevertheless, many challenges persist, including issues related to stability,\ncontrollability, completeness, and fluency. To mitigate these challenges, this\npaper proposes the Chain of Correction (CoC) for full-text error correction\nwith LLMs, which corrects errors segment by segment using pre-recognized text\nas guidance within a regular multi-turn chat format. The CoC also uses\npre-recognized full text for context, allowing the model to better grasp global\nsemantics and maintain a comprehensive overview of the entire content.\nUtilizing the open-sourced full-text error correction dataset ChFT, we\nfine-tune a pre-trained LLM to evaluate the performance of the CoC framework.\nExperimental results demonstrate that the CoC effectively corrects errors in\nfull-text ASR outputs, significantly outperforming baseline and benchmark\nsystems. We further analyze how to set the correction threshold to balance\nunder-correction and over-rephrasing, extrapolate the CoC model on extremely\nlong ASR outputs, and investigate whether other types of information can be\nemployed to guide the error correction process.", "published": "2025-04-02 09:06:23", "link": "http://arxiv.org/abs/2504.01519v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Spatial-Filter-Bank-Based Neural Method for Multichannel Speech Enhancement", "abstract": "The performance of deep learning-based multi-channel speech enhancement\nmethods often deteriorates when the geometric parameters of the microphone\narray change. Traditional approaches to mitigate this issue typically involve\ntraining on multiple microphone arrays, which can be costly. To address this\nchallenge, we focus on uniform circular arrays and propose the use of a spatial\nfilter bank to extract features that are approximately invariant to geometric\nparameters. These features are then processed by a two-stage conformer-based\nmodel (TSCBM) to enhance speech quality. Experimental results demonstrate that\nour proposed method can be trained on a fixed microphone array while\nmaintaining effective performance across uniform circular arrays with unseen\ngeometric configurations during applications.", "published": "2025-04-02 06:13:37", "link": "http://arxiv.org/abs/2504.01392v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "AIM: Acoustic Inertial Measurement for Indoor Drone Localization and Tracking", "abstract": "We present Acoustic Inertial Measurement (AIM), a one-of-a-kind technique for\nindoor drone localization and tracking. Indoor drone localization and tracking\nare arguably a crucial, yet unsolved challenge: in GPS-denied environments,\nexisting approaches enjoy limited applicability, especially in Non-Line of\nSight (NLoS), require extensive environment instrumentation, or demand\nconsiderable hardware/software changes on drones. In contrast, AIM exploits the\nacoustic characteristics of the drones to estimate their location and derive\ntheir motion, even in NLoS settings. We tame location estimation errors using a\ndedicated Kalman filter and the Interquartile Range rule (IQR). We implement\nAIM using an off-the-shelf microphone array and evaluate its performance with a\ncommercial drone under varied settings. Results indicate that the mean\nlocalization error of AIM is 46% lower than commercial UWB-based systems in\ncomplex indoor scenarios, where state-of-the-art infrared systems would not\neven work because of NLoS settings. We further demonstrate that AIM can be\nextended to support indoor spaces with arbitrary ranges and layouts without\nloss of accuracy by deploying distributed microphone arrays.", "published": "2025-04-02 02:01:16", "link": "http://arxiv.org/abs/2504.01297v1", "categories": ["cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
{"title": "BASIR: Budget-Assisted Sectoral Impact Ranking -- A Dataset for Sector Identification and Performance Prediction Using Language Models", "abstract": "Government fiscal policies, particularly annual union budgets, exert\nsignificant influence on financial markets. However, real-time analysis of\nbudgetary impacts on sector-specific equity performance remains\nmethodologically challenging and largely unexplored. This study proposes a\nframework to systematically identify and rank sectors poised to benefit from\nIndia's Union Budget announcements. The framework addresses two core tasks: (1)\nmulti-label classification of excerpts from budget transcripts into 81\npredefined economic sectors, and (2) performance ranking of these sectors.\nLeveraging a comprehensive corpus of Indian Union Budget transcripts from 1947\nto 2025, we introduce BASIR (Budget-Assisted Sectoral Impact Ranking), an\nannotated dataset mapping excerpts from budgetary transcripts to sectoral\nimpacts. Our architecture incorporates fine-tuned embeddings for sector\nidentification, coupled with language models that rank sectors based on their\npredicted performances. Our results demonstrate 0.605 F1-score in sector\nclassification, and 0.997 NDCG score in predicting ranks of sectors based on\npost-budget performances. The methodology enables investors and policymakers to\nquantify fiscal policy impacts through structured, data-driven insights,\naddressing critical gaps in manual analysis. The annotated dataset has been\nreleased under CC-BY-NC-SA-4.0 license to advance computational economics\nresearch.", "published": "2025-04-02 13:10:26", "link": "http://arxiv.org/abs/2504.13189v1", "categories": ["cs.CL", "q-fin.ST"], "primary_category": "cs.CL"}
