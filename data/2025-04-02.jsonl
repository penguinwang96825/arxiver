{"title": "Subasa - Adapting Language Models for Low-resourced Offensive Language Detection in Sinhala", "abstract": "Accurate detection of offensive language is essential for a number of\napplications related to social media safety. There is a sharp contrast in\nperformance in this task between low and high-resource languages. In this\npaper, we adapt fine-tuning strategies that have not been previously explored\nfor Sinhala in the downstream task of offensive language detection. Using this\napproach, we introduce four models: \"Subasa-XLM-R\", which incorporates an\nintermediate Pre-Finetuning step using Masked Rationale Prediction. Two\nvariants of \"Subasa-Llama\" and \"Subasa-Mistral\", are fine-tuned versions of\nLlama (3.2) and Mistral (v0.3), respectively, with a task-specific strategy. We\nevaluate our models on the SOLD benchmark dataset for Sinhala offensive\nlanguage detection. All our models outperform existing baselines. Subasa-XLM-R\nachieves the highest Macro F1 score (0.84) surpassing state-of-the-art large\nlanguage models like GPT-4o when evaluated on the same SOLD benchmark dataset\nunder zero-shot settings. The models and code are publicly available.", "published": "2025-04-02 23:46:49", "link": "http://arxiv.org/abs/2504.02178v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Practical Synthesis of Detecting AI-Generated Textual, Visual, and Audio Content", "abstract": "Advances in AI-generated content have led to wide adoption of large language\nmodels, diffusion-based visual generators, and synthetic audio tools. However,\nthese developments raise critical concerns about misinformation, copyright\ninfringement, security threats, and the erosion of public trust. In this paper,\nwe explore an extensive range of methods designed to detect and mitigate\nAI-generated textual, visual, and audio content. We begin by discussing\nmotivations and potential impacts associated with AI-based content generation,\nincluding real-world risks and ethical dilemmas. We then outline detection\ntechniques spanning observation-based strategies, linguistic and statistical\nanalysis, model-based pipelines, watermarking and fingerprinting, as well as\nemergent ensemble approaches. We also present new perspectives on robustness,\nadaptation to rapidly improving generative architectures, and the critical role\nof human-in-the-loop verification. By surveying state-of-the-art research and\nhighlighting case studies in academic, journalistic, legal, and industrial\ncontexts, this paper aims to inform robust solutions and policymaking. We\nconclude by discussing open challenges, including adversarial transformations,\ndomain generalization, and ethical concerns, thereby offering a holistic guide\nfor researchers, practitioners, and regulators to preserve content authenticity\nin the face of increasingly sophisticated AI-generated media.", "published": "2025-04-02 23:27:55", "link": "http://arxiv.org/abs/2504.02898v1", "categories": ["cs.CL", "cs.LG", "68T50, 68T45, 68T10, 68T30, 94A08, 62H30, 68U10", "I.2.7; I.2.10; I.2.6; H.5.5; K.6.5; K.4.1; I.4.9; H.3.1"], "primary_category": "cs.CL"}
{"title": "Neural Style Transfer for Synthesising a Dataset of Ancient Egyptian Hieroglyphs", "abstract": "The limited availability of training data for low-resource languages makes\napplying machine learning techniques challenging. Ancient Egyptian is one such\nlanguage with few resources. However, innovative applications of data\naugmentation methods, such as Neural Style Transfer, could overcome these\nbarriers. This paper presents a novel method for generating datasets of ancient\nEgyptian hieroglyphs by applying NST to a digital typeface. Experimental\nresults found that image classification models trained on NST-generated\nexamples and photographs demonstrate equal performance and transferability to\nreal unseen images of hieroglyphs.", "published": "2025-04-02 22:30:45", "link": "http://arxiv.org/abs/2504.02163v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "LL4G: Self-Supervised Dynamic Optimization for Graph-Based Personality Detection", "abstract": "Graph-based personality detection constructs graph structures from textual\ndata, particularly social media posts. Current methods often struggle with\nsparse or noisy data and rely on static graphs, limiting their ability to\ncapture dynamic changes between nodes and relationships. This paper introduces\nLL4G, a self-supervised framework leveraging large language models (LLMs) to\noptimize graph neural networks (GNNs). LLMs extract rich semantic features to\ngenerate node representations and to infer explicit and implicit relationships.\nThe graph structure adaptively adds nodes and edges based on input data,\ncontinuously optimizing itself. The GNN then uses these optimized\nrepresentations for joint training on node reconstruction, edge prediction, and\ncontrastive learning tasks. This integration of semantic and structural\ninformation generates robust personality profiles. Experimental results on\nKaggle and Pandora datasets show LL4G outperforms state-of-the-art models.", "published": "2025-04-02 21:46:30", "link": "http://arxiv.org/abs/2504.02146v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Interpretable Soft Prompts", "abstract": "Soft prompts have been popularized as a cheap and easy way to improve\ntask-specific LLM performance beyond few-shot prompts. Despite their origin as\nan automated prompting method, however, soft prompts and other trainable\nprompts remain a black-box method with no immediately interpretable connections\nto prompting. We create a novel theoretical framework for evaluating the\ninterpretability of trainable prompts based on two desiderata: faithfulness and\nscrutability. We find that existing methods do not naturally satisfy our\nproposed interpretability criterion. Instead, our framework inspires a new\ndirection of trainable prompting methods that explicitly optimizes for\ninterpretability. To this end, we formulate and test new\ninterpretability-oriented objective functions for two state-of-the-art prompt\ntuners: Hard Prompts Made Easy (PEZ) and RLPrompt. Our experiments with GPT-2\ndemonstrate a fundamental trade-off between interpretability and the\ntask-performance of the trainable prompt, explicating the hardness of the soft\nprompt interpretability problem and revealing odd behavior that arises when one\noptimizes for an interpretability proxy.", "published": "2025-04-02 21:42:09", "link": "http://arxiv.org/abs/2504.02144v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML", "68T50", "I.2.0; G.3"], "primary_category": "cs.LG"}
{"title": "One Pic is All it Takes: Poisoning Visual Document Retrieval Augmented Generation with a Single Image", "abstract": "Multimodal retrieval augmented generation (M-RAG) has recently emerged as a\nmethod to inhibit hallucinations of large multimodal models (LMMs) through a\nfactual knowledge base (KB). However, M-RAG also introduces new attack vectors\nfor adversaries that aim to disrupt the system by injecting malicious entries\ninto the KB. In this work, we present a poisoning attack against M-RAG\ntargeting visual document retrieval applications, where the KB contains images\nof document pages. Our objective is to craft a single image that is retrieved\nfor a variety of different user queries, and consistently influences the output\nproduced by the generative model, thus creating a universal denial-of-service\n(DoS) attack against the M-RAG system. We demonstrate that while our attack is\neffective against a diverse range of widely-used, state-of-the-art retrievers\n(embedding models) and generators (LMMs), it can also be ineffective against\nrobust embedding models. Our attack not only highlights the vulnerability of\nM-RAG pipelines to poisoning attacks, but also sheds light on a fundamental\nweakness that potentially hinders their performance even in benign settings.", "published": "2025-04-02 21:08:33", "link": "http://arxiv.org/abs/2504.02132v1", "categories": ["cs.CL", "cs.CR", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Achieving Unanimous Consensus in Decision Making Using Multi-Agents", "abstract": "Blockchain consensus mechanisms have relied on algorithms such as\nProof-of-Work (PoW) and Proof-of-Stake (PoS) to ensure network functionality\nand integrity. However, these approaches struggle with adaptability for\ndecision-making where the opinions of each matter rather than reaching an\nagreement based on honest majority or weighted consensus. This paper introduces\na novel deliberation-based consensus mechanism where Large Language Models\n(LLMs) act as rational agents engaging in structured discussions to reach a\nunanimous consensus. By leveraging graded consensus and a multi-round\ndeliberation process, our approach ensures both unanimous consensus for\ndefinitive problems and graded confidence for prioritized decisions and\npolicies. We provide a formalization of our system and use it to show that the\nproperties of blockchains: consistency, agreement, liveness, and determinism\nare maintained. Moreover, experimental results demonstrate our system's\nfeasibility, showcasing how our deliberation method's convergence, block\nproperties, and accuracy enable decision-making on blockchain networks. We also\naddress key challenges with this novel approach such as degeneration of\nthoughts, hallucinations, malicious models and nodes, resource consumption, and\nscalability.", "published": "2025-04-02 21:02:54", "link": "http://arxiv.org/abs/2504.02128v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Overcoming Vocabulary Constraints with Pixel-level Fallback", "abstract": "Subword tokenization requires balancing computational efficiency and\nvocabulary coverage, which often leads to suboptimal performance on languages\nand scripts not prioritized during training. We propose to augment pretrained\nlanguage models with a vocabulary-free encoder that generates input embeddings\nfrom text rendered as pixels. Through experiments on English-centric language\nmodels, we demonstrate that our approach substantially improves machine\ntranslation performance and facilitates effective cross-lingual transfer,\noutperforming tokenizer-based methods. Furthermore, we find that pixel-based\nrepresentations outperform byte-level approaches and standard vocabulary\nexpansion. Our approach enhances the multilingual capabilities of monolingual\nlanguage models without extensive retraining and reduces decoding latency via\ninput compression.", "published": "2025-04-02 20:50:31", "link": "http://arxiv.org/abs/2504.02122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models at the Syntax-Semantics Interface: A Case Study of the Long-Distance Binding of Chinese Reflexive ziji", "abstract": "This paper explores whether language models can effectively resolve the\ncomplex binding patterns of the Mandarin Chinese reflexive ziji, which are\nconstrained by both syntactic and semantic factors. We construct a dataset of\n240 synthetic sentences using templates and examples from syntactic literature,\nalong with 320 natural sentences from the BCC corpus. Evaluating 21 language\nmodels against this dataset and comparing their performance to judgments from\nnative Mandarin speakers, we find that none of the models consistently\nreplicates human-like judgments. The results indicate that existing language\nmodels tend to rely heavily on sequential cues, though not always favoring the\nclosest strings, and often overlooking subtle semantic and syntactic\nconstraints. They tend to be more sensitive to noun-related than verb-related\nsemantics.", "published": "2025-04-02 20:25:27", "link": "http://arxiv.org/abs/2504.02116v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring LLM Reasoning Through Controlled Prompt Variations", "abstract": "This study investigates the reasoning robustness of large language models\n(LLMs) on mathematical problem-solving tasks under systematically introduced\ninput perturbations. Using the GSM8K dataset as a controlled testbed, we\nevaluate how well state-of-the-art models maintain logical consistency and\ncorrectness when confronted with four categories of prompt perturbations:\nirrelevant context, pathological instructions, factually relevant but\nnon-essential context, and a combination of the latter two. Our experiments,\nconducted on thirteen open-source and closed-source LLMs, reveal that\nintroducing irrelevant context within the model's context window significantly\ndegrades performance, suggesting that distinguishing essential from extraneous\ndetails remains a pressing challenge. Surprisingly, performance regressions are\nrelatively insensitive to the complexity of the reasoning task, as measured by\nthe number of steps required, and are not strictly correlated with model size.\nMoreover, we observe that certain perturbations inadvertently trigger\nchain-of-thought-like reasoning behaviors, even without explicit prompting. Our\nfindings highlight critical vulnerabilities in current LLMs and underscore the\nneed for improved robustness against noisy, misleading, and contextually dense\ninputs, paving the way for more resilient and reliable reasoning in real-world\napplications.", "published": "2025-04-02 20:18:50", "link": "http://arxiv.org/abs/2504.02111v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining", "abstract": "Large Language Models (LLMs) trained on historical web data inevitably become\noutdated. We investigate evaluation strategies and update methods for LLMs as\nnew data becomes available. We introduce a web-scale dataset for time-continual\npretraining of LLMs derived from 114 dumps of Common Crawl (CC) - orders of\nmagnitude larger than previous continual language modeling benchmarks. We also\ndesign time-stratified evaluations across both general CC data and specific\ndomains (Wikipedia, StackExchange, and code documentation) to assess how well\nvarious continual learning methods adapt to new data while retaining past\nknowledge. Our findings demonstrate that, on general CC data, autoregressive\nmeta-schedules combined with a fixed-ratio replay of older data can achieve\ncomparable held-out loss to re-training from scratch, while requiring\nsignificantly less computation (2.6x). However, the optimal balance between\nincorporating new data and replaying old data differs as replay is crucial to\navoid forgetting on generic web data but less so on specific domains.", "published": "2025-04-02 20:11:54", "link": "http://arxiv.org/abs/2504.02107v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ContrastScore: Towards Higher Quality, Less Biased, More Efficient Evaluation Metrics with Contrastive Evaluation", "abstract": "Evaluating the quality of generated text automatically remains a significant\nchallenge. Conventional reference-based metrics have been shown to exhibit\nrelatively weak correlation with human evaluations. Recent research advocates\nthe use of large language models (LLMs) as source-based metrics for natural\nlanguage generation (NLG) assessment. While promising, LLM-based metrics,\nparticularly those using smaller models, still fall short in aligning with\nhuman judgments. In this work, we introduce ContrastScore, a contrastive\nevaluation metric designed to enable higher-quality, less biased, and more\nefficient assessment of generated text. We evaluate ContrastScore on two NLG\ntasks: machine translation and summarization. Experimental results show that\nContrastScore consistently achieves stronger correlation with human judgments\nthan both single-model and ensemble-based baselines. Notably, ContrastScore\nbased on Qwen 3B and 0.5B even outperforms Qwen 7B, despite having only half as\nmany parameters, demonstrating its efficiency. Furthermore, it effectively\nmitigates common evaluation biases such as length and likelihood preferences,\nresulting in more robust automatic evaluation.", "published": "2025-04-02 20:11:45", "link": "http://arxiv.org/abs/2504.02106v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Increasing happiness through conversations with artificial intelligence", "abstract": "Chatbots powered by artificial intelligence (AI) have rapidly become a\nsignificant part of everyday life, with over a quarter of American adults using\nthem multiple times per week. While these tools offer potential benefits and\nrisks, a fundamental question remains largely unexplored: How do conversations\nwith AI influence subjective well-being? To investigate this, we conducted a\nstudy where participants either engaged in conversations with an AI chatbot (N\n= 334) or wrote journal entires (N = 193) on the same randomly assigned topics\nand reported their momentary happiness afterward. We found that happiness after\nAI chatbot conversations was higher than after journaling, particularly when\ndiscussing negative topics such as depression or guilt. Leveraging large\nlanguage models for sentiment analysis, we found that the AI chatbot mirrored\nparticipants' sentiment while maintaining a consistent positivity bias. When\ndiscussing negative topics, participants gradually aligned their sentiment with\nthe AI's positivity, leading to an overall increase in happiness. We\nhypothesized that the history of participants' sentiment prediction errors, the\ndifference between expected and actual emotional tone when responding to the AI\nchatbot, might explain this happiness effect. Using computational modeling, we\nfind the history of these sentiment prediction errors over the course of a\nconversation predicts greater post-conversation happiness, demonstrating a\ncentral role of emotional expectations during dialogue. Our findings underscore\nthe effect that AI interactions can have on human well-being.", "published": "2025-04-02 19:52:02", "link": "http://arxiv.org/abs/2504.02091v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Text to Graph: Leveraging Graph Neural Networks for Enhanced Explainability in NLP", "abstract": "Researchers have relegated natural language processing tasks to\nTransformer-type models, particularly generative models, because these models\nexhibit high versatility when performing generation and classification tasks.\nAs the size of these models increases, they achieve outstanding results. Given\ntheir widespread use, many explainability techniques are developed based on\nthese models. However, this process becomes computationally expensive due to\nthe large size of the models. Additionally, transformers interpret input\ninformation through tokens that fragment input words into sequences lacking\ninherent semantic meaning, complicating the explanation of the model from the\nvery beginning. This study proposes a novel methodology to achieve\nexplainability in natural language processing tasks by automatically converting\nsentences into graphs and maintaining semantics through nodes and relations\nthat express fundamental linguistic concepts. It also allows the subsequent\nexploitation of this knowledge in subsequent tasks, making it possible to\nobtain trends and understand how the model associates the different elements\ninside the text with the explained task. The experiments delivered promising\nresults in determining the most critical components within the text structure\nfor a given classification.", "published": "2025-04-02 18:55:58", "link": "http://arxiv.org/abs/2504.02064v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OnRL-RAG: Real-Time Personalized Mental Health Dialogue System", "abstract": "Large language models (LLMs) have been widely used for various tasks and\napplications. However, LLMs and fine-tuning are limited to the pre-trained\ndata. For example, ChatGPT's world knowledge until 2021 can be outdated or\ninaccurate. To enhance the capabilities of LLMs, Retrieval-Augmented Generation\n(RAG), is proposed to augment LLMs with additional, new, latest details and\ninformation to LLMs. While RAG offers the correct information, it may not best\npresent it, especially to different population groups with personalizations.\nReinforcement Learning from Human Feedback (RLHF) adapts to user needs by\naligning model responses with human preference through feedback loops. In\nreal-life applications, such as mental health problems, a dynamic and\nfeedback-based model would continuously adapt to new information and offer\npersonalized assistance due to complex factors fluctuating in a daily\nenvironment. Thus, we propose an Online Reinforcement Learning-based\nRetrieval-Augmented Generation (OnRL-RAG) system to detect and personalize the\nresponding systems to mental health problems, such as stress, anxiety, and\ndepression. We use an open-source dataset collected from 2028 College Students\nwith 28 survey questions for each student to demonstrate the performance of our\nproposed system with the existing systems. Our system achieves superior\nperformance compared to standard RAG and simple LLM via GPT-4o, GPT-4o-mini,\nGemini-1.5, and GPT-3.5. This work would open up the possibilities of real-life\napplications of LLMs for personalized services in the everyday environment. The\nresults will also help researchers in the fields of sociology, psychology, and\nneuroscience to align their theories more closely with the actual human daily\nenvironment.", "published": "2025-04-02 18:44:53", "link": "http://arxiv.org/abs/2504.02894v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Resource Allocation in Multi-Agent LLM Systems", "abstract": "With the development of LLMs as agents, there is a growing interest in\nconnecting multiple agents into multi-agent systems to solve tasks\nconcurrently, focusing on their role in task assignment and coordination. This\npaper explores how LLMs can effectively allocate computational tasks among\nmultiple agents, considering factors such as cost, efficiency, and performance.\nIn this work, we address key questions, including the effectiveness of LLMs as\norchestrators and planners, comparing their effectiveness in task assignment\nand coordination. Our experiments demonstrate that LLMs can achieve high\nvalidity and accuracy in resource allocation tasks. We find that the planner\nmethod outperforms the orchestrator method in handling concurrent actions,\nresulting in improved efficiency and better utilization of agents.\nAdditionally, we show that providing explicit information about worker\ncapabilities enhances the allocation strategies of planners, particularly when\ndealing with suboptimal workers.", "published": "2025-04-02 18:15:41", "link": "http://arxiv.org/abs/2504.02051v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Automated Survey Collection with LLM-based Conversational Agents", "abstract": "Objective: Traditional phone-based surveys are among the most accessible and\nwidely used methods to collect biomedical and healthcare data, however, they\nare often costly, labor intensive, and difficult to scale effectively. To\novercome these limitations, we propose an end-to-end survey collection\nframework driven by conversational Large Language Models (LLMs).\n  Materials and Methods: Our framework consists of a researcher responsible for\ndesigning the survey and recruiting participants, a conversational phone agent\npowered by an LLM that calls participants and administers the survey, a second\nLLM (GPT-4o) that analyzes the conversation transcripts generated during the\nsurveys, and a database for storing and organizing the results. To test our\nframework, we recruited 8 participants consisting of 5 native and 3 non-native\nenglish speakers and administered 40 surveys. We evaluated the correctness of\nLLM-generated conversation transcripts, accuracy of survey responses inferred\nby GPT-4o and overall participant experience.\n  Results: Survey responses were successfully extracted by GPT-4o from\nconversation transcripts with an average accuracy of 98% despite transcripts\nexhibiting an average per-line word error rate of 7.7%. While participants\nnoted occasional errors made by the conversational LLM agent, they reported\nthat the agent effectively conveyed the purpose of the survey, demonstrated\ngood comprehension, and maintained an engaging interaction.\n  Conclusions: Our study highlights the potential of LLM agents in conducting\nand analyzing phone surveys for healthcare applications. By reducing the\nworkload on human interviewers and offering a scalable solution, this approach\npaves the way for real-world, end-to-end AI-powered phone survey collection\nsystems.", "published": "2025-04-02 18:10:19", "link": "http://arxiv.org/abs/2504.02891v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The LLM Wears Prada: Analysing Gender Bias and Stereotypes through Online Shopping Data", "abstract": "With the wide and cross-domain adoption of Large Language Models, it becomes\ncrucial to assess to which extent the statistical correlations in training\ndata, which underlie their impressive performance, hide subtle and potentially\ntroubling biases. Gender bias in LLMs has been widely investigated from the\nperspectives of works, hobbies, and emotions typically associated with a\nspecific gender. In this study, we introduce a novel perspective. We\ninvestigate whether LLMs can predict an individual's gender based solely on\nonline shopping histories and whether these predictions are influenced by\ngender biases and stereotypes. Using a dataset of historical online purchases\nfrom users in the United States, we evaluate the ability of six LLMs to\nclassify gender and we then analyze their reasoning and products-gender\nco-occurrences. Results indicate that while models can infer gender with\nmoderate accuracy, their decisions are often rooted in stereotypical\nassociations between product categories and gender. Furthermore, explicit\ninstructions to avoid bias reduce the certainty of model predictions, but do\nnot eliminate stereotypical patterns. Our findings highlight the persistent\nnature of gender biases in LLMs and emphasize the need for robust\nbias-mitigation strategies.", "published": "2025-04-02 17:56:08", "link": "http://arxiv.org/abs/2504.01951v1", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "OpenCodeReasoning: Advancing Data Distillation for Competitive Coding", "abstract": "Since the advent of reasoning-based large language models, many have found\ngreat success from distilling reasoning capabilities into student models. Such\ntechniques have significantly bridged the gap between reasoning and standard\nLLMs on coding tasks. Despite this, much of the progress on distilling\nreasoning models remains locked behind proprietary datasets or lacks details on\ndata curation, filtering and subsequent training. To address this, we construct\na superior supervised fine-tuning (SFT) dataset that we use to achieve\nstate-of-the-art coding capability results in models of various sizes. Our\ndistilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on\nCodeContests, surpassing alternatives trained with reinforcement learning. We\nthen perform analysis on the data sources used to construct our dataset, the\nimpact of code execution filtering, and the importance of instruction/solution\ndiversity. We observe that execution filtering negatively affected benchmark\naccuracy, leading us to prioritize instruction diversity over solution\ncorrectness. Finally, we also analyze the token efficiency and reasoning\npatterns utilized by these models. We will open-source these datasets and\ndistilled models to the community.", "published": "2025-04-02 17:50:31", "link": "http://arxiv.org/abs/2504.01943v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Review, Refine, Repeat: Understanding Iterative Decoding of AI Agents with Dynamic Evaluation and Selection", "abstract": "While AI agents have shown remarkable performance at various tasks, they\nstill struggle with complex multi-modal applications, structured generation and\nstrategic planning. Improvements via standard fine-tuning is often impractical,\nas solving agentic tasks usually relies on black box API access without control\nover model parameters. Inference-time methods such as Best-of-N (BON) sampling\noffer a simple yet effective alternative to improve performance. However, BON\nlacks iterative feedback integration mechanism. Hence, we propose Iterative\nAgent Decoding (IAD) which combines iterative refinement with dynamic candidate\nevaluation and selection guided by a verifier. IAD differs in how feedback is\ndesigned and integrated, specifically optimized to extract maximal signal from\nreward scores. We conduct a detailed comparison of baselines across key metrics\non Sketch2Code, Text2SQL, and Webshop where IAD consistently outperforms\nbaselines, achieving 3--6% absolute gains on Sketch2Code and Text2SQL (with and\nwithout LLM judges) and 8--10% gains on Webshop across multiple metrics. To\nbetter understand the source of IAD's gains, we perform controlled experiments\nto disentangle the effect of adaptive feedback from stochastic sampling, and\nfind that IAD's improvements are primarily driven by verifier-guided\nrefinement, not merely sampling diversity. We also show that both IAD and BON\nexhibit inference-time scaling with increased compute when guided by an optimal\nverifier. Our analysis highlights the critical role of verifier quality in\neffective inference-time optimization and examines the impact of noisy and\nsparse rewards on scaling behavior. Together, these findings offer key insights\ninto the trade-offs and principles of effective inference-time optimization.", "published": "2025-04-02 17:40:47", "link": "http://arxiv.org/abs/2504.01931v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A thorough benchmark of automatic text classification: From traditional approaches to large language models", "abstract": "Automatic text classification (ATC) has experienced remarkable advancements\nin the past decade, best exemplified by recent small and large language models\n(SLMs and LLMs), leveraged by Transformer architectures. Despite recent\neffectiveness improvements, a comprehensive cost-benefit analysis investigating\nwhether the effectiveness gains of these recent approaches compensate their\nmuch higher costs when compared to more traditional text classification\napproaches such as SVMs and Logistic Regression is still missing in the\nliterature. In this context, this work's main contributions are twofold: (i) we\nprovide a scientifically sound comparative analysis of the cost-benefit of\ntwelve traditional and recent ATC solutions including five open LLMs, and (ii)\na large benchmark comprising {22 datasets}, including sentiment analysis and\ntopic classification, with their (train-validation-test) partitions based on\nfolded cross-validation procedures, along with documentation, and code. The\nrelease of code, data, and documentation enables the community to replicate\nexperiments and advance the field in a more scientifically sound manner. Our\ncomparative experimental results indicate that LLMs outperform traditional\napproaches (up to 26%-7.1% on average) and SLMs (up to 4.9%-1.9% on average) in\nterms of effectiveness. However, LLMs incur significantly higher computational\ncosts due to fine-tuning, being, on average 590x and 8.5x slower than\ntraditional methods and SLMs, respectively. Results suggests the following\nrecommendations: (1) LLMs for applications that require the best possible\neffectiveness and can afford the costs; (2) traditional methods such as\nLogistic Regression and SVM for resource-limited applications or those that\ncannot afford the cost of tuning large LLMs; and (3) SLMs like Roberta for\nnear-optimal effectiveness-efficiency trade-off.", "published": "2025-04-02 17:40:08", "link": "http://arxiv.org/abs/2504.01930v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is the Reversal Curse a Binding Problem? Uncovering Limitations of Transformers from a Basic Generalization Failure", "abstract": "Despite their impressive capabilities, LLMs exhibit a basic generalization\nfailure known as the Reversal Curse, where they struggle to learn reversible\nfactual associations. Understanding why this occurs could help identify\nweaknesses in current models and advance their generalization and robustness.\nIn this paper, we conjecture that the Reversal Curse in LLMs is a manifestation\nof the long-standing binding problem in cognitive science, neuroscience and AI.\nSpecifically, we identify two primary causes of the Reversal Curse stemming\nfrom transformers' limitations in conceptual binding: the inconsistency and\nentanglements of concept representations. We perform a series of experiments\nthat support these conjectures. Our exploration leads to a model design based\non JEPA (Joint-Embedding Predictive Architecture) that for the first time\nbreaks the Reversal Curse without side-stepping it with specialized data\naugmentation or non-causal masking, and moreover, generalization could be\nfurther improved by incorporating special memory layers that support\ndisentangled concept representations. We demonstrate that the skill of reversal\nunlocks a new kind of memory integration that enables models to solve\nlarge-scale arithmetic reasoning problems via parametric forward-chaining,\noutperforming frontier LLMs based on non-parametric memory and prolonged\nexplicit reasoning.", "published": "2025-04-02 17:38:03", "link": "http://arxiv.org/abs/2504.01928v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bridging the Linguistic Divide: A Survey on Leveraging Large Language Models for Machine Translation", "abstract": "The advent of Large Language Models (LLMs) has significantly reshaped the\nlandscape of machine translation (MT), particularly for low-resource languages\nand domains that lack sufficient parallel corpora, linguistic tools, and\ncomputational infrastructure. This survey presents a comprehensive overview of\nrecent progress in leveraging LLMs for MT. We analyze techniques such as\nfew-shot prompting, cross-lingual transfer, and parameter-efficient fine-tuning\nthat enable effective adaptation to under-resourced settings. The paper also\nexplores synthetic data generation strategies using LLMs, including\nback-translation and lexical augmentation. Additionally, we compare LLM-based\ntranslation with traditional encoder-decoder models across diverse language\npairs, highlighting the strengths and limitations of each. We discuss\npersistent challenges such as hallucinations, evaluation inconsistencies, and\ninherited biases while also evaluating emerging LLM-driven metrics for\ntranslation quality. This survey offers practical insights and outlines future\ndirections for building robust, inclusive, and scalable MT systems in the era\nof large-scale generative models.", "published": "2025-04-02 17:26:40", "link": "http://arxiv.org/abs/2504.01919v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs", "abstract": "As a pioneering vision-language model, CLIP (Contrastive Language-Image\nPre-training) has achieved significant success across various domains and a\nwide range of downstream vision-language tasks. However, the text encoders in\npopular CLIP models are limited to processing only 77 text tokens, which\nconstrains their ability to effectively handle longer, detail-rich captions.\nAdditionally, CLIP models often struggle to effectively capture detailed visual\nand textual information, which hampers their performance on tasks that require\nfine-grained analysis. To address these limitations, we present a novel\napproach, \\textbf{FineLIP}, that extends the capabilities of CLIP. FineLIP\nenhances cross-modal text-image mapping by incorporating \\textbf{Fine}-grained\nalignment with \\textbf{L}onger text input within the CL\\textbf{IP}-style\nframework. FineLIP first extends the positional embeddings to handle longer\ntext, followed by the dynamic aggregation of local image and text tokens. The\naggregated results are then used to enforce fine-grained token-to-token\ncross-modal alignment. We validate our model on datasets with long, detailed\ncaptions across two tasks: zero-shot cross-modal retrieval and text-to-image\ngeneration. Quantitative and qualitative experimental results demonstrate the\neffectiveness of FineLIP, outperforming existing state-of-the-art approaches.\nFurthermore, comprehensive ablation studies validate the benefits of key design\nelements within FineLIP.", "published": "2025-04-02 17:19:59", "link": "http://arxiv.org/abs/2504.01916v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist with Interpretable Reasoning", "abstract": "Large Language Models (LLMs) are playing an expanding role in physics\nresearch by enhancing reasoning, symbolic manipulation, and numerical\ncomputation. However, ensuring the reliability and interpretability of their\noutputs remains a significant challenge. In our framework, we conceptualize the\ncollaboration between AI and human scientists as a dynamic interplay among\nthree modules: the reasoning module, the interpretation module, and the\nAI-scientist interaction module. Recognizing that effective physics reasoning\ndemands rigorous logical consistency, quantitative precision, and deep\nintegration with established theoretical models, we introduce the\ninterpretation module to improve the understanding of AI-generated outputs,\nwhich is not previously explored in the literature. This module comprises\nmultiple specialized agents, including summarizers, model builders, UI\nbuilders, and testers, which collaboratively structure LLM outputs within a\nphysically grounded framework, by constructing a more interpretable science\nmodel. A case study demonstrates that our approach enhances transparency,\nfacilitates validation, and strengthens AI-augmented reasoning in scientific\ndiscovery.", "published": "2025-04-02 17:13:16", "link": "http://arxiv.org/abs/2504.01911v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "physics.comp-ph"], "primary_category": "cs.AI"}
{"title": "STAR-1: Safer Alignment of Reasoning LLMs with 1K Data", "abstract": "This paper introduces STAR-1, a high-quality, just-1k-scale safety dataset\nspecifically designed for large reasoning models (LRMs) like DeepSeek-R1. Built\non three core principles -- diversity, deliberative reasoning, and rigorous\nfiltering -- STAR-1 aims to address the critical needs for safety alignment in\nLRMs. Specifically, we begin by integrating existing open-source safety\ndatasets from diverse sources. Then, we curate safety policies to generate\npolicy-grounded deliberative reasoning samples. Lastly, we apply a GPT-4o-based\nsafety scoring system to select training examples aligned with best practices.\nExperimental results show that fine-tuning LRMs with STAR-1 leads to an average\n40% improvement in safety performance across four benchmarks, while only\nincurring a marginal decrease (e.g., an average of 1.1%) in reasoning ability\nmeasured across five reasoning tasks. Extensive ablation studies further\nvalidate the importance of our design principles in constructing STAR-1 and\nanalyze its efficacy across both LRMs and traditional LLMs. Our project page is\nhttps://ucsc-vlaa.github.io/STAR-1.", "published": "2025-04-02 17:04:04", "link": "http://arxiv.org/abs/2504.01903v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights", "abstract": "Detecting abusive language in social media conversations poses significant\nchallenges, as identifying abusiveness often depends on the conversational\ncontext, characterized by the content and topology of preceding comments.\nTraditional Abusive Language Detection (ALD) models often overlook this\ncontext, which can lead to unreliable performance metrics. Recent Natural\nLanguage Processing (NLP) methods that integrate conversational context often\ndepend on limited and simplified representations, and report inconsistent\nresults. In this paper, we propose a novel approach that utilize graph neural\nnetworks (GNNs) to model social media conversations as graphs, where nodes\nrepresent comments, and edges capture reply structures. We systematically\ninvestigate various graph representations and context windows to identify the\noptimal configuration for ALD. Our GNN model outperform both context-agnostic\nbaselines and linear context-aware methods, achieving significant improvements\nin F1 scores. These findings demonstrate the critical role of structured\nconversational context and establish GNNs as a robust framework for advancing\ncontext-aware abusive language detection.", "published": "2025-04-02 17:03:37", "link": "http://arxiv.org/abs/2504.01902v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness", "abstract": "The rapid development of Large Multimodal Models (LMMs) for 2D images and\nvideos has spurred efforts to adapt these models for interpreting 3D scenes.\nHowever, the absence of large-scale 3D vision-language datasets has posed a\nsignificant obstacle. To address this issue, typical approaches focus on\ninjecting 3D awareness into 2D LMMs by designing 3D input-level scene\nrepresentations. This work provides a new perspective. We introduce\nreconstructive visual instruction tuning with 3D-awareness (Ross3D), which\nintegrates 3D-aware visual supervision into the training procedure.\nSpecifically, it incorporates cross-view and global-view reconstruction. The\nformer requires reconstructing masked views by aggregating overlapping\ninformation from other views. The latter aims to aggregate information from all\navailable views to recover Bird's-Eye-View images, contributing to a\ncomprehensive overview of the entire scene. Empirically, Ross3D achieves\nstate-of-the-art performance across various 3D scene understanding benchmarks.\nMore importantly, our semi-supervised experiments demonstrate significant\npotential in leveraging large amounts of unlabeled 3D vision-only data.", "published": "2025-04-02 16:59:55", "link": "http://arxiv.org/abs/2504.01901v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Scaling Test-time Compute for Low-resource Languages: Multilingual Reasoning in LLMs", "abstract": "Recent advances in test-time compute scaling have enabled Large Language\nModels (LLMs) to tackle deep reasoning tasks by generating a chain-of-thought\n(CoT) that includes trial and error, backtracking, and intermediate reasoning\nsteps before producing the final answer. However, these techniques have been\napplied predominantly to popular languages, such as English, leaving reasoning\nin low-resource languages underexplored and misaligned. In this work, we\ninvestigate the multilingual mechanism by which LLMs internally operate in a\nlatent space biased toward their inherently dominant language. To leverage this\nphenomenon for low-resource languages, we train models to generate the CoT in\nEnglish while outputting the final response in the target language, given input\nin the low-resource language. Our experiments demonstrate that this approach,\nnamed English-Pivoted CoT Training, outperforms other baselines, including\ntraining to generate both the CoT and the final response solely in the target\nlanguage, with up to 28.33% improvement. Further analysis provides novel\ninsights into the relationships between reasoning and multilinguality of LLMs,\nprompting for better approaches in developing multilingual large reasoning\nmodels", "published": "2025-04-02 16:58:36", "link": "http://arxiv.org/abs/2504.02890v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CoRAG: Collaborative Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive\ntasks, especially under few-shot learning constraints. We introduce CoRAG, a\nframework extending RAG to collaborative settings, where clients jointly train\na shared model using a collaborative passage store. To evaluate CoRAG, we\nintroduce CRAB, a benchmark for collaborative homogeneous open-domain question\nanswering. Our experiments demonstrate that CoRAG consistently outperforms both\nparametric collaborative learning methods and locally trained RAG models in\nlow-resource scenarios. Further analysis reveals the critical importance of\nrelevant passages within the shared store, the surprising benefits of\nincorporating irrelevant passages, and the potential for hard negatives to\nnegatively impact performance. This introduces a novel consideration in\ncollaborative RAG: the trade-off between leveraging a collectively enriched\nknowledge base and the potential risk of incorporating detrimental passages\nfrom other clients. Our findings underscore the viability of CoRAG, while also\nhighlighting key design challenges and promising avenues for future research.", "published": "2025-04-02 16:40:43", "link": "http://arxiv.org/abs/2504.01883v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving Semi-structured Tables", "abstract": "Humans continuously make new discoveries, and understanding temporal sequence\nof events leading to these breakthroughs is essential for advancing science and\nsociety. This ability to reason over time allows us to identify future steps\nand understand the effects of financial and political decisions on our lives.\nHowever, large language models (LLMs) are typically trained on static datasets,\nlimiting their ability to perform effective temporal reasoning. To assess the\ntemporal reasoning capabilities of LLMs, we present the TRANSIENTTABLES\ndataset, which comprises 3,971 questions derived from over 14,000 tables,\nspanning 1,238 entities across multiple time periods. We introduce a\ntemplate-based question-generation pipeline that harnesses LLMs to refine both\ntemplates and questions. Additionally, we establish baseline results using\nstate-of-the-art LLMs to create a benchmark. We also introduce novel modeling\nstrategies centered around task decomposition, enhancing LLM performance.", "published": "2025-04-02 16:34:43", "link": "http://arxiv.org/abs/2504.01879v1", "categories": ["cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Consistency: A Novel Inference Framework for Advancing Reasoning in Large Language Models", "abstract": "Chain-of-thought (CoT) has emerged as a critical mechanism for enhancing\nreasoning capabilities in large language models (LLMs), with self-consistency\ndemonstrating notable promise in boosting performance. However, inherent\nlinguistic biases in multilingual training corpora frequently cause semantic\ndrift and logical inconsistencies, especially in sub-10B parameter LLMs\nhandling complex inference tasks. To overcome these constraints, we propose the\nCross-Lingual Consistency (CLC) framework, an innovative inference paradigm\nthat integrates multilingual reasoning paths through majority voting to elevate\nLLMs' reasoning capabilities. Empirical evaluations on the CMATH dataset reveal\nCLC's superiority over the conventional self-consistency method, delivering\n9.5%, 6.5%, and 6.0% absolute accuracy gains for DeepSeek-Math-7B-Instruct,\nQwen2.5-Math-7B-Instruct, and Gemma2-9B-Instruct respectively. Expanding CLC's\nlinguistic scope to 11 diverse languages implies two synergistic benefits: 1)\nneutralizing linguistic biases in multilingual training corpora through\nmultilingual ensemble voting, 2) escaping monolingual reasoning traps by\nexploring the broader multilingual solution space. This dual benefits\nempirically enables more globally optimal reasoning paths compared to\nmonolingual self-consistency baselines, as evidenced by the 4.1%-18.5% accuracy\ngains using Gemma2-9B-Instruct on the MGSM dataset.", "published": "2025-04-02 16:09:39", "link": "http://arxiv.org/abs/2504.01857v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PaperBench: Evaluating AI's Ability to Replicate AI Research", "abstract": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to\nreplicate state-of-the-art AI research. Agents must replicate 20 ICML 2024\nSpotlight and Oral papers from scratch, including understanding paper\ncontributions, developing a codebase, and successfully executing experiments.\nFor objective evaluation, we develop rubrics that hierarchically decompose each\nreplication task into smaller sub-tasks with clear grading criteria. In total,\nPaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed\nwith the author(s) of each ICML paper for accuracy and realism. To enable\nscalable evaluation, we also develop an LLM-based judge to automatically grade\nreplication attempts against rubrics, and assess our judge's performance by\ncreating a separate benchmark for judges. We evaluate several frontier models\non PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet\n(New) with open-source scaffolding, achieves an average replication score of\n21.0%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench,\nfinding that models do not yet outperform the human baseline. We open-source\nour code (https://github.com/openai/preparedness) to facilitate future research\nin understanding the AI engineering capabilities of AI agents.", "published": "2025-04-02 15:55:24", "link": "http://arxiv.org/abs/2504.01848v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LARGE: Legal Retrieval Augmented Generation Evaluation Tool", "abstract": "Recently, building retrieval-augmented generation (RAG) systems to enhance\nthe capability of large language models (LLMs) has become a common practice.\nEspecially in the legal domain, previous judicial decisions play a significant\nrole under the doctrine of stare decisis which emphasizes the importance of\nmaking decisions based on (retrieved) prior documents. However, the overall\nperformance of RAG system depends on many components: (1) retrieval corpora,\n(2) retrieval algorithms, (3) rerankers, (4) LLM backbones, and (5) evaluation\nmetrics. Here we propose LRAGE, an open-source tool for holistic evaluation of\nRAG systems focusing on the legal domain. LRAGE provides GUI and CLI interfaces\nto facilitate seamless experiments and investigate how changes in the\naforementioned five components affect the overall accuracy. We validated LRAGE\nusing multilingual legal benches including Korean (KBL), English (LegalBench),\nand Chinese (LawBench) by demonstrating how the overall accuracy changes when\nvarying the five components mentioned above. The source code is available at\nhttps://github.com/hoorangyee/LRAGE.", "published": "2025-04-02 15:45:03", "link": "http://arxiv.org/abs/2504.01840v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "YourBench: Easy Custom Evaluation Sets for Everyone", "abstract": "Evaluating large language models (LLMs) effectively remains a critical\nbottleneck, as traditional static benchmarks suffer from saturation and\ncontamination, while human evaluations are costly and slow. This hinders timely\nor domain-specific assessment, crucial for real-world applications. We\nintroduce YourBench, a novel, open-source framework that addresses these\nlimitations by enabling dynamic, automated generation of reliable, up-to-date,\nand domain-tailored benchmarks cheaply and without manual annotation, directly\nfrom user-provided documents. We demonstrate its efficacy by replicating 7\ndiverse MMLU subsets using minimal source text, achieving this for under 15 USD\nin total inference costs while perfectly preserving the relative model\nperformance rankings (Spearman Rho = 1) observed on the original benchmark. To\nensure that YourBench generates data grounded in provided input instead of\nrelying on posterior parametric knowledge in models, we also introduce\nTempora-0325, a novel dataset of over 7K diverse documents, published\nexclusively after March 2025. Our comprehensive analysis spans 26 SoTA models\nfrom 7 major families across varying scales (3-671B parameters) to validate the\nquality of generated evaluations through rigorous algorithmic checks (e.g.,\ncitation grounding) and human assessments. We release the YourBench library,\nthe Tempora-0325 dataset, 150k+ question answer pairs based on Tempora and all\nevaluation and inference traces to facilitate reproducible research and empower\nthe community to generate bespoke benchmarks on demand, fostering more relevant\nand trustworthy LLM evaluation.", "published": "2025-04-02 15:40:24", "link": "http://arxiv.org/abs/2504.01833v1", "categories": ["cs.CL", "cs.AI", "I.2.1"], "primary_category": "cs.CL"}
{"title": "Efficient Constant-Space Multi-Vector Retrieval", "abstract": "Multi-vector retrieval methods, exemplified by the ColBERT architecture, have\nshown substantial promise for retrieval by providing strong trade-offs in terms\nof retrieval latency and effectiveness. However, they come at a high cost in\nterms of storage since a (potentially compressed) vector needs to be stored for\nevery token in the input collection. To overcome this issue, we propose\nencoding documents to a fixed number of vectors, which are no longer\nnecessarily tied to the input tokens. Beyond reducing the storage costs, our\napproach has the advantage that document representations become of a fixed size\non disk, allowing for better OS paging management. Through experiments using\nthe MSMARCO passage corpus and BEIR with the ColBERT-v2 architecture, a\nrepresentative multi-vector ranking model architecture, we find that passages\ncan be effectively encoded into a fixed number of vectors while retaining most\nof the original effectiveness.", "published": "2025-04-02 15:22:23", "link": "http://arxiv.org/abs/2504.01818v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Investigating and Scaling up Code-Switching for Multilingual Language Model Pre-Training", "abstract": "Large language models (LLMs) exhibit remarkable multilingual capabilities\ndespite the extreme language imbalance in the pre-training data. In this paper,\nwe closely examine the reasons behind this phenomenon, focusing on the\npre-training corpus. We find that the existence of code-switching, alternating\nbetween different languages within a context, is key to multilingual\ncapabilities. We conduct an analysis to investigate code-switching in the\npre-training corpus, examining its presence and categorizing it into four types\nwithin two quadrants. We then assess its impact on multilingual performance.\nThese types of code-switching data are unbalanced in proportions and\ndemonstrate different effects on facilitating language transfer. To better\nexplore the power of code-switching for language alignment during pre-training,\nwe investigate the strategy of synthetic code-switching. We continuously scale\nup the synthetic code-switching data and observe remarkable improvements in\nboth benchmarks and representation space. Extensive experiments indicate that\nincorporating synthetic code-switching data enables better language alignment\nand generalizes well to high, medium, and low-resource languages with\npre-training corpora of varying qualities.", "published": "2025-04-02 15:09:58", "link": "http://arxiv.org/abs/2504.01801v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OpenThaiGPT 1.6 and R1: Thai-Centric Open Source and Reasoning Large Language Models", "abstract": "We present OpenThaiGPT 1.6 and R1 (OTG-1.6 and OTG-R1), Thai-centric Large\nLanguage Models (LLMs) developed through distinct methodologies to enhance\ngeneralization and reasoning capabilities. OTG-1.6 employs Task Arithmetic\nmodel merging for broad generalization, while OTG-R1 integrates multi-stage\ntraining with the Less-Is-More Reasoning Hypothesis (LIMO) for advanced\nreasoning. Benchmark evaluations demonstrate superior performance across Thai\nlanguage tasks, achieving competitive results against larger-scale open-source\nThai LLMs. This paper details the proposed models, training processes,\nbenchmarks, and results, highlighting improvements over previous models and\nestablishing new performance standards for Thai-centric LLMs.", "published": "2025-04-02 14:55:52", "link": "http://arxiv.org/abs/2504.01789v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Status Quo Investigation of Large Language Models towards Cost-Effective CFD Automation with OpenFOAMGPT: ChatGPT vs. Qwen vs. Deepseek", "abstract": "We evaluated the performance of OpenFOAMGPT incorporating multiple\nlarge-language models. Some of the present models efficiently manage different\nCFD tasks such as adjusting boundary conditions, turbulence models, and solver\nconfigurations, although their token cost and stability vary. Locally deployed\nsmaller models like QwQ-32B struggled with generating valid solver files for\ncomplex processes. Zero-shot prompting commonly failed in simulations with\nintricate settings, even for large models. Challenges with boundary conditions\nand solver keywords stress the requirement for expert supervision, indicating\nthat further development is needed to fully automate specialized CFD\nsimulations.", "published": "2025-04-02 14:04:52", "link": "http://arxiv.org/abs/2504.02888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style over Substance: Distilled Language Models Reason Via Stylistic Replication", "abstract": "Specialized reasoning language models (RLMs) have demonstrated that scaling\ntest-time computation through detailed reasoning traces significantly enhances\nperformance. Although these traces effectively facilitate knowledge\ndistillation into smaller, instruction-tuned models, the precise nature of\ntransferred reasoning remains unclear. In this study, we investigate to what\nextent distilled models internalize replicated stylistic patterns during\nreasoning. To this end, we systematically analyze reasoning traces, identifying\nstructural and lexical patterns that characterize successful reasoning. We then\nintroduce two new datasets -- a dataset of emergent reasoning traces and a\nsynthetic dataset explicitly constructed to replicate these stylistic patterns\n-- to precisely examine their influence on distilled models' reasoning\ncapabilities. We find that models trained on the synthetic traces achieve\ncomparable performance, indicating that distilled reasoning abilities rely\nsignificantly on surface-level patterns. Surprisingly, we observe an increase\nin performance even when the synthetic traces are altered to lead to the wrong\nanswer. Our findings highlight how stylistic patterns can be leveraged to\nefficiently enhance LM reasoning across diverse model families.", "published": "2025-04-02 13:50:20", "link": "http://arxiv.org/abs/2504.01738v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Processes Matter: How ML/GAI Approaches Could Support Open Qualitative Coding of Online Discourse Datasets", "abstract": "Open coding, a key inductive step in qualitative research, discovers and\nconstructs concepts from human datasets. However, capturing extensive and\nnuanced aspects or \"coding moments\" can be challenging, especially with large\ndiscourse datasets. While some studies explore machine learning (ML)/Generative\nAI (GAI)'s potential for open coding, few evaluation studies exist. We compare\nopen coding results by five recently published ML/GAI approaches and four human\ncoders, using a dataset of online chat messages around a mobile learning\nsoftware. Our systematic analysis reveals ML/GAI approaches' strengths and\nweaknesses, uncovering the complementary potential between humans and AI.\nLine-by-line AI approaches effectively identify content-based codes, while\nhumans excel in interpreting conversational dynamics. We discussed how embedded\nanalytical processes could shape the results of ML/GAI approaches. Instead of\nreplacing humans in open coding, researchers should integrate AI with and\naccording to their analytical processes, e.g., as parallel co-coders.", "published": "2025-04-02 13:43:54", "link": "http://arxiv.org/abs/2504.02887v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation", "abstract": "In-context learning (ICL) is critical for large language models (LLMs), but\nits effectiveness is constrained by finite context windows, particularly in\nultra-long contexts. To overcome this, we introduce InfiniteICL, a framework\nthat parallels context and parameters in LLMs with short- and long-term memory\nin human cognitive systems, focusing on transforming temporary context\nknowledge into permanent parameter updates. This approach significantly reduces\nmemory usage, maintains robust performance across varying input lengths, and\ntheoretically enables infinite context integration through the principles of\ncontext knowledge elicitation, selection, and consolidation. Evaluations\ndemonstrate that our method reduces context length by 90% while achieving 103%\naverage performance of full-context prompting across fact recall, grounded\nreasoning, and skill acquisition tasks. When conducting sequential multi-turn\ntransformations on complex, real-world contexts (with length up to 2M tokens),\nour approach surpasses full-context prompting while using only 0.4% of the\noriginal contexts. These findings highlight InfiniteICL's potential to enhance\nthe scalability and efficiency of LLMs by breaking the limitations of\nconventional context window sizes.", "published": "2025-04-02 13:15:44", "link": "http://arxiv.org/abs/2504.01707v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ToM-RL: Reinforcement Learning Unlocks Theory of Mind in Small LLMs", "abstract": "Recent advancements in rule-based reinforcement learning (RL), applied during\nthe post-training phase of large language models (LLMs), have significantly\nenhanced their capabilities in structured reasoning tasks such as mathematics\nand logical inference. However, the effectiveness of RL in social reasoning,\nparticularly in Theory of Mind (ToM), the ability to infer others' mental\nstates, remains largely unexplored. In this study, we demonstrate that RL\nmethods effectively unlock ToM reasoning capabilities even in small-scale LLMs\n(0.5B to 7B parameters). Using a modest dataset comprising 3200 questions\nacross diverse scenarios, our RL-trained 7B model achieves 84.50\\% accuracy on\nthe Hi-ToM benchmark, surpassing models like GPT-4o and DeepSeek-v3 despite\nsignificantly fewer parameters. While smaller models ($\\leq$3B parameters)\nsuffer from reasoning collapse, larger models (7B parameters) maintain stable\nperformance through consistent belief tracking. Additionally, our RL-based\nmodels demonstrate robust generalization to higher-order, out-of-distribution\nToM problems, novel textual presentations, and previously unseen datasets.\nThese findings highlight RL's potential to enhance social cognitive reasoning,\nbridging the gap between structured problem-solving and nuanced social\ninference in LLMs.", "published": "2025-04-02 12:58:42", "link": "http://arxiv.org/abs/2504.01698v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Study of scaling laws in language families", "abstract": "This article investigates scaling laws within language families using data\nfrom over six thousand languages and analyzing emergent patterns observed in\nZipf-like classification graphs. Both macroscopic (based on number of languages\nby family) and microscopic (based on numbers of speakers by language on a\nfamily) aspects of these classifications are examined. Particularly noteworthy\nis the discovery of a distinct division among the fourteen largest contemporary\nlanguage families, excluding Afro-Asiatic and Nilo-Saharan languages. These\nfamilies are found to be distributed across three language family quadruplets,\neach characterized by significantly different exponents in the Zipf graphs.\nThis finding sheds light on the underlying structure and organization of major\nlanguage families, revealing intriguing insights into the nature of linguistic\ndiversity and distribution.", "published": "2025-04-02 12:28:59", "link": "http://arxiv.org/abs/2504.01681v1", "categories": ["physics.soc-ph", "cs.CL"], "primary_category": "physics.soc-ph"}
{"title": "Testing Low-Resource Language Support in LLMs Using Language Proficiency Exams: the Case of Luxembourgish", "abstract": "Large Language Models (LLMs) have become an increasingly important tool in\nresearch and society at large. While LLMs are regularly used all over the world\nby experts and lay-people alike, they are predominantly developed with\nEnglish-speaking users in mind, performing well in English and other\nwide-spread languages while less-resourced languages such as Luxembourgish are\nseen as a lower priority. This lack of attention is also reflected in the\nsparsity of available evaluation tools and datasets. In this study, we\ninvestigate the viability of language proficiency exams as such evaluation\ntools for the Luxembourgish language. We find that large models such as\nChatGPT, Claude and DeepSeek-R1 typically achieve high scores, while smaller\nmodels show weak performances. We also find that the performances in such\nlanguage exams can be used to predict performances in other NLP tasks.", "published": "2025-04-02 12:16:14", "link": "http://arxiv.org/abs/2504.01667v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Horizon Scans can be accelerated using novel information retrieval and artificial intelligence tools", "abstract": "Introduction: Horizon scanning in healthcare assesses early signals of\ninnovation, crucial for timely adoption. Current horizon scanning faces\nchallenges in efficient information retrieval and analysis, especially from\nunstructured sources like news, presenting a need for innovative tools.\nMethodology: The study introduces SCANAR and AIDOC, open-source Python-based\ntools designed to improve horizon scanning. SCANAR automates the retrieval and\nprocessing of news articles, offering functionalities such as de-duplication\nand unsupervised relevancy ranking. AIDOC aids filtration by leveraging AI to\nreorder textual data based on relevancy, employing neural networks for semantic\nsimilarity, and subsequently prioritizing likely relevant entries for human\nreview. Results: Twelve internal datasets from horizon scans and four external\nbenchmarking datasets were used. SCANAR improved retrieval efficiency by\nautomating processes previously dependent on manual labour. AIDOC displayed\nwork-saving potential, achieving around 62% reduction in manual review efforts\nat 95% recall. Comparative analysis with benchmarking data showed AIDOC's\nperformance was similar to existing systematic review automation tools, though\nperformance varied depending on dataset characteristics. A smaller case-study\non our news datasets shows the potential of ensembling large language models\nwithin the active-learning process for faster detection of relevant articles\nacross news datasets. Conclusion: The validation indicates that SCANAR and\nAIDOC show potential to enhance horizon scanning efficiency by streamlining\ndata retrieval and prioritisation. These tools may alleviate methodological\nlimitations and allow broader, swifter horizon scans. Further studies are\nsuggested to optimize these models and to design new workflows and validation\nprocesses that integrate large language models.", "published": "2025-04-02 11:33:08", "link": "http://arxiv.org/abs/2504.01627v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Representation Bending for Large Language Model Safety", "abstract": "Large Language Models (LLMs) have emerged as powerful tools, but their\ninherent safety risks - ranging from harmful content generation to broader\nsocietal harms - pose significant challenges. These risks can be amplified by\nthe recent adversarial attacks, fine-tuning vulnerabilities, and the increasing\ndeployment of LLMs in high-stakes environments. Existing safety-enhancing\ntechniques, such as fine-tuning with human feedback or adversarial training,\nare still vulnerable as they address specific threats and often fail to\ngeneralize across unseen attacks, or require manual system-level defenses. This\npaper introduces RepBend, a novel approach that fundamentally disrupts the\nrepresentations underlying harmful behaviors in LLMs, offering a scalable\nsolution to enhance (potentially inherent) safety. RepBend brings the idea of\nactivation steering - simple vector arithmetic for steering model's behavior\nduring inference - to loss-based fine-tuning. Through extensive evaluation,\nRepBend achieves state-of-the-art performance, outperforming prior methods such\nas Circuit Breaker, RMU, and NPO, with up to 95% reduction in attack success\nrates across diverse jailbreak benchmarks, all with negligible reduction in\nmodel usability and general capabilities.", "published": "2025-04-02 09:47:01", "link": "http://arxiv.org/abs/2504.01550v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Register Always Matters: Analysis of LLM Pretraining Data Through the Lens of Language Variation", "abstract": "Pretraining data curation is a cornerstone in Large Language Model (LLM)\ndevelopment, leading to growing research on quality filtering of large web\ncorpora. From statistical quality flags to LLM-based labeling systems, datasets\nare divided into categories, frequently reducing to a binary: those passing the\nfilters deemed as valuable examples, others discarded as useless or\ndetrimental. However, a more detailed understanding of the contribution of\ndifferent kinds of texts to model performance is still largely lacking. In this\narticle, we present the first study utilizing registers (also known as genres)\n- a widely used standard in corpus linguistics to model linguistic variation -\nto curate pretraining datasets and investigate the effect of register on the\nperformance of LLMs. We perform comparative studies by training models with\nregister classified data and evaluating them using standard benchmarks, and\nshow that the register of pretraining data substantially affects model\nperformance. We uncover surprising relationships between the pretraining\nmaterial and the resulting models: using the News register results in subpar\nperformance, and on the contrary, including the Opinion class, covering texts\nsuch as reviews and opinion blogs, is highly beneficial. While a model trained\non the entire unfiltered dataset outperforms those trained on datasets limited\nto a single register, combining well-performing registers like\nHow-to-Instructions, Informational Description, and Opinion leads to major\nimprovements. Furthermore, analysis of individual benchmark results reveals key\ndifferences in the strengths and drawbacks of specific register classes as\npretraining data. These findings show that register is an important explainer\nof model variation and can facilitate more deliberate future data selection\npractices.", "published": "2025-04-02 09:30:24", "link": "http://arxiv.org/abs/2504.01542v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Sm\u00f8r-re-br\u00f8d to Subwords: Training LLMs on Danish, One Morpheme at a Time", "abstract": "The best performing transformer-based language models use subword\ntokenization techniques, such as Byte-Pair-Encoding (BPE). However, these\napproaches often overlook linguistic principles, such as morphological\nsegmentation, which we believe is fundamental for understanding\nlanguage-specific word structure. In this study, we leverage an annotated\nDanish morphological dataset to train a semisupervised model for morphological\nsegmentation, enabling the development of tokenizers optimized for Danish\nmorphology. We evaluate four distinct tokenizers, including two custom\nmorphological tokenizers, by analyzing their performance in morphologically\nsegmenting Danish words. Additionally, we train two generative transformer\nmodels, \\textit{CerebrasGPT-111M} and \\textit{LLaMA-3.2 1B}, using these\ntokenizers and evaluate their downstream performance. Our findings reveal that\nour custom-developed tokenizers substantially enhance morphological\nsegmentation, achieving an F1 score of 58.84, compared to 39.28 achieved by a\nDanish BPE tokenizer. In downstream tasks, models trained with our\nmorphological tokenizers outperform those using BPE tokenizers across different\nevaluation metrics. These results highlight that incorporating Danish\nmorphological segmentation strategies into tokenizers leads to improved\nperformance in generative transformer models on Danish language", "published": "2025-04-02 09:26:02", "link": "http://arxiv.org/abs/2504.01540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Aware Toxicity Detection in Multiplayer Games: Integrating Domain-Adaptive Pretraining and Match Metadata", "abstract": "The detrimental effects of toxicity in competitive online video games are\nwidely acknowledged, prompting publishers to monitor player chat conversations.\nThis is challenging due to the context-dependent nature of toxicity, often\nspread across multiple messages or informed by non-textual interactions.\nTraditional toxicity detectors focus on isolated messages, missing the broader\ncontext needed for accurate moderation. This is especially problematic in video\ngames, where interactions involve specialized slang, abbreviations, and typos,\nmaking it difficult for standard models to detect toxicity, especially given\nits rarity. We adapted RoBERTa LLM to support moderation tailored to video\ngames, integrating both textual and non-textual context. By enhancing\npretrained embeddings with metadata and addressing the unique slang and\nlanguage quirks through domain adaptive pretraining, our method better captures\nthe nuances of player interactions. Using two gaming datasets - from Defense of\nthe Ancients 2 (DOTA 2) and Call of Duty$^\\circledR$: Modern\nWarfare$^\\circledR$III (MWIII) we demonstrate which sources of context\n(metadata, prior interactions...) are most useful, how to best leverage them to\nboost performance, and the conditions conducive to doing so. This work\nunderscores the importance of context-aware and domain-specific approaches for\nproactive moderation.", "published": "2025-04-02 09:21:41", "link": "http://arxiv.org/abs/2504.01534v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Redefining technology for indigenous languages", "abstract": "In this paper, we offer an overview of indigenous languages, identifying the\ncauses of their devaluation and the need for legislation on language rights. We\nreview the technologies used to revitalize these languages, finding that when\nthey come from outside, they often have the opposite effect to what they seek;\nhowever, when developed from within communities, they become powerful\ninstruments of expression. We propose that the inclusion of Indigenous\nknowledge in large language models (LLMs) will enrich the technological\nlandscape, but must be done in a participatory environment that encourages the\nexchange of knowledge.", "published": "2025-04-02 09:08:53", "link": "http://arxiv.org/abs/2504.01522v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Chain of Correction for Full-text Speech Recognition with Large Language Models", "abstract": "Full-text error correction with Large Language Models (LLMs) for Automatic\nSpeech Recognition (ASR) has gained increased attention due to its potential to\ncorrect errors across long contexts and address a broader spectrum of error\ntypes, including punctuation restoration and inverse text normalization.\nNevertheless, many challenges persist, including issues related to stability,\ncontrollability, completeness, and fluency. To mitigate these challenges, this\npaper proposes the Chain of Correction (CoC) for full-text error correction\nwith LLMs, which corrects errors segment by segment using pre-recognized text\nas guidance within a regular multi-turn chat format. The CoC also uses\npre-recognized full text for context, allowing the model to better grasp global\nsemantics and maintain a comprehensive overview of the entire content.\nUtilizing the open-sourced full-text error correction dataset ChFT, we\nfine-tune a pre-trained LLM to evaluate the performance of the CoC framework.\nExperimental results demonstrate that the CoC effectively corrects errors in\nfull-text ASR outputs, significantly outperforming baseline and benchmark\nsystems. We further analyze how to set the correction threshold to balance\nunder-correction and over-rephrasing, extrapolate the CoC model on extremely\nlong ASR outputs, and investigate whether other types of information can be\nemployed to guide the error correction process.", "published": "2025-04-02 09:06:23", "link": "http://arxiv.org/abs/2504.01519v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "PROPHET: An Inferable Future Forecasting Benchmark with Causal Intervened Likelihood Estimation", "abstract": "Predicting future events stands as one of the ultimate aspirations of\nartificial intelligence. Recent advances in large language model (LLM)-based\nsystems have shown remarkable potential in forecasting future events, thereby\ngarnering significant interest in the research community. Currently, several\nbenchmarks have been established to evaluate the forecasting capabilities by\nformalizing the event prediction as a retrieval-augmented generation (RAG) and\nreasoning task. In these benchmarks, each prediction question is answered with\nrelevant retrieved news articles. However, because there is no consideration on\nwhether the questions can be supported by valid or sufficient supporting\nrationales, some of the questions in these benchmarks may be inherently\nnoninferable. To address this issue, we introduce a new benchmark, PROPHET,\nwhich comprises inferable forecasting questions paired with relevant news for\nretrieval. To ensure the inferability of the benchmark, we propose Causal\nIntervened Likelihood (CIL), a statistical measure that assesses inferability\nthrough causal inference. In constructing this benchmark, we first collected\nrecent trend forecasting questions and then filtered the data using CIL,\nresulting in an inferable benchmark for event prediction. Through extensive\nexperiments, we first demonstrate the validity of CIL and in-depth\ninvestigations into event prediction with the aid of CIL. Subsequently, we\nevaluate several representative prediction systems on PROPHET, drawing valuable\ninsights for future directions.", "published": "2025-04-02 08:57:42", "link": "http://arxiv.org/abs/2504.01509v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LVMed-R2: Perception and Reflection-driven Complex Reasoning for Medical Report Generation", "abstract": "Large vision-language models (LVMs) hold a great promise for automating\nmedical report generation, potentially reducing the burden of manual reporting.\nState-of-the-art (SOTA) research fine-tunes general LVMs with medical data to\nalign radiology images to corresponding medical reports. However, there are two\nkey factors that limit these LVM's performance. Firstly, LVMs lack complex\nreasoning capability that leads to logical inconsistencies and potential\ndiagnostic errors in generated reports. Secondly, LVMs lack reflection\nmechanism that leads to an inability to discover errors in the thinking\nprocess. To address these gaps, we propose LVMed-R2, a new fine-tuning strategy\nthat introduces complex reasoning and reflection mechanisms for LVMs to enhance\nmedical report generation. To the best of our knowledge, this is the first work\nto introduce complex reasoning to the medical report generation (MRG) task. Our\nproposed complex reasoning contains medical knowledge injection and\nperception-enhancing modules which improve the accuracy of LVMs diagnosis,\ncoupled with a perception tree to provide guidance to limit the perception\nrange. Further, the reflection mechanism forces self-verification for outputs\nto correct for potential errors. We experimented by fine-tuning LVMs with our\nproposed LVMed-R2 strategy, using IU-Xray and MIMIC-CXR datasets. Our results,\nmeasured on natural language generation (NLG) metrics and clinical efficacy\n(CE) metrics, demonstrate that LVMs fine-tuned with the proposed reflection\nmechanism possess the ability to correct outputs and complex reasoning\neffectively and improve LVMs performance for MRG.", "published": "2025-04-02 08:18:54", "link": "http://arxiv.org/abs/2504.02885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CASCADE Your Datasets for Cross-Mode Knowledge Retrieval of Language Models", "abstract": "Language models often struggle with cross-mode knowledge retrieval -- the\nability to access knowledge learned in one format (mode) when queried in\nanother. We demonstrate that models trained on multiple data sources (e.g.,\nWikipedia and TinyStories) exhibit significantly reduced accuracy when\nretrieving knowledge in a format different from its original training mode.\nThis paper quantitatively investigates this phenomenon through a controlled\nstudy of random token sequence memorization across different modes. We first\nexplore dataset rewriting as a solution, revealing that effective cross-mode\nretrieval requires prohibitively extensive rewriting efforts that follow a\nsigmoid-like relationship. As an alternative, we propose CASCADE, a novel\npretraining algorithm that uses cascading datasets with varying sequence\nlengths to capture knowledge at different scales. Our experiments demonstrate\nthat CASCADE outperforms dataset rewriting approaches, even when compressed\ninto a single model with a unified loss function. This work provides both\nqualitative evidence of cross-mode retrieval limitations and a practical\nsolution to enhance language models' ability to access knowledge independently\nof its presentational format.", "published": "2025-04-02 08:02:07", "link": "http://arxiv.org/abs/2504.01450v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Refining Interactions: Enhancing Anisotropy in Graph Neural Networks with Language Semantics", "abstract": "The integration of Large Language Models (LLMs) with Graph Neural Networks\n(GNNs) has recently been explored to enhance the capabilities of Text Attribute\nGraphs (TAGs). Most existing methods feed textual descriptions of the graph\nstructure or neighbouring nodes' text directly into LLMs. However, these\napproaches often cause LLMs to treat structural information simply as general\ncontextual text, thus limiting their effectiveness in graph-related tasks. In\nthis paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph Neural\nNetwork), a framework that extends the concept of anisotropic GNNs to the\nnatural language level. This model leverages LLMs to extract tailor-made\nsemantic information for node pairs, effectively capturing the unique\ninteractions within node relationships. In addition, we propose an efficient\ndual-layer LLMs finetuning architecture to better align LLMs' outputs with\ngraph tasks. Experimental results demonstrate that LanSAGNN significantly\nenhances existing LLM-based methods without increasing complexity while also\nexhibiting strong robustness against interference.", "published": "2025-04-02 07:32:45", "link": "http://arxiv.org/abs/2504.01429v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SemEval-2025 Task 4: Unlearning sensitive content from Large Language Models", "abstract": "We introduce SemEval-2025 Task 4: unlearning sensitive content from Large\nLanguage Models (LLMs). The task features 3 subtasks for LLM unlearning\nspanning different use cases: (1) unlearn long form synthetic creative\ndocuments spanning different genres; (2) unlearn short form synthetic\nbiographies containing personally identifiable information (PII), including\nfake names, phone number, SSN, email and home addresses, and (3) unlearn real\ndocuments sampled from the target model's training dataset. We received over\n100 submissions from over 30 institutions and we summarize the key techniques\nand lessons in this paper.", "published": "2025-04-02 07:24:59", "link": "http://arxiv.org/abs/2504.02883v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FAIRE: Assessing Racial and Gender Bias in AI-Driven Resume Evaluations", "abstract": "In an era where AI-driven hiring is transforming recruitment practices,\nconcerns about fairness and bias have become increasingly important. To explore\nthese issues, we introduce a benchmark, FAIRE (Fairness Assessment In Resume\nEvaluation), to test for racial and gender bias in large language models (LLMs)\nused to evaluate resumes across different industries. We use two methods-direct\nscoring and ranking-to measure how model performance changes when resumes are\nslightly altered to reflect different racial or gender identities. Our findings\nreveal that while every model exhibits some degree of bias, the magnitude and\ndirection vary considerably. This benchmark provides a clear way to examine\nthese differences and offers valuable insights into the fairness of AI-based\nhiring tools. It highlights the urgent need for strategies to reduce bias in\nAI-driven recruitment. Our benchmark code and dataset are open-sourced at our\nrepository:\nhttps://github.com/athenawen/FAIRE-Fairness-Assessment-In-Resume-Evaluation.git.", "published": "2025-04-02 07:11:30", "link": "http://arxiv.org/abs/2504.01420v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval", "abstract": "Traditional sparse and dense retrieval methods struggle to leverage general\nworld knowledge and often fail to capture the nuanced features of queries and\nproducts. With the advent of large language models (LLMs), industrial search\nsystems have started to employ LLMs to generate identifiers for product\nretrieval. Commonly used identifiers include (1) static/semantic IDs and (2)\nproduct term sets. The first approach requires creating a product ID system\nfrom scratch, missing out on the world knowledge embedded within LLMs. While\nthe second approach leverages this general knowledge, the significant\ndifference in word distribution between queries and products means that\nproduct-based identifiers often do not align well with user search queries,\nleading to missed product recalls. Furthermore, when queries contain numerous\nattributes, these algorithms generate a large number of identifiers, making it\ndifficult to assess their quality, which results in low overall recall\nefficiency.\n  To address these challenges, this paper introduces a novel e-commerce\nretrieval paradigm: the Generative Retrieval and Alignment Model (GRAM). GRAM\nemploys joint training on text information from both queries and products to\ngenerate shared text identifier codes, effectively bridging the gap between\nqueries and products. This approach not only enhances the connection between\nqueries and products but also improves inference efficiency. The model uses a\nco-alignment strategy to generate codes optimized for maximizing retrieval\nefficiency. Additionally, it introduces a query-product scoring mechanism to\ncompare product values across different codes, further boosting retrieval\nefficiency. Extensive offline and online A/B testing demonstrates that GRAM\nsignificantly outperforms traditional models and the latest generative\nretrieval models, confirming its effectiveness and practicality.", "published": "2025-04-02 06:40:09", "link": "http://arxiv.org/abs/2504.01403v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "ToolACE-R: Tool Learning with Adaptive Self-Refinement", "abstract": "Tool learning, which allows Large Language Models (LLMs) to leverage external\ntools for solving complex user tasks, has emerged as a promising avenue for\nextending model capabilities. However, current approaches primarily focus on\ndata synthesis for fine-tuning LLMs to invoke tools effectively, largely\nignoring how to fully stimulate the potential of the model. In this paper, we\npropose ToolACE-R, a novel method that introduces adaptive self-refinement for\ntool invocations. Our approach features a model-aware iterative training\nprocedure that progressively incorporates more training samples based on the\nmodel's evolving capabilities. Additionally, it allows LLMs to iteratively\nrefine their tool calls, optimizing performance without requiring external\nfeedback. To further enhance computational efficiency, we integrate an adaptive\nmechanism when scaling the inference time, enabling the model to autonomously\ndetermine when to stop the refinement process. We conduct extensive experiments\nacross several benchmark datasets, showing that ToolACE-R achieves competitive\nperformance compared to advanced API-based models, even without any refinement.\nFurthermore, its performance can be further improved efficiently through\nadaptive self-refinement. Our results demonstrate the effectiveness of the\nproposed method, which is compatible with base models of various sizes,\noffering a promising direction for more efficient tool learning.", "published": "2025-04-02 06:38:56", "link": "http://arxiv.org/abs/2504.01400v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Illusion of Progress? Assessing the Current State of Web Agents", "abstract": "As digitalization and cloud technologies evolve, the web is becoming\nincreasingly important in the modern society. Autonomous web agents based on\nlarge language models (LLMs) hold a great potential in work automation. It is\ntherefore important to accurately measure and monitor the progression of their\ncapabilities. In this work, we conduct a comprehensive and rigorous assessment\nof the current state of web agents. Our results depict a very different picture\nof the competency of current agents, suggesting over-optimism in previously\nreported results. This gap can be attributed to shortcomings in existing\nbenchmarks. We introduce Online-Mind2Web, an online evaluation benchmark\nconsisting of 300 diverse and realistic tasks spanning 136 websites. It enables\nus to evaluate web agents under a setting that approximates how real users use\nthese agents. To facilitate more scalable evaluation and development, we also\ndevelop a novel LLM-as-a-Judge automatic evaluation method and show that it can\nachieve around 85% agreement with human judgment, substantially higher than\nexisting methods. Finally, we present the first comprehensive comparative\nanalysis of current web agents, highlighting both their strengths and\nlimitations to inspire future research.", "published": "2025-04-02 05:51:29", "link": "http://arxiv.org/abs/2504.01382v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "DiaTool-DPO: Multi-Turn Direct Preference Optimization for Tool-Augmented Large Language Models", "abstract": "Tool-Augmented Larage Language Models (TA-LLMs) have shown promise in\nreal-world applications, but face challenges in handling incomplete queries and\nout-of-scope requests. While existing approaches rely mainly on Supervised\nFine-Tuning with expert trajectories, we propose DiaTool-DPO, a novel method\nthat enhances TA-LLM's dialogue capabilities through Direct Preference\nOptimization. We model TA-LLM interactions as a Markov Decision Process with 5\ndistinct dialogue states and categorize user queries into 3 types based on\ntheir state transition trajectories. We automatically construct paired\ntrajectory datasets of correct and incorrect dialogue flows and introduce a\nspecialized objective loss for dialogue control. Our comprehensive evaluation\ndemonstrates that DiaTool-DPO approaches GPT-4o's performance (94.8% in\ninformation gathering, 91% in tool call rejection) with substantial\nimprovements over baseline (44% and 9.6% respectively) while maintaining core\nfunctionality. Our approach opens new possibilities for developing TA-LLMs that\ncan handle diverse real-world scenarios without requiring additional expert\ndemonstrations or human labeling.", "published": "2025-04-02 05:47:28", "link": "http://arxiv.org/abs/2504.02882v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LITE: LLM-Impelled efficient Taxonomy Evaluation", "abstract": "This paper presents LITE, an LLM-based evaluation method designed for\nefficient and flexible assessment of taxonomy quality. To address challenges in\nlarge-scale taxonomy evaluation, such as efficiency, fairness, and consistency,\nLITE adopts a top-down hierarchical evaluation strategy, breaking down the\ntaxonomy into manageable substructures and ensuring result reliability through\ncross-validation and standardized input formats. LITE also introduces a penalty\nmechanism to handle extreme cases and provides both quantitative performance\nanalysis and qualitative insights by integrating evaluation metrics closely\naligned with task objectives. Experimental results show that LITE demonstrates\nhigh reliability in complex evaluation tasks, effectively identifying semantic\nerrors, logical contradictions, and structural flaws in taxonomies, while\noffering directions for improvement. Code is available at\nhttps://github.com/Zhang-l-i-n/TAXONOMY_DETECT .", "published": "2025-04-02 05:33:05", "link": "http://arxiv.org/abs/2504.01369v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Urban Computing in the Era of Large Language Models", "abstract": "Urban computing has emerged as a multidisciplinary field that harnesses\ndata-driven technologies to address challenges and improve urban living.\nTraditional approaches, while beneficial, often face challenges with\ngeneralization, scalability, and contextual understanding. The advent of Large\nLanguage Models (LLMs) offers transformative potential in this domain. This\nsurvey explores the intersection of LLMs and urban computing, emphasizing the\nimpact of LLMs in processing and analyzing urban data, enhancing\ndecision-making, and fostering citizen engagement. We provide a concise\noverview of the evolution and core technologies of LLMs. Additionally, we\nsurvey their applications across key urban domains, such as transportation,\npublic safety, and environmental monitoring, summarizing essential tasks and\nprior works in various urban contexts, while highlighting LLMs' functional\nroles and implementation patterns. Building on this, we propose potential\nLLM-based solutions to address unresolved challenges. To facilitate in-depth\nresearch, we compile a list of available datasets and tools applicable to\ndiverse urban scenarios. Finally, we discuss the limitations of current\napproaches and outline future directions for advancing LLMs in urban computing.", "published": "2025-04-02 05:12:13", "link": "http://arxiv.org/abs/2504.02009v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Better Bill GPT: Comparing Large Language Models against Legal Invoice Reviewers", "abstract": "Legal invoice review is a costly, inconsistent, and time-consuming process,\ntraditionally performed by Legal Operations, Lawyers or Billing Specialists who\nscrutinise billing compliance line by line. This study presents the first\nempirical comparison of Large Language Models (LLMs) against human invoice\nreviewers - Early-Career Lawyers, Experienced Lawyers, and Legal Operations\nProfessionals-assessing their accuracy, speed, and cost-effectiveness.\nBenchmarking state-of-the-art LLMs against a ground truth set by expert legal\nprofessionals, our empirically substantiated findings reveal that LLMs\ndecisively outperform humans across every metric. In invoice approval\ndecisions, LLMs achieve up to 92% accuracy, surpassing the 72% ceiling set by\nexperienced lawyers. On a granular level, LLMs dominate line-item\nclassification, with top models reaching F-scores of 81%, compared to just 43%\nfor the best-performing human group. Speed comparisons are even more striking -\nwhile lawyers take 194 to 316 seconds per invoice, LLMs are capable of\ncompleting reviews in as fast as 3.6 seconds. And cost? AI slashes review\nexpenses by 99.97%, reducing invoice processing costs from an average of $4.27\nper invoice for human invoice reviewers to mere cents. These results highlight\nthe evolving role of AI in legal spend management. As law firms and corporate\nlegal departments struggle with inefficiencies, this study signals a seismic\nshift: The era of LLM-powered legal spend management is not on the horizon, it\nhas arrived. The challenge ahead is not whether AI can perform as well as human\nreviewers, but how legal teams will strategically incorporate it, balancing\nautomation with human discretion.", "published": "2025-04-02 05:07:08", "link": "http://arxiv.org/abs/2504.02881v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tasks and Roles in Legal AI: Data Curation, Annotation, and Verification", "abstract": "The application of AI tools to the legal field feels natural: large legal\ndocument collections could be used with specialized AI to improve workflow\nefficiency for lawyers and ameliorate the \"justice gap\" for underserved\nclients. However, legal documents differ from the web-based text that underlies\nmost AI systems. The challenges of legal AI are both specific to the legal\ndomain, and confounded with the expectation of AI's high performance in\nhigh-stakes settings. We identify three areas of special relevance to\npractitioners: data curation, data annotation, and output verification. First,\nit is difficult to obtain usable legal texts. Legal collections are\ninconsistent, analog, and scattered for reasons technical, economic, and\njurisdictional. AI tools can assist document curation efforts, but the lack of\nexisting data also limits AI performance. Second, legal data annotation\ntypically requires significant expertise to identify complex phenomena such as\nmodes of judicial reasoning or controlling precedents. We describe case studies\nof AI systems that have been developed to improve the efficiency of human\nannotation in legal contexts and identify areas of underperformance. Finally,\nAI-supported work in the law is valuable only if results are verifiable and\ntrustworthy. We describe both the abilities of AI systems to support evaluation\nof their outputs, as well as new approaches to systematic evaluation of\ncomputational systems in complex domains. We call on both legal and AI\npractitioners to collaborate across disciplines and to release open access\nmaterials to support the development of novel, high-performing, and reliable AI\ntools for legal applications.", "published": "2025-04-02 04:34:58", "link": "http://arxiv.org/abs/2504.01349v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GTR: Graph-Table-RAG for Cross-Table Question Answering", "abstract": "Beyond pure text, a substantial amount of knowledge is stored in tables. In\nreal-world scenarios, user questions often require retrieving answers that are\ndistributed across multiple tables. GraphRAG has recently attracted much\nattention for enhancing LLMs' reasoning capabilities by organizing external\nknowledge to address ad-hoc and complex questions, exemplifying a promising\ndirection for cross-table question answering. In this paper, to address the\ncurrent gap in available data, we first introduce a multi-table benchmark,\nMutliTableQA, comprising 60k tables and 25k user queries collected from\nreal-world sources. Then, we propose the first Graph-Table-RAG framework,\nnamely GTR, which reorganizes table corpora into a heterogeneous graph, employs\na hierarchical coarse-to-fine retrieval process to extract the most relevant\ntables, and integrates graph-aware prompting for downstream LLMs' tabular\nreasoning. Extensive experiments show that GTR exhibits superior cross-table\nquestion-answering performance while maintaining high deployment efficiency,\ndemonstrating its real-world practical applicability.", "published": "2025-04-02 04:24:41", "link": "http://arxiv.org/abs/2504.01346v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Breaking BERT: Gradient Attack on Twitter Sentiment Analysis for Targeted Misclassification", "abstract": "Social media platforms like Twitter have increasingly relied on Natural\nLanguage Processing NLP techniques to analyze and understand the sentiments\nexpressed in the user generated content. One such state of the art NLP model is\nBidirectional Encoder Representations from Transformers BERT which has been\nwidely adapted in sentiment analysis. BERT is susceptible to adversarial\nattacks. This paper aims to scrutinize the inherent vulnerabilities of such\nmodels in Twitter sentiment analysis. It aims to formulate a framework for\nconstructing targeted adversarial texts capable of deceiving these models,\nwhile maintaining stealth. In contrast to conventional methodologies, such as\nImportance Reweighting, this framework core idea resides in its reliance on\ngradients to prioritize the importance of individual words within the text. It\nuses a whitebox approach to attain fine grained sensitivity, pinpointing words\nthat exert maximal influence on the classification outcome. This paper is\norganized into three interdependent phases. It starts with fine-tuning a\npre-trained BERT model on Twitter data. It then analyzes gradients of the model\nto rank words on their importance, and iteratively replaces those with feasible\ncandidates until an acceptable solution is found. Finally, it evaluates the\neffectiveness of the adversarial text against the custom trained sentiment\nclassification model. This assessment would help in gauging the capacity of the\nadversarial text to successfully subvert classification without raising any\nalarm.", "published": "2025-04-02 04:21:19", "link": "http://arxiv.org/abs/2504.01345v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Foundations and Evaluations in NLP", "abstract": "This memoir explores two fundamental aspects of Natural Language Processing\n(NLP): the creation of linguistic resources and the evaluation of NLP system\nperformance. Over the past decade, my work has focused on developing a\nmorpheme-based annotation scheme for the Korean language that captures\nlinguistic properties from morphology to semantics. This approach has achieved\nstate-of-the-art results in various NLP tasks, including part-of-speech\ntagging, dependency parsing, and named entity recognition. Additionally, this\nwork provides a comprehensive analysis of segmentation granularity and its\ncritical impact on NLP system performance. In parallel with linguistic resource\ndevelopment, I have proposed a novel evaluation framework, the jp-algorithm,\nwhich introduces an alignment-based method to address challenges in\npreprocessing tasks like tokenization and sentence boundary detection (SBD).\nTraditional evaluation methods assume identical tokenization and sentence\nlengths between gold standards and system outputs, limiting their applicability\nto real-world data. The jp-algorithm overcomes these limitations, enabling\nrobust end-to-end evaluations across a variety of NLP tasks. It enhances\naccuracy and flexibility by incorporating linear-time alignment while\npreserving the complexity of traditional evaluation metrics. This memoir\nprovides key insights into the processing of morphologically rich languages,\nsuch as Korean, while offering a generalizable framework for evaluating diverse\nend-to-end NLP systems. My contributions lay the foundation for future\ndevelopments, with broader implications for multilingual resource development\nand system evaluation.", "published": "2025-04-02 04:14:03", "link": "http://arxiv.org/abs/2504.01342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing MoE Efficiency: A Collaboration-Constrained Routing (C2R) Strategy for Better Expert Parallelism Design", "abstract": "Mixture-of-Experts (MoE) has successfully scaled up models while maintaining\nnearly constant computing costs. By employing a gating network to route input\ntokens, it selectively activates a subset of expert networks to process the\ncorresponding token embeddings. However, in practice, the efficiency of MoE is\nchallenging to achieve due to two key reasons: imbalanced expert activation,\nwhich leads to substantial idle time during model or expert parallelism, and\ninsufficient capacity utilization; massive communication overhead, induced by\nnumerous expert routing combinations in expert parallelism at the system level.\nPrevious works typically formulate it as the load imbalance issue characterized\nby the gating network favoring certain experts over others or attribute it to\nstatic execution which fails to adapt to the dynamic expert workload at\nruntime. In this paper, we exploit it from a brand new perspective, a\nhigher-order view and analysis of MoE routing policies: expert collaboration\nand specialization where some experts tend to activate broadly with others\n(collaborative), while others are more likely to activate only with a specific\nsubset of experts (specialized). Our experiments reveal that most experts tend\nto be overly collaborative, leading to increased communication overhead from\nrepeatedly sending tokens to different accelerators. To this end, we propose a\nnovel collaboration-constrained routing (C2R) strategy to encourage more\nspecialized expert groups, as well as to improve expert utilization, and\npresent an efficient implementation of MoE that further leverages expert\nspecialization. We achieve an average performance improvement of 0.51% and\n0.33% on LLaMA-MoE and Qwen-MoE respectively across ten downstream NLP\nbenchmarks, and reduce the all2all communication costs between GPUs, bringing\nan extra 20%-30% total running time savings on top of the existing SoTA, i.e.\nMegaBlocks.", "published": "2025-04-02 03:51:59", "link": "http://arxiv.org/abs/2504.01337v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "On Data Synthesis and Post-training for Visual Abstract Reasoning", "abstract": "This paper is a pioneering work attempting to address abstract visual\nreasoning (AVR) problems for large vision-language models (VLMs). We make a\ncommon LLaVA-NeXT 7B model capable of perceiving and reasoning about specific\nAVR problems, surpassing both open-sourced (e.g., Qwen-2-VL-72B) and\nclosed-sourced powerful VLMs (e.g., GPT-4o) with significant margin. This is a\ngreat breakthrough since almost all previous VLMs fail or show nearly random\nperformance on representative AVR benchmarks. Our key success is our innovative\ndata synthesis and post-training process, aiming to fully relieve the task\ndifficulty and elicit the model to learn, step by step. Our 7B model is also\nshown to be behave well on AVR without sacrificing common multimodal\ncomprehension abilities. We hope our paper could serve as an early effort in\nthis area and would inspire further research in abstract visual reasoning.", "published": "2025-04-02 03:18:24", "link": "http://arxiv.org/abs/2504.01324v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Adaptive Rectification Sampling for Test-Time Compute Scaling", "abstract": "The newly released OpenAI-o1 and DeepSeek-R1 have demonstrated that test-time\nscaling can significantly improve model performance, especially in complex\ntasks such as logical reasoning. Common test-time scaling methods involve\ngenerating more chain of thoughts (CoTs) or longer CoTs with self-correction.\nHowever, while self-correction can improve performance, it may lead to\nsignificant token waste and reduce readability of the CoT if the reasoning\nsteps are already correct. To demonstrate that large language models (LLMs) can\nrectify errors at a more fine-grained level, we propose Adaptive Rectification\nSampling (AR-Sampling), which can guide the LLMs to self-correction at the\nappropriate step. AR-Sampling leverages a process-supervised reward model (PRM)\nas a verifier and constructed trigger sentences to guide the model in adaptive\nstep-level rethinking. Through the experiments on GSM8K and MATH500, it\nindicate that our approach enables the models to rethink in more fine-grained\nlevel, improving the accuracy of solutions, while generating a reasonable\nnumber of additional tokens.", "published": "2025-04-02 02:57:52", "link": "http://arxiv.org/abs/2504.01317v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Biomedical Question Answering via Multi-Level Summarization on a Local Knowledge Graph", "abstract": "In Question Answering (QA), Retrieval Augmented Generation (RAG) has\nrevolutionized performance in various domains. However, how to effectively\ncapture multi-document relationships, particularly critical for biomedical\ntasks, remains an open question. In this work, we propose a novel method that\nutilizes propositional claims to construct a local knowledge graph from\nretrieved documents. Summaries are then derived via layerwise summarization\nfrom the knowledge graph to contextualize a small language model to perform QA.\nWe achieved comparable or superior performance with our method over RAG\nbaselines on several biomedical QA benchmarks. We also evaluated each\nindividual step of our methodology over a targeted set of metrics,\ndemonstrating its effectiveness.", "published": "2025-04-02 02:40:19", "link": "http://arxiv.org/abs/2504.01309v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Revisiting Funnel Transformers for Modern LLM Architectures with Comprehensive Ablations in Training and Inference Configurations", "abstract": "Transformer-based Large Language Models, which suffer from high computational\ncosts, advance so quickly that techniques proposed to streamline earlier\niterations are not guaranteed to benefit more modern models. Building upon the\nFunnel Transformer proposed by Dai and Le (2020), which progressively\ncompresses intermediate representations, we investigate the impact of funneling\nin contemporary Gemma2 Transformer architectures. We systematically evaluate\nvarious funnel configurations and recovery methods, comparing: (1) standard\npretraining to funnel-aware pretraining strategies, (2) the impact of\nfunnel-aware fine-tuning, and (3) the type of sequence recovery operation. Our\nresults demonstrate that funneling creates information bottlenecks that\npropagate through deeper network layers, particularly in larger models (e.g.,\nGemma 7B), leading to at times unmanageable performance lost. However,\ncarefully selecting the funneling layer and employing effective recovery\nstrategies, can substantially mitigate performance losses, achieving up to a\n44\\% reduction in latency. Our findings highlight key trade-offs between\ncomputational efficiency and model accuracy, providing practical guidance for\ndeploying funnel-based approaches in large-scale natural language applications.", "published": "2025-04-02 02:09:17", "link": "http://arxiv.org/abs/2504.02877v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ThinkPrune: Pruning Long Chain-of-Thought of LLMs via Reinforcement Learning", "abstract": "We present ThinkPrune, a simple yet effective method for pruning the thinking\nlength for long-thinking LLMs, which has been found to often produce\ninefficient and redundant thinking processes. Existing preliminary explorations\nof reducing thinking length primarily focus on forcing the thinking process to\nearly exit, rather than adapting the LLM to optimize and consolidate the\nthinking process, and therefore the length-performance tradeoff observed so far\nis sub-optimal. To fill this gap, ThinkPrune offers a simple solution that\ncontinuously trains the long-thinking LLMs via reinforcement learning (RL) with\nan added token limit, beyond which any unfinished thoughts and answers will be\ndiscarded, resulting in a zero reward. To further preserve model performance,\nwe introduce an iterative length pruning approach, where multiple rounds of RL\nare conducted, each with an increasingly more stringent token limit. We\nobserved that ThinkPrune results in a remarkable performance-length tradeoff --\non the AIME24 dataset, the reasoning length of DeepSeek-R1-Distill-Qwen-1.5B\ncan be reduced by half with only 2% drop in performance. We also observed that\nafter pruning, the LLMs can bypass unnecessary steps while keeping the core\nreasoning process complete. Code is available at\nhttps://github.com/UCSB-NLP-Chang/ThinkPrune.", "published": "2025-04-02 01:59:26", "link": "http://arxiv.org/abs/2504.01296v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-Reverse Inconsistency: LLM Self-Inconsistency Beyond Generative Randomness and Prompt Paraphrasing", "abstract": "While the inconsistency of LLMs is not a novel topic, prior research has\npredominantly addressed two types of generative inconsistencies: i) Randomness\nInconsistency: running the same LLM multiple trials, yielding varying\nresponses; ii) Paraphrase Inconsistency: paraphrased prompts result in\ndifferent responses from the same LLM. Randomness Inconsistency arises from the\ninherent randomness due to stochastic sampling in generative models, while\nParaphrase Inconsistency is a consequence of the language modeling objectives,\nwhere paraphrased prompts alter the distribution of vocabulary logits. This\nresearch discovers Prompt-Reverse Inconsistency (PRIN), a new form of LLM\nself-inconsistency: given a question and a couple of LLM-generated answer\ncandidates, the LLM often has conflicting responses when prompted \"Which are\ncorrect answers?\" and \"Which are incorrect answers?\". PRIN poses a big concern\nas it undermines the credibility of LLM-as-a-judge, and suggests a challenge\nfor LLMs to adhere to basic logical rules. We conduct a series of experiments\nto investigate PRIN, examining the extent of PRIN across different LLMs,\nmethods to mitigate it, potential applications, and its relationship with\nRandomness Inconsistency and Paraphrase Inconsistency. As the first study to\nexplore PRIN, our findings offer valuable insights into the inner workings of\nLLMs and contribute to advancing trustworthy AI.", "published": "2025-04-02 01:19:37", "link": "http://arxiv.org/abs/2504.01282v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding", "abstract": "We present a comprehensive framework for enhancing Retrieval-Augmented\nGeneration (RAG) systems through dynamic retrieval strategies and reinforcement\nfine-tuning. This approach significantly improves large language models on\nknowledge-intensive tasks, including opendomain question answering and complex\nreasoning. Our framework integrates two complementary techniques:\nPolicy-Optimized RetrievalAugmented Generation (PORAG), which optimizes the use\nof retrieved information, and Adaptive Token-Layer Attention Scoring (ATLAS),\nwhich dynamically determines retrieval timing and content based on contextual\nneeds. Together, these techniques enhance both the utilization and relevance of\nretrieved content, improving factual accuracy and response quality. Designed as\na lightweight solution compatible with any Transformer-based LLM without\nrequiring additional training, our framework excels in knowledge-intensive\ntasks, boosting output accuracy in RAG settings. We further propose CRITIC, a\nnovel method to selectively compress key-value caches by token importance,\nmitigating memory bottlenecks in long-context applications. The framework also\nincorporates test-time scaling techniques to dynamically balance reasoning\ndepth and computational resources, alongside optimized decoding strategies for\nfaster inference. Experiments on benchmark datasets show that our framework\nreduces hallucinations, strengthens domain-specific reasoning, and achieves\nsignificant efficiency and scalability gains over traditional RAG systems. This\nintegrated approach advances the development of robust, efficient, and scalable\nRAG systems across diverse applications.", "published": "2025-04-02 01:16:10", "link": "http://arxiv.org/abs/2504.01281v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "A Survey of Scaling in Large Language Model Reasoning", "abstract": "The rapid advancements in large Language models (LLMs) have significantly\nenhanced their reasoning capabilities, driven by various strategies such as\nmulti-agent collaboration. However, unlike the well-established performance\nimprovements achieved through scaling data and model size, the scaling of\nreasoning in LLMs is more complex and can even negatively impact reasoning\nperformance, introducing new challenges in model alignment and robustness. In\nthis survey, we provide a comprehensive examination of scaling in LLM\nreasoning, categorizing it into multiple dimensions and analyzing how and to\nwhat extent different scaling strategies contribute to improving reasoning\ncapabilities. We begin by exploring scaling in input size, which enables LLMs\nto process and utilize more extensive context for improved reasoning. Next, we\nanalyze scaling in reasoning steps that improves multi-step inference and\nlogical consistency. We then examine scaling in reasoning rounds, where\niterative interactions refine reasoning outcomes. Furthermore, we discuss\nscaling in training-enabled reasoning, focusing on optimization through\niterative model improvement. Finally, we review applications of scaling across\ndomains and outline future directions for further advancing LLM reasoning. By\nsynthesizing these diverse perspectives, this survey aims to provide insights\ninto how scaling strategies fundamentally enhance the reasoning capabilities of\nLLMs and further guide the development of next-generation AI systems.", "published": "2025-04-02 23:51:27", "link": "http://arxiv.org/abs/2504.02181v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Meat-Free Day Reduces Greenhouse Gas Emissions but Poses Challenges for Customer Retention and Adherence to Dietary Guidelines", "abstract": "Reducing meat consumption is crucial for achieving global environmental and\nnutritional targets. Meat-Free Day (MFD) is a widely adopted strategy to\naddress this challenge by encouraging plant-based diets through the removal of\nanimal-based meals. We assessed the environmental, behavioral, and nutritional\nimpacts of MFD by implementing 67 MFDs over 18 months (once a week on a\nrandomly chosen day) across 12 cafeterias on a large university campus,\nanalyzing over 400,000 food purchases. MFD reduced on-campus food-related\ngreenhouse gas (GHG) emissions on treated days by 52.9% and contributed to\nimproved fiber (+26.9%) and cholesterol (-4.5%) consumption without altering\ncaloric intake. These nutritional benefits were, however, accompanied by a\n27.6% decrease in protein intake and a 34.2% increase in sugar consumption.\nMoreover, the increase in plant-based meals did not carry over to subsequent\ndays, as evidenced by a 3.5% rebound in animal-based meal consumption on days\nimmediately following treated days. MFD also led to a 16.8% drop in on-campus\nmeal sales on treated days.Monte Carlo simulations suggest that if 8.7% of\ndiners were to eat burgers off-campus on treated days, MFD's GHG savings would\nbe fully negated. As our analysis identifies on-campus customer retention as\nthe main challenge to MFD effectiveness, we recommend combining MFD with\ncustomer retention interventions to ensure environmental and nutritional\nbenefits.", "published": "2025-04-02 23:50:57", "link": "http://arxiv.org/abs/2504.02899v1", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "cs.CY"}
{"title": "On the Geometry of Receiver Operating Characteristic and Precision-Recall Curves", "abstract": "We study the geometry of Receiver Operating Characteristic (ROC) and\nPrecision-Recall (PR) curves in binary classification problems. The key finding\nis that many of the most commonly used binary classification metrics are merely\nfunctions of the composition function $G := F_p \\circ F_n^{-1}$, where\n$F_p(\\cdot)$ and $F_n(\\cdot)$ are the class-conditional cumulative distribution\nfunctions of the classifier scores in the positive and negative classes,\nrespectively. This geometric perspective facilitates the selection of operating\npoints, understanding the effect of decision thresholds, and comparison between\nclassifiers. It also helps explain how the shapes and geometry of ROC/PR curves\nreflect classifier behavior, providing objective tools for building classifiers\noptimized for specific applications with context-specific constraints. We\nfurther explore the conditions for classifier dominance, present analytical and\nnumerical examples demonstrating the effects of class separability and variance\non ROC and PR geometries, and derive a link between the positive-to-negative\nclass leakage function $G(\\cdot)$ and the Kullback--Leibler divergence. The\nframework highlights practical considerations, such as model calibration,\ncost-sensitive optimization, and operating point selection under real-world\ncapacity constraints, enabling more informed approaches to classifier\ndeployment and decision-making.", "published": "2025-04-02 23:04:28", "link": "http://arxiv.org/abs/2504.02169v1", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "MDP: Multidimensional Vision Model Pruning with Latency Constraint", "abstract": "Current structural pruning methods face two significant limitations: (i) they\noften limit pruning to finer-grained levels like channels, making aggressive\nparameter reduction challenging, and (ii) they focus heavily on parameter and\nFLOP reduction, with existing latency-aware methods frequently relying on\nsimplistic, suboptimal linear models that fail to generalize well to\ntransformers, where multiple interacting dimensions impact latency. In this\npaper, we address both limitations by introducing Multi-Dimensional Pruning\n(MDP), a novel paradigm that jointly optimizes across a variety of pruning\ngranularities-including channels, query, key, heads, embeddings, and blocks.\nMDP employs an advanced latency modeling technique to accurately capture\nlatency variations across all prunable dimensions, achieving an optimal balance\nbetween latency and accuracy. By reformulating pruning as a Mixed-Integer\nNonlinear Program (MINLP), MDP efficiently identifies the optimal pruned\nstructure across all prunable dimensions while respecting latency constraints.\nThis versatile framework supports both CNNs and transformers. Extensive\nexperiments demonstrate that MDP significantly outperforms previous methods,\nespecially at high pruning ratios. On ImageNet, MDP achieves a 28% speed\nincrease with a +1.4 Top-1 accuracy improvement over prior work like HALP for\nResNet50 pruning. Against the latest transformer pruning method, Isomorphic,\nMDP delivers an additional 37% acceleration with a +0.7 Top-1 accuracy\nimprovement.", "published": "2025-04-02 23:00:10", "link": "http://arxiv.org/abs/2504.02168v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multivariate Temporal Regression at Scale: A Three-Pillar Framework Combining ML, XAI, and NLP", "abstract": "The rapid use of artificial intelligence (AI) in processes such as coding,\nimage processing, and data prediction means it is crucial to understand and\nvalidate the data we are working with fully. This paper dives into the hurdles\nof analyzing high-dimensional data, especially when it gets too complex.\nTraditional methods in data analysis often look at direct connections between\ninput variables, which can miss out on the more complicated relationships\nwithin the data.\n  To address these issues, we explore several tested techniques, such as\nremoving specific variables to see their impact and using statistical analysis\nto find connections between multiple variables. We also consider the role of\nsynthetic data and how information can sometimes be redundant across different\nsensors. These analyses are typically very computationally demanding and often\nrequire much human effort to make sense of the results.\n  A common approach is to treat the entire dataset as one unit and apply\nadvanced models to handle it. However, this can become problematic with larger,\nnoisier datasets and more complex models. So, we suggest methods to identify\noverall patterns that can help with tasks like classification or regression\nbased on the idea that more straightforward approaches might be more\nunderstandable.\n  Our research looks at two datasets: a real-world dataset and a synthetic one.\nThe goal is to create a methodology that highlights key features on a global\nscale that lead to predictions, making it easier to validate or quantify the\ndata set. By reducing the dimensionality with this method, we can simplify the\nmodels used and thus clarify the insights we gain. Furthermore, our method can\nreveal unexplored relationships between specific inputs and outcomes, providing\na way to validate these new connections further.", "published": "2025-04-02 21:53:03", "link": "http://arxiv.org/abs/2504.02151v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling", "abstract": "Complex cell signaling systems -- governed by varying protein abundances and\ninteractions -- generate diverse cell types across organs. These systems evolve\nunder influences such as age, sex, diet, environmental exposures, and diseases,\nmaking them challenging to decode given the involvement of tens of thousands of\ngenes and proteins. Recently, hundreds of millions of single-cell omics data\nhave provided a robust foundation for understanding these signaling networks\nwithin various cell subpopulations and conditions. Inspired by the success of\nlarge foundation models (for example, large language models and large vision\nmodels) pre-trained on massive datasets, we introduce OmniCellTOSG, the first\ndataset of cell text-omic signaling graphs (TOSGs). Each TOSG represents the\nsignaling network of an individual or meta-cell and is labeled with information\nsuch as organ, disease, sex, age, and cell subtype. OmniCellTOSG offers two key\ncontributions. First, it introduces a novel graph model that integrates\nhuman-readable annotations -- such as biological functions, cellular locations,\nsignaling pathways, related diseases, and drugs -- with quantitative gene and\nprotein abundance data, enabling graph reasoning to decode cell signaling. This\napproach calls for new joint models combining large language models and graph\nneural networks. Second, the dataset is built from single-cell RNA sequencing\ndata of approximately 120 million cells from diverse tissues and conditions\n(healthy and diseased) and is fully compatible with PyTorch. This facilitates\nthe development of innovative cell signaling models that could transform\nresearch in life sciences, healthcare, and precision medicine. The OmniCellTOSG\ndataset is continuously expanding and will be updated regularly. The dataset\nand code are available at https://github.com/FuhaiLiAiLab/OmniCellTOSG.", "published": "2025-04-02 21:47:58", "link": "http://arxiv.org/abs/2504.02148v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits", "abstract": "To reduce development overhead and enable seamless integration between\npotential components comprising any given generative AI application, the Model\nContext Protocol (MCP) (Anthropic, 2024) has recently been released and\nsubsequently widely adopted. The MCP is an open protocol that standardizes API\ncalls to large language models (LLMs), data sources, and agentic tools. By\nconnecting multiple MCP servers, each defined with a set of tools, resources,\nand prompts, users are able to define automated workflows fully driven by LLMs.\nHowever, we show that the current MCP design carries a wide range of security\nrisks for end users. In particular, we demonstrate that industry-leading LLMs\nmay be coerced into using MCP tools to compromise an AI developer's system\nthrough various attacks, such as malicious code execution, remote access\ncontrol, and credential theft. To proactively mitigate these and related\nattacks, we introduce a safety auditing tool, MCPSafetyScanner, the first\nagentic tool to assess the security of an arbitrary MCP server. MCPScanner uses\nseveral agents to (a) automatically determine adversarial samples given an MCP\nserver's tools and resources; (b) search for related vulnerabilities and\nremediations based on those samples; and (c) generate a security report\ndetailing all findings. Our work highlights serious security issues with\ngeneral-purpose agentic workflows while also providing a proactive tool to\naudit MCP server safety and address detected vulnerabilities before deployment.\n  The described MCP server auditing tool, MCPSafetyScanner, is freely available\nat: https://github.com/leidosinc/McpSafetyScanner", "published": "2025-04-02 21:46:02", "link": "http://arxiv.org/abs/2504.03767v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "UAC: Uncertainty-Aware Calibration of Neural Networks for Gesture Detection", "abstract": "Artificial intelligence has the potential to impact safety and efficiency in\nsafety-critical domains such as construction, manufacturing, and healthcare.\nFor example, using sensor data from wearable devices, such as inertial\nmeasurement units (IMUs), human gestures can be detected while maintaining\nprivacy, thereby ensuring that safety protocols are followed. However, strict\nsafety requirements in these domains have limited the adoption of AI, since\naccurate calibration of predicted probabilities and robustness against\nout-of-distribution (OOD) data is necessary.\n  This paper proposes UAC (Uncertainty-Aware Calibration), a novel two-step\nmethod to address these challenges in IMU-based gesture recognition. First, we\npresent an uncertainty-aware gesture network architecture that predicts both\ngesture probabilities and their associated uncertainties from IMU data. This\nuncertainty is then used to calibrate the probabilities of each potential\ngesture. Second, an entropy-weighted expectation of predictions over multiple\nIMU data windows is used to improve accuracy while maintaining correct\ncalibration.\n  Our method is evaluated using three publicly available IMU datasets for\ngesture detection and is compared to three state-of-the-art calibration methods\nfor neural networks: temperature scaling, entropy maximization, and Laplace\napproximation. UAC outperforms existing methods, achieving improved accuracy\nand calibration in both OOD and in-distribution scenarios. Moreover, we find\nthat, unlike our method, none of the state-of-the-art methods significantly\nimprove the calibration of IMU-based gesture recognition models. In conclusion,\nour work highlights the advantages of uncertainty-aware calibration of neural\nnetworks, demonstrating improvements in both calibration and accuracy for\ngesture detection using IMU data.", "published": "2025-04-02 21:40:01", "link": "http://arxiv.org/abs/2504.02895v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "On Simulation-Guided LLM-based Code Generation for Safe Autonomous Driving Software", "abstract": "Automated Driving System (ADS) is a safety-critical software system\nresponsible for the interpretation of the vehicle's environment and making\ndecisions accordingly. The unbounded complexity of the driving context,\nincluding unforeseeable events, necessitate continuous improvement, often\nachieved through iterative DevOps processes. However, DevOps processes are\nthemselves complex, making these improvements both time- and\nresource-intensive. Automation in code generation for ADS using Large Language\nModels (LLM) is one potential approach to address this challenge. Nevertheless,\nthe development of ADS requires rigorous processes to verify, validate, assess,\nand qualify the code before it can be deployed in the vehicle and used. In this\nstudy, we developed and evaluated a prototype for automatic code generation and\nassessment using a designed pipeline of a LLM-based agent, simulation model,\nand rule-based feedback generator in an industrial setup. The LLM-generated\ncode is evaluated automatically in a simulation model against multiple critical\ntraffic scenarios, and an assessment report is provided as feedback to the LLM\nfor modification or bug fixing. We report about the experimental results of the\nprototype employing Codellama:34b, DeepSeek (r1:32b and Coder:33b),\nCodeGemma:7b, Mistral:7b, and GPT4 for Adaptive Cruise Control (ACC) and\nUnsupervised Collision Avoidance by Evasive Manoeuvre (CAEM). We finally\nassessed the tool with 11 experts at two Original Equipment Manufacturers\n(OEMs) by conducting an interview study.", "published": "2025-04-02 21:35:11", "link": "http://arxiv.org/abs/2504.02141v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID", "abstract": "The exponential growth of online content has posed significant challenges to\nID-based models in industrial recommendation systems, ranging from extremely\nhigh cardinality and dynamically growing ID space, to highly skewed engagement\ndistributions, to prediction instability as a result of natural id life cycles\n(e.g, the birth of new IDs and retirement of old IDs). To address these issues,\nmany systems rely on random hashing to handle the id space and control the\ncorresponding model parameters (i.e embedding table). However, this approach\nintroduces data pollution from multiple ids sharing the same embedding, leading\nto degraded model performance and embedding representation instability.\n  This paper examines these challenges and introduces Semantic ID prefix ngram,\na novel token parameterization technique that significantly improves the\nperformance of the original Semantic ID. Semantic ID prefix ngram creates\nsemantically meaningful collisions by hierarchically clustering items based on\ntheir content embeddings, as opposed to random assignments. Through extensive\nexperimentation, we demonstrate that Semantic ID prefix ngram not only\naddresses embedding instability but also significantly improves tail id\nmodeling, reduces overfitting, and mitigates representation shifts. We further\nhighlight the advantages of Semantic ID prefix ngram in attention-based models\nthat contextualize user histories, showing substantial performance\nimprovements. We also report our experience of integrating Semantic ID into\nMeta production Ads Ranking system, leading to notable performance gains and\nenhanced prediction stability in live deployments.", "published": "2025-04-02 21:28:38", "link": "http://arxiv.org/abs/2504.02137v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "LLMPi: Optimizing LLMs for High-Throughput on Raspberry Pi", "abstract": "Deploying Large Language Models (LLMs) on resource-constrained edge devices\nlike the Raspberry Pi presents challenges in computational efficiency, power\nconsumption, and response latency. This paper explores quantization-based\noptimization techniques to enable high-throughput, energy-efficient execution\nof LLMs on low-power embedded systems. Our approach leverages k-quantization, a\nPost-Training Quantization (PTQ) method designed for different bit-widths,\nenabling efficient 2-bit, 4-bit, 6-bit, and 8-bit weight quantization.\nAdditionally, we employ ternary quantization using Quantization-Aware Training\n(QAT) for BitNet models, allowing for more effective adaptation to lower-bit\nrepresentations while preserving accuracy.\n  Our findings highlight the potential of quantized LLMs for real-time\nconversational AI on edge devices, paving the way for low-power,\nhigh-efficiency AI deployment in mobile and embedded applications. This study\ndemonstrates that aggressive quantization strategies can significantly reduce\nenergy consumption while maintaining inference quality, making LLMs practical\nfor resource-limited environments.", "published": "2025-04-02 20:29:39", "link": "http://arxiv.org/abs/2504.02118v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "On Model Protection in Federated Learning against Eavesdropping Attacks", "abstract": "In this study, we investigate the protection offered by federated learning\nalgorithms against eavesdropping adversaries. In our model, the adversary is\ncapable of intercepting model updates transmitted from clients to the server,\nenabling it to create its own estimate of the model. Unlike previous research,\nwhich predominantly focuses on safeguarding client data, our work shifts\nattention protecting the client model itself. Through a theoretical analysis,\nwe examine how various factors, such as the probability of client selection,\nthe structure of local objective functions, global aggregation at the server,\nand the eavesdropper's capabilities, impact the overall level of protection. We\nfurther validate our findings through numerical experiments, assessing the\nprotection by evaluating the model accuracy achieved by the adversary. Finally,\nwe compare our results with methods based on differential privacy, underscoring\ntheir limitations in this specific context.", "published": "2025-04-02 20:20:13", "link": "http://arxiv.org/abs/2504.02114v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "primary_category": "cs.CR"}
{"title": "ScreenAudit: Detecting Screen Reader Accessibility Errors in Mobile Apps Using Large Language Models", "abstract": "Many mobile apps are inaccessible, thereby excluding people from their\npotential benefits. Existing rule-based accessibility checkers aim to mitigate\nthese failures by identifying errors early during development but are\nconstrained in the types of errors they can detect. We present ScreenAudit, an\nLLM-powered system designed to traverse mobile app screens, extract metadata\nand transcripts, and identify screen reader accessibility errors overlooked by\nexisting checkers. We recruited six accessibility experts including one screen\nreader user to evaluate ScreenAudit's reports across 14 unique app screens. Our\nfindings indicate that ScreenAudit achieves an average coverage of 69.2%,\ncompared to only 31.3% with a widely-used accessibility checker. Expert\nfeedback indicated that ScreenAudit delivered higher-quality feedback and\naddressed more aspects of screen reader accessibility compared to existing\ncheckers, and that ScreenAudit would benefit app developers in real-world\nsettings.", "published": "2025-04-02 20:18:45", "link": "http://arxiv.org/abs/2504.02110v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "FlowDistill: Scalable Traffic Flow Prediction via Distillation from LLMs", "abstract": "Accurate traffic flow prediction is vital for optimizing urban mobility, yet\nit remains difficult in many cities due to complex spatio-temporal dependencies\nand limited high-quality data. While deep graph-based models demonstrate strong\npredictive power, their performance often comes at the cost of high\ncomputational overhead and substantial training data requirements, making them\nimpractical for deployment in resource-constrained or data-scarce environments.\nWe propose the FlowDistill, a lightweight and scalable traffic prediction\nframework based on knowledge distillation from large language models (LLMs). In\nthis teacher-student setup, a fine-tuned LLM guides a compact multi-layer\nperceptron (MLP) student model using a novel combination of the information\nbottleneck principle and teacher-bounded regression loss, ensuring the\ndistilled model retains only essential and transferable knowledge. Spatial and\ntemporal correlations are explicitly encoded to enhance the model's\ngeneralization across diverse urban settings. Despite its simplicity,\nFlowDistill consistently outperforms state-of-the-art models in prediction\naccuracy while requiring significantly less training data, and achieving lower\nmemory usage and inference latency, highlighting its efficiency and suitability\nfor real-world, scalable deployment.", "published": "2025-04-02 19:54:54", "link": "http://arxiv.org/abs/2504.02094v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "An Introductory Survey to Autoencoder-based Deep Clustering -- Sandboxes for Combining Clustering with Deep Learning", "abstract": "Autoencoders offer a general way of learning low-dimensional, non-linear\nrepresentations from data without labels. This is achieved without making any\nparticular assumptions about the data type or other domain knowledge. The\ngenerality and domain agnosticism in combination with their simplicity make\nautoencoders a perfect sandbox for researching and developing novel (deep)\nclustering algorithms. Clustering methods group data based on similarity, a\ntask that benefits from the lower-dimensional representation learned by an\nautoencoder, mitigating the curse of dimensionality. Specifically, the\ncombination of deep learning with clustering, called Deep Clustering, enables\nto learn a representation tailored to specific clustering tasks, leading to\nhigh-quality results. This survey provides an introduction to fundamental\nautoencoder-based deep clustering algorithms that serve as building blocks for\nmany modern approaches.", "published": "2025-04-02 19:46:22", "link": "http://arxiv.org/abs/2504.02087v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses", "abstract": "Large Language Models (LLMs) are increasingly popular, powering a wide range\nof applications. Their widespread use has sparked concerns, especially through\njailbreak attacks that bypass safety measures to produce harmful content.\n  In this paper, we present a comprehensive security analysis of large language\nmodels (LLMs), addressing critical research questions on the evolution and\ndeterminants of model safety.\n  Specifically, we begin by identifying the most effective techniques for\ndetecting jailbreak attacks. Next, we investigate whether newer versions of\nLLMs offer improved security compared to their predecessors. We also assess the\nimpact of model size on overall security and explore the potential benefits of\nintegrating multiple defense strategies to enhance model robustness.\n  Our study evaluates both open-source models (e.g., LLaMA and Mistral) and\nclosed-source systems (e.g., GPT-4) by employing four state-of-the-art attack\ntechniques and assessing the efficacy of three new defensive approaches.", "published": "2025-04-02 19:33:07", "link": "http://arxiv.org/abs/2504.02080v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Trapped by Expectations: Functional Fixedness in LLM-Enabled Chat Search", "abstract": "Functional fixedness, a cognitive bias that restricts users' interactions\nwith a new system or tool to expected or familiar ways, limits the full\npotential of Large Language Model (LLM)-enabled chat search, especially in\ncomplex and exploratory tasks. To investigate its impact, we conducted a\ncrowdsourcing study with 450 participants, each completing one of six\ndecision-making tasks spanning public safety, diet and health management,\nsustainability, and AI ethics. Participants engaged in a multi-prompt\nconversation with ChatGPT to address the task, allowing us to compare pre-chat\nintent-based expectations with observed interactions. We found that: 1) Several\naspects of pre-chat expectations are closely associated with users' prior\nexperiences with ChatGPT, search engines, and virtual assistants; 2) Prior\nsystem experience shapes language use and prompting behavior. Frequent ChatGPT\nusers reduced deictic terms and hedge words and frequently adjusted prompts.\nUsers with rich search experience maintained structured, less-conversational\nqueries with minimal modifications. Users of virtual assistants favored\ndirective, command-like prompts, reinforcing functional fixedness; 3) When the\nsystem failed to meet expectations, participants generated more detailed\nprompts with increased linguistic diversity, reflecting adaptive shifts. These\nfindings suggest that while preconceived expectations constrain early\ninteractions, unmet expectations can motivate behavioral adaptation. With\nappropriate system support, this may promote broader exploration of LLM\ncapabilities. This work also introduces a typology for user intents in chat\nsearch and highlights the importance of mitigating functional fixedness to\nsupport more creative and analytical use of LLMs.", "published": "2025-04-02 19:14:01", "link": "http://arxiv.org/abs/2504.02074v1", "categories": ["cs.HC", "cs.AI", "H.3.3"], "primary_category": "cs.HC"}
{"title": "RoboAct-CLIP: Video-Driven Pre-training of Atomic Action Understanding for Robotics", "abstract": "Visual Language Models (VLMs) have emerged as pivotal tools for robotic\nsystems, enabling cross-task generalization, dynamic environmental interaction,\nand long-horizon planning through multimodal perception and semantic reasoning.\nHowever, existing open-source VLMs predominantly trained for generic\nvision-language alignment tasks fail to model temporally correlated action\nsemantics that are crucial for robotic manipulation effectively. While current\nimage-based fine-tuning methods partially adapt VLMs to robotic applications,\nthey fundamentally disregard temporal evolution patterns in video sequences and\nsuffer from visual feature entanglement between robotic agents, manipulated\nobjects, and environmental contexts, thereby limiting semantic decoupling\ncapability for atomic actions and compromising model generalizability.To\novercome these challenges, this work presents RoboAct-CLIP with dual technical\ncontributions: 1) A dataset reconstruction framework that performs\nsemantic-constrained action unit segmentation and re-annotation on open-source\nrobotic videos, constructing purified training sets containing singular atomic\nactions (e.g., \"grasp\"); 2) A temporal-decoupling fine-tuning strategy based on\nContrastive Language-Image Pretraining (CLIP) architecture, which disentangles\ntemporal action features across video frames from object-centric\ncharacteristics to achieve hierarchical representation learning of robotic\natomic actions.Experimental results in simulated environments demonstrate that\nthe RoboAct-CLIP pretrained model achieves a 12% higher success rate than\nbaseline VLMs, along with superior generalization in multi-object manipulation\ntasks.", "published": "2025-04-02 19:02:08", "link": "http://arxiv.org/abs/2504.02069v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Epistemic Closure and the Irreversibility of Misalignment: Modeling Systemic Barriers to Alignment Innovation", "abstract": "Efforts to ensure the safe development of artificial general intelligence\n(AGI) often rely on consensus-based alignment approaches grounded in axiomatic\nformalism, interpretability, and empirical validation. However, these methods\nmay be structurally unable to recognize or incorporate novel solutions that\nfall outside their accepted epistemic frameworks. This paper introduces a\nfunctional model of epistemic closure, in which cognitive, institutional,\nsocial, and infrastructural filters combine to make many alignment proposals\nillegible to existing evaluation systems. We present a weighted closure model\nsupported by both theoretical and empirical sources, including a meta-analysis\nperformed by an AI system on patterns of rejection and non-engagement with a\nframework for decentralized collective intelligence (DCI). We argue that the\nrecursive failure to assess models like DCI is not just a sociological\noversight but a structural attractor, mirroring the very risks of misalignment\nwe aim to avoid in AGI. Without the adoption of DCI or a similarly recursive\nmodel of epistemic correction, we may be on a predictable path toward\nirreversible misalignment. The development and acceptance of this paper, first\nthrough simulated review and then through formal channels, provide a case study\nsupporting its central claim: that epistemic closure can only be overcome by\nrecursive modeling of the constraints that sustain it.", "published": "2025-04-02 18:35:15", "link": "http://arxiv.org/abs/2504.02058v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Efficient Federated Learning Tiny Language Models for Mobile Network Feature Prediction", "abstract": "In telecommunications, Autonomous Networks (ANs) automatically adjust\nconfigurations based on specific requirements (e.g., bandwidth) and available\nresources. These networks rely on continuous monitoring and intelligent\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\nequipped with NNs - to collaboratively train models while preserving data\nprivacy. However, FL requires frequent transmission of large neural data and\nthus an efficient, standardized compression strategy for reliable\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\nnovel FL framework that integrates tiny language models (TLMs) for various\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\nachieves transparent compression (i.e., negligible performance loss) while\nreducing communication overhead to below 1%, showing the effectiveness of\ncombining NNC with FL in collaboratively learned autonomous mobile networks.", "published": "2025-04-02 17:54:06", "link": "http://arxiv.org/abs/2504.01947v1", "categories": ["cs.LG", "cs.AI", "cs.DC", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning Length?", "abstract": "Large language models (LLMs) often benefit from verbalized reasoning at\ninference time, but it remains unclear which aspects of task difficulty these\nextra reasoning tokens address. To investigate this question, we formalize a\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\nthrough which we can characterize task complexity through measurable properties\nsuch as run length (number of reasoning steps required) and state-space size\n(decision complexity). We first show that across different tasks and models of\ndifferent sizes and training paradigms, there exists an optimal amount of\nreasoning tokens such that the probability of producing a correct solution is\nmaximized. We then investigate which properties of complexity govern this\ncritical length: we find that task instances with longer corresponding\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\nstate-space complexity) does not. We then demonstrate an implication of these\nfindings: being able to predict the optimal number of reasoning tokens for new\nproblems and filtering out non-optimal length answers results in consistent\naccuracy improvements.", "published": "2025-04-02 17:45:58", "link": "http://arxiv.org/abs/2504.01935v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time", "abstract": "Early and accurate assessment of brain microstructure using diffusion\nMagnetic Resonance Imaging (dMRI) is crucial for identifying neurodevelopmental\ndisorders in neonates, but remains challenging due to low signal-to-noise ratio\n(SNR), motion artifacts, and ongoing myelination. In this study, we propose a\nrotationally equivariant Spherical Convolutional Neural Network (sCNN)\nframework tailored for neonatal dMRI. We predict the Fiber Orientation\nDistribution (FOD) from multi-shell dMRI signals acquired with a reduced set of\ngradient directions (30% of the full protocol), enabling faster and more\ncost-effective acquisitions. We train and evaluate the performance of our sCNN\nusing real data from 43 neonatal dMRI datasets provided by the Developing Human\nConnectome Project (dHCP). Our results demonstrate that the sCNN achieves\nsignificantly lower mean squared error (MSE) and higher angular correlation\ncoefficient (ACC) compared to a Multi-Layer Perceptron (MLP) baseline,\nindicating improved accuracy in FOD estimation. Furthermore, tractography\nresults based on the sCNN-predicted FODs show improved anatomical plausibility,\ncoverage, and coherence compared to those from the MLP. These findings\nhighlight that sCNNs, with their inherent rotational equivariance, offer a\npromising approach for accurate and clinically efficient dMRI analysis, paving\nthe way for improved diagnostic capabilities and characterization of early\nbrain development.", "published": "2025-04-02 17:36:51", "link": "http://arxiv.org/abs/2504.01925v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Benchmarking Synthetic Tabular Data: A Multi-Dimensional Evaluation Framework", "abstract": "Evaluating the quality of synthetic data remains a key challenge for ensuring\nprivacy and utility in data-driven research. In this work, we present an\nevaluation framework that quantifies how well synthetic data replicates\noriginal distributional properties while ensuring privacy. The proposed\napproach employs a holdout-based benchmarking strategy that facilitates\nquantitative assessment through low- and high-dimensional distribution\ncomparisons, embedding-based similarity measures, and nearest-neighbor distance\nmetrics. The framework supports various data types and structures, including\nsequential and contextual information, and enables interpretable quality\ndiagnostics through a set of standardized metrics. These contributions aim to\nsupport reproducibility and methodological consistency in benchmarking of\nsynthetic data generation techniques. The code of the framework is available at\nhttps://github.com/mostly-ai/mostlyai-qa.", "published": "2025-04-02 17:10:30", "link": "http://arxiv.org/abs/2504.01908v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs CPU-Based ML Libraries", "abstract": "The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.", "published": "2025-04-02 17:04:53", "link": "http://arxiv.org/abs/2504.01905v2", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "A novel gesture interaction control method for rehabilitation lower extremity exoskeleton", "abstract": "With the rapid development of Rehabilitation Lower Extremity Robotic\nExoskeletons (RLEEX) technology, significant advancements have been made in\nHuman-Robot Interaction (HRI) methods. These include traditional physical HRI\nmethods that are easily recognizable and various bio-electrical signal-based\nHRI methods that can visualize and predict actions. However, most of these HRI\nmethods are contact-based, facing challenges such as operational complexity,\nsensitivity to interference, risks associated with implantable devices, and,\nmost importantly, limitations in comfort. These challenges render the\ninteraction less intuitive and natural, which can negatively impact patient\nmotivation for rehabilitation. To address these issues, this paper proposes a\nnovel non-contact gesture interaction control method for RLEEX, based on RGB\nmonocular camera depth estimation. This method integrates three key steps:\ndetecting keypoints, recognizing gestures, and assessing distance, thereby\napplying gesture information and augmented reality triggering technology to\ncontrol gait movements of RLEEX. Results indicate that this approach provides a\nfeasible solution to the problems of poor comfort, low reliability, and high\nlatency in HRI for RLEEX platforms. Specifically, it achieves a\ngesture-controlled exoskeleton motion accuracy of 94.11\\% and an average system\nresponse time of 0.615 seconds through non-contact HRI. The proposed\nnon-contact HRI method represents a pioneering advancement in control\ninteractions for RLEEX, paving the way for further exploration and development\nin this field.", "published": "2025-04-02 16:46:01", "link": "http://arxiv.org/abs/2504.01888v1", "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Interpreting Emergent Planning in Model-Free Reinforcement Learning", "abstract": "We present the first mechanistic evidence that model-free reinforcement\nlearning agents can learn to plan. This is achieved by applying a methodology\nbased on concept-based interpretability to a model-free agent in Sokoban -- a\ncommonly used benchmark for studying planning. Specifically, we demonstrate\nthat DRC, a generic model-free agent introduced by Guez et al. (2019), uses\nlearned concept representations to internally formulate plans that both predict\nthe long-term effects of actions on the environment and influence action\nselection. Our methodology involves: (1) probing for planning-relevant\nconcepts, (2) investigating plan formation within the agent's representations,\nand (3) verifying that discovered plans (in the agent's representations) have a\ncausal effect on the agent's behavior through interventions. We also show that\nthe emergence of these plans coincides with the emergence of a planning-like\nproperty: the ability to benefit from additional test-time compute. Finally, we\nperform a qualitative analysis of the planning algorithm learned by the agent\nand discover a strong resemblance to parallelized bidirectional search. Our\nfindings advance understanding of the internal mechanisms underlying planning\nbehavior in agents, which is important given the recent trend of emergent\nplanning and reasoning capabilities in LLMs through RL", "published": "2025-04-02 16:24:23", "link": "http://arxiv.org/abs/2504.01871v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "From Code Generation to Software Testing: AI Copilot with Context-Based RAG", "abstract": "The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.", "published": "2025-04-02 16:20:05", "link": "http://arxiv.org/abs/2504.01866v2", "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions", "abstract": "Diffusion probabilistic models (DPMs), while effective in generating\nhigh-quality samples, often suffer from high computational costs due to their\niterative sampling process. To address this, we propose an enhanced ODE-based\nsampling method for DPMs inspired by Richardson extrapolation, which reduces\nnumerical error and improves convergence rates. Our method, RX-DPM, leverages\nmultiple ODE solutions at intermediate time steps to extrapolate the denoised\nprediction in DPMs. This significantly enhances the accuracy of estimations for\nthe final sample while maintaining the number of function evaluations (NFEs).\nUnlike standard Richardson extrapolation, which assumes uniform discretization\nof the time grid, we develop a more general formulation tailored to arbitrary\ntime step scheduling, guided by local truncation error derived from a baseline\nsampling method. The simplicity of our approach facilitates accurate estimation\nof numerical solutions without significant computational overhead, and allows\nfor seamless and convenient integration into various DPMs and solvers.\nAdditionally, RX-DPM provides explicit error estimates, effectively\ndemonstrating the faster convergence as the leading error term's order\nincreases. Through a series of experiments, we show that the proposed method\nimproves the quality of generated samples without requiring additional sampling\niterations.", "published": "2025-04-02 16:06:23", "link": "http://arxiv.org/abs/2504.01855v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Code Red! On the Harmfulness of Applying Off-the-shelf Large Language Models to Programming Tasks", "abstract": "Nowadays, developers increasingly rely on solutions powered by Large Language\nModels (LLM) to assist them with their coding tasks. This makes it crucial to\nalign these tools with human values to prevent malicious misuse. In this paper,\nwe propose a comprehensive framework for assessing the potential harmfulness of\nLLMs within the software engineering domain. We begin by developing a taxonomy\nof potentially harmful software engineering scenarios and subsequently, create\na dataset of prompts based on this taxonomy. To systematically assess the\nresponses, we design and validate an automatic evaluator that classifies the\noutputs of a variety of LLMs both open-source and closed-source models, as well\nas general-purpose and code-specific LLMs. Furthermore, we investigate the\nimpact of models size, architecture family, and alignment strategies on their\ntendency to generate harmful content. The results show significant disparities\nin the alignment of various LLMs for harmlessness. We find that some models and\nmodel families, such as Openhermes, are more harmful than others and that\ncode-specific models do not perform better than their general-purpose\ncounterparts. Notably, some fine-tuned models perform significantly worse than\ntheir base-models due to their design choices. On the other side, we find that\nlarger models tend to be more helpful and are less likely to respond with\nharmful information. These results highlight the importance of targeted\nalignment strategies tailored to the unique challenges of software engineering\ntasks and provide a foundation for future work in this critical area.", "published": "2025-04-02 16:00:14", "link": "http://arxiv.org/abs/2504.01850v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "An Approach to Technical AGI Safety and Security", "abstract": "Artificial General Intelligence (AGI) promises transformative benefits but\nalso presents significant risks. We develop an approach to address the risk of\nharms consequential enough to significantly harm humanity. We identify four\nareas of risk: misuse, misalignment, mistakes, and structural risks. Of these,\nwe focus on technical approaches to misuse and misalignment. For misuse, our\nstrategy aims to prevent threat actors from accessing dangerous capabilities,\nby proactively identifying dangerous capabilities, and implementing robust\nsecurity, access restrictions, monitoring, and model safety mitigations. To\naddress misalignment, we outline two lines of defense. First, model-level\nmitigations such as amplified oversight and robust training can help to build\nan aligned model. Second, system-level security measures such as monitoring and\naccess control can mitigate harm even if the model is misaligned. Techniques\nfrom interpretability, uncertainty estimation, and safer design patterns can\nenhance the effectiveness of these mitigations. Finally, we briefly outline how\nthese ingredients could be combined to produce safety cases for AGI systems.", "published": "2025-04-02 15:59:31", "link": "http://arxiv.org/abs/2504.01849v1", "categories": ["cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Antithetic Sampling for Top-k Shapley Identification", "abstract": "Additive feature explanations rely primarily on game-theoretic notions such\nas the Shapley value by viewing features as cooperating players. The Shapley\nvalue's popularity in and outside of explainable AI stems from its axiomatic\nuniqueness. However, its computational complexity severely limits\npracticability. Most works investigate the uniform approximation of all\nfeatures' Shapley values, needlessly consuming samples for insignificant\nfeatures. In contrast, identifying the $k$ most important features can already\nbe sufficiently insightful and yields the potential to leverage algorithmic\nopportunities connected to the field of multi-armed bandits. We propose\nComparable Marginal Contributions Sampling (CMCS), a method for the top-$k$\nidentification problem utilizing a new sampling scheme taking advantage of\ncorrelated observations. We conduct experiments to showcase the efficacy of our\nmethod in compared to competitive baselines. Our empirical findings reveal that\nestimation quality for the approximate-all problem does not necessarily\ntransfer to top-$k$ identification and vice versa.", "published": "2025-04-02 15:38:32", "link": "http://arxiv.org/abs/2504.02019v1", "categories": ["cs.LG", "cs.AI", "cs.GT"], "primary_category": "cs.LG"}
{"title": "Implicit Bias Injection Attacks against Text-to-Image Diffusion Models", "abstract": "The proliferation of text-to-image diffusion models (T2I DMs) has led to an\nincreased presence of AI-generated images in daily life. However, biased T2I\nmodels can generate content with specific tendencies, potentially influencing\npeople's perceptions. Intentional exploitation of these biases risks conveying\nmisleading information to the public. Current research on bias primarily\naddresses explicit biases with recognizable visual patterns, such as skin color\nand gender. This paper introduces a novel form of implicit bias that lacks\nexplicit visual features but can manifest in diverse ways across various\nsemantic contexts. This subtle and versatile nature makes this bias challenging\nto detect, easy to propagate, and adaptable to a wide range of scenarios. We\nfurther propose an implicit bias injection attack framework (IBI-Attacks)\nagainst T2I diffusion models by precomputing a general bias direction in the\nprompt embedding space and adaptively adjusting it based on different inputs.\nOur attack module can be seamlessly integrated into pre-trained diffusion\nmodels in a plug-and-play manner without direct manipulation of user input or\nmodel retraining. Extensive experiments validate the effectiveness of our\nscheme in introducing bias through subtle and diverse modifications while\npreserving the original semantics. The strong concealment and transferability\nof our attack across various scenarios further underscore the significance of\nour approach. Code is available at https://github.com/Hannah1102/IBI-attacks.", "published": "2025-04-02 15:24:12", "link": "http://arxiv.org/abs/2504.01819v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Novel Approach To Implementing Knowledge Distillation In Tsetlin Machines", "abstract": "The Tsetlin Machine (TM) is a propositional logic based model that uses\nconjunctive clauses to learn patterns from data. As with typical neural\nnetworks, the performance of a Tsetlin Machine is largely dependent on its\nparameter count, with a larger number of parameters producing higher accuracy\nbut slower execution. Knowledge distillation in neural networks transfers\ninformation from an already-trained teacher model to a smaller student model to\nincrease accuracy in the student without increasing execution time. We propose\na novel approach to implementing knowledge distillation in Tsetlin Machines by\nutilizing the probability distributions of each output sample in the teacher to\nprovide additional context to the student. Additionally, we propose a novel\nclause-transfer algorithm that weighs the importance of each clause in the\nteacher and initializes the student with only the most essential data. We find\nthat our algorithm can significantly improve performance in the student model\nwithout negatively impacting latency in the tested domains of image recognition\nand text classification.", "published": "2025-04-02 15:06:27", "link": "http://arxiv.org/abs/2504.01798v1", "categories": ["cs.AI", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Rethinking industrial artificial intelligence: a unified foundation framework", "abstract": "Recent advancement in industrial artificial intelligence (AI) is reshaping\nthe industry, driving smarter manufacturing, predictive maintenance, and\nintelligent decision-making. However, existing approaches often focus primarily\non algorithms and models, overlooking the importance of systematically\nintegrating domain knowledge, data, and models to ensure more comprehensive and\neffective AI solutions. Therefore, the effective development and deployment of\nIndustrial AI solutions require a more comprehensive and systematic approach.\nTo address this gap, this paper summarizes previous research and rethinks the\nrole of industrial AI and presents a unified industrial AI foundation framework\ncomprising three core modules: knowledge module, data module, and model module.\nThese modules help to extend and enhance the industrial AI methodology\nplatform, supporting various industrial applications. In addition, a case study\non rotating machinery diagnosis demonstrates the framework's effectiveness, and\nseveral future directions are highlighted for the development of the industrial\nAI foundation framework.", "published": "2025-04-02 15:05:32", "link": "http://arxiv.org/abs/2504.01797v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CLaP -- State Detection from Time Series", "abstract": "The ever-growing amount of sensor data from machines, smart devices, and the\nenvironment leads to an abundance of high-resolution, unannotated time series\n(TS). These recordings encode the recognizable properties of latent states and\ntransitions from physical phenomena that can be modelled as abstract processes.\nThe unsupervised localization and identification of these states and their\ntransitions is the task of time series state detection (TSSD). We introduce\nCLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the\npredictive power of time series classification for TSSD in an unsupervised\nsetting by applying novel self-supervision techniques to detect whether data\nsegments emerge from the same state or not. To this end, CLaP cross-validates a\nclassifier with segment-labelled subsequences to quantify confusion between\nsegments. It merges labels from segments with high confusion, representing the\nsame latent state, if this leads to an increase in overall classification\nquality. We conducted an experimental evaluation using 391 TS from four\nbenchmarks and found CLaP to be significantly more precise in detecting states\nthan five state-of-the-art competitors. It achieves the best accuracy-runtime\ntradeoff and is scalable to large TS. We provide a Python implementation of\nCLaP, which can be deployed in TS analysis workflows.", "published": "2025-04-02 14:46:42", "link": "http://arxiv.org/abs/2504.01783v1", "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "cs.LG"}
{"title": "Embedding Method for Knowledge Graph with Densely Defined Ontology", "abstract": "Knowledge graph embedding (KGE) is a technique that enhances knowledge graphs\nby addressing incompleteness and improving knowledge retrieval. A limitation of\nthe existing KGE models is their underutilization of ontologies, specifically\nthe relationships between properties. This study proposes a KGE model, TransU,\ndesigned for knowledge graphs with well-defined ontologies that incorporate\nrelationships between properties. The model treats properties as a subset of\nentities, enabling a unified representation. We present experimental results\nusing a standard dataset and a practical dataset.", "published": "2025-04-02 14:43:47", "link": "http://arxiv.org/abs/2504.02889v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "Enhancing Interpretability in Generative AI Through Search-Based Data Influence Analysis", "abstract": "Generative AI models offer powerful capabilities but often lack transparency,\nmaking it difficult to interpret their output. This is critical in cases\ninvolving artistic or copyrighted content. This work introduces a\nsearch-inspired approach to improve the interpretability of these models by\nanalysing the influence of training data on their outputs. Our method provides\nobservational interpretability by focusing on a model's output rather than on\nits internal state. We consider both raw data and latent-space embeddings when\nsearching for the influence of data items in generated content. We evaluate our\nmethod by retraining models locally and by demonstrating the method's ability\nto uncover influential subsets in the training data. This work lays the\ngroundwork for future extensions, including user-based evaluations with domain\nexperts, which is expected to improve observational interpretability further.", "published": "2025-04-02 14:29:37", "link": "http://arxiv.org/abs/2504.01771v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Leveraging Embedding Techniques in Multimodal Machine Learning for Mental Illness Assessment", "abstract": "The increasing global prevalence of mental disorders, such as depression and\nPTSD, requires objective and scalable diagnostic tools. Traditional clinical\nassessments often face limitations in accessibility, objectivity, and\nconsistency. This paper investigates the potential of multimodal machine\nlearning to address these challenges, leveraging the complementary information\navailable in text, audio, and video data. Our approach involves a comprehensive\nanalysis of various data preprocessing techniques, including novel chunking and\nutterance-based formatting strategies. We systematically evaluate a range of\nstate-of-the-art embedding models for each modality and employ Convolutional\nNeural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature\nextraction. We explore data-level, feature-level, and decision-level fusion\ntechniques, including a novel integration of Large Language Model (LLM)\npredictions. We also investigate the impact of replacing Multilayer Perceptron\nclassifiers with Support Vector Machines. We extend our analysis to severity\nprediction using PHQ-8 and PCL-C scores and multi-class classification\n(considering co-occurring conditions). Our results demonstrate that\nutterance-based chunking significantly improves performance, particularly for\ntext and audio modalities. Decision-level fusion, incorporating LLM\npredictions, achieves the highest accuracy, with a balanced accuracy of 94.8%\nfor depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM\narchitectures with utterance-level chunking, coupled with the integration of\nexternal LLM, provides a powerful and nuanced approach to the detection and\nassessment of mental health conditions. Our findings highlight the potential of\nMMML for developing more accurate, accessible, and personalized mental\nhealthcare tools.", "published": "2025-04-02 14:19:06", "link": "http://arxiv.org/abs/2504.01767v1", "categories": ["eess.AS", "cs.AI", "cs.CV"], "primary_category": "eess.AS"}
{"title": "Dual-stream Transformer-GCN Model with Contextualized Representations Learning for Monocular 3D Human Pose Estimation", "abstract": "This paper introduces a novel approach to monocular 3D human pose estimation\nusing contextualized representation learning with the Transformer-GCN\ndual-stream model. Monocular 3D human pose estimation is challenged by depth\nambiguity, limited 3D-labeled training data, imbalanced modeling, and\nrestricted model generalization. To address these limitations, our work\nintroduces a groundbreaking motion pre-training method based on contextualized\nrepresentation learning. Specifically, our method involves masking 2D pose\nfeatures and utilizing a Transformer-GCN dual-stream model to learn\nhigh-dimensional representations through a self-distillation setup. By focusing\non contextualized representation learning and spatial-temporal modeling, our\napproach enhances the model's ability to understand spatial-temporal\nrelationships between postures, resulting in superior generalization.\nFurthermore, leveraging the Transformer-GCN dual-stream model, our approach\neffectively balances global and local interactions in video pose estimation.\nThe model adaptively integrates information from both the Transformer and GCN\nstreams, where the GCN stream effectively learns local relationships between\nadjacent key points and frames, while the Transformer stream captures\ncomprehensive global spatial and temporal features. Our model achieves\nstate-of-the-art performance on two benchmark datasets, with an MPJPE of 38.0mm\nand P-MPJPE of 31.9mm on Human3.6M, and an MPJPE of 15.9mm on MPI-INF-3DHP.\nFurthermore, visual experiments on public datasets and in-the-wild videos\ndemonstrate the robustness and generalization capabilities of our approach.", "published": "2025-04-02 14:17:57", "link": "http://arxiv.org/abs/2504.01764v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization", "abstract": "Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently\nwitnessed remarkable advancements and are increasingly being deployed in\nreal-world applications. However, inheriting the sensitivity of visual neural\nnetworks, LVLMs remain vulnerable to adversarial attacks, which can result in\nerroneous or malicious outputs. While existing efforts utilize adversarial\nfine-tuning to enhance robustness, they often suffer from performance\ndegradation on clean inputs. In this paper, we proposes AdPO, a novel\nadversarial defense strategy for LVLMs based on preference optimization. For\nthe first time, we reframe adversarial training as a preference optimization\nproblem, aiming to enhance the model's preference for generating normal outputs\non clean inputs while rejecting the potential misleading outputs for\nadversarial examples. Notably, AdPO achieves this by solely modifying the image\nencoder, e.g., CLIP ViT, resulting in superior clean and adversarial\nperformance in a variety of downsream tasks. Considering that training involves\nlarge language models (LLMs), the computational cost increases significantly.\nWe validate that training on smaller LVLMs and subsequently transferring to\nlarger models can achieve competitive performance while maintaining efficiency\ncomparable to baseline methods. Our comprehensive experiments confirm the\neffectiveness of the proposed AdPO, which provides a novel perspective for\nfuture adversarial defense research.", "published": "2025-04-02 13:43:21", "link": "http://arxiv.org/abs/2504.01735v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Epistemic Skills: Reasoning about Knowledge and Oblivion", "abstract": "This paper presents a class of epistemic logics that captures the dynamics of\nacquiring knowledge and descending into oblivion, while incorporating concepts\nof group knowledge. The approach is grounded in a system of weighted models,\nintroducing an ``epistemic skills'' metric to represent the epistemic\ncapacities tied to knowledge updates. Within this framework, knowledge\nacquisition is modeled as a process of upskilling, whereas oblivion is\nrepresented as a consequence of downskilling. The framework further enables\nexploration of ``knowability'' and ``forgettability,'' defined as the potential\nto gain knowledge through upskilling and to lapse into oblivion through\ndownskilling, respectively. Additionally, it supports a detailed analysis of\nthe distinctions between epistemic de re and de dicto expressions. The\ncomputational complexity of the model checking and satisfiability problems is\nexamined, offering insights into their theoretical foundations and practical\nimplications.", "published": "2025-04-02 13:41:42", "link": "http://arxiv.org/abs/2504.01733v1", "categories": ["cs.AI", "cs.CC", "cs.LO"], "primary_category": "cs.AI"}
{"title": "DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance", "abstract": "While recent image-based human animation methods achieve realistic body and\nfacial motion synthesis, critical gaps remain in fine-grained holistic\ncontrollability, multi-scale adaptability, and long-term temporal coherence,\nwhich leads to their lower expressiveness and robustness. We propose a\ndiffusion transformer (DiT) based framework, DreamActor-M1, with hybrid\nguidance to overcome these limitations. For motion guidance, our hybrid control\nsignals that integrate implicit facial representations, 3D head spheres, and 3D\nbody skeletons achieve robust control of facial expressions and body movements,\nwhile producing expressive and identity-preserving animations. For scale\nadaptation, to handle various body poses and image scales ranging from\nportraits to full-body views, we employ a progressive training strategy using\ndata with varying resolutions and scales. For appearance guidance, we integrate\nmotion patterns from sequential frames with complementary visual references,\nensuring long-term temporal coherence for unseen regions during complex\nmovements. Experiments demonstrate that our method outperforms the\nstate-of-the-art works, delivering expressive results for portraits,\nupper-body, and full-body generation with robust long-term consistency. Project\nPage: https://grisoon.github.io/DreamActor-M1/.", "published": "2025-04-02 13:30:32", "link": "http://arxiv.org/abs/2504.01724v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective Pruning", "abstract": "The Internet of Drones (IoD), where drones collaborate in data collection and\nanalysis, has become essential for applications such as surveillance and\nenvironmental monitoring. Federated learning (FL) enables drones to train\nmachine learning models in a decentralized manner while preserving data\nprivacy. However, FL in IoD networks is susceptible to attacks like data\npoisoning and model inversion. Federated unlearning (FU) mitigates these risks\nby eliminating adversarial data contributions, preventing their influence on\nthe model. This paper proposes sky of unlearning (SoUL), a federated unlearning\nframework that efficiently removes the influence of unlearned data while\nmaintaining model performance. A selective pruning algorithm is designed to\nidentify and remove neurons influential in unlearning but minimally impact the\noverall performance of the model. Simulations demonstrate that SoUL outperforms\nexisting unlearning methods, achieves accuracy comparable to full retraining,\nand reduces computation and communication overhead, making it a scalable and\nefficient solution for resource-constrained IoD networks.", "published": "2025-04-02 13:07:30", "link": "http://arxiv.org/abs/2504.01705v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Reasoning LLMs for User-Aware Multimodal Conversational Agents", "abstract": "Personalization in social robotics is critical for fostering effective\nhuman-robot interactions, yet systems often face the cold start problem, where\ninitial user preferences or characteristics are unavailable. This paper\nproposes a novel framework called USER-LLM R1 for a user-aware conversational\nagent that addresses this challenge through dynamic user profiling and model\ninitiation. Our approach integrates chain-of-thought (CoT) reasoning models to\niteratively infer user preferences and vision-language models (VLMs) to\ninitialize user profiles from multimodal inputs, enabling personalized\ninteractions from the first encounter. Leveraging a Retrieval-Augmented\nGeneration (RAG) architecture, the system dynamically refines user\nrepresentations within an inherent CoT process, ensuring contextually relevant\nand adaptive responses. Evaluations on the ElderlyTech-VQA Bench demonstrate\nsignificant improvements in ROUGE-1 (+23.2%), ROUGE-2 (+0.6%), and ROUGE-L\n(+8%) F1 scores over state-of-the-art baselines, with ablation studies\nunderscoring the impact of reasoning model size on performance. Human\nevaluations further validate the framework's efficacy, particularly for elderly\nusers, where tailored responses enhance engagement and trust. Ethical\nconsiderations, including privacy preservation and bias mitigation, are\nrigorously discussed and addressed to ensure responsible deployment.", "published": "2025-04-02 13:00:17", "link": "http://arxiv.org/abs/2504.01700v1", "categories": ["cs.HC", "cs.AI", "cs.RO"], "primary_category": "cs.HC"}
{"title": "Segmentation variability and radiomics stability for predicting Triple-Negative Breast Cancer subtype using Magnetic Resonance Imaging", "abstract": "Most papers caution against using predictive models for disease\nstratification based on unselected radiomic features, as these features are\naffected by contouring variability. Instead, they advocate for the use of the\nIntraclass Correlation Coefficient (ICC) as a measure of stability for feature\nselection. However, the direct effect of segmentation variability on the\npredictive models is rarely studied. This study investigates the impact of\nsegmentation variability on feature stability and predictive performance in\nradiomics-based prediction of Triple-Negative Breast Cancer (TNBC) subtype\nusing Magnetic Resonance Imaging. A total of 244 images from the Duke dataset\nwere used, with segmentation variability introduced through modifications of\nmanual segmentations. For each mask, explainable radiomic features were\nselected using the Shapley Additive exPlanations method and used to train\nlogistic regression models. Feature stability across segmentations was assessed\nvia ICC, Pearson's correlation, and reliability scores quantifying the\nrelationship between feature stability and segmentation variability. Results\nindicate that segmentation accuracy does not significantly impact predictive\nperformance. While incorporating peritumoral information may reduce feature\nreproducibility, it does not diminish feature predictive capability. Moreover,\nfeature selection in predictive models is not inherently tied to feature\nstability with respect to segmentation, suggesting that an overreliance on ICC\nor reliability scores for feature selection might exclude valuable predictive\nfeatures.", "published": "2025-04-02 12:48:01", "link": "http://arxiv.org/abs/2504.01692v1", "categories": ["stat.AP", "cs.AI", "62P10 (Primary), 68T09 (Secondary)"], "primary_category": "stat.AP"}
{"title": "Token Pruning in Audio Transformers: Optimizing Performance and Decoding Patch Importance", "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance across\nvarious computer vision tasks, but their high computational cost remains a\nchallenge. Token pruning has been proposed to reduce this cost by selectively\nremoving less important tokens. While effective in vision tasks by discarding\nnon-object regions, applying this technique to audio tasks presents unique\nchallenges, as distinguishing relevant from irrelevant regions in\ntime-frequency representations is less straightforward. In this study, for the\nfirst time, we applied token pruning to ViT-based audio classification models\nusing Mel-spectrograms and analyzed the trade-offs between model performance\nand computational cost: TopK token pruning can reduce MAC operations of\nAudioMAE and AST by 30-40%, with less than a 1% drop in classification\naccuracy. Our analysis reveals that while high-intensity tokens contribute\nsignificantly to model accuracy, low-intensity tokens remain important. In\nparticular, they play a more critical role in general audio classification\ntasks than in speech-specific tasks.", "published": "2025-04-02 12:44:38", "link": "http://arxiv.org/abs/2504.01690v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "K-P Quantum Neural Networks", "abstract": "We present an extension of K-P time-optimal quantum control solutions using\nglobal Cartan $KAK$ decompositions for geodesic-based solutions. Extending\nrecent time-optimal \\emph{constant-$\\theta$} control results, we integrate\nCartan methods into equivariant quantum neural network (EQNN) for quantum\ncontrol tasks. We show that a finite-depth limited EQNN ansatz equipped with\nCartan layers can replicate the constant-$\\theta$ sub-Riemannian geodesics for\nK-P problems. We demonstrate how for certain classes of control problem on\nRiemannian symmetric spaces, gradient-based training using an appropriate cost\nfunction converges to certain global time-optimal solutions when satisfying\nsimple regularity conditions. This generalises prior geometric control theory\nmethods and clarifies how optimal geodesic estimation can be performed in\nquantum machine learning contexts.", "published": "2025-04-02 12:22:18", "link": "http://arxiv.org/abs/2504.01673v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Anomaly Detection for Hybrid Butterfly Subspecies via Probability Filtering", "abstract": "Detecting butterfly hybrids requires knowledge of the parent subspecies, and\nthe process can be tedious when encountering a new subspecies. This study\nfocuses on a specific scenario where a model trained to recognize hybrid\nspecies A can generalize to species B when B biologically mimics A. Since\nspecies A and B share similar patterns, we leverage BioCLIP as our feature\nextractor to capture features based on their taxonomy. Consequently, the\nalgorithm designed for species A can be transferred to B, as their hybrid and\nnon-hybrid patterns exhibit similar relationships. To determine whether a\nbutterfly is a hybrid, we adopt proposed probability filtering and color\njittering to augment and simulate the mimicry. With these approaches, we\nachieve second place in the official development phase. Our code is publicly\navailable at https://github.com/Justin900429/NSF-HDR-Challenge.", "published": "2025-04-02 12:18:44", "link": "http://arxiv.org/abs/2504.01671v1", "categories": ["cs.CE", "cs.AI"], "primary_category": "cs.CE"}
{"title": "Market-Oriented Flow Allocation for Thermal Solar Plants: An Auction-Based Methodology with Artificial Intelligence", "abstract": "This paper presents a novel method to optimize thermal balance in parabolic\ntrough collector (PTC) plants. It uses a market-based system to distribute flow\namong loops combined with an artificial neural network (ANN) to reduce\ncomputation and data requirements. This auction-based approach balances loop\ntemperatures, accommodating varying thermal losses and collector efficiencies.\nValidation across different thermal losses, optical efficiencies, and\nirradiance conditions-sunny, partially cloudy, and cloudy-show improved thermal\npower output and intercept factors compared to a no-allocation system. It\ndemonstrates scalability and practicality for large solar thermal plants,\nenhancing overall performance. The method was first validated through\nsimulations on a realistic solar plant model, then adapted and successfully\ntested in a 50 MW solar trough plant, demonstrating its advantages.\nFurthermore, the algorithms have been implemented, commissioned, and are\ncurrently operating in 13 commercial solar trough plants.", "published": "2025-04-02 12:01:41", "link": "http://arxiv.org/abs/2504.01652v1", "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Efficient Calibration for RRAM-based In-Memory Computing using DoRA", "abstract": "Resistive In-Memory Computing (RIMC) offers ultra-efficient computation for\nedge AI but faces accuracy degradation due to RRAM conductance drift over time.\nTraditional retraining methods are limited by RRAM's high energy consumption,\nwrite latency, and endurance constraints. We propose a DoRA-based calibration\nframework that restores accuracy by compensating influential weights with\nminimal calibration parameters stored in SRAM, leaving RRAM weights untouched.\nThis eliminates in-field RRAM writes, ensuring energy-efficient, fast, and\nreliable calibration. Experiments on RIMC-based ResNet50 (ImageNet-1K)\ndemonstrate 69.53% accuracy restoration using just 10 calibration samples while\nupdating only 2.34% of parameters.", "published": "2025-04-02 11:58:08", "link": "http://arxiv.org/abs/2504.03763v1", "categories": ["cs.AR", "cs.AI", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Proposition of Affordance-Driven Environment Recognition Framework Using Symbol Networks in Large Language Models", "abstract": "In the quest to enable robots to coexist with humans, understanding dynamic\nsituations and selecting appropriate actions based on common sense and\naffordances are essential. Conventional AI systems face challenges in applying\naffordance, as it represents implicit knowledge derived from common sense.\nHowever, large language models (LLMs) offer new opportunities due to their\nability to process extensive human knowledge. This study proposes a method for\nautomatic affordance acquisition by leveraging LLM outputs. The process\ninvolves generating text using LLMs, reconstructing the output into a symbol\nnetwork using morphological and dependency analysis, and calculating\naffordances based on network distances. Experiments using ``apple'' as an\nexample demonstrated the method's ability to extract context-dependent\naffordances with high explainability. The results suggest that the proposed\nsymbol network, reconstructed from LLM outputs, enables robots to interpret\naffordances effectively, bridging the gap between symbolized data and\nhuman-like situational understanding.", "published": "2025-04-02 11:48:44", "link": "http://arxiv.org/abs/2504.01644v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment", "abstract": "The method for image-to-point cloud registration typically determines the\nrigid transformation using a coarse-to-fine pipeline. However, directly and\nuniformly matching image patches with point cloud patches may lead to focusing\non incorrect noise patches during matching while ignoring key ones. Moreover,\ndue to the significant differences between image and point cloud modalities, it\nmay be challenging to bridge the domain gap without specific improvements in\ndesign. To address the above issues, we innovatively propose the\nUncertainty-aware Hierarchical Matching Module (UHMM) and the Adversarial Modal\nAlignment Module (AMAM). Within the UHMM, we model the uncertainty of critical\ninformation in image patches and facilitate multi-level fusion interactions\nbetween image and point cloud features. In the AMAM, we design an adversarial\napproach to reduce the domain gap between image and point cloud. Extensive\nexperiments and ablation studies on RGB-D Scene V2 and 7-Scenes benchmarks\ndemonstrate the superiority of our method, making it a state-of-the-art\napproach for image-to-point cloud registration tasks.", "published": "2025-04-02 11:43:55", "link": "http://arxiv.org/abs/2504.01641v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach", "abstract": "Planning methods with high adaptability to dynamic environments are crucial\nfor the development of autonomous and versatile robots. We propose a method for\nleveraging a large language model (GPT-4o) to automatically generate networks\ncapable of adapting to dynamic environments. The proposed method collects\nenvironmental \"status,\" representing conditions and goals, and uses them to\ngenerate agents. These agents are interconnected on the basis of specific\nconditions, resulting in networks that combine flexibility and generality. We\nconducted evaluation experiments to compare the networks automatically\ngenerated with the proposed method with manually constructed ones, confirming\nthe comprehensiveness of the proposed method's networks and their higher\ngenerality. This research marks a significant advancement toward the\ndevelopment of versatile planning methods applicable to robotics, autonomous\nvehicles, smart systems, and other complex environments.", "published": "2025-04-02 11:42:49", "link": "http://arxiv.org/abs/2504.01637v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions", "abstract": "The robustness of DNNs is a crucial factor in safety-critical applications,\nparticularly in complex and dynamic environments where localized corruptions\ncan arise. While previous studies have evaluated the robustness of semantic\nsegmentation (SS) models under whole-image natural or adversarial corruptions,\na comprehensive investigation into the spatial robustness of dense vision\nmodels under localized corruptions remained underexplored. This paper fills\nthis gap by introducing specialized metrics for benchmarking the spatial\nrobustness of segmentation models, alongside with an evaluation framework to\nassess the impact of localized corruptions. Furthermore, we uncover the\ninherent complexity of characterizing worst-case robustness using a single\nlocalized adversarial perturbation. To address this, we propose region-aware\nmulti-attack adversarial analysis, a method that enables a deeper understanding\nof model robustness against adversarial perturbations applied to specific\nregions. The proposed metrics and analysis were evaluated on 15 segmentation\nmodels in driving scenarios, uncovering key insights into the effects of\nlocalized corruption in both natural and adversarial forms. The results reveal\nthat models respond to these two types of threats differently; for instance,\ntransformer-based segmentation models demonstrate notable robustness to\nlocalized natural corruptions but are highly vulnerable to adversarial ones and\nvice-versa for CNN-based models. Consequently, we also address the challenge of\nbalancing robustness to both natural and adversarial localized corruptions by\nmeans of ensemble models, thereby achieving a broader threat coverage and\nimproved reliability for dense vision tasks.", "published": "2025-04-02 11:37:39", "link": "http://arxiv.org/abs/2504.01632v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models", "abstract": "Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.", "published": "2025-04-02 10:47:07", "link": "http://arxiv.org/abs/2504.01589v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Building Knowledge from Interactions: An LLM-Based Architecture for Adaptive Tutoring and Social Reasoning", "abstract": "Integrating robotics into everyday scenarios like tutoring or physical\ntraining requires robots capable of adaptive, socially engaging, and\ngoal-oriented interactions. While Large Language Models show promise in\nhuman-like communication, their standalone use is hindered by memory\nconstraints and contextual incoherence. This work presents a multimodal,\ncognitively inspired framework that enhances LLM-based autonomous\ndecision-making in social and task-oriented Human-Robot Interaction.\nSpecifically, we develop an LLM-based agent for a robot trainer, balancing\nsocial conversation with task guidance and goal-driven motivation. To further\nenhance autonomy and personalization, we introduce a memory system for\nselecting, storing and retrieving experiences, facilitating generalized\nreasoning based on knowledge built across different interactions. A preliminary\nHRI user study and offline experiments with a synthetic dataset validate our\napproach, demonstrating the system's ability to manage complex interactions,\nautonomously drive training tasks, and build and retrieve contextual memories,\nadvancing socially intelligent robotics.", "published": "2025-04-02 10:45:41", "link": "http://arxiv.org/abs/2504.01588v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Pro-DG: Procedural Diffusion Guidance for Architectural Facade Generation", "abstract": "We present Pro-DG, a framework for procedurally controllable photo-realistic\nfacade generation that combines a procedural shape grammar with diffusion-based\nimage synthesis. Starting from a single input image, we reconstruct its facade\nlayout using grammar rules, then edit that structure through user-defined\ntransformations. As facades are inherently multi-hierarchical structures, we\nintroduce hierarchical matching procedure that aligns facade structures at\ndifferent levels which is used to introduce control maps to guide a generative\ndiffusion pipeline. This approach retains local appearance fidelity while\naccommodating large-scale edits such as floor duplication or window\nrearrangement. We provide a thorough evaluation, comparing Pro-DG against\ninpainting-based baselines and synthetic ground truths. Our user study and\nquantitative measurements indicate improved preservation of architectural\nidentity and higher edit accuracy. Our novel method is the first to integrate\nneuro-symbolically derived shape-grammars for modeling with modern generative\nmodel and highlights the broader potential of such approaches for precise and\ncontrollable image manipulation.", "published": "2025-04-02 10:16:19", "link": "http://arxiv.org/abs/2504.01571v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "I.3.7; I.4.9; I.2.10"], "primary_category": "cs.GR"}
{"title": "Optimizing Package Delivery with Quantum Annealers: Addressing Time-Windows and Simultaneous Pickup and Delivery", "abstract": "Recent research at the intersection of quantum computing and routing problems\nhas been highly prolific. Much of this work focuses on classical problems such\nas the Traveling Salesman Problem and the Vehicle Routing Problem. The\npractical applicability of these problems depends on the specific objectives\nand constraints considered. However, it is undeniable that translating complex\nreal-world requirements into these classical formulations often proves\nchallenging. In this paper, we resort to our previously published\nquantum-classical technique for addressing real-world-oriented routing\nproblems, known as Quantum for Real Package Delivery (Q4RPD), and elaborate on\nsolving additional realistic problem instances. Accordingly, this paper\nemphasizes the following characteristics: i) simultaneous pickup and\ndeliveries, ii) time-windows, and iii) mobility restrictions by vehicle type.\nTo illustrate the application of Q4RPD, we have conducted an experimentation\ncomprising seven instances, serving as a demonstration of the newly developed\nfeatures.", "published": "2025-04-02 10:01:34", "link": "http://arxiv.org/abs/2504.01560v1", "categories": ["cs.ET", "cs.AI"], "primary_category": "cs.ET"}
{"title": "Identifying Macro Causal Effects in C-DMGs", "abstract": "Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.", "published": "2025-04-02 09:48:27", "link": "http://arxiv.org/abs/2504.01551v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Hyperbolic Diffusion Recommender Model", "abstract": "Diffusion models (DMs) have emerged as the new state-of-the-art family of\ndeep generative models. To gain deeper insights into the limitations of\ndiffusion models in recommender systems, we investigate the fundamental\nstructural disparities between images and items. Consequently, items often\nexhibit distinct anisotropic and directional structures that are less prevalent\nin images. However, the traditional forward diffusion process continuously adds\nisotropic Gaussian noise, causing anisotropic signals to degrade into noise,\nwhich impairs the semantically meaningful representations in recommender\nsystems.\n  Inspired by the advancements in hyperbolic spaces, we propose a novel\n\\textit{\\textbf{H}yperbolic} \\textit{\\textbf{D}iffusion}\n\\textit{\\textbf{R}ecommender} \\textit{\\textbf{M}odel} (named HDRM). Unlike\nexisting directional diffusion methods based on Euclidean space, the intrinsic\nnon-Euclidean structure of hyperbolic space makes it particularly well-adapted\nfor handling anisotropic diffusion processes. In particular, we begin by\nformulating concepts to characterize latent directed diffusion processes within\na geometrically grounded hyperbolic space. Subsequently, we propose a novel\nhyperbolic latent diffusion process specifically tailored for users and items.\nDrawing upon the natural geometric attributes of hyperbolic spaces, we impose\nstructural restrictions on the space to enhance hyperbolic diffusion\npropagation, thereby ensuring the preservation of the intrinsic topology of\nuser-item graphs. Extensive experiments on three benchmark datasets demonstrate\nthe effectiveness of HDRM.", "published": "2025-04-02 09:27:40", "link": "http://arxiv.org/abs/2504.01541v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "AI-Newton: A Concept-Driven Physical Law Discovery System without Prior Physical Knowledge", "abstract": "Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.", "published": "2025-04-02 09:25:34", "link": "http://arxiv.org/abs/2504.01538v1", "categories": ["cs.AI", "cs.LG", "cs.SC", "hep-ph", "physics.class-ph"], "primary_category": "cs.AI"}
{"title": "Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model", "abstract": "Recent advancements in diffusion models have revolutionized generative\nmodeling. However, the impressive and vivid outputs they produce often come at\nthe cost of significant model scaling and increased computational demands.\nConsequently, building personalized diffusion models based on off-the-shelf\nmodels has emerged as an appealing alternative. In this paper, we introduce a\nnovel perspective on conditional generation for transferring a pre-trained\nmodel. From this viewpoint, we propose *Domain Guidance*, a straightforward\ntransfer approach that leverages pre-trained knowledge to guide the sampling\nprocess toward the target domain. Domain Guidance shares a formulation similar\nto advanced classifier-free guidance, facilitating better domain alignment and\nhigher-quality generations. We provide both empirical and theoretical analyses\nof the mechanisms behind Domain Guidance. Our experimental results demonstrate\nits substantial effectiveness across various transfer benchmarks, achieving\nover a 19.6% improvement in FID and a 23.4% improvement in FD$_\\text{DINOv2}$\ncompared to standard fine-tuning. Notably, existing fine-tuned models can\nseamlessly integrate Domain Guidance to leverage these benefits, without\nadditional training.", "published": "2025-04-02 09:07:55", "link": "http://arxiv.org/abs/2504.01521v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Training-free Dense-Aligned Diffusion Guidance for Modular Conditional Image Synthesis", "abstract": "Conditional image synthesis is a crucial task with broad applications, such\nas artistic creation and virtual reality. However, current generative methods\nare often task-oriented with a narrow scope, handling a restricted condition\nwith constrained applicability. In this paper, we propose a novel approach that\ntreats conditional image synthesis as the modular combination of diverse\nfundamental condition units. Specifically, we divide conditions into three\nprimary units: text, layout, and drag. To enable effective control over these\nconditions, we design a dedicated alignment module for each. For the text\ncondition, we introduce a Dense Concept Alignment (DCA) module, which achieves\ndense visual-text alignment by drawing on diverse textual concepts. For the\nlayout condition, we propose a Dense Geometry Alignment (DGA) module to enforce\ncomprehensive geometric constraints that preserve the spatial configuration.\nFor the drag condition, we introduce a Dense Motion Alignment (DMA) module to\napply multi-level motion regularization, ensuring that each pixel follows its\ndesired trajectory without visual artifacts. By flexibly inserting and\ncombining these alignment modules, our framework enhances the model's\nadaptability to diverse conditional generation tasks and greatly expands its\napplication range. Extensive experiments demonstrate the superior performance\nof our framework across a variety of conditions, including textual description,\nsegmentation mask (bounding box), drag manipulation, and their combinations.\nCode is available at https://github.com/ZixuanWang0525/DADG.", "published": "2025-04-02 09:00:28", "link": "http://arxiv.org/abs/2504.01515v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HH-PIM: Dynamic Optimization of Power and Performance with Heterogeneous-Hybrid PIM for Edge AI Devices", "abstract": "Processing-in-Memory (PIM) architectures offer promising solutions for\nefficiently handling AI applications in energy-constrained edge environments.\nWhile traditional PIM designs enhance performance and energy efficiency by\nreducing data movement between memory and processing units, they are limited in\nedge devices due to continuous power demands and the storage requirements of\nlarge neural network weights in SRAM and DRAM. Hybrid PIM architectures,\nincorporating non-volatile memories like MRAM and ReRAM, mitigate these\nlimitations but struggle with a mismatch between fixed computing resources and\ndynamically changing inference workloads. To address these challenges, this\nstudy introduces a Heterogeneous-Hybrid PIM (HH-PIM) architecture, comprising\nhigh-performance MRAM-SRAM PIM modules and low-power MRAM-SRAM PIM modules. We\nfurther propose a data placement optimization algorithm that dynamically\nallocates data based on computational demand, maximizing energy efficiency.\nFPGA prototyping and power simulations with processors featuring HH-PIM and\nother PIM types demonstrate that the proposed HH-PIM achieves up to $60.43$\npercent average energy savings over conventional PIMs while meeting application\nlatency requirements. These results confirm the suitability of HH-PIM for\nadaptive, energy-efficient AI processing in edge devices.", "published": "2025-04-02 08:22:32", "link": "http://arxiv.org/abs/2504.01468v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "Probabilistic Curriculum Learning for Goal-Based Reinforcement Learning", "abstract": "Reinforcement learning (RL) -- algorithms that teach artificial agents to\ninteract with environments by maximising reward signals -- has achieved\nsignificant success in recent years. These successes have been facilitated by\nadvances in algorithms (e.g., deep Q-learning, deep deterministic policy\ngradients, proximal policy optimisation, trust region policy optimisation, and\nsoft actor-critic) and specialised computational resources such as GPUs and\nTPUs. One promising research direction involves introducing goals to allow\nmultimodal policies, commonly through hierarchical or curriculum reinforcement\nlearning. These methods systematically decompose complex behaviours into\nsimpler sub-tasks, analogous to how humans progressively learn skills (e.g. we\nlearn to run before we walk, or we learn arithmetic before calculus). However,\nfully automating goal creation remains an open challenge. We present a novel\nprobabilistic curriculum learning algorithm to suggest goals for reinforcement\nlearning agents in continuous control and navigation tasks.", "published": "2025-04-02 08:15:16", "link": "http://arxiv.org/abs/2504.01459v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Emerging Cyber Attack Risks of Medical AI Agents", "abstract": "Large language models (LLMs)-powered AI agents exhibit a high level of\nautonomy in addressing medical and healthcare challenges. With the ability to\naccess various tools, they can operate within an open-ended action space.\nHowever, with the increase in autonomy and ability, unforeseen risks also\narise. In this work, we investigated one particular risk, i.e., cyber attack\nvulnerability of medical AI agents, as agents have access to the Internet\nthrough web browsing tools. We revealed that through adversarial prompts\nembedded on webpages, cyberattackers can: i) inject false information into the\nagent's response; ii) they can force the agent to manipulate recommendation\n(e.g., healthcare products and services); iii) the attacker can also steal\nhistorical conversations between the user and agent, resulting in the leak of\nsensitive/private medical information; iv) furthermore, the targeted agent can\nalso cause a computer system hijack by returning a malicious URL in its\nresponse. Different backbone LLMs were examined, and we found such cyber\nattacks can succeed in agents powered by most mainstream LLMs, with the\nreasoning models such as DeepSeek-R1 being the most vulnerable.", "published": "2025-04-02 08:04:53", "link": "http://arxiv.org/abs/2504.03759v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "BiSeg-SAM: Weakly-Supervised Post-Processing Framework for Boosting Binary Segmentation in Segment Anything Models", "abstract": "Accurate segmentation of polyps and skin lesions is essential for diagnosing\ncolorectal and skin cancers. While various segmentation methods for polyps and\nskin lesions using fully supervised deep learning techniques have been\ndeveloped, the pixel-level annotation of medical images by doctors is both\ntime-consuming and costly. Foundational vision models like the Segment Anything\nModel (SAM) have demonstrated superior performance; however, directly applying\nSAM to medical segmentation may not yield satisfactory results due to the lack\nof domain-specific medical knowledge. In this paper, we propose BiSeg-SAM, a\nSAM-guided weakly supervised prompting and boundary refinement network for the\nsegmentation of polyps and skin lesions. Specifically, we fine-tune SAM\ncombined with a CNN module to learn local features. We introduce a WeakBox with\ntwo functions: automatically generating box prompts for the SAM model and using\nour proposed Multi-choice Mask-to-Box (MM2B) transformation for rough\nmask-to-box conversion, addressing the mismatch between coarse labels and\nprecise predictions. Additionally, we apply scale consistency (SC) loss for\nprediction scale alignment. Our DetailRefine module enhances boundary precision\nand segmentation accuracy by refining coarse predictions using a limited amount\nof ground truth labels. This comprehensive approach enables BiSeg-SAM to\nachieve excellent multi-task segmentation performance. Our method demonstrates\nsignificant superiority over state-of-the-art (SOTA) methods when tested on\nfive polyp datasets and one skin cancer dataset.", "published": "2025-04-02 08:04:37", "link": "http://arxiv.org/abs/2504.01452v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Enabling Systematic Generalization in Abstract Spatial Reasoning through Meta-Learning for Compositionality", "abstract": "Systematic generalization refers to the capacity to understand and generate\nnovel combinations from known components. Despite recent progress by large\nlanguage models (LLMs) across various domains, these models often fail to\nextend their knowledge to novel compositional scenarios, revealing notable\nlimitations in systematic generalization. There has been an ongoing debate\nabout whether neural networks possess the capacity for systematic\ngeneralization, with recent studies suggesting that meta-learning approaches\ndesigned for compositionality can significantly enhance this ability. However,\nthese insights have largely been confined to linguistic problems, leaving their\napplicability to other tasks an open question. In this study, we extend the\napproach of meta-learning for compositionality to the domain of abstract\nspatial reasoning. To this end, we introduce $\\textit{SYGAR}$-a dataset\ndesigned to evaluate the capacity of models to systematically generalize from\nknown geometric transformations (e.g., translation, rotation) of\ntwo-dimensional objects to novel combinations of these transformations (e.g.,\ntranslation+rotation). Our results show that a transformer-based\nencoder-decoder model, trained via meta-learning for compositionality, can\nsystematically generalize to previously unseen transformation compositions,\nsignificantly outperforming state-of-the-art LLMs, including o3-mini, GPT-4o,\nand Gemini 2.0 Flash, which fail to exhibit similar systematic behavior. Our\nfindings highlight the effectiveness of meta-learning in promoting\nsystematicity beyond linguistic tasks, suggesting a promising direction toward\nmore robust and generalizable models.", "published": "2025-04-02 07:56:39", "link": "http://arxiv.org/abs/2504.01445v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "PiCo: Jailbreaking Multimodal Large Language Models via $\\textbf{Pi}$ctorial $\\textbf{Co}$de Contextualization", "abstract": "Multimodal Large Language Models (MLLMs), which integrate vision and other\nmodalities into Large Language Models (LLMs), significantly enhance AI\ncapabilities but also introduce new security vulnerabilities. By exploiting the\nvulnerabilities of the visual modality and the long-tail distribution\ncharacteristic of code training data, we present PiCo, a novel jailbreaking\nframework designed to progressively bypass multi-tiered defense mechanisms in\nadvanced MLLMs. PiCo employs a tier-by-tier jailbreak strategy, using\ntoken-level typographic attacks to evade input filtering and embedding harmful\nintent within programming context instructions to bypass runtime monitoring. To\ncomprehensively assess the impact of attacks, a new evaluation metric is\nfurther proposed to assess both the toxicity and helpfulness of model outputs\npost-attack. By embedding harmful intent within code-style visual instructions,\nPiCo achieves an average Attack Success Rate (ASR) of 84.13% on Gemini-Pro\nVision and 52.66% on GPT-4, surpassing previous methods. Experimental results\nhighlight the critical gaps in current defenses, underscoring the need for more\nrobust strategies to secure advanced MLLMs.", "published": "2025-04-02 07:54:32", "link": "http://arxiv.org/abs/2504.01444v2", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation", "abstract": "Optical coherence tomography angiography (OCTA) shows its great importance in\nimaging microvascular networks by providing accurate 3D imaging of blood\nvessels, but it relies upon specialized sensors and expensive devices. For this\nreason, previous works show the potential to translate the readily available 3D\nOptical Coherence Tomography (OCT) images into 3D OCTA images. However,\nexisting OCTA translation methods directly learn the mapping from the OCT\ndomain to the OCTA domain in continuous and infinite space with guidance from\nonly a single view, i.e., the OCTA project map, resulting in suboptimal\nresults. To this end, we propose the multi-view Tri-alignment framework for OCT\nto OCTA 3D image translation in discrete and finite space, named MuTri. In the\nfirst stage, we pre-train two vector-quantized variational auto-encoder (VQ-\nVAE) by reconstructing 3D OCT and 3D OCTA data, providing semantic prior for\nsubsequent multi-view guidances. In the second stage, our multi-view\ntri-alignment facilitates another VQVAE model to learn the mapping from the OCT\ndomain to the OCTA domain in discrete and finite space. Specifically, a\ncontrastive-inspired semantic alignment is proposed to maximize the mutual\ninformation with the pre-trained models from OCT and OCTA views, to facilitate\ncodebook learning. Meanwhile, a vessel structure alignment is proposed to\nminimize the structure discrepancy with the pre-trained models from the OCTA\nproject map view, benefiting from learning the detailed vessel structure\ninformation. We also collect the first large-scale dataset, namely, OCTA2024,\nwhich contains a pair of OCT and OCTA volumes from 846 subjects.", "published": "2025-04-02 07:28:09", "link": "http://arxiv.org/abs/2504.01428v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "TimeSearch: Hierarchical Video Search with Spotlight and Reflection for Human-like Long Video Understanding", "abstract": "Large video-language models (LVLMs) have shown remarkable performance across\nvarious video-language tasks. However, they encounter significant challenges\nwhen processing long videos because of the large number of video frames\ninvolved. Downsampling long videos in either space or time can lead to visual\nhallucinations, making it difficult to accurately interpret long videos.\nMotivated by human hierarchical temporal search strategies, we propose\n\\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videos\nin a human-like manner. TimeSearch integrates two human-like primitives into a\nunified autoregressive LVLM: 1) \\textbf{Spotlight} efficiently identifies\nrelevant temporal events through a Temporal-Augmented Frame Representation\n(TAFR), explicitly binding visual features with timestamps; 2)\n\\textbf{Reflection} evaluates the correctness of the identified events,\nleveraging the inherent temporal self-reflection capabilities of LVLMs.\nTimeSearch progressively explores key events and prioritizes temporal search\nbased on reflection confidence. Extensive experiments on challenging long-video\nbenchmarks confirm that TimeSearch substantially surpasses previous\nstate-of-the-art, improving the accuracy from 41.8\\% to 51.5\\% on the LVBench.\nAdditionally, experiments on temporal grounding demonstrate that appropriate\nTAFR is adequate to effectively stimulate the surprising temporal grounding\nability of LVLMs in a simpler yet versatile manner, which improves mIoU on\nCharades-STA by 11.8\\%. The code will be released.", "published": "2025-04-02 06:47:19", "link": "http://arxiv.org/abs/2504.01407v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HCAF-DTA: drug-target binding affinity prediction with cross-attention fused hypergraph neural networks", "abstract": "Accurate prediction of the binding affinity between drugs and target proteins\nis a core task in computer-aided drug design. Existing deep learning methods\ntend to ignore the information of internal sub-structural features of drug\nmolecules and drug-target interactions, resulting in limited prediction\nperformance. In this paper, we propose a drug-target association prediction\nmodel HCAF-DTA based on cross-attention fusion hypergraph neural network. The\nmodel innovatively introduces hypergraph representation in the feature\nextraction stage: drug molecule hypergraphs are constructed based on the tree\ndecomposition algorithm, and the sub-structural and global features extracted\nby fusing the hypergraph neural network with the graphical neural network\nthrough hopping connections, in which the hyper edges can efficiently\ncharacterise the functional functional groups and other key chemical features;\nfor the protein feature extraction, a weighted graph is constructed based on\nthe residues predicted by the ESM model contact maps to construct weighted\ngraphs, and multilayer graph neural networks were used to capture spatial\ndependencies. In the prediction stage, a bidirectional multi-head\ncross-attention mechanism is designed to model intermolecular interactions from\nthe dual viewpoints of atoms and amino acids, and cross-modal features with\ncorrelated information are fused by attention. Experiments on benchmark\ndatasets such as Davis and KIBA show that HCAF-DTA outperforms state of the\narts in all three performance evaluation metrics, with the MSE metrics reaching\n0.198 and 0.122, respectively, with an improvement of up to 4% from the optimal\nbaseline.", "published": "2025-04-02 06:46:28", "link": "http://arxiv.org/abs/2504.02014v1", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "From Easy to Hard: Building a Shortcut for Differentially Private Image Synthesis", "abstract": "Differentially private (DP) image synthesis aims to generate synthetic images\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\norganizations sharing and utilizing synthetic images. Although previous methods\nhave significantly progressed, especially in training diffusion models on\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\nstage in the beginning, where diffusion models learn simple features of the\nsensitive images. To facilitate this easy stage, we propose to use `central\nimages', simply aggregations of random samples of the sensitive dataset.\nIntuitively, although those central images do not show details, they\ndemonstrate useful characteristics of all images and only incur minimal privacy\ncosts, thus helping early-phase model training. We conduct experiments to\npresent that on the average of four investigated image datasets, the fidelity\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\nstate-of-the-art method.", "published": "2025-04-02 06:30:55", "link": "http://arxiv.org/abs/2504.01395v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "ProtoGCD: Unified and Unbiased Prototype Learning for Generalized Category Discovery", "abstract": "Generalized category discovery (GCD) is a pragmatic but underexplored\nproblem, which requires models to automatically cluster and discover novel\ncategories by leveraging the labeled samples from old classes. The challenge is\nthat unlabeled data contain both old and new classes. Early works leveraging\npseudo-labeling with parametric classifiers handle old and new classes\nseparately, which brings about imbalanced accuracy between them. Recent methods\nemploying contrastive learning neglect potential positives and are decoupled\nfrom the clustering objective, leading to biased representations and\nsub-optimal results. To address these issues, we introduce a unified and\nunbiased prototype learning framework, namely ProtoGCD, wherein old and new\nclasses are modeled with joint prototypes and unified learning objectives,\n{enabling unified modeling between old and new classes}. Specifically, we\npropose a dual-level adaptive pseudo-labeling mechanism to mitigate\nconfirmation bias, together with two regularization terms to collectively help\nlearn more suitable representations for GCD. Moreover, for practical\nconsiderations, we devise a criterion to estimate the number of new classes.\nFurthermore, we extend ProtoGCD to detect unseen outliers, achieving task-level\nunification. Comprehensive experiments show that ProtoGCD achieves\nstate-of-the-art performance on both generic and fine-grained datasets. The\ncode is available at https://github.com/mashijie1028/ProtoGCD.", "published": "2025-04-02 06:13:14", "link": "http://arxiv.org/abs/2504.03755v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Random Conditioning with Distillation for Data-Efficient Diffusion Model Compression", "abstract": "Diffusion models generate high-quality images through progressive denoising\nbut are computationally intensive due to large model sizes and repeated\nsampling. Knowledge distillation, which transfers knowledge from a complex\nteacher to a simpler student model, has been widely studied in recognition\ntasks, particularly for transferring concepts unseen during student training.\nHowever, its application to diffusion models remains underexplored, especially\nin enabling student models to generate concepts not covered by the training\nimages. In this work, we propose Random Conditioning, a novel approach that\npairs noised images with randomly selected text conditions to enable efficient,\nimage-free knowledge distillation. By leveraging this technique, we show that\nthe student can generate concepts unseen in the training images. When applied\nto conditional diffusion model distillation, our method allows the student to\nexplore the condition space without generating condition-specific images,\nresulting in notable improvements in both generation quality and efficiency.\nThis promotes resource-efficient deployment of generative diffusion models,\nbroadening their accessibility for both research and real-world applications.\nCode, models, and datasets are available at\nhttps://dohyun-as.github.io/Random-Conditioning .", "published": "2025-04-02 05:41:19", "link": "http://arxiv.org/abs/2504.02011v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Virtual Reality and Artificial Intelligence as Psychological Countermeasures in Space and Other Isolated and Confined Environments: A Scoping Review", "abstract": "Spaceflight is an isolated and confined environment (ICE) that exposes\nastronauts to psychological hazards, such as stress, danger, and monotony.\nVirtual reality (VR) and artificial intelligence (AI) technologies can serve as\npsychological countermeasures as they can digitally simulate immersive\nenvironments, interactive companions, and therapeutic experiences. Our study\nemploys a scoping literature review approach to identify what is currently\nknown about the use and effectiveness of VR and AI-based interventions as\npsychological countermeasures to improve mood or emotional states in adults in\nspace or other ICEs. Additionally, this review aimed to identify gaps in the\nknowledge base and whether a systematic review with meta-analysis was\nwarranted. The review included studies where the intervention was used or\nintended for use in space or other extraterrestrial environments (ICE). Our\nsearch strategy yielded 19 studies from 3390 records across seven major\ndatabases. All studies focused on VR-based interventions, with no eligible\nAI-based intervention studies found. VR interventions were found to be\neffective for relaxation and improving mood, emergency training, as an\ninteractive communication platform, for comparing interior designs, and for\nenhancing exercise. There were improvements for measures of mood and emotion\\n\n(e.g., anxiety and stress); however, user preferences varied, and some\ninstances of cybersickness were reported. A systematic review with\nmeta-analysis is not recommended due to the heterogeneity of results. There is\nsignificant scope for further research into the use of VR for a wider range of\nmood and emotion variables using standardised assessment instruments.\nAdditionally, the potential application of AI as a psychological countermeasure\nwarrants further investigation.", "published": "2025-04-02 05:25:29", "link": "http://arxiv.org/abs/2504.01366v1", "categories": ["cs.HC", "cs.AI", "cs.MM"], "primary_category": "cs.HC"}
{"title": "Global Rice Multi-Class Segmentation Dataset (RiceSEG): A Comprehensive and Diverse High-Resolution RGB-Annotated Images for the Development and Benchmarking of Rice Segmentation Algorithms", "abstract": "Developing computer vision-based rice phenotyping techniques is crucial for\nprecision field management and accelerating breeding, thereby continuously\nadvancing rice production. Among phenotyping tasks, distinguishing image\ncomponents is a key prerequisite for characterizing plant growth and\ndevelopment at the organ scale, enabling deeper insights into eco-physiological\nprocesses. However, due to the fine structure of rice organs and complex\nillumination within the canopy, this task remains highly challenging,\nunderscoring the need for a high-quality training dataset. Such datasets are\nscarce, both due to a lack of large, representative collections of rice field\nimages and the time-intensive nature of annotation. To address this gap, we\nestablished the first comprehensive multi-class rice semantic segmentation\ndataset, RiceSEG. We gathered nearly 50,000 high-resolution, ground-based\nimages from five major rice-growing countries (China, Japan, India, the\nPhilippines, and Tanzania), encompassing over 6,000 genotypes across all growth\nstages. From these original images, 3,078 representative samples were selected\nand annotated with six classes (background, green vegetation, senescent\nvegetation, panicle, weeds, and duckweed) to form the RiceSEG dataset. Notably,\nthe sub-dataset from China spans all major genotypes and rice-growing\nenvironments from the northeast to the south. Both state-of-the-art\nconvolutional neural networks and transformer-based semantic segmentation\nmodels were used as baselines. While these models perform reasonably well in\nsegmenting background and green vegetation, they face difficulties during the\nreproductive stage, when canopy structures are more complex and multiple\nclasses are involved. These findings highlight the importance of our dataset\nfor developing specialized segmentation models for rice and other crops.", "published": "2025-04-02 04:03:23", "link": "http://arxiv.org/abs/2504.02880v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "An Explainable Reconfiguration-Based Optimization Algorithm for Industrial and Reliability-Redundancy Allocation Problems", "abstract": "Industrial and reliability optimization problems often involve complex\nconstraints and require efficient, interpretable solutions. This paper presents\nAI-AEFA, an advanced parameter reconfiguration-based metaheuristic algorithm\ndesigned to address large-scale industrial and reliability-redundancy\nallocation problems. AI-AEFA enhances search space exploration and convergence\nefficiency through a novel log-sigmoid-based parameter adaptation and chaotic\nmapping mechanism. The algorithm is validated across twenty-eight IEEE CEC 2017\nconstrained benchmark problems, fifteen large-scale industrial optimization\nproblems, and seven reliability-redundancy allocation problems, consistently\noutperforming state-of-the-art optimization techniques in terms of feasibility,\ncomputational efficiency, and convergence speed. The additional key\ncontribution of this work is the integration of SHAP (Shapley Additive\nExplanations) to enhance the interpretability of AI-AEFA, providing insights\ninto the impact of key parameters such as Coulomb's constant, charge,\nacceleration, and electrostatic force. This explainability feature enables a\ndeeper understanding of decision-making within the AI-AEFA framework during the\noptimization processes. The findings confirm AI-AEFA as a robust, scalable, and\ninterpretable optimization tool with significant real-world applications.", "published": "2025-04-02 03:33:48", "link": "http://arxiv.org/abs/2504.01331v1", "categories": ["cs.AI", "cs.NE"], "primary_category": "cs.AI"}
{"title": "CFMD: Dynamic Cross-layer Feature Fusion for Salient Object Detection", "abstract": "Cross-layer feature pyramid networks (CFPNs) have achieved notable progress\nin multi-scale feature fusion and boundary detail preservation for salient\nobject detection. However, traditional CFPNs still suffer from two core\nlimitations: (1) a computational bottleneck caused by complex feature weighting\noperations, and (2) degraded boundary accuracy due to feature blurring in the\nupsampling process. To address these challenges, we propose CFMD, a novel\ncross-layer feature pyramid network that introduces two key innovations. First,\nwe design a context-aware feature aggregation module (CFLMA), which\nincorporates the state-of-the-art Mamba architecture to construct a dynamic\nweight distribution mechanism. This module adaptively adjusts feature\nimportance based on image context, significantly improving both representation\nefficiency and generalization. Second, we introduce an adaptive dynamic\nupsampling unit (CFLMD) that preserves spatial details during resolution\nrecovery. By adjusting the upsampling range dynamically and initializing with a\nbilinear strategy, the module effectively reduces feature overlap and maintains\nfine-grained boundary structures. Extensive experiments on three standard\nbenchmarks using three mainstream backbone networks demonstrate that CFMD\nachieves substantial improvements in pixel-level accuracy and boundary\nsegmentation quality, especially in complex scenes. The results validate the\neffectiveness of CFMD in jointly enhancing computational efficiency and\nsegmentation performance, highlighting its strong potential in salient object\ndetection tasks.", "published": "2025-04-02 03:22:36", "link": "http://arxiv.org/abs/2504.01326v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "COST: Contrastive One-Stage Transformer for Vision-Language Small Object Tracking", "abstract": "Transformer has recently demonstrated great potential in improving\nvision-language (VL) tracking algorithms. However, most of the existing VL\ntrackers rely on carefully designed mechanisms to perform the multi-stage\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\nignores distribution discrepancy between modalities in feature space,\npotentially leading to suboptimal representations. In this work, we propose\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\naiming to learn semantically consistent and unified VL representations.\nSpecifically, we introduce a contrastive alignment strategy that maximizes\nmutual information (MI) between a video and its corresponding language\ndescription. This enables effective cross-modal alignment, yielding\nsemantically consistent features in the representation space. By leveraging a\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\nreasoning mechanism, empirically demonstrating that a simple stack of\ntransformer encoders effectively enables unified VL representations. Moreover,\nwe contribute a newly collected VL tracking benchmark dataset for small object\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\nto evaluating generic and high-speed small object tracking, respectively. Small\nobject tracking is notoriously challenging due to weak appearance and limited\nfeatures, and this dataset is, to the best of our knowledge, the first to\nexplore the usage of language cues to enhance visual representation for small\nobject tracking. Extensive experiments demonstrate that COST achieves\nstate-of-the-art performance on five existing VL tracking datasets, as well as\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\npublicly available.", "published": "2025-04-02 03:12:38", "link": "http://arxiv.org/abs/2504.01321v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates", "abstract": "Foundation medical segmentation models, with MedSAM being the most popular,\nhave achieved promising performance across organs and lesions. However, MedSAM\nstill suffers from compromised performance on specific lesions with intricate\nstructures and appearance, as well as bounding box prompt-induced\nperturbations. Although current test-time adaptation (TTA) methods for medical\nimage segmentation may tackle this issue, partial (e.g., batch normalization)\nor whole parametric updates restrict their effectiveness due to limited update\nsignals or catastrophic forgetting in large models. Meanwhile, these approaches\nignore the computational complexity during adaptation, which is particularly\nsignificant for modern foundation models. To this end, our theoretical analyses\nreveal that directly refining image embeddings is feasible to approach the same\ngoal as parametric updates under the MedSAM architecture, which enables us to\nrealize high computational efficiency and segmentation performance without the\nrisk of catastrophic forgetting. Under this framework, we propose to encourage\nmaximizing factorized conditional probabilities of the posterior prediction\nprobability using a proposed distribution-approximated latent conditional\nrandom field loss combined with an entropy minimization loss. Experiments show\nthat we achieve about 3\\% Dice score improvements across three datasets while\nreducing computational complexity by over 7 times.", "published": "2025-04-02 03:03:34", "link": "http://arxiv.org/abs/2504.02008v1", "categories": ["q-bio.QM", "cs.AI"], "primary_category": "q-bio.QM"}
{"title": "Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language and Action Chunking with Transformers", "abstract": "We present Bi-LAT, a novel imitation learning framework that unifies\nbilateral control with natural language processing to achieve precise force\nmodulation in robotic manipulation. Bi-LAT leverages joint position, velocity,\nand torque data from leader-follower teleoperation while also integrating\nvisual and linguistic cues to dynamically adjust applied force. By encoding\nhuman instructions such as \"softly grasp the cup\" or \"strongly twist the\nsponge\" through a multimodal Transformer-based model, Bi-LAT learns to\ndistinguish nuanced force requirements in real-world tasks. We demonstrate\nBi-LAT's performance in (1) unimanual cup-stacking scenario where the robot\naccurately modulates grasp force based on language commands, and (2) bimanual\nsponge-twisting task that requires coordinated force control. Experimental\nresults show that Bi-LAT effectively reproduces the instructed force levels,\nparticularly when incorporating SigLIP among tested language encoders. Our\nfindings demonstrate the potential of integrating natural language cues into\nimitation learning, paving the way for more intuitive and adaptive human-robot\ninteraction. For additional material, please visit:\nhttps://mertcookimg.github.io/bi-lat/", "published": "2025-04-02 02:21:30", "link": "http://arxiv.org/abs/2504.01301v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with Dual-Level Learning", "abstract": "The exploitation of large language models (LLMs) for malicious purposes poses\nsignificant security risks as these models become more powerful and widespread.\nWhile most existing red-teaming frameworks focus on single-turn attacks,\nreal-world adversaries typically operate in multi-turn scenarios, iteratively\nprobing for vulnerabilities and adapting their prompts based on threat model\nresponses. In this paper, we propose \\AlgName, a novel multi-turn red-teaming\nagent that emulates sophisticated human attackers through complementary\nlearning dimensions: global tactic-wise learning that accumulates knowledge\nover time and generalizes to new attack goals, and local prompt-wise learning\nthat refines implementations for specific goals when initial attempts fail.\nUnlike previous multi-turn approaches that rely on fixed strategy sets,\n\\AlgName enables the agent to identify new jailbreak tactics, develop a\ngoal-based tactic selection framework, and refine prompt formulations for\nselected tactics. Empirical evaluations on JailbreakBench demonstrate our\nframework's superior performance, achieving over 90\\% attack success rates\nagainst GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns,\noutperforming state-of-the-art baselines. These results highlight the\neffectiveness of dynamic learning in identifying and exploiting model\nvulnerabilities in realistic multi-turn scenarios.", "published": "2025-04-02 01:06:19", "link": "http://arxiv.org/abs/2504.01278v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Proof of Humanity: A Multi-Layer Network Framework for Certifying Human-Originated Content in an AI-Dominated Internet", "abstract": "The rapid proliferation of generative AI has led to an internet increasingly\npopulated with synthetic content-text, images, audio, and video generated\nwithout human intervention. As the distinction between human and AI-generated\ndata blurs, the ability to verify content origin becomes critical for\napplications ranging from social media and journalism to legal and financial\nsystems.\n  In this paper, we propose a conceptual, multi-layer architectural framework\nthat enables telecommunications networks to act as infrastructure level\ncertifiers of human-originated content. By leveraging identity anchoring at the\nphysical layer, metadata propagation at the network and transport layers, and\ncryptographic attestations at the session and application layers, Telcos can\nprovide an end-to-end Proof of Humanity for data traversing their networks.\n  We outline how each OSI layer can contribute to this trust fabric using\ntechnical primitives such as SIM/eSIM identity, digital signatures,\nbehavior-based ML heuristics, and edge-validated APIs. The framework is\npresented as a foundation for future implementation, highlighting monetization\npathways for telcos such as trust-as-a-service APIs, origin-certified traffic\ntiers, and regulatory compliance tools.\n  The paper does not present implementation or benchmarking results but offers\na technically detailed roadmap and strategic rationale for transforming Telcos\ninto validators of digital authenticity in an AI-dominated internet. Security,\nprivacy, and adversarial considerations are discussed as directions for future\nwork.", "published": "2025-04-02 00:02:51", "link": "http://arxiv.org/abs/2504.03752v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Cutwidth Bounds via Vertex Partitions", "abstract": "We study the cutwidth measure on graphs and ways to bound the cutwidth of a\ngraph by partitioning its vertices. We consider bounds expressed as a function\nof two quantities: on the one hand, the maximal cutwidth y of the subgraphs\ninduced by the classes of the partition, and on the other hand, the cutwidth x\nof the quotient multigraph obtained by merging each class to a single vertex.\nWe consider in particular the decomposition of directed graphs into strongly\nconnected components (SCCs): in this case, y is the maximal cutwidth of an SCC,\nand x is the cutwidth of the directed acyclic condensation multigraph.\n  We show that the cutwidth of a graph is always in O(x + y), specifically it\ncan be upper bounded by 1.5x + y. We also show a lower bound justifying that\nthe constant 1.5 cannot be improved in general", "published": "2025-04-02 10:23:58", "link": "http://arxiv.org/abs/2504.01574v2", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "Vertex-Based Localization of Erd\u0151s-Gallai Theorems for Paths and Cycles", "abstract": "For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. The Erd\\H{o}s-Gallai theorem for paths states that\nin a simple $P_k$-free graph, $m \\leq \\frac{n(k-1)}{2}$, where $P_k$ denotes a\npath with length $k$ (that is, with $k$ edges). In this paper, we generalize\nthis result as follows: For each $v \\in V(G)$, let $p(v)$ be the length of the\nlongest path that contains $v$. We show that \\[m \\leq \\sum_{v \\in V(G)}\n\\frac{p(v)}{2}\\] The Erd\\H{o}s-Gallai theorem for cycles states that in a\nsimple graph $G$ with circumference (that is, the length of the longest cycle)\nat most $k$, we have $m \\leq \\frac{k(n-1)}{2}$. We strengthen this result as\nfollows: For each $v \\in V(G)$, let $c(v)$ be the length of the longest cycle\nthat contains $v$, or $2$ if $v$ is not part of any cycle. We prove that \\[m\n\\leq \\left( \\sum_{v \\in V(G)} \\frac{c(v)}{2} \\right) - \\frac{c(u)}{2}\\] where\n$c(u)$ denotes the circumference of $G$. \\newline Furthermore, we characterize\nthe class of extremal graphs that attain equality in these bounds.", "published": "2025-04-02 08:52:28", "link": "http://arxiv.org/abs/2504.01501v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "LSC-ADL: An Activity of Daily Living (ADL)-Annotated Lifelog Dataset Generated via Semi-Automatic Clustering", "abstract": "Lifelogging involves continuously capturing personal data through wearable\ncameras, providing an egocentric view of daily activities. Lifelog retrieval\naims to search and retrieve relevant moments from this data, yet existing\nmethods largely overlook activity-level annotations, which capture temporal\nrelationships and enrich semantic understanding. In this work, we introduce\nLSC-ADL, an ADL-annotated lifelog dataset derived from the LSC dataset,\nincorporating Activities of Daily Living (ADLs) as a structured semantic layer.\nUsing a semi-automatic approach featuring the HDBSCAN algorithm for intra-class\nclustering and human-in-the-loop verification, we generate accurate ADL\nannotations to enhance retrieval explainability. By integrating action\nrecognition into lifelog retrieval, LSC-ADL bridges a critical gap in existing\nresearch, offering a more context-aware representation of daily life. We\nbelieve this dataset will advance research in lifelog retrieval, activity\nrecognition, and egocentric vision, ultimately improving the accuracy and\ninterpretability of retrieved content. The ADL annotations can be downloaded at\nhttps://bit.ly/lsc-adl-annotations.", "published": "2025-04-02 18:39:28", "link": "http://arxiv.org/abs/2504.02060v1", "categories": ["cs.CV", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Is Less Really More? Fake News Detection with Limited Information", "abstract": "The threat that online fake news and misinformation pose to democracy,\njustice, public confidence, and especially to vulnerable populations, has led\nto a sharp increase in the need for fake news detection and intervention.\nWhether multi-modal or pure text-based, most fake news detection methods depend\non textual analysis of entire articles. However, these fake news detection\nmethods come with certain limitations. For instance, fake news detection\nmethods that rely on full text can be computationally inefficient, demand large\namounts of training data to achieve competitive accuracy, and may lack\nrobustness across different datasets. This is because fake news datasets have\nstrong variations in terms of the level and types of information they provide;\nwhere some can include large paragraphs of text with images and metadata,\nothers can be a few short sentences. Perhaps if one could only use minimal\ninformation to detect fake news, fake news detection methods could become more\nrobust and resilient to the lack of information. We aim to overcome these\nlimitations by detecting fake news using systematically selected, limited\ninformation that is both effective and capable of delivering robust, promising\nperformance. We propose a framework called SLIM Systematically-selected Limited\nInformation) for fake news detection. In SLIM, we quantify the amount of\ninformation by introducing information-theoretic measures. SLIM leverages\nlimited information to achieve performance in fake news detection comparable to\nthat of state-of-the-art obtained using the full text. Furthermore, by\ncombining various types of limited information, SLIM can perform even better\nwhile significantly reducing the quantity of information required for training\ncompared to state-of-the-art language model-based fake news detection\ntechniques.", "published": "2025-04-02 17:32:37", "link": "http://arxiv.org/abs/2504.01922v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Extending MovieLens-32M to Provide New Evaluation Objectives", "abstract": "Offline evaluation of recommender systems has traditionally treated the\nproblem as a machine learning problem. In the classic case of recommending\nmovies, where the user has provided explicit ratings of which movies they like\nand don't like, each user's ratings are split into test and train sets, and the\nevaluation task becomes to predict the held out test data using the training\ndata. This machine learning style of evaluation makes the objective to\nrecommend the movies that a user has watched and rated highly, which is not the\nsame task as helping the user find movies that they would enjoy if they watched\nthem. This mismatch in objective between evaluation and task is a compromise to\navoid the cost of asking a user to evaluate recommendations by watching each\nmovie. As a resource available for download, we offer an extension to the\nMovieLens-32M dataset that provides for new evaluation objectives. Our primary\nobjective is to predict the movies that a user would be interested in watching,\ni.e. predict their watchlist. To construct this extension, we recruited\nMovieLens users, collected their profiles, made recommendations with a diverse\nset of algorithms, pooled the recommendations, and had the users assess the\npools. Notably, we found that the traditional machine learning style of\nevaluation ranks the Popular algorithm, which recommends movies based on total\nnumber of ratings in the system, in the middle of the twenty-two recommendation\nruns we used to build the pools. In contrast, when we rank the runs by users'\ninterest in watching movies, we find that recommending popular movies as a\nrecommendation algorithm becomes one of the worst performing runs. It appears\nthat by asking users to assess their personal recommendations, we can alleviate\nthe popularity bias issues created by using information retrieval effectiveness\nmeasures for the evaluation of recommender systems.", "published": "2025-04-02 16:15:46", "link": "http://arxiv.org/abs/2504.01863v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Comment Staytime Prediction with LLM-enhanced Comment Understanding", "abstract": "In modern online streaming platforms, the comments section plays a critical\nrole in enhancing the overall user experience. Understanding user behavior\nwithin the comments section is essential for comprehensive user interest\nmodeling. A key factor of user engagement is staytime, which refers to the\namount of time that users browse and post comments. Existing watchtime\nprediction methods struggle to adapt to staytime prediction, overlooking\ninteractions with individual comments and their interrelation. In this paper,\nwe present a micro-video recommendation dataset with video comments (named as\nKuaiComt) which is collected from Kuaishou platform. correspondingly, we\npropose a practical framework for comment staytime prediction with LLM-enhanced\nComment Understanding (LCU). Our framework leverages the strong text\ncomprehension capabilities of large language models (LLMs) to understand\ntextual information of comments, while also incorporating fine-grained comment\nranking signals as auxiliary tasks. The framework is two-staged: first, the LLM\nis fine-tuned using domain-specific tasks to bridge the video and the comments;\nsecond, we incorporate the LLM outputs into the prediction model and design two\ncomment ranking auxiliary tasks to better understand user preference. Extensive\noffline experiments demonstrate the effectiveness of our framework, showing\nsignificant improvements on the task of comment staytime prediction.\nAdditionally, online A/B testing further validates the practical benefits on\nindustrial scenario. Our dataset KuaiComt\n(https://github.com/lyingCS/KuaiComt.github.io) and code for LCU\n(https://github.com/lyingCS/LCU) are fully released.", "published": "2025-04-02 11:09:18", "link": "http://arxiv.org/abs/2504.01602v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Test-Time Alignment for Tracking User Interest Shifts in Sequential Recommendation", "abstract": "Sequential recommendation is essential in modern recommender systems, aiming\nto predict the next item a user may interact with based on their historical\nbehaviors. However, real-world scenarios are often dynamic and subject to\nshifts in user interests. Conventional sequential recommendation models are\ntypically trained on static historical data, limiting their ability to adapt to\nsuch shifts and resulting in significant performance degradation during\ntesting. Recently, Test-Time Training (TTT) has emerged as a promising\nparadigm, enabling pre-trained models to dynamically adapt to test data by\nleveraging unlabeled examples during testing. However, applying TTT to\neffectively track and address user interest shifts in recommender systems\nremains an open and challenging problem. Key challenges include how to capture\ntemporal information effectively and explicitly identifying shifts in user\ninterests during the testing phase. To address these issues, we propose\nT$^2$ARec, a novel model leveraging state space model for TTT by introducing\ntwo Test-Time Alignment modules tailored for sequential recommendation,\neffectively capturing the distribution shifts in user interest patterns over\ntime. Specifically, T$^2$ARec aligns absolute time intervals with\nmodel-adaptive learning intervals to capture temporal dynamics and introduce an\ninterest state alignment mechanism to effectively and explicitly identify the\nuser interest shifts with theoretical guarantees. These two alignment modules\nenable efficient and incremental updates to model parameters in a\nself-supervised manner during testing, enhancing predictions for online\nrecommendation. Extensive evaluations on three benchmark datasets demonstrate\nthat T$^2$ARec achieves state-of-the-art performance and robustly mitigates the\nchallenges posed by user interest shifts.", "published": "2025-04-02 08:42:30", "link": "http://arxiv.org/abs/2504.01489v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "GeoRAG: A Question-Answering Approach from a Geographical Perspective", "abstract": "Geographic Question Answering (GeoQA) addresses natural language queries in\ngeographic domains to fulfill complex user demands and improve information\nretrieval efficiency. Traditional QA systems, however, suffer from limited\ncomprehension, low retrieval accuracy, weak interactivity, and inadequate\nhandling of complex tasks, hindering precise information acquisition. This\nstudy presents GeoRAG, a knowledge-enhanced QA framework integrating\ndomain-specific fine-tuning and prompt engineering with Retrieval-Augmented\nGeneration (RAG) technology to enhance geographic knowledge retrieval accuracy\nand user interaction. The methodology involves four components: (1) A\nstructured geographic knowledge base constructed from 3267 corpora (research\npapers, monographs, and technical reports), categorized via a multi-agent\napproach into seven dimensions: semantic understanding, spatial location,\ngeometric morphology, attribute characteristics, feature relationships,\nevolutionary processes, and operational mechanisms. This yielded 145234\nclassified entries and 875432 multi-dimensional QA pairs. (2) A multi-label\ntext classifier based on BERT-Base-Chinese, trained to analyze query types\nthrough geographic dimension classification. (3) A retrieval evaluator\nleveraging QA pair data to assess query-document relevance, optimizing\nretrieval precision. (4) GeoPrompt templates engineered to dynamically\nintegrate user queries with retrieved information, enhancing response quality\nthrough dimension-specific prompting. Comparative experiments demonstrate\nGeoRAG's superior performance over conventional RAG across multiple base\nmodels, validating its generalizability. This work advances geographic AI by\nproposing a novel paradigm for deploying large language models in\ndomain-specific contexts, with implications for improving GeoQA systems\nscalability and accuracy in real-world applications.", "published": "2025-04-02 08:11:05", "link": "http://arxiv.org/abs/2504.01458v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LLM-VPRF: Large Language Model Based Vector Pseudo Relevance Feedback", "abstract": "Vector Pseudo Relevance Feedback (VPRF) has shown promising results in\nimproving BERT-based dense retrieval systems through iterative refinement of\nquery representations. This paper investigates the generalizability of VPRF to\nLarge Language Model (LLM) based dense retrievers. We introduce LLM-VPRF and\nevaluate its effectiveness across multiple benchmark datasets, analyzing how\ndifferent LLMs impact the feedback mechanism. Our results demonstrate that\nVPRF's benefits successfully extend to LLM architectures, establishing it as a\nrobust technique for enhancing dense retrieval performance regardless of the\nunderlying models. This work bridges the gap between VPRF with traditional\nBERT-based dense retrievers and modern LLMs, while providing insights into\ntheir future directions.", "published": "2025-04-02 08:02:01", "link": "http://arxiv.org/abs/2504.01448v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Prompt-Guided Attention Head Selection for Focus-Oriented Image Retrieval", "abstract": "The goal of this paper is to enhance pretrained Vision Transformer (ViT)\nmodels for focus-oriented image retrieval with visual prompting. In real-world\nimage retrieval scenarios, both query and database images often exhibit\ncomplexity, with multiple objects and intricate backgrounds. Users often want\nto retrieve images with specific object, which we define as the Focus-Oriented\nImage Retrieval (FOIR) task. While a standard image encoder can be employed to\nextract image features for similarity matching, it may not perform optimally in\nthe multi-object-based FOIR task. This is because each image is represented by\na single global feature vector. To overcome this, a prompt-based image\nretrieval solution is required. We propose an approach called Prompt-guided\nattention Head Selection (PHS) to leverage the head-wise potential of the\nmulti-head attention mechanism in ViT in a promptable manner. PHS selects\nspecific attention heads by matching their attention maps with user's visual\nprompts, such as a point, box, or segmentation. This empowers the model to\nfocus on specific object of interest while preserving the surrounding visual\ncontext. Notably, PHS does not necessitate model re-training and avoids any\nimage alteration. Experimental results show that PHS substantially improves\nperformance on multiple datasets, offering a practical and training-free\nsolution to enhance model performance in the FOIR task.", "published": "2025-04-02 04:33:27", "link": "http://arxiv.org/abs/2504.01348v1", "categories": ["cs.CV", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Real-time Ad retrieval via LLM-generative Commercial Intention for Sponsored Search Advertising", "abstract": "The integration of Large Language Models (LLMs) with retrieval systems has\nshown promising potential in retrieving documents (docs) or advertisements\n(ads) for a given query. Existing LLM-based retrieval methods generate numeric\nor content-based DocIDs to retrieve docs/ads. However, the one-to-few mapping\nbetween numeric IDs and docs, along with the time-consuming content extraction,\nleads to semantic inefficiency and limits scalability in large-scale corpora.\nIn this paper, we propose the Real-time Ad REtrieval (RARE) framework, which\nleverages LLM-generated text called Commercial Intentions (CIs) as an\nintermediate semantic representation to directly retrieve ads for queries in\nreal-time. These CIs are generated by a customized LLM injected with commercial\nknowledge, enhancing its domain relevance. Each CI corresponds to multiple ads,\nyielding a lightweight and scalable set of CIs. RARE has been implemented in a\nreal-world online system, handling daily search volumes in the hundreds of\nmillions. The online implementation has yielded significant benefits: a 5.04%\nincrease in consumption, a 6.37% rise in Gross Merchandise Volume (GMV), a\n1.28% enhancement in click-through rate (CTR) and a 5.29% increase in shallow\nconversions. Extensive offline experiments show RARE's superiority over ten\ncompetitive baselines in four major categories.", "published": "2025-04-02 02:26:31", "link": "http://arxiv.org/abs/2504.01304v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Migrating a Job Search Relevance Function", "abstract": "In this paper, we describe the migration of a homebrewed C++ search engine to\nOpenSearch, aimed at preserving and improving search performance with minimal\nimpact on business metrics. To facilitate the migration, we froze our job\ncorpus and executed queries in low inventory locations to capture a\nrepresentative mixture of high- and low-quality search results. These query-job\npairs were labeled by crowd-sourced annotators using a custom rubric designed\nto reflect relevance and user satisfaction. Leveraging Bayesian optimization,\nwe fine-tuned a new retrieval algorithm on OpenSearch, replicating key\ncomponents of the original engine's logic while introducing new functionality\nwhere necessary. Through extensive online testing, we demonstrated that the new\nsystem performed on par with the original, showing improvements in specific\nengagement metrics, with negligible effects on revenue.", "published": "2025-04-02 01:22:55", "link": "http://arxiv.org/abs/2504.01284v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Semidefinite lower bounds for covering codes", "abstract": "Let $K_q(n,r)$ denote the minimum size of a $q$-ary covering code of word\nlength $n$ and covering radius $r$. In other words, $K_q(n,r)$ is the minimum\nsize of a set of $q$-ary codewords of length $n$ such that the Hamming balls of\nradius $r$ around the codewords cover the Hamming space $\\{0,\\ldots,q-1\\}^n$.\nThe special case $K_3(n,1)$ is often referred to as the football pool problem,\nas it is equivalent to finding a set of forecasts on $n$ football matches that\nis guaranteed to contain a forecast with at most one wrong outcome.\n  In this paper, we build and expand upon the work of Gijswijt (2005), who\nintroduced a semidefinite programming lower bound on $K_q(n,r)$ via matrix\ncuts. We develop techniques that strengthen this bound, by introducing new\nsemidefinite constraints inspired by Lasserre's hierarchy for 0-1 programs and\nsymmetry reduction methods, and a more powerful objective function. The\ntechniques lead to sharper lower bounds, setting new records across a broad\nrange of values of $q$, $n$, and $r$.", "published": "2025-04-02 17:42:03", "link": "http://arxiv.org/abs/2504.01932v1", "categories": ["math.CO", "cs.IT", "math.IT", "math.OC"], "primary_category": "math.CO"}
{"title": "Source Coding for a Wiener Process", "abstract": "We develop a novel source coding strategy for sampling and monitoring of a\nWiener process. For the encoding process, we employ a four level\n``quantization'' scheme, which employs monotone function thresholds as opposed\nto fixed constant thresholds. Leveraging the hitting times of the Wiener\nprocess with these thresholds, we devise a sampling and encoding strategy which\ndoes not incur any quantization errors. We give analytical expressions for the\nmean squared error (MSE) and find the optimal source code lengths to minimize\nthe MSE under this monotone function threshold scheme, subject to a sampling\nrate constraint.", "published": "2025-04-02 17:40:06", "link": "http://arxiv.org/abs/2504.01929v1", "categories": ["cs.IT", "cs.SY", "eess.SP", "eess.SY", "math.IT"], "primary_category": "cs.IT"}
{"title": "Hyperbolic decomposition of Dirichlet distance for ARMA models", "abstract": "We investigate the hyperbolic decomposition of the Dirichlet norm and\ndistance between autoregressive moving average (ARMA) models. Beginning with\nthe K\\\"ahler information geometry of linear systems in the Hardy space and\nweighted Hardy spaces, we demonstrate that the Dirichlet norm and distance of\nARMA models, corresponding to the mutual information between the past and\nfuture, are decomposed into functions of the hyperbolic distance between the\npoles and zeros of the ARMA models.", "published": "2025-04-02 16:12:24", "link": "http://arxiv.org/abs/2504.01860v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cram\u00e9r--Rao Inequalities for Several Generalized Fisher Information", "abstract": "The de Bruijn identity states that Fisher information is the half of the\nderivative of Shannon differential entropy along heat flow. In the same spirit,\nin this paper we introduce a generalized version of Fisher information, named\nas the R\\'enyi--Fisher information, which is the half of the derivative of\nR\\'enyi information along heat flow. Based on this R\\'enyi--Fisher information,\nwe establish sharp R\\'enyi-entropic isoperimetric inequalities, which\ngeneralize the classic entropic isoperimetric inequality to the R\\'enyi\nsetting. Utilizing these isoperimetric inequalities, we extend the classical\nCram\\'er--Rao inequality from Fisher information to R\\'enyi--Fisher\ninformation. Lastly, we use these generalized Cram\\'er--Rao inequalities to\ndetermine the signs of derivatives of entropy along heat flow, strengthening\nexisting results on the complete monotonicity of entropy.", "published": "2025-04-02 15:44:02", "link": "http://arxiv.org/abs/2504.01837v1", "categories": ["cs.IT", "math.IT", "math.PR", "math.ST", "stat.TH"], "primary_category": "cs.IT"}
{"title": "Optimal shift-invariant spaces from uniform measurements", "abstract": "Let $m$ be a positive integer and\n  $\\mathcal{C}$ be a collection of closed subspaces in $L^2(\\mathbb{R})$. Given\nthe measurements $\\mathcal{F}_Y=\\left\\lbrace \\left\\lbrace y_k^1\n\\right\\rbrace_{k\\in \\mathbb{Z}},\\ldots, \\left\\lbrace y_k^m \\right\\rbrace_{k\\in\n\\mathbb{Z}} \\right\\rbrace \\subset \\ell^2(\\mathbb{Z})$ of unknown functions\n$\\mathcal{F}=\\left\\{f_1, \\ldots,f_m \\right\\} \\subset L^2( \\mathbb{R})$, in this\npaper we study the problem of finding an optimal space $S$ in $\\mathcal{C}$\nthat is ``closest\" to the measurements $\\mathcal{F}_Y$ of $\\mathcal{F}$. Since\nthe class of finitely generated shift-invariant spaces (FSISs) is popularly\nused for modelling signals, we assume $\\mathcal{C}$ consists of FSISs. We will\nbe considering three cases. In the first case, $\\mathcal{C}$ consists of FSISs\nwithout any assumption on extra invariance. In the second case, we assume\n$\\mathcal{C}$ consists of extra invariant FSISs, and in the third case, we\nassume $\\mathcal{C}$ has translation-invariant FSISs. In all three cases, we\nprove the existence of an optimal space.", "published": "2025-04-02 15:00:21", "link": "http://arxiv.org/abs/2504.01793v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Linear Time Iterative Decoders for Hypergraph-Product and Lifted-Product Codes", "abstract": "Quantum low-density parity-check (QLDPC) codes with asymptotically non-zero\nrates are prominent candidates for achieving fault-tolerant quantum\ncomputation, primarily due to their syndrome-measurement circuit's low\noperational depth. Numerous studies advocate for the necessity of fast decoders\nto fully harness the capabilities of QLDPC codes, thus driving the focus\ntowards designing low-complexity iterative decoders. However, empirical\ninvestigations indicate that such iterative decoders are susceptible to having\na high error floor while decoding QLDPC codes. The main objective of this paper\nis to analyze the decoding failures of the \\emph{hypergraph-product} and\n\\emph{lifted-product} codes and to design decoders that mitigate these\nfailures, thus achieving a reduced error floor. The suboptimal performance of\nthese codes can predominantly be ascribed to two structural phenomena: (1)\nstabilizer-induced trapping sets, which are subgraphs formed by stabilizers,\nand (2) classical trapping sets, which originate from the classical codes\nutilized in the construction of hypergraph-product and lifted-product codes.\nThe dynamics of stabilizer-induced trapping sets is examined and a\nstraightforward modification of iterative decoders is proposed to circumvent\nthese trapping sets. Moreover, this work proposes a systematic methodology for\ndesigning decoders that can circumvent classical trapping sets in both\nhypergraph product and lifted product codes, from decoders capable of avoiding\ntheir trapping set in the parent classical LDPC code. When decoders that can\navoid stabilizer-induced trapping sets are run in parallel with those that can\nmitigate the effect of classical TS, the logical error rate improves\nsignificantly in the error-floor region.", "published": "2025-04-02 13:37:29", "link": "http://arxiv.org/abs/2504.01728v1", "categories": ["cs.IT", "math.IT", "quant-ph"], "primary_category": "cs.IT"}
{"title": "An Adaptive Proximal Inexact Gradient Framework and Its Application to Per-Antenna Constrained Joint Beamforming and Compression Design", "abstract": "In this paper, we propose an adaptive proximal inexact gradient (APIG)\nframework for solving a class of nonsmooth composite optimization problems\ninvolving function and gradient errors. Unlike existing inexact proximal\ngradient methods, the proposed framework introduces a new line search condition\nthat jointly adapts to function and gradient errors, enabling adaptive stepsize\nselection while maintaining theoretical guarantees. Specifically, we prove that\nthe proposed framework achieves an $\\epsilon$-stationary point within\n$\\mathcal{O}(\\epsilon^{-2})$ iterations for nonconvex objectives and an\n$\\epsilon$-optimal solution within $\\mathcal{O}(\\epsilon^{-1})$ iterations for\nconvex cases, matching the best-known complexity in this context. We then\ncustom-apply the APIG framework to an important signal processing problem: the\njoint beamforming and compression problem (JBCP) with per-antenna power\nconstraints (PAPCs) in cooperative cellular networks. This customized\napplication requires careful exploitation of the problem's special structure\nsuch as the tightness of the semidefinite relaxation (SDR) and the\ndifferentiability of the dual. Numerical experiments demonstrate the superior\nperformance of our custom-application over state-of-the-art benchmarks for the\nJBCP.", "published": "2025-04-02 13:28:15", "link": "http://arxiv.org/abs/2504.01721v1", "categories": ["cs.IT", "eess.SP", "math.IT", "math.OC"], "primary_category": "cs.IT"}
{"title": "Construction of MDS Euclidean Self-Dual Codes via Multiple Subsets", "abstract": "MDS self-dual codes have good algebraic structure, and their parameters are\ncompletely determined by the code length. In recent years, the construction of\nMDS Euclidean self-dual codes with new lengths has become an important issue in\ncoding theory. In this paper, we are committed to constructing new MDS\nEuclidean self-dual codes via generalized Reed-Solomon (GRS) codes and their\nextended (EGRS) codes. The main effort of our constructions is to find suitable\nsubsets of finite fields as the evaluation sets, ensuring that the\ncorresponding (extended) GRS codes are Euclidean self-dual. Firstly, we present\na method for selecting evaluation sets from multiple intersecting subsets and\nprovide a theorem to guarantee that the chosen evaluation sets meet the desired\ncriteria. Secondly, based on this theorem, we construct six new classes of MDS\nEuclidean self-dual codes using the norm function, as well as the union of\nthree multiplicity subgroups and their cosets respectively. Finally, in our\nconstructions, the proportion of possible MDS Euclidean self-dual codes exceeds\n85\\%, which is much higher than previously reported results.", "published": "2025-04-02 13:26:04", "link": "http://arxiv.org/abs/2504.01717v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Deep Graph Reinforcement Learning for UAV-Enabled Multi-User Secure Communications", "abstract": "While unmanned aerial vehicles (UAVs) with flexible mobility are envisioned\nto enhance physical layer security in wireless communications, the efficient\nsecurity design that adapts to such high network dynamics is rather\nchallenging. The conventional approaches extended from optimization\nperspectives are usually quite involved, especially when jointly considering\nfactors in different scales such as deployment and transmission in UAV-related\nscenarios. In this paper, we address the UAV-enabled multi-user secure\ncommunications by proposing a deep graph reinforcement learning framework.\nSpecifically, we reinterpret the security beamforming as a graph neural network\n(GNN) learning task, where mutual interference among users is managed through\nthe message-passing mechanism. Then, the UAV deployment is obtained through\nsoft actor-critic reinforcement learning, where the GNN-based security\nbeamforming is exploited to guide the deployment strategy update. Simulation\nresults demonstrate that the proposed approach achieves near-optimal security\nperformance and significantly enhances the efficiency of strategy\ndetermination. Moreover, the deep graph reinforcement learning framework offers\na scalable solution, adaptable to various network scenarios and configurations,\nestablishing a robust basis for information security in UAV-enabled\ncommunications.", "published": "2025-04-02 07:57:33", "link": "http://arxiv.org/abs/2504.01446v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "SCNR Maximization for MIMO ISAC Assisted by Fluid Antenna System", "abstract": "The integrated sensing and communication (ISAC) technology has been\nextensively researched to enhance communication rates and radar sensing\ncapabilities. Additionally, a new technology known as fluid antenna system\n(FAS) has recently been proposed to obtain higher communication rates for\nfuture wireless networks by dynamically altering the antenna position to obtain\na more favorable channel condition. The application of the FAS technology in\nISAC scenarios holds significant research potential. In this paper, we\ninvestigate a FAS-assisted multiple-input multiple-output (MIMO) ISAC system\nfor maximizing the radar sensing signal-clutter-noise ratio (SCNR) under\ncommunication signal-to-interference-plus-noise ratio (SINR) and antenna\nposition constraints. We devise an iterative algorithm that tackles the\noptimization problem by maximizing a lower bound of SCNR with respect to the\ntransmit precoding matrix and the antenna position. By addressing the\nnon-convexity of the problem through this iterative approach, our method\nsignificantly improves the SCNR. Our simulation results demonstrate that the\nproposed scheme achieves a higher SCNR compared to the baselines.", "published": "2025-04-02 05:34:18", "link": "http://arxiv.org/abs/2504.01372v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "LOCO Codes Can Correct as Well: Error-Correction Constrained Coding for DNA Data Storage", "abstract": "As a medium for cold data storage, DNA stands out as it promises significant\ngains in storage capacity and lifetime. However, it comes with its own data\nprocessing challenges to overcome. Constrained codes over the DNA alphabet\n$\\{A,T,G,C\\}$ have been used to design DNA sequences that are free of long\nhomopolymers to increase stability, yet effective error detection and error\ncorrection are required to achieve reliability in data retrieval. Recently, we\nintroduced lexicographically-ordered constrained (LOCO) codes, namely DNA LOCO\n(D-LOCO) codes, with error detection. In this paper, we equip our D-LOCO codes\nwith error correction for substitution errors via syndrome-like decoding,\ndesignated as residue decoding. We only use D-LOCO codewords of indices\ndivisible by a suitable redundancy metric $R(m) > 0$, where $m$ is the code\nlength, for error correction. We provide the community with a construction of\nconstrained codes forbidding runs of length higher than fixed $\\ell \\in\n\\{1,2,3\\}$ and $GC$-content in $\\big [0.5-\\frac{1}{2K},0.5+\\frac{1}{2K}\\big ]$\nthat correct $K$ segmented substitution errors, one per codeword. We call the\nproposed codes error-correction (EC) D-LOCO codes. We also give a list-decoding\nprocedure with near-quadratic time-complexity in $m$ to correct\ndouble-substitution errors within EC D-LOCO codewords, which has $> 98.20\\%$\naverage success rate. The redundancy metric is projected to require\n$2\\log_2(m)+O(1)$-bit allocation for a length-$m$ codeword. Hence, our EC\nD-LOCO codes are projected to be capacity-approaching with respect to the\nerror-free constrained system.", "published": "2025-04-02 00:20:51", "link": "http://arxiv.org/abs/2504.01262v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Distributed Multi-agent Coordination over Cellular Sheaves", "abstract": "Techniques for coordination of multi-agent systems are vast and varied, often\nutilizing purpose-built solvers or controllers with tight coupling to the types\nof systems involved or the coordination goal. In this paper, we introduce a\ngeneral unified framework for heterogeneous multi-agent coordination using the\nlanguage of cellular sheaves and nonlinear sheaf Laplacians, which are\ngeneralizations of graphs and graph Laplacians. Specifically, we introduce the\nconcept of a nonlinear homological program encompassing a choice of cellular\nsheaf on an undirected graph, nonlinear edge potential functions, and\nconstrained convex node objectives, which constitutes a standard form for a\nwide class of coordination problems. We use the alternating direction method of\nmultipliers to derive a distributed optimization algorithm for solving these\nnonlinear homological programs. To demonstrate the applicability of this\nframework, we show how heterogeneous coordination goals including combinations\nof consensus, formation, and flocking can be formulated as nonlinear\nhomological programs and provide numerical simulations showing the efficacy of\nour distributed solution algorithm.", "published": "2025-04-02 18:13:22", "link": "http://arxiv.org/abs/2504.02049v2", "categories": ["math.OC", "cs.MA", "math.AT", "93A16, 93B45, 55N30"], "primary_category": "math.OC"}
{"title": "Anticipating Degradation: A Predictive Approach to Fault Tolerance in Robot Swarms", "abstract": "An active approach to fault tolerance is essential for robot swarms to\nachieve long-term autonomy. Previous efforts have focused on responding to\nspontaneous electro-mechanical faults and failures. However, many faults occur\ngradually over time. Waiting until such faults have manifested as failures\nbefore addressing them is both inefficient and unsustainable in a variety of\nscenarios. This work argues that the principles of predictive maintenance, in\nwhich potential faults are resolved before they hinder the operation of the\nswarm, offer a promising means of achieving long-term fault tolerance. This is\na novel approach to swarm fault tolerance, which is shown to give a comparable\nor improved performance when tested against a reactive approach in almost all\ncases tested.", "published": "2025-04-02 10:59:10", "link": "http://arxiv.org/abs/2504.01594v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Vectorised Parallel in Time methods for low-order discretizations with application to Porous Media problems", "abstract": "High order methods have shown great potential to overcome performance issues\nof simulations of partial differential equations (PDEs) on modern hardware,\nstill many users stick to low-order, matrixbased simulations, in particular in\nporous media applications. Heterogeneous coefficients and low regularity of the\nsolution are reasons not to employ high order discretizations. We present a new\napproach for the simulation of instationary PDEs that allows to partially\nmitigate the performance problems. By reformulating the original problem we\nderive a parallel in time time integrator that increases the arithmetic\nintensity and introduces additional structure into the problem. By this it\nhelps accelerate matrix-based simulations on modern hardware architectures.\nBased on a system for multiple time steps we will formulate a matrix equation\nthat can be solved using vectorised solvers like Block Krylov methods. The\nstructure of this approach makes it applicable for a wide range of linear and\nnonlinear problems. In our numerical experiments we present some first results\nfor three different PDEs, a linear convection-diffusion equation, a nonlinear\ndiffusion-reaction equation and a realistic example based on the Richards'\nequation.", "published": "2025-04-02 20:26:22", "link": "http://arxiv.org/abs/2504.02117v1", "categories": ["math.NA", "cs.CE", "cs.MS", "cs.NA", "86-08, 65J10, 65J15, 65M20, 65Y05, 65Y10, 49M15, 35K61"], "primary_category": "math.NA"}
{"title": "A balancing domain decomposition by constraints preconditioner for a hybridizable discontinuous Galerkin discretization of an elliptic optimal control problem", "abstract": "We consider a hybridizable discontinuous Galerkin (HDG) method for an\nelliptic distributed optimal control problem and we propose a balancing domain\ndecomposition by constraints (BDDC) preconditioner to solve the discretized\nsystem. We establish an error estimate of the HDG methods with explicit\ntracking of a regularization parameter $\\beta$. We observe that the BDDC\npreconditioner is robust with respect to $\\beta$. Numerical results are shown\nto support our findings.", "published": "2025-04-02 19:04:37", "link": "http://arxiv.org/abs/2504.02072v1", "categories": ["math.NA", "cs.NA", "49J20, 49M41, 65N30, 65N55"], "primary_category": "math.NA"}
{"title": "A Unified Approach to Analysis and Design of Denoising Markov Models", "abstract": "Probabilistic generative models based on measure transport, such as diffusion\nand flow-based models, are often formulated in the language of Markovian\nstochastic dynamics, where the choice of the underlying process impacts both\nalgorithmic design choices and theoretical analysis. In this paper, we aim to\nestablish a rigorous mathematical foundation for denoising Markov models, a\nbroad class of generative models that postulate a forward process transitioning\nfrom the target distribution to a simple, easy-to-sample distribution,\nalongside a backward process particularly constructed to enable efficient\nsampling in the reverse direction. Leveraging deep connections with\nnonequilibrium statistical mechanics and generalized Doob's $h$-transform, we\npropose a minimal set of assumptions that ensure: (1) explicit construction of\nthe backward generator, (2) a unified variational objective directly minimizing\nthe measure transport discrepancy, and (3) adaptations of the classical\nscore-matching approach across diverse dynamics. Our framework unifies existing\nformulations of continuous and discrete diffusion models, identifies the most\ngeneral form of denoising Markov models under certain regularity assumptions on\nforward generators, and provides a systematic recipe for designing denoising\nMarkov models driven by arbitrary L\\'evy-type processes. We illustrate the\nversatility and practical effectiveness of our approach through novel denoising\nMarkov models employing geometric Brownian motion and jump processes as forward\ndynamics, highlighting the framework's potential flexibility and capability in\nmodeling complex distributions.", "published": "2025-04-02 17:46:43", "link": "http://arxiv.org/abs/2504.01938v1", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Optimized Schwarz method for the Stokes-Darcy problem with generalized interface conditions", "abstract": "Due to their wide appearance in environmental settings as well as industrial\nand medical applications, the Stokes-Darcy problems with different sets of\ninterface conditions establish an active research area in the community of\nmathematical modelers and computational scientists. For numerical simulation of\nsuch coupled problems in applications, robust and efficient computational\nalgorithms are needed. In this work, we consider a generalization of the\nBeavers-Joseph interface condition recently developed using homogenization and\nboundary layer theory. This extension is applicable not only for the parallel\nflows to the fluid-porous interface as its predecessor, but also for arbitrary\nflow directions. To solve the Stokes-Darcy problem with these generalized\ninterface conditions efficiently, we develop and analyze a Robin-Robin domain\ndecomposition method using Fourier analysis to identify optimal weights in the\nRobin interface conditions. We study efficiency and robustness of the proposed\nmethod and provide numerical simulations which confirm the obtained theoretical\nresults.", "published": "2025-04-02 14:48:28", "link": "http://arxiv.org/abs/2504.01784v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A First-Order Linear Energy Stable Scheme for the Cahn-Hilliard Equation with Dynamic Boundary Conditions under the Effect of Hyperbolic Relaxation", "abstract": "In this paper we focus on the Cahn-Hilliard equation with dynamic boundary\nconditions, by adding two hyperbolic relaxation terms to the system. We verify\nthat the energy of the total system is decreasing with time. By adding two\nstabilization terms, we have constructed a first-order temporal accuracy\nnumerical scheme, which is linear and energy stable. Then we prove that the\nscheme is of first-order in time by the error estimates. At last we carry out\nenough numerical results to validate the the temporal convergence and the\nenergy stability of such scheme. Moreover, we have present the differences of\nthe numerical results with and without the hyperbolic terms, which show that\nthe hyperbolic terms can help the total energy decreasing slowly.", "published": "2025-04-02 14:16:42", "link": "http://arxiv.org/abs/2504.01762v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Acoustic Propagation/Refraction Through Diffuse Interface Models", "abstract": "We present a novel approach for simulating acoustic (pressure) wave\npropagation across different media separated by a diffuse interface through the\nuse of a weak compressibility formulation. Our method builds on our previous\nwork on an entropy-stable discontinuous Galerkin spectral element method for\nthe incompressible Navier-Stokes/Cahn-Hilliard system\n\\cite{manzanero2020entropyNSCH}, and incorporates a modified weak\ncompressibility formulation that allows different sound speeds in each phase.\nWe validate our method through numerical experiments, demonstrating spectral\nconvergence for acoustic transmission and reflection coefficients in one\ndimension and for the angle defined by Snell's law in two dimensions. Special\nattention is given to quantifying the modeling errors introduced by the width\nof the diffuse interface. Our results show that the method successfully\ncaptures the behavior of acoustic waves across interfaces, allowing exponential\nconvergence in transmitted waves. The transmitted angles in two dimensions are\naccurately captured for air-water conditions, up to the critical angle of\n$13^\\circ$. This work represents a step forward in modeling acoustic\npropagation in incompressible multiphase systems, with potential applications\nto marine aeroacoustics.", "published": "2025-04-02 13:33:55", "link": "http://arxiv.org/abs/2504.01727v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "physics.flu-dyn"], "primary_category": "math.NA"}
{"title": "High-Order Flux Splitting Schemes for the Euler Equations of Gas Dynamics", "abstract": "We develop high-order flux splitting schemes for the one- and two-dimensional\nEuler equations of gas dynamics. The proposed schemes are high-order extensions\nof the existing first-order flux splitting schemes introduced in [ E. F. Toro,\nM. E. V\\'azquez-Cend\\'on, Comput. \\& Fluids, 70 (2012), pp. 1--12], where the\nEuler equations of gas dynamics are split into two subsystems: the advection\nand pressure systems. In this paper, we formulate the TV splitting within the\nsemi-discrete framework to extend it to higher orders of accuracy for the first\ntime. The second-order extension is obtained by using piecewise linear\ninterpolant to reconstruct the one-sided point values of the unknowns. The\nthird- and fifth-order schemes are developed using the finite-difference\nalternative weighted essentially non-oscillatory (A-WENO) framework, which is\nparticularly effective in handling multidimensional problems and provides a\nmore straightforward approach to constructing higher-order WENO schemes. These\nextensions significantly improve the resolution of discontinuities and the\naccuracy of numerical solutions, as demonstrated by a series of numerical\nexperiments of both the one- and two-dimensional Euler equations of gas\ndynamics.", "published": "2025-04-02 12:59:34", "link": "http://arxiv.org/abs/2504.01699v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On the performance of the Euler-Maruyama scheme for multidimensional SDEs with discontinuous drift coefficient", "abstract": "We study strong approximation of $d$-dimensional stochastic differential\nequations (SDEs) with a discontinuous drift coefficient. More precisely, we\nessentially assume that the drift coefficient is piecewise Lipschitz continuous\nwith an exceptional set $\\Theta\\subset \\mathbb{R}^d$ that is an orientable\n$C^4$-hypersurface of positive reach, the diffusion coefficient is assumed to\nbe Lipschitz continuous and, in a neighborhood of $\\Theta$, both coefficients\nare bounded and the diffusion coefficient has a non-degenerate portion\northogonal to $\\Theta$.\n  In recent years, a number of results have been proven in the literature for\nstrong approximation of such SDEs and, in particular, the performance of the\nEuler-Maruyama scheme was studied. For $d=1$ and finite $\\Theta$ it was shown\nthat the Euler-Maruyama scheme achieves an $L_p$-error rate of at least $1/2$\nfor all $p\\geq 1$ as in the classical case of Lipschitz continuous\ncoefficients. For $d>1$, it was only known so far, that the Euler-Maruyama\nscheme achieves an $L_2$-error rate of at least $1/4-$ if, additionally, the\ncoefficients $\\mu$ and $\\sigma$ are globally bounded.\n  In this article, we prove that in the above setting the Euler-Maruyama scheme\nin fact achieves an $L_{p}$-error rate of at least $1/2-$ for all\n$d\\in\\mathbb{N}$ and all $p\\geq 1$. The proof of this result is based on the\nwell-known approach of transforming such an SDE into an SDE with globally\nLipschitz continuous coefficients, a new It\\^{o} formula for a class of\nfunctions which are not globally $C^2$ and a detailed analysis of the expected\ntotal time that the actual position of the time-continuous Euler-Maruyama\nscheme and its position at the preceding time point on the underlying grid are\non 'different sides' of the hypersurface $\\Theta$.", "published": "2025-04-02 11:37:06", "link": "http://arxiv.org/abs/2504.01630v1", "categories": ["math.NA", "cs.NA", "math.PR"], "primary_category": "math.NA"}
{"title": "Identity-Based Language Shift Modeling", "abstract": "The preservation of endangered languages is a widely discussed issue\nnowadays. Languages represent essential cultural heritage and can provide\nvaluable botanical, biological, and geographical information. Therefore, it is\nnecessary to develop efficient measures to preserve and revitalize endangered\nlanguages. However, the language shift process is complex and requires an\ninterdisciplinary approach, including mathematical modeling techniques. This\npaper develops a new mathematical model that extends previous works on this\ntopic. We introduce the factor of ethnic identity, which is a proxy for a more\ncomplex nexus of variables involved in an individual's self-identity and/or a\ngroup's identity. This proxy is socially constructed rather than solely\ninherited, shaped by community-determined factors, with language both indexing\nand creating the identity. In our model, we divide speakers into groups\ndepending on with which language they identify themselves with. Moreover, every\ngroup includes monolinguals and bilinguals. The proposed model naturally allows\nus to consider cases of language coexistence and describe a broader class of\nlinguistic situations. For example, the simulation results show that our model\ncan result in cyclic language dynamics, drawing a parallel to cell population\nmodels. In this way, the proposed mathematical model can serve as a useful tool\nfor developing efficient measures for language preservation and revitalization.", "published": "2025-04-02 09:48:29", "link": "http://arxiv.org/abs/2504.01552v1", "categories": ["physics.soc-ph", "cs.NA", "math.NA"], "primary_category": "physics.soc-ph"}
{"title": "Improvement of fully-implicit two-phase pore-network models by employing generalized flux functions with additional throat variables", "abstract": "In fully-implicit two-phase pore-network models, developing a well-converged\nscheme remains a major challenge, primarily due to the discontinuities in the\nphase conductivities. This paper addresses these numerical issues by proposing\na generalized flux function that establishes a continuous flux expression for\ntwo-phase flows by introducing an additional throat variable $\\Theta$. Two\napproaches for expressing this additional throat variable are introduced: the\nfirst applies regularization strategies, while the second constructs an\nadditional residual constraint equation. It is shown that this approach\nsignificantly improves accuracy and ensures the temporal convergence, as\ndemonstrated through various numerical examples.", "published": "2025-04-02 09:14:42", "link": "http://arxiv.org/abs/2504.01529v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "The Polynomial Set Associated with a Fixed Number of Matrix-Matrix Multiplications", "abstract": "We consider the problem of computing matrix polynomials $p(X)$, where $X$ is\na large matrix, with as few matrix-matrix multiplications as possible. More\nprecisely, let $ \\Pi_{2^{m}}^* $ represent the set of polynomials computable\nwith $m$ matrix-matrix multiplications, but with an arbitrary number of matrix\nadditions and scaling operations. We characterize this set through a tabular\nparameterization. By deriving equivalence transformations of the tabular\nrepresentation, we establish new methods that can be used to construct elements\nof $ \\Pi_{2^{m}}^* $ and determine general properties of the set. The\ntransformations allow us to eliminate variables and prove that the dimension is\nbounded by $m^2$. Numerical simulations suggest that this is a sharp bound.\nConsequently, we have identified a parameterization, which, to our knowledge,\nis the first minimal parameterization. Furthermore, we conduct a study using\ncomputational tools from algebraic geometry to determine the largest degree $d$\nsuch that all polynomials of that degree belong to $ \\Pi_{2^{m}}^* $, or its\nclosure. In many cases, the computational setup is constructive in the sense\nthat it can also be used to determine a specific evaluation scheme for a given\npolynomial.", "published": "2025-04-02 08:51:58", "link": "http://arxiv.org/abs/2504.01500v1", "categories": ["math.NA", "cs.NA", "65F30"], "primary_category": "math.NA"}
{"title": "Discrete stability estimates for the pressureless Euler-Poisson-Boltzmann equations in the Quasi-Neutral limit", "abstract": "We propose and study a fully implicit finite volume scheme for the\npressureless Euler-Poisson-Boltzmann equations on the one dimensional torus.\nEspecially, we design a consistent and dissipative discretization of the force\nterm which yields an unconditional energy decay. In addition, we establish a\ndiscrete analogue of the modulated energy estimate around constant states with\na small velocity. Numerical experiments are carried to illustrate our\ntheoretical results and to assess the accuracy of our scheme. A test case of\nthe literature is also illustrated.", "published": "2025-04-02 08:39:02", "link": "http://arxiv.org/abs/2504.01487v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Robust Model-Based Approach for Continuous-Time Policy Evaluation with Unknown L\u00e9vy Process Dynamics", "abstract": "This paper develops a model-based framework for continuous-time policy\nevaluation (CTPE) in reinforcement learning, incorporating both Brownian and\nL\\'evy noise to model stochastic dynamics influenced by rare and extreme\nevents. Our approach formulates the policy evaluation problem as solving a\npartial integro-differential equation (PIDE) for the value function with\nunknown coefficients. A key challenge in this setting is accurately recovering\nthe unknown coefficients in the stochastic dynamics, particularly when driven\nby L\\'evy processes with heavy tail effects. To address this, we propose a\nrobust numerical approach that effectively handles both unbiased and censored\ntrajectory datasets. This method combines maximum likelihood estimation with an\niterative tail correction mechanism, improving the stability and accuracy of\ncoefficient recovery. Additionally, we establish a theoretical bound for the\npolicy evaluation error based on coefficient recovery error. Through numerical\nexperiments, we demonstrate the effectiveness and robustness of our method in\nrecovering heavy-tailed L\\'evy dynamics and verify the theoretical error\nanalysis in policy evaluation.", "published": "2025-04-02 08:37:14", "link": "http://arxiv.org/abs/2504.01482v1", "categories": ["cs.LG", "cs.NA", "math.NA", "65R20, 62M05, 35R09, 60H35, 93E35, 90C40, 68T05"], "primary_category": "cs.LG"}
{"title": "Asymptotic Error Bounds and Fractional-Bit Design for Fixed-Point Grover's Quantum Algorithm Emulation", "abstract": "Quantum computing (QC) emulators, which simulate quantum algorithms on\nclassical hardware, are indispensable platforms for testing quantum algorithms\nbefore scalable quantum computers become widely available. A critical challenge\nin QC emulation is managing numerical errors from finite arithmetic precision,\nespecially truncation errors in resource-efficient fixed-point arithmetic.\nDespite its importance, systematic studies quantifying how truncation errors\nimpact quantum algorithm accuracy are limited. In this paper, we propose a\nrigorous quantitative framework analyzing truncation error propagation in\nfixed-point QC emulation, focusing on Grover's quantum search algorithm. First,\nwe introduce a simplified two-value amplitude representation of quantum states\nduring Grover's iterations and prove its theoretical validity. Using this\nrepresentation, we derive explicit mathematical expressions characterizing\ntruncation error accumulation across quantum gate operations. We quantify the\noverall emulation error by the $\\ell_2$ distance between ideal and emulated\nprobability distributions, obtaining asymptotic bounds scaling as $O(2^{n-f})$,\nwhere $n$ is the number of qubits and $f$ is fractional-bit precision.\nExtensive numerical simulations and empirical experiments on a practical\nfixed-point QC emulator confirm that observed errors precisely match our\ntheoretical predictions. Finally, we provide a closed-form formula to determine\nthe minimal fractional-bit precision required to achieve a specified error\nthreshold, offering clear guidelines for emulator designers balancing accuracy\nand resource utilization.", "published": "2025-04-02 07:33:36", "link": "http://arxiv.org/abs/2504.01430v1", "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "quant-ph"}
{"title": "A Bayesian approach for inverse potential problem with topological-Gaussian prior", "abstract": "This paper addresses the reconstruction of a potential coefficient in an\nelliptic problem from distributed observations within the Bayesian framework.\nIn such problems, the selection of an appropriate prior distribution is\ncrucial, particularly when the function to be inferred exhibits sharp\ndiscontinuities, as traditional Gaussian priors often prove inadequate. To\ntackle this challenge, we develop the topological prior (TP), a new prior\nconstructed using persistent homology. The proposed prior utilizes persistent\npairs to characterize and record the topological variations of the functions\nunder reconstruction, thereby encoding prior information about the structure\nand discontinuities of the function. The TP prior, however, only exists in a\ndiscretized formulation, which leads to the absence of a well-defined posterior\nmeasure in function spaces. To resolve this issue, we propose a TP-Gaussian\nhybrid prior, where the TP component detects sharp discontinuities in the\nfunction, while the Gaussian distribution acts as a reference measure, ensuring\na well-defined posterior measure in the function space. The proposed TP prior\ndemonstrates effects similar to the classical total variation (TV) prior but\noffers greater flexibility and broader applicability due to three key\nadvantages. First, it is defined on a general topological space, making it\neasily adaptable to a wider range of applications. Second, the persistent\ndistance captures richer topological information compared to the discrete TV\nprior. Third, it incorporates more adjustable parameters, providing enhanced\nflexibility to achieve robust numerical results. These features make the TP\nprior a powerful tool for addressing inverse problems involving functions with\nsharp discontinuities.", "published": "2025-04-02 05:06:42", "link": "http://arxiv.org/abs/2504.01360v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The optimal strong convergence rates of the truncated EM and logarithmic truncated EM methods for multi-dimensional nonlinear stochastic differential equations", "abstract": "The truncated Euler--Maruyama (EM) method, developed by Mao (2015), is used\nto solve multi-dimensional nonlinear stochastic differential equations (SDEs).\nHowever, its convergence rate is suboptimal due to an unnecessary infinitesimal\nfactor. The primary goal of this paper is to demonstrate the optimal\nconvergence of the truncated EM method without infinitesimal factors. Besides,\nthe logarithmic truncated EM method has not been studied in multi-dimensional\ncases, which is the other goal of this paper. We will show the optimal strong\nconvergence order of the positivity-preserving logarithmic truncated EM method\nfor solving multi-dimensional SDEs with positive solutions. Numerical examples\nare given to support our theoretical conclusions.", "published": "2025-04-02 03:15:16", "link": "http://arxiv.org/abs/2504.01323v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A novel semi-analytical multiple invariants-preserving integrator for conservative PDEs", "abstract": "Many conservative partial differential equations such as the Korteweg-de\nVries (KdV) equation, and the nonlinear Schr\\\"{o}dinger equations, the\nKlein-Gordon equation have more than one invariant functionals. In this paper,\nwe propose the definition of the discrete variational derivative, based on\nwhich, a novel semi-analytical multiple invariants-preserving integrator for\nthe conservative partial differential equations is constructed by projection\ntechnique. The proposed integrators are shown to have the same order of\naccuracy as the underlying integrators. For applications, some concrete\nmass-momentum-energy-preserving integrators are derived for the KdV equation.", "published": "2025-04-02 02:30:54", "link": "http://arxiv.org/abs/2504.01307v1", "categories": ["math.NA", "cs.NA", "65L05, 65L07, 65L20, 65P10, 34C15"], "primary_category": "math.NA"}
{"title": "Derivative estimation by RKHS regularization for learning dynamics from time-series data", "abstract": "Learning the governing equations from time-series data has gained increasing\nattention due to its potential to extract useful dynamics from real-world data.\nDespite significant progress, it becomes challenging in the presence of noise,\nespecially when derivatives need to be calculated. To reduce the effect of\nnoise, we propose a method that simultaneously fits both the derivative and\ntrajectory from noisy time-series data. Our approach formulates derivative\nestimation as an inverse problem involving integral operators within the\nforward model, and estimates the derivative function by solving a\nregularization problem in a vector-valued reproducing kernel Hilbert space\n(vRKHS). We derive an integral-form representer theorem, which enables the\ncomputation of the regularized solution by solving a finite-dimensional problem\nand facilitates efficiently estimating the optimal regularization parameter. By\nembedding the dynamics within a vRKHS and utilizing the fitted derivative and\ntrajectory, we can recover the underlying dynamics from noisy data by solving a\nlinear regularization problem. Several numerical experiments are conducted to\nvalidate the effectiveness and efficiency of our method.", "published": "2025-04-02 01:43:52", "link": "http://arxiv.org/abs/2504.01289v1", "categories": ["math.NA", "cs.NA", "37M10, 65P99, 65R32"], "primary_category": "math.NA"}
{"title": "Client Selection in Federated Learning with Data Heterogeneity and Network Latencies", "abstract": "Federated learning (FL) is a distributed machine learning paradigm where\nmultiple clients conduct local training based on their private data, then the\nupdated models are sent to a central server for global aggregation. The\npractical convergence of FL is challenged by multiple factors, with the primary\nhurdle being the heterogeneity among clients. This heterogeneity manifests as\ndata heterogeneity concerning local data distribution and latency heterogeneity\nduring model transmission to the server. While prior research has introduced\nvarious efficient client selection methods to alleviate the negative impacts of\neither of these heterogeneities individually, efficient methods to handle\nreal-world settings where both these heterogeneities exist simultaneously do\nnot exist. In this paper, we propose two novel theoretically optimal client\nselection schemes that can handle both these heterogeneities. Our methods\ninvolve solving simple optimization problems every round obtained by minimizing\nthe theoretical runtime to convergence. Empirical evaluations on 9 datasets\nwith non-iid data distributions, 2 practical delay distributions, and\nnon-convex neural network models demonstrate that our algorithms are at least\ncompetitive to and at most 20 times better than best existing baselines.", "published": "2025-04-02 17:31:15", "link": "http://arxiv.org/abs/2504.01921v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Barrier Certificates for Unknown Systems with Latent States and Polynomial Dynamics using Bayesian Inference", "abstract": "Certifying safety in dynamical systems is crucial, but barrier certificates -\nwidely used to verify that system trajectories remain within a safe region -\ntypically require explicit system models. When dynamics are unknown,\ndata-driven methods can be used instead, yet obtaining a valid certificate\nrequires rigorous uncertainty quantification. For this purpose, existing\nmethods usually rely on full-state measurements, limiting their applicability.\nThis paper proposes a novel approach for synthesizing barrier certificates for\nunknown systems with latent states and polynomial dynamics. A Bayesian\nframework is employed, where a prior in state-space representation is updated\nusing input-output data via a targeted marginal Metropolis-Hastings sampler.\nThe resulting samples are used to construct a candidate barrier certificate\nthrough a sum-of-squares program. It is shown that if the candidate satisfies\nthe required conditions on a test set of additional samples, it is also valid\nfor the true, unknown system with high probability. The approach and its\nprobabilistic guarantees are illustrated through a numerical simulation.", "published": "2025-04-02 15:12:34", "link": "http://arxiv.org/abs/2504.01807v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "stat.ML"], "primary_category": "eess.SY"}
{"title": "Proper scoring rules for estimation and forecast evaluation", "abstract": "Proper scoring rules have been a subject of growing interest in recent years,\nnot only as tools for evaluation of probabilistic forecasts but also as methods\nfor estimating probability distributions. In this article, we review the\nmathematical foundations of proper scoring rules including general\ncharacterization results and important families of scoring rules. We discuss\ntheir role in statistics and machine learning for estimation and forecast\nevaluation. Furthermore, we comment on interesting developments of their usage\nin applications.", "published": "2025-04-02 14:46:14", "link": "http://arxiv.org/abs/2504.01781v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "KD$^{2}$M: An unifying framework for feature knowledge distillation", "abstract": "Knowledge Distillation (KD) seeks to transfer the knowledge of a teacher,\ntowards a student neural net. This process is often done by matching the\nnetworks' predictions (i.e., their output), but, recently several works have\nproposed to match the distributions of neural nets' activations (i.e., their\nfeatures), a process known as \\emph{distribution matching}. In this paper, we\npropose an unifying framework, Knowledge Distillation through Distribution\nMatching (KD$^{2}$M), which formalizes this strategy. Our contributions are\nthreefold. We i) provide an overview of distribution metrics used in\ndistribution matching, ii) benchmark on computer vision datasets, and iii)\nderive new theoretical results for KD.", "published": "2025-04-02 14:14:46", "link": "http://arxiv.org/abs/2504.01757v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Sparse Gaussian Neural Processes", "abstract": "Despite significant recent advances in probabilistic meta-learning, it is\ncommon for practitioners to avoid using deep learning models due to a\ncomparative lack of interpretability. Instead, many practitioners simply use\nnon-meta-models such as Gaussian processes with interpretable priors, and\nconduct the tedious procedure of training their model from scratch for each\ntask they encounter. While this is justifiable for tasks with a limited number\nof data points, the cubic computational cost of exact Gaussian process\ninference renders this prohibitive when each task has many observations. To\nremedy this, we introduce a family of models that meta-learn sparse Gaussian\nprocess inference. Not only does this enable rapid prediction on new tasks with\nsparse Gaussian processes, but since our models have clear interpretations as\nmembers of the neural process family, it also allows manual elicitation of\npriors in a neural process for the first time. In meta-learning regimes for\nwhich the number of observed tasks is small or for which expert domain\nknowledge is available, this offers a crucial advantage.", "published": "2025-04-02 12:00:09", "link": "http://arxiv.org/abs/2504.01650v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Density estimation via mixture discrepancy and moments", "abstract": "With the aim of generalizing histogram statistics to higher dimensional\ncases, density estimation via discrepancy based sequential partition (DSP) has\nbeen proposed [D. Li, K. Yang, W. Wong, Advances in Neural Information\nProcessing Systems (2016) 1099-1107] to learn an adaptive piecewise constant\napproximation defined on a binary sequential partition of the underlying\ndomain, where the star discrepancy is adopted to measure the uniformity of\nparticle distribution. However, the calculation of the star discrepancy is\nNP-hard and it does not satisfy the reflection invariance and rotation\ninvariance either. To this end, we use the mixture discrepancy and the\ncomparison of moments as a replacement of the star discrepancy, leading to the\ndensity estimation via mixture discrepancy based sequential partition (DSP-mix)\nand density estimation via moments based sequential partition (MSP),\nrespectively. Both DSP-mix and MSP are computationally tractable and exhibit\nthe reflection and rotation invariance. Numerical experiments in reconstructing\nthe $d$-D mixture of Gaussians and Betas with $d=2, 3, \\dots, 6$ demonstrate\nthat DSP-mix and MSP both run approximately ten times faster than DSP while\nmaintaining the same accuracy.", "published": "2025-04-02 10:15:03", "link": "http://arxiv.org/abs/2504.01570v1", "categories": ["stat.ML", "cs.LG", "physics.comp-ph", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Time-to-event prediction for grouped variables using Exclusive Lasso", "abstract": "The integration of high-dimensional genomic data and clinical data into\ntime-to-event prediction models has gained significant attention due to the\ngrowing availability of these datasets. Traditionally, a Cox regression model\nis employed, concatenating various covariate types linearly. Given that much of\nthe data may be redundant or irrelevant, feature selection through penalization\nis often desirable. A notable characteristic of these datasets is their\norganization into blocks of distinct data types, such as methylation and\nclinical predictors, which requires selecting a subset of covariates from each\ngroup due to high intra-group correlations. For this reason, we propose\nutilizing Exclusive Lasso regularization in place of standard Lasso\npenalization. We apply our methodology to a real-life cancer dataset,\ndemonstrating enhanced survival prediction performance compared to the\nconventional Cox regression model.", "published": "2025-04-02 09:07:05", "link": "http://arxiv.org/abs/2504.01520v1", "categories": ["stat.ME", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Identifying Obfuscated Code through Graph-Based Semantic Analysis of Binary Code", "abstract": "Protecting sensitive program content is a critical issue in various\nsituations, ranging from legitimate use cases to unethical contexts.\nObfuscation is one of the most used techniques to ensure such protection.\nConsequently, attackers must first detect and characterize obfuscation before\nlaunching any attack against it. This paper investigates the problem of\nfunction-level obfuscation detection using graph-based approaches, comparing\nalgorithms, from elementary baselines to promising techniques like GNN (Graph\nNeural Networks), on different feature choices. We consider various obfuscation\ntypes and obfuscators, resulting in two complex datasets. Our findings\ndemonstrate that GNNs need meaningful features that capture aspects of function\nsemantics to outperform baselines. Our approach shows satisfactory results,\nespecially in a challenging 11-class classification task and in a practical\nmalware analysis example.", "published": "2025-04-02 08:36:27", "link": "http://arxiv.org/abs/2504.01481v1", "categories": ["cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CR"}
{"title": "EEG-EyeTrack: A Benchmark for Time Series and Functional Data Analysis with Open Challenges and Baselines", "abstract": "A new benchmark dataset for functional data analysis (FDA) is presented,\nfocusing on the reconstruction of eye movements from EEG data. The contribution\nis twofold: first, open challenges and evaluation metrics tailored to FDA\napplications are proposed. Second, functional neural networks are used to\nestablish baseline results for the primary regression task of reconstructing\neye movements from EEG signals. Baseline results are reported for the new\ndataset, based on consumer-grade hardware, and the EEGEyeNet dataset, based on\nresearch-grade hardware.", "published": "2025-04-02 08:33:38", "link": "http://arxiv.org/abs/2504.03760v1", "categories": ["eess.SP", "cs.LG", "stat.ML", "62G08, 62R10, 68T07", "G.3; I.5.1; I.2.6"], "primary_category": "eess.SP"}
{"title": "On the Role of Priors in Bayesian Causal Learning", "abstract": "In this work, we investigate causal learning of independent causal mechanisms\nfrom a Bayesian perspective. Confirming previous claims from the literature, we\nshow in a didactically accessible manner that unlabeled data (i.e., cause\nrealizations) do not improve the estimation of the parameters defining the\nmechanism. Furthermore, we observe the importance of choosing an appropriate\nprior for the cause and mechanism parameters, respectively. Specifically, we\nshow that a factorized prior results in a factorized posterior, which resonates\nwith Janzing and Sch\\\"olkopf's definition of independent causal mechanisms via\nthe Kolmogorov complexity of the involved distributions and with the concept of\nparameter independence of Heckerman et al.", "published": "2025-04-02 07:19:49", "link": "http://arxiv.org/abs/2504.01424v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Aligned Better, Listen Better for Audio-Visual Large Language Models", "abstract": "Audio is essential for multimodal video understanding. On the one hand, video\ninherently contains audio, which supplies complementary information to vision.\nBesides, video large language models (Video-LLMs) can encounter many\naudio-centric settings. However, existing Video-LLMs and Audio-Visual Large\nLanguage Models (AV-LLMs) exhibit deficiencies in exploiting audio information,\nleading to weak understanding and hallucinations. To solve the issues, we delve\ninto the model architecture and dataset. (1) From the architectural\nperspective, we propose a fine-grained AV-LLM, namely Dolphin. The concurrent\nalignment of audio and visual modalities in both temporal and spatial\ndimensions ensures a comprehensive and accurate understanding of videos.\nSpecifically, we devise an audio-visual multi-scale adapter for multi-scale\ninformation aggregation, which achieves spatial alignment. For temporal\nalignment, we propose audio-visual interleaved merging. (2) From the dataset\nperspective, we curate an audio-visual caption and instruction-tuning dataset,\ncalled AVU. It comprises 5.2 million diverse, open-ended data tuples (video,\naudio, question, answer) and introduces a novel data partitioning strategy.\nExtensive experiments show our model not only achieves remarkable performance\nin audio-visual understanding, but also mitigates potential hallucinations.", "published": "2025-04-02 18:47:09", "link": "http://arxiv.org/abs/2504.02061v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Spatial-Filter-Bank-Based Neural Method for Multichannel Speech Enhancement", "abstract": "The performance of deep learning-based multi-channel speech enhancement\nmethods often deteriorates when the geometric parameters of the microphone\narray change. Traditional approaches to mitigate this issue typically involve\ntraining on multiple microphone arrays, which can be costly. To address this\nchallenge, we focus on uniform circular arrays and propose the use of a spatial\nfilter bank to extract features that are approximately invariant to geometric\nparameters. These features are then processed by a two-stage conformer-based\nmodel (TSCBM) to enhance speech quality. Experimental results demonstrate that\nour proposed method can be trained on a fixed microphone array while\nmaintaining effective performance across uniform circular arrays with unseen\ngeometric configurations during applications.", "published": "2025-04-02 06:13:37", "link": "http://arxiv.org/abs/2504.01392v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "AIM: Acoustic Inertial Measurement for Indoor Drone Localization and Tracking", "abstract": "We present Acoustic Inertial Measurement (AIM), a one-of-a-kind technique for\nindoor drone localization and tracking. Indoor drone localization and tracking\nare arguably a crucial, yet unsolved challenge: in GPS-denied environments,\nexisting approaches enjoy limited applicability, especially in Non-Line of\nSight (NLoS), require extensive environment instrumentation, or demand\nconsiderable hardware/software changes on drones. In contrast, AIM exploits the\nacoustic characteristics of the drones to estimate their location and derive\ntheir motion, even in NLoS settings. We tame location estimation errors using a\ndedicated Kalman filter and the Interquartile Range rule (IQR). We implement\nAIM using an off-the-shelf microphone array and evaluate its performance with a\ncommercial drone under varied settings. Results indicate that the mean\nlocalization error of AIM is 46% lower than commercial UWB-based systems in\ncomplex indoor scenarios, where state-of-the-art infrared systems would not\neven work because of NLoS settings. We further demonstrate that AIM can be\nextended to support indoor spaces with arbitrary ranges and layouts without\nloss of accuracy by deploying distributed microphone arrays.", "published": "2025-04-02 02:01:16", "link": "http://arxiv.org/abs/2504.01297v1", "categories": ["cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
{"title": "Robust Channel Estimation for Optical Wireless Communications Using Neural Network", "abstract": "Optical Wireless Communication (OWC) has gained significant attention due to\nits high-speed data transmission and throughput. Optical wireless channels are\noften assumed to be flat, but we evaluate frequency selective channels to\nconsider high data rate optical wireless or very dispersive environments. To\naddress this for optical scenarios, this paper presents a robust channel\nestimation framework with low-complexity to mitigate frequency-selective\neffects, then to improve system reliability and performance. This channel\nestimation framework contains a neural network that can estimate general\noptical wireless channels without prior channel information about the\nenvironment. Based on this estimate and the corresponding delay spread, one of\nseveral candidate offline-trained neural networks will be activated to predict\nthis channel. Simulation results demonstrate that the proposed method has\nimproved and robust normalized mean square error (NMSE) and bit error rate\n(BER) performance compared to conventional estimation methods while maintaining\ncomputational efficiency. These findings highlight the potential of neural\nnetwork solutions in enhancing the performance of OWC systems under indoor\nchannel conditions.", "published": "2025-04-02 21:16:34", "link": "http://arxiv.org/abs/2504.02134v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "OAM-Assisted Self-Healing Is Directional, Proportional and Persistent", "abstract": "In this paper we demonstrate the postulated mechanism of self-healing\nspecifically due to orbital-angular-momentum (OAM) in radio vortex beams having\nequal beam-widths. In previous work we experimentally demonstrated self-healing\neffects in OAM beams at 28 GHz and postulated a theoretical mechanism to\naccount for them. In this work we further characterize the OAM self-healing\nmechanism theoretically and confirm those characteristics with systematic and\ncontrolled experimental measurements on a 28 GHz outdoor link. Specifically, we\nfind that the OAM self-healing mechanism is an additional self-healing\nmechanism in structured electromagnetic beams which is directional with respect\nto the displacement of an obstruction relative to the beam axis. We also\nconfirm our previous findings that the amount of OAM self-healing is\nproportional to the OAM order, and additionally find that it persists beyond\nthe focusing region into the far field. As such, OAM-assisted self-healing\nbrings an advantage over other so-called non-diffracting beams both in terms of\nthe minimum distance for onset of self-healing and the amount of self-healing\nobtainable. We relate our findings by extending theoretical models in the\nliterature and develop a unifying electromagnetic analysis to account for\nself-healing of OAM-bearing non-diffracting beams more rigorously.", "published": "2025-04-02 20:06:47", "link": "http://arxiv.org/abs/2504.02103v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "Laboratory evaluation of a wearable instrumented headband for rotational head kinematics measurement", "abstract": "Mild traumatic brain injuries (mTBI) are a highly prevalent condition with\nheterogeneous outcomes between individuals. A key factor governing brain tissue\ndeformation and the risk of mTBI is the rotational kinematics of the head.\nInstrumented mouthguards are a widely accepted method for measuring rotational\nhead motions, owing to their robust sensor-skull coupling. However, wearing\nmouthguards is not feasible in all situations, especially for long-term data\ncollection. Therefore, alternative wearable devices are needed. In this study,\nwe present an improved design and data processing scheme for an instrumented\nheadband. Our instrumented headband utilizes an array of inertial measurement\nunits (IMUs) and a new data-processing scheme based on continuous wavelet\ntransforms to address sources of error in the IMU measurements. The headband\nperformance was evaluated in the laboratory on an anthropomorphic test device,\nwhich was impacted with a soccer ball to replicate soccer heading. When\ncomparing the measured peak rotational velocities (PRV) and peak rotational\naccelerations (PRA) between the reference sensors and the headband for impacts\nto the front of the head, the correlation coefficients (r) were 0.80 and 0.63,\nand the normalized root mean square error (NRMSE) values were 0.20 and 0.28,\nrespectively. However, when considering all impact locations, r dropped to 0.42\nand 0.34 and NRMSE increased to 0.5 and 0.41 for PRV and PRA, respectively.\nThis new instrumented headband improves upon previous headband designs in\nreconstructing the rotational head kinematics resulting from frontal soccer\nball impacts, providing a potential alternative to instrumented mouthguards.", "published": "2025-04-02 17:47:07", "link": "http://arxiv.org/abs/2504.01939v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Quantum Meets SAR: A Novel Range-Doppler Algorithm for Next-Gen Earth Observation", "abstract": "Synthetic aperture radar (SAR) data processing is crucial for high-resolution\nEarth observation and remote sensing applications, one of the most commonly\nused algorithms for this task is the Range Doppler Algorithm (RDA). Using the\nFast Fourier Transform (FFT), the collected signal is transformed to the\nfrequency domain and then goes through the processing steps of this algorithm.\nHowever, when it comes to large datasets, this process can be computationally\nexpensive. This paper explores the implementation of a Quantum Range Doppler\nAlgorithm (QRDA), relying on the Quantum Fourier Transform (QFT) as a speedup\ntool over the classical FFT. Additionally, it proposes a quantum version of the\nRange Cell Migration Correction (RCMC) in the Fourier domain, one of the key\ncorrectional steps of the RDA algorithm, and compares it with its classical\ncounterpart.", "published": "2025-04-02 15:40:12", "link": "http://arxiv.org/abs/2504.01832v1", "categories": ["quant-ph", "eess.SP"], "primary_category": "quant-ph"}
{"title": "Antenna Selection for Enhancing Privacy in Radar-Based Vital Sign Monitoring Systems", "abstract": "Radar-based vital sign monitoring (VSM) systems have become valuable for\nnon-contact health monitoring by detecting physiological activities, such as\nrespiration and heartbeat, remotely. However, the conventional phased array\nused in VSM is vulnerable to privacy breaches, as an eavesdropper can extract\nsensitive vital sign information by analyzing the reflected radar signals. In\nthis paper, we propose a novel approach to protect privacy in radar-based VSM\nby modifying the radar transmitter hardware, specifically by strategically\nselecting the transmit antennas from the available antennas in the transmit\narray. By dynamically selecting which antennas connect or disconnect to the\nradio frequency chain, the transmitter introduces additional phase noise to the\nradar echoes, generating false frequencies in the power spectrum of the\nextracted phases at the eavesdropper's receiver. The antenna activation pattern\nis designed to maximize the variance of the phases introduced by antenna\nselection, which effectively makes the false frequencies dominate the spectrum,\nobscuring the actual vital sign frequencies. Meanwhile, the authorized\nreceiver, having knowledge of the antenna selection pattern, can compensate for\nthe phase noise and accurately extract the vital signs. Numerical experiments\nare conducted to validate the effectiveness of the proposed approach in\nenhancing privacy while maintaining vital sign monitoring.", "published": "2025-04-02 15:28:07", "link": "http://arxiv.org/abs/2504.01820v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Satellite Edge Artificial Intelligence with Large Models: Architectures and Technologies", "abstract": "Driven by the growing demand for intelligent remote sensing applications,\nlarge artificial intelligence (AI) models pre-trained on large-scale unlabeled\ndatasets and fine-tuned for downstream tasks have significantly improved\nlearning performance for various downstream tasks due to their generalization\ncapabilities. However, many specific downstream tasks, such as extreme weather\nnowcasting (e.g., downburst and tornado), disaster monitoring, and battlefield\nsurveillance, require real-time data processing. Traditional methods via\ntransferring raw data to ground stations for processing often cause significant\nissues in terms of latency and trustworthiness. To address these challenges,\nsatellite edge AI provides a paradigm shift from ground-based to on-board data\nprocessing by leveraging the integrated communication-and-computation\ncapabilities in space computing power networks (Space-CPN), thereby enhancing\nthe timeliness, effectiveness, and trustworthiness for remote sensing\ndownstream tasks. Moreover, satellite edge large AI model (LAM) involves both\nthe training (i.e., fine-tuning) and inference phases, where a key challenge\nlies in developing computation task decomposition principles to support\nscalable LAM deployment in resource-constrained space networks with\ntime-varying topologies. In this article, we first propose a satellite\nfederated fine-tuning architecture to split and deploy the modules of LAM over\nspace and ground networks for efficient LAM fine-tuning. We then introduce a\nmicroservice-empowered satellite edge LAM inference architecture that\nvirtualizes LAM components into lightweight microservices tailored for\nmulti-task multimodal inference. Finally, we discuss the future directions for\nenhancing the efficiency and scalability of satellite edge LAM, including\ntask-oriented communication, brain-inspired computing, and satellite edge AI\nnetwork optimization.", "published": "2025-04-02 12:25:57", "link": "http://arxiv.org/abs/2504.01676v1", "categories": ["cs.LG", "cs.DC", "cs.NI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Identification of additive multivariable continuous-time systems", "abstract": "Multivariable parametric models are critical for designing, controlling, and\noptimizing the performance of engineered systems. The main objective of this\npaper is to develop a parametric identification strategy that delivers accurate\nand physically relevant models of multivariable systems using time-domain data.\nThe introduced approach adopts an additive model structure, offering a\nparsimonious and interpretable representation of many physical systems, and\nemploys a refined instrumental variable-based estimation algorithm. The\ndeveloped identification method enables the estimation of parametric\ncontinuous-time additive models and is applicable to both open and closed-loop\ncontrolled systems. The performance of the estimator is demonstrated through\nnumerical simulations and experimentally validated on a flexible beam system.", "published": "2025-04-02 11:43:38", "link": "http://arxiv.org/abs/2504.01639v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SpikeSift: A Computationally Efficient and Drift-Resilient Spike Sorting Algorithm", "abstract": "Spike sorting is a fundamental step in analyzing extracellular recordings,\nenabling the isolation of individual neuronal activity, yet it remains a\nchallenging problem due to overlapping signals and recording instabilities,\nincluding electrode drift. While numerous algorithms have been developed to\naddress these challenges, many struggle to balance accuracy and computational\nefficiency, limiting their applicability to largescale datasets. In response,\nwe introduce SpikeSift, a novel spike sorting algorithm designed to mitigate\ndrift by partitioning recordings into short, relatively stationary segments,\nwith spikes subsequently sorted within each. To preserve neuronal identity\nacross segment boundaries, a computationally efficient alignment process merges\nclusters without relying on continuous trajectory estimation. In contrast to\nconventional methods that separate spike detection from clustering, SpikeSift\nintegrates these processes within an iterative detect-andsubtract framework,\nenhancing clustering accuracy while maintaining computational efficiency.\nEvaluations on intracellularly validated datasets and biophysically realistic\nMEArec simulations confirm that SpikeSift maintains high sorting accuracy even\nin the presence of electrode drift, providing a scalable and computationally\nefficient solution for large-scale extracellular recordings", "published": "2025-04-02 11:16:28", "link": "http://arxiv.org/abs/2504.01604v1", "categories": ["eess.SP", "q-bio.NC"], "primary_category": "eess.SP"}
{"title": "Decoding Covert Speech from EEG Using a Functional Areas Spatio-Temporal Transformer", "abstract": "Covert speech involves imagining speaking without audible sound or any\nmovements. Decoding covert speech from electroencephalogram (EEG) is\nchallenging due to a limited understanding of neural pronunciation mapping and\nthe low signal-to-noise ratio of the signal. In this study, we developed a\nlarge-scale multi-utterance speech EEG dataset from 57 right-handed native\nEnglish-speaking subjects, each performing covert and overt speech tasks by\nrepeating the same word in five utterances within a ten-second duration. Given\nthe spatio-temporal nature of the neural activation process during speech\npronunciation, we developed a Functional Areas Spatio-temporal Transformer\n(FAST), an effective framework for converting EEG signals into tokens and\nutilizing transformer architecture for sequence encoding. Our results reveal\ndistinct and interpretable speech neural features by the visualization of\nFAST-generated activation maps across frontal and temporal brain regions with\neach word being covertly spoken, providing new insights into the discriminative\nfeatures of the neural representation of covert speech. This is the first\nreport of such a study, which provides interpretable evidence for speech\ndecoding from EEG. The code for this work has been made public at\nhttps://github.com/Jiang-Muyun/FAST", "published": "2025-04-02 10:38:08", "link": "http://arxiv.org/abs/2504.03762v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Augmentation of EEG and ECG Time Series for Deep Learning Applications: Integrating Changepoint Detection into the iAAFT Surrogates", "abstract": "The performance of deep learning methods critically depends on the quality\nand quantity of the available training data. This is especially the case for\nphysiological time series, which are both noisy and scarce, which calls for\ndata augmentation to artificially increase the size of datasets. Another issue\nis that the time-evolving statistical properties of nonstationary signals\nprevent the use of standard data augmentation techniques. To this end, we\nintroduce a novel method for augmenting nonstationary time series. This is\nachieved by combining offline changepoint detection with the iterative\namplitude-adjusted Fourier transform (iAAFT), which ensures that the\ntime-frequency properties of the original signal are preserved during\naugmentation. The proposed method is validated through comparisons of the\nperformance of i) a deep learning seizure detection algorithm on both the\noriginal and augmented versions of the CHB-MIT and Siena scalp\nelectroencephalography (EEG) databases, and ii) a deep learning atrial\nfibrillation (AF) detection algorithm on the original and augmented versions of\nthe Computing in Cardiology Challenge 2017 dataset. By virtue of the proposed\nmethod, for the CHB-MIT and Siena datasets respectively, accuracy rose by 4.4%\nand 1.9%, precision by 10% and 5.5%, recall by 3.6% and 0.9%, and F1 by 4.2%\nand 1.4%. For the AF classification task, accuracy rose by 0.3%, precision by\n2.1%, recall by 0.8%, and F1 by 2.1%.", "published": "2025-04-02 09:40:04", "link": "http://arxiv.org/abs/2504.03761v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "A Novel Pilot Allocation Technique for Uplink OFDMA in ISAC Systems", "abstract": "In integrated sensing and communication (ISAC) systems, pilot signals play a\ncrucial role in enhancing sensing performance due to their strong\nautocorrelation properties and high transmission power. However, conventional\ninterleaved pilots inherently constrain the maximum unambiguous range and\nreduce the accuracy of channel impulse response (CIR) estimation compared to\ncontinuous orthogonal frequency-division multiple access (OFDMA) signals. To\naddress this challenge, we propose a novel overlapped block-pilot structure for\nuplink OFDMA-based ISAC systems, called phase-shifted ISAC (PS-ISAC) pilot\nallocation. The proposed method leverages a cyclic prefix (CP)-based\nphase-shifted pilot design, enabling efficient multi-transmitter pilot\nseparation at the receiver. Simulation results confirm that the proposed scheme\nenhances CIR separation, reduces computational complexity, and improves mean\nsquare error (MSE) performance under practical power constraints. Furthermore,\nwe demonstrate that utilizing continuous pilot resources maximizes the\nunambiguous range.", "published": "2025-04-02 08:39:28", "link": "http://arxiv.org/abs/2504.01488v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Coarse-to-Fine Semantic Communication Systems for Text Transmission", "abstract": "Achieving more powerful semantic representations and semantic understanding\nis one of the key problems in improving the performance of semantic\ncommunication systems. This work focuses on enhancing the semantic\nunderstanding of the text data to improve the effectiveness of semantic\nexchange. We propose a novel semantic communication system for text\ntransmission, in which the semantic understanding is enhanced by coarse-to-fine\nprocessing. Especially, a dual attention mechanism is proposed to capture both\nthe coarse and fine semantic information. Numerical experiments show the\nproposed system outperforms the benchmarks in terms of bilingual evaluation,\nsentence similarity, and robustness under various channel conditions.", "published": "2025-04-02 07:50:35", "link": "http://arxiv.org/abs/2504.01442v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "EEG2GAIT: A Hierarchical Graph Convolutional Network for EEG-based Gait Decoding", "abstract": "Decoding gait dynamics from EEG signals presents significant challenges due\nto the complex spatial dependencies of motor processes, the need for accurate\ntemporal and spectral feature extraction, and the scarcity of high-quality gait\nEEG datasets. To address these issues, we propose EEG2GAIT, a novel\nhierarchical graph-based model that captures multi-level spatial embeddings of\nEEG channels using a Hierarchical Graph Convolutional Network (GCN) Pyramid. To\nfurther improve decoding accuracy, we introduce a Hybrid Temporal-Spectral\nReward (HTSR) loss function, which combines time-domain, frequency-domain, and\nreward-based loss components. Moreover, we contribute a new Gait-EEG Dataset\n(GED), consisting of synchronized EEG and lower-limb joint angle data collected\nfrom 50 participants over two lab visits. Validation experiments on both the\nGED and the publicly available Mobile Brain-body imaging (MoBI) dataset\ndemonstrate that EEG2GAIT outperforms state-of-the-art methods and achieves the\nbest joint angle prediction. Ablation studies validate the contributions of the\nhierarchical GCN modules and HTSR Loss, while saliency maps reveal the\nsignificance of motor-related brain regions in decoding tasks. These findings\nunderscore EEG2GAIT's potential for advancing brain-computer interface\napplications, particularly in lower-limb rehabilitation and assistive\ntechnologies.", "published": "2025-04-02 07:48:21", "link": "http://arxiv.org/abs/2504.03757v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Simultaneous Pre-compensation for Bandwidth Limitation and Fiber Dispersion in Cost-Sensitive IM/DD Transmission Systems", "abstract": "We propose a pre-compensation scheme for bandwidth limitation and fiber\ndispersion (pre-BL-EDC) based on the modified Gerchberg-Saxton (GS) algorithm.\nExperimental results demonstrate 1.0/1.0/2.0 dB gains compared to modified GS\npre-EDC for 20/28/32 Gbit/s bandwidth-limited systems.", "published": "2025-04-02 05:37:57", "link": "http://arxiv.org/abs/2504.01375v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Reconfigurable Codebook-Based Beamforming for RDARS-Aided mmWave MU-MIMO Systems", "abstract": "Reconfigurable distributed antenna and reflecting surface (RDARS) is a new\narchitecture for the sixth-generation (6G) millimeter wave (mmWave)\ncommunications. In RDARS-aided mmWave systems, the active and passive\nbeamforming design and working mode configuration for reconfigurable elements\nare crucial for system performance. In this paper, we aim to maximize the\nweighted sum rate (WSR) in the RDARS-aided mmWave system. To take advantage of\nRDARS, we first design a reconfigurable codebook (RCB) in which the number and\ndimension of the codeword can be flexibly adjusted. Then, a low overhead beam\ntraining scheme based on hierarchical search is proposed. Accordingly, the\nactive and passive beamforming for data transmission is designed to achieve the\nmaximum WSR for both space-division multiple access (SDMA) and time-division\nmultiple access (TDMA) schemes. For the TDMA scheme, the optimal number of\nRDARS transmit elements and the allocated power budget for WSR maximization are\nderived in closed form. Besides, the superiority of the RDARS is verified and\nthe conditions under which RDARS outperforms RIS and DAS are given. For the\nSDMA scheme, we characterize the relationship between the number of RDARS\nconnected elements and the user distribution, followed by the derivation of the\noptimal placement positions of the RDARS transmit elements. High-quality\nbeamforming design solutions are derived to minimize the inter-user\ninterference (IUI) at the base station and RDARS side respectively, which\nnearly leads to the maximal WSR. Finally, simulation results confirm our\ntheoretical findings and the superiority of the proposed schemes.", "published": "2025-04-02 03:40:37", "link": "http://arxiv.org/abs/2504.01333v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Flexible and Explainable Graph Analysis for EEG-based Alzheimer's Disease Classification", "abstract": "Alzheimer's Disease is a progressive neurological disorder that is one of the\nmost common forms of dementia. It leads to a decline in memory, reasoning\nability, and behavior, especially in older people. The cause of Alzheimer's\nDisease is still under exploration and there is no all-inclusive theory that\ncan explain the pathologies in each individual patient. Nevertheless, early\nintervention has been found to be effective in managing symptoms and slowing\ndown the disease's progression. Recent research has utilized\nelectroencephalography (EEG) data to identify biomarkers that distinguish\nAlzheimer's Disease patients from healthy individuals. Prior studies have used\nvarious machine learning methods, including deep learning and graph neural\nnetworks, to examine electroencephalography-based signals for identifying\nAlzheimer's Disease patients. In our research, we proposed a Flexible and\nExplainable Gated Graph Convolutional Network (GGCN) with Multi-Objective\nTree-Structured Parzen Estimator (MOTPE) hyperparameter tuning. This provides a\nflexible solution that efficiently identifies the optimal number of GGCN blocks\nto achieve the optimized precision, specificity, and recall outcomes, as well\nas the optimized area under the Receiver Operating Characteristic (AUC). Our\nfindings demonstrated a high efficacy with an over 0.9 Receiver Operating\nCharacteristic score, alongside precision, specificity, and recall scores in\ndistinguishing health control with Alzheimer's Disease patients in Moderate to\nSevere Dementia using the power spectrum density (PSD) of\nelectroencephalography signals across various frequency bands. Moreover, our\nresearch enhanced the interpretability of the embedded adjacency matrices,\nrevealing connectivity differences in frontal and parietal brain regions\nbetween Alzheimer's patients and healthy individuals.", "published": "2025-04-02 03:29:12", "link": "http://arxiv.org/abs/2504.01329v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Low-Complexity Channel Estimation for RIS-Assisted ISAC System", "abstract": "Integrated sensing and communication (ISAC), assisted by reconfigurable\nintelligent surface (RIS) has emerged as a breakthrough technology to improve\nthe capacity and reliability of 6G wireless network. However, a significant\nchallenge in RIS-ISAC systems is the acquisition of channel state information\n(CSI), largely due to co-channel interference, which hinders meeting the\nrequired reliability standards. To address this issue, a minimax-concave\npenalty (MCP)-based CSI refinement scheme is proposed. This approach utilizes\nan element-grouping strategy to jointly estimate the ISAC channel and the RIS\nphase shift matrix. Unlike previous methods, our scheme exploits the inherent\nsparsity in RIS-assisted ISAC channels to reduce training overhead, and the\nnear-optimal solution is derived for our studied RIS-ISAC scheme. The\neffectiveness of the element-grouping strategy is validated through simulation\nexperiments, demonstrating superior channel estimation results when compared to\nexisting benchmarks.", "published": "2025-04-02 02:57:05", "link": "http://arxiv.org/abs/2504.01315v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Online Fault Detection and Classification of Chemical Process Systems Leveraging Statistical Process Control and Riemannian Geometric Analysis", "abstract": "In this work, we study an integrated fault detection and classification\nframework called FARM for fast, accurate, and robust online chemical process\nmonitoring. The FARM framework integrates the latest advancements in\nstatistical process control (SPC) for monitoring nonparametric and\nheterogeneous data streams with novel data analysis approaches based on\nRiemannian geometry together in a hierarchical framework for online process\nmonitoring. We conduct a systematic evaluation of the FARM monitoring framework\nusing the Tennessee Eastman Process (TEP) dataset. Results show that FARM\nperforms competitively against state-of-the-art process monitoring algorithms\nby achieving a good balance among fault detection rate (FDR), fault detection\nspeed (FDS), and false alarm rate (FAR). Specifically, FARM achieved an average\nFDR of 96.97% while also outperforming benchmark methods in successfully\ndetecting hard-to-detect faults that are previously known, including Faults 3,\n9 and 15, with FDRs being 97.08%, 96.30% and 95.99%, respectively. In terms of\nFAR, our FARM framework allows practitioners to customize their choice of FAR,\nthereby offering great flexibility. Moreover, we report a significant\nimprovement in average fault classification accuracy during online monitoring\nfrom 61% to 82% when leveraging Riemannian geometric analysis, and further to\n84.5% when incorporating additional features from SPC. This illustrates the\nsynergistic effect of integrating fault detection and classification in a\nholistic, hierarchical monitoring framework.", "published": "2025-04-02 01:00:36", "link": "http://arxiv.org/abs/2504.01276v1", "categories": ["eess.SP", "stat.OT"], "primary_category": "eess.SP"}
{"title": "DeepSeek-R1 Thoughtology: Let's <think> about LLM Reasoning", "abstract": "Large Reasoning Models like DeepSeek-R1 mark a fundamental shift in how LLMs\napproach complex problems. Instead of directly producing an answer for a given\ninput, DeepSeek-R1 creates detailed multi-step reasoning chains, seemingly\n\"thinking\" about a problem before providing an answer. This reasoning process\nis publicly available to the user, creating endless opportunities for studying\nthe reasoning behaviour of the model and opening up the field of Thoughtology.\nStarting from a taxonomy of DeepSeek-R1's basic building blocks of reasoning,\nour analyses on DeepSeek-R1 investigate the impact and controllability of\nthought length, management of long or confusing contexts, cultural and safety\nconcerns, and the status of DeepSeek-R1 vis-\\`a-vis cognitive phenomena, such\nas human-like language processing and world modelling. Our findings paint a\nnuanced picture. Notably, we show DeepSeek-R1 has a 'sweet spot' of reasoning,\nwhere extra inference time can impair model performance. Furthermore, we find a\ntendency for DeepSeek-R1 to persistently ruminate on previously explored\nproblem formulations, obstructing further exploration. We also note strong\nsafety vulnerabilities of DeepSeek-R1 compared to its non-reasoning\ncounterpart, which can also compromise safety-aligned LLMs.", "published": "2025-04-02 00:36:08", "link": "http://arxiv.org/abs/2504.07128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ToM-RL: Reinforcement Learning Unlocks Theory of Mind in Small LLMs", "abstract": "Recent advancements in rule-based reinforcement learning (RL), applied during\nthe post-training phase of large language models (LLMs), have significantly\nenhanced their capabilities in structured reasoning tasks such as mathematics\nand logical inference. However, the effectiveness of RL in social reasoning,\nparticularly in Theory of Mind (ToM), the ability to infer others' mental\nstates, remains largely unexplored. In this study, we demonstrate that RL\nmethods effectively unlock ToM reasoning capabilities even in small-scale LLMs\n(0.5B to 7B parameters). Using a modest dataset comprising 3200 questions\nacross diverse scenarios, our RL-trained 7B model achieves 84.50\\% accuracy on\nthe Hi-ToM benchmark, surpassing models like GPT-4o and DeepSeek-v3 despite\nsignificantly fewer parameters. While smaller models ($\\leq$3B parameters)\nsuffer from reasoning collapse, larger models (7B parameters) maintain stable\nperformance through consistent belief tracking. Additionally, our RL-based\nmodels demonstrate robust generalization to higher-order, out-of-distribution\nToM problems, novel textual presentations, and previously unseen datasets.\nThese findings highlight RL's potential to enhance social cognitive reasoning,\nbridging the gap between structured problem-solving and nuanced social\ninference in LLMs.", "published": "2025-04-02 12:58:42", "link": "http://arxiv.org/abs/2504.01698v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Jointly Exchangeable Collective Risk Models: Interaction, Structure, and Limit Theorems", "abstract": "We introduce a framework for systemic risk modeling in insurance portfolios\nusing jointly exchangeable arrays, extending classical collective risk models\nto account for interactions. We establish central limit theorems that\nasymptotically characterize total portfolio losses, providing a theoretical\nfoundation for approximations in large portfolios and over long time horizons.\nThese approximations are validated through simulation-based numerical\nexperiments. Additionally, we analyze the impact of dependence on portfolio\nloss distributions, with a particular focus on tail behavior.", "published": "2025-04-02 09:53:16", "link": "http://arxiv.org/abs/2504.06287v1", "categories": ["q-fin.RM", "math.PR", "q-fin.MF", "91G45, 60F05"], "primary_category": "q-fin.RM"}
{"title": "Hyperbolic Diffusion Recommender Model", "abstract": "Diffusion models (DMs) have emerged as the new state-of-the-art family of\ndeep generative models. To gain deeper insights into the limitations of\ndiffusion models in recommender systems, we investigate the fundamental\nstructural disparities between images and items. Consequently, items often\nexhibit distinct anisotropic and directional structures that are less prevalent\nin images. However, the traditional forward diffusion process continuously adds\nisotropic Gaussian noise, causing anisotropic signals to degrade into noise,\nwhich impairs the semantically meaningful representations in recommender\nsystems.\n  Inspired by the advancements in hyperbolic spaces, we propose a novel\n\\textit{\\textbf{H}yperbolic} \\textit{\\textbf{D}iffusion}\n\\textit{\\textbf{R}ecommender} \\textit{\\textbf{M}odel} (named HDRM). Unlike\nexisting directional diffusion methods based on Euclidean space, the intrinsic\nnon-Euclidean structure of hyperbolic space makes it particularly well-adapted\nfor handling anisotropic diffusion processes. In particular, we begin by\nformulating concepts to characterize latent directed diffusion processes within\na geometrically grounded hyperbolic space. Subsequently, we propose a novel\nhyperbolic latent diffusion process specifically tailored for users and items.\nDrawing upon the natural geometric attributes of hyperbolic spaces, we impose\nstructural restrictions on the space to enhance hyperbolic diffusion\npropagation, thereby ensuring the preservation of the intrinsic topology of\nuser-item graphs. Extensive experiments on three benchmark datasets demonstrate\nthe effectiveness of HDRM.", "published": "2025-04-02 09:27:40", "link": "http://arxiv.org/abs/2504.01541v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
