{"title": "A Large-scale Dataset for Hate Speech Detection on Vietnamese Social\n  Media Texts", "abstract": "In recent years, Vietnam witnesses the mass development of social network\nusers on different social platforms such as Facebook, Youtube, Instagram, and\nTiktok. On social medias, hate speech has become a critical problem for social\nnetwork users. To solve this problem, we introduce the ViHSD - a\nhuman-annotated dataset for automatically detecting hate speech on the social\nnetwork. This dataset contains over 30,000 comments, each comment in the\ndataset has one of three labels: CLEAN, OFFENSIVE, or HATE. Besides, we\nintroduce the data creation process for annotating and evaluating the quality\nof the dataset. Finally, we evaluated the dataset by deep learning models and\ntransformer models.", "published": "2021-03-22 00:55:47", "link": "http://arxiv.org/abs/2103.11528v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SparseGAN: Sparse Generative Adversarial Network for Text Generation", "abstract": "It is still a challenging task to learn a neural text generation model under\nthe framework of generative adversarial networks (GANs) since the entire\ntraining process is not differentiable. The existing training strategies either\nsuffer from unreliable gradient estimations or imprecise sentence\nrepresentations. Inspired by the principle of sparse coding, we propose a\nSparseGAN that generates semantic-interpretable, but sparse sentence\nrepresentations as inputs to the discriminator. The key idea is that we treat\nan embedding matrix as an over-complete dictionary, and use a linear\ncombination of very few selected word embeddings to approximate the output\nfeature representation of the generator at each time step. With such\nsemantic-rich representations, we not only reduce unnecessary noises for\nefficient adversarial training, but also make the entire training process fully\ndifferentiable. Experiments on multiple text generation datasets yield\nperformance improvements, especially in sequence-level metrics, such as BLEU.", "published": "2021-03-22 04:44:43", "link": "http://arxiv.org/abs/2103.11578v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monolingual and Parallel Corpora for Kangri Low Resource Language", "abstract": "In this paper we present the dataset of Himachali low resource endangered\nlanguage, Kangri (ISO 639-3xnr) listed in the United Nations Educational,\nScientific and Cultural Organization (UNESCO). The compilation of kangri corpus\nhas been a challenging task due to the non-availability of the digitalized\nresources. The corpus contains 1,81,552 Monolingual and 27,362 Hindi-Kangri\nParallel corpora. We shared pre-trained kangri word embeddings. We also\nreported the Bilingual Evaluation Understudy (BLEU) score and Metric for\nEvaluation of Translation with Explicit ORdering (METEOR) score of Statistical\nMachine Translation (SMT) and Neural Machine Translation (NMT) results for the\ncorpus. The corpus is freely available for non-commercial usages and research.\nTo the best of our knowledge, this is the first Himachali low resource\nendangered language corpus. The resources are available at\n(https://github.com/chauhanshweta/Kangri_corpus)", "published": "2021-03-22 05:52:51", "link": "http://arxiv.org/abs/2103.11596v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alleviate Exposure Bias in Sequence Prediction \\\\ with Recurrent Neural\n  Networks", "abstract": "A popular strategy to train recurrent neural networks (RNNs), known as\n``teacher forcing'' takes the ground truth as input at each time step and makes\nthe later predictions partly conditioned on those inputs. Such training\nstrategy impairs their ability to learn rich distributions over entire\nsequences because the chosen inputs hinders the gradients back-propagating to\nall previous states in an end-to-end manner. We propose a fully differentiable\ntraining algorithm for RNNs to better capture long-term dependencies by\nrecovering the probability of the whole sequence. The key idea is that at each\ntime step, the network takes as input a ``bundle'' of similar words predicted\nat the previous step instead of a single ground truth. The representations of\nthese similar words forms a convex hull, which can be taken as a kind of\nregularization to the input. Smoothing the inputs by this way makes the whole\nprocess trainable and differentiable. This design makes it possible for the\nmodel to explore more feasible combinations (possibly unseen sequences), and\ncan be interpreted as a computationally efficient approximation to the beam\nsearch. Experiments on multiple sequence generation tasks yield performance\nimprovements, especially in sequence-level metrics, such as BLUE or ROUGE-2.", "published": "2021-03-22 06:15:22", "link": "http://arxiv.org/abs/2103.11603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Complementary Evidence Identification in Open-Domain Question Answering", "abstract": "This paper proposes a new problem of complementary evidence identification\nfor open-domain question answering (QA). The problem aims to efficiently find a\nsmall set of passages that covers full evidence from multiple aspects as to\nanswer a complex question. To this end, we proposes a method that learns vector\nrepresentations of passages and models the sufficiency and diversity within the\nselected set, in addition to the relevance between the question and passages.\nOur experiments demonstrate that our method considers the dependence within the\nsupporting evidence and significantly improves the accuracy of complementary\nevidence selection in QA domain.", "published": "2021-03-22 08:04:50", "link": "http://arxiv.org/abs/2103.11643v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging the gap between supervised classification and unsupervised\n  topic modelling for social-media assisted crisis management", "abstract": "Social media such as Twitter provide valuable information to crisis managers\nand affected people during natural disasters. Machine learning can help\nstructure and extract information from the large volume of messages shared\nduring a crisis; however, the constantly evolving nature of crises makes\neffective domain adaptation essential. Supervised classification is limited by\nunchangeable class labels that may not be relevant to new events, and\nunsupervised topic modelling by insufficient prior knowledge. In this paper, we\nbridge the gap between the two and show that BERT embeddings finetuned on\ncrisis-related tweet classification can effectively be used to adapt to a new\ncrisis, discovering novel topics while preserving relevant classes from\nsupervised training, and leveraging bidirectional self-attention to extract\ntopic keywords. We create a dataset of tweets from a snowstorm to evaluate our\nmethod's transferability to new crises, and find that it outperforms\ntraditional topic models in both automatic, and human evaluations grounded in\nthe needs of crisis managers. More broadly, our method can be used for textual\ndomain adaptation where the latent classes are unknown but overlap with known\nclasses from other domains.", "published": "2021-03-22 13:30:39", "link": "http://arxiv.org/abs/2103.11835v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monitoring Covid-19 on social media using a novel triage and diagnosis\n  approach", "abstract": "Objective: This study aims to develop an end-to-end natural language\nprocessing pipeline for triage and diagnosis of COVID-19 from patient-authored\nsocial media posts, in order to provide researchers and public health\npractitioners with additional information on the symptoms, severity and\nprevalence of the disease rather than to provide an actionable decision at the\nindividual level. Materials and Methods: The text processing pipeline first\nextracts COVID-19 symptoms and related concepts such as severity, duration,\nnegations, and body parts from patients' posts using conditional random fields.\nAn unsupervised rule-based algorithm is then applied to establish relations\nbetween concepts in the next step of the pipeline. The extracted concepts and\nrelations are subsequently used to construct two different vector\nrepresentations of each post. These vectors are applied separately to build\nsupport vector machine learning models to triage patients into three categories\nand diagnose them for COVID-19. Results: We report that macro- and\nmicro-averaged F1 scores in the range of 71-96% and 61-87%, respectively, for\nthe triage and diagnosis of COVID-19, when the models are trained on human\nlabelled data. Our experimental results indicate that similar performance can\nbe achieved when the models are trained using predicted labels from concept\nextraction and rule-based classifiers, thus yielding end-to-end machine\nlearning. Also, we highlight important features uncovered by our diagnostic\nmachine learning models and compare them with the most frequent symptoms\nrevealed in another COVID-19 dataset. In particular, we found that the most\nimportant features are not always the most frequent ones.", "published": "2021-03-22 13:46:16", "link": "http://arxiv.org/abs/2103.11850v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nutri-bullets: Summarizing Health Studies by Composing Segments", "abstract": "We introduce \\emph{Nutri-bullets}, a multi-document summarization task for\nhealth and nutrition. First, we present two datasets of food and health\nsummaries from multiple scientific studies. Furthermore, we propose a novel\n\\emph{extract-compose} model to solve the problem in the regime of limited\nparallel data. We explicitly select key spans from several abstracts using a\npolicy network, followed by composing the selected spans to present a summary\nvia a task specific language model. Compared to state-of-the-art methods, our\napproach leads to more faithful, relevant and diverse summarization --\nproperties imperative to this application. For instance, on the BreastCancer\ndataset our approach gets a more than 50\\% improvement on relevance and\nfaithfulness.\\footnote{Our code and data is available at\n\\url{https://github.com/darsh10/Nutribullets.}}", "published": "2021-03-22 15:08:46", "link": "http://arxiv.org/abs/2103.11921v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Domain Question Answering over Tables via Dense Retrieval", "abstract": "Recent advances in open-domain QA have led to strong models based on dense\nretrieval, but only focused on retrieving textual passages. In this work, we\ntackle open-domain QA over tables for the first time, and show that retrieval\ncan be improved by a retriever designed to handle tabular context. We present\nan effective pre-training procedure for our retriever and improve retrieval\nquality with mined hard negatives. As relevant datasets are missing, we extract\na subset of Natural Questions (Kwiatkowski et al., 2019) into a Table QA\ndataset. We find that our retriever improves retrieval results from 72.0 to\n81.1 recall@10 and end-to-end QA results from 33.8 to 37.7 exact match, over a\nBERT based retriever.", "published": "2021-03-22 17:01:04", "link": "http://arxiv.org/abs/2103.12011v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating False-Negative Contexts in Multi-document Question Answering\n  with Retrieval Marginalization", "abstract": "Question Answering (QA) tasks requiring information from multiple documents\noften rely on a retrieval model to identify relevant information for reasoning.\nThe retrieval model is typically trained to maximize the likelihood of the\nlabeled supporting evidence. However, when retrieving from large text corpora\nsuch as Wikipedia, the correct answer can often be obtained from multiple\nevidence candidates. Moreover, not all such candidates are labeled as positive\nduring annotation, rendering the training signal weak and noisy. This problem\nis exacerbated when the questions are unanswerable or when the answers are\nBoolean, since the model cannot rely on lexical overlap to make a connection\nbetween the answer and supporting evidence. We develop a new parameterization\nof set-valued retrieval that handles unanswerable queries, and we show that\nmarginalizing over this set during training allows a model to mitigate false\nnegatives in supporting evidence annotations. We test our method on two\nmulti-document QA datasets, IIRC and HotpotQA. On IIRC, we show that joint\nmodeling with marginalization improves model performance by 5.5 F1 points and\nachieves a new state-of-the-art performance of 50.5 F1. We also show that\nretrieval marginalization results in 4.1 QA F1 improvement over a\nnon-marginalized baseline on HotpotQA in the fullwiki setting.", "published": "2021-03-22 23:44:35", "link": "http://arxiv.org/abs/2103.12235v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prototypical Representation Learning for Relation Extraction", "abstract": "Recognizing relations between entities is a pivotal task of relational\nlearning. Learning relation representations from distantly-labeled datasets is\ndifficult because of the abundant label noise and complicated expressions in\nhuman language. This paper aims to learn predictive, interpretable, and robust\nrelation representations from distantly-labeled data that are effective in\ndifferent settings, including supervised, distantly supervised, and few-shot\nlearning. Instead of solely relying on the supervision from noisy labels, we\npropose to learn prototypes for each relation from contextual information to\nbest explore the intrinsic semantics of relations. Prototypes are\nrepresentations in the feature space abstracting the essential semantics of\nrelations between entities in sentences. We learn prototypes based on\nobjectives with clear geometric interpretation, where the prototypes are unit\nvectors uniformly dispersed in a unit ball, and statement embeddings are\ncentered at the end of their corresponding prototype vectors on the surface of\nthe ball. This approach allows us to learn meaningful, interpretable prototypes\nfor the final classification. Results on several relation learning tasks show\nthat our model significantly outperforms the previous state-of-the-art models.\nWe further demonstrate the robustness of the encoder and the interpretability\nof prototypes with extensive experiments.", "published": "2021-03-22 08:11:43", "link": "http://arxiv.org/abs/2103.11647v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MasakhaNER: Named Entity Recognition for African Languages", "abstract": "We take a step towards addressing the under-representation of the African\ncontinent in NLP research by creating the first large publicly available\nhigh-quality dataset for named entity recognition (NER) in ten African\nlanguages, bringing together a variety of stakeholders. We detail\ncharacteristics of the languages to help researchers understand the challenges\nthat these languages pose for NER. We analyze our datasets and conduct an\nextensive empirical evaluation of state-of-the-art methods across both\nsupervised and transfer learning settings. We release the data, code, and\nmodels in order to inspire future research on African NLP.", "published": "2021-03-22 13:12:44", "link": "http://arxiv.org/abs/2103.11811v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Part of speech and gramset tagging algorithms for unknown words based on\n  morphological dictionaries of the Veps and Karelian languages", "abstract": "This research devoted to the low-resource Veps and Karelian languages.\nAlgorithms for assigning part of speech tags to words and grammatical\nproperties to words are presented in the article. These algorithms use our\nmorphological dictionaries, where the lemma, part of speech and a set of\ngrammatical features (gramset) are known for each word form. The algorithms are\nbased on the analogy hypothesis that words with the same suffixes are likely to\nhave the same inflectional models, the same part of speech and gramset. The\naccuracy of these algorithms were evaluated and compared. 313 thousand Vepsian\nand 66 thousand Karelian words were used to verify the accuracy of these\nalgorithms. The special functions were designed to assess the quality of\nresults of the developed algorithms. 92.4% of Vepsian words and 86.8% of\nKarelian words were assigned a correct part of speech by the developed\nalgorithm. 95.3% of Vepsian words and 90.7% of Karelian words were assigned a\ncorrect gramset by our algorithm. Morphological and semantic tagging of texts,\nwhich are closely related and inseparable in our corpus processes, are\ndescribed in the paper.", "published": "2021-03-22 13:58:46", "link": "http://arxiv.org/abs/2103.11859v1", "categories": ["cs.CL", "cs.IR", "68T50", "H.3.1; H.3.6"], "primary_category": "cs.CL"}
{"title": "#LaCulturaNonsiFerma: Report on Use and Diffusion of #Hashtags from the\n  Italian Cultural Institutions during the COVID-19 outbreak", "abstract": "This report presents an analysis of #hashtags used by Italian Cultural\nHeritage institutions to promote and communicate cultural content during the\nCOVID-19 lock-down period in Italy. Several activities to support and engage\nusers' have been proposed using social media. Most of these activities present\none or more #hashtags which help to aggregate content and create a community on\nspecific topics. Results show that on one side Italian institutions have been\nvery proactive in adapting to the pandemic scenario and on the other side\nusers' reacted very positively increasing their participation in the proposed\nactivities.", "published": "2021-03-22 14:02:57", "link": "http://arxiv.org/abs/2103.11865v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "BlonDe: An Automatic Evaluation Metric for Document-level Machine\n  Translation", "abstract": "Standard automatic metrics, e.g. BLEU, are not reliable for document-level MT\nevaluation. They can neither distinguish document-level improvements in\ntranslation quality from sentence-level ones, nor identify the discourse\nphenomena that cause context-agnostic translations. This paper introduces a\nnovel automatic metric BlonDe to widen the scope of automatic MT evaluation\nfrom sentence to document level. BlonDe takes discourse coherence into\nconsideration by categorizing discourse-related spans and calculating the\nsimilarity-based F1 measure of categorized spans. We conduct extensive\ncomparisons on a newly constructed dataset BWB. The experimental results show\nthat BlonDe possesses better selectivity and interpretability at the\ndocument-level, and is more sensitive to document-level nuances. In a\nlarge-scale human study, BlonDe also achieves significantly higher Pearson's r\ncorrelation with human judgments compared to previous metrics.", "published": "2021-03-22 14:14:58", "link": "http://arxiv.org/abs/2103.11878v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Retrieve Fast, Rerank Smart: Cooperative and Joint Approaches for\n  Improved Cross-Modal Retrieval", "abstract": "Current state-of-the-art approaches to cross-modal retrieval process text and\nvisual input jointly, relying on Transformer-based architectures with\ncross-attention mechanisms that attend over all words and objects in an image.\nWhile offering unmatched retrieval performance, such models: 1) are typically\npretrained from scratch and thus less scalable, 2) suffer from huge retrieval\nlatency and inefficiency issues, which makes them impractical in realistic\napplications. To address these crucial gaps towards both improved and efficient\ncross-modal retrieval, we propose a novel fine-tuning framework that turns any\npretrained text-image multi-modal model into an efficient retrieval model. The\nframework is based on a cooperative retrieve-and-rerank approach which\ncombines: 1) twin networks (i.e., a bi-encoder) to separately encode all items\nof a corpus, enabling efficient initial retrieval, and 2) a cross-encoder\ncomponent for a more nuanced (i.e., smarter) ranking of the retrieved small set\nof items. We also propose to jointly fine-tune the two components with shared\nweights, yielding a more parameter-efficient model. Our experiments on a series\nof standard cross-modal retrieval benchmarks in monolingual, multilingual, and\nzero-shot setups, demonstrate improved accuracy and huge efficiency benefits\nover the state-of-the-art cross-encoders.", "published": "2021-03-22 15:08:06", "link": "http://arxiv.org/abs/2103.11920v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets", "abstract": "With the success of large-scale pre-training and multilingual modeling in\nNatural Language Processing (NLP), recent years have seen a proliferation of\nlarge, web-mined text datasets covering hundreds of languages. We manually\naudit the quality of 205 language-specific corpora released with five major\npublic datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4). Lower-resource\ncorpora have systematic issues: At least 15 corpora have no usable text, and a\nsignificant fraction contains less than 50% sentences of acceptable quality. In\naddition, many are mislabeled or use nonstandard/ambiguous language codes. We\ndemonstrate that these issues are easy to detect even for non-proficient\nspeakers, and supplement the human audit with automatic analyses. Finally, we\nrecommend techniques to evaluate and improve multilingual corpora and discuss\npotential risks that come with low-quality data releases.", "published": "2021-03-22 17:30:33", "link": "http://arxiv.org/abs/2103.12028v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Extracting the Unknown from Long Math Problems", "abstract": "In problem solving, understanding the problem that one seeks to solve is an\nessential initial step. In this paper, we propose computational methods for\nfacilitating problem understanding through the task of recognizing the unknown\nin specifications of long Math problems. We focus on the topic of Probability.\nOur experimental results show that learning models yield strong results on the\ntask, a promising first step towards human interpretable, modular approaches to\nunderstanding long Math problems.", "published": "2021-03-22 17:51:10", "link": "http://arxiv.org/abs/2103.12048v3", "categories": ["cs.CL", "math.HO"], "primary_category": "cs.CL"}
{"title": "Grey-box Adversarial Attack And Defence For Sentiment Classification", "abstract": "We introduce a grey-box adversarial attack and defence framework for\nsentiment classification. We address the issues of differentiability, label\npreservation and input reconstruction for adversarial attack and defence in one\nunified framework. Our results show that once trained, the attacking model is\ncapable of generating high-quality adversarial examples substantially faster\n(one order of magnitude less in time) than state-of-the-art attacking methods.\nThese examples also preserve the original sentiment according to human\nevaluation. Additionally, our framework produces an improved classifier that is\nrobust in defending against multiple adversarial attacking methods. Code is\navailable at: https://github.com/ibm-aur-nlp/adv-def-text-dist.", "published": "2021-03-22 04:05:17", "link": "http://arxiv.org/abs/2103.11576v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Detection of fake news on CoViD-19 on Web Search Engines", "abstract": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.", "published": "2021-03-22 13:07:26", "link": "http://arxiv.org/abs/2103.11804v2", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Identifying Machine-Paraphrased Plagiarism", "abstract": "Employing paraphrasing tools to conceal plagiarized text is a severe threat\nto academic integrity. To enable the detection of machine-paraphrased text, we\nevaluate the effectiveness of five pre-trained word embedding models combined\nwith machine-learning classifiers and eight state-of-the-art neural language\nmodels. We analyzed preprints of research papers, graduation theses, and\nWikipedia articles, which we paraphrased using different configurations of the\ntools SpinBot and SpinnerChief. The best-performing technique, Longformer,\nachieved an average F1 score of 81.0% (F1=99.7% for SpinBot and F1=71.6% for\nSpinnerChief cases), while human evaluators achieved F1=78.4% for SpinBot and\nF1=65.6% for SpinnerChief cases. We show that the automated classification\nalleviates shortcomings of widely-used text-matching systems, such as Turnitin\nand PlagScan. To facilitate future research, all data, code, and two web\napplications showcasing our contributions are openly available at\nhttps://github.com/jpwahle/iconf22-paraphrase.", "published": "2021-03-22 14:54:54", "link": "http://arxiv.org/abs/2103.11909v7", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "BERT: A Review of Applications in Natural Language Processing and\n  Understanding", "abstract": "In this review, we describe the application of one of the most popular deep\nlearning-based language models - BERT. The paper describes the mechanism of\noperation of this model, the main areas of its application to the tasks of text\nanalytics, comparisons with similar models in each task, as well as a\ndescription of some proprietary models. In preparing this review, the data of\nseveral dozen original scientific articles published over the past few years,\nwhich attracted the most attention in the scientific community, were\nsystematized. This survey will be useful to all students and researchers who\nwant to get acquainted with the latest advances in the field of natural\nlanguage text analysis.", "published": "2021-03-22 15:34:39", "link": "http://arxiv.org/abs/2103.11943v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving and Simplifying Pattern Exploiting Training", "abstract": "Recently, pre-trained language models (LMs) have achieved strong performance\nwhen fine-tuned on difficult benchmarks like SuperGLUE. However, performance\ncan suffer when there are very few labeled examples available for fine-tuning.\nPattern Exploiting Training (PET) is a recent approach that leverages patterns\nfor few-shot learning. However, PET uses task-specific unlabeled data. In this\npaper, we focus on few-shot learning without any unlabeled data and introduce\nADAPET, which modifies PET's objective to provide denser supervision during\nfine-tuning. As a result, ADAPET outperforms PET on SuperGLUE without any\ntask-specific unlabeled data. Our code can be found at\nhttps://github.com/rrmenon10/ADAPET.", "published": "2021-03-22 15:52:45", "link": "http://arxiv.org/abs/2103.11955v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Human-like Controllable Image Captioning with Verb-specific Semantic\n  Roles", "abstract": "Controllable Image Captioning (CIC) -- generating image descriptions\nfollowing designated control signals -- has received unprecedented attention\nover the last few years. To emulate the human ability in controlling caption\ngeneration, current CIC studies focus exclusively on control signals concerning\nobjective properties, such as contents of interest or descriptive patterns.\nHowever, we argue that almost all existing objective control signals have\noverlooked two indispensable characteristics of an ideal control signal: 1)\nEvent-compatible: all visual contents referred to in a single sentence should\nbe compatible with the described activity. 2) Sample-suitable: the control\nsignals should be suitable for a specific image sample. To this end, we propose\na new control signal for CIC: Verb-specific Semantic Roles (VSR). VSR consists\nof a verb and some semantic roles, which represents a targeted activity and the\nroles of entities involved in this activity. Given a designated VSR, we first\ntrain a grounded semantic role labeling (GSRL) model to identify and ground all\nentities for each role. Then, we propose a semantic structure planner (SSP) to\nlearn human-like descriptive semantic structures. Lastly, we use a role-shift\ncaptioning model to generate the captions. Extensive experiments and ablations\ndemonstrate that our framework can achieve better controllability than several\nstrong baselines on two challenging CIC benchmarks. Besides, we can generate\nmulti-level diverse captions easily. The code is available at:\nhttps://github.com/mad-red/VSR-guided-CIC.", "published": "2021-03-22 22:17:42", "link": "http://arxiv.org/abs/2103.12204v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Musical Mix Clarity Predication using Decomposition and Perceptual\n  Masking Thresholds", "abstract": "Objective measurement of perceptually motivated music attributes has\napplication in both target driven mixing and mastering methodologies and music\ninformation retrieval. This work proposes a perceptual model of mix clarity\nwhich decomposes a mixed input signal into transient, steady-state, and\nresidual components. Masking thresholds are calculated for each component and\ntheir relative relationship is used to determine an overall masking score as\nthe model's output. Three variants of the model were tested against subjective\nmix clarity scores gathered from a controlled listening test. The best\nperforming variant achieved a Spearman's rank correlation of rho = 0.8382\n(p<0.01). Furthermore, the model output was analysed using an independent\ndataset generated by progressively applying degradation effects to the test\nstimuli. Analysis of the model suggested a close relationship between the\nproposed model and the subjective mix clarity scores particularly when masking\nwas measured using linearly spaced analysis bands. Moreover, the presence of\nnoise-like residual signals was shown to have a negative effect on the\nperceived mix clarity.", "published": "2021-03-22 20:03:40", "link": "http://arxiv.org/abs/2103.12152v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reduced basis methods for numerical room acoustic simulations with\n  parametrized boundaries", "abstract": "The use of model-based numerical simulation of wave propagation in rooms for\nengineering applications requires that acoustic conditions for multiple\nparameters are evaluated iteratively and this is computationally expensive. We\npresent a reduced basis methods (RBM) to achieve a computational cost reduction\nrelative to a traditional full order model (FOM), for wave-based room acoustic\nsimulations with parametrized boundary conditions. In this study, the FOM\nsolver is based on the spectral element method, however other numerical methods\ncould be applied. The RBM reduces the computational burden by solving the\nproblem in a low-dimensional subspace for parametrized frequency-independent\nand frequency-dependent boundary conditions. The problem is formulated and\nsolved in the Laplace domain, which ensures the stability of the reduced order\nmodel based on the RBM approach. We study the potential of the proposed RBM\nframework in terms of computational efficiency, accuracy and storage\nrequirements and we show that the RBM leads to 100-fold speed-ups for a 2D case\nwith an upper frequency of 2kHz and around 1000-fold speed-ups for an analogous\n3D case with an upper frequency of 1kHz. While the FOM simulations needed to\nconstruct the ROM are expensive, we demonstrate that despite this cost, the ROM\nhas a potential of three orders of magnitude faster than the FOM when four\ndifferent boundary conditions are simulated per room surface. Moreover, results\nshow that the storage model for the ROM is relatively high but affordable for\nthe presented 2D and 3D cases.", "published": "2021-03-22 11:13:21", "link": "http://arxiv.org/abs/2103.11730v2", "categories": ["cs.SD", "cs.CE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Self-paced ensemble learning for speech and audio classification", "abstract": "Combining multiple machine learning models into an ensemble is known to\nprovide superior performance levels compared to the individual components\nforming the ensemble. This is because models can complement each other in\ntaking better decisions. Instead of just combining the models, we propose a\nself-paced ensemble learning scheme in which models learn from each other over\nseveral iterations. During the self-paced learning process based on\npseudo-labeling, in addition to improving the individual models, our ensemble\nalso gains knowledge about the target domain. To demonstrate the generality of\nour self-paced ensemble learning (SPEL) scheme, we conduct experiments on three\naudio tasks. Our empirical results indicate that SPEL significantly outperforms\nthe baseline ensemble models. We also show that applying self-paced learning on\nindividual models is less effective, illustrating the idea that models in the\nensemble actually learn from each other.", "published": "2021-03-22 16:34:06", "link": "http://arxiv.org/abs/2103.11988v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Tiny Transformers for Environmental Sound Classification at the Edge", "abstract": "With the growth of the Internet of Things and the rise of Big Data, data\nprocessing and machine learning applications are being moved to cheap and low\nsize, weight, and power (SWaP) devices at the edge, often in the form of mobile\nphones, embedded systems, or microcontrollers. The field of Cyber-Physical\nMeasurements and Signature Intelligence (MASINT) makes use of these devices to\nanalyze and exploit data in ways not otherwise possible, which results in\nincreased data quality, increased security, and decreased bandwidth. However,\nmethods to train and deploy models at the edge are limited, and models with\nsufficient accuracy are often too large for the edge device. Therefore, there\nis a clear need for techniques to create efficient AI/ML at the edge. This work\npresents training techniques for audio models in the field of environmental\nsound classification at the edge. Specifically, we design and train\nTransformers to classify office sounds in audio clips. Results show that a\nBERT-based Transformer, trained on Mel spectrograms, can outperform a CNN using\n99.85% fewer parameters. To achieve this result, we first tested several audio\nfeature extraction techniques designed for Transformers, using ESC-50 for\nevaluation, along with various augmentations. Our final model outperforms the\nstate-of-the-art MFCC-based CNN on the office sounds dataset, using just over\n6,000 parameters -- small enough to run on a microcontroller.", "published": "2021-03-22 20:12:15", "link": "http://arxiv.org/abs/2103.12157v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
