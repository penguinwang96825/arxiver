{"title": "A Japanese-Chinese Parallel Corpus Using Crowdsourcing for Web Mining", "abstract": "Using crowdsourcing, we collected more than 10,000 URL pairs (parallel top\npage pairs) of bilingual websites that contain parallel documents and created a\nJapanese-Chinese parallel corpus of 4.6M sentence pairs from these websites. We\nused a Japanese-Chinese bilingual dictionary of 160K word pairs for document\nand sentence alignment. We then used high-quality 1.2M Japanese-Chinese\nsentence pairs to train a parallel corpus filter based on statistical language\nmodels and word translation probabilities. We compared the translation accuracy\nof the model trained on these 4.6M sentence pairs with that of the model\ntrained on Japanese-Chinese sentence pairs from CCMatrix (12.4M), a parallel\ncorpus from global web mining. Although our corpus is only one-third the size\nof CCMatrix, we found that the accuracy of the two models was comparable and\nconfirmed that it is feasible to use crowdsourcing for web mining of parallel\ndata.", "published": "2024-05-15 00:54:40", "link": "http://arxiv.org/abs/2405.09017v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A safety realignment framework via subspace-oriented model fusion for\n  large language models", "abstract": "The current safeguard mechanisms for large language models (LLMs) are indeed\nsusceptible to jailbreak attacks, making them inherently fragile. Even the\nprocess of fine-tuning on apparently benign data for downstream tasks can\njeopardize safety. One potential solution is to conduct safety fine-tuning\nsubsequent to downstream fine-tuning. However, there's a risk of catastrophic\nforgetting during safety fine-tuning, where LLMs may regain safety measures but\nlose the task-specific knowledge acquired during downstream fine-tuning. In\nthis paper, we introduce a safety realignment framework through\nsubspace-oriented model fusion (SOMF), aiming to combine the safeguard\ncapabilities of initially aligned model and the current fine-tuned model into a\nrealigned model. Our approach begins by disentangling all task vectors from the\nweights of each fine-tuned model. We then identify safety-related regions\nwithin these vectors by subspace masking techniques. Finally, we explore the\nfusion of the initial safely aligned LLM with all task vectors based on the\nidentified safety subspace. We validate that our safety realignment framework\nsatisfies the safety requirements of a single fine-tuned model as well as\nmultiple models during their fusion. Our findings confirm that SOMF preserves\nsafety without notably compromising performance on downstream tasks, including\ninstruction following in Chinese, English, and Hindi, as well as\nproblem-solving capabilities in Code and Math.", "published": "2024-05-15 03:04:05", "link": "http://arxiv.org/abs/2405.09055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HumanRankEval: Automatic Evaluation of LMs as Conversational Assistants", "abstract": "Language models (LMs) as conversational assistants recently became popular\ntools that help people accomplish a variety of tasks. These typically result\nfrom adapting LMs pretrained on general domain text sequences through further\ninstruction-tuning and possibly preference optimisation methods. The evaluation\nof such LMs would ideally be performed using human judgement, however, this is\nnot scalable. On the other hand, automatic evaluation featuring auxiliary LMs\nas judges and/or knowledge-based tasks is scalable but struggles with assessing\nconversational ability and adherence to instructions. To help accelerate the\ndevelopment of LMs as conversational assistants, we propose a novel automatic\nevaluation task: HumanRankEval (HRE). It consists of a large-scale, diverse and\nhigh-quality set of questions, each with several answers authored and scored by\nhumans. To perform evaluation, HRE ranks these answers based on their\nlog-likelihood under the LM's distribution, and subsequently calculates their\ncorrelation with the corresponding human rankings. We support HRE's efficacy by\ninvestigating how efficiently it separates pretrained and instruction-tuned LMs\nof various sizes. We show that HRE correlates well with human judgements and is\nparticularly responsive to model changes following instruction-tuning.", "published": "2024-05-15 08:47:26", "link": "http://arxiv.org/abs/2405.09186v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "New Textual Corpora for Serbian Language Modeling", "abstract": "This paper will present textual corpora for Serbian (and Serbo-Croatian),\nusable for the training of large language models and publicly available at one\nof the several notable online repositories. Each corpus will be classified\nusing multiple methods and its characteristics will be detailed. Additionally,\nthe paper will introduce three new corpora: a new umbrella web corpus of\nSerbo-Croatian, a new high-quality corpus based on the doctoral dissertations\nstored within National Repository of Doctoral Dissertations from all\nUniversities in Serbia, and a parallel corpus of abstract translation from the\nsame source. The uniqueness of both old and new corpora will be accessed via\nfrequency-based stylometric methods, and the results will be briefly discussed.", "published": "2024-05-15 11:05:16", "link": "http://arxiv.org/abs/2405.09250v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompting-based Synthetic Data Generation for Few-Shot Question\n  Answering", "abstract": "Although language models (LMs) have boosted the performance of Question\nAnswering, they still need plenty of data. Data annotation, in contrast, is a\ntime-consuming process. This especially applies to Question Answering, where\npossibly large documents have to be parsed and annotated with questions and\ntheir corresponding answers. Furthermore, Question Answering models often only\nwork well for the domain they were trained on. Since annotation is costly, we\nargue that domain-agnostic knowledge from LMs, such as linguistic\nunderstanding, is sufficient to create a well-curated dataset. With this\nmotivation, we show that using large language models can improve Question\nAnswering performance on various datasets in the few-shot setting compared to\nstate-of-the-art approaches. For this, we perform data generation leveraging\nthe Prompting framework, suggesting that language models contain valuable\ntask-agnostic knowledge that can be used beyond the common\npre-training/fine-tuning scheme. As a result, we consistently outperform\nprevious approaches on few-shot Question Answering.", "published": "2024-05-15 13:36:43", "link": "http://arxiv.org/abs/2405.09335v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic\n  Degeneration in Large Language Models", "abstract": "Recent advances in large language models (LLMs) have led to their extensive\nglobal deployment, and ensuring their safety calls for comprehensive and\nmultilingual toxicity evaluations. However, existing toxicity benchmarks are\noverwhelmingly focused on English, posing serious risks to deploying LLMs in\nother languages. We address this by introducing PolygloToxicityPrompts (PTP),\nthe first large-scale multilingual toxicity evaluation benchmark of 425K\nnaturally occurring prompts spanning 17 languages. We overcome the scarcity of\nnaturally occurring toxicity in web-text and ensure coverage across languages\nwith varying resources by automatically scraping over 100M web-text documents.\nUsing PTP, we investigate research questions to study the impact of model size,\nprompt language, and instruction and preference-tuning methods on toxicity by\nbenchmarking over 60 LLMs. Notably, we find that toxicity increases as language\nresources decrease or model size increases. Although instruction- and\npreference-tuning reduce toxicity, the choice of preference-tuning method does\nnot have any significant impact. Our findings shed light on crucial\nshortcomings of LLM safeguarding and highlight areas for future research.", "published": "2024-05-15 14:22:33", "link": "http://arxiv.org/abs/2405.09373v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tell Me Why: Explainable Public Health Fact-Checking with Large Language\n  Models", "abstract": "This paper presents a comprehensive analysis of explainable fact-checking\nthrough a series of experiments, focusing on the ability of large language\nmodels to verify public health claims and provide explanations or\njustifications for their veracity assessments. We examine the effectiveness of\nzero/few-shot prompting and parameter-efficient fine-tuning across various open\nand closed-source models, examining their performance in both isolated and\njoint tasks of veracity prediction and explanation generation. Importantly, we\nemploy a dual evaluation approach comprising previously established automatic\nmetrics and a novel set of criteria through human evaluation. Our automatic\nevaluation indicates that, within the zero-shot scenario, GPT-4 emerges as the\nstandout performer, but in few-shot and parameter-efficient fine-tuning\ncontexts, open-source models demonstrate their capacity to not only bridge the\nperformance gap but, in some instances, surpass GPT-4. Human evaluation reveals\nyet more nuance as well as indicating potential problems with the gold\nexplanations.", "published": "2024-05-15 15:49:06", "link": "http://arxiv.org/abs/2405.09454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty\n  Classification of Educational Texts", "abstract": "Using large language models (LLMs) for educational applications like\ndialogue-based teaching is a hot topic. Effective teaching, however, requires\nteachers to adapt the difficulty of content and explanations to the education\nlevel of their students. Even the best LLMs today struggle to do this well. If\nwe want to improve LLMs on this adaptation task, we need to be able to measure\nadaptation success reliably. However, current Static metrics for text\ndifficulty, like the Flesch-Kincaid Reading Ease score, are known to be crude\nand brittle. We, therefore, introduce and evaluate a new set of Prompt-based\nmetrics for text difficulty. Based on a user study, we create Prompt-based\nmetrics as inputs for LLMs. They leverage LLM's general language understanding\ncapabilities to capture more abstract and complex features than Static metrics.\nRegression experiments show that adding our Prompt-based metrics significantly\nimproves text difficulty classification over Static metrics alone. Our results\ndemonstrate the promise of using LLMs to evaluate text adaptation to different\neducation levels.", "published": "2024-05-15 16:22:16", "link": "http://arxiv.org/abs/2405.09482v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SCI 3.0: A Web-based Schema Curation Interface for Graphical Event\n  Representations", "abstract": "To understand the complexity of global events, one must navigate a web of\ninterwoven sub-events, identifying those most impactful elements within the\nlarger, abstract macro-event framework at play. This concept can be extended to\nthe field of natural language processing (NLP) through the creation of\nstructured event schemas which can serve as representations of these abstract\nevents. Central to our approach is the Schema Curation Interface 3.0 (SCI 3.0),\na web application that facilitates real-time editing of event schema properties\nwithin a generated graph e.g., adding, removing, or editing sub-events,\nentities, and relations directly through an interface.", "published": "2024-05-15 23:52:19", "link": "http://arxiv.org/abs/2405.09733v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Spatial Semantic Recurrent Mining for Referring Image Segmentation", "abstract": "Referring Image Segmentation (RIS) consistently requires language and\nappearance semantics to more understand each other. The need becomes acute\nespecially under hard situations. To achieve, existing works tend to resort to\nvarious trans-representing mechanisms to directly feed forward language\nsemantic along main RGB branch, which however will result in referent\ndistribution weakly-mined in space and non-referent semantic contaminated along\nchannel. In this paper, we propose Spatial Semantic Recurrent Mining\n(S\\textsuperscript{2}RM) to achieve high-quality cross-modality fusion. It\nfollows a working strategy of trilogy: distributing language feature, spatial\nsemantic recurrent coparsing, and parsed-semantic balancing. During fusion,\nS\\textsuperscript{2}RM will first generate a constraint-weak yet\ndistribution-aware language feature, then bundle features of each row and\ncolumn from rotated features of one modality context to recurrently correlate\nrelevant semantic contained in feature from other modality context, and finally\nresort to self-distilled weights to weigh on the contributions of different\nparsed semantics. Via coparsing, S\\textsuperscript{2}RM transports information\nfrom the near and remote slice layers of generator context to the current slice\nlayer of parsed context, capable of better modeling global relationship\nbidirectional and structured. Besides, we also propose a Cross-scale Abstract\nSemantic Guided Decoder (CASG) to emphasize the foreground of the referent,\nfinally integrating different grained features at a comparatively low cost.\nExtensive experimental results on four current challenging datasets show that\nour proposed method performs favorably against other state-of-the-art\nalgorithms.", "published": "2024-05-15 00:17:48", "link": "http://arxiv.org/abs/2405.09006v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Adapting Abstract Meaning Representation Parsing to the Clinical\n  Narrative -- the SPRING THYME parser", "abstract": "This paper is dedicated to the design and evaluation of the first AMR parser\ntailored for clinical notes. Our objective was to facilitate the precise\ntransformation of the clinical notes into structured AMR expressions, thereby\nenhancing the interpretability and usability of clinical text data at scale.\nLeveraging the colon cancer dataset from the Temporal Histories of Your Medical\nEvents (THYME) corpus, we adapted a state-of-the-art AMR parser utilizing\ncontinuous training. Our approach incorporates data augmentation techniques to\nenhance the accuracy of AMR structure predictions. Notably, through this\nlearning strategy, our parser achieved an impressive F1 score of 88% on the\nTHYME corpus's colon cancer dataset. Moreover, our research delved into the\nefficacy of data required for domain adaptation within the realm of clinical\nnotes, presenting domain adaptation data requirements for AMR parsing. This\nexploration not only underscores the parser's robust performance but also\nhighlights its potential in facilitating a deeper understanding of clinical\nnarratives through structured semantic representations.", "published": "2024-05-15 07:32:43", "link": "http://arxiv.org/abs/2405.09153v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Word Alignment as Preference for Machine Translation", "abstract": "The problem of hallucination and omission, a long-standing problem in machine\ntranslation (MT), is more pronounced when a large language model (LLM) is used\nin MT because an LLM itself is susceptible to these phenomena. In this work, we\nmitigate the problem in an LLM-based MT model by guiding it to better word\nalignment. We first study the correlation between word alignment and the\nphenomena of hallucination and omission in MT. Then we propose to utilize word\nalignment as preference to optimize the LLM-based MT model. The preference data\nare constructed by selecting chosen and rejected translations from multiple MT\ntools. Subsequently, direct preference optimization is used to optimize the\nLLM-based model towards the preference signal. Given the absence of evaluators\nspecifically designed for hallucination and omission in MT, we further propose\nselecting hard instances and utilizing GPT-4 to directly evaluate the\nperformance of the models in mitigating these issues. We verify the rationality\nof these designed evaluation methods by experiments, followed by extensive\nresults demonstrating the effectiveness of word alignment-based preference\noptimization to mitigate hallucination and omission. On the other hand,\nalthough it shows promise in mitigating hallucination and omission, the overall\nperformance of MT in different language directions remains mixed, with slight\nincreases in BLEU and decreases in COMET.", "published": "2024-05-15 10:04:19", "link": "http://arxiv.org/abs/2405.09223v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sign of the Times: Evaluating the use of Large Language Models for\n  Idiomaticity Detection", "abstract": "Despite the recent ubiquity of large language models and their high zero-shot\nprompted performance across a wide range of tasks, it is still not known how\nwell they perform on tasks which require processing of potentially idiomatic\nlanguage. In particular, how well do such models perform in comparison to\nencoder-only models fine-tuned specifically for idiomaticity tasks? In this\nwork, we attempt to answer this question by looking at the performance of a\nrange of LLMs (both local and software-as-a-service models) on three\nidiomaticity datasets: SemEval 2022 Task 2a, FLUTE, and MAGPIE. Overall, we\nfind that whilst these models do give competitive performance, they do not\nmatch the results of fine-tuned task-specific models, even at the largest\nscales (e.g. for GPT-4). Nevertheless, we do see consistent performance\nimprovements across model scale. Additionally, we investigate prompting\napproaches to improve performance, and discuss the practicalities of using LLMs\nfor these tasks.", "published": "2024-05-15 11:55:14", "link": "http://arxiv.org/abs/2405.09279v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do language models capture implied discourse meanings? An investigation\n  with exhaustivity implicatures of Korean morphology", "abstract": "Markedness in natural language is often associated with non-literal meanings\nin discourse. Differential Object Marking (DOM) in Korean is one instance of\nthis phenomenon, where post-positional markers are selected based on both the\nsemantic features of the noun phrases and the discourse features that are\northogonal to the semantic features. Previous work has shown that\ndistributional models of language recover certain semantic features of words --\ndo these models capture implied discourse-level meanings as well? We evaluate\nwhether a set of large language models are capable of associating discourse\nmeanings with different object markings in Korean. Results suggest that\ndiscourse meanings of a grammatical marker can be more challenging to encode\nthan that of a discourse marker.", "published": "2024-05-15 12:34:40", "link": "http://arxiv.org/abs/2405.09293v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Model Bias Mitigation from the Perspective of Knowledge\n  Editing", "abstract": "Existing debiasing methods inevitably make unreasonable or undesired\npredictions as they are designated and evaluated to achieve parity across\ndifferent social groups but leave aside individual facts, resulting in modified\nexisting knowledge. In this paper, we first establish a new bias mitigation\nbenchmark BiasKE leveraging existing and additional constructed datasets, which\nsystematically assesses debiasing performance by complementary metrics on\nfairness, specificity, and generalization. Meanwhile, we propose a novel\ndebiasing method, Fairness Stamp (FAST), which enables editable fairness\nthrough fine-grained calibration on individual biased knowledge. Comprehensive\nexperiments demonstrate that FAST surpasses state-of-the-art baselines with\nremarkable debiasing performance while not hampering overall model capability\nfor knowledge preservation, highlighting the prospect of fine-grained debiasing\nstrategies for editable fairness in LLMs.", "published": "2024-05-15 13:44:13", "link": "http://arxiv.org/abs/2405.09341v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Facilitating Opinion Diversity through Hybrid NLP Approaches", "abstract": "Modern democracies face a critical issue of declining citizen participation\nin decision-making. Online discussion forums are an important avenue for\nenhancing citizen participation. This thesis proposal 1) identifies the\nchallenges involved in facilitating large-scale online discussions with Natural\nLanguage Processing (NLP), 2) suggests solutions to these challenges by\nincorporating hybrid human-AI technologies, and 3) investigates what these\ntechnologies can reveal about individual perspectives in online discussions. We\npropose a three-layered hierarchy for representing perspectives that can be\nobtained by a mixture of human intelligence and large language models. We\nillustrate how these representations can draw insights into the diversity of\nperspectives and allow us to investigate interactions in online discussions.", "published": "2024-05-15 15:30:17", "link": "http://arxiv.org/abs/2405.09439v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ParaNames 1.0: Creating an Entity Name Corpus for 400+ Languages using\n  Wikidata", "abstract": "We introduce ParaNames, a massively multilingual parallel name resource\nconsisting of 140 million names spanning over 400 languages. Names are provided\nfor 16.8 million entities, and each entity is mapped from a complex type\nhierarchy to a standard type (PER/LOC/ORG). Using Wikidata as a source, we\ncreate the largest resource of this type to date. We describe our approach to\nfiltering and standardizing the data to provide the best quality possible.\nParaNames is useful for multilingual language processing, both in defining\ntasks for name translation/transliteration and as supplementary data for tasks\nsuch as named entity recognition and linking. We demonstrate the usefulness of\nParaNames on two tasks. First, we perform canonical name translation between\nEnglish and 17 other languages. Second, we use it as a gazetteer for\nmultilingual named entity recognition, obtaining performance improvements on\nall 10 languages evaluated.", "published": "2024-05-15 16:44:54", "link": "http://arxiv.org/abs/2405.09496v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "QueryNER: Segmentation of E-commerce Queries", "abstract": "We present QueryNER, a manually-annotated dataset and accompanying model for\ne-commerce query segmentation. Prior work in sequence labeling for e-commerce\nhas largely addressed aspect-value extraction which focuses on extracting\nportions of a product title or query for narrowly defined aspects. Our work\ninstead focuses on the goal of dividing a query into meaningful chunks with\nbroadly applicable types. We report baseline tagging results and conduct\nexperiments comparing token and entity dropping for null and low recall query\nrecovery. Challenging test sets are created using automatic transformations and\nshow how simple data augmentation techniques can make the models more robust to\nnoise. We make the QueryNER dataset publicly available.", "published": "2024-05-15 16:58:35", "link": "http://arxiv.org/abs/2405.09507v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modeling Bilingual Sentence Processing: Evaluating RNN and Transformer\n  Architectures for Cross-Language Structural Priming", "abstract": "This study evaluates the performance of Recurrent Neural Network (RNN) and\nTransformer models in replicating cross-language structural priming, a key\nindicator of abstract grammatical representations in human language processing.\nFocusing on Chinese-English priming, which involves two typologically distinct\nlanguages, we examine how these models handle the robust phenomenon of\nstructural priming, where exposure to a particular sentence structure increases\nthe likelihood of selecting a similar structure subsequently. Our findings\nindicate that transformers outperform RNNs in generating primed sentence\nstructures, with accuracy rates that exceed 25.84\\% to 33. 33\\%. This\nchallenges the conventional belief that human sentence processing primarily\ninvolves recurrent and immediate processing and suggests a role for cue-based\nretrieval mechanisms. This work contributes to our understanding of how\ncomputational models may reflect human cognitive processes across diverse\nlanguage families.", "published": "2024-05-15 17:01:02", "link": "http://arxiv.org/abs/2405.09508v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Simulating Policy Impacts: Developing a Generative Scenario Writing\n  Method to Evaluate the Perceived Effects of Regulation", "abstract": "The rapid advancement of AI technologies yields numerous future impacts on\nindividuals and society. Policymakers are tasked to react quickly and establish\npolicies that mitigate those impacts. However, anticipating the effectiveness\nof policies is a difficult task, as some impacts might only be observable in\nthe future and respective policies might not be applicable to the future\ndevelopment of AI. In this work we develop a method for using large language\nmodels (LLMs) to evaluate the efficacy of a given piece of policy at mitigating\nspecified negative impacts. We do so by using GPT-4 to generate scenarios both\npre- and post-introduction of policy and translating these vivid stories into\nmetrics based on human perceptions of impacts. We leverage an already\nestablished taxonomy of impacts of generative AI in the media environment to\ngenerate a set of scenario pairs both mitigated and non-mitigated by the\ntransparency policy in Article 50 of the EU AI Act. We then run a user study\n(n=234) to evaluate these scenarios across four risk-assessment dimensions:\nseverity, plausibility, magnitude, and specificity to vulnerable populations.\nWe find that this transparency legislation is perceived to be effective at\nmitigating harms in areas such as labor and well-being, but largely ineffective\nin areas such as social cohesion and security. Through this case study we\ndemonstrate the efficacy of our method as a tool to iterate on the\neffectiveness of policy for mitigating various negative impacts. We expect this\nmethod to be useful to researchers or other stakeholders who want to brainstorm\nthe potential utility of different pieces of policy or other mitigation\nstrategies.", "published": "2024-05-15 19:44:54", "link": "http://arxiv.org/abs/2405.09679v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Systematic Analysis on the Temporal Generalization of Language Models\n  in Social Media", "abstract": "In machine learning, temporal shifts occur when there are differences between\ntraining and test splits in terms of time. For streaming data such as news or\nsocial media, models are commonly trained on a fixed corpus from a certain\nperiod of time, and they can become obsolete due to the dynamism and evolving\nnature of online content. This paper focuses on temporal shifts in social media\nand, in particular, Twitter. We propose a unified evaluation scheme to assess\nthe performance of language models (LMs) under temporal shift on standard\nsocial media tasks. LMs are tested on five diverse social media NLP tasks under\ndifferent temporal settings, which revealed two important findings: (i) the\ndecrease in performance under temporal shift is consistent across different\nmodels for entity-focused tasks such as named entity recognition or\ndisambiguation, and hate speech detection, but not significant in the other\ntasks analysed (i.e., topic and sentiment classification); and (ii) continuous\npre-training on the test period does not improve the temporal adaptability of\nLMs.", "published": "2024-05-15 05:41:06", "link": "http://arxiv.org/abs/2405.13017v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey of Accelerated Generation Techniques in Large\n  Language Models", "abstract": "Despite the crucial importance of accelerating text generation in large\nlanguage models (LLMs) for efficiently producing content, the sequential nature\nof this process often leads to high inference latency, posing challenges for\nreal-time applications. Various techniques have been proposed and developed to\naddress these challenges and improve efficiency. This paper presents a\ncomprehensive survey of accelerated generation techniques in autoregressive\nlanguage models, aiming to understand the state-of-the-art methods and their\napplications. We categorize these techniques into several key areas:\nspeculative decoding, early exiting mechanisms, and non-autoregressive methods.\nWe discuss each category's underlying principles, advantages, limitations, and\nrecent advancements. Through this survey, we aim to offer insights into the\ncurrent landscape of techniques in LLMs and provide guidance for future\nresearch directions in this critical area of natural language processing.", "published": "2024-05-15 07:36:56", "link": "http://arxiv.org/abs/2405.13019v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using Combinatorial Optimization to Design a High quality LLM Solution", "abstract": "We introduce a novel LLM based solution design approach that utilizes\ncombinatorial optimization and sampling. Specifically, a set of factors that\ninfluence the quality of the solution are identified. They typically include\nfactors that represent prompt types, LLM inputs alternatives, and parameters\ngoverning the generation and design alternatives. Identifying the factors that\ngovern the LLM solution quality enables the infusion of subject matter expert\nknowledge. Next, a set of interactions between the factors are defined and\ncombinatorial optimization is used to create a small subset $P$ that ensures\nall desired interactions occur in $P$. Each element $p \\in P$ is then developed\ninto an appropriate benchmark. Applying the alternative solutions on each\ncombination, $p \\in P$ and evaluating the results facilitate the design of a\nhigh quality LLM solution pipeline. The approach is especially applicable when\nthe design and evaluation of each benchmark in $P$ is time-consuming and\ninvolves manual steps and human evaluation. Given its efficiency the approach\ncan also be used as a baseline to compare and validate an autoML approach that\nsearches over the factors governing the solution.", "published": "2024-05-15 11:13:39", "link": "http://arxiv.org/abs/2405.13020v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLMs can learn self-restraint through iterative self-reflection", "abstract": "In order to be deployed safely, Large Language Models (LLMs) must be capable\nof dynamically adapting their behavior based on their level of knowledge and\nuncertainty associated with specific topics. This adaptive behavior, which we\nrefer to as self-restraint, is non-trivial to teach since it depends on the\ninternal knowledge of an LLM. By default, LLMs are trained to maximize the next\ntoken likelihood, which does not teach the model to modulate its answer based\non its level of uncertainty. In order to learn self-restraint, we devise a\nutility function that can encourage the model to produce responses only when it\nis confident in them. This utility function can be used to score generation of\ndifferent length and abstention. To optimize this function, we introduce\nReSearch, a process of \"self-reflection\" consisting of iterative self-prompting\nand self-evaluation. We use the ReSearch algorithm to generate synthetic data\non which we finetune our models. Compared to their original versions, our\nresulting models generate fewer \\emph{hallucinations} overall at no additional\ninference cost, for both known and unknown topics, as the model learns to\nselectively restrain itself. In addition, our method elegantly incorporates the\nability to abstain by augmenting the samples generated by the model during the\nsearch procedure with an answer expressing abstention.", "published": "2024-05-15 13:35:43", "link": "http://arxiv.org/abs/2405.13022v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Survey on Transformers in NLP with Focus on Efficiency", "abstract": "The advent of transformers with attention mechanisms and associated\npre-trained models have revolutionized the field of Natural Language Processing\n(NLP). However, such models are resource-intensive due to highly complex\narchitecture. This limits their application to resource-constrained\nenvironments. While choosing an appropriate NLP model, a major trade-off exists\nover choosing accuracy over efficiency and vice versa. This paper presents a\ncommentary on the evolution of NLP and its applications with emphasis on their\naccuracy as-well-as efficiency. Following this, a survey of research\ncontributions towards enhancing the efficiency of transformer-based models at\nvarious stages of model development along with hardware considerations has been\nconducted. The goal of this survey is to determine how current NLP techniques\ncontribute towards a sustainable society and to establish a foundation for\nfuture research.", "published": "2024-05-15 10:32:41", "link": "http://arxiv.org/abs/2406.16893v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ALPINE: Unveiling the Planning Capability of Autoregressive Learning in\n  Language Models", "abstract": "Planning is a crucial element of both human intelligence and contemporary\nlarge language models (LLMs). In this paper, we initiate a theoretical\ninvestigation into the emergence of planning capabilities in Transformer-based\nLLMs via their next-word prediction mechanisms. We model planning as a network\npath-finding task, where the objective is to generate a valid path from a\nspecified source node to a designated target node. Our mathematical\ncharacterization shows that Transformer architectures can execute path-finding\nby embedding the adjacency and reachability matrices within their weights.\nFurthermore, our theoretical analysis of gradient-based learning dynamics\nreveals that LLMs can learn both the adjacency and a limited form of the\nreachability matrices. These theoretical insights are then validated through\nexperiments, which demonstrate that Transformer architectures indeed learn the\nadjacency and an incomplete reachability matrices, consistent with our\ntheoretical predictions. When applying our methodology to the real-world\nplanning benchmark Blocksworld, our observations remain consistent.\nAdditionally, our analyses uncover a fundamental limitation of current\nTransformer architectures in path-finding: these architectures cannot identify\nreachability relationships through transitivity, which leads to failures in\ngenerating paths when concatenation is required. These findings provide new\ninsights into how the internal mechanisms of autoregressive learning facilitate\nintelligent planning and deepen our understanding of how future LLMs might\nachieve more advanced and general planning-and-reasoning capabilities across\ndiverse applications.", "published": "2024-05-15 09:59:37", "link": "http://arxiv.org/abs/2405.09220v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Bridging the gap in online hate speech detection: a comparative analysis\n  of BERT and traditional models for homophobic content identification on\n  X/Twitter", "abstract": "Our study addresses a significant gap in online hate speech detection\nresearch by focusing on homophobia, an area often neglected in sentiment\nanalysis research. Utilising advanced sentiment analysis models, particularly\nBERT, and traditional machine learning methods, we developed a nuanced approach\nto identify homophobic content on X/Twitter. This research is pivotal due to\nthe persistent underrepresentation of homophobia in detection models. Our\nfindings reveal that while BERT outperforms traditional methods, the choice of\nvalidation technique can impact model performance. This underscores the\nimportance of contextual understanding in detecting nuanced hate speech. By\nreleasing the largest open-source labelled English dataset for homophobia\ndetection known to us, an analysis of various models' performance and our\nstrongest BERT-based model, we aim to enhance online safety and inclusivity.\nFuture work will extend to broader LGBTQIA+ hate speech detection, addressing\nthe challenges of sourcing diverse datasets. Through this endeavour, we\ncontribute to the larger effort against online hate, advocating for a more\ninclusive digital landscape. Our study not only offers insights into the\neffective detection of homophobic content by improving on previous research\nresults, but it also lays groundwork for future advancements in hate speech\nanalysis.", "published": "2024-05-15 10:02:47", "link": "http://arxiv.org/abs/2405.09221v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "H.5; I.2; J.5"], "primary_category": "cs.CL"}
{"title": "Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A\n  Blind Assessment of Large Language Models for Psychological Support", "abstract": "Background: Rapid advancements in natural language processing have led to the\ndevelopment of large language models with the potential to revolutionize mental\nhealth care. These models have shown promise in assisting clinicians and\nproviding support to individuals experiencing various psychological challenges.\n  Objective: This study aims to compare the performance of two large language\nmodels, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts,\nto assess their potential applicability in mental health care settings.\n  Methods: A blind methodology was employed, with a clinical psychologist\nevaluating the models' responses without knowledge of their origins. The\nprompts encompassed a diverse range of mental health topics, including\ndepression, anxiety, and trauma, to ensure a comprehensive assessment.\n  Results: The results demonstrated a significant difference in performance\nbetween the two models (p > 0.05). GPT-4 achieved an average rating of 8.29 out\nof 10, while Chat-GPT received an average rating of 6.52. The clinical\npsychologist's evaluation suggested that GPT-4 was more effective at generating\nclinically relevant and empathetic responses, thereby providing better support\nand guidance to potential users.\n  Conclusions: This study contributes to the growing body of literature on the\napplicability of large language models in mental health care settings. The\nfindings underscore the importance of continued research and development in the\nfield to optimize these models for clinical use. Further investigation is\nnecessary to understand the specific factors underlying the performance\ndifferences between the two models and to explore their generalizability across\nvarious populations and mental health conditions.", "published": "2024-05-15 12:44:54", "link": "http://arxiv.org/abs/2405.09300v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Matching domain experts by training from scratch on domain knowledge", "abstract": "Recently, large language models (LLMs) have outperformed human experts in\npredicting the results of neuroscience experiments (Luo et al., 2024). What is\nthe basis for this performance? One possibility is that statistical patterns in\nthat specific scientific literature, as opposed to emergent reasoning abilities\narising from broader training, underlie LLMs' performance. To evaluate this\npossibility, we trained (next word prediction) a relatively small\n124M-parameter GPT-2 model on 1.3 billion tokens of domain-specific knowledge.\nDespite being orders of magnitude smaller than larger LLMs trained on trillions\nof tokens, small models achieved expert-level performance in predicting\nneuroscience results. Small models trained on the neuroscience literature\nsucceeded when they were trained from scratch using a tokenizer specifically\ntrained on neuroscience text or when the neuroscience literature was used to\nfinetune a pretrained GPT-2. Our results indicate that expert-level performance\nmay be attained by even small LLMs through domain-specific, auto-regressive\ntraining approaches.", "published": "2024-05-15 14:50:51", "link": "http://arxiv.org/abs/2405.09395v2", "categories": ["q-bio.NC", "cs.AI", "cs.CL"], "primary_category": "q-bio.NC"}
{"title": "Elements of World Knowledge (EWOK): A cognition-inspired framework for\n  evaluating basic world knowledge in language models", "abstract": "The ability to build and leverage world models is essential for a\ngeneral-purpose AI agent. Testing such capabilities is hard, in part because\nthe building blocks of world models are ill-defined. We present Elements of\nWorld Knowledge (EWOK), a framework for evaluating world modeling in language\nmodels by testing their ability to use knowledge of a concept to match a target\ntext with a plausible/implausible context. EWOK targets specific concepts from\nmultiple knowledge domains known to be vital for world modeling in humans.\nDomains range from social interactions (help/hinder) to spatial relations\n(left/right). Both, contexts and targets are minimal pairs. Objects, agents,\nand locations in the items can be flexibly filled in enabling easy generation\nof multiple controlled datasets. We then introduce EWOK-CORE-1.0, a dataset of\n4,374 items covering 11 world knowledge domains. We evaluate 20 openweights\nlarge language models (1.3B--70B parameters) across a battery of evaluation\nparadigms along with a human norming study comprising 12,480 measurements. The\noverall performance of all tested models is worse than human performance, with\nresults varying drastically across domains. These data highlight simple cases\nwhere even large models fail and present rich avenues for targeted research on\nLLM world modeling capabilities.", "published": "2024-05-15 17:19:42", "link": "http://arxiv.org/abs/2405.09605v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LoRA Learns Less and Forgets Less", "abstract": "Low-Rank Adaptation (LoRA) is a widely-used parameter-efficient finetuning\nmethod for large language models. LoRA saves memory by training only low rank\nperturbations to selected weight matrices. In this work, we compare the\nperformance of LoRA and full finetuning on two target domains, programming and\nmathematics. We consider both the instruction finetuning (approximately 100K\nprompt-response pairs) and continued pretraining (20B unstructured tokens) data\nregimes. Our results show that, in the standard low-rank settings, LoRA\nsubstantially underperforms full finetuning. Nevertheless, LoRA better\nmaintains the base model's performance on tasks outside the target domain. We\nshow that LoRA mitigates forgetting more than common regularization techniques\nsuch as weight decay and dropout; it also helps maintain more diverse\ngenerations. Finally, we show that full finetuning learns perturbations with a\nrank that is 10-100X greater than typical LoRA configurations, possibly\nexplaining some of the reported gaps. We conclude by proposing best practices\nfor finetuning with LoRA.", "published": "2024-05-15 19:27:45", "link": "http://arxiv.org/abs/2405.09673v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "STAR: A Benchmark for Situated Reasoning in Real-World Videos", "abstract": "Reasoning in the real world is not divorced from situations. How to capture\nthe present knowledge from surrounding situations and perform reasoning\naccordingly is crucial and challenging for machine intelligence. This paper\nintroduces a new benchmark that evaluates the situated reasoning ability via\nsituation abstraction and logic-grounded question answering for real-world\nvideos, called Situated Reasoning in Real-World Videos (STAR Benchmark). This\nbenchmark is built upon the real-world videos associated with human actions or\ninteractions, which are naturally dynamic, compositional, and logical. The\ndataset includes four types of questions, including interaction, sequence,\nprediction, and feasibility. We represent the situations in real-world videos\nby hyper-graphs connecting extracted atomic entities and relations (e.g.,\nactions, persons, objects, and relationships). Besides visual perception,\nsituated reasoning also requires structured situation comprehension and logical\nreasoning. Questions and answers are procedurally generated. The answering\nlogic of each question is represented by a functional program based on a\nsituation hyper-graph. We compare various existing video reasoning models and\nfind that they all struggle on this challenging situated reasoning task. We\nfurther propose a diagnostic neuro-symbolic model that can disentangle visual\nperception, situation abstraction, language understanding, and functional\nreasoning to understand the challenges of this benchmark.", "published": "2024-05-15 21:53:54", "link": "http://arxiv.org/abs/2405.09711v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World\n  Knowledge", "abstract": "Learning commonsense reasoning from visual contexts and scenes in real-world\nis a crucial step toward advanced artificial intelligence. However, existing\nvideo reasoning benchmarks are still inadequate since they were mainly designed\nfor factual or situated reasoning and rarely involve broader knowledge in the\nreal world. Our work aims to delve deeper into reasoning evaluations,\nspecifically within dynamic, open-world, and structured context knowledge. We\npropose a new benchmark (SOK-Bench), consisting of 44K questions and 10K\nsituations with instance-level annotations depicted in the videos. The\nreasoning process is required to understand and apply situated knowledge and\ngeneral knowledge for problem-solving. To create such a dataset, we propose an\nautomatic and scalable generation method to generate question-answer pairs,\nknowledge graphs, and rationales by instructing the combinations of LLMs and\nMLLMs. Concretely, we first extract observable situated entities, relations,\nand processes from videos for situated knowledge and then extend to open-world\nknowledge beyond the visible content. The task generation is facilitated\nthrough multiple dialogues as iterations and subsequently corrected and refined\nby our designed self-promptings and demonstrations. With a corpus of both\nexplicit situated facts and implicit commonsense, we generate associated\nquestion-answer pairs and reasoning processes, finally followed by manual\nreviews for quality assurance. We evaluated recent mainstream large\nvision-language models on the benchmark and found several insightful\nconclusions. For more information, please refer to our benchmark at\nwww.bobbywu.com/SOKBench.", "published": "2024-05-15 21:55:31", "link": "http://arxiv.org/abs/2405.09713v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Spectral Editing of Activations for Large Language Model Alignment", "abstract": "Large language models (LLMs) often exhibit undesirable behaviours, such as\ngenerating untruthful or biased content. Editing their internal representations\nhas been shown to be effective in mitigating such behaviours on top of the\nexisting alignment methods. We propose a novel inference-time editing method,\nnamely spectral editing of activations (SEA), to project the input\nrepresentations into directions with maximal covariance with the positive\ndemonstrations (e.g., truthful) while minimising covariance with the negative\ndemonstrations (e.g., hallucinated). We also extend our method to non-linear\nediting using feature functions. We run extensive experiments on benchmarks\nconcerning truthfulness and bias with six open-source LLMs of different sizes\nand model families. The results demonstrate the superiority of SEA in\neffectiveness, generalisation to similar tasks, as well as computation and data\nefficiency. We also show that SEA editing only has a limited negative impact on\nother model capabilities.", "published": "2024-05-15 22:28:23", "link": "http://arxiv.org/abs/2405.09719v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Continued Pretraining for Domain Adaptation of Wav2vec2.0 in Automatic\n  Speech Recognition for Elementary Math Classroom Settings", "abstract": "Creating Automatic Speech Recognition (ASR) systems that are robust and\nresilient to classroom conditions is paramount to the development of AI tools\nto aid teachers and students. In this work, we study the efficacy of continued\npretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that\nCPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of\nWav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the\nmodel's robustness to different noises, microphones, classroom conditions as\nwell as classroom demographics. Our CPT models show improved ability to\ngeneralize to different demographics unseen in the labeled finetuning data.", "published": "2024-05-15 06:59:33", "link": "http://arxiv.org/abs/2405.13018v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning\n  Inner Monologues", "abstract": "Although the Retrieval-Augmented Generation (RAG) paradigms can use external\nknowledge to enhance and ground the outputs of Large Language Models (LLMs) to\nmitigate generative hallucinations and static knowledge base problems, they\nstill suffer from limited flexibility in adopting Information Retrieval (IR)\nsystems with varying capabilities, constrained interpretability during the\nmulti-round retrieval process, and a lack of end-to-end optimization. To\naddress these challenges, we propose a novel LLM-centric approach, IM-RAG, that\nintegrates IR systems with LLMs to support multi-round RAG through learning\nInner Monologues (IM, i.e., the human inner voice that narrates one's\nthoughts). During the IM process, the LLM serves as the core reasoning model\n(i.e., Reasoner) to either propose queries to collect more information via the\nRetriever or to provide a final answer based on the conversational context. We\nalso introduce a Refiner that improves the outputs from the Retriever,\neffectively bridging the gap between the Reasoner and IR modules with varying\ncapabilities and fostering multi-round communications. The entire IM process is\noptimized via Reinforcement Learning (RL) where a Progress Tracker is\nincorporated to provide mid-step rewards, and the answer prediction is further\nseparately optimized via Supervised Fine-Tuning (SFT). We conduct extensive\nexperiments with the HotPotQA dataset, a popular benchmark for retrieval-based,\nmulti-step question-answering. The results show that our approach achieves\nstate-of-the-art (SOTA) performance while providing high flexibility in\nintegrating IR modules as well as strong interpretability exhibited in the\nlearned inner monologues.", "published": "2024-05-15 12:41:20", "link": "http://arxiv.org/abs/2405.13021v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Intelligent Tutor: Leveraging ChatGPT and Microsoft Copilot Studio to\n  Deliver a Generative AI Student Support and Feedback System within Teams", "abstract": "This study explores the integration of the ChatGPT API with GPT-4 model and\nMicrosoft Copilot Studio on the Microsoft Teams platform to develop an\nintelligent tutoring system. Designed to provide instant support to students,\nthe system dynamically adjusts educational content in response to the learners'\nprogress and feedback. Utilizing advancements in natural language processing\nand machine learning, it interprets student inquiries, offers tailored\nfeedback, and facilitates the educational journey. Initial implementation\nhighlights the system's potential in boosting students' motivation and\nengagement, while equipping educators with critical insights into the learning\nprocess, thus promoting tailored educational experiences and enhancing\ninstructional effectiveness.", "published": "2024-05-15 15:09:41", "link": "http://arxiv.org/abs/2405.13024v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A survey on fairness of large language models in e-commerce: progress,\n  application, and challenge", "abstract": "This survey explores the fairness of large language models (LLMs) in\ne-commerce, examining their progress, applications, and the challenges they\nface. LLMs have become pivotal in the e-commerce domain, offering innovative\nsolutions and enhancing customer experiences. This work presents a\ncomprehensive survey on the applications and challenges of LLMs in e-commerce.\nThe paper begins by introducing the key principles underlying the use of LLMs\nin e-commerce, detailing the processes of pretraining, fine-tuning, and\nprompting that tailor these models to specific needs. It then explores the\nvaried applications of LLMs in e-commerce, including product reviews, where\nthey synthesize and analyze customer feedback; product recommendations, where\nthey leverage consumer data to suggest relevant items; product information\ntranslation, enhancing global accessibility; and product question and answer\nsections, where they automate customer support. The paper critically addresses\nthe fairness challenges in e-commerce, highlighting how biases in training data\nand algorithms can lead to unfair outcomes, such as reinforcing stereotypes or\ndiscriminating against certain groups. These issues not only undermine consumer\ntrust, but also raise ethical and legal concerns. Finally, the work outlines\nfuture research directions, emphasizing the need for more equitable and\ntransparent LLMs in e-commerce. It advocates for ongoing efforts to mitigate\nbiases and improve the fairness of these systems, ensuring they serve diverse\nglobal markets effectively and ethically. Through this comprehensive analysis,\nthe survey provides a holistic view of the current landscape of LLMs in\ne-commerce, offering insights into their potential and limitations, and guiding\nfuture endeavors in creating fairer and more inclusive e-commerce environments.", "published": "2024-05-15 23:25:19", "link": "http://arxiv.org/abs/2405.13025v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Infer Induced Sentiment of Comment Response to Video: A New Task,\n  Dataset and Baseline", "abstract": "Existing video multi-modal sentiment analysis mainly focuses on the sentiment\nexpression of people within the video, yet often neglects the induced sentiment\nof viewers while watching the videos. Induced sentiment of viewers is essential\nfor inferring the public response to videos, has broad application in analyzing\npublic societal sentiment, effectiveness of advertising and other areas. The\nmicro videos and the related comments provide a rich application scenario for\nviewers induced sentiment analysis. In light of this, we introduces a novel\nresearch task, Multi-modal Sentiment Analysis for Comment Response of Video\nInduced(MSA-CRVI), aims to inferring opinions and emotions according to the\ncomments response to micro video. Meanwhile, we manually annotate a dataset\nnamed Comment Sentiment toward to Micro Video (CSMV) to support this research.\nIt is the largest video multi-modal sentiment dataset in terms of scale and\nvideo duration to our knowledge, containing 107,267 comments and 8,210 micro\nvideos with a video duration of 68.83 hours. To infer the induced sentiment of\ncomment should leverage the video content, so we propose the Video\nContent-aware Comment Sentiment Analysis (VC-CSA) method as baseline to address\nthe challenges inherent in this new task. Extensive experiments demonstrate\nthat our method is showing significant improvements over other established\nbaselines.", "published": "2024-05-15 10:24:54", "link": "http://arxiv.org/abs/2407.06115v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Comprehensive Survey of Hallucination in Large Language, Image, Video\n  and Audio Foundation Models", "abstract": "The rapid advancement of foundation models (FMs) across language, image,\naudio, and video domains has shown remarkable capabilities in diverse tasks.\nHowever, the proliferation of FMs brings forth a critical challenge: the\npotential to generate hallucinated outputs, particularly in high-stakes\napplications. The tendency of foundation models to produce hallucinated content\narguably represents the biggest hindrance to their widespread adoption in\nreal-world scenarios, especially in domains where reliability and accuracy are\nparamount. This survey paper presents a comprehensive overview of recent\ndevelopments that aim to identify and mitigate the problem of hallucination in\nFMs, spanning text, image, video, and audio modalities. By synthesizing recent\nadvancements in detecting and mitigating hallucination across various\nmodalities, the paper aims to provide valuable insights for researchers,\ndevelopers, and practitioners. Essentially, it establishes a clear framework\nencompassing definition, taxonomy, and detection strategies for addressing\nhallucination in multimodal foundation models, laying the foundation for future\nresearch in this pivotal area.", "published": "2024-05-15 10:16:25", "link": "http://arxiv.org/abs/2405.09589v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "QiandaoEar22: A high quality noise dataset for identifying specific ship\n  from multiple underwater acoustic targets using ship-radiated noise", "abstract": "Target identification of ship-radiated noise is a crucial area in underwater\ntarget recognition. However, there is currently a lack of multi-target ship\ndatasets that accurately represent real-world underwater acoustic conditions.\nTo tackle this issue, we conducted experimental data acquisition, resulting in\nthe release of QiandaoEar22 \\textemdash a comprehensive underwater acoustic\nmulti-target dataset. This dataset encompasses 9 hours and 28 minutes of\nreal-world ship-radiated noise data and 21 hours and 58 minutes of background\nnoise data. To demonstrate the availability of QiandaoEar22, we executed two\nexperimental tasks. The first task focuses on assessing the presence of\nship-radiated noise, while the second task involves identifying specific ships\nwithin the recognized targets in the multi-ship mixed data. In the latter task,\nwe extracted eight features from the data and employed six deep learning\nnetworks for classification, aiming to evaluate and compare the performance of\nvarious features and networks. The experimental results reveal that\nship-radiated noise can be successfully identified from background noise in\nover 99\\% of cases. Additionally, for the specific identification of individual\nships, the optimal recognition accuracy achieves 99.56\\%. Finally, based on our\nfindings, we provide advice on selecting appropriate features and deep learning\nnetworks, which may offer valuable insights for related research. Our work not\nonly establishes a benchmark for algorithm evaluation but also inspires the\ndevelopment of innovative methods to enhance UATD and UATR systems.", "published": "2024-05-15 07:22:57", "link": "http://arxiv.org/abs/2406.04354v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Speaker Embeddings With Weakly Supervised Voice Activity Detection For\n  Efficient Speaker Diarization", "abstract": "Current speaker diarization systems rely on an external voice activity\ndetection model prior to speaker embedding extraction on the detected speech\nsegments. In this paper, we establish that the attention system of a speaker\nembedding extractor acts as a weakly supervised internal VAD model and performs\nequally or better than comparable supervised VAD systems. Subsequently, speaker\ndiarization can be performed efficiently by extracting the VAD logits and\ncorresponding speaker embedding simultaneously, alleviating the need and\ncomputational overhead of an external VAD model. We provide an extensive\nanalysis of the behavior of the frame-level attention system in current speaker\nverification models and propose a novel speaker diarization pipeline using\nECAPA2 speaker embeddings for both VAD and embedding extraction. The proposed\nstrategy gains state-of-the-art performance on the AMI, VoxConverse and DIHARD\nIII diarization benchmarks.", "published": "2024-05-15 07:13:24", "link": "http://arxiv.org/abs/2405.09142v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hierarchical Emotion Prediction and Control in Text-to-Speech Synthesis", "abstract": "It remains a challenge to effectively control the emotion rendering in\ntext-to-speech (TTS) synthesis. Prior studies have primarily focused on\nlearning a global prosodic representation at the utterance level, which\nstrongly correlates with linguistic prosody. Our goal is to construct a\nhierarchical emotion distribution (ED) that effectively encapsulates intensity\nvariations of emotions at various levels of granularity, encompassing phonemes,\nwords, and utterances. During TTS training, the hierarchical ED is extracted\nfrom the ground-truth audio and guides the predictor to establish a connection\nbetween emotional and linguistic prosody. At run-time inference, the TTS model\ngenerates emotional speech and, at the same time, provides quantitative control\nof emotion over the speech constituents. Both objective and subjective\nevaluations validate the effectiveness of the proposed framework in terms of\nemotion prediction and control.", "published": "2024-05-15 08:21:56", "link": "http://arxiv.org/abs/2405.09171v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SMUG-Explain: A Framework for Symbolic Music Graph Explanations", "abstract": "In this work, we present Score MUsic Graph (SMUG)-Explain, a framework for\ngenerating and visualizing explanations of graph neural networks applied to\narbitrary prediction tasks on musical scores. Our system allows the user to\nvisualize the contribution of input notes (and note features) to the network\noutput, directly in the context of the musical score. We provide an interactive\ninterface based on the music notation engraving library Verovio. We showcase\nthe usage of SMUG-Explain on the task of cadence detection in classical music.\nAll code is available on https://github.com/manoskary/SMUG-Explain.", "published": "2024-05-15 10:41:47", "link": "http://arxiv.org/abs/2405.09241v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Introducing the Brand New QiandaoEar22 Dataset for Specific Ship\n  Identification Using Ship-Radiated Noise", "abstract": "Target identification of ship-radiated noise is a crucial area in underwater\ntarget recognition. However, there is currently a lack of multi-target ship\ndatasets that accurately represent real-world underwater acoustic conditions.\nTo ntackle this issue, we release QiandaoEar22 \\textemdash an underwater\nacoustic multi-target dataset, which can be download on\nhttps://ieee-dataport.org/documents/qiandaoear22. This dataset encompasses 9\nhours and 28 minutes of real-world ship-radiated noise data and 21 hours and 58\nminutes of background noise data. We demonstrate the availability of\nQiandaoEar22 by conducting an experiment of identifying specific ship from the\nmultiple targets. Taking different features as the input and six deep learning\nnetworks as classifier, we evaluate the baseline performance of different\nmethods. The experimental results reveal that identifying the specific target\nof UUV from others can achieve the optimal recognition accuracy of 97.78\\%, and\nwe find using spectrum and MFCC as feature inputs and DenseNet as the\nclassifier can achieve better recognition performance. Our work not only\nestablishes a benchmark for the dataset but helps the further development of\ninnovative methods for the tasks of underwater acoustic target detection (UATD)\nand underwater acoustic target recognition(UATR).", "published": "2024-05-15 06:59:20", "link": "http://arxiv.org/abs/2406.04353v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Naturalistic Music Decoding from EEG Data via Latent Diffusion Models", "abstract": "In this article, we explore the potential of using latent diffusion models, a\nfamily of powerful generative models, for the task of reconstructing\nnaturalistic music from electroencephalogram (EEG) recordings. Unlike simpler\nmusic with limited timbres, such as MIDI-generated tunes or monophonic pieces,\nthe focus here is on intricate music featuring a diverse array of instruments,\nvoices, and effects, rich in harmonics and timbre. This study represents an\ninitial foray into achieving general music reconstruction of high-quality using\nnon-invasive EEG data, employing an end-to-end training approach directly on\nraw data without the need for manual pre-processing and channel selection. We\ntrain our models on the public NMED-T dataset and perform quantitative\nevaluation proposing neural embedding-based metrics. Our work contributes to\nthe ongoing research in neural decoding and brain-computer interfaces, offering\ninsights into the feasibility of using EEG data for complex auditory\ninformation reconstruction.", "published": "2024-05-15 03:26:01", "link": "http://arxiv.org/abs/2405.09062v6", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Perception-Inspired Graph Convolution for Music Understanding Tasks", "abstract": "We propose a new graph convolutional block, called MusGConv, specifically\ndesigned for the efficient processing of musical score data and motivated by\ngeneral perceptual principles. It focuses on two fundamental dimensions of\nmusic, pitch and rhythm, and considers both relative and absolute\nrepresentations of these components. We evaluate our approach on four different\nmusical understanding problems: monophonic voice separation, harmonic analysis,\ncadence detection, and composer identification which, in abstract terms,\ntranslate to different graph learning problems, namely, node classification,\nlink prediction, and graph classification. Our experiments demonstrate that\nMusGConv improves the performance on three of the aforementioned tasks while\nbeing conceptually very simple and efficient. We interpret this as evidence\nthat it is beneficial to include perception-informed processing of fundamental\nmusical concepts when developing graph network applications on musical score\ndata.", "published": "2024-05-15 10:04:44", "link": "http://arxiv.org/abs/2405.09224v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Evaluating the Robustness of Automatic Speech Recognition\n  Systems via Audio Style Transfer", "abstract": "In light of the widespread application of Automatic Speech Recognition (ASR)\nsystems, their security concerns have received much more attention than ever\nbefore, primarily due to the susceptibility of Deep Neural Networks. Previous\nstudies have illustrated that surreptitiously crafting adversarial\nperturbations enables the manipulation of speech recognition systems, resulting\nin the production of malicious commands. These attack methods mostly require\nadding noise perturbations under $\\ell_p$ norm constraints, inevitably leaving\nbehind artifacts of manual modifications. Recent research has alleviated this\nlimitation by manipulating style vectors to synthesize adversarial examples\nbased on Text-to-Speech (TTS) synthesis audio. However, style modifications\nbased on optimization objectives significantly reduce the controllability and\neditability of audio styles. In this paper, we propose an attack on ASR systems\nbased on user-customized style transfer. We first test the effect of Style\nTransfer Attack (STA) which combines style transfer and adversarial attack in\nsequential order. And then, as an improvement, we propose an iterative Style\nCode Attack (SCA) to maintain audio quality. Experimental results show that our\nmethod can meet the need for user-customized styles and achieve a success rate\nof 82% in attacks, while keeping sound naturalness due to our user study.", "published": "2024-05-15 16:05:24", "link": "http://arxiv.org/abs/2405.09470v1", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dance Any Beat: Blending Beats with Visuals in Dance Video Generation", "abstract": "Generating dance from music is crucial for advancing automated choreography.\nCurrent methods typically produce skeleton keypoint sequences instead of dance\nvideos and lack the capability to make specific individuals dance, which\nreduces their real-world applicability. These methods also require precise\nkeypoint annotations, complicating data collection and limiting the use of\nself-collected video datasets. To overcome these challenges, we introduce a\nnovel task: generating dance videos directly from images of individuals guided\nby music. This task enables the dance generation of specific individuals\nwithout requiring keypoint annotations, making it more versatile and applicable\nto various situations. Our solution, the Dance Any Beat Diffusion model\n(DabFusion), utilizes a reference image and a music piece to generate dance\nvideos featuring various dance types and choreographies. The music is analyzed\nby our specially designed music encoder, which identifies essential features\nincluding dance style, movement, and rhythm. DabFusion excels in generating\ndance videos not only for individuals in the training dataset but also for any\npreviously unseen person. This versatility stems from its approach of\ngenerating latent optical flow, which contains all necessary motion information\nto animate any person in the image. We evaluate DabFusion's performance using\nthe AIST++ dataset, focusing on video quality, audio-video synchronization, and\nmotion-music alignment. We propose a 2D Motion-Music Alignment Score (2D-MM\nAlign), which builds on the Beat Alignment Score to more effectively evaluate\nmotion-music alignment for this new task. Experiments show that our DabFusion\nestablishes a solid baseline for this innovative task. Video results can be\nfound on our project page: https://DabFusion.github.io.", "published": "2024-05-15 11:33:07", "link": "http://arxiv.org/abs/2405.09266v3", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
