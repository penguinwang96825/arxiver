{"title": "Bayesian CART models for aggregate claim modeling", "abstract": "This paper proposes three types of Bayesian CART (or BCART) models for\naggregate claim amount, namely, frequency-severity models, sequential models\nand joint models. We propose a general framework for the BCART models\napplicable to data with multivariate responses, which is particularly useful\nfor the joint BCART models with a bivariate response: the number of claims and\naggregate claim amount. To facilitate frequency-severity modeling, we\ninvestigate BCART models for the right-skewed and heavy-tailed claim severity\ndata by using various distributions. We discover that the Weibull distribution\nis superior to gamma and lognormal distributions, due to its ability to capture\ndifferent tail characteristics in tree models. Additionally, we find that\nsequential BCART models and joint BCART models, which incorporate dependence\nbetween the number of claims and average severity, are beneficial and thus\npreferable to the frequency-severity BCART models in which independence is\nassumed. The effectiveness of these models' performance is illustrated by\ncarefully designed simulations and real insurance data.", "published": "2024-09-03 13:58:09", "link": "http://arxiv.org/abs/2409.01908v1", "categories": ["stat.ME", "cs.LG", "q-fin.ST", "stat.AP", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Review of the EU ETS Literature: A Bibliometric Perspective", "abstract": "This study conducts a bibliometric review of scientific literature on the\nEuropean Union Emissions Trading System (EU ETS) from 2004 to 2024, using\nresearch articles from the Scopus database. Using the Bibliometrix R package,\nwe analyze publication trends, key themes, influential authors, and prominent\njournals related to the EU ETS. Our results indicate a notable increase in\nresearch activity over the past two decades, particularly during significant\npolicy changes and economic events affecting carbon markets. Key research\nfocuses include carbon pricing, market volatility, and economic impacts,\nhighlighting a shift toward financial analysis and policy implications.\nThematic mapping shows cap-and-trade systems, and carbon leakage as central\ntopics linking various research areas. Additionally, we observe key areas where\nfurther research could be beneficial, such as expanding non-parametric\nmethodologies, deepening the exploration of macroeconomic factors, and\nenhancing the examination of financial market connections. Moreover, we\nhighlight recent and innovative papers that contribute new insights, showcasing\nemerging trends and cutting-edge approaches within the field. This review\nprovides insights for researchers and policymakers, highlighting the evolving\nlandscape of EU ETS research and its relevance to global climate strategies.", "published": "2024-09-03 09:30:19", "link": "http://arxiv.org/abs/2409.01739v3", "categories": ["q-fin.ST", "91B76, 91B82, 91B44, 62P20, 91B84, 62-00", "H.3.7; H.2.8; I.2.7"], "primary_category": "q-fin.ST"}
{"title": "Logarithmic regret in the ergodic Avellaneda-Stoikov market making model", "abstract": "We analyse the regret arising from learning the price sensitivity parameter\n$\\kappa$ of liquidity takers in the ergodic version of the Avellaneda-Stoikov\nmarket making model. We show that a learning algorithm based on a regularised\nmaximum-likelihood estimator for the parameter achieves the regret upper bound\nof order $\\ln^2 T$ in expectation. To obtain the result we need two key\ningredients. The first are tight upper bounds on the derivative of the ergodic\nconstant in the Hamilton-Jacobi-Bellman (HJB) equation with respect to\n$\\kappa$. The second is the learning rate of the maximum-likelihood estimator\nwhich is obtained from concentration inequalities for Bernoulli signals.\nNumerical experiment confirms the convergence and the robustness of the\nproposed algorithm.", "published": "2024-09-03 16:20:07", "link": "http://arxiv.org/abs/2409.02025v1", "categories": ["math.OC", "q-fin.TR", "Primary 93E35, Secondary 93C40, 93C41, 93E20, 91G80"], "primary_category": "math.OC"}
{"title": "It is Time to Develop an Auditing Framework to Promote Value Aware\n  Chatbots", "abstract": "The launch of ChatGPT in November 2022 marked the beginning of a new era in\nAI, the availability of generative AI tools for everyone to use. ChatGPT and\nother similar chatbots boast a wide range of capabilities from answering\nstudent homework questions to creating music and art. Given the large amounts\nof human data chatbots are built on, it is inevitable that they will inherit\nhuman errors and biases. These biases have the potential to inflict significant\nharm or increase inequity on different subpopulations. Because chatbots do not\nhave an inherent understanding of societal values, they may create new content\nthat is contrary to established norms. Examples of concerning generated content\nincludes child pornography, inaccurate facts, and discriminatory posts. In this\nposition paper, we argue that the speed of advancement of this technology\nrequires us, as computer and data scientists, to mobilize and develop a\nvalues-based auditing framework containing a community established standard set\nof measurements to monitor the health of different chatbots and LLMs. To\nsupport our argument, we use a simple audit template to share the results of\nbasic audits we conduct that are focused on measuring potential bias in search\nengine style tasks, code generation, and story generation. We identify\nresponses from GPT 3.5 and GPT 4 that are both consistent and not consistent\nwith values derived from existing law. While the findings come as no surprise,\nthey do underscore the urgency of developing a robust auditing framework for\nopenly sharing results in a consistent way so that mitigation strategies can be\ndeveloped by the academic community, government agencies, and companies when\nour values are not being adhered to. We conclude this paper with\nrecommendations for value-based strategies for improving the technologies.", "published": "2024-09-03 02:15:34", "link": "http://arxiv.org/abs/2409.01539v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Implementation of Werewolf Agent That does not Truly Trust LLMs", "abstract": "Werewolf is an incomplete information game, which has several challenges when\ncreating a computer agent as a player given the lack of understanding of the\nsituation and individuality of utterance (e.g., computer agents are not capable\nof characterful utterance or situational lying). We propose a werewolf agent\nthat solves some of those difficulties by combining a Large Language Model\n(LLM) and a rule-based algorithm. In particular, our agent uses a rule-based\nalgorithm to select an output either from an LLM or a template prepared\nbeforehand based on the results of analyzing conversation history using an LLM.\nIt allows the agent to refute in specific situations, identify when to end the\nconversation, and behave with persona. This approach mitigated conversational\ninconsistencies and facilitated logical utterance as a result. We also\nconducted a qualitative evaluation, which resulted in our agent being perceived\nas more human-like compared to an unmodified LLM. The agent is freely available\nfor contributing to advance the research in the field of Werewolf game.", "published": "2024-09-03 03:16:03", "link": "http://arxiv.org/abs/2409.01575v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision\n  Language Models", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves,\nthey are increasingly capable of responding in multiple languages, and there is\nan expectation that the demand for explanations generated by LVLMs will grow.\nHowever, pre-training of Vision Encoder and the integrated training of LLMs\nwith Vision Encoder are mainly conducted using English training data, leaving\nit uncertain whether LVLMs can completely handle their potential when\ngenerating explanations in languages other than English. In addition,\nmultilingual QA benchmarks that create datasets using machine translation have\ncultural differences and biases, remaining issues for use as evaluation tasks.\nTo address these challenges, this study created an extended dataset in multiple\nlanguages without relying on machine translation. This dataset that takes into\naccount nuances and country-specific phrases was then used to evaluate the\ngeneration explanation abilities of LVLMs. Furthermore, this study examined\nwhether Instruction-Tuning in resource-rich English improves performance in\nother languages. Our findings indicate that LVLMs perform worse in languages\nother than English compared to English. In addition, it was observed that LVLMs\nstruggle to effectively manage the knowledge learned from English data. Our\ndataset is available at https://huggingface.co/datasets/naist-nlp/MultiExpArt", "published": "2024-09-03 03:42:56", "link": "http://arxiv.org/abs/2409.01584v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Yes-Men to Truth-Tellers: Addressing Sycophancy in Large Language\n  Models with Pinpoint Tuning", "abstract": "Large Language Models (LLMs) tend to prioritize adherence to user prompts\nover providing veracious responses, leading to the sycophancy issue. When\nchallenged by users, LLMs tend to admit mistakes and provide inaccurate\nresponses even if they initially provided the correct answer. Recent works\npropose to employ supervised fine-tuning (SFT) to mitigate the sycophancy\nissue, while it typically leads to the degeneration of LLMs' general\ncapability. To address the challenge, we propose a novel supervised pinpoint\ntuning (SPT), where the region-of-interest modules are tuned for a given\nobjective. Specifically, SPT first reveals and verifies a small percentage\n(<5%) of the basic modules, which significantly affect a particular behavior of\nLLMs. i.e., sycophancy. Subsequently, SPT merely fine-tunes these identified\nmodules while freezing the rest. To verify the effectiveness of the proposed\nSPT, we conduct comprehensive experiments, demonstrating that SPT significantly\nmitigates the sycophancy issue of LLMs (even better than SFT). Moreover, SPT\nintroduces limited or even no side effects on the general capability of LLMs.\nOur results shed light on how to precisely, effectively, and efficiently\nexplain and improve the targeted ability of LLMs. Code and data are available\nat https://github.com/yellowtownhz/sycophancy-interpretability.", "published": "2024-09-03 07:01:37", "link": "http://arxiv.org/abs/2409.01658v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpreting and Improving Large Language Models in Arithmetic\n  Calculation", "abstract": "Large language models (LLMs) have demonstrated remarkable potential across\nnumerous applications and have shown an emergent ability to tackle complex\nreasoning tasks, such as mathematical computations. However, even for the\nsimplest arithmetic calculations, the intrinsic mechanisms behind LLMs remain\nmysterious, making it challenging to ensure reliability. In this work, we delve\ninto uncovering a specific mechanism by which LLMs execute calculations.\nThrough comprehensive experiments, we find that LLMs frequently involve a small\nfraction (< 5%) of attention heads, which play a pivotal role in focusing on\noperands and operators during calculation processes. Subsequently, the\ninformation from these operands is processed through multi-layer perceptrons\n(MLPs), progressively leading to the final solution. These pivotal heads/MLPs,\nthough identified on a specific dataset, exhibit transferability across\ndifferent datasets and even distinct tasks. This insight prompted us to\ninvestigate the potential benefits of selectively fine-tuning these essential\nheads/MLPs to boost the LLMs' computational performance. We empirically find\nthat such precise tuning can yield notable enhancements on mathematical\nprowess, without compromising the performance on non-mathematical tasks. Our\nwork serves as a preliminary exploration into the arithmetic calculation\nabilities inherent in LLMs, laying a solid foundation to reveal more intricate\nmathematical tasks.", "published": "2024-09-03 07:01:46", "link": "http://arxiv.org/abs/2409.01659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In Defense of RAG in the Era of Long-Context Language Models", "abstract": "Overcoming the limited context limitations in early-generation LLMs,\nretrieval-augmented generation (RAG) has been a reliable solution for\ncontext-based answer generation in the past. Recently, the emergence of\nlong-context LLMs allows the models to incorporate much longer text sequences,\nmaking RAG less attractive. Recent studies show that long-context LLMs\nsignificantly outperform RAG in long-context applications. Unlike the existing\nworks favoring the long-context LLM over RAG, we argue that the extremely long\ncontext in LLMs suffers from a diminished focus on relevant information and\nleads to potential degradation in answer quality. This paper revisits the RAG\nin long-context answer generation. We propose an order-preserve\nretrieval-augmented generation (OP-RAG) mechanism, which significantly improves\nthe performance of RAG for long-context question-answer applications. With\nOP-RAG, as the number of retrieved chunks increases, the answer quality\ninitially rises, and then declines, forming an inverted U-shaped curve. There\nexist sweet points where OP-RAG could achieve higher answer quality with much\nless tokens than long-context LLM taking the whole context as input. Extensive\nexperiments on public benchmark demonstrate the superiority of our OP-RAG.", "published": "2024-09-03 07:17:41", "link": "http://arxiv.org/abs/2409.01666v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "State-of-the-art Advances of Deep-learning Linguistic Steganalysis\n  Research", "abstract": "With the evolution of generative linguistic steganography techniques,\nconventional steganalysis falls short in robustly quantifying the alterations\ninduced by steganography, thereby complicating detection. Consequently, the\nresearch paradigm has pivoted towards deep-learning-based linguistic\nsteganalysis. This study offers a comprehensive review of existing\ncontributions and evaluates prevailing developmental trajectories.\nSpecifically, we first provided a formalized exposition of the general formulas\nfor linguistic steganalysis, while comparing the differences between this field\nand the domain of text classification. Subsequently, we classified the existing\nwork into two levels based on vector space mapping and feature extraction\nmodels, thereby comparing the research motivations, model advantages, and other\ndetails. A comparative analysis of the experiments is conducted to assess the\nperformances. Finally, the challenges faced by this field are discussed, and\nseveral directions for future development and key issues that urgently need to\nbe addressed are proposed.", "published": "2024-09-03 10:49:42", "link": "http://arxiv.org/abs/2409.01780v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-GAN: Construct Generative Adversarial Network Through Large Language\n  Models For Explainable Fake News Detection", "abstract": "Explainable fake news detection predicts the authenticity of news items with\nannotated explanations. Today, Large Language Models (LLMs) are known for their\npowerful natural language understanding and explanation generation abilities.\nHowever, presenting LLMs for explainable fake news detection remains two main\nchallenges. Firstly, fake news appears reasonable and could easily mislead\nLLMs, leaving them unable to understand the complex news-faking process.\nSecondly, utilizing LLMs for this task would generate both correct and\nincorrect explanations, which necessitates abundant labor in the loop. In this\npaper, we propose LLM-GAN, a novel framework that utilizes prompting mechanisms\nto enable an LLM to become Generator and Detector and for realistic fake news\ngeneration and detection. Our results demonstrate LLM-GAN's effectiveness in\nboth prediction performance and explanation quality. We further showcase the\nintegration of LLM-GAN to a cloud-native AI platform to provide better fake\nnews detection service in the cloud.", "published": "2024-09-03 11:06:45", "link": "http://arxiv.org/abs/2409.01787v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AgentRE: An Agent-Based Framework for Navigating Complex Information\n  Landscapes in Relation Extraction", "abstract": "The relation extraction (RE) in complex scenarios faces challenges such as\ndiverse relation types and ambiguous relations between entities within a single\nsentence, leading to the poor performance of pure \"text-in, text-out\" language\nmodels (LMs). To address these challenges, in this paper, we propose an\nagent-based RE framework, namely AgentRE, which fully leverages the potential\nof large language models (LLMs) including memory, retrieval and reflection, to\nachieve RE in complex scenarios. Specifically, three major modules are built in\nAgentRE serving as the tools to help the agent acquire and process various\nuseful information, thereby obtaining improved RE performance. Our extensive\nexperimental results upon two datasets in English and Chinese demonstrate our\nAgentRE's superior performance, especially in low-resource scenarios.\nAdditionally, the trajectories generated by AgentRE can be refined to construct\na high-quality training dataset incorporating different reasoning methods,\nwhich can be used to fine-tune smaller models. Code is available at\nhttps://github.com/Lightblues/AgentRE.", "published": "2024-09-03 12:53:05", "link": "http://arxiv.org/abs/2409.01854v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Expert-in-the-Loop LLM Discourse Patterns for Ancient\n  Intertextual Analysis", "abstract": "This study explores the potential of large language models (LLMs) for\nidentifying and examining intertextual relationships within biblical, Koine\nGreek texts. By evaluating the performance of LLMs on various intertextuality\nscenarios the study demonstrates that these models can detect direct\nquotations, allusions, and echoes between texts. The LLM's ability to generate\nnovel intertextual observations and connections highlights its potential to\nuncover new insights. However, the model also struggles with long query\npassages and the inclusion of false intertextual dependences, emphasizing the\nimportance of expert evaluation. The expert-in-the-loop methodology presented\noffers a scalable approach for intertextual research into the complex web of\nintertextuality within and beyond the biblical corpus.", "published": "2024-09-03 13:23:11", "link": "http://arxiv.org/abs/2409.01882v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FuzzCoder: Byte-level Fuzzing Test via Large Language Model", "abstract": "Fuzzing is an important dynamic program analysis technique designed for\nfinding vulnerabilities in complex software. Fuzzing involves presenting a\ntarget program with crafted malicious input to cause crashes, buffer overflows,\nmemory errors, and exceptions. Crafting malicious inputs in an efficient manner\nis a difficult open problem and the best approaches often apply uniform random\nmutations to pre-existing valid inputs. In this work, we propose to adopt\nfine-tuned large language models (FuzzCoder) to learn patterns in the input\nfiles from successful attacks to guide future fuzzing explorations.\nSpecifically, we develop a framework to leverage the code LLMs to guide the\nmutation process of inputs in fuzzing. The mutation process is formulated as\nthe sequence-to-sequence modeling, where LLM receives a sequence of bytes and\nthen outputs the mutated byte sequence. FuzzCoder is fine-tuned on the created\ninstruction dataset (Fuzz-Instruct), where the successful fuzzing history is\ncollected from the heuristic fuzzing tool. FuzzCoder can predict mutation\nlocations and strategies locations in input files to trigger abnormal behaviors\nof the program. Experimental results show that FuzzCoder based on AFL (American\nFuzzy Lop) gain significant improvements in terms of effective proportion of\nmutation (EPM) and number of crashes (NC) for various input formats including\nELF, JPG, MP3, and XML.", "published": "2024-09-03 14:40:31", "link": "http://arxiv.org/abs/2409.01944v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LongGenBench: Benchmarking Long-Form Generation in Long Context LLMs", "abstract": "Current benchmarks like Needle-in-a-Haystack (NIAH), Ruler, and Needlebench\nfocus on models' ability to understand long-context input sequences but fail to\ncapture a critical dimension: the generation of high-quality long-form text.\nApplications such as design proposals, technical documentation, and creative\nwriting rely on coherent, instruction-following outputs over extended sequences\n- a challenge that existing benchmarks do not adequately address. To fill this\ngap, we introduce LongGenBench, a novel benchmark designed to rigorously\nevaluate large language models' (LLMs) ability to generate long text while\nadhering to complex instructions. Through tasks requiring specific events or\nconstraints within generated text, LongGenBench evaluates model performance\nacross four distinct scenarios, three instruction types, and two\ngeneration-lengths (16K and 32K tokens). Our evaluation of ten state-of-the-art\nLLMs reveals that, despite strong results on Ruler, all models struggled with\nlong text generation on LongGenBench, particularly as text length increased.\nThis suggests that current LLMs are not yet equipped to meet the demands of\nreal-world, long-form text generation.", "published": "2024-09-03 17:25:54", "link": "http://arxiv.org/abs/2409.02076v7", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Political DEBATE: Efficient Zero-shot and Few-shot Classifiers for\n  Political Text", "abstract": "Social scientists quickly adopted large language models due to their ability\nto annotate documents without supervised training, an ability known as\nzero-shot learning. However, due to their compute demands, cost, and often\nproprietary nature, these models are often at odds with replication and open\nscience standards. This paper introduces the Political DEBATE (DeBERTa\nAlgorithm for Textual Entailment) language models for zero-shot and few-shot\nclassification of political documents. These models are not only as good, or\nbetter than, state-of-the art large language models at zero and few-shot\nclassification, but are orders of magnitude more efficient and completely open\nsource. By training the models on a simple random sample of 10-25 documents,\nthey can outperform supervised classifiers trained on hundreds or thousands of\ndocuments and state-of-the-art generative models with complex, engineered\nprompts. Additionally, we release the PolNLI dataset used to train these models\n-- a corpus of over 200,000 political documents with highly accurate labels\nacross over 800 classification tasks.", "published": "2024-09-03 17:26:17", "link": "http://arxiv.org/abs/2409.02078v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "S^3cMath: Spontaneous Step-level Self-correction Makes Large Language\n  Models Better Mathematical Reasoners", "abstract": "Self-correction is a novel method that can stimulate the potential reasoning\nabilities of large language models (LLMs). It involves detecting and correcting\nerrors during the inference process when LLMs solve reasoning problems.\nHowever, recent works do not regard self-correction as a spontaneous and\nintrinsic capability of LLMs. Instead, such correction is achieved through\npost-hoc generation, external knowledge introduction, multi-model\ncollaboration, and similar techniques. In this paper, we propose a series of\nmathematical LLMs called S$^3$c-Math, which are able to perform Spontaneous\nStep-level Self-correction for Mathematical reasoning. This capability helps\nLLMs to recognize whether their ongoing inference tends to contain errors and\nsimultaneously correct these errors to produce a more reliable response. We\nproposed a method, which employs a step-level sampling approach to construct\nstep-wise self-correction data for achieving such ability. Additionally, we\nimplement a training strategy that uses above constructed data to equip LLMs\nwith spontaneous step-level self-correction capacities. Our data and methods\nhave been demonstrated to be effective across various foundation LLMs,\nconsistently showing significant progress in evaluations on GSM8K, MATH, and\nother mathematical benchmarks. To the best of our knowledge, we are the first\nto introduce the spontaneous step-level self-correction ability of LLMs in\nmathematical reasoning.", "published": "2024-09-03 01:40:21", "link": "http://arxiv.org/abs/2409.01524v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Instructed Derived Prompt Generation Meets In-Context Learning:\n  Unlocking New Potential of Black-Box LLMs", "abstract": "Large language models (LLMs) have shown success in generating high-quality\nresponses. In order to achieve better alignment with LLMs with human\npreference, various works are proposed based on specific optimization process,\nwhich, however, is not suitable to Black-Box LLMs like GPT-4, due to\ninaccessible parameters. In Black-Box LLMs case, their performance is highly\ndependent on the quality of the provided prompts. Existing methods to enhance\nresponse quality often involve a prompt refinement model, yet these approaches\npotentially suffer from semantic inconsistencies between the refined and\noriginal prompts, and typically overlook the relationship between them. To\naddress these challenges, we introduce a self-instructed in-context learning\nframework that empowers LLMs to deliver more effective responses by generating\nreliable derived prompts to construct informative contextual environments. Our\napproach incorporates a self-instructed reinforcement learning mechanism,\nenabling direct interaction with the response model during derived prompt\ngeneration for better alignment. We then formulate querying as an in-context\nlearning task, using responses from LLMs combined with the derived prompts to\nestablish a contextual demonstration for the original prompt. This strategy\nensures alignment with the original query, reduces discrepancies from refined\nprompts, and maximizes the LLMs' in-context learning capability. Extensive\nexperiments demonstrate that the proposed method not only generates more\nreliable derived prompts but also significantly enhances LLMs' ability to\ndeliver more effective responses, including Black-Box models such as GPT-4.", "published": "2024-09-03 02:42:39", "link": "http://arxiv.org/abs/2409.01552v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmarking Cognitive Domains for LLMs: Insights from Taiwanese Hakka\n  Culture", "abstract": "This study introduces a comprehensive benchmark designed to evaluate the\nperformance of large language models (LLMs) in understanding and processing\ncultural knowledge, with a specific focus on Hakka culture as a case study.\nLeveraging Bloom's Taxonomy, the study develops a multi-dimensional framework\nthat systematically assesses LLMs across six cognitive domains: Remembering,\nUnderstanding, Applying, Analyzing, Evaluating, and Creating. This benchmark\nextends beyond traditional single-dimensional evaluations by providing a deeper\nanalysis of LLMs' abilities to handle culturally specific content, ranging from\nbasic recall of facts to higher-order cognitive tasks such as creative\nsynthesis. Additionally, the study integrates Retrieval-Augmented Generation\n(RAG) technology to address the challenges of minority cultural knowledge\nrepresentation in LLMs, demonstrating how RAG enhances the models' performance\nby dynamically incorporating relevant external information. The results\nhighlight the effectiveness of RAG in improving accuracy across all cognitive\ndomains, particularly in tasks requiring precise retrieval and application of\ncultural knowledge. However, the findings also reveal the limitations of RAG in\ncreative tasks, underscoring the need for further optimization. This benchmark\nprovides a robust tool for evaluating and comparing LLMs in culturally diverse\ncontexts, offering valuable insights for future research and development in\nAI-driven cultural knowledge preservation and dissemination.", "published": "2024-09-03 02:50:04", "link": "http://arxiv.org/abs/2409.01556v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AdaComp: Extractive Context Compression with Adaptive Predictor for\n  Retrieval-Augmented Large Language Models", "abstract": "Retrieved documents containing noise will hinder RAG from detecting answer\nclues and make the inference process slow and expensive. Therefore, context\ncompression is necessary to enhance its accuracy and efficiency. Existing\ncontext compression methods use extractive or generative models to retain the\nmost query-relevant sentences or apply the information bottleneck theory to\npreserve sufficient information. However, these methods may face issues such as\nover-compression or high computational costs. We observe that the retriever\noften ranks relevant documents at the top, but the exact number of documents\nneeded to answer the query is uncertain due to the impact of query complexity\nand retrieval quality: complex queries like multi-hop questions may require\nretaining more documents than simpler queries, and a low-quality retrieval may\nneed to rely on more documents to generate accurate outputs. Therefore,\ndetermining the minimum number of required documents (compression rate) is\nstill a challenge for RAG. In this paper, we introduce AdaComp, a low-cost\nextractive context compression method that adaptively determines the\ncompression rate based on both query complexity and retrieval quality.\nSpecifically, we first annotate the minimum top-k documents necessary for the\nRAG system to answer the current query as the compression rate and then\nconstruct triplets of the query, retrieved documents, and its compression rate.\nThen, we use this triplet dataset to train a compression-rate predictor.\nExperiments on three QA datasets and one conversational Muiti-doc QA dataset\nshow that AdaComp significantly reduces inference costs while maintaining\nperformance nearly identical to uncompressed models, achieving a balance\nbetween efficiency and performance.", "published": "2024-09-03 03:25:59", "link": "http://arxiv.org/abs/2409.01579v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Booster: Tackling Harmful Fine-tuning for Large Language Models via\n  Attenuating Harmful Perturbation", "abstract": "Harmful fine-tuning attack poses serious safety concerns for large language\nmodels' fine-tuning-as-a-service. While existing defenses have been proposed to\nmitigate the issue, their performances are still far away from satisfactory,\nand the root cause of the problem has not been fully recovered. To this end, we\nin this paper show that harmful perturbation over the model weights could be a\nprobable cause of alignment-broken. In order to attenuate the negative impact\nof harmful perturbation, we propose an alignment-stage solution, dubbed\nBooster. Technically, along with the original alignment loss, we append a loss\nregularizer in the alignment stage's optimization. The regularizer ensures that\nthe model's harmful loss reduction after the simulated harmful perturbation is\nattenuated, thereby mitigating the subsequent fine-tuning risk. Empirical\nresults show that Booster can effectively reduce the harmful score of the\nfine-tuned models while maintaining the performance of downstream tasks. Our\ncode is available at https://github.com/git-disl/Booster.", "published": "2024-09-03 03:59:22", "link": "http://arxiv.org/abs/2409.01586v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CTG-KrEW: Generating Synthetic Structured Contextually Correlated\n  Content by Conditional Tabular GAN with K-Means Clustering and Efficient Word\n  Embedding", "abstract": "Conditional Tabular Generative Adversarial Networks (CTGAN) and their various\nderivatives are attractive for their ability to efficiently and flexibly create\nsynthetic tabular data, showcasing strong performance and adaptability.\nHowever, there are certain critical limitations to such models. The first is\ntheir inability to preserve the semantic integrity of contextually correlated\nwords or phrases. For instance, skillset in freelancer profiles is one such\nattribute where individual skills are semantically interconnected and\nindicative of specific domain interests or qualifications. The second challenge\nof traditional approaches is that, when applied to generate contextually\ncorrelated tabular content, besides generating semantically shallow content,\nthey consume huge memory resources and CPU time during the training stage. To\naddress these problems, we introduce a novel framework, CTGKrEW (Conditional\nTabular GAN with KMeans Clustering and Word Embedding), which is adept at\ngenerating realistic synthetic tabular data where attributes are collections of\nsemantically and contextually coherent words. CTGKrEW is trained and evaluated\nusing a dataset from Upwork, a realworld freelancing platform. Comprehensive\nexperiments were conducted to analyze the variability, contextual similarity,\nfrequency distribution, and associativity of the generated data, along with\ntesting the framework's system feasibility. CTGKrEW also takes around 99\\% less\nCPU time and 33\\% less memory footprints than the conventional approach.\nFurthermore, we developed KrEW, a web application to facilitate the generation\nof realistic data containing skill-related information. This application,\navailable at https://riyasamanta.github.io/krew.html, is freely accessible to\nboth the general public and the research community.", "published": "2024-09-03 05:53:57", "link": "http://arxiv.org/abs/2409.01628v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Taming CLIP for Fine-grained and Structured Visual Understanding of\n  Museum Exhibits", "abstract": "CLIP is a powerful and widely used tool for understanding images in the\ncontext of natural language descriptions to perform nuanced tasks. However, it\ndoes not offer application-specific fine-grained and structured understanding,\ndue to its generic nature. In this work, we aim to adapt CLIP for fine-grained\nand structured -- in the form of tabular data -- visual understanding of museum\nexhibits. To facilitate such understanding we (a) collect, curate, and\nbenchmark a dataset of 200K+ image-table pairs, and (b) develop a method that\nallows predicting tabular outputs for input images. Our dataset is the first of\nits kind in the public domain. At the same time, the proposed method is novel\nin leveraging CLIP's powerful representations for fine-grained and tabular\nunderstanding. The proposed method (MUZE) learns to map CLIP's image embeddings\nto the tabular structure by means of a proposed transformer-based parsing\nnetwork (parseNet). More specifically, parseNet enables prediction of missing\nattribute values while integrating context from known attribute-value pairs for\nan input image. We show that this leads to significant improvement in accuracy.\nThrough exhaustive experiments, we show the effectiveness of the proposed\nmethod on fine-grained and structured understanding of museum exhibits, by\nachieving encouraging results in a newly established benchmark. Our dataset and\nsource-code can be found at: https://github.com/insait-institute/MUZE", "published": "2024-09-03 08:13:06", "link": "http://arxiv.org/abs/2409.01690v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "FC-KAN: Function Combinations in Kolmogorov-Arnold Networks", "abstract": "In this paper, we introduce FC-KAN, a Kolmogorov-Arnold Network (KAN) that\nleverages combinations of popular mathematical functions such as B-splines,\nwavelets, and radial basis functions on low-dimensional data through\nelement-wise operations. We explore several methods for combining the outputs\nof these functions, including sum, element-wise product, the addition of sum\nand element-wise product, representations of quadratic and cubic functions,\nconcatenation, linear transformation of the concatenated output, and others. In\nour experiments, we compare FC-KAN with a multi-layer perceptron network (MLP)\nand other existing KANs, such as BSRBF-KAN, EfficientKAN, FastKAN, and\nFasterKAN, on the MNIST and Fashion-MNIST datasets. Two variants of FC-KAN,\nwhich use a combination of outputs from B-splines and Difference of Gaussians\n(DoG) and from B-splines and linear transformations in the form of a quadratic\nfunction, outperformed overall other models on the average of 5 independent\ntraining runs. We expect that FC-KAN can leverage function combinations to\ndesign future KANs. Our repository is publicly available at:\nhttps://github.com/hoangthangta/FC_KAN.", "published": "2024-09-03 10:16:43", "link": "http://arxiv.org/abs/2409.01763v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Training on the Benchmark Is Not All You Need", "abstract": "The success of Large Language Models (LLMs) relies heavily on the huge amount\nof pre-training data learned in the pre-training phase. The opacity of the\npre-training process and the training data causes the results of many benchmark\ntests to become unreliable. If any model has been trained on a benchmark test\nset, it can seriously hinder the health of the field. In order to automate and\nefficiently test the capabilities of large language models, numerous mainstream\nbenchmarks adopt a multiple-choice format. As the swapping of the contents of\nmultiple-choice options does not affect the meaning of the question itself, we\npropose a simple and effective data leakage detection method based on this\nproperty. Specifically, we shuffle the contents of the options in the data to\ngenerate the corresponding derived data sets, and then detect data leakage\nbased on the model's log probability distribution over the derived data sets.\nIf there is a maximum and outlier in the set of log probabilities, it indicates\nthat the data is leaked. Our method is able to work under gray-box conditions\nwithout access to model training data or weights, effectively identifying data\nleakage from benchmark test sets in model pre-training data, including both\nnormal scenarios and complex scenarios where options may have been shuffled\nintentionally or unintentionally. Through experiments based on two LLMs and\nbenchmark designs, we demonstrate the effectiveness of our method. In addition,\nwe evaluate the degree of data leakage of 35 mainstream open-source LLMs on\nfour benchmark datasets and give a ranking of the leaked LLMs for each\nbenchmark, and we find that the Qwen family of LLMs has the highest degree of\ndata leakage.", "published": "2024-09-03 11:09:44", "link": "http://arxiv.org/abs/2409.01790v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dialogue You Can Trust: Human and AI Perspectives on Generated\n  Conversations", "abstract": "As dialogue systems and chatbots increasingly integrate into everyday\ninteractions, the need for efficient and accurate evaluation methods becomes\nparamount. This study explores the comparative performance of human and AI\nassessments across a range of dialogue scenarios, focusing on seven key\nperformance indicators (KPIs): Coherence, Innovation, Concreteness, Goal\nContribution, Commonsense Contradiction, Incorrect Fact, and Redundancy.\nUtilizing the GPT-4o API, we generated a diverse dataset of conversations and\nconducted a two-part experimental analysis. In Experiment 1, we evaluated\nmulti-party conversations on Coherence, Innovation, Concreteness, and Goal\nContribution, revealing that GPT models align closely with human judgments.\nNotably, both human and AI evaluators exhibited a tendency towards binary\njudgment rather than linear scaling, highlighting a shared challenge in these\nassessments. Experiment 2 extended the work of Finch et al. (2023) by focusing\non dyadic dialogues and assessing Commonsense Contradiction, Incorrect Fact,\nand Redundancy. The results indicate that while GPT-4o demonstrates strong\nperformance in maintaining factual accuracy and commonsense reasoning, it still\nstruggles with reducing redundancy and self-contradiction. Our findings\nunderscore the potential of GPT models to closely replicate human evaluation in\ndialogue systems, while also pointing to areas for improvement. This research\noffers valuable insights for advancing the development and implementation of\nmore refined dialogue evaluation methodologies, contributing to the evolution\nof more effective and human-like AI communication tools.", "published": "2024-09-03 11:40:38", "link": "http://arxiv.org/abs/2409.01808v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Generative Class Prompt Learning for Fine-grained Visual\n  Recognition", "abstract": "Although foundational vision-language models (VLMs) have proven to be very\nsuccessful for various semantic discrimination tasks, they still struggle to\nperform faithfully for fine-grained categorization. Moreover, foundational\nmodels trained on one domain do not generalize well on a different domain\nwithout fine-tuning. We attribute these to the limitations of the VLM's\nsemantic representations and attempt to improve their fine-grained visual\nawareness using generative modeling. Specifically, we propose two novel\nmethods: Generative Class Prompt Learning (GCPL) and Contrastive Multi-class\nPrompt Learning (CoMPLe). Utilizing text-to-image diffusion models, GCPL\nsignificantly improves the visio-linguistic synergy in class embeddings by\nconditioning on few-shot exemplars with learnable class prompts. CoMPLe builds\non this foundation by introducing a contrastive learning component that\nencourages inter-class separation during the generative optimization process.\nOur empirical results demonstrate that such a generative class prompt learning\napproach substantially outperform existing methods, offering a better\nalternative to few shot image recognition challenges. The source code will be\nmade available at: https://github.com/soumitri2001/GCPL.", "published": "2024-09-03 12:34:21", "link": "http://arxiv.org/abs/2409.01835v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "What are the Essential Factors in Crafting Effective Long Context\n  Multi-Hop Instruction Datasets? Insights and Best Practices", "abstract": "Recent advancements in large language models (LLMs) with extended context\nwindows have significantly improved tasks such as information extraction,\nquestion answering, and complex planning scenarios. In order to achieve success\nin long context tasks, a large amount of work has been done to enhance the long\ncontext capabilities of the model through synthetic data. Existing methods\ntypically utilize the Self-Instruct framework to generate instruction tuning\ndata for better long context capability improvement. However, our preliminary\nexperiments indicate that less than 35% of generated samples are multi-hop, and\nmore than 40% exhibit poor quality, limiting comprehensive understanding and\nfurther research. To improve the quality of synthetic data, we propose the\nMulti-agent Interactive Multi-hop Generation (MIMG) framework, incorporating a\nQuality Verification Agent, a Single-hop Question Generation Agent, a Multiple\nQuestion Sampling Strategy, and a Multi-hop Question Merger Agent. This\nframework improves the data quality, with the proportion of high-quality,\nmulti-hop, and diverse data exceeding 85%. Furthermore, we systematically\ninvestigate strategies for document selection, question merging, and validation\ntechniques through extensive experiments across various models. Our findings\nshow that our synthetic high-quality long-context instruction data\nsignificantly enhances model performance, even surpassing models trained on\nlarger amounts of human-annotated data. Our code is available at:\nhttps://github.com/WowCZ/LongMIT.", "published": "2024-09-03 13:30:00", "link": "http://arxiv.org/abs/2409.01893v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Leveraging Large Language Models for Automated Medical Q&A\n  Evaluation", "abstract": "This paper explores the potential of using Large Language Models (LLMs) to\nautomate the evaluation of responses in medical Question and Answer (Q\\&A)\nsystems, a crucial form of Natural Language Processing. Traditionally, human\nevaluation has been indispensable for assessing the quality of these responses.\nHowever, manual evaluation by medical professionals is time-consuming and\ncostly. Our study examines whether LLMs can reliably replicate human\nevaluations by using questions derived from patient data, thereby saving\nvaluable time for medical experts. While the findings suggest promising\nresults, further research is needed to address more specific or complex\nquestions that were beyond the scope of this initial investigation.", "published": "2024-09-03 14:38:29", "link": "http://arxiv.org/abs/2409.01941v1", "categories": ["cs.CL", "cs.LG", "I.2.7; J.3"], "primary_category": "cs.CL"}
{"title": "Learning Machines: In Search of a Concept Oriented Language", "abstract": "What is the next step after the data/digital revolution? What do we need the\nmost to reach this aim? How machines can memorize, learn or discover? What\nshould they be able to do to be qualified as \"intelligent\"? These questions\nrelate to the next generation \"intelligent\" machines. Probably, these machines\nshould be able to handle knowledge discovery, decision-making and concepts. In\nthis paper, we will take into account some historical contributions and discuss\nthese different questions through an analogy to human intelligence. Also, a\ngeneral framework for a concept oriented language will be proposed.", "published": "2024-09-03 15:05:47", "link": "http://arxiv.org/abs/2409.01968v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Foundations of Large Language Model Compression -- Part 1: Weight\n  Quantization", "abstract": "In recent years, compression of large language models (LLMs) has emerged as\nan important problem to enable language model deployment on\nresource-constrained devices, reduce computational costs, and mitigate the\nenvironmental footprint of large-scale AI infrastructure. In this paper, we lay\ndown the foundation for LLM quantization from a convex optimization perspective\nand propose a quantization technique that builds on this foundation for optimum\nquantization outcomes. Our quantization framework, CVXQ, scales to models\ncontaining hundreds of billions of weight parameters and provides users with\nthe flexibility to compress models to any specified model size, post-training.\nA reference implementation of CVXQ can be obtained from github.com/seannz/cvxq.", "published": "2024-09-03 16:20:22", "link": "http://arxiv.org/abs/2409.02026v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Unforgettable Generalization in Language Models", "abstract": "When language models (LMs) are trained to forget (or \"unlearn'') a skill, how\nprecisely does their behavior change? We study the behavior of transformer LMs\nin which tasks have been forgotten via fine-tuning on randomized labels. Such\nLMs learn to generate near-random predictions for individual examples in the\n\"training'' set used for forgetting. Across tasks, however, LMs exhibit extreme\nvariability in whether LM predictions change on examples outside the training\nset. In some tasks (like entailment classification), forgetting generalizes\nrobustly, and causes models to produce uninformative predictions on new task\ninstances; in other tasks (like physical commonsense reasoning and scientific\nquestion answering) forgetting affects only the training examples, and models\ncontinue to perform the \"forgotten'' task accurately even for examples very\nsimilar to those that appeared in the training set. Dataset difficulty is not\npredictive of whether a behavior can be forgotten; instead, generalization in\nforgetting is (weakly) predicted by the confidence of LMs' initial task\npredictions and the variability of LM representations of training data, with\nlow confidence and low variability both associated with greater generalization.\nPerhaps most surprisingly, random-label forgetting appears to be somewhat\ninsensitive to the contents of the training set: for example, models trained on\nscience questions with random labels continue to answer other science questions\naccurately, but begin to produce random labels on entailment classification\ntasks. Finally, we show that even generalizable forgetting is shallow: linear\nprobes trained on LMs' representations can still perform tasks reliably after\nforgetting. Our results highlight the difficulty and unpredictability of\nperforming targeted skill removal from models via fine-tuning.", "published": "2024-09-03 18:55:54", "link": "http://arxiv.org/abs/2409.02228v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Therapy as an NLP Task: Psychologists' Comparison of LLMs and Human\n  Peers in CBT", "abstract": "Wider access to therapeutic care is one of the biggest challenges in mental\nhealth treatment. Due to institutional barriers, some people seeking mental\nhealth support have turned to large language models (LLMs) for personalized\ntherapy, even though these models are largely unsanctioned and untested. We\ninvestigate the potential and limitations of using LLMs as providers of\nevidence-based therapy by using mixed methods clinical metrics. Using HELPERT,\na prompt run on a large language model using the same process and training as a\ncomparative group of peer counselors, we replicated publicly accessible mental\nhealth conversations rooted in Cognitive Behavioral Therapy (CBT) to compare\nsession dynamics and counselor's CBT-based behaviors between original peer\nsupport sessions and their reconstructed HELPERT sessions. Two licensed,\nCBT-trained clinical psychologists evaluated the sessions using the Cognitive\nTherapy Rating Scale and provided qualitative feedback. Our findings show that\nthe peer sessions are characterized by empathy, small talk, therapeutic\nalliance, and shared experiences but often exhibit therapist drift. Conversely,\nHELPERT reconstructed sessions exhibit minimal therapist drift and higher\nadherence to CBT methods but display a lack of collaboration, empathy, and\ncultural understanding. Through CTRS ratings and psychologists' feedback, we\nhighlight the importance of human-AI collaboration for scalable mental health.\nOur work outlines the ethical implication of imparting human-like subjective\nqualities to LLMs in therapeutic settings, particularly the risk of deceptive\nempathy, which may lead to unrealistic patient expectations and potential harm.", "published": "2024-09-03 19:19:13", "link": "http://arxiv.org/abs/2409.02244v1", "categories": ["cs.HC", "cs.CL", "I.2.7; J.4"], "primary_category": "cs.HC"}
{"title": "MMLU-Pro+: Evaluating Higher-Order Reasoning and Shortcut Learning in\n  LLMs", "abstract": "Existing benchmarks for large language models (LLMs) increasingly struggle to\ndifferentiate between top-performing models, underscoring the need for more\nchallenging evaluation frameworks. We introduce MMLU-Pro+, an enhanced\nbenchmark building upon MMLU-Pro to assess shortcut learning and higher-order\nreasoning in LLMs. By incorporating questions with multiple correct answers\nacross diverse domains, MMLU-Pro+ tests LLMs' ability to engage in complex\nreasoning and resist simplistic problem-solving strategies. Our results show\nthat MMLU-Pro+ maintains MMLU-Pro's difficulty while providing a more rigorous\ntest of model discrimination, particularly in multi-correct answer scenarios.\nWe introduce novel metrics like shortcut selection ratio and correct pair\nidentification ratio, offering deeper insights into model behavior and\nanchoring bias. Evaluations of six state-of-the-art LLMs reveal significant\nperformance gaps, highlighting variations in reasoning abilities and bias\nsusceptibility. We release the dataset and evaluation codes at\n\\url{https://github.com/asgsaeid/mmlu-pro-plus}.", "published": "2024-09-03 19:31:03", "link": "http://arxiv.org/abs/2409.02257v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining", "abstract": "Recent studies have been increasingly demonstrating that high-quality data is\ncrucial for effective pretraining of language models. However, the precise\ndefinition of \"high-quality\" remains underexplored. Focusing on the code\ndomain, we introduce Arctic-SnowCoder-1.3B, a data-efficient base code model\npretrained on 555B tokens through three phases of progressively refined data:\n(1) general pretraining with 500B standard-quality code tokens, preprocessed\nthrough basic filtering, deduplication, and decontamination, (2) continued\npretraining with 50B high-quality tokens, selected from phase one by a\nBERT-style quality annotator trained to distinguish good code from random data,\nusing positive examples drawn from high-quality code files, along with\ninstruction data from Magicoder and StarCoder2-Instruct, and (3) enhanced\npretraining with 5B synthetic data created by Llama-3.1-70B using phase two\ndata as seeds, adapting the Magicoder approach for pretraining. Despite being\ntrained on a limited dataset, Arctic-SnowCoder achieves state-of-the-art\nperformance on BigCodeBench, a coding benchmark focusing on practical and\nchallenging programming tasks, compared to similarly sized models trained on no\nmore than 1T tokens, outperforming Phi-1.5-1.3B by 36%. Across all evaluated\nbenchmarks, Arctic-SnowCoder-1.3B beats StarCoderBase-3B pretrained on 1T\ntokens. Additionally, it matches the performance of leading small base code\nmodels trained on trillions of tokens. For example, Arctic-SnowCoder-1.3B\nsurpasses StarCoder2-3B, pretrained on over 3.3T tokens, on HumanEval+, a\nbenchmark that evaluates function-level code generation, and remains\ncompetitive on BigCodeBench. Our evaluation presents a comprehensive analysis\njustifying various design choices for Arctic-SnowCoder. Most importantly, we\nfind that the key to high-quality data is its alignment with the distribution\nof downstream applications.", "published": "2024-09-03 22:36:42", "link": "http://arxiv.org/abs/2409.02326v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Visually Grounded Speech Models for Low-resource Languages and Cognitive\n  Modelling", "abstract": "This dissertation examines visually grounded speech (VGS) models that learn\nfrom unlabelled speech paired with images. It focuses on applications for\nlow-resource languages and understanding human language acquisition. We\nintroduce a task called visually prompted keyword localisation to detect and\nlocalise keywords in speech using images. We demonstrate the effectiveness of\nVGS models in few-shot learning scenarios for low-resource languages like\nYoruba. Additionally, we examine the mutual exclusivity bias in VGS models. Our\nmonolingual VGS model exhibits this bias, but we found that multilingualism\ndoes not affect the bias in this VGS model similarly to what is observed in\nchildren.", "published": "2024-09-03 17:59:50", "link": "http://arxiv.org/abs/2409.02865v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "The NGT200 Dataset: Geometric Multi-View Isolated Sign Recognition", "abstract": "Sign Language Processing (SLP) provides a foundation for a more inclusive\nfuture in language technology; however, the field faces several significant\nchallenges that must be addressed to achieve practical, real-world\napplications. This work addresses multi-view isolated sign recognition\n(MV-ISR), and highlights the essential role of 3D awareness and geometry in SLP\nsystems. We introduce the NGT200 dataset, a novel spatio-temporal multi-view\nbenchmark, establishing MV-ISR as distinct from single-view ISR (SV-ISR). We\ndemonstrate the benefits of synthetic data and propose conditioning sign\nrepresentations on spatial symmetries inherent in sign language. Leveraging an\nSE(2) equivariant model improves MV-ISR performance by 8%-22% over the\nbaseline.", "published": "2024-09-03 13:46:08", "link": "http://arxiv.org/abs/2409.15284v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Effective Noise-aware Data Simulation for Domain-adaptive Speech\n  Enhancement Leveraging Dynamic Stochastic Perturbation", "abstract": "Cross-domain speech enhancement (SE) is often faced with severe challenges\ndue to the scarcity of noise and background information in an unseen target\ndomain, leading to a mismatch between training and test conditions. This study\nputs forward a novel data simulation method to address this issue, leveraging\nnoise-extractive techniques and generative adversarial networks (GANs) with\nonly limited target noisy speech data. Notably, our method employs a noise\nencoder to extract noise embeddings from target-domain data. These embeddings\naptly guide the generator to synthesize utterances acoustically fitted to the\ntarget domain while authentically preserving the phonetic content of the input\nclean speech. Furthermore, we introduce the notion of dynamic stochastic\nperturbation, which can inject controlled perturbations into the noise\nembeddings during inference, thereby enabling the model to generalize well to\nunseen noise conditions. Experiments on the VoiceBank-DEMAND benchmark dataset\ndemonstrate that our domain-adaptive SE method outperforms an existing strong\nbaseline based on data simulation.", "published": "2024-09-03 02:29:01", "link": "http://arxiv.org/abs/2409.01545v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VoxHakka: A Dialectally Diverse Multi-speaker Text-to-Speech System for\n  Taiwanese Hakka", "abstract": "This paper introduces VoxHakka, a text-to-speech (TTS) system designed for\nTaiwanese Hakka, a critically under-resourced language spoken in Taiwan.\nLeveraging the YourTTS framework, VoxHakka achieves high naturalness and\naccuracy and low real-time factor in speech synthesis while supporting six\ndistinct Hakka dialects. This is achieved by training the model with\ndialect-specific data, allowing for the generation of speaker-aware Hakka\nspeech. To address the scarcity of publicly available Hakka speech corpora, we\nemployed a cost-effective approach utilizing a web scraping pipeline coupled\nwith automatic speech recognition (ASR)-based data cleaning techniques. This\nprocess ensured the acquisition of a high-quality, multi-speaker, multi-dialect\ndataset suitable for TTS training. Subjective listening tests conducted using\ncomparative mean opinion scores (CMOS) demonstrate that VoxHakka significantly\noutperforms existing publicly available Hakka TTS systems in terms of\npronunciation accuracy, tone correctness, and overall naturalness. This work\nrepresents a significant advancement in Hakka language technology and provides\na valuable resource for language preservation and revitalization efforts.", "published": "2024-09-03 02:37:34", "link": "http://arxiv.org/abs/2409.01548v3", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Empirical evidence of Large Language Model's influence on human spoken\n  communication", "abstract": "Artificial Intelligence (AI) agents now interact with billions of humans in\nnatural language, thanks to advances in Large Language Models (LLMs) like\nChatGPT. This raises the question of whether AI has the potential to shape a\nfundamental aspect of human culture: the way we speak. Recent analyses revealed\nthat scientific publications already exhibit evidence of AI-specific language.\nBut this evidence is inconclusive, since scientists may simply be using AI to\ncopy-edit their writing. To explore whether AI has influenced human spoken\ncommunication, we transcribed and analyzed about 280,000 English-language\nvideos of presentations, talks, and speeches from more than 20,000 YouTube\nchannels of academic institutions. We find a significant shift in the trend of\nword usage specific to words distinctively associated with ChatGPT following\nits release. These findings provide the first empirical evidence that humans\nincreasingly imitate LLMs in their spoken language. Our results raise societal\nand policy-relevant concerns about the potential of AI to unintentionally\nreduce linguistic diversity, or to be deliberately misused for mass\nmanipulation. They also highlight the need for further investigation into the\nfeedback loops between machine behavior and human culture.", "published": "2024-09-03 10:01:51", "link": "http://arxiv.org/abs/2409.01754v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "LASP: Surveying the State-of-the-Art in Large Language Model-Assisted AI\n  Planning", "abstract": "Effective planning is essential for the success of any task, from organizing\na vacation to routing autonomous vehicles and developing corporate strategies.\nIt involves setting goals, formulating plans, and allocating resources to\nachieve them. LLMs are particularly well-suited for automated planning due to\ntheir strong capabilities in commonsense reasoning. They can deduce a sequence\nof actions needed to achieve a goal from a given state and identify an\neffective course of action. However, it is frequently observed that plans\ngenerated through direct prompting often fail upon execution. Our survey aims\nto highlight the existing challenges in planning with language models, focusing\non key areas such as embodied environments, optimal scheduling, competitive and\ncooperative games, task decomposition, reasoning, and planning. Through this\nstudy, we explore how LLMs transform AI planning and provide unique insights\ninto the future of LM-assisted planning.", "published": "2024-09-03 11:39:52", "link": "http://arxiv.org/abs/2409.01806v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "3D-LEX v1.0: 3D Lexicons for American Sign Language and Sign Language of\n  the Netherlands", "abstract": "In this work, we present an efficient approach for capturing sign language in\n3D, introduce the 3D-LEX v1.0 dataset, and detail a method for semi-automatic\nannotation of phonetic properties. Our procedure integrates three motion\ncapture techniques encompassing high-resolution 3D poses, 3D handshapes, and\ndepth-aware facial features, and attains an average sampling rate of one sign\nevery 10 seconds. This includes the time for presenting a sign example,\nperforming and recording the sign, and archiving the capture. The 3D-LEX\ndataset includes 1,000 signs from American Sign Language and an additional\n1,000 signs from the Sign Language of the Netherlands. We showcase the dataset\nutility by presenting a simple method for generating handshape annotations\ndirectly from 3D-LEX. We produce handshape labels for 1,000 signs from American\nSign Language and evaluate the labels in a sign recognition task. The labels\nenhance gloss recognition accuracy by 5% over using no handshape annotations,\nand by 1% over expert annotations. Our motion capture data supports in-depth\nanalysis of sign features and facilitates the generation of 2D projections from\nany viewpoint. The 3D-LEX collection has been aligned with existing sign\nlanguage benchmarks and linguistic resources, to support studies in 3D-aware\nsign language processing.", "published": "2024-09-03 13:44:56", "link": "http://arxiv.org/abs/2409.01901v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "BEAVER: An Enterprise Benchmark for Text-to-SQL", "abstract": "Existing text-to-SQL benchmarks have largely been constructed from web tables\nwith human-generated question-SQL pairs. LLMs typically show strong results on\nthese benchmarks, leading to a belief that LLMs are effective at text-to-SQL\ntasks. However, how these results transfer to enterprise settings is unclear\nbecause tables in enterprise databases might differ substantially from web\ntables in structure and content. To contend with this problem, we introduce a\nnew dataset BEAVER, the first enterprise text-to-SQL benchmark sourced from\nreal private enterprise data warehouses. This dataset includes natural language\nqueries and their correct SQL statements, which we collected from actual query\nlogs. We then benchmark off-the-shelf LLMs on this dataset. LLMs perform\npoorly, even when augmented with standard prompt engineering and RAG\ntechniques. We identify three main reasons for the poor performance: (1)\nschemas of enterprise tables are more complex than the schemas in public data,\nresulting in SQL-generation tasks intrinsically harder; (2) business-oriented\nquestions are often more complex, requiring joins over multiple tables,\naggregations, and nested queries; (3) public LLMs cannot train on private\nenterprise data warehouses that are not publicly accessible, and therefore it\nis difficult for the model to learn to solve (1) and (2). We believe BEAVER\nwill facilitate future research in building text-to-SQL systems that perform\nbetter in enterprise settings.", "published": "2024-09-03 16:37:45", "link": "http://arxiv.org/abs/2409.02038v2", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Enhancing Code-Switching Speech Recognition with LID-Based Collaborative\n  Mixture of Experts Model", "abstract": "Due to the inherent difficulty in modeling phonetic similarities across\ndifferent languages, code-switching speech recognition presents a formidable\nchallenge. This study proposes a Collaborative-MoE, a Mixture of Experts (MoE)\nmodel that leverages a collaborative mechanism among expert groups. Initially,\na preceding routing network explicitly learns Language Identification (LID)\ntasks and selects experts based on acquired LID weights. This process ensures\nrobust routing information to the MoE layer, mitigating interference from\ndiverse language domains on expert network parameter updates. The LID weights\nare also employed to facilitate inter-group collaboration, enabling the\nintegration of language-specific representations. Furthermore, within each\nlanguage expert group, a gating network operates unsupervised to foster\ncollaboration on attributes beyond language. Extensive experiments demonstrate\nthe efficacy of our approach, achieving significant performance enhancements\ncompared to alternative methods. Importantly, our method preserves the\nefficient inference capabilities characteristic of MoE models without\nnecessitating additional pre-training.", "published": "2024-09-03 16:53:38", "link": "http://arxiv.org/abs/2409.02050v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "OLMoE: Open Mixture-of-Experts Language Models", "abstract": "We introduce OLMoE, a fully open, state-of-the-art language model leveraging\nsparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but\nuses only 1B per input token. We pretrain it on 5 trillion tokens and further\nadapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available\nmodels with similar active parameters, even surpassing larger ones like\nLlama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE\ntraining, analyze routing in our model showing high specialization, and\nopen-source all aspects of our work: model weights, training data, code, and\nlogs.", "published": "2024-09-03 17:08:20", "link": "http://arxiv.org/abs/2409.02060v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CRAFT Your Dataset: Task-Specific Synthetic Dataset Generation Through\n  Corpus Retrieval and Augmentation", "abstract": "Building high-quality datasets for specialized tasks is a time-consuming and\nresource-intensive process that often requires specialized domain knowledge. We\npropose Corpus Retrieval and Augmentation for Fine-Tuning (CRAFT), a method for\ngenerating synthetic datasets, given a small number of user-written few-shots\nthat demonstrate the task to be performed. Given the few-shot examples, we use\nlarge-scale public web-crawled corpora and similarity-based document retrieval\nto find other relevant human-written documents. Lastly, instruction-tuned large\nlanguage models (LLMs) augment the retrieved documents into custom-formatted\ntask samples, which then can be used for fine-tuning. We demonstrate that CRAFT\ncan efficiently generate large-scale task-specific training datasets for four\ndiverse tasks: biology question-answering (QA), medicine QA and commonsense QA\nas well as summarization. Our experiments show that CRAFT-based models\noutperform or achieve comparable performance to general LLMs for QA tasks,\nwhile CRAFT-based summarization models outperform models trained on\nhuman-curated data by 46 preference points.", "published": "2024-09-03 17:54:40", "link": "http://arxiv.org/abs/2409.02098v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Temporal Order Preserved Optimal Transport-based Cross-modal Knowledge\n  Transfer Learning for ASR", "abstract": "Transferring linguistic knowledge from a pretrained language model (PLM) to\nan acoustic model has been shown to greatly improve the performance of\nautomatic speech recognition (ASR). However, due to the heterogeneous feature\ndistributions in cross-modalities, designing an effective model for feature\nalignment and knowledge transfer between linguistic and acoustic sequences\nremains a challenging task. Optimal transport (OT), which efficiently measures\nprobability distribution discrepancies, holds great potential for aligning and\ntransferring knowledge between acoustic and linguistic modalities. Nonetheless,\nthe original OT treats acoustic and linguistic feature sequences as two\nunordered sets in alignment and neglects temporal order information during OT\ncoupling estimation. Consequently, a time-consuming pretraining stage is\nrequired to learn a good alignment between the acoustic and linguistic\nrepresentations. In this paper, we propose a Temporal Order Preserved OT\n(TOT)-based Cross-modal Alignment and Knowledge Transfer (CAKT) (TOT-CAKT) for\nASR. In the TOT-CAKT, local neighboring frames of acoustic sequences are\nsmoothly mapped to neighboring regions of linguistic sequences, preserving\ntheir temporal order relationship in feature alignment and matching. With the\nTOT-CAKT model framework, we conduct Mandarin ASR experiments with a pretrained\nChinese PLM for linguistic knowledge transfer. Our results demonstrate that the\nproposed TOT-CAKT significantly improves ASR performance compared to several\nstate-of-the-art models employing linguistic knowledge transfer, and addresses\nthe weaknesses of the original OT-based method in sequential feature alignment\nfor ASR.", "published": "2024-09-03 19:11:15", "link": "http://arxiv.org/abs/2409.02239v2", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging Large Language Models for Solving Rare MIP Challenges", "abstract": "Mixed Integer Programming (MIP) has been extensively applied in areas\nrequiring mathematical solvers to address complex instances within tight time\nconstraints. However, as the problem scale increases, the complexity of model\nformulation and finding feasible solutions escalates significantly. In\ncontrast, the model-building cost for end-to-end models, such as large language\nmodels (LLMs), remains largely unaffected by problem scale due to their pattern\nrecognition capabilities. While LLMs, like GPT-4, without fine-tuning, can\nhandle some traditional medium-scale MIP problems, they struggle with uncommon\nor highly specialized MIP scenarios. Fine-tuning LLMs can yield some feasible\nsolutions for medium-scale MIP instances, but these models typically fail to\nexplore diverse solutions when constrained by a low and constant temperature,\nlimiting their performance. In this paper, we propose and evaluate a\nrecursively dynamic temperature method integrated with a chain-of-thought\napproach. Our findings show that starting with a high temperature and gradually\nlowering it leads to better feasible solutions compared to other dynamic\ntemperature strategies. Additionally, by comparing results generated by the LLM\nwith those from Gurobi, we demonstrate that the LLM can produce solutions that\ncomplement traditional solvers by accelerating the pruning process and\nimproving overall efficiency.", "published": "2024-09-03 07:25:01", "link": "http://arxiv.org/abs/2409.04464v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "math.OC"], "primary_category": "cs.CL"}
{"title": "Multi-Source Knowledge Pruning for Retrieval-Augmented Generation: A\n  Benchmark and Empirical Study", "abstract": "Retrieval-augmented generation (RAG) is increasingly recognized as an\neffective approach to mitigating the hallucination of large language models\n(LLMs) through the integration of external knowledge. While numerous efforts,\nmost studies focus on a single type of external knowledge source. In contrast,\nmost real-world applications involve diverse knowledge from various sources, a\nscenario that has been relatively underexplored. The main dilemma is the lack\nof a suitable dataset incorporating multiple knowledge sources and\npre-exploration of the associated issues. To address these challenges, we\nstandardize a benchmark dataset that combines structured and unstructured\nknowledge across diverse and complementary domains. Building upon the dataset,\nwe identify the limitations of existing methods under such conditions.\nTherefore, we develop PruningRAG, a plug-and-play RAG framework that uses\nmulti-granularity pruning strategies to more effectively incorporate relevant\ncontext and mitigate the negative impact of misleading information. Extensive\nexperimental results demonstrate superior performance of PruningRAG and our\ninsightful findings are also reported. Our dataset and code are publicly\navailable\\footnote{https://github.com/USTCAGI/PruningRAG}.", "published": "2024-09-03 03:31:37", "link": "http://arxiv.org/abs/2409.13694v3", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "You Only Use Reactive Attention Slice For Long Context Retrieval", "abstract": "Supporting longer context for Large Language Models (LLM) is a promising\ndirection to advance LLMs. As training a model for a longer context window is\ncomputationally expensive, many alternative solutions, such as Retrieval\nAugmented Generation (RAG), have been used. However, most existing RAG methods\nadopt embedding-based retrieval that falls short on long contexts.\n  To address such challenges, we propose an attention-based retrieval\ntechnique, You Only Use Reactive Attention slice (YOURA). YOURA leverages a\nnovel retrieval heuristic called reaction score to rank the relevance of each\nsentence in the input context with the query sentence. Intuitively, we measure\nhow the per-token attention score \"reacts\" to the query and greedily retrieves\nthe most reactive sentences. Internally, YOURA generates a token-indexed vector\n(called reaction vector) for the whole input context. To map each sentence to\nthe token-indexed vector, we propose an Embedding-Agnostic Sentence Yield\n(EASY), a best-effort token wiggling algorithm.\n  We evaluate our retrieval technique on three open-source pre-trained LLM\nmodels across six LongBench QA datasets. Our technique achieves up to 30% vLLM\ninference throughput improvement for serving long-context queries with a nearly\nidentical quality score to the simple yet effective truncate-middle approach.", "published": "2024-09-03 15:30:57", "link": "http://arxiv.org/abs/2409.13695v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The Role of Large Language Models in Musicology: Are We Ready to Trust\n  the Machines?", "abstract": "In this work, we explore the use and reliability of Large Language Models\n(LLMs) in musicology. From a discussion with experts and students, we assess\nthe current acceptance and concerns regarding this, nowadays ubiquitous,\ntechnology. We aim to go one step further, proposing a semi-automatic method to\ncreate an initial benchmark using retrieval-augmented generation models and\nmultiple-choice question generation, validated by human experts. Our evaluation\non 400 human-validated questions shows that current vanilla LLMs are less\nreliable than retrieval augmented generation from music dictionaries. This\npaper suggests that the potential of LLMs in musicology requires musicology\ndriven research that can specialized LLMs by including accurate and reliable\ndomain knowledge.", "published": "2024-09-03 13:05:38", "link": "http://arxiv.org/abs/2409.01864v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.DL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Optimal L-Systems for Stochastic L-system Inference Problems", "abstract": "This paper presents two novel theorems that address two open problems in\nstochastic Lindenmayer-system (L-system) inference, specifically focusing on\nthe construction of an optimal stochastic L-system capable of generating a\ngiven sequence of strings. The first theorem delineates a method for crafting a\nstochastic L-system that has the maximum probability of a derivation producing\na given sequence of words through a single derivation (noting that multiple\nderivations may generate the same sequence). Furthermore, the second theorem\ndetermines the stochastic L-systems with the highest probability of producing a\ngiven sequence of words with multiple possible derivations. From these, we\nintroduce an algorithm to infer an optimal stochastic L-system from a given\nsequence. This algorithm incorporates advanced optimization techniques, such as\ninterior point methods, to ensure the creation of a stochastic L-system that\nmaximizes the probability of generating the given sequence (allowing for\nmultiple derivations). This allows for the use of stochastic L-systems as a\nmodel for machine learning using only positive data for training.", "published": "2024-09-03 19:34:25", "link": "http://arxiv.org/abs/2409.02259v2", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.DS", "cs.FL"], "primary_category": "cs.LG"}
{"title": "AIvril: AI-Driven RTL Generation With Verification In-The-Loop", "abstract": "Large Language Models (LLMs) are computational models capable of performing\ncomplex natural language processing tasks. Leveraging these capabilities, LLMs\nhold the potential to transform the entire hardware design stack, with\npredictions suggesting that front-end and back-end tasks could be fully\nautomated in the near future. Currently, LLMs show great promise in\nstreamlining Register Transfer Level (RTL) generation, enhancing efficiency,\nand accelerating innovation. However, their probabilistic nature makes them\nprone to inaccuracies - a significant drawback in RTL design, where reliability\nand precision are essential.\n  To address these challenges, this paper introduces AIvril, an advanced\nframework designed to enhance the accuracy and reliability of RTL-aware LLMs.\nAIvril employs a multi-agent, LLM-agnostic system for automatic syntax\ncorrection and functional verification, significantly reducing - and in many\ncases, completely eliminating - instances of erroneous code generation.\nExperimental results conducted on the VerilogEval-Human dataset show that our\nframework improves code quality by nearly 2x when compared to previous works,\nwhile achieving an 88.46% success rate in meeting verification objectives. This\nrepresents a critical step toward automating and optimizing hardware design\nworkflows, offering a more dependable methodology for AI-driven RTL design.", "published": "2024-09-03 15:07:11", "link": "http://arxiv.org/abs/2409.11411v1", "categories": ["cs.AI", "cs.AR", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "The USTC-NERCSLIP Systems for the CHiME-8 NOTSOFAR-1 Challenge", "abstract": "This technical report outlines our submission system for the CHiME-8\nNOTSOFAR-1 Challenge. The primary difficulty of this challenge is the dataset\nrecorded across various conference rooms, which captures real-world\ncomplexities such as high overlap rates, background noises, a variable number\nof speakers, and natural conversation styles. To address these issues, we\noptimized the system in several aspects: For front-end speech signal\nprocessing, we introduced a data-driven joint training method for diarization\nand separation (JDS) to enhance audio quality. Additionally, we also integrated\ntraditional guided source separation (GSS) for multi-channel track to provide\ncomplementary information for the JDS. For back-end speech recognition, we\nenhanced Whisper with WavLM, ConvNeXt, and Transformer innovations, applying\nmulti-task training and Noise KLD augmentation, to significantly advance ASR\nrobustness and accuracy. Our system attained a Time-Constrained minimum\nPermutation Word Error Rate (tcpWER) of 14.265% and 22.989% on the CHiME-8\nNOTSOFAR-1 Dev-set-2 multi-channel and single-channel tracks, respectively.", "published": "2024-09-03 16:42:07", "link": "http://arxiv.org/abs/2409.02041v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Pureformer-VC: Non-parallel One-Shot Voice Conversion with Pure\n  Transformer Blocks and Triplet Discriminative Training", "abstract": "One-shot voice conversion(VC) aims to change the timbre of any source speech\nto match that of the target speaker with only one speech sample. Existing style\ntransfer-based VC methods relied on speech representation disentanglement and\nsuffered from accurately and independently encoding each speech component and\nrecomposing back to converted speech effectively. To tackle this, we proposed\nPureformer-VC, which utilizes Conformer blocks to build a disentangled encoder,\nand Zipformer blocks to build a style transfer decoder as the generator. In the\ndecoder, we used effective styleformer blocks to integrate speaker\ncharacteristics effectively into the generated speech. The models used the\ngenerative VAE loss for encoding components and triplet loss for unsupervised\ndiscriminative training. We applied the styleformer method to Zipformer's\nshared weights for style transfer. The experimental results show that the\nproposed model achieves comparable subjective scores and exhibits improvements\nin objective metrics compared to existing methods in a one-shot voice\nconversion scenario.", "published": "2024-09-03 07:21:19", "link": "http://arxiv.org/abs/2409.01668v3", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "USTC-KXDIGIT System Description for ASVspoof5 Challenge", "abstract": "This paper describes the USTC-KXDIGIT system submitted to the ASVspoof5\nChallenge for Track 1 (speech deepfake detection) and Track 2 (spoofing-robust\nautomatic speaker verification, SASV). Track 1 showcases a diverse range of\ntechnical qualities from potential processing algorithms and includes both open\nand closed conditions. For these conditions, our system consists of a cascade\nof a frontend feature extractor and a back-end classifier. We focus on\nextensive embedding engineering and enhancing the generalization of the\nback-end classifier model. Specifically, the embedding engineering is based on\nhand-crafted features and speech representations from a self-supervised model,\nused for closed and open conditions, respectively. To detect spoof attacks\nunder various adversarial conditions, we trained multiple systems on an\naugmented training set. Additionally, we used voice conversion technology to\nsynthesize fake audio from genuine audio in the training set to enrich the\nsynthesis algorithms. To leverage the complementary information learned by\ndifferent model architectures, we employed activation ensemble and fused scores\nfrom different systems to obtain the final decision score for spoof detection.\nDuring the evaluation phase, the proposed methods achieved 0.3948 minDCF and\n14.33% EER in the close condition, and 0.0750 minDCF and 2.59% EER in the open\ncondition, demonstrating the robustness of our submitted systems under\nadversarial conditions. In Track 2, we continued using the CM system from Track\n1 and fused it with a CNN-based ASV system. This approach achieved 0.2814\nmin-aDCF in the closed condition and 0.0756 min-aDCF in the open condition,\nshowcasing superior performance in the SASV system.", "published": "2024-09-03 08:28:58", "link": "http://arxiv.org/abs/2409.01695v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Steered Response Power-Based Direction-of-Arrival Estimation Exploiting\n  an Auxiliary Microphone", "abstract": "Accurately estimating the direction-of-arrival (DOA) of a speech source using\na compact microphone array (CMA) is often complicated by background noise and\nreverberation. A commonly used DOA estimation method is the steered response\npower with phase transform (SRP-PHAT) function, which has been shown to work\nreliably in moderate levels of noise and reverberation. Since for closely\nspaced microphones the spatial coherence of noise and reverberation may be high\nover an extended frequency range, this may negatively affect the SRP-PHAT\nspectra, resulting in DOA estimation errors. Assuming the availability of an\nauxiliary microphone at an unknown position which is spatially separated from\nthe CMA, in this paper we propose to compute the SRP-PHAT spectra between the\nmicrophones of the CMA based on the SRP-PHAT spectra between the auxiliary\nmicrophone and the microphones of the CMA. For different levels of noise and\nreverberation, we show how far the auxiliary microphone needs to be spatially\nseparated from the CMA for the auxiliary microphone-based SRP-PHAT spectra to\nbe more reliable than the SRP-PHAT spectra without the auxiliary microphone.\nThese findings are validated based on simulated microphone signals for several\nauxiliary microphone positions and two different noise and reverberation\nconditions.", "published": "2024-09-03 10:38:35", "link": "http://arxiv.org/abs/2409.01776v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Reassessing Noise Augmentation Methods in the Context of Adversarial\n  Speech", "abstract": "In this study, we investigate if noise-augmented training can concurrently\nimprove adversarial robustness in automatic speech recognition (ASR) systems.\nWe conduct a comparative analysis of the adversarial robustness of four\ndifferent state-of-the-art ASR architectures, where each of the ASR\narchitectures is trained under three different augmentation conditions: one\nsubject to background noise, speed variations, and reverberations, another\nsubject to speed variations only, and a third without any form of data\naugmentation. The results demonstrate that noise augmentation not only improves\nmodel performance on noisy speech but also the model's robustness to\nadversarial attacks.", "published": "2024-09-03 11:51:10", "link": "http://arxiv.org/abs/2409.01813v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Activity-Guided Industrial Anomalous Sound Detection against\n  Interferences", "abstract": "We address a practical scenario of anomaly detection for industrial sound\ndata, where the sound of a target machine is corrupted by background noise and\ninterference from neighboring machines. Overcoming this challenge is difficult\nsince the interference is often virtually indistinguishable from the target\nmachine without additional information. To address the issue, we propose SSAD,\na framework of source separation (SS) followed by anomaly detection (AD), which\nleverages machine activity information, often readily available in practical\nsettings. SSAD consists of two components: (i) activity-informed SS, enabling\neffective source separation even given interference with similar timbre, and\n(ii) two-step masking, robustifying anomaly detection by emphasizing anomalies\naligned with the machine activity. Our experiments demonstrate that SSAD\nachieves comparable accuracy to a baseline with full access to clean signals,\nwhile SSAD is provided only a corrupted signal and activity information. In\naddition, thanks to the activity-informed SS and AD with the two-step masking,\nSSAD outperforms standard approaches, particularly in cases with interference.\nIt highlights the practical efficacy of SSAD in addressing the complexities of\nanomaly detection in industrial sound data.", "published": "2024-09-03 13:26:25", "link": "http://arxiv.org/abs/2409.01885v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders", "abstract": "We propose a new speech discrete token vocoder, vec2wav 2.0, which advances\nvoice conversion (VC). We use discrete tokens from speech self-supervised\nmodels as the content features of source speech, and treat VC as a prompted\nvocoding task. To amend the loss of speaker timbre in the content tokens,\nvec2wav 2.0 utilizes the WavLM features to provide strong timbre-dependent\ninformation. A novel adaptive Snake activation function is proposed to better\nincorporate timbre into the waveform reconstruction process. In this way,\nvec2wav 2.0 learns to alter the speaker timbre appropriately given different\nreference prompts. Also, no supervised data is required for vec2wav 2.0 to be\neffectively trained. Experimental results demonstrate that vec2wav 2.0\noutperforms all other baselines to a considerable margin in terms of audio\nquality and speaker similarity in any-to-any VC. Ablation studies verify the\neffects made by the proposed techniques. Moreover, vec2wav 2.0 achieves\ncompetitive cross-lingual VC even only trained on monolingual corpus. Thus,\nvec2wav 2.0 shows timbre can potentially be manipulated only by speech token\nvocoders, pushing the frontiers of VC and speech synthesis.", "published": "2024-09-03 15:41:07", "link": "http://arxiv.org/abs/2409.01995v3", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LSTMSE-Net: Long Short Term Speech Enhancement Network for Audio-visual\n  Speech Enhancement", "abstract": "In this paper, we propose long short term memory speech enhancement network\n(LSTMSE-Net), an audio-visual speech enhancement (AVSE) method. This innovative\nmethod leverages the complementary nature of visual and audio information to\nboost the quality of speech signals. Visual features are extracted with\nVisualFeatNet (VFN), and audio features are processed through an encoder and\ndecoder. The system scales and concatenates visual and audio features, then\nprocesses them through a separator network for optimized speech enhancement.\nThe architecture highlights advancements in leveraging multi-modal data and\ninterpolation techniques for robust AVSE challenge systems. The performance of\nLSTMSE-Net surpasses that of the baseline model from the COG-MHEAR AVSE\nChallenge 2024 by a margin of 0.06 in scale-invariant signal-to-distortion\nratio (SISDR), $0.03$ in short-time objective intelligibility (STOI), and\n$1.32$ in perceptual evaluation of speech quality (PESQ). The source code of\nthe proposed LSTMSE-Net is available at\n\\url{https://github.com/mtanveer1/AVSEC-3-Challenge}.", "published": "2024-09-03 19:52:49", "link": "http://arxiv.org/abs/2409.02266v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech Foundation Model Ensembles for the Controlled Singing Voice\n  Deepfake Detection (CtrSVDD) Challenge 2024", "abstract": "This work details our approach to achieving a leading system with a 1.79%\npooled equal error rate (EER) on the evaluation set of the Controlled Singing\nVoice Deepfake Detection (CtrSVDD). The rapid advancement of generative AI\nmodels presents significant challenges for detecting AI-generated deepfake\nsinging voices, attracting increased research attention. The Singing Voice\nDeepfake Detection (SVDD) Challenge 2024 aims to address this complex task. In\nthis work, we explore the ensemble methods, utilizing speech foundation models\nto develop robust singing voice anti-spoofing systems. We also introduce a\nnovel Squeeze-and-Excitation Aggregation (SEA) method, which efficiently and\neffectively integrates representation features from the speech foundation\nmodels, surpassing the performance of our other individual systems. Evaluation\nresults confirm the efficacy of our approach in detecting deepfake singing\nvoices. The codes can be accessed at https://github.com/Anmol2059/SVDD2024.", "published": "2024-09-03 21:28:45", "link": "http://arxiv.org/abs/2409.02302v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Applications and Advances of Artificial Intelligence in Music\n  Generation:A Review", "abstract": "In recent years, artificial intelligence (AI) has made significant progress\nin the field of music generation, driving innovation in music creation and\napplications. This paper provides a systematic review of the latest research\nadvancements in AI music generation, covering key technologies, models,\ndatasets, evaluation methods, and their practical applications across various\nfields. The main contributions of this review include: (1) presenting a\ncomprehensive summary framework that systematically categorizes and compares\ndifferent technological approaches, including symbolic generation, audio\ngeneration, and hybrid models, helping readers better understand the full\nspectrum of technologies in the field; (2) offering an extensive survey of\ncurrent literature, covering emerging topics such as multimodal datasets and\nemotion expression evaluation, providing a broad reference for related\nresearch; (3) conducting a detailed analysis of the practical impact of AI\nmusic generation in various application domains, particularly in real-time\ninteraction and interdisciplinary applications, offering new perspectives and\ninsights; (4) summarizing the existing challenges and limitations of music\nquality evaluation methods and proposing potential future research directions,\naiming to promote the standardization and broader adoption of evaluation\ntechniques. Through these innovative summaries and analyses, this paper serves\nas a comprehensive reference tool for researchers and practitioners in AI music\ngeneration, while also outlining future directions for the field.", "published": "2024-09-03 13:50:55", "link": "http://arxiv.org/abs/2409.03715v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FastVoiceGrad: One-step Diffusion-Based Voice Conversion with\n  Adversarial Conditional Diffusion Distillation", "abstract": "Diffusion-based voice conversion (VC) techniques such as VoiceGrad have\nattracted interest because of their high VC performance in terms of speech\nquality and speaker similarity. However, a notable limitation is the slow\ninference caused by the multi-step reverse diffusion. Therefore, we propose\nFastVoiceGrad, a novel one-step diffusion-based VC that reduces the number of\niterations from dozens to one while inheriting the high VC performance of the\nmulti-step diffusion-based VC. We obtain the model using adversarial\nconditional diffusion distillation (ACDD), leveraging the ability of generative\nadversarial networks and diffusion models while reconsidering the initial\nstates in sampling. Evaluations of one-shot any-to-any VC demonstrate that\nFastVoiceGrad achieves VC performance superior to or comparable to that of\nprevious multi-step diffusion-based VC while enhancing the inference speed.\nAudio samples are available at\nhttps://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/fastvoicegrad/.", "published": "2024-09-03 19:19:48", "link": "http://arxiv.org/abs/2409.02245v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Equivariance-based self-supervised learning for audio signal recovery\n  from clipped measurements", "abstract": "In numerous inverse problems, state-of-the-art solving strategies involve\ntraining neural networks from ground truth and associated measurement datasets\nthat, however, may be expensive or impossible to collect. Recently,\nself-supervised learning techniques have emerged, with the major advantage of\nno longer requiring ground truth data. Most theoretical and experimental\nresults on self-supervised learning focus on linear inverse problems. The\npresent work aims to study self-supervised learning for the non-linear inverse\nproblem of recovering audio signals from clipped measurements. An\nequivariance-based selfsupervised loss is proposed and studied. Performance is\nassessed on simulated clipped measurements with controlled and varied levels of\nclipping, and further reported on standard real music signals. We show that the\nperformance of the proposed equivariance-based self-supervised declipping\nstrategy compares favorably to fully supervised learning while only requiring\nclipped measurements alone for training.", "published": "2024-09-03 06:12:01", "link": "http://arxiv.org/abs/2409.15283v1", "categories": ["eess.AS", "cs.IR", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
