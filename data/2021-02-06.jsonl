{"title": "Child-directed Listening: How Caregiver Inference Enables Children's\n  Early Verbal Communication", "abstract": "How do adults understand children's speech? Children's productions over the\ncourse of language development often bear little resemblance to typical adult\npronunciations, yet caregivers nonetheless reliably recover meaning from them.\nHere, we employ a suite of Bayesian models of spoken word recognition to\nunderstand how adults overcome the noisiness of child language, showing that\ncommunicative success between children and adults relies heavily on adult\ninferential processes. By evaluating competing models on phonetically-annotated\ncorpora, we show that adults' recovered meanings are best predicted by prior\nexpectations fitted specifically to the child language environment, rather than\nto typical adult-adult language. After quantifying the contribution of this\n\"child-directed listening\" over developmental time, we discuss the consequences\nfor theories of language acquisition, as well as the implications for\ncommonly-used methods for assessing children's linguistic proficiency.", "published": "2021-02-06 00:54:34", "link": "http://arxiv.org/abs/2102.03462v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does the Order of Training Samples Matter? Improving Neural Data-to-Text\n  Generation with Curriculum Learning", "abstract": "Recent advancements in data-to-text generation largely take on the form of\nneural end-to-end systems. Efforts have been dedicated to improving text\ngeneration systems by changing the order of training samples in a process known\nas curriculum learning. Past research on sequence-to-sequence learning showed\nthat curriculum learning helps to improve both the performance and convergence\nspeed. In this work, we delve into the same idea surrounding the training\nsamples consisting of structured data and text pairs, where at each update, the\ncurriculum framework selects training samples based on the model's competence.\nSpecifically, we experiment with various difficulty metrics and put forward a\nsoft edit distance metric for ranking training samples. Our benchmarks show\nfaster convergence speed where training time is reduced by 38.7% and\nperformance is boosted by 4.84 BLEU.", "published": "2021-02-06 10:14:18", "link": "http://arxiv.org/abs/2102.03554v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Data-to-Text Generation with LM-based Text Augmentation", "abstract": "For many new application domains for data-to-text generation, the main\nobstacle in training neural models consists of a lack of training data. While\nusually large numbers of instances are available on the data side, often only\nvery few text samples are available. To address this problem, we here propose a\nnovel few-shot approach for this setting. Our approach automatically augments\nthe data available for training by (i) generating new text samples based on\nreplacing specific values by alternative ones from the same category, (ii)\ngenerating new text samples based on GPT-2, and (iii) proposing an automatic\nmethod for pairing the new text samples with data samples. As the text\naugmentation can introduce noise to the training data, we use cycle consistency\nas an objective, in order to make sure that a given data sample can be\ncorrectly reconstructed after having been formulated as text (and that text\nsamples can be reconstructed from data). On both the E2E and WebNLG benchmarks,\nwe show that this weakly supervised training paradigm is able to outperform\nfully supervised seq2seq models with less than 10% annotations. By utilizing\nall annotated data, our model can boost the performance of a standard seq2seq\nmodel by over 5 BLEU points, establishing a new state-of-the-art on both\ndatasets.", "published": "2021-02-06 10:21:48", "link": "http://arxiv.org/abs/2102.03556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word\n  Understanding of Language Models", "abstract": "Recent progress in pretraining language models on large corpora has resulted\nin large performance gains on many NLP tasks. These large models acquire\nlinguistic knowledge during pretraining, which helps to improve performance on\ndownstream tasks via fine-tuning. To assess what kind of knowledge is acquired,\nlanguage models are commonly probed by querying them with `fill in the blank'\nstyle cloze questions. Existing probing datasets mainly focus on knowledge\nabout relations between words and entities. We introduce WDLMPro (Word\nDefinition Language Model Probing) to evaluate word understanding directly\nusing dictionary definitions of words. In our experiments, three popular\npretrained language models struggle to match words and their definitions. This\nindicates that they understand many words poorly and that our new probing task\nis a difficult challenge that could help guide research on LMs in the future.", "published": "2021-02-06 15:15:57", "link": "http://arxiv.org/abs/2102.03596v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Toxicity in Online Comments to Incivility in American News: Proceed\n  with Caution", "abstract": "The ability to quantify incivility online, in news and in congressional\ndebates, is of great interest to political scientists. Computational tools for\ndetecting online incivility for English are now fairly accessible and\npotentially could be applied more broadly. We test the Jigsaw Perspective API\nfor its ability to detect the degree of incivility on a corpus that we\ndeveloped, consisting of manual annotations of civility in American news. We\ndemonstrate that toxicity models, as exemplified by Perspective, are inadequate\nfor the analysis of incivility in news. We carry out error analysis that points\nto the need to develop methods to remove spurious correlations between words\noften mentioned in the news, especially identity descriptors and incivility.\nWithout such improvements, applying Perspective or similar models on news is\nlikely to lead to wrong conclusions, that are not aligned with the human\nperception of incivility.", "published": "2021-02-06 21:49:17", "link": "http://arxiv.org/abs/2102.03671v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Jointly Improving Language Understanding and Generation with\n  Quality-Weighted Weak Supervision of Automatic Labeling", "abstract": "Neural natural language generation (NLG) and understanding (NLU) models are\ndata-hungry and require massive amounts of annotated data to be competitive.\nRecent frameworks address this bottleneck with generative models that\nsynthesize weak labels at scale, where a small amount of training labels are\nexpert-curated and the rest of the data is automatically annotated. We follow\nthat approach, by automatically constructing a large-scale weakly-labeled data\nwith a fine-tuned GPT-2, and employ a semi-supervised framework to jointly\ntrain the NLG and NLU models. The proposed framework adapts the parameter\nupdates to the models according to the estimated label-quality. On both the E2E\nand Weather benchmarks, we show that this weakly supervised training paradigm\nis an effective approach under low resource scenarios and outperforming\nbenchmark systems on both datasets when 100% of training data is used.", "published": "2021-02-06 10:06:15", "link": "http://arxiv.org/abs/2102.03551v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A bandit approach to curriculum generation for automatic speech\n  recognition", "abstract": "The Automated Speech Recognition (ASR) task has been a challenging domain\nespecially for low data scenarios with few audio examples. This is the main\nproblem in training ASR systems on the data from low-resource or marginalized\nlanguages. In this paper we present an approach to mitigate the lack of\ntraining data by employing Automated Curriculum Learning in combination with an\nadversarial bandit approach inspired by Reinforcement learning. The goal of the\napproach is to optimize the training sequence of mini-batches ranked by the\nlevel of difficulty and compare the ASR performance metrics against the random\ntraining sequence and discrete curriculum. We test our approach on a truly\nlow-resource language and show that the bandit framework has a good improvement\nover the baseline transfer-learning model.", "published": "2021-02-06 20:32:10", "link": "http://arxiv.org/abs/2102.03662v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The DKU-Duke-Lenovo System Description for the Third DIHARD Speech\n  Diarization Challenge", "abstract": "In this paper, we present the submitted system for the third DIHARD Speech\nDiarization Challenge from the DKU-Duke-Lenovo team. Our system consists of\nseveral modules: voice activity detection (VAD), segmentation, speaker\nembedding extraction, attentive similarity scoring, agglomerative hierarchical\nclustering. In addition, the target speaker VAD (TSVAD) is used for the phone\ncall data to further improve the performance. Our final submitted system\nachieves a DER of 15.43% for the core evaluation set and 13.39% for the full\nevaluation set on task 1, and we also get a DER of 21.63% for core evaluation\nset and 18.90% for full evaluation set on task 2.", "published": "2021-02-06 19:41:42", "link": "http://arxiv.org/abs/2102.03649v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sound Event Detection in Urban Audio With Single and Multi-Rate PCEN", "abstract": "Recent literature has demonstrated that the use of per-channel energy\nnormalization (PCEN), has significant performance improvements over traditional\nlog-scaled mel-frequency spectrograms in acoustic sound event detection (SED)\nin a multi-class setting with overlapping events. However, the configuration of\nPCEN's parameters is sensitive to the recording environment, the\ncharacteristics of the class of events of interest, and the presence of\nmultiple overlapping events. This leads to improvements on a class-by-class\nbasis, but poor cross-class performance. In this article, we experiment using\nPCEN spectrograms as an alternative method for SED in urban audio using the\nUrbanSED dataset, demonstrating per-class improvements based on parameter\nconfiguration. Furthermore, we address cross-class performance with PCEN using\na novel method, Multi-Rate PCEN (MRPCEN). We demonstrate cross-class SED\nperformance with MRPCEN, demonstrating improvements to cross-class performance\ncompared to traditional single-rate PCEN.", "published": "2021-02-06 01:23:43", "link": "http://arxiv.org/abs/2102.03468v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speaker attribution with voice profiles by graph-based semi-supervised\n  learning", "abstract": "Speaker attribution is required in many real-world applications, such as\nmeeting transcription, where speaker identity is assigned to each utterance\naccording to speaker voice profiles. In this paper, we propose to solve the\nspeaker attribution problem by using graph-based semi-supervised learning\nmethods. A graph of speech segments is built for each session, on which\nsegments from voice profiles are represented by labeled nodes while segments\nfrom test utterances are unlabeled nodes. The weight of edges between nodes is\nevaluated by the similarities between the pretrained speaker embeddings of\nspeech segments. Speaker attribution then becomes a semi-supervised learning\nproblem on graphs, on which two graph-based methods are applied: label\npropagation (LP) and graph neural networks (GNNs). The proposed approaches are\nable to utilize the structural information of the graph to improve speaker\nattribution performance. Experimental results on real meeting data show that\nthe graph based approaches reduce speaker attribution error by up to 68%\ncompared to a baseline speaker identification approach that processes each\nutterance independently.", "published": "2021-02-06 18:35:56", "link": "http://arxiv.org/abs/2102.03634v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
