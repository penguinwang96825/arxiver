{"title": "Mining User Opinions in Mobile App Reviews: A Keyword-based Approach", "abstract": "User reviews of mobile apps often contain complaints or suggestions which are\nvaluable for app developers to improve user experience and satisfaction.\nHowever, due to the large volume and noisy-nature of those reviews, manually\nanalyzing them for useful opinions is inherently challenging. To address this\nproblem, we propose MARK, a keyword-based framework for semi-automated review\nanalysis. MARK allows an analyst describing his interests in one or some mobile\napps by a set of keywords. It then finds and lists the reviews most relevant to\nthose keywords for further analysis. It can also draw the trends over time of\nthose keywords and detect their sudden changes, which might indicate the\noccurrences of serious issues. To help analysts describe their interests more\neffectively, MARK can automatically extract keywords from raw reviews and rank\nthem by their associations with negative reviews. In addition, based on a\nvector-based semantic representation of keywords, MARK can divide a large set\nof keywords into more cohesive subsets, or suggest keywords similar to the\nselected ones.", "published": "2015-05-18 14:25:03", "link": "http://arxiv.org/abs/1505.04657v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Recurrent Neural Network Training with Dark Knowledge Transfer", "abstract": "Recurrent neural networks (RNNs), particularly long short-term memory (LSTM),\nhave gained much attention in automatic speech recognition (ASR). Although some\nsuccessful stories have been reported, training RNNs remains highly\nchallenging, especially with limited training data. Recent research found that\na well-trained model can be used as a teacher to train other child models, by\nusing the predictions generated by the teacher model as supervision. This\nknowledge transfer learning has been employed to train simple neural nets with\na complex one, so that the final performance can reach a level that is\ninfeasible to obtain by regular training. In this paper, we employ the\nknowledge transfer learning approach to train RNNs (precisely LSTM) using a\ndeep neural network (DNN) model as the teacher. This is different from most of\nthe existing research on knowledge transfer learning, since the teacher (DNN)\nis assumed to be weaker than the child (RNN); however, our experiments on an\nASR task showed that it works fairly well: without applying any tricks on the\nlearning scheme, this approach can train RNNs successfully even with limited\ntraining data.", "published": "2015-05-18 13:26:02", "link": "http://arxiv.org/abs/1505.04630v5", "categories": ["stat.ML", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "stat.ML"}
{"title": "DopeLearning: A Computational Approach to Rap Lyrics Generation", "abstract": "Writing rap lyrics requires both creativity to construct a meaningful,\ninteresting story and lyrical skills to produce complex rhyme patterns, which\nform the cornerstone of good flow. We present a rap lyrics generation method\nthat captures both of these aspects. First, we develop a prediction model to\nidentify the next line of existing lyrics from a set of candidate next lines.\nThis model is based on two machine-learning techniques: the RankSVM algorithm\nand a deep neural network model with a novel structure. Results show that the\nprediction model can identify the true next line among 299 randomly selected\nlines with an accuracy of 17%, i.e., over 50 times more likely than by random.\nSecond, we employ the prediction model to combine lines from existing songs,\nproducing lyrics with rhyme and a meaning. An evaluation of the produced lyrics\nshows that in terms of quantitative rhyme density, the method outperforms the\nbest human rappers by 21%. The rap lyrics generator has been deployed as an\nonline tool called DeepBeat, and the performance of the tool has been assessed\nby analyzing its usage logs. This analysis shows that machine-learned rankings\ncorrelate with user preferences.", "published": "2015-05-18 19:35:21", "link": "http://arxiv.org/abs/1505.04771v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE", "I.2.7; H.3.3"], "primary_category": "cs.LG"}
