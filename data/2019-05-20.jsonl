{"title": "Target Based Speech Act Classification in Political Campaign Text", "abstract": "We study pragmatics in political campaign text, through analysis of speech\nacts and the target of each utterance. We propose a new annotation schema\nincorporating domain-specific speech acts, such as commissive-action, and\npresent a novel annotated corpus of media releases and speech transcripts from\nthe 2016 Australian election cycle. We show how speech acts and target\nreferents can be modeled as sequential classification, and evaluate several\ntechniques, exploiting contextualized word representations, semi-supervised\nlearning, task dependencies and speaker meta-data.", "published": "2019-05-20 03:14:11", "link": "http://arxiv.org/abs/1905.07856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable Neural Predictions with Differentiable Binary Variables", "abstract": "The success of neural networks comes hand in hand with a desire for more\ninterpretability. We focus on text classifiers and make them more interpretable\nby having them provide a justification, a rationale, for their predictions. We\napproach this problem by jointly training two neural network models: a latent\nmodel that selects a rationale (i.e. a short and informative part of the input\ntext), and a classifier that learns from the words in the rationale alone.\nPrevious work proposed to assign binary latent masks to input positions and to\npromote short selections via sparsity-inducing penalties such as L0\nregularisation. We propose a latent model that mixes discrete and continuous\nbehaviour allowing at the same time for binary selections and gradient-based\ntraining without REINFORCE. In our formulation, we can tractably compute the\nexpected value of penalties such as L0, which allows us to directly optimise\nthe model towards a pre-specified text selection rate. We show that our\napproach is competitive with previous work on rationale extraction, and explore\nfurther uses in attention mechanisms.", "published": "2019-05-20 15:07:36", "link": "http://arxiv.org/abs/1905.08160v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Neural, Interactive-predictive System for Multimodal Sequence to\n  Sequence Tasks", "abstract": "We present a demonstration of a neural interactive-predictive system for\ntackling multimodal sequence to sequence tasks. The system generates text\npredictions to different sequence to sequence tasks: machine translation, image\nand video captioning. These predictions are revised by a human agent, who\nintroduces corrections in the form of characters. The system reacts to each\ncorrection, providing alternative hypotheses, compelling with the feedback\nprovided by the user. The final objective is to reduce the human effort\nrequired during this correction process.\n  This system is implemented following a client-server architecture. For\naccessing the system, we developed a website, which communicates with the\nneural model, hosted in a local server. From this website, the different tasks\ncan be tackled following the interactive-predictive framework. We open-source\nall the code developed for building this system. The demonstration in hosted in\nhttp://casmacat.prhlt.upv.es/interactive-seq2seq.", "published": "2019-05-20 15:53:09", "link": "http://arxiv.org/abs/1905.08181v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate\n  Representation", "abstract": "We present a neural approach called IRNet for complex and cross-domain\nText-to-SQL. IRNet aims to address two challenges: 1) the mismatch between\nintents expressed in natural language (NL) and the implementation details in\nSQL; 2) the challenge in predicting columns caused by the large number of\nout-of-domain words. Instead of end-to-end synthesizing a SQL query, IRNet\ndecomposes the synthesis process into three phases. In the first phase, IRNet\nperforms a schema linking over a question and a database schema. Then, IRNet\nadopts a grammar-based neural model to synthesize a SemQL query which is an\nintermediate representation that we design to bridge NL and SQL. Finally, IRNet\ndeterministically infers a SQL query from the synthesized SemQL query with\ndomain knowledge. On the challenging Text-to-SQL benchmark Spider, IRNet\nachieves 46.7% accuracy, obtaining 19.5% absolute improvement over previous\nstate-of-the-art approaches. At the time of writing, IRNet achieves the first\nposition on the Spider leaderboard.", "published": "2019-05-20 16:44:00", "link": "http://arxiv.org/abs/1905.08205v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Target Conditioned Sampling: Optimizing Data Selection for Multilingual\n  Neural Machine Translation", "abstract": "To improve low-resource Neural Machine Translation (NMT) with multilingual\ncorpora, training on the most related high-resource language only is often more\neffective than using all data available (Neubig and Hu, 2018). However, it is\npossible that an intelligent data selection strategy can further improve\nlow-resource NMT with data from other auxiliary languages. In this paper, we\nseek to construct a sampling distribution over all multilingual data, so that\nit minimizes the training loss of the low-resource language. Based on this\nformulation, we propose an efficient algorithm, Target Conditioned Sampling\n(TCS), which first samples a target sentence, and then conditionally samples\nits source sentence. Experiments show that TCS brings significant gains of up\nto 2 BLEU on three of four languages we test, with minimal training overhead.", "published": "2019-05-20 16:54:43", "link": "http://arxiv.org/abs/1905.08212v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enriching Pre-trained Language Model with Entity Information for\n  Relation Classification", "abstract": "Relation classification is an important NLP task to extract relations between\nentities. The state-of-the-art methods for relation classification are\nprimarily based on Convolutional or Recurrent Neural Networks. Recently, the\npre-trained BERT model achieves very successful results in many NLP\nclassification / sequence labeling tasks. Relation classification differs from\nthose tasks in that it relies on information of both the sentence and the two\ntarget entities. In this paper, we propose a model that both leverages the\npre-trained BERT language model and incorporates information from the target\nentities to tackle the relation classification task. We locate the target\nentities and transfer the information through the pre-trained architecture and\nincorporate the corresponding encoding of the two entities. We achieve\nsignificant improvement over the state-of-the-art method on the SemEval-2010\ntask 8 relational dataset.", "published": "2019-05-20 18:22:18", "link": "http://arxiv.org/abs/1905.08284v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word Usage Similarity Estimation with Sentence Representations and\n  Automatic Substitutes", "abstract": "Usage similarity estimation addresses the semantic proximity of word\ninstances in different contexts. We apply contextualized (ELMo and BERT) word\nand sentence embeddings to this task, and propose supervised models that\nleverage these representations for prediction. Our models are further assisted\nby lexical substitute annotations automatically assigned to word instances by\ncontext2vec, a neural model that relies on a bidirectional LSTM. We perform an\nextensive comparison of existing word and sentence representations on benchmark\ndatasets addressing both graded and binary similarity. The best performing\nmodels outperform previous methods in both settings.", "published": "2019-05-20 23:10:42", "link": "http://arxiv.org/abs/1905.08377v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PaperRobot: Incremental Draft Generation of Scientific Ideas", "abstract": "We present a PaperRobot who performs as an automatic research assistant by\n(1) conducting deep understanding of a large collection of human-written papers\nin a target domain and constructing comprehensive background knowledge graphs\n(KGs); (2) creating new ideas by predicting links from the background KGs, by\ncombining graph attention and contextual text attention; (3) incrementally\nwriting some key elements of a new paper based on memory-attention networks:\nfrom the input title along with predicted related entities to generate a paper\nabstract, from the abstract to generate conclusion and future work, and finally\nfrom future work to generate a title for a follow-on paper. Turing Tests, where\na biomedical domain expert is asked to compare a system output and a\nhuman-authored string, show PaperRobot generated abstracts, conclusion and\nfuture work sections, and new titles are chosen over human-written ones up to\n30%, 24% and 12% of the time, respectively.", "published": "2019-05-20 04:41:10", "link": "http://arxiv.org/abs/1905.07870v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Abusive Language Detection in Online Conversations by Combining\n  Content-and Graph-based Features", "abstract": "In recent years, online social networks have allowed worldwide users to meet\nand discuss. As guarantors of these communities, the administrators of these\nplatforms must prevent users from adopting inappropriate behaviors. This\nverification task, mainly done by humans, is more and more difficult due to the\never growing amount of messages to check. Methods have been proposed to\nautomatize this moderation process, mainly by providing approaches based on the\ntextual content of the exchanged messages. Recent work has also shown that\ncharacteristics derived from the structure of conversations, in the form of\nconversational graphs, can help detecting these abusive messages. In this\npaper, we propose to take advantage of both sources of information by proposing\nfusion methods integrating content-and graph-based features. Our experiments on\nraw chat logs show that the content of the messages, but also of their dynamics\nwithin a conversation contain partially complementary information, allowing\nperformance improvements on an abusive message classification task with a final\nF-measure of 93.26%.", "published": "2019-05-20 06:15:07", "link": "http://arxiv.org/abs/1905.07894v1", "categories": ["cs.IR", "cs.CL", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Image Captioning based on Deep Learning Methods: A Survey", "abstract": "Image captioning is a challenging task and attracting more and more attention\nin the field of Artificial Intelligence, and which can be applied to efficient\nimage retrieval, intelligent blind guidance and human-computer interaction,\netc. In this paper, we present a survey on advances in image captioning based\non Deep Learning methods, including Encoder-Decoder structure, improved methods\nin Encoder, improved methods in Decoder, and other improvements. Furthermore,\nwe discussed future research directions.", "published": "2019-05-20 13:43:52", "link": "http://arxiv.org/abs/1905.08110v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Neural Network Architecture for Learning Word-Referent Associations in\n  Multiple Contexts", "abstract": "This article proposes a biologically inspired neurocomputational architecture\nwhich learns associations between words and referents in different contexts,\nconsidering evidence collected from the literature of Psycholinguistics and\nNeurolinguistics. The multi-layered architecture takes as input raw images of\nobjects (referents) and streams of word's phonemes (labels), builds an adequate\nrepresentation, recognizes the current context, and associates label with\nreferents incrementally, by employing a Self-Organizing Map which creates new\nassociation nodes (prototypes) as required, adjusts the existing prototypes to\nbetter represent the input stimuli and removes prototypes that become\nobsolete/unused. The model takes into account the current context to retrieve\nthe correct meaning of words with multiple meanings. Simulations show that the\nmodel can reach up to 78% of word-referent association accuracy in ambiguous\nsituations and approximates well the learning rates of humans as reported by\nthree different authors in five Cross-Situational Word Learning experiments,\nalso displaying similar learning patterns in the different learning conditions.", "published": "2019-05-20 19:05:12", "link": "http://arxiv.org/abs/1905.08300v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Independent Vector Analysis with more Microphones than Sources", "abstract": "We extend frequency-domain blind source separation based on independent\nvector analysis to the case where there are more microphones than sources. The\nsignal is modelled as non-Gaussian sources in a Gaussian background. The\nproposed algorithm is based on a parametrization of the demixing matrix\ndecreasing the number of parameters to estimate. Furthermore, orthogonal\nconstraints between the signal and background subspaces are imposed to\nregularize the separation. The problem can then be posed as a constrained\nlikelihood maximization. We propose efficient alternating updates guaranteed to\nconverge to a stationary point of the cost function. The performance of the\nalgorithm is assessed on simulated signals. We find that the separation\nperformance is on par with that of the conventional determined algorithm at a\nfraction of the computational cost.", "published": "2019-05-20 05:32:36", "link": "http://arxiv.org/abs/1905.07880v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust sound event detection in bioacoustic sensor networks", "abstract": "Bioacoustic sensors, sometimes known as autonomous recording units (ARUs),\ncan record sounds of wildlife over long periods of time in scalable and\nminimally invasive ways. Deriving per-species abundance estimates from these\nsensors requires detection, classification, and quantification of animal\nvocalizations as individual acoustic events. Yet, variability in ambient noise,\nboth over time and across sensors, hinders the reliability of current automated\nsystems for sound event detection (SED), such as convolutional neural networks\n(CNN) in the time-frequency domain. In this article, we develop, benchmark, and\ncombine several machine listening techniques to improve the generalizability of\nSED models across heterogeneous acoustic environments. As a case study, we\nconsider the problem of detecting avian flight calls from a ten-hour recording\nof nocturnal bird migration, recorded by a network of six ARUs in the presence\nof heterogeneous background noise. Starting from a CNN yielding\nstate-of-the-art accuracy on this task, we introduce two noise adaptation\ntechniques, respectively integrating short-term (60 milliseconds) and long-term\n(30 minutes) context. First, we apply per-channel energy normalization (PCEN)\nin the time-frequency domain, which applies short-term automatic gain control\nto every subband in the mel-frequency spectrogram. Secondly, we replace the\nlast dense layer in the network by a context-adaptive neural network (CA-NN)\nlayer. Combining them yields state-of-the-art results that are unmatched by\nartificial data augmentation alone. We release a pre-trained version of our\nbest performing system under the name of BirdVoxDetect, a ready-to-use detector\nof avian flight calls in field recordings.", "published": "2019-05-20 21:25:48", "link": "http://arxiv.org/abs/1905.08352v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
