{"title": "CLVR Ordering of Transactions on AMMs", "abstract": "Trading on decentralized exchanges via an Automated Market Maker (AMM)\nmechanism has been massively adopted, with a daily trading volume reaching $1B.\nThis trading method has also received close attention from researchers, central\nbanks, and financial firms, who have the potential to adopt it to traditional\nfinancial markets such as foreign exchanges and stock markets. A critical\nchallenge of AMM-powered trading is that transaction order has high financial\nvalue, so a policy or method to order transactions in a \"good\" (optimal) manner\nis vital. We offer economic measures of both price stability (low volatility)\nand inequality that inform how a \"social planner\" should pick an optimal\nordering. We show that there is a trade-off between achieving price stability\nand reducing inequality, and that policymakers must choose which to prioritize.\nIn addition, picking the optimal order can often be costly, especially when\nperforming an exhaustive search over trade orderings (permutations). As an\nalternative we provide a simple algorithm, Clever Look-ahead Volatility\nReduction (CLVR). This algorithm constructs an ordering which approximately\nminimizes price volatility with a small computation cost. We also provide\ninsight into the strategy changes that may occur if traders are subject to this\nsequencing algorithm.", "published": "2024-08-05 16:58:48", "link": "http://arxiv.org/abs/2408.02634v1", "categories": ["cs.GT", "q-fin.MF", "q-fin.TR"], "primary_category": "cs.GT"}
{"title": "Quantile Regression using Random Forest Proximities", "abstract": "Due to the dynamic nature of financial markets, maintaining models that\nproduce precise predictions over time is difficult. Often the goal isn't just\npoint prediction but determining uncertainty. Quantifying uncertainty,\nespecially the aleatoric uncertainty due to the unpredictable nature of market\ndrivers, helps investors understand varying risk levels. Recently, quantile\nregression forests (QRF) have emerged as a promising solution: Unlike most\nbasic quantile regression methods that need separate models for each quantile,\nquantile regression forests estimate the entire conditional distribution of the\ntarget variable with a single model, while retaining all the salient features\nof a typical random forest. We introduce a novel approach to compute quantile\nregressions from random forests that leverages the proximity (i.e., distance\nmetric) learned by the model and infers the conditional distribution of the\ntarget variable. We evaluate the proposed methodology using publicly available\ndatasets and then apply it towards the problem of forecasting the average daily\nvolume of corporate bonds. We show that using quantile regression using Random\nForest proximities demonstrates superior performance in approximating\nconditional target distributions and prediction intervals to the original\nversion of QRF. We also demonstrate that the proposed framework is\nsignificantly more computationally efficient than traditional approaches to\nquantile regressions.", "published": "2024-08-05 10:02:33", "link": "http://arxiv.org/abs/2408.02355v1", "categories": ["stat.ML", "cs.LG", "q-fin.ST", "q-fin.TR"], "primary_category": "stat.ML"}
{"title": "Consistent time travel for realistic interactions with historical data: reinforcement learning for market making", "abstract": "Reinforcement learning works best when the impact of the agent's actions on\nits environment can be perfectly simulated or fully appraised from available\ndata. Some systems are however both hard to simulate and very sensitive to\nsmall perturbations. An additional difficulty arises when a RL agent is trained\noffline to be part of a multi-agent system using only anonymous data, which\nmakes it impossible to infer the state of each agent, thus to use data\ndirectly. Typical examples are competitive systems without agent-resolved data\nsuch as financial markets. We introduce consistent data time travel for offline\nRL as a remedy for these problems: instead of using historical data in a\nsequential way, we argue that one needs to perform time travel in historical\ndata, i.e., to adjust the time index so that both the past state and the\ninfluence of the RL agent's action on the system coincide with real data. This\nboth alleviates the need to resort to imperfect models and consistently\naccounts for both the immediate and long-term reactions of the system when\nusing anonymous historical data. We apply this idea to market making in limit\norder books, a notoriously difficult task for RL; it turns out that the gain of\nthe agent is significantly higher with data time travel than with naive\nsequential data, which suggests that the difficulty of this task for RL may\nhave been overestimated.", "published": "2024-08-05 09:07:36", "link": "http://arxiv.org/abs/2408.02322v2", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Machine Learning-based Relative Valuation of Municipal Bonds", "abstract": "The trading ecosystem of the Municipal (muni) bond is complex and unique.\nWith nearly 2\\% of securities from over a million securities outstanding\ntrading daily, determining the value or relative value of a bond among its\npeers is challenging. Traditionally, relative value calculation has been done\nusing rule-based or heuristics-driven approaches, which may introduce human\nbiases and often fail to account for complex relationships between the bond\ncharacteristics. We propose a data-driven model to develop a supervised\nsimilarity framework for the muni bond market based on CatBoost algorithm. This\nalgorithm learns from a large-scale dataset to identify bonds that are similar\nto each other based on their risk profiles. This allows us to evaluate the\nprice of a muni bond relative to a cohort of bonds with a similar risk profile.\nWe propose and deploy a back-testing methodology to compare various benchmarks\nand the proposed methods and show that the similarity-based method outperforms\nboth rule-based and heuristic-based methods.", "published": "2024-08-05 07:05:21", "link": "http://arxiv.org/abs/2408.02273v1", "categories": ["q-fin.ST", "q-fin.TR", "stat.AP"], "primary_category": "q-fin.ST"}
{"title": "Do Large Language Models Speak All Languages Equally? A Comparative\n  Study in Low-Resource Settings", "abstract": "Large language models (LLMs) have garnered significant interest in natural\nlanguage processing (NLP), particularly their remarkable performance in various\ndownstream tasks in resource-rich languages. Recent studies have highlighted\nthe limitations of LLMs in low-resource languages, primarily focusing on binary\nclassification tasks and giving minimal attention to South Asian languages.\nThese limitations are primarily attributed to constraints such as dataset\nscarcity, computational costs, and research gaps specific to low-resource\nlanguages. To address this gap, we present datasets for sentiment and hate\nspeech tasks by translating from English to Bangla, Hindi, and Urdu,\nfacilitating research in low-resource language processing. Further, we\ncomprehensively examine zero-shot learning using multiple LLMs in English and\nwidely spoken South Asian languages. Our findings indicate that GPT-4\nconsistently outperforms Llama 2 and Gemini, with English consistently\ndemonstrating superior performance across diverse tasks compared to\nlow-resource languages. Furthermore, our analysis reveals that natural language\ninference (NLI) exhibits the highest performance among the evaluated tasks,\nwith GPT-4 demonstrating superior capabilities.", "published": "2024-08-05 05:09:23", "link": "http://arxiv.org/abs/2408.02237v1", "categories": ["cs.CL", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "BOTS-LM: Training Large Language Models for Setswana", "abstract": "In this work we present BOTS-LM, a series of bilingual language models\nproficient in both Setswana and English. Leveraging recent advancements in data\navailability and efficient fine-tuning, BOTS-LM achieves performance similar to\nmodels significantly larger than itself while maintaining computational\nefficiency. Our initial release features an 8 billion parameter generative\nlarge language model, with upcoming 0.5 billion and 1 billion parameter large\nlanguage models and a 278 million parameter encoder-only model soon to be\nreleased. We find the 8 billion parameter model significantly outperforms\nLlama-3-70B and Aya 23 on English-Setswana translation tasks, approaching the\nperformance of dedicated machine translation models, while approaching 70B\nparameter performance on Setswana reasoning as measured by a machine translated\nsubset of the MMLU benchmark. To accompany the BOTS-LM series of language\nmodels, we release the largest Setswana web dataset, SetsText, totalling over\n267 million tokens. In addition, we release the largest machine translated\nSetswana dataset, the first and largest synthetic Setswana dataset, training\nand evaluation code, training logs, and MMLU-tsn, a machine translated subset\nof MMLU.", "published": "2024-08-05 05:15:17", "link": "http://arxiv.org/abs/2408.02239v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing Post-OCR Correction: A Comparative Study of Synthetic Data", "abstract": "This paper explores the application of synthetic data in the post-OCR domain\non multiple fronts by conducting experiments to assess the impact of data\nvolume, augmentation, and synthetic data generation methods on model\nperformance. Furthermore, we introduce a novel algorithm that leverages\ncomputer vision feature detection algorithms to calculate glyph similarity for\nconstructing post-OCR synthetic data. Through experiments conducted across a\nvariety of languages, including several low-resource ones, we demonstrate that\nmodels like ByT5 can significantly reduce Character Error Rates (CER) without\nthe need for manually annotated data, and our proposed synthetic data\ngeneration method shows advantages over traditional methods, particularly in\nlow-resource languages.", "published": "2024-08-05 05:56:37", "link": "http://arxiv.org/abs/2408.02253v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "To Aggregate or Not to Aggregate. That is the Question: A Case Study on\n  Annotation Subjectivity in Span Prediction", "abstract": "This paper explores the task of automatic prediction of text spans in a legal\nproblem description that support a legal area label. We use a corpus of problem\ndescriptions written by laypeople in English that is annotated by practising\nlawyers. Inherent subjectivity exists in our task because legal area\ncategorisation is a complex task, and lawyers often have different views on a\nproblem, especially in the face of legally-imprecise descriptions of issues.\nExperiments show that training on majority-voted spans outperforms training on\ndisaggregated ones.", "published": "2024-08-05 06:16:31", "link": "http://arxiv.org/abs/2408.02257v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StyEmp: Stylizing Empathetic Response Generation via Multi-Grained\n  Prefix Encoder and Personality Reinforcement", "abstract": "Recent approaches for empathetic response generation mainly focus on\nemotional resonance and user understanding, without considering the system's\npersonality. Consistent personality is evident in real human expression and is\nimportant for creating trustworthy systems. To address this problem, we propose\nStyEmp, which aims to stylize the empathetic response generation with a\nconsistent personality. Specifically, it incorporates a multi-grained prefix\nmechanism designed to capture the intricate relationship between a system's\npersonality and its empathetic expressions. Furthermore, we introduce a\npersonality reinforcement module that leverages contrastive learning to\ncalibrate the generation model, ensuring that responses are both empathetic and\nreflective of a distinct personality. Automatic and human evaluations on the\nEMPATHETICDIALOGUES benchmark show that StyEmp outperforms competitive\nbaselines in terms of both empathy and personality expressions.", "published": "2024-08-05 06:59:56", "link": "http://arxiv.org/abs/2408.02271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen\n  Languages", "abstract": "Multilingual neural machine translation systems learn to map sentences of\ndifferent languages into a common representation space. Intuitively, with a\ngrowing number of seen languages the encoder sentence representation grows more\nflexible and easily adaptable to new languages. In this work, we test this\nhypothesis by zero-shot translating from unseen languages. To deal with unknown\nvocabularies from unknown languages we propose a setup where we decouple\nlearning of vocabulary and syntax, i.e. for each language we learn word\nrepresentations in a separate step (using cross-lingual word embeddings), and\nthen train to translate while keeping those word representations frozen. We\ndemonstrate that this setup enables zero-shot translation from entirely unseen\nlanguages. Zero-shot translating with a model trained on Germanic and Romance\nlanguages we achieve scores of 42.6 BLEU for Portuguese-English and 20.7 BLEU\nfor Russian-English on TED domain. We explore how this zero-shot translation\ncapability develops with varying number of languages seen by the encoder.\nLastly, we explore the effectiveness of our decoupled learning strategy for\nunsupervised machine translation. By exploiting our model's zero-shot\ntranslation capability for iterative back-translation we attain near parity\nwith a supervised setting.", "published": "2024-08-05 07:58:58", "link": "http://arxiv.org/abs/2408.02290v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese\n  Large Language Models", "abstract": "Large language models (LLMs) have become powerful tools for advancing natural\nlanguage processing applications in the financial industry. However, existing\nfinancial LLMs often face challenges such as hallucinations or superficial\nparameter training, resulting in suboptimal performance, particularly in\nfinancial computing and machine reading comprehension (MRC). To address these\nissues, we propose a novel large language model specifically designed for the\nChinese financial domain, named SNFinLLM. SNFinLLM excels in domain-specific\ntasks such as answering questions, summarizing financial research reports,\nanalyzing sentiment, and executing financial calculations. We then perform the\nsupervised fine-tuning (SFT) to enhance the model's proficiency across various\nfinancial domains. Specifically, we gather extensive financial data and create\na high-quality instruction dataset composed of news articles, professional\npapers, and research reports of finance domain. Utilizing both domain-specific\nand general datasets, we proceed with continuous pre-training on an established\nopen-source base model, resulting in SNFinLLM-base. Following this, we engage\nin supervised fine-tuning (SFT) to bolster the model's capability across\nmultiple financial tasks. Crucially, we employ a straightforward Direct\nPreference Optimization (DPO) method to better align the model with human\npreferences. Extensive experiments conducted on finance benchmarks and our\nevaluation dataset demonstrate that SNFinLLM markedly outperforms other\nstate-of-the-art financial language models. For more details, check out our\ndemo video here: https://www.youtube.com/watch?v=GYT-65HZwus.", "published": "2024-08-05 08:24:24", "link": "http://arxiv.org/abs/2408.02302v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Infusing Emotions into Task-oriented Dialogue Systems: Understanding,\n  Management, and Generation", "abstract": "Emotions are indispensable in human communication, but are often overlooked\nin task-oriented dialogue (ToD) modelling, where the task success is the\nprimary focus. While existing works have explored user emotions or similar\nconcepts in some ToD tasks, none has so far included emotion modelling into a\nfully-fledged ToD system nor conducted interaction with human or simulated\nusers. In this work, we incorporate emotion into the complete ToD processing\nloop, involving understanding, management, and generation. To this end, we\nextend the EmoWOZ dataset (Feng et al., 2022) with system affective behaviour\nlabels. Through interactive experimentation involving both simulated and human\nusers, we demonstrate that our proposed framework significantly enhances the\nuser's emotional experience as well as the task success.", "published": "2024-08-05 12:21:04", "link": "http://arxiv.org/abs/2408.02417v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let Me Speak Freely? A Study on the Impact of Format Restrictions on\n  Performance of Large Language Models", "abstract": "Structured generation, the process of producing content in standardized\nformats like JSON and XML, is widely utilized in real-world applications to\nextract key output information from large language models (LLMs). This study\ninvestigates whether such constraints on generation space impact LLMs\nabilities, including reasoning and domain knowledge comprehension.\nSpecifically, we evaluate LLMs performance when restricted to adhere to\nstructured formats versus generating free-form responses across various common\ntasks. Surprisingly, we observe a significant decline in LLMs reasoning\nabilities under format restrictions. Furthermore, we find that stricter format\nconstraints generally lead to greater performance degradation in reasoning\ntasks.", "published": "2024-08-05 13:08:24", "link": "http://arxiv.org/abs/2408.02442v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks\n  With Large Language Model", "abstract": "Significant advancements has recently been achieved in the field of\nmulti-modal large language models (MLLMs), demonstrating their remarkable\ncapabilities in understanding and reasoning across diverse tasks. However,\nthese models are often trained for specific tasks and rely on task-specific\ninput-output formats, limiting their applicability to a broader range of tasks.\nThis raises a fundamental question: Can we develop a unified approach to\nrepresent and handle different multi-modal tasks to maximize the\ngeneralizability of MLLMs? In this paper, we propose UnifiedMLLM, a\ncomprehensive model designed to represent various tasks using a unified\nrepresentation. Our model exhibits strong capabilities in comprehending the\nimplicit intent of user instructions and preforming reasoning. In addition to\ngenerating textual responses, our model also outputs task tokens and grounding\ntokens, serving as indicators of task types and task granularity. These outputs\nare subsequently routed through the task router and directed to specific expert\nmodels for task completion. To train our model, we construct a task-specific\ndataset and an 100k multi-task dataset encompassing complex scenarios.\nEmploying a three-stage training strategy, we equip our model with robust\nreasoning and task processing capabilities while preserving its generalization\ncapacity and knowledge reservoir. Extensive experiments showcase the impressive\nperformance of our unified representation approach across various tasks,\nsurpassing existing methodologies. Furthermore, our approach exhibits\nexceptional scalability and generality. Our code, model, and dataset will be\navailable at \\url{https://github.com/lzw-lzw/UnifiedMLLM}.", "published": "2024-08-05 14:27:39", "link": "http://arxiv.org/abs/2408.02503v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OneLove beyond the field -- A few-shot pipeline for topic and sentiment\n  analysis during the FIFA World Cup in Qatar", "abstract": "The FIFA World Cup in Qatar was discussed extensively in the news and on\nsocial media. Due to news reports with allegations of human rights violations,\nthere were calls to boycott it. Wearing a OneLove armband was part of a planned\nprotest activity. Controversy around the armband arose when FIFA threatened to\nsanction captains who wear it. To understand what topics Twitter users Tweeted\nabout and what the opinion of German Twitter users was towards the OneLove\narmband, we performed an analysis of German Tweets published during the World\nCup using in-context learning with LLMs. We validated the labels on human\nannotations. We found that Twitter users initially discussed the armband's\nimpact, LGBT rights, and politics; after the ban, the conversation shifted\ntowards politics in sports in general, accompanied by a subtle shift in\nsentiment towards neutrality. Our evaluation serves as a framework for future\nresearch to explore the impact of sports activism and evolving public\nsentiment. This is especially useful in settings where labeling datasets for\nspecific opinions is unfeasible, such as when events are unfolding.", "published": "2024-08-05 14:40:40", "link": "http://arxiv.org/abs/2408.02520v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Caution for the Environment: Multimodal Agents are Susceptible to\n  Environmental Distractions", "abstract": "This paper investigates the faithfulness of multimodal large language model\n(MLLM) agents in the graphical user interface (GUI) environment, aiming to\naddress the research question of whether multimodal GUI agents can be\ndistracted by environmental context. A general setting is proposed where both\nthe user and the agent are benign, and the environment, while not malicious,\ncontains unrelated content. A wide range of MLLMs are evaluated as GUI agents\nusing our simulated dataset, following three working patterns with different\nlevels of perception. Experimental results reveal that even the most powerful\nmodels, whether generalist agents or specialist GUI agents, are susceptible to\ndistractions. While recent studies predominantly focus on the helpfulness\n(i.e., action accuracy) of multimodal agents, our findings indicate that these\nagents are prone to environmental distractions, resulting in unfaithful\nbehaviors. Furthermore, we switch to the adversarial perspective and implement\nenvironment injection, demonstrating that such unfaithfulness can be exploited,\nleading to unexpected risks.", "published": "2024-08-05 15:16:22", "link": "http://arxiv.org/abs/2408.02544v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BioMamba: A Pre-trained Biomedical Language Representation Model\n  Leveraging Mamba", "abstract": "The advancement of natural language processing (NLP) in biology hinges on\nmodels' ability to interpret intricate biomedical literature. Traditional\nmodels often struggle with the complex and domain-specific language in this\nfield. In this paper, we present BioMamba, a pre-trained model specifically\ndesigned for biomedical text mining. BioMamba builds upon the Mamba\narchitecture and is pre-trained on an extensive corpus of biomedical\nliterature. Our empirical studies demonstrate that BioMamba significantly\noutperforms models like BioBERT and general-domain Mamba across various\nbiomedical tasks. For instance, BioMamba achieves a 100 times reduction in\nperplexity and a 4 times reduction in cross-entropy loss on the BioASQ test\nset. We provide an overview of the model architecture, pre-training process,\nand fine-tuning techniques. Additionally, we release the code and trained model\nto facilitate further research.", "published": "2024-08-05 16:21:36", "link": "http://arxiv.org/abs/2408.02600v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory", "abstract": "Humans are not homo economicus (i.e., rational economic beings). As humans,\nwe exhibit systematic behavioral biases such as loss aversion, anchoring,\nframing, etc., which lead us to make suboptimal economic decisions. Insofar as\nsuch biases may be embedded in text data on which large language models (LLMs)\nare trained, to what extent are LLMs prone to the same behavioral biases?\nUnderstanding these biases in LLMs is crucial for deploying LLMs to support\nhuman decision-making. We propose utility theory-a paradigm at the core of\nmodern economic theory-as an approach to evaluate the economic biases of LLMs.\nUtility theory enables the quantification and comparison of economic behavior\nagainst benchmarks such as perfect rationality or human behavior. To\ndemonstrate our approach, we quantify and compare the economic behavior of a\nvariety of open- and closed-source LLMs. We find that the economic behavior of\ncurrent LLMs is neither entirely human-like nor entirely economicus-like. We\nalso find that most current LLMs struggle to maintain consistent economic\nbehavior across settings. Finally, we illustrate how our approach can measure\nthe effect of interventions such as prompting on economic biases.", "published": "2024-08-05 19:00:43", "link": "http://arxiv.org/abs/2408.02784v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Mechanics of Conceptual Interpretation in GPT Models: Interpretative\n  Insights", "abstract": "Locating and editing knowledge in large language models (LLMs) is crucial for\nenhancing their accuracy, safety, and inference rationale. We introduce\n``concept editing'', an innovative variation of knowledge editing that uncovers\nconceptualisation mechanisms within these models. Using the reverse dictionary\ntask, inference tracing, and input abstraction, we analyse the Multi-Layer\nPerceptron (MLP), Multi-Head Attention (MHA), and hidden state components of\ntransformer models. Our results reveal distinct patterns: MLP layers employ\nkey-value retrieval mechanism and context-dependent processing, which are\nhighly associated with relative input tokens. MHA layers demonstrate a\ndistributed nature with significant higher-level activations, suggesting\nsophisticated semantic integration. Hidden states emphasise the importance of\nthe last token and top layers in the inference process. We observe evidence of\ngradual information building and distributed representation. These observations\nelucidate how transformer models process semantic information, paving the way\nfor targeted interventions and improved interpretability techniques. Our work\nhighlights the complex, layered nature of semantic processing in LLMs and the\nchallenges of isolating and modifying specific concepts within these models.", "published": "2024-08-05 18:50:08", "link": "http://arxiv.org/abs/2408.11827v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs", "abstract": "Large language models (LLMs) have shown great potential in code-related\ntasks, yet open-source models lag behind their closed-source counterparts. To\nbridge this performance gap, existing methods generate vast amounts of\nsynthetic data for fine-tuning, leading to inefficiencies in training.\nMotivated by the need for more effective and efficient training, we propose the\nCode Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces\nthe Complexity and Diversity Aware Sampling (CDAS) method to select\nhigh-quality training data based on complexity and diversity, and the Dynamic\nPack padding strategy to reduce computational resource usage by minimizing\npadding tokens during training. Experimental results demonstrate that\nCodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,\nachieves an 8.6% performance increase on HumanEval, reduces training time by\n78%, and decreases peak GPU memory usage by 27%. These findings underscore\nCodeACT's ability to enhance the performance and efficiency of open-source\nmodels. By optimizing both the data selection and training processes, CodeACT\noffers a comprehensive approach to improving the capabilities of open-source\nLLMs while significantly reducing computational requirements, addressing the\ndual challenges of data quality and training efficiency, and paving the way for\nmore resource-efficient and performant models.", "published": "2024-08-05 02:38:48", "link": "http://arxiv.org/abs/2408.02193v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating the Performance of Large Language Models for SDG Mapping\n  (Technical Report)", "abstract": "The use of large language models (LLMs) is expanding rapidly, and open-source\nversions are becoming available, offering users safer and more adaptable\noptions. These models enable users to protect data privacy by eliminating the\nneed to provide data to third parties and can be customized for specific tasks.\nIn this study, we compare the performance of various language models on the\nSustainable Development Goal (SDG) mapping task, using the output of GPT-4o as\nthe baseline. The selected open-source models for comparison include Mixtral,\nLLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a more\nspecialized version of GPT-4o, was included to extend the comparison. Given the\nmulti-label nature of the SDG mapping task, we employed metrics such as F1\nscore, precision, and recall with micro-averaging to evaluate different aspects\nof the models' performance. These metrics are derived from the confusion matrix\nto ensure a comprehensive evaluation. We provide a clear observation and\nanalysis of each model's performance by plotting curves based on F1 score,\nprecision, and recall at different thresholds. According to the results of this\nexperiment, LLaMA 2 and Gemma still have significant room for improvement. The\nother four models do not exhibit particularly large differences in performance.\nThe outputs from all seven models are available on Zenodo:\nhttps://doi.org/10.5281/zenodo.12789375.", "published": "2024-08-05 03:05:02", "link": "http://arxiv.org/abs/2408.02201v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method\n  for Legal Charge Prediction", "abstract": "Legal charge prediction, an essential task in legal AI, seeks to assign\naccurate charge labels to case descriptions, attracting significant recent\ninterest. Existing methods primarily employ diverse neural network structures\nfor modeling case descriptions directly, failing to effectively leverage\nmulti-source external knowledge. We propose a prompt learning framework-based\nmethod that simultaneously leverages multi-source heterogeneous external\nknowledge from a legal knowledge base, a conversational LLM, and related legal\narticles. Specifically, we match knowledge snippets in case descriptions via\nthe legal knowledge base and encapsulate them into the input through a hard\nprompt template. Additionally, we retrieve legal articles related to a given\ncase description through contrastive learning, and then obtain factual elements\nwithin the case description through a conversational LLM. We fuse the embedding\nvectors of soft prompt tokens with the encoding vector of factual elements to\nachieve knowledge-enhanced model forward inference. Experimental results show\nthat our method achieved state-of-the-art results on CAIL-2018, the largest\nlegal charge prediction dataset, and our method has lower data dependency. Case\nstudies also demonstrate our method's strong interpretability.", "published": "2024-08-05 04:53:17", "link": "http://arxiv.org/abs/2408.02233v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Few-Shot Approach for Relation Extraction Domain Adaptation using\n  Large Language Models", "abstract": "Knowledge graphs (KGs) have been successfully applied to the analysis of\ncomplex scientific and technological domains, with automatic KG generation\nmethods typically building upon relation extraction models capturing\nfine-grained relations between domain entities in text. While these relations\nare fully applicable across scientific areas, existing models are trained on\nfew domain-specific datasets such as SciERC and do not perform well on new\ntarget domains. In this paper, we experiment with leveraging in-context\nlearning capabilities of Large Language Models to perform schema-constrained\ndata annotation, collecting in-domain training instances for a\nTransformer-based relation extraction model deployed on titles and abstracts of\nresearch papers in the Architecture, Construction, Engineering and Operations\n(AECO) domain. By assessing the performance gain with respect to a baseline\nDeep Learning architecture trained on off-domain data, we show that by using a\nfew-shot learning strategy with structured prompts and only minimal expert\nannotation the presented approach can potentially support domain adaptation of\na science KG generation model.", "published": "2024-08-05 11:06:36", "link": "http://arxiv.org/abs/2408.02377v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in\n  Customized Large Language Models", "abstract": "The drastic increase of large language models' (LLMs) parameters has led to a\nnew research direction of fine-tuning-free downstream customization by prompts,\ni.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)\nplay an important role in many businesses, there has emerged growing concerns\nabout the prompt leakage, which undermines the intellectual properties of these\nservices and causes downstream attacks. In this paper, we analyze the\nunderlying mechanism of prompt leakage, which we refer to as prompt\nmemorization, and develop corresponding defending strategies. By exploring the\nscaling laws in prompt extraction, we analyze key attributes that influence\nprompt extraction, including model sizes, prompt lengths, as well as the types\nof prompts. Then we propose two hypotheses that explain how LLMs expose their\nprompts. The first is attributed to the perplexity, i.e. the familiarity of\nLLMs to texts, whereas the second is based on the straightforward token\ntranslation path in attention matrices. To defend against such threats, we\ninvestigate whether alignments can undermine the extraction of prompts. We find\nthat current LLMs, even those with safety alignments like GPT-4, are highly\nvulnerable to prompt extraction attacks, even under the most straightforward\nuser attacks. Therefore, we put forward several defense strategies with the\ninspiration of our findings, which achieve 83.8\\% and 71.0\\% drop in the prompt\nextraction rate for Llama2-7B and GPT-3.5, respectively. Source code is\navaliable at https://github.com/liangzid/PromptExtractionEval.", "published": "2024-08-05 12:20:39", "link": "http://arxiv.org/abs/2408.02416v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Long Input Benchmark for Russian Analysis", "abstract": "Recent advancements in Natural Language Processing (NLP) have fostered the\ndevelopment of Large Language Models (LLMs) that can solve an immense variety\nof tasks. One of the key aspects of their application is their ability to work\nwith long text documents and to process long sequences of tokens. This has\ncreated a demand for proper evaluation of long-context understanding. To\naddress this need for the Russian language, we propose LIBRA (Long Input\nBenchmark for Russian Analysis), which comprises 21 adapted datasets to study\nthe LLM's abilities to understand long texts thoroughly. The tests are divided\ninto four complexity groups and allow the evaluation of models across various\ncontext lengths ranging from 4k up to 128k tokens. We provide the open-source\ndatasets, codebase, and public leaderboard for LIBRA to guide forthcoming\nresearch.", "published": "2024-08-05 12:59:35", "link": "http://arxiv.org/abs/2408.02439v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan:\n  A Multi-Player Cooperative Game under Imperfect Information", "abstract": "Large language models (LLMs) have shown success in handling simple games with\nimperfect information and enabling multi-agent coordination, but their ability\nto facilitate practical collaboration against other agents in complex,\nimperfect information environments, especially in a non-English environment,\nstill needs to be explored. This study investigates the applicability of\nknowledge acquired by open-source and API-based LLMs to sophisticated\ntext-based games requiring agent collaboration under imperfect information,\ncomparing their performance to established baselines using other types of\nagents. We propose a Theory of Mind (ToM) planning technique that allows LLM\nagents to adapt their strategy against various adversaries using only game\nrules, current state, and historical context as input. An external tool was\nincorporated to mitigate the challenge of dynamic and extensive action spaces\nin this card game. Our results show that although a performance gap exists\nbetween current LLMs and state-of-the-art reinforcement learning (RL) models,\nLLMs demonstrate ToM capabilities in this game setting. It consistently\nimproves their performance against opposing agents, suggesting their ability to\nunderstand the actions of allies and adversaries and establish collaboration\nwith allies. To encourage further research and understanding, we have made our\ncodebase openly accessible.", "published": "2024-08-05 15:36:46", "link": "http://arxiv.org/abs/2408.02559v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Artificial Intelligence for Public Health Surveillance in Africa:\n  Applications and Opportunities", "abstract": "Artificial Intelligence (AI) is revolutionizing various fields, including\npublic health surveillance. In Africa, where health systems frequently\nencounter challenges such as limited resources, inadequate infrastructure,\nfailed health information systems and a shortage of skilled health\nprofessionals, AI offers a transformative opportunity. This paper investigates\nthe applications of AI in public health surveillance across the continent,\npresenting successful case studies and examining the benefits, opportunities,\nand challenges of implementing AI technologies in African healthcare settings.\nOur paper highlights AI's potential to enhance disease monitoring and health\noutcomes, and support effective public health interventions. The findings\npresented in the paper demonstrate that AI can significantly improve the\naccuracy and timeliness of disease detection and prediction, optimize resource\nallocation, and facilitate targeted public health strategies. Additionally, our\npaper identified key barriers to the widespread adoption of AI in African\npublic health systems and proposed actionable recommendations to overcome these\nchallenges.", "published": "2024-08-05 15:48:51", "link": "http://arxiv.org/abs/2408.02575v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Progressively Label Enhancement for Large Language Model Alignment", "abstract": "Large Language Models (LLM) alignment aims to prevent models from producing\ncontent that misaligns with human expectations, which can lead to ethical and\nlegal concerns. In the last few years, Reinforcement Learning from Human\nFeedback (RLHF) has been the most prominent method for achieving alignment. Due\nto challenges in stability and scalability with RLHF stages, which arise from\nthe complex interactions between multiple models, researchers are exploring\nalternative methods to achieve effects comparable to those of RLHF. However,\nthese methods often rely on large high-quality datasets. Despite some methods\nconsidering the generation of additional data to expand datasets, they often\ntreat model training and data generation as separate and static processes,\noverlooking the fact that these processes are highly interdependent, leading to\ninefficient utilization of the generated data. To deal with this problem, we\npropose PLE, i.e., Progressively Label Enhancement for LLM Alignment, a\nframework that dynamically adjusts the model's training process based on the\nevolving quality of the generated data. Specifically, we prompt the model to\ngenerate responses for both the original query and the query guided by a set of\ncarefully designed principles, and then utilize a dynamic threshold to\ndetermine the appropriate training approach for both responses based on their\ncorresponding reward scores. Experimental results demonstrate the effectiveness\nof PLE compared to existing LLM alignment methods.", "published": "2024-08-05 16:21:17", "link": "http://arxiv.org/abs/2408.02599v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language\n  Models", "abstract": "As large language models (LLMs) continue to advance in capability and\ninfluence, ensuring their security and preventing harmful outputs has become\ncrucial. A promising approach to address these concerns involves training\nmodels to automatically generate adversarial prompts for red teaming. However,\nthe evolving subtlety of vulnerabilities in LLMs challenges the effectiveness\nof current adversarial methods, which struggle to specifically target and\nexplore the weaknesses of these models. To tackle these challenges, we\nintroduce the $\\mathbf{S}\\text{elf-}\\mathbf{E}\\text{volving\n}\\mathbf{A}\\text{dversarial }\\mathbf{S}\\text{afety }\\mathbf{(SEAS)}$\noptimization framework, which enhances security by leveraging data generated by\nthe model itself. SEAS operates through three iterative stages: Initialization,\nAttack, and Adversarial Optimization, refining both the Red Team and Target\nmodels to improve robustness and safety. This framework reduces reliance on\nmanual testing and significantly enhances the security capabilities of LLMs.\nOur contributions include a novel adversarial framework, a comprehensive safety\ndataset, and after three iterations, the Target model achieves a security level\ncomparable to GPT-4, while the Red Team model shows a marked increase in attack\nsuccess rate (ASR) against advanced models. Our code and datasets are released\nat https://SEAS-LLM.github.io/.", "published": "2024-08-05 16:55:06", "link": "http://arxiv.org/abs/2408.02632v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Taught Evaluators", "abstract": "Model-based evaluation is at the heart of successful model development -- as\na reward model for training, and as a replacement for human evaluation. To\ntrain such evaluators, the standard approach is to collect a large amount of\nhuman preference judgments over model responses, which is costly and the data\nbecomes stale as models improve. In this work, we present an approach that aims\nto im-prove evaluators without human annotations, using synthetic training data\nonly. Starting from unlabeled instructions, our iterative self-improvement\nscheme generates contrasting model outputs and trains an LLM-as-a-Judge to\nproduce reasoning traces and final judgments, repeating this training at each\nnew iteration using the improved predictions. Without any labeled preference\ndata, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct)\nfrom 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms\ncommonly used LLM judges such as GPT-4 and matches the performance of the\ntop-performing reward models trained with labeled examples.", "published": "2024-08-05 17:57:02", "link": "http://arxiv.org/abs/2408.02666v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Entity Retrieval for Answering Entity-Centric Questions", "abstract": "The similarity between the question and indexed documents is a crucial factor\nin document retrieval for retrieval-augmented question answering. Although this\nis typically the only method for obtaining the relevant documents, it is not\nthe sole approach when dealing with entity-centric questions. In this study, we\npropose Entity Retrieval, a novel retrieval method which rather than relying on\nquestion-document similarity, depends on the salient entities within the\nquestion to identify the retrieval documents. We conduct an in-depth analysis\nof the performance of both dense and sparse retrieval methods in comparison to\nEntity Retrieval. Our findings reveal that our method not only leads to more\naccurate answers to entity-centric questions but also operates more\nefficiently.", "published": "2024-08-05 19:23:20", "link": "http://arxiv.org/abs/2408.02795v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback", "abstract": "Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.", "published": "2024-08-05 23:20:32", "link": "http://arxiv.org/abs/2408.02861v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Batching BPE Tokenization Merges", "abstract": "The Byte Pair Encoding algorithm can be safely batched to merge hundreds of\npairs of tokens at a time when building up a tokenizer's vocabulary. This\ntechnique combined with reducing the memory footprint of text used in\nvocabulary training make it feasible to train a high quality tokenizer on a\nbasic laptop. This paper presents BatchBPE, an open-source pure Python\nimplementation of these concepts, with the goal of making experimenting with\nnew tokenization strategies more accessible especially in compute- and\nmemory-constrained contexts. BatchBPE's usefulness and malleability are\ndemonstrated through the training of several token vocabularies to explore the\nbatch merging process and experiment with preprocessing a stop word list and\nignoring the least common text chunks in a dataset. Resultant encoded lengths\nof texts are used as a basic evaluation metric.", "published": "2024-08-05 09:37:21", "link": "http://arxiv.org/abs/2408.04653v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Strong and weak alignment of large language models with human values", "abstract": "Minimizing negative impacts of Artificial Intelligent (AI) systems on human\nsocieties without human supervision requires them to be able to align with\nhuman values. However, most current work only addresses this issue from a\ntechnical point of view, e.g., improving current methods relying on\nreinforcement learning from human feedback, neglecting what it means and is\nrequired for alignment to occur. Here, we propose to distinguish strong and\nweak value alignment. Strong alignment requires cognitive abilities (either\nhuman-like or different from humans) such as understanding and reasoning about\nagents' intentions and their ability to causally produce desired effects. We\nargue that this is required for AI systems like large language models (LLMs) to\nbe able to recognize situations presenting a risk that human values may be\nflouted. To illustrate this distinction, we present a series of prompts showing\nChatGPT's, Gemini's and Copilot's failures to recognize some of these\nsituations. We moreover analyze word embeddings to show that the nearest\nneighbors of some human values in LLMs differ from humans' semantic\nrepresentations. We then propose a new thought experiment that we call \"the\nChinese room with a word transition dictionary\", in extension of John Searle's\nfamous proposal. We finally mention current promising research directions\ntowards a weak alignment, which could produce statistically satisfying answers\nin a number of common situations, however so far without ensuring any truth\nvalue.", "published": "2024-08-05 11:27:51", "link": "http://arxiv.org/abs/2408.04655v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Semantic Markup of Mathematical Documents via User Interaction", "abstract": "Mathematical documents written in LaTeX often contain ambiguities. We can\nresolve some of them via semantic markup using, e.g., sTeX, which also has\nother potential benefits, such as interoperability with computer algebra\nsystems, proof systems, and increased accessibility. However, semantic markup\nis more involved than \"regular\" typesetting and presents a challenge for\nauthors of mathematical documents. We aim to smooth out the transition from\nplain LaTeX to semantic markup by developing semi-automatic tools for authors.\nIn this paper we present an approach to semantic markup of formulas by\n(semi-)automatically generating grammars from existing sTeX macro definitions\nand parsing mathematical formulas with them. We also present a GUI-based tool\nfor the disambiguation of parse results and showcase its functionality and\npotential using a grammar for parsing untyped $\\lambda$-terms.", "published": "2024-08-05 12:36:40", "link": "http://arxiv.org/abs/2408.04656v1", "categories": ["cs.CL", "cs.IR", "68V30"], "primary_category": "cs.CL"}
{"title": "XMainframe: A Large Language Model for Mainframe Modernization", "abstract": "Mainframe operating systems, despite their inception in the 1940s, continue\nto support critical sectors like finance and government. However, these systems\nare often viewed as outdated, requiring extensive maintenance and\nmodernization. Addressing this challenge necessitates innovative tools that can\nunderstand and interact with legacy codebases. To this end, we introduce\nXMainframe, a state-of-the-art large language model (LLM) specifically designed\nwith knowledge of mainframe legacy systems and COBOL codebases. Our solution\ninvolves the creation of an extensive data collection pipeline to produce\nhigh-quality training datasets, enhancing XMainframe's performance in this\nspecialized domain. Additionally, we present MainframeBench, a comprehensive\nbenchmark for assessing mainframe knowledge, including multiple-choice\nquestions, question answering, and COBOL code summarization. Our empirical\nevaluations demonstrate that XMainframe consistently outperforms existing\nstate-of-the-art LLMs across these tasks. Specifically, XMainframe achieves 30%\nhigher accuracy than DeepSeek-Coder on multiple-choice questions, doubles the\nBLEU score of Mixtral-Instruct 8x7B on question answering, and scores six times\nhigher than GPT-3.5 on COBOL summarization. Our work highlights the potential\nof XMainframe to drive significant advancements in managing and modernizing\nlegacy systems, thereby enhancing productivity and saving time for software\ndevelopers.", "published": "2024-08-05 20:01:10", "link": "http://arxiv.org/abs/2408.04660v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MaterioMiner -- An ontology-based text mining dataset for extraction of\n  process-structure-property entities", "abstract": "While large language models learn sound statistical representations of the\nlanguage and information therein, ontologies are symbolic knowledge\nrepresentations that can complement the former ideally. Research at this\ncritical intersection relies on datasets that intertwine ontologies and text\ncorpora to enable training and comprehensive benchmarking of neurosymbolic\nmodels. We present the MaterioMiner dataset and the linked materials mechanics\nontology where ontological concepts from the mechanics of materials domain are\nassociated with textual entities within the literature corpus. Another\ndistinctive feature of the dataset is its eminently fine-granular annotation.\nSpecifically, 179 distinct classes are manually annotated by three raters\nwithin four publications, amounting to a total of 2191 entities that were\nannotated and curated. Conceptual work is presented for the symbolic\nrepresentation of causal composition-process-microstructure-property\nrelationships. We explore the annotation consistency between the three raters\nand perform fine-tuning of pre-trained models to showcase the feasibility of\nnamed-entity recognition model training. Reusing the dataset can foster\ntraining and benchmarking of materials language models, automated ontology\nconstruction, and knowledge graph generation from textual data.", "published": "2024-08-05 21:42:59", "link": "http://arxiv.org/abs/2408.04661v1", "categories": ["cs.CL", "cond-mat.mtrl-sci"], "primary_category": "cs.CL"}
{"title": "ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems", "abstract": "Recently, there has been increasing interest in using Large Language Models\n(LLMs) to construct complex multi-agent systems to perform tasks such as\ncompiling literature reviews, drafting consumer reports, and planning\nvacations. Many tools and libraries exist for helping create such systems,\nhowever none support recursive multi-agent systems -- where the models\nthemselves flexibly decide when to delegate tasks and how to organize their\ndelegation structure. In this work, we introduce ReDel: a toolkit for recursive\nmulti-agent systems that supports custom tool-use, delegation schemes,\nevent-based logging, and interactive replay in an easy-to-use web interface. We\nshow that, using ReDel, we are able to easily identify potential areas of\nimprovements through the visualization and debugging tools. Our code,\ndocumentation, and PyPI package are open-source and free to use under the MIT\nlicense at https://github.com/zhudotexe/redel.", "published": "2024-08-05 05:43:23", "link": "http://arxiv.org/abs/2408.02248v2", "categories": ["cs.CL", "cs.MA", "cs.SE", "I.2.7"], "primary_category": "cs.CL"}
{"title": "COM Kitchens: An Unedited Overhead-view Video Dataset as a\n  Vision-Language Benchmark", "abstract": "Procedural video understanding is gaining attention in the vision and\nlanguage community. Deep learning-based video analysis requires extensive data.\nConsequently, existing works often use web videos as training resources, making\nit challenging to query instructional contents from raw video observations. To\naddress this issue, we propose a new dataset, COM Kitchens. The dataset\nconsists of unedited overhead-view videos captured by smartphones, in which\nparticipants performed food preparation based on given recipes. Fixed-viewpoint\nvideo datasets often lack environmental diversity due to high camera setup\ncosts. We used modern wide-angle smartphone lenses to cover cooking counters\nfrom sink to cooktop in an overhead view, capturing activity without in-person\nassistance. With this setup, we collected a diverse dataset by distributing\nsmartphones to participants. With this dataset, we propose the novel\nvideo-to-text retrieval task Online Recipe Retrieval (OnRR) and new video\ncaptioning domain Dense Video Captioning on unedited Overhead-View videos\n(DVC-OV). Our experiments verified the capabilities and limitations of current\nweb-video-based SOTA methods in handling these tasks.", "published": "2024-08-05 07:00:10", "link": "http://arxiv.org/abs/2408.02272v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Spin glass model of in-context learning", "abstract": "Large language models show a surprising in-context learning ability -- being\nable to use a prompt to form a prediction for a query, yet without additional\ntraining, in stark contrast to old-fashioned supervised learning. Providing a\nmechanistic interpretation and linking the empirical phenomenon to physics are\nthus challenging and remain unsolved. We study a simple yet expressive\ntransformer with linear attention and map this structure to a spin glass model\nwith real-valued spins, where the couplings and fields explain the intrinsic\ndisorder in data. The spin glass model explains how the weight parameters\ninteract with each other during pre-training, and further clarifies why an\nunseen function can be predicted by providing only a prompt yet without further\ntraining. Our theory reveals that for single-instance learning, increasing the\ntask diversity leads to the emergence of in-context learning, by allowing the\nBoltzmann distribution to converge to a unique correct solution of weight\nparameters. Therefore the pre-trained transformer displays a prediction power\nin a novel prompt setting. The proposed analytically tractable model thus\noffers a promising avenue for thinking about how to interpret many intriguing\nbut puzzling properties of large language models.", "published": "2024-08-05 07:54:01", "link": "http://arxiv.org/abs/2408.02288v2", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.CL"], "primary_category": "cond-mat.dis-nn"}
{"title": "Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR\n  Dataset Construction", "abstract": "Advancements in AI and natural language processing have revolutionized\nmachine-human language interactions, with question answering (QA) systems\nplaying a pivotal role. The knowledge base question answering (KBQA) task,\nutilizing structured knowledge graphs (KG), allows for handling extensive\nknowledge-intensive questions. However, a significant gap exists in KBQA\ndatasets, especially for low-resource languages. Many existing construction\npipelines for these datasets are outdated and inefficient in human labor, and\nmodern assisting tools like Large Language Models (LLM) are not utilized to\nreduce the workload. To address this, we have designed and implemented a\nmodern, semi-automated approach for creating datasets, encompassing tasks such\nas KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),\ntailored explicitly for low-resource environments. We executed this pipeline\nand introduced the PUGG dataset, the first Polish KBQA dataset, and novel\ndatasets for MRC and IR. Additionally, we provide a comprehensive\nimplementation, insightful findings, detailed statistics, and evaluation of\nbaseline models.", "published": "2024-08-05 09:23:49", "link": "http://arxiv.org/abs/2408.02337v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "An approach to optimize inference of the DIART speaker diarization\n  pipeline", "abstract": "Speaker diarization answers the question \"who spoke when\" for an audio file.\nIn some diarization scenarios, low latency is required for transcription.\nSpeaker diarization with low latency is referred to as online speaker\ndiarization. The DIART pipeline is an online speaker diarization system. It\nconsists of a segmentation and an embedding model. The embedding model has the\nlargest share of the overall latency. The aim of this paper is to optimize the\ninference latency of the DIART pipeline. Different inference optimization\nmethods such as knowledge distilation, pruning, quantization and layer fusion\nare applied to the embedding model of the pipeline. It turns out that knowledge\ndistillation optimizes the latency, but has a negative effect on the accuracy.\nQuantization and layer fusion also have a positive influence on the latency\nwithout worsening the accuracy. Pruning, on the other hand, does not improve\nlatency.", "published": "2024-08-05 09:38:07", "link": "http://arxiv.org/abs/2408.02341v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding", "abstract": "State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.", "published": "2024-08-05 10:10:01", "link": "http://arxiv.org/abs/2408.02361v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of\n  Current, Challenges and Future", "abstract": "With the rise of large language models (LLMs), researchers are increasingly\nexploring their applications in var ious vertical domains, such as software\nengineering. LLMs have achieved remarkable success in areas including code\ngeneration and vulnerability detection. However, they also exhibit numerous\nlimitations and shortcomings. LLM-based agents, a novel tech nology with the\npotential for Artificial General Intelligence (AGI), combine LLMs as the core\nfor decision-making and action-taking, addressing some of the inherent\nlimitations of LLMs such as lack of autonomy and self-improvement. Despite\nnumerous studies and surveys exploring the possibility of using LLMs in\nsoftware engineering, it lacks a clear distinction between LLMs and LLM based\nagents. It is still in its early stage for a unified standard and benchmarking\nto qualify an LLM solution as an LLM-based agent in its domain. In this survey,\nwe broadly investigate the current practice and solutions for LLMs and\nLLM-based agents for software engineering. In particular we summarise six key\ntopics: requirement engineering, code generation, autonomous decision-making,\nsoftware design, test generation, and software maintenance. We review and\ndifferentiate the work of LLMs and LLM-based agents from these six topics,\nexamining their differences and similarities in tasks, benchmarks, and\nevaluation metrics. Finally, we discuss the models and benchmarks used,\nproviding a comprehensive analysis of their applications and effectiveness in\nsoftware engineering. We anticipate this work will shed some lights on pushing\nthe boundaries of LLM-based agents in software engineering for future research.", "published": "2024-08-05 14:01:15", "link": "http://arxiv.org/abs/2408.02479v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented\n  Generation", "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.", "published": "2024-08-05 15:16:24", "link": "http://arxiv.org/abs/2408.02545v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality\n  Aspect-Based Summarization", "abstract": "The ever-increasing volume of digital information necessitates efficient\nmethods for users to extract key insights from lengthy documents. Aspect-based\nsummarization offers a targeted approach, generating summaries focused on\nspecific aspects within a document. Despite advancements in aspect-based\nsummarization research, there is a continuous quest for improved model\nperformance. Given that large language models (LLMs) have demonstrated the\npotential to revolutionize diverse tasks within natural language processing,\nparticularly in the problem of summarization, this paper explores the potential\nof fine-tuning LLMs for the aspect-based summarization task. We evaluate the\nimpact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,\nGemma and Aya, on a publicly available domain-specific aspect based summary\ndataset. We hypothesize that this approach will enable these models to\neffectively identify and extract aspect-related information, leading to\nsuperior quality aspect-based summaries compared to the state-of-the-art. We\nestablish a comprehensive evaluation framework to compare the performance of\nfine-tuned LLMs against competing aspect-based summarization methods and\nvanilla counterparts of the fine-tuned LLMs. Our work contributes to the field\nof aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs\nfor generating high-quality aspect-based summaries. Furthermore, it opens doors\nfor further exploration of using LLMs for targeted information extraction tasks\nacross various NLP domains.", "published": "2024-08-05 16:00:21", "link": "http://arxiv.org/abs/2408.02584v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large\n  Language Models?", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language tasks, but their safety and morality remain contentious due to\ntheir training on internet text corpora. To address these concerns, alignment\ntechniques have been developed to improve the public usability and safety of\nLLMs. Yet, the potential for generating harmful content through these models\nseems to persist. This paper explores the concept of jailbreaking\nLLMs-reversing their alignment through adversarial triggers. Previous methods,\nsuch as soft embedding prompts, manually crafted prompts, and gradient-based\nautomatic prompts, have had limited success on black-box models due to their\nrequirements for model access and for producing a low variety of manually\ncrafted prompts, making them susceptible to being blocked. This paper\nintroduces a novel approach using reinforcement learning to optimize\nadversarial triggers, requiring only inference API access to the target model\nand a small surrogate model. Our method, which leverages a BERTScore-based\nreward function, enhances the transferability and effectiveness of adversarial\ntriggers on new black-box models. We demonstrate that this approach improves\nthe performance of adversarial triggers on a previously untested language\nmodel.", "published": "2024-08-05 17:27:29", "link": "http://arxiv.org/abs/2408.02651v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Examining Gender and Power on Wikipedia Through Face and Politeness", "abstract": "We propose a framework for analyzing discourse by combining two\ninterdependent concepts from sociolinguistic theory: face acts and politeness.\nWhile politeness has robust existing tools and data, face acts are less\nresourced. We introduce a new corpus created by annotating Wikipedia talk pages\nwith face acts and we use this to train a face act tagger. We then employ our\nframework to study how face and politeness interact with gender and power in\ndiscussions between Wikipedia editors. Among other findings, we observe that\nfemale Wikipedians are not only more polite, which is consistent with prior\nstudies, but that this difference corresponds with significantly more language\ndirected at humbling aspects of their own face. Interestingly, the distinction\nnearly vanishes once limiting to editors with administrative power.", "published": "2024-08-05 19:28:58", "link": "http://arxiv.org/abs/2408.02798v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Interpretation of the Intent Detection Problem as Dynamics in a\n  Low-dimensional Space", "abstract": "Intent detection is a text classification task whose aim is to recognize and\nlabel the semantics behind a users query. It plays a critical role in various\nbusiness applications. The output of the intent detection module strongly\nconditions the behavior of the whole system. This sequence analysis task is\nmainly tackled using deep learning techniques. Despite the widespread use of\nthese techniques, the internal mechanisms used by networks to solve the problem\nare poorly understood. Recent lines of work have analyzed the computational\nmechanisms learned by RNNs from a dynamical systems perspective. In this work,\nwe investigate how different RNN architectures solve the SNIPS intent detection\nproblem. Sentences injected into trained networks can be interpreted as\ntrajectories traversing a hidden state space. This space is constrained to a\nlow-dimensional manifold whose dimensionality is related to the embedding and\nhidden layer sizes. To generate predictions, RNN steers the trajectories\ntowards concrete regions, spatially aligned with the output layer matrix rows\ndirections. Underlying the system dynamics, an unexpected fixed point topology\nhas been identified with a limited number of attractors. Our results provide\nnew insights into the inner workings of networks that solve the intent\ndetection task.", "published": "2024-08-05 21:22:36", "link": "http://arxiv.org/abs/2408.02838v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "VisionUnite: A Vision-Language Foundation Model for Ophthalmology\n  Enhanced with Clinical Knowledge", "abstract": "The need for improved diagnostic methods in ophthalmology is acute,\nespecially in the less developed regions with limited access to specialists and\nadvanced equipment. Therefore, we introduce VisionUnite, a novel\nvision-language foundation model for ophthalmology enhanced with clinical\nknowledge. VisionUnite has been pretrained on an extensive dataset comprising\n1.24 million image-text pairs, and further refined using our proposed MMFundus\ndataset, which includes 296,379 high-quality fundus image-text pairs and\n889,137 simulated doctor-patient dialogue instances. Our experiments indicate\nthat VisionUnite outperforms existing generative foundation models such as\nGPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable\nto junior ophthalmologists. VisionUnite performs well in various clinical\nscenarios including open-ended multi-disease diagnosis, clinical explanation,\nand patient interaction, making it a highly versatile tool for initial\nophthalmic disease screening. VisionUnite can also serve as an educational aid\nfor junior ophthalmologists, accelerating their acquisition of knowledge\nregarding both common and rare ophthalmic conditions. VisionUnite represents a\nsignificant advancement in ophthalmology, with broad implications for\ndiagnostics, medical education, and understanding of disease mechanisms.", "published": "2024-08-05 23:31:07", "link": "http://arxiv.org/abs/2408.02865v1", "categories": ["eess.IV", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "eess.IV"}
{"title": "miniCTX: Neural Theorem Proving with (Long-)Contexts", "abstract": "Real-world formal theorem proving often depends on a wealth of context,\nincluding definitions, lemmas, comments, file structure, and other information.\nWe introduce miniCTX, which tests a model's ability to prove formal\nmathematical theorems that depend on new context that is not seen during\ntraining. miniCTX contains theorems sourced from real Lean projects and\ntextbooks, each associated with a context that can span tens of thousands of\ntokens. Models are tasked with proving a theorem given access to code from the\ntheorem's repository, which contains context that is needed for the proof. As a\nbaseline for miniCTX, we tested fine-tuning and prompting methods that\ncondition theorem proving on preceding context. Both approaches substantially\noutperform traditional methods that rely solely on state information. We found\nthat this ability to use context is not captured by previous benchmarks such as\nminiF2F. Alongside miniCTX, we offer ntp-toolkit for automatically extracting\nand annotating theorem proving data, making it easy to add new projects into\nminiCTX to ensure that contexts are not seen during training. miniCTX offers a\nchallenging and realistic evaluation of neural theorem provers.", "published": "2024-08-05 20:19:18", "link": "http://arxiv.org/abs/2408.03350v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Winning Amazon KDD Cup'24", "abstract": "This paper describes the winning solution of all 5 tasks for the Amazon KDD\nCup 2024 Multi Task Online Shopping Challenge for LLMs. The challenge was to\nbuild a useful assistant, answering questions in the domain of online shopping.\nThe competition contained 57 diverse tasks, covering 5 different task types\n(e.g. multiple choice) and across 4 different tracks (e.g. multi-lingual). Our\nsolution is a single model per track. We fine-tune Qwen2-72B-Instruct on our\nown training dataset. As the competition released only 96 example questions, we\ndeveloped our own training dataset by processing multiple public datasets or\nusing Large Language Models for data augmentation and synthetic data\ngeneration. We apply wise-ft to account for distribution shifts and ensemble\nmultiple LoRA adapters in one model. We employed Logits Processors to constrain\nthe model output on relevant tokens for the tasks. AWQ 4-bit Quantization and\nvLLM are used during inference to predict the test dataset in the time\nconstraints of 20 to 140 minutes depending on the track. Our solution achieved\nthe first place in each individual track and is the first place overall of\nAmazons KDD Cup 2024.", "published": "2024-08-05 14:40:04", "link": "http://arxiv.org/abs/2408.04658v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Supply Chain Visibility with Knowledge Graphs and Large\n  Language Models", "abstract": "In today's globalized economy, comprehensive supply chain visibility is\ncrucial for effective risk management. Achieving visibility remains a\nsignificant challenge due to limited information sharing among supply chain\npartners. This paper presents a novel framework leveraging Knowledge Graphs\n(KGs) and Large Language Models (LLMs) to enhance supply chain visibility\nwithout relying on direct stakeholder information sharing. Our zero-shot,\nLLM-driven approach automates the extraction of supply chain information from\ndiverse public sources and constructs KGs to capture complex interdependencies\nbetween supply chain entities. We employ zero-shot prompting for Named Entity\nRecognition (NER) and Relation Extraction (RE) tasks, eliminating the need for\nextensive domain-specific training. We validate the framework with a case study\non electric vehicle supply chains, focusing on tracking critical minerals for\nbattery manufacturing. Results show significant improvements in supply chain\nmapping, extending visibility beyond tier-2 suppliers. The framework reveals\ncritical dependencies and alternative sourcing options, enhancing risk\nmanagement and strategic planning. With high accuracy in NER and RE tasks, it\nprovides an effective tool for understanding complex, multi-tiered supply\nnetworks. This research offers a scalable, flexible method for constructing\ndomain-specific supply chain KGs, addressing longstanding challenges in\nvisibility and paving the way for advancements in digital supply chain\nsurveillance.", "published": "2024-08-05 17:11:29", "link": "http://arxiv.org/abs/2408.07705v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "VyAnG-Net: A Novel Multi-Modal Sarcasm Recognition Model by Uncovering\n  Visual, Acoustic and Glossary Features", "abstract": "Various linguistic and non-linguistic clues, such as excessive emphasis on a\nword, a shift in the tone of voice, or an awkward expression, frequently convey\nsarcasm. The computer vision problem of sarcasm recognition in conversation\naims to identify hidden sarcastic, criticizing, and metaphorical information\nembedded in everyday dialogue. Prior, sarcasm recognition has focused mainly on\ntext. Still, it is critical to consider all textual information, audio stream,\nfacial expression, and body position for reliable sarcasm identification.\nHence, we propose a novel approach that combines a lightweight depth attention\nmodule with a self-regulated ConvNet to concentrate on the most crucial\nfeatures of visual data and an attentional tokenizer based strategy to extract\nthe most critical context-specific information from the textual data. The\nfollowing is a list of the key contributions that our experimentation has made\nin response to performing the task of Multi-modal Sarcasm Recognition: an\nattentional tokenizer branch to get beneficial features from the glossary\ncontent provided by the subtitles; a visual branch for acquiring the most\nprominent features from the video frames; an utterance-level feature extraction\nfrom acoustic content and a multi-headed attention based feature fusion branch\nto blend features obtained from multiple modalities. Extensive testing on one\nof the benchmark video datasets, MUSTaRD, yielded an accuracy of 79.86% for\nspeaker dependent and 76.94% for speaker independent configuration\ndemonstrating that our approach is superior to the existing methods. We have\nalso conducted a cross-dataset analysis to test the adaptability of VyAnG-Net\nwith unseen samples of another dataset MUStARD++.", "published": "2024-08-05 15:36:52", "link": "http://arxiv.org/abs/2408.10246v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.CV"}
{"title": "LLM Agents Improve Semantic Code Search", "abstract": "Code Search is a key task that many programmers often have to perform while\ndeveloping solutions to problems. Current methodologies suffer from an\ninability to perform accurately on prompts that contain some ambiguity or ones\nthat require additional context relative to a code-base. We introduce the\napproach of using Retrieval Augmented Generation (RAG) powered agents to inject\ninformation into user prompts allowing for better inputs into embedding models.\nBy utilizing RAG, agents enhance user queries with relevant details from GitHub\nrepositories, making them more informative and contextually aligned.\nAdditionally, we introduce a multi-stream ensemble approach which when paired\nwith agentic workflow can obtain improved retrieval accuracy, which we deploy\non application called repo-rift.com. Experimental results on the CodeSearchNet\ndataset demonstrate that RepoRift significantly outperforms existing methods,\nachieving an 78.2% success rate at Success@10 and a 34.6% success rate at\nSuccess@1. This research presents a substantial advancement in semantic code\nsearch, highlighting the potential of agentic LLMs and RAG to enhance code\nretrieval systems.", "published": "2024-08-05 00:43:56", "link": "http://arxiv.org/abs/2408.11058v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.SE"}
{"title": "Language Model Can Listen While Speaking", "abstract": "Dialogue serves as the most natural manner of human-computer interaction\n(HCI). Recent advancements in speech language models (SLM) have significantly\nenhanced speech-based conversational AI. However, these models are limited to\nturn-based conversation, lacking the ability to interact with humans in\nreal-time spoken scenarios, for example, being interrupted when the generated\ncontent is not satisfactory. To address these limitations, we explore full\nduplex modeling (FDM) in interactive speech language models (iSLM), focusing on\nenhancing real-time interaction and, more explicitly, exploring the\nquintessential ability of interruption. We introduce a novel model design,\nnamely listening-while-speaking language model (LSLM), an end-to-end system\nequipped with both listening and speaking channels. Our LSLM employs a\ntoken-based decoder-only TTS for speech generation and a streaming\nself-supervised learning (SSL) encoder for real-time audio input. LSLM fuses\nboth channels for autoregressive generation and detects turn-taking in real\ntime. Three fusion strategies -- early fusion, middle fusion, and late fusion\n-- are explored, with middle fusion achieving an optimal balance between speech\ngeneration and real-time interaction. Two experimental settings, command-based\nFDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity\nto diverse instructions. Our results highlight LSLM's capability to achieve\nduplex communication with minimal impact on existing systems. This study aims\nto advance the development of interactive speech dialogue systems, enhancing\ntheir applicability in real-world contexts.", "published": "2024-08-05 16:47:22", "link": "http://arxiv.org/abs/2408.02622v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Large Model Strategic Thinking, Small Model Efficiency: Transferring\n  Theory of Mind in Large Language Models", "abstract": "As the performance of larger, newer Large Language Models continues to\nimprove for strategic Theory of Mind (ToM) tasks, the demand for these\nstate-of-the-art models increases commensurately. However, their deployment is\ncostly both in terms of processing power and time. In this paper, we\ninvestigate the feasibility of creating smaller, highly-performing specialized\nalgorithms by way of fine-tuning. To do this, we first present a large\npre-trained model with 20 unique scenarios that combine different social\ncontexts with games of varying social dilemmas, record its answers, and use\nthem for Q&A fine-tuning on a smaller model of the same family. Our focus is on\nin-context game-theoretic decision-making, the same domain within which human\ninteraction occurs and that requires both a theory of mind (or a semblance\nthereof) and an understanding of social dynamics. The smaller model is\ntherefore trained not just on the answers provided, but also on the motivations\nprovided by the larger model, which should contain advice and guidelines to\nnavigate both strategic dilemmas and social cues. We find that the fine-tuned\nsmaller language model consistently bridged the gap in performance between the\nsmaller pre-trained version of the model and its larger relative and that its\nimprovements extended in areas and contexts beyond the ones provided in the\ntraining examples, including on out-of-sample scenarios that include completely\ndifferent game structures. On average for all games, through fine-tuning, the\nsmaller model showed a 46% improvement measured as alignment towards the\nbehavior of the larger model, with 100% representing indistinguishable\nbehavior. When presented with out-of-sample social contexts and games, the\nfine-tuned model still displays remarkable levels of alignment, reaching an\nimprovement of 18% and 28% respectively.", "published": "2024-08-05 20:49:48", "link": "http://arxiv.org/abs/2408.05241v4", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.ET", "cs.GT"], "primary_category": "cs.CL"}
{"title": "Beyond Orthography: Automatic Recovery of Short Vowels and Dialectal\n  Sounds in Arabic", "abstract": "This paper presents a novel Dialectal Sound and Vowelization Recovery\nframework, designed to recognize borrowed and dialectal sounds within\nphonologically diverse and dialect-rich languages, that extends beyond its\nstandard orthographic sound sets. The proposed framework utilized a quantized\nsequence of input with(out) continuous pretrained self-supervised\nrepresentation. We show the efficacy of the pipeline using limited data for\nArabic, a dialect-rich language containing more than 22 major dialects.\nPhonetically correct transcribed speech resources for dialectal Arabic are\nscarce. Therefore, we introduce ArabVoice15, a first-of-its-kind, curated test\nset featuring 5 hours of dialectal speech across 15 Arab countries, with\nphonetically accurate transcriptions, including borrowed and dialect-specific\nsounds. We described in detail the annotation guideline along with the analysis\nof the dialectal confusion pairs. Our extensive evaluation includes both\nsubjective -- human perception tests and objective measures. Our empirical\nresults, reported with three test sets, show that with only one and half hours\nof training data, our model improve character error rate by ~ 7\\% in\nArabVoice15 compared to the baseline.", "published": "2024-08-05 12:38:39", "link": "http://arxiv.org/abs/2408.02430v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "StreamVoice+: Evolving into End-to-end Streaming Zero-shot Voice\n  Conversion", "abstract": "StreamVoice has recently pushed the boundaries of zero-shot voice conversion\n(VC) in the streaming domain. It uses a streamable language model (LM) with a\ncontext-aware approach to convert semantic features from automatic speech\nrecognition (ASR) into acoustic features with the desired speaker timbre.\nDespite its innovations, StreamVoice faces challenges due to its dependency on\na streaming ASR within a cascaded framework, which complicates system\ndeployment and optimization, affects VC system's design and performance based\non the choice of ASR, and struggles with conversion stability when faced with\nlow-quality semantic inputs. To overcome these limitations, we introduce\nStreamVoice+, an enhanced LM-based end-to-end streaming framework that operates\nindependently of streaming ASR. StreamVoice+ integrates a semantic encoder and\na connector with the original StreamVoice framework, now trained using a\nnon-streaming ASR. This model undergoes a two-stage training process:\ninitially, the StreamVoice backbone is pre-trained for voice conversion and the\nsemantic encoder for robust semantic extraction. Subsequently, the system is\nfine-tuned end-to-end, incorporating a LoRA matrix to activate comprehensive\nstreaming functionality. Furthermore, StreamVoice+ mainly introduces two\nstrategic enhancements to boost conversion quality: a residual compensation\nmechanism in the connector to ensure effective semantic transmission and a\nself-refinement strategy that leverages pseudo-parallel speech pairs generated\nby the conversion backbone to improve speech decoupling. Experiments\ndemonstrate that StreamVoice+ not only achieves higher naturalness and speaker\nsimilarity in voice conversion than its predecessor but also provides versatile\nsupport for both streaming and non-streaming conversion scenarios.", "published": "2024-08-05 01:32:19", "link": "http://arxiv.org/abs/2408.02178v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Steer-by-prior Editing of Symbolic Music Loops", "abstract": "With the goal of building a system capable of controllable symbolic music\nloop generation and editing, this paper explores a generalisation of Masked\nLanguage Modelling we call Superposed Language Modelling. Rather than input\ntokens being known or unknown, a Superposed Language Model takes priors over\nthe sequence as input, enabling us to apply various constraints to the\ngeneration at inference time. After detailing our approach, we demonstrate our\nmodel across various editing tasks in the domain of multi-instrument MIDI\nloops. We end by highlighting some limitations of the approach and avenues for\nfuture work. We provides examples from the SLM across multiple generation and\nediting tasks at https://erl-j.github.io/slm-mml-demo/.", "published": "2024-08-05 12:47:29", "link": "http://arxiv.org/abs/2408.02434v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Stem-JEPA: A Joint-Embedding Predictive Architecture for Musical Stem\n  Compatibility Estimation", "abstract": "This paper explores the automated process of determining stem compatibility\nby identifying audio recordings of single instruments that blend well with a\ngiven musical context. To tackle this challenge, we present Stem-JEPA, a novel\nJoint-Embedding Predictive Architecture (JEPA) trained on a multi-track dataset\nusing a self-supervised learning approach.\n  Our model comprises two networks: an encoder and a predictor, which are\njointly trained to predict the embeddings of compatible stems from the\nembeddings of a given context, typically a mix of several instruments. Training\na model in this manner allows its use in estimating stem compatibility -\nretrieving, aligning, or generating a stem to match a given mix - or for\ndownstream tasks such as genre or key estimation, as the training paradigm\nrequires the model to learn information related to timbre, harmony, and rhythm.\n  We evaluate our model's performance on a retrieval task on the MUSDB18\ndataset, testing its ability to find the missing stem from a mix and through a\nsubjective user study. We also show that the learned embeddings capture\ntemporal alignment information and, finally, evaluate the representations\nlearned by our model on several downstream tasks, highlighting that they\neffectively capture meaningful musical features.", "published": "2024-08-05 14:34:40", "link": "http://arxiv.org/abs/2408.02514v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Clustering and Mining Accented Speech for Inclusive and Fair Speech\n  Recognition", "abstract": "Modern automatic speech recognition (ASR) systems are typically trained on\nmore than tens of thousands hours of speech data, which is one of the main\nfactors for their great success. However, the distribution of such data is\ntypically biased towards common accents or typical speech patterns. As a\nresult, those systems often poorly perform on atypical accented speech. In this\npaper, we present accent clustering and mining schemes for fair speech\nrecognition systems which can perform equally well on under-represented\naccented speech. For accent recognition, we applied three schemes to overcome\nlimited size of supervised accent data: supervised or unsupervised\npre-training, distributionally robust optimization (DRO) and unsupervised\nclustering. Three schemes can significantly improve the accent recognition\nmodel especially for unbalanced and small accented speech. Fine-tuning ASR on\nthe mined Indian accent speech using the proposed supervised or unsupervised\nclustering schemes showed 10.0% and 5.3% relative improvements compared to\nfine-tuning on the randomly sampled speech, respectively.", "published": "2024-08-05 16:00:07", "link": "http://arxiv.org/abs/2408.02582v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Text Conditioned Symbolic Drumbeat Generation using Latent Diffusion\n  Models", "abstract": "This study introduces a text-conditioned approach to generating drumbeats\nwith Latent Diffusion Models (LDMs). It uses informative conditioning text\nextracted from training data filenames. By pretraining a text and drumbeat\nencoder through contrastive learning within a multimodal network, aligned\nfollowing CLIP, we align the modalities of text and music closely.\nAdditionally, we examine an alternative text encoder based on multihot text\nencodings. Inspired by musics multi-resolution nature, we propose a novel LSTM\nvariant, MultiResolutionLSTM, designed to operate at various resolutions\nindependently. In common with recent LDMs in the image space, it speeds up the\ngeneration process by running diffusion in a latent space provided by a\npretrained unconditional autoencoder. We demonstrate the originality and\nvariety of the generated drumbeats by measuring distance (both over binary\npianorolls and in the latent space) versus the training dataset and among the\ngenerated drumbeats. We also assess the generated drumbeats through a listening\ntest focused on questions of quality, aptness for the prompt text, and novelty.\nWe show that the generated drumbeats are novel and apt to the prompt text, and\ncomparable in quality to those created by human musicians.", "published": "2024-08-05 13:23:05", "link": "http://arxiv.org/abs/2408.02711v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic Voice Identification after Speech Resynthesis using PPG", "abstract": "Speech resynthesis is a generic task for which we want to synthesize audio\nwith another audio as input, which finds applications for media monitors and\njournalists.Among different tasks addressed by speech resynthesis, voice\nconversion preserves the linguistic information while modifying the identity of\nthe speaker, and speech edition preserves the identity of the speaker but some\nwords are modified.In both cases, we need to disentangle speaker and phonetic\ncontents in intermediate representations.Phonetic PosteriorGrams (PPG) are a\nframe-level probabilistic representation of phonemes, and are usually\nconsidered speaker-independent.This paper presents a PPG-based speech\nresynthesis system.A perceptive evaluation assesses that it produces correct\naudio quality.Then, we demonstrate that an automatic speaker verification model\nis not able to recover the source speaker after re-synthesis with PPG, even\nwhen the model is trained on synthetic data.", "published": "2024-08-05 13:59:40", "link": "http://arxiv.org/abs/2408.02712v1", "categories": ["cs.SD", "cs.AI", "cs.NE", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
