{"title": "English-Japanese Neural Machine Translation with\n  Encoder-Decoder-Reconstructor", "abstract": "Neural machine translation (NMT) has recently become popular in the field of\nmachine translation. However, NMT suffers from the problem of repeating or\nmissing words in the translation. To address this problem, Tu et al. (2017)\nproposed an encoder-decoder-reconstructor framework for NMT using\nback-translation. In this method, they selected the best forward translation\nmodel in the same manner as Bahdanau et al. (2015), and then trained a\nbi-directional translation model as fine-tuning. Their experiments show that it\noffers significant improvement in BLEU scores in Chinese-English translation\ntask. We confirm that our re-implementation also shows the same tendency and\nalleviates the problem of repeating and missing words in the translation on a\nEnglish-Japanese task too. In addition, we evaluate the effectiveness of\npre-training by comparing it with a jointly-trained model of forward\ntranslation and back-translation.", "published": "2017-06-26 00:55:04", "link": "http://arxiv.org/abs/1706.08198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog\n  Systems with Chatting Capability", "abstract": "Generative encoder-decoder models offer great promise in developing\ndomain-general dialog systems. However, they have mainly been applied to\nopen-domain conversations. This paper presents a practical and novel framework\nfor building task-oriented dialog systems based on encoder-decoder models. This\nframework enables encoder-decoder models to accomplish slot-value independent\ndecision-making and interact with external databases. Moreover, this paper\nshows the flexibility of the proposed method by interleaving chatting\ncapability with a slot-filling system for better out-of-domain recovery. The\nmodels were trained on both real-user data from a bus information system and\nhuman-human chat data. Results show that the proposed framework achieves good\nperformance in both offline evaluation metrics and in task success rate with\nhuman users.", "published": "2017-06-26 16:52:42", "link": "http://arxiv.org/abs/1706.08476v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Minor Fall, the Major Lift: Inferring Emotional Valence of Musical\n  Chords through Lyrics", "abstract": "We investigate the association between musical chords and lyrics by analyzing\na large dataset of user-contributed guitar tablatures. Motivated by the idea\nthat the emotional content of chords is reflected in the words used in\ncorresponding lyrics, we analyze associations between lyrics and chord\ncategories. We also examine the usage patterns of chords and lyrics in\ndifferent musical genres, historical eras, and geographical regions. Our\noverall results confirms a previously known association between Major chords\nand positive valence. We also report a wide variation in this association\nacross regions, genres, and eras. Our results suggest possible existence of\ndifferent emotional associations for other types of chords.", "published": "2017-06-26 21:34:29", "link": "http://arxiv.org/abs/1706.08609v2", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog", "abstract": "A number of recent works have proposed techniques for end-to-end learning of\ncommunication protocols among cooperative multi-agent populations, and have\nsimultaneously found the emergence of grounded human-interpretable language in\nthe protocols developed by the agents, all learned without any human\nsupervision!\n  In this paper, using a Task and Tell reference game between two agents as a\ntestbed, we present a sequence of 'negative' results culminating in a\n'positive' one -- showing that while most agent-invented languages are\neffective (i.e. achieve near-perfect task rewards), they are decidedly not\ninterpretable or compositional.\n  In essence, we find that natural language does not emerge 'naturally',\ndespite the semblance of ease of natural-language-emergence that one may gather\nfrom recent literature. We discuss how it is possible to coax the invented\nlanguages to become more and more human-like and compositional by increasing\nrestrictions on how two agents may communicate.", "published": "2017-06-26 17:47:46", "link": "http://arxiv.org/abs/1706.08502v3", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Neural Question Answering at BioASQ 5B", "abstract": "This paper describes our submission to the 2017 BioASQ challenge. We\nparticipated in Task B, Phase B which is concerned with biomedical question\nanswering (QA). We focus on factoid and list question, using an extractive QA\nmodel, that is, we restrict our system to output substrings of the provided\ntext snippets. At the core of our system, we use FastQA, a state-of-the-art\nneural QA system. We extended it with biomedical word embeddings and changed\nits answer layer to be able to answer list questions in addition to factoid\nquestions. We pre-trained the model on a large-scale open-domain QA dataset,\nSQuAD, and then fine-tuned the parameters on the BioASQ training set. With our\napproach, we achieve state-of-the-art results on factoid questions and\ncompetitive results on list questions.", "published": "2017-06-26 19:14:10", "link": "http://arxiv.org/abs/1706.08568v1", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
