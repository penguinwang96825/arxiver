{"title": "Co-Attention Hierarchical Network: Generating Coherent Long Distractors\n  for Reading Comprehension", "abstract": "In reading comprehension, generating sentence-level distractors is a\nsignificant task, which requires a deep understanding of the article and\nquestion. The traditional entity-centered methods can only generate word-level\nor phrase-level distractors. Although recently proposed neural-based methods\nlike sequence-to-sequence (Seq2Seq) model show great potential in generating\ncreative text, the previous neural methods for distractor generation ignore two\nimportant aspects. First, they didn't model the interactions between the\narticle and question, making the generated distractors tend to be too general\nor not relevant to question context. Second, they didn't emphasize the\nrelationship between the distractor and article, making the generated\ndistractors not semantically relevant to the article and thus fail to form a\nset of meaningful options. To solve the first problem, we propose a\nco-attention enhanced hierarchical architecture to better capture the\ninteractions between the article and question, thus guide the decoder to\ngenerate more coherent distractors. To alleviate the second problem, we add an\nadditional semantic similarity loss to push the generated distractors more\nrelevant to the article. Experimental results show that our model outperforms\nseveral strong baselines on automatic metrics, achieving state-of-the-art\nperformance. Further human evaluation indicates that our generated distractors\nare more coherent and more educative compared with those distractors generated\nby baselines.", "published": "2019-11-20 00:48:36", "link": "http://arxiv.org/abs/1911.08648v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Global Greedy Dependency Parsing", "abstract": "Most syntactic dependency parsing models may fall into one of two categories:\ntransition- and graph-based models. The former models enjoy high inference\nefficiency with linear time complexity, but they rely on the stacking or\nre-ranking of partially-built parse trees to build a complete parse tree and\nare stuck with slower training for the necessity of dynamic oracle training.\nThe latter, graph-based models, may boast better performance but are\nunfortunately marred by polynomial time inference. In this paper, we propose a\nnovel parsing order objective, resulting in a novel dependency parsing model\ncapable of both global (in sentence scope) feature extraction as in graph\nmodels and linear time inference as in transitional models. The proposed global\ngreedy parser only uses two arc-building actions, left and right arcs, for\nprojective parsing. When equipped with two extra non-projective arc-building\nactions, the proposed parser may also smoothly support non-projective parsing.\nUsing multiple benchmark treebanks, including the Penn Treebank (PTB), the\nCoNLL-X treebanks, and the Universal Dependency Treebanks, we evaluate our\nparser and demonstrate that the proposed novel parser achieves good performance\nwith faster training and decoding.", "published": "2019-11-20 02:57:53", "link": "http://arxiv.org/abs/1911.08673v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmpDG: Multiresolution Interactive Empathetic Dialogue Generation", "abstract": "A humanized dialogue system is expected to generate empathetic replies, which\nshould be sensitive to the users' expressed emotion. The task of empathetic\ndialogue generation is proposed to address this problem. The essential\nchallenges lie in accurately capturing the nuances of human emotion and\nconsidering the potential of user feedback, which are overlooked by the\nmajority of existing work. In response to this problem, we propose a\nmulti-resolution adversarial model -- EmpDG, to generate more empathetic\nresponses. EmpDG exploits both the coarse-grained dialogue-level and\nfine-grained token-level emotions, the latter of which helps to better capture\nthe nuances of user emotion. In addition, we introduce an interactive\nadversarial learning framework which exploits the user feedback, to identify\nwhether the generated responses evoke emotion perceptivity in dialogues.\nExperimental results show that the proposed approach significantly outperforms\nthe state-of-the-art baselines in both content quality and emotion\nperceptivity.", "published": "2019-11-20 04:25:20", "link": "http://arxiv.org/abs/1911.08698v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controlling Neural Machine Translation Formality with Synthetic\n  Supervision", "abstract": "This work aims to produce translations that convey source language content at\na formality level that is appropriate for a particular audience. Framing this\nproblem as a neural sequence-to-sequence task ideally requires training\ntriplets consisting of a bilingual sentence pair labeled with target language\nformality. However, in practice, available training examples are limited to\nEnglish sentence pairs of different styles, and bilingual parallel sentences of\nunknown formality. We introduce a novel training scheme for multi-task models\nthat automatically generates synthetic training triplets by inferring the\nmissing element on the fly, thus enabling end-to-end training. Comprehensive\nautomatic and human assessments show that our best model outperforms existing\nmodels by producing translations that better match desired formality levels\nwhile preserving the source meaning.", "published": "2019-11-20 04:54:21", "link": "http://arxiv.org/abs/1911.08706v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Emotion Label Space Modelling for Affect Lexica", "abstract": "Emotion lexica are commonly used resources to combat data poverty in\nautomatic emotion detection. However, vocabulary coverage issues, differences\nin construction method and discrepancies in emotion framework and\nrepresentation result in a heterogeneous landscape of emotion detection\nresources, calling for a unified approach to utilising them. To combat this, we\npresent an extended emotion lexicon of 30,273 unique entries, which is a result\nof merging eight existing emotion lexica by means of a multi-view variational\nautoencoder (VAE). We showed that a VAE is a valid approach for combining\nlexica with different label spaces into a joint emotion label space with a\nchosen number of dimensions, and that these dimensions are still interpretable.\nWe tested the utility of the unified VAE lexicon by employing the lexicon\nvalues as features in an emotion detection model. We found that the VAE lexicon\noutperformed individual lexica, but contrary to our expectations, it did not\noutperform a naive concatenation of lexica, although it did contribute to the\nnaive concatenation when added as an extra lexicon. Furthermore, using lexicon\ninformation as additional features on top of state-of-the-art language models\nusually resulted in a better performance than when no lexicon information was\nused.", "published": "2019-11-20 09:24:38", "link": "http://arxiv.org/abs/1911.08782v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Generation Challenges for Explainable AI", "abstract": "Good quality explanations of artificial intelligence (XAI) reasoning must be\nwritten (and evaluated) for an explanatory purpose, targeted towards their\nreaders, have a good narrative and causal structure, and highlight where\nuncertainty and data quality affect the AI output. I discuss these challenges\nfrom a Natural Language Generation (NLG) perspective, and highlight four\nspecific NLG for XAI research challenges.", "published": "2019-11-20 09:52:23", "link": "http://arxiv.org/abs/1911.08794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Casting a Wide Net: Robust Extraction of Potentially Idiomatic\n  Expressions", "abstract": "Idiomatic expressions like `out of the woods' and `up the ante' present a\nrange of difficulties for natural language processing applications. We present\nwork on the annotation and extraction of what we term potentially idiomatic\nexpressions (PIEs), a subclass of multiword expressions covering both literal\nand non-literal uses of idiomatic expressions. Existing corpora of PIEs are\nsmall and have limited coverage of different PIE types, which hampers research.\nTo further progress on the extraction and disambiguation of potentially\nidiomatic expressions, larger corpora of PIEs are required. In addition, larger\ncorpora are a potential source for valuable linguistic insights into idiomatic\nexpressions and their variability. We propose automatic tools to facilitate the\nbuilding of larger PIE corpora, by investigating the feasibility of using\ndictionary-based extraction of PIEs as a pre-extraction tool for English. We do\nthis by assessing the reliability and coverage of idiom dictionaries, the\nannotation of a PIE corpus, and the automatic extraction of PIEs from a large\ncorpus. Results show that combinations of dictionaries are a reliable source of\nidiomatic expressions, that PIEs can be annotated with a high reliability\n(0.74-0.91 Fleiss' Kappa), and that parse-based PIE extraction yields highly\naccurate performance (88% F1-score). Combining complementary PIE extraction\nmethods increases reliability further, to over 92% F1-score. Moreover, the\nextraction method presented here could be extended to other types of multiword\nexpressions and to other languages, given that sufficient NLP tools are\navailable.", "published": "2019-11-20 11:15:47", "link": "http://arxiv.org/abs/1911.08829v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Table-Of-Contents generation on contemporary documents", "abstract": "The generation of precise and detailed Table-Of-Contents (TOC) from a\ndocument is a problem of major importance for document understanding and\ninformation extraction. Despite its importance, it is still a challenging task,\nespecially for non-standardized documents with rich layout information such as\ncommercial documents. In this paper, we present a new neural-based pipeline for\nTOC generation applicable to any searchable document. Unlike previous methods,\nwe do not use semantic labeling nor assume the presence of parsable TOC pages\nin the document. Moreover, we analyze the influence of using external knowledge\nencoded as a template. We empirically show that this approach is only useful in\na very low resource environment. Finally, we propose a new domain-specific data\nset that sheds some light on the difficulties of TOC generation in real-world\ndocuments. The proposed method shows better performance than the\nstate-of-the-art on a public data set and on the newly released data set.", "published": "2019-11-20 11:29:47", "link": "http://arxiv.org/abs/1911.08836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain", "abstract": "In this paper, we introduce CAIL2019-SCM, Chinese AI and Law 2019 Similar\nCase Matching dataset. CAIL2019-SCM contains 8,964 triplets of cases published\nby the Supreme People's Court of China. CAIL2019-SCM focuses on detecting\nsimilar cases, and the participants are required to check which two cases are\nmore similar in the triplets. There are 711 teams who participated in this\nyear's competition, and the best team has reached a score of 71.88. We have\nalso implemented several baselines to help researchers better understand this\ntask. The dataset and more details can be found from\nhttps://github.com/china-ai-law-challenge/CAIL2019/tree/master/scm.", "published": "2019-11-20 15:23:59", "link": "http://arxiv.org/abs/1911.08962v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Real-Time Emotion Recognition via Attention Gated Hierarchical Memory\n  Network", "abstract": "Real-time emotion recognition (RTER) in conversations is significant for\ndeveloping emotionally intelligent chatting machines. Without the future\ncontext in RTER, it becomes critical to build the memory bank carefully for\ncapturing historical context and summarize the memories appropriately to\nretrieve relevant information. We propose an Attention Gated Hierarchical\nMemory Network (AGHMN) to address the problems of prior work: (1) Commonly used\nconvolutional neural networks (CNNs) for utterance feature extraction are less\ncompatible in the memory modules; (2) Unidirectional gated recurrent units\n(GRUs) only allow each historical utterance to have context before it,\npreventing information propagation in the opposite direction; (3) The Soft\nAttention for summarizing loses the positional and ordering information of\nmemories, regardless of how the memory bank is built. Particularly, we propose\na Hierarchical Memory Network (HMN) with a bidirectional GRU (BiGRU) as the\nutterance reader and a BiGRU fusion layer for the interaction between\nhistorical utterances. For memory summarizing, we propose an Attention GRU\n(AGRU) where we utilize the attention weights to update the internal state of\nGRU. We further promote the AGRU to a bidirectional variant (BiAGRU) to balance\nthe contextual information from recent memories and that from distant memories.\nWe conduct experiments on two emotion conversation datasets with extensive\nanalysis, demonstrating the efficacy of our AGHMN models.", "published": "2019-11-20 18:27:22", "link": "http://arxiv.org/abs/1911.09075v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Semantic Parsing for Instructions", "abstract": "We consider a zero-shot semantic parsing task: parsing instructions into\ncompositional logical forms, in domains that were not seen during training. We\npresent a new dataset with 1,390 examples from 7 application domains (e.g. a\ncalendar or a file manager), each example consisting of a triplet: (a) the\napplication's initial state, (b) an instruction, to be carried out in the\ncontext of that state, and (c) the state of the application after carrying out\nthe instruction. We introduce a new training algorithm that aims to train a\nsemantic parser on examples from a set of source domains, so that it can\neffectively parse instructions from an unknown target domain. We integrate our\nalgorithm into the floating parser of Pasupat and Liang (2015), and further\naugment the parser with features and a logical form candidate filtering logic,\nto support zero-shot adaptation. Our experiments with various zero-shot\nadaptation setups demonstrate substantial performance gains over a non-adapted\nparser.", "published": "2019-11-20 11:14:07", "link": "http://arxiv.org/abs/1911.08827v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Discovering New Intents via Constrained Deep Adaptive Clustering with\n  Cluster Refinement", "abstract": "Identifying new user intents is an essential task in the dialogue system.\nHowever, it is hard to get satisfying clustering results since the definition\nof intents is strongly guided by prior knowledge. Existing methods incorporate\nprior knowledge by intensive feature engineering, which not only leads to\noverfitting but also makes it sensitive to the number of clusters. In this\npaper, we propose constrained deep adaptive clustering with cluster refinement\n(CDAC+), an end-to-end clustering method that can naturally incorporate\npairwise constraints as prior knowledge to guide the clustering process.\nMoreover, we refine the clusters by forcing the model to learn from the high\nconfidence assignments. After eliminating low confidence assignments, our\napproach is surprisingly insensitive to the number of clusters. Experimental\nresults on the three benchmark datasets show that our method can yield\nsignificant improvements over strong baselines.", "published": "2019-11-20 13:26:43", "link": "http://arxiv.org/abs/1911.08891v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SemanticZ at SemEval-2016 Task 3: Ranking Relevant Answers in Community\n  Question Answering Using Semantic Similarity Based on Fine-tuned Word\n  Embeddings", "abstract": "We describe our system for finding good answers in a community forum, as\ndefined in SemEval-2016, Task 3 on Community Question Answering. Our approach\nrelies on several semantic similarity features based on fine-tuned word\nembeddings and topics similarities. In the main Subtask C, our primary\nsubmission was ranked third, with a MAP of 51.68 and accuracy of 69.94. In\nSubtask A, our primary submission was also third, with MAP of 77.58 and\naccuracy of 73.39.", "published": "2019-11-20 07:16:16", "link": "http://arxiv.org/abs/1911.08743v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Global Thread-Level Inference for Comment Classification in Community\n  Question Answering", "abstract": "Community question answering, a recent evolution of question answering in the\nWeb context, allows a user to quickly consult the opinion of a number of people\non a particular topic, thus taking advantage of the wisdom of the crowd. Here\nwe try to help the user by deciding automatically which answers are good and\nwhich are bad for a given question. In particular, we focus on exploiting the\noutput structure at the thread level in order to make more consistent global\ndecisions. More specifically, we exploit the relations between pairs of\ncomments at any distance in the thread, which we incorporate in a graph-cut and\nin an ILP frameworks. We evaluated our approach on the benchmark dataset of\nSemEval-2015 Task 3. Results improved over the state of the art, confirming the\nimportance of using thread level information.", "published": "2019-11-20 08:09:36", "link": "http://arxiv.org/abs/1911.08755v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LO", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Paraphrasing Verbs for Noun Compound Interpretation", "abstract": "An important challenge for the automatic analysis of English written text is\nthe abundance of noun compounds: sequences of nouns acting as a single noun. In\nour view, their semantics is best characterized by the set of all possible\nparaphrasing verbs, with associated weights, e.g., malaria mosquito is carry\n(23), spread (16), cause (12), transmit (9), etc. Using Amazon's Mechanical\nTurk, we collect paraphrasing verbs for 250 noun-noun compounds previously\nproposed in the linguistic literature, thus creating a valuable resource for\nnoun compound interpretation. Using these verbs, we further construct a dataset\nof pairs of sentences representing a special kind of textual entailment task,\nwhere a binary decision is to be made about whether an expression involving a\nverb and two nouns can be transformed into a noun compound, while preserving\nthe sentence meaning.", "published": "2019-11-20 08:29:10", "link": "http://arxiv.org/abs/1911.08762v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Joint Embedding Learning of Educational Knowledge Graphs", "abstract": "As an efficient model for knowledge organization, the knowledge graph has\nbeen widely adopted in several fields, e.g., biomedicine, sociology, and\neducation. And there is a steady trend of learning embedding representations of\nknowledge graphs to facilitate knowledge graph construction and downstream\ntasks. In general, knowledge graph embedding techniques aim to learn vectorized\nrepresentations which preserve the structural information of the graph. And\nconventional embedding learning models rely on structural relationships among\nentities and relations. However, in educational knowledge graphs, structural\nrelationships are not the focus. Instead, rich literals of the graphs are more\nvaluable. In this paper, we focus on this problem and propose a novel model for\nembedding learning of educational knowledge graphs. Our model considers both\nstructural and literal information and jointly learns embedding\nrepresentations. Three experimental graphs were constructed based on an\neducational knowledge graph which has been applied in real-world teaching. We\nconducted two experiments on the three graphs and other common benchmark\ngraphs. The experimental results proved the effectiveness of our model and its\nsuperiority over other baselines when processing educational knowledge graphs.", "published": "2019-11-20 09:05:11", "link": "http://arxiv.org/abs/1911.08776v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Characterizing Scalability of Sparse Matrix-Vector Multiplications on\n  Phytium FT-2000+ Many-cores", "abstract": "Understanding the scalability of parallel programs is crucial for software\noptimization and hardware architecture design. As HPC hardware is moving\ntowards many-core design, it becomes increasingly difficult for a parallel\nprogram to make effective use of all available processor cores. This makes\nscalability analysis increasingly important. This paper presents a quantitative\nstudy for characterizing the scalability of sparse matrix-vector\nmultiplications (SpMV) on Phytium FT-2000+, an ARM-based many-core architecture\nfor HPC computing. We choose to study SpMV as it is a common operation in\nscientific and HPC applications. Due to the newness of ARM-based many-core\narchitectures, there is little work on understanding the SpMV scalability on\nsuch hardware design. To close the gap, we carry out a large-scale empirical\nevaluation involved over 1,000 representative SpMV datasets. We show that,\nwhile many computation-intensive SpMV applications contain extensive\nparallelism, achieving a linear speedup is non-trivial on Phytium FT-2000+. To\nbetter understand what software and hardware parameters are most important for\ndetermining the scalability of a given SpMV kernel, we develop a performance\nanalytical model based on the regression tree. We show that our model is highly\neffective in characterizing SpMV scalability, offering useful insights to help\napplication developers for better optimizing SpMV on an emerging HPC\narchitecture.", "published": "2019-11-20 09:12:58", "link": "http://arxiv.org/abs/1911.08779v1", "categories": ["cs.DC", "cs.CL", "cs.PF"], "primary_category": "cs.DC"}
{"title": "A Comparative Study on End-to-end Speech to Text Translation", "abstract": "Recent advances in deep learning show that end-to-end speech to text\ntranslation model is a promising approach to direct the speech translation\nfield. In this work, we provide an overview of different end-to-end\narchitectures, as well as the usage of an auxiliary connectionist temporal\nclassification (CTC) loss for better convergence. We also investigate on\npre-training variants such as initializing different components of a model\nusing pre-trained models, and their impact on the final performance, which\ngives boosts up to 4% in BLEU and 5% in TER. Our experiments are performed on\n270h IWSLT TED-talks En->De, and 100h LibriSpeech Audiobooks En->Fr. We also\nshow improvements over the current end-to-end state-of-the-art systems on both\ntasks.", "published": "2019-11-20 13:01:56", "link": "http://arxiv.org/abs/1911.08870v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "On Using SpecAugment for End-to-End Speech Translation", "abstract": "This work investigates a simple data augmentation technique, SpecAugment, for\nend-to-end speech translation. SpecAugment is a low-cost implementation method\napplied directly to the audio input features and it consists of masking blocks\nof frequency channels, and/or time steps. We apply SpecAugment on end-to-end\nspeech translation tasks and achieve up to +2.2\\% \\BLEU on LibriSpeech\nAudiobooks En->Fr and +1.2% on IWSLT TED-talks En->De by alleviating\noverfitting to some extent. We also examine the effectiveness of the method in\na variety of data scenarios and show that the method also leads to significant\nimprovements in various data conditions irrespective of the amount of training\ndata.", "published": "2019-11-20 13:11:41", "link": "http://arxiv.org/abs/1911.08876v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "On using 2D sequence-to-sequence models for speech recognition", "abstract": "Attention-based sequence-to-sequence models have shown promising results in\nautomatic speech recognition. Using these architectures, one-dimensional input\nand output sequences are related by an attention approach, thereby replacing\nmore explicit alignment processes, like in classical HMM-based modeling. In\ncontrast, here we apply a novel two-dimensional long short-term memory (2DLSTM)\narchitecture to directly model the input/output relation between audio/feature\nvector sequences and word sequences. The proposed model is an alternative model\nsuch that instead of using any type of attention components, we apply a 2DLSTM\nlayer to assimilate the context from both input observations and output\ntranscriptions. The experimental evaluation on the Switchboard 300h automatic\nspeech recognition task shows word error rates for the 2DLSTM model that are\ncompetitive to end-to-end attention-based model.", "published": "2019-11-20 13:25:06", "link": "http://arxiv.org/abs/1911.08888v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Demystifying TasNet: A Dissecting Approach", "abstract": "In recent years time domain speech separation has excelled over frequency\ndomain separation in single channel scenarios and noise-free environments. In\nthis paper we dissect the gains of the time-domain audio separation network\n(TasNet) approach by gradually replacing components of an utterance-level\npermutation invariant training (u-PIT) based separation system in the frequency\ndomain until the TasNet system is reached, thus blending components of\nfrequency domain approaches with those of time domain approaches. Some of the\nintermediate variants achieve comparable signal-to-distortion ratio (SDR) gains\nto TasNet, but retain the advantage of frequency domain processing:\ncompatibility with classic signal processing tools such as frequency-domain\nbeamforming and the human interpretability of the masks. Furthermore, we show\nthat the scale invariant signal-to-distortion ratio (si-SDR) criterion used as\nloss function in TasNet is related to a logarithmic mean square error criterion\nand that it is this criterion which contributes most reliable to the\nperformance advantage of TasNet. Finally, we critically assess which gains in a\nnoise-free single channel environment generalize to more realistic reverberant\nconditions.", "published": "2019-11-20 13:28:34", "link": "http://arxiv.org/abs/1911.08895v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Rule-Guided Compositional Representation Learning on Knowledge Graphs", "abstract": "Representation learning on a knowledge graph (KG) is to embed entities and\nrelations of a KG into low-dimensional continuous vector spaces. Early KG\nembedding methods only pay attention to structured information encoded in\ntriples, which would cause limited performance due to the structure sparseness\nof KGs. Some recent attempts consider paths information to expand the structure\nof KGs but lack explainability in the process of obtaining the path\nrepresentations. In this paper, we propose a novel Rule and Path-based Joint\nEmbedding (RPJE) scheme, which takes full advantage of the explainability and\naccuracy of logic rules, the generalization of KG embedding as well as the\nsupplementary semantic structure of paths. Specifically, logic rules of\ndifferent lengths (the number of relations in rule body) in the form of Horn\nclauses are first mined from the KG and elaborately encoded for representation\nlearning. Then, the rules of length 2 are applied to compose paths accurately\nwhile the rules of length 1 are explicitly employed to create semantic\nassociations among relations and constrain relation embeddings. Besides, the\nconfidence level of each rule is also considered in optimization to guarantee\nthe availability of applying the rule to representation learning. Extensive\nexperimental results illustrate that RPJE outperforms other state-of-the-art\nbaselines on KG completion task, which also demonstrate the superiority of\nutilizing logic rules as well as paths for improving the accuracy and\nexplainability of representation learning.", "published": "2019-11-20 14:38:58", "link": "http://arxiv.org/abs/1911.08935v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood\n  Aggregation", "abstract": "Graph neural networks (GNNs) have emerged as a powerful paradigm for\nembedding-based entity alignment due to their capability of identifying\nisomorphic subgraphs. However, in real knowledge graphs (KGs), the counterpart\nentities usually have non-isomorphic neighborhood structures, which easily\ncauses GNNs to yield different representations for them. To tackle this\nproblem, we propose a new KG alignment network, namely AliNet, aiming at\nmitigating the non-isomorphism of neighborhood structures in an end-to-end\nmanner. As the direct neighbors of counterpart entities are usually dissimilar\ndue to the schema heterogeneity, AliNet introduces distant neighbors to expand\nthe overlap between their neighborhood structures. It employs an attention\nmechanism to highlight helpful distant neighbors and reduce noises. Then, it\ncontrols the aggregation of both direct and distant neighborhood information\nusing a gating mechanism. We further propose a relation loss to refine entity\nrepresentations. We perform thorough experiments with detailed ablation studies\nand analyses on five entity alignment datasets, demonstrating the effectiveness\nof AliNet.", "published": "2019-11-20 14:40:23", "link": "http://arxiv.org/abs/1911.08936v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Red Dragon AI at TextGraphs 2019 Shared Task: Language Model Assisted\n  Explanation Generation", "abstract": "The TextGraphs-13 Shared Task on Explanation Regeneration asked participants\nto develop methods to reconstruct gold explanations for elementary science\nquestions. Red Dragon AI's entries used the language of the questions and\nexplanation text directly, rather than a constructing a separate graph-like\nrepresentation. Our leaderboard submission placed us 3rd in the competition,\nbut we present here three methods of increasing sophistication, each of which\nscored successively higher on the test set after the competition close.", "published": "2019-11-20 15:41:47", "link": "http://arxiv.org/abs/1911.08976v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Generating Interactive Worlds with Text", "abstract": "Procedurally generating cohesive and interesting game environments is\nchallenging and time-consuming. In order for the relationships between the game\nelements to be natural, common-sense has to be encoded into arrangement of the\nelements. In this work, we investigate a machine learning approach for world\ncreation using content from the multi-player text adventure game environment\nLIGHT. We introduce neural network based models to compositionally arrange\nlocations, characters, and objects into a coherent whole. In addition to\ncreating worlds based on existing elements, our models can generate new game\ncontent. Humans can also leverage our models to interactively aid in\nworldbuilding. We show that the game environments created with our approach are\ncohesive, diverse, and preferred by human evaluators compared to other machine\nlearning based world construction algorithms.", "published": "2019-11-20 22:20:52", "link": "http://arxiv.org/abs/1911.09194v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Perceptual Loss Function for Neural Modelling of Audio Systems", "abstract": "This work investigates alternate pre-emphasis filters used as part of the\nloss function during neural network training for nonlinear audio processing. In\nour previous work, the error-to-signal ratio loss function was used during\nnetwork training, with a first-order highpass pre-emphasis filter applied to\nboth the target signal and neural network output. This work considers more\nperceptually relevant pre-emphasis filters, which include lowpass filtering at\nhigh frequencies. We conducted listening tests to determine whether they offer\nan improvement to the quality of a neural network model of a guitar tube\namplifier. Listening test results indicate that the use of an A-weighting\npre-emphasis filter offers the best improvement among the tested filters. The\nproposed perceptual loss function improves the sound quality of neural network\nmodels in audio processing without affecting the computational cost.", "published": "2019-11-20 14:08:53", "link": "http://arxiv.org/abs/1911.08922v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Moving to Communicate, Moving to Interact: Patterns of Body Motion in\n  Musical Duo Performance", "abstract": "Skilled ensemble musicians coordinate with high precision, even when\nimprovising or interpreting loosely-defined notation. Successful coordination\nis supported primarily through shared attention to the musical output; however,\nmusicians also interact visually, particularly when the musical timing is\nirregular. This study investigated the performance conditions that encourage\nvisual signalling and interaction between ensemble members. Piano and clarinet\nduos rehearsed a new piece as their body motion was recorded. Analyses of head\nmovement showed that performers communicated gesturally following held notes.\nGesture patterns became more consistent as duos rehearsed, though consistency\ndropped again during a final performance given under no-visual-contact\nconditions. Movements were smoother and interperformer coordination was\nstronger during irregularly-timed passages than elsewhere in the piece,\nsuggesting heightened visual interaction. Performers moved more after\nrehearsing than before, and more when they could see each other than when\nvisual contact was occluded. Periods of temporal instability and increased\nfamiliarity with the music and co-performer seem to encourage visual\ninteraction, while specific communicative gestures are integrated into\nperformance routines through rehearsal. We propose that visual interaction may\nsupport successful ensemble performance by affirming coordination throughout\nperiods of temporal instability and serving as a social motivator to promote\ncreative risk-taking.", "published": "2019-11-20 16:46:23", "link": "http://arxiv.org/abs/1911.09018v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CAT: CRF-based ASR Toolkit", "abstract": "In this paper, we present a new open source toolkit for automatic speech\nrecognition (ASR), named CAT (CRF-based ASR Toolkit). A key feature of CAT is\ndiscriminative training in the framework of conditional random field (CRF),\nparticularly with connectionist temporal classification (CTC) inspired state\ntopology. CAT contains a full-fledged implementation of CTC-CRF and provides a\ncomplete workflow for CRF-based end-to-end speech recognition. Evaluation\nresults on Chinese and English benchmarks such as Switchboard and Aishell show\nthat CAT obtains the state-of-the-art results among existing end-to-end models\nwith less parameters, and is competitive compared with the hybrid DNN-HMM\nmodels. Towards flexibility, we show that i-vector based speaker-adapted\nrecognition and latency control mechanism can be explored easily and\neffectively in CAT. We hope CAT, especially the CRF-based framework and\nsoftware, will be of broad interest to the community, and can be further\nexplored and improved.", "published": "2019-11-20 07:33:21", "link": "http://arxiv.org/abs/1911.08747v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Joint NN-Supported Multichannel Reduction of Acoustic Echo,\n  Reverberation and Noise", "abstract": "We consider the problem of simultaneous reduction of acoustic echo,\nreverberation and noise. In real scenarios, these distortion sources may occur\nsimultaneously and reducing them implies combining the corresponding\ndistortion-specific filters. As these filters interact with each other, they\nmust be jointly optimized. We propose to model the target and residual signals\nafter linear echo cancellation and dereverberation using a multichannel\nGaussian modeling framework and to jointly represent their spectra by means of\na neural network. We develop an iterative block-coordinate ascent algorithm to\nupdate all the filters. We evaluate our system on real recordings of acoustic\necho, reverberation and noise acquired with a smart speaker in various\nsituations. The proposed approach outperforms in terms of overall distortion a\ncascade of the individual approaches and a joint reduction approach which does\nnot rely on a spectral model of the target and residual signals.", "published": "2019-11-20 14:37:36", "link": "http://arxiv.org/abs/1911.08934v4", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
