{"title": "Restructuring Conversations using Discourse Relations for Zero-shot\n  Abstractive Dialogue Summarization", "abstract": "Dialogue summarization is a challenging problem due to the informal and\nunstructured nature of conversational data. Recent advances in abstractive\nsummarization have been focused on data-hungry neural models and adapting these\nmodels to a new domain requires the availability of domain-specific manually\nannotated corpus created by linguistic experts. We propose a zero-shot\nabstractive dialogue summarization method that uses discourse relations to\nprovide structure to conversations, and then uses an out-of-the-box document\nsummarization model to create final summaries. Experiments on the AMI and ICSI\nmeeting corpus, with document summarization models like PGN and BART, shows\nthat our method improves the ROGUE score by up to 3 points, and even performs\ncompetitively against other state-of-the-art methods.", "published": "2019-02-05 09:50:47", "link": "http://arxiv.org/abs/1902.01615v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Choice of Modeling Unit for Sequence-to-Sequence Speech\n  Recognition", "abstract": "In conventional speech recognition, phoneme-based models outperform\ngrapheme-based models for non-phonetic languages such as English. The\nperformance gap between the two typically reduces as the amount of training\ndata is increased. In this work, we examine the impact of the choice of\nmodeling unit for attention-based encoder-decoder models. We conduct\nexperiments on the LibriSpeech 100hr, 460hr, and 960hr tasks, using various\ntarget units (phoneme, grapheme, and word-piece); across all tasks, we find\nthat grapheme or word-piece models consistently outperform phoneme-based\nmodels, even though they are evaluated without a lexicon or an external\nlanguage model. We also investigate model complementarity: we find that we can\nimprove WERs by up to 9% relative by rescoring N-best lists generated from a\nstrong word-piece based baseline with either the phoneme or the grapheme model.\nRescoring an N-best list generated by the phonemic system, however, provides\nlimited improvements. Further analysis shows that the word-piece-based models\nproduce more diverse N-best hypotheses, and thus lower oracle WERs, than\nphonemic models.", "published": "2019-02-05 22:16:15", "link": "http://arxiv.org/abs/1902.01955v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Ensemble Dialogue System for Facts-Based Sentence Generation", "abstract": "This study aims to generate responses based on real-world facts by\nconditioning context and external facts extracted from information websites.\nOur system is an ensemble system that combines three modules: generated-based\nmodule, retrieval-based module, and reranking module. Therefore, this system\ncan return diverse and meaningful responses from various perspectives. The\nexperiments and evaluations are conducted with the sentence generation task in\nDialog System Technology Challenges 7 (DSTC7-Task2). As a result, the proposed\nsystem performed significantly better than sole modules, and worked fine at the\nDSTC7-Task2, specifically on the objective evaluation.", "published": "2019-02-05 03:25:24", "link": "http://arxiv.org/abs/1902.01529v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Referential Reader: A Recurrent Entity Network for Anaphora\n  Resolution", "abstract": "We present a new architecture for storing and accessing entity mentions\nduring online text processing. While reading the text, entity references are\nidentified, and may be stored by either updating or overwriting a cell in a\nfixed-length memory. The update operation implies coreference with the other\nmentions that are stored in the same cell; the overwrite operation causes these\nmentions to be forgotten. By encoding the memory operations as differentiable\ngates, it is possible to train the model end-to-end, using both a supervised\nanaphora resolution objective as well as a supplementary language modeling\nobjective. Evaluation on a dataset of pronoun-name anaphora demonstrates strong\nperformance with purely incremental text processing.", "published": "2019-02-05 04:41:55", "link": "http://arxiv.org/abs/1902.01541v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "End-to-End Open-Domain Question Answering with BERTserini", "abstract": "We demonstrate an end-to-end question answering system that integrates BERT\nwith the open-source Anserini information retrieval toolkit. In contrast to\nmost question answering and reading comprehension models today, which operate\nover small amounts of input text, our system integrates best practices from IR\nwith a BERT-based reader to identify answers from a large corpus of Wikipedia\narticles in an end-to-end fashion. We report large improvements over previous\nresults on a standard benchmark test collection, showing that fine-tuning\npretrained BERT with SQuAD is sufficient to achieve high accuracy in\nidentifying answer spans.", "published": "2019-02-05 14:50:48", "link": "http://arxiv.org/abs/1902.01718v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CMS Sematrix: A Tool to Aid the Development of Clinical Quality Measures\n  (CQMs)", "abstract": "As part of the effort to improve quality and to reduce national healthcare\ncosts, the Centers for Medicare and Medicaid Services (CMS) are responsible for\ncreating and maintaining an array of clinical quality measures (CQMs) for\nassessing healthcare structure, process, outcome, and patient experience across\nvarious conditions, clinical specialties, and settings. The development and\nmaintenance of CQMs involves substantial and ongoing evaluation of the evidence\non the measure's properties: importance, reliability, validity, feasibility,\nand usability. As such, CMS conducts monthly environmental scans of the\npublished clinical and health service literature. Conducting time consuming,\nexhaustive evaluations of the ever-changing healthcare literature presents one\nof the largest challenges to an evidence-based approach to healthcare quality\nimprovement. Thus, it is imperative to leverage automated techniques to aid CMS\nin the identification of clinical and health services literature relevant to\nCQMs. Additionally, the estimated labor hours and related cost savings of using\nCMS Sematrix compared to a traditional literature review are roughly 818 hours\nand 122,000 dollars for a single monthly environmental scan.", "published": "2019-02-05 21:26:57", "link": "http://arxiv.org/abs/1902.01918v1", "categories": ["stat.OT", "cs.CL"], "primary_category": "stat.OT"}
{"title": "Training on Synthetic Noise Improves Robustness to Natural Noise in\n  Machine Translation", "abstract": "We consider the problem of making machine translation more robust to\ncharacter-level variation at the source side, such as typos. Existing methods\nachieve greater coverage by applying subword models such as byte-pair encoding\n(BPE) and character-level encoders, but these methods are highly sensitive to\nspelling mistakes. We show how training on a mild amount of random synthetic\nnoise can dramatically improve robustness to these variations, without\ndiminishing performance on clean text. We focus on translation performance on\nnatural noise, as captured by frequent corrections in Wikipedia edit logs, and\nshow that robustness to such noise can be achieved using a balanced diet of\nsimple synthetic noises at training time, without access to the natural noise\ndata or distribution.", "published": "2019-02-05 01:17:07", "link": "http://arxiv.org/abs/1902.01509v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Non-Monotonic Sequential Text Generation", "abstract": "Standard sequential generation methods assume a pre-specified generation\norder, such as text generation methods which generate words from left to right.\nIn this work, we propose a framework for training models of text generation\nthat operate in non-monotonic orders; the model directly learns good orders,\nwithout any additional annotation. Our framework operates by generating a word\nat an arbitrary position, and then recursively generating words to its left and\nthen words to its right, yielding a binary tree. Learning is framed as\nimitation learning, including a coaching method which moves from imitating an\noracle to reinforcing the policy's own preferences. Experimental results\ndemonstrate that using the proposed method, it is possible to learn policies\nwhich generate text without pre-specifying a generation order, while achieving\ncompetitive performance with conventional left-to-right generation.", "published": "2019-02-05 14:02:45", "link": "http://arxiv.org/abs/1902.02192v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "An Ensemble SVM-based Approach for Voice Activity Detection", "abstract": "Voice activity detection (VAD), used as the front end of speech enhancement,\nspeech and speaker recognition algorithms, determines the overall accuracy and\nefficiency of the algorithms. Therefore, a VAD with low complexity and high\naccuracy is highly desirable for speech processing applications. In this paper,\nwe propose a novel training method on large dataset for supervised\nlearning-based VAD system using support vector machine (SVM). Despite of high\nclassification accuracy of support vector machines (SVM), trivial SVM is not\nsuitable for classification of large data sets needed for a good VAD system\nbecause of high training complexity. To overcome this problem, a novel\nensemble-based approach using SVM has been proposed in this paper.The\nperformance of the proposed ensemble structure has been compared with a\nfeedforward neural network (NN). Although NN performs better than single\nSVM-based VAD trained on a small portion of the training data, ensemble SVM\ngives accuracy comparable to neural network-based VAD. Ensemble SVM and NN give\n88.74% and 86.28% accuracy respectively whereas the stand-alone SVM shows\n57.05% accuracy on average on the test dataset.", "published": "2019-02-05 04:48:17", "link": "http://arxiv.org/abs/1902.01544v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "A variance modeling framework based on variational autoencoders for\n  speech enhancement", "abstract": "In this paper we address the problem of enhancing speech signals in noisy\nmixtures using a source separation approach. We explore the use of neural\nnetworks as an alternative to a popular speech variance model based on\nsupervised non-negative matrix factorization (NMF). More precisely, we use a\nvariational autoencoder as a speaker-independent supervised generative speech\nmodel, highlighting the conceptual similarities that this approach shares with\nits NMF-based counterpart. In order to be free of generalization issues\nregarding the noisy recording environments, we follow the approach of having a\nsupervised model only for the target speech signal, the noise model being based\non unsupervised NMF. We develop a Monte Carlo expectation-maximization\nalgorithm for inferring the latent variables in the variational autoencoder and\nestimating the unsupervised model parameters. Experiments show that the\nproposed method outperforms a semi-supervised NMF baseline and a\nstate-of-the-art fully supervised deep learning approach.", "published": "2019-02-05 09:36:18", "link": "http://arxiv.org/abs/1902.01605v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Polyphonic Music Composition with LSTM Neural Networks and Reinforcement\n  Learning", "abstract": "In the domain of algorithmic music composition, machine learning-driven\nsystems eliminate the need for carefully hand-crafting rules for composition.\nIn particular, the capability of recurrent neural networks to learn complex\ntemporal patterns lends itself well to the musical domain. Promising results\nhave been observed across a number of recent attempts at music composition\nusing deep RNNs. These approaches generally aim at first training neural\nnetworks to reproduce subsequences drawn from existing songs. Subsequently,\nthey are used to compose music either at the audio sample-level or at the\nnote-level. We designed a representation that divides polyphonic music into a\nsmall number of monophonic streams. This representation greatly reduces the\ncomplexity of the problem and eliminates an exponential number of probably poor\ncompositions. On top of our LSTM neural network that learnt musical sequences\nin this representation, we built an RL agent that learnt to find combinations\nof songs whose joint dominance produced pleasant compositions. We present\nAmadeus, an algorithmic music composition system that composes music that\nconsists of intricate melodies, basic chords, and even occasional contrapuntal\nsequences.", "published": "2019-02-05 23:22:05", "link": "http://arxiv.org/abs/1902.01973v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
