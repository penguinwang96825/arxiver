{"title": "AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models", "abstract": "The reasoning-capable large language models (LLMs) demonstrate strong\nperformance on complex reasoning tasks but often suffer from overthinking,\ngenerating unnecessarily long chain-of-thought (CoT) reasoning paths for easy\nreasoning questions, thereby increasing inference cost and latency. Recent\napproaches attempt to address this challenge by manually deciding when to apply\nlong or short reasoning. However, they lack the flexibility to adapt CoT length\ndynamically based on question complexity. In this paper, we propose Auto\nLong-Short Reasoning (AutoL2S), a dynamic and model-agnostic framework that\nenables LLMs to dynamically compress their generated reasoning path based on\nthe complexity of the reasoning question. AutoL2S enables a learned paradigm,\nin which LLMs themselves can decide when longer reasoning is necessary and when\nshorter reasoning suffices, by training on data annotated with our proposed\nmethod, which includes both long and short CoT paths and a special <EASY>\ntoken. We then use <EASY> token to indicate when the model can skip generating\nlengthy CoT reasoning. This proposed annotation strategy can enhance the LLMs'\nability to generate shorter CoT reasoning paths with improved quality after\ntraining. Extensive evaluation results show that AutoL2S reduces the length of\nreasoning generation by up to 57% without compromising performance,\ndemonstrating the effectiveness of AutoL2S for scalable and efficient LLM\nreasoning.", "published": "2025-05-28 17:59:53", "link": "http://arxiv.org/abs/2505.22662v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning", "abstract": "The evaluation of large language models (LLMs) has traditionally relied on\nstatic benchmarks, a paradigm that poses two major limitations: (1) predefined\ntest sets lack adaptability to diverse application domains, and (2)\nstandardized evaluation protocols often fail to capture fine-grained\nassessments of domain-specific knowledge and contextual reasoning abilities. To\novercome these challenges, we propose GuessArena, an adaptive evaluation\nframework grounded in adversarial game-based interactions. Inspired by the\ninteractive structure of the Guess Who I Am? game, our framework seamlessly\nintegrates dynamic domain knowledge modeling with progressive reasoning\nassessment to improve evaluation fidelity. Empirical studies across five\nvertical domains-finance, healthcare, manufacturing, information technology,\nand education-demonstrate that GuessArena effectively distinguishes LLMs in\nterms of domain knowledge coverage and reasoning chain completeness. Compared\nto conventional benchmarks, our method provides substantial advantages in\ninterpretability, scalability, and scenario adaptability.", "published": "2025-05-28 17:59:43", "link": "http://arxiv.org/abs/2505.22661v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model", "abstract": "Humans excel at performing complex tasks by leveraging long-term memory\nacross temporal and spatial experiences. In contrast, current Large Language\nModels (LLMs) struggle to effectively plan and act in dynamic, multi-room 3D\nenvironments. We posit that part of this limitation is due to the lack of\nproper 3D spatial-temporal memory modeling in LLMs. To address this, we first\nintroduce 3DMem-Bench, a comprehensive benchmark comprising over 26,000\ntrajectories and 2,892 embodied tasks, question-answering and captioning,\ndesigned to evaluate an agent's ability to reason over long-term memory in 3D\nenvironments. Second, we propose 3DLLM-Mem, a novel dynamic memory management\nand fusion model for embodied spatial-temporal reasoning and actions in LLMs.\nOur model uses working memory tokens, which represents current observations, as\nqueries to selectively attend to and fuse the most useful spatial and temporal\nfeatures from episodic memory, which stores past observations and interactions.\nOur approach allows the agent to focus on task-relevant information while\nmaintaining memory efficiency in complex, long-horizon environments.\nExperimental results demonstrate that 3DLLM-Mem achieves state-of-the-art\nperformance across various tasks, outperforming the strongest baselines by\n16.5% in success rate on 3DMem-Bench's most challenging in-the-wild embodied\ntasks.", "published": "2025-05-28 17:59:13", "link": "http://arxiv.org/abs/2505.22657v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents", "abstract": "Large-language models (LLMs) and chatbot agents are known to provide wrong\noutputs at times, and it was recently found that this can never be fully\nprevented. Hence, uncertainty quantification plays a crucial role, aiming to\nquantify the level of ambiguity in either one overall number or two numbers for\naleatoric and epistemic uncertainty. This position paper argues that this\ntraditional dichotomy of uncertainties is too limited for the open and\ninteractive setup that LLM agents operate in when communicating with a user,\nand that we need to research avenues that enrich uncertainties in this novel\nscenario. We review the literature and find that popular definitions of\naleatoric and epistemic uncertainties directly contradict each other and lose\ntheir meaning in interactive LLM agent settings. Hence, we propose three novel\nresearch directions that focus on uncertainties in such human-computer\ninteractions: Underspecification uncertainties, for when users do not provide\nall information or define the exact task at the first go, interactive learning,\nto ask follow-up questions and reduce the uncertainty about the current\ncontext, and output uncertainties, to utilize the rich language and speech\nspace to express uncertainties as more than mere numbers. We expect that these\nnew ways of dealing with and communicating uncertainties will lead to LLM agent\ninteractions that are more transparent, trustworthy, and intuitive.", "published": "2025-05-28 17:59:08", "link": "http://arxiv.org/abs/2505.22655v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in Learning to Reason", "abstract": "Recent studies on post-training large language models (LLMs) for reasoning\nthrough reinforcement learning (RL) typically focus on tasks that can be\naccurately verified and rewarded, such as solving math problems. In contrast,\nour research investigates the impact of reward noise, a more practical\nconsideration for real-world scenarios involving the post-training of LLMs\nusing reward models. We found that LLMs demonstrate strong robustness to\nsubstantial reward noise. For example, manually flipping 40% of the reward\nfunction's outputs in math tasks still allows a Qwen-2.5-7B model to achieve\nrapid convergence, improving its performance on math tasks from 5% to 72%,\ncompared to the 75% accuracy achieved by a model trained with noiseless\nrewards. Surprisingly, by only rewarding the appearance of key reasoning\nphrases (namely reasoning pattern reward, RPR), such as ``first, I need\nto''-without verifying the correctness of answers, the model achieved peak\ndownstream performance (over 70% accuracy for Qwen-2.5-7B) comparable to models\ntrained with strict correctness verification and accurate rewards. Recognizing\nthe importance of the reasoning process over the final results, we combined RPR\nwith noisy reward models. RPR helped calibrate the noisy reward models,\nmitigating potential false negatives and enhancing the LLM's performance on\nopen-ended tasks. These findings suggest the importance of improving models'\nfoundational abilities during the pre-training phase while providing insights\nfor advancing post-training techniques. Our code and scripts are available at\nhttps://github.com/trestad/Noisy-Rewards-in-Learning-to-Reason.", "published": "2025-05-28 17:59:03", "link": "http://arxiv.org/abs/2505.22653v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sherlock: Self-Correcting Reasoning in Vision-Language Models", "abstract": "Reasoning Vision-Language Models (VLMs) have shown promising performance on\ncomplex multimodal tasks. However, they still face significant challenges: they\nare highly sensitive to reasoning errors, require large volumes of annotated\ndata or accurate verifiers, and struggle to generalize beyond specific domains.\nTo address these limitations, we explore self-correction as a strategy to\nenhance reasoning VLMs. We first conduct an in-depth analysis of reasoning\nVLMs' self-correction abilities and identify key gaps. Based on our findings,\nwe introduce Sherlock, a self-correction and self-improvement training\nframework. Sherlock introduces a trajectory-level self-correction objective, a\npreference data construction method based on visual perturbation, and a dynamic\n$\\beta$ for preference tuning. Once the model acquires self-correction\ncapabilities using only 20k randomly sampled annotated data, it continues to\nself-improve without external supervision. Built on the Llama3.2-Vision-11B\nmodel, Sherlock achieves remarkable results across eight benchmarks, reaching\nan average accuracy of 64.1 with direct generation and 65.4 after\nself-correction. It outperforms LLaVA-CoT (63.2), Mulberry (63.9), and\nLlamaV-o1 (63.4) while using less than 20% of the annotated data.", "published": "2025-05-28 17:58:03", "link": "http://arxiv.org/abs/2505.22651v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "WebDancer: Towards Autonomous Information Seeking Agency", "abstract": "Addressing intricate real-world problems necessitates in-depth information\nseeking and multi-step reasoning. Recent progress in agentic systems,\nexemplified by Deep Research, underscores the potential for autonomous\nmulti-step research. In this work, we present a cohesive paradigm for building\nend-to-end agentic information seeking agents from a data-centric and\ntraining-stage perspective. Our approach consists of four key stages: (1)\nbrowsing data construction, (2) trajectories sampling, (3) supervised\nfine-tuning for effective cold start, and (4) reinforcement learning for\nenhanced generalisation. We instantiate this framework in a web agent based on\nthe ReAct, WebDancer. Empirical evaluations on the challenging information\nseeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of\nWebDancer, achieving considerable results and highlighting the efficacy of our\ntraining paradigm. Further analysis of agent training provides valuable\ninsights and actionable, systematic pathways for developing more capable\nagentic models. The codes and demo will be released in\nhttps://github.com/Alibaba-NLP/WebAgent.", "published": "2025-05-28 17:57:07", "link": "http://arxiv.org/abs/2505.22648v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Characterizing Bias: Benchmarking Large Language Models in Simplified versus Traditional Chinese", "abstract": "While the capabilities of Large Language Models (LLMs) have been studied in\nboth Simplified and Traditional Chinese, it is yet unclear whether LLMs exhibit\ndifferential performance when prompted in these two variants of written\nChinese. This understanding is critical, as disparities in the quality of LLM\nresponses can perpetuate representational harms by ignoring the different\ncultural contexts underlying Simplified versus Traditional Chinese, and can\nexacerbate downstream harms in LLM-facilitated decision-making in domains such\nas education or hiring. To investigate potential LLM performance disparities,\nwe design two benchmark tasks that reflect real-world scenarios: regional term\nchoice (prompting the LLM to name a described item which is referred to\ndifferently in Mainland China and Taiwan), and regional name choice (prompting\nthe LLM to choose who to hire from a list of names in both Simplified and\nTraditional Chinese). For both tasks, we audit the performance of 11 leading\ncommercial LLM services and open-sourced models -- spanning those primarily\ntrained on English, Simplified Chinese, or Traditional Chinese. Our analyses\nindicate that biases in LLM responses are dependent on both the task and\nprompting language: while most LLMs disproportionately favored Simplified\nChinese responses in the regional term choice task, they surprisingly favored\nTraditional Chinese names in the regional name choice task. We find that these\ndisparities may arise from differences in training data representation, written\ncharacter preferences, and tokenization of Simplified and Traditional Chinese.\nThese findings highlight the need for further analysis of LLM biases; as such,\nwe provide an open-sourced benchmark dataset to foster reproducible evaluations\nof future LLM behavior across Chinese language variants\n(https://github.com/brucelyu17/SC-TC-Bench).", "published": "2025-05-28 17:56:49", "link": "http://arxiv.org/abs/2505.22645v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Learning Composable Chains-of-Thought", "abstract": "A common approach for teaching large language models (LLMs) to reason is to\ntrain on chain-of-thought (CoT) traces of in-distribution reasoning problems,\nbut such annotated data is costly to obtain for every problem of interest. We\nwant reasoning models to generalize beyond their training distribution, and\nideally to generalize compositionally: combine atomic reasoning skills to solve\nharder, unseen reasoning tasks. We take a step towards compositional\ngeneralization of reasoning skills when addressing a target compositional task\nthat has no labeled CoT data. We find that simply training models on CoT data\nof atomic tasks leads to limited generalization, but minimally modifying CoT\nformats of constituent atomic tasks to be composable can lead to improvements.\nWe can train \"atomic CoT\" models on the atomic tasks with Composable CoT data\nand combine them with multitask learning or model merging for better zero-shot\nperformance on the target compositional task. Such a combined model can be\nfurther bootstrapped on a small amount of compositional data using rejection\nsampling fine-tuning (RFT). Results on string operations and natural language\nskill compositions show that training LLMs on Composable CoT outperforms\nmultitask learning and continued fine-tuning baselines within a given training\ndata budget.", "published": "2025-05-28 17:51:10", "link": "http://arxiv.org/abs/2505.22635v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Spatial Knowledge Graph-Guided Multimodal Synthesis", "abstract": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly enhanced their capabilities; however, their spatial perception\nabilities remain a notable limitation. To address this challenge, multimodal\ndata synthesis offers a promising solution. Yet, ensuring that synthesized data\nadhere to spatial common sense is a non-trivial task. In this work, we\nintroduce SKG2Data, a novel multimodal synthesis approach guided by spatial\nknowledge graphs, grounded in the concept of knowledge-to-data generation.\nSKG2Data automatically constructs a Spatial Knowledge Graph (SKG) to emulate\nhuman-like perception of spatial directions and distances, which is\nsubsequently utilized to guide multimodal data synthesis. Extensive experiments\ndemonstrate that data synthesized from diverse types of spatial knowledge,\nincluding direction and distance, not only enhance the spatial perception and\nreasoning abilities of MLLMs but also exhibit strong generalization\ncapabilities. We hope that the idea of knowledge-based data synthesis can\nadvance the development of spatial intelligence.", "published": "2025-05-28 17:50:21", "link": "http://arxiv.org/abs/2505.22633v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs", "abstract": "The widespread success of large language models (LLMs) on NLP benchmarks has\nbeen accompanied by concerns that LLMs function primarily as stochastic parrots\nthat reproduce texts similar to what they saw during pre-training, often\nerroneously. But what is the nature of their errors, and do these errors\nexhibit any regularities? In this work, we examine irrelevant context\nhallucinations, in which models integrate misleading contextual cues into their\npredictions. Through behavioral analysis, we show that these errors result from\na structured yet flawed mechanism that we term class-based (mis)generalization,\nin which models combine abstract class cues with features extracted from the\nquery or context to derive answers. Furthermore, mechanistic interpretability\nexperiments on Llama-3, Mistral, and Pythia across 39 factual recall relation\ntypes reveal that this behavior is reflected in the model's internal\ncomputations: (i) abstract class representations are constructed in lower\nlayers before being refined into specific answers in higher layers, (ii)\nfeature selection is governed by two competing circuits -- one prioritizing\ndirect query-based reasoning, the other incorporating contextual cues -- whose\nrelative influences determine the final output. Our findings provide a more\nnuanced perspective on the stochastic parrot argument: through form-based\ntraining, LLMs can exhibit generalization leveraging abstractions, albeit in\nunreliable ways based on contextual cues -- what we term stochastic chameleons.", "published": "2025-05-28 17:47:52", "link": "http://arxiv.org/abs/2505.22630v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Talkers (CoTalk): Fast Human Annotation of Dense Image Captions", "abstract": "While densely annotated image captions significantly facilitate the learning\nof robust vision-language alignment, methodologies for systematically\noptimizing human annotation efforts remain underexplored. We introduce\nChain-of-Talkers (CoTalk), an AI-in-the-loop methodology designed to maximize\nthe number of annotated samples and improve their comprehensiveness under fixed\nbudget constraints (e.g., total human annotation time). The framework is built\nupon two key insights. First, sequential annotation reduces redundant workload\ncompared to conventional parallel annotation, as subsequent annotators only\nneed to annotate the ``residual'' -- the missing visual information that\nprevious annotations have not covered. Second, humans process textual input\nfaster by reading while outputting annotations with much higher throughput via\ntalking; thus a multimodal interface enables optimized efficiency. We evaluate\nour framework from two aspects: intrinsic evaluations that assess the\ncomprehensiveness of semantic units, obtained by parsing detailed captions into\nobject-attribute trees and analyzing their effective connections; extrinsic\nevaluation measures the practical usage of the annotated captions in\nfacilitating vision-language alignment. Experiments with eight participants\nshow our Chain-of-Talkers (CoTalk) improves annotation speed (0.42 vs. 0.30\nunits/sec) and retrieval performance (41.13\\% vs. 40.52\\%) over the parallel\nmethod.", "published": "2025-05-28 17:45:55", "link": "http://arxiv.org/abs/2505.22627v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding", "abstract": "Diffusion-based large language models (Diffusion LLMs) have shown promise for\nnon-autoregressive text generation with parallel decoding capabilities.\nHowever, the practical inference speed of open-sourced Diffusion LLMs often\nlags behind autoregressive models due to the lack of Key-Value (KV) Cache and\nquality degradation when decoding multiple tokens simultaneously. To bridge\nthis gap, we introduce a novel block-wise approximate KV Cache mechanism\ntailored for bidirectional diffusion models, enabling cache reuse with\nnegligible performance drop. Additionally, we identify the root cause of\ngeneration quality degradation in parallel decoding as the disruption of token\ndependencies under the conditional independence assumption. To address this, we\npropose a confidence-aware parallel decoding strategy that selectively decodes\ntokens exceeding a confidence threshold, mitigating dependency violations and\nmaintaining generation quality. Experimental results on LLaDA and Dream models\nacross multiple LLM benchmarks demonstrate up to \\textbf{27.6$\\times$\nthroughput} improvement with minimal accuracy loss, closing the performance gap\nwith autoregressive models and paving the way for practical deployment of\nDiffusion LLMs.", "published": "2025-05-28 17:39:15", "link": "http://arxiv.org/abs/2505.22618v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models", "abstract": "This paper aims to overcome a major obstacle in scaling RL for reasoning with\nLLMs, namely the collapse of policy entropy. Such phenomenon is consistently\nobserved across vast RL runs without entropy intervention, where the policy\nentropy dropped sharply at the early training stage, this diminished\nexploratory ability is always accompanied with the saturation of policy\nperformance. In practice, we establish a transformation equation R=-a*e^H+b\nbetween entropy H and downstream performance R. This empirical law strongly\nindicates that, the policy performance is traded from policy entropy, thus\nbottlenecked by its exhaustion, and the ceiling is fully predictable H=0,\nR=-a+b. Our finding necessitates entropy management for continuous exploration\ntoward scaling compute for RL. To this end, we investigate entropy dynamics\nboth theoretically and empirically. Our derivation highlights that, the change\nin policy entropy is driven by the covariance between action probability and\nthe change in logits, which is proportional to its advantage when using Policy\nGradient-like algorithms. Empirical study shows that, the values of covariance\nterm and entropy differences matched exactly, supporting the theoretical\nconclusion. Moreover, the covariance term stays mostly positive throughout\ntraining, further explaining why policy entropy would decrease monotonically.\nThrough understanding the mechanism behind entropy dynamics, we motivate to\ncontrol entropy by restricting the update of high-covariance tokens.\nSpecifically, we propose two simple yet effective techniques, namely Clip-Cov\nand KL-Cov, which clip and apply KL penalty to tokens with high covariances\nrespectively. Experiments show that these methods encourage exploration, thus\nhelping policy escape entropy collapse and achieve better downstream\nperformance.", "published": "2025-05-28 17:38:45", "link": "http://arxiv.org/abs/2505.22617v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction", "abstract": "Image recaptioning is widely used to generate training datasets with enhanced\nquality for various multimodal tasks. Existing recaptioning methods typically\nrely on powerful multimodal large language models (MLLMs) to enhance textual\ndescriptions, but often suffer from inaccuracies due to hallucinations and\nincompleteness caused by missing fine-grained details. To address these\nlimitations, we propose RICO, a novel framework that refines captions through\nvisual reconstruction. Specifically, we leverage a text-to-image model to\nreconstruct a caption into a reference image, and prompt an MLLM to identify\ndiscrepancies between the original and reconstructed images to refine the\ncaption. This process is performed iteratively, further progressively promoting\nthe generation of more faithful and comprehensive descriptions. To mitigate the\nadditional computational cost induced by the iterative process, we introduce\nRICO-Flash, which learns to generate captions like RICO using DPO. Extensive\nexperiments demonstrate that our approach significantly improves caption\naccuracy and completeness, outperforms most baselines by approximately 10% on\nboth CapsBench and CompreCap. Code released at\nhttps://github.com/wangyuchi369/RICO.", "published": "2025-05-28 17:29:34", "link": "http://arxiv.org/abs/2505.22613v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning", "abstract": "Although large language models demonstrate strong performance across various\ndomains, they still struggle with numerous bad cases in mathematical reasoning.\nPrevious approaches to learning from errors synthesize training data by solely\nextrapolating from isolated bad cases, thereby failing to generalize the\nextensive patterns inherent within these cases. This paper presents\nSelf-Error-Instruct (SEI), a framework that addresses these model weaknesses\nand synthesizes more generalized targeted training data. Specifically, we\nexplore a target model on two mathematical datasets, GSM8K and MATH, to\npinpoint bad cases. Then, we generate error keyphrases for these cases based on\nthe instructor model's (GPT-4o) analysis and identify error types by clustering\nthese keyphrases. Next, we sample a few bad cases during each generation for\neach identified error type and input them into the instructor model, which\nsynthesizes additional training data using a self-instruct approach. This new\ndata is refined through a one-shot learning process to ensure that only the\nmost effective examples are kept. Finally, we use these curated data to\nfine-tune the target model, iteratively repeating the process to enhance\nperformance. We apply our framework to various models and observe improvements\nin their reasoning abilities across both in-domain and out-of-domain\nmathematics datasets. These results demonstrate the effectiveness of self-error\ninstruction in improving LLMs' mathematical reasoning through error\ngeneralization.", "published": "2025-05-28 17:02:47", "link": "http://arxiv.org/abs/2505.22591v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Precise In-Parameter Concept Erasure in Large Language Models", "abstract": "Large language models (LLMs) often acquire knowledge during pretraining that\nis undesirable in downstream deployments, e.g., sensitive information or\ncopyrighted content. Existing approaches for removing such knowledge rely on\nfine-tuning, training low-rank adapters or fact-level editing, but these are\neither too coarse, too shallow, or ineffective. In this work, we propose PISCES\n(Precise In-parameter Suppression for Concept EraSure), a novel framework for\nprecisely erasing entire concepts from model parameters by directly editing\ndirections that encode them in parameter space. PISCES uses a disentangler\nmodel to decompose MLP vectors into interpretable features, identifies those\nassociated with a target concept using automated interpretability techniques,\nand removes them from model parameters. Experiments on Gemma 2 and Llama 3.1\nover various concepts show that PISCES achieves modest gains in efficacy over\nleading erasure methods, reducing accuracy on the target concept to as low as\n7.7%, while dramatically improving erasure specificity (by up to 31%) and\nrobustness (by up to 38%). Overall, these results demonstrate that\nfeature-based in-parameter editing enables a more precise and reliable approach\nfor removing conceptual knowledge in language models.", "published": "2025-05-28 16:58:23", "link": "http://arxiv.org/abs/2505.22586v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts", "abstract": "Continually expanding new languages for existing large language models (LLMs)\nis a promising yet challenging approach to building powerful multilingual LLMs.\nThe biggest challenge is to make the model continuously learn new languages\nwhile preserving the proficient ability of old languages. To achieve this,\nrecent work utilizes the Mixture-of-Experts (MoE) architecture to expand new\nlanguages by adding new experts and avoid catastrophic forgetting of old\nlanguages by routing corresponding tokens to the original model backbone (old\nexperts). Although intuitive, this kind of method is parameter-costly when\nexpanding new languages and still inevitably impacts the performance of old\nlanguages. To address these limitations, we analyze the language\ncharacteristics of different layers in LLMs and propose a layer-wise expert\nallocation algorithm (LayerMoE) to determine the appropriate number of new\nexperts for each layer. Specifically, we find different layers in LLMs exhibit\ndifferent representation similarities between languages and then utilize the\nsimilarity as the indicator to allocate experts for each layer, i.e., the\nhigher similarity, the fewer experts. Additionally, to further mitigate the\nforgetting of old languages, we add a classifier in front of the router network\non the layers with higher similarity to guide the routing of old language\ntokens. Experimental results show that our method outperforms the previous\nstate-of-the-art baseline with 60% fewer experts in the single-expansion\nsetting and with 33.3% fewer experts in the lifelong-expansion setting,\ndemonstrating the effectiveness of our method.", "published": "2025-05-28 16:54:53", "link": "http://arxiv.org/abs/2505.22582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fusion Steering: Prompt-Specific Activation Control", "abstract": "We present Fusion Steering, an activation steering methodology that improves\nfactual accuracy in large language models (LLMs) for question-answering (QA)\ntasks. This approach introduces flexible steering configurations, including\nfull-layer steering and segmented steering. Unlike traditional methods\nconstrained to single-layer or fixed-layer operations, Fusion Steering employs\ndynamic injection of prompt-specific activation deltas across all transformer\nlayers. These activation deltas are derived from reference completions that\ncombine the ground-truth answer with a model-generated explanation to\nfacilitate semantically enriched, example-specific steering. The injection\nweights are optimized per prompt using Optuna, targeting a joint objective that\nbalances token overlap (factual alignment) and perplexity (fluency proxy).\nEvaluation employs a composite score integrating token overlap and LLM-graded\nquality, encompassing factual accuracy, coherence, and relevance. Empirical\nresults on 260 SimpleQA prompts (selected from 500 where the baseline failed)\nshowcase the efficacy of segmented steering. Using Gemma-2-2B-IT with 8-bit\nquantization, segmented steering achieves an accuracy of 25.4% (outputs scoring\n$\\geq 0.6$), outperforming the baseline at 3.5% and full-layer steering at\n16.2%. Under the stricter SimpleQA rubric, segmented steering boosts fully\ncorrect responses from 0.0% to 13.1%. These findings highlight the strengths of\nsegmented, dynamic intervention strategies and the promise of per-prompt,\nfull-network activation control. Fusion Steering is also amenable to sparse\nrepresentations, such as Neuronpedia or sparse crosscoders, suggesting a\npromising direction for interpretable and scalable activation-level control in\nLLMs.", "published": "2025-05-28 16:46:55", "link": "http://arxiv.org/abs/2505.22572v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems", "abstract": "This paper presents a novel approach for unified retrieval-augmented\ngeneration (RAG) systems using the recent emerging large language model (LLM)\nagent concept. Specifically, Agent LLM, which utilizes LLM as fundamental\ncontrollers, has become a promising approach to enable the interpretability of\nRAG tasks, especially for complex reasoning question-answering systems (e.g.,\nmulti-hop queries). Nonetheless, previous works mainly focus on solving RAG\nsystems with either single-hop or multi-hop approaches separately, which limits\nthe application of those approaches to real-world applications. In this study,\nwe propose a trainable agent framework called Agent-UniRAG for unified\nretrieval-augmented LLM systems, which enhances the effectiveness and\ninterpretability of RAG systems. The main idea is to design an LLM agent\nframework to solve RAG tasks step-by-step based on the complexity of the\ninputs, simultaneously including single-hop and multi-hop queries in an\nend-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset\nto enable the proposed agent framework for small open-source LLMs (e.g.,\nLlama-3-8B). The results show comparable performances with closed-source and\nlarger open-source LLMs across various RAG benchmarks. Our source code and\ndataset are publicly available for further exploitation.", "published": "2025-05-28 16:46:31", "link": "http://arxiv.org/abs/2505.22571v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Think Like the Brain? Sentence-Level Evidence from fMRI and Hierarchical Embeddings", "abstract": "Understanding whether large language models (LLMs) and the human brain\nconverge on similar computational principles remains a fundamental and\nimportant question in cognitive neuroscience and AI. Do the brain-like patterns\nobserved in LLMs emerge simply from scaling, or do they reflect deeper\nalignment with the architecture of human language processing? This study\nfocuses on the sentence-level neural mechanisms of language models,\nsystematically investigating how hierarchical representations in LLMs align\nwith the dynamic neural responses during human sentence comprehension. By\ncomparing hierarchical embeddings from 14 publicly available LLMs with fMRI\ndata collected from participants, who were exposed to a naturalistic narrative\nstory, we constructed sentence-level neural prediction models to precisely\nidentify the model layers most significantly correlated with brain region\nactivations. Results show that improvements in model performance drive the\nevolution of representational architectures toward brain-like hierarchies,\nparticularly achieving stronger functional and anatomical correspondence at\nhigher semantic abstraction levels.", "published": "2025-05-28 16:40:06", "link": "http://arxiv.org/abs/2505.22563v1", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM", "abstract": "Integrating knowledge graphs (KGs) to enhance the reasoning capabilities of\nlarge language models (LLMs) is an emerging research challenge in claim\nverification. While KGs provide structured, semantically rich representations\nwell-suited for reasoning, most existing verification methods rely on\nunstructured text corpora, limiting their ability to effectively leverage KGs.\nAdditionally, despite possessing strong reasoning abilities, modern LLMs\nstruggle with multi-step modular pipelines and reasoning over KGs without\nadaptation. To address these challenges, we propose ClaimPKG, an end-to-end\nframework that seamlessly integrates LLM reasoning with structured knowledge\nfrom KGs. Specifically, the main idea of ClaimPKG is to employ a lightweight,\nspecialized LLM to represent the input claim as pseudo-subgraphs, guiding a\ndedicated subgraph retrieval module to identify relevant KG subgraphs. These\nretrieved subgraphs are then processed by a general-purpose LLM to produce the\nfinal verdict and justification. Extensive experiments on the FactKG dataset\ndemonstrate that ClaimPKG achieves state-of-the-art performance, outperforming\nstrong baselines in this research field by 9%-12% accuracy points across\nmultiple categories. Furthermore, ClaimPKG exhibits zero-shot generalizability\nto unstructured datasets such as HoVer and FEVEROUS, effectively combining\nstructured knowledge from KGs with LLM reasoning across various LLM backbones.", "published": "2025-05-28 16:34:14", "link": "http://arxiv.org/abs/2505.22552v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Emotion-o1: Adaptive Long Reasoning for Emotion Understanding in LLMs", "abstract": "Emotion understanding includes basic tasks (e.g., sentiment/emotion\nclassification) and advanced tasks (e.g., sarcasm/humor detection). Current\nmethods rely on fixed-length CoT reasoning, failing to adapt to the varying\ncomplexity of emotions. We propose a task-adaptive reasoning framework that\nemploys DeepSeek-R1 to generate variable-length reasoning chains for different\nemotion tasks. By combining fine-tuning with reinforcement learning, we design\na composite reward function that balances four objectives: prediction accuracy,\nadaptive reasoning depth control, structural diversity in reasoning paths, and\nsuppression of repetitive logic. This approach achieves dynamic\ncontext-sensitive inference while enabling LLMs to autonomously develop deep\nreasoning capabilities. Experimental results demonstrate consistent\nimprovements in both Acc and F1 scores across four tasks: emotion, sentiment,\nhumor, and sarcasm. Notably, peak enhancements reached 3.56% F1 (2.76% Acc) for\nbasic tasks and 37.95% F1 (23.14% Acc) for advanced tasks. Our work bridges\nrigid CoT reasoning and emotional complexity through adaptive-depth analysis.", "published": "2025-05-28 16:32:16", "link": "http://arxiv.org/abs/2505.22548v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thinking with Generated Images", "abstract": "We present Thinking with Generated Images, a novel paradigm that\nfundamentally transforms how large multimodal models (LMMs) engage with visual\nreasoning by enabling them to natively think across text and vision modalities\nthrough spontaneous generation of intermediate visual thinking steps. Current\nvisual reasoning with LMMs is constrained to either processing fixed\nuser-provided images or reasoning solely through text-based chain-of-thought\n(CoT). Thinking with Generated Images unlocks a new dimension of cognitive\ncapability where models can actively construct intermediate visual thoughts,\ncritique their own visual hypotheses, and refine them as integral components of\ntheir reasoning process. We demonstrate the effectiveness of our approach\nthrough two complementary mechanisms: (1) vision generation with intermediate\nvisual subgoals, where models decompose complex visual tasks into manageable\ncomponents that are generated and integrated progressively, and (2) vision\ngeneration with self-critique, where models generate an initial visual\nhypothesis, analyze its shortcomings through textual reasoning, and produce\nrefined outputs based on their own critiques. Our experiments on vision\ngeneration benchmarks show substantial improvements over baseline approaches,\nwith our models achieving up to 50% (from 38% to 57%) relative improvement in\nhandling complex multi-object scenarios. From biochemists exploring novel\nprotein structures, and architects iterating on spatial designs, to forensic\nanalysts reconstructing crime scenes, and basketball players envisioning\nstrategic plays, our approach enables AI models to engage in the kind of visual\nimagination and iterative refinement that characterizes human creative,\nanalytical, and strategic thinking. We release our open-source suite at\nhttps://github.com/GAIR-NLP/thinking-with-generated-images.", "published": "2025-05-28 16:12:45", "link": "http://arxiv.org/abs/2505.22525v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multi-MLLM Knowledge Distillation for Out-of-Context News Detection", "abstract": "Multimodal out-of-context news is a type of misinformation in which the image\nis used outside of its original context. Many existing works have leveraged\nmultimodal large language models (MLLMs) for detecting out-of-context news.\nHowever, observing the limited zero-shot performance of smaller MLLMs, they\ngenerally require label-rich fine-tuning and/or expensive API calls to GPT\nmodels to improve the performance, which is impractical in low-resource\nscenarios. In contrast, we aim to improve the performance of small MLLMs in a\nmore label-efficient and cost-effective manner. To this end, we first prompt\nmultiple teacher MLLMs to generate both label predictions and corresponding\nrationales, which collectively serve as the teachers' knowledge. We then\nintroduce a two-stage knowledge distillation framework to transfer this\nknowledge to a student MLLM. In Stage 1, we apply LoRA fine-tuning to the\nstudent model using all training data. In Stage 2, we further fine-tune the\nstudent model using both LoRA fine-tuning and DPO on the data points where\nteachers' predictions conflict. This two-stage strategy reduces annotation\ncosts and helps the student model uncover subtle patterns in more challenging\ncases. Experimental results demonstrate that our approach achieves\nstate-of-the-art performance using less than 10% labeled data.", "published": "2025-05-28 16:03:41", "link": "http://arxiv.org/abs/2505.22517v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "EvolveSearch: An Iterative Self-Evolving Search Agent", "abstract": "The rapid advancement of large language models (LLMs) has transformed the\nlandscape of agentic information seeking capabilities through the integration\nof tools such as search engines and web browsers. However, current mainstream\napproaches for enabling LLM web search proficiency face significant challenges:\nsupervised fine-tuning struggles with data production in open-search domains,\nwhile RL converges quickly, limiting their data utilization efficiency. To\naddress these issues, we propose EvolveSearch, a novel iterative self-evolution\nframework that combines SFT and RL to enhance agentic web search capabilities\nwithout any external human-annotated reasoning data. Extensive experiments on\nseven multi-hop question-answering (MHQA) benchmarks demonstrate that\nEvolveSearch consistently improves performance across iterations, ultimately\nachieving an average improvement of 4.7\\% over the current state-of-the-art\nacross seven benchmarks, opening the door to self-evolution agentic\ncapabilities in open web search domains.", "published": "2025-05-28 15:50:48", "link": "http://arxiv.org/abs/2505.22501v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Context in Neural Speech Models", "abstract": "Modern neural speech models benefit from having longer context, and many\napproaches have been proposed to increase the maximum context a model can use.\nHowever, few have attempted to measure how much context these models actually\nuse, i.e., the effective context. Here, we propose two approaches to measuring\nthe effective context, and use them to analyze different speech Transformers.\nFor supervised models, we find that the effective context correlates well with\nthe nature of the task, with fundamental frequency tracking, phone\nclassification, and word classification requiring increasing amounts of\neffective context. For self-supervised models, we find that effective context\nincreases mainly in the early layers, and remains relatively short -- similar\nto the supervised phone model. Given that these models do not use a long\ncontext during prediction, we show that HuBERT can be run in streaming mode\nwithout modification to the architecture and without further fine-tuning.", "published": "2025-05-28 15:36:44", "link": "http://arxiv.org/abs/2505.22487v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fostering Video Reasoning via Next-Event Prediction", "abstract": "Next-token prediction serves as the foundational learning task enabling\nreasoning in LLMs. But what should the learning task be when aiming to equip\nMLLMs with temporal reasoning capabilities over video inputs? Existing tasks\nsuch as video question answering often rely on annotations from humans or much\nstronger MLLMs, while video captioning tends to entangle temporal reasoning\nwith spatial information. To address this gap, we propose next-event prediction\n(NEP), a learning task that harnesses future video segments as a rich,\nself-supervised signal to foster temporal reasoning. We segment each video into\npast and future frames: the MLLM takes the past frames as input and predicts a\nsummary of events derived from the future frames, thereby encouraging the model\nto reason temporally in order to complete the task. To support this task, we\ncurate V1-33K, a dataset comprising 33,000 automatically extracted video\nsegments spanning diverse real-world scenarios. We further explore a range of\nvideo instruction-tuning strategies to study their effects on temporal\nreasoning. To evaluate progress, we introduce FutureBench to assess coherence\nin predicting unseen future events. Experiments validate that NEP offers a\nscalable and effective training paradigm for fostering temporal reasoning in\nMLLMs.", "published": "2025-05-28 15:13:34", "link": "http://arxiv.org/abs/2505.22457v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO", "abstract": "Improving Multi-modal Large Language Models (MLLMs) in the post-training\nstage typically relies on supervised fine-tuning (SFT) or reinforcement\nlearning (RL). However, these supervised methods require expensive and manually\nannotated multi-modal data--an ultimately unsustainable resource. While recent\nefforts have explored unsupervised post-training, their methods are complex and\ndifficult to iterate. In this work, we are the first to investigate the use of\nGRPO, a stable and scalable online RL algorithm, for enabling continual\nself-improvement without any external supervision. We propose MM-UPT, a simple\nyet effective framework for unsupervised post-training of MLLMs. MM-UPT builds\nupon GRPO, replacing traditional reward signals with a self-rewarding mechanism\nbased on majority voting over multiple sampled responses. Our experiments\ndemonstrate that MM-UPT significantly improves the reasoning ability of\nQwen2.5-VL-7B (e.g., 66.3 %$\\rightarrow$72.9 % on MathVista, 62.9\n%$\\rightarrow$68.7 % on We-Math), using standard dataset without ground truth\nlabels. MM-UPT also outperforms prior unsupervised baselines and even\napproaches the results of supervised GRPO. Furthermore, we show that\nincorporating synthetic questions, generated solely by MLLM itself, can boost\nperformance as well, highlighting a promising approach for scalable\nself-improvement. Overall, MM-UPT offers a new paradigm for continual,\nautonomous enhancement of MLLMs in the absence of external supervision. Our\ncode is available at https://github.com/waltonfuture/MM-UPT.", "published": "2025-05-28 15:11:16", "link": "http://arxiv.org/abs/2505.22453v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RAG-Zeval: Towards Robust and Interpretable Evaluation on RAG Responses through End-to-End Rule-Guided Reasoning", "abstract": "Robust evaluation is critical for deploying trustworthy retrieval-augmented\ngeneration (RAG) systems. However, current LLM-based evaluation frameworks\npredominantly rely on directly prompting resource-intensive models with complex\nmulti-stage prompts, underutilizing models' reasoning capabilities and\nintroducing significant computational cost. In this paper, we present RAG-Zeval\n(RAG-Zero Evaluator), a novel end-to-end framework that formulates faithfulness\nand correctness evaluation as a rule-guided reasoning task. Our approach trains\nevaluators with reinforcement learning, facilitating compact models to generate\ncomprehensive and sound assessments with detailed explanation in one-pass. We\nintroduce a ranking-based outcome reward mechanism, using preference judgments\nrather than absolute scores, to address the challenge of obtaining precise\npointwise reward signals. To this end, we synthesize the ranking references by\ngenerating quality-controlled responses with zero human annotation. Experiments\ndemonstrate RAG-Zeval's superior performance, achieving the strongest\ncorrelation with human judgments and outperforming baselines that rely on LLMs\nwith 10-100 times more parameters. Our approach also exhibits superior\ninterpretability in response evaluation.", "published": "2025-05-28 14:55:33", "link": "http://arxiv.org/abs/2505.22430v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Reasoning without Attention", "abstract": "Large language models (LLMs) have made significant advances in complex\nreasoning tasks, yet they remain bottlenecked by two core challenges:\narchitectural inefficiency due to reliance on Transformers, and a lack of\nstructured fine-tuning for high-difficulty domains. We introduce \\ourmodel, an\nattention-free language model that addresses both issues through architectural\nand data-centric innovations. Built on the state space dual (SSD) layers of\nMamba-2, our model eliminates the need for self-attention and key-value\ncaching, enabling fixed-memory, constant-time inference. To train it for\ncomplex reasoning, we propose a two-phase curriculum fine-tuning strategy based\non the \\textsc{PromptCoT} synthesis paradigm, which generates pedagogically\nstructured problems via abstract concept selection and rationale-guided\ngeneration. On benchmark evaluations, \\ourmodel-7B outperforms strong\nTransformer and hybrid models of comparable scale, and even surpasses the much\nlarger Gemma3-27B by 2.6\\% on AIME 24, 0.6\\% on AIME 25, and 3.0\\% on\nLivecodebench. These results highlight the potential of state space models as\nefficient and scalable alternatives to attention-based architectures for\nhigh-capacity reasoning.", "published": "2025-05-28 14:52:15", "link": "http://arxiv.org/abs/2505.22425v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Mitigating Overthinking in Large Reasoning Models via Manifold Steering", "abstract": "Recent advances in Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in solving complex tasks such as mathematics and coding. However,\nthese models frequently exhibit a phenomenon known as overthinking during\ninference, characterized by excessive validation loops and redundant\ndeliberation, leading to substantial computational overheads. In this paper, we\naim to mitigate overthinking by investigating the underlying mechanisms from\nthe perspective of mechanistic interpretability. We first showcase that the\ntendency of overthinking can be effectively captured by a single direction in\nthe model's activation space and the issue can be eased by intervening the\nactivations along this direction. However, this efficacy soon reaches a plateau\nand even deteriorates as the intervention strength increases. We therefore\nsystematically explore the activation space and find that the overthinking\nphenomenon is actually tied to a low-dimensional manifold, which indicates that\nthe limited effect stems from the noises introduced by the high-dimensional\nsteering direction. Based on this insight, we propose Manifold Steering, a\nnovel approach that elegantly projects the steering direction onto the\nlow-dimensional activation manifold given the theoretical approximation of the\ninterference noise. Extensive experiments on DeepSeek-R1 distilled models\nvalidate that our method reduces output tokens by up to 71% while maintaining\nand even improving the accuracy on several mathematical benchmarks. Our method\nalso exhibits robust cross-domain transferability, delivering consistent token\nreduction performance in code generation and knowledge-based QA tasks. Code is\navailable at: https://github.com/Aries-iai/Manifold_Steering.", "published": "2025-05-28 14:39:26", "link": "http://arxiv.org/abs/2505.22411v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition", "abstract": "This work presents Pangu Embedded, an efficient Large Language Model (LLM)\nreasoner developed on Ascend Neural Processing Units (NPUs), featuring flexible\nfast and slow thinking capabilities. Pangu Embedded addresses the significant\ncomputational costs and inference latency challenges prevalent in existing\nreasoning-optimized LLMs. We propose a two-stage training framework for its\nconstruction. In Stage 1, the model is finetuned via an iterative distillation\nprocess, incorporating inter-iteration model merging to effectively aggregate\ncomplementary knowledge. This is followed by reinforcement learning on Ascend\nclusters, optimized by a latency-tolerant scheduler that combines stale\nsynchronous parallelism with prioritized data queues. The RL process is guided\nby a Multi-source Adaptive Reward System (MARS), which generates dynamic,\ntask-specific reward signals using deterministic metrics and lightweight LLM\nevaluators for mathematics, coding, and general problem-solving tasks. Stage 2\nintroduces a dual-system framework, endowing Pangu Embedded with a \"fast\" mode\nfor routine queries and a deeper \"slow\" mode for complex inference. This\nframework offers both manual mode switching for user control and an automatic,\ncomplexity-aware mode selection mechanism that dynamically allocates\ncomputational resources to balance latency and reasoning depth. Experimental\nresults on benchmarks including AIME 2024, GPQA, and LiveCodeBench demonstrate\nthat Pangu Embedded with 7B parameters, outperforms similar-size models like\nQwen3-8B and GLM4-9B. It delivers rapid responses and state-of-the-art\nreasoning quality within a single, unified model architecture, highlighting a\npromising direction for developing powerful yet practically deployable LLM\nreasoners.", "published": "2025-05-28 14:03:02", "link": "http://arxiv.org/abs/2505.22375v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs Struggle to Reject False Presuppositions when Misinformation Stakes are High", "abstract": "This paper examines how LLMs handle false presuppositions and whether certain\nlinguistic factors influence their responses to falsely presupposed content.\nPresuppositions subtly introduce information as given, making them highly\neffective at embedding disputable or false information. This raises concerns\nabout whether LLMs, like humans, may fail to detect and correct misleading\nassumptions introduced as false presuppositions, even when the stakes of\nmisinformation are high. Using a systematic approach based on linguistic\npresupposition analysis, we investigate the conditions under which LLMs are\nmore or less sensitive to adopt or reject false presuppositions. Focusing on\npolitical contexts, we examine how factors like linguistic construction,\npolitical party, and scenario probability impact the recognition of false\npresuppositions. We conduct experiments with a newly created dataset and\nexamine three LLMs: OpenAI's GPT-4-o, Meta's LLama-3-8B, and MistralAI's\nMistral-7B-v03. Our results show that the models struggle to recognize false\npresuppositions, with performance varying by condition. This study highlights\nthat linguistic presupposition analysis is a valuable tool for uncovering the\nreinforcement of political misinformation in LLM responses.", "published": "2025-05-28 13:35:07", "link": "http://arxiv.org/abs/2505.22354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text2Grad: Reinforcement Learning from Natural Language Feedback", "abstract": "Traditional RLHF optimizes language models with coarse, scalar rewards that\nmask the fine-grained reasons behind success or failure, leading to slow and\nopaque learning. Recent work augments RL with textual critiques through\nprompting or reflection, improving interpretability but leaving model\nparameters untouched. We introduce Text2Grad, a reinforcement-learning paradigm\nthat turns free-form textual feedback into span-level gradients. Given human\n(or programmatic) critiques, Text2Grad aligns each feedback phrase with the\nrelevant token spans, converts these alignments into differentiable reward\nsignals, and performs gradient updates that directly refine the offending\nportions of the model's policy. This yields precise, feedback-conditioned\nadjustments instead of global nudges. Text2Grad is realized through three\ncomponents: (1) a high-quality feedback-annotation pipeline that pairs\ncritiques with token spans; (2) a fine-grained reward model that predicts\nspan-level reward on answer while generating explanatory critiques; and (3) a\nspan-level policy optimizer that back-propagates natural-language gradients.\nAcross summarization, code generation, and question answering, Text2Grad\nconsistently surpasses scalar-reward RL and prompt-only baselines, providing\nboth higher task metrics and richer interpretability. Our results demonstrate\nthat natural-language feedback, when converted to gradients, is a powerful\nsignal for fine-grained policy optimization. The code for our method is\navailable at https://github.com/microsoft/Text2Grad", "published": "2025-05-28 13:23:49", "link": "http://arxiv.org/abs/2505.22338v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start", "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nimpressive chain-of-thought reasoning capabilities, with reinforcement learning\n(RL) playing a crucial role in this progress. While \"aha moment\"\npatterns--where models exhibit self-correction through reflection--are often\nattributed to emergent properties from RL, we first demonstrate that these\npatterns exist in multimodal LLMs (MLLMs) prior to RL training but may not\nnecessarily correlate with improved reasoning performance. Building on these\ninsights, we present a comprehensive study on enhancing multimodal reasoning\nthrough a two-stage approach: (1) supervised fine-tuning (SFT) as a cold start\nwith structured chain-of-thought reasoning patterns, followed by (2)\nreinforcement learning via GRPO to further refine these capabilities. Our\nextensive experiments show that this combined approach consistently outperforms\nboth SFT-only and RL-only methods across challenging multimodal reasoning\nbenchmarks. The resulting models achieve state-of-the-art performance among\nopen-source MLLMs at both 3B and 7B scales, with our 7B model showing\nsubstantial improvements over base models (e.g., 66.3 %$\\rightarrow$73.4 % on\nMathVista, 62.9 %$\\rightarrow$70.4 % on We-Math) and our 3B model achieving\nperformance competitive with several 7B models. Overall, this work provides\npractical guidance for building advanced multimodal reasoning models. Our code\nis available at https://github.com/waltonfuture/RL-with-Cold-Start.", "published": "2025-05-28 13:21:38", "link": "http://arxiv.org/abs/2505.22334v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLP for Social Good: A Survey of Challenges, Opportunities, and Responsible Deployment", "abstract": "Recent advancements in large language models (LLMs) have unlocked\nunprecedented possibilities across a range of applications. However, as a\ncommunity, we believe that the field of Natural Language Processing (NLP) has a\ngrowing need to approach deployment with greater intentionality and\nresponsibility. In alignment with the broader vision of AI for Social Good\n(Toma\\v{s}ev et al., 2020), this paper examines the role of NLP in addressing\npressing societal challenges. Through a cross-disciplinary analysis of social\ngoals and emerging risks, we highlight promising research directions and\noutline challenges that must be addressed to ensure responsible and equitable\nprogress in NLP4SG research.", "published": "2025-05-28 13:14:44", "link": "http://arxiv.org/abs/2505.22327v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Advancing Expert Specialization for Better MoE", "abstract": "Mixture-of-Experts (MoE) models enable efficient scaling of large language\nmodels (LLMs) by activating only a subset of experts per input. However, we\nobserve that the commonly used auxiliary load balancing loss often leads to\nexpert overlap and overly uniform routing, which hinders expert specialization\nand degrades overall performance during post-training. To address this, we\npropose a simple yet effective solution that introduces two complementary\nobjectives: (1) an orthogonality loss to encourage experts to process distinct\ntypes of tokens, and (2) a variance loss to encourage more discriminative\nrouting decisions. Gradient-level analysis demonstrates that these objectives\nare compatible with the existing auxiliary loss and contribute to optimizing\nthe training process. Experimental results over various model architectures and\nacross multiple benchmarks show that our method significantly enhances expert\nspecialization. Notably, our method improves classic MoE baselines with\nauxiliary loss by up to 23.79%, while also maintaining load balancing in\ndownstream tasks, without any architectural modifications or additional\ncomponents. We will release our code to contribute to the community.", "published": "2025-05-28 13:09:47", "link": "http://arxiv.org/abs/2505.22323v1", "categories": ["cs.CL", "cs.SE", "68T07", "I.2.7"], "primary_category": "cs.CL"}
{"title": "If Pigs Could Fly... Can LLMs Logically Reason Through Counterfactuals?", "abstract": "Large Language Models (LLMs) demonstrate impressive reasoning capabilities in\nfamiliar contexts, but struggle when the context conflicts with their\nparametric knowledge. To investigate this phenomenon, we introduce\nCounterLogic, a dataset containing 1,800 examples across 9 logical schemas,\nexplicitly designed to evaluate logical reasoning through counterfactual\n(hypothetical knowledge-conflicting) scenarios. Our systematic evaluation of 11\nLLMs across 6 different datasets reveals a consistent performance degradation,\nwith accuracies dropping by 27% on average when reasoning through\ncounterfactual information. We propose Self-Segregate, a prompting method\nenabling metacognitive awareness (explicitly identifying knowledge conflicts)\nbefore reasoning. Our method dramatically narrows the average performance gaps\nfrom 27% to just 11%, while significantly increasing the overall accuracy\n(+7.5%). We discuss the implications of these findings and draw parallels to\nhuman cognitive processes, particularly on how humans disambiguate conflicting\ninformation during reasoning tasks. Our findings offer practical insights for\nunderstanding and enhancing LLMs reasoning capabilities in real-world\napplications, especially where models must logically reason independently of\ntheir factual knowledge.", "published": "2025-05-28 13:03:18", "link": "http://arxiv.org/abs/2505.22318v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Skywork Open Reasoner 1 Technical Report", "abstract": "The success of DeepSeek-R1 underscores the significant role of reinforcement\nlearning (RL) in enhancing the reasoning capabilities of large language models\n(LLMs). In this work, we present Skywork-OR1, an effective and scalable RL\nimplementation for long Chain-of-Thought (CoT) models. Building on the\nDeepSeek-R1-Distill model series, our RL approach achieves notable performance\ngains, increasing average accuracy across AIME24, AIME25, and LiveCodeBench\nfrom 57.8% to 72.8% (+15.0%) for the 32B model and from 43.6% to 57.5% (+13.9%)\nfor the 7B model. Our Skywork-OR1-32B model surpasses both DeepSeek-R1 and\nQwen3-32B on the AIME24 and AIME25 benchmarks, while achieving comparable\nresults on LiveCodeBench. The Skywork-OR1-7B and Skywork-OR1-Math-7B models\ndemonstrate competitive reasoning capabilities among models of similar size. We\nperform comprehensive ablation studies on the core components of our training\npipeline to validate their effectiveness. Additionally, we thoroughly\ninvestigate the phenomenon of entropy collapse, identify key factors affecting\nentropy dynamics, and demonstrate that mitigating premature entropy collapse is\ncritical for improved test performance. To support community research, we fully\nopen-source our model weights, training code, and training datasets.", "published": "2025-05-28 12:56:04", "link": "http://arxiv.org/abs/2505.22312v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing", "abstract": "Large language models (LLMs) exhibit impressive language capabilities but\nremain vulnerable to malicious prompts and jailbreaking attacks. Existing\nknowledge editing methods for LLM detoxification face two major challenges.\nFirst, they often rely on entity-specific localization, making them ineffective\nagainst adversarial inputs without explicit entities. Second, these methods\nsuffer from over-editing, where detoxified models reject legitimate queries,\ncompromising overall performance. In this paper, we propose ToxEdit, a\ntoxicity-aware knowledge editing approach that dynamically detects toxic\nactivation patterns during forward propagation. It then routes computations\nthrough adaptive inter-layer pathways to mitigate toxicity effectively. This\ndesign ensures precise toxicity mitigation while preserving LLMs' general\ncapabilities. To more accurately assess over-editing, we also enhance the\nSafeEdit benchmark by incorporating instruction-following evaluation tasks.\nExperimental results on multiple LLMs demonstrate that our ToxEdit outperforms\nprevious state-of-the-art methods in both detoxification performance and\nsafeguarding general capabilities of LLMs.", "published": "2025-05-28 12:37:06", "link": "http://arxiv.org/abs/2505.22298v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "360-LLaMA-Factory: Plug & Play Sequence Parallelism for Long Post-Training", "abstract": "Adding sequence parallelism into LLaMA-Factory, we open-sourced\n360-LLaMA-Factory at https://github.com/Qihoo360/360-LLaMA-Factory.\n360-LLaMA-Factory has received wide recognition and used in models such as\nLight-R1 arXiv:2503.10460, TinyR1 arXiv:2503.04872, Kaggle AIMO math models and\nalso in large companies' training frameworks. This technical report delves\ndeeper into the different sequence parallel modes behind 360-LLaMA-Factory and\ndiscusses our implementation insights.", "published": "2025-05-28 12:33:46", "link": "http://arxiv.org/abs/2505.22296v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Compensating for Data with Reasoning: Low-Resource Machine Translation with LLMs", "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in\nmultilingual machine translation, sometimes even outperforming traditional\nneural systems. However, previous research has highlighted the challenges of\nusing LLMs, particularly with prompt engineering, for low-resource languages.\nIn this work, we introduce Fragment-Shot Prompting, a novel in-context learning\nmethod that segments input and retrieves translation examples based on\nsyntactic coverage, along with Pivoted Fragment-Shot, an extension that enables\ntranslation without direct parallel data. We evaluate these methods using\nGPT-3.5, GPT-4o, o1-mini, LLaMA-3.3, and DeepSeek-R1 for translation between\nItalian and two Ladin variants, revealing three key findings: (1) Fragment-Shot\nPrompting is effective for translating into and between the studied\nlow-resource languages, with syntactic coverage positively correlating with\ntranslation quality; (2) Models with stronger reasoning abilities make more\neffective use of retrieved knowledge, generally produce better translations,\nand enable Pivoted Fragment-Shot to significantly improve translation quality\nbetween the Ladin variants; and (3) prompt engineering offers limited, if any,\nimprovements when translating from a low-resource to a high-resource language,\nwhere zero-shot prompting already yields satisfactory results. We publicly\nrelease our code and the retrieval corpora.", "published": "2025-05-28 12:29:05", "link": "http://arxiv.org/abs/2505.22293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling", "abstract": "Recent research has highlighted that Large Language Models (LLMs), even when\ntrained to generate extended long reasoning steps, still face significant\nchallenges on hard reasoning problems. However, much of the existing literature\nrelies on direct prompting with simple in-context learning examples for\nevaluation, which largely overlooks advanced techniques to elicit LLMs'\ndeliberate reasoning before drawing conclusions that LLMs hit a performance\nceiling. In this paper, we systematically explore the combined potential of\nin-context search and test-time scaling on super hard reasoning tasks. We find\nthat by employing advanced in-context search prompting to LLMs augmented with\ninternal scaling, one can achieve transformative performance breakthroughs on\ntasks previously deemed \"unsolvable\" (e.g., reported success rates below 5%).\nWe provide both empirical results and theoretical analysis of how this\ncombination can unleash LLM reasoning capabilities: i) Empirically, on\ncontrolled NP-hard tasks and complex real-world planning benchmarks, our\napproach achieves up to a 30x improvement in success rates compared to\npreviously reported results without any external mechanisms; ii) Theoretically,\nwe show that in-context search prompting, when combined with internal scaling,\nsignificantly extends the complexity class of solvable reasoning problems.\nThese findings challenge prevailing assumptions about the limitations of LLMs\non complex tasks, indicating that current evaluation paradigms systematically\nunderestimate their true potential. Our work calls for a critical reassessment\nof how LLM reasoning is benchmarked and a more robust evaluation strategy that\nfully captures the true capabilities of contemporary LLMs, which can lead to a\nbetter understanding of their operational reasoning boundaries in real-world\ndeployments.", "published": "2025-05-28 12:28:18", "link": "http://arxiv.org/abs/2505.22290v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Natural Language Processing in Support of Evidence-based Medicine: A Scoping Review", "abstract": "Evidence-based medicine (EBM) is at the forefront of modern healthcare,\nemphasizing the use of the best available scientific evidence to guide clinical\ndecisions. Due to the sheer volume and rapid growth of medical literature and\nthe high cost of curation, there is a critical need to investigate Natural\nLanguage Processing (NLP) methods to identify, appraise, synthesize, summarize,\nand disseminate evidence in EBM. This survey presents an in-depth review of 129\nresearch studies on leveraging NLP for EBM, illustrating its pivotal role in\nenhancing clinical decision-making processes. The paper systematically explores\nhow NLP supports the five fundamental steps of EBM -- Ask, Acquire, Appraise,\nApply, and Assess. The review not only identifies current limitations within\nthe field but also proposes directions for future research, emphasizing the\npotential for NLP to revolutionize EBM by refining evidence extraction,\nevidence synthesis, appraisal, summarization, enhancing data comprehensibility,\nand facilitating a more efficient clinical workflow.", "published": "2025-05-28 12:17:01", "link": "http://arxiv.org/abs/2505.22280v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comprehensive Evaluation on Lexical Normalization: Boundary-Aware Approaches for Unsegmented Languages", "abstract": "Lexical normalization research has sought to tackle the challenge of\nprocessing informal expressions in user-generated text, yet the absence of\ncomprehensive evaluations leaves it unclear which methods excel across multiple\nperspectives. Focusing on unsegmented languages, we make three key\ncontributions: (1) creating a large-scale, multi-domain Japanese normalization\ndataset, (2) developing normalization methods based on state-of-the-art\npretrained models, and (3) conducting experiments across multiple evaluation\nperspectives. Our experiments show that both encoder-only and decoder-only\napproaches achieve promising results in both accuracy and efficiency.", "published": "2025-05-28 12:02:45", "link": "http://arxiv.org/abs/2505.22273v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Test-Time Immunization: A Universal Defense Framework Against Jailbreaks for (Multimodal) Large Language Models", "abstract": "While (multimodal) large language models (LLMs) have attracted widespread\nattention due to their exceptional capabilities, they remain vulnerable to\njailbreak attacks. Various defense methods are proposed to defend against\njailbreak attacks, however, they are often tailored to specific types of\njailbreak attacks, limiting their effectiveness against diverse adversarial\nstrategies. For instance, rephrasing-based defenses are effective against text\nadversarial jailbreaks but fail to counteract image-based attacks. To overcome\nthese limitations, we propose a universal defense framework, termed Test-time\nIMmunization (TIM), which can adaptively defend against various jailbreak\nattacks in a self-evolving way. Specifically, TIM initially trains a gist token\nfor efficient detection, which it subsequently applies to detect jailbreak\nactivities during inference. When jailbreak attempts are identified, TIM\nimplements safety fine-tuning using the detected jailbreak instructions paired\nwith refusal answers. Furthermore, to mitigate potential performance\ndegradation in the detector caused by parameter updates during safety\nfine-tuning, we decouple the fine-tuning process from the detection module.\nExtensive experiments on both LLMs and multimodal LLMs demonstrate the efficacy\nof TIM.", "published": "2025-05-28 11:57:46", "link": "http://arxiv.org/abs/2505.22271v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps", "abstract": "In this paper we expose our approach to solve the \\textit{SemEval 2025 Task\n8: Question-Answering over Tabular Data} challenge. Our strategy leverages\nPython code generation with LLMs to interact with the table and get the answer\nto the questions. The process is composed of multiple steps: understanding the\ncontent of the table, generating natural language instructions in the form of\nsteps to follow in order to get the answer, translating these instructions to\ncode, running it and handling potential errors or exceptions. These steps use\nopen source LLMs and fine grained optimized prompts for each task (step). With\nthis approach, we achieved a score of $70.50\\%$ for subtask 1.", "published": "2025-05-28 11:50:22", "link": "http://arxiv.org/abs/2505.22264v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Train Sparse Autoencoders Efficiently by Utilizing Features Correlation", "abstract": "Sparse Autoencoders (SAEs) have demonstrated significant promise in\ninterpreting the hidden states of language models by decomposing them into\ninterpretable latent directions. However, training SAEs at scale remains\nchallenging, especially when large dictionary sizes are used. While decoders\ncan leverage sparse-aware kernels for efficiency, encoders still require\ncomputationally intensive linear operations with large output dimensions. To\naddress this, we propose KronSAE, a novel architecture that factorizes the\nlatent representation via Kronecker product decomposition, drastically reducing\nmemory and computational overhead. Furthermore, we introduce mAND, a\ndifferentiable activation function approximating the binary AND operation,\nwhich improves interpretability and performance in our factorized framework.", "published": "2025-05-28 11:41:11", "link": "http://arxiv.org/abs/2505.22255v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition", "abstract": "Recent work suggests that large language models (LLMs) can improve\nperformance of speech tasks compared to existing systems. To support their\nclaims, results on LibriSpeech and Common Voice are often quoted. However, this\nwork finds that a substantial amount of the LibriSpeech and Common Voice\nevaluation sets appear in public LLM pretraining corpora. This calls into\nquestion the reliability of findings drawn from these two datasets. To measure\nthe impact of contamination, LLMs trained with or without contamination are\ncompared, showing that a contaminated LLM is more likely to generate test\nsentences it has seen during training. Speech recognisers using contaminated\nLLMs shows only subtle differences in error rates, but assigns significantly\nhigher probabilities to transcriptions seen during training. Results show that\nLLM outputs can be biased by tiny amounts of data contamination, highlighting\nthe importance of evaluating LLM-based speech systems with held-out data.", "published": "2025-05-28 11:39:59", "link": "http://arxiv.org/abs/2505.22251v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain", "abstract": "Biomedical reasoning often requires traversing interconnected relationships\nacross entities such as drugs, diseases, and proteins. Despite the increasing\nprominence of large language models (LLMs), existing benchmarks lack the\nability to evaluate multi-hop reasoning in the biomedical domain, particularly\nfor queries involving one-to-many and many-to-many relationships. This gap\nleaves the critical challenges of biomedical multi-hop reasoning underexplored.\nTo address this, we introduce BioHopR, a novel benchmark designed to evaluate\nmulti-hop, multi-answer reasoning in structured biomedical knowledge graphs.\nBuilt from the comprehensive PrimeKG, BioHopR includes 1-hop and 2-hop\nreasoning tasks that reflect real-world biomedical complexities.\n  Evaluations of state-of-the-art models reveal that O3-mini, a proprietary\nreasoning-focused model, achieves 37.93% precision on 1-hop tasks and 14.57% on\n2-hop tasks, outperforming proprietary models such as GPT4O and open-source\nbiomedical models including HuatuoGPT-o1-70B and Llama-3.3-70B. However, all\nmodels exhibit significant declines in multi-hop performance, underscoring the\nchallenges of resolving implicit reasoning steps in the biomedical domain. By\naddressing the lack of benchmarks for multi-hop reasoning in biomedical domain,\nBioHopR sets a new standard for evaluating reasoning capabilities and\nhighlights critical gaps between proprietary and open-source models while\npaving the way for future advancements in biomedical LLMs.", "published": "2025-05-28 11:19:01", "link": "http://arxiv.org/abs/2505.22240v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Linguistically Motivated Analysis of Intonational Phrasing in Text-to-Speech Systems: Revealing Gaps in Syntactic Sensitivity", "abstract": "We analyze the syntactic sensitivity of Text-to-Speech (TTS) systems using\nmethods inspired by psycholinguistic research. Specifically, we focus on the\ngeneration of intonational phrase boundaries, which can often be predicted by\nidentifying syntactic boundaries within a sentence. We find that TTS systems\nstruggle to accurately generate intonational phrase boundaries in sentences\nwhere syntactic boundaries are ambiguous (e.g., garden path sentences or\nsentences with attachment ambiguity). In these cases, systems need superficial\ncues such as commas to place boundaries at the correct positions. In contrast,\nfor sentences with simpler syntactic structures, we find that systems do\nincorporate syntactic cues beyond surface markers. Finally, we finetune models\non sentences without commas at the syntactic boundary positions, encouraging\nthem to focus on more subtle linguistic cues. Our findings indicate that this\nleads to more distinct intonation patterns that better reflect the underlying\nstructure.", "published": "2025-05-28 11:11:29", "link": "http://arxiv.org/abs/2505.22236v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Judging Quality Across Languages: A Multilingual Approach to Pretraining Data Filtering with Language Models", "abstract": "High-quality multilingual training data is essential for effectively\npretraining large language models (LLMs). Yet, the availability of suitable\nopen-source multilingual datasets remains limited. Existing state-of-the-art\ndatasets mostly rely on heuristic filtering methods, restricting both their\ncross-lingual transferability and scalability. Here, we introduce JQL, a\nsystematic approach that efficiently curates diverse and high-quality\nmultilingual data at scale while significantly reducing computational demands.\nJQL distills LLMs' annotation capabilities into lightweight annotators based on\npretrained multilingual embeddings. These models exhibit robust multilingual\nand cross-lingual performance, even for languages and scripts unseen during\ntraining. Evaluated empirically across 35 languages, the resulting annotation\npipeline substantially outperforms current heuristic filtering methods like\nFineweb2. JQL notably enhances downstream model training quality and increases\ndata retention rates. Our research provides practical insights and valuable\nresources for multilingual data curation, raising the standards of multilingual\ndataset development.", "published": "2025-05-28 11:06:54", "link": "http://arxiv.org/abs/2505.22232v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Advancing Hearing Assessment: An ASR-Based Frequency-Specific Speech Test for Diagnosing Presbycusis", "abstract": "Traditional audiometry often fails to fully characterize the functional\nimpact of hearing loss on speech understanding, particularly supra-threshold\ndeficits and frequency-specific perception challenges in conditions like\npresbycusis. This paper presents the development and simulated evaluation of a\nnovel Automatic Speech Recognition (ASR)-based frequency-specific speech test\ndesigned to provide granular diagnostic insights. Our approach leverages ASR to\nsimulate the perceptual effects of moderate sloping hearing loss by processing\nspeech stimuli under controlled acoustic degradation and subsequently analyzing\nphoneme-level confusion patterns. Key findings indicate that simulated hearing\nloss introduces specific phoneme confusions, predominantly affecting\nhigh-frequency consonants (e.g., alveolar/palatal to labiodental substitutions)\nand leading to significant phoneme deletions, consistent with the acoustic cues\ndegraded in presbycusis. A test battery curated from these ASR-derived\nconfusions demonstrated diagnostic value, effectively differentiating between\nsimulated normal-hearing and hearing-impaired listeners in a comprehensive\nsimulation. This ASR-driven methodology offers a promising avenue for\ndeveloping objective, granular, and frequency-specific hearing assessment tools\nthat complement traditional audiometry. Future work will focus on validating\nthese findings with human participants and exploring the integration of\nadvanced AI models for enhanced diagnostic precision.", "published": "2025-05-28 11:06:22", "link": "http://arxiv.org/abs/2505.22231v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation", "abstract": "Recent advancements in multimodal Large Language Models (LLMs) have\nsignificantly enhanced the automation of medical image analysis, particularly\nin generating radiology reports from chest X-rays (CXR). However, these models\nstill suffer from hallucinations and clinically significant errors, limiting\ntheir reliability in real-world applications. In this study, we propose Look &\nMark (L&M), a novel grounding fixation strategy that integrates radiologist eye\nfixations (Look) and bounding box annotations (Mark) into the LLM prompting\nframework. Unlike conventional fine-tuning, L&M leverages in-context learning\nto achieve substantial performance gains without retraining. When evaluated\nacross multiple domain-specific and general-purpose models, L&M demonstrates\nsignificant gains, including a 1.2% improvement in overall metrics (A.AVG) for\nCXR-LLaVA compared to baseline prompting and a remarkable 9.2% boost for\nLLaVA-Med. General-purpose models also benefit from L&M combined with\nin-context learning, with LLaVA-OV achieving an 87.3% clinical average\nperformance (C.AVG)-the highest among all models, even surpassing those\nexplicitly trained for CXR report generation. Expert evaluations further\nconfirm that L&M reduces clinically significant errors (by 0.43 average errors\nper report), such as false predictions and omissions, enhancing both accuracy\nand reliability. These findings highlight L&M's potential as a scalable and\nefficient solution for AI-assisted radiology, paving the way for improved\ndiagnostic workflows in low-resource clinical settings.", "published": "2025-05-28 10:54:40", "link": "http://arxiv.org/abs/2505.22222v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Pitfalls of Rule- and Model-based Verifiers -- A Case Study on Mathematical Reasoning", "abstract": "Trustworthy verifiers are essential for the success of reinforcement learning\nwith verifiable reward (RLVR), which is the core methodology behind various\nlarge reasoning models such as DeepSeek-R1. In complex domains like\nmathematical reasoning, rule-based verifiers have been widely adopted in\nprevious works to train strong reasoning models. However, the reliability of\nthese verifiers and their impact on the RL training process remain poorly\nunderstood. In this work, we take mathematical reasoning as a case study and\nconduct a comprehensive analysis of various verifiers in both static evaluation\nand RL training scenarios. First, we find that current open-source rule-based\nverifiers often fail to recognize equivalent answers presented in different\nformats across multiple commonly used mathematical datasets, resulting in\nnon-negligible false negative rates. This limitation adversely affects RL\ntraining performance and becomes more pronounced as the policy model gets\nstronger. Subsequently, we investigate model-based verifiers as a potential\nsolution to address these limitations. While the static evaluation shows that\nmodel-based verifiers achieve significantly higher verification accuracy,\nfurther analysis and RL training results imply that they are highly susceptible\nto hacking, where they misclassify certain patterns in responses as correct\n(i.e., false positives). This vulnerability is exploited during policy model\noptimization, leading to artificially inflated rewards. Our findings underscore\nthe unique risks inherent to both rule-based and model-based verifiers, aiming\nto offer valuable insights to develop more robust reward systems in\nreinforcement learning.", "published": "2025-05-28 10:28:41", "link": "http://arxiv.org/abs/2505.22203v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Let's Predict Sentence by Sentence", "abstract": "Autoregressive language models (LMs) generate one token at a time, yet human\nreasoning operates over higher-level abstractions - sentences, propositions,\nand concepts. This contrast raises a central question- Can LMs likewise learn\nto reason over structured semantic units rather than raw token sequences? In\nthis work, we investigate whether pretrained LMs can be lifted into such\nabstract reasoning spaces by building on their learned representations. We\npresent a framework that adapts a pretrained token-level LM to operate in\nsentence space by autoregressively predicting continuous embeddings of next\nsentences. We explore two embedding paradigms inspired by classical\nrepresentation learning: 1) semantic embeddings, learned via autoencoding to\npreserve surface meaning; and 2) contextual embeddings, trained via\nnext-sentence prediction to encode anticipatory structure. We evaluate both\nunder two inference regimes: Discretized, which decodes each predicted\nembedding into text before re-encoding; and Continuous, which reasons entirely\nin embedding space for improved efficiency. Across four domains - mathematics,\nlogic, commonsense, and planning - contextual embeddings under continuous\ninference show competitive performance with Chain-of-Thought (CoT) while\nreducing inference-time FLOPs on average by half. We also present early signs\nof scalability and modular adaptation. Finally, to visualize latent\ntrajectories, we introduce SentenceLens, a diagnostic tool that decodes\nintermediate model states into interpretable sentences. Together, our results\nindicate that pretrained LMs can effectively transition to abstract, structured\nreasoning within latent embedding spaces.", "published": "2025-05-28 10:28:35", "link": "http://arxiv.org/abs/2505.22202v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Breaking the Cloak! Unveiling Chinese Cloaked Toxicity with Homophone Graph and Toxic Lexicon", "abstract": "Social media platforms have experienced a significant rise in toxic content,\nincluding abusive language and discriminatory remarks, presenting growing\nchallenges for content moderation. Some users evade censorship by deliberately\ndisguising toxic words through homophonic cloak, which necessitates the task of\nunveiling cloaked toxicity. Existing methods are mostly designed for English\ntexts, while Chinese cloaked toxicity unveiling has not been solved yet. To\ntackle the issue, we propose C$^2$TU, a novel training-free and prompt-free\nmethod for Chinese cloaked toxic content unveiling. It first employs substring\nmatching to identify candidate toxic words based on Chinese homo-graph and\ntoxic lexicon. Then it filters those candidates that are non-toxic and corrects\ncloaks to be their corresponding toxicities. Specifically, we develop two model\nvariants for filtering, which are based on BERT and LLMs, respectively. For\nLLMs, we address the auto-regressive limitation in computing word occurrence\nprobability and utilize the full semantic contexts of a text sequence to reveal\ncloaked toxic words. Extensive experiments demonstrate that C$^2$TU can achieve\nsuperior performance on two Chinese toxic datasets. In particular, our method\noutperforms the best competitor by up to 71% on the F1 score and 35% on\naccuracy, respectively.", "published": "2025-05-28 09:58:15", "link": "http://arxiv.org/abs/2505.22184v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design", "abstract": "Speculative decoding and quantization effectively accelerate memory-bound\ninference of large language models. Speculative decoding mitigates the memory\nbandwidth bottleneck by verifying multiple tokens within a single forward pass,\nwhich increases computational effort. Quantization achieves this optimization\nby compressing weights and activations into lower bit-widths and also reduces\ncomputations via low-bit matrix multiplications. To further leverage their\nstrengths, we investigate the integration of these two techniques.\nSurprisingly, experiments applying the advanced speculative decoding method\nEAGLE-2 to various quantized models reveal that the memory benefits from 4-bit\nweight quantization are diminished by the computational load from speculative\ndecoding. Specifically, verifying a tree-style draft incurs significantly more\ntime overhead than a single-token forward pass on 4-bit weight quantized\nmodels. This finding led to our new speculative decoding design: a hierarchical\nframework that employs a small model as an intermediate stage to turn\ntree-style drafts into sequence drafts, leveraging the memory access benefits\nof the target quantized model. Experimental results show that our hierarchical\napproach achieves a 2.78$\\times$ speedup across various tasks for the 4-bit\nweight Llama-3-70B model on an A100 GPU, outperforming EAGLE-2 by 1.31$\\times$.\nCode available at https://github.com/AI9Stars/SpecMQuant.", "published": "2025-05-28 09:55:08", "link": "http://arxiv.org/abs/2505.22179v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation", "abstract": "Evaluating tables qualitatively & quantitatively presents a significant\nchallenge, as traditional metrics often fail to capture nuanced structural and\ncontent discrepancies. To address this, we introduce a novel, methodical rubric\nintegrating multi-level structural descriptors with fine-grained contextual\nquantification, thereby establishing a robust foundation for comprehensive\ntable comparison. Building on this foundation, we propose TabXEval, an\neXhaustive and eXplainable two-phase evaluation framework. TabXEval initially\naligns reference tables structurally via TabAlign & subsequently conducts a\nsystematic semantic and syntactic comparison using TabCompare; this approach\nclarifies the evaluation process and pinpoints subtle discrepancies overlooked\nby conventional methods. The efficacy of this framework is assessed using\nTabXBench, a novel, diverse, multi-domain benchmark we developed, featuring\nrealistic table perturbations and human-annotated assessments. Finally, a\nsystematic analysis of existing evaluation methods through\nsensitivity-specificity trade-offs demonstrates the qualitative and\nquantitative effectiveness of TabXEval across diverse table-related tasks and\ndomains, paving the way for future innovations in explainable table evaluation.", "published": "2025-05-28 09:50:29", "link": "http://arxiv.org/abs/2505.22176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reverse Preference Optimization for Complex Instruction Following", "abstract": "Instruction following (IF) is a critical capability for large language models\n(LLMs). However, handling complex instructions with multiple constraints\nremains challenging. Previous methods typically select preference pairs based\non the number of constraints they satisfy, introducing noise where chosen\nexamples may fail to follow some constraints and rejected examples may excel in\ncertain respects over the chosen ones. To address the challenge of aligning\nwith multiple preferences, we propose a simple yet effective method called\nReverse Preference Optimization (RPO). It mitigates noise in preference pairs\nby dynamically reversing the constraints within the instruction to ensure the\nchosen response is perfect, alleviating the burden of extensive sampling and\nfiltering to collect perfect responses. Besides, reversal also enlarges the gap\nbetween chosen and rejected responses, thereby clarifying the optimization\ndirection and making it more robust to noise. We evaluate RPO on two multi-turn\nIF benchmarks, Sysbench and Multi-IF, demonstrating average improvements over\nthe DPO baseline of 4.6 and 2.5 points (on Llama-3.1 8B), respectively.\nMoreover, RPO scales effectively across model sizes (8B to 70B parameters),\nwith the 70B RPO model surpassing GPT-4o.", "published": "2025-05-28 09:44:27", "link": "http://arxiv.org/abs/2505.22172v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments", "abstract": "LLMs are highly sensitive to prompt phrasing, yet standard benchmarks\ntypically report performance using a single prompt, raising concerns about the\nreliability of such evaluations. In this work, we argue for a stochastic method\nof moments evaluation over the space of meaning-preserving prompt\nperturbations. We introduce a formal definition of reliable evaluation that\naccounts for prompt sensitivity, and suggest ReliableEval - a method for\nestimating the number of prompt resamplings needed to obtain meaningful\nresults. Using our framework, we stochastically evaluate five frontier LLMs and\nfind that even top-performing models like GPT-4o and Claude-3.7-Sonnet exhibit\nsubstantial prompt sensitivity. Our approach is model-, task-, and\nmetric-agnostic, offering a recipe for meaningful and robust LLM evaluation.", "published": "2025-05-28 09:40:48", "link": "http://arxiv.org/abs/2505.22169v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes", "abstract": "Diffusion models have emerged as a promising approach for text generation,\nwith recent works falling into two main categories: discrete and continuous\ndiffusion models. Discrete diffusion models apply token corruption\nindependently using categorical distributions, allowing for different diffusion\nprogress across tokens but lacking fine-grained control. Continuous diffusion\nmodels map tokens to continuous spaces and apply fine-grained noise, but the\ndiffusion progress is uniform across tokens, limiting their ability to capture\nsemantic nuances. To address these limitations, we propose\n\\textbf{\\underline{N}}on-simultan\\textbf{\\underline{e}}ous\nC\\textbf{\\underline{o}}ntinuous \\textbf{\\underline{Diff}}usion Models\n(NeoDiff), a novel diffusion model that integrates the strengths of both\ndiscrete and continuous approaches. NeoDiff introduces a Poisson diffusion\nprocess for the forward process, enabling a flexible and fine-grained noising\nparadigm, and employs a time predictor for the reverse process to adaptively\nmodulate the denoising progress based on token semantics. Furthermore, NeoDiff\nutilizes an optimized schedule for inference to ensure more precise noise\ncontrol and improved performance. Our approach unifies the theories of discrete\nand continuous diffusion models, offering a more principled and effective\nframework for text generation. Experimental results on several text generation\ntasks demonstrate NeoDiff's superior performance compared to baselines of\nnon-autoregressive continuous and discrete diffusion models, iterative-based\nmethods and autoregressive diffusion-based methods. These results highlight\nNeoDiff's potential as a powerful tool for generating high-quality text and\nadvancing the field of diffusion-based text generation.", "published": "2025-05-28 09:28:52", "link": "http://arxiv.org/abs/2505.22165v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Stratified Selective Sampling for Instruction Tuning with Dedicated Scoring Strategy", "abstract": "Recent work shows that post-training datasets for LLMs can be substantially\ndownsampled without noticeably deteriorating performance. However, data\nselection often incurs high computational costs or is limited to narrow\ndomains. In this paper, we demonstrate that data selection can be both --\nefficient and universal -- by using a multi-step pipeline in which we\nefficiently bin data points into groups, estimate quality using specialized\nmodels, and score difficulty with a robust, lightweight method. Task-based\ncategorization allows us to control the composition of our final data --\ncrucial for finetuning multi-purpose models. To guarantee diversity, we improve\nupon previous work using embedding models and a clustering algorithm. This\nintegrated strategy enables high-performance fine-tuning with minimal overhead.", "published": "2025-05-28 09:22:25", "link": "http://arxiv.org/abs/2505.22157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InComeS: Integrating Compression and Selection Mechanisms into LLMs for Efficient Model Editing", "abstract": "Although existing model editing methods perform well in recalling exact edit\nfacts, they often struggle in complex scenarios that require deeper semantic\nunderstanding rather than mere knowledge regurgitation. Leveraging the strong\ncontextual reasoning abilities of large language models (LLMs), in-context\nlearning (ICL) becomes a promising editing method by comprehending edit\ninformation through context encoding. However, this method is constrained by\nthe limited context window of LLMs, leading to degraded performance and\nefficiency as the number of edits increases. To overcome this limitation, we\npropose InComeS, a flexible framework that enhances LLMs' ability to process\nediting contexts through explicit compression and selection mechanisms.\nSpecifically, InComeS compresses each editing context into the key-value (KV)\ncache of a special gist token, enabling efficient handling of multiple edits\nwithout being restricted by the model's context window. Furthermore,\nspecialized cross-attention modules are added to dynamically select the most\nrelevant information from the gist pools, enabling adaptive and effective\nutilization of edit information. We conduct experiments on diverse model\nediting benchmarks with various editing formats, and the results demonstrate\nthe effectiveness and efficiency of our method.", "published": "2025-05-28 09:20:18", "link": "http://arxiv.org/abs/2505.22156v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging", "abstract": "Brain-to-Image reconstruction aims to recover visual stimuli perceived by\nhumans from brain activity. However, the reconstructed visual stimuli often\nmissing details and semantic inconsistencies, which may be attributed to\ninsufficient semantic information. To address this issue, we propose an\napproach named Fine-grained Brain-to-Image reconstruction (FgB2I), which\nemploys fine-grained text as bridge to improve image reconstruction. FgB2I\ncomprises three key stages: detail enhancement, decoding fine-grained text\ndescriptions, and text-bridged brain-to-image reconstruction. In the\ndetail-enhancement stage, we leverage large vision-language models to generate\nfine-grained captions for visual stimuli and experimentally validate its\nimportance. We propose three reward metrics (object accuracy, text-image\nsemantic similarity, and image-image semantic similarity) to guide the language\nmodel in decoding fine-grained text descriptions from fMRI signals. The\nfine-grained text descriptions can be integrated into existing reconstruction\nmethods to achieve fine-grained Brain-to-Image reconstruction.", "published": "2025-05-28 09:16:44", "link": "http://arxiv.org/abs/2505.22150v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Flexible Tool Selection through Low-dimensional Attribute Alignment of Vision and Language", "abstract": "Flexible tool selection reflects a complex cognitive ability that\ndistinguishes humans from other species, yet computational models that capture\nthis ability remain underdeveloped. We developed a framework using\nlow-dimensional attribute representations to bridge visual tool perception and\nlinguistic task understanding. We constructed a comprehensive dataset (ToolNet)\ncontaining 115 common tools labeled with 13 carefully designed attributes\nspanning physical, functional, and psychological properties, paired with\nnatural language scenarios describing tool usage. Visual encoders (ResNet or\nViT) extract attributes from tool images while fine-tuned language models\n(GPT-2, LLaMA, DeepSeek) derive required attributes from task descriptions. Our\napproach achieves 74% accuracy in tool selection tasks-significantly\noutperforming direct tool matching (20%) and smaller multimodal models\n(21%-58%), while approaching performance of much larger models like GPT-4o\n(73%) with substantially fewer parameters. Ablation studies revealed that\nmanipulation-related attributes (graspability, hand-relatedness, elongation)\nconsistently prove most critical across modalities. This work provides a\nparameter-efficient, interpretable solution that mimics human-like tool\ncognition, advancing both cognitive science understanding and practical\napplications in tool selection tasks.", "published": "2025-05-28 09:06:04", "link": "http://arxiv.org/abs/2505.22146v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "q-bio.NC"], "primary_category": "cs.CV"}
{"title": "Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments", "abstract": "Identifying arguments is a necessary prerequisite for various tasks in\nautomated discourse analysis, particularly within contexts such as political\ndebates, online discussions, and scientific reasoning. In addition to\ntheoretical advances in understanding the constitution of arguments, a\nsignificant body of research has emerged around practical argument mining,\nsupported by a growing number of publicly available datasets. On these\nbenchmarks, BERT-like transformers have consistently performed best,\nreinforcing the belief that such models are broadly applicable across diverse\ncontexts of debate. This study offers the first large-scale re-evaluation of\nsuch state-of-the-art models, with a specific focus on their ability to\ngeneralize in identifying arguments. We evaluate four transformers, three\nstandard and one enhanced with contrastive pre-training for better\ngeneralization, on 17 English sentence-level datasets as most relevant to the\ntask. Our findings show that, to varying degrees, these models tend to rely on\nlexical shortcuts tied to content words, suggesting that apparent progress may\noften be driven by dataset-specific cues rather than true task alignment. While\nthe models achieve strong results on familiar benchmarks, their performance\ndrops markedly when applied to unseen datasets. Nonetheless, incorporating both\ntask-specific pre-training and joint benchmark training proves effective in\nenhancing both robustness and generalization.", "published": "2025-05-28 09:00:56", "link": "http://arxiv.org/abs/2505.22137v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding", "abstract": "Hybrid models combining Transformers and State Space Models (SSMs) are\npromising for balancing performance and efficiency. However, optimizing these\nhybrid models, particularly by addressing the potential redundancy inherent\nwithin the Transformer components, remains a significant challenge. In this\npaper, we propose RAD (Redundancy-Aware Distillation), a novel framework that\nuses self-speculative decoding as a diagnostic tool to identify redundant\nattention layers within the model. These identified layers are then selectively\nreplaced with SSM components, followed by targeted (self-)distillation.\nSpecifically, RAD focuses knowledge transfer on the components identified as\nredundant, considering architectural changes and specific weight initialization\nstrategies. We experimentally demonstrate that self-distillation using RAD\nsignificantly surpasses the performance of the original base model on\nmathematical and coding tasks. Furthermore, RAD is also effective in standard\nknowledge distillation settings, achieving up to approximately 2x faster\nconvergence compared to baseline methods. Notably, while a baseline model\ndistilled from a Llama-3.1 70B teacher achieves scores of 46.17 on GSM8K and\n22.75 on CRUX, RAD achieves significantly higher scores of 71.27 on GSM8K and\n28.25 on CRUX, even when using a much smaller Llama-3.1 8B teacher. RAD offers\na new pathway for efficient optimization and performance enhancement in the\ndistillation of hybrid models.", "published": "2025-05-28 08:59:02", "link": "http://arxiv.org/abs/2505.22135v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EULER: Enhancing the Reasoning Ability of Large Language Models through Error-Induced Learning", "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities\nand achieved promising results in mathematical problem-solving tasks. Learning\nfrom errors offers the potential to further enhance the performance of LLMs\nduring Supervised Fine-Tuning (SFT). However, the errors in synthesized\nsolutions are typically gathered from sampling trails, making it challenging to\ngenerate solution errors for each mathematical problem. This paper introduces\nthe Error-IndUced LEaRning (EULER) model, which aims to develop an error\nexposure model that generates high-quality solution errors to enhance the\nmathematical reasoning capabilities of LLMs. Specifically, EULER optimizes the\nerror exposure model to increase the generation probability of self-made\nsolution errors while utilizing solutions produced by a superior LLM to\nregularize the generation quality. Our experiments across various mathematical\nproblem datasets demonstrate the effectiveness of the EULER model, achieving an\nimprovement of over 4% compared to all baseline models. Further analysis\nreveals that EULER is capable of synthesizing more challenging and educational\nsolution errors, which facilitate both the training and inference processes of\nLLMs. All codes are available at https://github.com/NEUIR/EULER.", "published": "2025-05-28 08:57:03", "link": "http://arxiv.org/abs/2505.22131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LoKI: Low-damage Knowledge Implanting of Large Language Models", "abstract": "Fine-tuning adapts pretrained models for specific tasks but poses the risk of\ncatastrophic forgetting (CF), where critical knowledge from pre-training is\noverwritten. Current Parameter-Efficient Fine-Tuning (PEFT) methods for Large\nLanguage Models (LLMs), while efficient, often sacrifice general capabilities.\nTo address the issue of CF in a general-purpose PEFT framework, we propose\n\\textbf{Lo}w-damage \\textbf{K}nowledge \\textbf{I}mplanting (\\textbf{LoKI}), a\nPEFT technique that is based on a mechanistic understanding of how knowledge is\nstored in transformer architectures. In two real-world scenarios, LoKI\ndemonstrates task-specific performance that is comparable to or even surpasses\nthat of full fine-tuning and LoRA-based methods across various model types,\nwhile significantly better preserving general capabilities. Our work connects\nmechanistic insights into LLM knowledge storage with practical fine-tuning\nobjectives, achieving state-of-the-art trade-offs between task specialization\nand the preservation of general capabilities. Our implementation is publicly\navailable as ready-to-use code\\footnote{https://github.com/Nexround/LoKI}.", "published": "2025-05-28 08:47:26", "link": "http://arxiv.org/abs/2505.22120v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual vs Crosslingual Retrieval of Fact-Checked Claims: A Tale of Two Approaches", "abstract": "Retrieval of previously fact-checked claims is a well-established task, whose\nautomation can assist professional fact-checkers in the initial steps of\ninformation verification. Previous works have mostly tackled the task\nmonolingually, i.e., having both the input and the retrieved claims in the same\nlanguage. However, especially for languages with a limited availability of\nfact-checks and in case of global narratives, such as pandemics, wars, or\ninternational politics, it is crucial to be able to retrieve claims across\nlanguages. In this work, we examine strategies to improve the multilingual and\ncrosslingual performance, namely selection of negative examples (in the\nsupervised) and re-ranking (in the unsupervised setting). We evaluate all\napproaches on a dataset containing posts and claims in 47 languages (283\nlanguage combinations). We observe that the best results are obtained by using\nLLM-based re-ranking, followed by fine-tuning with negative examples sampled\nusing a sentence similarity-based strategy. Most importantly, we show that\ncrosslinguality is a setup with its own unique characteristics compared to the\nmultilingual setup.", "published": "2025-05-28 08:47:10", "link": "http://arxiv.org/abs/2505.22118v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model", "abstract": "Intraoperative hypotension (IOH) frequently occurs under general anesthesia\nand is strongly linked to adverse outcomes such as myocardial injury and\nincreased mortality. Despite its significance, IOH prediction is hindered by\nevent sparsity and the challenge of integrating static and dynamic data across\ndiverse patients. In this paper, we propose \\textbf{IOHFuseLM}, a multimodal\nlanguage model framework. To accurately identify and differentiate sparse\nhypotensive events, we leverage a two-stage training strategy. The first stage\ninvolves domain adaptive pretraining on IOH physiological time series augmented\nthrough diffusion methods, thereby enhancing the model sensitivity to patterns\nassociated with hypotension. Subsequently, task fine-tuning is performed on the\noriginal clinical dataset to further enhance the ability to distinguish\nnormotensive from hypotensive states. To enable multimodal fusion for each\npatient, we align structured clinical descriptions with the corresponding\nphysiological time series at the token level. Such alignment enables the model\nto capture individualized temporal patterns alongside their corresponding\nclinical semantics. In addition, we convert static patient attributes into\nstructured text to enrich personalized information. Experimental evaluations on\ntwo intraoperative datasets demonstrate that IOHFuseLM outperforms established\nbaselines in accurately identifying IOH events, highlighting its applicability\nin clinical decision support scenarios. Our code is publicly available to\npromote reproducibility at https://github.com/zjt-gpu/IOHFuseLM.", "published": "2025-05-28 08:44:55", "link": "http://arxiv.org/abs/2505.22116v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "THINK-Bench: Evaluating Thinking Efficiency and Chain-of-Thought Quality of Large Reasoning Models", "abstract": "Large reasoning models (LRMs) have achieved impressive performance in complex\ntasks, often outperforming conventional large language models (LLMs). However,\nthe prevalent issue of overthinking severely limits their computational\nefficiency. Overthinking occurs when models generate excessive and redundant\ntokens that contribute little to accurate outcomes, especially in simple tasks,\nresulting in a significant waste of computational resources. To systematically\ninvestigate this issue, we introduce Think-Bench, a benchmark designed to\nevaluate the reasoning efficiency of LRMs. We also propose novel efficiency\nmetrics and conduct a comprehensive evaluation of various LRMs across multiple\ndimensions, including the reasoning process, outcome quality, and\nchain-of-thought (CoT) characteristics. Our analysis reveals that most LRMs\nexhibit overthinking in handling easy questions, generating unnecessarily\nlengthy reasoning chains. While many LRMs demonstrate high CoT quality, several\nsuffer from low efficiency. We hope that Think-Bench can serve as a robust\nfoundation for advancing research into LRMs.", "published": "2025-05-28 08:41:14", "link": "http://arxiv.org/abs/2505.22113v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "abstract": "Transformer-based large language models (LLMs) excel in natural language\nprocessing tasks by capturing long-range dependencies through self-attention\nmechanisms. However, long-context modeling faces significant computational\ninefficiencies due to \\textit{redundant} attention computations: while\nattention weights are often \\textit{sparse}, all tokens consume \\textit{equal}\ncomputational resources. In this paper, we reformulate traditional\nprobabilistic sequence modeling as a \\textit{supervised learning task},\nenabling the separation of relevant and irrelevant tokens and providing a\nclearer understanding of redundancy. Based on this reformulation, we\ntheoretically analyze attention sparsity, revealing that only a few tokens\nsignificantly contribute to predictions. Building on this, we formulate\nattention optimization as a linear coding problem and propose a \\textit{group\ncoding strategy}, theoretically showing its ability to improve robustness\nagainst random noise and enhance learning efficiency. Motivated by this, we\npropose \\textit{Dynamic Group Attention} (DGA), which leverages the group\ncoding to explicitly reduce redundancy by aggregating less important tokens\nduring attention computation. Empirical results show that our DGA significantly\nreduces computational costs while maintaining competitive performance.Code is\navailable at https://github.com/bolixinyu/DynamicGroupAttention.", "published": "2025-05-28 08:34:46", "link": "http://arxiv.org/abs/2505.22107v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models", "abstract": "Large Language Models (LLMs) have emerged as foundational infrastructure in\nthe pursuit of Artificial General Intelligence (AGI). Despite their remarkable\ncapabilities in language perception and generation, current LLMs fundamentally\nlack a unified and structured architecture for handling memory. They primarily\nrely on parametric memory (knowledge encoded in model weights) and ephemeral\nactivation memory (context-limited runtime states). While emerging methods like\nRetrieval-Augmented Generation (RAG) incorporate plaintext memory, they lack\nlifecycle management and multi-modal integration, limiting their capacity for\nlong-term knowledge evolution. To address this, we introduce MemOS, a memory\noperating system designed for LLMs that, for the first time, elevates memory to\na first-class operational resource. It builds unified mechanisms for\nrepresentation, organization, and governance across three core memory types:\nparametric, activation, and plaintext. At its core is the MemCube, a\nstandardized memory abstraction that enables tracking, fusion, and migration of\nheterogeneous memory, while offering structured, traceable access across tasks\nand contexts. MemOS establishes a memory-centric execution framework with\nstrong controllability, adaptability, and evolvability. It fills a critical gap\nin current LLM infrastructure and lays the groundwork for continual adaptation,\npersonalized intelligence, and cross-platform coordination in next-generation\nintelligent systems.", "published": "2025-05-28 08:27:12", "link": "http://arxiv.org/abs/2505.22101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Base Construction for Knowledge-Augmented Text-to-SQL", "abstract": "Text-to-SQL aims to translate natural language queries into SQL statements,\nwhich is practical as it enables anyone to easily retrieve the desired\ninformation from databases. Recently, many existing approaches tackle this\nproblem with Large Language Models (LLMs), leveraging their strong capability\nin understanding user queries and generating corresponding SQL code. Yet, the\nparametric knowledge in LLMs might be limited to covering all the diverse and\ndomain-specific queries that require grounding in various database schemas,\nwhich makes generated SQLs less accurate oftentimes. To tackle this, we propose\nconstructing the knowledge base for text-to-SQL, a foundational source of\nknowledge, from which we retrieve and generate the necessary knowledge for\ngiven queries. In particular, unlike existing approaches that either manually\nannotate knowledge or generate only a few pieces of knowledge for each query,\nour knowledge base is comprehensive, which is constructed based on a\ncombination of all the available questions and their associated database\nschemas along with their relevant knowledge, and can be reused for unseen\ndatabases from different datasets and domains. We validate our approach on\nmultiple text-to-SQL datasets, considering both the overlapping and\nnon-overlapping database scenarios, where it outperforms relevant baselines\nsubstantially.", "published": "2025-05-28 08:17:58", "link": "http://arxiv.org/abs/2505.22096v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning", "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) has shown promise in\nmitigating hallucinations in Multimodal Large Language Models (MLLMs) by\nincorporating external knowledge during generation. Existing MRAG methods\ntypically adopt a static retrieval pipeline that fetches relevant information\nfrom multiple Knowledge Bases (KBs), followed by a refinement step. However,\nthese approaches overlook the reasoning and planning capabilities of MLLMs to\ndynamically determine how to interact with different KBs during the reasoning\nprocess. To address this limitation, we propose R1-Router, a novel MRAG\nframework that learns to decide when and where to retrieve knowledge based on\nthe evolving reasoning state. Specifically, R1-Router can generate follow-up\nqueries according to the current reasoning step, routing these intermediate\nqueries to the most suitable KB, and integrating external knowledge into a\ncoherent reasoning trajectory to answer the original query. Furthermore, we\nintroduce Step-wise Group Relative Policy Optimization (Step-GRPO), a tailored\nreinforcement learning algorithm that assigns step-specific rewards to optimize\nthe reasoning behavior of MLLMs. Experimental results on various open-domain QA\nbenchmarks across multiple modalities demonstrate that R1-Router outperforms\nbaseline models by over 7%. Further analysis shows that R1-Router can\nadaptively and effectively leverage diverse KBs, reducing unnecessary\nretrievals and improving both efficiency and accuracy.", "published": "2025-05-28 08:17:57", "link": "http://arxiv.org/abs/2505.22095v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual Cues Support Robust Turn-taking Prediction in Noise", "abstract": "Accurate predictive turn-taking models (PTTMs) are essential for naturalistic\nhuman-robot interaction. However, little is known about their performance in\nnoise. This study therefore explores PTTM performance in types of noise likely\nto be encountered once deployed. Our analyses reveal PTTMs are highly sensitive\nto noise. Hold/shift accuracy drops from 84% in clean speech to just 52% in 10\ndB music noise. Training with noisy data enables a multimodal PTTM, which\nincludes visual features to better exploit visual cues, with 72% accuracy in 10\ndB music noise. The multimodal PTTM outperforms the audio-only PTTM across all\nnoise types and SNRs, highlighting its ability to exploit visual cues; however,\nthis does not always generalise to new types of noise. Analysis also reveals\nthat successful training relies on accurate transcription, limiting the use of\nASR-derived transcriptions to clean conditions. We make code publicly available\nfor future research.", "published": "2025-05-28 08:11:13", "link": "http://arxiv.org/abs/2505.22088v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation", "abstract": "Training large language models (LLMs) to follow instructions has\nsignificantly enhanced their ability to tackle unseen tasks. However, despite\ntheir strong generalization capabilities, instruction-following LLMs encounter\ndifficulties when dealing with tasks that require domain knowledge. This work\nintroduces a specialized instruction fine-tuning for the domain of\ncomputational argumentation (CA). The goal is to enable an LLM to effectively\ntackle any unseen CA tasks while preserving its generalization capabilities.\nReviewing existing CA research, we crafted natural language instructions for\n105 CA tasks to this end. On this basis, we developed a CA-specific benchmark\nfor LLMs that allows for a comprehensive evaluation of LLMs' capabilities in\nsolving various CA tasks. We synthesized 52k CA-related instructions, adapting\nthe self-instruct process to train a CA-specialized instruction-following LLM.\nOur experiments suggest that CA-specialized instruction fine-tuning\nsignificantly enhances the LLM on both seen and unseen CA tasks. At the same\ntime, performance on the general NLP tasks of the SuperNI benchmark remains\nstable.", "published": "2025-05-28 07:58:29", "link": "http://arxiv.org/abs/2505.22076v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond path selection: Better LLMs for Scientific Information Extraction with MimicSFT and Relevance and Rule-induced(R$^2$)GRPO", "abstract": "Previous study suggest that powerful Large Language Models (LLMs) trained\nwith Reinforcement Learning with Verifiable Rewards (RLVR) only refines\nreasoning path without improving the reasoning capacity in math tasks while\nsupervised-finetuning(SFT) with distillation can. We study this from the view\nof Scientific information extraction (SciIE) where LLMs and reasoning LLMs\nunderperforms small Bert-based models. SciIE require both the reasoning and\nmemorization. We argue that both SFT and RLVR can refine the reasoning path and\nimprove reasoning capacity in a simple way based on SciIE. We propose two-stage\ntraining with 1. MimicSFT, using structured reasoning templates without needing\nhigh-quality chain-of-thought data, 2. R$^2$GRPO with relevance and\nrule-induced rewards. Experiments on scientific IE benchmarks show that both\nmethods can improve the reasoning capacity. R$^2$GRPO with mimicSFT surpasses\nbaseline LLMs and specialized supervised models in relation extraction. Our\ncode is available at https://github.com/ranlislz/R2GRPO.", "published": "2025-05-28 07:47:46", "link": "http://arxiv.org/abs/2505.22068v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Safeguarding Privacy of Retrieval Data against Membership Inference Attacks: Is This Query Too Close to Home?", "abstract": "Retrieval-augmented generation (RAG) mitigates the hallucination problem in\nlarge language models (LLMs) and has proven effective for specific,\npersonalized applications. However, passing private retrieved documents\ndirectly to LLMs introduces vulnerability to membership inference attacks\n(MIAs), which try to determine whether the target datum exists in the private\nexternal database or not. Based on the insight that MIA queries typically\nexhibit high similarity to only one target document, we introduce Mirabel, a\nsimilarity-based MIA detection framework designed for the RAG system. With the\nproposed Mirabel, we show that simple detect-and-hide strategies can\nsuccessfully obfuscate attackers, maintain data utility, and remain\nsystem-agnostic. We experimentally prove its detection and defense against\nvarious state-of-the-art MIA methods and its adaptability to existing private\nRAG systems.", "published": "2025-05-28 07:35:07", "link": "http://arxiv.org/abs/2505.22061v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Voice Adaptation for Swiss German", "abstract": "This work investigates the performance of Voice Adaptation models for Swiss\nGerman dialects, i.e., translating Standard German text to Swiss German dialect\nspeech. For this, we preprocess a large dataset of Swiss podcasts, which we\nautomatically transcribe and annotate with dialect classes, yielding\napproximately 5000 hours of weakly labeled training material. We fine-tune the\nXTTSv2 model on this dataset and show that it achieves good scores in human and\nautomated evaluations and can correctly render the desired dialect. Our work\nshows a step towards adapting Voice Cloning technology to underrepresented\nlanguages. The resulting model achieves CMOS scores of up to -0.28 and SMOS\nscores of 3.8.", "published": "2025-05-28 07:24:40", "link": "http://arxiv.org/abs/2505.22054v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Jailbreak Distillation: Renewable Safety Benchmarking", "abstract": "Large language models (LLMs) are rapidly deployed in critical applications,\nraising urgent needs for robust safety benchmarking. We propose Jailbreak\nDistillation (JBDistill), a novel benchmark construction framework that\n\"distills\" jailbreak attacks into high-quality and easily-updatable safety\nbenchmarks. JBDistill utilizes a small set of development models and existing\njailbreak attack algorithms to create a candidate prompt pool, then employs\nprompt selection algorithms to identify an effective subset of prompts as\nsafety benchmarks. JBDistill addresses challenges in existing safety\nevaluation: the use of consistent evaluation prompts across models ensures fair\ncomparisons and reproducibility. It requires minimal human effort to rerun the\nJBDistill pipeline and produce updated benchmarks, alleviating concerns on\nsaturation and contamination. Extensive experiments demonstrate our benchmarks\ngeneralize robustly to 13 diverse evaluation models held out from benchmark\nconstruction, including proprietary, specialized, and newer-generation LLMs,\nsignificantly outperforming existing safety benchmarks in effectiveness while\nmaintaining high separability and diversity. Our framework thus provides an\neffective, sustainable, and adaptable solution for streamlining safety\nevaluation.", "published": "2025-05-28 06:59:46", "link": "http://arxiv.org/abs/2505.22037v1", "categories": ["cs.CL", "cs.CR", "cs.SE"], "primary_category": "cs.CL"}
{"title": "VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning", "abstract": "Effectively retrieving, reasoning and understanding visually rich information\nremains a challenge for RAG methods. Traditional text-based methods cannot\nhandle visual-related information. On the other hand, current vision-based RAG\napproaches are often limited by fixed pipelines and frequently struggle to\nreason effectively due to the insufficient activation of the fundamental\ncapabilities of models. As RL has been proven to be beneficial for model\nreasoning, we introduce VRAG-RL, a novel RL framework tailored for complex\nreasoning across visually rich information. With this framework, VLMs interact\nwith search engines, autonomously sampling single-turn or multi-turn reasoning\ntrajectories with the help of visual perception tokens and undergoing continual\noptimization based on these samples. Our approach highlights key limitations of\nRL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely\nincorporate images into the context, leading to insufficient reasoning token\nallocation and neglecting visual-specific perception; and (ii) When models\ninteract with search engines, their queries often fail to retrieve relevant\ninformation due to the inability to articulate requirements, thereby leading to\nsuboptimal performance. To address these challenges, we define an action space\ntailored for visually rich inputs, with actions including cropping and scaling,\nallowing the model to gather information from a coarse-to-fine perspective.\nFurthermore, to bridge the gap between users' original inquiries and the\nretriever, we employ a simple yet effective reward that integrates query\nrewriting and retrieval performance with a model-based reward. Our VRAG-RL\noptimizes VLMs for RAG tasks using specially designed RL strategies, aligning\nthe model with real-world applications. The code is available at\n\\hyperlink{https://github.com/Alibaba-NLP/VRAG}{https://github.com/Alibaba-NLP/VRAG}.", "published": "2025-05-28 06:30:51", "link": "http://arxiv.org/abs/2505.22019v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Improving Continual Pre-training Through Seamless Data Packing", "abstract": "Continual pre-training has demonstrated significant potential in enhancing\nmodel performance, particularly in domain-specific scenarios. The most common\napproach for packing data before continual pre-training involves concatenating\ninput texts and splitting them into fixed-length sequences. While\nstraightforward and efficient, this method often leads to excessive truncation\nand context discontinuity, which can hinder model performance. To address these\nissues, we explore the potential of data engineering to enhance continual\npre-training, particularly its impact on model performance and efficiency. We\npropose Seamless Packing (SP), a novel data packing strategy aimed at\npreserving contextual information more effectively and enhancing model\nperformance. Our approach employs a sliding window technique in the first stage\nthat synchronizes overlapping tokens across consecutive sequences, ensuring\nbetter continuity and contextual coherence. In the second stage, we adopt a\nFirst-Fit-Decreasing algorithm to pack shorter texts into bins slightly larger\nthan the target sequence length, thereby minimizing padding and truncation.\nEmpirical evaluations across various model architectures and corpus domains\ndemonstrate the effectiveness of our method, outperforming baseline method in\n99% of all settings. Code is available at\nhttps://github.com/Infernus-WIND/Seamless-Packing.", "published": "2025-05-28 06:30:37", "link": "http://arxiv.org/abs/2505.22018v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoThink: Token-Efficient Reasoning via Instruct Models Guiding Reasoning Models", "abstract": "Large language models (LLMs) benefit from increased test-time compute, a\nphenomenon known as test-time scaling. However, reasoning-optimized models\noften overthink even simple problems, producing excessively verbose outputs and\nleading to low token efficiency. By comparing these models with equally sized\ninstruct models, we identify two key causes of this verbosity: (1)\nreinforcement learning reduces the information density of forward reasoning,\nand (2) backward chain-of thought training encourages redundant and often\nunnecessary verification steps. Since LLMs cannot assess the difficulty of a\ngiven problem, they tend to apply the same cautious reasoning strategy across\nall tasks, resulting in inefficient overthinking. To address this, we propose\nCoThink, an embarrassingly simple pipeline: an instruct model first drafts a\nhigh-level solution outline; a reasoning model then works out the solution. We\nobserve that CoThink enables dynamic adjustment of reasoning depth based on\ninput difficulty. Evaluated with three reasoning models DAPO, DeepSeek-R1, and\nQwQ on three datasets GSM8K, MATH500, and AIME24, CoThink reduces total token\ngeneration by 22.3% while maintaining pass@1 accuracy within a 0.42% margin on\naverage. With reference to the instruct model, we formally define reasoning\nefficiency and observe a potential reasoning efficiency scaling law in LLMs.", "published": "2025-05-28 06:24:45", "link": "http://arxiv.org/abs/2505.22017v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Legal Assist AI: Leveraging Transformer-Based Model for Effective Legal Assistance", "abstract": "Pursuit of accessible legal assistance in India faces a critical gap, as many\ncitizens struggle to leverage their legal rights due to limited awareness and\naccess to relevant legal information. This paper introduces Legal Assist AI, a\ntransformer-based model designed to bridge this gap by offering effective legal\nassistance through large language models (LLMs). The system retrieves relevant\nlegal information from a curated database and generates accurate responses,\nenabling effective assistance for diverse users, including legal professionals,\nscholars, and the general public. The model was fine-tuned on extensive\ndatasets from the Indian legal domain, including Indian Constitution, Bharatiya\nNyaya Sanhita (BNS), Bharatiya Nagarik Suraksha Sanhita (BNSS) and so forth,\nproviding a robust understanding of the complexities of Indian law. By\nincorporating domain-specific legal datasets, the proposed model demonstrated\nremarkable efficiency and specialization in legal Question-Answering. The model\nwas evaluated against state-of-the-art models such as GPT-3.5 Turbo and Mistral\n7B, achieving a 60.08% score on the AIBE, outperforming its competitors in\nlegal reasoning and accuracy. Unlike other models, Legal Assist AI avoided\ncommon issues such as hallucinations, making it highly reliable for practical\nlegal applications. It showcases the model's applicability in real-world legal\nscenarios, with future iterations aiming to enhance performance and expand its\ndataset to cover a broader range of multilingual and case-specific queries as\nwell.", "published": "2025-05-28 06:06:53", "link": "http://arxiv.org/abs/2505.22003v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Found in Translation: Measuring Multilingual LLM Consistency as Simple as Translate then Evaluate", "abstract": "Large language models (LLMs) provide detailed and impressive responses to\nqueries in English. However, are they really consistent at responding to the\nsame query in other languages? The popular way of evaluating for multilingual\nperformance of LLMs requires expensive-to-collect annotated datasets. Further,\nevaluating for tasks like open-ended generation, where multiple correct answers\nmay exist, is nontrivial. Instead, we propose to evaluate the predictability of\nmodel response across different languages. In this work, we propose a framework\nto evaluate LLM's cross-lingual consistency based on a simple Translate then\nEvaluate strategy. We instantiate this evaluation framework along two\ndimensions of consistency: information and empathy. Our results reveal\npronounced inconsistencies in popular LLM responses across thirty languages,\nwith severe performance deficits in certain language families and scripts,\nunderscoring critical weaknesses in their multilingual capabilities. These\nfindings necessitate cross-lingual evaluations that are consistent along\nmultiple dimensions. We invite practitioners to use our framework for future\nmultilingual LLM benchmarking.", "published": "2025-05-28 06:00:21", "link": "http://arxiv.org/abs/2505.21999v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Interview-Informed LLMs to Model Survey Responses: Comparative Insights from AI-Generated and Human Data", "abstract": "Mixed methods research integrates quantitative and qualitative data but faces\nchallenges in aligning their distinct structures, particularly in examining\nmeasurement characteristics and individual response patterns. Advances in large\nlanguage models (LLMs) offer promising solutions by generating synthetic survey\nresponses informed by qualitative data. This study investigates whether LLMs,\nguided by personal interviews, can reliably predict human survey responses,\nusing the Behavioral Regulations in Exercise Questionnaire (BREQ) and\ninterviews from after-school program staff as a case study. Results indicate\nthat LLMs capture overall response patterns but exhibit lower variability than\nhumans. Incorporating interview data improves response diversity for some\nmodels (e.g., Claude, GPT), while well-crafted prompts and low-temperature\nsettings enhance alignment between LLM and human responses. Demographic\ninformation had less impact than interview content on alignment accuracy. These\nfindings underscore the potential of interview-informed LLMs to bridge\nqualitative and quantitative methodologies while revealing limitations in\nresponse variability, emotional interpretation, and psychometric fidelity.\nFuture research should refine prompt design, explore bias mitigation, and\noptimize model settings to enhance the validity of LLM-generated survey data in\nsocial science research.", "published": "2025-05-28 05:57:26", "link": "http://arxiv.org/abs/2505.21997v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Compositional Behaviors from Demonstration and Language", "abstract": "We introduce Behavior from Language and Demonstration (BLADE), a framework\nfor long-horizon robotic manipulation by integrating imitation learning and\nmodel-based planning. BLADE leverages language-annotated demonstrations,\nextracts abstract action knowledge from large language models (LLMs), and\nconstructs a library of structured, high-level action representations. These\nrepresentations include preconditions and effects grounded in visual perception\nfor each high-level action, along with corresponding controllers implemented as\nneural network-based policies. BLADE can recover such structured\nrepresentations automatically, without manually labeled states or symbolic\ndefinitions. BLADE shows significant capabilities in generalizing to novel\nsituations, including novel initial states, external state perturbations, and\nnovel goals. We validate the effectiveness of our approach both in simulation\nand on real robots with a diverse set of objects with articulated parts,\npartial observability, and geometric constraints.", "published": "2025-05-28 05:19:59", "link": "http://arxiv.org/abs/2505.21981v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset", "abstract": "Mainstream large vision-language models (LVLMs) inherently encode cultural\nbiases, highlighting the need for diverse multimodal datasets. To address this\ngap, we introduce Pearl, a large-scale Arabic multimodal dataset and benchmark\nexplicitly designed for cultural understanding. Constructed through advanced\nagentic workflows and extensive human-in-the-loop annotations by 45 annotators\nfrom across the Arab world, Pearl comprises over K multimodal examples spanning\nten culturally significant domains covering all Arab countries. We further\nprovide two robust evaluation benchmarks Pearl and Pearl-Lite along with a\nspecialized subset Pearl-X explicitly developed to assess nuanced cultural\nvariations. Comprehensive evaluations on state-of-the-art open and proprietary\nLVLMs demonstrate that reasoning-centric instruction alignment substantially\nimproves models' cultural grounding compared to conventional scaling methods.\nPearl establishes a foundational resource for advancing culturally-informed\nmultimodal modeling research. All datasets and benchmarks are publicly\navailable.", "published": "2025-05-28 05:14:47", "link": "http://arxiv.org/abs/2505.21979v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack", "abstract": "Large Vision-Language Models (LVLMs) have shown remarkable capabilities\nacross a wide range of multimodal tasks. However, their integration of visual\ninputs introduces expanded attack surfaces, thereby exposing them to novel\nsecurity vulnerabilities. In this work, we conduct a systematic\nrepresentational analysis to uncover why conventional adversarial attacks can\ncircumvent the safety mechanisms embedded in LVLMs. We further propose a novel\ntwo stage evaluation framework for adversarial attacks on LVLMs. The first\nstage differentiates among instruction non compliance, outright refusal, and\nsuccessful adversarial exploitation. The second stage quantifies the degree to\nwhich the model's output fulfills the harmful intent of the adversarial prompt,\nwhile categorizing refusal behavior into direct refusals, soft refusals, and\npartial refusals that remain inadvertently helpful. Finally, we introduce a\nnormative schema that defines idealized model behavior when confronted with\nharmful prompts, offering a principled target for safety alignment in\nmultimodal systems.", "published": "2025-05-28 04:43:39", "link": "http://arxiv.org/abs/2505.21967v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MapStory: LLM-Powered Text-Driven Map Animation Prototyping with Human-in-the-Loop Editing", "abstract": "We introduce MapStory, an LLM-powered animation authoring tool that generates\neditable map animation sequences directly from natural language text. Given a\nuser-written script, MapStory leverages an agentic architecture to\nautomatically produce a scene breakdown, which decomposes the script into key\nanimation building blocks such as camera movements, visual highlights, and\nanimated elements. Our system includes a researcher component that accurately\nqueries geospatial information by leveraging an LLM with web search, enabling\nthe automatic extraction of relevant regions, paths, and coordinates while\nallowing users to edit and query for changes or additional information to\nrefine the results. Additionally, users can fine-tune parameters of these\nblocks through an interactive timeline editor. We detail the system's design\nand architecture, informed by formative interviews with professional animators\nand an analysis of 200 existing map animation videos. Our evaluation, which\nincludes expert interviews (N=5) and a usability study (N=12), demonstrates\nthat MapStory enables users to create map animations with ease, facilitates\nfaster iteration, encourages creative exploration, and lowers barriers to\ncreating map-centric stories.", "published": "2025-05-28 04:36:08", "link": "http://arxiv.org/abs/2505.21966v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.MM", "H.5.2, H.5.1"], "primary_category": "cs.HC"}
{"title": "UI-Evol: Automatic Knowledge Evolving for Computer Use Agents", "abstract": "External knowledge has played a crucial role in the recent development of\ncomputer use agents. We identify a critical knowledge-execution gap: retrieved\nknowledge often fails to translate into effective real-world task execution.\nOur analysis shows even 90\\% correct knowledge yields only 41\\% execution\nsuccess rate. To bridge this gap, we propose UI-Evol, a plug-and-play module\nfor autonomous GUI knowledge evolution. UI-Evol consists of two stages: a\nRetrace Stage that extracts faithful objective action sequences from actual\nagent-environment interactions, and a Critique Stage that refines existing\nknowledge by comparing these sequences against external references. We conduct\ncomprehensive experiments on the OSWorld benchmark with the state-of-the-art\nAgent S2. Our results demonstrate that UI-Evol not only significantly boosts\ntask performance but also addresses a previously overlooked issue of high\nbehavioral standard deviation in computer use agents, leading to superior\nperformance on computer use tasks and substantially improved agent reliability.", "published": "2025-05-28 04:32:05", "link": "http://arxiv.org/abs/2505.21964v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance across\na wide range of tasks. To further tailor LLMs to specific domains or\napplications, post-training techniques such as Supervised Fine-Tuning (SFT),\nPreference Learning, and model merging are commonly employed. While each of\nthese methods has been extensively studied in isolation, the automated\nconstruction of complete post-training pipelines remains an underexplored area.\nExisting approaches typically rely on manual design or focus narrowly on\noptimizing individual components, such as data ordering or merging strategies.\nIn this work, we introduce LaMDAgent (short for Language Model Developing\nAgent), a novel framework that autonomously constructs and optimizes full\npost-training pipelines through the use of LLM-based agents. LaMDAgent\nsystematically explores diverse model generation techniques, datasets, and\nhyperparameter configurations, leveraging task-based feedback to discover\nhigh-performing pipelines with minimal human intervention. Our experiments show\nthat LaMDAgent improves tool-use accuracy by 9.0 points while preserving\ninstruction-following capabilities. Moreover, it uncovers effective\npost-training strategies that are often overlooked by conventional human-driven\nexploration. We further analyze the impact of data and model size scaling to\nreduce computational costs on the exploration, finding that model size scalings\nintroduces new challenges, whereas scaling data size enables cost-effective\npipeline discovery.", "published": "2025-05-28 04:30:51", "link": "http://arxiv.org/abs/2505.21963v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EnsemW2S: Enhancing Weak-to-Strong Generalization with Large Language Model Ensembles", "abstract": "With Large Language Models (LLMs) rapidly approaching and potentially\nsurpassing human-level performance, it has become imperative to develop\napproaches capable of effectively supervising and enhancing these powerful\nmodels using smaller, human-level models exposed to only human-level data. We\naddress this critical weak-to-strong (W2S) generalization challenge by\nproposing a novel method aimed at improving weak experts, by training on the\nsame limited human-level data, enabling them to generalize to complex,\nsuper-human-level tasks. Our approach, called \\textbf{EnsemW2S}, employs a\ntoken-level ensemble strategy that iteratively combines multiple weak experts,\nsystematically addressing the shortcomings identified in preceding iterations.\nBy continuously refining these weak models, we significantly enhance their\ncollective ability to supervise stronger student models. We extensively\nevaluate the generalization performance of both the ensemble of weak experts\nand the subsequent strong student model across in-distribution (ID) and\nout-of-distribution (OOD) datasets. For OOD, we specifically introduce question\ndifficulty as an additional dimension for defining distributional shifts. Our\nempirical results demonstrate notable improvements, achieving 4\\%, and 3.2\\%\nimprovements on ID datasets and, upto 6\\% and 2.28\\% on OOD datasets for\nexperts and student models respectively, underscoring the effectiveness of our\nproposed method in advancing W2S generalization.", "published": "2025-05-28 04:23:12", "link": "http://arxiv.org/abs/2505.21959v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Resolving Knowledge Conflicts in Domain-specific Data Selection: A Case Study on Medical Instruction-tuning", "abstract": "Domain-specific instruction-tuning has become the defacto standard for\nimproving the performance of large language models (LLMs) in specialized\napplications, e.g., medical question answering. Since the instruction-tuning\ndataset might contain redundant or low-quality data, data selection (DS) is\nusually required to maximize the data efficiency. Despite the successes in the\ngeneral domain, current DS methods often struggle to select the desired data\nfor domain-specific instruction-tuning. One of the main reasons is that they\nneglect the impact of knowledge conflicts, i.e., the discrepancy between LLMs'\npretrained knowledge and context knowledge of instruction data, which could\ndamage LLMs' prior abilities and lead to hallucination. To this end, we propose\na simple-yet-effective Knowledge-aware Data Selection (namely KDS) framework to\nselect the domain-specific instruction-tuning data that meets LLMs' actual\nneeds. The core of KDS is to leverage two knowledge-aware metrics for\nquantitatively measuring knowledge conflicts from two aspects: context-memory\nknowledge alignment and intra-memory knowledge consistency. By filtering the\ndata with large knowledge conflicts and sampling the high-quality and diverse\ndata, KDS can effectively stimulate the LLMs' abilities and achieve better\ndomain-specific performance. Taking the medical domain as the testbed, we\nconduct extensive experiments and empirically prove that KDS surpasses the\nother baselines and brings significant and consistent performance gains among\nall LLMs. More encouragingly, KDS effectively improves the model generalization\nand alleviates the hallucination problem.", "published": "2025-05-28 04:18:24", "link": "http://arxiv.org/abs/2505.21958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation", "abstract": "Text-to-image generation increasingly demands access to domain-specific,\nfine-grained, and rapidly evolving knowledge that pretrained models cannot\nfully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to\naddress this by retrieving globally relevant images, but they fail when no\nsingle image contains all desired elements from a complex user query. We\npropose Cross-modal RAG, a novel framework that decomposes both queries and\nimages into sub-dimensional components, enabling subquery-aware retrieval and\ngeneration. Our method introduces a hybrid retrieval strategy - combining a\nsub-dimensional sparse retriever with a dense retriever - to identify a\nPareto-optimal set of images, each contributing complementary aspects of the\nquery. During generation, a multimodal large language model is guided to\nselectively condition on relevant visual features aligned to specific\nsubqueries, ensuring subquery-aware image synthesis. Extensive experiments on\nMS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal\nRAG significantly outperforms existing baselines in both retrieval and\ngeneration quality, while maintaining high efficiency.", "published": "2025-05-28 04:09:49", "link": "http://arxiv.org/abs/2505.21956v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Test-Time Scaling with Repeated Sampling Improves Multilingual Text Generation", "abstract": "Inference-time scaling via repeated sampling has shown promise in reasoning\ntasks, but its effectiveness in multilingual generation remains underexplored.\nWe evaluate this approach using perplexity- and reward-based verifiers on two\nmultilingual benchmarks: the Aya Evaluation Suite and m-ArenaHard. Our results\nshow consistent quality improvements, with gains exceeding 35% in some cases.\nWhile perplexity-based scoring is effective for open-ended prompts, only\nreward-based verifiers improve performance on tasks requiring reasoning (e.g.,\nmath, code). Our results demonstrate the broader utility of repeated sampling\nfor multilingual text generation and underscore the importance of selecting\nright verifiers for the task.", "published": "2025-05-28 03:50:19", "link": "http://arxiv.org/abs/2505.21941v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Maximizing Confidence Alone Improves Reasoning", "abstract": "Reinforcement learning (RL) has enabled machine learning models to achieve\nsignificant advances in many fields. Most recently, RL has empowered frontier\nlanguage models to solve challenging math, science, and coding problems.\nHowever, central to any RL algorithm is the reward function, and reward\nengineering is a notoriously difficult problem in any domain. In this paper, we\npropose RENT: Reinforcement Learning via Entropy Minimization -- a fully\nunsupervised RL method that requires no external reward or ground-truth\nanswers, and instead uses the model's entropy of its underlying distribution as\nan intrinsic reward. We find that by reinforcing the chains of thought that\nyield high model confidence on its generated answers, the model improves its\nreasoning ability. In our experiments, we showcase these improvements on an\nextensive suite of commonly-used reasoning benchmarks, including GSM8K,\nMATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen and\nMistral families. The generality of our unsupervised learning method lends\nitself to applicability in a wide range of domains where external supervision\nis limited or unavailable.", "published": "2025-05-28 17:59:37", "link": "http://arxiv.org/abs/2505.22660v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Pre-training for Recommendation Unlearning", "abstract": "Modern recommender systems powered by Graph Neural Networks (GNNs) excel at\nmodeling complex user-item interactions, yet increasingly face scenarios\nrequiring selective forgetting of training data. Beyond user requests to remove\nspecific interactions due to privacy concerns or preference changes, regulatory\nframeworks mandate recommender systems' ability to eliminate the influence of\ncertain user data from models. This recommendation unlearning challenge\npresents unique difficulties as removing connections within interaction graphs\ncreates ripple effects throughout the model, potentially impacting\nrecommendations for numerous users. Traditional approaches suffer from\nsignificant drawbacks: fragmentation methods damage graph structure and\ndiminish performance, while influence function techniques make assumptions that\nmay not hold in complex GNNs, particularly with self-supervised or random\narchitectures. To address these limitations, we propose a novel model-agnostic\npre-training paradigm UnlearnRec that prepares systems for efficient unlearning\noperations. Our Influence Encoder takes unlearning requests together with\nexisting model parameters and directly produces updated parameters of unlearned\nmodel with little fine-tuning, avoiding complete retraining while preserving\nmodel performance characteristics. Extensive evaluation on public benchmarks\ndemonstrates that our method delivers exceptional unlearning effectiveness\nwhile providing more than 10x speedup compared to retraining approaches. We\nrelease our method implementation at: https://github.com/HKUDS/UnlearnRec.", "published": "2025-05-28 17:57:11", "link": "http://arxiv.org/abs/2505.22649v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control", "abstract": "Reinforcement learning (RL) has driven significant progress in robotics, but\nits complexity and long training times remain major bottlenecks. In this\nreport, we introduce FastTD3, a simple, fast, and capable RL algorithm that\nsignificantly speeds up training for humanoid robots in popular suites such as\nHumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably\nsimple: we train an off-policy TD3 agent with several modifications -- parallel\nsimulation, large-batch updates, a distributional critic, and carefully tuned\nhyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours\non a single A100 GPU, while remaining stable during training. We also provide a\nlightweight and easy-to-use implementation of FastTD3 to accelerate RL research\nin robotics.", "published": "2025-05-28 17:55:26", "link": "http://arxiv.org/abs/2505.22642v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning", "abstract": "Imitation learning advances robot capabilities by enabling the acquisition of\ndiverse behaviors from human demonstrations. However, large-scale datasets used\nfor policy training often introduce substantial variability in quality, which\ncan negatively impact performance. As a result, automatically curating datasets\nby filtering low-quality samples to improve quality becomes essential. Existing\nrobotic curation approaches rely on costly manual annotations and perform\ncuration at a coarse granularity, such as the dataset or trajectory level,\nfailing to account for the quality of individual state-action pairs. To address\nthis, we introduce SCIZOR, a self-supervised data curation framework that\nfilters out low-quality state-action pairs to improve the performance of\nimitation learning policies. SCIZOR targets two complementary sources of\nlow-quality data: suboptimal data, which hinders learning with undesirable\nactions, and redundant data, which dilutes training with repetitive patterns.\nSCIZOR leverages a self-supervised task progress predictor for suboptimal data\nto remove samples lacking task progression, and a deduplication module\noperating on joint state-action representation for samples with redundant\npatterns. Empirically, we show that SCIZOR enables imitation learning policies\nto achieve higher performance with less data, yielding an average improvement\nof 15.4% across multiple benchmarks. More information is available at:\nhttps://ut-austin-rpl.github.io/SCIZOR/", "published": "2025-05-28 17:45:05", "link": "http://arxiv.org/abs/2505.22626v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Effective and Efficient One-pass Compression of Speech Foundation Models Using Sparsity-aware Self-pinching Gates", "abstract": "This paper presents a novel approach for speech foundation models compression\nthat tightly integrates model pruning and parameter update into a single stage.\nHighly compact layer-level tied self-pinching gates each containing only a\nsingle learnable threshold are jointly trained with uncompressed models and\nused in fine-grained neuron level pruning. Experiments conducted on the\nLibriSpeech-100hr corpus suggest that our approach reduces the number of\nparameters of wav2vec2.0-base and HuBERT-large models by 65% and 60%\nrespectively, while incurring no statistically significant word error rate\n(WER) increase on the test-clean dataset. Compared to previously published\nmethods on the same task, our approach not only achieves the lowest WER of\n7.05% on the test-clean dataset under a comparable model compression ratio of\n4.26x, but also operates with at least 25% less model compression time.", "published": "2025-05-28 17:24:21", "link": "http://arxiv.org/abs/2505.22608v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "One Rank at a Time: Cascading Error Dynamics in Sequential Learning", "abstract": "Sequential learning -- where complex tasks are broken down into simpler,\nhierarchical components -- has emerged as a paradigm in AI. This paper views\nsequential learning through the lens of low-rank linear regression, focusing\nspecifically on how errors propagate when learning rank-1 subspaces\nsequentially. We present an analysis framework that decomposes the learning\nprocess into a series of rank-1 estimation problems, where each subsequent\nestimation depends on the accuracy of previous steps. Our contribution is a\ncharacterization of the error propagation in this sequential process,\nestablishing bounds on how errors -- e.g., due to limited computational budgets\nand finite precision -- affect the overall model accuracy. We prove that these\nerrors compound in predictable ways, with implications for both algorithmic\ndesign and stability guarantees.", "published": "2025-05-28 17:16:24", "link": "http://arxiv.org/abs/2505.22602v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "Machine Unlearning under Overparameterization", "abstract": "Machine unlearning algorithms aim to remove the influence of specific\ntraining samples, ideally recovering the model that would have resulted from\ntraining on the remaining data alone. We study unlearning in the\noverparameterized setting, where many models interpolate the data, and defining\nthe unlearning solution as any loss minimizer over the retained\nset$\\unicode{x2013}$as in prior work in the underparameterized\nsetting$\\unicode{x2013}$is inadequate, since the original model may already\ninterpolate the retained data and satisfy this condition. In this regime, loss\ngradients vanish, rendering prior methods based on gradient perturbations\nineffective, motivating both new unlearning definitions and algorithms. For\nthis setting, we define the unlearning solution as the minimum-complexity\ninterpolator over the retained data and propose a new algorithmic framework\nthat only requires access to model gradients on the retained set at the\noriginal solution. We minimize a regularized objective over perturbations\nconstrained to be orthogonal to these model gradients, a first-order relaxation\nof the interpolation condition. For different model classes, we provide exact\nand approximate unlearning guarantees, and we demonstrate that an\nimplementation of our framework outperforms existing baselines across various\nunlearning experiments.", "published": "2025-05-28 17:14:57", "link": "http://arxiv.org/abs/2505.22601v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "On the performance of machine-learning assisted Monte Carlo in sampling from simple statistical physics models", "abstract": "Recent years have seen a rise in the application of machine learning\ntechniques to aid the simulation of hard-to-sample systems that cannot be\nstudied using traditional methods. Despite the introduction of many different\narchitectures and procedures, a wide theoretical understanding is still\nlacking, with the risk of suboptimal implementations. As a first step to\naddress this gap, we provide here a complete analytic study of the widely-used\nSequential Tempering procedure applied to a shallow MADE architecture for the\nCurie-Weiss model. The contribution of this work is twofold: firstly, we give a\ndescription of the optimal weights and of the training under Gradient Descent\noptimization. Secondly, we compare what happens in Sequential Tempering with\nand without the addition of local Metropolis Monte Carlo steps. We are thus\nable to give theoretical predictions on the best procedure to apply in this\ncase. This work establishes a clear theoretical basis for the integration of\nmachine learning techniques into Monte Carlo sampling and optimization.", "published": "2025-05-28 17:13:11", "link": "http://arxiv.org/abs/2505.22598v1", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.LG", "physics.comp-ph"], "primary_category": "cond-mat.dis-nn"}
{"title": "HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined in HDDL with OpenAI Gym", "abstract": "In recent years, reinforcement learning (RL) methods have been widely tested\nusing tools like OpenAI Gym, though many tasks in these environments could also\nbenefit from hierarchical planning. However, there is a lack of a tool that\nenables seamless integration of hierarchical planning with RL. Hierarchical\nDomain Definition Language (HDDL), used in classical planning, introduces a\nstructured approach well-suited for model-based RL to address this gap. To\nbridge this integration, we introduce HDDLGym, a Python-based tool that\nautomatically generates OpenAI Gym environments from HDDL domains and problems.\nHDDLGym serves as a link between RL and hierarchical planning, supporting\nmulti-agent scenarios and enabling collaborative planning among agents. This\npaper provides an overview of HDDLGym's design and implementation, highlighting\nthe challenges and design choices involved in integrating HDDL with the Gym\ninterface, and applying RL policies to support hierarchical planning. We also\nprovide detailed instructions and demonstrations for using the HDDLGym\nframework, including how to work with existing HDDL domains and problems from\nInternational Planning Competitions, exemplified by the Transport domain.\nAdditionally, we offer guidance on creating new HDDL domains for multi-agent\nscenarios and demonstrate the practical use of HDDLGym in the Overcooked\ndomain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a\nvaluable tool for studying RL in hierarchical planning, particularly in\nmulti-agent contexts.", "published": "2025-05-28 17:10:43", "link": "http://arxiv.org/abs/2505.22597v1", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git", "abstract": "Benchmarks for Software Engineering (SE) AI agents, most notably SWE-bench,\nhave catalyzed progress in programming capabilities of AI agents. However, they\noverlook critical developer workflows such as Version Control System (VCS)\noperations. To address this issue, we present GitGoodBench, a novel benchmark\nfor evaluating AI agent performance on VCS tasks. GitGoodBench covers three\ncore Git scenarios extracted from permissive open-source Python, Java, and\nKotlin repositories. Our benchmark provides three datasets: a comprehensive\nevaluation suite (900 samples), a rapid prototyping version (120 samples), and\na training corpus (17,469 samples). We establish baseline performance on the\nprototyping version of our benchmark using GPT-4o equipped with custom tools,\nachieving a 21.11% solve rate overall. We expect GitGoodBench to serve as a\ncrucial stepping stone toward truly comprehensive SE agents that go beyond mere\nprogramming.", "published": "2025-05-28 16:56:11", "link": "http://arxiv.org/abs/2505.22583v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Tell me Habibi, is it Real or Fake?", "abstract": "Deepfake generation methods are evolving fast, making fake media harder to\ndetect and raising serious societal concerns. Most deepfake detection and\ndataset creation research focuses on monolingual content, often overlooking the\nchallenges of multilingual and code-switched speech, where multiple languages\nare mixed within the same discourse. Code-switching, especially between Arabic\nand English, is common in the Arab world and is widely used in digital\ncommunication. This linguistic mixing poses extra challenges for deepfake\ndetection, as it can confuse models trained mostly on monolingual data. To\naddress this, we introduce \\textbf{ArEnAV}, the first large-scale\nArabic-English audio-visual deepfake dataset featuring intra-utterance\ncode-switching, dialectal variation, and monolingual Arabic content. It\n\\textbf{contains 387k videos and over 765 hours of real and fake videos}. Our\ndataset is generated using a novel pipeline integrating four Text-To-Speech and\ntwo lip-sync models, enabling comprehensive analysis of multilingual multimodal\ndeepfake detection. We benchmark our dataset against existing monolingual and\nmultilingual datasets, state-of-the-art deepfake detection models, and a human\nevaluation, highlighting its potential to advance deepfake research. The\ndataset can be accessed\n\\href{https://huggingface.co/datasets/kartik060702/ArEnAV-Full}{here}.", "published": "2025-05-28 16:54:36", "link": "http://arxiv.org/abs/2505.22581v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Universal Visuo-Tactile Video Understanding for Embodied Interaction", "abstract": "Tactile perception is essential for embodied agents to understand physical\nattributes of objects that cannot be determined through visual inspection\nalone. While existing approaches have made progress in visual and language\nmodalities for physical understanding, they fail to effectively incorporate\ntactile information that provides crucial haptic feedback for real-world\ninteraction. In this paper, we present VTV-LLM, the first multi-modal large\nlanguage model for universal Visuo-Tactile Video (VTV) understanding that\nbridges the gap between tactile perception and natural language. To address the\nchallenges of cross-sensor and cross-modal integration, we contribute VTV150K,\na comprehensive dataset comprising 150,000 video frames from 100 diverse\nobjects captured across three different tactile sensors (GelSight Mini, DIGIT,\nand Tac3D), annotated with four fundamental tactile attributes (hardness,\nprotrusion, elasticity, and friction). We develop a novel three-stage training\nparadigm that includes VTV enhancement for robust visuo-tactile representation,\nVTV-text alignment for cross-modal correspondence, and text prompt finetuning\nfor natural language generation. Our framework enables sophisticated tactile\nreasoning capabilities including feature assessment, comparative analysis,\nscenario-based decision making and so on. Experimental evaluations demonstrate\nthat VTV-LLM achieves superior performance in tactile video understanding\ntasks, establishing a foundation for more intuitive human-machine interaction\nin tactile domains.", "published": "2025-05-28 16:43:01", "link": "http://arxiv.org/abs/2505.22566v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PRISM: Video Dataset Condensation with Progressive Refinement and Insertion for Sparse Motion", "abstract": "Video dataset condensation has emerged as a critical technique for addressing\nthe computational challenges associated with large-scale video data processing\nin deep learning applications. While significant progress has been made in\nimage dataset condensation, the video domain presents unique challenges due to\nthe complex interplay between spatial content and temporal dynamics. This paper\nintroduces PRISM, Progressive Refinement and Insertion for Sparse Motion, for\nvideo dataset condensation, a novel approach that fundamentally reconsiders how\nvideo data should be condensed. Unlike the previous method that separates\nstatic content from dynamic motion, our method preserves the essential\ninterdependence between these elements. Our approach progressively refines and\ninserts frames to fully accommodate the motion in an action while achieving\nbetter performance but less storage, considering the relation of gradients for\neach frame. Extensive experiments across standard video action recognition\nbenchmarks demonstrate that PRISM outperforms existing disentangled approaches\nwhile maintaining compact representations suitable for resource-constrained\nenvironments.", "published": "2025-05-28 16:42:10", "link": "http://arxiv.org/abs/2505.22564v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Scaling-up Perceptual Video Quality Assessment", "abstract": "The data scaling law has been shown to significantly enhance the performance\nof large multi-modal models (LMMs) across various downstream tasks. However, in\nthe domain of perceptual video quality assessment (VQA), the potential of\nscaling law remains unprecedented due to the scarcity of labeled resources and\nthe insufficient scale of datasets. To address this, we propose\n\\textbf{OmniVQA}, an efficient framework designed to efficiently build\nhigh-quality, human-in-the-loop VQA multi-modal instruction databases (MIDBs).\nWe then scale up to create \\textbf{OmniVQA-Chat-400K}, the largest MIDB in the\nVQA field concurrently. Our focus is on the technical and aesthetic quality\ndimensions, with abundant in-context instruction data to provide fine-grained\nVQA knowledge. Additionally, we have built the \\textbf{OmniVQA-MOS-20K} dataset\nto enhance the model's quantitative quality rating capabilities. We then\nintroduce a \\textbf{complementary} training strategy that effectively leverages\nthe knowledge from datasets for quality understanding and quality rating tasks.\nFurthermore, we propose the \\textbf{OmniVQA-FG (fine-grain)-Benchmark} to\nevaluate the fine-grained performance of the models. Our results demonstrate\nthat our models achieve state-of-the-art performance in both quality\nunderstanding and rating tasks.", "published": "2025-05-28 16:24:52", "link": "http://arxiv.org/abs/2505.22543v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "TabularQGAN: A Quantum Generative Model for Tabular Data", "abstract": "In this paper, we introduce a novel quantum generative model for synthesizing\ntabular data. Synthetic data is valuable in scenarios where real-world data is\nscarce or private, it can be used to augment or replace existing datasets.\nReal-world enterprise data is predominantly tabular and heterogeneous, often\ncomprising a mixture of categorical and numerical features, making it highly\nrelevant across various industries such as healthcare, finance, and software.\nWe propose a quantum generative adversarial network architecture with flexible\ndata encoding and a novel quantum circuit ansatz to effectively model tabular\ndata. The proposed approach is tested on the MIMIC III healthcare and Adult\nCensus datasets, with extensive benchmarking against leading classical models,\nCTGAN, and CopulaGAN. Experimental results demonstrate that our quantum model\noutperforms classical models by an average of 8.5% with respect to an overall\nsimilarity score from SDMetrics, while using only 0.072% of the parameters of\nthe classical models. Additionally, we evaluate the generalization capabilities\nof the models using two custom-designed metrics that demonstrate the ability of\nthe proposed quantum model to generate useful and novel samples. To our\nknowledge, this is one of the first demonstrations of a successful quantum\ngenerative model for handling tabular data, indicating that this task could be\nwell-suited to quantum computers.", "published": "2025-05-28 16:19:39", "link": "http://arxiv.org/abs/2505.22533v1", "categories": ["cs.LG", "cs.AI", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Training RL Agents for Multi-Objective Network Defense Tasks", "abstract": "Open-ended learning (OEL) -- which emphasizes training agents that achieve\nbroad capability over narrow competency -- is emerging as a paradigm to develop\nartificial intelligence (AI) agents to achieve robustness and generalization.\nHowever, despite promising results that demonstrate the benefits of OEL,\napplying OEL to develop autonomous agents for real-world cybersecurity\napplications remains a challenge.\n  We propose a training approach, inspired by OEL, to develop autonomous\nnetwork defenders. Our results demonstrate that like in other domains, OEL\nprinciples can translate into more robust and generalizable agents for cyber\ndefense. To apply OEL to network defense, it is necessary to address several\ntechnical challenges. Most importantly, it is critical to provide a task\nrepresentation approach over a broad universe of tasks that maintains a\nconsistent interface over goals, rewards and action spaces. This way, the\nlearning agent can train with varying network conditions, attacker behaviors,\nand defender goals while being able to build on previously gained knowledge.\n  With our tools and results, we aim to fundamentally impact research that\napplies AI to solve cybersecurity problems. Specifically, as researchers\ndevelop gyms and benchmarks for cyber defense, it is paramount that they\nconsider diverse tasks with consistent representations, such as those we\npropose in our work.", "published": "2025-05-28 16:18:21", "link": "http://arxiv.org/abs/2505.22531v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data", "abstract": "Fraud detection remains a critical task in high-stakes domains such as\nfinance and e-commerce, where undetected fraudulent transactions can lead to\nsignificant economic losses. In this study, we systematically compare the\nperformance of four supervised learning models - Logistic Regression, Random\nForest, Light Gradient Boosting Machine (LightGBM), and a Gated Recurrent Unit\n(GRU) network - on a large-scale, highly imbalanced online transaction dataset.\nWhile ensemble methods such as Random Forest and LightGBM demonstrated superior\nperformance in both overall and class-specific metrics, Logistic Regression\noffered a reliable and interpretable baseline. The GRU model showed strong\nrecall for the minority fraud class, though at the cost of precision,\nhighlighting a trade-off relevant for real-world deployment. Our evaluation\nemphasizes not only weighted averages but also per-class precision, recall, and\nF1-scores, providing a nuanced view of each model's effectiveness in detecting\nrare but consequential fraudulent activity. The findings underscore the\nimportance of choosing models based on the specific risk tolerance and\noperational needs of fraud detection systems.", "published": "2025-05-28 16:08:04", "link": "http://arxiv.org/abs/2505.22521v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Strengthening Proportionality in Temporal Voting", "abstract": "We study proportional representation in the framework of temporal voting with\napproval ballots. Prior work adapted basic proportional representation concepts\n-- justified representation (JR), proportional JR (PJR), and extended JR (EJR)\n-- from the multiwinner setting to the temporal setting. Our work introduces\nand examines ways of going beyond EJR. Specifically, we consider stronger\nvariants of JR, PJR, and EJR, and introduce temporal adaptations of more\ndemanding multiwinner axioms, such as EJR+, full JR (FJR), full proportional JR\n(FPJR), and the Core. For each of these concepts, we investigate its existence\nand study its relationship to existing notions, thereby establishing a rich\nhierarchy of proportionality concepts. Notably, we show that two of our\nproposed axioms -- EJR+ and FJR -- strengthen EJR while remaining satisfiable\nin every temporal election.", "published": "2025-05-28 16:02:52", "link": "http://arxiv.org/abs/2505.22513v1", "categories": ["cs.GT", "cs.AI"], "primary_category": "cs.GT"}
{"title": "From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation", "abstract": "While embodied agents have made significant progress in performing complex\nphysical tasks, real-world applications demand more than pure task execution.\nThe agents must collaborate with unfamiliar agents and human users, whose goals\nare often vague and implicit. In such settings, interpreting ambiguous\ninstructions and uncovering underlying desires is essential for effective\nassistance. Therefore, fast and accurate desire alignment becomes a critical\ncapability for embodied agents. In this work, we first develop a home\nassistance simulation environment HA-Desire that integrates an LLM-driven human\nuser agent exhibiting realistic value-driven goal selection and communication.\nThe ego agent must interact with this proxy user to infer and adapt to the\nuser's latent desires. To achieve this, we present a novel framework FAMER for\nfast desire alignment, which introduces a desire-based mental reasoning\nmechanism to identify user intent and filter desire-irrelevant actions. We\nfurther design a reflection-based communication module that reduces redundant\ninquiries, and incorporate goal-relevant information extraction with memory\npersistence to improve information reuse and reduce unnecessary exploration.\nExtensive experiments demonstrate that our framework significantly enhances\nboth task execution and communication efficiency, enabling embodied agents to\nquickly adapt to user-specific desires in complex embodied environments.", "published": "2025-05-28 15:51:13", "link": "http://arxiv.org/abs/2505.22503v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Demystifying the Paradox of Importance Sampling with an Estimated History-Dependent Behavior Policy in Off-Policy Evaluation", "abstract": "This paper studies off-policy evaluation (OPE) in reinforcement learning with\na focus on behavior policy estimation for importance sampling. Prior work has\nshown empirically that estimating a history-dependent behavior policy can lead\nto lower mean squared error (MSE) even when the true behavior policy is\nMarkovian. However, the question of why the use of history should lower MSE\nremains open. In this paper, we theoretically demystify this paradox by\nderiving a bias-variance decomposition of the MSE of ordinary importance\nsampling (IS) estimators, demonstrating that history-dependent behavior policy\nestimation decreases their asymptotic variances while increasing their\nfinite-sample biases. Additionally, as the estimated behavior policy conditions\non a longer history, we show a consistent decrease in variance. We extend these\nfindings to a range of other OPE estimators, including the sequential IS\nestimator, the doubly robust estimator and the marginalized IS estimator, with\nthe behavior policy estimated either parametrically or non-parametrically.", "published": "2025-05-28 15:42:20", "link": "http://arxiv.org/abs/2505.22492v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On the Surprising Effectiveness of Large Learning Rates under Standard Width Scaling", "abstract": "The dominant paradigm for training large-scale vision and language models is\nHe initialization and a single global learning rate (\\textit{standard\nparameterization}, SP). Despite its practical success, standard parametrization\nremains poorly understood from a theoretical perspective: Existing\ninfinite-width theory would predict instability under large learning rates and\nvanishing feature learning under stable learning rates. However, empirically\noptimal learning rates consistently decay much slower than theoretically\npredicted. By carefully studying neural network training dynamics, we\ndemonstrate that this discrepancy is not fully explained by finite-width\nphenomena such as catapult effects or a lack of alignment between weights and\nincoming activations. We instead show that the apparent contradiction can be\nfundamentally resolved by taking the loss function into account: In contrast to\nMean Squared Error (MSE) loss, we prove that under cross-entropy (CE) loss, an\nintermediate \\textit{controlled divergence} regime emerges, where logits\ndiverge but loss, gradients, and activations remain stable. Stable training\nunder large learning rates enables persistent feature evolution at scale in all\nhidden layers, which is crucial for the practical success of SP. In experiments\nacross optimizers (SGD, Adam), architectures (MLPs, GPT) and data modalities\n(vision, language), we validate that neural networks operate in this controlled\ndivergence regime under CE loss but not under MSE loss. Our empirical evidence\nsuggests that width-scaling considerations are surprisingly useful for\npredicting empirically optimal learning rate exponents. Finally, our analysis\nclarifies the effectiveness and limitations of recently proposed layerwise\nlearning rate scalings for standard initialization.", "published": "2025-05-28 15:40:48", "link": "http://arxiv.org/abs/2505.22491v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Closer Look at Multimodal Representation Collapse", "abstract": "We aim to develop a fundamental understanding of modality collapse, a\nrecently observed empirical phenomenon wherein models trained for multimodal\nfusion tend to rely only on a subset of the modalities, ignoring the rest. We\nshow that modality collapse happens when noisy features from one modality are\nentangled, via a shared set of neurons in the fusion head, with predictive\nfeatures from another, effectively masking out positive contributions from the\npredictive features of the former modality and leading to its collapse. We\nfurther prove that cross-modal knowledge distillation implicitly disentangles\nsuch representations by freeing up rank bottlenecks in the student encoder,\ndenoising the fusion-head outputs without negatively impacting the predictive\nfeatures from either modality. Based on the above findings, we propose an\nalgorithm that prevents modality collapse through explicit basis reallocation,\nwith applications in dealing with missing modalities. Extensive experiments on\nmultiple multimodal benchmarks validate our theoretical claims. Project page:\nhttps://abhrac.github.io/mmcollapse/.", "published": "2025-05-28 15:31:53", "link": "http://arxiv.org/abs/2505.22483v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Human-Centered Human-AI Collaboration (HCHAC)", "abstract": "In the intelligent era, the interaction between humans and intelligent\nsystems fundamentally involves collaboration with autonomous intelligent\nagents. Human-AI Collaboration (HAC) represents a novel type of human-machine\nrelationship facilitated by autonomous intelligent machines equipped with AI\ntechnologies. In this paradigm, AI agents serve not only as auxiliary tools but\nalso as active teammates, partnering with humans to accomplish tasks\ncollaboratively. Human-centered AI (HCAI) emphasizes that humans play critical\nleadership roles in the collaboration. This human-led collaboration imparts new\ndimensions to the human-machine relationship, necessitating innovative research\nperspectives, paradigms, and agenda to address the unique challenges posed by\nHAC. This chapter delves into the essence of HAC from the human-centered\nperspective, outlining its core concepts and distinguishing features. It\nreviews the current research methodologies and research agenda within the HAC\nfield from the HCAI perspective, highlighting advancements and ongoing studies.\nFurthermore, a framework for human-centered HAC (HCHAC) is proposed by\nintegrating these reviews and analyses. A case study of HAC in the context of\nautonomous vehicles is provided, illustrating practical applications and the\nsynergistic interactions between humans and AI agents. Finally, it identifies\npotential future research directions aimed at enhancing the effectiveness,\nreliability, and ethical integration of human-centered HAC systems in diverse\ndomains.", "published": "2025-05-28 15:27:52", "link": "http://arxiv.org/abs/2505.22477v1", "categories": ["cs.HC", "cs.AI", "cs.CY"], "primary_category": "cs.HC"}
{"title": "Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems", "abstract": "Large Language Model-based Multi-Agent Systems (MASs) have emerged as a\npowerful paradigm for tackling complex tasks through collaborative\nintelligence. Nevertheless, the question of how agents should be structurally\norganized for optimal cooperation remains largely unexplored. In this position\npaper, we aim to gently redirect the focus of the MAS research community toward\nthis critical dimension: develop topology-aware MASs for specific tasks.\nSpecifically, the system consists of three core components - agents,\ncommunication links, and communication patterns - that collectively shape its\ncoordination performance and efficiency. To this end, we introduce a\nsystematic, three-stage framework: agent selection, structure profiling, and\ntopology synthesis. Each stage would trigger new research opportunities in\nareas such as language models, reinforcement learning, graph learning, and\ngenerative modeling; together, they could unleash the full potential of MASs in\ncomplicated real-world applications. Then, we discuss the potential challenges\nand opportunities in the evaluation of multiple systems. We hope our\nperspective and framework can offer critical new insights in the era of agentic\nAI.", "published": "2025-05-28 15:20:09", "link": "http://arxiv.org/abs/2505.22467v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "AI Mathematician: Towards Fully Automated Frontier Mathematical Research", "abstract": "Large Reasoning Models (LRMs) have made significant progress in mathematical\ncapabilities in recent times. However, these successes have been primarily\nconfined to competition-level problems. In this work, we propose AI\nMathematician (AIM) framework, which harnesses the reasoning strength of LRMs\nto support frontier mathematical research. We have identified two critical\nchallenges of mathematical research compared to competition, {\\it the intrinsic\ncomplexity of research problems} and {\\it the requirement of procedural rigor}.\nTo address these challenges, AIM incorporates two core strategies: an\nexploration mechanism to foster longer solution paths, and the pessimistic\nreasonable verification method to ensure reliability.\n  This early version of AIM already exhibits strong capability in tackling\nresearch-level tasks. We conducted extensive experiments across several\nreal-world mathematical topics and obtained promising results. AIM is able to\nautonomously construct substantial portions of proofs and uncover non-trivial\ninsights within each research area. These findings highlight the potential of\nLRMs in mathematical discovery and suggest that LRM-based agent systems could\nsignificantly accelerate mathematical research in the future.", "published": "2025-05-28 15:10:37", "link": "http://arxiv.org/abs/2505.22451v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "NFR: Neural Feature-Guided Non-Rigid Shape Registration", "abstract": "In this paper, we propose a novel learning-based framework for 3D shape\nregistration, which overcomes the challenges of significant non-rigid\ndeformation and partiality undergoing among input shapes, and, remarkably,\nrequires no correspondence annotation during training. Our key insight is to\nincorporate neural features learned by deep learning-based shape matching\nnetworks into an iterative, geometric shape registration pipeline. The\nadvantage of our approach is two-fold -- On one hand, neural features provide\nmore accurate and semantically meaningful correspondence estimation than\nspatial features (e.g., coordinates), which is critical in the presence of\nlarge non-rigid deformations; On the other hand, the correspondences are\ndynamically updated according to the intermediate registrations and filtered by\nconsistency prior, which prominently robustify the overall pipeline. Empirical\nresults show that, with as few as dozens of training shapes of limited\nvariability, our pipeline achieves state-of-the-art results on several\nbenchmarks of non-rigid point cloud matching and partial shape matching across\nvarying settings, but also delivers high-quality correspondences between unseen\nchallenging shape pairs that undergo both significant extrinsic and intrinsic\ndeformations, in which case neither traditional registration methods nor\nintrinsic methods work.", "published": "2025-05-28 15:08:49", "link": "http://arxiv.org/abs/2505.22445v1", "categories": ["cs.CV", "cs.AI", "I.4.m; I.2.6"], "primary_category": "cs.CV"}
{"title": "SOReL and TOReL: Two Methods for Fully Offline Reinforcement Learning", "abstract": "Sample efficiency remains a major obstacle for real world adoption of\nreinforcement learning (RL): success has been limited to settings where\nsimulators provide access to essentially unlimited environment interactions,\nwhich in reality are typically costly or dangerous to obtain. Offline RL in\nprinciple offers a solution by exploiting offline data to learn a near-optimal\npolicy before deployment. In practice, however, current offline RL methods rely\non extensive online interactions for hyperparameter tuning, and have no\nreliable bound on their initial online performance. To address these two\nissues, we introduce two algorithms. Firstly, SOReL: an algorithm for safe\noffline reinforcement learning. Using only offline data, our Bayesian approach\ninfers a posterior over environment dynamics to obtain a reliable estimate of\nthe online performance via the posterior predictive uncertainty. Crucially, all\nhyperparameters are also tuned fully offline. Secondly, we introduce TOReL: a\ntuning for offline reinforcement learning algorithm that extends our\ninformation rate based offline hyperparameter tuning methods to general offline\nRL approaches. Our empirical evaluation confirms SOReL's ability to accurately\nestimate regret in the Bayesian setting whilst TOReL's offline hyperparameter\ntuning achieves competitive performance with the best online hyperparameter\ntuning methods using only offline data. Thus, SOReL and TOReL make a\nsignificant step towards safe and reliable offline RL, unlocking the potential\nfor RL in the real world. Our implementations are publicly available:\nhttps://github.com/CWibault/sorel\\_torel.", "published": "2025-05-28 15:07:24", "link": "http://arxiv.org/abs/2505.22442v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Can NeRFs See without Cameras?", "abstract": "Neural Radiance Fields (NeRFs) have been remarkably successful at\nsynthesizing novel views of 3D scenes by optimizing a volumetric scene\nfunction. This scene function models how optical rays bring color information\nfrom a 3D object to the camera pixels. Radio frequency (RF) or audio signals\ncan also be viewed as a vehicle for delivering information about the\nenvironment to a sensor. However, unlike camera pixels, an RF/audio sensor\nreceives a mixture of signals that contain many environmental reflections (also\ncalled \"multipath\"). Is it still possible to infer the environment using such\nmultipath signals? We show that with redesign, NeRFs can be taught to learn\nfrom multipath signals, and thereby \"see\" the environment. As a grounding\napplication, we aim to infer the indoor floorplan of a home from sparse WiFi\nmeasurements made at multiple locations inside the home. Although a difficult\ninverse problem, our implicitly learnt floorplans look promising, and enables\nforward applications, such as indoor signal prediction and basic ray tracing.", "published": "2025-05-28 15:04:46", "link": "http://arxiv.org/abs/2505.22441v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Synonymous Variational Inference for Perceptual Image Compression", "abstract": "Recent contributions of semantic information theory reveal the set-element\nrelationship between semantic and syntactic information, represented as\nsynonymous relationships. In this paper, we propose a synonymous variational\ninference (SVI) method based on this synonymity viewpoint to re-analyze the\nperceptual image compression problem. It takes perceptual similarity as a\ntypical synonymous criterion to build an ideal synonymous set (Synset), and\napproximate the posterior of its latent synonymous representation with a\nparametric density by minimizing a partial semantic KL divergence. This\nanalysis theoretically proves that the optimization direction of perception\nimage compression follows a triple tradeoff that can cover the existing\nrate-distortion-perception schemes. Additionally, we introduce synonymous image\ncompression (SIC), a new image compression scheme that corresponds to the\nanalytical process of SVI, and implement a progressive SIC codec to fully\nleverage the model's capabilities. Experimental results demonstrate comparable\nrate-distortion-perception performance using a single progressive SIC codec,\nthus verifying the effectiveness of our proposed analysis method.", "published": "2025-05-28 15:03:27", "link": "http://arxiv.org/abs/2505.22438v1", "categories": ["cs.IT", "cs.AI", "cs.CV", "cs.LG", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
{"title": "Physics-Informed Distillation of Diffusion Models for PDE-Constrained Generation", "abstract": "Modeling physical systems in a generative manner offers several advantages,\nincluding the ability to handle partial observations, generate diverse\nsolutions, and address both forward and inverse problems. Recently, diffusion\nmodels have gained increasing attention in the modeling of physical systems,\nparticularly those governed by partial differential equations (PDEs). However,\ndiffusion models only access noisy data $\\boldsymbol{x}_t$ at intermediate\nsteps, making it infeasible to directly enforce constraints on the clean sample\n$\\boldsymbol{x}_0$ at each noisy level. As a workaround, constraints are\ntypically applied to the expectation of clean samples\n$\\mathbb{E}[\\boldsymbol{x}_0|\\boldsymbol{x}_t]$, which is estimated using the\nlearned score network. However, imposing PDE constraints on the expectation\ndoes not strictly represent the one on the true clean data, known as Jensen's\nGap. This gap creates a trade-off: enforcing PDE constraints may come at the\ncost of reduced accuracy in generative modeling. To address this, we propose a\nsimple yet effective post-hoc distillation approach, where PDE constraints are\nnot injected directly into the diffusion process, but instead enforced during a\npost-hoc distillation stage. We term our method as Physics-Informed\nDistillation of Diffusion Models (PIDDM). This distillation not only\nfacilitates single-step generation with improved PDE satisfaction, but also\nsupport both forward and inverse problem solving and reconstruction from\nrandomly partial observation. Extensive experiments across various PDE\nbenchmarks demonstrate that PIDDM significantly improves PDE satisfaction over\nseveral recent and competitive baselines, such as PIDM, DiffusionPDE, and\nECI-sampling, with less computation overhead. Our approach can shed light on\nmore efficient and effective strategies for incorporating physical constraints\ninto diffusion models.", "published": "2025-05-28 14:17:58", "link": "http://arxiv.org/abs/2505.22391v1", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning", "abstract": "Continual Learning (CL) aims to enable models to continuously acquire new\nknowledge from a sequence of tasks with avoiding the forgetting of learned\ninformation. However, existing CL methods only rely on the parameters of the\nmost recent task for inference, which makes them susceptible to catastrophic\nforgetting. Inspired by the recent success of model merging techniques, we\npropose \\textbf{Perturb-and-Merge (P\\&M)}, a novel continual learning framework\nthat integrates model merging into the CL paradigm to mitigate forgetting.\nSpecifically, after training on each task, P\\&M constructs a new model by\nforming a convex combination of the previous model and the newly trained\ntask-specific model. Through theoretical analysis, we minimize the total loss\nincrease across all tasks and derive an analytical solution for the optimal\nmerging coefficient. To further improve the performance of the merged model, we\nobserve that the degradation introduced during merging can be alleviated by a\nregularization term composed of the task vector and the Hessian matrix of the\nloss function. Interestingly, we show that this term can be efficiently\napproximated using second-order symmetric finite differences, and a stochastic\nperturbation strategy along the task vector direction is accordingly devised\nwhich incurs no additional forward or backward passes while providing an\neffective approximation of the regularization term. Finally, we combine P\\&M\nwith LoRA, a parameter-efficient fine-tuning method, to reduce memory overhead.\nOur proposed approach achieves state-of-the-art performance on several\ncontinual learning benchmark datasets.", "published": "2025-05-28 14:14:19", "link": "http://arxiv.org/abs/2505.22389v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DAM: Domain-Aware Module for Multi-Domain Dataset Condensation", "abstract": "Dataset Condensation (DC) has emerged as a promising solution to mitigate the\ncomputational and storage burdens associated with training deep learning\nmodels. However, existing DC methods largely overlook the multi-domain nature\nof modern datasets, which are increasingly composed of heterogeneous images\nspanning multiple domains. In this paper, we extend DC and introduce\nMulti-Domain Dataset Condensation (MDDC), which aims to condense data that\ngeneralizes across both single-domain and multi-domain settings. To this end,\nwe propose the Domain-Aware Module (DAM), a training-time module that embeds\ndomain-related features into each synthetic image via learnable spatial masks.\nAs explicit domain labels are mostly unavailable in real-world datasets, we\nemploy frequency-based pseudo-domain labeling, which leverages low-frequency\namplitude statistics. DAM is only active during the condensation process, thus\npreserving the same images per class (IPC) with prior methods. Experiments show\nthat DAM consistently improves in-domain, out-of-domain, and cross-architecture\nperformance over baseline dataset condensation methods.", "published": "2025-05-28 14:13:38", "link": "http://arxiv.org/abs/2505.22387v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Exact Algorithms and Lower Bounds for Forming Coalitions of Constrained Maximum Size", "abstract": "Imagine we want to split a group of agents into teams in the most\n\\emph{efficient} way, considering that each agent has their own preferences\nabout their teammates. This scenario is modeled by the extensively studied\n\\textsc{Coalition Formation} problem. Here, we study a version of this problem\nwhere each team must additionally be of bounded size.\n  We conduct a systematic algorithmic study, providing several intractability\nresults as well as multiple exact algorithms that scale well as the input grows\n(FPT), which could prove useful in practice.\n  Our main contribution is an algorithm that deals efficiently with tree-like\nstructures (bounded \\emph{treewidth}) for ``small'' teams. We complement this\nresult by proving that our algorithm is asymptotically optimal. Particularly,\nthere can be no algorithm that vastly outperforms the one we present, under\nreasonable theoretical assumptions, even when considering star-like structures\n(bounded \\emph{vertex cover number}).", "published": "2025-05-28 14:11:14", "link": "http://arxiv.org/abs/2505.22384v1", "categories": ["cs.DS", "cs.AI"], "primary_category": "cs.DS"}
{"title": "SplitLoRA: Balancing Stability and Plasticity in Continual Learning Through Gradient Space Splitting", "abstract": "Continual Learning requires a model to learn multiple tasks in sequence while\nmaintaining both stability:preserving knowledge from previously learned tasks,\nand plasticity:effectively learning new tasks. Gradient projection has emerged\nas an effective and popular paradigm in CL, where it partitions the gradient\nspace of previously learned tasks into two orthogonal subspaces: a primary\nsubspace and a minor subspace. New tasks are learned effectively within the\nminor subspace, thereby reducing interference with previously acquired\nknowledge. However, existing Gradient Projection methods struggle to achieve an\noptimal balance between plasticity and stability, as it is hard to\nappropriately partition the gradient space. In this work, we consider a\ncontinual learning paradigm based on Low-Rank Adaptation, which has gained\nconsiderable attention due to its efficiency and wide applicability, and\npropose a novel approach for continual learning, called SplitLoRA. We first\nprovide a theoretical analysis of how subspace partitioning affects model\nstability and plasticity. Informed by this analysis, we then introduce an\neffective method that derives the optimal partition of the gradient space for\npreviously learned tasks. This approach effectively balances stability and\nplasticity in continual learning. Experimental results on multiple datasets\ndemonstrate that the proposed method achieves state-of-the-art performance.", "published": "2025-05-28 13:57:56", "link": "http://arxiv.org/abs/2505.22370v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AgentDNS: A Root Domain Naming System for LLM Agents", "abstract": "The rapid evolution of Large Language Model (LLM) agents has highlighted\ncritical challenges in cross-vendor service discovery, interoperability, and\ncommunication. Existing protocols like model context protocol and\nagent-to-agent protocol have made significant strides in standardizing\ninteroperability between agents and tools, as well as communication among\nmulti-agents. However, there remains a lack of standardized protocols and\nsolutions for service discovery across different agent and tool vendors. In\nthis paper, we propose AgentDNS, a root domain naming and service discovery\nsystem designed to enable LLM agents to autonomously discover, resolve, and\nsecurely invoke third-party agent and tool services across organizational and\ntechnological boundaries. Inspired by the principles of the traditional DNS,\nAgentDNS introduces a structured mechanism for service registration, semantic\nservice discovery, secure invocation, and unified billing. We detail the\narchitecture, core functionalities, and use cases of AgentDNS, demonstrating\nits potential to streamline multi-agent collaboration in real-world scenarios.\nThe source code will be published on https://github.com/agentdns.", "published": "2025-05-28 13:56:22", "link": "http://arxiv.org/abs/2505.22368v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Budget-Adaptive Adapter Tuning in Orthogonal Subspaces for Continual Learning in LLMs", "abstract": "Large language models (LLMs) often suffer from catastrophic forgetting in\ncontinual learning (CL) scenarios, where performance on previously learned\ntasks degrades severely while training on sequentially arriving tasks. Although\npioneering CL approaches using orthogonal subspaces can mitigate task\ninterference, they typically employ fixed budget allocation, neglecting the\nvarying complexity across tasks and layers. Besides, recent budget-adaptive\ntuning methods for LLMs often adopt multi-stage paradigms that decouple\noptimization and budget allocation. Such decoupling results in potential\nmisalignment, which hinders those approaches' practical application in CL\nscenarios. To address these limitations, we propose OA-Adapter, a novel\nparameter-efficient approach for continual learning in LLMs that unifies\ndynamic budget adaptation with orthogonal subspace learning in a single\nend-to-end training stage. Specifically, OA-Adapter introduces a dynamic\nbottleneck dimension adaptation mechanism that simultaneously allocates an\nefficient parameter budget and optimizes task objectives without misalignment.\nTo effectively preserve previously acquired knowledge while coordinating with\nthe dynamic budget allocation, orthogonal constraints are applied specifically\nbetween the parameter subspace of the current task and the dynamically\nallocated parameter subspaces of historical tasks. Experimental results on\ncontinual learning benchmarks demonstrate that OA-Adapter outperforms\nstate-of-the-art methods in both accuracy and parameter efficiency, achieving\nhigher average accuracy while using 58.5% fewer parameters on the standard CL\nbenchmark.", "published": "2025-05-28 13:38:21", "link": "http://arxiv.org/abs/2505.22358v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Suitability Filter: A Statistical Framework for Classifier Evaluation in Real-World Deployment Settings", "abstract": "Deploying machine learning models in safety-critical domains poses a key\nchallenge: ensuring reliable model performance on downstream user data without\naccess to ground truth labels for direct validation. We propose the suitability\nfilter, a novel framework designed to detect performance deterioration by\nutilizing suitability signals -- model output features that are sensitive to\ncovariate shifts and indicative of potential prediction errors. The suitability\nfilter evaluates whether classifier accuracy on unlabeled user data shows\nsignificant degradation compared to the accuracy measured on the labeled test\ndataset. Specifically, it ensures that this degradation does not exceed a\npre-specified margin, which represents the maximum acceptable drop in accuracy.\nTo achieve reliable performance evaluation, we aggregate suitability signals\nfor both test and user data and compare these empirical distributions using\nstatistical hypothesis testing, thus providing insights into decision\nuncertainty. Our modular method adapts to various models and domains. Empirical\nevaluations across different classification tasks demonstrate that the\nsuitability filter reliably detects performance deviations due to covariate\nshift. This enables proactive mitigation of potential failures in high-stakes\napplications.", "published": "2025-05-28 13:37:04", "link": "http://arxiv.org/abs/2505.22356v1", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "primary_category": "cs.LG"}
{"title": "VME: A Satellite Imagery Dataset and Benchmark for Detecting Vehicles in the Middle East and Beyond", "abstract": "Detecting vehicles in satellite images is crucial for traffic management,\nurban planning, and disaster response. However, current models struggle with\nreal-world diversity, particularly across different regions. This challenge is\namplified by geographic bias in existing datasets, which often focus on\nspecific areas and overlook regions like the Middle East. To address this gap,\nwe present the Vehicles in the Middle East (VME) dataset, designed explicitly\nfor vehicle detection in high-resolution satellite images from Middle Eastern\ncountries. Sourced from Maxar, the VME dataset spans 54 cities across 12\ncountries, comprising over 4,000 image tiles and more than 100,000 vehicles,\nannotated using both manual and semi-automated methods. Additionally, we\nintroduce the largest benchmark dataset for Car Detection in Satellite Imagery\n(CDSI), combining images from multiple sources to enhance global car detection.\nOur experiments demonstrate that models trained on existing datasets perform\npoorly on Middle Eastern images, while the VME dataset significantly improves\ndetection accuracy in this region. Moreover, state-of-the-art models trained on\nCDSI achieve substantial improvements in global car detection.", "published": "2025-05-28 13:34:05", "link": "http://arxiv.org/abs/2505.22353v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ChatPD: An LLM-driven Paper-Dataset Networking System", "abstract": "Scientific research heavily depends on suitable datasets for method\nvalidation, but existing academic platforms with dataset management like\nPapersWithCode suffer from inefficiencies in their manual workflow. To overcome\nthis bottleneck, we present a system, called ChatPD, that utilizes Large\nLanguage Models (LLMs) to automate dataset information extraction from academic\npapers and construct a structured paper-dataset network. Our system consists of\nthree key modules: \\textit{paper collection}, \\textit{dataset information\nextraction}, and \\textit{dataset entity resolution} to construct paper-dataset\nnetworks. Specifically, we propose a \\textit{Graph Completion and Inference}\nstrategy to map dataset descriptions to their corresponding entities. Through\nextensive experiments, we demonstrate that ChatPD not only outperforms the\nexisting platform PapersWithCode in dataset usage extraction but also achieves\nabout 90\\% precision and recall in entity resolution tasks. Moreover, we have\ndeployed ChatPD to continuously extract which datasets are used in papers, and\nprovide a dataset discovery service, such as task-specific dataset queries and\nsimilar dataset recommendations. We open source ChatPD and the current\npaper-dataset network on this [GitHub\nrepository]{https://github.com/ChatPD-web/ChatPD}.", "published": "2025-05-28 13:31:08", "link": "http://arxiv.org/abs/2505.22349v1", "categories": ["cs.DB", "cs.AI", "cs.IR"], "primary_category": "cs.DB"}
{"title": "Empowering Intelligent Low-altitude Economy with Large AI Model Deployment", "abstract": "Low-altitude economy (LAE) represents an emerging economic paradigm that\nredefines commercial and social aerial activities. Large artificial\nintelligence models (LAIMs) offer transformative potential to further enhance\nthe intelligence of LAE services. However, deploying LAIMs in LAE poses several\nchallenges, including the significant gap between their computational/storage\ndemands and the limited onboard resources of LAE entities, the mismatch between\nlab-trained LAIMs and dynamic physical environments, and the inefficiencies of\ntraditional decoupled designs for sensing, communication, and computation. To\naddress these issues, we first propose a hierarchical system architecture\ntailored for LAIM deployment and present representative LAE application\nscenarios. Next, we explore key enabling techniques that facilitate the mutual\nco-evolution of LAIMs and low-altitude systems, and introduce a task-oriented\nexecution pipeline for scalable and adaptive service delivery. Then, the\nproposed framework is validated through real-world case studies. Finally, we\noutline open challenges to inspire future research.", "published": "2025-05-28 13:27:07", "link": "http://arxiv.org/abs/2505.22343v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications", "abstract": "With the advent of 6G communications, intelligent communication systems face\nmultiple challenges, including constrained perception and response\ncapabilities, limited scalability, and low adaptability in dynamic\nenvironments. This tutorial provides a systematic introduction to the\nprinciples, design, and applications of Large Artificial Intelligence Models\n(LAMs) and Agentic AI technologies in intelligent communication systems, aiming\nto offer researchers a comprehensive overview of cutting-edge technologies and\npractical guidance. First, we outline the background of 6G communications,\nreview the technological evolution from LAMs to Agentic AI, and clarify the\ntutorial's motivation and main contributions. Subsequently, we present a\ncomprehensive review of the key components required for constructing LAMs. We\nfurther categorize LAMs and analyze their applicability, covering Large\nLanguage Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models\n(LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a\nLAM-centric design paradigm tailored for communications, encompassing dataset\nconstruction and both internal and external learning approaches. Building upon\nthis, we develop an LAM-based Agentic AI system for intelligent communications,\nclarifying its core components such as planners, knowledge bases, tools, and\nmemory modules, as well as its interaction mechanisms. We also introduce a\nmulti-agent framework with data retrieval, collaborative planning, and\nreflective evaluation for 6G. Subsequently, we provide a detailed overview of\nthe applications of LAMs and Agentic AI in communication scenarios. Finally, we\nsummarize the research challenges and future directions in current studies,\naiming to support the development of efficient, secure, and sustainable\nnext-generation intelligent communication systems.", "published": "2025-05-28 12:54:07", "link": "http://arxiv.org/abs/2505.22311v1", "categories": ["cs.AI", "cs.CY", "cs.NI", "eess.SP"], "primary_category": "cs.AI"}
{"title": "From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization", "abstract": "Recent unlearning methods for LLMs are vulnerable to relearning attacks:\nknowledge believed-to-be-unlearned re-emerges by fine-tuning on a small set of\n(even seemingly-unrelated) examples. We study this phenomenon in a controlled\nsetting for example-level unlearning in vision classifiers. We make the\nsurprising discovery that forget-set accuracy can recover from around 50%\npost-unlearning to nearly 100% with fine-tuning on just the retain set -- i.e.,\nzero examples of the forget set. We observe this effect across a wide variety\nof unlearning methods, whereas for a model retrained from scratch excluding the\nforget set (gold standard), the accuracy remains at 50%. We observe that\nresistance to relearning attacks can be predicted by weight-space properties,\nspecifically, $L_2$-distance and linear mode connectivity between the original\nand the unlearned model. Leveraging this insight, we propose a new class of\nmethods that achieve state-of-the-art resistance to relearning attacks.", "published": "2025-05-28 12:53:08", "link": "http://arxiv.org/abs/2505.22310v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Versatile Cardiovascular Signal Generation with a Unified Diffusion Transformer", "abstract": "Cardiovascular signals such as photoplethysmography (PPG),\nelectrocardiography (ECG), and blood pressure (BP) are inherently correlated\nand complementary, together reflecting the health of cardiovascular system.\nHowever, their joint utilization in real-time monitoring is severely limited by\ndiverse acquisition challenges from noisy wearable recordings to burdened\ninvasive procedures. Here we propose UniCardio, a multi-modal diffusion\ntransformer that reconstructs low-quality signals and synthesizes unrecorded\nsignals in a unified generative framework. Its key innovations include a\nspecialized model architecture to manage the signal modalities involved in\ngeneration tasks and a continual learning paradigm to incorporate varying\nmodality combinations. By exploiting the complementary nature of cardiovascular\nsignals, UniCardio clearly outperforms recent task-specific baselines in signal\ndenoising, imputation, and translation. The generated signals match the\nperformance of ground-truth signals in detecting abnormal health conditions and\nestimating vital signs, even in unseen domains, while ensuring interpretability\nfor human experts. These advantages position UniCardio as a promising avenue\nfor advancing AI-assisted healthcare.", "published": "2025-05-28 12:45:39", "link": "http://arxiv.org/abs/2505.22306v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Voice CMS: updating the knowledge base of a digital assistant through conversation", "abstract": "In this study, we propose a solution based on a multi-agent LLM architecture\nand a voice user interface (VUI) designed to update the knowledge base of a\ndigital assistant. Its usability is evaluated in comparison to a more\ntraditional graphical content management system (CMS), with a focus on\nunderstanding the relationship between user preferences and the complexity of\nthe information being provided. The findings demonstrate that, while the\noverall usability of the VUI is rated lower than the graphical interface, it is\nalready preferred by users for less complex tasks. Furthermore, the quality of\ncontent entered through the VUI is comparable to that achieved with the\ngraphical interface, even for highly complex tasks. Obtained qualitative\nresults suggest that a hybrid interface combining the strengths of both\napproaches could address the key challenges identified during the experiment,\nsuch as reducing cognitive load through graphical feedback while maintaining\nthe intuitive nature of voice-based interactions. This work highlights the\npotential of conversational interfaces as a viable and effective method for\nknowledge management in specific business contexts.", "published": "2025-05-28 12:40:37", "link": "http://arxiv.org/abs/2505.22303v1", "categories": ["cs.HC", "cs.AI", "cs.MA"], "primary_category": "cs.HC"}
{"title": "Neural Restoration of Greening Defects in Historical Autochrome Photographs Based on Purely Synthetic Data", "abstract": "The preservation of early visual arts, particularly color photographs, is\nchallenged by deterioration caused by aging and improper storage, leading to\nissues like blurring, scratches, color bleeding, and fading defects. In this\npaper, we present the first approach for the automatic removal of greening\ncolor defects in digitized autochrome photographs. Our main contributions\ninclude a method based on synthetic dataset generation and the use of\ngenerative AI with a carefully designed loss function for the restoration of\nvisual arts. To address the lack of suitable training datasets for analyzing\ngreening defects in damaged autochromes, we introduce a novel approach for\naccurately simulating such defects in synthetic data. We also propose a\nmodified weighted loss function for the ChaIR method to account for color\nimbalances between defected and non-defected areas. While existing methods\nstruggle with accurately reproducing original colors and may require\nsignificant manual effort, our method allows for efficient restoration with\nreduced time requirements.", "published": "2025-05-28 12:28:35", "link": "http://arxiv.org/abs/2505.22291v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Compression versus Accuracy: A Hierarchy of Lifted Models", "abstract": "Probabilistic graphical models that encode indistinguishable objects and\nrelations among them use first-order logic constructs to compress a\npropositional factorised model for more efficient (lifted) inference. To obtain\na lifted representation, the state-of-the-art algorithm Advanced Colour Passing\n(ACP) groups factors that represent matching distributions. In an approximate\nversion using $\\varepsilon$ as a hyperparameter, factors are grouped that\ndiffer by a factor of at most $(1\\pm \\varepsilon)$. However, finding a suitable\n$\\varepsilon$ is not obvious and may need a lot of exploration, possibly\nrequiring many ACP runs with different $\\varepsilon$ values. Additionally,\nvarying $\\varepsilon$ can yield wildly different models, leading to decreased\ninterpretability. Therefore, this paper presents a hierarchical approach to\nlifted model construction that is hyperparameter-free. It efficiently computes\na hierarchy of $\\varepsilon$ values that ensures a hierarchy of models, meaning\nthat once factors are grouped together given some $\\varepsilon$, these factors\nwill be grouped together for larger $\\varepsilon$ as well. The hierarchy of\n$\\varepsilon$ values also leads to a hierarchy of error bounds. This allows for\nexplicitly weighing compression versus accuracy when choosing specific\n$\\varepsilon$ values to run ACP with and enables interpretability between the\ndifferent models.", "published": "2025-05-28 12:27:32", "link": "http://arxiv.org/abs/2505.22288v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "New Tools are Needed for Tracking Adherence to AI Model Behavioral Use Clauses", "abstract": "Foundation models have had a transformative impact on AI. A combination of\nlarge investments in research and development, growing sources of digital data\nfor training, and architectures that scale with data and compute has led to\nmodels with powerful capabilities. Releasing assets is fundamental to\nscientific advancement and commercial enterprise. However, concerns over\nnegligent or malicious uses of AI have led to the design of mechanisms to limit\nthe risks of the technology. The result has been a proliferation of licenses\nwith behavioral-use clauses and acceptable-use-policies that are increasingly\nbeing adopted by commonly used families of models (Llama, Gemma, Deepseek) and\na myriad of smaller projects. We created and deployed a custom AI licenses\ngenerator to facilitate license creation and have quantitatively and\nqualitatively analyzed over 300 customized licenses created with this tool.\nAlongside this we analyzed 1.7 million models licenses on the HuggingFace model\nhub. Our results show increasing adoption of these licenses, interest in tools\nthat support their creation and a convergence on common clause configurations.\nIn this paper we take the position that tools for tracking adoption of, and\nadherence to, these licenses is the natural next step and urgently needed in\norder to ensure they have the desired impact of ensuring responsible use.", "published": "2025-05-28 12:26:55", "link": "http://arxiv.org/abs/2505.22287v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "A Preprocessing Framework for Efficient Approximate Bi-Objective Shortest-Path Computation in the Presence of Correlated Objectives", "abstract": "The bi-objective shortest-path (BOSP) problem seeks to find paths between\nstart and target vertices of a graph while optimizing two conflicting objective\nfunctions. We consider the BOSP problem in the presence of correlated\nobjectives. Such correlations often occur in real-world settings such as road\nnetworks, where optimizing two positively correlated objectives, such as travel\ntime and fuel consumption, is common. BOSP is generally computationally\nchallenging as the size of the search space is exponential in the number of\nobjective functions and the graph size. Bounded sub-optimal BOSP solvers such\nas A*pex alleviate this complexity by approximating the Pareto-optimal solution\nset rather than computing it exactly (given a user-provided approximation\nfactor). As the correlation between objective functions increases, smaller\napproximation factors are sufficient for collapsing the entire Pareto-optimal\nset into a single solution. We leverage this insight to propose an efficient\nalgorithm that reduces the search effort in the presence of correlated\nobjectives. Our approach for computing approximations of the entire\nPareto-optimal set is inspired by graph-clustering algorithms. It uses a\npreprocessing phase to identify correlated clusters within a graph and to\ngenerate a new graph representation. This allows a natural generalization of\nA*pex to run up to five times faster on DIMACS dataset instances, a standard\nbenchmark in the field. To the best of our knowledge, this is the first\nalgorithm proposed that efficiently and effectively exploits correlations in\nthe context of bi-objective search while providing theoretical guarantees on\nsolution quality.", "published": "2025-05-28 11:26:14", "link": "http://arxiv.org/abs/2505.22244v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Solver-Free Decision-Focused Learning for Linear Optimization Problems", "abstract": "Mathematical optimization is a fundamental tool for decision-making in a wide\nrange of applications. However, in many real-world scenarios, the parameters of\nthe optimization problem are not known a priori and must be predicted from\ncontextual features. This gives rise to predict-then-optimize problems, where a\nmachine learning model predicts problem parameters that are then used to make\ndecisions via optimization. A growing body of work on decision-focused learning\n(DFL) addresses this setting by training models specifically to produce\npredictions that maximize downstream decision quality, rather than accuracy.\nWhile effective, DFL is computationally expensive, because it requires solving\nthe optimization problem with the predicted parameters at each loss evaluation.\nIn this work, we address this computational bottleneck for linear optimization\nproblems, a common class of problems in both DFL literature and real-world\napplications. We propose a solver-free training method that exploits the\ngeometric structure of linear optimization to enable efficient training with\nminimal degradation in solution quality. Our method is based on the insight\nthat a solution is optimal if and only if it achieves an objective value that\nis at least as good as that of its adjacent vertices on the feasible polytope.\nBuilding on this, our method compares the estimated quality of the ground-truth\noptimal solution with that of its precomputed adjacent vertices, and uses this\nas loss function. Experiments demonstrate that our method significantly reduces\ncomputational cost while maintaining high decision quality.", "published": "2025-05-28 10:55:16", "link": "http://arxiv.org/abs/2505.22224v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Investigating Mechanisms for In-Context Vision Language Binding", "abstract": "To understand a prompt, Vision-Language models (VLMs) must perceive the\nimage, comprehend the text, and build associations within and across both\nmodalities. For instance, given an 'image of a red toy car', the model should\nassociate this image to phrases like 'car', 'red toy', 'red object', etc. Feng\nand Steinhardt propose the Binding ID mechanism in LLMs, suggesting that the\nentity and its corresponding attribute tokens share a Binding ID in the model\nactivations. We investigate this for image-text binding in VLMs using a\nsynthetic dataset and task that requires models to associate 3D objects in an\nimage with their descriptions in the text. Our experiments demonstrate that\nVLMs assign a distinct Binding ID to an object's image tokens and its textual\nreferences, enabling in-context association.", "published": "2025-05-28 10:25:43", "link": "http://arxiv.org/abs/2505.22200v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Enhancing Uncertainty Estimation and Interpretability via Bayesian Non-negative Decision Layer", "abstract": "Although deep neural networks have demonstrated significant success due to\ntheir powerful expressiveness, most models struggle to meet practical\nrequirements for uncertainty estimation. Concurrently, the entangled nature of\ndeep neural networks leads to a multifaceted problem, where various localized\nexplanation techniques reveal that multiple unrelated features influence the\ndecisions, thereby undermining interpretability. To address these challenges,\nwe develop a Bayesian Non-negative Decision Layer (BNDL), which reformulates\ndeep neural networks as a conditional Bayesian non-negative factor analysis. By\nleveraging stochastic latent variables, the BNDL can model complex dependencies\nand provide robust uncertainty estimation. Moreover, the sparsity and\nnon-negativity of the latent variables encourage the model to learn\ndisentangled representations and decision layers, thereby improving\ninterpretability. We also offer theoretical guarantees that BNDL can achieve\neffective disentangled learning. In addition, we developed a corresponding\nvariational inference method utilizing a Weibull variational inference network\nto approximate the posterior distribution of the latent variables. Our\nexperimental results demonstrate that with enhanced disentanglement\ncapabilities, BNDL not only improves the model's accuracy but also provides\nreliable uncertainty estimation and improved interpretability.", "published": "2025-05-28 10:23:34", "link": "http://arxiv.org/abs/2505.22199v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Physics-inspired Generative AI models via real hardware-based noisy quantum diffusion", "abstract": "Quantum Diffusion Models (QDMs) are an emerging paradigm in Generative AI\nthat aims to use quantum properties to improve the performances of their\nclassical counterparts. However, existing algorithms are not easily scalable\ndue to the limitations of near-term quantum devices. Following our previous\nwork on QDMs, here we propose and implement two physics-inspired protocols. In\nthe first, we use the formalism of quantum stochastic walks, showing that a\nspecific interplay of quantum and classical dynamics in the forward process\nproduces statistically more robust models generating sets of MNIST images with\nlower Fr\\'echet Inception Distance (FID) than using totally classical dynamics.\nIn the second approach, we realize an algorithm to generate images by\nexploiting the intrinsic noise of real IBM quantum hardware with only four\nqubits. Our work could be a starting point to pave the way for new scenarios\nfor large-scale algorithms in quantum Generative AI, where quantum noise is\nneither mitigated nor corrected, but instead exploited as a useful resource.", "published": "2025-05-28 10:11:48", "link": "http://arxiv.org/abs/2505.22193v1", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.AI", "cs.CV", "cs.LG", "81P68, 81P40, 81P47, 68Q12, 68T07,", "I.2.6; I.3.3; J.2"], "primary_category": "quant-ph"}
{"title": "Online Fair Division for Personalized $2$-Value Instances", "abstract": "We study an online fair division setting, where goods arrive one at a time\nand there is a fixed set of $n$ agents, each of whom has an additive valuation\nfunction over the goods. Once a good appears, the value each agent has for it\nis revealed and it must be allocated immediately and irrevocably to one of the\nagents. It is known that without any assumptions about the values being\nseverely restricted or coming from a distribution, very strong impossibility\nresults hold in this setting. To bypass the latter, we turn our attention to\ninstances where the valuation functions are restricted. In particular, we study\npersonalized $2$-value instances, where there are only two possible values each\nagent may have for each good, possibly different across agents, and we show how\nto obtain worst case guarantees with respect to well-known fairness notions,\nsuch as maximin share fairness and envy-freeness up to one (or two) good(s). We\nsuggest a deterministic algorithm that maintains a $1/(2n-1)$-MMS allocation at\nevery time step and show that this is the best possible any deterministic\nalgorithm can achieve if one cares about every single time step; nevertheless,\neventually the allocation constructed by our algorithm becomes a $1/4$-MMS\nallocation. To achieve this, the algorithm implicitly maintains a fragile\nsystem of priority levels for all agents. Further, we show that, by allowing\nsome limited access to future information, it is possible to have stronger\nresults with less involved approaches. By knowing the values of goods for $n-1$\ntime steps into the future, we design a matching-based algorithm that achieves\nan EF$1$ allocation every $n$ time steps, while always maintaining an EF$2$\nallocation. Finally, we show that our results allow us to get the first\nnontrivial guarantees for additive instances in which the ratio of the maximum\nover the minimum value an agent has for a good is bounded.", "published": "2025-05-28 09:48:16", "link": "http://arxiv.org/abs/2505.22174v1", "categories": ["cs.GT", "cs.AI", "cs.MA"], "primary_category": "cs.GT"}
{"title": "What Makes a Good Reasoning Chain? Uncovering Structural Patterns in Long Chain-of-Thought Reasoning", "abstract": "Recent advances in reasoning with large language models (LLMs) have\npopularized Long Chain-of-Thought (LCoT), a strategy that encourages deliberate\nand step-by-step reasoning before producing a final answer. While LCoTs have\nenabled expert-level performance in complex tasks, how the internal structures\nof their reasoning chains drive, or even predict, the correctness of final\nanswers remains a critical yet underexplored question. In this work, we present\nLCoT2Tree, an automated framework that converts sequential LCoTs into\nhierarchical tree structures and thus enables deeper structural analysis of LLM\nreasoning. Using graph neural networks (GNNs), we reveal that structural\npatterns extracted by LCoT2Tree, including exploration, backtracking, and\nverification, serve as stronger predictors of final performance across a wide\nrange of tasks and models. Leveraging an explainability technique, we further\nidentify critical thought patterns such as over-branching that account for\nfailures. Beyond diagnostic insights, the structural patterns by LCoT2Tree\nsupport practical applications, including improving Best-of-N decoding\neffectiveness. Overall, our results underscore the critical role of internal\nstructures of reasoning chains, positioning LCoT2Tree as a powerful tool for\ndiagnosing, interpreting, and improving reasoning in LLMs.", "published": "2025-05-28 09:12:31", "link": "http://arxiv.org/abs/2505.22148v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions", "abstract": "Decision making is a central problem in AI that can be formalized using a\nMarkov Decision Process. A problem is that, with increasing numbers of\n(indistinguishable) objects, the state space grows exponentially. To compute\npolicies, the state space has to be enumerated. Even more possibilities have to\nbe enumerated if the size of the action space depends on the size of the state\nspace, especially if we allow concurrent actions. To tackle the exponential\nblow-up in the action and state space, we present a first-order representation\nto store the spaces in polynomial instead of exponential size in the number of\nobjects and introduce Foreplan, a relational forward planner, which uses this\nrepresentation to efficiently compute policies for numerous indistinguishable\nobjects and actions. Additionally, we introduce an even faster approximate\nversion of Foreplan. Moreover, Foreplan identifies how many objects an agent\nshould act on to achieve a certain task given restrictions. Further, we provide\na theoretical analysis and an empirical evaluation of Foreplan, demonstrating a\nspeedup of at least four orders of magnitude.", "published": "2025-05-28 09:08:27", "link": "http://arxiv.org/abs/2505.22147v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FaceEditTalker: Interactive Talking Head Generation with Facial Attribute Editing", "abstract": "Recent advances in audio-driven talking head generation have achieved\nimpressive results in lip synchronization and emotional expression. However,\nthey largely overlook the crucial task of facial attribute editing. This\ncapability is crucial for achieving deep personalization and expanding the\nrange of practical applications, including user-tailored digital avatars,\nengaging online education content, and brand-specific digital customer service.\nIn these key domains, the flexible adjustment of visual attributes-such as\nhairstyle, accessories, and subtle facial features is essential for aligning\nwith user preferences, reflecting diverse brand identities, and adapting to\nvarying contextual demands. In this paper, we present FaceEditTalker, a unified\nframework that enables controllable facial attribute manipulation while\ngenerating high-quality, audio-synchronized talking head videos. Our method\nconsists of two key components: an image feature space editing module, which\nextracts semantic and detail features and allows flexible control over\nattributes like expression, hairstyle, and accessories; and an audio-driven\nvideo generation module, which fuses these edited features with audio-guided\nfacial landmarks to drive a diffusion-based generator. This design ensures\ntemporal coherence, visual fidelity, and identity preservation across frames.\nExtensive experiments on public datasets demonstrate that our method\noutperforms state-of-the-art approaches in lip-sync accuracy, video quality,\nand attribute controllability. Project page:\nhttps://peterfanfan.github.io/FaceEditTalker/", "published": "2025-05-28 09:04:00", "link": "http://arxiv.org/abs/2505.22141v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Real-Time Blind Defocus Deblurring for Earth Observation: The IMAGIN-e Mission Approach", "abstract": "This work addresses mechanical defocus in Earth observation images from the\nIMAGIN-e mission aboard the ISS, proposing a blind deblurring approach adapted\nto space-based edge computing constraints. Leveraging Sentinel-2 data, our\nmethod estimates the defocus kernel and trains a restoration model within a GAN\nframework, effectively operating without reference images.\n  On Sentinel-2 images with synthetic degradation, SSIM improved by 72.47% and\nPSNR by 25.00%, confirming the model's ability to recover lost details when the\noriginal clean image is known. On IMAGIN-e, where no reference images exist,\nperceptual quality metrics indicate a substantial enhancement, with NIQE\nimproving by 60.66% and BRISQUE by 48.38%, validating real-world onboard\nrestoration. The approach is currently deployed aboard the IMAGIN-e mission,\ndemonstrating its practical application in an operational space environment.\n  By efficiently handling high-resolution images under edge computing\nconstraints, the method enables applications such as water body segmentation\nand contour detection while maintaining processing viability despite resource\nlimitations.", "published": "2025-05-28 08:52:38", "link": "http://arxiv.org/abs/2505.22128v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SridBench: Benchmark of Scientific Research Illustration Drawing of Image Generation Model", "abstract": "Recent years have seen rapid advances in AI-driven image generation. Early\ndiffusion models emphasized perceptual quality, while newer multimodal models\nlike GPT-4o-image integrate high-level reasoning, improving semantic\nunderstanding and structural composition. Scientific illustration generation\nexemplifies this evolution: unlike general image synthesis, it demands accurate\ninterpretation of technical content and transformation of abstract ideas into\nclear, standardized visuals. This task is significantly more\nknowledge-intensive and laborious, often requiring hours of manual work and\nspecialized tools. Automating it in a controllable, intelligent manner would\nprovide substantial practical value. Yet, no benchmark currently exists to\nevaluate AI on this front. To fill this gap, we introduce SridBench, the first\nbenchmark for scientific figure generation. It comprises 1,120 instances\ncurated from leading scientific papers across 13 natural and computer science\ndisciplines, collected via human experts and MLLMs. Each sample is evaluated\nalong six dimensions, including semantic fidelity and structural accuracy.\nExperimental results reveal that even top-tier models like GPT-4o-image lag\nbehind human performance, with common issues in text/visual clarity and\nscientific correctness. These findings highlight the need for more advanced\nreasoning-driven visual generation capabilities.", "published": "2025-05-28 08:51:01", "link": "http://arxiv.org/abs/2505.22126v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Sentiment Simulation using Generative AI Agents", "abstract": "Traditional sentiment analysis relies on surface-level linguistic patterns\nand retrospective data, limiting its ability to capture the psychological and\ncontextual drivers of human sentiment. These limitations constrain its\neffectiveness in applications that require predictive insight, such as policy\ntesting, narrative framing, and behavioral forecasting. We present a robust\nframework for sentiment simulation using generative AI agents embedded with\npsychologically rich profiles. Agents are instantiated from a nationally\nrepresentative survey of 2,485 Filipino respondents, combining sociodemographic\ninformation with validated constructs of personality traits, values, beliefs,\nand socio-political attitudes. The framework includes three stages: (1) agent\nembodiment via categorical or contextualized encodings, (2) exposure to\nreal-world political and economic scenarios, and (3) generation of sentiment\nratings accompanied by explanatory rationales. Using Quadratic Weighted\nAccuracy (QWA), we evaluated alignment between agent-generated and human\nresponses. Contextualized encoding achieved 92% alignment in replicating\noriginal survey responses. In sentiment simulation tasks, agents reached\n81%--86% accuracy against ground truth sentiment, with contextualized profile\nencodings significantly outperforming categorical (p < 0.0001, Cohen's d =\n0.70). Simulation results remained consistent across repeated trials\n(+/-0.2--0.5% SD) and resilient to variation in scenario framing (p = 0.9676,\nCohen's d = 0.02). Our findings establish a scalable framework for sentiment\nmodeling through psychographically grounded AI agents. This work signals a\nparadigm shift in sentiment analysis from retrospective classification to\nprospective and dynamic simulation grounded in psychology of sentiment\nformation.", "published": "2025-05-28 08:50:56", "link": "http://arxiv.org/abs/2505.22125v1", "categories": ["cs.MA", "cs.AI", "cs.CY", "I.2; I.6; J.4"], "primary_category": "cs.MA"}
{"title": "Visual Large Language Models Exhibit Human-Level Cognitive Flexibility in the Wisconsin Card Sorting Test", "abstract": "Cognitive flexibility has been extensively studied in human cognition but\nremains relatively unexplored in the context of Visual Large Language Models\n(VLLMs). This study assesses the cognitive flexibility of state-of-the-art\nVLLMs (GPT-4o, Gemini-1.5 Pro, and Claude-3.5 Sonnet) using the Wisconsin Card\nSorting Test (WCST), a classic measure of set-shifting ability. Our results\nreveal that VLLMs achieve or surpass human-level set-shifting capabilities\nunder chain-of-thought prompting with text-based inputs. However, their\nabilities are highly influenced by both input modality and prompting strategy.\nIn addition, we find that through role-playing, VLLMs can simulate various\nfunctional deficits aligned with patients having impairments in cognitive\nflexibility, suggesting that VLLMs may possess a cognitive architecture, at\nleast regarding the ability of set-shifting, similar to the brain. This study\nreveals the fact that VLLMs have already approached the human level on a key\ncomponent underlying our higher cognition, and highlights the potential to use\nthem to emulate complex brain processes.", "published": "2025-05-28 08:40:55", "link": "http://arxiv.org/abs/2505.22112v1", "categories": ["cs.AI", "q-bio.NC"], "primary_category": "cs.AI"}
{"title": "The quest for the GRAph Level autoEncoder (GRALE)", "abstract": "Although graph-based learning has attracted a lot of attention, graph\nrepresentation learning is still a challenging task whose resolution may impact\nkey application fields such as chemistry or biology. To this end, we introduce\nGRALE, a novel graph autoencoder that encodes and decodes graphs of varying\nsizes into a shared embedding space. GRALE is trained using an Optimal\nTransport-inspired loss that compares the original and reconstructed graphs and\nleverages a differentiable node matching module, which is trained jointly with\nthe encoder and decoder. The proposed attention-based architecture relies on\nEvoformer, the core component of AlphaFold, which we extend to support both\ngraph encoding and decoding. We show, in numerical experiments on simulated and\nmolecular data, that GRALE enables a highly general form of pre-training,\napplicable to a wide range of downstream tasks, from classification and\nregression to more complex tasks such as graph interpolation, editing,\nmatching, and prediction.", "published": "2025-05-28 08:37:33", "link": "http://arxiv.org/abs/2505.22109v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Inclusive, Differentially Private Federated Learning for Clinical Data", "abstract": "Federated Learning (FL) offers a promising approach for training clinical AI\nmodels without centralizing sensitive patient data. However, its real-world\nadoption is hindered by challenges related to privacy, resource constraints,\nand compliance. Existing Differential Privacy (DP) approaches often apply\nuniform noise, which disproportionately degrades model performance, even among\nwell-compliant institutions. In this work, we propose a novel compliance-aware\nFL framework that enhances DP by adaptively adjusting noise based on\nquantifiable client compliance scores. Additionally, we introduce a compliance\nscoring tool based on key healthcare and security standards to promote secure,\ninclusive, and equitable participation across diverse clinical settings.\nExtensive experiments on public datasets demonstrate that integrating\nunder-resourced, less compliant clinics with highly regulated institutions\nyields accuracy improvements of up to 15% over traditional FL. This work\nadvances FL by balancing privacy, compliance, and performance, making it a\nviable solution for real-world clinical workflows in global healthcare.", "published": "2025-05-28 08:36:21", "link": "http://arxiv.org/abs/2505.22108v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "primary_category": "cs.LG"}
{"title": "AudioTurbo: Fast Text-to-Audio Generation with Rectified Diffusion", "abstract": "Diffusion models have significantly improved the quality and diversity of\naudio generation but are hindered by slow inference speed. Rectified flow\nenhances inference speed by learning straight-line ordinary differential\nequation (ODE) paths. However, this approach requires training a flow-matching\nmodel from scratch and tends to perform suboptimally, or even poorly, at low\nstep counts. To address the limitations of rectified flow while leveraging the\nadvantages of advanced pre-trained diffusion models, this study integrates\npre-trained models with the rectified diffusion method to improve the\nefficiency of text-to-audio (TTA) generation. Specifically, we propose\nAudioTurbo, which learns first-order ODE paths from deterministic noise sample\npairs generated by a pre-trained TTA model. Experiments on the AudioCaps\ndataset demonstrate that our model, with only 10 sampling steps, outperforms\nprior models and reduces inference to 3 steps compared to a flow-matching-based\nacceleration model.", "published": "2025-05-28 08:33:58", "link": "http://arxiv.org/abs/2505.22106v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Dynamic Shielding for Parametric Safety Specifications", "abstract": "Shielding has emerged as a promising approach for ensuring safety of\nAI-controlled autonomous systems. The algorithmic goal is to compute a shield,\nwhich is a runtime safety enforcement tool that needs to monitor and intervene\nthe AI controller's actions if safety could be compromised otherwise.\nTraditional shields are designed statically for a specific safety requirement.\nTherefore, if the safety requirement changes at runtime due to changing\noperating conditions, the shield needs to be recomputed from scratch, causing\ndelays that could be fatal. We introduce dynamic shields for parametric safety\nspecifications, which are succinctly represented sets of all possible safety\nspecifications that may be encountered at runtime. Our dynamic shields are\nstatically designed for a given safety parameter set, and are able to\ndynamically adapt as the true safety specification (permissible by the\nparameters) is revealed at runtime. The main algorithmic novelty lies in the\ndynamic adaptation procedure, which is a simple and fast algorithm that\nutilizes known features of standard safety shields, like maximal\npermissiveness. We report experimental results for a robot navigation problem\nin unknown territories, where the safety specification evolves as new obstacles\nare discovered at runtime. In our experiments, the dynamic shields took a few\nminutes for their offline design, and took between a fraction of a second and a\nfew seconds for online adaptation at each step, whereas the brute-force online\nrecomputation approach was up to 5 times slower.", "published": "2025-05-28 08:30:03", "link": "http://arxiv.org/abs/2505.22104v1", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "From Coders to Critics: Empowering Students through Peer Assessment in the Age of AI Copilots", "abstract": "The rapid adoption of AI powered coding assistants like ChatGPT and other\ncoding copilots is transforming programming education, raising questions about\nassessment practices, academic integrity, and skill development. As educators\nseek alternatives to traditional grading methods susceptible to AI enabled\nplagiarism, structured peer assessment could be a promising strategy. This\npaper presents an empirical study of a rubric based, anonymized peer review\nprocess implemented in a large introductory programming course.\n  Students evaluated each other's final projects (2D game), and their\nassessments were compared to instructor grades using correlation, mean absolute\nerror, and root mean square error (RMSE). Additionally, reflective surveys from\n47 teams captured student perceptions of fairness, grading behavior, and\npreferences regarding grade aggregation. Results show that peer review can\napproximate instructor evaluation with moderate accuracy and foster student\nengagement, evaluative thinking, and interest in providing good feedback to\ntheir peers. We discuss these findings for designing scalable, trustworthy peer\nassessment systems to face the age of AI assisted coding.", "published": "2025-05-28 08:17:05", "link": "http://arxiv.org/abs/2505.22093v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "VIRAL: Vision-grounded Integration for Reward design And Learning", "abstract": "The alignment between humans and machines is a critical challenge in\nartificial intelligence today. Reinforcement learning, which aims to maximize a\nreward function, is particularly vulnerable to the risks associated with poorly\ndesigned reward functions. Recent advancements has shown that Large Language\nModels (LLMs) for reward generation can outperform human performance in this\ncontext. We introduce VIRAL, a pipeline for generating and refining reward\nfunctions through the use of multi-modal LLMs. VIRAL autonomously creates and\ninteractively improves reward functions based on a given environment and a goal\nprompt or annotated image. The refinement process can incorporate human\nfeedback or be guided by a description generated by a video LLM, which explains\nthe agent's policy in video form. We evaluated VIRAL in five Gymnasium\nenvironments, demonstrating that it accelerates the learning of new behaviors\nwhile ensuring improved alignment with user intent. The source-code and demo\nvideo are available at: https://github.com/VIRAL-UCBL1/VIRAL and\nhttps://youtu.be/t4_BXugBm9Q.", "published": "2025-05-28 08:16:09", "link": "http://arxiv.org/abs/2505.22092v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Cognitively-Inspired Emergent Communication via Knowledge Graphs for Assisting the Visually Impaired", "abstract": "Assistive systems for visually impaired individuals must deliver rapid,\ninterpretable, and adaptive feedback to facilitate real-time navigation.\nCurrent approaches face a trade-off between latency and semantic richness:\nnatural language-based systems provide detailed guidance but are too slow for\ndynamic scenarios, while emergent communication frameworks offer low-latency\nsymbolic languages but lack semantic depth, limiting their utility in tactile\nmodalities like vibration. To address these limitations, we introduce a novel\nframework, Cognitively-Inspired Emergent Communication via Knowledge Graphs\n(VAG-EC), which emulates human visual perception and cognitive mapping. Our\nmethod constructs knowledge graphs to represent objects and their\nrelationships, incorporating attention mechanisms to prioritize task-relevant\nentities, thereby mirroring human selective attention. This structured approach\nenables the emergence of compact, interpretable, and context-sensitive symbolic\nlanguages. Extensive experiments across varying vocabulary sizes and message\nlengths demonstrate that VAG-EC outperforms traditional emergent communication\nmethods in Topographic Similarity (TopSim) and Context Independence (CI). These\nfindings underscore the potential of cognitively grounded emergent\ncommunication as a fast, adaptive, and human-aligned solution for real-time\nassistive technologies. Code is available at\nhttps://github.com/Anonymous-NLPcode/Anonymous_submission/tree/main.", "published": "2025-05-28 08:09:06", "link": "http://arxiv.org/abs/2505.22087v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "iDSE: Navigating Design Space Exploration in High-Level Synthesis Using LLMs", "abstract": "High-Level Synthesis (HLS) serves as an agile hardware development tool that\nstreamlines the circuit design by abstracting the register transfer level into\nbehavioral descriptions, while allowing designers to customize the generated\nmicroarchitectures through optimization directives. However, the combinatorial\nexplosion of possible directive configurations yields an intractable design\nspace. Traditional design space exploration (DSE) methods, despite adopting\nheuristics or constructing predictive models to accelerate Pareto-optimal\ndesign acquisition, still suffer from prohibitive exploration costs and\nsuboptimal results. Addressing these concerns, we introduce iDSE, the first\nLLM-aided DSE framework that leverages HLS design quality perception to\neffectively navigate the design space. iDSE intelligently pruns the design\nspace to guide LLMs in calibrating representative initial sampling designs,\nexpediting convergence toward the Pareto front. By exploiting the convergent\nand divergent thinking patterns inherent in LLMs for hardware optimization,\niDSE achieves multi-path refinement of the design quality and diversity.\nExtensive experiments demonstrate that iDSE outperforms heuristic-based DSE\nmethods by 5.1$\\times$$\\sim$16.6$\\times$ in proximity to the reference Pareto\nfront, matching NSGA-II with only 4.6% of the explored designs. Our work\ndemonstrates the transformative potential of LLMs in scalable and efficient HLS\ndesign optimization, offering new insights into multiobjective optimization\nchallenges.", "published": "2025-05-28 08:08:57", "link": "http://arxiv.org/abs/2505.22086v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "Zero-Shot Vision Encoder Grafting via LLM Surrogates", "abstract": "Vision language models (VLMs) typically pair a modestly sized vision encoder\nwith a large language model (LLM), e.g., Llama-70B, making the decoder the\nprimary computational burden during training. To reduce costs, a potential\npromising strategy is to first train the vision encoder using a small language\nmodel before transferring it to the large one. We construct small \"surrogate\nmodels\" that share the same embedding space and representation language as the\nlarge target LLM by directly inheriting its shallow layers. Vision encoders\ntrained on the surrogate can then be directly transferred to the larger model,\na process we call zero-shot grafting -- when plugged directly into the\nfull-size target LLM, the grafted pair surpasses the encoder-surrogate pair\nand, on some benchmarks, even performs on par with full decoder training with\nthe target LLM. Furthermore, our surrogate training approach reduces overall\nVLM training costs by ~45% when using Llama-70B as the decoder.", "published": "2025-05-28 17:59:59", "link": "http://arxiv.org/abs/2505.22664v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Training Free Stylized Abstraction", "abstract": "Stylized abstraction synthesizes visually exaggerated yet semantically\nfaithful representations of subjects, balancing recognizability with perceptual\ndistortion. Unlike image-to-image translation, which prioritizes structural\nfidelity, stylized abstraction demands selective retention of identity cues\nwhile embracing stylistic divergence, especially challenging for\nout-of-distribution individuals. We propose a training-free framework that\ngenerates stylized abstractions from a single image using inference-time\nscaling in vision-language models (VLLMs) to extract identity-relevant\nfeatures, and a novel cross-domain rectified flow inversion strategy that\nreconstructs structure based on style-dependent priors. Our method adapts\nstructural restoration dynamically through style-aware temporal scheduling,\nenabling high-fidelity reconstructions that honor both subject and style. It\nsupports multi-round abstraction-aware generation without fine-tuning. To\nevaluate this task, we introduce StyleBench, a GPT-based human-aligned metric\nsuited for abstract styles where pixel-level similarity fails. Experiments\nacross diverse abstraction (e.g., LEGO, knitted dolls, South Park) show strong\ngeneralization to unseen identities and styles in a fully open-source setup.", "published": "2025-05-28 17:59:57", "link": "http://arxiv.org/abs/2505.22663v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models", "abstract": "Recent Large Vision-Language Models (LVLMs) have advanced multi-modal\nunderstanding by incorporating finer-grained visual perception and encoding.\nHowever, such methods incur significant computational costs due to longer\nvisual token sequences, posing challenges for real-time deployment. To mitigate\nthis, prior studies have explored pruning unimportant visual tokens either at\nthe output layer of the visual encoder or at the early layers of the language\nmodel. In this work, we revisit these design choices and reassess their\neffectiveness through comprehensive empirical studies of how visual tokens are\nprocessed throughout the visual encoding and language decoding stages. Guided\nby these insights, we propose VScan, a two-stage visual token reduction\nframework that addresses token redundancy by: (1) integrating complementary\nglobal and local scans with token merging during visual encoding, and (2)\nintroducing pruning at intermediate layers of the language model. Extensive\nexperimental results across four LVLMs validate the effectiveness of VScan in\naccelerating inference and demonstrate its superior performance over current\nstate-of-the-arts on sixteen benchmarks. Notably, when applied to\nLLaVA-NeXT-7B, VScan achieves a 2.91$\\times$ speedup in prefilling and a\n10$\\times$ reduction in FLOPs, while retaining 95.4% of the original\nperformance.", "published": "2025-05-28 17:59:08", "link": "http://arxiv.org/abs/2505.22654v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation", "abstract": "Audio-driven human animation methods, such as talking head and talking body\ngeneration, have made remarkable progress in generating synchronized facial\nmovements and appealing visual quality videos. However, existing methods\nprimarily focus on single human animation and struggle with multi-stream audio\ninputs, facing incorrect binding problems between audio and persons.\nAdditionally, they exhibit limitations in instruction-following capabilities.\nTo solve this problem, in this paper, we propose a novel task: Multi-Person\nConversational Video Generation, and introduce a new framework, MultiTalk, to\naddress the challenges during multi-person generation. Specifically, for audio\ninjection, we investigate several schemes and propose the Label Rotary Position\nEmbedding (L-RoPE) method to resolve the audio and person binding problem.\nFurthermore, during training, we observe that partial parameter training and\nmulti-task training are crucial for preserving the instruction-following\nability of the base model. MultiTalk achieves superior performance compared to\nother methods on several datasets, including talking head, talking body, and\nmulti-person datasets, demonstrating the powerful generation capabilities of\nour approach.", "published": "2025-05-28 17:57:06", "link": "http://arxiv.org/abs/2505.22647v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SPIRAL: Semantic-Aware Progressive LiDAR Scene Generation", "abstract": "Leveraging recent diffusion models, LiDAR-based large-scale 3D scene\ngeneration has achieved great success. While recent voxel-based approaches can\ngenerate both geometric structures and semantic labels, existing range-view\nmethods are limited to producing unlabeled LiDAR scenes. Relying on pretrained\nsegmentation models to predict the semantic maps often results in suboptimal\ncross-modal consistency. To address this limitation while preserving the\nadvantages of range-view representations, such as computational efficiency and\nsimplified network design, we propose Spiral, a novel range-view LiDAR\ndiffusion model that simultaneously generates depth, reflectance images, and\nsemantic maps. Furthermore, we introduce novel semantic-aware metrics to\nevaluate the quality of the generated labeled range-view data. Experiments on\nthe SemanticKITTI and nuScenes datasets demonstrate that Spiral achieves\nstate-of-the-art performance with the smallest parameter size, outperforming\ntwo-step methods that combine the generative and segmentation models.\nAdditionally, we validate that range images generated by Spiral can be\neffectively used for synthetic data augmentation in the downstream segmentation\ntraining, significantly reducing the labeling effort on LiDAR data.", "published": "2025-05-28 17:55:35", "link": "http://arxiv.org/abs/2505.22643v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ObjectClear: Complete Object Removal via Object-Effect Attention", "abstract": "Object removal requires eliminating not only the target object but also its\neffects, such as shadows and reflections. However, diffusion-based inpainting\nmethods often produce artifacts, hallucinate content, alter background, and\nstruggle to remove object effects accurately. To address this challenge, we\nintroduce a new dataset for OBject-Effect Removal, named OBER, which provides\npaired images with and without object effects, along with precise masks for\nboth objects and their associated visual artifacts. The dataset comprises\nhigh-quality captured and simulated data, covering diverse object categories\nand complex multi-object scenes. Building on OBER, we propose a novel\nframework, ObjectClear, which incorporates an object-effect attention mechanism\nto guide the model toward the foreground removal regions by learning attention\nmasks, effectively decoupling foreground removal from background\nreconstruction. Furthermore, the predicted attention map enables an\nattention-guided fusion strategy during inference, greatly preserving\nbackground details. Extensive experiments demonstrate that ObjectClear\noutperforms existing methods, achieving improved object-effect removal quality\nand background fidelity, especially in complex scenarios.", "published": "2025-05-28 17:51:17", "link": "http://arxiv.org/abs/2505.22636v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization", "abstract": "Neural rendering methods have gained significant attention for their ability\nto reconstruct 3D scenes from 2D images. The core idea is to take multiple\nviews as input and optimize the reconstructed scene by minimizing the\nuncertainty in geometry and appearance across the views. However, the\nreconstruction quality is limited by the number of input views. This limitation\nis further pronounced in complex and dynamic scenes, where certain angles of\nobjects are never seen. In this paper, we propose to use video frame\ninterpolation as the data augmentation method for neural rendering.\nFurthermore, we design a lightweight yet high-quality video frame interpolation\nmodel, PS4PRO (Pixel-to-pixel Supervision for Photorealistic Rendering and\nOptimization). PS4PRO is trained on diverse video datasets, implicitly modeling\ncamera movement as well as real-world 3D geometry. Our model performs as an\nimplicit world prior, enriching the photo supervision for 3D reconstruction. By\nleveraging the proposed method, we effectively augment existing datasets for\nneural rendering methods. Our experimental results indicate that our method\nimproves the reconstruction performance on both static and dynamic scenes.", "published": "2025-05-28 17:35:39", "link": "http://arxiv.org/abs/2505.22616v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Chest Disease Detection In X-Ray Images Using Deep Learning Classification Method", "abstract": "In this work, we investigate the performance across multiple classification\nmodels to classify chest X-ray images into four categories of COVID-19,\npneumonia, tuberculosis (TB), and normal cases. We leveraged transfer learning\ntechniques with state-of-the-art pre-trained Convolutional Neural Networks\n(CNNs) models. We fine-tuned these pre-trained architectures on a labeled\nmedical x-ray images. The initial results are promising with high accuracy and\nstrong performance in key classification metrics such as precision, recall, and\nF1 score. We applied Gradient-weighted Class Activation Mapping (Grad-CAM) for\nmodel interpretability to provide visual explanations for classification\ndecisions, improving trust and transparency in clinical applications.", "published": "2025-05-28 17:24:33", "link": "http://arxiv.org/abs/2505.22609v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Adversarially Robust AI-Generated Image Detection for Free: An Information Theoretic Perspective", "abstract": "Rapid advances in Artificial Intelligence Generated Images (AIGI) have\nfacilitated malicious use, such as forgery and misinformation. Therefore,\nnumerous methods have been proposed to detect fake images. Although such\ndetectors have been proven to be universally vulnerable to adversarial attacks,\ndefenses in this field are scarce. In this paper, we first identify that\nadversarial training (AT), widely regarded as the most effective defense,\nsuffers from performance collapse in AIGI detection. Through an\ninformation-theoretic lens, we further attribute the cause of collapse to\nfeature entanglement, which disrupts the preservation of feature-label mutual\ninformation. Instead, standard detectors show clear feature separation.\nMotivated by this difference, we propose Training-free Robust Detection via\nInformation-theoretic Measures (TRIM), the first training-free adversarial\ndefense for AIGI detection. TRIM builds on standard detectors and quantifies\nfeature shifts using prediction entropy and KL divergence. Extensive\nexperiments across multiple datasets and attacks validate the superiority of\nour TRIM, e.g., outperforming the state-of-the-art defense by 33.88% (28.91%)\non ProGAN (GenImage), while well maintaining original accuracy.", "published": "2025-05-28 17:20:49", "link": "http://arxiv.org/abs/2505.22604v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAM-R1: Leveraging SAM for Reward Feedback in Multimodal Segmentation via Reinforcement Learning", "abstract": "Leveraging multimodal large models for image segmentation has become a\nprominent research direction. However, existing approaches typically rely\nheavily on manually annotated datasets that include explicit reasoning\nprocesses, which are costly and time-consuming to produce. Recent advances\nsuggest that reinforcement learning (RL) can endow large models with reasoning\ncapabilities without requiring such reasoning-annotated data. In this paper, we\npropose SAM-R1, a novel framework that enables multimodal large models to\nperform fine-grained reasoning in image understanding tasks. Our approach is\nthe first to incorporate fine-grained segmentation settings during the training\nof multimodal reasoning models. By integrating task-specific, fine-grained\nrewards with a tailored optimization objective, we further enhance the model's\nreasoning and segmentation alignment. We also leverage the Segment Anything\nModel (SAM) as a strong and flexible reward provider to guide the learning\nprocess. With only 3k training samples, SAM-R1 achieves strong performance\nacross multiple benchmarks, demonstrating the effectiveness of reinforcement\nlearning in equipping multimodal models with segmentation-oriented reasoning\ncapabilities.", "published": "2025-05-28 17:08:28", "link": "http://arxiv.org/abs/2505.22596v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Comparative Analysis of Machine Learning Models for Lung Cancer Mutation Detection and Staging Using 3D CT Scans", "abstract": "Lung cancer is the leading cause of cancer mortality worldwide, and\nnon-invasive methods for detecting key mutations and staging are essential for\nimproving patient outcomes. Here, we compare the performance of two machine\nlearning models - FMCIB+XGBoost, a supervised model with domain-specific\npretraining, and Dinov2+ABMIL, a self-supervised model with attention-based\nmultiple-instance learning - on 3D lung nodule data from the Stanford\nRadiogenomics and Lung-CT-PT-Dx cohorts. In the task of KRAS and EGFR mutation\ndetection, FMCIB+XGBoost consistently outperformed Dinov2+ABMIL, achieving\naccuracies of 0.846 and 0.883 for KRAS and EGFR mutations, respectively. In\ncancer staging, Dinov2+ABMIL demonstrated competitive generalization, achieving\nan accuracy of 0.797 for T-stage prediction in the Lung-CT-PT-Dx cohort,\nsuggesting SSL's adaptability across diverse datasets. Our results emphasize\nthe clinical utility of supervised models in mutation detection and highlight\nthe potential of SSL to improve staging generalization, while identifying areas\nfor enhancement in mutation sensitivity.", "published": "2025-05-28 17:04:35", "link": "http://arxiv.org/abs/2505.22592v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "ImageReFL: Balancing Quality and Diversity in Human-Aligned Diffusion Models", "abstract": "Recent advances in diffusion models have led to impressive image generation\ncapabilities, but aligning these models with human preferences remains\nchallenging. Reward-based fine-tuning using models trained on human feedback\nimproves alignment but often harms diversity, producing less varied outputs. In\nthis work, we address this trade-off with two contributions. First, we\nintroduce \\textit{combined generation}, a novel sampling strategy that applies\na reward-tuned diffusion model only in the later stages of the generation\nprocess, while preserving the base model for earlier steps. This approach\nmitigates early-stage overfitting and helps retain global structure and\ndiversity. Second, we propose \\textit{ImageReFL}, a fine-tuning method that\nimproves image diversity with minimal loss in quality by training on real\nimages and incorporating multiple regularizers, including diffusion and ReFL\nlosses. Our approach outperforms conventional reward tuning methods on standard\nquality and diversity metrics. A user study further confirms that our method\nbetter balances human preference alignment and visual diversity. The source\ncode can be found at https://github.com/ControlGenAI/ImageReFL .", "published": "2025-05-28 16:45:07", "link": "http://arxiv.org/abs/2505.22569v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multipath cycleGAN for harmonization of paired and unpaired low-dose lung computed tomography reconstruction kernels", "abstract": "Reconstruction kernels in computed tomography (CT) affect spatial resolution\nand noise characteristics, introducing systematic variability in quantitative\nimaging measurements such as emphysema quantification. Choosing an appropriate\nkernel is therefore essential for consistent quantitative analysis. We propose\na multipath cycleGAN model for CT kernel harmonization, trained on a mixture of\npaired and unpaired data from a low-dose lung cancer screening cohort. The\nmodel features domain-specific encoders and decoders with a shared latent space\nand uses discriminators tailored for each domain.We train the model on 42\nkernel combinations using 100 scans each from seven representative kernels in\nthe National Lung Screening Trial (NLST) dataset. To evaluate performance, 240\nscans from each kernel are harmonized to a reference soft kernel, and emphysema\nis quantified before and after harmonization. A general linear model assesses\nthe impact of age, sex, smoking status, and kernel on emphysema. We also\nevaluate harmonization from soft kernels to a reference hard kernel. To assess\nanatomical consistency, we compare segmentations of lung vessels, muscle, and\nsubcutaneous adipose tissue generated by TotalSegmentator between harmonized\nand original images. Our model is benchmarked against traditional and\nswitchable cycleGANs. For paired kernels, our approach reduces bias in\nemphysema scores, as seen in Bland-Altman plots (p<0.05). For unpaired kernels,\nharmonization eliminates confounding differences in emphysema (p>0.05). High\nDice scores confirm preservation of muscle and fat anatomy, while lung vessel\noverlap remains reasonable. Overall, our shared latent space multipath cycleGAN\nenables robust harmonization across paired and unpaired CT kernels, improving\nemphysema quantification and preserving anatomical fidelity.", "published": "2025-05-28 16:44:42", "link": "http://arxiv.org/abs/2505.22568v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism", "abstract": "Human pose estimation based on Channel State Information (CSI) has emerged as\na promising approach for non-intrusive and precise human activity monitoring,\nyet faces challenges including accurate multi-person pose recognition and\neffective CSI feature learning. This paper presents MultiFormer, a wireless\nsensing system that accurately estimates human pose through CSI. The proposed\nsystem adopts a Transformer based time-frequency dual-token feature extractor\nwith multi-head self-attention. This feature extractor is able to model\ninter-subcarrier correlations and temporal dependencies of the CSI. The\nextracted CSI features and the pose probability heatmaps are then fused by\nMulti-Stage Feature Fusion Network (MSFN) to enforce the anatomical\nconstraints. Extensive experiments conducted on on the public MM-Fi dataset and\nour self-collected dataset show that the MultiFormer achieves higher accuracy\nover state-of-the-art approaches, especially for high-mobility keypoints\n(wrists, elbows) that are particularly difficult for previous methods to\naccurately estimate.", "published": "2025-05-28 16:36:02", "link": "http://arxiv.org/abs/2505.22555v1", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Deep Learning-Based BMD Estimation from Radiographs with Conformal Uncertainty Quantification", "abstract": "Limited DXA access hinders osteoporosis screening. This proof-of-concept\nstudy proposes using widely available knee X-rays for opportunistic Bone\nMineral Density (BMD) estimation via deep learning, emphasizing robust\nuncertainty quantification essential for clinical use. An EfficientNet model\nwas trained on the OAI dataset to predict BMD from bilateral knee radiographs.\nTwo Test-Time Augmentation (TTA) methods were compared: traditional averaging\nand a multi-sample approach. Crucially, Split Conformal Prediction was\nimplemented to provide statistically rigorous, patient-specific prediction\nintervals with guaranteed coverage. Results showed a Pearson correlation of\n0.68 (traditional TTA). While traditional TTA yielded better point predictions,\nthe multi-sample approach produced slightly tighter confidence intervals (90%,\n95%, 99%) while maintaining coverage. The framework appropriately expressed\nhigher uncertainty for challenging cases. Although anatomical mismatch between\nknee X-rays and standard DXA limits immediate clinical use, this method\nestablishes a foundation for trustworthy AI-assisted BMD screening using\nroutine radiographs, potentially improving early osteoporosis detection.", "published": "2025-05-28 16:33:49", "link": "http://arxiv.org/abs/2505.22551v1", "categories": ["cs.CV", "stat.AP"], "primary_category": "cs.CV"}
{"title": "RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting", "abstract": "Recent deep learning approaches for river discharge forecasting have improved\nthe accuracy and efficiency in flood forecasting, enabling more reliable early\nwarning systems for risk management. Nevertheless, existing deep learning\napproaches in hydrology remain largely confined to local-scale applications and\ndo not leverage the inherent spatial connections of bodies of water. Thus,\nthere is a strong need for new deep learning methodologies that are capable of\nmodeling spatio-temporal relations to improve river discharge and flood\nforecasting for scientific and operational applications. To address this, we\npresent RiverMamba, a novel deep learning model that is pretrained with\nlong-term reanalysis data and that can forecast global river discharge and\nfloods on a $0.05^\\circ$ grid up to 7 days lead time, which is of high\nrelevance in early warning. To achieve this, RiverMamba leverages efficient\nMamba blocks that enable the model to capture global-scale channel network\nrouting and enhance its forecast capability for longer lead times. The forecast\nblocks integrate ECMWF HRES meteorological forecasts, while accounting for\ntheir inaccuracies through spatio-temporal modeling. Our analysis demonstrates\nthat RiverMamba delivers reliable predictions of river discharge, including\nextreme floods across return periods and lead times, surpassing both\noperational AI- and physics-based models.", "published": "2025-05-28 16:21:58", "link": "http://arxiv.org/abs/2505.22535v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "PrismLayers: Open Data for High-Quality Multi-Layer Transparent Image Generative Models", "abstract": "Generating high-quality, multi-layer transparent images from text prompts can\nunlock a new level of creative control, allowing users to edit each layer as\neffortlessly as editing text outputs from LLMs. However, the development of\nmulti-layer generative models lags behind that of conventional text-to-image\nmodels due to the absence of a large, high-quality corpus of multi-layer\ntransparent data. In this paper, we address this fundamental challenge by: (i)\nreleasing the first open, ultra-high-fidelity PrismLayers (PrismLayersPro)\ndataset of 200K (20K) multilayer transparent images with accurate alpha mattes,\n(ii) introducing a trainingfree synthesis pipeline that generates such data on\ndemand using off-the-shelf diffusion models, and (iii) delivering a strong,\nopen-source multi-layer generation model, ART+, which matches the aesthetics of\nmodern text-to-image generation models. The key technical contributions\ninclude: LayerFLUX, which excels at generating high-quality single transparent\nlayers with accurate alpha mattes, and MultiLayerFLUX, which composes multiple\nLayerFLUX outputs into complete images, guided by human-annotated semantic\nlayout. To ensure higher quality, we apply a rigorous filtering stage to remove\nartifacts and semantic mismatches, followed by human selection. Fine-tuning the\nstate-of-the-art ART model on our synthetic PrismLayersPro yields ART+, which\noutperforms the original ART in 60% of head-to-head user study comparisons and\neven matches the visual quality of images generated by the FLUX.1-[dev] model.\nWe anticipate that our work will establish a solid dataset foundation for the\nmulti-layer transparent image generation task, enabling research and\napplications that require precise, editable, and visually compelling layered\nimagery.", "published": "2025-05-28 16:09:33", "link": "http://arxiv.org/abs/2505.22523v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PathFL: Multi-Alignment Federated Learning for Pathology Image Segmentation", "abstract": "Pathology image segmentation across multiple centers encounters significant\nchallenges due to diverse sources of heterogeneity including imaging\nmodalities, organs, and scanning equipment, whose variability brings\nrepresentation bias and impedes the development of generalizable segmentation\nmodels. In this paper, we propose PathFL, a novel multi-alignment Federated\nLearning framework for pathology image segmentation that addresses these\nchallenges through three-level alignment strategies of image, feature, and\nmodel aggregation. Firstly, at the image level, a collaborative style\nenhancement module aligns and diversifies local data by facilitating style\ninformation exchange across clients. Secondly, at the feature level, an\nadaptive feature alignment module ensures implicit alignment in the\nrepresentation space by infusing local features with global insights, promoting\nconsistency across heterogeneous client features learning. Finally, at the\nmodel aggregation level, a stratified similarity aggregation strategy\nhierarchically aligns and aggregates models on the server, using layer-specific\nsimilarity to account for client discrepancies and enhance global\ngeneralization. Comprehensive evaluations on four sets of heterogeneous\npathology image datasets, encompassing cross-source, cross-modality,\ncross-organ, and cross-scanner variations, validate the effectiveness of our\nPathFL in achieving better performance and robustness against data\nheterogeneity.", "published": "2025-05-28 16:09:02", "link": "http://arxiv.org/abs/2505.22522v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Surf2CT: Cascaded 3D Flow Matching Models for Torso 3D CT Synthesis from Skin Surface", "abstract": "We present Surf2CT, a novel cascaded flow matching framework that synthesizes\nfull 3D computed tomography (CT) volumes of the human torso from external\nsurface scans and simple demographic data (age, sex, height, weight). This is\nthe first approach capable of generating realistic volumetric internal anatomy\nimages solely based on external body shape and demographics, without any\ninternal imaging. Surf2CT proceeds through three sequential stages: (1) Surface\nCompletion, reconstructing a complete signed distance function (SDF) from\npartial torso scans using conditional 3D flow matching; (2) Coarse CT\nSynthesis, generating a low-resolution CT volume from the completed SDF and\ndemographic information; and (3) CT Super-Resolution, refining the coarse\nvolume into a high-resolution CT via a patch-wise conditional flow model. Each\nstage utilizes a 3D-adapted EDM2 backbone trained via flow matching. We trained\nour model on a combined dataset of 3,198 torso CT scans (approximately 1.13\nmillion axial slices) sourced from Massachusetts General Hospital (MGH) and the\nAutoPET challenge. Evaluation on 700 paired torso surface-CT cases demonstrated\nstrong anatomical fidelity: organ volumes exhibited small mean percentage\ndifferences (range from -11.1% to 4.4%), and muscle/fat body composition\nmetrics matched ground truth with strong correlation (range from 0.67 to 0.96).\nLung localization had minimal bias (mean difference -2.5 mm), and surface\ncompletion significantly improved metrics (Chamfer distance: from 521.8 mm to\n2.7 mm; Intersection-over-Union: from 0.87 to 0.98). Surf2CT establishes a new\nparadigm for non-invasive internal anatomical imaging using only external data,\nopening opportunities for home-based healthcare, preventive medicine, and\npersonalized clinical assessments without the risks associated with\nconventional imaging techniques.", "published": "2025-05-28 16:01:36", "link": "http://arxiv.org/abs/2505.22511v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector", "abstract": "3D object detection is a critical component in autonomous driving systems. It\nallows real-time recognition and detection of vehicles, pedestrians and\nobstacles under varying environmental conditions. Among existing methods, 3D\nobject detection in the Bird's Eye View (BEV) has emerged as the mainstream\nframework. To guarantee a safe, robust and trustworthy 3D object detection, 3D\nadversarial attacks are investigated, where attacks are placed in 3D\nenvironments to evaluate the model performance, e.g., putting a film on a car,\nclothing a pedestrian. The vulnerability of 3D object detection models to 3D\nadversarial attacks serves as an important indicator to evaluate the robustness\nof the model against perturbations. To investigate this vulnerability, we\ngenerate non-invasive 3D adversarial objects tailored for real-world attack\nscenarios. Our method verifies the existence of universal adversarial objects\nthat are spatially consistent across time and camera views. Specifically, we\nemploy differentiable rendering techniques to accurately model the spatial\nrelationship between adversarial objects and the target vehicle. Furthermore,\nwe introduce an occlusion-aware module to enhance visual consistency and\nrealism under different viewpoints. To maintain attack effectiveness across\nmultiple frames, we design a BEV spatial feature-guided optimization strategy.\nExperimental results demonstrate that our approach can reliably suppress\nvehicle predictions from state-of-the-art 3D object detectors, serving as an\nimportant tool to test robustness of 3D object detection models before\ndeployment. Moreover, the generated adversarial objects exhibit strong\ngeneralization capabilities, retaining its effectiveness at various positions\nand distances in the scene.", "published": "2025-05-28 15:49:54", "link": "http://arxiv.org/abs/2505.22499v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Risk-Sensitive Conformal Prediction for Catheter Placement Detection in Chest X-rays", "abstract": "This paper presents a novel approach to catheter and line position detection\nin chest X-rays, combining multi-task learning with risk-sensitive conformal\nprediction to address critical clinical requirements. Our model simultaneously\nperforms classification, segmentation, and landmark detection, leveraging the\nsynergistic relationship between these tasks to improve overall performance. We\nfurther enhance clinical reliability through risk-sensitive conformal\nprediction, which provides statistically guaranteed prediction sets with higher\nreliability for clinically critical findings. Experimental results demonstrate\nexcellent performance with 90.68\\% overall empirical coverage and 99.29\\%\ncoverage for critical conditions, while maintaining remarkable precision in\nprediction sets. Most importantly, our risk-sensitive approach achieves zero\nhigh-risk mispredictions (cases where the system dangerously declares\nproblematic tubes as confidently normal), making the system particularly\nsuitable for clinical deployment. This work offers both accurate predictions\nand reliably quantified uncertainty -- essential features for life-critical\nmedical applications.", "published": "2025-05-28 15:47:10", "link": "http://arxiv.org/abs/2505.22496v1", "categories": ["eess.IV", "cs.CV", "stat.AP"], "primary_category": "eess.IV"}
{"title": "ProCrop: Learning Aesthetic Image Cropping from Professional Compositions", "abstract": "Image cropping is crucial for enhancing the visual appeal and narrative\nimpact of photographs, yet existing rule-based and data-driven approaches often\nlack diversity or require annotated training data. We introduce ProCrop, a\nretrieval-based method that leverages professional photography to guide\ncropping decisions. By fusing features from professional photographs with those\nof the query image, ProCrop learns from professional compositions,\nsignificantly boosting performance. Additionally, we present a large-scale\ndataset of 242K weakly-annotated images, generated by out-painting professional\nimages and iteratively refining diverse crop proposals. This composition-aware\ndataset generation offers diverse high-quality crop proposals guided by\naesthetic principles and becomes the largest publicly available dataset for\nimage cropping. Extensive experiments show that ProCrop significantly\noutperforms existing methods in both supervised and weakly-supervised settings.\nNotably, when trained on the new dataset, our ProCrop surpasses previous\nweakly-supervised methods and even matches fully supervised approaches. Both\nthe code and dataset will be made publicly available to advance research in\nimage aesthetics and composition analysis.", "published": "2025-05-28 15:38:44", "link": "http://arxiv.org/abs/2505.22490v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cascaded 3D Diffusion Models for Whole-body 3D 18-F FDG PET/CT synthesis from Demographics", "abstract": "We propose a cascaded 3D diffusion model framework to synthesize\nhigh-fidelity 3D PET/CT volumes directly from demographic variables, addressing\nthe growing need for realistic digital twins in oncologic imaging, virtual\ntrials, and AI-driven data augmentation. Unlike deterministic phantoms, which\nrely on predefined anatomical and metabolic templates, our method employs a\ntwo-stage generative process. An initial score-based diffusion model\nsynthesizes low-resolution PET/CT volumes from demographic variables alone,\nproviding global anatomical structures and approximate metabolic activity. This\nis followed by a super-resolution residual diffusion model that refines spatial\nresolution. Our framework was trained on 18-F FDG PET/CT scans from the AutoPET\ndataset and evaluated using organ-wise volume and standardized uptake value\n(SUV) distributions, comparing synthetic and real data between demographic\nsubgroups. The organ-wise comparison demonstrated strong concordance between\nsynthetic and real images. In particular, most deviations in metabolic uptake\nvalues remained within 3-5% of the ground truth in subgroup analysis. These\nfindings highlight the potential of cascaded 3D diffusion models to generate\nanatomically and metabolically accurate PET/CT images, offering a robust\nalternative to traditional phantoms and enabling scalable, population-informed\nsynthetic imaging for clinical and research applications.", "published": "2025-05-28 15:38:33", "link": "http://arxiv.org/abs/2505.22489v1", "categories": ["eess.IV", "cs.CV", "cs.GR"], "primary_category": "eess.IV"}
{"title": "Understanding Adversarial Training with Energy-based Models", "abstract": "We aim at using Energy-based Model (EBM) framework to better understand\nadversarial training (AT) in classifiers, and additionally to analyze the\nintrinsic generative capabilities of robust classifiers. By viewing standard\nclassifiers through an energy lens, we begin by analyzing how the energies of\nadversarial examples, generated by various attacks, differ from those of the\nnatural samples. The central focus of our work is to understand the critical\nphenomena of Catastrophic Overfitting (CO) and Robust Overfitting (RO) in AT\nfrom an energy perspective. We analyze the impact of existing AT approaches on\nthe energy of samples during training and observe that the behavior of the\n``delta energy' -- change in energy between original sample and its adversarial\ncounterpart -- diverges significantly when CO or RO occurs. After a thorough\nanalysis of these energy dynamics and their relationship with overfitting, we\npropose a novel regularizer, the Delta Energy Regularizer (DER), designed to\nsmoothen the energy landscape during training. We demonstrate that DER is\neffective in mitigating both CO and RO across multiple benchmarks. We further\nshow that robust classifiers, when being used as generative models, have limits\nin handling trade-off between image quality and variability. We propose an\nimproved technique based on a local class-wise principal component analysis\n(PCA) and energy-based guidance for better class-specific initialization and\nadaptive stopping, enhancing sample diversity and generation quality.\nConsidering that we do not explicitly train for generative modeling, we achieve\na competitive Inception Score (IS) and Fr\\'echet inception distance (FID)\ncompared to hybrid discriminative-generative models.", "published": "2025-05-28 15:36:02", "link": "http://arxiv.org/abs/2505.22486v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Single Domain Generalization for Alzheimer's Detection from 3D MRIs with Pseudo-Morphological Augmentations and Contrastive Learning", "abstract": "Although Alzheimer's disease detection via MRIs has advanced significantly\nthanks to contemporary deep learning models, challenges such as class\nimbalance, protocol variations, and limited dataset diversity often hinder\ntheir generalization capacity. To address this issue, this article focuses on\nthe single domain generalization setting, where given the data of one domain, a\nmodel is designed and developed with maximal performance w.r.t. an unseen\ndomain of distinct distribution. Since brain morphology is known to play a\ncrucial role in Alzheimer's diagnosis, we propose the use of learnable\npseudo-morphological modules aimed at producing shape-aware, anatomically\nmeaningful class-specific augmentations in combination with a supervised\ncontrastive learning module to extract robust class-specific representations.\nExperiments conducted across three datasets show improved performance and\ngeneralization capacity, especially under class imbalance and imaging protocol\nvariations. The source code will be made available upon acceptance at\nhttps://github.com/zobia111/SDG-Alzheimer.", "published": "2025-05-28 15:18:16", "link": "http://arxiv.org/abs/2505.22465v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels", "abstract": "3D occupancy prediction has attracted much attention in the field of\nautonomous driving due to its powerful geometric perception and object\nrecognition capabilities. However, existing methods have not explored the most\nessential distribution patterns of voxels, resulting in unsatisfactory results.\nThis paper first explores the inter-class distribution and geometric\ndistribution of voxels, thereby solving the long-tail problem caused by the\ninter-class distribution and the poor performance caused by the geometric\ndistribution. Specifically, this paper proposes SHTOcc (Sparse Head-Tail\nOccupancy), which uses sparse head-tail voxel construction to accurately\nidentify and balance key voxels in the head and tail classes, while using\ndecoupled learning to reduce the model's bias towards the dominant (head)\ncategory and enhance the focus on the tail class. Experiments show that\nsignificant improvements have been made on multiple baselines: SHTOcc reduces\nGPU memory usage by 42.2%, increases inference speed by 58.6%, and improves\naccuracy by about 7%, verifying its effectiveness and efficiency. The code is\navailable at https://github.com/ge95net/SHTOcc", "published": "2025-05-28 15:16:15", "link": "http://arxiv.org/abs/2505.22461v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Universal Domain Adaptation for Semantic Segmentation", "abstract": "Unsupervised domain adaptation for semantic segmentation (UDA-SS) aims to\ntransfer knowledge from labeled source data to unlabeled target data. However,\ntraditional UDA-SS methods assume that category settings between source and\ntarget domains are known, which is unrealistic in real-world scenarios. This\nleads to performance degradation if private classes exist. To address this\nlimitation, we propose Universal Domain Adaptation for Semantic Segmentation\n(UniDA-SS), achieving robust adaptation even without prior knowledge of\ncategory settings. We define the problem in the UniDA-SS scenario as low\nconfidence scores of common classes in the target domain, which leads to\nconfusion with private classes. To solve this problem, we propose UniMAP:\nUniDA-SS with Image Matching and Prototype-based Distinction, a novel framework\ncomposed of two key components. First, Domain-Specific Prototype-based\nDistinction (DSPD) divides each class into two domain-specific prototypes,\nenabling finer separation of domain-specific features and enhancing the\nidentification of common classes across domains. Second, Target-based Image\nMatching (TIM) selects a source image containing the most common-class pixels\nbased on the target pseudo-label and pairs it in a batch to promote effective\nlearning of common classes. We also introduce a new UniDA-SS benchmark and\ndemonstrate through various experiments that UniMAP significantly outperforms\nbaselines. The code is available at\n\\href{https://github.com/KU-VGI/UniMAP}{this https URL}.", "published": "2025-05-28 15:14:11", "link": "http://arxiv.org/abs/2505.22458v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On Geometry-Enhanced Parameter-Efficient Fine-Tuning for 3D Scene Segmentation", "abstract": "The emergence of large-scale pre-trained point cloud models has significantly\nadvanced 3D scene understanding, but adapting these models to specific\ndownstream tasks typically demands full fine-tuning, incurring high\ncomputational and storage costs. Parameter-efficient fine-tuning (PEFT)\ntechniques, successful in natural language processing and 2D vision tasks,\nwould underperform when naively applied to 3D point cloud models due to\nsignificant geometric and spatial distribution shifts. Existing PEFT methods\ncommonly treat points as orderless tokens, neglecting important local spatial\nstructures and global geometric contexts in 3D modeling. To bridge this gap, we\nintroduce the Geometric Encoding Mixer (GEM), a novel geometry-aware PEFT\nmodule specifically designed for 3D point cloud transformers. GEM explicitly\nintegrates fine-grained local positional encodings with a lightweight latent\nattention mechanism to capture comprehensive global context, thereby\neffectively addressing the spatial and geometric distribution mismatch.\nExtensive experiments demonstrate that GEM achieves performance comparable to\nor sometimes even exceeding full fine-tuning, while only updating 1.6% of the\nmodel's parameters, fewer than other PEFT methods. With significantly reduced\ntraining time and memory requirements, our approach thus sets a new benchmark\nfor efficient, scalable, and geometry-aware fine-tuning of large-scale 3D point\ncloud models. Code will be released.", "published": "2025-05-28 15:08:36", "link": "http://arxiv.org/abs/2505.22444v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Distance Transform Guided Mixup for Alzheimer's Detection", "abstract": "Alzheimer's detection efforts aim to develop accurate models for early\ndisease diagnosis. Significant advances have been achieved with convolutional\nneural networks and vision transformer based approaches. However, medical\ndatasets suffer heavily from class imbalance, variations in imaging protocols,\nand limited dataset diversity, which hinder model generalization. To overcome\nthese challenges, this study focuses on single-domain generalization by\nextending the well-known mixup method. The key idea is to compute the distance\ntransform of MRI scans, separate them spatially into multiple layers and then\ncombine layers stemming from distinct samples to produce augmented images. The\nproposed approach generates diverse data while preserving the brain's\nstructure. Experimental results show generalization performance improvement\nacross both ADNI and AIBL datasets.", "published": "2025-05-28 14:56:59", "link": "http://arxiv.org/abs/2505.22434v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Zero-Shot 3D Visual Grounding from Vision-Language Models", "abstract": "3D Visual Grounding (3DVG) seeks to locate target objects in 3D scenes using\nnatural language descriptions, enabling downstream applications such as\naugmented reality and robotics. Existing approaches typically rely on labeled\n3D data and predefined categories, limiting scalability to open-world settings.\nWe present SeeGround, a zero-shot 3DVG framework that leverages 2D\nVision-Language Models (VLMs) to bypass the need for 3D-specific training. To\nbridge the modality gap, we introduce a hybrid input format that pairs\nquery-aligned rendered views with spatially enriched textual descriptions. Our\nframework incorporates two core components: a Perspective Adaptation Module\nthat dynamically selects optimal viewpoints based on the query, and a Fusion\nAlignment Module that integrates visual and spatial signals to enhance\nlocalization precision. Extensive evaluations on ScanRefer and Nr3D confirm\nthat SeeGround achieves substantial improvements over existing zero-shot\nbaselines -- outperforming them by 7.7% and 7.1%, respectively -- and even\nrivals fully supervised alternatives, demonstrating strong generalization under\nchallenging conditions.", "published": "2025-05-28 14:53:53", "link": "http://arxiv.org/abs/2505.22429v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network", "abstract": "This paper presents a groundbreaking approach - the first online automatic\ngeometric calibration method for radar and camera systems. Given the\nsignificant data sparsity and measurement uncertainty in radar height data,\nachieving automatic calibration during system operation has long been a\nchallenge. To address the sparsity issue, we propose a Dual-Perspective\nrepresentation that gathers features from both frontal and bird's-eye views.\nThe frontal view contains rich but sensitive height information, whereas the\nbird's-eye view provides robust features against height uncertainty. We thereby\npropose a novel Selective Fusion Mechanism to identify and fuse reliable\nfeatures from both perspectives, reducing the effect of height uncertainty.\nMoreover, for each view, we incorporate a Multi-Modal Cross-Attention Mechanism\nto explicitly find location correspondences through cross-modal matching.\nDuring the training phase, we also design a Noise-Resistant Matcher to provide\nbetter supervision and enhance the robustness of the matching mechanism against\nsparsity and height uncertainty. Our experimental results, tested on the\nnuScenes dataset, demonstrate that our method significantly outperforms\nprevious radar-camera auto-calibration methods, as well as existing\nstate-of-the-art LiDAR-camera calibration techniques, establishing a new\nbenchmark for future research. The code is available at\nhttps://github.com/nycu-acm/RC-AutoCalib.", "published": "2025-05-28 14:52:31", "link": "http://arxiv.org/abs/2505.22427v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control", "abstract": "Recent advancements in world models have revolutionized dynamic environment\nsimulation, allowing systems to foresee future states and assess potential\nactions. In autonomous driving, these capabilities help vehicles anticipate the\nbehavior of other road users, perform risk-aware planning, accelerate training\nin simulation, and adapt to novel scenarios, thereby enhancing safety and\nreliability. Current approaches exhibit deficiencies in maintaining robust 3D\ngeometric consistency or accumulating artifacts during occlusion handling, both\ncritical for reliable safety assessment in autonomous navigation tasks. To\naddress this, we introduce GeoDrive, which explicitly integrates robust 3D\ngeometry conditions into driving world models to enhance spatial understanding\nand action controllability. Specifically, we first extract a 3D representation\nfrom the input frame and then obtain its 2D rendering based on the\nuser-specified ego-car trajectory. To enable dynamic modeling, we propose a\ndynamic editing module during training to enhance the renderings by editing the\npositions of the vehicles. Extensive experiments demonstrate that our method\nsignificantly outperforms existing models in both action accuracy and 3D\nspatial awareness, leading to more realistic, adaptable, and reliable scene\nmodeling for safer autonomous driving. Additionally, our model can generalize\nto novel trajectories and offers interactive scene editing capabilities, such\nas object editing and object trajectory control.", "published": "2025-05-28 14:46:51", "link": "http://arxiv.org/abs/2505.22421v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Neural Face Skinning for Mesh-agnostic Facial Expression Cloning", "abstract": "Accurately retargeting facial expressions to a face mesh while enabling\nmanipulation is a key challenge in facial animation retargeting. Recent\ndeep-learning methods address this by encoding facial expressions into a global\nlatent code, but they often fail to capture fine-grained details in local\nregions. While some methods improve local accuracy by transferring deformations\nlocally, this often complicates overall control of the facial expression. To\naddress this, we propose a method that combines the strengths of both global\nand local deformation models. Our approach enables intuitive control and\ndetailed expression cloning across diverse face meshes, regardless of their\nunderlying structures. The core idea is to localize the influence of the global\nlatent code on the target mesh. Our model learns to predict skinning weights\nfor each vertex of the target face mesh through indirect supervision from\npredefined segmentation labels. These predicted weights localize the global\nlatent code, enabling precise and region-specific deformations even for meshes\nwith unseen shapes. We supervise the latent code using Facial Action Coding\nSystem (FACS)-based blendshapes to ensure interpretability and allow\nstraightforward editing of the generated animation. Through extensive\nexperiments, we demonstrate improved performance over state-of-the-art methods\nin terms of expression fidelity, deformation transfer accuracy, and\nadaptability across diverse mesh structures.", "published": "2025-05-28 14:43:43", "link": "http://arxiv.org/abs/2505.22416v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Frugal Incremental Generative Modeling using Variational Autoencoders", "abstract": "Continual or incremental learning holds tremendous potential in deep learning\nwith different challenges including catastrophic forgetting. The advent of\npowerful foundation and generative models has propelled this paradigm even\nfurther, making it one of the most viable solution to train these models.\nHowever, one of the persisting issues lies in the increasing volume of data\nparticularly with replay-based methods. This growth introduces challenges with\nscalability since continuously expanding data becomes increasingly demanding as\nthe number of tasks grows. In this paper, we attenuate this issue by devising a\nnovel replay-free incremental learning model based on Variational Autoencoders\n(VAEs). The main contribution of this work includes (i) a novel incremental\ngenerative modelling, built upon a well designed multi-modal latent space, and\nalso (ii) an orthogonality criterion that mitigates catastrophic forgetting of\nthe learned VAEs. The proposed method considers two variants of these VAEs:\nstatic and dynamic with no (or at most a controlled) growth in the number of\nparameters. Extensive experiments show that our method is (at least) an order\nof magnitude more ``memory-frugal'' compared to the closely related works while\nachieving SOTA accuracy scores.", "published": "2025-05-28 14:37:57", "link": "http://arxiv.org/abs/2505.22408v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Self-Reflective Reinforcement Learning for Diffusion-based Image Reasoning Generation", "abstract": "Diffusion models have recently demonstrated exceptional performance in image\ngeneration task. However, existing image generation methods still significantly\nsuffer from the dilemma of image reasoning, especially in logic-centered image\ngeneration tasks. Inspired by the success of Chain of Thought (CoT) and\nReinforcement Learning (RL) in LLMs, we propose SRRL, a self-reflective RL\nalgorithm for diffusion models to achieve reasoning generation of logical\nimages by performing reflection and iteration across generation trajectories.\nThe intermediate samples in the denoising process carry noise, making accurate\nreward evaluation difficult. To address this challenge, SRRL treats the entire\ndenoising trajectory as a CoT step with multi-round reflective denoising\nprocess and introduces condition guided forward process, which allows for\nreflective iteration between CoT steps. Through SRRL-based iterative diffusion\ntraining, we introduce image reasoning through CoT into generation tasks\nadhering to physical laws and unconventional physical phenomena for the first\ntime. Notably, experimental results of case study exhibit that the superior\nperformance of our SRRL algorithm even compared with GPT-4o. The project page\nis https://jadenpan0.github.io/srrl.github.io/.", "published": "2025-05-28 14:37:21", "link": "http://arxiv.org/abs/2505.22407v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "STDR: Spatio-Temporal Decoupling for Real-Time Dynamic Scene Rendering", "abstract": "Although dynamic scene reconstruction has long been a fundamental challenge\nin 3D vision, the recent emergence of 3D Gaussian Splatting (3DGS) offers a\npromising direction by enabling high-quality, real-time rendering through\nexplicit Gaussian primitives. However, existing 3DGS-based methods for dynamic\nreconstruction often suffer from \\textit{spatio-temporal incoherence} during\ninitialization, where canonical Gaussians are constructed by aggregating\nobservations from multiple frames without temporal distinction. This results in\nspatio-temporally entangled representations, making it difficult to model\ndynamic motion accurately. To overcome this limitation, we propose\n\\textbf{STDR} (Spatio-Temporal Decoupling for Real-time rendering), a\nplug-and-play module that learns spatio-temporal probability distributions for\neach Gaussian. STDR introduces a spatio-temporal mask, a separated deformation\nfield, and a consistency regularization to jointly disentangle spatial and\ntemporal patterns. Extensive experiments demonstrate that incorporating our\nmodule into existing 3DGS-based dynamic scene reconstruction frameworks leads\nto notable improvements in both reconstruction quality and spatio-temporal\nconsistency across synthetic and real-world benchmarks.", "published": "2025-05-28 14:26:41", "link": "http://arxiv.org/abs/2505.22400v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Zooming from Context to Cue: Hierarchical Preference Optimization for Multi-Image MLLMs", "abstract": "Multi-modal Large Language Models (MLLMs) excel at single-image tasks but\nstruggle with multi-image understanding due to cross-modal misalignment,\nleading to hallucinations (context omission, conflation, and\nmisinterpretation). Existing methods using Direct Preference Optimization (DPO)\nconstrain optimization to a solitary image reference within the input sequence,\nneglecting holistic context modeling. We propose Context-to-Cue Direct\nPreference Optimization (CcDPO), a multi-level preference optimization\nframework that enhances per-image perception in multi-image settings by zooming\ninto visual clues -- from sequential context to local details. It features: (i)\nContext-Level Optimization : Re-evaluates cognitive biases underlying MLLMs'\nmulti-image context comprehension and integrates a spectrum of low-cost global\nsequence preferences for bias mitigation. (ii) Needle-Level Optimization :\nDirects attention to fine-grained visual details through region-targeted visual\nprompts and multimodal preference supervision. To support scalable\noptimization, we also construct MultiScope-42k, an automatically generated\ndataset with high-quality multi-level preference pairs. Experiments show that\nCcDPO significantly reduces hallucinations and yields consistent performance\ngains across general single- and multi-image tasks.", "published": "2025-05-28 14:24:02", "link": "http://arxiv.org/abs/2505.22396v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PacTure: Efficient PBR Texture Generation on Packed Views with Visual Autoregressive Models", "abstract": "We present PacTure, a novel framework for generating physically-based\nrendering (PBR) material textures from an untextured 3D mesh, a text\ndescription, and an optional image prompt. Early 2D generation-based texturing\napproaches generate textures sequentially from different views, resulting in\nlong inference times and globally inconsistent textures. More recent approaches\nadopt multi-view generation with cross-view attention to enhance global\nconsistency, which, however, limits the resolution for each view. In response\nto these weaknesses, we first introduce view packing, a novel technique that\nsignificantly increases the effective resolution for each view during\nmulti-view generation without imposing additional inference cost, by\nformulating the arrangement of multi-view maps as a 2D rectangle bin packing\nproblem. In contrast to UV mapping, it preserves the spatial proximity\nessential for image generation and maintains full compatibility with current 2D\ngenerative models. To further reduce the inference cost, we enable fine-grained\ncontrol and multi-domain generation within the next-scale prediction\nautoregressive framework to create an efficient multi-view multi-domain\ngenerative backbone. Extensive experiments show that PacTure outperforms\nstate-of-the-art methods in both quality of generated PBR textures and\nefficiency in training and inference.", "published": "2025-05-28 14:23:30", "link": "http://arxiv.org/abs/2505.22394v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Identity-Preserving Text-to-Image Generation via Dual-Level Feature Decoupling and Expert-Guided Fusion", "abstract": "Recent advances in large-scale text-to-image generation models have led to a\nsurge in subject-driven text-to-image generation, which aims to produce\ncustomized images that align with textual descriptions while preserving the\nidentity of specific subjects. Despite significant progress, current methods\nstruggle to disentangle identity-relevant information from identity-irrelevant\ndetails in the input images, resulting in overfitting or failure to maintain\nsubject identity. In this work, we propose a novel framework that improves the\nseparation of identity-related and identity-unrelated features and introduces\nan innovative feature fusion mechanism to improve the quality and text\nalignment of generated images. Our framework consists of two key components: an\nImplicit-Explicit foreground-background Decoupling Module (IEDM) and a Feature\nFusion Module (FFM) based on a Mixture of Experts (MoE). IEDM combines\nlearnable adapters for implicit decoupling at the feature level with inpainting\ntechniques for explicit foreground-background separation at the image level.\nFFM dynamically integrates identity-irrelevant features with identity-related\nfeatures, enabling refined feature representations even in cases of incomplete\ndecoupling. In addition, we introduce three complementary loss functions to\nguide the decoupling process. Extensive experiments demonstrate the\neffectiveness of our proposed method in enhancing image generation quality,\nimproving flexibility in scene adaptation, and increasing the diversity of\ngenerated outputs across various textual descriptions.", "published": "2025-05-28 13:40:46", "link": "http://arxiv.org/abs/2505.22360v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Task-Driven Implicit Representations for Automated Design of LiDAR Systems", "abstract": "Imaging system design is a complex, time-consuming, and largely manual\nprocess; LiDAR design, ubiquitous in mobile devices, autonomous vehicles, and\naerial imaging platforms, adds further complexity through unique spatial and\ntemporal sampling requirements. In this work, we propose a framework for\nautomated, task-driven LiDAR system design under arbitrary constraints. To\nachieve this, we represent LiDAR configurations in a continuous six-dimensional\ndesign space and learn task-specific implicit densities in this space via\nflow-based generative modeling. We then synthesize new LiDAR systems by\nmodeling sensors as parametric distributions in 6D space and fitting these\ndistributions to our learned implicit density using expectation-maximization,\nenabling efficient, constraint-aware LiDAR system design. We validate our\nmethod on diverse tasks in 3D vision, enabling automated LiDAR system design\nacross real-world-inspired applications in face scanning, robotic tracking, and\nobject detection.", "published": "2025-05-28 13:27:42", "link": "http://arxiv.org/abs/2505.22344v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Progressive Data Dropout: An Embarrassingly Simple Approach to Faster Training", "abstract": "The success of the machine learning field has reliably depended on training\non large datasets. While effective, this trend comes at an extraordinary cost.\nThis is due to two deeply intertwined factors: the size of models and the size\nof datasets. While promising research efforts focus on reducing the size of\nmodels, the other half of the equation remains fairly mysterious. Indeed, it is\nsurprising that the standard approach to training remains to iterate over and\nover, uniformly sampling the training dataset. In this paper we explore a\nseries of alternative training paradigms that leverage insights from\nhard-data-mining and dropout, simple enough to implement and use that can\nbecome the new training standard. The proposed Progressive Data Dropout reduces\nthe number of effective epochs to as little as 12.4% of the baseline. This\nsavings actually do not come at any cost for accuracy. Surprisingly, the\nproposed method improves accuracy by up to 4.82%. Our approach requires no\nchanges to model architecture or optimizer, and can be applied across standard\ntraining pipelines, thus posing an excellent opportunity for wide adoption.\nCode can be found here: https://github.com/bazyagami/LearningWithRevision", "published": "2025-05-28 13:26:52", "link": "http://arxiv.org/abs/2505.22342v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning to Infer Parameterized Representations of Plants from 3D Scans", "abstract": "Reconstructing faithfully the 3D architecture of plants from unstructured\nobservations is a challenging task. Plants frequently contain numerous organs,\norganized in branching systems in more or less complex spatial networks,\nleading to specific computational issues due to self-occlusion or spatial\nproximity between organs. Existing works either consider inverse modeling where\nthe aim is to recover the procedural rules that allow to simulate virtual\nplants, or focus on specific tasks such as segmentation or skeletonization. We\npropose a unified approach that, given a 3D scan of a plant, allows to infer a\nparameterized representation of the plant. This representation describes the\nplant's branching structure, contains parametric information for each plant\norgan, and can therefore be used directly in a variety of tasks. In this\ndata-driven approach, we train a recursive neural network with virtual plants\ngenerated using an L-systems-based procedural model. After training, the\nnetwork allows to infer a parametric tree-like representation based on an input\n3D point cloud. Our method is applicable to any plant that can be represented\nas binary axial tree. We evaluate our approach on Chenopodium Album plants,\nusing experiments on synthetic plants to show that our unified framework allows\nfor different tasks including reconstruction, segmentation and skeletonization,\nwhile achieving results on-par with state-of-the-art for each task.", "published": "2025-05-28 13:23:48", "link": "http://arxiv.org/abs/2505.22337v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UP-SLAM: Adaptively Structured Gaussian SLAM with Uncertainty Prediction in Dynamic Environments", "abstract": "Recent 3D Gaussian Splatting (3DGS) techniques for Visual Simultaneous\nLocalization and Mapping (SLAM) have significantly progressed in tracking and\nhigh-fidelity mapping. However, their sequential optimization framework and\nsensitivity to dynamic objects limit real-time performance and robustness in\nreal-world scenarios. We present UP-SLAM, a real-time RGB-D SLAM system for\ndynamic environments that decouples tracking and mapping through a parallelized\nframework. A probabilistic octree is employed to manage Gaussian primitives\nadaptively, enabling efficient initialization and pruning without hand-crafted\nthresholds. To robustly filter dynamic regions during tracking, we propose a\ntraining-free uncertainty estimator that fuses multi-modal residuals to\nestimate per-pixel motion uncertainty, achieving open-set dynamic object\nhandling without reliance on semantic labels. Furthermore, a temporal encoder\nis designed to enhance rendering quality. Concurrently, low-dimensional\nfeatures are efficiently transformed via a shallow multilayer perceptron to\nconstruct DINO features, which are then employed to enrich the Gaussian field\nand improve the robustness of uncertainty prediction. Extensive experiments on\nmultiple challenging datasets suggest that UP-SLAM outperforms state-of-the-art\nmethods in both localization accuracy (by 59.8%) and rendering quality (by 4.57\ndB PSNR), while maintaining real-time performance and producing reusable,\nartifact-free static maps in dynamic environments.The project:\nhttps://aczheng-cai.github.io/up_slam.github.io/", "published": "2025-05-28 13:23:16", "link": "http://arxiv.org/abs/2505.22335v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Large-Area Fabrication-aware Computational Diffractive Optics", "abstract": "Differentiable optics, as an emerging paradigm that jointly optimizes optics\nand (optional) image processing algorithms, has made innovative optical designs\npossible across a broad range of applications. Many of these systems utilize\ndiffractive optical components (DOEs) for holography, PSF engineering, or\nwavefront shaping. Existing approaches have, however, mostly remained limited\nto laboratory prototypes, owing to a large quality gap between simulation and\nmanufactured devices. We aim at lifting the fundamental technical barriers to\nthe practical use of learned diffractive optical systems. To this end, we\npropose a fabrication-aware design pipeline for diffractive optics fabricated\nby direct-write grayscale lithography followed by nano-imprinting replication,\nwhich is directly suited for inexpensive mass production of large area designs.\nWe propose a super-resolved neural lithography model that can accurately\npredict the 3D geometry generated by the fabrication process. This model can be\nseamlessly integrated into existing differentiable optics frameworks, enabling\nfabrication-aware, end-to-end optimization of computational optical systems. To\ntackle the computational challenges, we also devise tensor-parallel compute\nframework centered on distributing large-scale FFT computation across many\nGPUs. As such, we demonstrate large scale diffractive optics designs up to\n32.16 mm $\\times$ 21.44 mm, simulated on grids of up to 128,640 by 85,760\nfeature points. We find adequate agreement between simulation and fabricated\nprototypes for applications such as holography and PSF engineering. We also\nachieve high image quality from an imaging system comprised only of a single\nDOE, with images processed only by a Wiener filter utilizing the simulation\nPSF. We believe our findings lift the fabrication limitations for real-world\napplications of diffractive optics and differentiable optical design.", "published": "2025-05-28 12:56:46", "link": "http://arxiv.org/abs/2505.22313v1", "categories": ["physics.optics", "cs.CV", "cs.ET", "cs.GR"], "primary_category": "physics.optics"}
{"title": "IKIWISI: An Interactive Visual Pattern Generator for Evaluating the Reliability of Vision-Language Models Without Ground Truth", "abstract": "We present IKIWISI (\"I Know It When I See It\"), an interactive visual pattern\ngenerator for assessing vision-language models in video object recognition when\nground truth is unavailable. IKIWISI transforms model outputs into a binary\nheatmap where green cells indicate object presence and red cells indicate\nobject absence. This visualization leverages humans' innate pattern recognition\nabilities to evaluate model reliability. IKIWISI introduces \"spy objects\":\nadversarial instances users know are absent, to discern models hallucinating on\nnonexistent items. The tool functions as a cognitive audit mechanism, surfacing\nmismatches between human and machine perception by visualizing where models\ndiverge from human understanding.\n  Our study with 15 participants found that users considered IKIWISI easy to\nuse, made assessments that correlated with objective metrics when available,\nand reached informed conclusions by examining only a small fraction of heatmap\ncells. This approach not only complements traditional evaluation methods\nthrough visual assessment of model behavior with custom object sets, but also\nreveals opportunities for improving alignment between human perception and\nmachine understanding in vision-language systems.", "published": "2025-05-28 12:41:08", "link": "http://arxiv.org/abs/2505.22305v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction", "abstract": "Computer-aided design (CAD) is crucial in prototyping 3D objects through\ngeometric instructions (i.e., CAD programs). In practical design workflows,\ndesigners often engage in time-consuming reviews and refinements of these\nprototypes by comparing them with reference images. To bridge this gap, we\nintroduce the CAD review task to automatically detect and correct potential\nerrors, ensuring consistency between the constructed 3D objects and reference\nimages. However, recent advanced multimodal large language models (MLLMs)\nstruggle to recognize multiple geometric components and perform spatial\ngeometric operations within the CAD program, leading to inaccurate reviews. In\nthis paper, we propose the CAD program repairer (ReCAD) framework to\neffectively detect program errors and provide helpful feedback on error\ncorrection. Additionally, we create a dataset, CADReview, consisting of over\n20K program-image pairs, with diverse errors for the CAD review task. Extensive\nexperiments demonstrate that our ReCAD significantly outperforms existing\nMLLMs, which shows great potential in design applications.", "published": "2025-05-28 12:41:00", "link": "http://arxiv.org/abs/2505.22304v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Controlled Scenarios to Real-World: Cross-Domain Degradation Pattern Matching for All-in-One Image Restoration", "abstract": "As a fundamental imaging task, All-in-One Image Restoration (AiOIR) aims to\nachieve image restoration caused by multiple degradation patterns via a single\nmodel with unified parameters. Although existing AiOIR approaches obtain\npromising performance in closed and controlled scenarios, they still suffered\nfrom considerable performance reduction in real-world scenarios since the gap\nof data distributions between the training samples (source domain) and\nreal-world test samples (target domain) can lead inferior degradation awareness\nability. To address this issue, a Unified Domain-Adaptive Image Restoration\n(UDAIR) framework is proposed to effectively achieve AiOIR by leveraging the\nlearned knowledge from source domain to target domain. To improve the\ndegradation identification, a codebook is designed to learn a group of discrete\nembeddings to denote the degradation patterns, and the cross-sample contrastive\nlearning mechanism is further proposed to capture shared features from\ndifferent samples of certain degradation. To bridge the data gap, a domain\nadaptation strategy is proposed to build the feature projection between the\nsource and target domains by dynamically aligning their codebook embeddings,\nand a correlation alignment-based test-time adaptation mechanism is designed to\nfine-tune the alignment discrepancies by tightening the degradation embeddings\nto the corresponding cluster center in the source domain. Experimental results\non 10 open-source datasets demonstrate that UDAIR achieves new state-of-the-art\nperformance for the AiOIR task. Most importantly, the feature cluster validate\nthe degradation identification under unknown conditions, and qualitative\ncomparisons showcase robust generalization to real-world scenarios.", "published": "2025-05-28 12:22:00", "link": "http://arxiv.org/abs/2505.22284v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Fine-Grained Geometry for Sparse-View Splatting via Cascade Depth Loss", "abstract": "Novel view synthesis is a fundamental task in 3D computer vision that aims to\nreconstruct realistic images from a set of posed input views. However,\nreconstruction quality degrades significantly under sparse-view conditions due\nto limited geometric cues. Existing methods, such as Neural Radiance Fields\n(NeRF) and the more recent 3D Gaussian Splatting (3DGS), often suffer from\nblurred details and structural artifacts when trained with insufficient views.\nRecent works have identified the quality of rendered depth as a key factor in\nmitigating these artifacts, as it directly affects geometric accuracy and view\nconsistency. In this paper, we address these challenges by introducing\nHierarchical Depth-Guided Splatting (HDGS), a depth supervision framework that\nprogressively refines geometry from coarse to fine levels. Central to HDGS is a\nnovel Cascade Pearson Correlation Loss (CPCL), which aligns rendered and\nestimated monocular depths across multiple spatial scales. By enforcing\nmulti-scale depth consistency, our method substantially improves structural\nfidelity in sparse-view scenarios. Extensive experiments on the LLFF and DTU\nbenchmarks demonstrate that HDGS achieves state-of-the-art performance under\nsparse-view settings while maintaining efficient and high-quality rendering", "published": "2025-05-28 12:16:42", "link": "http://arxiv.org/abs/2505.22279v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Domain Adaptation of Attention Heads for Zero-shot Anomaly Detection", "abstract": "Zero-shot anomaly detection (ZSAD) in images is an approach that can detect\nanomalies without access to normal samples, which can be beneficial in various\nrealistic scenarios where model training is not possible. However, existing\nZSAD research has shown limitations by either not considering domain adaptation\nof general-purpose backbone models to anomaly detection domains or by\nimplementing only partial adaptation to some model components. In this paper,\nwe propose HeadCLIP to overcome these limitations by effectively adapting both\ntext and image encoders to the domain. HeadCLIP generalizes the concepts of\nnormality and abnormality through learnable prompts in the text encoder, and\nintroduces learnable head weights to the image encoder to dynamically adjust\nthe features held by each attention head according to domain characteristics.\nAdditionally, we maximize the effect of domain adaptation by introducing a\njoint anomaly score that utilizes domain-adapted pixel-level information for\nimage-level anomaly detection. Experimental results using multiple real\ndatasets in both industrial and medical domains show that HeadCLIP outperforms\nexisting ZSAD techniques at both pixel and image levels. In the industrial\ndomain, improvements of up to 4.9%p in pixel-level mean anomaly detection score\n(mAD) and up to 3.0%p in image-level mAD were achieved, with similar\nimprovements (3.2%p, 3.1%p) in the medical domain.", "published": "2025-05-28 11:45:51", "link": "http://arxiv.org/abs/2505.22259v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LiDAR Based Semantic Perception for Forklifts in Outdoor Environments", "abstract": "In this study, we present a novel LiDAR-based semantic segmentation framework\ntailored for autonomous forklifts operating in complex outdoor environments.\nCentral to our approach is the integration of a dual LiDAR system, which\ncombines forward-facing and downward-angled LiDAR sensors to enable\ncomprehensive scene understanding, specifically tailored for industrial\nmaterial handling tasks. The dual configuration improves the detection and\nsegmentation of dynamic and static obstacles with high spatial precision. Using\nhigh-resolution 3D point clouds captured from two sensors, our method employs a\nlightweight yet robust approach that segments the point clouds into\nsafety-critical instance classes such as pedestrians, vehicles, and forklifts,\nas well as environmental classes such as driveable ground, lanes, and\nbuildings. Experimental validation demonstrates that our approach achieves high\nsegmentation accuracy while satisfying strict runtime requirements,\nestablishing its viability for safety-aware, fully autonomous forklift\nnavigation in dynamic warehouse and yard environments.", "published": "2025-05-28 11:45:14", "link": "http://arxiv.org/abs/2505.22258v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "YH-MINER: Multimodal Intelligent System for Natural Ecological Reef Metric Extraction", "abstract": "Coral reefs, crucial for sustaining marine biodiversity and ecological\nprocesses (e.g., nutrient cycling, habitat provision), face escalating threats,\nunderscoring the need for efficient monitoring. Coral reef ecological\nmonitoring faces dual challenges of low efficiency in manual analysis and\ninsufficient segmentation accuracy in complex underwater scenarios. This study\ndevelops the YH-OSI system, establishing an intelligent framework centered on\nthe Multimodal Large Model (MLLM) for \"object detection-semantic\nsegmentation-prior input\". The system uses the object detection module\n(mAP@0.5=0.78) to generate spatial prior boxes for coral instances, driving the\nsegment module to complete pixel-level segmentation in low-light and densely\noccluded scenarios. The segmentation masks and finetuned classification\ninstructions are fed into the Qwen2-VL-based multimodal model as prior inputs,\nachieving a genus-level classification accuracy of 88% and simultaneously\nextracting core ecological metrics. Meanwhile, the system retains the\nscalability of the multimodal model through standardized interfaces, laying a\nfoundation for future integration into multimodal agent-based underwater robots\nand supporting the full-process automation of \"image acquisition-prior\ngeneration-real-time analysis.\"", "published": "2025-05-28 11:36:18", "link": "http://arxiv.org/abs/2505.22250v1", "categories": ["cs.CV", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "StateSpaceDiffuser: Bringing Long Context to Diffusion World Models", "abstract": "World models have recently become promising tools for predicting realistic\nvisuals based on actions in complex environments. However, their reliance on a\nshort sequence of observations causes them to quickly lose track of context. As\na result, visual consistency breaks down after just a few steps, and generated\nscenes no longer reflect information seen earlier. This limitation of the\nstate-of-the-art diffusion-based world models comes from their lack of a\nlasting environment state. To address this problem, we introduce\nStateSpaceDiffuser, where a diffusion model is enabled to perform on\nlong-context tasks by integrating a sequence representation from a state-space\nmodel (Mamba), representing the entire interaction history. This design\nrestores long-term memory without sacrificing the high-fidelity synthesis of\ndiffusion models. To rigorously measure temporal consistency, we develop an\nevaluation protocol that probes a model's ability to reinstantiate seen content\nin extended rollouts. Comprehensive experiments show that StateSpaceDiffuser\nsignificantly outperforms a strong diffusion-only baseline, maintaining a\ncoherent visual context for an order of magnitude more steps. It delivers\nconsistent views in both a 2D maze navigation and a complex 3D environment.\nThese results establish that bringing state-space representations into\ndiffusion models is highly effective in demonstrating both visual details and\nlong-term memory.", "published": "2025-05-28 11:27:54", "link": "http://arxiv.org/abs/2505.22246v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enjoying Information Dividend: Gaze Track-based Medical Weakly Supervised Segmentation", "abstract": "Weakly supervised semantic segmentation (WSSS) in medical imaging struggles\nwith effectively using sparse annotations. One promising direction for WSSS\nleverages gaze annotations, captured via eye trackers that record regions of\ninterest during diagnostic procedures. However, existing gaze-based methods,\nsuch as GazeMedSeg, do not fully exploit the rich information embedded in gaze\ndata. In this paper, we propose GradTrack, a framework that utilizes\nphysicians' gaze track, including fixation points, durations, and temporal\norder, to enhance WSSS performance. GradTrack comprises two key components:\nGaze Track Map Generation and Track Attention, which collaboratively enable\nprogressive feature refinement through multi-level gaze supervision during the\ndecoding process. Experiments on the Kvasir-SEG and NCI-ISBI datasets\ndemonstrate that GradTrack consistently outperforms existing gaze-based\nmethods, achieving Dice score improvements of 3.21\\% and 2.61\\%, respectively.\nMoreover, GradTrack significantly narrows the performance gap with fully\nsupervised models such as nnUNet.", "published": "2025-05-28 11:05:50", "link": "http://arxiv.org/abs/2505.22230v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GoMatching++: Parameter- and Data-Efficient Arbitrary-Shaped Video Text Spotting and Benchmarking", "abstract": "Video text spotting (VTS) extends image text spotting (ITS) by adding text\ntracking, significantly increasing task complexity. Despite progress in VTS,\nexisting methods still fall short of the performance seen in ITS. This paper\nidentifies a key limitation in current video text spotters: limited recognition\ncapability, even after extensive end-to-end training. To address this, we\npropose GoMatching++, a parameter- and data-efficient method that transforms an\noff-the-shelf image text spotter into a video specialist. The core idea lies in\nfreezing the image text spotter and introducing a lightweight, trainable\ntracker, which can be optimized efficiently with minimal training data. Our\napproach includes two key components: (1) a rescoring mechanism to bridge the\ndomain gap between image and video data, and (2) the LST-Matcher, which\nenhances the frozen image text spotter's ability to handle video text. We\nexplore various architectures for LST-Matcher to ensure efficiency in both\nparameters and training data. As a result, GoMatching++ sets new performance\nrecords on challenging benchmarks such as ICDAR15-video, DSText, and BOVText,\nwhile significantly reducing training costs. To address the lack of curved text\ndatasets in VTS, we introduce ArTVideo, a new benchmark featuring over 30%\ncurved text with detailed annotations. We also provide a comprehensive\nstatistical analysis and experimental results for ArTVideo. We believe that\nGoMatching++ and the ArTVideo benchmark will drive future advancements in video\ntext spotting. The source code, models and dataset are publicly available at\nhttps://github.com/Hxyz-123/GoMatching.", "published": "2025-05-28 11:02:45", "link": "http://arxiv.org/abs/2505.22228v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hadaptive-Net: Efficient Vision Models via Adaptive Cross-Hadamard Synergy", "abstract": "Recent studies have revealed the immense potential of Hadamard product in\nenhancing network representational capacity and dimensional compression.\nHowever, despite its theoretical promise, this technique has not been\nsystematically explored or effectively applied in practice, leaving its full\ncapabilities underdeveloped. In this work, we first analyze and identify the\nadvantages of Hadamard product over standard convolutional operations in\ncross-channel interaction and channel expansion. Building upon these insights,\nwe propose a computationally efficient module: Adaptive Cross-Hadamard (ACH),\nwhich leverages adaptive cross-channel Hadamard products for high-dimensional\nchannel expansion. Furthermore, we introduce Hadaptive-Net (Hadamard Adaptive\nNetwork), a lightweight network backbone for visual tasks, which is\ndemonstrated through experiments that it achieves an unprecedented balance\nbetween inference speed and accuracy through our proposed module.", "published": "2025-05-28 10:58:56", "link": "http://arxiv.org/abs/2505.22226v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Survey on Training-free Open-Vocabulary Semantic Segmentation", "abstract": "Semantic segmentation is one of the most fundamental tasks in image\nunderstanding with a long history of research, and subsequently a myriad of\ndifferent approaches. Traditional methods strive to train models up from\nscratch, requiring vast amounts of computational resources and training data.\nIn the advent of moving to open-vocabulary semantic segmentation, which asks\nmodels to classify beyond learned categories, large quantities of finely\nannotated data would be prohibitively expensive. Researchers have instead\nturned to training-free methods where they leverage existing models made for\ntasks where data is more easily acquired. Specifically, this survey will cover\nthe history, nuance, idea development and the state-of-the-art in training-free\nopen-vocabulary semantic segmentation that leverages existing multi-modal\nclassification models. We will first give a preliminary on the task definition\nfollowed by an overview of popular model archetypes and then spotlight over 30\napproaches split into broader research branches: purely CLIP-based, those\nleveraging auxiliary visual foundation models and ones relying on generative\nmethods. Subsequently, we will discuss the limitations and potential problems\nof current research, as well as provide some underexplored ideas for future\nstudy. We believe this survey will serve as a good onboarding read to new\nresearchers and spark increased interest in the area.", "published": "2025-05-28 10:37:52", "link": "http://arxiv.org/abs/2505.22209v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "S2AFormer: Strip Self-Attention for Efficient Vision Transformer", "abstract": "Vision Transformer (ViT) has made significant advancements in computer\nvision, thanks to its token mixer's sophisticated ability to capture global\ndependencies between all tokens. However, the quadratic growth in computational\ndemands as the number of tokens increases limits its practical efficiency.\nAlthough recent methods have combined the strengths of convolutions and\nself-attention to achieve better trade-offs, the expensive pairwise token\naffinity and complex matrix operations inherent in self-attention remain a\nbottleneck. To address this challenge, we propose S2AFormer, an efficient\nVision Transformer architecture featuring novel Strip Self-Attention (SSA). We\ndesign simple yet effective Hybrid Perception Blocks (HPBs) to effectively\nintegrate the local perception capabilities of CNNs with the global context\nmodeling of Transformer's attention mechanisms. A key innovation of SSA lies in\nits reducing the spatial dimensions of $K$ and $V$ while compressing the\nchannel dimensions of $Q$ and $K$. This design significantly reduces\ncomputational overhead while preserving accuracy, striking an optimal balance\nbetween efficiency and effectiveness. We evaluate the robustness and efficiency\nof S2AFormer through extensive experiments on multiple vision benchmarks,\nincluding ImageNet-1k for image classification, ADE20k for semantic\nsegmentation, and COCO for object detection and instance segmentation. Results\ndemonstrate that S2AFormer achieves significant accuracy gains with superior\nefficiency in both GPU and non-GPU environments, making it a strong candidate\nfor efficient vision Transformers.", "published": "2025-05-28 10:17:23", "link": "http://arxiv.org/abs/2505.22195v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Q-VDiT: Towards Accurate Quantization and Distillation of Video-Generation Diffusion Transformers", "abstract": "Diffusion transformers (DiT) have demonstrated exceptional performance in\nvideo generation. However, their large number of parameters and high\ncomputational complexity limit their deployment on edge devices. Quantization\ncan reduce storage requirements and accelerate inference by lowering the\nbit-width of model parameters. Yet, existing quantization methods for image\ngeneration models do not generalize well to video generation tasks. We identify\ntwo primary challenges: the loss of information during quantization and the\nmisalignment between optimization objectives and the unique requirements of\nvideo generation. To address these challenges, we present Q-VDiT, a\nquantization framework specifically designed for video DiT models. From the\nquantization perspective, we propose the Token-aware Quantization Estimator\n(TQE), which compensates for quantization errors in both the token and feature\ndimensions. From the optimization perspective, we introduce Temporal\nMaintenance Distillation (TMD), which preserves the spatiotemporal correlations\nbetween frames and enables the optimization of each frame with respect to the\noverall video context. Our W3A6 Q-VDiT achieves a scene consistency of 23.40,\nsetting a new benchmark and outperforming current state-of-the-art quantization\nmethods by 1.9$\\times$. Code will be available at\nhttps://github.com/cantbebetter2/Q-VDiT.", "published": "2025-05-28 09:33:52", "link": "http://arxiv.org/abs/2505.22167v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation", "abstract": "Vision-Language-Action (VLA) models have advanced general-purpose robotic\nmanipulation by leveraging pretrained visual and linguistic representations.\nHowever, they struggle with contact-rich tasks that require fine-grained\ncontrol involving force, especially under visual occlusion or dynamic\nuncertainty. To address these limitations, we propose \\textbf{ForceVLA}, a\nnovel end-to-end manipulation framework that treats external force sensing as a\nfirst-class modality within VLA systems. ForceVLA introduces \\textbf{FVLMoE}, a\nforce-aware Mixture-of-Experts fusion module that dynamically integrates\npretrained visual-language embeddings with real-time 6-axis force feedback\nduring action decoding. This enables context-aware routing across\nmodality-specific experts, enhancing the robot's ability to adapt to subtle\ncontact dynamics. We also introduce \\textbf{ForceVLA-Data}, a new dataset\ncomprising synchronized vision, proprioception, and force-torque signals across\nfive contact-rich manipulation tasks. ForceVLA improves average task success by\n23.2\\% over strong $\\pi_0$-based baselines, achieving up to 80\\% success in\ntasks such as plug insertion. Our approach highlights the importance of\nmultimodal integration for dexterous manipulation and sets a new benchmark for\nphysically intelligent robotic control. Code and data will be released at\nhttps://sites.google.com/view/forcevla2025.", "published": "2025-05-28 09:24:25", "link": "http://arxiv.org/abs/2505.22159v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Learning A Robust RGB-Thermal Detector for Extreme Modality Imbalance", "abstract": "RGB-Thermal (RGB-T) object detection utilizes thermal infrared (TIR) images\nto complement RGB data, improving robustness in challenging conditions.\nTraditional RGB-T detectors assume balanced training data, where both\nmodalities contribute equally. However, in real-world scenarios, modality\ndegradation-due to environmental factors or technical issues-can lead to\nextreme modality imbalance, causing out-of-distribution (OOD) issues during\ntesting and disrupting model convergence during training. This paper addresses\nthese challenges by proposing a novel base-and-auxiliary detector architecture.\nWe introduce a modality interaction module to adaptively weigh modalities based\non their quality and handle imbalanced samples effectively. Additionally, we\nleverage modality pseudo-degradation to simulate real-world imbalances in\ntraining data. The base detector, trained on high-quality pairs, provides a\nconsistency constraint for the auxiliary detector, which receives degraded\nsamples. This framework enhances model robustness, ensuring reliable\nperformance even under severe modality degradation. Experimental results\ndemonstrate the effectiveness of our method in handling extreme modality\nimbalances~(decreasing the Missing Rate by 55%) and improving performance\nacross various baseline detectors.", "published": "2025-05-28 09:18:55", "link": "http://arxiv.org/abs/2505.22154v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Question Answering via only 2D Vision-Language Models", "abstract": "Large vision-language models (LVLMs) have significantly advanced numerous\nfields. In this work, we explore how to harness their potential to address 3D\nscene understanding tasks, using 3D question answering (3D-QA) as a\nrepresentative example. Due to the limited training data in 3D, we do not train\nLVLMs but infer in a zero-shot manner. Specifically, we sample 2D views from a\n3D point cloud and feed them into 2D models to answer a given question. When\nthe 2D model is chosen, e.g., LLAVA-OV, the quality of sampled views matters\nthe most. We propose cdViews, a novel approach to automatically selecting\ncritical and diverse Views for 3D-QA. cdViews consists of two key components:\nviewSelector prioritizing critical views based on their potential to provide\nanswer-specific information, and viewNMS enhancing diversity by removing\nredundant views based on spatial overlap. We evaluate cdViews on the\nwidely-used ScanQA and SQA benchmarks, demonstrating that it achieves\nstate-of-the-art performance in 3D-QA while relying solely on 2D models without\nfine-tuning. These findings support our belief that 2D LVLMs are currently the\nmost effective alternative (of the resource-intensive 3D LVLMs) for addressing\n3D tasks.", "published": "2025-05-28 09:04:39", "link": "http://arxiv.org/abs/2505.22143v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "What Makes for Text to 360-degree Panorama Generation with Stable Diffusion?", "abstract": "Recent prosperity of text-to-image diffusion models, e.g. Stable Diffusion,\nhas stimulated research to adapt them to 360-degree panorama generation. Prior\nwork has demonstrated the feasibility of using conventional low-rank adaptation\ntechniques on pre-trained diffusion models to generate panoramic images.\nHowever, the substantial domain gap between perspective and panoramic images\nraises questions about the underlying mechanisms enabling this empirical\nsuccess. We hypothesize and examine that the trainable counterparts exhibit\ndistinct behaviors when fine-tuned on panoramic data, and such an adaptation\nconceals some intrinsic mechanism to leverage the prior knowledge within the\npre-trained diffusion models. Our analysis reveals the following: 1) the query\nand key matrices in the attention modules are responsible for common\ninformation that can be shared between the panoramic and perspective domains,\nthus are less relevant to panorama generation; and 2) the value and output\nweight matrices specialize in adapting pre-trained knowledge to the panoramic\ndomain, playing a more critical role during fine-tuning for panorama\ngeneration. We empirically verify these insights by introducing a simple\nframework called UniPano, with the objective of establishing an elegant\nbaseline for future research. UniPano not only outperforms existing methods but\nalso significantly reduces memory usage and training time compared to prior\ndual-branch approaches, making it scalable for end-to-end panorama generation\nwith higher resolution. The code will be released.", "published": "2025-05-28 08:54:04", "link": "http://arxiv.org/abs/2505.22129v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Autoregression-free video prediction using diffusion model for mitigating error propagation", "abstract": "Existing long-term video prediction methods often rely on an autoregressive\nvideo prediction mechanism. However, this approach suffers from error\npropagation, particularly in distant future frames. To address this limitation,\nthis paper proposes the first AutoRegression-Free (ARFree) video prediction\nframework using diffusion models. Different from an autoregressive video\nprediction mechanism, ARFree directly predicts any future frame tuples from the\ncontext frame tuple. The proposed ARFree consists of two key components: 1) a\nmotion prediction module that predicts a future motion using motion feature\nextracted from the context frame tuple; 2) a training method that improves\nmotion continuity and contextual consistency between adjacent future frame\ntuples. Our experiments with two benchmark datasets show that the proposed\nARFree video prediction framework outperforms several state-of-the-art video\nprediction methods.", "published": "2025-05-28 08:40:38", "link": "http://arxiv.org/abs/2505.22111v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adapting Segment Anything Model for Power Transmission Corridor Hazard Segmentation", "abstract": "Power transmission corridor hazard segmentation (PTCHS) aims to separate\ntransmission equipment and surrounding hazards from complex background,\nconveying great significance to maintaining electric power transmission safety.\nRecently, the Segment Anything Model (SAM) has emerged as a foundational vision\nmodel and pushed the boundaries of segmentation tasks. However, SAM struggles\nto deal with the target objects in complex transmission corridor scenario,\nespecially those with fine structure. In this paper, we propose ELE-SAM,\nadapting SAM for the PTCHS task. Technically, we develop a Context-Aware Prompt\nAdapter to achieve better prompt tokens via incorporating global-local features\nand focusing more on key regions. Subsequently, to tackle the hazard objects\nwith fine structure in complex background, we design a High-Fidelity Mask\nDecoder by leveraging multi-granularity mask features and then scaling them to\na higher resolution. Moreover, to train ELE-SAM and advance this field, we\nconstruct the ELE-40K benchmark, the first large-scale and real-world dataset\nfor PTCHS including 44,094 image-mask pairs. Experimental results for ELE-40K\ndemonstrate the superior performance that ELE-SAM outperforms the baseline\nmodel with the average 16.8% mIoU and 20.6% mBIoU performance improvement.\nMoreover, compared with the state-of-the-art method on HQSeg-44K, the average\n2.9% mIoU and 3.8% mBIoU absolute improvements further validate the\neffectiveness of our method on high-quality generic object segmentation. The\nsource code and dataset are available at https://github.com/Hhaizee/ELE-SAM.", "published": "2025-05-28 08:32:55", "link": "http://arxiv.org/abs/2505.22105v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On the Transferability and Discriminability of Repersentation Learning in Unsupervised Domain Adaptation", "abstract": "In this paper, we addressed the limitation of relying solely on distribution\nalignment and source-domain empirical risk minimization in Unsupervised Domain\nAdaptation (UDA). Our information-theoretic analysis showed that this standard\nadversarial-based framework neglects the discriminability of target-domain\nfeatures, leading to suboptimal performance. To bridge this\ntheoretical-practical gap, we defined \"good representation learning\" as\nguaranteeing both transferability and discriminability, and proved that an\nadditional loss term targeting target-domain discriminability is necessary.\nBuilding on these insights, we proposed a novel adversarial-based UDA framework\nthat explicitly integrates a domain alignment objective with a\ndiscriminability-enhancing constraint. Instantiated as Domain-Invariant\nRepresentation Learning with Global and Local Consistency (RLGLC), our method\nleverages Asymmetrically-Relaxed Wasserstein of Wasserstein Distance (AR-WWD)\nto address class imbalance and semantic dimension weighting, and employs a\nlocal consistency mechanism to preserve fine-grained target-domain\ndiscriminative information. Extensive experiments across multiple benchmark\ndatasets demonstrate that RLGLC consistently surpasses state-of-the-art\nmethods, confirming the value of our theoretical perspective and underscoring\nthe necessity of enforcing both transferability and discriminability in\nadversarial-based UDA.", "published": "2025-05-28 08:24:43", "link": "http://arxiv.org/abs/2505.22099v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "UAVPairs: A Challenging Benchmark for Match Pair Retrieval of Large-scale UAV Images", "abstract": "The primary contribution of this paper is a challenging benchmark dataset,\nUAVPairs, and a training pipeline designed for match pair retrieval of\nlarge-scale UAV images. First, the UAVPairs dataset, comprising 21,622\nhigh-resolution images across 30 diverse scenes, is constructed; the 3D points\nand tracks generated by SfM-based 3D reconstruction are employed to define the\ngeometric similarity of image pairs, ensuring genuinely matchable image pairs\nare used for training. Second, to solve the problem of expensive mining cost\nfor global hard negative mining, a batched nontrivial sample mining strategy is\nproposed, leveraging the geometric similarity and multi-scene structure of the\nUAVPairs to generate training samples as to accelerate training. Third,\nrecognizing the limitation of pair-based losses, the ranked list loss is\ndesigned to improve the discrimination of image retrieval models, which\noptimizes the global similarity structure constructed from the positive set and\nnegative set. Finally, the effectiveness of the UAVPairs dataset and training\npipeline is validated through comprehensive experiments on three distinct\nlarge-scale UAV datasets. The experiment results demonstrate that models\ntrained with the UAVPairs dataset and the ranked list loss achieve\nsignificantly improved retrieval accuracy compared to models trained on\nexisting datasets or with conventional losses. Furthermore, these improvements\ntranslate to enhanced view graph connectivity and higher quality of\nreconstructed 3D models. The models trained by the proposed approach perform\nmore robustly compared with hand-crafted global features, particularly in\nchallenging repetitively textured scenes and weakly textured scenes. For match\npair retrieval of large-scale UAV images, the trained image retrieval models\noffer an effective solution. The dataset would be made publicly available at\nhttps://github.com/json87/UAVPairs.", "published": "2025-05-28 08:21:05", "link": "http://arxiv.org/abs/2505.22098v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fast Feature Matching of UAV Images via Matrix Band Reduction-based GPU Data Schedule", "abstract": "Feature matching dominats the time costs in structure from motion (SfM). The\nprimary contribution of this study is a GPU data schedule algorithm for\nefficient feature matching of Unmanned aerial vehicle (UAV) images. The core\nidea is to divide the whole dataset into blocks based on the matrix band\nreduction (MBR) and achieve efficient feature matching via GPU-accelerated\ncascade hashing. First, match pairs are selected by using an image retrieval\ntechnique, which converts images into global descriptors and searches\nhigh-dimension nearest neighbors with graph indexing. Second, compact image\nblocks are iteratively generated from a MBR-based data schedule strategy, which\nexploits image connections to avoid redundant data IO (input/output) burden and\nincreases the usage of GPU computing power. Third, guided by the generated\nimage blocks, feature matching is executed sequentially within the framework of\nGPU-accelerated cascade hashing, and initial candidate matches are refined by\ncombining a local geometric constraint and RANSAC-based global verification.\nFor further performance improvement, these two seps are designed to execute\nparallelly in GPU and CPU. Finally, the performance of the proposed solution is\nevaluated by using large-scale UAV datasets. The results demonstrate that it\nincreases the efficiency of feature matching with speedup ratios ranging from\n77.0 to 100.0 compared with KD-Tree based matching methods, and achieves\ncomparable accuracy in relative and absolute bundle adjustment (BA). The\nproposed algorithm is an efficient solution for feature matching of UAV images.", "published": "2025-05-28 08:12:12", "link": "http://arxiv.org/abs/2505.22089v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MObyGaze: a film dataset of multimodal objectification densely annotated by experts", "abstract": "Characterizing and quantifying gender representation disparities in\naudiovisual storytelling contents is necessary to grasp how stereotypes may\nperpetuate on screen. In this article, we consider the high-level construct of\nobjectification and introduce a new AI task to the ML community: characterize\nand quantify complex multimodal (visual, speech, audio) temporal patterns\nproducing objectification in films. Building on film studies and psychology, we\ndefine the construct of objectification in a structured thesaurus involving 5\nsub-constructs manifesting through 11 concepts spanning 3 modalities. We\nintroduce the Multimodal Objectifying Gaze (MObyGaze) dataset, made of 20\nmovies annotated densely by experts for objectification levels and concepts\nover freely delimited segments: it amounts to 6072 segments over 43 hours of\nvideo with fine-grained localization and categorization. We formulate different\nlearning tasks, propose and investigate best ways to learn from the diversity\nof labels among a low number of annotators, and benchmark recent vision, text\nand audio models, showing the feasibility of the task. We make our code and our\ndataset available to the community and described in the Croissant format:\nhttps://anonymous.4open.science/r/MObyGaze-F600/.", "published": "2025-05-28 08:07:28", "link": "http://arxiv.org/abs/2505.22084v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis", "abstract": "The development of large-scale image-text pair datasets has significantly\nadvanced self-supervised learning in Vision-Language Processing (VLP). However,\ndirectly applying general-domain architectures such as CLIP to medical data\npresents challenges, particularly in handling negations and addressing the\ninherent data imbalance of medical datasets. To address these issues, we\npropose a novel approach that integrates clinically-enhanced dynamic soft\nlabels and medical graphical alignment, thereby improving clinical\ncomprehension and the applicability of contrastive loss in medical contexts.\nFurthermore, we introduce negation-based hard negatives to deepen the model's\nunderstanding of the complexities of clinical language. Our approach is easily\nintegrated into the medical CLIP training pipeline and achieves\nstate-of-the-art performance across multiple tasks, including zero-shot,\nfine-tuned classification, and report retrieval. To comprehensively evaluate\nour model's capacity for understanding clinical language, we introduce\nCXR-Align, a benchmark uniquely designed to evaluate the understanding of\nnegation and clinical information within chest X-ray (CXR) datasets.\nExperimental results demonstrate that our proposed methods are straightforward\nto implement and generalize effectively across contrastive learning frameworks,\nenhancing medical VLP capabilities and advancing clinical language\nunderstanding in medical imaging.", "published": "2025-05-28 08:00:18", "link": "http://arxiv.org/abs/2505.22079v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving", "abstract": "Ensuring robust and generalizable autonomous driving requires not only broad\nscenario coverage but also efficient repair of failure cases, particularly\nthose related to challenging and safety-critical scenarios. However, existing\nscenario generation and selection methods often lack adaptivity and semantic\nrelevance, limiting their impact on performance improvement. In this paper, we\npropose \\textbf{SERA}, an LLM-powered framework that enables autonomous driving\nsystems to self-evolve by repairing failure cases through targeted scenario\nrecommendation. By analyzing performance logs, SERA identifies failure patterns\nand dynamically retrieves semantically aligned scenarios from a structured\nbank. An LLM-based reflection mechanism further refines these recommendations\nto maximize relevance and diversity. The selected scenarios are used for\nfew-shot fine-tuning, enabling targeted adaptation with minimal data.\nExperiments on the benchmark show that SERA consistently improves key metrics\nacross multiple autonomous driving baselines, demonstrating its effectiveness\nand generalizability under safety-critical conditions.", "published": "2025-05-28 07:46:19", "link": "http://arxiv.org/abs/2505.22067v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "AquaMonitor: A multimodal multi-view image sequence dataset for real-life aquatic invertebrate biodiversity monitoring", "abstract": "This paper presents the AquaMonitor dataset, the first large computer vision\ndataset of aquatic invertebrates collected during routine environmental\nmonitoring. While several large species identification datasets exist, they are\nrarely collected using standardized collection protocols, and none focus on\naquatic invertebrates, which are particularly laborious to collect. For\nAquaMonitor, we imaged all specimens from two years of monitoring whenever\nimaging was possible given practical limitations. The dataset enables the\nevaluation of automated identification methods for real-life monitoring\npurposes using a realistically challenging and unbiased setup. The dataset has\n2.7M images from 43,189 specimens, DNA sequences for 1358 specimens, and dry\nmass and size measurements for 1494 specimens, making it also one of the\nlargest biological multi-view and multimodal datasets to date. We define three\nbenchmark tasks and provide strong baselines for these: 1) Monitoring\nbenchmark, reflecting real-life deployment challenges such as open-set\nrecognition, distribution shift, and extreme class imbalance, 2) Classification\nbenchmark, which follows a standard fine-grained visual categorization setup,\nand 3) Few-shot benchmark, which targets classes with only few training\nexamples from very fine-grained categories. Advancements on the Monitoring\nbenchmark can directly translate to improvement of aquatic biodiversity\nmonitoring, which is an important component of regular legislative water\nquality assessment in many countries.", "published": "2025-05-28 07:45:20", "link": "http://arxiv.org/abs/2505.22065v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Counting big Ramsey degrees of the homogeneous and universal $K_4$-free graph", "abstract": "Big Ramsey degrees of Fra\\\"iss\\'e limits of finitely constrained free\namalgamation classes in finite binary languages have been recently fully\ncharacterised by Balko, Chodounsk\\'y, Dobrinen, Hubi\\v{c}ka, Kone\\v{c}n\\'y,\nVena, and Zucker. A special case of this characterisation is the universal\nhomogeneous $K_4$-free graph. We give a self-contained and relatively compact\npresentation of this case and compute the actual big Ramsey degrees of small\ngraphs.", "published": "2025-05-28 17:43:21", "link": "http://arxiv.org/abs/2505.22620v1", "categories": ["math.CO", "cs.DM", "math.LO", "05C55, 05D10, 05C30", "G.2.1; G.2.2"], "primary_category": "math.CO"}
{"title": "Oscillating subalgebras of the atomless countable Boolean algebra", "abstract": "We show that the big Ramsey degree of the Boolean algebra with 3 atoms within\nthe countable atomless Boolean algebra is infinite.", "published": "2025-05-28 17:17:39", "link": "http://arxiv.org/abs/2505.22603v1", "categories": ["math.LO", "cs.DM", "math.CO", "05C55, 06E05, 03E02, 05D10", "G.2.1"], "primary_category": "math.LO"}
{"title": "On Big Ramsey degrees of universal $\u03c9$-edge-labeled hypergraphs", "abstract": "We show that the big Ramsey degrees of every countable universal $u$-uniform\n$\\omega$-edge-labeled hypergraph are infinite for every $u\\geq 2$. Together\nwith a recent result of Braunfeld, Chodounsk\\'y, de Rancourt, Hubi\\v{c}ka,\nKawach, and Kone\\v{c}n\\'y this finishes full characterisation of unrestricted\nrelational structures with finite big Ramsey degrees.", "published": "2025-05-28 16:38:40", "link": "http://arxiv.org/abs/2505.22561v1", "categories": ["math.CO", "cs.DM", "math.LO", "05C55, 03E02, 05D10, 05C15", "G.2.1"], "primary_category": "math.CO"}
{"title": "Finding $d$-Cuts in Probe $H$-Free Graphs", "abstract": "For an integer $d\\geq 1$, the $d$-Cut problem is that of deciding whether a\ngraph has an edge cut in which each vertex is adjacent to at most $d$ vertices\non the opposite side of the cut. The $1$-Cut problem is the well-known Matching\nCut problem. The $d$-Cut problem has been extensively studied for $H$-free\ngraphs. We extend these results to the probe graph model, where we do not know\nall the edges of the input graph. For a graph $H$, a partitioned probe $H$-free\ngraph $(G,P,N)$ consists of a graph $G=(V,E)$, together with a set $P\\subseteq\nV$ of probes and an independent set $N=V\\setminus P$ of non-probes such that we\ncan change $G$ into an $H$-free graph by adding zero or more edges between\nvertices in $N$. For every graph $H$ and every integer $d\\geq 1$, we completely\ndetermine the complexity of $d$-Cut on partitioned probe $H$-free graphs.", "published": "2025-05-28 13:32:59", "link": "http://arxiv.org/abs/2505.22351v1", "categories": ["cs.DS", "cs.CC", "cs.DM", "math.CO"], "primary_category": "cs.DS"}
{"title": "DocReRank: Single-Page Hard Negative Query Generation for Training Multi-Modal RAG Rerankers", "abstract": "Rerankers play a critical role in multimodal Retrieval-Augmented Generation\n(RAG) by refining ranking of an initial set of retrieved documents. Rerankers\nare typically trained using hard negative mining, whose goal is to select pages\nfor each query which rank high, but are actually irrelevant. However, this\nselection process is typically passive and restricted to what the retriever can\nfind in the available corpus, leading to several inherent limitations. These\ninclude: limited diversity, negative examples which are often not hard enough,\nlow controllability, and frequent false negatives which harm training. Our\npaper proposes an alternative approach: Single-Page Hard Negative Query\nGeneration, which goes the other way around. Instead of retrieving negative\npages per query, we generate hard negative queries per page. Using an automated\nLLM-VLM pipeline, and given a page and its positive query, we create hard\nnegatives by rephrasing the query to be as similar as possible in form and\ncontext, yet not answerable from the page. This paradigm enables fine-grained\ncontrol over the generated queries, resulting in diverse, hard, and targeted\nnegatives. It also supports efficient false negative verification. Our\nexperiments show that rerankers trained with data generated using our approach\noutperform existing models and significantly improve retrieval performance.", "published": "2025-05-28 16:56:41", "link": "http://arxiv.org/abs/2505.22584v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Domain specific ontologies from Linked Open Data (LOD)", "abstract": "Logical and probabilistic reasoning tasks that require a deeper knowledge of\nsemantics are increasingly relying on general purpose ontologies such as\nWikidata and DBpedia. However, tasks such as entity disambiguation and linking\nmay benefit from domain specific knowledge graphs, which make it more efficient\nto consume the knowledge and easier to extend with proprietary content. We\ndiscuss our experience bootstrapping one such ontology for IT with a\ndomain-agnostic pipeline, and extending it using domain-specific glossaries.", "published": "2025-05-28 16:33:01", "link": "http://arxiv.org/abs/2505.22550v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Logical Consistency is Vital: Neural-Symbolic Information Retrieval for Negative-Constraint Queries", "abstract": "Information retrieval plays a crucial role in resource localization. Current\ndense retrievers retrieve the relevant documents within a corpus via embedding\nsimilarities, which compute similarities between dense vectors mainly depending\non word co-occurrence between queries and documents, but overlook the real\nquery intents.\n  Thus, they often retrieve numerous irrelevant documents. Particularly in the\nscenarios of complex queries such as \\emph{negative-constraint queries}, their\nretrieval performance could be catastrophic. To address the issue, we propose a\nneuro-symbolic information retrieval method, namely \\textbf{NS-IR}, that\nleverages first-order logic (FOL) to optimize the embeddings of naive natural\nlanguage by considering the \\emph{logical consistency} between queries and\ndocuments. Specifically, we introduce two novel techniques, \\emph{logic\nalignment} and \\emph{connective constraint}, to rerank candidate documents,\nthereby enhancing retrieval relevance.\n  Furthermore, we construct a new dataset \\textbf{NegConstraint} including\nnegative-constraint queries to evaluate our NS-IR's performance on such complex\nIR scenarios.\n  Our extensive experiments demonstrate that NS-IR not only achieves superior\nzero-shot retrieval performance on web search and low-resource retrieval tasks,\nbut also performs better on negative-constraint queries. Our scource code and\ndataset are available at https://github.com/xgl-git/NS-IR-main.", "published": "2025-05-28 12:37:09", "link": "http://arxiv.org/abs/2505.22299v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "UDuo: Universal Dual Optimization Framework for Online Matching", "abstract": "Online resource allocation under budget constraints critically depends on\nproper modeling of user arrival dynamics. Classical approaches employ\nstochastic user arrival models to derive near-optimal solutions through\nfractional matching formulations of exposed users for downstream allocation\ntasks. However, this is no longer a reasonable assumption when the environment\nchanges dynamically. In this work, We propose the Universal Dual optimization\nframework UDuo, a novel paradigm that fundamentally rethinks online allocation\nthrough three key innovations: (i) a temporal user arrival representation\nvector that explicitly captures distribution shifts in user arrival patterns\nand resource consumption dynamics, (ii) a resource pacing learner with adaptive\nallocation policies that generalize to heterogeneous constraint scenarios, and\n(iii) an online time-series forecasting approach for future user arrival\ndistributions that achieves asymptotically optimal solutions with constraint\nfeasibility guarantees in dynamic environments. Experimental results show that\nUDuo achieves higher efficiency and faster convergence than the traditional\nstochastic arrival model in real-world pricing while maintaining rigorous\ntheoretical validity for general online allocation problems.", "published": "2025-05-28 11:25:50", "link": "http://arxiv.org/abs/2505.22243v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Yambda-5B -- A Large-Scale Multi-modal Dataset for Ranking And Retrieval", "abstract": "We present Yambda-5B, a large-scale open dataset sourced from the\nYandex.Music streaming platform. Yambda-5B contains 4.79 billion user-item\ninteractions from 1 million users across 9.39 million tracks. The dataset\nincludes two primary types of interactions: implicit feedback (listening\nevents) and explicit feedback (likes, dislikes, unlikes and undislikes). In\naddition, we provide audio embeddings for most tracks, generated by a\nconvolutional neural network trained on audio spectrograms. A key\ndistinguishing feature of Yambda-5B is the inclusion of the is_organic flag,\nwhich separates organic user actions from recommendation-driven events. This\ndistinction is critical for developing and evaluating machine learning\nalgorithms, as Yandex.Music relies on recommender systems to personalize track\nselection for users. To support rigorous benchmarking, we introduce an\nevaluation protocol based on a Global Temporal Split, allowing recommendation\nalgorithms to be assessed in conditions that closely mirror real-world use. We\nreport benchmark results for standard baselines (ItemKNN, iALS) and advanced\nmodels (SANSA, SASRec) using a variety of evaluation metrics. By releasing\nYambda-5B to the community, we aim to provide a readily accessible,\nindustrial-scale resource to advance research, foster innovation, and promote\nreproducible results in recommender systems.", "published": "2025-05-28 11:12:57", "link": "http://arxiv.org/abs/2505.22238v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Personalized Tree based progressive regression model for watch-time prediction in short video recommendation", "abstract": "In online video platforms, accurate watch time prediction has become a\nfundamental and challenging problem in video recommendation. Previous research\nhas revealed that the accuracy of watch time prediction highly depends on both\nthe transformation of watch-time labels and the decomposition of the estimation\nprocess. TPM (Tree based Progressive Regression Model) achieves\nState-of-the-Art performance with a carefully designed and effective\ndecomposition paradigm. TPM discretizes the watch time into several ordinal\nintervals and organizes them into a binary decision tree, where each node\ncorresponds to a specific interval. At each non-leaf node, a binary classifier\nis used to determine the specific interval in which the watch time variable\nmost likely falls, based on the prediction outcome at its parent node.\n  The tree structure serves as the core of TPM, as it defines the decomposition\nof watch time estimation and determines how the ordinal intervals are\ndiscretized. However, in TPM, the tree is predefined as a full binary tree,\nwhich may be sub-optimal for the following reasons. First, a full binary tree\nimplies an equal partitioning of the watch time space, which may struggle to\ncapture the complexity of real-world watch time distributions. Second, instead\nof relying on a globally fixed tree structure, we advocate for a personalized,\ndata-driven tree that can be learned in an end-to-end manner. Therefore, we\npropose PTPM to enable a highly personalized decomposition of watch estimation\nwith better efficacy and efficiency. Moreover, we reveal that TPM is affected\nby selection bias due to conditional modeling and devise a simple approach to\naddress it. We conduct extensive experiments on both offline datasets and\nonline environments. PTPM has been fully deployed in core traffic scenarios and\nserves more than 400 million users per day.", "published": "2025-05-28 09:18:48", "link": "http://arxiv.org/abs/2505.22153v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "ConsRec: Denoising Sequential Recommendation through User-Consistent Preference Modeling", "abstract": "User-item interaction histories are pivotal for sequential recommendation\nsystems but often include noise, such as unintended clicks or actions that fail\nto reflect genuine user preferences. To address this issue, we propose the\nUser-Consistent Preference-based Sequential Recommendation System (ConsRec),\ndesigned to capture stable user preferences and filter noisy items from\ninteraction histories. Specifically, ConsRec constructs a user-interacted item\ngraph, learns item similarities from their text representations, and then\nextracts the maximum connected subgraph from the user-interacted item graph for\ndenoising items. Experimental results on the Yelp and Amazon Product datasets\nillustrate that ConsRec achieves a 13% improvement over baseline recommendation\nmodels, showing its effectiveness in denoising user-interacted items. Further\nanalysis reveals that the denoised interaction histories form semantically\ntighter clusters of user-preferred items, leading to higher relevance scores\nfor ground-truth targets and more accurate recommendations. All codes are\navailable at https://github.com/NEUIR/ConsRec.", "published": "2025-05-28 08:55:13", "link": "http://arxiv.org/abs/2505.22130v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Shapley Value-driven Data Pruning for Recommender Systems", "abstract": "Recommender systems often suffer from noisy interactions like accidental\nclicks or popularity bias. Existing denoising methods typically identify users'\nintent in their interactions, and filter out noisy interactions that deviate\nfrom the assumed intent. However, they ignore that interactions deemed noisy\ncould still aid model training, while some ``clean'' interactions offer little\nlearning value. To bridge this gap, we propose Shapley Value-driven Valuation\n(SVV), a framework that evaluates interactions based on their objective impact\non model training rather than subjective intent assumptions. In SVV, a\nreal-time Shapley value estimation method is devised to quantify each\ninteraction's value based on its contribution to reducing training loss.\nAfterward, SVV highlights the interactions with high values while downplaying\nlow ones to achieve effective data pruning for recommender systems. In\naddition, we develop a simulated noise protocol to examine the performance of\nvarious denoising approaches systematically. Experiments on four real-world\ndatasets show that SVV outperforms existing denoising methods in both accuracy\nand robustness. Further analysis also demonstrates that our SVV can preserve\ntraining-critical interactions and offer interpretable noise assessment. This\nwork shifts denoising from heuristic filtering to principled, model-driven\ninteraction valuation.", "published": "2025-05-28 07:27:59", "link": "http://arxiv.org/abs/2505.22057v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Extracting Research Instruments from Educational Literature Using LLMs", "abstract": "Large Language Models (LLMs) are transforming information extraction from\nacademic literature, offering new possibilities for knowledge management. This\nstudy presents an LLM-based system designed to extract detailed information\nabout research instruments used in the education field, including their names,\ntypes, target respondents, measured constructs, and outcomes. Using multi-step\nprompting and a domain-specific data schema, it generates structured outputs\noptimized for educational research. Our evaluation shows that this system\nsignificantly outperforms other approaches, particularly in identifying\ninstrument names and detailed information. This demonstrates the potential of\nLLM-powered information extraction in educational contexts, offering a\nsystematic way to organize research instrument information. The ability to\naggregate such information at scale enhances accessibility for researchers and\neducation leaders, facilitating informed decision-making in educational\nresearch and policy.", "published": "2025-05-28 01:00:32", "link": "http://arxiv.org/abs/2505.21855v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Xinyu AI Search: Enhanced Relevance and Comprehensive Results with Rich Answer Presentations", "abstract": "Traditional search engines struggle to synthesize fragmented information for\ncomplex queries, while generative AI search engines face challenges in\nrelevance, comprehensiveness, and presentation. To address these limitations,\nwe introduce Xinyu AI Search, a novel system that incorporates a\nquery-decomposition graph to dynamically break down complex queries into\nsub-queries, enabling stepwise retrieval and generation. Our retrieval pipeline\nenhances diversity through multi-source aggregation and query expansion, while\nfiltering and re-ranking strategies optimize passage relevance. Additionally,\nXinyu AI Search introduces a novel approach for fine-grained, precise built-in\ncitation and innovates in result presentation by integrating timeline\nvisualization and textual-visual choreography. Evaluated on recent real-world\nqueries, Xinyu AI Search outperforms eight existing technologies in human\nassessments, excelling in relevance, comprehensiveness, and insightfulness.\nAblation studies validate the necessity of its key sub-modules. Our work\npresents the first comprehensive framework for generative AI search engines,\nbridging retrieval, generation, and user-centric presentation.", "published": "2025-05-28 00:30:22", "link": "http://arxiv.org/abs/2505.21849v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "The Ingleton inequality holds for metacyclic groups and fails for supersoluble groups", "abstract": "The Ingleton inequality first appeared in matroid theory, where Ingleton\nproved in 1971 that every rank function coming from a representable matroid on\nfour subsets satisfies a particular inequality. Because this inequality is not\nimplied by submodularity, Shannon-type axioms alone, it and various analogues\nplay a central role in separately linear and non-linear phenomena in a variety\nof areas of mathematics. The Ingleton inequality for finite groups concerns the\nvarious intersections of four subgroups. It holds for many quadruples of\nsubgroups of finite groups, but not all, the smallest example being four\nsubgroups of $S_5$, of order 120. Open questions are whether the Inlgeton\ninequality always holds for metacycle and nilpotent groups. (There is a proof\nin the literature due to Oggier and Stancu, but there is an already known issue\nwith their proof, which we address in this article.)\n  In this paper we prove that the Ingleton inequality always holds for\nmetacycle groups, but that it fails for supersoluble groups, a class of groups\nonly a little larger than nilpotent groups. Although we do not resolve the\nnilpotent case here we do make some reductions, and also prove that there are\nno nilpotent violators of the Ingleton inequality of order less than 1024. We\nend with a list of Ingleton inequality violating groups of order at most 1023.\n  The article comes with a Magma package that allows reproduction of all\nresults in the paper and for the reader to check the Ingleton inequality for\nany given finite group.", "published": "2025-05-28 16:42:48", "link": "http://arxiv.org/abs/2505.22565v1", "categories": ["math.GR", "cs.IT", "math.IT"], "primary_category": "math.GR"}
{"title": "Wireless Communication for Low-Altitude Economy with UAV Swarm Enabled Two-Level Movable Antenna System", "abstract": "Unmanned aerial vehicle (UAV) is regarded as a key enabling platform for\nlow-altitude economy, due to its advantages such as 3D maneuverability,\nflexible deployment, and LoS air-to-air/ground communication links. In\nparticular, the intrinsic high mobility renders UAV especially suitable for\noperating as a movable antenna (MA) from the sky. In this paper, by exploiting\nthe flexible mobility of UAV swarm and antenna position adjustment of MA, we\npropose a novel UAV swarm enabled two-level MA system, where UAVs not only\nindividually deploy a local MA array, but also form a larger-scale MA system\nwith their individual MA arrays via swarm coordination. We formulate a general\noptimization problem to maximize the minimum achievable rate over all ground\nUEs, by jointly optimizing the 3D UAV swarm placement positions, their\nindividual MAs' positions, and receive beamforming for different UEs. We first\nconsider the special case where each UAV has only one antenna, under different\nscenarios of one single UE, two UEs, and arbitrary number of UEs. In\nparticular, for the two-UE case, we derive the optimal UAV swarm placement\npositions in closed-form that achieves IUI-free communication, where the UAV\nswarm forms a uniform sparse array (USA) satisfying collision avoidance\nconstraint. While for the general case with arbitrary number of UEs, we propose\nan efficient alternating optimization algorithm to solve the formulated\nnon-convex optimization problem. Then, we extend the results to the case where\neach UAV is equipped with multiple antennas. Numerical results verify that the\nproposed low-altitude UAV swarm enabled MA system significantly outperforms\nvarious benchmark schemes, thanks to the exploitation of two-level mobility to\ncreate more favorable channel conditions for multi-UE communications.", "published": "2025-05-28 12:22:09", "link": "http://arxiv.org/abs/2505.22286v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Attention-Enhanced Prompt Decision Transformers for UAV-Assisted Communications with AoI", "abstract": "Decision Transformer (DT) has recently demonstrated strong generalizability\nin dynamic resource allocation within unmanned aerial vehicle (UAV) networks,\ncompared to conventional deep reinforcement learning (DRL). However, its\nperformance is hindered due to zero-padding for varying state dimensions,\ninability to manage long-term energy constraint, and challenges in acquiring\nexpert samples for few-shot fine-tuning in new scenarios. To overcome these\nlimitations, we propose an attention-enhanced prompt Decision Transformer\n(APDT) framework to optimize trajectory planning and user scheduling, aiming to\nminimize the average age of information (AoI) under long-term energy constraint\nin UAV-assisted Internet of Things (IoT) networks. Specifically, we enhance the\nconvenional DT framework by incorporating an attention mechanism to accommodate\nvarying numbers of terrestrial users, introducing a prompt mechanism based on\nshort trajectory demonstrations for rapid adaptation to new scenarios, and\ndesigning a token-assisted method to address the UAV's long-term energy\nconstraint. The APDT framework is first pre-trained on offline datasets and\nthen efficiently generalized to new scenarios. Simulations demonstrate that\nAPDT achieves twice faster in terms of convergence rate and reduces average AoI\nby $8\\%$ compared to conventional DT.", "published": "2025-05-28 09:41:10", "link": "http://arxiv.org/abs/2505.22170v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Interpolation of Quantum Polar Codes and Quantum Reed-Muller Codes", "abstract": "Good quantum error-correcting codes that fulfill practical considerations,\nsuch as simple encoding circuits and efficient decoders, are essential for\nfunctional quantum information processing systems. Quantum polar codes satisfy\nsome of these requirements but lack certain critical features, thereby\nhindering their widespread use. Existing constructions either require\nentanglement assistance to produce valid quantum codes, suffer from poor\nfinite-size performance, or fail to tailor polar codes to the underlying\nchannel properties. Meanwhile, quantum Reed-Muller (RM) codes demonstrate\nstrong performance, though no known efficient decoding algorithm exists for\nthem. In this work, we propose strategies to interpolate between quantum polar\ncodes and quantum RM codes, thus addressing the challenges of designing valid\nquantum polar codes without entanglement assistance and improving finite-size\ncode performance.", "published": "2025-05-28 09:04:02", "link": "http://arxiv.org/abs/2505.22142v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "The Tri-Hybrid MIMO Architecture", "abstract": "We present an evolution of multiple-input multiple-output (MIMO) wireless\ncommunications known as the tri-hybrid MIMO architecture. In this framework,\nthe traditional operations of linear precoding at the transmitter are\ndistributed across digital beamforming, analog beamforming, and reconfigurable\nantennas. Compared with the hybrid MIMO architecture, which combines digital\nand analog beamforming, the tri-hybrid approach introduces a third layer of\nelectromagnetic beamforming through antenna reconfigurability. This added layer\noffers a pathway to scale MIMO spatial dimensions, important for 6G systems\noperating in centimeter-wave bands, where the tension between larger bandwidths\nand infrastructure reuse necessitates ultra-large antenna arrays. We introduce\nthe key features of the tri-hybrid architecture by (i)~reviewing the benefits\nand challenges of communicating with reconfigurable antennas, (ii)~examining\ntradeoffs between spectral and energy efficiency enabled by reconfigurability,\nand (iii)~exploring configuration challenges across the three layers. Overall,\nthe tri-hybrid MIMO architecture offers a new approach for integrating emerging\nantenna technologies in the MIMO precoding framework.", "published": "2025-05-28 04:50:03", "link": "http://arxiv.org/abs/2505.21971v1", "categories": ["cs.IT", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "When Feedback Empowers the Uplink: Integrating Adaptive Coding with Wireless Power Transfer", "abstract": "Energy consumption and device lifetime are critical concerns for\nbattery-constrained IoT devices. This paper introduces the Feedback-Aided\nCoding and Energy Transfer (FACET) framework, which synergistically combines\nadaptive feedback channel coding with wireless power transfer. FACET leverages\nthe saturation effect of feedback coding, where increasing downlink power\nyields diminishing returns, to design a dual-purpose feedback mechanism that\nsimultaneously guides uplink coding and replenishes device energy. We\ncharacterize the inherent tradeoff between feedback precision and harvested\npower, and formulate a fairness-constrained min-max optimization problem to\nminimize worst-case net energy consumption. An efficient algorithm based on\nalternating optimization and Lagrangian duality is developed, with each\nsubproblem admitting a closed-form solution. Simulations show that FACET nearly\ntriples device lifetime compared to conventional feedback coding architectures,\nand remains robust across a wide range of power regimes. These results suggest\nthat FACET not only improves communication efficiency but also redefines the\nrole of feedback in energy-constrained IoT systems.", "published": "2025-05-28 04:04:24", "link": "http://arxiv.org/abs/2505.21951v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Provable Approach for End-to-End Safe Reinforcement Learning", "abstract": "A longstanding goal in safe reinforcement learning (RL) is a method to ensure\nthe safety of a policy throughout the entire process, from learning to\noperation. However, existing safe RL paradigms inherently struggle to achieve\nthis objective. We propose a method, called Provably Lifetime Safe RL (PLS),\nthat integrates offline safe RL with safe policy deployment to address this\nchallenge. Our proposed method learns a policy offline using return-conditioned\nsupervised learning and then deploys the resulting policy while cautiously\noptimizing a limited set of parameters, known as target returns, using Gaussian\nprocesses (GPs). Theoretically, we justify the use of GPs by analyzing the\nmathematical relationship between target and actual returns. We then prove that\nPLS finds near-optimal target returns while guaranteeing safety with high\nprobability. Empirically, we demonstrate that PLS outperforms baselines both in\nsafety and reward performance, thereby achieving the longstanding goal to\nobtain high rewards while ensuring the safety of a policy throughout the\nlifetime from learning to operation.", "published": "2025-05-28 00:48:20", "link": "http://arxiv.org/abs/2505.21852v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.RO", "math.IT"], "primary_category": "cs.LG"}
{"title": "On Learning Verifiers for Chain-of-Thought Reasoning", "abstract": "Chain-of-Thought reasoning has emerged as a powerful approach for solving\ncomplex mathematical and logical problems. However, it can often veer off track\nthrough incorrect or unsubstantiated inferences. Formal mathematical reasoning,\nwhich can be checked with a formal verifier, is one approach to addressing this\nissue. However, currently LLMs are simply not good enough to solve complex\nproblems in a formal way, and even just formalizing an informal problem\nstatement can be challenging. Motivated by this fact, in this work we consider\nthe problem of learning reliable verifiers for natural language\nChain-of-Thought reasoning. That is, given a problem statement and step-by-step\nsolution in natural language, the aim of the verifier is to output [Yes] if the\nreasoning steps in the solution are all valid, and [No] otherwise. In this work\nwe give a formal PAC-learning framework for studying this problem. We propose\nand analyze several natural verification goals, at different levels of\nstrength, in this framework. We provide sample complexity upper-bounds for\nlearning verifiers satisfying these goals, as well as lower-bound and\nimpossibility results for learning other natural verification objectives\nwithout additional assumptions.", "published": "2025-05-28 17:57:29", "link": "http://arxiv.org/abs/2505.22650v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Spectral Survival Analysis", "abstract": "Survival analysis is widely deployed in a diverse set of fields, including\nhealthcare, business, ecology, etc. The Cox Proportional Hazard (CoxPH) model\nis a semi-parametric model often encountered in the literature. Despite its\npopularity, wide deployment, and numerous variants, scaling CoxPH to large\ndatasets and deep architectures poses a challenge, especially in the\nhigh-dimensional regime. We identify a fundamental connection between rank\nregression and the CoxPH model: this allows us to adapt and extend the\nso-called spectral method for rank regression to survival analysis. Our\napproach is versatile, naturally generalizing to several CoxPH variants,\nincluding deep models. We empirically verify our method's scalability on\nmultiple real-world high-dimensional datasets; our method outperforms legacy\nmethods w.r.t. predictive performance and efficiency.", "published": "2025-05-28 17:54:39", "link": "http://arxiv.org/abs/2505.22641v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SimProcess: High Fidelity Simulation of Noisy ICS Physical Processes", "abstract": "Industrial Control Systems (ICS) manage critical infrastructures like power\ngrids and water treatment plants. Cyberattacks on ICSs can disrupt operations,\ncausing severe economic, environmental, and safety issues. For example,\nundetected pollution in a water plant can put the lives of thousands at stake.\nICS researchers have increasingly turned to honeypots -- decoy systems designed\nto attract attackers, study their behaviors, and eventually improve defensive\nmechanisms. However, existing ICS honeypots struggle to replicate the ICS\nphysical process, making them susceptible to detection. Accurately simulating\nthe noise in ICS physical processes is challenging because different factors\nproduce it, including sensor imperfections and external interferences.\n  In this paper, we propose SimProcess, a novel framework to rank the fidelity\nof ICS simulations by evaluating how closely they resemble real-world and noisy\nphysical processes. It measures the simulation distance from a target system by\nestimating the noise distribution with machine learning models like Random\nForest. Unlike existing solutions that require detailed mathematical models or\nare limited to simple systems, SimProcess operates with only a timeseries of\nmeasurements from the real system, making it applicable to a broader range of\ncomplex dynamic systems. We demonstrate the framework's effectiveness through a\ncase study using real-world power grid data from the EPIC testbed. We compare\nthe performance of various simulation methods, including static and generative\nnoise techniques. Our model correctly classifies real samples with a recall of\nup to 1.0. It also identifies Gaussian and Gaussian Mixture as the best\ndistribution to simulate our power systems, together with a generative solution\nprovided by an autoencoder, thereby helping developers to improve honeypot\nfidelity. Additionally, we make our code publicly available.", "published": "2025-05-28 17:54:23", "link": "http://arxiv.org/abs/2505.22638v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Understanding (Un)Reliability of Steering Vectors in Language Models", "abstract": "Steering vectors are a lightweight method to control language model behavior\nby adding a learned bias to the activations at inference time. Although\nsteering demonstrates promising performance, recent work shows that it can be\nunreliable or even counterproductive in some cases. This paper studies the\ninfluence of prompt types and the geometry of activation differences on\nsteering reliability. First, we find that all seven prompt types used in our\nexperiments produce a net positive steering effect, but exhibit high variance\nacross samples, and often give an effect opposite of the desired one. No prompt\ntype clearly outperforms the others, and yet the steering vectors resulting\nfrom the different prompt types often differ directionally (as measured by\ncosine similarity). Second, we show that higher cosine similarity between\ntraining set activation differences predicts more effective steering. Finally,\nwe observe that datasets where positive and negative activations are better\nseparated are more steerable. Our results suggest that vector steering is\nunreliable when the target behavior is not represented by a coherent direction.", "published": "2025-05-28 17:53:31", "link": "http://arxiv.org/abs/2505.22637v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Principled Out-of-Distribution Generalization via Simplicity", "abstract": "Modern foundation models exhibit remarkable out-of-distribution (OOD)\ngeneralization, solving tasks far beyond the support of their training data.\nHowever, the theoretical principles underpinning this phenomenon remain\nelusive. This paper investigates this problem by examining the compositional\ngeneralization abilities of diffusion models in image generation. Our analysis\nreveals that while neural network architectures are expressive enough to\nrepresent a wide range of models -- including many with undesirable behavior on\nOOD inputs -- the true, generalizable model that aligns with human expectations\ntypically corresponds to the simplest among those consistent with the training\ndata.\n  Motivated by this observation, we develop a theoretical framework for OOD\ngeneralization via simplicity, quantified using a predefined simplicity metric.\nWe analyze two key regimes: (1) the constant-gap setting, where the true model\nis strictly simpler than all spurious alternatives by a fixed gap, and (2) the\nvanishing-gap setting, where the fixed gap is replaced by a smoothness\ncondition ensuring that models close in simplicity to the true model yield\nsimilar predictions. For both regimes, we study the regularized maximum\nlikelihood estimator and establish the first sharp sample complexity guarantees\nfor learning the true, generalizable, simple model.", "published": "2025-05-28 17:44:10", "link": "http://arxiv.org/abs/2505.22622v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Benignity of loss landscape with weight decay requires both large overparametrization and initialization", "abstract": "The optimization of neural networks under weight decay remains poorly\nunderstood from a theoretical standpoint. While weight decay is standard\npractice in modern training procedures, most theoretical analyses focus on\nunregularized settings. In this work, we investigate the loss landscape of the\n$\\ell_2$-regularized training loss for two-layer ReLU networks. We show that\nthe landscape becomes benign -- i.e., free of spurious local minima -- under\nlarge overparametrization, specifically when the network width $m$ satisfies $m\n\\gtrsim \\min(n^d, 2^n)$, where $n$ is the number of data points and $d$ the\ninput dimension. More precisely in this regime, almost all constant activation\nregions contain a global minimum and no spurious local minima. We further show\nthat this level of overparametrization is not only sufficient but also\nnecessary via the example of orthogonal data. Finally, we demonstrate that such\nloss landscape results primarily hold relevance in the large initialization\nregime. In contrast, for small initializations -- corresponding to the feature\nlearning regime -- optimization can still converge to spurious local minima,\ndespite the global benignity of the landscape.", "published": "2025-05-28 16:53:48", "link": "http://arxiv.org/abs/2505.22578v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FNOPE: Simulation-based inference on function spaces with Fourier Neural Operators", "abstract": "Simulation-based inference (SBI) is an established approach for performing\nBayesian inference on scientific simulators. SBI so far works best on\nlow-dimensional parametric models. However, it is difficult to infer\nfunction-valued parameters, which frequently occur in disciplines that model\nspatiotemporal processes such as the climate and earth sciences. Here, we\nintroduce an approach for efficient posterior estimation, using a Fourier\nNeural Operator (FNO) architecture with a flow matching objective. We show that\nour approach, FNOPE, can perform inference of function-valued parameters at a\nfraction of the simulation budget of state of the art methods. In addition,\nFNOPE supports posterior evaluation at arbitrary discretizations of the domain,\nas well as simultaneous estimation of vector-valued parameters. We demonstrate\nthe effectiveness of our approach on several benchmark tasks and a challenging\nspatial inference task from glaciology. FNOPE extends the applicability of SBI\nmethods to new scientific domains by enabling the inference of function-valued\nparameters.", "published": "2025-05-28 16:46:56", "link": "http://arxiv.org/abs/2505.22573v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Geometric Hyena Networks for Large-scale Equivariant Learning", "abstract": "Processing global geometric context while preserving equivariance is crucial\nwhen modeling biological, chemical, and physical systems. Yet, this is\nchallenging due to the computational demands of equivariance and global context\nat scale. Standard methods such as equivariant self-attention suffer from\nquadratic complexity, while local methods such as distance-based message\npassing sacrifice global information. Inspired by the recent success of\nstate-space and long-convolutional models, we introduce Geometric Hyena, the\nfirst equivariant long-convolutional model for geometric systems. Geometric\nHyena captures global geometric context at sub-quadratic complexity while\nmaintaining equivariance to rotations and translations. Evaluated on all-atom\nproperty prediction of large RNA molecules and full protein molecular dynamics,\nGeometric Hyena outperforms existing equivariant models while requiring\nsignificantly less memory and compute that equivariant self-attention. Notably,\nour model processes the geometric context of 30k tokens 20x faster than the\nequivariant transformer and allows 72x longer context within the same budget.", "published": "2025-05-28 16:38:35", "link": "http://arxiv.org/abs/2505.22560v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Can Copulas Be Used for Feature Selection? A Machine Learning Study on Diabetes Risk Prediction", "abstract": "Accurate diabetes risk prediction relies on identifying key features from\ncomplex health datasets, but conventional methods like mutual information (MI)\nfilters and genetic algorithms (GAs) often overlook extreme dependencies\ncritical for high-risk subpopulations. In this study we introduce a\nfeature-selection framework using the upper-tail dependence coefficient\n({\\lambda}U) of the novel A2 copula, which quantifies how often extreme higher\nvalues of a predictor co-occur with diabetes diagnoses (target variable).\nApplied to the CDC Diabetes Health Indicators dataset (n=253,680), our method\nprioritizes five predictors (self-reported general health, high blood pressure,\nbody mass index, mobility limitations, and high cholesterol levels) based on\nupper tail dependencies. These features match or outperform MI and GA selected\nsubsets across four classifiers (Random Forest, XGBoost, Logistic Regression,\nGradient Boosting), achieving accuracy up to 86.5% (XGBoost) and AUC up to\n0.806 (Gradient Boosting), rivaling the full 21-feature model. Permutation\nimportance confirms clinical relevance, with BMI and general health driving\naccuracy. To our knowledge, this is the first work to apply a copula's\nupper-tail dependence for supervised feature selection, bridging extreme-value\ntheory and machine learning to deliver a practical toolkit for diabetes\nprevention.", "published": "2025-05-28 16:34:58", "link": "http://arxiv.org/abs/2505.22554v1", "categories": ["stat.ML", "cs.LG", "62H05, 62H12, 62P10, 68T07"], "primary_category": "stat.ML"}
{"title": "DES-LOC: Desynced Low Communication Adaptive Optimizers for Training Foundation Models", "abstract": "Scaling foundation model training with Distributed Data Parallel (DDP)\nmethods is bandwidth-limited. Existing infrequent communication methods like\nLocal SGD were designed to synchronize only model parameters and cannot be\ntrivially applied to adaptive optimizers due to additional optimizer states.\nCurrent approaches extending Local SGD either lack convergence guarantees or\nrequire synchronizing all optimizer states, tripling communication costs. We\npropose Desynced Low Communication Adaptive Optimizers (DES-LOC), a family of\noptimizers assigning independent synchronization periods to parameters and\nmomenta, enabling lower communication costs while preserving convergence.\nThrough extensive experiments on language models of up to 1.7B, we show that\nDES-LOC can communicate 170x less than DDP and 2x less than the previous\nstate-of-the-art Local ADAM. Furthermore, unlike previous heuristic approaches,\nDES-LOC is suited for practical training scenarios prone to system failures.\nDES-LOC offers a scalable, bandwidth-efficient, and fault-tolerant solution for\nfoundation model training.", "published": "2025-05-28 16:32:33", "link": "http://arxiv.org/abs/2505.22549v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Human-Centric Approach to Explainable AI for Personalized Education", "abstract": "Deep neural networks form the backbone of artificial intelligence research,\nwith potential to transform the human experience in areas ranging from\nautonomous driving to personal assistants, healthcare to education. However,\ntheir integration into the daily routines of real-world classrooms remains\nlimited. It is not yet common for a teacher to assign students individualized\nhomework targeting their specific weaknesses, provide students with instant\nfeedback, or simulate student responses to a new exam question. While these\nmodels excel in predictive performance, this lack of adoption can be attributed\nto a significant weakness: the lack of explainability of model decisions,\nleading to a lack of trust from students, parents, and teachers. This thesis\naims to bring human needs to the forefront of eXplainable AI (XAI) research,\ngrounded in the concrete use case of personalized learning and teaching. We\nframe the contributions along two verticals: technical advances in XAI and\ntheir aligned human studies. We investigate explainability in AI for education,\nrevealing systematic disagreements between post-hoc explainers and identifying\na need for inherently interpretable model architectures. We propose four novel\ntechnical contributions in interpretability with a multimodal modular\narchitecture (MultiModN), an interpretable mixture-of-experts model\n(InterpretCC), adversarial training for explainer stability, and a\ntheory-driven LLM-XAI framework to present explanations to students\n(iLLuMinaTE), which we evaluate in diverse settings with professors, teachers,\nlearning scientists, and university students. By combining empirical\nevaluations of existing explainers with novel architectural designs and human\nstudies, our work lays a foundation for human-centric AI systems that balance\nstate-of-the-art performance with built-in transparency and trust.", "published": "2025-05-28 16:23:48", "link": "http://arxiv.org/abs/2505.22541v1", "categories": ["cs.LG", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to Prediction Tasks", "abstract": "We address the problem of uncertainty quantification and propose measures of\ntotal, aleatoric, and epistemic uncertainty based on a known decomposition of\n(strictly) proper scoring rules, a specific type of loss function, into a\ndivergence and an entropy component. This leads to a flexible framework for\nuncertainty quantification that can be instantiated with different losses\n(scoring rules), which makes it possible to tailor uncertainty quantification\nto the use case at hand. We show that this flexibility is indeed advantageous.\nIn particular, we analyze the task of selective prediction and show that the\nscoring rule should ideally match the task loss. In addition, we perform\nexperiments on two other common tasks. For out-of-distribution detection, our\nresults confirm that a widely used measure of epistemic uncertainty, mutual\ninformation, performs best. Moreover, in the setting of active learning, our\nmeasure of epistemic uncertainty based on the zero-one-loss consistently\noutperforms other uncertainty measures.", "published": "2025-05-28 16:22:53", "link": "http://arxiv.org/abs/2505.22538v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Symplectic Generative Networks (SGNs): A Hamiltonian Framework for Invertible Deep Generative Modeling", "abstract": "We introduce the Symplectic Generative Network (SGN), a deep generative model\nthat leverages Hamiltonian mechanics to construct an invertible,\nvolume-preserving mapping between a latent space and the data space. By\nendowing the latent space with a symplectic structure and modeling data\ngeneration as the time evolution of a Hamiltonian system, SGN achieves exact\nlikelihood evaluation without incurring the computational overhead of Jacobian\ndeterminant calculations. In this work, we provide a rigorous mathematical\nfoundation for SGNs through a comprehensive theoretical framework that\nincludes: (i) complete proofs of invertibility and volume preservation, (ii) a\nformal complexity analysis with theoretical comparisons to Variational\nAutoencoders and Normalizing Flows, (iii) strengthened universal approximation\nresults with quantitative error bounds, (iv) an information-theoretic analysis\nbased on the geometry of statistical manifolds, and (v) an extensive stability\nanalysis with adaptive integration guarantees. These contributions highlight\nthe fundamental advantages of SGNs and establish a solid foundation for future\nempirical investigations and applications to complex, high-dimensional data.", "published": "2025-05-28 16:13:36", "link": "http://arxiv.org/abs/2505.22527v1", "categories": ["stat.ML", "cs.LG", "68T07, 37J39, 65P10, 62B10, 53D22, 94A17"], "primary_category": "stat.ML"}
{"title": "Test-Time Alignment of Discrete Diffusion Models with Sequential Monte Carlo", "abstract": "Discrete diffusion models have become highly effective across various\ndomains. However, real-world applications often require the generative process\nto adhere to certain constraints but without task-specific fine-tuning. To this\nend, we propose a training-free method based on Sequential Monte Carlo (SMC) to\nsample from the reward-aligned target distribution at the test time. Our\napproach leverages twisted SMC with an approximate locally optimal proposal,\nobtained via a first-order Taylor expansion of the reward function. To address\nthe challenge of ill-defined gradients in discrete spaces, we incorporate a\nGumbel-Softmax relaxation, enabling efficient gradient-based approximation\nwithin the discrete generative framework. Empirical results on both synthetic\ndatasets and image modelling validate the effectiveness of our approach.", "published": "2025-05-28 16:12:03", "link": "http://arxiv.org/abs/2505.22524v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "IGNIS: A Neural Network Framework for Robust Parameter Estimation in Archimedean Copulas", "abstract": "Parameter estimation for Archimedean copulas remains a challenging problem,\nparticularly for the recently developed A1 and A2 families that exhibit complex\ndependency structures. Traditional methods, such as the Method of Moments\n(MoM), Maximum Likelihood Estimation (MLE), and Maximum Pseudo-Likelihood\n(MPL), often struggle due to issues of non-monotonic relationship with\ndependency measures such as Kendall's tau (as in the case of A1) and numerical\ninstability. In this paper, we present the IGNIS Network, a novel, unified\nneural framework that learns a direct mapping from observable dependency\nmeasures to copula parameters, thereby overcoming the limitations of classical\napproaches. Our approach is trained on simulated data spanning five Archimedean\ncopula families including Clayton, Gumbel, Frank, A1, and A2, ensuring its\ngeneral applicability across the entire family. Extensive simulation studies\ndemonstrate that the IGNIS Network reduces estimation errors compared to MoM,\nwhile inherently enforcing parameter constraints through theory-guided\npost-processing. We further validate the practical utility of our method on\ndiverse real-world datasets, including financial returns (AAPL-MSFT),\nhealthcare metrics (CDC Diabetes indicators), and environmental measurements\n(PM2.5 air quality). Our results underscore the transformative potential of\nneural methods for robust and accurate dependence modeling in modern\napplications.", "published": "2025-05-28 16:04:17", "link": "http://arxiv.org/abs/2505.22518v1", "categories": ["stat.ML", "cs.LG", "62H05, 62H12, 62F10, 68T07, 62-08"], "primary_category": "stat.ML"}
{"title": "Accelerating Optimization via Differentiable Stopping Time", "abstract": "Optimization is an important module of modern machine learning applications.\nTremendous efforts have been made to accelerate optimization algorithms. A\ncommon formulation is achieving a lower loss at a given time. This enables a\ndifferentiable framework with respect to the algorithm hyperparameters. In\ncontrast, its dual, minimizing the time to reach a target loss, is believed to\nbe non-differentiable, as the time is not differentiable. As a result, it\nusually serves as a conceptual framework or is optimized using zeroth-order\nmethods. To address this limitation, we propose a differentiable stopping time\nand theoretically justify it based on differential equations. An efficient\nalgorithm is designed to backpropagate through it. As a result, the proposed\ndifferentiable stopping time enables a new differentiable formulation for\naccelerating algorithms. We further discuss its applications, such as online\nhyperparameter tuning and learning to optimize. Our proposed methods show\nsuperior performance in comprehensive experiments across various problems,\nwhich confirms their effectiveness.", "published": "2025-05-28 15:59:13", "link": "http://arxiv.org/abs/2505.22509v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Sparsification and Reconstruction from the Perspective of Representation Geometry", "abstract": "Sparse Autoencoders (SAEs) have emerged as a predominant tool in mechanistic\ninterpretability, aiming to identify interpretable monosemantic features.\nHowever, how does sparse encoding organize the representations of activation\nvector from language models? What is the relationship between this\norganizational paradigm and feature disentanglement as well as reconstruction\nperformance? To address these questions, we propose the SAEMA, which validates\nthe stratified structure of the representation by observing the variability of\nthe rank of the symmetric semipositive definite (SSPD) matrix corresponding to\nthe modal tensor unfolded along the latent tensor with the level of noise added\nto the residual stream. To systematically investigate how sparse encoding\nalters representational structures, we define local and global representations,\ndemonstrating that they amplify inter-feature distinctions by merging similar\nsemantic features and introducing additional dimensionality. Furthermore, we\nintervene the global representation from an optimization perspective, proving a\nsignificant causal relationship between their separability and the\nreconstruction performance. This study explains the principles of sparsity from\nthe perspective of representational geometry and demonstrates the impact of\nchanges in representational structure on reconstruction performance.\nParticularly emphasizes the necessity of understanding representations and\nincorporating representational constraints, providing empirical references for\ndeveloping new interpretable tools and improving SAEs. The code is available at\n\\hyperlink{https://github.com/wenjie1835/SAERepGeo}{https://github.com/wenjie1835/SAERepGeo}.", "published": "2025-05-28 15:54:33", "link": "http://arxiv.org/abs/2505.22506v1", "categories": ["cs.LG", "22-08", "I.2.4; I.2.7"], "primary_category": "cs.LG"}
{"title": "Geometric GNNs for Charged Particle Tracking at GlueX", "abstract": "Nuclear physics experiments are aimed at uncovering the fundamental building\nblocks of matter. The experiments involve high-energy collisions that produce\ncomplex events with many particle trajectories. Tracking charged particles\nresulting from collisions in the presence of a strong magnetic field is\ncritical to enable the reconstruction of particle trajectories and precise\ndetermination of interactions. It is traditionally achieved through\ncombinatorial approaches that scale worse than linearly as the number of hits\ngrows. Since particle hit data naturally form a 3-dimensional point cloud and\ncan be structured as graphs, Graph Neural Networks (GNNs) emerge as an\nintuitive and effective choice for this task. In this study, we evaluate the\nGNN model for track finding on the data from the GlueX experiment at Jefferson\nLab. We use simulation data to train the model and test on both simulation and\nreal GlueX measurements. We demonstrate that GNN-based track finding\noutperforms the currently used traditional method at GlueX in terms of\nsegment-based efficiency at a fixed purity while providing faster inferences.\nWe show that the GNN model can achieve significant speedup by processing\nmultiple events in batches, which exploits the parallel computation capability\nof Graphical Processing Units (GPUs). Finally, we compare the GNN\nimplementation on GPU and FPGA and describe the trade-off.", "published": "2025-05-28 15:52:22", "link": "http://arxiv.org/abs/2505.22504v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Assessing Quantum Advantage for Gaussian Process Regression", "abstract": "Gaussian Process Regression is a well-known machine learning technique for\nwhich several quantum algorithms have been proposed. We show here that in a\nwide range of scenarios these algorithms show no exponential speedup. We\nachieve this by rigorously proving that the condition number of a kernel matrix\nscales at least linearly with the matrix size under general assumptions on the\ndata and kernel. We additionally prove that the sparsity and Frobenius norm of\na kernel matrix scale linearly under similar assumptions. The implications for\nthe quantum algorithms runtime are independent of the complexity of loading\nclassical data on a quantum computer and also apply to dequantised algorithms.\nWe supplement our theoretical analysis with numerical verification for popular\nkernels in machine learning.", "published": "2025-05-28 15:50:56", "link": "http://arxiv.org/abs/2505.22502v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "ProSpero: Active Learning for Robust Protein Design Beyond Wild-Type Neighborhoods", "abstract": "Designing protein sequences of both high fitness and novelty is a challenging\ntask in data-efficient protein engineering. Exploration beyond wild-type\nneighborhoods often leads to biologically implausible sequences or relies on\nsurrogate models that lose fidelity in novel regions. Here, we propose\nProSpero, an active learning framework in which a frozen pre-trained generative\nmodel is guided by a surrogate updated from oracle feedback. By integrating\nfitness-relevant residue selection with biologically-constrained Sequential\nMonte Carlo sampling, our approach enables exploration beyond wild-type\nneighborhoods while preserving biological plausibility. We show that our\nframework remains effective even when the surrogate is misspecified. ProSpero\nconsistently outperforms or matches existing methods across diverse protein\nengineering tasks, retrieving sequences of both high fitness and novelty.", "published": "2025-05-28 15:45:43", "link": "http://arxiv.org/abs/2505.22494v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Hypothesis Testing in Imaging Inverse Problems", "abstract": "This paper proposes a framework for semantic hypothesis testing tailored to\nimaging inverse problems. Modern imaging methods struggle to support hypothesis\ntesting, a core component of the scientific method that is essential for the\nrigorous interpretation of experiments and robust interfacing with\ndecision-making processes. There are three main reasons why image-based\nhypothesis testing is challenging. First, the difficulty of using a single\nobservation to simultaneously reconstruct an image, formulate hypotheses, and\nquantify their statistical significance. Second, the hypotheses encountered in\nimaging are mostly of semantic nature, rather than quantitative statements\nabout pixel values. Third, it is challenging to control test error\nprobabilities because the null and alternative distributions are often unknown.\nOur proposed approach addresses these difficulties by leveraging concepts from\nself-supervised computational imaging, vision-language models, and\nnon-parametric hypothesis testing with e-values. We demonstrate our proposed\nframework through numerical experiments related to image-based phenotyping,\nwhere we achieve excellent power while robustly controlling Type I errors.", "published": "2025-05-28 15:29:43", "link": "http://arxiv.org/abs/2505.22481v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Non-Asymptotic Analysis of (Sticky) Track-and-Stop", "abstract": "In pure exploration problems, a statistician sequentially collects\ninformation to answer a question about some stochastic and unknown environment.\nThe probability of returning a wrong answer should not exceed a maximum risk\nparameter $\\delta$ and good algorithms make as few queries to the environment\nas possible. The Track-and-Stop algorithm is a pioneering method to solve these\nproblems. Specifically, it is well-known that it enjoys asymptotic optimality\nsample complexity guarantees for $\\delta\\to 0$ whenever the map from the\nenvironment to its correct answers is single-valued (e.g., best-arm\nidentification with a unique optimal arm). The Sticky Track-and-Stop algorithm\nextends these results to settings where, for each environment, there might\nexist multiple correct answers (e.g., $\\epsilon$-optimal arm identification).\nAlthough both methods are optimal in the asymptotic regime, their\nnon-asymptotic guarantees remain unknown. In this work, we fill this gap and\nprovide non-asymptotic guarantees for both algorithms.", "published": "2025-05-28 15:26:55", "link": "http://arxiv.org/abs/2505.22475v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Forecasting Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis", "abstract": "The forecasting of multivariate urban data presents a complex challenge due\nto the intricate dependencies between various urban metrics such as weather,\nair pollution, carbon intensity, and energy demand. This paper introduces a\nnovel multivariate time-series forecasting model that utilizes advanced Graph\nNeural Networks (GNNs) to capture spatial dependencies among different\ntime-series variables. The proposed model incorporates a decomposition-based\npreprocessing step, isolating trend, seasonal, and residual components to\nenhance the accuracy and interpretability of forecasts. By leveraging the\ndynamic capabilities of GNNs, the model effectively captures interdependencies\nand improves the forecasting performance. Extensive experiments on real-world\ndatasets, including electricity usage, weather metrics, carbon intensity, and\nair pollution data, demonstrate the effectiveness of the proposed approach\nacross various forecasting scenarios. The results highlight the potential of\nthe model to optimize smart infrastructure systems, contributing to\nenergy-efficient urban development and enhanced public well-being.", "published": "2025-05-28 15:24:04", "link": "http://arxiv.org/abs/2505.22474v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Pure Exploration with Infinite Answers", "abstract": "We study pure exploration problems where the set of correct answers is\npossibly infinite, e.g., the regression of any continuous function of the means\nof the bandit. We derive an instance-dependent lower bound for these problems.\nBy analyzing it, we discuss why existing methods (i.e., Sticky Track-and-Stop)\nfor finite answer problems fail at being asymptotically optimal in this more\ngeneral setting. Finally, we present a framework, Sticky-Sequence\nTrack-and-Stop, which generalizes both Track-and-Stop and Sticky\nTrack-and-Stop, and that enjoys asymptotic optimality. Due to its generality,\nour analysis also highlights special cases where existing methods enjoy\noptimality.", "published": "2025-05-28 15:23:36", "link": "http://arxiv.org/abs/2505.22473v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "CPINN-ABPI: Physics-Informed Neural Networks for Accurate Power Estimation in MPSoCs", "abstract": "Efficient thermal and power management in modern multiprocessor\nsystems-on-chip (MPSoCs) demands accurate power consumption estimation. One of\nthe state-of-the-art approaches, Alternative Blind Power Identification (ABPI),\ntheoretically eliminates the dependence on steady-state temperatures,\naddressing a major shortcoming of previous approaches. However, ABPI\nperformance has remained unverified in actual hardware implementations. In this\nstudy, we conduct the first empirical validation of ABPI on commercial hardware\nusing the NVIDIA Jetson Xavier AGX platform. Our findings reveal that, while\nABPI provides computational efficiency and independence from steady-state\ntemperature, it exhibits considerable accuracy deficiencies in real-world\nscenarios. To overcome these limitations, we introduce a novel approach that\nintegrates Custom Physics-Informed Neural Networks (CPINNs) with the underlying\nthermal model of ABPI. Our approach employs a specialized loss function that\nharmonizes physical principles with data-driven learning, complemented by\nmulti-objective genetic algorithm optimization to balance estimation accuracy\nand computational cost. In experimental validation, CPINN-ABPI achieves a\nreduction of 84.7\\% CPU and 73.9\\% GPU in the mean absolute error (MAE)\nrelative to ABPI, with the weighted mean absolute percentage error (WMAPE)\nimproving from 47\\%--81\\% to $\\sim$12\\%. The method maintains real-time\nperformance with 195.3~$\\mu$s of inference time, with similar 85\\%--99\\%\naccuracy gains across heterogeneous SoCs.", "published": "2025-05-28 15:22:15", "link": "http://arxiv.org/abs/2505.22469v1", "categories": ["cs.PF", "cs.LG"], "primary_category": "cs.PF"}
{"title": "Depth-Based Matrix Classification for the HHL Quantum Algorithm", "abstract": "Under the nearing error-corrected era of quantum computing, it is necessary\nto understand the suitability of certain post-NISQ algorithms for practical\nproblems. One of the most promising, applicable and yet difficult to implement\nin practical terms is the Harrow, Hassidim and Lloyd (HHL) algorithm for linear\nsystems of equations. An enormous number of problems can be expressed as linear\nsystems of equations, from Machine Learning to fluid dynamics. However, in most\ncases, HHL will not be able to provide a practical, reasonable solution to\nthese problems. This paper's goal inquires about whether problems can be\nlabeled using Machine Learning classifiers as suitable or unsuitable for HHL\nimplementation when some numerical information about the problem is known\nbeforehand. This work demonstrates that training on significantly\nrepresentative data distributions is critical to achieve good classifications\nof the problems based on the numerical properties of the matrix representing\nthe system of equations. Accurate classification is possible through\nMulti-Layer Perceptrons, although with careful design of the training data\ndistribution and classifier parameters.", "published": "2025-05-28 15:11:53", "link": "http://arxiv.org/abs/2505.22454v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Position: All Current Generative Fidelity and Diversity Metrics are Flawed", "abstract": "Any method's development and practical application is limited by our ability\nto measure its reliability. The popularity of generative modeling emphasizes\nthe importance of good synthetic data metrics. Unfortunately, previous works\nhave found many failure cases in current metrics, for example lack of outlier\nrobustness and unclear lower and upper bounds. We propose a list of desiderata\nfor synthetic data metrics, and a suite of sanity checks: carefully chosen\nsimple experiments that aim to detect specific and known generative modeling\nfailure modes. Based on these desiderata and the results of our checks, we\narrive at our position: all current generative fidelity and diversity metrics\nare flawed. This significantly hinders practical use of synthetic data. Our aim\nis to convince the research community to spend more effort in developing\nmetrics, instead of models. Additionally, through analyzing how current metrics\nfail, we provide practitioners with guidelines on how these metrics should\n(not) be used.", "published": "2025-05-28 15:10:33", "link": "http://arxiv.org/abs/2505.22450v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Data-Driven Antenna Miniaturization: A Knowledge-Based System Integrating Quantum PSO and Predictive Machine Learning Models", "abstract": "The rapid evolution of wireless technologies necessitates automated design\nframeworks to address antenna miniaturization and performance optimization\nwithin constrained development cycles. This study demonstrates a machine\nlearning enhanced workflow integrating Quantum-Behaved Dynamic Particle Swarm\nOptimization (QDPSO) with ANSYS HFSS simulations to accelerate antenna design.\nThe QDPSO algorithm autonomously optimized loop dimensions in 11.53 seconds,\nachieving a resonance frequency of 1.4208 GHz a 12.7 percent reduction compared\nto conventional 1.60 GHz designs. Machine learning models (SVM, Random Forest,\nXGBoost, and Stacked ensembles) predicted resonance frequencies in 0.75 seconds\nusing 936 simulation datasets, with stacked models showing superior training\naccuracy (R2=0.9825) and SVM demonstrating optimal validation performance\n(R2=0.7197). The complete design cycle, encompassing optimization, prediction,\nand ANSYS validation, required 12.42 minutes on standard desktop hardware\n(Intel i5-8500, 16GB RAM), contrasting sharply with the 50-hour benchmark of\nPSADEA-based approaches. This 240 times of acceleration eliminates traditional\ntrial-and-error methods that often extend beyond seven expert-led days. The\nsystem enables precise specifications of performance targets with automated\ngeneration of fabrication-ready parameters, particularly benefiting compact\nconsumer devices requiring rapid frequency tuning. By bridging AI-driven\noptimization with CAD validation, this framework reduces engineering workloads\nwhile ensuring production-ready designs, establishing a scalable paradigm for\nnext-generation RF systems in 6G and IoT applications.", "published": "2025-05-28 15:04:36", "link": "http://arxiv.org/abs/2505.22440v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "STaR-Bets: Sequential Target-Recalculating Bets for Tighter Confidence Intervals", "abstract": "The construction of confidence intervals for the mean of a bounded random\nvariable is a classical problem in statistics with numerous applications in\nmachine learning and virtually all scientific fields. In particular, obtaining\nthe tightest possible confidence intervals is vital every time the sampling of\nthe random variables is expensive. The current state-of-the-art method to\nconstruct confidence intervals is by using betting algorithms. This is a very\nsuccessful approach for deriving optimal confidence sequences, even matching\nthe rate of law of iterated logarithms. However, in the fixed horizon setting,\nthese approaches are either sub-optimal or based on heuristic solutions with\nstrong empirical performance but without a finite-time guarantee. Hence, no\nbetting-based algorithm guaranteeing the optimal\n$\\mathcal{O}(\\sqrt{\\frac{\\sigma^2\\log\\frac1\\delta}{n}})$ width of the\nconfidence intervals are known. This work bridges this gap. We propose a\nbetting-based algorithm to compute confidence intervals that empirically\noutperforms the competitors. Our betting strategy uses the optimal strategy in\nevery step (in a certain sense), whereas the standard betting methods choose a\nconstant strategy in advance. Leveraging this fact results in strict\nimprovements even for classical concentration inequalities, such as the ones of\nHoeffding or Bernstein. Moreover, we also prove that the width of our\nconfidence intervals is optimal up to an $1+o(1)$ factor diminishing with $n$.\nThe code is available\non~https://github.com/vvoracek/STaR-bets-confidence-interval.", "published": "2025-05-28 14:48:07", "link": "http://arxiv.org/abs/2505.22422v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Divide-and-Conquer Approach for Modeling Arrival Times in Business Process Simulation", "abstract": "Business Process Simulation (BPS) is a critical tool for analyzing and\nimproving organizational processes by estimating the impact of process changes.\nA key component of BPS is the case-arrival model, which determines the pattern\nof new case entries into a process. Although accurate case-arrival modeling is\nessential for reliable simulations, as it influences waiting and overall cycle\ntimes, existing approaches often rely on oversimplified static distributions of\ninter-arrival times. These approaches fail to capture the dynamic and temporal\ncomplexities inherent in organizational environments, leading to less accurate\nand reliable outcomes. To address this limitation, we propose Auto Time Kernel\nDensity Estimation (AT-KDE), a divide-and-conquer approach that models arrival\ntimes of processes by incorporating global dynamics, day-of-week variations,\nand intraday distributional changes, ensuring both precision and scalability.\nExperiments conducted across 20 diverse processes demonstrate that AT-KDE is\nfar more accurate and robust than existing approaches while maintaining\nsensible execution time efficiency.", "published": "2025-05-28 14:09:51", "link": "http://arxiv.org/abs/2505.22381v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Computing Optimal Transport Maps and Wasserstein Barycenters Using Conditional Normalizing Flows", "abstract": "We present a novel method for efficiently computing optimal transport maps\nand Wasserstein barycenters in high-dimensional spaces. Our approach uses\nconditional normalizing flows to approximate the input distributions as\ninvertible pushforward transformations from a common latent space. This makes\nit possible to directly solve the primal problem using gradient-based\nminimization of the transport cost, unlike previous methods that rely on dual\nformulations and complex adversarial optimization. We show how this approach\ncan be extended to compute Wasserstein barycenters by solving a conditional\nvariance minimization problem. A key advantage of our conditional architecture\nis that it enables the computation of barycenters for hundreds of input\ndistributions, which was computationally infeasible with previous methods. Our\nnumerical experiments illustrate that our approach yields accurate results\nacross various high-dimensional tasks and compares favorably with previous\nstate-of-the-art methods.", "published": "2025-05-28 13:46:07", "link": "http://arxiv.org/abs/2505.22364v1", "categories": ["stat.ML", "cs.LG", "65K99 (Primary) 68T07, 68T99 (Secondary)"], "primary_category": "stat.ML"}
{"title": "Directed Homophily-Aware Graph Neural Network", "abstract": "Graph Neural Networks (GNNs) have achieved significant success in various\nlearning tasks on graph-structured data. Nevertheless, most GNNs struggle to\ngeneralize to heterophilic neighborhoods. Additionally, many GNNs ignore the\ndirectional nature of real-world graphs, resulting in suboptimal performance on\ndirected graphs with asymmetric structures. In this work, we propose Directed\nHomophily-aware Graph Neural Network (DHGNN), a novel framework that addresses\nthese limitations by incorporating homophily-aware and direction-sensitive\ncomponents. DHGNN employs a resettable gating mechanism to adaptively modulate\nmessage contributions based on homophily levels and informativeness, and a\nstructure-aware noise-tolerant fusion module to effectively integrate node\nrepresentations from the original and reverse directions. Extensive experiments\non both homophilic and heterophilic directed graph datasets demonstrate that\nDHGNN outperforms state-of-the-art methods in node classification and link\nprediction. In particular, DHGNN improves over the best baseline by up to\n15.07% in link prediction. Our analysis further shows that the gating mechanism\ncaptures directional homophily gaps and fluctuating homophily across layers,\nproviding deeper insights into message-passing behavior on complex graph\nstructures.", "published": "2025-05-28 13:41:04", "link": "http://arxiv.org/abs/2505.22362v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Continuum-armed Bandit Optimization with Batch Pairwise Comparison Oracles", "abstract": "This paper studies a bandit optimization problem where the goal is to\nmaximize a function $f(x)$ over $T$ periods for some unknown strongly concave\nfunction $f$. We consider a new pairwise comparison oracle, where the\ndecision-maker chooses a pair of actions $(x, x')$ for a consecutive number of\nperiods and then obtains an estimate of $f(x)-f(x')$. We show that such a\npairwise comparison oracle finds important applications to joint pricing and\ninventory replenishment problems and network revenue management. The challenge\nin this bandit optimization is twofold. First, the decision-maker not only\nneeds to determine a pair of actions $(x, x')$ but also a stopping time $n$\n(i.e., the number of queries based on $(x, x')$). Second, motivated by our\ninventory application, the estimate of the difference $f(x)-f(x')$ is biased,\nwhich is different from existing oracles in stochastic optimization literature.\nTo address these challenges, we first introduce a discretization technique and\nlocal polynomial approximation to relate this problem to linear bandits. Then\nwe developed a tournament successive elimination technique to localize the\ndiscretized cell and run an interactive batched version of LinUCB algorithm on\ncells. We establish regret bounds that are optimal up to poly-logarithmic\nfactors. Furthermore, we apply our proposed algorithm and analytical framework\nto the two operations management problems and obtain results that improve\nstate-of-the-art results in the existing literature.", "published": "2025-05-28 13:41:00", "link": "http://arxiv.org/abs/2505.22361v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multiclass Loss Geometry Matters for Generalization of Gradient Descent in Separable Classification", "abstract": "We study the generalization performance of unregularized gradient methods for\nseparable linear classification. While previous work mostly deal with the\nbinary case, we focus on the multiclass setting with $k$ classes and establish\nnovel population risk bounds for Gradient Descent for loss functions that decay\nto zero. In this setting, we show risk bounds that reveal that convergence\nrates are crucially influenced by the geometry of the loss template, as\nformalized by Wang and Scott (2024), rather than of the loss function itself.\nParticularly, we establish risk upper bounds that holds for any decay rate of\nthe loss whose template is smooth with respect to the $p$-norm. In the case of\nexponentially decaying losses, our results indicates a contrast between the\n$p=\\infty$ case, where the risk exhibits a logarithmic dependence on $k$, and\n$p=2$ where the risk scales linearly with $k$. To establish this separation\nformally, we also prove a lower bound in the latter scenario, demonstrating\nthat the polynomial dependence on $k$ is unavoidable. Central to our analysis\nis a novel bound on the Rademacher complexity of low-noise vector-valued linear\npredictors with a loss template smooth w.r.t.~general $p$-norms.", "published": "2025-05-28 13:39:14", "link": "http://arxiv.org/abs/2505.22359v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient and Full Fine-Tuning", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods achieve performance comparable\nto Full Fine-Tuning (FFT) while requiring significantly fewer computing\nresources, making it the go-to choice for researchers. We find that although\nPEFT can achieve competitive results on some benchmarks, its performance falls\nshort of FFT in complex tasks, such as reasoning and instruction-based\nfine-tuning. In this paper, we compare the characteristics of PEFT and FFT in\nterms of representational capacity and robustness based on optimization theory.\nWe theoretically demonstrate that PEFT is a strict subset of FFT. By providing\ntheoretical upper bounds for PEFT, we show that the limited parameter space\nconstrains the model's representational ability, making it more susceptible to\nperturbations. Experiments on 15 datasets encompassing classification,\ngeneration, reasoning, instruction fine-tuning tasks and 11 adversarial test\nsets validate our theories. We hope that these results spark further research\nbeyond the realms of well established PEFT. The source code is in the anonymous\nGithub repository\\footnote{https://github.com/misonsky/PEFTEval}.", "published": "2025-05-28 13:35:12", "link": "http://arxiv.org/abs/2505.22355v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Credal Prediction based on Relative Likelihood", "abstract": "Predictions in the form of sets of probability distributions, so-called\ncredal sets, provide a suitable means to represent a learner's epistemic\nuncertainty. In this paper, we propose a theoretically grounded approach to\ncredal prediction based on the statistical notion of relative likelihood: The\ntarget of prediction is the set of all (conditional) probability distributions\nproduced by the collection of plausible models, namely those models whose\nrelative likelihood exceeds a specified threshold. This threshold has an\nintuitive interpretation and allows for controlling the trade-off between\ncorrectness and precision of credal predictions. We tackle the problem of\napproximating credal sets defined in this way by means of suitably modified\nensemble learning techniques. To validate our approach, we illustrate its\neffectiveness by experiments on benchmark datasets demonstrating superior\nuncertainty representation without compromising predictive performance. We also\ncompare our method against several state-of-the-art baselines in credal\nprediction.", "published": "2025-05-28 13:20:20", "link": "http://arxiv.org/abs/2505.22332v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Individualised Counterfactual Examples Using Conformal Prediction Intervals", "abstract": "Counterfactual explanations for black-box models aim to pr ovide insight into\nan algorithmic decision to its recipient. For a binary classification problem\nan individual counterfactual details which features might be changed for the\nmodel to infer the opposite class. High-dimensional feature spaces that are\ntypical of machine learning classification models admit many possible\ncounterfactual examples to a decision, and so it is important to identify\nadditional criteria to select the most useful counterfactuals. In this paper,\nwe explore the idea that the counterfactuals should be maximally informative\nwhen considering the knowledge of a specific individual about the underlying\nclassifier. To quantify this information gain we explicitly model the knowledge\nof the individual, and assess the uncertainty of predictions which the\nindividual makes by the width of a conformal prediction interval. Regions of\nfeature space where the prediction interval is wide correspond to areas where\nthe confidence in decision making is low, and an additional counterfactual\nexample might be more informative to an individual. To explore and evaluate our\nindividualised conformal prediction interval counterfactuals (CPICFs), first we\npresent a synthetic data set on a hypercube which allows us to fully visualise\nthe decision boundary, conformal intervals via three different methods, and\nresultant CPICFs. Second, in this synthetic data set we explore the impact of a\nsingle CPICF on the knowledge of an individual locally around the original\nquery. Finally, in both our synthetic data set and a complex real world dataset\nwith a combination of continuous and discrete variables, we measure the utility\nof these counterfactuals via data augmentation, testing the performance on a\nheld out set.", "published": "2025-05-28 13:13:52", "link": "http://arxiv.org/abs/2505.22326v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "A Closer Look on Memorization in Tabular Diffusion Model: A Data-Centric Perspective", "abstract": "Diffusion models have shown strong performance in generating high-quality\ntabular data, but they carry privacy risks by reproducing exact training\nsamples. While prior work focuses on dataset-level augmentation to reduce\nmemorization, little is known about which individual samples contribute most.\nWe present the first data-centric study of memorization dynamics in tabular\ndiffusion models. We quantify memorization for each real sample based on how\nmany generated samples are flagged as replicas, using a relative distance\nratio. Our empirical analysis reveals a heavy-tailed distribution of\nmemorization counts: a small subset of samples contributes disproportionately\nto leakage, confirmed via sample-removal experiments. To understand this, we\ndivide real samples into top- and non-top-memorized groups and analyze their\ntraining-time behaviors. We track when each sample is first memorized and\nmonitor per-epoch memorization intensity (AUC). Memorized samples are memorized\nslightly earlier and show stronger signals in early training. Based on these\ninsights, we propose DynamicCut, a two-stage, model-agnostic mitigation method:\n(a) rank samples by epoch-wise intensity, (b) prune a tunable top fraction, and\n(c) retrain on the filtered dataset. Across multiple tabular datasets and\nmodels, DynamicCut reduces memorization with minimal impact on data diversity\nand downstream performance. It also complements augmentation-based defenses.\nFurthermore, DynamicCut enables cross-model transferability: high-ranked\nsamples identified from one model (e.g., a diffusion model) are also effective\nfor reducing memorization when removed from others, such as GANs and VAEs.", "published": "2025-05-28 13:06:00", "link": "http://arxiv.org/abs/2505.22322v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Rethinking BPS: A Utility-Based Evaluation Framework", "abstract": "Business process simulation (BPS) is a key tool for analyzing and optimizing\norganizational workflows, supporting decision-making by estimating the impact\nof process changes. The reliability of such estimates depends on the ability of\na BPS model to accurately mimic the process under analysis, making rigorous\naccuracy evaluation essential. However, the state-of-the-art approach to\nevaluating BPS models has two key limitations. First, it treats simulation as a\nforecasting problem, testing whether models can predict unseen future events.\nThis fails to assess how well a model captures the as-is process, particularly\nwhen process behavior changes from train to test period. Thus, it becomes\ndifficult to determine whether poor results stem from an inaccurate model or\nthe inherent complexity of the data, such as unpredictable drift. Second, the\nevaluation approach strongly relies on Earth Mover's Distance-based metrics,\nwhich can obscure temporal patterns and thus yield misleading conclusions about\nsimulation quality. To address these issues, we propose a novel framework that\nevaluates simulation quality based on its ability to generate representative\nprocess behavior. Instead of comparing simulated logs to future real-world\nexecutions, we evaluate whether predictive process monitoring models trained on\nsimulated data perform comparably to those trained on real data for downstream\nanalysis tasks. Empirical results show that our framework not only helps\nidentify sources of discrepancies but also distinguishes between model accuracy\nand data complexity, offering a more meaningful way to assess BPS quality.", "published": "2025-05-28 13:00:52", "link": "http://arxiv.org/abs/2505.22316v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Transformers Pretrained on Procedural Data Contain Modular Structures for Algorithmic Reasoning", "abstract": "Pretraining on large, semantically rich datasets is key for developing\nlanguage models. Surprisingly, recent studies have shown that even synthetic\ndata, generated procedurally through simple semantic-free algorithms, can yield\nsome of the same benefits as natural language pretraining. It is unclear what\nspecific capabilities such simple synthetic data instils in a model, where\nthese capabilities reside in the architecture, and how they manifest within its\nweights. In this short paper, we identify several beneficial forms of\nprocedural data, together with specific algorithmic reasoning skills that\nimprove in small transformers. Our core finding is that different procedural\nrules instil distinct but complementary inductive structures in the model. With\nextensive ablations and partial-transfer experiments, we discover that these\nstructures reside in different parts of the model. Attention layers often carry\nthe most transferable information, but some pretraining rules impart useful\nstructure to MLP blocks instead. Most interestingly, the structures induced by\nmultiple rules can be composed to jointly reinforce multiple capabilities.\nThese results suggest an exciting possibility of disentangling the acquisition\nof knowledge from reasoning in language models, with the goal of improving\ntheir robustness and data efficiency.", "published": "2025-05-28 12:50:09", "link": "http://arxiv.org/abs/2505.22308v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Full Domain Analysis in Fluid Dynamics", "abstract": "Novel techniques in evolutionary optimization, simulation and machine\nlearning allow for a broad analysis of domains like fluid dynamics, in which\ncomputation is expensive and flow behavior is complex. Under the term of full\ndomain analysis we understand the ability to efficiently determine the full\nspace of solutions in a problem domain, and analyze the behavior of those\nsolutions in an accessible and interactive manner. The goal of full domain\nanalysis is to deepen our understanding of domains by generating many examples\nof flow, their diversification, optimization and analysis. We define a formal\nmodel for full domain analysis, its current state of the art, and requirements\nof subcomponents. Finally, an example is given to show what we can learn by\nusing full domain analysis. Full domain analysis, rooted in optimization and\nmachine learning, can be a helpful tool in understanding complex systems in\ncomputational physics and beyond.", "published": "2025-05-28 12:06:48", "link": "http://arxiv.org/abs/2505.22275v1", "categories": ["cs.LG", "cs.NE", "68U01", "I.2.1; I.2.6"], "primary_category": "cs.LG"}
{"title": "Revisiting Group Relative Policy Optimization: Insights into On-Policy and Off-Policy Training", "abstract": "We revisit Group Relative Policy Optimization (GRPO) in both on-policy and\noff-policy optimization regimes. Our motivation comes from recent work on\noff-policy Proximal Policy Optimization (PPO), which improves training\nstability, sampling efficiency, and memory usage. In addition, a recent\nanalysis of GRPO suggests that estimating the advantage function with\noff-policy samples could be beneficial. Building on these observations, we\nadapt GRPO to the off-policy setting. We show that both on-policy and\noff-policy GRPO objectives yield an improvement in the reward. This result\nmotivates the use of clipped surrogate objectives in the off-policy version of\nGRPO. We then compare the empirical performance of reinforcement learning with\nverifiable rewards in post-training using both GRPO variants. Our results show\nthat off-policy GRPO either significantly outperforms or performs on par with\nits on-policy counterpart.", "published": "2025-05-28 11:42:33", "link": "http://arxiv.org/abs/2505.22257v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Unified Online-Offline Framework for Co-Branding Campaign Recommendations", "abstract": "Co-branding has become a vital strategy for businesses aiming to expand\nmarket reach within recommendation systems. However, identifying effective\ncross-industry partnerships remains challenging due to resource imbalances,\nuncertain brand willingness, and ever-changing market conditions. In this\npaper, we provide the first systematic study of this problem and propose a\nunified online-offline framework to enable co-branding recommendations. Our\napproach begins by constructing a bipartite graph linking ``initiating'' and\n``target'' brands to quantify co-branding probabilities and assess market\nbenefits. During the online learning phase, we dynamically update the graph in\nresponse to market feedback, while striking a balance between exploring new\ncollaborations for long-term gains and exploiting established partnerships for\nimmediate benefits. To address the high initial co-branding costs, our\nframework mitigates redundant exploration, thereby enhancing short-term\nperformance while ensuring sustainable strategic growth. In the offline\noptimization phase, our framework consolidates the interests of multiple\nsub-brands under the same parent brand to maximize overall returns, avoid\nexcessive investment in single sub-brands, and reduce unnecessary costs\nassociated with over-prioritizing a single sub-brand. We present a theoretical\nanalysis of our approach, establishing a highly nontrivial sublinear regret\nbound for online learning in the complex co-branding problem, and enhancing the\napproximation guarantee for the NP-hard offline budget allocation optimization.\nExperiments on both synthetic and real-world co-branding datasets demonstrate\nthe practical effectiveness of our framework, with at least 12\\% improvement.", "published": "2025-05-28 11:41:07", "link": "http://arxiv.org/abs/2505.22254v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "B-XAIC Dataset: Benchmarking Explainable AI for Graph Neural Networks Using Chemical Data", "abstract": "Understanding the reasoning behind deep learning model predictions is crucial\nin cheminformatics and drug discovery, where molecular design determines their\nproperties. However, current evaluation frameworks for Explainable AI (XAI) in\nthis domain often rely on artificial datasets or simplified tasks, employing\ndata-derived metrics that fail to capture the complexity of real-world\nscenarios and lack a direct link to explanation faithfulness. To address this,\nwe introduce B-XAIC, a novel benchmark constructed from real-world molecular\ndata and diverse tasks with known ground-truth rationales for assigned labels.\nThrough a comprehensive evaluation using B-XAIC, we reveal limitations of\nexisting XAI methods for Graph Neural Networks (GNNs) in the molecular domain.\nThis benchmark provides a valuable resource for gaining deeper insights into\nthe faithfulness of XAI, facilitating the development of more reliable and\ninterpretable models.", "published": "2025-05-28 11:40:48", "link": "http://arxiv.org/abs/2505.22252v1", "categories": ["cs.LG", "cs.CE"], "primary_category": "cs.LG"}
{"title": "Optimal kernel regression bounds under energy-bounded noise", "abstract": "Non-conservative uncertainty bounds are key for both assessing an estimation\nalgorithm's accuracy and in view of downstream tasks, such as its deployment in\nsafety-critical contexts. In this paper, we derive a tight, non-asymptotic\nuncertainty bound for kernel-based estimation, which can also handle correlated\nnoise sequences. Its computation relies on a mild norm-boundedness assumption\non the unknown function and the noise, returning the worst-case function\nrealization within the hypothesis class at an arbitrary query input location.\nThe value of this function is shown to be given in terms of the posterior mean\nand covariance of a Gaussian process for an optimal choice of the measurement\nnoise covariance. By rigorously analyzing the proposed approach and comparing\nit with other results in the literature, we show its effectiveness in returning\ntight and easy-to-compute bounds for kernel-based estimates.", "published": "2025-05-28 11:11:24", "link": "http://arxiv.org/abs/2505.22235v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LaMM: Semi-Supervised Pre-Training of Large-Scale Materials Models", "abstract": "Neural network potentials (NNPs) are crucial for accelerating computational\nmaterials science by surrogating density functional theory (DFT) calculations.\nImproving their accuracy is possible through pre-training and fine-tuning,\nwhere an NNP model is first pre-trained on a large-scale dataset and then\nfine-tuned on a smaller target dataset. However, this approach is\ncomputationally expensive, mainly due to the cost of DFT-based dataset labeling\nand load imbalances during large-scale pre-training. To address this, we\npropose LaMM, a semi-supervised pre-training method incorporating improved\ndenoising self-supervised learning and a load-balancing algorithm for efficient\nmulti-node training. We demonstrate that our approach effectively leverages a\nlarge-scale dataset of $\\sim$300 million semi-labeled samples to train a single\nNNP model, resulting in improved fine-tuning performance in terms of both speed\nand accuracy.", "published": "2025-05-28 10:36:49", "link": "http://arxiv.org/abs/2505.22208v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An Augmentation-Aware Theory for Self-Supervised Contrastive Learning", "abstract": "Self-supervised contrastive learning has emerged as a powerful tool in\nmachine learning and computer vision to learn meaningful representations from\nunlabeled data. Meanwhile, its empirical success has encouraged many\ntheoretical studies to reveal the learning mechanisms. However, in the existing\ntheoretical research, the role of data augmentation is still under-exploited,\nespecially the effects of specific augmentation types. To fill in the blank, we\nfor the first time propose an augmentation-aware error bound for\nself-supervised contrastive learning, showing that the supervised risk is\nbounded not only by the unsupervised risk, but also explicitly by a trade-off\ninduced by data augmentation. Then, under a novel semantic label assumption, we\ndiscuss how certain augmentation methods affect the error bound. Lastly, we\nconduct both pixel- and representation-level experiments to verify our proposed\ntheoretical results.", "published": "2025-05-28 10:18:20", "link": "http://arxiv.org/abs/2505.22196v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient Leave-one-out Approximation in LLM Multi-agent Debate Based on Introspection", "abstract": "Multi-agent systems based on large language models (LLMs) advance automatic\ntask completion in various fields, where debate is a common cooperation form\nfor agents to solve complicated problems with reasoning and cross-review to\nsolidify answers. Assessing the individual contributions of agents within these\ndebates is crucial for system refinement and outcome reliability. Traditional\nleave-one-out (LOO) method offers a clear framework for evaluating each agent's\nrole but face challenges in LLM-based systems due to high computational costs\nand associated financial implications. This paper presents\nintrospective-leave-one-out (IntrospecLOO), a simple yet effective prompting\nfor approximation of LOO in LLM-powered multi-agent debates. IntrospecLOO\nintroduces an additional querying round after standard debates, prompting\nagents to update their answers while ignoring responses from a designated\nagent. This strategy effectively isolates and gauges each participant's\ninfluence at a reduced query complexity compared to the original LOO\napproaches. Validation through experiments on three benchmark datasets confirms\nthe effectiveness of IntrospecLOO.", "published": "2025-05-28 10:08:31", "link": "http://arxiv.org/abs/2505.22192v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation", "abstract": "Multimodality-to-Multiaudio (MM2MA) generation faces significant challenges\nin synthesizing diverse and contextually aligned audio types (e.g., sound\neffects, speech, music, and songs) from multimodal inputs (e.g., video, text,\nimages), owing to the scarcity of high-quality paired datasets and the lack of\nrobust multi-task learning frameworks. Recently, multi-agent system shows great\npotential in tackling the above issues. However, directly applying it to MM2MA\ntask presents three critical challenges: (1) inadequate fine-grained\nunderstanding of multimodal inputs (especially for video), (2) the inability of\nsingle models to handle diverse audio events, and (3) the absence of\nself-correction mechanisms for reliable outputs. To this end, we propose\nAudioGenie, a novel training-free multi-agent system featuring a dual-layer\narchitecture with a generation team and a supervisor team. For the generation\nteam, a fine-grained task decomposition and an adaptive Mixture-of-Experts\n(MoE) collaborative entity are designed for dynamic model selection, and a\ntrial-and-error iterative refinement module is designed for self-correction.\nThe supervisor team ensures temporal-spatial consistency and verifies outputs\nthrough feedback loops. Moreover, we build MA-Bench, the first benchmark for\nMM2MA tasks, comprising 198 annotated videos with multi-type audios.\nExperiments demonstrate that our AudioGenie outperforms state-of-the-art (SOTA)\nmethods across 9 metrics in 8 tasks. User study further validate the\neffectiveness of the proposed method in terms of quality, accuracy, alignment,\nand aesthetic. The anonymous project website with samples can be found at\nhttps://audiogenie.github.io/.", "published": "2025-05-28 07:23:53", "link": "http://arxiv.org/abs/2505.22053v1", "categories": ["cs.SD", "cs.MA", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement Learning", "abstract": "In multi-agent reinforcement learning (MARL), effective communication\nimproves agent performance, particularly under partial observability. We\npropose MARL-CPC, a framework that enables communication among fully\ndecentralized, independent agents without parameter sharing. MARL-CPC\nincorporates a message learning model based on collective predictive coding\n(CPC) from emergent communication research. Unlike conventional methods that\ntreat messages as part of the action space and assume cooperation, MARL-CPC\nlinks messages to state inference, supporting communication in non-cooperative,\nreward-independent settings. We introduce two algorithms -Bandit-CPC and\nIPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that\nboth outperform standard message-as-action approaches, establishing effective\ncommunication even when messages offer no direct benefit to the sender. These\nresults highlight MARL-CPC's potential for enabling coordination in complex,\ndecentralized environments.", "published": "2025-05-28 05:23:47", "link": "http://arxiv.org/abs/2505.21985v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Properties of zero-determinant strategies in multichannel games", "abstract": "Controlling payoffs in repeated games is one of the important topics in\ncontrol theory of multi-agent systems. Recently proposed zero-determinant\nstrategies enable players to unilaterally enforce linear relations between\npayoffs. Furthermore, based on the mathematics of zero-determinant strategies,\nregional payoff control, in which payoffs are enforced into some feasible\nregions, has been discovered in social dilemma situations. More recently,\ntheory of payoff control was extended to multichannel games, where players\nparallelly interact with each other in multiple channels. However, properties\nof zero-determinant strategies specific to multichannel games are still not\nclear. In this paper, we elucidate properties of zero-determinant strategies in\nmultichannel games. First, we relate the existence condition of\nzero-determinant strategies in multichannel games to that of zero-determinant\nstrategies in each channel. We then show that the existence of zero-determinant\nstrategies in multichannel games requires the existence of zero-determinant\nstrategies in some channels. This result implies that the existence of\nzero-determinant strategies in multichannel games is tightly restricted by\nstructure of games played in each channel.", "published": "2025-05-28 04:06:04", "link": "http://arxiv.org/abs/2505.21952v1", "categories": ["physics.soc-ph", "cs.GT", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "physics.soc-ph"}
{"title": "Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development", "abstract": "Recent advancements in Large Language Models (LLMs) and autonomous agents\nhave demonstrated remarkable capabilities across various domains. However,\nstandalone agents frequently encounter limitations when handling complex tasks\nthat demand extensive interactions and substantial computational resources.\nAlthough Multi-Agent Systems (MAS) alleviate some of these limitations through\ncollaborative mechanisms like task decomposition, iterative communication, and\nrole specialization, they typically remain resource-unaware, incurring\nsignificant inefficiencies due to high token consumption and excessive\nexecution time. To address these limitations, we propose a resource-aware\nmulti-agent system -- Co-Saving (meaning that multiple agents collaboratively\nengage in resource-saving activities), which leverages experiential knowledge\nto enhance operational efficiency and solution quality. Our key innovation is\nthe introduction of \"shortcuts\" -- instructional transitions learned from\nhistorically successful trajectories -- which allows to bypass redundant\nreasoning agents and expedite the collective problem-solving process.\nExperiments for software development tasks demonstrate significant advantages\nover existing methods. Specifically, compared to the state-of-the-art MAS\nChatDev, our method achieves an average reduction of 50.85% in token usage, and\nimproves the overall code quality by 10.06%.", "published": "2025-05-28 02:23:53", "link": "http://arxiv.org/abs/2505.21898v1", "categories": ["cs.CL", "cs.AI", "cs.MA", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation", "abstract": "This study presents an innovative approach to urban mobility simulation by\nintegrating a Large Language Model (LLM) with Agent-Based Modeling (ABM).\nUnlike traditional rule-based ABM, the proposed framework leverages LLM to\nenhance agent diversity and realism by generating synthetic population\nprofiles, allocating routine and occasional locations, and simulating\npersonalized routes. Using real-world data, the simulation models individual\nbehaviors and large-scale mobility patterns in Taipei City. Key insights, such\nas route heat maps and mode-specific indicators, provide urban planners with\nactionable information for policy-making. Future work focuses on establishing\nrobust validation frameworks to ensure accuracy and reliability in urban\nplanning applications.", "published": "2025-05-28 01:54:28", "link": "http://arxiv.org/abs/2505.21880v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.MA"}
{"title": "Asymptotic-preserving schemes for the initial-boundary value problem of hyperbolic relaxation systems", "abstract": "In this work, we present a numerical method for the initial-boundary value\nproblem (IBVP) of first-order hyperbolic systems with source terms. The scheme\ndirectly solves the relaxation system using a relatively coarse mesh and\ncaptures the equilibrium behavior quite well, even in the presence of boundary\nlayers. This method extends the concept of asymptotic-preserving schemes from\ninitial-value problems to IBVPs. Moreover, we apply this idea to design a\nunified numerical scheme for the interface problem of relaxation systems.", "published": "2025-05-28 17:59:13", "link": "http://arxiv.org/abs/2505.22656v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A hybrid PDE-ABM model for angiogenesis and tumour microenvironment with application to resistance in cancer treatment", "abstract": "The main obstacle to effective cancer treatment is the development of drug\nresistance, which can be divided into two categories: spontaneous and acquired\ndrug resistance. Non-small cell lung cancer (NSCLC) is the main cause of\ncancer-related deaths worldwide. A subset of lung cancer, adenocarcinomas, is\ncharacterised by mutations in the epidermal growth factor receptor (EGFR) gene.\nTreatment of EGFR-mutated lung adenocarcinomas has become less effective over\ntime due to drug resistance development, which is associated with a second\nmutation in the EGFR gene. An important factor in the development of cancer is\nangiogenesis, which is the formation of blood vessels from the existing\nvasculature. These newly formed blood vessels provide oxygen and nutrients to\ntumour cells to maintain tumour growth and proliferation. We applied a hybrid\ndiscrete-continuous (HDC) model to capture the dynamic vasculature in the\ntumour microenvironment (TME). In the case of pre-existing resistance, the\nformation of angiogenic networks creates a microenvironment that supports\ntumour survival and enhances drug resistance. In the case of spontaneous\nmutation-induced resistance, earlier and more frequent mutations confer a\ngreater survival advantage to the tumour population. There is also a mutually\nreinforcing relationship between a high proliferation rate and high resistance\ncharacteristics. These findings explain two conflicting experimental results\nabout the second mutation in NSCLC.", "published": "2025-05-28 16:54:29", "link": "http://arxiv.org/abs/2505.22580v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Gautschi-type and implicit-explicit integrators for constrained wave equations", "abstract": "This paper deals with the construction and analysis of two integrators for\n(semi-linear) second-order partial differential-algebraic equations of\nsemi-explicit type. More precisely, we consider an implicit-explicit\nCrank-Nicolson scheme as well as an exponential integrator of Gautschi type.\nFor this, well-known wave integrators for unconstrained systems are combined\nwith techniques known from the field of differential-algebraic equations. The\nresult are efficient time stepping schemes, which are provable of second order.\nMoreover, we discuss the practical implementation of the Gautschi-type method,\nwhich involves the solution of certain saddle point problems. The theoretical\nresults are verified by numerical experiments for the the wave equation with\nkinetic boundary conditions.", "published": "2025-05-28 16:19:22", "link": "http://arxiv.org/abs/2505.22532v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Lanczos with compression for symmetric matrix Lyapunov equations", "abstract": "This work considers large-scale Lyapunov matrix equations of the form $AX +\nXA = \\boldsymbol{c}\\boldsymbol{c}^T$, where $A$ is a symmetric positive\ndefinite matrix and $\\boldsymbol{c}$ is a vector. Motivated by the need to\nsolve such equations in a wide range of applications, various numerical methods\nhave been developed to compute low-rank approximations of the solution matrix\n$X$. In this work, we focus on the Lanczos method, which has the distinct\nadvantage of requiring only matrix-vector products with $A$, making it broadly\napplicable. However, the Lanczos method may suffer from slow convergence when\n$A$ is ill-conditioned, leading to excessive memory requirements for storing\nthe Krylov subspace basis generated by the algorithm. To address this issue, we\npropose a novel compression strategy for the Krylov subspace basis that\nsignificantly reduces memory usage without hindering convergence. This is\nsupported by both numerical experiments and a convergence analysis. Our\nanalysis also accounts for the loss of orthogonality due to round-off errors in\nthe Lanczos process.", "published": "2025-05-28 15:49:35", "link": "http://arxiv.org/abs/2505.22498v1", "categories": ["math.NA", "cs.NA", "65F45, 65F50, 65F55"], "primary_category": "math.NA"}
{"title": "Hybrid High-Order formulations with turbulence modelling capabilities for incompressible flow problems", "abstract": "We propose a Hybrid High-Order (HHO) formulation of the incompressible\nNavier--Stokes equations, that is well suited to be employed for the simulation\nof turbulent flows. The spatial discretization relies on hybrid velocity and\npressure spaces and the temporal discretization is based on Explicit Singly\nDiagonal Implicit Runge-Kutta (ESDIRK) methods. The formulation possesses some\nattractive features that can be fruitfully exploited when high-fidelity\ncomputations are required, namely: pressure-robustness, conservation of mass\nenforced cell-by-cell up to machine precision, robustness in the inviscid\nlimit, implicit high-order accurate time stepping with local time step\nadaptation, reduced memory footprint thanks to static condensation of both\nvelocity and pressure, possibility to exploit inherited $p$-multilevel solution\nstrategies to improve performance of iterative solvers. After demonstrating the\nrelevant properties of the scheme in practice, performing challenging 2D and 3D\ntest cases, we consider the simulation of the Taylor--Green Vortex flow problem\nat Reynolds 1600.", "published": "2025-05-28 15:29:00", "link": "http://arxiv.org/abs/2505.22480v1", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "primary_category": "physics.flu-dyn"}
{"title": "Continuity and approximability of competitive spectral radii", "abstract": "The competitive spectral radius extends the notion of joint spectral radius\nto the two-player case: two players alternatively select matrices in prescribed\ncompact sets, resulting in an infinite matrix product; one player wishes to\nmaximize the growth rate of this product, whereas the other player wishes to\nminimize it. We show that when the matrices represent linear operators\npreserving a cone and satisfying a \"strict positivity\" assumption, the\ncompetitive spectral radius depends continuously - and even in a\nLipschitz-continuous way - on the matrix sets. Moreover, we show that the\ncompetive spectral radius can be approximated up to any accuracy. This relies\non the solution of a discretized infinite dimensional non-linear eigenproblem.\nWe illustrate the approach with an example of age-structured population\ndynamics.", "published": "2025-05-28 15:20:25", "link": "http://arxiv.org/abs/2505.22468v1", "categories": ["math.OC", "cs.NA", "math.DS", "math.NA"], "primary_category": "math.OC"}
{"title": "Numerical Optimization Strategies for the Variational Hamiltonian Ansatz in Noisy Quantum Environments", "abstract": "We conduct a benchmark of eight optimization algorithms for variational\nquantum chemistry using the tVHA, evaluating performance on $H_2$, $H_4$, and\n$LiH$ (in both full and active spaces) under noiseless and sampling noise\nconditions. Sampling noise fundamentally alters optimizer behavior, with\ngradient-based methods performing best in ideal conditions, while\npopulation-based algorithms, such as CMA-ES, show greater resilience under\nnoise. Hartree-Fock initialization reduces the number of function evaluations\nby 27-60% and consistently yields higher final accuracy compared to random\nstarting points. We identify a precision limit set by sampling noise, with\ndiminishing returns beyond approximately 1000 shots.", "published": "2025-05-28 14:26:04", "link": "http://arxiv.org/abs/2505.22398v1", "categories": ["quant-ph", "cs.NA", "math.NA", "65Zxx"], "primary_category": "quant-ph"}
{"title": "Fast evaluation of Riemann theta functions in any dimension", "abstract": "We describe an algorithm to numerically evaluate Riemann theta functions in\nany dimension in quasi-linear time in terms of the required precision,\nuniformly on reduced input. This algorithm is implemented in the FLINT number\ntheory library and vastly outperforms existing software.", "published": "2025-05-28 14:09:57", "link": "http://arxiv.org/abs/2505.22382v1", "categories": ["math.NT", "cs.NA", "math.AG", "math.NA"], "primary_category": "math.NT"}
{"title": "Multiprecision computing for multistage fractional physics-informed neural networks", "abstract": "Fractional physics-informed neural networks (fPINNs) have been successfully\nintroduced in [Pang, Lu and Karniadakis, SIAM J. Sci. Comput. 41 (2019)\nA2603-A2626], which observe relative errors of $10^{-3} \\, \\sim \\, 10^{-4}$ for\nthe subdiffusion equations. However their high-precision (multiprecision)\nnumerical solution remains challenging, due to the limited regularity of the\nsubdiffusion model caused by the nonlocal operator. To fill in the gap, we\npresent the multistage fPINNs based on traditional multistage PINNs [Wang and\nLai, J. Comput. Phys. 504 (2024) 112865]. Numerical experiments show that the\nrelative errors improve to $10^{-7} \\, \\sim \\, 10^{-8}$ for the subdiffusion\nequations on uniform or nouniform meshes.", "published": "2025-05-28 14:06:11", "link": "http://arxiv.org/abs/2505.22377v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Coupled Hydro-Morphodynamic Model for Sediment Transport using the Moment Approach", "abstract": "Sediment transport is crucial in the hydro-morphodynamic evolution of free\nsurface flows in shallow water environments, which is typically modeled under\nthe shallow water assumption. In classical shallow water modeling for sediment\ntransport, the vertical structure of the flow is collapsed into a\ndepth-averaged and near-bed velocity, usually reconstructed empirically, e.g.,\nusing a parameterized logarithmic profile. In practice, large variations from\nsuch empirical profiles can occur. It is therefore essential to resolve the\nvertical structure of the velocity profile within the shallow water framework\nto better approximate near-bed velocity. This study introduces a model and\nsimulations that incorporate vertical velocity variations and bottom\nerosion-deposition effects in sediment transport, providing a computationally\nefficient framework for predicting sediment dynamics in shallow water\nenvironments. We employ the so-called moment model approach for the velocity\nvariation, which considers a polynomial expansion of the horizontal velocity in\nthe scaled vertical direction. This allows the use of a complex velocity\nprofile with an extended set of variables determined by the polynomial basis\ncoefficients, resolving the vertical structure as part of the solution. The\nextended model comprises four components: (1) the standard shallow water\nequations; (2) moment equations governing evolution of the basis coefficients;\n(3) an evolution equation for sediment concentration; and (4) a transport\nequation for the bed. This enables a coupled model for bedload and suspended\nload transport. We use a hyperbolic regularization technique to ensure model\nstability and realistic eigenvalues. Several numerical tests, including\ndam-break cases with and without wet/dry fronts, validate our results against\nlaboratory data.", "published": "2025-05-28 12:13:43", "link": "http://arxiv.org/abs/2505.22278v1", "categories": ["math.NA", "cs.NA", "physics.geo-ph"], "primary_category": "math.NA"}
{"title": "Direct Algorithms for Reconstructing Small Conductivity Inclusions in Subdiffusion", "abstract": "The subdiffusion model that involves a Caputo fractional derivative in time\nis widely used to describe anomalously slow diffusion processes. In this work\nwe aim at recovering the locations of small conductivity inclusions in the\nmodel from boundary measurement, and develop novel direct algorithms based on\nthe asymptotic expansion of the boundary measurement with respect to the size\nof the inclusions and approximate fundamental solutions. These algorithms\ninvolve only algebraic manipulations and are computationally cheap. To the best\nof our knowledge, they are first direct algorithms for the inverse conductivity\nproblem in the context of the subdiffusion model. Moreover, we provide relevant\ntheoretical underpinnings for the algorithms. Also we present numerical results\nto illustrate their performance under various scenarios, e.g., the size of\ninclusions, noise level of the data, and the number of inclusions, showing that\nthe algorithms are efficient and robust.", "published": "2025-05-28 11:27:48", "link": "http://arxiv.org/abs/2505.22245v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Discrete stochastic maximal regularity", "abstract": "In this paper, we investigate discrete regularity estimates for a broad class\nof temporal numerical schemes for parabolic stochastic evolution equations. We\nprovide a characterization of discrete stochastic maximal $\\ell^p$-regularity\nin terms of its continuous counterpart, thereby establishing a unified\nframework that yields numerous new discrete regularity results. Moreover, as a\nconsequence of the continuous-time theory, we establish several important\nproperties of discrete stochastic maximal regularity such as extrapolation in\nthe exponent $p$ and with respect to a power weight. Furthermore, employing the\n$H^\\infty$-functional calculus, we derive a powerful discrete maximal estimate\nin the trace space norm $D_A(1-\\frac1p,p)$ for $p \\in [2,\\infty)$.", "published": "2025-05-28 09:05:15", "link": "http://arxiv.org/abs/2505.22145v1", "categories": ["math.AP", "cs.NA", "math.FA", "math.NA", "math.PR", "Primary: 46N40, 60H15, Secondary: 35B65, 42B37, 47D06, 60H35, 65J10,\n  65M12"], "primary_category": "math.AP"}
{"title": "Optimized Schwarz methods for heterogeneous heat transfer problems", "abstract": "We present here nonoverlapping optimized Schwarz methods applied to heat\ntransfer problems with heterogeneous diffusion coefficients. After a Laplace\ntransform in time, we derive the error equation and obtain the convergence\nfactor. The optimal transmission operators are nonlocal, and thus inconvenient\nto use in practice. We introduce three versions of local approximations for the\ntransmission parameter, and provide a detailed analysis at the continuous level\nin each case to identify the best local transmission conditions. Numerical\nexperiments are presented to illustrate the performance of each local\ntransmission condition. As shown in our analysis, local transmission\nconditions, which are scaled appropriately with respect to the heterogeneous\ndiffusion coefficients, are more efficient and robust especially when the\ndiscontinuity of the diffusion coefficient is large.", "published": "2025-05-28 08:29:08", "link": "http://arxiv.org/abs/2505.22103v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "PADAM: Parallel averaged Adam reduces the error for stochastic optimization in scientific machine learning", "abstract": "Averaging techniques such as Ruppert--Polyak averaging and exponential\nmovering averaging (EMA) are powerful approaches to accelerate optimization\nprocedures of stochastic gradient descent (SGD) optimization methods such as\nthe popular ADAM optimizer. However, depending on the specific optimization\nproblem under consideration, the type and the parameters for the averaging need\nto be adjusted to achieve the smallest optimization error. In this work we\npropose an averaging approach, which we refer to as parallel averaged ADAM\n(PADAM), in which we compute parallely different averaged variants of ADAM and\nduring the training process dynamically select the variant with the smallest\noptimization error. A central feature of this approach is that this procedure\nrequires no more gradient evaluations than the usual ADAM optimizer as each of\nthe averaged trajectories relies on the same underlying ADAM trajectory and\nthus on the same underlying gradients. We test the proposed PADAM optimizer in\n13 stochastic optimization and deep neural network (DNN) learning problems and\ncompare its performance with known optimizers from the literature such as\nstandard SGD, momentum SGD, Adam with and without EMA, and ADAMW. In\nparticular, we apply the compared optimizers to physics-informed neural\nnetwork, deep Galerkin, deep backward stochastic differential equation and deep\nKolmogorov approximations for boundary value partial differential equation\nproblems from scientific machine learning, as well as to DNN approximations for\noptimal control and optimal stopping problems. In nearly all of the considered\nexamples PADAM achieves, sometimes among others and sometimes exclusively,\nessentially the smallest optimization error. This work thus strongly suggest to\nconsider PADAM for scientific machine learning problems and also motivates\nfurther research for adaptive averaging procedures within the training of DNNs.", "published": "2025-05-28 08:07:34", "link": "http://arxiv.org/abs/2505.22085v1", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Local cubic spline interpolation for Vlasov-type equations on a multi-patch geometry", "abstract": "We present a semi-Lagrangian method for the numerical resolution of\nVlasov-type equations on multi-patch meshes. We employ a local cubic spline\ninterpolation with Hermite boundary conditions between the patches. The\nderivative reconstruction is adapted to cope with non-uniform meshes as well as\nnon-conforming situations. In the conforming case, there are no longer any\nconstraints on the number of points for each patch; however, a small global\nsystem must now be solved. In that case, the local spline representations\ncoincide with the corresponding global spline reconstruction. Alternatively, we\ncan choose not to apply the global system and the derivatives can be\napproximated. The influence of the most distant points diminishes as the number\nof points per patch increases. For uniform per patch configurations, a study of\nthe explicit and asymptotic behavior of this influence has been led. The method\nis validated using a two-dimensional guiding-center model with an O-point. All\nthe numerical results are carried out in the Gyselalib++ library.", "published": "2025-05-28 08:00:15", "link": "http://arxiv.org/abs/2505.22078v1", "categories": ["math.NA", "cs.NA", "65M25, 65D07"], "primary_category": "math.NA"}
{"title": "A High Accuracy Symplectic Scheme for Advection Diffusion Reaction Models in Bioseparation", "abstract": "We analyze an advection-diffusion-reaction problem with non-homogeneous\nboundary conditions that models the chromatography process, a vital stage in\nbioseparation. We prove stability and error estimates for both constant and\naffine adsorption, using the symplectic one-step implicit midpoint method for\ntime discretization and finite elements for spatial discretization. In\naddition, we perform the stability analysis for the nonlinear, explicit\nadsorption in the continuous and semi-discrete cases. For the nonlinear,\nexplicit adsorption, we also complete the error analysis for the semi-discrete\ncase and prove the existence of a solution for the fully discrete case. The\nnumerical tests validate our theoretical results.", "published": "2025-05-28 06:38:20", "link": "http://arxiv.org/abs/2505.22022v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Locking-Free Training of Physics-Informed Neural Network for Solving Nearly Incompressible Elasticity Equations", "abstract": "Due to divergence instability, the accuracy of low-order conforming finite\nelement methods for nearly incompressible homogeneous elasticity equations\ndeteriorates as the Lam\\'e coefficient $\\lambda\\to\\infty$, or equivalently as\nthe Poisson ratio $\\nu\\to1/2$. This phenomenon, known as locking or\nnon-robustness, remains not fully understood despite extensive investigation.\nIn this paper, we propose a robust method based on a fundamentally different,\nmachine-learning-driven approach. Leveraging recently developed\nPhysics-Informed Neural Networks (PINNs), we address the numerical solution of\nlinear elasticity equations governing nearly incompressible materials. The core\nidea of our method is to appropriately decompose the given equations to\nalleviate the extreme imbalance in the coefficients, while simultaneously\nsolving both the forward and inverse problems to recover the solutions of the\ndecomposed systems as well as the associated external conditions. Through\nvarious numerical experiments, including constant, variable and parametric\nLam\\'e coefficients, we illustrate the efficiency of the proposed methodology.", "published": "2025-05-28 05:52:03", "link": "http://arxiv.org/abs/2505.21994v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Structured Divide-and-Conquer for the Definite Generalized Eigenvalue Problem", "abstract": "This paper presents a fast, randomized divide-and-conquer algorithm for the\ndefinite generalized eigenvalue problem, which corresponds to pencils $(A,B)$\nin which $A$ and $B$ are Hermitian and the Crawford number $\\gamma(A,B) =\n\\min_{||x||_2 = 1} |x^H(A+iB)x|$ is positive. Adapted from the fastest known\nmethod for diagonalizing arbitrary matrix pencils [Foundations of Computational\nMathematics 2024], the algorithm is both inverse-free and highly parallel. As\nin the general case, randomization takes the form of perturbations applied to\nthe input matrices, which regularize the problem for compatibility with fast,\ndivide-and-conquer eigensolvers -- i.e., the now well-established phenomenon of\npseudospectral shattering. We demonstrate that this high-level approach to\ndiagonalization can be executed in a structure-aware fashion by (1) extending\npseudospectral shattering to definite pencils under structured perturbations\n(either random diagonal or sampled from the Gaussian Unitary Ensemble) and (2)\nformulating the divide-and-conquer procedure in a way that maintains\ndefiniteness. The result is a specialized solver whose complexity, when applied\nto definite pencils, is provably lower than that of general divide-and-conquer.", "published": "2025-05-28 03:04:06", "link": "http://arxiv.org/abs/2505.21917v1", "categories": ["math.NA", "cs.NA", "15A22, 15B57, 65F15"], "primary_category": "math.NA"}
{"title": "Multi-period Mean-Buffered Probability of Exceedance in Defined Contribution Portfolio Optimization", "abstract": "We investigate multi-period mean-risk portfolio optimization for long-horizon\nDefined Contribution plans, focusing on buffered Probability of Exceedance\n(bPoE), a more intuitive, dollar-based alternative to Conditional Value-at-Risk\n(CVaR). We formulate both pre-commitment and time-consistent Mean-bPoE and\nMean-CVaR portfolio optimization problems under realistic investment\nconstraints (e.g., no leverage, no short selling) and jump-diffusion dynamics.\nThese formulations are naturally framed as bilevel optimization problems, with\nan outer search over the shortfall threshold and an inner optimization over\nrebalancing decisions. We establish an equivalence between the pre-commitment\nformulations through a one-to-one correspondence of their scalarization optimal\nsets, while showing that no such equivalence holds in the time-consistent\nsetting. We develop provably convergent numerical schemes for the value\nfunctions associated with both pre-commitment and time-consistent formulations\nof these mean-risk control problems.\n  Using nearly a century of market data, we find that time-consistent Mean-bPoE\nstrategies closely resemble their pre-commitment counterparts. In particular,\nthey maintain alignment with investors' preferences for a minimum acceptable\nterminal wealth level-unlike time-consistent Mean-CVaR, which often leads to\ncounterintuitive control behavior. We further show that bPoE, as a strictly\ntail-oriented measure, prioritizes guarding against catastrophic shortfalls\nwhile allowing meaningful upside exposure, making it especially appealing for\nlong-horizon wealth security. These findings highlight bPoE's practical\nadvantages for long-horizon retirement planning.", "published": "2025-05-28 08:47:54", "link": "http://arxiv.org/abs/2505.22121v1", "categories": ["q-fin.PM", "q-fin.CP", "91G, 65R20, 93E20, 49M25"], "primary_category": "q-fin.PM"}
{"title": "GLAMP: An Approximate Message Passing Framework for Transfer Learning with Applications to Lasso-based Estimators", "abstract": "Approximate Message Passing (AMP) algorithms enable precise characterization\nof certain classes of random objects in the high-dimensional limit, and have\nfound widespread applications in fields such as statistics, deep learning,\ngenetics, and communications. However, existing AMP frameworks cannot\nsimultaneously handle matrix-valued iterates and non-separable denoising\nfunctions. This limitation prevents them from precisely characterizing\nestimators that draw information from multiple data sources with distribution\nshifts. In this work, we introduce Generalized Long Approximate Message Passing\n(GLAMP), a novel extension of AMP that addresses this limitation. We rigorously\nprove state evolution for GLAMP. GLAMP significantly broadens the scope of AMP,\nenabling the analysis of transfer learning estimators that were previously out\nof reach. We demonstrate the utility of GLAMP by precisely characterizing the\nrisk of three Lasso-based transfer learning estimators: the Stacked Lasso, the\nModel Averaging Estimator, and the Second Step Estimator. We also demonstrate\nthe remarkable finite sample accuracy of our theory via extensive simulations.", "published": "2025-05-28 17:05:09", "link": "http://arxiv.org/abs/2505.22594v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Handling bounded response in high dimensions: a Horseshoe prior Bayesian Beta regression approach", "abstract": "Bounded continuous responses -- such as proportions -- arise frequently in\ndiverse scientific fields including climatology, biostatistics, and finance.\nBeta regression is a widely adopted framework for modeling such data, due to\nthe flexibility of the Beta distribution over the unit interval. While Bayesian\nextensions of Beta regression have shown promise, existing methods are limited\nto low-dimensional settings and lack theoretical guarantees. In this work, we\npropose a novel Bayesian approach for high-dimensional sparse Beta regression\nframework that employs a tempered posterior. Our method incorporates the\nHorseshoe prior for effective shrinkage and variable selection. Most notable,\nwe propose a novel Gibbs sampling algorithm using P\\'olya-Gamma augmentation\nfor efficient inference in Beta regression model. We also provide the first\ntheoretical results establishing posterior consistency and convergence rates\nfor Bayesian Beta regression. Through extensive simulation studies in both low-\nand high-dimensional scenarios, we demonstrate that our approach outperforms\nexisting alternatives, offering improved estimation accuracy and model\ninterpretability.\n  Our method is implemented in the R package ``betaregbayes\" available on\nGithub.", "published": "2025-05-28 10:39:05", "link": "http://arxiv.org/abs/2505.22211v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Learning Curves of Stochastic Gradient Descent in Kernel Regression", "abstract": "This paper considers a canonical problem in kernel regression: how good are\nthe model performances when it is trained by the popular online first-order\nalgorithms, compared to the offline ones, such as ridge and ridgeless\nregression? In this paper, we analyze the foundational single-pass Stochastic\nGradient Descent (SGD) in kernel regression under source condition where the\noptimal predictor can even not belong to the RKHS, i.e. the model is\nmisspecified. Specifically, we focus on the inner product kernel over the\nsphere and characterize the exact orders of the excess risk curves under\ndifferent scales of sample sizes $n$ concerning the input dimension $d$.\nSurprisingly, we show that SGD achieves min-max optimal rates up to constants\namong all the scales, without suffering the saturation, a prevalent phenomenon\nobserved in (ridge) regression, except when the model is highly misspecified\nand the learning is in a final stage where $n\\gg d^{\\gamma}$ with any constant\n$\\gamma >0$. The main reason for SGD to overcome the curse of saturation is the\nexponentially decaying step size schedule, a common practice in deep neural\nnetwork training. As a byproduct, we provide the \\emph{first} provable\nadvantage of the scheme over the iterative averaging method in the common\nsetting.", "published": "2025-05-28 07:16:11", "link": "http://arxiv.org/abs/2505.22048v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Judging LLMs on a Simplex", "abstract": "Automated evaluation of free-form outputs from large language models (LLMs)\nis challenging because many distinct answers can be equally valid. A common\npractice is to use LLMs themselves as judges, but the theoretical properties of\nthis approach are not yet well understood. We show that a geometric framework\nthat represents both judges and candidates as points on a probability simplex\ncan provide helpful insight on what is or is not identifiable using LLM judges.\nOur theoretical analysis uncovers a \"phase transition\" in ranking\nidentifiability: for binary scoring systems, true rankings are identifiable\neven with weak judges under mild assumptions, while rankings become\nnon-identifiable for three or more scoring levels even with infinite data,\nabsent additional prior knowledge. This non-identifiability highlights how\nuncertainty in rankings stems from not only aleatoric uncertainty (i.e.,\ninherent stochasticity in the data) but also epistemic uncertainty regarding\nwhich assumptions hold, an aspect that has received limited attention until\nnow. To integrate both types of uncertainty, we use Bayesian inference to\nencode assumptions as priors and conduct sensitivity analysis of ranking\nestimates and credible intervals. Empirical evaluations across multiple\nbenchmarks demonstrate that Bayesian inference yields more accurate rankings\nand substantially improves coverage rates. These results underscore the\nimportance of taking a more holistic approach to uncertainty quantification\nwhen using LLMs as judges.", "published": "2025-05-28 04:50:41", "link": "http://arxiv.org/abs/2505.21972v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Continual Learning Beyond Experience Rehearsal and Full Model Surrogates", "abstract": "Continual learning (CL) has remained a significant challenge for deep neural\nnetworks as learning new tasks erases previously acquired knowledge, either\npartially or completely. Existing solutions often rely on experience rehearsal\nor full model surrogates to mitigate CF. While effective, these approaches\nintroduce substantial memory and computational overhead, limiting their\nscalability and applicability in real-world scenarios. To address this, we\npropose SPARC, a scalable CL approach that eliminates the need for experience\nrehearsal and full-model surrogates. By effectively combining task-specific\nworking memories and task-agnostic semantic memory for cross-task knowledge\nconsolidation, SPARC results in a remarkable parameter efficiency, using only\n6% of the parameters required by full-model surrogates. Despite its lightweight\ndesign, SPARC achieves superior performance on Seq-TinyImageNet and matches\nrehearsal-based methods on various CL benchmarks. Additionally, weight\nre-normalization in the classification layer mitigates task-specific biases,\nestablishing SPARC as a practical and scalable solution for CL under stringent\nefficiency constraints.", "published": "2025-05-28 03:52:34", "link": "http://arxiv.org/abs/2505.21942v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Higher-Order Group Synchronization", "abstract": "Group synchronization is the problem of determining reliable global estimates\nfrom noisy local measurements on networks. The typical task for group\nsynchronization is to assign elements of a group to the nodes of a graph in a\nway that respects group elements given on the edges which encode information\nabout local pairwise relationships between the nodes. In this paper, we\nintroduce a novel higher-order group synchronization problem which operates on\na hypergraph and seeks to synchronize higher-order local measurements on the\nhyperedges to obtain global estimates on the nodes. Higher-order group\nsynchronization is motivated by applications to computer vision and image\nprocessing, among other computational problems. First, we define the problem of\nhigher-order group synchronization and discuss its mathematical foundations.\nSpecifically, we give necessary and sufficient synchronizability conditions\nwhich establish the importance of cycle consistency in higher-order group\nsynchronization. Then, we propose the first computational framework for general\nhigher-order group synchronization; it acts globally and directly on\nhigher-order measurements using a message passing algorithm. We discuss\ntheoretical guarantees for our framework, including convergence analyses under\noutliers and noise. Finally, we show potential advantages of our method through\nnumerical experiments. In particular, we show that in certain cases our\nhigher-order method applied to rotational and angular synchronization\noutperforms standard pairwise synchronization methods and is more robust to\noutliers. We also show that our method has comparable performance on simulated\ncryo-electron microscopy (cryo-EM) data compared to a standard cryo-EM\nreconstruction package.", "published": "2025-05-28 03:37:10", "link": "http://arxiv.org/abs/2505.21932v1", "categories": ["stat.ML", "cs.CV", "cs.LG", "math.CO", "math.OC"], "primary_category": "stat.ML"}
{"title": "Almost Linear Convergence under Minimal Score Assumptions: Quantized Transition Diffusion", "abstract": "Continuous diffusion models have demonstrated remarkable performance in data\ngeneration across various domains, yet their efficiency remains constrained by\ntwo critical limitations: (1) the local adjacency structure of the forward\nMarkov process, which restricts long-range transitions in the data space, and\n(2) inherent biases introduced during the simulation of time-inhomogeneous\nreverse denoising processes. To address these challenges, we propose Quantized\nTransition Diffusion (QTD), a novel approach that integrates data quantization\nwith discrete diffusion dynamics. Our method first transforms the continuous\ndata distribution $p_*$ into a discrete one $q_*$ via histogram approximation\nand binary encoding, enabling efficient representation in a structured discrete\nlatent space. We then design a continuous-time Markov chain (CTMC) with Hamming\ndistance-based transitions as the forward process, which inherently supports\nlong-range movements in the original data space. For reverse-time sampling, we\nintroduce a \\textit{truncated uniformization} technique to simulate the reverse\nCTMC, which can provably provide unbiased generation from $q_*$ under minimal\nscore assumptions. Through a novel KL dynamic analysis of the reverse CTMC, we\nprove that QTD can generate samples with $O(d\\ln^2(d/\\epsilon))$ score\nevaluations in expectation to approximate the $d$--dimensional target\ndistribution $p_*$ within an $\\epsilon$ error tolerance. Our method not only\nestablishes state-of-the-art inference efficiency but also advances the\ntheoretical foundations of diffusion-based generative modeling by unifying\ndiscrete and continuous diffusion paradigms.", "published": "2025-05-28 02:10:11", "link": "http://arxiv.org/abs/2505.21892v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Revisiting Bayesian Model Averaging in the Era of Foundation Models", "abstract": "We revisit the classical, full-fledged Bayesian model averaging (BMA)\nparadigm to ensemble pre-trained and/or lightly-finetuned foundation models to\nenhance the classification performance on image and text data. To make BMA\ntractable under foundation models, we introduce trainable linear classifiers\nthat take frozen features from the pre-trained foundation models as inputs. The\nmodel posteriors over the linear classifiers tell us which linear heads and\nfrozen features are better suited for a given dataset, resulting in a\nprincipled model ensembling method. Furthermore, we propose a computationally\ncheaper, optimizable model averaging scheme (OMA). In OMA, we directly optimize\nthe model ensemble weights, just like those weights based on model posterior\ndistributions in BMA, by reducing the amount of surprise (expected entropy of\nthe predictions) we get from predictions of ensembled models. With the rapid\ndevelopment of foundation models, these approaches will enable the\nincorporation of future, possibly significantly better foundation models to\nenhance the performance of challenging classification tasks.", "published": "2025-05-28 01:03:28", "link": "http://arxiv.org/abs/2505.21857v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Spectral clustering for dependent community Hawkes process models of temporal networks", "abstract": "Temporal networks observed continuously over time through timestamped\nrelational events data are commonly encountered in application settings\nincluding online social media communications, financial transactions, and\ninternational relations. Temporal networks often exhibit community structure\nand strong dependence patterns among node pairs. This dependence can be modeled\nthrough mutual excitations, where an interaction event from a sender to a\nreceiver node increases the possibility of future events among other node\npairs.\n  We provide statistical results for a class of models that we call dependent\ncommunity Hawkes (DCH) models, which combine the stochastic block model with\nmutually exciting Hawkes processes for modeling both community structure and\ndependence among node pairs, respectively. We derive a non-asymptotic upper\nbound on the misclustering error of spectral clustering on the event count\nmatrix as a function of the number of nodes and communities, time duration, and\nthe amount of dependence in the model. Our result leverages recent results on\nbounding an appropriate distance between a multivariate Hawkes process count\nvector and a Gaussian vector, along with results from random matrix theory. We\nalso propose a DCH model that incorporates only self and reciprocal excitation\nalong with highly scalable parameter estimation using a Generalized Method of\nMoments (GMM) estimator that we demonstrate to be consistent for growing\nnetwork size and time duration.", "published": "2025-05-28 00:25:10", "link": "http://arxiv.org/abs/2505.21845v1", "categories": ["stat.ML", "cs.LG", "cs.SI", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Towards General Discrete Speech Codec for Complex Acoustic Environments: A Study of Reconstruction and Downstream Task Consistency", "abstract": "Neural speech codecs excel in reconstructing clean speech signals; however,\ntheir efficacy in complex acoustic environments and downstream signal\nprocessing tasks remains underexplored. In this study, we introduce a novel\nbenchmark named Environment-Resilient Speech Codec Benchmark (ERSB) to\nsystematically evaluate whether neural speech codecs are environment-resilient.\nSpecifically, we assess two key capabilities: (1) robust reconstruction, which\nmeasures the preservation of both speech and non-speech acoustic details, and\n(2) downstream task consistency, which ensures minimal deviation in downstream\nsignal processing tasks when using reconstructed speech instead of the\noriginal. Our comprehensive experiments reveal that complex acoustic\nenvironments significantly degrade signal reconstruction and downstream task\nconsistency. This work highlights the limitations of current speech codecs and\nraises a future direction that improves them for greater environmental\nresilience.", "published": "2025-05-28 16:03:03", "link": "http://arxiv.org/abs/2505.22515v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Articulatory modeling of the S-shaped F2 trajectories observed in \u00d6hman's spectrographic analysis of VCV syllables", "abstract": "The synthesis of Ohman's VCV sequences with intervocalic plosive consonants\nwas first achieved 30 years ago using the DRM model. However, this approach\nremains primarily acoustic and lacks articulatory constraints. In this study,\nthe same 75 VCVs are analyzed, but generated with the Maeda model, using\ntrajectory planning that differentiates vowel-to-vowel transitions from\nconsonantal influences. Synthetic data exhibit similar characteristics to\nOhman's sequences, including the presence of S-shaped F2 trajectories.\nFurthermore, locus equations (LEs) for F2 and F3 are computed from synthetic CV\ndata to investigate their underlying determinism, leading to a reassessment of\nconventional interpretations. The findings indicate that, although articulatory\nplanning is structured separately for vowel and consonant groups, S-shaped F2\ntrajectories emerge from a composite mechanism governed by the coordinated\nsynergy of all articulators.", "published": "2025-05-28 15:12:53", "link": "http://arxiv.org/abs/2505.22455v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FGS-Audio: Fixed-Decoder Framework for Audio Steganography with Adversarial Perturbation Generation", "abstract": "The rapid development of Artificial Intelligence Generated Content (AIGC) has\nmade high-fidelity generated audio widely available across the Internet,\noffering an abundant and versatile source of cover signals for covert\ncommunication. Driven by advances in deep learning, current audio steganography\nframeworks are mainly based on encoding-decoding network architectures. While\nthese methods greatly improve the security of audio steganography, they\ntypically employ elaborate training workflows and rely on extensive pre-trained\nmodels. To address the aforementioned issues, this paper pioneers a\nFixed-Decoder Framework for Audio Steganography with Adversarial Perturbation\nGeneration (FGS-Audio). The adversarial perturbations that carry secret\ninformation are embedded into cover audio to generate stego audio. The receiver\nonly needs to share the structure and weights of the fixed decoding network to\naccurately extract the secret information from the stego audio, thus\neliminating the reliance on large pre-trained models. In FGS-Audio, we propose\nan audio Adversarial Perturbation Generation (APG) strategy and design a\nlightweight fixed decoder. The fixed decoder guarantees reliable extraction of\nthe hidden message, while the adversarial perturbations are optimized to keep\nthe stego audio perceptually and statistically close to the cover audio,\nthereby improving resistance to steganalysis. The experimental results show\nthat the method exhibits excellent anti-steganalysis performance under\ndifferent relative payloads, outperforming existing SOTA approaches. In terms\nof stego audio quality, FGS-Audio achieves an average PSNR improvement of over\n10 dB compared to SOTA method.", "published": "2025-05-28 11:54:09", "link": "http://arxiv.org/abs/2505.22266v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Two-stage Audio-Visual Target Speaker Extraction System for Real-Time Processing On Edge Device", "abstract": "Audio-Visual Target Speaker Extraction (AVTSE) aims to isolate a target\nspeaker's voice in a multi-speaker environment with visual cues as auxiliary.\nMost of the existing AVTSE methods encode visual and audio features\nsimultaneously, resulting in extremely high computational complexity and making\nit impractical for real-time processing on edge devices. To tackle this issue,\nwe proposed a two-stage ultra-compact AVTSE system. Specifically, in the first\nstage, a compact network is employed for voice activity detection (VAD) using\nvisual information. In the second stage, the VAD results are combined with\naudio inputs to isolate the target speaker's voice. Experiments show that the\nproposed system effectively suppresses background noise and interfering voices\nwhile spending little computational resources.", "published": "2025-05-28 11:05:24", "link": "http://arxiv.org/abs/2505.22229v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Developing a Top-tier Framework in Naturalistic Conditions Challenge for Categorized Emotion Prediction: From Speech Foundation Models and Learning Objective to Data Augmentation and Engineering Choices", "abstract": "Speech emotion recognition (SER), particularly for naturally expressed\nemotions, remains a challenging computational task. Key challenges include the\ninherent subjectivity in emotion annotation and the imbalanced distribution of\nemotion labels in datasets. This paper introduces the \\texttt{SAILER} system\ndeveloped for participation in the INTERSPEECH 2025 Emotion Recognition\nChallenge (Task 1). The challenge dataset, which contains natural emotional\nspeech from podcasts, serves as a valuable resource for studying imbalanced and\nsubjective emotion annotations. Our system is designed to be simple,\nreproducible, and effective, highlighting critical choices in modeling,\nlearning objectives, data augmentation, and engineering choices. Results show\nthat even a single system (without ensembling) can outperform more than 95\\% of\nthe submissions, with a Macro-F1 score exceeding 0.4. Moreover, an ensemble of\nthree systems further improves performance, achieving a competitively ranked\nscore (top-3 performing team). Our model is at:\nhttps://github.com/tiantiaf0627/vox-profile-release.", "published": "2025-05-28 08:58:22", "link": "http://arxiv.org/abs/2505.22133v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On-the-fly Routing for Zero-shot MoE Speaker Adaptation of Speech Foundation Models for Dysarthric Speech Recognition", "abstract": "This paper proposes a novel MoE-based speaker adaptation framework for\nfoundation models based dysarthric speech recognition. This approach enables\nzero-shot adaptation and real-time processing while incorporating domain\nknowledge. Speech impairment severity and gender conditioned adapter experts\nare dynamically combined using on-the-fly predicted speaker-dependent routing\nparameters. KL-divergence is used to further enforce diversity among experts\nand their generalization to unseen speakers. Experimental results on the\nUASpeech corpus suggest that on-the-fly MoE-based adaptation produces\nstatistically significant WER reductions of up to 1.34% absolute (6.36%\nrelative) over the unadapted baseline HuBERT/WavLM models. Consistent WER\nreductions of up to 2.55% absolute (11.44% relative) and RTF speedups of up to\n7 times are obtained over batch-mode adaptation across varying speaker-level\ndata quantities. The lowest published WER of 16.35% (46.77% on very low\nintelligibility) is obtained.", "published": "2025-05-28 07:52:58", "link": "http://arxiv.org/abs/2505.22072v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Delayed-KD: Delayed Knowledge Distillation based CTC for Low-Latency Streaming ASR", "abstract": "CTC-based streaming ASR has gained significant attention in real-world\napplications but faces two main challenges: accuracy degradation in small\nchunks and token emission latency. To mitigate these challenges, we propose\nDelayed-KD, which applies delayed knowledge distillation on CTC posterior\nprobabilities from a non-streaming to a streaming model. Specifically, with a\ntiny chunk size, we introduce a Temporal Alignment Buffer (TAB) that defines a\nrelative delay range compared to the non-streaming teacher model to align CTC\noutputs and mitigate non-blank token mismatches. Additionally, TAB enables\nfine-grained control over token emission delay. Experiments on 178-hour\nAISHELL-1 and 10,000-hour WenetSpeech Mandarin datasets show consistent\nsuperiority of Delayed-KD. Impressively, Delayed-KD at 40 ms latency achieves a\nlower character error rate (CER) of 5.42% on AISHELL-1, comparable to the\ncompetitive U2++ model running at 320 ms latency.", "published": "2025-05-28 07:51:21", "link": "http://arxiv.org/abs/2505.22069v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Weakly Supervised Data Refinement and Flexible Sequence Compression for Efficient Thai LLM-based ASR", "abstract": "Despite remarkable achievements, automatic speech recognition (ASR) in\nlow-resource scenarios still faces two challenges: high-quality data scarcity\nand high computational demands. This paper proposes EThai-ASR, the first to\napply large language models (LLMs) to Thai ASR and create an efficient\nLLM-based ASR system. EThai-ASR comprises a speech encoder, a connection module\nand a Thai LLM decoder. To address the data scarcity and obtain a powerful\nspeech encoder, EThai-ASR introduces a self-evolving data refinement strategy\nto refine weak labels, yielding an enhanced speech encoder. Moreover, we\npropose a pluggable sequence compression module used in the connection module\nwith three modes designed to reduce the sequence length, thus decreasing\ncomputational demands while maintaining decent performance. Extensive\nexperiments demonstrate that EThai-ASR has achieved state-of-the-art accuracy\nin multiple datasets. We release our refined text transcripts to promote\nfurther research.", "published": "2025-05-28 07:39:25", "link": "http://arxiv.org/abs/2505.22063v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ARiSE: Auto-Regressive Multi-Channel Speech Enhancement", "abstract": "We propose ARiSE, an auto-regressive algorithm for multi-channel speech\nenhancement. ARiSE improves existing deep neural network (DNN) based\nframe-online multi-channel speech enhancement models by introducing\nauto-regressive connections, where the estimated target speech at previous\nframes is leveraged as extra input features to help the DNN estimate the target\nspeech at the current frame. The extra input features can be derived from (a)\nthe estimated target speech in previous frames; and (b) a beamformed mixture\nwith the beamformer computed based on the previous estimated target speech. On\nthe other hand, naively training the DNN in an auto-regressive manner is very\nslow. To deal with this, we propose a parallel training mechanism to speed up\nthe training. Evaluation results in noisy-reverberant conditions show the\neffectiveness and potential of the proposed algorithms.", "published": "2025-05-28 07:22:28", "link": "http://arxiv.org/abs/2505.22051v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Mitigating Audiovisual Mismatch in Visual-Guide Audio Captioning", "abstract": "Current vision-guided audio captioning systems frequently fail to address\naudiovisual misalignment in real-world scenarios, such as dubbed content or\noff-screen sounds. To bridge this critical gap, we present an entropy-aware\ngated fusion framework that dynamically modulates visual information flow\nthrough cross-modal uncertainty quantification. Our novel approach employs\nattention entropy analysis in cross-attention layers to automatically identify\nand suppress misleading visual cues during modal fusion. Complementing this\narchitecture, we develop a batch-wise audiovisual shuffling technique that\ngenerates synthetic mismatched training pairs, greatly enhancing model\nresilience against alignment noise. Evaluations on the AudioCaps benchmark\ndemonstrate our system's superior performance over existing baselines,\nespecially in mismatched modality scenarios. Furthermore, our solution\ndemonstrates an approximately 6x improvement in inference speed compared to the\nbaseline.", "published": "2025-05-28 07:08:17", "link": "http://arxiv.org/abs/2505.22045v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Analysis and Evaluation of Synthetic Data Generation in Speech Dysfluency Detection", "abstract": "Speech dysfluency detection is crucial for clinical diagnosis and language\nassessment, but existing methods are limited by the scarcity of high-quality\nannotated data. Although recent advances in TTS model have enabled synthetic\ndysfluency generation, existing synthetic datasets suffer from unnatural\nprosody and limited contextual diversity. To address these limitations, we\npropose LLM-Dys -- the most comprehensive dysfluent speech corpus with\nLLM-enhanced dysfluency simulation. This dataset captures 11 dysfluency\ncategories spanning both word and phoneme levels. Building upon this resource,\nwe improve an end-to-end dysfluency detection framework. Experimental\nvalidation demonstrates state-of-the-art performance. All data, models, and\ncode are open-sourced at https://github.com/Berkeley-Speech-Group/LLM-Dys.", "published": "2025-05-28 06:52:10", "link": "http://arxiv.org/abs/2505.22029v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Respiratory Sound Classification with Architecture-Agnostic Knowledge Distillation from Ensembles", "abstract": "Respiratory sound datasets are limited in size and quality, making high\nperformance difficult to achieve. Ensemble models help but inevitably increase\ncompute cost at inference time. Soft label training distills knowledge\nefficiently with extra cost only at training. In this study, we explore soft\nlabels for respiratory sound classification as an architecture-agnostic\napproach to distill an ensemble of teacher models into a student model. We\nexamine different variations of our approach and find that even a single\nteacher, identical to the student, considerably improves performance beyond its\nown capability, with optimal gains achieved using only a few teachers. We\nachieve the new state-of-the-art Score of 64.39 on ICHBI, surpassing the\nprevious best by 0.85 and improving average Scores across architectures by more\nthan 1.16. Our results highlight the effectiveness of knowledge distillation\nwith soft labels for respiratory sound classification, regardless of size or\narchitecture.", "published": "2025-05-28 06:49:18", "link": "http://arxiv.org/abs/2505.22027v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RESOUND: Speech Reconstruction from Silent Videos via Acoustic-Semantic Decomposed Modeling", "abstract": "Lip-to-speech (L2S) synthesis, which reconstructs speech from visual cues,\nfaces challenges in accuracy and naturalness due to limited supervision in\ncapturing linguistic content, accents, and prosody. In this paper, we propose\nRESOUND, a novel L2S system that generates intelligible and expressive speech\nfrom silent talking face videos. Leveraging source-filter theory, our method\ninvolves two components: an acoustic path to predict prosody and a semantic\npath to extract linguistic features. This separation simplifies learning,\nallowing independent optimization of each representation. Additionally, we\nenhance performance by integrating speech units, a proven unsupervised speech\nrepresentation technique, into waveform generation alongside mel-spectrograms.\nThis allows RESOUND to synthesize prosodic speech while preserving content and\nspeaker identity. Experiments conducted on two standard L2S benchmarks confirm\nthe effectiveness of the proposed method across various metrics.", "published": "2025-05-28 06:46:13", "link": "http://arxiv.org/abs/2505.22024v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Overlap-Adaptive Hybrid Speaker Diarization and ASR-Aware Observation Addition for MISP 2025 Challenge", "abstract": "This paper presents the system developed to address the MISP 2025 Challenge.\nFor the diarization system, we proposed a hybrid approach combining a WavLM\nend-to-end segmentation method with a traditional multi-module clustering\ntechnique to adaptively select the appropriate model for handling varying\ndegrees of overlapping speech. For the automatic speech recognition (ASR)\nsystem, we proposed an ASR-aware observation addition method that compensates\nfor the performance limitations of Guided Source Separation (GSS) under low\nsignal-to-noise ratio conditions. Finally, we integrated the speaker\ndiarization and ASR systems in a cascaded architecture to address Track 3. Our\nsystem achieved character error rates (CER) of 9.48% on Track 2 and\nconcatenated minimum permutation character error rate (cpCER) of 11.56% on\nTrack 3, ultimately securing first place in both tracks and thereby\ndemonstrating the effectiveness of the proposed methods in real-world meeting\nscenarios.", "published": "2025-05-28 06:22:37", "link": "http://arxiv.org/abs/2505.22013v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging LLM for Stuttering Speech: A Unified Architecture Bridging Recognition and Event Detection", "abstract": "The performance bottleneck of Automatic Speech Recognition (ASR) in\nstuttering speech scenarios has limited its applicability in domains such as\nspeech rehabilitation. This paper proposed an LLM-driven ASR-SED multi-task\nlearning framework that jointly optimized the ASR and Stuttering Event\nDetection (SED) tasks. We proposed a dynamic interaction mechanism where the\nASR branch leveraged CTC-generated soft prompts to assist LLM context modeling,\nwhile the SED branch output stutter embeddings to enhance LLM comprehension of\nstuttered speech. We incorporated contrastive learning to strengthen the\ndiscriminative power of stuttering acoustic features and applied Focal Loss to\nmitigate the long-tailed distribution in stuttering event categories.\nEvaluations on the AS-70 Mandarin stuttering dataset demonstrated that our\nframework reduced the ASR character error rate (CER) to 5.45% (-37.71% relative\nreduction) and achieved an average SED F1-score of 73.63% (+46.58% relative\nimprovement).", "published": "2025-05-28 06:12:19", "link": "http://arxiv.org/abs/2505.22005v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Toward Fully Neuromorphic Receivers for Ultra-Power Efficient Communications", "abstract": "Neuromorphic computing, inspired by biological neural systems, has emerged as\na promising approach for ultra-energy-efficient data processing by leveraging\nanalog neuron structures and spike-based computation. However, its application\nin communication systems remains largely unexplored, with existing efforts\nmainly focused on mapping isolated communication algorithms onto spiking\nnetworks, often accompanied by substantial, traditional computational overhead\ndue to transformations required to adapt problems to the spiking paradigm. In\nthis work, we take a fundamentally different route and, for the first time,\npropose a fully neuromorphic communication receiver by applying neuromorphic\nprinciples directly in the analog domain from the very start of the receiver\nprocessing chain. Specifically, we examine a simple transmission scenario: a\nBPSK receiver with repetition coding, and show that we can achieve joint\ndetection and decoding entirely through spiking signals. Our approach\ndemonstrates error-rate performance gains over conventional digital\nrealizations with power consumption on the order of microwatts, comparable with\na single very low-resolution Analog-to-Digital Converter (ADC) utilized in\ndigital receivers. To maintain performance under varying noise conditions, we\nalso introduce a novel noise-tracking mechanism that dynamically adjusts neural\nparameters during transmission. Finally, we discuss the key challenges and\ndirections toward ultra-efficient neuromorphic transceivers.", "published": "2025-05-28 15:57:16", "link": "http://arxiv.org/abs/2505.22508v1", "categories": ["eess.SP", "94A12", "C.1.3; C.2.1"], "primary_category": "eess.SP"}
{"title": "Frequency Resource Management in 6G User-Centric CFmMIMO: A Hybrid Reinforcement Learning and Metaheuristic Approach", "abstract": "As sixth-generation (6G) networks continue to evolve, AI-driven solutions are\nplaying a crucial role in enabling more efficient and adaptive resource\nmanagement in wireless communication. One of the key innovations in 6G is\nuser-centric cell-free massive Multiple-Input Multiple-Output (UC-CFmMIMO), a\nparadigm that eliminates traditional cell boundaries and enhances network\nperformance by dynamically assigning access points (APs) to users. This\napproach is particularly well-suited for vehicular networks, offering seamless,\nhomogeneous, ultra-reliable, and low-latency connectivity. However, in dense\nnetworks, a key challenge lies in efficiently allocating frequency resources\nwithin a limited shared subband spectrum while accounting for frequency\nselectivity and the dependency of signal propagation on bandwidth. These\nfactors make resource allocation increasingly complex, especially in dynamic\nenvironments where maintaining Quality of Service (QoS) is critical. This paper\ntackles these challenges by proposing a hybrid multi-user allocation strategy\nthat integrates reinforcement learning (RL) and metaheuristic optimization to\nenhance spectral efficiency (SE), ensure fairness, and mitigate interference\nwithin shared subbands. To assess its effectiveness, we compare this hybrid\napproach with two other methods: the bio-inspired Aquila Optimizer (AO) and\nDeep Deterministic Policy Gradient (DDPG)-based Actor-Critic Reinforcement\nLearning (AC-RL). Our evaluation is grounded in real-world patterns and channel\ncharacteristics, utilizing the 3GPP-3D channel modeling framework (QuaDRiGa) to\ncapture realistic propagation conditions. The results demonstrate that the\nproposed hybrid strategy achieves a superior balance among competing\nobjectives, underscoring the role of AI-driven resource allocation in advancing\nUC-CFmMIMO systems for next-generation wireless networks.", "published": "2025-05-28 15:07:56", "link": "http://arxiv.org/abs/2505.22443v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments", "abstract": "With the rapid growth of IoT devices and their diverse workloads,\ncontainer-based microservices deployed at edge nodes have become a lightweight\nand scalable solution. However, existing microservice scheduling algorithms\noften assume static resource availability, which is unrealistic when multiple\ncontainers are assigned to an edge node. Besides, containers suffer from\ncold-start inefficiencies during early-stage training in currently popular\nreinforcement learning (RL) algorithms. In this paper, we propose a hybrid\nlearning framework that combines offline imitation learning (IL) with online\nSoft Actor-Critic (SAC) optimization to enable a cold-start-aware microservice\nscheduling with dynamic allocation for computing resources. We first formulate\na delay-and-energy-aware scheduling problem and construct a rule-based expert\nto generate demonstration data for behavior cloning. Then, a GRU-enhanced\npolicy network is designed in the policy network to extract the correlation\namong multiple decisions by separately encoding slow-evolving node states and\nfast-changing microservice features, and an action selection mechanism is given\nto speed up the convergence. Extensive experiments show that our method\nsignificantly accelerates convergence and achieves superior final performance.\nCompared with baselines, our algorithm improves the total objective by $50\\%$\nand convergence speed by $70\\%$, and demonstrates the highest stability and\nrobustness across various edge configurations.", "published": "2025-05-28 14:51:57", "link": "http://arxiv.org/abs/2505.22424v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Aspects of density approximation by tensor trains", "abstract": "Point-mass filters solve Bayesian recursive relations by approximating\nprobability density functions of a system state over grids of discrete points.\nThe approach suffers from the curse of dimensionality. The exponential increase\nof the number of the grid points can be mitigated by application of low-rank\napproximations of multidimensional arrays. Tensor train decompositions\nrepresent individual values by the product of matrices. This paper focuses on\nselected issues that are substantial in state estimation. Namely, the\ncontamination of the density approximations by negative values is discussed\nfirst. Functional decompositions of quadratic functions are compared with\ndecompositions of discretised Gaussian densities next. In particular, the\nconnection of correlation with tensor train ranks is explored. Last, the\nconsequences of interpolating the density values from one grid to a new grid\nare analysed.", "published": "2025-05-28 10:50:50", "link": "http://arxiv.org/abs/2505.22218v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MONSTR: Model-Oriented Neutron Strain Tomographic Reconstruction", "abstract": "Residual strain, a tensor quantity, is a critical material property that\nimpacts the overall performance of metal parts. Neutron Bragg edge strain\ntomography is a technique for imaging residual strain that works by making\nconventional hyperspectral computed tomography measurements, extracting the\naverage projected strain at each detector pixel, and processing the resulting\nstrain sinogram using a reconstruction algorithm. However, the reconstruction\nis severely ill-posed as the underlying inverse problem involves inferring a\ntensor at each voxel from scalar sinogram data.\n  In this paper, we introduce the model-oriented neutron strain tomographic\nreconstruction (MONSTR) algorithm that reconstructs the 2D residual strain\ntensor from the neutron Bragg edge strain measurements. MONSTR is based on\nusing the multi-agent consensus equilibrium framework for the tensor\ntomographic reconstruction. Specifically, we formulate the reconstruction as a\nconsensus solution of a collection of agents representing detector physics, the\ntomographic reconstruction process, and physics-based constraints from\ncontinuum mechanics. Using simulated data, we demonstrate high-quality\nreconstruction of the strain tensor even when using very few measurements.", "published": "2025-05-28 09:59:37", "link": "http://arxiv.org/abs/2505.22187v1", "categories": ["eess.IV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Algorithm Unrolling-based Denoising of Multimodal Graph Signals", "abstract": "We propose a denoising method of multimodal graph signals by iteratively\nsolving signal restoration and graph learning problems. Many complex-structured\ndata, i.e., those on sensor networks, can capture multiple modalities at each\nmeasurement point, referred to as modalities. They are also assumed to have an\nunderlying structure or correlations in modality as well as space. Such\nmultimodal data are regarded as graph signals on a twofold graph and they are\noften corrupted by noise. Furthermore, their spatial/modality relationships are\nnot always given a priori: We need to estimate twofold graphs during a\ndenoising algorithm. In this paper, we consider a signal denoising method on\ntwofold graphs, where graphs are learned simultaneously. We formulate an\noptimization problem for that and parameters in an iterative algorithm are\nlearned from training data by unrolling the iteration with deep algorithm\nunrolling. Experimental results on synthetic and real-world data demonstrate\nthat the proposed method outperforms existing model- and deep learning-based\ngraph signal denoising methods.", "published": "2025-05-28 09:49:52", "link": "http://arxiv.org/abs/2505.22175v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Real-World Modeling of Computation Offloading for Neural Networks with Early Exits and Splits", "abstract": "We focus on computation offloading of applications based on convolutional\nneural network (CNN) from moving devices, such as mobile robots or autonomous\nvehicles, to MultiAccess Edge Computing (MEC) servers via a mobile network. In\norder to reduce overall CNN inference time, we design and implement CNN with\nearly exits and splits, allowing a flexible partial or full offloading of CNN\ninference. Through real-world experiments, we analyze an impact of the CNN\ninference offloading on the total CNN processing delay, energy consumption, and\nclassification accuracy in a practical road sign recognition task. The results\nconfirm that offloading of CNN with early exits and splits can significantly\nreduce both total processing delay and energy consumption compared to full\nlocal processing while not impairing classification accuracy. Based on the\nresults of real-world experiments, we derive practical models for energy\nconsumption and total processing delay related to offloading of CNN with early\nexits and splits.", "published": "2025-05-28 09:16:13", "link": "http://arxiv.org/abs/2505.22149v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Polarforming Design with Phase Shifter Based Polarization Reconfigurable Antennas", "abstract": "In this paper, we propose a new form of polarization reconfigurable antennas\n(PRAs) that can form linear, circular, and general elliptical polarizations\nassisted by phase shifters (PSs). With PRAs, polarforming is achieved, which\nenables the antenna to shape its polarization into a desired state for aligning\nwith that of the received electromagnetic (EM) wave or reconfiguring that of\nthe transmit EM wave. To demonstrate the benefits of polarforming, we\ninvestigate a PRA-aided single-input single-output (SISO) communication system\nequipped with tunable PSs for polarization adaptation. We characterize the\nachievable signal-to-noise ratio (SNR) at the receiver as a function of the\nphase shifts of PS-based PRAs. Moreover, we develop an alternating optimization\napproach to maximize the SNR by optimizing the phase shifts at both the\ntransmitter and receiver. Finally, comprehensive simulation results are\npresented, which not only validate the effectiveness of polarforming in\nmitigating the channel depolarization effects, but also demonstrate its\nsubstantial performance improvement over conventional systems.", "published": "2025-05-28 05:36:05", "link": "http://arxiv.org/abs/2505.21990v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Target Localization with Coprime Multistatic MIMO Radar via Coupled Canonical Polyadic Decomposition Based on Joint Eigenvalue Decomposition", "abstract": "This paper investigates target localization using a multistatic\nmultiple-input multiple-output (MIMO) radar system with two distinct coprime\narray configurations: coprime L-shaped arrays and coprime planar arrays. The\nobserved signals are modeled as tensors that admit a coupled canonical polyadic\ndecomposition (C-CPD) model. For each configuration, a C-CPD method is\npresented based on joint eigenvalue decomposition (J-EVD). This computational\nframework includes (semi-)algebraic and optimization-based C-CPD algorithms and\ntarget localization that fuses direction-of-arrivals (DOAs) information to\ncalculate the optimal position of each target. Specifically, the proposed\n(semi-)algebraic methods exploit the rotational invariance of the Vandermonde\nstructure in coprime arrays, similar to the multiple invariance property of\n\\added{estimation of signal parameters via rotational invariance techniques}\n(ESPRIT), which transforms the model into a J-EVD problem and reduces\ncomputational complexity. The study also investigates the working conditions of\nthe algorithm to understand model identifiability. Additionally, the proposed\nmethod does not rely on prior knowledge of non-orthogonal probing waveforms and\nis effective in challenging underdetermined scenarios. Experimental results\ndemonstrate that our method outperforms existing tensor-based approaches in\nboth accuracy and computational efficiency.", "published": "2025-05-28 04:34:13", "link": "http://arxiv.org/abs/2505.21965v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CSI-Bench: A Large-Scale In-the-Wild Dataset for Multi-task WiFi Sensing", "abstract": "WiFi sensing has emerged as a compelling contactless modality for human\nactivity monitoring by capturing fine-grained variations in Channel State\nInformation (CSI). Its ability to operate continuously and non-intrusively\nwhile preserving user privacy makes it particularly suitable for health\nmonitoring. However, existing WiFi sensing systems struggle to generalize in\nreal-world settings, largely due to datasets collected in controlled\nenvironments with homogeneous hardware and fragmented, session-based recordings\nthat fail to reflect continuous daily activity.\n  We present CSI-Bench, a large-scale, in-the-wild benchmark dataset collected\nusing commercial WiFi edge devices across 26 diverse indoor environments with\n35 real users. Spanning over 461 hours of effective data, CSI-Bench captures\nrealistic signal variability under natural conditions. It includes\ntask-specific datasets for fall detection, breathing monitoring, localization,\nand motion source recognition, as well as a co-labeled multitask dataset with\njoint annotations for user identity, activity, and proximity. To support the\ndevelopment of robust and generalizable models, CSI-Bench provides standardized\nevaluation splits and baseline results for both single-task and multi-task\nlearning. CSI-Bench offers a foundation for scalable, privacy-preserving WiFi\nsensing systems in health and broader human-centric applications.", "published": "2025-05-28 01:29:29", "link": "http://arxiv.org/abs/2505.21866v1", "categories": ["eess.SP", "cs.AI", "cs.DB"], "primary_category": "eess.SP"}
{"title": "Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems", "abstract": "This paper presents a novel approach for unified retrieval-augmented\ngeneration (RAG) systems using the recent emerging large language model (LLM)\nagent concept. Specifically, Agent LLM, which utilizes LLM as fundamental\ncontrollers, has become a promising approach to enable the interpretability of\nRAG tasks, especially for complex reasoning question-answering systems (e.g.,\nmulti-hop queries). Nonetheless, previous works mainly focus on solving RAG\nsystems with either single-hop or multi-hop approaches separately, which limits\nthe application of those approaches to real-world applications. In this study,\nwe propose a trainable agent framework called Agent-UniRAG for unified\nretrieval-augmented LLM systems, which enhances the effectiveness and\ninterpretability of RAG systems. The main idea is to design an LLM agent\nframework to solve RAG tasks step-by-step based on the complexity of the\ninputs, simultaneously including single-hop and multi-hop queries in an\nend-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset\nto enable the proposed agent framework for small open-source LLMs (e.g.,\nLlama-3-8B). The results show comparable performances with closed-source and\nlarger open-source LLMs across various RAG benchmarks. Our source code and\ndataset are publicly available for further exploitation.", "published": "2025-05-28 16:46:31", "link": "http://arxiv.org/abs/2505.22571v2", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition", "abstract": "This work presents Pangu Embedded, an efficient Large Language Model (LLM)\nreasoner developed on Ascend Neural Processing Units (NPUs), featuring flexible\nfast and slow thinking capabilities. Pangu Embedded addresses the significant\ncomputational costs and inference latency challenges prevalent in existing\nreasoning-optimized LLMs. We propose a two-stage training framework for its\nconstruction. In Stage 1, the model is finetuned via an iterative distillation\nprocess, incorporating inter-iteration model merging to effectively aggregate\ncomplementary knowledge. This is followed by reinforcement learning on Ascend\nclusters, optimized by a latency-tolerant scheduler that combines stale\nsynchronous parallelism with prioritized data queues. The RL process is guided\nby a Multi-source Adaptive Reward System (MARS), which generates dynamic,\ntask-specific reward signals using deterministic metrics and lightweight LLM\nevaluators for mathematics, coding, and general problem-solving tasks. Stage 2\nintroduces a dual-system framework, endowing Pangu Embedded with a \"fast\" mode\nfor routine queries and a deeper \"slow\" mode for complex inference. This\nframework offers both manual mode switching for user control and an automatic,\ncomplexity-aware mode selection mechanism that dynamically allocates\ncomputational resources to balance latency and reasoning depth. Experimental\nresults on benchmarks including AIME 2024, GPQA, and LiveCodeBench demonstrate\nthat Pangu Embedded with 7B parameters, outperforms similar-size models like\nQwen3-8B and GLM4-9B. It delivers rapid responses and state-of-the-art\nreasoning quality within a single, unified model architecture, highlighting a\npromising direction for developing powerful yet practically deployable LLM\nreasoners.", "published": "2025-05-28 14:03:02", "link": "http://arxiv.org/abs/2505.22375v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Skywork Open Reasoner 1 Technical Report", "abstract": "The success of DeepSeek-R1 underscores the significant role of reinforcement\nlearning (RL) in enhancing the reasoning capabilities of large language models\n(LLMs). In this work, we present Skywork-OR1, an effective and scalable RL\nimplementation for long Chain-of-Thought (CoT) models. Building on the\nDeepSeek-R1-Distill model series, our RL approach achieves notable performance\ngains, increasing average accuracy across AIME24, AIME25, and LiveCodeBench\nfrom 57.8% to 72.8% (+15.0%) for the 32B model and from 43.6% to 57.5% (+13.9%)\nfor the 7B model. Our Skywork-OR1-32B model surpasses both DeepSeek-R1 and\nQwen3-32B on the AIME24 and AIME25 benchmarks, while achieving comparable\nresults on LiveCodeBench. The Skywork-OR1-7B and Skywork-OR1-Math-7B models\ndemonstrate competitive reasoning capabilities among models of similar size. We\nperform comprehensive ablation studies on the core components of our training\npipeline to validate their effectiveness. Additionally, we thoroughly\ninvestigate the phenomenon of entropy collapse, identify key factors affecting\nentropy dynamics, and demonstrate that mitigating premature entropy collapse is\ncritical for improved test performance. To support community research, we fully\nopen-source our model weights, training code, and training datasets.", "published": "2025-05-28 12:56:04", "link": "http://arxiv.org/abs/2505.22312v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design", "abstract": "Speculative decoding and quantization effectively accelerate memory-bound\ninference of large language models. Speculative decoding mitigates the memory\nbandwidth bottleneck by verifying multiple tokens within a single forward pass,\nwhich increases computational effort. Quantization achieves this optimization\nby compressing weights and activations into lower bit-widths and also reduces\ncomputations via low-bit matrix multiplications. To further leverage their\nstrengths, we investigate the integration of these two techniques.\nSurprisingly, experiments applying the advanced speculative decoding method\nEAGLE-2 to various quantized models reveal that the memory benefits from 4-bit\nweight quantization are diminished by the computational load from speculative\ndecoding. Specifically, verifying a tree-style draft incurs significantly more\ntime overhead than a single-token forward pass on 4-bit weight quantized\nmodels. This finding led to our new speculative decoding design: a hierarchical\nframework that employs a small model as an intermediate stage to turn\ntree-style drafts into sequence drafts, leveraging the memory access benefits\nof the target quantized model. Experimental results show that our hierarchical\napproach achieves a 2.78$\\times$ speedup across various tasks for the 4-bit\nweight Llama-3-70B model on an A100 GPU, outperforming EAGLE-2 by 1.31$\\times$.\nCode available at https://github.com/AI9Stars/SpecMQuant.", "published": "2025-05-28 09:55:08", "link": "http://arxiv.org/abs/2505.22179v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging", "abstract": "Brain-to-Image reconstruction aims to recover visual stimuli perceived by\nhumans from brain activity. However, the reconstructed visual stimuli often\nmissing details and semantic inconsistencies, which may be attributed to\ninsufficient semantic information. To address this issue, we propose an\napproach named Fine-grained Brain-to-Image reconstruction (FgB2I), which\nemploys fine-grained text as bridge to improve image reconstruction. FgB2I\ncomprises three key stages: detail enhancement, decoding fine-grained text\ndescriptions, and text-bridged brain-to-image reconstruction. In the\ndetail-enhancement stage, we leverage large vision-language models to generate\nfine-grained captions for visual stimuli and experimentally validate its\nimportance. We propose three reward metrics (object accuracy, text-image\nsemantic similarity, and image-image semantic similarity) to guide the language\nmodel in decoding fine-grained text descriptions from fMRI signals. The\nfine-grained text descriptions can be integrated into existing reconstruction\nmethods to achieve fine-grained Brain-to-Image reconstruction.", "published": "2025-05-28 09:16:44", "link": "http://arxiv.org/abs/2505.22150v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Improving Continual Pre-training Through Seamless Data Packing", "abstract": "Continual pre-training has demonstrated significant potential in enhancing\nmodel performance, particularly in domain-specific scenarios. The most common\napproach for packing data before continual pre-training involves concatenating\ninput texts and splitting them into fixed-length sequences. While\nstraightforward and efficient, this method often leads to excessive truncation\nand context discontinuity, which can hinder model performance. To address these\nissues, we explore the potential of data engineering to enhance continual\npre-training, particularly its impact on model performance and efficiency. We\npropose Seamless Packing (SP), a novel data packing strategy aimed at\npreserving contextual information more effectively and enhancing model\nperformance. Our approach employs a sliding window technique in the first stage\nthat synchronizes overlapping tokens across consecutive sequences, ensuring\nbetter continuity and contextual coherence. In the second stage, we adopt a\nFirst-Fit-Decreasing algorithm to pack shorter texts into bins slightly larger\nthan the target sequence length, thereby minimizing padding and truncation.\nEmpirical evaluations across various model architectures and corpus domains\ndemonstrate the effectiveness of our method, outperforming baseline method in\n99% of all settings. Code is available at\nhttps://github.com/Infernus-WIND/Seamless-Packing.", "published": "2025-05-28 06:30:37", "link": "http://arxiv.org/abs/2505.22018v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation", "abstract": "Text-to-image generation increasingly demands access to domain-specific,\nfine-grained, and rapidly evolving knowledge that pretrained models cannot\nfully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to\naddress this by retrieving globally relevant images, but they fail when no\nsingle image contains all desired elements from a complex user query. We\npropose Cross-modal RAG, a novel framework that decomposes both queries and\nimages into sub-dimensional components, enabling subquery-aware retrieval and\ngeneration. Our method introduces a hybrid retrieval strategy - combining a\nsub-dimensional sparse retriever with a dense retriever - to identify a\nPareto-optimal set of images, each contributing complementary aspects of the\nquery. During generation, a multimodal large language model is guided to\nselectively condition on relevant visual features aligned to specific\nsubqueries, ensuring subquery-aware image synthesis. Extensive experiments on\nMS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal\nRAG significantly outperforms existing baselines in both retrieval and\ngeneration quality, while maintaining high efficiency.", "published": "2025-05-28 04:09:49", "link": "http://arxiv.org/abs/2505.21956v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Maximizing Confidence Alone Improves Reasoning", "abstract": "Reinforcement learning (RL) has enabled machine learning models to achieve\nsignificant advances in many fields. Most recently, RL has empowered frontier\nlanguage models to solve challenging math, science, and coding problems.\nHowever, central to any RL algorithm is the reward function, and reward\nengineering is a notoriously difficult problem in any domain. In this paper, we\npropose RENT: Reinforcement Learning via Entropy Minimization -- a fully\nunsupervised RL method that requires no external reward or ground-truth\nanswers, and instead uses the model's entropy of its underlying distribution as\nan intrinsic reward. We find that by reinforcing the chains of thought that\nyield high model confidence on its generated answers, the model improves its\nreasoning ability. In our experiments, we showcase these improvements on an\nextensive suite of commonly-used reasoning benchmarks, including GSM8K,\nMATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen and\nMistral families. The generality of our unsupervised learning method lends\nitself to applicability in a wide range of domains where external supervision\nis unavailable.", "published": "2025-05-28 17:59:37", "link": "http://arxiv.org/abs/2505.22660v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Pre-training for Recommendation Unlearning", "abstract": "Modern recommender systems powered by Graph Neural Networks (GNNs) excel at\nmodeling complex user-item interactions, yet increasingly face scenarios\nrequiring selective forgetting of training data. Beyond user requests to remove\nspecific interactions due to privacy concerns or preference changes, regulatory\nframeworks mandate recommender systems' ability to eliminate the influence of\ncertain user data from models. This recommendation unlearning challenge\npresents unique difficulties as removing connections within interaction graphs\ncreates ripple effects throughout the model, potentially impacting\nrecommendations for numerous users. Traditional approaches suffer from\nsignificant drawbacks: fragmentation methods damage graph structure and\ndiminish performance, while influence function techniques make assumptions that\nmay not hold in complex GNNs, particularly with self-supervised or random\narchitectures. To address these limitations, we propose a novel model-agnostic\npre-training paradigm UnlearnRec that prepares systems for efficient unlearning\noperations. Our Influence Encoder takes unlearning requests together with\nexisting model parameters and directly produces updated parameters of unlearned\nmodel with little fine-tuning, avoiding complete retraining while preserving\nmodel performance characteristics. Extensive evaluation on public benchmarks\ndemonstrates that our method delivers exceptional unlearning effectiveness\nwhile providing more than 10x speedup compared to retraining approaches. We\nrelease our method implementation at: https://github.com/HKUDS/UnlearnRec.", "published": "2025-05-28 17:57:11", "link": "http://arxiv.org/abs/2505.22649v2", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control", "abstract": "Reinforcement learning (RL) has driven significant progress in robotics, but\nits complexity and long training times remain major bottlenecks. In this\nreport, we introduce FastTD3, a simple, fast, and capable RL algorithm that\nsignificantly speeds up training for humanoid robots in popular suites such as\nHumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably\nsimple: we train an off-policy TD3 agent with several modifications -- parallel\nsimulation, large-batch updates, a distributional critic, and carefully tuned\nhyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours\non a single A100 GPU, while remaining stable during training. We also provide a\nlightweight and easy-to-use implementation of FastTD3 to accelerate RL research\nin robotics.", "published": "2025-05-28 17:55:26", "link": "http://arxiv.org/abs/2505.22642v2", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "On the performance of machine-learning-assisted Monte Carlo in sampling from simple statistical physics models", "abstract": "Recent years have seen a rise in the application of machine learning\ntechniques to aid the simulation of hard-to-sample systems that cannot be\nstudied using traditional methods. Despite the introduction of many different\narchitectures and procedures, a wide theoretical understanding is still\nlacking, with the risk of suboptimal implementations. As a first step to\naddress this gap, we provide here a complete analytic study of the widely-used\nSequential Tempering procedure applied to a shallow MADE architecture for the\nCurie-Weiss model. The contribution of this work is twofold: firstly, we give a\ndescription of the optimal weights and of the training under Gradient Descent\noptimization. Secondly, we compare what happens in Sequential Tempering with\nand without the addition of local Metropolis Monte Carlo steps. We are thus\nable to give theoretical predictions on the best procedure to apply in this\ncase. This work establishes a clear theoretical basis for the integration of\nmachine learning techniques into Monte Carlo sampling and optimization.", "published": "2025-05-28 17:13:11", "link": "http://arxiv.org/abs/2505.22598v2", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.LG", "physics.comp-ph"], "primary_category": "cond-mat.dis-nn"}
{"title": "Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems", "abstract": "Large Language Model-based Multi-Agent Systems (MASs) have emerged as a\npowerful paradigm for tackling complex tasks through collaborative\nintelligence. Nevertheless, the question of how agents should be structurally\norganized for optimal cooperation remains largely unexplored. In this position\npaper, we aim to gently redirect the focus of the MAS research community toward\nthis critical dimension: develop topology-aware MASs for specific tasks.\nSpecifically, the system consists of three core components - agents,\ncommunication links, and communication patterns - that collectively shape its\ncoordination performance and efficiency. To this end, we introduce a\nsystematic, three-stage framework: agent selection, structure profiling, and\ntopology synthesis. Each stage would trigger new research opportunities in\nareas such as language models, reinforcement learning, graph learning, and\ngenerative modeling; together, they could unleash the full potential of MASs in\ncomplicated real-world applications. Then, we discuss the potential challenges\nand opportunities in the evaluation of multiple systems. We hope our\nperspective and framework can offer critical new insights in the era of agentic\nAI.", "published": "2025-05-28 15:20:09", "link": "http://arxiv.org/abs/2505.22467v2", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning", "abstract": "Continual Learning (CL) aims to enable models to continuously acquire new\nknowledge from a sequence of tasks with avoiding the forgetting of learned\ninformation. However, existing CL methods only rely on the parameters of the\nmost recent task for inference, which makes them susceptible to catastrophic\nforgetting. Inspired by the recent success of model merging techniques, we\npropose \\textbf{Perturb-and-Merge (P\\&M)}, a novel continual learning framework\nthat integrates model merging into the CL paradigm to mitigate forgetting.\nSpecifically, after training on each task, P\\&M constructs a new model by\nforming a convex combination of the previous model and the newly trained\ntask-specific model. Through theoretical analysis, we minimize the total loss\nincrease across all tasks and derive an analytical solution for the optimal\nmerging coefficient. To further improve the performance of the merged model, we\nobserve that the degradation introduced during merging can be alleviated by a\nregularization term composed of the task vector and the Hessian matrix of the\nloss function. Interestingly, we show that this term can be efficiently\napproximated using second-order symmetric finite differences, and a stochastic\nperturbation strategy along the task vector direction is accordingly devised\nwhich incurs no additional forward or backward passes while providing an\neffective approximation of the regularization term. Finally, we combine P\\&M\nwith LoRA, a parameter-efficient fine-tuning method, to reduce memory overhead.\nOur proposed approach achieves state-of-the-art performance on several\ncontinual learning benchmark datasets.", "published": "2025-05-28 14:14:19", "link": "http://arxiv.org/abs/2505.22389v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SplitLoRA: Balancing Stability and Plasticity in Continual Learning Through Gradient Space Splitting", "abstract": "Continual Learning requires a model to learn multiple tasks in sequence while\nmaintaining both stability:preserving knowledge from previously learned tasks,\nand plasticity:effectively learning new tasks. Gradient projection has emerged\nas an effective and popular paradigm in CL, where it partitions the gradient\nspace of previously learned tasks into two orthogonal subspaces: a primary\nsubspace and a minor subspace. New tasks are learned effectively within the\nminor subspace, thereby reducing interference with previously acquired\nknowledge. However, existing Gradient Projection methods struggle to achieve an\noptimal balance between plasticity and stability, as it is hard to\nappropriately partition the gradient space. In this work, we consider a\ncontinual learning paradigm based on Low-Rank Adaptation, which has gained\nconsiderable attention due to its efficiency and wide applicability, and\npropose a novel approach for continual learning, called SplitLoRA. We first\nprovide a theoretical analysis of how subspace partitioning affects model\nstability and plasticity. Informed by this analysis, we then introduce an\neffective method that derives the optimal partition of the gradient space for\npreviously learned tasks. This approach effectively balances stability and\nplasticity in continual learning. Experimental results on multiple datasets\ndemonstrate that the proposed method achieves state-of-the-art performance.", "published": "2025-05-28 13:57:56", "link": "http://arxiv.org/abs/2505.22370v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting", "abstract": "Recent deep learning approaches for river discharge forecasting have improved\nthe accuracy and efficiency in flood forecasting, enabling more reliable early\nwarning systems for risk management. Nevertheless, existing deep learning\napproaches in hydrology remain largely confined to local-scale applications and\ndo not leverage the inherent spatial connections of bodies of water. Thus,\nthere is a strong need for new deep learning methodologies that are capable of\nmodeling spatio-temporal relations to improve river discharge and flood\nforecasting for scientific and operational applications. To address this, we\npresent RiverMamba, a novel deep learning model that is pretrained with\nlong-term reanalysis data and that can forecast global river discharge and\nfloods on a $0.05^\\circ$ grid up to 7 days lead time, which is of high\nrelevance in early warning. To achieve this, RiverMamba leverages efficient\nMamba blocks that enable the model to capture global-scale channel network\nrouting and enhance its forecast capability for longer lead times. The forecast\nblocks integrate ECMWF HRES meteorological forecasts, while accounting for\ntheir inaccuracies through spatio-temporal modeling. Our analysis demonstrates\nthat RiverMamba delivers reliable predictions of river discharge, including\nextreme floods across return periods and lead times, surpassing both\noperational AI- and physics-based models.", "published": "2025-05-28 16:21:58", "link": "http://arxiv.org/abs/2505.22535v2", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Surf2CT: Cascaded 3D Flow Matching Models for Torso 3D CT Synthesis from Skin Surface", "abstract": "We present Surf2CT, a novel cascaded flow matching framework that synthesizes\nfull 3D computed tomography (CT) volumes of the human torso from external\nsurface scans and simple demographic data (age, sex, height, weight). This is\nthe first approach capable of generating realistic volumetric internal anatomy\nimages solely based on external body shape and demographics, without any\ninternal imaging. Surf2CT proceeds through three sequential stages: (1) Surface\nCompletion, reconstructing a complete signed distance function (SDF) from\npartial torso scans using conditional 3D flow matching; (2) Coarse CT\nSynthesis, generating a low-resolution CT volume from the completed SDF and\ndemographic information; and (3) CT Super-Resolution, refining the coarse\nvolume into a high-resolution CT via a patch-wise conditional flow model. Each\nstage utilizes a 3D-adapted EDM2 backbone trained via flow matching. We trained\nour model on a combined dataset of 3,198 torso CT scans (approximately 1.13\nmillion axial slices) sourced from Massachusetts General Hospital (MGH) and the\nAutoPET challenge. Evaluation on 700 paired torso surface-CT cases demonstrated\nstrong anatomical fidelity: organ volumes exhibited small mean percentage\ndifferences (range from -11.1% to 4.4%), and muscle/fat body composition\nmetrics matched ground truth with strong correlation (range from 0.67 to 0.96).\nLung localization had minimal bias (mean difference -2.5 mm), and surface\ncompletion significantly improved metrics (Chamfer distance: from 521.8 mm to\n2.7 mm; Intersection-over-Union: from 0.87 to 0.98). Surf2CT establishes a new\nparadigm for non-invasive internal anatomical imaging using only external data,\nopening opportunities for home-based healthcare, preventive medicine, and\npersonalized clinical assessments without the risks associated with\nconventional imaging techniques.", "published": "2025-05-28 16:01:36", "link": "http://arxiv.org/abs/2505.22511v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector", "abstract": "3D object detection is a critical component in autonomous driving systems. It\nallows real-time recognition and detection of vehicles, pedestrians and\nobstacles under varying environmental conditions. Among existing methods, 3D\nobject detection in the Bird's Eye View (BEV) has emerged as the mainstream\nframework. To guarantee a safe, robust and trustworthy 3D object detection, 3D\nadversarial attacks are investigated, where attacks are placed in 3D\nenvironments to evaluate the model performance, e.g. putting a film on a car,\nclothing a pedestrian. The vulnerability of 3D object detection models to 3D\nadversarial attacks serves as an important indicator to evaluate the robustness\nof the model against perturbations. To investigate this vulnerability, we\ngenerate non-invasive 3D adversarial objects tailored for real-world attack\nscenarios. Our method verifies the existence of universal adversarial objects\nthat are spatially consistent across time and camera views. Specifically, we\nemploy differentiable rendering techniques to accurately model the spatial\nrelationship between adversarial objects and the target vehicle. Furthermore,\nwe introduce an occlusion-aware module to enhance visual consistency and\nrealism under different viewpoints. To maintain attack effectiveness across\nmultiple frames, we design a BEV spatial feature-guided optimization strategy.\nExperimental results demonstrate that our approach can reliably suppress\nvehicle predictions from state-of-the-art 3D object detectors, serving as an\nimportant tool to test robustness of 3D object detection models before\ndeployment. Moreover, the generated adversarial objects exhibit strong\ngeneralization capabilities, retaining its effectiveness at various positions\nand distances in the scene.", "published": "2025-05-28 15:49:54", "link": "http://arxiv.org/abs/2505.22499v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels", "abstract": "3D occupancy prediction has attracted much attention in the field of\nautonomous driving due to its powerful geometric perception and object\nrecognition capabilities. However, existing methods have not explored the most\nessential distribution patterns of voxels, resulting in unsatisfactory results.\nThis paper first explores the inter-class distribution and geometric\ndistribution of voxels, thereby solving the long-tail problem caused by the\ninter-class distribution and the poor performance caused by the geometric\ndistribution. Specifically, this paper proposes SHTOcc (Sparse Head-Tail\nOccupancy), which uses sparse head-tail voxel construction to accurately\nidentify and balance key voxels in the head and tail classes, while using\ndecoupled learning to reduce the model's bias towards the dominant (head)\ncategory and enhance the focus on the tail class. Experiments show that\nsignificant improvements have been made on multiple baselines: SHTOcc reduces\nGPU memory usage by 42.2%, increases inference speed by 58.6%, and improves\naccuracy by about 7%, verifying its effectiveness and efficiency. The code is\navailable at https://github.com/ge95net/SHTOcc", "published": "2025-05-28 15:16:15", "link": "http://arxiv.org/abs/2505.22461v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control", "abstract": "Recent advancements in world models have revolutionized dynamic environment\nsimulation, allowing systems to foresee future states and assess potential\nactions. In autonomous driving, these capabilities help vehicles anticipate the\nbehavior of other road users, perform risk-aware planning, accelerate training\nin simulation, and adapt to novel scenarios, thereby enhancing safety and\nreliability. Current approaches exhibit deficiencies in maintaining robust 3D\ngeometric consistency or accumulating artifacts during occlusion handling, both\ncritical for reliable safety assessment in autonomous navigation tasks. To\naddress this, we introduce GeoDrive, which explicitly integrates robust 3D\ngeometry conditions into driving world models to enhance spatial understanding\nand action controllability. Specifically, we first extract a 3D representation\nfrom the input frame and then obtain its 2D rendering based on the\nuser-specified ego-car trajectory. To enable dynamic modeling, we propose a\ndynamic editing module during training to enhance the renderings by editing the\npositions of the vehicles. Extensive experiments demonstrate that our method\nsignificantly outperforms existing models in both action accuracy and 3D\nspatial awareness, leading to more realistic, adaptable, and reliable scene\nmodeling for safer autonomous driving. Additionally, our model can generalize\nto novel trajectories and offers interactive scene editing capabilities, such\nas object editing and object trajectory control.", "published": "2025-05-28 14:46:51", "link": "http://arxiv.org/abs/2505.22421v2", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "YH-MINER: Multimodal Intelligent System for Natural Ecological Reef Metric Extraction", "abstract": "Coral reefs, crucial for sustaining marine biodiversity and ecological\nprocesses (e.g., nutrient cycling, habitat provision), face escalating threats,\nunderscoring the need for efficient monitoring. Coral reef ecological\nmonitoring faces dual challenges of low efficiency in manual analysis and\ninsufficient segmentation accuracy in complex underwater scenarios. This study\ndevelops the YH-MINER system, establishing an intelligent framework centered on\nthe Multimodal Large Model (MLLM) for \"object detection-semantic\nsegmentation-prior input\". The system uses the object detection module\n(mAP@0.5=0.78) to generate spatial prior boxes for coral instances, driving the\nsegment module to complete pixel-level segmentation in low-light and densely\noccluded scenarios. The segmentation masks and finetuned classification\ninstructions are fed into the Qwen2-VL-based multimodal model as prior inputs,\nachieving a genus-level classification accuracy of 88% and simultaneously\nextracting core ecological metrics. Meanwhile, the system retains the\nscalability of the multimodal model through standardized interfaces, laying a\nfoundation for future integration into multimodal agent-based underwater robots\nand supporting the full-process automation of \"image acquisition-prior\ngeneration-real-time analysis\".", "published": "2025-05-28 11:36:18", "link": "http://arxiv.org/abs/2505.22250v2", "categories": ["cs.CV", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "Logical Consistency is Vital: Neural-Symbolic Information Retrieval for Negative-Constraint Queries", "abstract": "Information retrieval plays a crucial role in resource localization. Current\ndense retrievers retrieve the relevant documents within a corpus via embedding\nsimilarities, which compute similarities between dense vectors mainly depending\non word co-occurrence between queries and documents, but overlook the real\nquery intents.\n  Thus, they often retrieve numerous irrelevant documents. Particularly in the\nscenarios of complex queries such as \\emph{negative-constraint queries}, their\nretrieval performance could be catastrophic. To address the issue, we propose a\nneuro-symbolic information retrieval method, namely \\textbf{NS-IR}, that\nleverages first-order logic (FOL) to optimize the embeddings of naive natural\nlanguage by considering the \\emph{logical consistency} between queries and\ndocuments. Specifically, we introduce two novel techniques, \\emph{logic\nalignment} and \\emph{connective constraint}, to rerank candidate documents,\nthereby enhancing retrieval relevance.\n  Furthermore, we construct a new dataset \\textbf{NegConstraint} including\nnegative-constraint queries to evaluate our NS-IR's performance on such complex\nIR scenarios.\n  Our extensive experiments demonstrate that NS-IR not only achieves superior\nzero-shot retrieval performance on web search and low-resource retrieval tasks,\nbut also performs better on negative-constraint queries. Our scource code and\ndataset are available at https://github.com/xgl-git/NS-IR-main.", "published": "2025-05-28 12:37:09", "link": "http://arxiv.org/abs/2505.22299v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Numerical Optimization Strategies for the Variational Hamiltonian Ansatz in Noisy Quantum Environments", "abstract": "We conduct a benchmark of eight optimization algorithms for variational\nquantum chemistry using the tVHA, evaluating performance on $H_2$, $H_4$, and\n$LiH$ (in both full and active spaces) under noiseless and sampling noise\nconditions. Sampling noise fundamentally alters optimizer behavior, with\ngradient-based methods performing best in ideal conditions, while\npopulation-based algorithms, such as CMA-ES, show greater resilience under\nnoise. Hartree-Fock initialization reduces the number of function evaluations\nby 27-60% and consistently yields higher final accuracy compared to random\nstarting points. We identify a precision limit set by sampling noise, with\ndiminishing returns beyond approximately 1000 shots.", "published": "2025-05-28 14:26:04", "link": "http://arxiv.org/abs/2505.22398v2", "categories": ["quant-ph", "cs.NA", "math.NA", "65Zxx"], "primary_category": "quant-ph"}
{"title": "The only Class 0 Flower snark is the smallest", "abstract": "Graph pebbling is a game played on graphs with pebbles on their vertices. A\npebbling move removes two pebbles from one vertex and places one pebble on an\nadjacent vertex. The pebbling number is the smallest $t$ so that from any\ninitial configuration of $t$ pebbles it is possible, after a sequence of\npebbling moves, to place a pebble on any given target vertex. Graphs whose\npebbling number is equal to the number of vertices are called Class~$0$ and\nprovide a challenging set of graphs that resist being characterized. In this\nnote, we answer a question recently proposed by the pioneering study on the\npebbling number of snark graphs: we prove that the smallest Flower snark $J_3$\nis Class~$0$, establishing that $J_3$ is in fact the only Class~$0$ Flower\nsnark.", "published": "2025-05-28 23:45:27", "link": "http://arxiv.org/abs/2505.22941v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Monotone Bounded-Depth Complexity of Homomorphism Polynomials", "abstract": "For every fixed graph $H$, it is known that homomorphism counts from $H$ and\ncolorful $H$-subgraph counts can be determined in $O(n^{t+1})$ time on\n$n$-vertex input graphs $G$, where $t$ is the treewidth of $H$. On the other\nhand, a running time of $n^{o(t / \\log t)}$ would refute the exponential-time\nhypothesis. Komarath, Pandey and Rahul (Algorithmica, 2023) studied algebraic\nvariants of these counting problems, i.e., homomorphism and subgraph\n$\\textit{polynomials}$ for fixed graphs $H$. These polynomials are weighted\nsums over the objects counted above, where each object is weighted by the\nproduct of variables corresponding to edges contained in the object. As shown\nby Komarath et al., the $\\textit{monotone}$ circuit complexity of the\nhomomorphism polynomial for $H$ is $\\Theta(n^{\\mathrm{tw}(H)+1})$.\n  In this paper, we characterize the power of monotone $\\textit{bounded-depth}$\ncircuits for homomorphism and colorful subgraph polynomials. This leads us to\ndiscover a natural hierarchy of graph parameters $\\mathrm{tw}_\\Delta(H)$, for\nfixed $\\Delta \\in \\mathbb N$, which capture the width of tree-decompositions\nfor $H$ when the underlying tree is required to have depth at most $\\Delta$. We\nprove that monotone circuits of product-depth $\\Delta$ computing the\nhomomorphism polynomial for $H$ require size\n$\\Theta(n^{\\mathrm{tw}_\\Delta(H^{\\dagger})+1})$, where $H^{\\dagger}$ is the\ngraph obtained from $H$ by removing all degree-$1$ vertices. This allows us to\nderive an optimal depth hierarchy theorem for monotone bounded-depth circuits\nthrough graph-theoretic arguments.", "published": "2025-05-28 21:56:54", "link": "http://arxiv.org/abs/2505.22894v1", "categories": ["cs.CC", "cs.DM"], "primary_category": "cs.CC"}
{"title": "Assembly in Directed Hypergraphs", "abstract": "Assembly theory has received considerable attention in the recent past. Here\nwe analyze the formal framework of this model and show that assembly pathways\ncoincide with certain minimal hyperpaths in B-hypergraphs. This makes it\npossible to generalize the notion of assembly to general chemical reaction\nsystems and to make explicit the connection to rule based models of chemistry,\nin particular DPO graph rewriting. We observe, furthermore, that assembly\ntheory is closely related to retrosynthetic analysis in chemistry. The assembly\nindex fits seamlessly into a large family of cost measures for directed\nhyperpath problems that also encompasses cost functions used in computational\nsynthesis planning. This allows to devise a generic approach to compute\ncomplexity measures derived from minimal hyperpaths in rule-derived directed\nhypergraphs using integer linear programming.", "published": "2025-05-28 20:10:22", "link": "http://arxiv.org/abs/2505.22826v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "From Signed Networks to Group Graphs", "abstract": "I show that when there is a symmetry in a process defined on the nodes of a\nnetwork, this can be captured by a new structure, the ``group graph'', in which\ngroup elements label the links of a network. I show that group graphs are a\ngeneralisation of signed networks which are an example of a $Z_2$ group graph.\nI also show that the concept of balance in signed networks can be generalised\nto group graphs. Finally, I show how the dynamics of processes on a consistent\ngroup graph are completely controlled by the topology of the underlying\nnetwork, not by the symmetry group. This generalises recent results on signed\nnetworks (Tian and Lambiotte, 2024a) and complex networks (Tian and Lambiotte,\n2024b).", "published": "2025-05-28 19:23:41", "link": "http://arxiv.org/abs/2505.22802v1", "categories": ["physics.soc-ph", "cs.DM", "cs.SI"], "primary_category": "physics.soc-ph"}
{"title": "Distribution free M-estimation", "abstract": "The basic question of delineating those statistical problems that are\nsolvable without making any assumptions on the underlying data distribution has\nlong animated statistics and learning theory. This paper characterizes when a\n(univariate) convex M-estimation or stochastic optimization problem is solvable\nin such an assumption-free setting, providing a precise dividing line between\nsolvable and unsolvable problems. The conditions we identify show, perhaps\nsurprisingly, that Lipschitz continuity of the loss being minimized is not\nnecessary for distribution free minimization, and they are also distinct from\nclassical characterizations of learnability in machine learning.", "published": "2025-05-28 19:33:12", "link": "http://arxiv.org/abs/2505.22807v1", "categories": ["math.ST", "cs.IT", "cs.LG", "math.IT", "stat.TH"], "primary_category": "math.ST"}
{"title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems", "abstract": "Manufacturing environments are becoming more complex and unpredictable due to\nfactors such as demand variations and shorter product lifespans. This\ncomplexity requires real-time decision-making and adaptation to disruptions.\nTraditional control approaches highlight the need for advanced control\nstrategies capable of overcoming unforeseen challenges, as they demonstrate\nlimitations in responsiveness within dynamic industrial settings. Multi-agent\nsystems address these challenges through decentralization of decision-making,\nenabling systems to respond dynamically to operational changes. However,\ncurrent multi-agent systems encounter challenges related to real-time\nadaptation, context-aware decision-making, and the dynamic exploration of\nresource capabilities. Large language models provide the possibility to\novercome these limitations through context-aware decision-making capabilities.\nThis paper introduces a large language model-enabled control architecture for\nmulti-agent manufacturing systems to dynamically explore resource capabilities\nin response to real-time disruptions. A simulation-based case study\ndemonstrates that the proposed architecture improves system resilience and\nflexibility. The case study findings show improved throughput and efficient\nresource utilization compared to existing approaches.", "published": "2025-05-28 19:43:12", "link": "http://arxiv.org/abs/2505.22814v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large Language Models", "abstract": "Recent manufacturing systems are increasingly adopting multi-robot\ncollaboration to handle complex and dynamic environments. While multi-agent\narchitectures support decentralized coordination among robot agents, they often\nface challenges in enabling real-time adaptability for unexpected disruptions\nwithout predefined rules. Recent advances in large language models offer new\nopportunities for context-aware decision-making to enable adaptive responses to\nunexpected changes. This paper presents an initial exploratory implementation\nof a large language model-enabled control framework for dynamic task\nreassignment in multi-robot manufacturing systems. A central controller agent\nleverages the large language model's ability to interpret structured robot\nconfiguration data and generate valid reassignments in response to robot\nfailures. Experiments in a real-world setup demonstrate high task success rates\nin recovering from failures, highlighting the potential of this approach to\nimprove adaptability in multi-robot manufacturing systems.", "published": "2025-05-28 19:26:07", "link": "http://arxiv.org/abs/2505.22804v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields", "abstract": "We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent\nPath Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of\nagents must move to their goal locations without collisions, whereas in LMAPF,\nnew goals are generated upon arrival. We propose methods for incorporating APFs\nin a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and\nPriority Inheritance with Backtracking (PIBT). Experimental results show that\nusing APF is not beneficial for MAPF but yields up to a 7-fold increase in\noverall system throughput for LMAPF.", "published": "2025-05-28 18:13:10", "link": "http://arxiv.org/abs/2505.22753v1", "categories": ["cs.AI", "cs.MA", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Defining Foundation Models for Computational Science: A Call for Clarity and Rigor", "abstract": "The widespread success of foundation models in natural language processing\nand computer vision has inspired researchers to extend the concept to\nscientific machine learning and computational science. However, this position\npaper argues that as the term \"foundation model\" is an evolving concept, its\napplication in computational science is increasingly used without a universally\naccepted definition, potentially creating confusion and diluting its precise\nscientific meaning. In this paper, we address this gap by proposing a formal\ndefinition of foundation models in computational science, grounded in the core\nvalues of generality, reusability, and scalability. We articulate a set of\nessential and desirable characteristics that such models must exhibit, drawing\nparallels with traditional foundational methods, like the finite element and\nfinite volume methods. Furthermore, we introduce the Data-Driven Finite Element\nMethod (DD-FEM), a framework that fuses the modular structure of classical FEM\nwith the representational power of data-driven learning. We demonstrate how\nDD-FEM addresses many of the key challenges in realizing foundation models for\ncomputational science, including scalability, adaptability, and physics\nconsistency. By bridging traditional numerical methods with modern AI\nparadigms, this work provides a rigorous foundation for evaluating and\ndeveloping novel approaches toward future foundation models in computational\nscience.", "published": "2025-05-28 22:10:16", "link": "http://arxiv.org/abs/2505.22904v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Physics-Infused Reduced-Order Modeling for Analysis of Multi-Layered Hypersonic Thermal Protection Systems", "abstract": "This work presents a physics-infused reduced-order modeling (PIROM) framework\nfor efficient and accurate prediction of transient thermal behavior in\nmulti-layered hypersonic thermal protection systems (TPS). The PIROM\narchitecture integrates a reduced-physics backbone, based on the\nlumped-capacitance model (LCM), with data-driven correction dynamics formulated\nvia a coarse-graining approach rooted in the Mori-Zwanzig formalism. While the\nLCM captures the dominant heat transfer mechanisms, the correction terms\ncompensate for residual dynamics arising from higher-order non-linear\ninteractions and heterogeneities across material layers. The proposed PIROM is\nbenchmarked against two non-intrusive reduced-order models (ROMs): Operator\nInference (OpInf) and Neural Ordinary Differential Equations (NODE). The PIROM\nconsistently achieves errors below 1% for a wide range of extrapolative\nsettings involving time- and space-dependent boundary conditions and\ntemperature-varying material property perturbations. In contrast, OpInf\nexhibits moderate degradation, and NODE suffers substantial loss in accuracy\ndue to its lack of embedded physics. Despite higher training costs, PIROM\ndelivers online evaluations of two orders of magnitude faster than the\nfull-order model. These results demonstrate that PIROM effectively reconciles\nthe trade-offs between accuracy, generalizability, and efficiency, providing a\nrobust framework for thermal modeling of TPS under diverse operating\nconditions.", "published": "2025-05-28 21:46:19", "link": "http://arxiv.org/abs/2505.22890v1", "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "primary_category": "physics.comp-ph"}
{"title": "Fast Trajectory-Independent Model-Based Reconstruction Algorithm for Multi-Dimensional Magnetic Particle Imaging", "abstract": "Magnetic Particle Imaging (MPI) is a promising tomographic technique for\nvisualizing the spatio-temporal distribution of superparamagnetic\nnanoparticles, with applications ranging from cancer detection to real-time\ncardiovascular monitoring. Traditional MPI reconstruction relies on either\ntime-consuming calibration (measured system matrix) or model-based simulation\nof the forward operator. Recent developments have shown the applicability of\nChebyshev polynomials to multi-dimensional Lissajous Field-Free Point (FFP)\nscans. This method is bound to the particular choice of sinusoidal scanning\ntrajectories. In this paper, we present the first reconstruction on real 2D MPI\ndata with a trajectory-independent model-based MPI reconstruction algorithm. We\nfurther develop the zero-shot Plug-and-Play (PnP) algorithm of the authors --\nwith automatic noise level estimation -- to address the present deconvolution\nproblem, leveraging a state-of-the-art denoiser trained on natural images\nwithout retraining on MPI-specific data. We evaluate our method on the publicly\navailable 2D FFP MPI dataset ``MPIdata: Equilibrium Model with Anisotropy\",\nfeaturing scans of six phantoms acquired using a Bruker preclinical scanner.\nMoreover, we show reconstruction performed on custom data on a 2D scanner with\nadditional high-frequency excitation field and partial data. Our results\ndemonstrate strong reconstruction capabilities across different scanning\nscenarios -- setting a precedent for general-purpose, flexible model-based MPI\nreconstruction.", "published": "2025-05-28 19:13:46", "link": "http://arxiv.org/abs/2505.22797v1", "categories": ["cs.CV", "cs.NA", "math.NA", "physics.med-ph"], "primary_category": "cs.CV"}
{"title": "Model-Free Deep Hedging with Transaction Costs and Light Data Requirements", "abstract": "Option pricing theory, such as the Black and Scholes (1973) model, provides\nan explicit solution to construct a strategy that perfectly hedges an option in\na continuous-time setting. In practice, however, trading occurs in discrete\ntime and often involves transaction costs, making the direct application of\ncontinuous-time solutions potentially suboptimal. Previous studies, such as\nthose by Buehler et al. (2018), Buehler et al. (2019) and Cao et al. (2019),\nhave shown that deep learning or reinforcement learning can be used to derive\nbetter hedging strategies than those based on continuous-time models. However,\nthese approaches typically rely on a large number of trajectories (of the order\nof $10^5$ or $10^6$) to train the model. In this work, we show that using as\nfew as 256 trajectories is sufficient to train a neural network that\nsignificantly outperforms, in the Geometric Brownian Motion framework, both the\nclassical Black & Scholes formula and the Leland model, which is arguably one\nof the most effective explicit alternatives for incorporating transaction\ncosts. The ability to train neural networks with such a small number of\ntrajectories suggests the potential for more practical and simple\nimplementation on real-time financial series.", "published": "2025-05-28 20:16:07", "link": "http://arxiv.org/abs/2505.22836v1", "categories": ["q-fin.MF", "q-fin.ST"], "primary_category": "q-fin.MF"}
{"title": "Smart Surrogate Losses for Contextual Stochastic Linear Optimization with Robust Constraints", "abstract": "We study an extension of contextual stochastic linear optimization (CSLO)\nthat, in contrast to most of the existing literature, involves inequality\nconstraints that depend on uncertain parameters predicted by a machine learning\nmodel. To handle the constraint uncertainty, we use contextual uncertainty sets\nconstructed via methods like conformal prediction. Given a contextual\nuncertainty set method, we introduce the \"Smart Predict-then-Optimize with\nRobust Constraints\" (SPO-RC) loss, a feasibility-sensitive adaptation of the\nSPO loss that measures decision error of predicted objective parameters. We\nalso introduce a convex surrogate, SPO-RC+, and prove Fisher consistency with\nSPO-RC. To enhance performance, we train on truncated datasets where true\nconstraint parameters lie within the uncertainty sets, and we correct the\ninduced sample selection bias using importance reweighting techniques. Through\nexperiments on fractional knapsack and alloy production problem instances, we\ndemonstrate that SPO-RC+ effectively handles uncertainty in constraints and\nthat combining truncation with importance reweighting can further improve\nperformance.", "published": "2025-05-28 21:29:40", "link": "http://arxiv.org/abs/2505.22881v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Forecasting Residential Heating and Electricity Demand with Scalable, High-Resolution, Open-Source Models", "abstract": "We present a novel framework for high-resolution forecasting of residential\nheating and electricity demand using probabilistic deep learning models. We\nfocus specifically on providing hourly building-level electricity and heating\ndemand forecasts for the residential sector. Leveraging multimodal\nbuilding-level information -- including data on building footprint areas,\nheights, nearby building density, nearby building size, land use patterns, and\nhigh-resolution weather data -- and probabilistic modeling, our methods provide\ngranular insights into demand heterogeneity. Validation at the building level\nunderscores a step change improvement in performance relative to NREL's\nResStock model, which has emerged as a research community standard for\nresidential heating and electricity demand characterization. In building-level\nheating and electricity estimation backtests, our probabilistic models\nrespectively achieve RMSE scores 18.3\\% and 35.1\\% lower than those based on\nResStock. By offering an open-source, scalable, high-resolution platform for\ndemand estimation and forecasting, this research advances the tools available\nfor policymakers and grid planners, contributing to the broader effort to\ndecarbonize the U.S. building stock and meeting climate objectives.", "published": "2025-05-28 21:16:27", "link": "http://arxiv.org/abs/2505.22873v1", "categories": ["econ.GN", "q-fin.EC", "stat.ML"], "primary_category": "econ.GN"}
{"title": "Kernel-Smoothed Scores for Denoising Diffusion: A Bias-Variance Study", "abstract": "Diffusion models now set the benchmark in high-fidelity generative sampling,\nyet they can, in principle, be prone to memorization. In this case, their\nlearned score overfits the finite dataset so that the reverse-time SDE samples\nare mostly training points. In this paper, we interpret the empirical score as\na noisy version of the true score and show that its covariance matrix is\nasymptotically a re-weighted data PCA. In large dimension, the small time limit\nmakes the noise variance blow up while simultaneously reducing spatial\ncorrelation. To reduce this variance, we introduce a kernel-smoothed empirical\nscore and analyze its bias-variance trade-off. We derive asymptotic bounds on\nthe Kullback-Leibler divergence between the true distribution and the one\ngenerated by the modified reverse SDE. Regularization on the score has the same\neffect as increasing the size of the training dataset, and thus helps prevent\nmemorization. A spectral decomposition of the forward diffusion suggests better\nvariance control under some regularity conditions of the true data\ndistribution. Reverse diffusion with kernel-smoothed empirical score can be\nreformulated as a gradient descent drifted toward a Log-Exponential\nDouble-Kernel Density Estimator (LED-KDE). This perspective highlights two\nregularization mechanisms taking place in denoising diffusions: an initial\nGaussian kernel first diffuses mass isotropically in the ambient space, while a\nsecond kernel applied in score space concentrates and spreads that mass along\nthe data manifold. Hence, even a straightforward regularization-without any\nlearning-already mitigates memorization and enhances generalization.\nNumerically, we illustrate our results with several experiments on synthetic\nand MNIST datasets.", "published": "2025-05-28 20:22:18", "link": "http://arxiv.org/abs/2505.22841v1", "categories": ["cs.LG", "math.PR", "stat.ML", "G.3; I.2.6"], "primary_category": "cs.LG"}
{"title": "Highly Efficient and Effective LLMs with Multi-Boolean Architectures", "abstract": "Weight binarization has emerged as a promising strategy to drastically reduce\nthe complexity of large language models (LLMs). It is mainly classified into\ntwo approaches: post-training binarization and finetuning with training-aware\nbinarization methods. The first approach, while having low complexity, leads to\nsignificant loss of information from the original LLMs, resulting in poor\nperformance. The second approach, on the other hand, relies heavily on\nfull-precision latent weights for gradient approximation of binary weights,\nwhich not only remains suboptimal but also introduces substantial complexity.\nIn this paper, we introduce a novel framework that effectively transforms LLMs\ninto multi-kernel Boolean parameters, for the first time, finetunes them\ndirectly in the Boolean domain, eliminating the need for expensive latent\nweights. This significantly reduces complexity during both finetuning and\ninference. Through extensive and insightful experiments across a wide range of\nLLMs, we demonstrate that our method outperforms recent ultra low-bit\nquantization and binarization methods.", "published": "2025-05-28 19:40:34", "link": "http://arxiv.org/abs/2505.22811v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Finite-Sample Convergence Bounds for Trust Region Policy Optimization in Mean-Field Games", "abstract": "We introduce Mean-Field Trust Region Policy Optimization (MF-TRPO), a novel\nalgorithm designed to compute approximate Nash equilibria for ergodic\nMean-Field Games (MFG) in finite state-action spaces. Building on the\nwell-established performance of TRPO in the reinforcement learning (RL)\nsetting, we extend its methodology to the MFG framework, leveraging its\nstability and robustness in policy optimization. Under standard assumptions in\nthe MFG literature, we provide a rigorous analysis of MF-TRPO, establishing\ntheoretical guarantees on its convergence. Our results cover both the exact\nformulation of the algorithm and its sample-based counterpart, where we derive\nhigh-probability guarantees and finite sample complexity. This work advances\nMFG optimization by bridging RL techniques with mean-field decision-making,\noffering a theoretically grounded approach to solving complex multi-agent\nproblems.", "published": "2025-05-28 18:50:25", "link": "http://arxiv.org/abs/2505.22781v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Private Rate-Constrained Optimization with Applications to Fair Learning", "abstract": "Many problems in trustworthy ML can be formulated as minimization of the\nmodel error under constraints on the prediction rates of the model for\nsuitably-chosen marginals, including most group fairness constraints\n(demographic parity, equality of odds, etc.). In this work, we study such\nconstrained minimization problems under differential privacy (DP). Standard DP\noptimization techniques like DP-SGD rely on the loss function's decomposability\ninto per-sample contributions. However, rate constraints introduce inter-sample\ndependencies, violating the decomposability requirement. To address this, we\ndevelop RaCO-DP, a DP variant of the Stochastic Gradient Descent-Ascent (SGDA)\nalgorithm which solves the Lagrangian formulation of rate constraint problems.\nWe demonstrate that the additional privacy cost of incorporating these\nconstraints reduces to privately estimating a histogram over the mini-batch at\neach optimization step. We prove the convergence of our algorithm through a\nnovel analysis of SGDA that leverages the linear structure of the dual\nparameter. Finally, empirical results on learning under group fairness\nconstraints demonstrate that our method Pareto-dominates existing private\nlearning approaches in fairness-utility trade-offs.", "published": "2025-05-28 17:55:01", "link": "http://arxiv.org/abs/2505.22703v1", "categories": ["cs.LG", "cs.CR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Investigating the effectiveness of multimodal data in forecasting SARS-COV-2 case surges", "abstract": "The COVID-19 pandemic response relied heavily on statistical and machine\nlearning models to predict key outcomes such as case prevalence and fatality\nrates. These predictions were instrumental in enabling timely public health\ninterventions that helped break transmission cycles. While most existing models\nare grounded in traditional epidemiological data, the potential of alternative\ndatasets, such as those derived from genomic information and human behavior,\nremains underexplored. In the current study, we investigated the usefulness of\ndiverse modalities of feature sets in predicting case surges. Our results\nhighlight the relative effectiveness of biological (e.g., mutations), public\nhealth (e.g., case counts, policy interventions) and human behavioral features\n(e.g., mobility and social media conversations) in predicting country-level\ncase surges. Importantly, we uncover considerable heterogeneity in predictive\nperformance across countries and feature modalities, suggesting that surge\nprediction models may need to be tailored to specific national contexts and\npandemic phases. Overall, our work highlights the value of integrating\nalternative data sources into existing disease surveillance frameworks to\nenhance the prediction of pandemic dynamics.", "published": "2025-05-28 01:00:02", "link": "http://arxiv.org/abs/2505.22688v1", "categories": ["q-bio.QM", "cs.LG", "stat.ML"], "primary_category": "q-bio.QM"}
{"title": "NGPU-LM: GPU-Accelerated N-Gram Language Model for Context-Biasing in Greedy ASR Decoding", "abstract": "Statistical n-gram language models are widely used for context-biasing tasks\nin Automatic Speech Recognition (ASR). However, existing implementations lack\ncomputational efficiency due to poor parallelization, making context-biasing\nless appealing for industrial use. This work rethinks data structures for\nstatistical n-gram language models to enable fast and parallel operations for\nGPU-optimized inference. Our approach, named NGPU-LM, introduces customizable\ngreedy decoding for all major ASR model types - including transducers,\nattention encoder-decoder models, and CTC - with less than 7% computational\noverhead. The proposed approach can eliminate more than 50% of the accuracy gap\nbetween greedy and beam search for out-of-domain scenarios while avoiding\nsignificant slowdown caused by beam search. The implementation of the proposed\nNGPU-LM is open-sourced.", "published": "2025-05-28 20:43:10", "link": "http://arxiv.org/abs/2505.22857v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "StressTest: Can YOUR Speech LM Handle the Stress?", "abstract": "Sentence stress refers to emphasis, placed on specific words within a spoken\nutterance to highlight or contrast an idea, or to introduce new information. It\nis often used to imply an underlying intention that is not explicitly stated.\nRecent advances in speech-aware language models (SLMs) have enabled direct\nprocessing of audio, allowing models to bypass transcription and access the\nfull richness of the speech signal and perform audio reasoning tasks such as\nspoken question answering. Despite the crucial role of sentence stress in\nshaping meaning and speaker intent, it remains largely overlooked in evaluation\nand development of such models. In this work, we address this gap by\nintroducing StressTest, a benchmark specifically designed to evaluate a model's\nability to distinguish between interpretations of spoken sentences based on the\nstress pattern. We assess the performance of several leading SLMs and find\nthat, despite their overall capabilities, they perform poorly on such tasks. To\novercome this limitation, we propose a novel synthetic data generation\npipeline, and create Stress17k, a training set that simulates change of meaning\nimplied by stress variation. Then, we empirically show that optimizing models\nwith this synthetic dataset aligns well with real-world recordings and enables\neffective finetuning of SLMs. Results suggest, that our finetuned model,\nStresSLM, significantly outperforms existing models on both sentence stress\nreasoning and detection tasks. Code, models, data, and audio samples -\npages.cs.huji.ac.il/adiyoss-lab/stresstest.", "published": "2025-05-28 18:32:56", "link": "http://arxiv.org/abs/2505.22765v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Flexure-FET-Based Receiver with Competitive Binding for Interference Mitigation in Molecular Communication", "abstract": "Molecular communication (MC), a biologically inspired technology, enables\napplications in nanonetworks and the Internet of Everything (IoE), with great\npotential for intra-body systems such as drug delivery, health monitoring, and\ndisease detection. This paper extends our prior work on the Flexure-FET MC\nreceiver by integrating a competitive binding model to enhance performance in\nhigh-interference environments, where multiple molecular species coexist in the\nreception space. Previous studies have largely focused on ligand concentration\nestimation and detection, without fully addressing the effects of inter-species\ncompetition for receptor binding. Our proposed framework captures this\ncompetition, offering a more biologically accurate model for multitarget\nenvironments. By incorporating competition dynamics, the model improves\nunderstanding of MC behavior under interference. This approach enables\nfine-tuning of receptor responses by adjusting ligand concentrations and\nreceptor affinities, thereby optimizing the performance of the Flexure-FET MC\nreceiver. Comprehensive analysis shows that accounting for competitive binding\nis crucial for improving reliability and accuracy in complex MC systems.\nFactors such as signal-to-noise ratio (SNR), symbol error probability (SEP),\ninterferer concentration, and receptor dynamics are shown to significantly\naffect performance. The proposed framework highlights the need to manage these\nfactors effectively. Results demonstrate that modeling interference through\ncompetitive binding offers a realistic system perspective and allows tuning of\nreceiver response, enabling robust detection in environments with multiple\ncoexisting species.", "published": "2025-05-28 20:33:31", "link": "http://arxiv.org/abs/2505.22849v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Temporal Convolutional Autoencoder for Interference Mitigation in FMCW Radar Altimeters", "abstract": "We investigate the end-to-end altitude estimation performance of a\nconvolutional autoencoder-based interference mitigation approach for\nfrequency-modulated continuous-wave (FMCW) radar altimeters. Specifically, we\nshow that a Temporal Convolutional Network (TCN) autoencoder effectively\nexploits temporal correlations in the received signal, providing superior\ninterference suppression compared to a Least Mean Squares (LMS) adaptive\nfilter. Unlike existing approaches, the present method operates directly on the\nreceived FMCW signal. Additionally, we identify key challenges in applying deep\nlearning to wideband FMCW interference mitigation and outline directions for\nfuture research to enhance real-time feasibility and generalization to\narbitrary interference conditions.", "published": "2025-05-28 18:52:10", "link": "http://arxiv.org/abs/2505.22783v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models", "abstract": "Binaural rendering aims to synthesize binaural audio that mimics natural\nhearing based on a mono audio and the locations of the speaker and listener.\nAlthough many methods have been proposed to solve this problem, they struggle\nwith rendering quality and streamable inference. Synthesizing high-quality\nbinaural audio that is indistinguishable from real-world recordings requires\nprecise modeling of binaural cues, room reverb, and ambient sounds.\nAdditionally, real-world applications demand streaming inference. To address\nthese challenges, we propose a flow matching based streaming binaural speech\nsynthesis framework called BinauralFlow. We consider binaural rendering to be a\ngeneration problem rather than a regression problem and design a conditional\nflow matching model to render high-quality audio. Moreover, we design a causal\nU-Net architecture that estimates the current audio frame solely based on past\ninformation to tailor generative models for streaming inference. Finally, we\nintroduce a continuous inference pipeline incorporating streaming STFT/ISTFT\noperations, a buffer bank, a midpoint solver, and an early skip schedule to\nimprove rendering continuity and speed. Quantitative and qualitative\nevaluations demonstrate the superiority of our method over SOTA approaches. A\nperceptual study further reveals that our model is nearly indistinguishable\nfrom real-world recordings, with a $42\\%$ confusion rate.", "published": "2025-05-28 20:59:15", "link": "http://arxiv.org/abs/2505.22865v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems", "abstract": "This paper presents a novel approach for unified retrieval-augmented\ngeneration (RAG) systems using the recent emerging large language model (LLM)\nagent concept. Specifically, Agent LLM, which utilizes LLM as fundamental\ncontrollers, has become a promising approach to enable the interpretability of\nRAG tasks, especially for complex reasoning question-answering systems (e.g.,\nmulti-hop queries). Nonetheless, previous works mainly focus on solving RAG\nsystems with either single-hop or multi-hop approaches separately, which limits\nthe application of those approaches to real-world applications. In this study,\nwe propose a trainable agent framework called Agent-UniRAG for unified\nretrieval-augmented LLM systems, which enhances the effectiveness and\ninterpretability of RAG systems. The main idea is to design an LLM agent\nframework to solve RAG tasks step-by-step based on the complexity of the\ninputs, simultaneously including single-hop and multi-hop queries in an\nend-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset\nto enable the proposed agent framework for small open-source LLMs (e.g.,\nLlama-3-8B). The results show comparable performances with closed-source and\nlarger open-source LLMs across various RAG benchmarks. Our source code and\ndataset are publicly available for further exploitation.", "published": "2025-05-28 16:46:31", "link": "http://arxiv.org/abs/2505.22571v3", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Defining Foundation Models for Computational Science: A Call for Clarity and Rigor", "abstract": "The widespread success of foundation models in natural language processing\nand computer vision has inspired researchers to extend the concept to\nscientific machine learning and computational science. However, this position\npaper argues that as the term \"foundation model\" is an evolving concept, its\napplication in computational science is increasingly used without a universally\naccepted definition, potentially creating confusion and diluting its precise\nscientific meaning. In this paper, we address this gap by proposing a formal\ndefinition of foundation models in computational science, grounded in the core\nvalues of generality, reusability, and scalability. We articulate a set of\nessential and desirable characteristics that such models must exhibit, drawing\nparallels with traditional foundational methods, like the finite element and\nfinite volume methods. Furthermore, we introduce the Data-Driven Finite Element\nMethod (DD-FEM), a framework that fuses the modular structure of classical FEM\nwith the representational power of data-driven learning. We demonstrate how\nDD-FEM addresses many of the key challenges in realizing foundation models for\ncomputational science, including scalability, adaptability, and physics\nconsistency. By bridging traditional numerical methods with modern AI\nparadigms, this work provides a rigorous foundation for evaluating and\ndeveloping novel approaches toward future foundation models in computational\nscience.", "published": "2025-05-28 22:10:16", "link": "http://arxiv.org/abs/2505.22904v2", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Revisiting Group Relative Policy Optimization: Insights into On-Policy and Off-Policy Training", "abstract": "We revisit Group Relative Policy Optimization (GRPO) in both on-policy and\noff-policy optimization regimes. Our motivation comes from recent work on\noff-policy Proximal Policy Optimization (PPO), which improves training\nstability, sampling efficiency, and memory usage. In addition, a recent\nanalysis of GRPO suggests that estimating the advantage function with\noff-policy samples could be beneficial. Building on these observations, we\nadapt GRPO to the off-policy setting. We show that both on-policy and\noff-policy GRPO objectives yield an improvement in the reward. This result\nmotivates the use of clipped surrogate objectives in the off-policy version of\nGRPO. We then compare the empirical performance of reinforcement learning with\nverifiable rewards in post-training using both GRPO variants. Our results show\nthat off-policy GRPO either significantly outperforms or performs on par with\nits on-policy counterpart.", "published": "2025-05-28 11:42:33", "link": "http://arxiv.org/abs/2505.22257v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Investigating the effectiveness of multimodal data in forecasting SARS-COV-2 case surges", "abstract": "The COVID-19 pandemic response relied heavily on statistical and machine\nlearning models to predict key outcomes such as case prevalence and fatality\nrates. These predictions were instrumental in enabling timely public health\ninterventions that helped break transmission cycles. While most existing models\nare grounded in traditional epidemiological data, the potential of alternative\ndatasets, such as those derived from genomic information and human behavior,\nremains underexplored. In the current study, we investigated the usefulness of\ndiverse modalities of feature sets in predicting case surges. Our results\nhighlight the relative effectiveness of biological (e.g., mutations), public\nhealth (e.g., case counts, policy interventions) and human behavioral features\n(e.g., mobility and social media conversations) in predicting country-level\ncase surges. Importantly, we uncover considerable heterogeneity in predictive\nperformance across countries and feature modalities, suggesting that surge\nprediction models may need to be tailored to specific national contexts and\npandemic phases. Overall, our work highlights the value of integrating\nalternative data sources into existing disease surveillance frameworks to\nenhance the prediction of pandemic dynamics.", "published": "2025-05-28 01:00:02", "link": "http://arxiv.org/abs/2505.22688v2", "categories": ["q-bio.QM", "cs.LG", "stat.ML"], "primary_category": "q-bio.QM"}
{"title": "SkewRoute: Training-Free LLM Routing for Knowledge Graph Retrieval-Augmented Generation via Score Skewness of Retrieved Context", "abstract": "Large language models excel at many tasks but often incur high inference\ncosts during deployment. To mitigate hallucination, many systems use a\nknowledge graph to enhance retrieval-augmented generation (KG-RAG). However,\nthe large amount of retrieved knowledge contexts increase these inference costs\nfurther. A promising solution to balance performance and cost is LLM routing,\nwhich directs simple queries to smaller LLMs and complex ones to larger LLMs.\nHowever, no dedicated routing methods currently exist for RAG, and existing\ntraining-based routers face challenges scaling to this domain due to the need\nfor extensive training data. We observe that the score distributions produced\nby the retrieval scorer strongly correlate with query difficulty. Based on\nthis, we propose a novel, training-free routing framework, the first tailored\nto KG-RAG that effectively balances performance and cost in a plug-and-play\nmanner. Experiments show our method reduces calls to larger LLMs by up to 50%\nwithout sacrificing response quality, demonstrating its potential for efficient\nand scalable LLM deployment.", "published": "2025-05-28 14:45:56", "link": "http://arxiv.org/abs/2505.23841v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Exploring the Landscape of Text-to-SQL with Large Language Models: Progresses, Challenges and Opportunities", "abstract": "Converting natural language (NL) questions into SQL queries, referred to as\nText-to-SQL, has emerged as a pivotal technology for facilitating access to\nrelational databases, especially for users without SQL knowledge. Recent\nprogress in large language models (LLMs) has markedly propelled the field of\nnatural language processing (NLP), opening new avenues to improve text-to-SQL\nsystems. This study presents a systematic review of LLM-based text-to-SQL,\nfocusing on four key aspects: (1) an analysis of the research trends in\nLLM-based text-to-SQL; (2) an in-depth analysis of existing LLM-based\ntext-to-SQL techniques from diverse perspectives; (3) summarization of existing\ntext-to-SQL datasets and evaluation metrics; and (4) discussion on potential\nobstacles and avenues for future exploration in this domain. This survey seeks\nto furnish researchers with an in-depth understanding of LLM-based text-to-SQL,\nsparking new innovations and advancements in this field.", "published": "2025-05-28 13:23:38", "link": "http://arxiv.org/abs/2505.23838v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CoMaPOI: A Collaborative Multi-Agent Framework for Next POI Prediction Bridging the Gap Between Trajectory and Language", "abstract": "Large Language Models (LLMs) offer new opportunities for the next\nPoint-Of-Interest (POI) prediction task, leveraging their capabilities in\nsemantic understanding of POI trajectories. However, previous LLM-based\nmethods, which are superficially adapted to next POI prediction, largely\noverlook critical challenges associated with applying LLMs to this task.\nSpecifically, LLMs encounter two critical challenges: (1) a lack of intrinsic\nunderstanding of numeric spatiotemporal data, which hinders accurate modeling\nof users' spatiotemporal distributions and preferences; and (2) an excessively\nlarge and unconstrained candidate POI space, which often results in random or\nirrelevant predictions. To address these issues, we propose a Collaborative\nMulti Agent Framework for Next POI Prediction, named CoMaPOI. Through the close\ninteraction of three specialized agents (Profiler, Forecaster, and Predictor),\nCoMaPOI collaboratively addresses the two critical challenges. The Profiler\nagent is responsible for converting numeric data into language descriptions,\nenhancing semantic understanding. The Forecaster agent focuses on dynamically\nconstraining and refining the candidate POI space. The Predictor agent\nintegrates this information to generate high-precision predictions. Extensive\nexperiments on three benchmark datasets (NYC, TKY, and CA) demonstrate that\nCoMaPOI achieves state of the art performance, improving all metrics by 5% to\n10% compared to SOTA baselines. This work pioneers the investigation of\nchallenges associated with applying LLMs to complex spatiotemporal tasks by\nleveraging tailored collaborative agents.", "published": "2025-05-28 12:32:01", "link": "http://arxiv.org/abs/2505.23837v1", "categories": ["cs.CL", "cs.IR", "I.2.0"], "primary_category": "cs.CL"}
{"title": "LegalSearchLM: Rethinking Legal Case Retrieval as Legal Elements Generation", "abstract": "Legal Case Retrieval (LCR), which retrieves relevant cases from a query case,\nis a fundamental task for legal professionals in research and decision-making.\nHowever, existing studies on LCR face two major limitations. First, they are\nevaluated on relatively small-scale retrieval corpora (e.g., 100-55K cases) and\nuse a narrow range of criminal query types, which cannot sufficiently reflect\nthe complexity of real-world legal retrieval scenarios. Second, their reliance\non embedding-based or lexical matching methods often results in limited\nrepresentations and legally irrelevant matches. To address these issues, we\npresent: (1) LEGAR BENCH, the first large-scale Korean LCR benchmark, covering\n411 diverse crime types in queries over 1.2M legal cases; and (2)\nLegalSearchLM, a retrieval model that performs legal element reasoning over the\nquery case and directly generates content grounded in the target cases through\nconstrained decoding. Experimental results show that LegalSearchLM outperforms\nbaselines by 6-20% on LEGAR BENCH, achieving state-of-the-art performance. It\nalso demonstrates strong generalization to out-of-domain cases, outperforming\nnaive generative models trained on in-domain data by 15%.", "published": "2025-05-28 09:02:41", "link": "http://arxiv.org/abs/2505.23832v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Representation of Symmetric Shift Registers", "abstract": "The objective of this work is to establish a mathematical framework for the\nstudy of symmetric shift registers over the field GF(2). The present paper\ngives a new approach where the symmetric shift registers are represented by\nassociated systems of nonlinear difference equations. Arithmetical progressions\nwill play a central part. This approach clarifies the underlying structures and\nmakes it easier to determine the minimal periods of the sequences generated by\nthe symmetric shift registers. Key words: Shift registers, nonlinear difference\nequations, periods, arithmetical progressions, GF(2).", "published": "2025-05-28 16:37:12", "link": "http://arxiv.org/abs/2505.23974v1", "categories": ["math.CO", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "Scalable, Symbiotic, AI and Non-AI Agent Based Parallel Discrete Event Simulations", "abstract": "To fully leverage the potential of artificial intelligence (AI) systems in a\ntrustworthy manner, it is desirable to couple multiple AI and non-AI systems\ntogether seamlessly for constraining and ensuring correctness of the output.\nThis paper introduces a novel parallel discrete event simulation (PDES) based\nmethodology to combine multiple AI and non-AI agents in a causal, rule-based\nway. Our approach tightly integrates the concept of passage of time, with each\nagent considered as an entity in the PDES framework and responding to prior\nrequests from other agents. Such coupling mechanism enables the agents to work\nin a co-operative environment towards a common goal while many tasks run in\nparallel throughout the simulation. It further enables setting up boundaries to\nthe outputs of the AI agents by applying necessary dynamic constraints using\nnon-AI agents while allowing for scalability through deployment of hundreds of\nsuch agents in a larger compute cluster. Distributing smaller AI agents can\nenable extremely scalable simulations in the future, addressing local memory\nbottlenecks for model parameter storage. Within a PDES involving both AI and\nnon-AI agents, we break down the problem at hand into structured steps, when\nnecessary, providing a set of multiple choices to the AI agents, and then\nprogressively solve these steps towards a final goal. At each step, the non-AI\nagents act as unbiased auditors, verifying each action by the AI agents so that\ncertain rules of engagement are followed. We evaluate our approach by solving\nfour problems from four different domains and comparing the results with those\nfrom AI models alone. Our results show greater accuracy in solving problems\nfrom various domains where the AI models struggle to solve the problems solely\nby themselves. Results show that overall accuracy of our approach is 68% where\nas the accuracy of vanilla models is less than 23%.", "published": "2025-05-28 17:50:01", "link": "http://arxiv.org/abs/2505.23846v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Patient-Aware Feature Alignment for Robust Lung Sound Classification:Cohesion-Separation and Global Alignment Losses", "abstract": "Lung sound classification is vital for early diagnosis of respiratory\ndiseases. However, biomedical signals often exhibit inter-patient variability\neven among patients with the same symptoms, requiring a learning approach that\nconsiders individual differences. We propose a Patient-Aware Feature Alignment\n(PAFA) framework with two novel losses, Patient Cohesion-Separation Loss (PCSL)\nand Global Patient Alignment Loss (GPAL). PCSL clusters features of the same\npatient while separating those from other patients to capture patient\nvariability, whereas GPAL draws each patient's centroid toward a global center,\npreventing feature space fragmentation. Our method achieves outstanding results\non the ICBHI dataset with a score of 64.84\\% for four-class and 72.08\\% for\ntwo-class classification. These findings highlight PAFA's ability to capture\nindividualized patterns and demonstrate performance gains in distinct patient\nclusters, offering broader applications for patient-centered healthcare.", "published": "2025-05-28 10:56:55", "link": "http://arxiv.org/abs/2505.23834v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking", "abstract": "With the surge of social media, maliciously tampered public speeches,\nespecially those from influential figures, have seriously affected social\nstability and public trust. Existing speech tampering detection methods remain\ninsufficient: they either rely on external reference data or fail to be both\nsensitive to attacks and robust to benign operations, such as compression and\nresampling. To tackle these challenges, we introduce SpeechVerifer to\nproactively verify speech integrity using only the published speech itself,\ni.e., without requiring any external references. Inspired by audio\nfingerprinting and watermarking, SpeechVerifier can (i) effectively detect\ntampering attacks, (ii) be robust to benign operations and (iii) verify the\nintegrity only based on published speeches. Briefly, SpeechVerifier utilizes\nmultiscale feature extraction to capture speech features across different\ntemporal resolutions. Then, it employs contrastive learning to generate\nfingerprints that can detect modifications at varying granularities. These\nfingerprints are designed to be robust to benign operations, but exhibit\nsignificant changes when malicious tampering occurs. To enable speech\nverification in a self-contained manner, the generated fingerprints are then\nembedded into the speech signal by segment-wise watermarking. Without external\nreferences, SpeechVerifier can retrieve the fingerprint from the published\naudio and check it with the embedded watermark to verify the integrity of the\nspeech. Extensive experimental results demonstrate that the proposed\nSpeechVerifier is effective in detecting tampering attacks and robust to benign\noperations.", "published": "2025-05-28 02:20:33", "link": "http://arxiv.org/abs/2505.23821v1", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Counting big Ramsey degrees of the homogeneous and universal $K_4$-free graph", "abstract": "Big Ramsey degrees of Fra\\\"iss\\'e limits of finitely constrained free\namalgamation classes in finite binary languages have been recently fully\ncharacterised by Balko, Chodounsk\\'y, Dobrinen, Hubi\\v{c}ka, Kone\\v{c}n\\'y,\nVena, and Zucker. A special case of this characterisation is the universal\nhomogeneous $K_4$-free graph. We give a self-contained and relatively compact\npresentation of this case and compute the actual big Ramsey degrees of small\ngraphs.", "published": "2025-05-28 17:43:21", "link": "http://arxiv.org/abs/2505.22620v2", "categories": ["math.CO", "cs.DM", "math.LO", "05C55, 05D10, 05C30", "G.2.1; G.2.2"], "primary_category": "math.CO"}
{"title": "On Big Ramsey degrees of universal $\u03c9$-edge-labeled hypergraphs", "abstract": "We show that the big Ramsey degrees of every countable universal $u$-uniform\n$\\omega$-edge-labeled hypergraph are infinite for every $u\\geq 2$. Together\nwith a recent result of Braunfeld, Chodounsk\\'y, de Rancourt, Hubi\\v{c}ka,\nKawach, and Kone\\v{c}n\\'y this finishes full characterisation of unrestricted\nrelational structures with finite big Ramsey degrees.", "published": "2025-05-28 16:38:40", "link": "http://arxiv.org/abs/2505.22561v2", "categories": ["math.CO", "cs.DM", "math.LO", "05C55, 03E02, 05D10, 05C15", "G.2.1"], "primary_category": "math.CO"}
{"title": "Yambda-5B -- A Large-Scale Multi-modal Dataset for Ranking And Retrieval", "abstract": "We present Yambda-5B, a large-scale open dataset sourced from the Yandex\nMusic streaming platform. Yambda-5B contains 4.79 billion user-item\ninteractions from 1 million users across 9.39 million tracks. The dataset\nincludes two primary types of interactions: implicit feedback (listening\nevents) and explicit feedback (likes, dislikes, unlikes and undislikes). In\naddition, we provide audio embeddings for most tracks, generated by a\nconvolutional neural network trained on audio spectrograms. A key\ndistinguishing feature of Yambda-5B is the inclusion of the is_organic flag,\nwhich separates organic user actions from recommendation-driven events. This\ndistinction is critical for developing and evaluating machine learning\nalgorithms, as Yandex Music relies on recommender systems to personalize track\nselection for users. To support rigorous benchmarking, we introduce an\nevaluation protocol based on a Global Temporal Split, allowing recommendation\nalgorithms to be assessed in conditions that closely mirror real-world use. We\nreport benchmark results for standard baselines (ItemKNN, iALS) and advanced\nmodels (SANSA, SASRec) using a variety of evaluation metrics. By releasing\nYambda-5B to the community, we aim to provide a readily accessible,\nindustrial-scale resource to advance research, foster innovation, and promote\nreproducible results in recommender systems.", "published": "2025-05-28 11:12:57", "link": "http://arxiv.org/abs/2505.22238v2", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Developing a Top-tier Framework in Naturalistic Conditions Challenge for Categorized Emotion Prediction: From Speech Foundation Models and Learning Objective to Data Augmentation and Engineering Choices", "abstract": "Speech emotion recognition (SER), particularly for naturally expressed\nemotions, remains a challenging computational task. Key challenges include the\ninherent subjectivity in emotion annotation and the imbalanced distribution of\nemotion labels in datasets. This paper introduces the \\texttt{SAILER} system\ndeveloped for participation in the INTERSPEECH 2025 Emotion Recognition\nChallenge (Task 1). The challenge dataset, which contains natural emotional\nspeech from podcasts, serves as a valuable resource for studying imbalanced and\nsubjective emotion annotations. Our system is designed to be simple,\nreproducible, and effective, highlighting critical choices in modeling,\nlearning objectives, data augmentation, and engineering choices. Results show\nthat even a single system (without ensembling) can outperform more than 95\\% of\nthe submissions, with a Macro-F1 score exceeding 0.4. Moreover, an ensemble of\nthree systems further improves performance, achieving a competitively ranked\nscore (top-3 performing team). Our model is at:\nhttps://github.com/tiantiaf0627/vox-profile-release.", "published": "2025-05-28 08:58:22", "link": "http://arxiv.org/abs/2505.22133v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking", "abstract": "With the surge of social media, maliciously tampered public speeches,\nespecially those from influential figures, have seriously affected social\nstability and public trust. Existing speech tampering detection methods remain\ninsufficient: they either rely on external reference data or fail to be both\nsensitive to attacks and robust to benign operations, such as compression and\nresampling. To tackle these challenges, we introduce SpeechVerifer to\nproactively verify speech integrity using only the published speech itself,\ni.e., without requiring any external references. Inspired by audio\nfingerprinting and watermarking, SpeechVerifier can (i) effectively detect\ntampering attacks, (ii) be robust to benign operations and (iii) verify the\nintegrity only based on published speeches. Briefly, SpeechVerifier utilizes\nmultiscale feature extraction to capture speech features across different\ntemporal resolutions. Then, it employs contrastive learning to generate\nfingerprints that can detect modifications at varying granularities. These\nfingerprints are designed to be robust to benign operations, but exhibit\nsignificant changes when malicious tampering occurs. To enable speech\nverification in a self-contained manner, the generated fingerprints are then\nembedded into the speech signal by segment-wise watermarking. Without external\nreferences, SpeechVerifier can retrieve the fingerprint from the published\naudio and check it with the embedded watermark to verify the integrity of the\nspeech. Extensive experimental results demonstrate that the proposed\nSpeechVerifier is effective in detecting tampering attacks and robust to benign\noperations.", "published": "2025-05-28 02:20:33", "link": "http://arxiv.org/abs/2505.23821v2", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "The only Class 0 Flower snark is the smallest", "abstract": "Graph pebbling is a game played on graphs with pebbles on their vertices. A\npebbling move removes two pebbles from one vertex and places one pebble on an\nadjacent vertex. The pebbling number is the smallest $t$ so that from any\ninitial configuration of $t$ pebbles it is possible, after a sequence of\npebbling moves, to place a pebble on any given target vertex. Graphs whose\npebbling number is equal to the number of vertices are called Class~$0$ and\nprovide a challenging set of graphs that resist being characterized. In this\nnote, we answer a question recently proposed by the pioneering study on the\npebbling number of snark graphs: we prove that the smallest Flower snark $J_3$\nis Class~$0$, establishing that $J_3$ is in fact the only Class~$0$ Flower\nsnark.", "published": "2025-05-28 23:45:27", "link": "http://arxiv.org/abs/2505.22941v2", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Retrieval-Augmented Generation: A Comprehensive Survey of Architectures, Enhancements, and Robustness Frontiers", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to\nenhance large language models (LLMs) by conditioning generation on external\nevidence retrieved at inference time. While RAG addresses critical limitations\nof parametric knowledge storage-such as factual inconsistency and domain\ninflexibility-it introduces new challenges in retrieval quality, grounding\nfidelity, pipeline efficiency, and robustness against noisy or adversarial\ninputs. This survey provides a comprehensive synthesis of recent advances in\nRAG systems, offering a taxonomy that categorizes architectures into\nretriever-centric, generator-centric, hybrid, and robustness-oriented designs.\nWe systematically analyze enhancements across retrieval optimization, context\nfiltering, decoding control, and efficiency improvements, supported by\ncomparative performance analyses on short-form and multi-hop question answering\ntasks. Furthermore, we review state-of-the-art evaluation frameworks and\nbenchmarks, highlighting trends in retrieval-aware evaluation, robustness\ntesting, and federated retrieval settings. Our analysis reveals recurring\ntrade-offs between retrieval precision and generation flexibility, efficiency\nand faithfulness, and modularity and coordination. We conclude by identifying\nopen challenges and future research directions, including adaptive retrieval\narchitectures, real-time retrieval integration, structured reasoning over\nmulti-hop evidence, and privacy-preserving retrieval mechanisms. This survey\naims to consolidate current knowledge in RAG research and serve as a foundation\nfor the next generation of retrieval-augmented language modeling systems.", "published": "2025-05-28 22:57:04", "link": "http://arxiv.org/abs/2506.00054v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Rethinking Hybrid Retrieval: When Small Embeddings and LLM Re-ranking Beat Bigger Models", "abstract": "This paper presents a comparison of embedding models in tri-modal hybrid\nretrieval for Retrieval-Augmented Generation (RAG) systems. We investigate the\nfusion of dense semantic, sparse lexical, and graph-based embeddings, focusing\non the performance of the MiniLM-v6 and BGE-Large architectures. Contrary to\nconventional assumptions, our results show that the compact MiniLM-v6\noutperforms the larger BGE-Large when integrated with LLM-based re-ranking\nwithin our tri-modal hybrid framework. Experiments conducted on the SciFact,\nFIQA, and NFCorpus datasets demonstrate significant improvements in retrieval\nquality with the MiniLM-v6 configuration. The performance difference is\nparticularly pronounced in agentic re-ranking scenarios, indicating better\nalignment between MiniLM-v6's embedding space and LLM reasoning. Our findings\nsuggest that embedding model selection for RAG systems should prioritize\ncompatibility with multi-signal fusion and LLM alignment, rather than relying\nsolely on larger models. This approach may reduce computational requirements\nwhile improving retrieval accuracy and efficiency.", "published": "2025-05-28 18:39:40", "link": "http://arxiv.org/abs/2506.00049v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Graph Contrastive Learning for Optimizing Sparse Data in Recommender Systems with LightGCL", "abstract": "Graph Neural Networks (GNNs) are powerful tools for recommendation systems,\nbut they often struggle under data sparsity and noise. To address these issues,\nwe implemented LightGCL, a graph contrastive learning model that uses Singular\nValue Decomposition (SVD) for robust graph augmentation, preserving semantic\nintegrity without relying on stochastic or heuristic perturbations. LightGCL\nenables structural refinement and captures global collaborative signals,\nachieving significant gains over state-of-the-art models across benchmark\ndatasets. Our experiments also demonstrate improved fairness and resilience to\npopularity bias, making it well-suited for real-world recommender systems.", "published": "2025-05-28 17:21:41", "link": "http://arxiv.org/abs/2506.00048v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Decoding Dense Embeddings: Sparse Autoencoders for Interpreting and Discretizing Dense Retrieval", "abstract": "Despite their strong performance, Dense Passage Retrieval (DPR) models suffer\nfrom a lack of interpretability. In this work, we propose a novel\ninterpretability framework that leverages Sparse Autoencoders (SAEs) to\ndecompose previously uninterpretable dense embeddings from DPR models into\ndistinct, interpretable latent concepts. We generate natural language\ndescriptions for each latent concept, enabling human interpretations of both\nthe dense embeddings and the query-document similarity scores of DPR models. We\nfurther introduce Concept-Level Sparse Retrieval (CL-SR), a retrieval framework\nthat directly utilizes the extracted latent concepts as indexing units. CL-SR\neffectively combines the semantic expressiveness of dense embeddings with the\ntransparency and efficiency of sparse representations. We show that CL-SR\nachieves high index-space and computational efficiency while maintaining robust\nperformance across vocabulary and semantic mismatches.", "published": "2025-05-28 02:50:17", "link": "http://arxiv.org/abs/2506.00041v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Using LLMs to Advance the Cognitive Science of Collectives", "abstract": "LLMs are already transforming the study of individual cognition, but their\napplication to studying collective cognition has been underexplored. We lay out\nhow LLMs may be able to address the complexity that has hindered the study of\ncollectives and raise possible risks that warrant new methods.", "published": "2025-05-28 21:15:46", "link": "http://arxiv.org/abs/2506.00052v1", "categories": ["q-bio.NC", "cs.AI", "cs.HC", "cs.MA", "cs.SI"], "primary_category": "q-bio.NC"}
{"title": "Behavioral alignment in social networks", "abstract": "The orderly behaviors observed in large-scale groups, such as fish schooling\nand the organized movement of crowds, are both ubiquitous and essential for the\nsurvival and stability of these systems. Such complex collective behaviors\noften emerge from simple local interactions and strategy adjustments among\nindividuals. Understanding how these basic rules shape complex group dynamics\nhas long been a significant scientific challenge. Historically, research has\npredominantly focused on imitation and social learning, where individuals adopt\nthe strategies of more successful peers to refine their behavior. However, in\nrecent years, an alternative learning approach, self-exploration and\nintrospective learning, has garnered increasing attention. In this paradigm,\nindividuals assess their own circumstances and select strategies that best\nalign with their specific conditions. Two primary forms of this learning are\ncoordination and anti-coordination, where individuals align with and diverge\nfrom the local majority, respectively. In this study, we analyze networked\nsystems of coordinating and anti-coordinating individuals, exploring the\ncombined effects of system dynamics, network structure, and behavioral\npatterns. We address several practical questions, including the number of\nequilibria, their characteristics, the equilibrium time, and the resilience of\nsystems. We find that the number of equilibrium states can be extremely large,\neven increasing exponentially with minor alternations to the network structure.\nMoreover, the network structure has a significant impact on the average\nequilibrium time. Despite the complexity of these findings, variations can be\ncaptured by a single, simple network characteristic: the average path length.\nOur research offers valuable insights into how modifications to the interaction\nstructure can influence behavioral alignment in social networks.", "published": "2025-05-28 13:55:58", "link": "http://arxiv.org/abs/2506.00046v1", "categories": ["physics.soc-ph", "cs.MA", "cs.SI", "nlin.AO"], "primary_category": "physics.soc-ph"}
