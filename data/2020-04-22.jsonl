{"title": "Supervised Grapheme-to-Phoneme Conversion of Orthographic Schwas in\n  Hindi and Punjabi", "abstract": "Hindi grapheme-to-phoneme (G2P) conversion is mostly trivial, with one\nexception: whether a schwa represented in the orthography is pronounced or\nunpronounced (deleted). Previous work has attempted to predict schwa deletion\nin a rule-based fashion using prosodic or phonetic analysis. We present the\nfirst statistical schwa deletion classifier for Hindi, which relies solely on\nthe orthography as the input and outperforms previous approaches. We trained\nour model on a newly-compiled pronunciation lexicon extracted from various\nonline dictionaries. Our best Hindi model achieves state of the art\nperformance, and also achieves good performance on a closely related language,\nPunjabi, without modification.", "published": "2020-04-22 00:53:40", "link": "http://arxiv.org/abs/2004.10353v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Trading Off Diversity and Quality in Natural Language Generation", "abstract": "For open-ended language generation tasks such as storytelling and dialogue,\nchoosing the right decoding algorithm is critical to controlling the tradeoff\nbetween generation quality and diversity. However, there presently exists no\nconsensus on which decoding procedure is best or even the criteria by which to\ncompare them. We address these issues by casting decoding as a multi-objective\noptimization problem aiming to simultaneously maximize both response quality\nand diversity. Our framework enables us to perform the first large-scale\nevaluation of decoding methods along the entire quality-diversity spectrum. We\nfind that when diversity is a priority, all methods perform similarly, but when\nquality is viewed as more important, the recently proposed nucleus sampling\n(Holtzman et al. 2019) outperforms all other evaluated decoding algorithms. Our\nexperiments also confirm the existence of the `likelihood trap', the\ncounter-intuitive observation that high likelihood sequences are often\nsurprisingly low quality. We leverage our findings to create and evaluate an\nalgorithm called \\emph{selective sampling} which tractably approximates\nglobally-normalized temperature sampling.", "published": "2020-04-22 09:12:10", "link": "http://arxiv.org/abs/2004.10450v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Keyphrase Prediction With Pre-trained Language Model", "abstract": "Recently, generative methods have been widely used in keyphrase prediction,\nthanks to their capability to produce both present keyphrases that appear in\nthe source text and absent keyphrases that do not match any source text.\nHowever, the absent keyphrases are generated at the cost of the performance on\npresent keyphrase prediction, since previous works mainly use generative models\nthat rely on the copying mechanism and select words step by step. Besides, the\nextractive model that directly extracts a text span is more suitable for\npredicting the present keyphrase. Considering the different characteristics of\nextractive and generative methods, we propose to divide the keyphrase\nprediction into two subtasks, i.e., present keyphrase extraction (PKE) and\nabsent keyphrase generation (AKG), to fully exploit their respective\nadvantages. On this basis, a joint inference framework is proposed to make the\nmost of BERT in two subtasks. For PKE, we tackle this task as a sequence\nlabeling problem with the pre-trained language model BERT. For AKG, we\nintroduce a Transformer-based architecture, which fully integrates the present\nkeyphrase knowledge learned from PKE by the fine-tuned BERT. The experimental\nresults show that our approach can achieve state-of-the-art results on both\ntasks on benchmark datasets.", "published": "2020-04-22 09:35:02", "link": "http://arxiv.org/abs/2004.10462v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Where is the context? -- A critique of recent dialogue datasets", "abstract": "Recent dialogue datasets like MultiWOZ 2.1 and Taskmaster-1 constitute some\nof the most challenging tasks for present-day dialogue models and, therefore,\nare widely used for system evaluation. We identify several issues with the\nabove-mentioned datasets, such as history independence, strong knowledge base\ndependence, and ambiguous system responses. Finally, we outline key desiderata\nfor future datasets that we believe would be more suitable for the construction\nof conversational artificial intelligence.", "published": "2020-04-22 10:05:52", "link": "http://arxiv.org/abs/2004.10473v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When and Why is Unsupervised Neural Machine Translation Useless?", "abstract": "This paper studies the practicality of the current state-of-the-art\nunsupervised methods in neural machine translation (NMT). In ten translation\ntasks with various data settings, we analyze the conditions under which the\nunsupervised methods fail to produce reasonable translations. We show that\ntheir performance is severely affected by linguistic dissimilarity and domain\nmismatch between source and target monolingual data. Such conditions are common\nfor low-resource language pairs, where unsupervised learning works poorly. In\nall of our experiments, supervised and semi-supervised baselines with\n50k-sentence bilingual data outperform the best unsupervised results. Our\nanalyses pinpoint the limits of the current unsupervised NMT and also suggest\nimmediate research directions.", "published": "2020-04-22 14:00:55", "link": "http://arxiv.org/abs/2004.10581v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "R-VGAE: Relational-variational Graph Autoencoder for Unsupervised\n  Prerequisite Chain Learning", "abstract": "The task of concept prerequisite chain learning is to automatically determine\nthe existence of prerequisite relationships among concept pairs. In this paper,\nwe frame learning prerequisite relationships among concepts as an unsupervised\ntask with no access to labeled concept pairs during training. We propose a\nmodel called the Relational-Variational Graph AutoEncoder (R-VGAE) to predict\nconcept relations within a graph consisting of concept and resource nodes.\nResults show that our unsupervised approach outperforms graph-based\nsemi-supervised methods and other baseline methods by up to 9.77% and 10.47% in\nterms of prerequisite relation prediction accuracy and F1 score. Our method is\nnotably the first graph-based model that attempts to make use of deep learning\nrepresentations for the task of unsupervised prerequisite learning. We also\nexpand an existing corpus which totals 1,717 English Natural Language\nProcessing (NLP)-related lecture slide files and manual concept pair\nannotations over 322 topics.", "published": "2020-04-22 14:48:03", "link": "http://arxiv.org/abs/2004.10610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Entity Enrichment by Leveraging Multilingual Descriptions for\n  Link Prediction", "abstract": "Most Knowledge Graphs (KGs) contain textual descriptions of entities in\nvarious natural languages. These descriptions of entities provide valuable\ninformation that may not be explicitly represented in the structured part of\nthe KG. Based on this fact, some link prediction methods which make use of the\ninformation presented in the textual descriptions of entities have been\nproposed to learn representations of (monolingual) KGs. However, these methods\nuse entity descriptions in only one language and ignore the fact that\ndescriptions given in different languages may provide complementary information\nand thereby also additional semantics. In this position paper, the problem of\neffectively leveraging multilingual entity descriptions for the purpose of link\nprediction in KGs will be discussed along with potential solutions to the\nproblem.", "published": "2020-04-22 15:34:11", "link": "http://arxiv.org/abs/2004.10640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Universal Dependencies v2: An Evergrowing Multilingual Treebank\n  Collection", "abstract": "Universal Dependencies is an open community effort to create\ncross-linguistically consistent treebank annotation for many languages within a\ndependency-based lexicalist framework. The annotation consists in a\nlinguistically motivated word segmentation; a morphological layer comprising\nlemmas, universal part-of-speech tags, and standardized morphological features;\nand a syntactic layer focusing on syntactic relations between predicates,\narguments and modifiers. In this paper, we describe version 2 of the guidelines\n(UD v2), discuss the major changes from UD v1 to UD v2, and give an overview of\nthe currently available treebanks for 90 languages.", "published": "2020-04-22 15:38:18", "link": "http://arxiv.org/abs/2004.10643v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast and Scalable Dialogue State Tracking with Explicit Modular\n  Decomposition", "abstract": "We present a fast and scalable architecture called Explicit Modular\nDecomposition (EMD), in which we incorporate both classification-based and\nextraction-based methods and design four modules (for classification and\nsequence labelling) to jointly extract dialogue states. Experimental results\nbased on the MultiWoz 2.0 dataset validates the superiority of our proposed\nmodel in terms of both complexity and scalability when compared to the\nstate-of-the-art methods, especially in the scenario of multi-domain dialogues\nentangled with many turns of utterances.", "published": "2020-04-22 16:00:09", "link": "http://arxiv.org/abs/2004.10663v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Classify Intents and Slot Labels Given a Handful of Examples", "abstract": "Intent classification (IC) and slot filling (SF) are core components in most\ngoal-oriented dialogue systems. Current IC/SF models perform poorly when the\nnumber of training examples per class is small. We propose a new few-shot\nlearning task, few-shot IC/SF, to study and improve the performance of IC and\nSF models on classes not seen at training time in ultra low resource scenarios.\nWe establish a few-shot IC/SF benchmark by defining few-shot splits for three\npublic IC/SF datasets, ATIS, TOP, and Snips. We show that two popular few-shot\nlearning algorithms, model agnostic meta learning (MAML) and prototypical\nnetworks, outperform a fine-tuning baseline on this benchmark. Prototypical\nnetworks achieves significant gains in IC performance on the ATIS and TOP\ndatasets, while both prototypical networks and MAML outperform the baseline\nwith respect to SF on all three datasets. In addition, we demonstrate that\njoint training as well as the use of pre-trained language models, ELMo and BERT\nin our case, are complementary to these few-shot learning methods and yield\nfurther gains.", "published": "2020-04-22 18:54:38", "link": "http://arxiv.org/abs/2004.10793v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polarized-VAE: Proximity Based Disentangled Representation Learning for\n  Text Generation", "abstract": "Learning disentangled representations of real-world data is a challenging\nopen problem. Most previous methods have focused on either supervised\napproaches which use attribute labels or unsupervised approaches that\nmanipulate the factorization in the latent space of models such as the\nvariational autoencoder (VAE) by training with task-specific losses. In this\nwork, we propose polarized-VAE, an approach that disentangles select attributes\nin the latent space based on proximity measures reflecting the similarity\nbetween data points with respect to these attributes. We apply our method to\ndisentangle the semantics and syntax of sentences and carry out transfer\nexperiments. Polarized-VAE outperforms the VAE baseline and is competitive with\nstate-of-the-art approaches, while being more a general framework that is\napplicable to other attribute disentanglement tasks.", "published": "2020-04-22 19:26:09", "link": "http://arxiv.org/abs/2004.10809v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting the Context Window for Cross-lingual Word Embeddings", "abstract": "Existing approaches to mapping-based cross-lingual word embeddings are based\non the assumption that the source and target embedding spaces are structurally\nsimilar. The structures of embedding spaces largely depend on the co-occurrence\nstatistics of each word, which the choice of context window determines. Despite\nthis obvious connection between the context window and mapping-based\ncross-lingual embeddings, their relationship has been underexplored in prior\nwork. In this work, we provide a thorough evaluation, in various languages,\ndomains, and tasks, of bilingual embeddings trained with different context\nwindows. The highlight of our findings is that increasing the size of both the\nsource and target window sizes improves the performance of bilingual lexicon\ninduction, especially the performance on frequent nouns.", "published": "2020-04-22 19:29:43", "link": "http://arxiv.org/abs/2004.10813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactic Structure from Deep Learning", "abstract": "Modern deep neural networks achieve impressive performance in engineering\napplications that require extensive linguistic skills, such as machine\ntranslation. This success has sparked interest in probing whether these models\nare inducing human-like grammatical knowledge from the raw data they are\nexposed to, and, consequently, whether they can shed new light on long-standing\ndebates concerning the innate structure necessary for language acquisition. In\nthis article, we survey representative studies of the syntactic abilities of\ndeep networks, and discuss the broader implications that this work has for\ntheoretical linguistics.", "published": "2020-04-22 20:02:49", "link": "http://arxiv.org/abs/2004.10827v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dense Embeddings Preserving the Semantic Relationships in WordNet", "abstract": "In this paper, we provide a novel way to generate low dimensional vector\nembeddings for the noun and verb synsets in WordNet, where the hypernym-hyponym\nrelationship is preserved in the embeddings. We call this embedding the Sense\nSpectrum (and Sense Spectra for embeddings). In order to create suitable labels\nfor the training of sense spectra, we designed a new similarity measurement for\nnoun and verb synsets in WordNet. We call this similarity measurement the\nHypernym Intersection Similarity (HIS), since it compares the common and unique\nhypernyms between two synsets. Our experiments show that on the noun and verb\npairs of the SimLex-999 dataset, HIS outperforms the three similarity\nmeasurements in WordNet. Moreover, to the best of our knowledge, the sense\nspectra provide the first dense synset embeddings that preserve the semantic\nrelationships in WordNet.", "published": "2020-04-22 21:09:47", "link": "http://arxiv.org/abs/2004.10863v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Every Document Owns Its Structure: Inductive Text Classification via\n  Graph Neural Networks", "abstract": "Text classification is fundamental in natural language processing (NLP), and\nGraph Neural Networks (GNN) are recently applied in this task. However, the\nexisting graph-based works can neither capture the contextual word\nrelationships within each document nor fulfil the inductive learning of new\nwords. In this work, to overcome such problems, we propose TextING for\ninductive text classification via GNN. We first build individual graphs for\neach document and then use GNN to learn the fine-grained word representations\nbased on their local structures, which can also effectively produce embeddings\nfor unseen words in the new document. Finally, the word nodes are aggregated as\nthe document embedding. Extensive experiments on four benchmark datasets show\nthat our method outperforms state-of-the-art text classification methods.", "published": "2020-04-22 07:23:47", "link": "http://arxiv.org/abs/2004.13826v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Testing Machine Translation via Referential Transparency", "abstract": "Machine translation software has seen rapid progress in recent years due to\nthe advancement of deep neural networks. People routinely use machine\ntranslation software in their daily lives, such as ordering food in a foreign\nrestaurant, receiving medical diagnosis and treatment from foreign doctors, and\nreading international political news online. However, due to the complexity and\nintractability of the underlying neural networks, modern machine translation\nsoftware is still far from robust and can produce poor or incorrect\ntranslations; this can lead to misunderstanding, financial loss, threats to\npersonal safety and health, and political conflicts. To address this problem,\nwe introduce referentially transparent inputs (RTIs), a simple, widely\napplicable methodology for validating machine translation software. A\nreferentially transparent input is a piece of text that should have similar\ntranslations when used in different contexts. Our practical implementation,\nPurity, detects when this property is broken by a translation. To evaluate RTI,\nwe use Purity to test Google Translate and Bing Microsoft Translator with 200\nunlabeled sentences, which detected 123 and 142 erroneous translations with\nhigh precision (79.3% and 78.3%). The translation errors are diverse, including\nexamples of under-translation, over-translation, word/phrase mistranslation,\nincorrect modification, and unclear logic.", "published": "2020-04-22 01:37:18", "link": "http://arxiv.org/abs/2004.10361v2", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Logical Natural Language Generation from Open-Domain Tables", "abstract": "Neural natural language generation (NLG) models have recently shown\nremarkable progress in fluency and coherence. However, existing studies on\nneural NLG are primarily focused on surface-level realizations with limited\nemphasis on logical inference, an important aspect of human thinking and\nlanguage. In this paper, we suggest a new NLG task where a model is tasked with\ngenerating natural language statements that can be \\emph{logically entailed} by\nthe facts in an open-domain semi-structured table. To facilitate the study of\nthe proposed logical NLG problem, we use the existing TabFact dataset\n\\cite{chen2019tabfact} featured with a wide range of logical/symbolic\ninferences as our testbed, and propose new automatic metrics to evaluate the\nfidelity of generation models w.r.t.\\ logical inference. The new task poses\nchallenges to the existing monotonic generation frameworks due to the mismatch\nbetween sequence order and logical order. In our experiments, we\ncomprehensively survey different generation architectures (LSTM, Transformer,\nPre-Trained LM) trained with different algorithms (RL, Adversarial Training,\nCoarse-to-Fine) on the dataset and made following observations: 1) Pre-Trained\nLM can significantly boost both the fluency and logical fidelity metrics, 2) RL\nand Adversarial Training are trading fluency for fidelity, 3) Coarse-to-Fine\ngeneration can help partially alleviate the fidelity issue while maintaining\nhigh language fluency. The code and data are available at\n\\url{https://github.com/wenhuchen/LogicNLG}.", "published": "2020-04-22 06:03:10", "link": "http://arxiv.org/abs/2004.10404v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contextualised Graph Attention for Improved Relation Extraction", "abstract": "This paper presents a contextualized graph attention network that combines\nedge features and multiple sub-graphs for improving relation extraction. A\nnovel method is proposed to use multiple sub-graphs to learn rich node\nrepresentations in graph-based networks. To this end multiple sub-graphs are\nobtained from a single dependency tree. Two types of edge features are\nproposed, which are effectively combined with GAT and GCN models to apply for\nrelation extraction. The proposed model achieves state-of-the-art performance\non Semeval 2010 Task 8 dataset, achieving an F1-score of 86.3.", "published": "2020-04-22 15:04:52", "link": "http://arxiv.org/abs/2004.10624v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "AmbigQA: Answering Ambiguous Open-domain Questions", "abstract": "Ambiguity is inherent to open-domain question answering; especially when\nexploring new topics, it can be difficult to ask questions that have a single,\nunambiguous answer. In this paper, we introduce AmbigQA, a new open-domain\nquestion answering task which involves finding every plausible answer, and then\nrewriting the question for each one to resolve the ambiguity. To study this\ntask, we construct AmbigNQ, a dataset covering 14,042 questions from NQ-open,\nan existing open-domain QA benchmark. We find that over half of the questions\nin NQ-open are ambiguous, with diverse sources of ambiguity such as event and\nentity references. We also present strong baseline models for AmbigQA which we\nshow benefit from weakly supervised learning that incorporates NQ-open,\nstrongly suggesting our new task and data will support significant future\nresearch effort. Our data and baselines are available at\nhttps://nlp.cs.washington.edu/ambigqa.", "published": "2020-04-22 15:42:13", "link": "http://arxiv.org/abs/2004.10645v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CORD-19: The COVID-19 Open Research Dataset", "abstract": "The COVID-19 Open Research Dataset (CORD-19) is a growing resource of\nscientific papers on COVID-19 and related historical coronavirus research.\nCORD-19 is designed to facilitate the development of text mining and\ninformation retrieval systems over its rich collection of metadata and\nstructured full text papers. Since its release, CORD-19 has been downloaded\nover 200K times and has served as the basis of many COVID-19 text mining and\ndiscovery systems. In this article, we describe the mechanics of dataset\nconstruction, highlighting challenges and key design decisions, provide an\noverview of how CORD-19 has been used, and describe several shared tasks built\naround the dataset. We hope this resource will continue to bring together the\ncomputing community, biomedical experts, and policy makers in the search for\neffective treatments and management policies for COVID-19.", "published": "2020-04-22 17:10:18", "link": "http://arxiv.org/abs/2004.10706v4", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "VisualCOMET: Reasoning about the Dynamic Context of a Still Image", "abstract": "Even from a single frame of a still image, people can reason about the\ndynamic story of the image before, after, and beyond the frame. For example,\ngiven an image of a man struggling to stay afloat in water, we can reason that\nthe man fell into the water sometime in the past, the intent of that man at the\nmoment is to stay alive, and he will need help in the near future or else he\nwill get washed away. We propose VisualComet, the novel framework of visual\ncommonsense reasoning tasks to predict events that might have happened before,\nevents that might happen next, and the intents of the people at present. To\nsupport research toward visual commonsense reasoning, we introduce the first\nlarge-scale repository of Visual Commonsense Graphs that consists of over 1.4\nmillion textual descriptions of visual commonsense inferences carefully\nannotated over a diverse set of 60,000 images, each paired with short video\nsummaries of before and after. In addition, we provide person-grounding (i.e.,\nco-reference links) between people appearing in the image and people mentioned\nin the textual commonsense descriptions, allowing for tighter integration\nbetween images and text. We establish strong baseline performances on this task\nand demonstrate that integration between visual and textual commonsense\nreasoning is the key and wins over non-integrative alternatives.", "published": "2020-04-22 19:02:20", "link": "http://arxiv.org/abs/2004.10796v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Residual Energy-Based Models for Text Generation", "abstract": "Text generation is ubiquitous in many NLP tasks, from summarization, to\ndialogue and machine translation. The dominant parametric approach is based on\nlocally normalized models which predict one word at a time. While these work\nremarkably well, they are plagued by exposure bias due to the greedy nature of\nthe generation process. In this work, we investigate un-normalized energy-based\nmodels (EBMs) which operate not at the token but at the sequence level. In\norder to make training tractable, we first work in the residual of a pretrained\nlocally normalized language model and second we train using noise contrastive\nestimation. Furthermore, since the EBM works at the sequence level, we can\nleverage pretrained bi-directional contextual representations, such as BERT and\nRoBERTa. Our experiments on two large language modeling datasets show that\nresidual EBMs yield lower perplexity compared to locally normalized baselines.\nMoreover, generation via importance sampling is very efficient and of higher\nquality than the baseline models according to human evaluation.", "published": "2020-04-22 23:19:55", "link": "http://arxiv.org/abs/2004.11714v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Study of Non-autoregressive Model for Sequence Generation", "abstract": "Non-autoregressive (NAR) models generate all the tokens of a sequence in\nparallel, resulting in faster generation speed compared to their autoregressive\n(AR) counterparts but at the cost of lower accuracy. Different techniques\nincluding knowledge distillation and source-target alignment have been proposed\nto bridge the gap between AR and NAR models in various tasks such as neural\nmachine translation (NMT), automatic speech recognition (ASR), and text to\nspeech (TTS). With the help of those techniques, NAR models can catch up with\nthe accuracy of AR models in some tasks but not in some others. In this work,\nwe conduct a study to understand the difficulty of NAR sequence generation and\ntry to answer: (1) Why NAR models can catch up with AR models in some tasks but\nnot all? (2) Why techniques like knowledge distillation and source-target\nalignment can help NAR models. Since the main difference between AR and NAR\nmodels is that NAR models do not use dependency among target tokens while AR\nmodels do, intuitively the difficulty of NAR sequence generation heavily\ndepends on the strongness of dependency among target tokens. To quantify such\ndependency, we propose an analysis model called CoMMA to characterize the\ndifficulty of different NAR sequence generation tasks. We have several\ninteresting findings: 1) Among the NMT, ASR and TTS tasks, ASR has the most\ntarget-token dependency while TTS has the least. 2) Knowledge distillation\nreduces the target-token dependency in target sequence and thus improves the\naccuracy of NAR models. 3) Source-target alignment constraint encourages\ndependency of a target token on source tokens and thus eases the training of\nNAR models.", "published": "2020-04-22 09:16:09", "link": "http://arxiv.org/abs/2004.10454v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Scaling through abstractions -- high-performance vectorial wave\n  simulations for seismic inversion with Devito", "abstract": "[Devito] is an open-source Python project based on domain-specific language\nand compiler technology. Driven by the requirements of rapid HPC applications\ndevelopment in exploration seismology, the language and compiler have evolved\nsignificantly since inception. Sophisticated boundary conditions, tensor\ncontractions, sparse operations and features such as staggered grids and\nsub-domains are all supported; operators of essentially arbitrary complexity\ncan be generated. To accommodate this flexibility whilst ensuring performance,\ndata dependency analysis is utilized to schedule loops and detect\ncomputational-properties such as parallelism. In this article, the generation\nand simulation of MPI-parallel propagators (along with their adjoints) for the\npseudo-acoustic wave-equation in tilted transverse isotropic media and the\nelastic wave-equation are presented. Simulations are carried out on industry\nscale synthetic models in a HPC Cloud system and reach a performance of\n28TFLOP/s, hence demonstrating Devito's suitability for production-grade\nseismic inversion problems.", "published": "2020-04-22 12:20:07", "link": "http://arxiv.org/abs/2004.10519v1", "categories": ["physics.comp-ph", "cs.CL", "cs.PF", "physics.ao-ph"], "primary_category": "physics.comp-ph"}
{"title": "Improve Variational Autoencoder for Text Generationwith Discrete Latent\n  Bottleneck", "abstract": "Variational autoencoders (VAEs) are essential tools in end-to-end\nrepresentation learning. However, the sequential text generation common pitfall\nwith VAEs is that the model tends to ignore latent variables with a strong\nauto-regressive decoder. In this paper, we propose a principled approach to\nalleviate this issue by applying a discretized bottleneck to enforce an\nimplicit latent feature matching in a more compact latent space. We impose a\nshared discrete latent space where each input is learned to choose a\ncombination of latent atoms as a regularized latent representation. Our model\nendows a promising capability to model underlying semantics of discrete\nsequences and thus provide more interpretative latent structures. Empirically,\nwe demonstrate our model's efficiency and effectiveness on a broad range of\ntasks, including language modeling, unaligned text style transfer, dialog\nresponse generation, and neural machine translation.", "published": "2020-04-22 14:41:37", "link": "http://arxiv.org/abs/2004.10603v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Categories of Semantic Concepts", "abstract": "Modelling concept representation is a foundational problem in the study of\ncognition and linguistics. This work builds on the confluence of conceptual\ntools from G\\\"ardenfors semantic spaces, categorical compositional linguistics,\nand applied category theory to present a domain-independent and categorical\nformalism of 'concept'.", "published": "2020-04-22 17:50:04", "link": "http://arxiv.org/abs/2004.10741v2", "categories": ["cs.CL", "cs.LO", "math.CT", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Towards a Competitive End-to-End Speech Recognition for CHiME-6 Dinner\n  Party Transcription", "abstract": "While end-to-end ASR systems have proven competitive with the conventional\nhybrid approach, they are prone to accuracy degradation when it comes to noisy\nand low-resource conditions. In this paper, we argue that, even in such\ndifficult cases, some end-to-end approaches show performance close to the\nhybrid baseline. To demonstrate this, we use the CHiME-6 Challenge data as an\nexample of challenging environments and noisy conditions of everyday speech. We\nexperimentally compare and analyze CTC-Attention versus RNN-Transducer\napproaches along with RNN versus Transformer architectures. We also provide a\ncomparison of acoustic features and speech enhancements. Besides, we evaluate\nthe effectiveness of neural network language models for hypothesis re-scoring\nin low-resource conditions. Our best end-to-end model based on RNN-Transducer,\ntogether with improved beam search, reaches quality by only 3.8% WER abs. worse\nthan the LF-MMI TDNN-F CHiME-6 Challenge baseline. With the Guided Source\nSeparation based training data augmentation, this approach outperforms the\nhybrid baseline system by 2.7% WER abs. and the end-to-end system best known\nbefore by 25.7% WER abs.", "published": "2020-04-22 19:08:33", "link": "http://arxiv.org/abs/2004.10799v3", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ParsEL 1.0: Unsupervised Entity Linking in Persian Social Media Texts", "abstract": "In recent years, social media data has exponentially increased, which can be\nenumerated as one of the largest data repositories in the world. A large\nportion of this social media data is natural language text. However, the\nnatural language is highly ambiguous due to exposure to the frequent\noccurrences of entities, which have polysemous words or phrases. Entity linking\nis the task of linking the entity mentions in the text to their corresponding\nentities in a knowledge base. Recently, FarsBase, a Persian knowledge graph,\nhas been introduced containing almost half a million entities. In this paper,\nwe propose an unsupervised Persian Entity Linking system, the first entity\nlinking system specially focused on the Persian language, which utilizes\ncontext-dependent and context-independent features. For this purpose, we also\npublish the first entity linking corpus of the Persian language containing\n67,595 words that have been crawled from social media texts of some popular\nchannels in the Telegram messenger. The output of the proposed method is 86.94%\nf-score for the Persian language, which is comparable with the similar\nstate-of-the-art methods in the English language.", "published": "2020-04-22 19:34:13", "link": "http://arxiv.org/abs/2004.10816v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What are We Depressed about When We Talk about COVID19: Mental Health\n  Analysis on Tweets Using Natural Language Processing", "abstract": "The outbreak of coronavirus disease 2019 (COVID-19) recently has affected\nhuman life to a great extent. Besides direct physical and economic threats, the\npandemic also indirectly impact people's mental health conditions, which can be\noverwhelming but difficult to measure. The problem may come from various\nreasons such as unemployment status, stay-at-home policy, fear for the virus,\nand so forth. In this work, we focus on applying natural language processing\n(NLP) techniques to analyze tweets in terms of mental health. We trained deep\nmodels that classify each tweet into the following emotions: anger,\nanticipation, disgust, fear, joy, sadness, surprise and trust. We build the\nEmoCT (Emotion-Covid19-Tweet) dataset for the training purpose by manually\nlabeling 1,000 English tweets. Furthermore, we propose and compare two methods\nto find out the reasons that are causing sadness and fear.", "published": "2020-04-22 23:45:04", "link": "http://arxiv.org/abs/2004.10899v3", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TransEdge: Translating Relation-contextualized Embeddings for Knowledge\n  Graphs", "abstract": "Learning knowledge graph (KG) embeddings has received increasing attention in\nrecent years. Most embedding models in literature interpret relations as linear\nor bilinear mapping functions to operate on entity embeddings. However, we find\nthat such relation-level modeling cannot capture the diverse relational\nstructures of KGs well. In this paper, we propose a novel edge-centric\nembedding model TransEdge, which contextualizes relation representations in\nterms of specific head-tail entity pairs. We refer to such contextualized\nrepresentations of a relation as edge embeddings and interpret them as\ntranslations between entity embeddings. TransEdge achieves promising\nperformance on different prediction tasks. Our experiments on benchmark\ndatasets indicate that it obtains the state-of-the-art results on\nembedding-based entity alignment. We also show that TransEdge is complementary\nwith conventional entity alignment methods. Moreover, it shows very competitive\nperformance on link prediction.", "published": "2020-04-22 03:00:45", "link": "http://arxiv.org/abs/2004.13579v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "DeepSubQE: Quality estimation for subtitle translations", "abstract": "Quality estimation (QE) for tasks involving language data is hard owing to\nnumerous aspects of natural language like variations in paraphrasing, style,\ngrammar, etc. There can be multiple answers with varying levels of\nacceptability depending on the application at hand. In this work, we look at\nestimating quality of translations for video subtitles. We show how existing QE\nmethods are inadequate and propose our method DeepSubQE as a system to estimate\nquality of translation given subtitles data for a pair of languages. We rely on\nvarious data augmentation strategies for automated labelling and synthesis for\ntraining. We create a hybrid network which learns semantic and syntactic\nfeatures of bilingual data and compare it with only-LSTM and only-CNN networks.\nOur proposed network outperforms them by significant margin.", "published": "2020-04-22 09:41:15", "link": "http://arxiv.org/abs/2004.13828v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Answer Generation through Unified Memories over Multiple Passages", "abstract": "Machine reading comprehension methods that generate answers by referring to\nmultiple passages for a question have gained much attention in AI and NLP\ncommunities. The current methods, however, do not investigate the relationships\namong multiple passages in the answer generation process, even though topics\ncorrelated among the passages may be answer candidates. Our method, called\nneural answer Generation through Unified Memories over Multiple Passages\n(GUM-MP), solves this problem as follows. First, it determines which tokens in\nthe passages are matched to the question. In particular, it investigates\nmatches between tokens in positive passages, which are assigned to the\nquestion, and those in negative passages, which are not related to the\nquestion. Next, it determines which tokens in the passage are matched to other\npassages assigned to the same question and at the same time it investigates the\ntopics in which they are matched. Finally, it encodes the token sequences with\nthe above two matching results into unified memories in the passage encoders\nand learns the answer sequence by using an encoder-decoder with a\nmultiple-pointer-generator mechanism. As a result, GUM-MP can generate answers\nby pointing to important tokens present across passages. Evaluations indicate\nthat GUM-MP generates much more accurate results than the current models do.", "published": "2020-04-22 11:46:40", "link": "http://arxiv.org/abs/2004.13829v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Linking the Lakh and IMSLP Datasets", "abstract": "This paper investigates the problem of matching a MIDI file against a large\ndatabase of piano sheet music images. Previous sheet-audio and sheet-MIDI\nalignment approaches have primarily focused on a 1-to-1 alignment task, which\nis not a scalable solution for retrieval from large databases. We propose a\nmethod for scalable cross-modal retrieval that might be used to link the Lakh\nMIDI dataset with IMSLP sheet music data. Our approach is to modify a\npreviously proposed feature representation called a symbolic bootleg score to\nbe suitable for hashing. On a database of 5,000 piano scores containing 55,000\nindividual sheet music images, our system achieves a mean reciprocal rank of\n0.84 and an average retrieval time of 25.4 seconds.", "published": "2020-04-22 04:13:10", "link": "http://arxiv.org/abs/2004.10391v1", "categories": ["eess.AS", "cs.MM", "cs.SD", "eess.IV"], "primary_category": "eess.AS"}
{"title": "Utterance-level Sequential Modeling For Deep Gaussian Process Based\n  Speech Synthesis Using Simple Recurrent Unit", "abstract": "This paper presents a deep Gaussian process (DGP) model with a recurrent\narchitecture for speech sequence modeling. DGP is a Bayesian deep model that\ncan be trained effectively with the consideration of model complexity and is a\nkernel regression model that can have high expressibility. In the previous\nstudies, it was shown that the DGP-based speech synthesis outperformed neural\nnetwork-based one, in which both models used a feed-forward architecture. To\nimprove the naturalness of synthetic speech, in this paper, we show that DGP\ncan be applied to utterance-level modeling using recurrent architecture models.\nWe adopt a simple recurrent unit (SRU) for the proposed model to achieve a\nrecurrent architecture, in which we can execute fast speech parameter\ngeneration by using the high parallelization nature of SRU. The objective and\nsubjective evaluation results show that the proposed SRU-DGP-based speech\nsynthesis outperforms not only feed-forward DGP but also automatically tuned\nSRU- and long short-term memory (LSTM)-based neural networks.", "published": "2020-04-22 19:51:36", "link": "http://arxiv.org/abs/2004.10823v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Using Cell Phone Pictures of Sheet Music To Retrieve MIDI Passages", "abstract": "This article investigates a cross-modal retrieval problem in which a user\nwould like to retrieve a passage of music from a MIDI file by taking a cell\nphone picture of several lines of sheet music. This problem is challenging for\ntwo reasons: it has a significant runtime constraint since it is a user-facing\napplication, and there is very little relevant training data containing cell\nphone images of sheet music. To solve this problem, we introduce a novel\nfeature representation called a bootleg score which encodes the position of\nnoteheads relative to staff lines in sheet music. The MIDI representation can\nbe converted into a bootleg score using deterministic rules of Western musical\nnotation, and the sheet music image can be converted into a bootleg score using\nclassical computer vision techniques for detecting simple geometrical shapes.\nOnce the MIDI and cell phone image have been converted into bootleg scores, we\ncan estimate the alignment using dynamic programming. The most notable\ncharacteristic of our system is that it has no trainable weights at all -- only\na set of about 40 hyperparameters. With a training set of just 400 images, we\nshow that our system generalizes well to a much larger set of 1600 test images\nfrom 160 unseen musical scores. Our system achieves a test F measure score of\n0.89, has an average runtime of 0.90 seconds, and outperforms baseline systems\nbased on music object detection and sheet-audio alignment. We provide extensive\nexperimental validation and analysis of our system.", "published": "2020-04-22 00:37:43", "link": "http://arxiv.org/abs/2004.11724v1", "categories": ["cs.MM", "cs.SD", "eess.AS", "eess.IV"], "primary_category": "cs.MM"}
