{"title": "Modeling Subjective Assessments of Guilt in Newspaper Crime Narratives", "abstract": "Crime reporting is a prevalent form of journalism with the power to shape\npublic perceptions and social policies. How does the language of these reports\nact on readers? We seek to address this question with the SuspectGuilt Corpus\nof annotated crime stories from English-language newspapers in the U.S. For\nSuspectGuilt, annotators read short crime articles and provided text-level\nratings concerning the guilt of the main suspect as well as span-level\nannotations indicating which parts of the story they felt most influenced their\nratings. SuspectGuilt thus provides a rich picture of how linguistic choices\naffect subjective guilt judgments. In addition, we use SuspectGuilt to train\nand assess predictive models, and show that these models benefit from genre\npretraining and joint supervision from the text-level ratings and span-level\nannotations. Such models might be used as tools for understanding the societal\neffects of crime reporting.", "published": "2020-06-17 01:21:19", "link": "http://arxiv.org/abs/2006.09589v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building Low-Resource NER Models Using Non-Speaker Annotation", "abstract": "In low-resource natural language processing (NLP), the key problems are a\nlack of target language training data, and a lack of native speakers to create\nit. Cross-lingual methods have had notable success in addressing these\nconcerns, but in certain common circumstances, such as insufficient\npre-training corpora or languages far from the source language, their\nperformance suffers. In this work we propose a complementary approach to\nbuilding low-resource Named Entity Recognition (NER) models using\n``non-speaker'' (NS) annotations, provided by annotators with no prior\nexperience in the target language. We recruit 30 participants in a carefully\ncontrolled annotation experiment with Indonesian, Russian, and Hindi. We show\nthat use of NS annotators produces results that are consistently on par or\nbetter than cross-lingual methods built on modern contextual representations,\nand have the potential to outperform with additional effort. We conclude with\nobservations of common annotation patterns and recommended implementation\npractices, and motivate how NS annotations can be used in addition to prior\nmethods for improved performance. For more details,\nhttp://cogcomp.org/page/publication_view/941", "published": "2020-06-17 03:24:38", "link": "http://arxiv.org/abs/2006.09627v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Iterative Edit-Based Unsupervised Sentence Simplification", "abstract": "We present a novel iterative, edit-based approach to unsupervised sentence\nsimplification. Our model is guided by a scoring function involving fluency,\nsimplicity, and meaning preservation. Then, we iteratively perform word and\nphrase-level edits on the complex sentence. Compared with previous approaches,\nour model does not require a parallel training set, but is more controllable\nand interpretable. Experiments on Newsela and WikiLarge datasets show that our\napproach is nearly as effective as state-of-the-art supervised approaches.", "published": "2020-06-17 03:53:12", "link": "http://arxiv.org/abs/2006.09639v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Review Neighbors for Contextualized Helpfulness Prediction", "abstract": "Helpfulness prediction techniques have been widely used to identify and\nrecommend high-quality online reviews to customers. Currently, the vast\nmajority of studies assume that a review's helpfulness is self-contained. In\npractice, however, customers hardly process reviews independently given the\nsequential nature. The perceived helpfulness of a review is likely to be\naffected by its sequential neighbors (i.e., context), which has been largely\nignored. This paper proposes a new methodology to capture the missing\ninteraction between reviews and their neighbors. The first end-to-end neural\narchitecture is developed for neighbor-aware helpfulness prediction (NAP). For\neach review, NAP allows for three types of neighbor selection: its preceding,\nfollowing, and surrounding neighbors. Four weighting schemes are designed to\nlearn context clues from the selected neighbors. A review is then\ncontextualized into the learned clues for neighbor-aware helpfulness\nprediction. NAP is evaluated on six domains of real-world online reviews\nagainst a series of state-of-the-art baselines. Extensive experiments confirm\nthe effectiveness of NAP and the influence of sequential neighbors on a current\nreviews. Further hyperparameter analysis reveals three main findings. (1) On\naverage, eight neighbors treated with uneven importance are engaged for context\nconstruction. (2) The benefit of neighbor-aware prediction mainly results from\ncloser neighbors. (3) Equally considering up to five closest neighbors of a\nreview can usually produce a weaker but tolerable prediction result.", "published": "2020-06-17 07:02:42", "link": "http://arxiv.org/abs/2006.09685v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatically Ranked Russian Paraphrase Corpus for Text Generation", "abstract": "The article is focused on automatic development and ranking of a large corpus\nfor Russian paraphrase generation which proves to be the first corpus of such\ntype in Russian computational linguistics. Existing manually annotated\nparaphrase datasets for Russian are limited to small-sized ParaPhraser corpus\nand ParaPlag which are suitable for a set of NLP tasks, such as paraphrase and\nplagiarism detection, sentence similarity and relatedness estimation, etc. Due\nto size restrictions, these datasets can hardly be applied in end-to-end text\ngeneration solutions. Meanwhile, paraphrase generation requires a large amount\nof training data. In our study we propose a solution to the problem: we\ncollect, rank and evaluate a new publicly available headline paraphrase corpus\n(ParaPhraser Plus), and then perform text generation experiments with manual\nevaluation on automatically ranked corpora using the Universal Transformer\narchitecture.", "published": "2020-06-17 08:40:52", "link": "http://arxiv.org/abs/2006.09719v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving unsupervised neural aspect extraction for online discussions\n  using out-of-domain classification", "abstract": "Deep learning architectures based on self-attention have recently achieved\nand surpassed state of the art results in the task of unsupervised aspect\nextraction and topic modeling. While models such as neural attention-based\naspect extraction (ABAE) have been successfully applied to user-generated\ntexts, they are less coherent when applied to traditional data sources such as\nnews articles and newsgroup documents. In this work, we introduce a simple\napproach based on sentence filtering in order to improve topical aspects\nlearned from newsgroups-based content without modifying the basic mechanism of\nABAE. We train a probabilistic classifier to distinguish between out-of-domain\ntexts (outer dataset) and in-domain texts (target dataset). Then, during data\npreparation we filter out sentences that have a low probability of being\nin-domain and train the neural model on the remaining sentences. The positive\neffect of sentence filtering on topic coherence is demonstrated in comparison\nto aspect extraction models trained on unfiltered texts.", "published": "2020-06-17 10:34:16", "link": "http://arxiv.org/abs/2006.09766v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extensively Matching for Few-shot Learning Event Detection", "abstract": "Current event detection models under super-vised learning settings fail to\ntransfer to newevent types. Few-shot learning has not beenexplored in event\ndetection even though it al-lows a model to perform well with high\ngener-alization on new event types. In this work, weformulate event detection\nas a few-shot learn-ing problem to enable to extend event detec-tion to new\nevent types. We propose two novelloss factors that matching examples in the\nsup-port set to provide more training signals to themodel. Moreover, these\ntraining signals can beapplied in many metric-based few-shot learn-ing models.\nOur extensive experiments on theACE-2005 dataset (under a few-shot\nlearningsetting) show that the proposed method can im-prove the performance of\nfew-shot learning", "published": "2020-06-17 18:30:30", "link": "http://arxiv.org/abs/2006.10093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is this Dialogue Coherent? Learning from Dialogue Acts and Entities", "abstract": "In this work, we investigate the human perception of coherence in open-domain\ndialogues. In particular, we address the problem of annotating and modeling the\ncoherence of next-turn candidates while considering the entire history of the\ndialogue. First, we create the Switchboard Coherence (SWBD-Coh) corpus, a\ndataset of human-human spoken dialogues annotated with turn coherence ratings,\nwhere next-turn candidate utterances ratings are provided considering the full\ndialogue context. Our statistical analysis of the corpus indicates how turn\ncoherence perception is affected by patterns of distribution of entities\npreviously introduced and the Dialogue Acts used. Second, we experiment with\ndifferent architectures to model entities, Dialogue Acts and their combination\nand evaluate their performance in predicting human coherence ratings on\nSWBD-Coh. We find that models combining both DA and entity information yield\nthe best performances both for response selection and turn coherence rating.", "published": "2020-06-17 21:02:40", "link": "http://arxiv.org/abs/2006.10157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Canonicalizing Open Knowledge Bases with Multi-Layered Meta-Graph Neural\n  Network", "abstract": "Noun phrases and relational phrases in Open Knowledge Bases are often not\ncanonical, leading to redundant and ambiguous facts. In this work, we integrate\nstructural information (from which tuple, which sentence) and semantic\ninformation (semantic similarity) to do the canonicalization. We represent the\ntwo types of information as a multi-layered graph: the structural information\nforms the links across the sentence, relational phrase, and noun phrase layers;\nthe semantic information forms weighted intra-layer links for each layer. We\npropose a graph neural network model to aggregate the representations of noun\nphrases and relational phrases through the multi-layered meta-graph structure.\nExperiments show that our model outperforms existing approaches on a public\ndatasets in general domain.", "published": "2020-06-17 02:32:36", "link": "http://arxiv.org/abs/2006.09610v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Exploratory Study of Argumentative Writing by Young Students: A\n  Transformer-based Approach", "abstract": "We present a computational exploration of argument critique writing by young\nstudents. Middle school students were asked to criticize an argument presented\nin the prompt, focusing on identifying and explaining the reasoning flaws. This\ntask resembles an established college-level argument critique task. Lexical and\ndiscourse features that utilize detailed domain knowledge to identify critiques\nexist for the college task but do not perform well on the young students data.\nInstead, transformer-based architecture (e.g., BERT) fine-tuned on a large\ncorpus of critique essays from the college task performs much better (over 20%\nimprovement in F1 score). Analysis of the performance of various configurations\nof the system suggests that while children's writing does not exhibit the\nstandard discourse structure of an argumentative essay, it does share basic\nlocal sequential structures with the more mature writers.", "published": "2020-06-17 13:55:31", "link": "http://arxiv.org/abs/2006.09873v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fine-grained Sentiment Controlled Text Generation", "abstract": "Controlled text generation techniques aim to regulate specific attributes\n(e.g. sentiment) while preserving the attribute independent content. The\nstate-of-the-art approaches model the specified attribute as a structured or\ndiscrete representation while making the content representation independent of\nit to achieve a better control. However, disentangling the text representation\ninto separate latent spaces overlooks complex dependencies between content and\nattribute, leading to generation of poorly constructed and not so meaningful\nsentences. Moreover, such an approach fails to provide a finer control on the\ndegree of attribute change. To address these problems of controlled text\ngeneration, in this paper, we propose DE-VAE, a hierarchical framework which\ncaptures both information enriched entangled representation and attribute\nspecific disentangled representation in different hierarchies. DE-VAE achieves\nbetter control of sentiment as an attribute while preserving the content by\nlearning a suitable lossless transformation network from the disentangled\nsentiment space to the desired entangled representation. Through feature\nsupervision on a single dimension of the disentangled representation, DE-VAE\nmaps the variation of sentiment to a continuous space which helps in smoothly\nregulating sentiment from positive to negative and vice versa. Detailed\nexperiments on three publicly available review datasets show the superiority of\nDE-VAE over recent state-of-the-art approaches.", "published": "2020-06-17 14:17:58", "link": "http://arxiv.org/abs/2006.09891v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using Sentiment Information for Preemptive Detection of Toxic Comments\n  in Online Conversations", "abstract": "The challenge of automatic detection of toxic comments online has been the\nsubject of a lot of research recently, but the focus has been mostly on\ndetecting it in individual messages after they have been posted. Some authors\nhave tried to predict if a conversation will derail into toxicity using the\nfeatures of the first few messages. In this paper, we combine that approach\nwith previous work on toxicity detection using sentiment information, and show\nhow the sentiments expressed in the first messages of a conversation can help\npredict upcoming toxicity. Our results show that adding sentiment features does\nhelp improve the accuracy of toxicity prediction, and also allow us to make\nimportant observations on the general task of preemptive toxicity detection.", "published": "2020-06-17 20:41:57", "link": "http://arxiv.org/abs/2006.10145v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "CO-Search: COVID-19 Information Retrieval with Semantic Search, Question\n  Answering, and Abstractive Summarization", "abstract": "The COVID-19 global pandemic has resulted in international efforts to\nunderstand, track, and mitigate the disease, yielding a significant corpus of\nCOVID-19 and SARS-CoV-2-related publications across scientific disciplines. As\nof May 2020, 128,000 coronavirus-related publications have been collected\nthrough the COVID-19 Open Research Dataset Challenge. Here we present\nCO-Search, a retriever-ranker semantic search engine designed to handle complex\nqueries over the COVID-19 literature, potentially aiding overburdened health\nworkers in finding scientific answers during a time of crisis. The retriever is\nbuilt from a Siamese-BERT encoder that is linearly composed with a TF-IDF\nvectorizer, and reciprocal-rank fused with a BM25 vectorizer. The ranker is\ncomposed of a multi-hop question-answering module, that together with a\nmulti-paragraph abstractive summarizer adjust retriever scores. To account for\nthe domain-specific and relatively limited dataset, we generate a bipartite\ngraph of document paragraphs and citations, creating 1.3 million (citation\ntitle, paragraph) tuples for training the encoder. We evaluate our system on\nthe data of the TREC-COVID information retrieval challenge. CO-Search obtains\ntop performance on the datasets of the first and second rounds, across several\nkey metrics: normalized discounted cumulative gain, precision, mean average\nprecision, and binary preference.", "published": "2020-06-17 01:32:48", "link": "http://arxiv.org/abs/2006.09595v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "De-Anonymizing Text by Fingerprinting Language Generation", "abstract": "Components of machine learning systems are not (yet) perceived as security\nhotspots. Secure coding practices, such as ensuring that no execution paths\ndepend on confidential inputs, have not yet been adopted by ML developers. We\ninitiate the study of code security of ML systems by investigating how nucleus\nsampling---a popular approach for generating text, used for applications such\nas auto-completion---unwittingly leaks texts typed by users. Our main result is\nthat the series of nucleus sizes for many natural English word sequences is a\nunique fingerprint. We then show how an attacker can infer typed text by\nmeasuring these fingerprints via a suitable side channel (e.g., cache access\ntimes), explain how this attack could help de-anonymize anonymous texts, and\ndiscuss defenses.", "published": "2020-06-17 02:49:15", "link": "http://arxiv.org/abs/2006.09615v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A Tweet-based Dataset for Company-Level Stock Return Prediction", "abstract": "Public opinion influences events, especially related to stock market\nmovement, in which a subtle hint can influence the local outcome of the market.\nIn this paper, we present a dataset that allows for company-level analysis of\ntweet based impact on one-, two-, three-, and seven-day stock returns. Our\ndataset consists of 862, 231 labelled instances from twitter in English, we\nalso release a cleaned subset of 85, 176 labelled instances to the community.\nWe also provide baselines using standard machine learning algorithms and a\nmulti-view learning based approach that makes use of different types of\nfeatures. Our dataset, scripts and models are publicly available at:\nhttps://github.com/ImperialNLP/stockreturnpred.", "published": "2020-06-17 08:55:11", "link": "http://arxiv.org/abs/2006.09723v1", "categories": ["cs.CL", "cs.SI", "q-fin.ST"], "primary_category": "cs.CL"}
{"title": "On the Learnability of Concepts: With Applications to Comparing Word\n  Embedding Algorithms", "abstract": "Word Embeddings are used widely in multiple Natural Language Processing (NLP)\napplications. They are coordinates associated with each word in a dictionary,\ninferred from statistical properties of these words in a large corpus. In this\npaper we introduce the notion of \"concept\" as a list of words that have shared\nsemantic content. We use this notion to analyse the learnability of certain\nconcepts, defined as the capability of a classifier to recognise unseen members\nof a concept after training on a random subset of it. We first use this method\nto measure the learnability of concepts on pretrained word embeddings. We then\ndevelop a statistical analysis of concept learnability, based on hypothesis\ntesting and ROC curves, in order to compare the relative merits of various\nembedding algorithms using a fixed corpora and hyper parameters. We find that\nall embedding methods capture the semantic content of those word lists, but\nfastText performs better than the others.", "published": "2020-06-17 14:25:36", "link": "http://arxiv.org/abs/2006.09896v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning for Weakly Supervised Phrase Grounding", "abstract": "Phrase grounding, the problem of associating image regions to caption words,\nis a crucial component of vision-language tasks. We show that phrase grounding\ncan be learned by optimizing word-region attention to maximize a lower bound on\nmutual information between images and caption words. Given pairs of images and\ncaptions, we maximize compatibility of the attention-weighted regions and the\nwords in the corresponding caption, compared to non-corresponding pairs of\nimages and captions. A key idea is to construct effective negative captions for\nlearning through language model guided word substitutions. Training with our\nnegatives yields a $\\sim10\\%$ absolute gain in accuracy over randomly-sampled\nnegatives from the training data. Our weakly supervised phrase grounding model\ntrained on COCO-Captions shows a healthy gain of $5.7\\%$ to achieve $76.7\\%$\naccuracy on Flickr30K Entities benchmark.", "published": "2020-06-17 15:00:53", "link": "http://arxiv.org/abs/2006.09920v3", "categories": ["cs.CV", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Conversational Neuro-Symbolic Commonsense Reasoning", "abstract": "In order for conversational AI systems to hold more natural and broad-ranging\nconversations, they will require much more commonsense, including the ability\nto identify unstated presumptions of their conversational partners. For\nexample, in the command \"If it snows at night then wake me up early because I\ndon't want to be late for work\" the speaker relies on commonsense reasoning of\nthe listener to infer the implicit presumption that they wish to be woken only\nif it snows enough to cause traffic slowdowns. We consider here the problem of\nunderstanding such imprecisely stated natural language commands given in the\nform of \"if-(state), then-(action), because-(goal)\" statements. More precisely,\nwe consider the problem of identifying the unstated presumptions of the speaker\nthat allow the requested action to achieve the desired goal from the given\nstate (perhaps elaborated by making the implicit presumptions explicit). We\nrelease a benchmark data set for this task, collected from humans and annotated\nwith commonsense presumptions. We present a neuro-symbolic theorem prover that\nextracts multi-hop reasoning chains, and apply it to this problem. Furthermore,\nto accommodate the reality that current AI commonsense systems lack full\ncoverage, we also present an interactive conversational framework built on our\nneuro-symbolic system, that conversationally evokes commonsense knowledge from\nhumans to complete its reasoning chains.", "published": "2020-06-17 17:28:38", "link": "http://arxiv.org/abs/2006.10022v3", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Overcoming Statistical Shortcuts for Open-ended Visual Counting", "abstract": "Machine learning models tend to over-rely on statistical shortcuts. These\nspurious correlations between parts of the input and the output labels does not\nhold in real-world settings. We target this issue on the recent open-ended\nvisual counting task which is well suited to study statistical shortcuts. We\naim to develop models that learn a proper mechanism of counting regardless of\nthe output label. First, we propose the Modifying Count Distribution (MCD)\nprotocol, which penalizes models that over-rely on statistical shortcuts. It is\nbased on pairs of training and testing sets that do not follow the same count\nlabel distribution such as the odd-even sets. Intuitively, models that have\nlearned a proper mechanism of counting on odd numbers should perform well on\neven numbers. Secondly, we introduce the Spatial Counting Network (SCN), which\nis dedicated to visual analysis and counting based on natural language\nquestions. Our model selects relevant image regions, scores them with fusion\nand self-attention mechanisms, and provides a final counting score. We apply\nour protocol on the recent dataset, TallyQA, and show superior performances\ncompared to state-of-the-art models. We also demonstrate the ability of our\nmodel to select the correct instances to count in the image. Code and datasets\nare available: https://github.com/cdancette/spatial-counting-network", "published": "2020-06-17 18:02:01", "link": "http://arxiv.org/abs/2006.10079v2", "categories": ["cs.CV", "cs.CL", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "MIMICS: A Large-Scale Data Collection for Search Clarification", "abstract": "Search clarification has recently attracted much attention due to its\napplications in search engines. It has also been recognized as a major\ncomponent in conversational information seeking systems. Despite its\nimportance, the research community still feels the lack of a large-scale data\nfor studying different aspects of search clarification. In this paper, we\nintroduce MIMICS, a collection of search clarification datasets for real web\nsearch queries sampled from the Bing query logs. Each clarification in MIMICS\nis generated by a Bing production algorithm and consists of a clarifying\nquestion and up to five candidate answers. MIMICS contains three datasets: (1)\nMIMICS-Click includes over 400k unique queries, their associated clarification\npanes, and the corresponding aggregated user interaction signals (i.e.,\nclicks). (2) MIMICS-ClickExplore is an exploration data that includes\naggregated user interaction signals for over 60k unique queries, each with\nmultiple clarification panes. (3) MIMICS-Manual includes over 2k unique real\nsearch queries. Each query-clarification pair in this dataset has been manually\nlabeled by at least three trained annotators. It contains graded quality labels\nfor the clarifying question, the candidate answer set, and the landing result\npage for each candidate answer.\n  MIMICS is publicly available for research purposes, thus enables researchers\nto study a number of tasks related to search clarification, including\nclarification generation and selection, user engagement prediction for\nclarification, click models for clarification, and analyzing user interactions\nwith search clarification.", "published": "2020-06-17 21:54:41", "link": "http://arxiv.org/abs/2006.10174v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Political Advertising Dataset: the use case of the Polish 2020\n  Presidential Elections", "abstract": "Political campaigns are full of political ads posted by candidates on social\nmedia. Political advertisements constitute a basic form of campaigning,\nsubjected to various social requirements. We present the first publicly open\ndataset for detecting specific text chunks and categories of political\nadvertising in the Polish language. It contains 1,705 human-annotated tweets\ntagged with nine categories, which constitute campaigning under Polish\nelectoral law. We achieved a 0.65 inter-annotator agreement (Cohen's kappa\nscore). An additional annotator resolved the mismatches between the first two\nannotators improving the consistency and complexity of the annotation process.\nWe used the newly created dataset to train a well established neural tagger\n(achieving a 70% percent points F1 score). We also present a possible direction\nof use cases for such datasets and models with an initial analysis of the\nPolish 2020 Presidential Elections on Twitter.", "published": "2020-06-17 23:58:01", "link": "http://arxiv.org/abs/2006.10207v1", "categories": ["cs.CL", "cs.CC", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards User Friendly Medication Mapping Using Entity-Boosted Two-Tower\n  Neural Network", "abstract": "Recent advancements in medical entity linking have been applied in the area\nof scientific literature and social media data. However, with the adoption of\ntelemedicine and conversational agents such as Alexa in healthcare settings,\nmedical name inference has become an important task. Medication name inference\nis the task of mapping user friendly medication names from a free-form text to\na concept in a normalized medication list. This is challenging due to the\ndifferences in the use of medical terminology from health care professionals\nand user conversations coming from the lay public. We begin with mapping\ndescriptive medication phrases (DMP) to standard medication names (SMN). Given\nthe prescriptions of each patient, we want to provide them with the flexibility\nof referring to the medication in their preferred ways. We approach this as a\nranking problem which maps SMN to DMP by ordering the list of medications in\nthe patient's prescription list obtained from pharmacies. Furthermore, we\nleveraged the output of intermediate layers and performed medication\nclustering. We present the Medication Inference Model (MIM) achieving\nstate-of-the-art results. By incorporating medical entities based attention, we\nhave obtained further improvement for ranking models.", "published": "2020-06-17 18:56:44", "link": "http://arxiv.org/abs/2007.00492v2", "categories": ["cs.CL", "cs.CY", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Real-time visualisation of fugue played by a string quartet", "abstract": "We present a new system for real-time visualisation of music performance,\nfocused for the moment on a fugue played by a string quartet. The basic\nprinciple is to offer a visual guide to better understand music using\nstrategies that should be as engaging, accessible and effective as possible.\nThe pitch curves related to the separate voices are drawn on a space whose\ntemporal axis is normalised with respect to metrical positions, and aligned\nvertically with respect to their thematic and motivic classification. Aspects\nrelated to tonality are represented as well. We describe the underlying\ntechnologies we have developed and the technical setting. In particular, the\nrhythmical and structural representation of the piece relies on real-time\npolyphonic audio-to-score alignment using online dynamic time warping. The\nvisualisation will be presented at a concert of the Danish String Quartet,\nperforming the last piece of The Art of Fugue by Johann Sebastian Bach.", "published": "2020-06-17 21:31:54", "link": "http://arxiv.org/abs/2006.10168v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Visual Attention for Musical Instrument Recognition", "abstract": "In the field of music information retrieval, the task of simultaneously\nidentifying the presence or absence of multiple musical instruments in a\npolyphonic recording remains a hard problem. Previous works have seen some\nsuccess in improving instrument classification by applying temporal attention\nin a multi-instance multi-label setting, while another series of work has also\nsuggested the role of pitch and timbre in improving instrument recognition\nperformance. In this project, we further explore the use of attention mechanism\nin a timbral-temporal sense, \\`a la visual attention, to improve the\nperformance of musical instrument recognition using weakly-labeled data. Two\napproaches to this task have been explored. The first approach applies\nattention mechanism to the sliding-window paradigm, where a prediction based on\neach timbral-temporal `instance' is given an attention weight, before\naggregation to produce the final prediction. The second approach is based on a\nrecurrent model of visual attention where the network only attends to parts of\nthe spectrogram and decide where to attend to next, given a limited number of\n`glimpses'.", "published": "2020-06-17 03:56:44", "link": "http://arxiv.org/abs/2006.09640v2", "categories": ["eess.AS", "cs.IR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ExSampling: a system for the real-time ensemble performance of\n  field-recorded environmental sounds", "abstract": "We propose ExSampling: an integrated system of recording application and Deep\nLearning environment for a real-time music performance of environmental sounds\nsampled by field recording. Automated sound mapping to Ableton Live tracks by\nDeep Learning enables field recording to be applied to real-time performance,\nand create interactions among sound recorders, composers and performers.", "published": "2020-06-17 04:07:13", "link": "http://arxiv.org/abs/2006.09645v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Are you wearing a mask? Improving mask detection from speech using\n  augmentation by cycle-consistent GANs", "abstract": "The task of detecting whether a person wears a face mask from speech is\nuseful in modelling speech in forensic investigations, communication between\nsurgeons or people protecting themselves against infectious diseases such as\nCOVID-19. In this paper, we propose a novel data augmentation approach for mask\ndetection from speech. Our approach is based on (i) training Generative\nAdversarial Networks (GANs) with cycle-consistency loss to translate unpaired\nutterances between two classes (with mask and without mask), and on (ii)\ngenerating new training utterances using the cycle-consistent GANs, assigning\nopposite labels to each translated utterance. Original and translated\nutterances are converted into spectrograms which are provided as input to a set\nof ResNet neural networks with various depths. The networks are combined into\nan ensemble through a Support Vector Machines (SVM) classifier. With this\nsystem, we participated in the Mask Sub-Challenge (MSC) of the INTERSPEECH 2020\nComputational Paralinguistics Challenge, surpassing the baseline proposed by\nthe organizers by 2.8%. Our data augmentation technique provided a performance\nboost of 0.9% on the private test set. Furthermore, we show that our data\naugmentation approach yields better results than other baseline and\nstate-of-the-art augmentation methods.", "published": "2020-06-17 20:46:50", "link": "http://arxiv.org/abs/2006.10147v2", "categories": ["eess.AS", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Artificial Musical Intelligence: A Survey", "abstract": "Computers have been used to analyze and create music since they were first\nintroduced in the 1950s and 1960s. Beginning in the late 1990s, the rise of the\nInternet and large scale platforms for music recommendation and retrieval have\nmade music an increasingly prevalent domain of machine learning and artificial\nintelligence research. While still nascent, several different approaches have\nbeen employed to tackle what may broadly be referred to as \"musical\nintelligence.\" This article provides a definition of musical intelligence,\nintroduces a taxonomy of its constituent components, and surveys the wide range\nof AI methods that can be, and have been, brought to bear in its pursuit, with\na particular emphasis on machine learning methods.", "published": "2020-06-17 04:46:32", "link": "http://arxiv.org/abs/2006.10553v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quick Lists: Enriched Playlist Embeddings for Future Playlist\n  Recommendation", "abstract": "Recommending playlists to users in the context of a digital music service is\na difficult task because a playlist is often more than the mere sum of its\nparts. We present a novel method for generating playlist embeddings that are\ninvariant to playlist length and sensitive to local and global track ordering.\nThe embeddings also capture information about playlist sequencing, and are\nenriched with side information about the playlist user. We show that these\nembeddings are useful for generating next-best playlist recommendations, and\nthat side information can be used for the cold start problem.", "published": "2020-06-17 17:08:52", "link": "http://arxiv.org/abs/2006.12382v1", "categories": ["cs.IR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
