{"title": "Automated Identification of Drug-Drug Interactions in Pediatric\n  Congestive Heart Failure Patients", "abstract": "Congestive Heart Failure, or CHF, is a serious medical condition that can\nresult in fluid buildup in the body as a result of a weak heart. When the heart\ncan't pump enough blood to efficiently deliver nutrients and oxygen to the\nbody, kidney function may be impaired, resulting in fluid retention. CHF\npatients require a broad drug regimen to maintain the delicate system balance,\nparticularly between their heart and kidneys. These drugs include ACE\ninhibitors and Beta Blockers to control blood pressure, anticoagulants to\nprevent blood clots, and diuretics to reduce fluid overload. Many of these\ndrugs may interact, and potential effects of these interactions must be weighed\nagainst their benefits. For this project, we consider a set of 44 drugs\nidentified as specifically relevant for treating CHF by pediatric cardiologists\nat Lucile Packard Children's Hospital. This list was generated as part of our\ncurrent work at the LPCH Heart Center. The goal of this project is to identify\nand evaluate potentially harmful drug-drug interactions (DDIs) within pediatric\npatients with Congestive Heart Failure. This identification will be done\nautonomously, so that it may continuously update by evaluating newly published\nliterature.", "published": "2017-02-11 02:21:42", "link": "http://arxiv.org/abs/1702.04615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parallel Long Short-Term Memory for Multi-stream Classification", "abstract": "Recently, machine learning methods have provided a broad spectrum of original\nand efficient algorithms based on Deep Neural Networks (DNN) to automatically\npredict an outcome with respect to a sequence of inputs. Recurrent hidden cells\nallow these DNN-based models to manage long-term dependencies such as Recurrent\nNeural Networks (RNN) and Long Short-Term Memory (LSTM). Nevertheless, these\nRNNs process a single input stream in one (LSTM) or two (Bidirectional LSTM)\ndirections. But most of the information available nowadays is from multistreams\nor multimedia documents, and require RNNs to process these information\nsynchronously during the training. This paper presents an original LSTM-based\narchitecture, named Parallel LSTM (PLSTM), that carries out multiple parallel\nsynchronized input sequences in order to predict a common output. The proposed\nPLSTM method could be used for parallel sequence classification purposes. The\nPLSTM approach is evaluated on an automatic telecast genre sequences\nclassification task and compared with different state-of-the-art architectures.\nResults show that the proposed PLSTM method outperforms the baseline n-gram\nmodels as well as the state-of-the-art LSTM approach.", "published": "2017-02-11 09:50:40", "link": "http://arxiv.org/abs/1702.03402v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
