{"title": "The Latent Structure of Dictionaries", "abstract": "How many words (and which ones) are sufficient to define all other words?\nWhen dictionaries are analyzed as directed graphs with links from defining\nwords to defined words, they reveal a latent structure. Recursively removing\nall words that are reachable by definition but that do not define any further\nwords reduces the dictionary to a Kernel of about 10%. This is still not the\nsmallest number of words that can define all the rest. About 75% of the Kernel\nturns out to be its Core, a Strongly Connected Subset of words with a\ndefinitional path to and from any pair of its words and no word's definition\ndepending on a word outside the set. But the Core cannot define all the rest of\nthe dictionary. The 25% of the Kernel surrounding the Core consists of small\nstrongly connected subsets of words: the Satellites. The size of the smallest\nset of words that can define all the rest (the graph's Minimum Feedback Vertex\nSet or MinSet) is about 1% of the dictionary, 15% of the Kernel, and half-Core,\nhalf-Satellite. But every dictionary has a huge number of MinSets. The Core\nwords are learned earlier, more frequent, and less concrete than the\nSatellites, which in turn are learned earlier and more frequent but more\nconcrete than the rest of the Dictionary. In principle, only one MinSet's words\nwould need to be grounded through the sensorimotor capacity to recognize and\ncategorize their referents. In a dual-code sensorimotor-symbolic model of the\nmental lexicon, the symbolic code could do all the rest via re-combinatory\ndefinition.", "published": "2014-11-01 15:52:05", "link": "http://arxiv.org/abs/1411.0129v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
