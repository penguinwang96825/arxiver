{"title": "Comparative Error Analysis in Neural and Finite-state Models for\n  Unsupervised Character-level Transduction", "abstract": "Traditionally, character-level transduction problems have been solved with\nfinite-state models designed to encode structural and linguistic knowledge of\nthe underlying process, whereas recent approaches rely on the power and\nflexibility of sequence-to-sequence models with attention. Focusing on the less\nexplored unsupervised learning scenario, we compare the two model classes side\nby side and find that they tend to make different types of errors even when\nachieving comparable performance. We analyze the distributions of different\nerror classes using two unsupervised tasks as testbeds: converting informally\nromanized text into the native script of its language (for Russian, Arabic, and\nKannada) and translating between a pair of closely related languages (Serbian\nand Bosnian). Finally, we investigate how combining finite-state and\nsequence-to-sequence models at decoding time affects the output quantitatively\nand qualitatively.", "published": "2021-06-24 00:09:24", "link": "http://arxiv.org/abs/2106.12698v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Efficient Group-based Search Engine Marketing System for E-Commerce", "abstract": "With the increasing scale of search engine marketing, designing an efficient\nbidding system is becoming paramount for the success of e-commerce companies.\nThe critical challenges faced by a modern industrial-level bidding system\ninclude: 1. the catalog is enormous, and the relevant bidding features are of\nhigh sparsity; 2. the large volume of bidding requests induces significant\ncomputation burden to both the offline and online serving. Leveraging\nextraneous user-item information proves essential to mitigate the sparsity\nissue, for which we exploit the natural language signals from the users' query\nand the contextual knowledge from the products. In particular, we extract the\nvector representations of ads via the Transformer model and leverage their\ngeometric relation to building collaborative bidding predictions via\nclustering. The two-step procedure also significantly reduces the computation\nstress of bid evaluation and optimization. In this paper, we introduce the\nend-to-end structure of the bidding system for search engine marketing for\nWalmart e-commerce, which successfully handles tens of millions of bids each\nday. We analyze the online and offline performances of our approach and discuss\nhow we find it as a production-efficient solution.", "published": "2021-06-24 00:12:07", "link": "http://arxiv.org/abs/2106.12700v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Diagnostic Label Correlation for Automatic ICD Coding", "abstract": "Given the clinical notes written in electronic health records (EHRs), it is\nchallenging to predict the diagnostic codes which is formulated as a\nmulti-label classification task. The large set of labels, the hierarchical\ndependency, and the imbalanced data make this prediction task extremely hard.\nMost existing work built a binary prediction for each label independently,\nignoring the dependencies between labels. To address this problem, we propose a\ntwo-stage framework to improve automatic ICD coding by capturing the label\ncorrelation. Specifically, we train a label set distribution estimator to\nrescore the probability of each label set candidate generated by a base\npredictor. This paper is the first attempt at learning the label set\ndistribution as a reranking module for medical code prediction. In the\nexperiments, our proposed framework is able to improve upon best-performing\npredictors on the benchmark MIMIC datasets. The source code of this project is\navailable at https://github.com/MiuLab/ICD-Correlation.", "published": "2021-06-24 07:26:30", "link": "http://arxiv.org/abs/2106.12800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OKGIT: Open Knowledge Graph Link Prediction with Implicit Types", "abstract": "Open Knowledge Graphs (OpenKG) refer to a set of (head noun phrase, relation\nphrase, tail noun phrase) triples such as (tesla, return to, new york)\nextracted from a corpus using OpenIE tools. While OpenKGs are easy to bootstrap\nfor a domain, they are very sparse and far from being directly usable in an end\ntask. Therefore, the task of predicting new facts, i.e., link prediction,\nbecomes an important step while using these graphs in downstream tasks such as\ntext comprehension, question answering, and web search query recommendation.\nLearning embeddings for OpenKGs is one approach for link prediction that has\nreceived some attention lately. However, on careful examination, we found that\ncurrent OpenKG link prediction algorithms often predict noun phrases (NPs) with\nincompatible types for given noun and relation phrases. We address this problem\nin this work and propose OKGIT that improves OpenKG link prediction using novel\ntype compatibility score and type regularization. With extensive experiments on\nmultiple datasets, we show that the proposed method achieves state-of-the-art\nperformance while producing type compatible NPs in the link prediction task.", "published": "2021-06-24 07:48:05", "link": "http://arxiv.org/abs/2106.12806v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Influence of Machine Translation on Language Origin Obfuscation", "abstract": "In the last decade, machine translation has become a popular means to deal\nwith multilingual digital content. By providing higher quality translations,\nobfuscating the source language of a text becomes more attractive. In this\npaper, we analyze the ability to detect the source language from the translated\noutput of two widely used commercial machine translation systems by utilizing\nmachine-learning algorithms with basic textual features like n-grams.\nEvaluations show that the source language can be reconstructed with high\naccuracy for documents that contain a sufficient amount of translated text. In\naddition, we analyze how the document size influences the performance of the\nprediction, as well as how limiting the set of possible source languages\nimproves the classification accuracy.", "published": "2021-06-24 08:33:24", "link": "http://arxiv.org/abs/2106.12830v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Self-Identified Counseling Expertise in Online Support Forums", "abstract": "A growing number of people engage in online health forums, making it\nimportant to understand the quality of the advice they receive. In this paper,\nwe explore the role of expertise in responses provided to help-seeking posts\nregarding mental health. We study the differences between (1) interactions with\npeers; and (2) interactions with self-identified mental health professionals.\nFirst, we show that a classifier can distinguish between these two groups,\nindicating that their language use does in fact differ. To understand this\ndifference, we perform several analyses addressing engagement aspects,\nincluding whether their comments engage the support-seeker further as well as\nlinguistic aspects, such as dominant language and linguistic style matching.\nOur work contributes toward the developing efforts of understanding how health\nexperts engage with health information- and support-seekers in social networks.\nMore broadly, it is a step toward a deeper understanding of the styles of\ninteractions that cultivate supportive engagement in online communities.", "published": "2021-06-24 12:53:07", "link": "http://arxiv.org/abs/2106.12976v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Splitting EUD graphs into trees: A quick and clatty approach", "abstract": "We present the system submission from the FASTPARSE team for the EUD Shared\nTask at IWPT 2021. We engaged in the task last year by focusing on efficiency.\nThis year we have focused on experimenting with new ideas on a limited time\nbudget. Our system is based on splitting the EUD graph into several trees,\nbased on linguistic criteria. We predict these trees using a sequence-labelling\nparser and combine them into an EUD graph. The results were relatively poor,\nalthough not a total disaster and could probably be improved with some\npolishing of the system's rough edges.", "published": "2021-06-24 16:28:55", "link": "http://arxiv.org/abs/2106.13155v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VOGUE: Answer Verbalization through Multi-Task Learning", "abstract": "In recent years, there have been significant developments in Question\nAnswering over Knowledge Graphs (KGQA). Despite all the notable advancements,\ncurrent KGQA systems only focus on answer generation techniques and not on\nanswer verbalization. However, in real-world scenarios (e.g., voice assistants\nsuch as Alexa, Siri, etc.), users prefer verbalized answers instead of a\ngenerated response. This paper addresses the task of answer verbalization for\n(complex) question answering over knowledge graphs. In this context, we propose\na multi-task-based answer verbalization framework: VOGUE (Verbalization thrOuGh\nmUlti-task lEarning). The VOGUE framework attempts to generate a verbalized\nanswer using a hybrid approach through a multi-task learning paradigm. Our\nframework can generate results based on using questions and queries as inputs\nconcurrently. VOGUE comprises four modules that are trained simultaneously\nthrough multi-task learning. We evaluate our framework on existing datasets for\nanswer verbalization, and it outperforms all current baselines on both BLEU and\nMETEOR scores.", "published": "2021-06-24 21:05:32", "link": "http://arxiv.org/abs/2106.13316v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discovering novel drug-supplement interactions using a dietary\n  supplements knowledge graph generated from the biomedical literature", "abstract": "OBJECTIVE: Leverage existing biomedical NLP tools and DS domain terminology\nto produce a novel and comprehensive knowledge graph containing dietary\nsupplement (DS) information for discovering interactions between DS and drugs,\nor Drug-Supplement Interactions (DSI). MATERIALS AND METHODS: We created\nSemRepDS (an extension of SemRep), capable of extracting semantic relations\nfrom abstracts by leveraging a DS-specific terminology (iDISK) containing\n28,884 DS terms not found in the UMLS. PubMed abstracts were processed using\nSemRepDS to generate semantic relations, which were then filtered using a\nPubMedBERT-based model to remove incorrect relations before generating our\nknowledge graph (SuppKG). Two pathways are used to identify potential DS-Drug\ninteractions which are then evaluated by medical professionals for mechanistic\nplausibility. RESULTS: Comparison analysis found that SemRepDS returned 206.9%\nmore DS relations and 158.5% more DS entities than SemRep. The fine-tuned BERT\nmodel obtained an F1 score of 0.8605 and removed 43.86% of the relations,\nimproving the precision of the relations by 26.4% compared to pre-filtering.\nSuppKG consists of 2,928 DS-specific nodes. Manual review of findings\nidentified 44 (88%) proposed DS-Gene-Drug and 32 (64%) proposed\nDS-Gene1-Function-Gene2-Drug pathways to be mechanistically plausible.\nDISCUSSION: The additional relations extracted using SemRepDS generated SuppKG\nthat was used to find plausible DSI not found in the current literature. By the\nnature of the SuppKG, these interactions are unlikely to have been found using\nSemRep without the expanded DS terminology. CONCLUSION: We successfully extend\nSemRep to include DS information and produce SuppKG which can be used to find\npotential DS-Drug interactions.", "published": "2021-06-24 02:57:24", "link": "http://arxiv.org/abs/2106.12741v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "An Automated Knowledge Mining and Document Classification System with\n  Multi-model Transfer Learning", "abstract": "Service manual documents are crucial to the engineering company as they\nprovide guidelines and knowledge to service engineers. However, it has become\ninconvenient and inefficient for service engineers to retrieve specific\nknowledge from documents due to the complexity of resources. In this research,\nwe propose an automated knowledge mining and document classification system\nwith novel multi-model transfer learning approaches. Particularly, the\nclassification performance of the system has been improved with three effective\ntechniques: fine-tuning, pruning, and multi-model method. The fine-tuning\ntechnique optimizes a pre-trained BERT model by adding a feed-forward neural\nnetwork layer and the pruning technique is used to retrain the BERT model with\nnew data. The multi-model method initializes and trains multiple BERT models to\novercome the randomness of data ordering during the fine-tuning process. In the\nfirst iteration of the training process, multiple BERT models are being trained\nsimultaneously. The best model is then selected for the next phase of the\ntraining process with another two iterations and the training processes for\nother BERT models will be terminated. The performance of the proposed system\nhas been evaluated by comparing with two robust baseline methods, BERT and\nBERT-CNN. Experimental results on a widely used Corpus of Linguistic\nAcceptability (CoLA) dataset have shown that the proposed techniques perform\nbetter than these baseline methods in terms of accuracy and MCC score.", "published": "2021-06-24 03:03:46", "link": "http://arxiv.org/abs/2106.12744v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Evaluation of Representation Models for Text Classification with AutoML\n  Tools", "abstract": "Automated Machine Learning (AutoML) has gained increasing success on tabular\ndata in recent years. However, processing unstructured data like text is a\nchallenge and not widely supported by open-source AutoML tools. This work\ncompares three manually created text representations and text embeddings\nautomatically created by AutoML tools. Our benchmark includes four popular\nopen-source AutoML tools and eight datasets for text classification purposes.\nThe results show that straightforward text representations perform better than\nAutoML tools with automatically created text embeddings.", "published": "2021-06-24 07:19:44", "link": "http://arxiv.org/abs/2106.12798v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AIT-QA: Question Answering Dataset over Complex Tables in the Airline\n  Industry", "abstract": "Recent advances in transformers have enabled Table Question Answering (Table\nQA) systems to achieve high accuracy and SOTA results on open domain datasets\nlike WikiTableQuestions and WikiSQL. Such transformers are frequently\npre-trained on open-domain content such as Wikipedia, where they effectively\nencode questions and corresponding tables from Wikipedia as seen in Table QA\ndataset. However, web tables in Wikipedia are notably flat in their layout,\nwith the first row as the sole column header. The layout lends to a relational\nview of tables where each row is a tuple. Whereas, tables in domain-specific\nbusiness or scientific documents often have a much more complex layout,\nincluding hierarchical row and column headers, in addition to having\nspecialized vocabulary terms from that domain.\n  To address this problem, we introduce the domain-specific Table QA dataset\nAIT-QA (Airline Industry Table QA). The dataset consists of 515 questions\nauthored by human annotators on 116 tables extracted from public U.S. SEC\nfilings (publicly available at: https://www.sec.gov/edgar.shtml) of major\nairline companies for the fiscal years 2017-2019. We also provide annotations\npertaining to the nature of questions, marking those that require hierarchical\nheaders, domain-specific terminology, and paraphrased forms. Our zero-shot\nbaseline evaluation of three transformer-based SOTA Table QA methods - TaPAS\n(end-to-end), TaBERT (semantic parsing-based), and RCI (row-column\nencoding-based) - clearly exposes the limitation of these methods in this\npractical setting, with the best accuracy at just 51.8\\% (RCI). We also present\npragmatic table preprocessing steps used to pivot and project these complex\ntables into a layout suitable for the SOTA Table QA models.", "published": "2021-06-24 12:14:18", "link": "http://arxiv.org/abs/2106.12944v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Topic Segmentation of Meetings with BERT Embeddings", "abstract": "Topic segmentation of meetings is the task of dividing multi-person meeting\ntranscripts into topic blocks. Supervised approaches to the problem have proven\nintractable due to the difficulties in collecting and accurately annotating\nlarge datasets. In this paper we show how previous unsupervised topic\nsegmentation methods can be improved using pre-trained neural architectures. We\nintroduce an unsupervised approach based on BERT embeddings that achieves a\n15.5% reduction in error rate over existing unsupervised approaches applied to\ntwo popular datasets for meeting transcripts.", "published": "2021-06-24 12:54:43", "link": "http://arxiv.org/abs/2106.12978v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Transformer-based Cross-modal Fusion Model with Adversarial Training\n  for VQA Challenge 2021", "abstract": "In this paper, inspired by the successes of visionlanguage pre-trained models\nand the benefits from training with adversarial attacks, we present a novel\ntransformerbased cross-modal fusion modeling by incorporating the both notions\nfor VQA challenge 2021. Specifically, the proposed model is on top of the\narchitecture of VinVL model [19], and the adversarial training strategy [4] is\napplied to make the model robust and generalized. Moreover, two implementation\ntricks are also used in our system to obtain better results. The experiments\ndemonstrate that the novel framework can achieve 76.72% on VQAv2 test-std set.", "published": "2021-06-24 14:09:57", "link": "http://arxiv.org/abs/2106.13033v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "byteSteady: Fast Classification Using Byte-Level n-Gram Embeddings", "abstract": "This article introduces byteSteady -- a fast model for classification using\nbyte-level n-gram embeddings. byteSteady assumes that each input comes as a\nsequence of bytes. A representation vector is produced using the averaged\nembedding vectors of byte-level n-grams, with a pre-defined set of n. The\nhashing trick is used to reduce the number of embedding vectors. This input\nrepresentation vector is then fed into a linear classifier. A straightforward\napplication of byteSteady is text classification. We also apply byteSteady to\none type of non-language data -- DNA sequences for gene classification. For\nboth problems we achieved competitive classification results against strong\nbaselines, suggesting that byteSteady can be applied to both language and\nnon-language data. Furthermore, we find that simple compression using Huffman\ncoding does not significantly impact the results, which offers an\naccuracy-speed trade-off previously unexplored in machine learning.", "published": "2021-06-24 20:14:48", "link": "http://arxiv.org/abs/2106.13302v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with\n  Language Models", "abstract": "Prompting language models (LMs) with training examples and task descriptions\nhas been seen as critical to recent successes in few-shot learning. In this\nwork, we show that finetuning LMs in the few-shot setting can considerably\nreduce the need for prompt engineering. In fact, one can use null prompts,\nprompts that contain neither task-specific templates nor training examples, and\nachieve competitive accuracy to manually-tuned prompts across a wide range of\ntasks. While finetuning LMs does introduce new parameters for each downstream\ntask, we show that this memory overhead can be substantially reduced:\nfinetuning only the bias terms can achieve comparable or better accuracy than\nstandard finetuning while only updating 0.1% of the parameters. All in all, we\nrecommend finetuning LMs for few-shot learning as it is more accurate, robust\nto different prompts, and can be made nearly as efficient as using frozen LMs.", "published": "2021-06-24 23:38:10", "link": "http://arxiv.org/abs/2106.13353v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TagRuler: Interactive Tool for Span-Level Data Programming by\n  Demonstration", "abstract": "Despite rapid developments in the field of machine learning research,\ncollecting high-quality labels for supervised learning remains a bottleneck for\nmany applications. This difficulty is exacerbated by the fact that\nstate-of-the-art models for NLP tasks are becoming deeper and more complex,\noften increasing the amount of training data required even for fine-tuning.\nWeak supervision methods, including data programming, address this problem and\nreduce the cost of label collection by using noisy label sources for\nsupervision. However, until recently, data programming was only accessible to\nusers who knew how to program. To bridge this gap, the Data Programming by\nDemonstration framework was proposed to facilitate the automatic creation of\nlabeling functions based on a few examples labeled by a domain expert. This\nframework has proven successful for generating high-accuracy labeling models\nfor document classification. In this work, we extend the DPBD framework to\nspan-level annotation tasks, arguably one of the most time-consuming NLP\nlabeling tasks. We built a novel tool, TagRuler, that makes it easy for\nannotators to build span-level labeling functions without programming and\nencourages them to explore trade-offs between different labeling models and\nactive learning strategies. We empirically demonstrated that an annotator could\nachieve a higher F1 score using the proposed tool compared to manual labeling\nfor different span-level annotation tasks.", "published": "2021-06-24 04:49:42", "link": "http://arxiv.org/abs/2106.12767v1", "categories": ["cs.CL", "cs.DB", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A comprehensive empirical analysis on cross-domain semantic enrichment\n  for detection of depressive language", "abstract": "We analyze the process of creating word embedding feature representations\ndesigned for a learning task when annotated data is scarce, for example, in\ndepressive language detection from Tweets. We start with a rich word embedding\npre-trained from a large general dataset, which is then augmented with\nembeddings learned from a much smaller and more specific domain dataset through\na simple non-linear mapping mechanism. We also experimented with several other\nmore sophisticated methods of such mapping including, several auto-encoder\nbased and custom loss-function based methods that learn embedding\nrepresentations through gradually learning to be close to the words of similar\nsemantics and distant to dissimilar semantics. Our strengthened representations\nbetter capture the semantics of the depression domain, as it combines the\nsemantics learned from the specific domain coupled with word coverage from the\ngeneral language. We also present a comparative performance analyses of our\nword embedding representations with a simple bag-of-words model, well known\nsentiment and psycholinguistic lexicons, and a general pre-trained word\nembedding. When used as feature representations for several different machine\nlearning methods, including deep learning models in a depressive Tweets\nidentification task, we show that our augmented word embedding representations\nachieve a significantly better F1 score than the others, specially when applied\nto a high quality dataset. Also, we present several data ablation tests which\nconfirm the efficacy of our augmentation techniques.", "published": "2021-06-24 07:15:09", "link": "http://arxiv.org/abs/2106.12797v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual transfer of acoustic word embeddings improves when training\n  on languages related to the target zero-resource language", "abstract": "Acoustic word embedding models map variable duration speech segments to fixed\ndimensional vectors, enabling efficient speech search and discovery. Previous\nwork explored how embeddings can be obtained in zero-resource settings where no\nlabelled data is available in the target language. The current best approach\nuses transfer learning: a single supervised multilingual model is trained using\nlabelled data from multiple well-resourced languages and then applied to a\ntarget zero-resource language (without fine-tuning). However, it is still\nunclear how the specific choice of training languages affect downstream\nperformance. Concretely, here we ask whether it is beneficial to use training\nlanguages related to the target. Using data from eleven languages spoken in\nSouthern Africa, we experiment with adding data from different language\nfamilies while controlling for the amount of data per language. In word\ndiscrimination and query-by-example search evaluations, we show that training\non languages from the same family gives large improvements. Through\nfiner-grained analysis, we show that training on even just a single related\nlanguage gives the largest gain. We also find that adding data from unrelated\nlanguages generally doesn't hurt performance.", "published": "2021-06-24 08:37:05", "link": "http://arxiv.org/abs/2106.12834v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "QASR: QCRI Aljazeera Speech Resource -- A Large Scale Annotated Arabic\n  Speech Corpus", "abstract": "We introduce the largest transcribed Arabic speech corpus, QASR, collected\nfrom the broadcast domain. This multi-dialect speech dataset contains 2,000\nhours of speech sampled at 16kHz crawled from Aljazeera news channel. The\ndataset is released with lightly supervised transcriptions, aligned with the\naudio segments. Unlike previous datasets, QASR contains linguistically\nmotivated segmentation, punctuation, speaker information among others. QASR is\nsuitable for training and evaluating speech recognition systems, acoustics-\nand/or linguistics- based Arabic dialect identification, punctuation\nrestoration, speaker identification, speaker linking, and potentially other NLP\nmodules for spoken data. In addition to QASR transcription, we release a\ndataset of 130M words to aid in designing and training a better language model.\nWe show that end-to-end automatic speech recognition trained on QASR reports a\ncompetitive word error rate compared to the previous MGB-2 corpus. We report\nbaseline results for downstream natural language processing tasks such as named\nentity recognition using speech transcript. We also report the first baseline\nfor Arabic punctuation restoration. We make the corpus available for the\nresearch community.", "published": "2021-06-24 13:20:40", "link": "http://arxiv.org/abs/2106.13000v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Where are we in semantic concept extraction for Spoken Language\n  Understanding?", "abstract": "Spoken language understanding (SLU) topic has seen a lot of progress these\nlast three years, with the emergence of end-to-end neural approaches. Spoken\nlanguage understanding refers to natural language processing tasks related to\nsemantic extraction from speech signal, like named entity recognition from\nspeech or slot filling task in a context of human-machine dialogue.\nClassically, SLU tasks were processed through a cascade approach that consists\nin applying, firstly, an automatic speech recognition process, followed by a\nnatural language processing module applied to the automatic transcriptions.\nThese three last years, end-to-end neural approaches, based on deep neural\nnetworks, have been proposed in order to directly extract the semantics from\nspeech signal, by using a single neural model. More recent works on\nself-supervised training with unlabeled data open new perspectives in term of\nperformance for automatic speech recognition and natural language processing.\nIn this paper, we present a brief overview of the recent advances on the French\nMEDIA benchmark dataset for SLU, with or without the use of additional data. We\nalso present our last results that significantly outperform the current\nstate-of-the-art with a Concept Error Rate (CER) of 11.2%, instead of 13.6% for\nthe last state-of-the-art system presented this year.", "published": "2021-06-24 14:18:32", "link": "http://arxiv.org/abs/2106.13045v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Learning Language and Multimodal Privacy-Preserving Markers of Mood from\n  Mobile Data", "abstract": "Mental health conditions remain underdiagnosed even in countries with common\naccess to advanced medical care. The ability to accurately and efficiently\npredict mood from easily collectible data has several important implications\nfor the early detection, intervention, and treatment of mental health\ndisorders. One promising data source to help monitor human behavior is daily\nsmartphone usage. However, care must be taken to summarize behaviors without\nidentifying the user through personal (e.g., personally identifiable\ninformation) or protected (e.g., race, gender) attributes. In this paper, we\nstudy behavioral markers of daily mood using a recent dataset of mobile\nbehaviors from adolescent populations at high risk of suicidal behaviors. Using\ncomputational models, we find that language and multimodal representations of\nmobile typed text (spanning typed characters, words, keystroke timings, and app\nusage) are predictive of daily mood. However, we find that models trained to\npredict mood often also capture private user identities in their intermediate\nrepresentations. To tackle this problem, we evaluate approaches that obfuscate\nuser identity while remaining predictive. By combining multimodal\nrepresentations with privacy-preserving learning, we are able to push forward\nthe performance-privacy frontier.", "published": "2021-06-24 17:46:03", "link": "http://arxiv.org/abs/2106.13213v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Towards Understanding and Mitigating Social Biases in Language Models", "abstract": "As machine learning methods are deployed in real-world settings such as\nhealthcare, legal systems, and social science, it is crucial to recognize how\nthey shape social biases and stereotypes in these sensitive decision-making\nprocesses. Among such real-world deployments are large-scale pretrained\nlanguage models (LMs) that can be potentially dangerous in manifesting\nundesirable representational biases - harmful biases resulting from\nstereotyping that propagate negative generalizations involving gender, race,\nreligion, and other social constructs. As a step towards improving the fairness\nof LMs, we carefully define several sources of representational biases before\nproposing new benchmarks and metrics to measure them. With these tools, we\npropose steps towards mitigating social biases during text generation. Our\nempirical results and human evaluation demonstrate effectiveness in mitigating\nbias while retaining crucial contextual information for high-fidelity text\ngeneration, thereby pushing forward the performance-fairness Pareto frontier.", "published": "2021-06-24 17:52:43", "link": "http://arxiv.org/abs/2106.13219v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A new system for evaluating brand importance: A use case from the\n  fashion industry", "abstract": "Today brand managers and marketing specialists can leverage huge amount of\ndata to reveal patterns and trends in consumer perceptions, monitoring positive\nor negative associations of brands with respect to desired topics. In this\nstudy, we apply the Semantic Brand Score (SBS) indicator to assess brand\nimportance in the fashion industry. To this purpose, we measure and visualize\ntext data using the SBS Business Intelligence App (SBS BI), which relies on\nmethods and tools of text mining and social network analysis. We collected and\nanalyzed about 206,000 tweets that mentioned the fashion brands Fendi, Gucci\nand Prada, during the period from March 5 to March 12, 2021. From the analysis\nof the three SBS dimensions - prevalence, diversity and connectivity - we found\nthat Gucci dominated the discourse, with high values of SBS. We use this case\nstudy as an example to present a new system for evaluating brand importance and\nimage, through the analysis of (big) textual data.", "published": "2021-06-24 09:04:26", "link": "http://arxiv.org/abs/2106.14657v1", "categories": ["cs.IR", "cs.CL", "cs.SI", "physics.soc-ph", "D.2; I.2.7; H.0; I.7.0; I.2.5"], "primary_category": "cs.IR"}
{"title": "Differential Privacy for Credit Risk Model", "abstract": "The use of machine learning algorithms to model user behavior and drive\nbusiness decisions has become increasingly commonplace, specifically providing\nintelligent recommendations to automated decision making. This has led to an\nincrease in the use of customers personal data to analyze customer behavior and\npredict their interests in a companys products. Increased use of this customer\npersonal data can lead to better models but also to the potential of customer\ndata being leaked, reverse engineered, and mishandled. In this paper, we assess\ndifferential privacy as a solution to address these privacy problems by\nbuilding privacy protections into the data engineering and model training\nstages of predictive model development. Our interest is a pragmatic\nimplementation in an operational environment, which necessitates a general\npurpose differentially private modeling framework, and we evaluate one such\ntool from LeapYear as applied to the Credit Risk modeling domain. Credit Risk\nModel is a major modeling methodology in banking and finance where user data is\nanalyzed to determine the total Expected Loss to the bank. We examine the\napplication of differential privacy on the credit risk model and evaluate the\nperformance of a Differentially Private Model with a Non Differentially Private\nModel. Credit Risk Model is a major modeling methodology in banking and finance\nwhere users data is analyzed to determine the total Expected Loss to the bank.\nIn this paper, we explore the application of differential privacy on the credit\nrisk model and evaluate the performance of a Non Differentially Private Model\nwith Differentially Private Model.", "published": "2021-06-24 09:58:49", "link": "http://arxiv.org/abs/2106.15343v1", "categories": ["cs.CR", "cs.CL", "cs.LG", "I.6.4; E.m; J.1"], "primary_category": "cs.CR"}
{"title": "Lexical Access Model for Italian -- Modeling human speech processing:\n  identification of words in running speech toward lexical access based on the\n  detection of landmarks and other acoustic cues to features", "abstract": "Modelling the process that a listener actuates in deriving the words intended\nby a speaker requires setting a hypothesis on how lexical items are stored in\nmemory. This work aims at developing a system that imitates humans when\nidentifying words in running speech and, in this way, provide a framework to\nbetter understand human speech processing. We build a speech recognizer for\nItalian based on the principles of Stevens' model of Lexical Access in which\nwords are stored as hierarchical arrangements of distinctive features (Stevens,\nK. N. (2002). \"Toward a model for lexical access based on acoustic landmarks\nand distinctive features,\" J. Acoust. Soc. Am., 111(4):1872-1891). Over the\npast few decades, the Speech Communication Group at the Massachusetts Institute\nof Technology (MIT) developed a speech recognition system for English based on\nthis approach. Italian will be the first language beyond English to be\nexplored; the extension to another language provides the opportunity to test\nthe hypothesis that words are represented in memory as a set of\nhierarchically-arranged distinctive features, and reveal which of the\nunderlying mechanisms may have a language-independent nature. This paper also\nintroduces a new Lexical Access corpus, the LaMIT database, created and labeled\nspecifically for this work, that will be provided freely to the speech research\ncommunity. Future developments will test the hypothesis that specific acoustic\ndiscontinuities - called landmarks - that serve as cues to features, are\nlanguage independent, while other cues may be language-dependent, with powerful\nimplications for understanding how the human brain recognizes speech.", "published": "2021-06-24 10:54:56", "link": "http://arxiv.org/abs/2107.02720v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Simultaneous Denoising and Dereverberation Framework with Target\n  Decoupling", "abstract": "Background noise and room reverberation are regarded as two major factors to\ndegrade the subjective speech quality. In this paper, we propose an integrated\nframework to address simultaneous denoising and dereverberation under\ncomplicated scenario environments. It adopts a chain optimization strategy and\ndesigns four sub-stages accordingly. In the first two stages, we decouple the\nmulti-task learning w.r.t. complex spectrum into magnitude and phase, and only\nimplement noise and reverberation removal in the magnitude domain. Based on the\nestimated priors above, we further polish the spectrum in the third stage,\nwhere both magnitude and phase information are explicitly repaired with the\nresidual learning. Due to the data mismatch and nonlinear effect of DNNs, the\nresidual noise often exists in the DNN-processed spectrum. To resolve the\nproblem, we adopt a light-weight algorithm as the post-processing module to\ncapture and suppress the residual noise in the non-active regions. In the\nInterspeech 2021 Deep Noise Suppression (DNS) Challenge, our submitted system\nranked top-1 for the real-time track in terms of Mean Opinion Score (MOS) with\nITU-T P.835 framework", "published": "2021-06-24 03:01:50", "link": "http://arxiv.org/abs/2106.12743v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Additive Phoneme-aware Margin Softmax Loss for Language Recognition", "abstract": "This paper proposes an additive phoneme-aware margin softmax (APM-Softmax)\nloss to train the multi-task learning network with phonetic information for\nlanguage recognition. In additive margin softmax (AM-Softmax) loss, the margin\nis set as a constant during the entire training for all training samples, and\nthat is a suboptimal method since the recognition difficulty varies in training\nsamples. In additive angular margin softmax (AAM-Softmax) loss, the additional\nangular margin is set as a costant as well. In this paper, we propose an\nAPM-Softmax loss for language recognition with phoneitc multi-task learning, in\nwhich the additive phoneme-aware margin is automatically tuned for different\ntraining samples. More specifically, the margin of language recognition is\nadjusted according to the results of phoneme recognition. Experiments are\nreported on Oriental Language Recognition (OLR) datasets, and the proposed\nmethod improves AM-Softmax loss and AAM-Softmax loss in different language\nrecognition testing conditions.", "published": "2021-06-24 09:24:31", "link": "http://arxiv.org/abs/2106.12851v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SRIB-LEAP submission to Far-field Multi-Channel Speech Enhancement\n  Challenge for Video Conferencing", "abstract": "This paper presents the details of the SRIB-LEAP submission to the\nConferencingSpeech challenge 2021. The challenge involved the task of\nmulti-channel speech enhancement to improve the quality of far field speech\nfrom microphone arrays in a video conferencing room. We propose a two stage\nmethod involving a beamformer followed by single channel enhancement. For the\nbeamformer, we incorporated self-attention mechanism as inter-channel\nprocessing layer in the filter-and-sum network (FaSNet), an end-to-end\ntime-domain beamforming system. The single channel speech enhancement is done\nin log spectral domain using convolution neural network (CNN)-long short term\nmemory (LSTM) based architecture. We achieved improvements in objective quality\nmetrics - perceptual evaluation of speech quality (PESQ) of 0.5 on the noisy\ndata. On subjective quality evaluation, the proposed approach improved the mean\nopinion score (MOS) by an absolute measure of 0.9 over the noisy audio.", "published": "2021-06-24 04:15:31", "link": "http://arxiv.org/abs/2106.12763v1", "categories": ["eess.AS", "cs.SD", "eess.IV", "eess.SP"], "primary_category": "eess.AS"}
{"title": "SofaMyRoom: a fast and multiplatform \"shoebox\" room simulator for\n  binaural room impulse response dataset generation", "abstract": "This paper introduces a shoebox room simulator able to systematically\ngenerate synthetic datasets of binaural room impulse responses (BRIRs) given an\narbitrary set of head-related transfer functions (HRTFs). The evaluation of\nmachine hearing algorithms frequently requires BRIR datasets in order to\nsimulate the acoustics of any environment. However, currently available\nsolutions typically consider only HRTFs measured on dummy heads, which poorly\ncharacterize the high variability in spatial sound perception. Our solution\nallows to integrate a room impulse response (RIR) simulator with different HRTF\nsets represented in Spatially Oriented Format for Acoustics (SOFA). The source\ncode and the compiled binaries for different operating systems allow to both\nadvanced and non-expert users to benefit from our toolbox, see\nhttps://github.com/spatialaudiotools/sofamyroom/ .", "published": "2021-06-24 13:07:51", "link": "http://arxiv.org/abs/2106.12992v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "I.6.3; C.3"], "primary_category": "cs.SD"}
{"title": "AudioCLIP: Extending CLIP to Image, Text and Audio", "abstract": "In the past, the rapidly evolving field of sound classification greatly\nbenefited from the application of methods from other domains. Today, we observe\nthe trend to fuse domain-specific tasks and approaches together, which provides\nthe community with new outstanding models.\n  In this work, we present an extension of the CLIP model that handles audio in\naddition to text and images. Our proposed model incorporates the ESResNeXt\naudio-model into the CLIP framework using the AudioSet dataset. Such a\ncombination enables the proposed model to perform bimodal and unimodal\nclassification and querying, while keeping CLIP's ability to generalize to\nunseen datasets in a zero-shot inference fashion.\n  AudioCLIP achieves new state-of-the-art results in the Environmental Sound\nClassification (ESC) task, out-performing other approaches by reaching\naccuracies of 90.07% on the UrbanSound8K and 97.15% on the ESC-50 datasets.\nFurther it sets new baselines in the zero-shot ESC-task on the same datasets\n(68.78% and 69.40%, respectively).\n  Finally, we also assess the cross-modal querying performance of the proposed\nmodel as well as the influence of full and partial training on the results. For\nthe sake of reproducibility, our code is published.", "published": "2021-06-24 14:16:38", "link": "http://arxiv.org/abs/2106.13043v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
