{"title": "Hindi to English Transfer Based Machine Translation System", "abstract": "In large societies like India there is a huge demand to convert one human\nlanguage into another. Lots of work has been done in this area. Many transfer\nbased MTS have developed for English to other languages, as MANTRA CDAC Pune,\nMATRA CDAC Pune, SHAKTI IISc Bangalore and IIIT Hyderabad. Still there is a\nlittle work done for Hindi to other languages. Currently we are working on it.\nIn this paper we focus on designing a system, that translate the document from\nHindi to English by using transfer based approach. This system takes an input\ntext check its structure through parsing. Reordering rules are used to generate\nthe text in target language. It is better than Corpus Based MTS because Corpus\nBased MTS require large amount of word aligned data for translation that is not\navailable for many languages while Transfer Based MTS requires only knowledge\nof both the languages(source language and target language) to make transfer\nrules. We get correct translation for simple assertive sentences and almost\ncorrect for complex and compound sentences.", "published": "2015-07-08 03:50:47", "link": "http://arxiv.org/abs/1507.02012v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Your Username Says About You", "abstract": "Usernames are ubiquitous on the Internet, and they are often suggestive of\nuser demographics. This work looks at the degree to which gender and language\ncan be inferred from a username alone by making use of unsupervised morphology\ninduction to decompose usernames into sub-units. Experimental results on the\ntwo tasks demonstrate the effectiveness of the proposed morphological features\ncompared to a character n-gram baseline.", "published": "2015-07-08 06:52:50", "link": "http://arxiv.org/abs/1507.02045v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Document Summarization via Discriminative Summary Reranking", "abstract": "Existing multi-document summarization systems usually rely on a specific\nsummarization model (i.e., a summarization method with a specific parameter\nsetting) to extract summaries for different document sets with different\ntopics. However, according to our quantitative analysis, none of the existing\nsummarization models can always produce high-quality summaries for different\ndocument sets, and even a summarization model with good overall performance may\nproduce low-quality summaries for some document sets. On the contrary, a\nbaseline summarization model may produce high-quality summaries for some\ndocument sets. Based on the above observations, we treat the summaries produced\nby different summarization models as candidate summaries, and then explore\ndiscriminative reranking techniques to identify high-quality summaries from the\ncandidates for difference document sets. We propose to extract a set of\ncandidate summaries for each document set based on an ILP framework, and then\nleverage Ranking SVM for summary reranking. Various useful features have been\ndeveloped for the reranking process, including word-level features,\nsentence-level features and summary-level features. Evaluation results on the\nbenchmark DUC datasets validate the efficacy and robustness of our proposed\napproach.", "published": "2015-07-08 08:26:23", "link": "http://arxiv.org/abs/1507.02062v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Mine Chinese Coordinate Terms Using the Web", "abstract": "Coordinate relation refers to the relation between instances of a concept and\nthe relation between the directly hyponyms of a concept. In this paper, we\nfocus on the task of extracting terms which are coordinate with a user given\nseed term in Chinese, and grouping the terms which belong to different concepts\nif the seed term has several meanings. We propose a semi-supervised method that\nintegrates manually defined linguistic patterns and automatically learned\nsemi-structural patterns to extract coordinate terms in Chinese from web search\nresults. In addition, terms are grouped into different concepts based on their\nco-occurring terms and contexts. We further calculate the saliency scores of\nextracted terms and rank them accordingly. Experimental results demonstrate\nthat our proposed method generates results with high quality and wide coverage.", "published": "2015-07-08 13:27:43", "link": "http://arxiv.org/abs/1507.02145v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Role of Pragmatics in Legal Norm Representation", "abstract": "Despite the 'apparent clarity' of a given legal provision, its application\nmay result in an outcome that does not exactly conform to the semantic level of\na statute. The vagueness within a legal text is induced intentionally to\naccommodate all possible scenarios under which such norms should be applied,\nthus making the role of pragmatics an important aspect also in the\nrepresentation of a legal norm and reasoning on top of it. The notion of\npragmatics considered in this paper does not focus on the aspects associated\nwith judicial decision making. The paper aims to shed light on the aspects of\npragmatics in legal linguistics, mainly focusing on the domain of patent law,\nonly from a knowledge representation perspective. The philosophical discussions\npresented in this paper are grounded based on the legal theories from Grice and\nMarmor.", "published": "2015-07-08 10:04:14", "link": "http://arxiv.org/abs/1507.02086v1", "categories": ["cs.CL", "cs.AI", "68T30", "J.1; I.2.1"], "primary_category": "cs.CL"}
{"title": "Talking to the crowd: What do people react to in online discussions?", "abstract": "This paper addresses the question of how language use affects community\nreaction to comments in online discussion forums, and the relative importance\nof the message vs. the messenger. A new comment ranking task is proposed based\non community annotated karma in Reddit discussions, which controls for topic\nand timing of comments. Experimental work with discussion threads from six\nsubreddits shows that the importance of different types of language features\nvaries with the community of interest.", "published": "2015-07-08 15:55:18", "link": "http://arxiv.org/abs/1507.02205v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Generating Navigable Semantic Maps from Social Sciences Corpora", "abstract": "It is now commonplace to observe that we are facing a deluge of online\ninformation. Researchers have of course long acknowledged the potential value\nof this information since digital traces make it possible to directly observe,\ndescribe and analyze social facts, and above all the co-evolution of ideas and\ncommunities over time. However, most online information is expressed through\ntext, which means it is not directly usable by machines, since computers\nrequire structured, organized and typed information in order to be able to\nmanipulate it. Our goal is thus twofold: 1. Provide new natural language\nprocessing techniques aiming at automatically extracting relevant information\nfrom texts, especially in the context of social sciences, and connect these\npieces of information so as to obtain relevant socio-semantic networks; 2.\nProvide new ways of exploring these socio-semantic networks, thanks to tools\nallowing one to dynamically navigate these networks, de-construct and\nre-construct them interactively, from different points of view following the\nneeds expressed by domain experts.", "published": "2015-07-08 04:27:48", "link": "http://arxiv.org/abs/1507.02020v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Mining and Analyzing the Future Works in Scientific Articles", "abstract": "Future works in scientific articles are valuable for researchers and they can\nguide researchers to new research directions or ideas. In this paper, we mine\nthe future works in scientific articles in order to 1) provide an insight for\nfuture work analysis and 2) facilitate researchers to search and browse future\nworks in a research area. First, we study the problem of future work extraction\nand propose a regular expression based method to address the problem. Second,\nwe define four different categories for the future works by observing the data\nand investigate the multi-class future work classification problem. Third, we\napply the extraction method and the classification model to a paper dataset in\nthe computer science field and conduct a further analysis of the future works.\nFinally, we design a prototype system to search and demonstrate the future\nworks mined from the scientific papers. Our evaluation results show that our\nextraction method can get high precision and recall values and our\nclassification model can also get good results and it outperforms several\nbaseline models. Further analysis of the future work sentences also indicates\ninteresting results.", "published": "2015-07-08 13:14:38", "link": "http://arxiv.org/abs/1507.02140v1", "categories": ["cs.DL", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
