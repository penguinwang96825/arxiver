{"title": "SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions", "abstract": "Concept Bottleneck Models (CBMs) and other concept-based interpretable models\nshow great promise for making AI applications more transparent, which is\nessential in fields like medicine. Despite their success, we demonstrate that\nCBMs struggle to reliably identify the correct concepts under distribution\nshifts. To assess the robustness of CBMs to concept variations, we introduce\nSUB: a fine-grained image and concept benchmark containing 38,400 synthetic\nimages based on the CUB dataset. To create SUB, we select a CUB subset of 33\nbird classes and 45 concepts to generate images which substitute a specific\nconcept, such as wing color or belly pattern. We introduce a novel Tied\nDiffusion Guidance (TDG) method to precisely control generated images, where\nnoise sharing for two parallel denoising processes ensures that both the\ncorrect bird class and the correct attribute are generated. This novel\nbenchmark enables rigorous evaluation of CBMs and similar interpretable models,\ncontributing to the development of more robust methods. Our code is available\nat https://github.com/ExplainableML/sub and the dataset at\nhttp://huggingface.co/datasets/Jessica-bader/SUB.", "published": "2025-07-31 17:59:40", "link": "http://arxiv.org/abs/2507.23784v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding", "abstract": "Current auto-regressive models can generate high-quality, topologically\nprecise meshes; however, they necessitate thousands-or even tens of\nthousands-of next-token predictions during inference, resulting in substantial\nlatency. We introduce XSpecMesh, a quality-preserving acceleration method for\nauto-regressive mesh generation models. XSpecMesh employs a lightweight,\nmulti-head speculative decoding scheme to predict multiple tokens in parallel\nwithin a single forward pass, thereby accelerating inference. We further\npropose a verification and resampling strategy: the backbone model verifies\neach predicted token and resamples any tokens that do not meet the quality\ncriteria. In addition, we propose a distillation strategy that trains the\nlightweight decoding heads by distilling from the backbone model, encouraging\ntheir prediction distributions to align and improving the success rate of\nspeculative predictions. Extensive experiments demonstrate that our method\nachieves a 1.7x speedup without sacrificing generation quality. Our code will\nbe released.", "published": "2025-07-31 17:58:30", "link": "http://arxiv.org/abs/2507.23777v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "abstract": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.", "published": "2025-07-31 17:57:20", "link": "http://arxiv.org/abs/2507.23773v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Consensus-Driven Active Model Selection", "abstract": "The widespread availability of off-the-shelf machine learning models poses a\nchallenge: which model, of the many available candidates, should be chosen for\na given data analysis task? This question of model selection is traditionally\nanswered by collecting and annotating a validation dataset -- a costly and\ntime-intensive process. We propose a method for active model selection, using\npredictions from candidate models to prioritize the labeling of test data\npoints that efficiently differentiate the best candidate. Our method, CODA,\nperforms consensus-driven active model selection by modeling relationships\nbetween classifiers, categories, and data points within a probabilistic\nframework. The framework uses the consensus and disagreement between models in\nthe candidate pool to guide the label acquisition process, and Bayesian\ninference to update beliefs about which model is best as more information is\ncollected. We validate our approach by curating a collection of 26 benchmark\ntasks capturing a range of model selection scenarios. CODA outperforms existing\nmethods for active model selection significantly, reducing the annotation\neffort required to discover the best model by upwards of 70% compared to the\nprevious state-of-the-art. Code and data are available at\nhttps://github.com/justinkay/coda.", "published": "2025-07-31 17:56:28", "link": "http://arxiv.org/abs/2507.23771v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Formal Bayesian Transfer Learning via the Total Risk Prior", "abstract": "In analyses with severe data-limitations, augmenting the target dataset with\ninformation from ancillary datasets in the application domain, called source\ndatasets, can lead to significantly improved statistical procedures. However,\nexisting methods for this transfer learning struggle to deal with situations\nwhere the source datasets are also limited and not guaranteed to be\nwell-aligned with the target dataset. A typical strategy is to use the\nempirical loss minimizer on the source data as a prior mean for the target\nparameters, which places the estimation of source parameters outside of the\nBayesian formalism. Our key conceptual contribution is to use a risk minimizer\nconditional on source parameters instead. This allows us to construct a single\njoint prior distribution for all parameters from the source datasets as well as\nthe target dataset. As a consequence, we benefit from full Bayesian uncertainty\nquantification and can perform model averaging via Gibbs sampling over\nindicator variables governing the inclusion of each source dataset. We show how\na particular instantiation of our prior leads to a Bayesian Lasso in a\ntransformed coordinate system and discuss computational techniques to scale our\napproach to moderately sized datasets. We also demonstrate that recently\nproposed minimax-frequentist transfer learning techniques may be viewed as an\napproximate Maximum a Posteriori approach to our model. Finally, we demonstrate\nsuperior predictive performance relative to the frequentist baseline on a\ngenetics application, especially when the source data are limited.", "published": "2025-07-31 17:55:16", "link": "http://arxiv.org/abs/2507.23768v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Scaled Beta Models and Feature Dilution for Dynamic Ticket Pricing", "abstract": "A novel approach is presented for identifying distinct signatures of\nperforming acts in the secondary ticket resale market by analyzing dynamic\npricing distributions. Using a newly curated, time series dataset from the\nSeatGeek API, we model ticket pricing distributions as scaled Beta\ndistributions. This enables accurate parameter estimation from incomplete\nstatistical data using a hybrid of quantile matching and the method of moments.\nIncorporating the estimated $\\alpha$ and $\\beta$ parameters into Random Forest\nclassifiers significantly improves pairwise artist classification accuracy,\ndemonstrating the unique economic signatures in event pricing data.\nAdditionally, we provide theoretical and empirical evidence that incorporating\nzero-variance (constant-value) features into Random Forest models acts as an\nimplicit regularizer, enhancing feature variety and robustness. This\nregularization promotes deeper, more varied trees in the ensemble, improving\nthe bias-variance tradeoff and mitigating overfitting to dominant features.\nThese findings are validated on both the new ticket pricing dataset and the\nstandard UCI ML handwritten digits dataset.", "published": "2025-07-31 17:55:07", "link": "http://arxiv.org/abs/2507.23767v1", "categories": ["stat.ML", "cs.LG", "68T05, 62H30, 62F10, 68Q32", "F.2.2; I.2.6; I.5.2; G.3"], "primary_category": "stat.ML"}
{"title": "Improving annotator selection in Active Learning using a mood and fatigue-aware Recommender System", "abstract": "This study centers on overcoming the challenge of selecting the best\nannotators for each query in Active Learning (AL), with the objective of\nminimizing misclassifications. AL recognizes the challenges related to cost and\ntime when acquiring labeled data, and decreases the number of labeled data\nneeded. Nevertheless, there is still the necessity to reduce annotation errors,\naiming to be as efficient as possible, to achieve the expected accuracy faster.\nMost strategies for query-annotator pairs do not consider internal factors that\naffect productivity, such as mood, attention, motivation, and fatigue levels.\nThis work addresses this gap in the existing literature, by not only\nconsidering how the internal factors influence annotators (mood and fatigue\nlevels) but also presenting a new query-annotator pair strategy, using a\nKnowledge-Based Recommendation System (RS). The RS ranks the available\nannotators, allowing to choose one or more to label the queried instance using\ntheir past accuracy values, and their mood and fatigue levels, as well as\ninformation about the instance queried. This work bases itself on existing\nliterature on mood and fatigue influence on human performance, simulating\nannotators in a realistic manner, and predicting their performance with the RS.\nThe results show that considering past accuracy values, as well as mood and\nfatigue levels reduces the number of annotation errors made by the annotators,\nand the uncertainty of the model through its training, when compared to not\nusing internal factors. Accuracy and F1-score values were also better in the\nproposed approach, despite not being as substantial as the aforementioned. The\nmethodologies and findings presented in this study begin to explore the open\nchallenge of human cognitive factors affecting AL.", "published": "2025-07-31 17:41:30", "link": "http://arxiv.org/abs/2507.23756v1", "categories": ["cs.LG", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs", "abstract": "Knowledge graphs (KGs) often contain sufficient information to support the\ninference of new facts. Identifying logical rules not only improves the\ncompleteness of a knowledge graph but also enables the detection of potential\nerrors, reveals subtle data patterns, and enhances the overall capacity for\nreasoning and interpretation. However, the complexity of such rules, combined\nwith the unique labeling conventions of each KG, can make them difficult for\nhumans to understand. In this paper, we explore the potential of large language\nmodels to generate natural language explanations for logical rules.\nSpecifically, we extract logical rules using the AMIE 3.5.1 rule discovery\nalgorithm from the benchmark dataset FB15k-237 and two large-scale datasets,\nFB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including\nzero- and few-shot prompting, including variable entity types, and\nchain-of-thought reasoning. We conduct a comprehensive human evaluation of the\ngenerated explanations based on correctness, clarity, and hallucination, and\nalso assess the use of large language models as automatic judges. Our results\ndemonstrate promising performance in terms of explanation correctness and\nclarity, although several challenges remain for future research. All scripts\nand data used in this study are publicly available at\nhttps://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.", "published": "2025-07-31 17:24:04", "link": "http://arxiv.org/abs/2507.23740v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DICOM De-Identification via Hybrid AI and Rule-Based Framework for Scalable, Uncertainty-Aware Redaction", "abstract": "Access to medical imaging and associated text data has the potential to drive\nmajor advances in healthcare research and patient outcomes. However, the\npresence of Protected Health Information (PHI) and Personally Identifiable\nInformation (PII) in Digital Imaging and Communications in Medicine (DICOM)\nfiles presents a significant barrier to the ethical and secure sharing of\nimaging datasets. This paper presents a hybrid de-identification framework\ndeveloped by Impact Business Information Solutions (IBIS) that combines\nrule-based and AI-driven techniques, and rigorous uncertainty quantification\nfor comprehensive PHI/PII removal from both metadata and pixel data.\n  Our approach begins with a two-tiered rule-based system targeting explicit\nand inferred metadata elements, further augmented by a large language model\n(LLM) fine-tuned for Named Entity Recognition (NER), and trained on a suite of\nsynthetic datasets simulating realistic clinical PHI/PII. For pixel data, we\nemploy an uncertainty-aware Faster R-CNN model to localize embedded text,\nextract candidate PHI via Optical Character Recognition (OCR), and apply the\nNER pipeline for final redaction. Crucially, uncertainty quantification\nprovides confidence measures for AI-based detections to enhance automation\nreliability and enable informed human-in-the-loop verification to manage\nresidual risks.\n  This uncertainty-aware deidentification framework achieves robust performance\nacross benchmark datasets and regulatory standards, including DICOM, HIPAA, and\nTCIA compliance metrics. By combining scalable automation, uncertainty\nquantification, and rigorous quality assurance, our solution addresses critical\nchallenges in medical data de-identification and supports the secure, ethical,\nand trustworthy release of imaging data for research.", "published": "2025-07-31 17:19:38", "link": "http://arxiv.org/abs/2507.23736v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Anomalous Samples for Few-Shot Anomaly Detection", "abstract": "Several anomaly detection and classification methods rely on large amounts of\nnon-anomalous or \"normal\" samples under the assump- tion that anomalous data is\ntypically harder to acquire. This hypothesis becomes questionable in Few-Shot\nsettings, where as little as one anno- tated sample can make a significant\ndifference. In this paper, we tackle the question of utilizing anomalous\nsamples in training a model for bi- nary anomaly classification. We propose a\nmethodology that incorporates anomalous samples in a multi-score anomaly\ndetection score leveraging recent Zero-Shot and memory-based techniques. We\ncompare the utility of anomalous samples to that of regular samples and study\nthe benefits and limitations of each. In addition, we propose an\naugmentation-based validation technique to optimize the aggregation of the\ndifferent anomaly scores and demonstrate its effectiveness on popular\nindustrial anomaly detection datasets.", "published": "2025-07-31 16:41:06", "link": "http://arxiv.org/abs/2507.23712v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models", "abstract": "Visual-Language-Action (VLA) models have emerged as a popular paradigm for\nlearning robot manipulation policies that can follow language instructions and\ngeneralize to novel scenarios. Recent work has begun to explore the\nincorporation of latent actions, an abstract representation of visual change\nbetween two frames, into VLA pre-training. In this paper, we introduce villa-X,\na novel Visual-Language-Latent-Action (ViLLA) framework that advances latent\naction modeling for learning generalizable robot manipulation policies. Our\napproach improves both how latent actions are learned and how they are\nincorporated into VLA pre-training. Together, these contributions enable\nvilla-X to achieve superior performance across simulated environments including\nSIMPLER and LIBERO, as well as on two real-world robot setups including gripper\nand dexterous hand manipulation. We believe the ViLLA paradigm holds\nsignificant promise, and that our villa-X provides a strong foundation for\nfuture research.", "published": "2025-07-31 15:57:46", "link": "http://arxiv.org/abs/2507.23682v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data", "abstract": "Microbiome data analysis is essential for understanding host health and\ndisease, yet its inherent sparsity and noise pose major challenges for accurate\nimputation, hindering downstream tasks such as biomarker discovery. Existing\nimputation methods, including recent diffusion-based models, often fail to\ncapture the complex interdependencies between microbial taxa and overlook\ncontextual metadata that can inform imputation. We introduce DepMicroDiff, a\nnovel framework that combines diffusion-based generative modeling with a\nDependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise\ndependencies and autoregressive relationships. DepMicroDiff is further enhanced\nby VAE-based pretraining across diverse cancer datasets and conditioning on\npatient metadata encoded via a large language model (LLM). Experiments on TCGA\nmicrobiome datasets show that DepMicroDiff substantially outperforms\nstate-of-the-art baselines, achieving higher Pearson correlation (up to 0.712),\ncosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer\ntypes, demonstrating its robustness and generalizability for microbiome\nimputation.", "published": "2025-07-31 15:51:41", "link": "http://arxiv.org/abs/2507.23676v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "One-Step Flow Policy Mirror Descent", "abstract": "Diffusion policies have achieved great success in online reinforcement\nlearning (RL) due to their strong expressive capacity. However, the inference\nof diffusion policy models relies on a slow iterative sampling process, which\nlimits their responsiveness. To overcome this limitation, we propose Flow\nPolicy Mirror Descent (FPMD), an online RL algorithm that enables 1-step\nsampling during policy inference. Our approach exploits a theoretical\nconnection between the distribution variance and the discretization error of\nsingle-step sampling in straight interpolation flow matching models, and\nrequires no extra distillation or consistency training. We present two\nalgorithm variants based on flow policy and MeanFlow policy parametrizations,\nrespectively. Extensive empirical evaluations on MuJoCo benchmarks demonstrate\nthat our algorithms show strong performance comparable to diffusion policy\nbaselines while requiring hundreds of times fewer function evaluations during\ninference.", "published": "2025-07-31 15:51:10", "link": "http://arxiv.org/abs/2507.23675v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses", "abstract": "Large Language Models (LLMs) process millions of queries daily, making\nefficient response caching a compelling optimization for reducing cost and\nlatency. However, preserving relevance to user queries using this approach\nproves difficult due to the personalized nature of chatbot interactions and the\nlimited accuracy of semantic similarity search. To address this, we present\nTweakLLM, a novel routing architecture that employs a lightweight LLM to\ndynamically adapt cached responses to incoming prompts. Through comprehensive\nevaluation, including user studies with side-by-side comparisons, satisfaction\nvoting, as well as multi-agent LLM debates, we demonstrate that TweakLLM\nmaintains response quality comparable to frontier models while significantly\nimproving cache effectiveness. Our results across real-world datasets highlight\nTweakLLM as a scalable, resource-efficient caching solution for high-volume LLM\ndeployments without compromising user experience.", "published": "2025-07-31 15:50:57", "link": "http://arxiv.org/abs/2507.23674v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation", "abstract": "Hyperspectral imaging (HSI) provides rich spectral information for medical\nimaging, yet encounters significant challenges due to data limitations and\nhardware variations. We introduce SAMSA, a novel interactive segmentation\nframework that combines an RGB foundation model with spectral analysis. SAMSA\nefficiently utilizes user clicks to guide both RGB segmentation and spectral\nsimilarity computations. The method addresses key limitations in HSI\nsegmentation through a unique spectral feature fusion strategy that operates\nindependently of spectral band count and resolution. Performance evaluation on\npublicly available datasets has shown 81.0% 1-click and 93.4% 5-click DICE on a\nneurosurgical and 81.1% 1-click and 89.2% 5-click DICE on an intraoperative\nporcine hyperspectral dataset. Experimental results demonstrate SAMSA's\neffectiveness in few-shot and zero-shot learning scenarios and using minimal\ntraining examples. Our approach enables seamless integration of datasets with\ndifferent spectral characteristics, providing a flexible framework for\nhyperspectral medical image analysis.", "published": "2025-07-31 15:49:57", "link": "http://arxiv.org/abs/2507.23673v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SHAP-Guided Regularization in Machine Learning Models", "abstract": "Feature attribution methods such as SHapley Additive exPlanations (SHAP) have\nbecome instrumental in understanding machine learning models, but their role in\nguiding model optimization remains underexplored. In this paper, we propose a\nSHAP-guided regularization framework that incorporates feature importance\nconstraints into model training to enhance both predictive performance and\ninterpretability. Our approach applies entropy-based penalties to encourage\nsparse, concentrated feature attributions while promoting stability across\nsamples. The framework is applicable to both regression and classification\ntasks. Our first exploration started with investigating a tree-based model\nregularization using TreeSHAP. Through extensive experiments on benchmark\nregression and classification datasets, we demonstrate that our method improves\ngeneralization performance while ensuring robust and interpretable feature\nattributions. The proposed technique offers a novel, explainability-driven\nregularization approach, making machine learning models both more accurate and\nmore reliable.", "published": "2025-07-31 15:45:38", "link": "http://arxiv.org/abs/2507.23665v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting", "abstract": "Federated Learning (FL) enables collaborative model training across\ndistributed medical institutions while preserving patient privacy, but remains\nvulnerable to Byzantine attacks and statistical heterogeneity. We present\nOptiGradTrust, a comprehensive defense framework that evaluates gradient\nupdates through a novel six-dimensional fingerprint including VAE\nreconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency\nratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module\nfor adaptive trust scoring. To address convergence challenges under data\nheterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch\nNormalization with proximal regularization for optimal accuracy-convergence\ntrade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI\ndatasets under various Byzantine attack scenarios demonstrates significant\nimprovements over state-of-the-art defenses, achieving up to +1.6 percentage\npoints over FLGuard under non-IID conditions while maintaining robust\nperformance against diverse attack patterns through our adaptive learning\napproach.", "published": "2025-07-31 15:14:36", "link": "http://arxiv.org/abs/2507.23638v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective", "abstract": "Since its introduction, softmax attention has become the backbone of modern\ntransformer architectures due to its expressiveness and scalability across a\nwide range of tasks. However, the main drawback of softmax attention is the\nquadratic memory requirement and computational complexity with respect to the\nsequence length. By replacing the softmax nonlinearity, linear attention and\nsimilar methods have been introduced to avoid the quadratic bottleneck of\nsoftmax attention. Despite these linear forms of attention being derived from\nthe original softmax formulation, they typically lag in terms of downstream\naccuracy. While strong intuition of the softmax nonlinearity on the query and\nkey inner product suggests that it has desirable properties compared to other\nnonlinearities, the question of why this discrepancy exists still remains\nunanswered. This work demonstrates that linear attention is an approximation of\nsoftmax attention by deriving the recurrent form of softmax attention. Using\nthis form, each part of softmax attention can be described in the language of\nrecurrent neural networks (RNNs). Describing softmax attention as an RNN allows\nfor the ablation of the components of softmax attention to understand the\nimportance of each part and how they interact. In this way, our work helps\nexplain why softmax attention is more expressive than its counterparts.", "published": "2025-07-31 15:10:03", "link": "http://arxiv.org/abs/2507.23632v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DivControl: Knowledge Diversion for Controllable Image Generation", "abstract": "Diffusion models have advanced from text-to-image (T2I) to image-to-image\n(I2I) generation by incorporating structured inputs such as depth maps,\nenabling fine-grained spatial control. However, existing methods either train\nseparate models for each condition or rely on unified architectures with\nentangled representations, resulting in poor generalization and high adaptation\ncosts for novel conditions. To this end, we propose DivControl, a decomposable\npretraining framework for unified controllable generation and efficient\nadaptation. DivControl factorizes ControlNet via SVD into basic\ncomponents-pairs of singular vectors-which are disentangled into\ncondition-agnostic learngenes and condition-specific tailors through knowledge\ndiversion during multi-condition training. Knowledge diversion is implemented\nvia a dynamic gate that performs soft routing over tailors based on the\nsemantics of condition instructions, enabling zero-shot generalization and\nparameter-efficient adaptation to novel conditions. To further improve\ncondition fidelity and training efficiency, we introduce a representation\nalignment loss that aligns condition embeddings with early diffusion features.\nExtensive experiments demonstrate that DivControl achieves state-of-the-art\ncontrollability with 36.4$\\times$ less training cost, while simultaneously\nimproving average performance on basic conditions. It also delivers strong\nzero-shot and few-shot performance on unseen conditions, demonstrating superior\nscalability, modularity, and transferability.", "published": "2025-07-31 15:00:15", "link": "http://arxiv.org/abs/2507.23620v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "L-GTA: Latent Generative Modeling for Time Series Augmentation", "abstract": "Data augmentation is gaining importance across various aspects of time series\nanalysis, from forecasting to classification and anomaly detection tasks. We\nintroduce the Latent Generative Transformer Augmentation (L-GTA) model, a\ngenerative approach using a transformer-based variational recurrent\nautoencoder. This model uses controlled transformations within the latent space\nof the model to generate new time series that preserve the intrinsic properties\nof the original dataset. L-GTA enables the application of diverse\ntransformations, ranging from simple jittering to magnitude warping, and\ncombining these basic transformations to generate more complex synthetic time\nseries datasets. Our evaluation of several real-world datasets demonstrates the\nability of L-GTA to produce more reliable, consistent, and controllable\naugmented data. This translates into significant improvements in predictive\naccuracy and similarity measures compared to direct transformation methods.", "published": "2025-07-31 14:53:35", "link": "http://arxiv.org/abs/2507.23615v1", "categories": ["cs.LG", "cs.AI", "68T01", "I.5.1; G.3; H.2.8; I.2.1"], "primary_category": "cs.LG"}
{"title": "Consistent Point Matching", "abstract": "This study demonstrates that incorporating a consistency heuristic into the\npoint-matching algorithm \\cite{yerebakan2023hierarchical} improves robustness\nin matching anatomical locations across pairs of medical images. We validated\nour approach on diverse longitudinal internal and public datasets spanning CT\nand MRI modalities. Notably, it surpasses state-of-the-art results on the Deep\nLesion Tracking dataset. Additionally, we show that the method effectively\naddresses landmark localization. The algorithm operates efficiently on standard\nCPU hardware and allows configurable trade-offs between speed and robustness.\nThe method enables high-precision navigation between medical images without\nrequiring a machine learning model or training data.", "published": "2025-07-31 14:47:40", "link": "http://arxiv.org/abs/2507.23609v1", "categories": ["cs.CV", "cs.DC", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates", "abstract": "Clinical trials are a systematic endeavor to assess the safety and efficacy\nof new drugs or treatments. Conducting such trials typically demands\nsignificant financial investment and meticulous planning, highlighting the need\nfor accurate predictions of trial outcomes. Accurately predicting patient\nenrollment, a key factor in trial success, is one of the primary challenges\nduring the planning phase. In this work, we propose a novel deep learning-based\nmethod to address this critical challenge. Our method, implemented as a neural\nnetwork model, leverages pre-trained language models (PLMs) to capture the\ncomplexities and nuances of clinical documents, transforming them into\nexpressive representations. These representations are then combined with\nencoded tabular features via an attention mechanism. To account for\nuncertainties in enrollment prediction, we enhance the model with a\nprobabilistic layer based on the Gamma distribution, which enables range\nestimation. We apply the proposed model to predict clinical trial duration,\nassuming site-level enrollment follows a Poisson-Gamma process. We carry out\nextensive experiments on real-world clinical trial data, and show that the\nproposed method can effectively predict the number of patients enrolled at a\nnumber of sites for a given clinical trial, outperforming established baseline\nmodels.", "published": "2025-07-31 14:47:16", "link": "http://arxiv.org/abs/2507.23607v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Hierarchical Message-Passing Policies for Multi-Agent Reinforcement Learning", "abstract": "Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for\nlearning scalable multi-agent policies, but suffer from partial observability\nand induced non-stationarity. These challenges can be addressed by introducing\nmechanisms that facilitate coordination and high-level planning. Specifically,\ncoordination and temporal abstraction can be achieved through communication\n(e.g., message passing) and Hierarchical Reinforcement Learning (HRL)\napproaches to decision-making. However, optimization issues limit the\napplicability of hierarchical policies to multi-agent systems. As such, the\ncombination of these approaches has not been fully explored. To fill this void,\nwe propose a novel and effective methodology for learning multi-agent\nhierarchies of message-passing policies. We adopt the feudal HRL framework and\nrely on a hierarchical graph structure for planning and coordination among\nagents. Agents at lower levels in the hierarchy receive goals from the upper\nlevels and exchange messages with neighboring agents at the same level. To\nlearn hierarchical multi-agent policies, we design a novel reward-assignment\nmethod based on training the lower-level policies to maximize the advantage\nfunction associated with the upper levels. Results on relevant benchmarks show\nthat our method performs favorably compared to the state of the art.", "published": "2025-07-31 14:42:12", "link": "http://arxiv.org/abs/2507.23604v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution", "abstract": "Signal unmixing analysis decomposes data into basic patterns and is widely\napplied in chemical and biological research. Multivariate curve resolution\n(MCR), a branch of signal unmixing, separates mixed chemical signals into base\npatterns (components) and their concentrations, playing a key role in\nunderstanding composition. Classical MCR is typically framed as matrix\nfactorization (MF) and requires a user-specified component count, usually\nunknown in real data. As dataset size or component count increases, the\nscalability and reliability of MF-based MCR face significant challenges. This\nstudy reformulates MCR as a generative process (gMCR), and introduces an\nenergy-based deep learning solver, EB-gMCR, that automatically discovers the\nsmallest component set able to reconstruct the data faithfully. EB-gMCR starts\nfrom a large candidate pool (e.g., 1024 spectra) and employs a differentiable\ngating network to retain only active components while estimating their\nconcentrations. On noisy synthetic datasets containing up to 256 latent\nsources, EB-gMCR maintained R^2 >= 0.98 and recovered the component count\nwithin 5% of the ground truth; at lower noise it achieved R^2 >= 0.99 with near\nexact component estimation. Additional chemical priors, such as non-negativity\nor nonlinear mixing, enter as simple plug-in functions, enabling adaptation to\nother instruments or domains without altering the core learning process. By\nuniting high-capacity generative modeling and hard component selection, EB-gMCR\noffers a practical route to large-scale signal unmixing analysis, including\nchemical library-driven scenarios. The source code is available at\nhttps://github.com/b05611038/ebgmcr_solver.", "published": "2025-07-31 14:40:33", "link": "http://arxiv.org/abs/2507.23600v1", "categories": ["cs.LG", "cs.CE", "G.1.6; G.3; G.4; I.6.5"], "primary_category": "cs.LG"}
{"title": "GraphRAG-R1: Graph Retrieval-Augmented Generation with Process-Constrained Reinforcement Learning", "abstract": "Graph Retrieval-Augmented Generation (GraphRAG) has shown great effectiveness\nin enhancing the reasoning abilities of LLMs by leveraging graph structures for\nknowledge representation and modeling complex real-world relationships.\nHowever, existing GraphRAG methods still face significant bottlenecks when\nhandling complex problems that require multi-hop reasoning, as their query and\nretrieval phases are largely based on pre-defined heuristics and do not fully\nutilize the reasoning potentials of LLMs. To address this problem, we propose\nGraphRAG-R1, an adaptive GraphRAG framework by training LLMs with\nprocess-constrained outcome-based reinforcement learning (RL) to enhance the\nmulti-hop reasoning ability. Our method can decompose complex problems,\nautonomously invoke retrieval tools to acquire necessary information, and\nperform effective reasoning. Specifically, we utilize a modified version of\nGroup Relative Policy Optimization (GRPO) that supports rollout-with-thinking\ncapability. Next, we design two process-constrained reward functions. To handle\nthe shallow retrieval problem, we design a Progressive Retrieval Attenuation\n(PRA) reward to encourage essential retrievals. Then, to handle the\nover-thinking problem, we design Cost-Aware F1 (CAF) reward to balance the\nmodel performance with computational costs. We further design a phase-dependent\ntraining strategy, containing three training stages corresponding to cold start\nand these two rewards. Lastly, our method adopts a hybrid graph-textual\nretrieval to improve the reasoning capacity. Extensive experimental results\ndemonstrate that GraphRAG-R1 boosts LLM capabilities in solving complex\nreasoning problems compared to state-of-the-art GraphRAG methods on both\nin-domain and out-of-domain datasets. Furthermore, our framework can be\nflexibly integrated with various existing retrieval methods, consistently\ndelivering performance improvements.", "published": "2025-07-31 14:11:16", "link": "http://arxiv.org/abs/2507.23581v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Optimised Feature Subset Selection via Simulated Annealing", "abstract": "We introduce SA-FDR, a novel algorithm for $\\ell_0$-norm feature selection\nthat considers this task as a combinatorial optimisation problem and solves it\nby using simulated annealing to perform a global search over the space of\nfeature subsets. The optimisation is guided by the Fisher discriminant ratio,\nwhich we use as a computationally efficient proxy for model quality in\nclassification tasks. Our experiments, conducted on datasets with up to\nhundreds of thousands of samples and hundreds of features, demonstrate that\nSA-FDR consistently selects more compact feature subsets while achieving a high\npredictive accuracy. This ability to recover informative yet minimal sets of\nfeatures stems from its capacity to capture inter-feature dependencies often\nmissed by greedy optimisation approaches. As a result, SA-FDR provides a\nflexible and effective solution for designing interpretable models in\nhigh-dimensional settings, particularly when model sparsity, interpretability,\nand performance are crucial.", "published": "2025-07-31 13:57:38", "link": "http://arxiv.org/abs/2507.23568v1", "categories": ["cs.LG", "cond-mat.stat-mech", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2 Neuromorphic Platform", "abstract": "Spiking Neural Networks (SNNs) promise orders-of-magnitude lower power\nconsumption and low-latency inference on neuromorphic hardware for a wide range\nof robotic tasks. In this work, we present an energy-efficient implementation\nof a reinforcement learning (RL) algorithm using quantized SNNs to solve two\nclassical control tasks. The network is trained using the Q-learning algorithm,\nthen fine-tuned and quantized to low-bit (8-bit) precision for embedded\ndeployment on the SpiNNaker2 neuromorphic chip. To evaluate the comparative\nadvantage of SpiNNaker2 over conventional computing platforms, we analyze\ninference latency, dynamic power consumption, and energy cost per inference for\nour SNN models, comparing performance against a GTX 1650 GPU baseline. Our\nresults demonstrate SpiNNaker2's strong potential for scalable, low-energy\nneuromorphic computing, achieving up to 32x reduction in energy consumption.\nInference latency remains on par with GPU-based execution, with improvements\nobserved in certain task settings, reinforcing SpiNNaker2's viability for\nreal-time neuromorphic control and making the neuromorphic approach a\ncompelling direction for efficient deep Q-learning.", "published": "2025-07-31 13:49:44", "link": "http://arxiv.org/abs/2507.23562v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Improved Algorithms for Kernel Matrix-Vector Multiplication Under Sparsity Assumptions", "abstract": "Motivated by the problem of fast processing of attention matrices, we study\nfast algorithms for computing matrix-vector products for asymmetric Gaussian\nKernel matrices $K\\in \\mathbb{R}^{n\\times n}$. $K$'s columns are indexed by a\nset of $n$ keys $k_1,k_2\\ldots, k_n\\in \\mathbb{R}^d$, rows by a set of $n$\nqueries $q_1,q_2,\\ldots,q_n\\in \\mathbb{R}^d $, and its $i,j$ entry is $K_{ij} =\ne^{-\\|q_i-k_j\\|_2^2/2\\sigma^2}$ for some bandwidth parameter $\\sigma>0$. Given\na vector $x\\in \\mathbb{R}^n$ and error parameter $\\epsilon>0$, our task is to\noutput a $y\\in \\mathbb{R}^n$ such that $\\|Kx-y\\|_2\\leq \\epsilon \\|x\\|_2$ in\ntime subquadratic in $n$ and linear in $d$. Our algorithms rely on the\nfollowing modelling assumption about the matrices $K$: the sum of the entries\nof $K$ scales linearly in $n$, as opposed to worst case quadratic growth. We\nvalidate this assumption experimentally, for Gaussian kernel matrices\nencountered in various settings such as fast attention computation in LLMs. We\nobtain the first subquadratic-time algorithm that works under this assumption,\nfor unrestricted vectors.", "published": "2025-07-31 13:29:43", "link": "http://arxiv.org/abs/2507.23539v1", "categories": ["cs.LG", "cs.DS"], "primary_category": "cs.LG"}
{"title": "From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices", "abstract": "Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs\nof updating deep learning models by minimizing the number of additional\nparameters used to adapt a model to a down- stream task. While extensively\nresearched in large language models (LLMs), their application to smaller models\nused on edge devices, such as convolutional neural networks, remains\nunderexplored. This paper benchmarks and analyzes popular PEFT methods on\nconvolutional architectures typically deployed in resource-constrained edge\nenvironments. We evaluate LoRA, DoRA, and GaLore for updating standard and\ndepthwise convolutional architectures to handle distribution shifts and\naccommodate unseen classes. We utilize recently proposed PyTorch profilers to\ncompare the updated model performance and computational costs of these PEFT\nmethods with traditional fine-tuning approaches. With resource efficiency in\nmind, we investigate their update behavior across different rank dimensions. We\nfind that the evaluated PEFT methods are only half as memory-efficient when\napplied to depthwise-separable convolution architectures, compared to their\nefficiency with LLMs. Conversely, when targeting convolu- tional architectures\noptimized for edge deployment, adapter-based PEFT methods can reduce floating\npoint operations (FLOPs) during model updates by up to 95%. These insights\noffer valuable guidance for selecting PEFT methods based on hardware\nconstraints, performance requirements, and application needs. Our code is\nonline.", "published": "2025-07-31 13:23:21", "link": "http://arxiv.org/abs/2507.23536v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Transparent AI: The Case for Interpretability and Explainability", "abstract": "As artificial intelligence systems increasingly inform high-stakes decisions\nacross sectors, transparency has become foundational to responsible and\ntrustworthy AI implementation. Leveraging our role as a leading institute in\nadvancing AI research and enabling industry adoption, we present key insights\nand lessons learned from practical interpretability applications across diverse\ndomains. This paper offers actionable strategies and implementation guidance\ntailored to organizations at varying stages of AI maturity, emphasizing the\nintegration of interpretability as a core design principle rather than a\nretrospective add-on.", "published": "2025-07-31 13:22:14", "link": "http://arxiv.org/abs/2507.23535v1", "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Continual Learning with Synthetic Boundary Experience Blending", "abstract": "Continual learning (CL) aims to address catastrophic forgetting in models\ntrained sequentially on multiple tasks. While experience replay has shown\npromise, its effectiveness is often limited by the sparse distribution of\nstored key samples, leading to overly simplified decision boundaries. We\nhypothesize that introducing synthetic data near the decision boundary\n(Synthetic Boundary Data, or SBD) during training serves as an implicit\nregularizer, improving boundary stability and mitigating forgetting. To\nvalidate this hypothesis, we propose a novel training framework, {\\bf\nExperience Blending}, which integrates knowledge from both stored key samples\nand synthetic, boundary-adjacent data. Experience blending consists of two core\ncomponents: (1) a multivariate Differential Privacy (DP) noise mechanism that\ninjects batch-wise noise into low-dimensional feature representations,\ngenerating SBD; and (2) an end-to-end training strategy that jointly leverages\nboth stored key samples and SBD. Extensive experiments on CIFAR-10, CIFAR-100,\nand Tiny ImageNet demonstrate that our method outperforms nine CL baselines,\nachieving accuracy improvements of 10%, 6%, and 13%, respectively.", "published": "2025-07-31 13:20:17", "link": "http://arxiv.org/abs/2507.23534v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation", "abstract": "Imitation learning for robotic manipulation faces a fundamental challenge:\nthe scarcity of large-scale, high-quality robot demonstration data. Recent\nrobotic foundation models often pre-train on cross-embodiment robot datasets to\nincrease data scale, while they face significant limitations as the diverse\nmorphologies and action spaces across different robot embodiments make unified\ntraining challenging. In this paper, we present H-RDT (Human to Robotics\nDiffusion Transformer), a novel approach that leverages human manipulation data\nto enhance robot manipulation capabilities. Our key insight is that large-scale\negocentric human manipulation videos with paired 3D hand pose annotations\nprovide rich behavioral priors that capture natural manipulation strategies and\ncan benefit robotic policy learning. We introduce a two-stage training\nparadigm: (1) pre-training on large-scale egocentric human manipulation data,\nand (2) cross-embodiment fine-tuning on robot-specific data with modular action\nencoders and decoders. Built on a diffusion transformer architecture with 2B\nparameters, H-RDT uses flow matching to model complex action distributions.\nExtensive evaluations encompassing both simulation and real-world experiments,\nsingle-task and multitask scenarios, as well as few-shot learning and\nrobustness assessments, demonstrate that H-RDT outperforms training from\nscratch and existing state-of-the-art methods, including Pi0 and RDT, achieving\nsignificant improvements of 13.9% and 40.5% over training from scratch in\nsimulation and real-world experiments, respectively. The results validate our\ncore hypothesis that human manipulation data can serve as a powerful foundation\nfor learning bimanual robotic manipulation policies.", "published": "2025-07-31 13:06:59", "link": "http://arxiv.org/abs/2507.23523v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level", "abstract": "Gradient clipping is a fundamental tool in Deep Learning, improving the\nhigh-probability convergence of stochastic first-order methods like SGD,\nAdaGrad, and Adam under heavy-tailed noise, which is common in training large\nlanguage models. It is also a crucial component of Differential Privacy (DP)\nmechanisms. However, existing high-probability convergence analyses typically\nrequire the clipping threshold to increase with the number of optimization\nsteps, which is incompatible with standard DP mechanisms like the Gaussian\nmechanism. In this work, we close this gap by providing the first\nhigh-probability convergence analysis for DP-Clipped-SGD with a fixed clipping\nlevel, applicable to both convex and non-convex smooth optimization under\nheavy-tailed noise, characterized by a bounded central $\\alpha$-th moment\nassumption, $\\alpha \\in (1,2]$. Our results show that, with a fixed clipping\nlevel, the method converges to a neighborhood of the optimal solution with a\nfaster rate than the existing ones. The neighborhood can be balanced against\nthe noise introduced by DP, providing a refined trade-off between convergence\nspeed and privacy guarantees.", "published": "2025-07-31 12:48:29", "link": "http://arxiv.org/abs/2507.23512v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "A Verifier Hierarchy", "abstract": "We investigate the trade-off between certificate length and verifier runtime.\nWe prove a Verifier Trade-off Theorem showing that reducing the inherent\nverification time of a language from \\(f(n)\\) to \\(g(n)\\), where \\(f(n) \\ge\ng(n)\\), requires certificates of length at least \\(\\Omega(\\log(f(n) / g(n)))\\).\nThis theorem induces a natural hierarchy based on certificate complexity. We\ndemonstrate its applicability to analyzing conjectured separations between\ncomplexity classes (e.g., \\(\\np\\) and \\(\\exptime\\)) and to studying natural\nproblems such as string periodicity and rotation detection. Additionally, we\nprovide perspectives on the \\(\\p\\) vs. \\(\\np\\) problem by relating it to the\nexistence of sub-linear certificates.", "published": "2025-07-31 12:42:42", "link": "http://arxiv.org/abs/2507.23504v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Directional Ensemble Aggregation for Actor-Critics", "abstract": "Off-policy reinforcement learning in continuous control tasks depends\ncritically on accurate $Q$-value estimates. Conservative aggregation over\nensembles, such as taking the minimum, is commonly used to mitigate\noverestimation bias. However, these static rules are coarse, discard valuable\ninformation from the ensemble, and cannot adapt to task-specific needs or\ndifferent learning regimes. We propose Directional Ensemble Aggregation (DEA),\nan aggregation method that adaptively combines $Q$-value estimates in\nactor-critic frameworks. DEA introduces two fully learnable directional\nparameters: one that modulates critic-side conservatism and another that guides\nactor-side policy exploration. Both parameters are learned using ensemble\ndisagreement-weighted Bellman errors, which weight each sample solely by the\ndirection of its Bellman error. This directional learning mechanism allows DEA\nto adjust conservatism and exploration in a data-driven way, adapting\naggregation to both uncertainty levels and the phase of training. We evaluate\nDEA across continuous control benchmarks and learning regimes - from\ninteractive to sample-efficient - and demonstrate its effectiveness over static\nensemble strategies.", "published": "2025-07-31 12:40:50", "link": "http://arxiv.org/abs/2507.23501v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Incorporating structural uncertainty in causal decision making", "abstract": "Practitioners making decisions based on causal effects typically ignore\nstructural uncertainty. We analyze when this uncertainty is consequential\nenough to warrant methodological solutions (Bayesian model averaging over\ncompeting causal structures). Focusing on bivariate relationships ($X\n\\rightarrow Y$ vs. $X \\leftarrow Y$), we establish that model averaging is\nbeneficial when: (1) structural uncertainty is moderate to high, (2) causal\neffects differ substantially between structures, and (3) loss functions are\nsufficiently sensitive to the size of the causal effect. We prove optimality\nresults of our suggested methodological solution under regularity conditions\nand demonstrate through simulations that modern causal discovery methods can\nprovide, within limits, the necessary quantification. Our framework complements\nexisting robust causal inference approaches by addressing a distinct source of\nuncertainty typically overlooked in practice.", "published": "2025-07-31 12:29:49", "link": "http://arxiv.org/abs/2507.23495v1", "categories": ["cs.LG", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Explainable artificial intelligence model predicting the risk of all-cause mortality in patients with type 2 diabetes mellitus", "abstract": "Objective. Type 2 diabetes mellitus (T2DM) is a highly prevalent\nnon-communicable chronic disease that substantially reduces life expectancy.\nAccurate estimation of all-cause mortality risk in T2DM patients is crucial for\npersonalizing and optimizing treatment strategies. Research Design and Methods.\nThis study analyzed a cohort of 554 patients (aged 40-87 years) with diagnosed\nT2DM over a maximum follow-up period of 16.8 years, during which 202 patients\n(36%) died. Key survival-associated features were identified, and multiple\nmachine learning (ML) models were trained and validated to predict all-cause\nmortality risk. To improve model interpretability, Shapley additive\nexplanations (SHAP) was applied to the best-performing model. Results. The\nextra survival trees (EST) model, incorporating ten key features, demonstrated\nthe best predictive performance. The model achieved a C-statistic of 0.776,\nwith the area under the receiver operating characteristic curve (AUC) values of\n0.86, 0.80, 0.841, and 0.826 for 5-, 10-, 15-, and 16.8-year all-cause\nmortality predictions, respectively. The SHAP approach was employed to\ninterpret the model's individual decision-making processes. Conclusions. The\ndeveloped model exhibited strong predictive performance for mortality risk\nassessment. Its clinically interpretable outputs enable potential bedside\napplication, improving the identification of high-risk patients and supporting\ntimely treatment optimization.", "published": "2025-07-31 12:23:10", "link": "http://arxiv.org/abs/2507.23491v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Machine learning and machine learned prediction in chest X-ray images", "abstract": "Machine learning and artificial intelligence are fast-growing fields of\nresearch in which data is used to train algorithms, learn patterns, and make\npredictions. This approach helps to solve seemingly intricate problems with\nsignificant accuracy without explicit programming by recognizing complex\nrelationships in data. Taking an example of 5824 chest X-ray images, we\nimplement two machine learning algorithms, namely, a baseline convolutional\nneural network (CNN) and a DenseNet-121, and present our analysis in making\nmachine-learned predictions in predicting patients with ailments. Both baseline\nCNN and DenseNet-121 perform very well in the binary classification problem\npresented in this work. Gradient-weighted class activation mapping shows that\nDenseNet-121 correctly focuses on essential parts of the input chest X-ray\nimages in its decision-making more than the baseline CNN.", "published": "2025-07-31 11:31:25", "link": "http://arxiv.org/abs/2507.23455v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Manifold-regularised Signature Kernel Large-Margin $\\ell_p$-SVDD for Multidimensional Time Series Anomaly Detection", "abstract": "We generalise the recently introduced large-margin $\\ell_p$-SVDD approach to\nexploit the geometry of data distribution via manifold regularising and a\nsignature kernel representation for time series anomaly detection.\nSpecifically, we formulate a manifold-regularised variant of the $\\ell_p$-SVDD\nmethod to encourage label smoothness on the underlying manifold to capture\nstructural information for improved detection performance. Drawing on an\nexisting Representer theorem, we then provide an effective optimisation\ntechnique for the proposed method and show that it can benefit from the\nsignature kernel to capture time series complexities for anomaly detection.\n  We theoretically study the proposed approach using Rademacher complexities to\nanalyse its generalisation performance and also provide an experimental\nassessment of the proposed method across various data sets to compare its\nperformance against other methods.", "published": "2025-07-31 11:27:01", "link": "http://arxiv.org/abs/2507.23449v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adjoint-Based Aerodynamic Shape Optimization with a Manifold Constraint Learned by Diffusion Models", "abstract": "We introduce an adjoint-based aerodynamic shape optimization framework that\nintegrates a diffusion model trained on existing designs to learn a smooth\nmanifold of aerodynamically viable shapes. This manifold is enforced as an\nequality constraint to the shape optimization problem. Central to our method is\nthe computation of adjoint gradients of the design objectives (e.g., drag and\nlift) with respect to the manifold space. These gradients are derived by first\ncomputing shape derivatives with respect to conventional shape design\nparameters (e.g., Hicks-Henne parameters) and then backpropagating them through\nthe diffusion model to its latent space via automatic differentiation. Our\nframework preserves mathematical rigor and can be integrated into existing\nadjoint-based design workflows with minimal modification. Demonstrated on\nextensive transonic RANS airfoil design cases using off-the-shelf and\ngeneral-purpose nonlinear optimizers, our approach eliminates ad hoc parameter\ntuning and variable scaling, maintains robustness across initialization and\noptimizer choices, and achieves superior aerodynamic performance compared to\nconventional approaches. This work establishes how AI generated priors\nintegrates effectively with adjoint methods to enable robust, high-fidelity\naerodynamic shape optimization through automatic differentiation.", "published": "2025-07-31 11:21:20", "link": "http://arxiv.org/abs/2507.23443v1", "categories": ["cs.CE", "cs.LG", "math.OC"], "primary_category": "cs.CE"}
{"title": "Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design", "abstract": "Hardware-Aware Neural Architecture Search (HW-NAS) is an efficient approach\nto automatically co-optimizing neural network performance and hardware energy\nefficiency, making it particularly useful for the development of Deep Neural\nNetwork accelerators on the edge. However, the extensive search space and high\ncomputational cost pose significant challenges to its practical adoption. To\naddress these limitations, we propose Coflex, a novel HW-NAS framework that\nintegrates the Sparse Gaussian Process (SGP) with multi-objective Bayesian\noptimization. By leveraging sparse inducing points, Coflex reduces the GP\nkernel complexity from cubic to near-linear with respect to the number of\ntraining samples, without compromising optimization performance. This enables\nscalable approximation of large-scale search space, substantially decreasing\ncomputational overhead while preserving high predictive accuracy. We evaluate\nthe efficacy of Coflex across various benchmarks, focusing on\naccelerator-specific architecture. Our experi- mental results show that Coflex\noutperforms state-of-the-art methods in terms of network accuracy and\nEnergy-Delay-Product, while achieving a computational speed-up ranging from\n1.9x to 9.5x.", "published": "2025-07-31 11:16:46", "link": "http://arxiv.org/abs/2507.23437v1", "categories": ["cs.LG", "I.2.6; C.1.3; C.3"], "primary_category": "cs.LG"}
{"title": "Merging Memory and Space: A Spatiotemporal State Space Neural Operator", "abstract": "We propose the Spatiotemporal State Space Neural Operator (ST-SSM), a compact\narchitecture for learning solution operators of time-dependent partial\ndifferential equations (PDEs). ST-SSM introduces a novel factorization of the\nspatial and temporal dimensions, using structured state-space models to\nindependently model temporal evolution and spatial interactions. This design\nenables parameter efficiency and flexible modeling of long-range spatiotemporal\ndynamics. A theoretical connection is established between SSMs and neural\noperators, and a unified universality theorem is proved for the resulting class\nof architectures. Empirically, we demonstrate that our factorized formulation\noutperforms alternative schemes such as zigzag scanning and parallel\nindependent processing on several PDE benchmarks, including 1D Burgers'\nequation, 1D Kuramoto-Sivashinsky equation, and 2D Navier-Stokes equations\nunder varying physical conditions. Our model performs competitively with\nexisting baselines while using significantly fewer parameters. In addition, our\nresults reinforce previous findings on the benefits of temporal memory by\nshowing improved performance under partial observability. Our results highlight\nthe advantages of dimensionally factorized operator learning for efficient and\ngeneralizable PDE modeling, and put this approach on a firm theoretical\nfooting.", "published": "2025-07-31 11:09:15", "link": "http://arxiv.org/abs/2507.23428v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Detection of Adulteration in Coconut Milk using Infrared Spectroscopy and Machine Learning", "abstract": "In this paper, we propose a system for detecting adulteration in coconut\nmilk, utilizing infrared spectroscopy. The machine learning-based proposed\nsystem comprises three phases: preprocessing, feature extraction, and\nclassification. The first phase involves removing irrelevant data from coconut\nmilk spectral signals. In the second phase, we employ the Linear Discriminant\nAnalysis (LDA) algorithm for extracting the most discriminating features. In\nthe third phase, we use the K-Nearest Neighbor (KNN) model to classify coconut\nmilk samples into authentic or adulterated. We evaluate the performance of the\nproposed system using a public dataset comprising Fourier Transform Infrared\n(FTIR) spectral information of pure and contaminated coconut milk samples.\nFindings show that the proposed method successfully detects adulteration with a\ncross-validation accuracy of 93.33%.", "published": "2025-07-31 10:44:36", "link": "http://arxiv.org/abs/2507.23418v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Honey Adulteration Detection using Hyperspectral Imaging and Machine Learning", "abstract": "This paper aims to develop a machine learning-based system for automatically\ndetecting honey adulteration with sugar syrup, based on honey hyperspectral\nimaging data. First, the floral source of a honey sample is classified by a\nbotanical origin identification subsystem. Then, the sugar syrup adulteration\nis identified, and its concentration is quantified by an adulteration detection\nsubsystem. Both subsystems consist of two steps. The first step involves\nextracting relevant features from the honey sample using Linear Discriminant\nAnalysis (LDA). In the second step, we utilize the K-Nearest Neighbors (KNN)\nmodel to classify the honey botanical origin in the first subsystem and\nidentify the adulteration level in the second subsystem. We assess the proposed\nsystem performance on a public honey hyperspectral image dataset. The result\nindicates that the proposed system can detect adulteration in honey with an\noverall cross-validation accuracy of 96.39%, making it an appropriate\nalternative to the current chemical-based detection methods.", "published": "2025-07-31 10:41:45", "link": "http://arxiv.org/abs/2507.23416v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Machine Learning Approach for Honey Adulteration Detection using Mineral Element Profiles", "abstract": "This paper aims to develop a Machine Learning (ML)-based system for detecting\nhoney adulteration utilizing honey mineral element profiles. The proposed\nsystem comprises two phases: preprocessing and classification. The\npreprocessing phase involves the treatment of missing-value attributes and\nnormalization. In the classifica-tion phase, we use three supervised ML models:\nlogistic regression, decision tree, and random forest, to dis-criminate between\nauthentic and adulterated honey. To evaluate the performance of the ML models,\nwe use a public dataset comprising measurements of mineral element content of\nauthentic honey, sugar syrups, and adul-terated honey. Experimental findings\nshow that mineral element content in honey provides robust discriminative\ninformation for detecting honey adulteration. Results also demonstrate that the\nrandom forest-based classifier outperforms other classifiers on this dataset,\nachieving the highest cross-validation accuracy of 98.37%.", "published": "2025-07-31 10:36:58", "link": "http://arxiv.org/abs/2507.23412v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "AGA: An adaptive group alignment framework for structured medical cross-modal representation learning", "abstract": "Learning medical visual representations from paired images and reports is a\npromising direction in representation learning. However, current\nvision-language pretraining methods in the medical domain often simplify\nclinical reports into single entities or fragmented tokens, ignoring their\ninherent structure. In addition, contrastive learning frameworks typically\ndepend on large quantities of hard negative samples, which is impractical for\nsmall-scale medical datasets. To tackle these challenges, we propose Adaptive\nGrouped Alignment (AGA), a new framework that captures structured semantics\nfrom paired medical images and reports. AGA introduces a bidirectional grouping\nmechanism based on a sparse similarity matrix. For each image-report pair, we\ncompute fine-grained similarities between text tokens and image patches. Each\ntoken selects its top-matching patches to form a visual group, and each patch\nselects its most related tokens to form a language group. To enable adaptive\ngrouping, we design two threshold gating modules, called Language Grouped\nThreshold Gate and Vision Grouped Threshold Gate, which learn grouping\nthresholds dynamically. Group representations are computed as weighted averages\nbased on similarity scores. To align each token with its group representation,\nwe introduce an Instance Aware Group Alignment loss that operates within each\nimage-text pair, removing the need for external negatives. Finally, a\nBidirectional Cross-modal Grouped Alignment module is applied to enhance\nfine-grained alignment between visual and linguistic group representations.\nExtensive experiments on public and private datasets show that our method\nachieves strong performance on image-text retrieval and classification tasks\nunder both fine-tuning and zero-shot settings.", "published": "2025-07-31 10:14:49", "link": "http://arxiv.org/abs/2507.23402v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Policy Learning from Large Vision-Language Model Feedback without Reward Modeling", "abstract": "Offline reinforcement learning (RL) provides a powerful framework for\ntraining robotic agents using pre-collected, suboptimal datasets, eliminating\nthe need for costly, time-consuming, and potentially hazardous online\ninteractions. This is particularly useful in safety-critical real-world\napplications, where online data collection is expensive and impractical.\nHowever, existing offline RL algorithms typically require reward labeled data,\nwhich introduces an additional bottleneck: reward function design is itself\ncostly, labor-intensive, and requires significant domain expertise. In this\npaper, we introduce PLARE, a novel approach that leverages large\nvision-language models (VLMs) to provide guidance signals for agent training.\nInstead of relying on manually designed reward functions, PLARE queries a VLM\nfor preference labels on pairs of visual trajectory segments based on a\nlanguage task description. The policy is then trained directly from these\npreference labels using a supervised contrastive preference learning objective,\nbypassing the need to learn explicit reward models. Through extensive\nexperiments on robotic manipulation tasks from the MetaWorld, PLARE achieves\nperformance on par with or surpassing existing state-of-the-art VLM-based\nreward generation methods. Furthermore, we demonstrate the effectiveness of\nPLARE in real-world manipulation tasks with a physical robot, further\nvalidating its practical applicability.", "published": "2025-07-31 10:07:49", "link": "http://arxiv.org/abs/2507.23391v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Causal Explanation of Concept Drift -- A Truly Actionable Approach", "abstract": "In a world that constantly changes, it is crucial to understand how those\nchanges impact different systems, such as industrial manufacturing or critical\ninfrastructure. Explaining critical changes, referred to as concept drift in\nthe field of machine learning, is the first step towards enabling targeted\ninterventions to avoid or correct model failures, as well as malfunctions and\nerrors in the physical world. Therefore, in this work, we extend model-based\ndrift explanations towards causal explanations, which increases the\nactionability of the provided explanations. We evaluate our explanation\nstrategy on a number of use cases, demonstrating the practical usefulness of\nour framework, which isolates the causally relevant features impacted by\nconcept drift and, thus, allows for targeted intervention.", "published": "2025-07-31 10:02:28", "link": "http://arxiv.org/abs/2507.23389v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SWE-Exp: Experience-Driven Software Issue Resolution", "abstract": "Recent advances in large language model (LLM) agents have shown remarkable\nprogress in software issue resolution, leveraging advanced techniques such as\nmulti-agent collaboration and Monte Carlo Tree Search (MCTS). However, current\nagents act as memoryless explorers - treating each problem separately without\nretaining or reusing knowledge from previous repair experiences. This leads to\nredundant exploration of failed trajectories and missed chances to adapt\nsuccessful issue resolution methods to similar problems. To address this\nproblem, we introduce SWE-Exp, an experience - enhanced approach that distills\nconcise and actionable experience from prior agent trajectories, enabling\ncontinuous learning across issues. Our method introduces a multi-faceted\nexperience bank that captures both successful and failed repair attempts.\nSpecifically, it extracts reusable issue resolution knowledge at different\nlevels - from high-level problem comprehension to specific code changes.\nExperiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%\nPass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach\nestablishes a new paradigm in which automated software engineering agents\nsystematically accumulate and leverage repair expertise, fundamentally shifting\nfrom trial-and-error exploration to strategic, experience-driven issue\nresolution.", "published": "2025-07-31 09:13:42", "link": "http://arxiv.org/abs/2507.23361v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Optimal Transport Learning: Balancing Value Optimization and Fairness in Individualized Treatment Rules", "abstract": "Individualized treatment rules (ITRs) have gained significant attention due\nto their wide-ranging applications in fields such as precision medicine,\nridesharing, and advertising recommendations. However, when ITRs are influenced\nby sensitive attributes such as race, gender, or age, they can lead to outcomes\nwhere certain groups are unfairly advantaged or disadvantaged. To address this\ngap, we propose a flexible approach based on the optimal transport theory,\nwhich is capable of transforming any optimal ITR into a fair ITR that ensures\ndemographic parity. Recognizing the potential loss of value under fairness\nconstraints, we introduce an ``improved trade-off ITR,\" designed to balance\nvalue optimization and fairness while accommodating varying levels of fairness\nthrough parameter adjustment. To maximize the value of the improved trade-off\nITR under specific fairness levels, we propose a smoothed fairness constraint\nfor estimating the adjustable parameter. Additionally, we establish a\ntheoretical upper bound on the value loss for the improved trade-off ITR. We\ndemonstrate performance of the proposed method through extensive simulation\nstudies and application to the Next 36 entrepreneurial program dataset.", "published": "2025-07-31 08:56:03", "link": "http://arxiv.org/abs/2507.23349v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution", "abstract": "Issue resolution has made remarkable progress thanks to the advanced\nreasoning capabilities of large language models (LLMs). Recently, agent-based\nframeworks such as SWE-agent have further advanced this progress by enabling\nautonomous, tool-using agents to tackle complex software engineering tasks.\nWhile existing agent-based issue resolution approaches are primarily based on\nagents' independent explorations, they often get stuck in local solutions and\nfail to identify issue patterns that span across different parts of the\ncodebase. To address this limitation, we propose SWE-Debate, a competitive\nmulti-agent debate framework that encourages diverse reasoning paths and\nachieves more consolidated issue localization. SWE-Debate first creates\nmultiple fault propagation traces as localization proposals by traversing a\ncode dependency graph. Then, it organizes a three-round debate among\nspecialized agents, each embodying distinct reasoning perspectives along the\nfault propagation trace. This structured competition enables agents to\ncollaboratively converge on a consolidated fix plan. Finally, this consolidated\nfix plan is integrated into an MCTS-based code modification agent for patch\ngeneration. Experiments on the SWE-bench benchmark show that SWE-Debate\nachieves new state-of-the-art results in open-source agent frameworks and\noutperforms baselines by a large margin.", "published": "2025-07-31 08:54:46", "link": "http://arxiv.org/abs/2507.23348v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation", "abstract": "Bike-sharing systems are emerging in various cities as a new ecofriendly\ntransportation system. In these systems, spatiotemporally varying user demands\nlead to imbalanced inventory at bicycle stations, resulting in additional\nrelocation costs. Therefore, it is essential to manage user demand through\noptimal dynamic pricing for the system. However, optimal pricing design for\nsuch a system is challenging because the system involves users with diverse\nbackgrounds and their probabilistic choices. To address this problem, we\ndevelop a differentiable agent-based simulation to rapidly design dynamic\npricing in bike-sharing systems, achieving balanced bicycle inventory despite\nspatiotemporally heterogeneous trips and probabilistic user decisions. We first\nvalidate our approach against conventional methods through numerical\nexperiments involving 25 bicycle stations and five time slots, yielding 100\nparameters. Compared to the conventional methods, our approach obtains a more\naccurate solution with a 73% to 78% reduction in loss while achieving more than\na 100-fold increase in convergence speed. We further validate our approach on a\nlarge-scale urban bike-sharing system scenario involving 289 bicycle stations,\nresulting in a total of 1156 parameters. Through simulations using the obtained\npricing policies, we confirm that these policies can naturally induce balanced\ninventory without any manual relocation. Additionally, we find that the cost of\ndiscounts to induce the balanced inventory can be minimized by setting\nappropriate initial conditions.", "published": "2025-07-31 08:43:54", "link": "http://arxiv.org/abs/2507.23344v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Scalable and Precise Patch Robustness Certification for Deep Learning Models with Top-k Predictions", "abstract": "Patch robustness certification is an emerging verification approach for\ndefending against adversarial patch attacks with provable guarantees for deep\nlearning systems. Certified recovery techniques guarantee the prediction of the\nsole true label of a certified sample. However, existing techniques, if\napplicable to top-k predictions, commonly conduct pairwise comparisons on those\nvotes between labels, failing to certify the sole true label within the top k\nprediction labels precisely due to the inflation on the number of votes\ncontrolled by the attacker (i.e., attack budget); yet enumerating all\ncombinations of vote allocation suffers from the combinatorial explosion\nproblem. We propose CostCert, a novel, scalable, and precise voting-based\ncertified recovery defender. CostCert verifies the true label of a sample\nwithin the top k predictions without pairwise comparisons and combinatorial\nexplosion through a novel design: whether the attack budget on the sample is\ninfeasible to cover the smallest total additional votes on top of the votes\nuncontrollable by the attacker to exclude the true labels from the top k\nprediction labels. Experiments show that CostCert significantly outperforms the\ncurrent state-of-the-art defender PatchGuard, such as retaining up to 57.3% in\ncertified accuracy when the patch size is 96, whereas PatchGuard has already\ndropped to zero.", "published": "2025-07-31 08:31:59", "link": "http://arxiv.org/abs/2507.23335v1", "categories": ["cs.LG", "cs.SE"], "primary_category": "cs.LG"}
{"title": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "abstract": "Recent advancements in Large language models (LLMs) have demonstrated\nremarkable capabilities across diverse domains. While they exhibit strong\nzero-shot performance on various tasks, LLMs' effectiveness in music-related\napplications remains limited due to the relatively small proportion of\nmusic-specific knowledge in their training data. To address this limitation, we\npropose MusT-RAG, a comprehensive framework based on Retrieval Augmented\nGeneration (RAG) to adapt general-purpose LLMs for text-only music question\nanswering (MQA) tasks. RAG is a technique that provides external knowledge to\nLLMs by retrieving relevant context information when generating answers to\nquestions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a\nmusic-specialized vector database for the retrieval stage, and (2) utilizes\ncontext information during both inference and fine-tuning processes to\neffectively transform general-purpose LLMs into music-specific models. Our\nexperiment demonstrates that MusT-RAG significantly outperforms traditional\nfine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,\nshowing consistent improvements across both in-domain and out-of-domain MQA\nbenchmarks. Additionally, our MusWikiDB proves substantially more effective\nthan general Wikipedia corpora, delivering superior performance and\ncomputational efficiency.", "published": "2025-07-31 08:31:05", "link": "http://arxiv.org/abs/2507.23334v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Good Learners Think Their Thinking: Generative PRM Makes Large Reasoning Model More Efficient Math Learner", "abstract": "Large reasoning models (LRMs) have recently shown promise in solving complex\nmath problems when optimized with Reinforcement Learning (RL). But conventional\napproaches rely on outcome-only rewards that provide sparse feedback, resulting\nin inefficient optimization process. In this work, we investigate the function\nof process reward models (PRMs) to accelerate the RL training for LRMs. We\npropose a novel intrinsic signal-driven generative process evaluation mechanism\noperating at the thought level to address major bottlenecks in RL-based\ntraining. Specifically, instead of requiring PRMs to know how to solve\nproblems, our method uses intrinsic signals in solutions to judge stepwise\ncorrectness and aggregate contiguous correct/incorrect steps into coherent\n'thought' units. This structured, thought-level rewards enable more reliable\ncredit assignment by reducing ambiguity in step segmentation and alleviating\nreward hacking. We further introduce a capability-adaptive reward mechanism\nthat dynamically balances exploration and exploitation based on the LRM's\ncurrent proficiency, guiding learning without stifling creative\ntrial-and-error. These innovations are integrated into a new off-policy RL\nalgorithm, TP-GRPO, which extends grouped proximal optimization with\nprocess-based rewards and improves training efficiency. Experiments on 1.5B and\n7B parameter LRMs demonstrate that our method achieves higher problem-solving\naccuracy with significantly fewer training samples than outcome-only reward\nbaselines. The results validate that well-structured process rewards can\nsubstantially accelerate LRM optimization in math reasoning tasks. Code is\navailable at https://github.com/cs-holder/tp_grpo.", "published": "2025-07-31 07:54:58", "link": "http://arxiv.org/abs/2507.23317v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification", "abstract": "Lightweight convolutional and transformer-based models have become vital for\nreal-time image classification in resource-constrained applications, such as\nembedded systems and edge devices. This work analyzes the influence of\nhyperparameter adjustment on the accuracy and convergence behavior of seven\nefficient deep learning architectures: EfficientNetV2-S, ConvNeXt-T, MobileViT\nv2 (XXS/XS/S), MobileNetV3-L, TinyViT-21M, and RepVGG-A2. All models are\ntrained on the ImageNet-1K dataset under consistent training settings, with an\nemphasis on real-time practicality. An comprehensive ablation study is\nundertaken to separate the effect of critical hyperparameters, including\nlearning rate schedules, batch sizes, input resolution, data augmentation,\nregularization approaches, and optimizer choice. To assess appropriateness for\nreal-time applications, each model is assessed not only in terms of Top-1 and\nTop-5 classification accuracy, but also in terms of inference time, parameter\ncount, model size, and frames-per-second (FPS) on a GPU-accelerated edge\ndeployment simulation. Results demonstrate that cosine learning rate decay and\nadjustable batch size may greatly boost both accuracy and convergence speed,\nwhile keeping low latency and memory cost. Notably, RepVGG-A2 achieves over 80%\nTop-1 accuracy with efficient inference performance, offering a compelling\nbalance between accuracy and deployment cost for VGG-style models. The results\ngive practical guidance for constructing resource-efficient deep learning\nmodels appropriate for real-time image processing pipelines. All code and\ntraining logs are publicly accessible at\nhttps://github.com/VineetKumarRakesh/lcnn-opt.", "published": "2025-07-31 07:47:30", "link": "http://arxiv.org/abs/2507.23315v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "An Interpretable Data-Driven Unsupervised Approach for the Prevention of Forgotten Items", "abstract": "Accurately identifying items forgotten during a supermarket visit and\nproviding clear, interpretable explanations for recommending them remains an\nunderexplored problem within the Next Basket Prediction (NBP) domain. Existing\nNBP approaches typically only focus on forecasting future purchases, without\nexplicitly addressing the detection of unintentionally omitted items. This gap\nis partly due to the scarcity of real-world datasets that allow for the\nreliable estimation of forgotten items. Furthermore, most current NBP methods\nrely on black-box models, which lack transparency and limit the ability to\njustify recommendations to end users. In this paper, we formally introduce the\nforgotten item prediction task and propose two novel interpretable-by-design\nalgorithms. These methods are tailored to identify forgotten items while\noffering intuitive, human-understandable explanations. Experiments on a\nreal-world retail dataset show our algorithms outperform state-of-the-art NBP\nbaselines by 10-15% across multiple evaluation metrics.", "published": "2025-07-31 07:37:54", "link": "http://arxiv.org/abs/2507.23303v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Simulation-based inference for Precision Neutrino Physics through Neural Monte Carlo tuning", "abstract": "Precise modeling of detector energy response is crucial for next-generation\nneutrino experiments which present computational challenges due to lack of\nanalytical likelihoods. We propose a solution using neural likelihood\nestimation within the simulation-based inference framework. We develop two\ncomplementary neural density estimators that model likelihoods of calibration\ndata: conditional normalizing flows and a transformer-based regressor. We adopt\nJUNO - a large neutrino experiment - as a case study. The energy response of\nJUNO depends on several parameters, all of which should be tuned, given their\nnon-linear behavior and strong correlations in the calibration data. To this\nend, we integrate the modeled likelihoods with Bayesian nested sampling for\nparameter inference, achieving uncertainties limited only by statistics with\nnear-zero systematic biases. The normalizing flows model enables unbinned\nlikelihood analysis, while the transformer provides an efficient binned\nalternative. By providing both options, our framework offers flexibility to\nchoose the most appropriate method for specific needs. Finally, our approach\nestablishes a template for similar applications across experimental neutrino\nand broader particle physics.", "published": "2025-07-31 07:33:05", "link": "http://arxiv.org/abs/2507.23297v1", "categories": ["physics.data-an", "cs.LG", "hep-ex", "hep-ph", "physics.ins-det"], "primary_category": "physics.data-an"}
{"title": "SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy", "abstract": "We introduce a neural network layer API and library for sequence modeling,\ndesigned for easy creation of sequence models that can be executed both\nlayer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,\nautoregressive sampling). To achieve this, layers define an explicit\nrepresentation of their state over time (e.g., a Transformer KV cache, a\nconvolution buffer, an RNN hidden state), and a step method that evolves that\nstate, tested to give identical results to a stateless layer-wise invocation.\nThis and other aspects of the SequenceLayers contract enables complex models to\nbe immediately streamable, mitigates a wide range of common bugs arising in\nboth streaming and parallel sequence processing, and can be implemented in any\ndeep learning library. A composable and declarative API, along with a\ncomprehensive suite of layers and combinators, streamlines the construction of\nproduction-scale models from simple streamable components while preserving\nstrong correctness guarantees. Our current implementations of SequenceLayers\n(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.", "published": "2025-07-31 07:10:39", "link": "http://arxiv.org/abs/2507.23292v1", "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Evaluating the Dynamics of Membership Privacy in Deep Learning", "abstract": "Membership inference attacks (MIAs) pose a critical threat to the privacy of\ntraining data in deep learning. Despite significant progress in attack\nmethodologies, our understanding of when and how models encode membership\ninformation during training remains limited. This paper presents a dynamic\nanalytical framework for dissecting and quantifying privacy leakage dynamics at\nthe individual sample level. By tracking per-sample vulnerabilities on an\nFPR-TPR plane throughout training, our framework systematically measures how\nfactors such as dataset complexity, model architecture, and optimizer choice\ninfluence the rate and severity at which samples become vulnerable. Crucially,\nwe discover a robust correlation between a sample's intrinsic learning\ndifficulty, and find that the privacy risk of samples highly vulnerable in the\nfinal trained model is largely determined early during training. Our results\nthus provide a deeper understanding of how privacy risks dynamically emerge\nduring training, laying the groundwork for proactive, privacy-aware model\ntraining strategies.", "published": "2025-07-31 07:09:52", "link": "http://arxiv.org/abs/2507.23291v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System", "abstract": "Current multi-agent systems (MAS) frameworks often rely on manually designed\nand static collaboration graph structures, limiting adaptability and\nperformance. To address these limitations, we propose DynaSwarm, a dynamic\nframework that enhances LLM-based MAS through two key innovations: (1) an\nactor-critic reinforcement learning (A2C) mechanism to optimize graph\nstructures with improved stability over prior RL methods, and (2) a dynamic\ngraph selector that adaptively chooses the optimal graph structure for each\ninput sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the\nneed for rigid, one-fits-all graph architectures, instead leveraging\nsample-specific idiosyncrasies to dynamically route queries through specialized\nagent networks. (c) We propose to fine-tune the demonstration retriever to\nfully exploit the power of in-context learning (ICL). Extensive experiments on\nquestion answering, mathematical reasoning, and coding tasks demonstrate that\nDynaSwarm consistently outperforms state-of-the-art single-agent and MAS\nbaselines across multiple LLM backbones. Our findings highlight the importance\nof sample-aware structural flexibility in LLM MAS designs.", "published": "2025-07-31 05:52:30", "link": "http://arxiv.org/abs/2507.23261v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Efficient Machine Unlearning via Influence Approximation", "abstract": "Due to growing privacy concerns, machine unlearning, which aims at enabling\nmachine learning models to ``forget\" specific training data, has received\nincreasing attention. Among existing methods, influence-based unlearning has\nemerged as a prominent approach due to its ability to estimate the impact of\nindividual training samples on model parameters without retraining. However,\nthis approach suffers from prohibitive computational overhead arising from the\nnecessity to compute the Hessian matrix and its inverse across all training\nsamples and parameters, rendering it impractical for large-scale models and\nscenarios involving frequent data deletion requests. This highlights the\ndifficulty of forgetting. Inspired by cognitive science, which suggests that\nmemorizing is easier than forgetting, this paper establishes a theoretical link\nbetween memorizing (incremental learning) and forgetting (unlearning). This\nconnection allows machine unlearning to be addressed from the perspective of\nincremental learning. Unlike the time-consuming Hessian computations in\nunlearning (forgetting), incremental learning (memorizing) typically relies on\nmore efficient gradient optimization, which supports the aforementioned\ncognitive theory. Based on this connection, we introduce the Influence\nApproximation Unlearning (IAU) algorithm for efficient machine unlearning from\nthe incremental perspective. Extensive empirical evaluations demonstrate that\nIAU achieves a superior balance among removal guarantee, unlearning efficiency,\nand comparable model utility, while outperforming state-of-the-art methods\nacross diverse datasets and model architectures. Our code is available at\nhttps://github.com/Lolo1222/IAU.", "published": "2025-07-31 05:34:27", "link": "http://arxiv.org/abs/2507.23257v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis", "abstract": "Bengali is an underrepresented language in NLP research. However, it remains\na challenge due to its unique linguistic structure and computational\nconstraints. In this work, we systematically investigate the challenges that\nhinder Bengali NLP performance by focusing on the absence of standardized\nevaluation benchmarks. We then evaluated 10 recent open source Large Language\nModels (LLMs) in 8 of the translated datasets and performed a comprehensive\nerror analysis to pinpoint their primary failure modes. Our findings reveal\nconsistent performance gaps for Bengali compared to English, particularly for\nsmaller models and specific model families like Mistral. We also identified\npromising robustness in certain architectures, such as DeepSeek, that maintain\nmore stable performance across languages. Our analysis reveals an inverse\nrelationship between tokenization efficiency and LLM accuracy where models tend\nto perform worse when inputs are excessively tokenized, whereas more efficient\n\\& concise tokenization results in improved performance. These findings\nhighlight critical areas where current models fall short and underscore the\nneed for improved dataset quality and evaluation methodologies tailored to\nmultilingual contexts. This work will catalyze further research on NLP for\nunderrepresented languages, helping to democratize access to advanced language\ntechnologies worldwide. The code and dataset used in this research is publicly\navailable at https://github.com/BengaliAI/bn-llm-benchmark.", "published": "2025-07-31 05:16:43", "link": "http://arxiv.org/abs/2507.23248v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents", "abstract": "Retrieval-Augmented Generation (RAG) systems rely heavily on effective query\nformulation to unlock external knowledge, yet optimizing queries for diverse,\nunstructured real-world documents remains a challenge. We introduce\n\\textbf{RL-QR}, a reinforcement learning framework for retriever-specific query\nrewriting that eliminates the need for human-annotated datasets and extends\napplicability to both text-only and multi-modal databases. By synthesizing\nscenario-question pairs and leveraging Generalized Reward Policy Optimization\n(GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing\nretrieval performance across varied domains. Experiments on industrial in-house\ndata demonstrate significant improvements, with\n$\\text{RL-QR}_{\\text{multi-modal}}$ achieving an 11\\% relative gain in NDCG@3\nfor multi-modal RAG and $\\text{RL-QR}_{\\text{lexical}}$ yielding a 9\\% gain for\nlexical retrievers. However, challenges persist with semantic and hybrid\nretrievers, where rewriters failed to improve performance, likely due to\ntraining misalignments. Our findings highlight RL-QR's potential to\nrevolutionize query optimization for RAG systems, offering a scalable,\nannotation-free solution for real-world retrieval tasks, while identifying\navenues for further refinement in semantic retrieval contexts.", "published": "2025-07-31 04:55:21", "link": "http://arxiv.org/abs/2507.23242v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs", "abstract": "Early and accurate diagnosis of Alzheimer's disease (AD), a complex\nneurodegenerative disorder, requires analysis of heterogeneous biomarkers\n(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal\nfluid proteins) typically represented in a tabular format. With flexible\nfew-shot reasoning, multimodal integration, and natural-language-based\ninterpretability, large language models (LLMs) offer unprecedented\nopportunities for prediction with structured biomedical data. We propose a\nnovel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts\nTableGPT2, a multimodal tabular-specialized LLM originally developed for\nbusiness intelligence tasks, for AD diagnosis using structured biomarker data\nwith small sample sizes. Our approach constructs few-shot tabular prompts using\nin-context learning examples from structured biomedical data and finetunes\nTableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary\nclassification task of AD or cognitively normal (CN). The TAP-GPT framework\nharnesses the powerful tabular understanding ability of TableGPT2 and the\nencoded prior knowledge of LLMs to outperform more advanced general-purpose\nLLMs and a tabular foundation model (TFM) developed for prediction tasks. To\nour knowledge, this is the first application of LLMs to the prediction task\nusing tabular biomarker data, paving the way for future LLM-driven multi-agent\nframeworks in biomedical informatics.", "published": "2025-07-31 03:49:31", "link": "http://arxiv.org/abs/2507.23227v1", "categories": ["cs.CL", "cs.LG", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "A Single Direction of Truth: An Observer Model's Linear Residual Probe Exposes and Steers Contextual Hallucinations", "abstract": "Contextual hallucinations -- statements unsupported by given context --\nremain a significant challenge in AI. We demonstrate a practical\ninterpretability insight: a generator-agnostic observer model detects\nhallucinations via a single forward pass and a linear probe on its residual\nstream. This probe isolates a single, transferable linear direction separating\nhallucinated from faithful text, outperforming baselines by 5-27 points and\nshowing robust mid-layer performance across Gemma-2 models (2B to 27B).\nGradient-times-activation localises this signal to sparse, late-layer MLP\nactivity. Critically, manipulating this direction causally steers generator\nhallucination rates, proving its actionability. Our results offer novel\nevidence of internal, low-dimensional hallucination tracking linked to specific\nMLP sub-circuits, exploitable for detection and mitigation. We release the\n2000-example ContraTales benchmark for realistic assessment of such solutions.", "published": "2025-07-31 03:26:57", "link": "http://arxiv.org/abs/2507.23221v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders", "abstract": "Traditional topic models are effective at uncovering latent themes in large\ntext collections. However, due to their reliance on bag-of-words\nrepresentations, they struggle to capture semantically abstract features. While\nsome neural variants use richer representations, they are similarly constrained\nby expressing topics as word lists, which limits their ability to articulate\ncomplex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic\nmodels that operate on interpretable features learned by sparse autoencoders\n(SAEs). By defining topics over this semantically rich space, MTMs can reveal\ndeeper conceptual themes with expressive feature descriptions. Moreover,\nuniquely among topic models, MTMs enable controllable text generation using\ntopic-based steering vectors. To properly evaluate MTM topics against\nword-list-based approaches, we propose \\textit{topic judge}, an LLM-based\npairwise comparison evaluation framework. Across five datasets, MTMs match or\nexceed traditional and neural baselines on coherence metrics, are consistently\npreferred by topic judge, and enable effective steering of LLM outputs.", "published": "2025-07-31 03:17:43", "link": "http://arxiv.org/abs/2507.23220v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation", "abstract": "Understanding complex multimodal documents remains challenging due to their\nstructural inconsistencies and limited training data availability. We introduce\n\\textit{DocsRay}, a training-free document understanding system that integrates\npseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented\nGeneration (RAG). Our approach leverages multimodal Large Language Models'\n(LLMs) native capabilities to seamlessly process documents containing diverse\nelements such as text, images, charts, and tables without requiring specialized\nmodels or additional training. DocsRay's framework synergistically combines\nthree key techniques: (1) a semantic structuring module using prompt-based LLM\ninteractions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal\nanalysis that converts diverse document elements into unified, text-centric\nrepresentations using the inherent capabilities of multimodal LLMs, and (3) an\nefficient two-stage hierarchical retrieval system that reduces retrieval\ncomplexity from $O(N)$ to $O(S + k_1 \\cdot N_s)$. Evaluated on documents\naveraging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency\nfrom 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the\nMMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%,\nsubstantially surpassing previous state-of-the-art results.", "published": "2025-07-31 03:14:45", "link": "http://arxiv.org/abs/2507.23217v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Not Just What, But When: Integrating Irregular Intervals to LLM for Sequential Recommendation", "abstract": "Time intervals between purchasing items are a crucial factor in sequential\nrecommendation tasks, whereas existing approaches focus on item sequences and\noften overlook by assuming the intervals between items are static. However,\ndynamic intervals serve as a dimension that describes user profiling on not\nonly the history within a user but also different users with the same item\nhistory. In this work, we propose IntervalLLM, a novel framework that\nintegrates interval information into LLM and incorporates the novel\ninterval-infused attention to jointly consider information of items and\nintervals. Furthermore, unlike prior studies that address the cold-start\nscenario only from the perspectives of users and items, we introduce a new\nviewpoint: the interval perspective to serve as an additional metric for\nevaluating recommendation methods on the warm and cold scenarios. Extensive\nexperiments on 3 benchmarks with both traditional- and LLM-based baselines\ndemonstrate that our IntervalLLM achieves not only 4.4% improvements in average\nbut also the best-performing warm and cold scenarios across all users, items,\nand the proposed interval perspectives. In addition, we observe that the cold\nscenario from the interval perspective experiences the most significant\nperformance drop among all recommendation methods. This finding underscores the\nnecessity of further research on interval-based cold challenges and our\nintegration of interval information in the realm of sequential recommendation\ntasks. Our code is available here:\nhttps://github.com/sony/ds-research-code/tree/master/recsys25-IntervalLLM.", "published": "2025-07-31 03:05:05", "link": "http://arxiv.org/abs/2507.23209v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Are Recommenders Self-Aware? Label-Free Recommendation Performance Estimation via Model Uncertainty", "abstract": "Can a recommendation model be self-aware? This paper investigates the\nrecommender's self-awareness by quantifying its uncertainty, which provides a\nlabel-free estimation of its performance. Such self-assessment can enable more\ninformed understanding and decision-making before the recommender engages with\nany users. To this end, we propose an intuitive and effective method,\nprobability-based List Distribution uncertainty (LiDu). LiDu measures\nuncertainty by determining the probability that a recommender will generate a\ncertain ranking list based on the prediction distributions of individual items.\nWe validate LiDu's ability to represent model self-awareness in two settings:\n(1) with a matrix factorization model on a synthetic dataset, and (2) with\npopular recommendation algorithms on real-world datasets. Experimental results\nshow that LiDu is more correlated with recommendation performance than a series\nof label-free performance estimators. Additionally, LiDu provides valuable\ninsights into the dynamic inner states of models throughout training and\ninference. This work establishes an empirical connection between recommendation\nuncertainty and performance, framing it as a step towards more transparent and\nself-evaluating recommender systems.", "published": "2025-07-31 03:04:34", "link": "http://arxiv.org/abs/2507.23208v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks", "abstract": "The demand for AI-generated GPU kernels is rapidly growing, influenced by the\nneed for scalable, hardware-optimized solutions in both industry and academia.\nAs deep learning workloads grow in complexity and diversity, it is imperative\nto automate low-level kernel development to meet performance and productivity\ndemands. Major cloud providers, semiconductor companies, and research\ninstitutions are now investing heavily in AI-driven code generation for GPUs,\naiming to reduce manual optimization efforts while achieving near-expert\nperformance on hardware like AMD MI300X. The Triton language, a Python-based\nDSL for GPU programming, has emerged as a popular target for such AI-generated\nkernels due to its balance of performance and ease-of-coding. In this work, we\npresent an evaluation suite for Triton-based GPU kernels and GEAK (Generating\nEfficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs\nto generate performant Triton code specifically for AMD GPUs, including the AMD\nMI300X and MI250. GEAK leverages inference-time compute scaling to produce\nTriton-based GPU kernels using a reasoning loop adapted from Reflexion-style\nfeedback mechanisms. On two evaluation benchmarks, GEAK significantly\noutperformed the baselines of directly prompting frontier LLMs as well as\nReflexion-based generation pipelines by achieving correctness up to $63$% and\nexecution speed up of up to $2.59$X. These results highlight the promise of\nGEAK-like agentic code generation for accelerating the adoption of diverse\nhardware platforms and democratizing access to expert-level kernel performance.", "published": "2025-07-31 02:26:58", "link": "http://arxiv.org/abs/2507.23194v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions", "abstract": "Sparsity detection in black-box functions enables significant computational\nspeedups in gradient-based optimization through Jacobian compression, but\nexisting finite-difference methods suffer from false negatives due to\ncoincidental zero gradients. These false negatives can silently corrupt\ngradient calculations, leading to difficult-to-diagnose errors. We introduce\nNaN-propagation, which exploits the universal contamination property of IEEE\n754 Not-a-Number floating-point values to trace input-output dependencies\nthrough floating-point numerical computations. By systematically contaminating\ninputs with NaN and observing which outputs become NaN, the method reconstructs\nconservative sparsity patterns that eliminate false negatives. We demonstrate\nthe approach on an aerospace wing weight model, achieving a 1.52x speedup while\ndetecting dozens of dependencies missed by conventional methods -- a\nsignificant improvement since gradient computation is the bottleneck in many\noptimization workflows. The technique leverages IEEE 754 compliance to work\nacross programming languages and math libraries without modifying existing\nblack-box codes. Advanced strategies including NaN payload encoding enable\nfaster-than-linear time complexity, improving upon existing black-box sparsity\ndetection methods. Practical algorithms are also proposed to mitigate\nchallenges from branching code execution common in engineering applications.", "published": "2025-07-31 01:48:56", "link": "http://arxiv.org/abs/2507.23186v1", "categories": ["cs.LG", "cs.PL"], "primary_category": "cs.LG"}
{"title": "CNN-based solution for mango classification in agricultural environments", "abstract": "This article exemplifies the design of a fruit detection and classification\nsystem using Convolutional\n  Neural Networks (CNN). The goal is to develop a system that automatically\nassesses fruit quality for\n  farm inventory management. Specifically, a method for mango fruit\nclassification was developed using\n  image processing, ensuring both accuracy and efficiency. Resnet-18 was\nselected as the preliminary\n  architecture for classification, while a cascade detector was used for\ndetection, balancing execution speed\n  and computational resource consumption. Detection and classification results\nwere displayed through a\n  graphical interface developed in MatLab App Designer, streamlining system\ninteraction. The integration\n  of convolutional neural networks and cascade detectors proffers a reliable\nsolution for fruit classification\n  and detection, with potential applications in agricultural quality control.", "published": "2025-07-31 00:58:34", "link": "http://arxiv.org/abs/2507.23174v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BAR Conjecture: the Feasibility of Inference Budget-Constrained LLM Services with Authenticity and Reasoning", "abstract": "When designing LLM services, practitioners care about three key properties:\ninference-time budget, factual authenticity, and reasoning capacity. However,\nour analysis shows that no model can simultaneously optimize for all three. We\nformally prove this trade-off and propose a principled framework named The BAR\nTheorem for LLM-application design.", "published": "2025-07-31 00:51:16", "link": "http://arxiv.org/abs/2507.23170v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration", "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across\nvarious tasks, with different models excelling in distinct domains and specific\nabilities. Effectively combining the predictions of multiple LLMs is crucial\nfor enhancing system robustness and performance. However, existing ensemble\nmethods often rely on simple techniques like voting or logits ensembling, which\noverlook the varying confidence and reliability of models in different\ncontexts. In this work, we propose LENS (Learning ENsemble confidence from\nNeural States), a novel approach that learns to estimate model confidence by\nanalyzing internal representations. For each LLM, we train a lightweight linear\nconfidence predictor that leverages layer-wise hidden states and normalized\nprobabilities as inputs. This allows for more nuanced weighting of model\npredictions based on their context-dependent reliability. Our method does not\nrequire modifying the model parameters and requires negligible additional\ncomputation. Experimental results on multiple-choice and boolean\nquestion-answering tasks demonstrate that LENS outperforms traditional ensemble\nmethods by a substantial margin. Our findings suggest that internal\nrepresentations provide valuable signals for determining model confidence and\ncan be effectively leveraged for ensemble learning.", "published": "2025-07-31 00:35:45", "link": "http://arxiv.org/abs/2507.23167v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Information geometry of L\u00e9vy processes and financial models", "abstract": "We explore the information geometry of L\\'evy processes. As a starting point,\nwe derive the $\\alpha$-divergence between two L\\'evy processes. Subsequently,\nthe Fisher information matrix and the $\\alpha$-connection associated with the\ngeometry of L\\'evy processes are computed from the $\\alpha$-divergence. In\naddition, we discuss statistical applications of this information geometry. As\nillustrative examples, we investigate the differential-geometric structures of\nvarious L\\'evy processes relevant to financial modeling, including tempered\nstable processes, the CGMY model, and variance gamma processes.", "published": "2025-07-31 15:24:16", "link": "http://arxiv.org/abs/2507.23646v1", "categories": ["stat.TH", "cs.IT", "math.DG", "math.IT", "math.PR", "q-fin.MF"], "primary_category": "stat.TH"}
{"title": "Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions", "abstract": "We compare two methodologies for calibrating implied volatility surfaces: a\nsecond-order asymptotic expansion method derived via Malliavin calculus, and a\ndata-driven approach based on path signatures from rough path theory. The\nformer, developed in Al\\`os et al. (2015), yields efficient and accurate\ncalibration formulas under the assumption that the asset price follows a\nHeston-type stochastic volatility model. The latter models volatility as a\nlinear functional of the signature of a primary stochastic process, enabling a\nflexible approximation without requiring a specific parametric form.\n  Our numerical experiments show that the signature-based method achieves\ncalibration accuracy comparable to the asymptotic approach when the true\ndynamics are Heston. We then test the model in a more general setting where the\nasset follows a rough Bergomi volatility process-a regime beyond the scope of\nthe asymptotic expansion-and show that the signature approach continues to\ndeliver accurate results. These findings highlight the model-independence,\nrobustness and adaptability of signature-based calibration methods in settings\nwhere volatility exhibits rough or non-Markovian features.", "published": "2025-07-31 10:08:02", "link": "http://arxiv.org/abs/2507.23392v1", "categories": ["q-fin.MF", "math.PR", "60L70, 60H10, 91G20, 91G60, 60G22"], "primary_category": "q-fin.MF"}
{"title": "Complexity of Financial Time Series: Multifractal and Multiscale Entropy Analyses", "abstract": "We employed Multifractal Detrended Fluctuation Analysis (MF-DFA) and Refined\nComposite Multiscale Sample Entropy (RCMSE) to investigate the complexity of\nBitcoin, GBP/USD, gold, and natural gas price log-return time series. This\nstudy provides a comparative analysis of these markets and offers insights into\ntheir predictability and associated risks. Each tool presents a unique method\nto quantify time series complexity. The RCMSE and MF-DFA methods demonstrate a\nhigher complexity for the Bitcoin time series than others. It is discussed that\nthe increased complexity of Bitcoin may be attributable to the presence of\nhigher nonlinear correlations within its log-return time series.", "published": "2025-07-31 10:39:43", "link": "http://arxiv.org/abs/2507.23414v1", "categories": ["q-fin.ST", "physics.data-an"], "primary_category": "q-fin.ST"}
{"title": "Barycentric subspace analysis of network-valued data", "abstract": "Certain data are naturally modeled by networks or weighted graphs, be they\narterial networks or mobility networks. When there is no canonical labeling of\nthe nodes across the dataset, we talk about unlabeled networks. In this paper,\nwe focus on the question of dimensionality reduction for this type of data.\nMore specifically, we address the issue of interpreting the feature subspace\nconstructed by dimensionality reduction methods. Most existing methods for\nnetwork-valued data are derived from principal component analysis (PCA) and\ntherefore rely on subspaces generated by a set of vectors, which we identify as\na major limitation in terms of interpretability. Instead, we propose to\nimplement the method called barycentric subspace analysis (BSA), which relies\non subspaces generated by a set of points. In order to provide a\ncomputationally feasible framework for BSA, we introduce a novel embedding for\nunlabeled networks where we replace their usual representation by equivalence\nclasses of isomorphic networks with that by equivalence classes of cospectral\nnetworks. We then illustrate BSA on simulated and real-world datasets, and\ncompare it to tangent PCA.", "published": "2025-07-31 13:46:36", "link": "http://arxiv.org/abs/2507.23559v1", "categories": ["math.DG", "stat.ML"], "primary_category": "math.DG"}
{"title": "Overcoming error-in-variable problem in data-driven model discovery by orthogonal distance regression", "abstract": "Despite the recent proliferation of machine learning methods like SINDy that\npromise automatic discovery of governing equations from time-series data, there\nremain significant challenges to discovering models from noisy datasets. One\nreason is that the linear regression underlying these methods assumes that all\nnoise resides in the training target (the regressand), which is the time\nderivative, whereas the measurement noise is in the states (the regressors).\nRecent methods like modified-SINDy and DySMHO address this error-in-variable\nproblem by leveraging information from the model's temporal evolution, but they\nare also imposing the equation as a hard constraint, which effectively assumes\nno error in the regressand. Without relaxation, this hard constraint prevents\nassimilation of data longer than Lyapunov time. Instead, the fulfilment of the\nmodel equation should be treated as a soft constraint to account for the small\nyet critical error introduced by numerical truncation. The uncertainties in\nboth the regressor and the regressand invite the use of orthogonal distance\nregression (ODR). By incorporating ODR with the Bayesian framework for model\nselection, we introduce a novel method for model discovery, termed ODR-BINDy,\nand assess its performance against current SINDy variants using the Lorenz63,\nRossler, and Van Der Pol systems as case studies. Our findings indicate that\nODR-BINDy consistently outperforms all existing methods in recovering the\ncorrect model from sparse and noisy datasets. For instance, our ODR-BINDy\nmethod reliably recovers the Lorenz63 equation from data with noise\ncontamination levels of up to 30%.", "published": "2025-07-31 11:06:30", "link": "http://arxiv.org/abs/2507.23426v1", "categories": ["stat.ME", "nlin.CD", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities", "abstract": "While question-answering~(QA) benchmark performance is an automatic and\nscalable method to compare LLMs, it is an indirect method of evaluating their\nunderlying problem-solving capabilities. Therefore, we propose a holistic and\ngeneralizable framework based on \\emph{cascaded question disclosure} that\nprovides a more accurate estimate of the models' problem-solving capabilities\nwhile maintaining the scalability and automation. This approach collects model\nresponses in a stagewise manner with each stage revealing partial information\nabout the question designed to elicit generalized reasoning in LLMs. We find\nthat our approach not only provides a better comparison between LLMs, but also\ninduces better intermediate traces in models compared to the standard QA\nparadigm. We empirically verify this behavior on diverse reasoning and\nknowledge-heavy QA datasets by comparing LLMs of varying sizes and families.\nOur approach narrows the performance gap observed in the standard QA evaluation\nsettings, indicating that the prevalent indirect QA paradigm of evaluation\noverestimates the differences in performance between models. We further\nvalidate our findings by extensive ablation studies.", "published": "2025-07-31 17:58:25", "link": "http://arxiv.org/abs/2507.23776v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks", "abstract": "We propose CoT-Self-Instruct, a synthetic data generation method that\ninstructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the\ngiven seed tasks, and then to generate a new synthetic prompt of similar\nquality and complexity for use in LLM training, followed by filtering for\nhigh-quality data with automatic metrics. In verifiable reasoning, our\nsynthetic data significantly outperforms existing training datasets, such as\ns1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For\nnon-verifiable instruction-following tasks, our method surpasses the\nperformance of human or standard self-instruct prompts on both AlpacaEval 2.0\nand Arena-Hard.", "published": "2025-07-31 17:38:50", "link": "http://arxiv.org/abs/2507.23751v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "abstract": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.", "published": "2025-07-31 17:00:30", "link": "http://arxiv.org/abs/2507.23726v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "TextQuests: How Good are LLMs at Text-Based Video Games?", "abstract": "Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai.", "published": "2025-07-31 16:22:55", "link": "http://arxiv.org/abs/2507.23701v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning", "abstract": "Hate speech identification in social media has become an increasingly\nimportant issue in recent years. In this research, we address two problems: 1)\nto detect hate speech in Arabic text, 2) to clean a given text from hate\nspeech. The meaning of cleaning here is replacing each bad word with stars\nbased on the number of letters for each word. Regarding the first problem, we\nconduct several experiments using deep learning models and transformers to\ndetermine the best model in terms of the F1 score. Regarding second problem, we\nconsider it as a machine translation task, where the input is a sentence\ncontaining dirty text and the output is the same sentence with masking the\ndirty text. The presented methods achieve the best model in hate speech\ndetection with a 92\\% Macro F1 score and 95\\% accuracy. Regarding the text\ncleaning experiment, the best result in the hate speech masking model reached\n0.3 in BLEU score with 1-gram, which is a good result compared with the state\nof the art machine translation systems.", "published": "2025-07-31 15:39:46", "link": "http://arxiv.org/abs/2507.23661v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "DiffLoRA: Differential Low-Rank Adapters for Large Language Models", "abstract": "Differential Transformer has recently been proposed to improve performance in\nTransformer models by canceling out noise through a denoiser attention\nmechanism. In this work, we introduce DiffLoRA, a parameter-efficient\nadaptation of the differential attention mechanism, with low-rank adapters on\nboth positive and negative attention terms. This approach retains the\nefficiency of LoRA while aiming to benefit from the performance gains of\ndifferential attention. We evaluate DiffLoRA across a broad range of NLP tasks,\nincluding general benchmarks, many-shot in-context learning, RAG, and\nlong-context tests. We observe that, although DiffLoRA falls short of other\nparameter-efficient fine-tuning methods in most evaluation tasks, it shows\ninteresting results in certain domains (+11 pts on LoRA for HumanEval). We\nanalyze the attention patterns post-finetuning to identify the reasons for this\nbehavior.", "published": "2025-07-31 14:24:59", "link": "http://arxiv.org/abs/2507.23588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text", "abstract": "The proliferation of sophisticated text generation models necessitates the\ndevelopment of robust detection methods capable of identifying\nmachine-generated content, particularly text designed to evade detection\nthrough adversarial perturbations. Existing zero-shot detectors often rely on\nstatistical measures that implicitly assume Gaussian distributions, a premise\nthat falters when confronted with the heavy-tailed statistical artifacts\ncharacteristic of adversarial or non-native English texts. This paper\nintroduces T-Detect, a novel detection method that fundamentally redesigns the\nstatistical core of curvature-based detectors. Our primary innovation is the\nreplacement of standard Gaussian normalization with a heavy-tailed discrepancy\nscore derived from the Student's t-distribution. This approach is theoretically\ngrounded in the empirical observation that adversarial texts exhibit\nsignificant leptokurtosis, rendering traditional statistical assumptions\ninadequate. T-Detect computes a detection score by normalizing the\nlog-likelihood of a passage against the expected moments of a t-distribution,\nproviding superior resilience to statistical outliers. We validate our approach\non the challenging RAID benchmark for adversarial text and the comprehensive\nHART dataset. Experiments show that T-Detect provides a consistent performance\nuplift over strong baselines, improving AUROC by up to 3.9\\% in targeted\ndomains. When integrated into a two-dimensional detection framework (CT), our\nmethod achieves state-of-the-art performance, with an AUROC of 0.926 on the\nBooks domain of RAID. Our contributions are a new, theoretically-justified\nstatistical foundation for text detection, an ablation-validated method that\ndemonstrates superior robustness, and a comprehensive analysis of its\nperformance under adversarial conditions. Ours code are released at\nhttps://github.com/ResearAI/t-detect.", "published": "2025-07-31 14:08:04", "link": "http://arxiv.org/abs/2507.23577v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning", "abstract": "In medical scenarios, effectively retrieving external knowledge and\nleveraging it for rigorous logical reasoning is of significant importance.\nDespite their potential, existing work has predominantly focused on enhancing\neither retrieval or reasoning capabilities of the models in isolation, with\nlittle attention given to their joint optimization, which leads to limited\ncoordination between the two processes. Additionally, current methods rely\nheavily on supervised fine-tuning (SFT), which can cause models to memorize\nexisting problem-solving pathways, thereby restricting their generalization\nability when confronted with novel problem contexts. Furthermore, while some\nstudies have explored to improve retrieval-augmented reasoning in general\ndomains via reinforcement learning, their reward function designs do not\nadequately capture the specific demands of the medical domain. To address these\nchallenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented\n**R**easoning framework driven by progressive **R**einforcement learning. In\nthis framework, we first develop the model's ability to perform logical\nreasoning over medical problems. Subsequently, on the basis of this foundation,\nwe adaptively optimize the retrieval capability to better align with the\ncharacteristics of knowledge corpus and external information utilization\nthroughout the reasoning process. Finally, we conduct joint optimization of the\nmodel's retrieval and reasoning coordination. Extensive experiments indicate\nthat **Med-R$^3$** could achieve state-of-the-art performances, with\nLLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by\n3.93\\% at a comparable parameter scale, while Qwen2.5-14B augmented with\nMed-R$^3$ shows a more substantial gain of 13.53\\%.", "published": "2025-07-31 13:31:01", "link": "http://arxiv.org/abs/2507.23541v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks", "abstract": "While large audio-language models have advanced open-ended audio\nunderstanding, they still fall short of nuanced human-level comprehension. This\ngap persists largely because current benchmarks, limited by data annotations\nand evaluation metrics, fail to reliably distinguish between generic and highly\ndetailed model outputs. To this end, this work introduces MECAT, a Multi-Expert\nConstructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via\na pipeline that integrates analysis from specialized expert models with\nChain-of-Thought large language model reasoning, MECAT provides\nmulti-perspective, fine-grained captions and open-set question-answering pairs.\nThe benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced\nAudio Text Evaluation). This metric penalizes generic terms and rewards\ndetailed descriptions by combining single-sample semantic similarity with\ncross-sample discriminability. A comprehensive evaluation of state-of-the-art\naudio models is also presented, providing new insights into their current\ncapabilities and limitations. The data and code are available at\nhttps://github.com/xiaomi-research/mecat", "published": "2025-07-31 12:47:43", "link": "http://arxiv.org/abs/2507.23511v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains", "abstract": "Large language models (LLMs) hold promise in clinical decision support but\nface major challenges in safety evaluation and effectiveness validation. We\ndeveloped the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a\nmultidimensional framework built on clinical expert consensus, encompassing 30\ncriteria covering critical areas like critical illness recognition, guideline\nadherence, and medication safety, with weighted consequence measures.\nThirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A\nitems aligned with these criteria, spanning 26 clinical departments to simulate\nreal-world scenarios. Benchmark testing of six LLMs revealed moderate overall\nperformance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),\nwith a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).\nDomain-specific medical LLMs showed consistent performance advantages over\ngeneral-purpose models, with relatively higher top scores in safety (0.912) and\neffectiveness (0.861). The findings of this study not only provide a\nstandardized metric for evaluating the clinical application of medical LLMs,\nfacilitating comparative analyses, risk exposure identification, and\nimprovement directions across different scenarios, but also hold the potential\nto promote safer and more effective deployment of large language models in\nhealthcare environments.", "published": "2025-07-31 12:10:00", "link": "http://arxiv.org/abs/2507.23486v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations", "abstract": "As large language models (LLMs) are increasingly deployed in enterprise\nsettings, controlling model behavior based on user roles becomes an essential\nrequirement. Existing safety methods typically assume uniform access and focus\non preventing harmful or toxic outputs, without addressing role-specific access\nconstraints. In this work, we investigate whether LLMs can be fine-tuned to\ngenerate responses that reflect the access privileges associated with different\norganizational roles. We explore three modeling strategies: a BERT-based\nclassifier, an LLM-based classifier, and role-conditioned generation. To\nevaluate these approaches, we construct two complementary datasets. The first\nis adapted from existing instruction-tuning corpora through clustering and role\nlabeling, while the second is synthetically generated to reflect realistic,\nrole-sensitive enterprise scenarios. We assess model performance across varying\norganizational structures and analyze robustness to prompt injection, role\nmismatch, and jailbreak attempts.", "published": "2025-07-31 11:41:04", "link": "http://arxiv.org/abs/2507.23465v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems", "abstract": "This paper investigates defenses for LLM-based evaluation systems against\nprompt injection. We formalize a class of threats called blind attacks, where a\ncandidate answer is crafted independently of the true answer to deceive the\nevaluator. To counter such attacks, we propose a framework that augments\nStandard Evaluation (SE) with Counterfactual Evaluation (CFE), which\nre-evaluates the submission against a deliberately false ground-truth answer.\nAn attack is detected if the system validates an answer under both standard and\ncounterfactual conditions. Experiments show that while standard evaluation is\nhighly vulnerable, our SE+CFE framework significantly improves security by\nboosting attack detection with minimal performance trade-offs.", "published": "2025-07-31 11:29:42", "link": "http://arxiv.org/abs/2507.23453v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration", "abstract": "Critical thinking is essential for building robust AI systems, preventing\nthem from blindly accepting flawed data or biased reasoning. However, prior\nwork has primarily focused on passive critical thinking, where models simply\nreject problematic queries without taking constructive steps to address user\nrequests. In this work, we introduce proactive critical thinking, a paradigm\nwhere models actively seek missing or clarifying information from users to\nresolve their queries better. To evaluate this capability, we present GSM-MC\nand GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical\nreasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math\nproblems with a key variable deliberately removed, requiring models to identify\nand request the missing information. GSM-MCE further increases the difficulty\nby introducing irrelevant details to test robustness against distractions.\nExperiments on Qwen3 and Llama series models show that, while these models\nexcel in traditional reasoning tasks due to extensive post-training and\ninference-time scaling, they struggle with proactive critical thinking,\nespecially smaller ones. However, we demonstrate that reinforcement learning\n(RL) can significantly improve this ability. Using our enhanced RL algorithm,\nwe achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to\n73.98% on GSM-MC. We hope this work advances models that collaborate more\neffectively with users in problem-solving through proactive critical thinking.", "published": "2025-07-31 10:27:48", "link": "http://arxiv.org/abs/2507.23407v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Arabic Text Retrieval with Attentive Relevance Scoring", "abstract": "Arabic poses a particular challenge for natural language processing (NLP) and\ninformation retrieval (IR) due to its complex morphology, optional diacritics\nand the coexistence of Modern Standard Arabic (MSA) and various dialects.\nDespite the growing global significance of Arabic, it is still underrepresented\nin NLP research and benchmark resources. In this paper, we present an enhanced\nDense Passage Retrieval (DPR) framework developed specifically for Arabic. At\nthe core of our approach is a novel Attentive Relevance Scoring (ARS) that\nreplaces standard interaction mechanisms with an adaptive scoring function that\nmore effectively models the semantic relevance between questions and passages.\nOur method integrates pre-trained Arabic language models and architectural\nrefinements to improve retrieval performance and significantly increase ranking\naccuracy when answering Arabic questions. The code is made publicly available\nat \\href{https://github.com/Bekhouche/APR}{GitHub}.", "published": "2025-07-31 10:18:28", "link": "http://arxiv.org/abs/2507.23404v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization", "abstract": "The core challenge faced by multi-document summarization is the complexity of\nrelationships among documents and the presence of information redundancy. Graph\nclustering is an effective paradigm for addressing this issue, as it models the\ncomplex relationships among documents using graph structures and reduces\ninformation redundancy through clustering, achieving significant research\nprogress. However, existing methods often only consider single-relational\ngraphs and require a predefined number of clusters, which hinders their ability\nto fully represent rich relational information and adaptively partition\nsentence groups to reduce redundancy. To overcome these limitations, we propose\nMRGSEM-Sum, an unsupervised multi-document summarization framework based on\nmulti-relational graphs and structural entropy minimization. Specifically, we\nconstruct a multi-relational graph that integrates semantic and discourse\nrelations between sentences, comprehensively modeling the intricate and dynamic\nconnections among sentences across documents. We then apply a two-dimensional\nstructural entropy minimization algorithm for clustering, automatically\ndetermining the optimal number of clusters and effectively organizing sentences\ninto coherent groups. Finally, we introduce a position-aware compression\nmechanism to distill each cluster, generating concise and informative\nsummaries. Extensive experiments on four benchmark datasets (Multi-News,\nDUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently\noutperforms previous unsupervised methods and, in several cases, achieves\nperformance comparable to supervised models and large language models. Human\nevaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high\nconsistency and coverage, approaching human-level quality.", "published": "2025-07-31 10:14:03", "link": "http://arxiv.org/abs/2507.23400v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators", "abstract": "The rapid proliferation of Large Language Models presents both opportunities\nand challenges for the translation field. While commercial, cloud-based AI\nchatbots have garnered significant attention in translation studies, concerns\nregarding data privacy, security, and equitable access necessitate exploration\nof alternative deployment models. This paper investigates the feasibility and\nperformance of locally deployable, free language models as a viable alternative\nto proprietary, cloud-based AI solutions. This study evaluates three\nopen-source models installed on CPU-based platforms and compared against\ncommercially available online chat-bots. The evaluation focuses on functional\nperformance rather than a comparative analysis of human-machine translation\nquality, an area already subject to extensive research. The platforms assessed\nwere chosen for their accessibility and ease of use across various operating\nsystems. While local deployment introduces its own challenges, the benefits of\nenhanced data control, improved privacy, and reduced dependency on cloud\nservices are compelling. The findings of this study contribute to a growing\nbody of knowledge concerning the democratization of AI technology and inform\nfuture research and development efforts aimed at making LLMs more accessible\nand practical for a wider range of users, specifically focusing on the needs of\nindividual translators and small businesses.", "published": "2025-07-31 10:13:48", "link": "http://arxiv.org/abs/2507.23399v1", "categories": ["cs.CL", "cs.CY", "I.2.7; K.4.3"], "primary_category": "cs.CL"}
{"title": "Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models", "abstract": "Decoder-only large language models (LLMs) are increasingly used to build\nembedding models that effectively encode the semantic information of natural\nlanguage texts into dense vector representations for various embedding tasks.\nHowever, many existing methods primarily focus on removing the causal attention\nmask in LLMs to enable bidirectional attention, potentially undermining the\nmodel's ability to extract semantic information acquired during pretraining.\nAdditionally, leading unidirectional approaches often rely on extra input text\nto overcome the inherent limitations of causal attention, inevitably increasing\ncomputational costs. In this work, we propose Causal2Vec, a general-purpose\nembedding model tailored to enhance the performance of decoder-only LLMs\nwithout altering their original architectures or introducing significant\ncomputational overhead. Specifically, we first employ a lightweight BERT-style\nmodel to pre-encode the input text into a single Contextual token, which is\nthen prepended to the LLM's input sequence, allowing each token to capture\ncontextualized information even without attending to future tokens.\nFurthermore, to mitigate the recency bias introduced by last-token pooling and\nhelp LLMs better leverage the semantic information encoded in the Contextual\ntoken, we concatenate the last hidden states of Contextual and EOS tokens as\nthe final text embedding. In practice, Causal2Vec achieves state-of-the-art\nperformance on the Massive Text Embeddings Benchmark (MTEB) among models\ntrained solely on publicly available retrieval datasets, while reducing the\nrequired sequence length by up to 85% and inference time by up to 82% compared\nto best-performing methods.", "published": "2025-07-31 10:01:11", "link": "http://arxiv.org/abs/2507.23386v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models", "abstract": "Multimodal planning capabilities refer to the ability to predict, reason, and\ndesign steps for task execution with multimodal context, which is essential for\ncomplex reasoning and decision-making across multiple steps. However, current\nbenchmarks face two key challenges: (1) they cannot directly assess multimodal\nreal-world planning capabilities, and (2) they lack constraints or implicit\nconstraints across modalities. To address these issues, we introduce Multimodal\nPlanning with Complex Constraints (MPCC), the first benchmark to systematically\nevaluate MLLMs' ability to handle multimodal constraints in planning. To\naddress the first challenge, MPCC focuses on three real-world tasks: Flight\nPlanning, Calendar Planning, and Meeting Planning. To solve the second\nchallenge, we introduce complex constraints (e.g. budget, temporal, and\nspatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to\nseparate constraint complexity from search space expansion. Experiments on 13\nadvanced MLLMs reveal significant challenges: closed-source models achieve only\n21.3% feasible plans, while open-source models average below 11%. Additionally,\nwe observe that MLLMs are highly sensitive to constraint complexity and that\ntraditional multimodal prompting strategies fail in multi-constraint scenarios.\nOur work formalizes multimodal constraints in planning, provides a rigorous\nevaluation framework, and highlights the need for advancements in\nconstraint-aware reasoning for real-world MLLM applications.", "published": "2025-07-31 09:59:17", "link": "http://arxiv.org/abs/2507.23382v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "I.2.8; I.2.10"], "primary_category": "cs.CL"}
{"title": "Holistic Evaluations of Topic Models", "abstract": "Topic models are gaining increasing commercial and academic interest for\ntheir ability to summarize large volumes of unstructured text. As unsupervised\nmachine learning methods, they enable researchers to explore data and help\ngeneral users understand key themes in large text collections. However, they\nrisk becoming a 'black box', where users input data and accept the output as an\naccurate summary without scrutiny. This article evaluates topic models from a\ndatabase perspective, drawing insights from 1140 BERTopic model runs. The goal\nis to identify trade-offs in optimizing model parameters and to reflect on what\nthese findings mean for the interpretation and responsible use of topic models", "published": "2025-07-31 09:20:04", "link": "http://arxiv.org/abs/2507.23364v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Text-to-SQL Task-oriented Dialogue Ontology Construction", "abstract": "Large language models (LLMs) are widely used as general-purpose knowledge\nsources, but they rely on parametric knowledge, limiting explainability and\ntrustworthiness. In task-oriented dialogue (TOD) systems, this separation is\nexplicit, using an external database structured by an explicit ontology to\nensure explainability and controllability. However, building such ontologies\nrequires manual labels or supervised training. We introduce TeQoDO: a\nText-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM\nautonomously builds a TOD ontology from scratch without supervision using its\ninherent SQL programming capabilities combined with dialogue theory provided in\nthe prompt. We show that TeQoDO outperforms transfer learning approaches, and\nits constructed ontology is competitive on a downstream dialogue state tracking\ntask. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also\nscales to allow construction of much larger ontologies, which we investigate on\na Wikipedia and ArXiv dataset. We view this as a step towards broader\napplication of ontologies to increase LLM explainability.", "published": "2025-07-31 09:08:59", "link": "http://arxiv.org/abs/2507.23358v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "cs.CL"}
{"title": "DSBC : Data Science task Benchmarking with Context engineering", "abstract": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.", "published": "2025-07-31 08:32:37", "link": "http://arxiv.org/abs/2507.23336v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content", "abstract": "Proprietary Large Language Models (LLMs) have shown tendencies toward\npoliteness, formality, and implicit content moderation. While previous research\nhas primarily focused on explicitly training models to moderate and detoxify\nsensitive content, there has been limited exploration of whether LLMs\nimplicitly sanitize language without explicit instructions. This study\nempirically analyzes the implicit moderation behavior of GPT-4o-mini when\nparaphrasing sensitive content and evaluates the extent of sensitivity shifts.\nOur experiments indicate that GPT-4o-mini systematically moderates content\ntoward less sensitive classes, with substantial reductions in derogatory and\ntaboo language. Also, we evaluate the zero-shot capabilities of LLMs in\nclassifying sentence sensitivity, comparing their performances against\ntraditional methods.", "published": "2025-07-31 08:02:04", "link": "http://arxiv.org/abs/2507.23319v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unveiling Super Experts in Mixture-of-Experts Large Language Models", "abstract": "Sparsely activated Mixture-of-Experts (MoE) models have shown promise in\nenhancing the learning capacity of large language models (LLMs). Leveraging the\nintrinsic importance differences among experts, recent research has explored\nexpert-level compression techniques to improve the efficiency of MoE LLMs.\nHowever, existing approaches often rely on empirical criteria to identify\ncritical experts, lacking a deeper exploration and understanding of the\nheterogeneous importance of experts. In this study, we present the first\ndiscovery and investigation of a distinct subset of experts that play a crucial\nrole in the underlying mechanisms during the model's forward inference. These\nexperts are prevalent in open-source MoE LLMs, and despite their limited\nnumber, pruning them leads to a significant decline in model performance (e.g.,\npruning three causes Qwen3-30B-A3B to produce repetitive and uninformative\noutputs). We refer to these experts as Super Experts (SEs). Our comprehensive\nanalysis provides progressively deeper insights into SEs. (i) SEs are\ncharacterized by rare but extreme activation outliers in the output of the\ndown_proj, which give rise to massive activations in the hidden states between\ndecoder layers. Moreover, the distribution of SEs remains model-specific and is\nunaffected by post-training processes. (ii) By pruning SEs, we assess their\nsignificance across a variety of tasks, revealing their considerable impact on\nthe model's overall performance, particularly in mathematical reasoning. (iii)\nWe further enhance our understanding of the influence of SEs compression. Our\nfindings confirm that MoE LLMs rely on SEs to induce attention sinks, which are\ncrucial for the distribution of attention scores but are significantly\ndisrupted by SE pruning. The code is available at\nhttps://github.com/ZunhaiSu/Super-Experts-Profilling.", "published": "2025-07-31 06:35:33", "link": "http://arxiv.org/abs/2507.23279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication", "abstract": "There has been an increase in recent advancements in the explainability and\ndevelopment of personalized chatbots for mental health. However, the reasoning\naspects for explainability and dialogue discourse have not been explored\npreviously for mental health. Hence, we are investigating the pragmatic\nreasoning capability of large language models (LLMs) in this domain. We\nintroduce P-ReMe dataset, and propose a modified definition for the pragmatic\nphenomena of implicature (implied meaning) and presupposition (implicit\nassumption) in mental health. Following the definition, we formulate two tasks\nin implicature and one task in presupposition. To benchmark the dataset and the\npresented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and\nQwen. The results of the experiments suggest that Mistral and Qwen show\nsubstantial reasoning capabilities in the domain. In addition, we also propose\nStiPRompts to study the stigma around mental health with the state-of-the-art\nLLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings\nshow that Claude-3.5-haiku deals with the stigma more responsibly compared to\nthe other two LLMs.", "published": "2025-07-31 05:10:38", "link": "http://arxiv.org/abs/2507.23247v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples", "abstract": "Large Language Models exhibit powerful few-shot in-context learning (ICL)\ncapabilities, but the performance is highly sensitive to provided examples.\n  Recent research has focused on retrieving corresponding examples for each\ninput query, not only enhancing the efficiency and scalability of the learning\nprocess but also mitigating inherent biases in manual example selection.\n  However, these studies have primarily emphasized leveraging Positive samples\nwhile overlooking the additional information within Negative samples for\ncontextual learning.\n  We propose a novel method that utilizes Negative samples to better select\nPositive sample examples, thereby enhancing the performance of few-shot ICL.\nInitially, we construct Positive and Negative sample corpora based on\nZero-Shot-Cot. Then, during inference, we employ a semantic similarity-based\napproach to select the most similar examples from both the Positive and\nNegative corpora for a given query. Subsequently, we further retrieve Positive\nexamples from the Positive sample corpus based on semantic similarity to the\nNegative examples, then concatenating them with the previously selected\nPositive examples to serve as ICL demonstrations. Experimental results\ndemonstrate that our approach surpasses methods solely relying on the most\nsimilar positive examples for context, validating that the additional\ninformation in negative samples aids in enhancing ICL performance through\nimproved Positive sample selection.", "published": "2025-07-31 03:06:27", "link": "http://arxiv.org/abs/2507.23211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding", "abstract": "With the development of multimodal reasoning models, Computer Use Agents\n(CUAs), akin to Jarvis from \\textit{\"Iron Man\"}, are becoming a reality. GUI\ngrounding is a core component for CUAs to execute actual actions, similar to\nmechanical control in robotics, and it directly leads to the success or failure\nof the system. It determines actions such as clicking and typing, as well as\nrelated parameters like the coordinates for clicks. Current end-to-end\ngrounding models still achieve less than 65\\% accuracy on challenging\nbenchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from\nbeing ready for deployment. % , as a single misclick can result in unacceptable\nconsequences. In this work, we conduct an empirical study on the training of\ngrounding models, examining details from data collection to model training.\nUltimately, we developed the \\textbf{Phi-Ground} model family, which achieves\nstate-of-the-art performance across all five grounding benchmarks for models\nunder $10B$ parameters in agent settings. In the end-to-end model setting, our\nmodel still achieves SOTA results with scores of \\textit{\\textbf{43.2}} on\nScreenSpot-pro and \\textit{\\textbf{27.2}} on UI-Vision. We believe that the\nvarious details discussed in this paper, along with our successes and failures,\nnot only clarify the construction of grounding models but also benefit other\nperception tasks. Project homepage:\n\\href{https://zhangmiaosen2000.github.io/Phi-Ground/}{https://zhangmiaosen2000.github.io/Phi-Ground/}", "published": "2025-07-31 17:59:09", "link": "http://arxiv.org/abs/2507.23779v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Distributed AI Agents for Cognitive Underwater Robot Autonomy", "abstract": "Achieving robust cognitive autonomy in robots navigating complex,\nunpredictable environments remains a fundamental challenge in robotics. This\npaper presents Underwater Robot Self-Organizing Autonomy (UROSA), a\ngroundbreaking architecture leveraging distributed Large Language Model AI\nagents integrated within the Robot Operating System 2 (ROS 2) framework to\nenable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA\ndecentralises cognition into specialised AI agents responsible for multimodal\nperception, adaptive reasoning, dynamic mission planning, and real-time\ndecision-making. Central innovations include flexible agents dynamically\nadapting their roles, retrieval-augmented generation utilising vector databases\nfor efficient knowledge management, reinforcement learning-driven behavioural\noptimisation, and autonomous on-the-fly ROS 2 node generation for runtime\nfunctional extensibility. Extensive empirical validation demonstrates UROSA's\npromising adaptability and reliability through realistic underwater missions in\nsimulation and real-world deployments, showing significant advantages over\ntraditional rule-based architectures in handling unforeseen scenarios,\nenvironmental uncertainties, and novel mission objectives. This work not only\nadvances underwater autonomy but also establishes a scalable, safe, and\nversatile cognitive robotics framework capable of generalising to a diverse\narray of real-world applications.", "published": "2025-07-31 17:18:55", "link": "http://arxiv.org/abs/2507.23735v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Enhanced Velocity Field Modeling for Gaussian Video Reconstruction", "abstract": "High-fidelity 3D video reconstruction is essential for enabling real-time\nrendering of dynamic scenes with realistic motion in virtual and augmented\nreality (VR/AR). The deformation field paradigm of 3D Gaussian splatting has\nachieved near-photorealistic results in video reconstruction due to the great\nrepresentation capability of deep deformation networks. However, in videos with\ncomplex motion and significant scale variations, deformation networks often\noverfit to irregular Gaussian trajectories, leading to suboptimal visual\nquality. Moreover, the gradient-based densification strategy designed for\nstatic scene reconstruction proves inadequate to address the absence of dynamic\ncontent. In light of these challenges, we propose a flow-empowered velocity\nfield modeling scheme tailored for Gaussian video reconstruction, dubbed\nFlowGaussian-VR. It consists of two core components: a velocity field rendering\n(VFR) pipeline which enables optical flow-based optimization, and a\nflow-assisted adaptive densification (FAD) strategy that adjusts the number and\nsize of Gaussians in dynamic regions. We validate our model's effectiveness on\nmulti-view dynamic reconstruction and novel view synthesis with multiple\nreal-world datasets containing challenging motion scenarios, demonstrating not\nonly notable visual improvements (over 2.5 dB gain in PSNR) and less blurry\nartifacts in dynamic textures, but also regularized and trackable per-Gaussian\ntrajectories.", "published": "2025-07-31 16:26:22", "link": "http://arxiv.org/abs/2507.23704v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents", "abstract": "While Reinforcement Learning (RL) has achieved remarkable success in language\nmodeling, its triumph hasn't yet fully translated to visuomotor agents. A\nprimary challenge in RL models is their tendency to overfit specific tasks or\nenvironments, thereby hindering the acquisition of generalizable behaviors\nacross diverse settings. This paper provides a preliminary answer to this\nchallenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can\nachieve zero-shot generalization to unseen worlds. Specifically, we explore\nRL's potential to enhance generalizable spatial reasoning and interaction\ncapabilities in 3D worlds. To address challenges in multi-task RL\nrepresentation, we analyze and establish cross-view goal specification as a\nunified multi-task goal space for visuomotor policies. Furthermore, to overcome\nthe significant bottleneck of manual task design, we propose automated task\nsynthesis within the highly customizable Minecraft environment for large-scale\nmulti-task RL training, and we construct an efficient distributed RL framework\nto support this. Experimental results show RL significantly boosts interaction\nsuccess rates by $4\\times$ and enables zero-shot generalization of spatial\nreasoning across diverse environments, including real-world settings. Our\nfindings underscore the immense potential of RL training in 3D simulated\nenvironments, especially those amenable to large-scale task generation, for\nsignificantly advancing visuomotor agents' spatial reasoning.", "published": "2025-07-31 16:20:02", "link": "http://arxiv.org/abs/2507.23698v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A survey of multi-agent geosimulation methodologies: from ABM to LLM", "abstract": "We provide a comprehensive examination of agent-based approaches that codify\nthe principles and linkages underlying multi-agent systems, simulations, and\ninformation systems. Based on two decades of study, this paper confirms a\nframework intended as a formal specification for geosimulation platforms. Our\nfindings show that large language models (LLMs) can be effectively incorporated\nas agent components if they follow a structured architecture specific to\nfundamental agent activities such as perception, memory, planning, and action.\nThis integration is precisely consistent with the architecture that we\nformalize, providing a solid platform for next-generation geosimulation\nsystems.", "published": "2025-07-31 16:12:22", "link": "http://arxiv.org/abs/2507.23694v1", "categories": ["cs.MA", "cs.AI", "68T42", "I.2.11"], "primary_category": "cs.MA"}
{"title": "Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database", "abstract": "Artificial Intelligence (AI) systems are transforming critical sectors such\nas healthcare, finance, and transportation, enhancing operational efficiency\nand decision-making processes. However, their deployment in high-stakes domains\nhas exposed vulnerabilities that can result in significant societal harm. To\nsystematically study and mitigate these risk, initiatives like the AI Incident\nDatabase (AIID) have emerged, cataloging over 3,000 real-world AI failure\nreports. Currently, associating a new report with the appropriate AI Incident\nrelies on manual expert intervention, limiting scalability and delaying the\nidentification of emerging failure patterns.\n  To address this limitation, we propose a retrieval-based framework that\nautomates the association of new reports with existing AI Incidents through\nsemantic similarity modeling. We formalize the task as a ranking problem, where\neach report-comprising a title and a full textual description-is compared to\npreviously documented AI Incidents based on embedding cosine similarity.\nBenchmarking traditional lexical methods, cross-encoder architectures, and\ntransformer-based sentence embedding models, we find that the latter\nconsistently achieve superior performance. Our analysis further shows that\ncombining titles and descriptions yields substantial improvements in ranking\naccuracy compared to using titles alone. Moreover, retrieval performance\nremains stable across variations in description length, highlighting the\nrobustness of the framework. Finally, we find that retrieval performance\nconsistently improves as the training set expands. Our approach provides a\nscalable and efficient solution for supporting the maintenance of the AIID.", "published": "2025-07-31 15:48:12", "link": "http://arxiv.org/abs/2507.23669v1", "categories": ["cs.CY", "cs.AI", "cs.IR"], "primary_category": "cs.CY"}
{"title": "Personalized Education with Ranking Alignment Recommendation", "abstract": "Personalized question recommendation aims to guide individual students\nthrough questions to enhance their mastery of learning targets. Most previous\nmethods model this task as a Markov Decision Process and use reinforcement\nlearning to solve, but they struggle with efficient exploration, failing to\nidentify the best questions for each student during training. To address this,\nwe propose Ranking Alignment Recommendation (RAR), which incorporates\ncollaborative ideas into the exploration mechanism, enabling more efficient\nexploration within limited training episodes. Experiments show that RAR\neffectively improves recommendation performance, and our framework can be\napplied to any RL-based question recommender. Our code is available in\nhttps://github.com/wuming29/RAR.git.", "published": "2025-07-31 15:43:51", "link": "http://arxiv.org/abs/2507.23664v1", "categories": ["cs.AI", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation", "abstract": "Few-shot classification and segmentation (FS-CS) focuses on jointly\nperforming multi-label classification and multi-class segmentation using few\nannotated examples. Although the current state of the art (SOTA) achieves high\naccuracy in both tasks, it struggles with small objects. To overcome this, we\npropose the Efficient Masked Attention Transformer (EMAT), which improves\nclassification and segmentation accuracy, especially for small objects. EMAT\nintroduces three modifications: a novel memory-efficient masked attention\nmechanism, a learnable downscaling strategy, and parameter-efficiency\nenhancements. EMAT outperforms all FS-CS methods on the PASCAL-5$^i$ and\nCOCO-20$^i$ datasets, using at least four times fewer trainable parameters.\nMoreover, as the current FS-CS evaluation setting discards available\nannotations, despite their costly collection, we introduce two novel evaluation\nsettings that consider these annotations to better reflect practical scenarios.", "published": "2025-07-31 15:19:55", "link": "http://arxiv.org/abs/2507.23642v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying", "abstract": "Agent-assisted memory recall is one critical research problem in the field of\nhuman-computer interaction. In conventional methods, the agent can retrieve\ninformation from its equipped memory module to help the person recall\nincomplete or vague memories. The limited size of memory module hinders the\nacquisition of complete memories and impacts the memory recall performance in\npractice. Memory theories suggest that the person's relevant memory can be\nproactively activated through some effective cues. Inspired by this, we propose\na novel strategy-guided agent-assisted memory recall method, allowing the agent\nto transform an original query into a cue-rich one via the judiciously designed\nstrategy to help the person recall memories. To this end, there are two key\nchallenges. (1) How to choose the appropriate recall strategy for diverse\nforgetting scenarios with distinct memory-recall characteristics? (2) How to\nobtain the high-quality responses leveraging recall strategies, given only\nabstract and sparsely annotated strategy patterns? To address the challenges,\nwe propose a Recall Router framework. Specifically, we design a 5W Recall Map\nto classify memory queries into five typical scenarios and define fifteen\nrecall strategy patterns across the corresponding scenarios. We then propose a\nhierarchical recall tree combined with the Monte Carlo Tree Search algorithm to\noptimize the selection of strategy and the generation of strategy responses. We\nconstruct an instruction tuning dataset and fine-tune multiple open-source\nlarge language models (LLMs) to develop MemoCue, an agent that excels in\nproviding memory-inspired responses. Experiments on three representative\ndatasets show that MemoCue surpasses LLM-based methods by 17.74% in recall\ninspiration. Further human evaluation highlights its advantages in\nmemory-recall applications.", "published": "2025-07-31 15:11:38", "link": "http://arxiv.org/abs/2507.23633v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora", "abstract": "Infostealers exfiltrate credentials, session cookies, and sensitive data from\ninfected systems. With over 29 million stealer logs reported in 2024, manual\nanalysis and mitigation at scale are virtually unfeasible/unpractical. While\nmost research focuses on proactive malware detection, a significant gap remains\nin leveraging reactive analysis of stealer logs and their associated artifacts.\nSpecifically, infection artifacts such as screenshots, image captured at the\npoint of compromise, are largely overlooked by the current literature. This\npaper introduces a novel approach leveraging Large Language Models (LLMs), more\nspecifically gpt-4o-mini, to analyze infection screenshots to extract potential\nIndicators of Compromise (IoCs), map infection vectors, and track campaigns.\nFocusing on the Aurora infostealer, we demonstrate how LLMs can process\nscreenshots to identify infection vectors, such as malicious URLs, installer\nfiles, and exploited software themes. Our method extracted 337 actionable URLs\nand 246 relevant files from 1000 screenshots, revealing key malware\ndistribution methods and social engineering tactics. By correlating extracted\nfilenames, URLs, and infection themes, we identified three distinct malware\ncampaigns, demonstrating the potential of LLM-driven analysis for uncovering\ninfection workflows and enhancing threat intelligence. By shifting malware\nanalysis from traditional log-based detection methods to a reactive,\nartifact-driven approach that leverages infection screenshots, this research\npresents a scalable method for identifying infection vectors and enabling early\nintervention.", "published": "2025-07-31 14:49:03", "link": "http://arxiv.org/abs/2507.23611v1", "categories": ["cs.CR", "cs.AI", "cs.CV"], "primary_category": "cs.CR"}
{"title": "Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study", "abstract": "Recent advancements in Large Language Models have sparked interest in their\npotential for robotic task planning. While these models demonstrate strong\ngenerative capabilities, their effectiveness in producing structured and\nexecutable plans remains uncertain. This paper presents a systematic evaluation\nof a broad spectrum of current state of the art language models, each directly\nprompted using Planning Domain Definition Language domain and problem files,\nand compares their planning performance with the Fast Downward planner across a\nvariety of benchmarks. In addition to measuring success rates, we assess how\nfaithfully the generated plans translate into sequences of actions that can\nactually be executed, identifying both strengths and limitations of using these\nmodels in this setting. Our findings show that while the models perform well on\nsimpler planning tasks, they continue to struggle with more complex scenarios\nthat require precise resource management, consistent state tracking, and strict\nconstraint compliance. These results underscore fundamental challenges in\napplying language models to robotic planning in real world environments. By\noutlining the gaps that emerge during execution, we aim to guide future\nresearch toward combined approaches that integrate language models with\nclassical planners in order to enhance the reliability and scalability of\nplanning in autonomous robotics.", "published": "2025-07-31 14:25:54", "link": "http://arxiv.org/abs/2507.23589v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "abstract": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation.", "published": "2025-07-31 13:53:25", "link": "http://arxiv.org/abs/2507.23565v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "abstract": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents.", "published": "2025-07-31 13:42:14", "link": "http://arxiv.org/abs/2507.23554v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ART: Adaptive Relation Tuning for Generalized Relation Prediction", "abstract": "Visual relation detection (VRD) is the task of identifying the relationships\nbetween objects in a scene. VRD models trained solely on relation detection\ndata struggle to generalize beyond the relations on which they are trained.\nWhile prompt tuning has been used to adapt vision-language models (VLMs) for\nVRD, it uses handcrafted prompts and struggles with novel or complex relations.\nWe argue that instruction tuning offers a more effective solution by\nfine-tuning VLMs on diverse instructional data. We thus introduce ART, an\nAdaptive Relation Tuning framework that adapts VLMs for VRD through instruction\ntuning and strategic instance selection. By converting VRD datasets into an\ninstruction tuning format and employing an adaptive sampling algorithm, ART\ndirects the VLM to focus on informative relations while maintaining\ngeneralizability. Specifically, we focus on the relation classification, where\nsubject-object boxes are given and the model predicts the predicate between\nthem. We tune on a held-in set and evaluate across multiple held-out datasets\nof varying complexity. Our approach strongly improves over its baselines and\ncan infer unseen relation concepts, a capability absent in mainstream VRD\nmethods. We demonstrate ART's practical value by using the predicted relations\nfor segmenting complex scenes.", "published": "2025-07-31 13:34:06", "link": "http://arxiv.org/abs/2507.23543v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving", "abstract": "Autonomous driving systems face significant challenges in achieving\nhuman-like adaptability, robustness, and interpretability in complex,\nopen-world environments. These challenges stem from fragmented architectures,\nlimited generalization to novel scenarios, and insufficient semantic extraction\nfrom perception. To address these limitations, we propose a unified\nPerception-Language-Action (PLA) framework that integrates multi-sensor fusion\n(cameras, LiDAR, radar) with a large language model (LLM)-augmented\nVision-Language-Action (VLA) architecture, specifically a GPT-4.1-powered\nreasoning core. This framework unifies low-level sensory processing with\nhigh-level contextual reasoning, tightly coupling perception with natural\nlanguage-based semantic understanding and decision-making to enable\ncontext-aware, explainable, and safety-bounded autonomous driving. Evaluations\non an urban intersection scenario with a construction zone demonstrate superior\nperformance in trajectory tracking, speed prediction, and adaptive planning.\nThe results highlight the potential of language-augmented cognitive frameworks\nfor advancing the safety, interpretability, and scalability of autonomous\ndriving systems.", "published": "2025-07-31 13:30:47", "link": "http://arxiv.org/abs/2507.23540v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "I Am Big, You Are Little; I Am Right, You Are Wrong", "abstract": "Machine learning for image classification is an active and rapidly developing\nfield. With the proliferation of classifiers of different sizes and different\narchitectures, the problem of choosing the right model becomes more and more\nimportant.\n  While we can assess a model's classification accuracy statistically, our\nunderstanding of the way these models work is unfortunately limited. In order\nto gain insight into the decision-making process of different vision models, we\npropose using minimal sufficient pixels sets to gauge a model's\n`concentration': the pixels that capture the essence of an image through the\nlens of the model. By comparing position, overlap, and size of sets of pixels,\nwe identify that different architectures have statistically different\nconcentration, in both size and position. In particular, ConvNext and EVA\nmodels differ markedly from the others. We also identify that images which are\nmisclassified are associated with larger pixels sets than correct\nclassifications.", "published": "2025-07-31 12:45:09", "link": "http://arxiv.org/abs/2507.23509v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "abstract": "Existing algorithms for explaining the outputs of image classifiers are based\non a variety of approaches and produce explanations that lack formal rigor. On\nthe other hand, logic-based explanations are formally and rigorously defined\nbut their computability relies on strict assumptions about the model that do\nnot hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being\nformally and rigorously defined, enjoy the same formal properties as\nlogic-based ones, while still lending themselves to black-box algorithms and\nbeing a natural fit for image classifiers. We prove formal properties of causal\nexplanations and introduce contrastive causal explanations for image\nclassifiers. Moreover, we augment the definition of explanation with confidence\nawareness and introduce complete causal explanations: explanations that are\nclassified with exactly the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that\ndifferent models have different patterns of sufficiency, contrastiveness, and\ncompleteness. Our algorithms are efficiently computable, taking on average 6s\nper image on a ResNet50 model to compute all types of explanations, and are\ntotally black-box, needing no knowledge of the model, no access to model\ninternals, no access to gradient, nor requiring any properties, such as\nmonotonicity, of the model.", "published": "2025-07-31 12:33:00", "link": "http://arxiv.org/abs/2507.23497v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Digital literacy interventions can boost humans in discerning deepfakes", "abstract": "Deepfakes, i.e., images generated by artificial intelligence (AI), can erode\ntrust in institutions and compromise election outcomes, as people often\nstruggle to discern real images from deepfakes. Improving digital literacy can\nhelp address these challenges, yet scalable and effective approaches remain\nlargely unexplored. Here, we compare the efficacy of five digital literacy\ninterventions to boost people's ability to discern deepfakes: (1) textual\nguidance on common indicators of deepfakes; (2) visual demonstrations of these\nindicators; (3) a gamified exercise for identifying deepfakes; (4) implicit\nlearning through repeated exposure and feedback; and (5) explanations of how\ndeepfakes are generated with the help of AI. We conducted an experiment with\nN=1,200 participants from the United States to test the immediate and long-term\neffectiveness of our interventions. Our results show that our interventions can\nboost deepfake discernment by up to 13 percentage points while maintaining\ntrust in real images. Altogether, our approach is scalable, suitable for\ndiverse populations, and highly effective for boosting deepfake detection while\nmaintaining trust in truthful information.", "published": "2025-07-31 12:23:45", "link": "http://arxiv.org/abs/2507.23492v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery", "abstract": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains.", "published": "2025-07-31 12:10:27", "link": "http://arxiv.org/abs/2507.23488v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Automated Feedback on Student-Generated UML and ER Diagrams Using Large Language Models", "abstract": "UML and ER diagrams are foundational in computer science education but come\nwith challenges for learners due to the need for abstract thinking, contextual\nunderstanding, and mastery of both syntax and semantics. These complexities are\ndifficult to address through traditional teaching methods, which often struggle\nto provide scalable, personalized feedback, especially in large classes. We\nintroduce DUET (Diagrammatic UML & ER Tutor), a prototype of an LLM-based tool,\nwhich converts a reference diagram and a student-submitted diagram into a\ntextual representation and provides structured feedback based on the\ndifferences. It uses a multi-stage LLM pipeline to compare diagrams and\ngenerate reflective feedback. Furthermore, the tool enables analytical insights\nfor educators, aiming to foster self-directed learning and inform instructional\nstrategies. We evaluated DUET through semi-structured interviews with six\nparticipants, including two educators and four teaching assistants. They\nidentified strengths such as accessibility, scalability, and learning support\nalongside limitations, including reliability and potential misuse. Participants\nalso suggested potential improvements, such as bulk upload functionality and\ninteractive clarification features. DUET presents a promising direction for\nintegrating LLMs into modeling education and offers a foundation for future\nclassroom integration and empirical evaluation.", "published": "2025-07-31 11:49:01", "link": "http://arxiv.org/abs/2507.23470v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection", "abstract": "The Federated Learning (FL) approach enables effective learning across\ndistributed systems, while preserving user data privacy. To date, research has\nprimarily focused on addressing statistical heterogeneity and communication\nefficiency, through which FL has achieved success in classification tasks.\nHowever, its application to non-classification tasks, such as human pose\nestimation, remains underexplored. This paper identifies and investigates a\ncritical issue termed ``resolution-drift,'' where performance degrades\nsignificantly due to resolution variability across clients. Unlike class-level\nheterogeneity, resolution drift highlights the importance of resolution as\nanother axis of not independent or identically distributed (non-IID) data. To\naddress this issue, we present resolution-adaptive federated learning (RAF), a\nmethod that leverages heatmap-based knowledge distillation. Through\nmulti-resolution knowledge distillation between higher-resolution outputs\n(teachers) and lower-resolution outputs (students), our approach enhances\nresolution robustness without overfitting. Extensive experiments and\ntheoretical analysis demonstrate that RAF not only effectively mitigates\nresolution drift and achieves significant performance improvements, but also\ncan be integrated seamlessly into existing FL frameworks. Furthermore, although\nthis paper focuses on human pose estimation, our t-SNE analysis reveals\ndistinct characteristics between classification and high-resolution\nrepresentation tasks, supporting the generalizability of RAF to other tasks\nthat rely on preserving spatial detail.", "published": "2025-07-31 11:38:20", "link": "http://arxiv.org/abs/2507.23461v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "KLAN: Kuaishou Landing-page Adaptive Navigator", "abstract": "Modern online platforms configure multiple pages to accommodate diverse user\nneeds. This multi-page architecture inherently establishes a two-stage\ninteraction paradigm between the user and the platform: (1) Stage I: page\nnavigation, navigating users to a specific page and (2) Stage II: in-page\ninteraction, where users engage with customized content within the specific\npage. While the majority of research has been focusing on the sequential\nrecommendation task that improves users' feedback in Stage II, there has been\nlittle investigation on how to achieve better page navigation in Stage I. To\nfill this gap, we formally define the task of Personalized Landing Page\nModeling (PLPM) into the field of recommender systems: Given a user upon app\nentry, the goal of PLPM is to proactively select the most suitable landing page\nfrom a set of candidates (e.g., functional tabs, content channels, or\naggregation pages) to optimize the short-term PDR metric and the long-term user\nengagement and satisfaction metrics, while adhering to industrial constraints.\nAdditionally, we propose KLAN (Kuaishou Landing-page Adaptive Navigator), a\nhierarchical solution framework designed to provide personalized landing pages\nunder the formulation of PLPM. KLAN comprises three key components: (1)\nKLAN-ISP captures inter-day static page preference; (2) KLAN-IIT captures\nintra-day dynamic interest transitions and (3) KLAN-AM adaptively integrates\nboth components for optimal navigation decisions. Extensive online experiments\nconducted on the Kuaishou platform demonstrate the effectiveness of KLAN,\nobtaining +0.205% and +0.192% improvements on in Daily Active Users (DAU) and\nuser Lifetime (LT). Our KLAN is ultimately deployed on the online platform at\nfull traffic, serving hundreds of millions of users. To promote further\nresearch in this important area, we will release our dataset and code upon\npaper acceptance.", "published": "2025-07-31 11:37:11", "link": "http://arxiv.org/abs/2507.23459v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation", "abstract": "Large language models (LLMs) with instruction following capabilities have\ndemonstrated impressive problem-solving abilities. While synthesizing\ninstructional data from unsupervised text has become a common approach for\ntraining such models, conventional methods rely heavily on human effort for\ndata annotation. Although existing automated synthesis paradigms have\nalleviated this constraint, they still exhibit significant limitations in\nensuring adequate diversity and difficulty of synthesized instructions. To\naddress these challenges, we propose Self-Foveate, an innovative LLM-driven\nmethod for instruction synthesis. This approach introduces a\n\"Micro-Scatter-Macro\" multi-level foveation methodology that effectively guides\nthe LLM to deeply excavate fine-grained information embedded in unsupervised\ntext, thereby enhancing both the diversity and difficulty of synthesized\ninstructions. Comprehensive experiments across multiple unsupervised corpora\nand diverse model architectures validate the effectiveness and superiority of\nour proposed method. We publicly release our data and codes:\nhttps://github.com/Mubuky/Self-Foveate", "published": "2025-07-31 11:18:42", "link": "http://arxiv.org/abs/2507.23440v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Chatting with your ERP: A Recipe", "abstract": "This paper presents the design, implementation, and evaluation behind a Large\nLanguage Model (LLM) agent that chats with an industrial production-grade ERP\nsystem. The agent is capable of interpreting natural language queries and\ntranslating them into executable SQL statements, leveraging open-weight LLMs. A\nnovel dual-agent architecture combining reasoning and critique stages was\nproposed to improve query generation reliability.", "published": "2025-07-31 11:09:50", "link": "http://arxiv.org/abs/2507.23429v1", "categories": ["cs.AI", "cs.DB", "cs.ET", "cs.HC", "cs.MA", "68T50, 68P20", "I.2.7; H.2.5; H.2.8; H.5.m"], "primary_category": "cs.AI"}
{"title": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform", "abstract": "Large language models (LLMs) have significantly reshaped different walks of\nbusiness. To meet the increasing demands for individualized railway service, we\ndevelop LLM4Rail - a novel LLM-augmented railway service consulting platform.\nEmpowered by LLM, LLM4Rail can provide custom modules for ticketing, railway\nfood & drink recommendations, weather information, and chitchat. In LLM4Rail,\nwe propose the iterative \"Question-Thought-Action-Observation (QTAO)\" prompting\nframework. It meticulously integrates verbal reasoning with task-oriented\nactions, that is, reasoning to guide action selection, to effectively retrieve\nexternal observations relevant to railway operation and service to generate\naccurate responses. To provide personalized onboard dining services, we first\nconstruct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible\ntakeout dataset tailored for railway services. CRFD-25 covers a wide range of\nsignature dishes categorized by cities, cuisines, age groups, and spiciness\nlevels. We further introduce an LLM-based zero-shot conversational recommender\nfor railway catering. To address the unconstrained nature of open\nrecommendations, the feature similarity-based post-processing step is\nintroduced to ensure all the recommended items are aligned with CRFD-25\ndataset.", "published": "2025-07-31 09:45:55", "link": "http://arxiv.org/abs/2507.23377v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling", "abstract": "Software issue resolution is a critical challenge in software engineering and\nhas garnered increasing attention in recent years. With the rapid advancement\nof large language models (LLMs), substantial progress has been made in\naddressing real-world software engineering tasks. Recent studies have\nintroduced ensemble reasoning techniques to enhance the performance of\nLLM-based issue resolution. However, existing prompting-based methods still\nface limitations in effectively exploring large ensemble spaces and lack the\ncapacity for repository-level understanding, both of which constrain their\noverall effectiveness. In this paper, we propose Trae Agent, the first\nagent-based ensemble reasoning approach for repository-level issue resolution.\nTrae Agent formulates our goal as an optimal solution search problem and\naddresses two key challenges, i.e., large ensemble spaces and repository-level\nunderstanding, through modular agents for generation, pruning, and selection.\nWe conduct extensive experiments using three leading LLMs on the widely-adopted\nSWE-bench benchmark, comparing Trae Agent against four state-of-the-art\nensemble reasoning techniques. Experimental results demonstrate that Trae Agent\nconsistently achieves superior performance, with an average improvement of\n10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first\nplace on the SWE-bench Verified leaderboard, with a notable Pass@1 score of\n75.20%. We are pleased to release Trae Agent as an open-source project to\nsupport the research community, with all resources available at\nhttps://github.com/bytedance/trae-agent.", "published": "2025-07-31 09:37:22", "link": "http://arxiv.org/abs/2507.23370v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "\"I made this (sort of)\": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation", "abstract": "I reflect on my experience creating two music albums centered on\nstate-of-the-art prompt-based AI music generation platforms. The first album\nexplicitly poses the question: What happens when I collide my junk mail with\nthese platforms? The second album is a direct response to the first, and toys\nwith the inability of state-of-the-art prompt-based AI music generation\nplatforms to generate music that is not ``practiced'', ``polished'', and\n``produced''. I seed a large language model (LLM) with information about these\nalbums and have it interview me, which results in the exploration of several\ndeeper questions: To what extent am I the author? Where am I in the resulting\nmusic? How is my musical identity changing as I am faced with machines that are\nin some ways far more talented than I? What new musical spaces does my work\nopen, for me or anyone/thing else? I conclude by reflecting on my reflections,\nas well as LLM-mediated self-reflection as method.", "published": "2025-07-31 09:25:55", "link": "http://arxiv.org/abs/2507.23365v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2; J.5"], "primary_category": "cs.SD"}
{"title": "Quality Evaluation of COBOL to Java Code Transformation", "abstract": "We present an automated evaluation system for assessing COBOL-to-Java code\ntranslation within IBM's watsonx Code Assistant for Z (WCA4Z). The system\naddresses key challenges in evaluating LLM-based translators, including model\nopacity and the complexity of translation quality assessment. Our approach\ncombines analytic checkers with LLM-as-a-judge (LaaJ) techniques to deliver\nscalable, multi-faceted evaluations. The system supports continuous integration\nworkflows, enables large-scale benchmarking, and reduces reliance on manual\nreview. We describe the system architecture, evaluation strategies, and\nreporting mechanisms that provide actionable insights for developers and\nproject managers, facilitating the evolution of high-quality, modernized\ncodebases.", "published": "2025-07-31 09:06:20", "link": "http://arxiv.org/abs/2507.23356v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications", "abstract": "There is a growing demand for autonomous mobile robots capable of navigating\nunstructured agricultural environments. Tasks such as weed control in meadows\nrequire efficient path planning through an unordered set of coordinates while\nminimizing travel distance and adhering to curvature constraints to prevent\nsoil damage and protect vegetation. This paper presents an integrated\nnavigation framework combining a global path planner based on the Dubins\nTraveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control\n(NMPC) strategy for local path planning and control. The DTSP generates a\nminimum-length, curvature-constrained path that efficiently visits all targets,\nwhile the NMPC leverages this path to compute control signals to accurately\nreach each waypoint. The system's performance was validated through comparative\nsimulation analysis on real-world field datasets, demonstrating that the\ncoupled DTSP-based planner produced smoother and shorter paths, with a\nreduction of about 16% in the provided scenario, compared to decoupled methods.\nBased thereon, the NMPC controller effectively steered the robot to the desired\nwaypoints, while locally optimizing the trajectory and ensuring adherence to\nconstraints. These findings demonstrate the potential of the proposed framework\nfor efficient autonomous navigation in agricultural environments.", "published": "2025-07-31 08:56:24", "link": "http://arxiv.org/abs/2507.23350v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "AI Must not be Fully Autonomous", "abstract": "Autonomous Artificial Intelligence (AI) has many benefits. It also has many\nrisks. In this work, we identify the 3 levels of autonomous AI. We are of the\nposition that AI must not be fully autonomous because of the many risks,\nespecially as artificial superintelligence (ASI) is speculated to be just\ndecades away. Fully autonomous AI, which can develop its own objectives, is at\nlevel 3 and without responsible human oversight. However, responsible human\noversight is crucial for mitigating the risks. To ague for our position, we\ndiscuss theories of autonomy, AI and agents. Then, we offer 12 distinct\narguments and 6 counterarguments with rebuttals to the counterarguments. We\nalso present 15 pieces of recent evidence of AI misaligned values and other\nrisks in the appendix.", "published": "2025-07-31 08:22:49", "link": "http://arxiv.org/abs/2507.23330v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning", "abstract": "Vision-Language-Action (VLA) models have demonstrated significant potential\nin complex scene understanding and action reasoning, leading to their\nincreasing adoption in end-to-end autonomous driving systems. However, the long\nvisual tokens of VLA models greatly increase computational costs. Current\nvisual token pruning methods in Vision-Language Models (VLM) rely on either\nvisual token similarity or visual-text attention, but both have shown poor\nperformance in autonomous driving scenarios. Given that human drivers\nconcentrate on relevant foreground areas while driving, we assert that\nretaining visual tokens containing this foreground information is essential for\neffective decision-making. Inspired by this, we propose FastDriveVLA, a novel\nreconstruction-based vision token pruning framework designed specifically for\nautonomous driving. FastDriveVLA includes a plug-and-play visual token pruner\ncalled ReconPruner, which prioritizes foreground information through MAE-style\npixel reconstruction. A novel adversarial foreground-background reconstruction\nstrategy is designed to train ReconPruner for the visual encoder of VLA models.\nOnce trained, ReconPruner can be seamlessly applied to different VLA models\nwith the same visual encoder without retraining. To train ReconPruner, we also\nintroduce a large-scale dataset called nuScenes-FG, consisting of 241K\nimage-mask pairs with annotated foreground regions. Our approach achieves\nstate-of-the-art results on the nuScenes closed-loop planning benchmark across\ndifferent pruning ratios.", "published": "2025-07-31 07:55:56", "link": "http://arxiv.org/abs/2507.23318v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "How Far Are AI Scientists from Changing the World?", "abstract": "The emergence of large language models (LLMs) is propelling automated\nscientific discovery to the next level, with LLM-based Artificial Intelligence\n(AI) Scientist systems now taking the lead in scientific research. Several\ninfluential works have already appeared in the field of AI Scientist systems,\nwith AI-generated research papers having been accepted at the ICLR 2025\nworkshop, suggesting that a human-level AI Scientist capable of uncovering\nphenomena previously unknown to humans, may soon become a reality. In this\nsurvey, we focus on the central question: How far are AI scientists from\nchanging the world and reshaping the scientific research paradigm? To answer\nthis question, we provide a prospect-driven review that comprehensively\nanalyzes the current achievements of AI Scientist systems, identifying key\nbottlenecks and the critical components required for the emergence of a\nscientific agent capable of producing ground-breaking discoveries that solve\ngrand challenges. We hope this survey will contribute to a clearer\nunderstanding of limitations of current AI Scientist systems, showing where we\nare, what is missing, and what the ultimate goals for scientific AI should be.", "published": "2025-07-31 06:32:06", "link": "http://arxiv.org/abs/2507.23276v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2", "abstract": "Breast MRI provides high-resolution volumetric imaging critical for tumor\nassessment and treatment planning, yet manual interpretation of 3D scans\nremains labor-intensive and subjective. While AI-powered tools hold promise for\naccelerating medical image analysis, adoption of commercial medical AI products\nremains limited in low- and middle-income countries due to high license costs,\nproprietary software, and infrastructure demands. In this work, we investigate\nwhether the Segment Anything Model 2 (SAM2) can be adapted for low-cost,\nminimal-input 3D tumor segmentation in breast MRI. Using a single bounding box\nannotation on one slice, we propagate segmentation predictions across the 3D\nvolume using three different slice-wise tracking strategies: top-to-bottom,\nbottom-to-top, and center-outward. We evaluate these strategies across a large\ncohort of patients and find that center-outward propagation yields the most\nconsistent and accurate segmentations. Despite being a zero-shot model not\ntrained for volumetric medical data, SAM2 achieves strong segmentation\nperformance under minimal supervision. We further analyze how segmentation\nperformance relates to tumor size, location, and shape, identifying key failure\nmodes. Our results suggest that general-purpose foundation models such as SAM2\ncan support 3D medical image analysis with minimal supervision, offering an\naccessible and affordable alternative for resource-constrained settings.", "published": "2025-07-31 06:15:44", "link": "http://arxiv.org/abs/2507.23272v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "XABPs: Towards eXplainable Autonomous Business Processes", "abstract": "Autonomous business processes (ABPs), i.e., self-executing workflows\nleveraging AI/ML, have the potential to improve operational efficiency, reduce\nerrors, lower costs, improve response times, and free human workers for more\nstrategic and creative work. However, ABPs may raise specific concerns\nincluding decreased stakeholder trust, difficulties in debugging, hindered\naccountability, risk of bias, and issues with regulatory compliance. We argue\nfor eXplainable ABPs (XABPs) to address these concerns by enabling systems to\narticulate their rationale. The paper outlines a systematic approach to XABPs,\ncharacterizing their forms, structuring explainability, and identifying key BPM\nresearch challenges towards XABPs.", "published": "2025-07-31 06:10:49", "link": "http://arxiv.org/abs/2507.23269v1", "categories": ["cs.SE", "cs.AI", "cs.MA"], "primary_category": "cs.SE"}
{"title": "An Information Bottleneck Asset Pricing Model", "abstract": "Deep neural networks (DNNs) have garnered significant attention in financial\nasset pricing, due to their strong capacity for modeling complex nonlinear\nrelationships within financial data. However, sophisticated models are prone to\nover-fitting to the noise information in financial data, resulting in inferior\nperformance. To address this issue, we propose an information bottleneck asset\npricing model that compresses data with low signal-to-noise ratios to eliminate\nredundant information and retain the critical information for asset pricing.\nOur model imposes constraints of mutual information during the nonlinear\nmapping process. Specifically, we progressively reduce the mutual information\nbetween the input data and the compressed representation while increasing the\nmutual information between the compressed representation and the output\nprediction. The design ensures that irrelevant information, which is\nessentially the noise in the data, is forgotten during the modeling of\nfinancial nonlinear relationships without affecting the final asset pricing. By\nleveraging the constraints of the Information bottleneck, our model not only\nharnesses the nonlinear modeling capabilities of deep networks to capture the\nintricate relationships within financial data but also ensures that noise\ninformation is filtered out during the information compression process.", "published": "2025-07-31 03:15:58", "link": "http://arxiv.org/abs/2507.23218v1", "categories": ["cs.CE", "cs.AI"], "primary_category": "cs.CE"}
{"title": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification", "abstract": "To handle complex instances, we revisit a divide-and-conquer approach to\nbreak down the complexity: instead of few complex BaB calls, we rely on many\nsmall {\\em partial} MILP calls. The crucial step is to select very few but very\nimportant ReLUs to treat using (costly) binary variables. The previous attempts\nwere suboptimal in that respect. To select these important ReLU variables, we\npropose a novel {\\em solution-aware} ReLU scoring ({\\sf SAS}), as well as adapt\nthe BaB-SR and BaB-FSB branching functions as {\\em global} ReLU scoring ({\\sf\nGS}) functions. We compare them theoretically as well as experimentally, and\n{\\sf SAS} is more efficient at selecting a set of variables to open using\nbinary variables. Compared with previous attempts, SAS reduces the number of\nbinary variables by around 6 times, while maintaining the same level of\naccuracy. Implemented in {\\em Hybrid MILP}, calling first $\\alpha,\\beta$-CROWN\nwith a short time-out to solve easier instances, and then partial MILP,\nproduces a very accurate yet efficient verifier, reducing by up to $40\\%$ the\nnumber of undecided instances to low levels ($8-15\\%$), while keeping a\nreasonable runtime ($46s-417s$ on average per instance), even for fairly large\nCNNs with 2 million parameters.", "published": "2025-07-31 02:43:57", "link": "http://arxiv.org/abs/2507.23197v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Tractable Responsibility Measures for Ontology-Mediated Query Answering", "abstract": "Recent work on quantitative approaches to explaining query answers employs\nresponsibility measures to assign scores to facts in order to quantify their\nrespective contributions to obtaining a given answer. In this paper, we study\nthe complexity of computing such responsibility scores in the setting of\nontology-mediated query answering, focusing on a very recently introduced\nfamily of Shapley-value-based responsibility measures defined in terms of\nweighted sums of minimal supports (WSMS). By exploiting results from the\ndatabase setting, we can show that such measures enjoy polynomial data\ncomplexity for classes of ontology-mediated queries that are\nfirst-order-rewritable, whereas the problem becomes \"shP\"-hard when the\nontology language can encode reachability queries (via axioms like $\\exists R.\nA \\sqsubseteq A$). To better understand the tractability frontier, we next\nexplore the combined complexity of WSMS computation. We prove that\nintractability applies already to atomic queries if the ontology language\nsupports conjunction, as well as to unions of `well-behaved' conjunctive\nqueries, even in the absence of an ontology. By contrast, our study yields\npositive results for common DL-Lite dialects: by means of careful analysis, we\nidentify classes of structurally restricted conjunctive queries (which\nintuitively disallow undesirable interactions between query atoms) that admit\ntractable WSMS computation.", "published": "2025-07-31 02:08:12", "link": "http://arxiv.org/abs/2507.23191v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Accessibility Scout: Personalized Accessibility Scans of Built Environments", "abstract": "Assessing the accessibility of unfamiliar built environments is critical for\npeople with disabilities. However, manual assessments, performed by users or\ntheir personal health professionals, are laborious and unscalable, while\nautomatic machine learning methods often neglect an individual user's unique\nneeds. Recent advances in Large Language Models (LLMs) enable novel approaches\nto this problem, balancing personalization with scalability to enable more\nadaptive and context-aware assessments of accessibility. We present\nAccessibility Scout, an LLM-based accessibility scanning system that identifies\naccessibility concerns from photos of built environments. With use,\nAccessibility Scout becomes an increasingly capable \"accessibility scout\",\ntailoring accessibility scans to an individual's mobility level, preferences,\nand specific environmental interests through collaborative Human-AI\nassessments. We present findings from three studies: a formative study with six\nparticipants to inform the design of Accessibility Scout, a technical\nevaluation of 500 images of built environments, and a user study with 10\nparticipants of varying mobility. Results from our technical evaluation and\nuser study show that Accessibility Scout can generate personalized\naccessibility scans that extend beyond traditional ADA considerations. Finally,\nwe conclude with a discussion on the implications of our work and future steps\nfor building more scalable and personalized accessibility assessments of the\nphysical world.", "published": "2025-07-31 02:07:31", "link": "http://arxiv.org/abs/2507.23190v1", "categories": ["cs.HC", "cs.AI", "cs.CV", "cs.MA"], "primary_category": "cs.HC"}
{"title": "AutoBridge: Automating Smart Device Integration with Centralized Platform", "abstract": "Multimodal IoT systems coordinate diverse IoT devices to deliver\nhuman-centered services. The ability to incorporate new IoT devices under the\nmanagement of a centralized platform is an essential requirement. However, it\nrequires significant human expertise and effort to program the complex IoT\nintegration code that enables the platform to understand and control the device\nfunctions. Therefore, we propose AutoBridge to automate IoT integration code\ngeneration. Specifically, AutoBridge adopts a divide-and-conquer strategy: it\nfirst generates device control logic by progressively retrieving\ndevice-specific knowledge, then synthesizes platformcompliant integration code\nusing platform-specific knowledge. To ensure correctness, AutoBridge features a\nmulti-stage debugging pipeline, including an automated debugger for virtual IoT\ndevice testing and an interactive hardware-in-the-loop debugger that requires\nonly binary user feedback (yes and no) for real-device verification. We\nevaluate AutoBridge on a benchmark of 34 IoT devices across two open-source IoT\nplatforms. The results demonstrate that AutoBridge can achieves an average\nsuccess rate of 93.87% and an average function coverage of 94.87%, without any\nhuman involvement. With minimal binary yes and no feedback from users, the code\nis then revised to reach 100% function coverage. A user study with 15\nparticipants further shows that AutoBridge outperforms expert programmers by\n50% to 80% in code accuracy, even when the programmers are allowed to use\ncommercial code LLMs.", "published": "2025-07-31 01:14:14", "link": "http://arxiv.org/abs/2507.23178v1", "categories": ["cs.SE", "cs.AI", "I.2.5"], "primary_category": "cs.SE"}
{"title": "Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis", "abstract": "In this paper, we present a novel framework for video-to-4D generation that\ncreates high-quality dynamic 3D content from single video inputs. Direct 4D\ndiffusion modeling is extremely challenging due to costly data construction and\nthe high-dimensional nature of jointly representing 3D shape, appearance, and\nmotion. We address these challenges by introducing a Direct 4DMesh-to-GS\nVariation Field VAE that directly encodes canonical Gaussian Splats (GS) and\ntheir temporal variations from 3D animation data without per-instance fitting,\nand compresses high-dimensional animations into a compact latent space.\nBuilding upon this efficient representation, we train a Gaussian Variation\nField diffusion model with temporal-aware Diffusion Transformer conditioned on\ninput videos and canonical GS. Trained on carefully-curated animatable 3D\nobjects from the Objaverse dataset, our model demonstrates superior generation\nquality compared to existing methods. It also exhibits remarkable\ngeneralization to in-the-wild video inputs despite being trained exclusively on\nsynthetic data, paving the way for generating high-quality animated 3D content.\nProject page: https://gvfdiffusion.github.io/.", "published": "2025-07-31 17:59:51", "link": "http://arxiv.org/abs/2507.23785v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MonoFusion: Sparse-View 4D Reconstruction via Monocular Fusion", "abstract": "We address the problem of dynamic scene reconstruction from sparse-view\nvideos. Prior work often requires dense multi-view captures with hundreds of\ncalibrated cameras (e.g. Panoptic Studio). Such multi-view setups are\nprohibitively expensive to build and cannot capture diverse scenes in-the-wild.\nIn contrast, we aim to reconstruct dynamic human behaviors, such as repairing a\nbike or dancing, from a small set of sparse-view cameras with complete scene\ncoverage (e.g. four equidistant inward-facing static cameras). We find that\ndense multi-view reconstruction methods struggle to adapt to this sparse-view\nsetup due to limited overlap between viewpoints. To address these limitations,\nwe carefully align independent monocular reconstructions of each camera to\nproduce time- and view-consistent dynamic scene reconstructions. Extensive\nexperiments on PanopticStudio and Ego-Exo4D demonstrate that our method\nachieves higher quality reconstructions than prior art, particularly when\nrendering novel views. Code, data, and data-processing scripts are available on\nhttps://github.com/ImNotPrepared/MonoFusion.", "published": "2025-07-31 17:59:32", "link": "http://arxiv.org/abs/2507.23782v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions", "abstract": "While current general-purpose 3D human models (e.g., SMPL-X) efficiently\nrepresent accurate human shape and pose, they lacks the ability to physically\ninteract with the environment due to the kinematic nature. As a result,\nkinematic-based interaction models often suffer from issues such as\ninterpenetration and unrealistic object dynamics. To address this limitation,\nwe introduce a novel approach that embeds SMPL-X into a tangible entity capable\nof dynamic physical interactions with its surroundings. Specifically, we\npropose a \"half-physics\" mechanism that transforms 3D kinematic motion into a\nphysics simulation. Our approach maintains kinematic control over inherent\nSMPL-X poses while ensuring physically plausible interactions with scenes and\nobjects, effectively eliminating penetration and unrealistic object dynamics.\nUnlike reinforcement learning-based methods, which demand extensive and complex\ntraining, our half-physics method is learning-free and generalizes to any body\nshape and motion; meanwhile, it operates in real time. Moreover, it preserves\nthe fidelity of the original kinematic motion while seamlessly integrating\nphysical interactions", "published": "2025-07-31 17:58:33", "link": "http://arxiv.org/abs/2507.23778v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting", "abstract": "3D affordance reasoning, the task of associating human instructions with the\nfunctional regions of 3D objects, is a critical capability for embodied agents.\nCurrent methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited\nto single-object, single-step interactions, a paradigm that falls short of\naddressing the long-horizon, multi-object tasks required for complex real-world\napplications. To bridge this gap, we introduce the novel task of Sequential 3D\nGaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale\nbenchmark featuring 1800+ scenes to support research on long-horizon affordance\nunderstanding in complex 3DGS environments. We then propose SeqSplatNet, an\nend-to-end framework that directly maps an instruction to a sequence of 3D\naffordance masks. SeqSplatNet employs a large language model that\nautoregressively generates text interleaved with special segmentation tokens,\nguiding a conditional decoder to produce the corresponding 3D mask. To handle\ncomplex scene geometry, we introduce a pre-training strategy, Conditional\nGeometric Reconstruction, where the model learns to reconstruct complete\naffordance region masks from known geometric observations, thereby building a\nrobust geometric prior. Furthermore, to resolve semantic ambiguities, we design\na feature injection mechanism that lifts rich semantic features from 2D Vision\nFoundation Models (VFM) and fuses them into the 3D decoder at multiple scales.\nExtensive experiments demonstrate that our method sets a new state-of-the-art\non our challenging benchmark, effectively advancing affordance reasoning from\nsingle-step interactions to complex, sequential tasks at the scene level.", "published": "2025-07-31 17:56:55", "link": "http://arxiv.org/abs/2507.23772v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic", "abstract": "Deep learning-based medical image segmentation techniques have shown\npromising results when evaluated based on conventional metrics such as the Dice\nscore or Intersection-over-Union. However, these fully automatic methods often\nfail to meet clinically acceptable accuracy, especially when topological\nconstraints should be observed, e.g., continuous boundaries or closed surfaces.\nIn medical image segmentation, the correctness of a segmentation in terms of\nthe required topological genus sometimes is even more important than the\npixel-wise accuracy. Existing topology-aware approaches commonly estimate and\nconstrain the topological structure via the concept of persistent homology\n(PH). However, these methods are difficult to implement for high dimensional\ndata due to their polynomial computational complexity. To overcome this\nproblem, we propose a novel and fast approach for topology-aware segmentation\nbased on the Euler Characteristic ($\\chi$). First, we propose a fast\nformulation for $\\chi$ computation in both 2D and 3D. The scalar $\\chi$ error\nbetween the prediction and ground-truth serves as the topological evaluation\nmetric. Then we estimate the spatial topology correctness of any segmentation\nnetwork via a so-called topological violation map, i.e., a detailed map that\nhighlights regions with $\\chi$ errors. Finally, the segmentation results from\nthe arbitrary network are refined based on the topological violation maps by a\ntopology-aware correction network. Our experiments are conducted on both 2D and\n3D datasets and show that our method can significantly improve topological\ncorrectness while preserving pixel-wise segmentation accuracy.", "published": "2025-07-31 17:51:04", "link": "http://arxiv.org/abs/2507.23763v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Slot Attention with Re-Initialization and Self-Distillation", "abstract": "Unlike popular solutions based on dense feature maps, Object-Centric Learning\n(OCL) represents visual scenes as sub-symbolic object-level feature vectors,\ntermed slots, which are highly versatile for tasks involving visual modalities.\nOCL typically aggregates object superpixels into slots by iteratively applying\ncompetitive cross attention, known as Slot Attention, with the slots as the\nquery. However, once initialized, these slots are reused naively, causing\nredundant slots to compete with informative ones for representing objects. This\noften results in objects being erroneously segmented into parts. Additionally,\nmainstream methods derive supervision signals solely from decoding slots into\nthe input's reconstruction, overlooking potential supervision based on internal\ninformation. To address these issues, we propose Slot Attention with\nre-Initialization and self-Distillation (DIAS): $\\emph{i)}$ We reduce\nredundancy in the aggregated slots and re-initialize extra aggregation to\nupdate the remaining slots; $\\emph{ii)}$ We drive the bad attention map at the\nfirst aggregation iteration to approximate the good at the last iteration to\nenable self-distillation. Experiments demonstrate that DIAS achieves\nstate-of-the-art on OCL tasks like object discovery and recognition, while also\nimproving advanced visual prediction and reasoning. Our code is available on\nhttps://github.com/Genera1Z/DIAS.", "published": "2025-07-31 17:41:18", "link": "http://arxiv.org/abs/2507.23755v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping", "abstract": "General robotic grasping systems require accurate object affordance\nperception in diverse open-world scenarios following human instructions.\nHowever, current studies suffer from the problem of lacking reasoning-based\nlarge-scale affordance prediction data, leading to considerable concern about\nopen-world effectiveness. To address this limitation, we build a large-scale\ngrasping-oriented affordance segmentation benchmark with human-like\ninstructions, named RAGNet. It contains 273k images, 180 categories, and 26k\nreasoning instructions. The images cover diverse embodied data domains, such as\nwild, robot, ego-centric, and even simulation data. They are carefully\nannotated with an affordance map, while the difficulty of language instructions\nis largely increased by removing their category name and only providing\nfunctional descriptions. Furthermore, we propose a comprehensive\naffordance-based grasping framework, named AffordanceNet, which consists of a\nVLM pre-trained on our massive affordance data and a grasping network that\nconditions an affordance map to grasp the target. Extensive experiments on\naffordance segmentation benchmarks and real-robot manipulation tasks show that\nour model has a powerful open-world generalization ability. Our data and code\nis available at https://github.com/wudongming97/AffordanceNet.", "published": "2025-07-31 17:17:05", "link": "http://arxiv.org/abs/2507.23734v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "DiffuMatch: Category-Agnostic Spectral Diffusion Priors for Robust Non-rigid Shape Matching", "abstract": "Deep functional maps have recently emerged as a powerful tool for solving\nnon-rigid shape correspondence tasks. Methods that use this approach combine\nthe power and flexibility of the functional map framework, with data-driven\nlearning for improved accuracy and generality. However, most existing methods\nin this area restrict the learning aspect only to the feature functions and\nstill rely on axiomatic modeling for formulating the training loss or for\nfunctional map regularization inside the networks. This limits both the\naccuracy and the applicability of the resulting approaches only to scenarios\nwhere assumptions of the axiomatic models hold. In this work, we show, for the\nfirst time, that both in-network regularization and functional map training can\nbe replaced with data-driven methods. For this, we first train a generative\nmodel of functional maps in the spectral domain using score-based generative\nmodeling, built from a large collection of high-quality maps. We then exploit\nthe resulting model to promote the structural properties of ground truth\nfunctional maps on new shape collections. Remarkably, we demonstrate that the\nlearned models are category-agnostic, and can fully replace commonly used\nstrategies such as enforcing Laplacian commutativity or orthogonality of\nfunctional maps. Our key technical contribution is a novel distillation\nstrategy from diffusion models in the spectral domain. Experiments demonstrate\nthat our learned regularization leads to better results than axiomatic\napproaches for zero-shot non-rigid shape matching. Our code is available at:\nhttps://github.com/daidedou/diffumatch/", "published": "2025-07-31 16:44:54", "link": "http://arxiv.org/abs/2507.23715v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Explainable Image Classification with Reduced Overconfidence for Tissue Characterisation", "abstract": "The deployment of Machine Learning models intraoperatively for tissue\ncharacterisation can assist decision making and guide safe tumour resections.\nFor image classification models, pixel attribution methods are popular to infer\nexplainability. However, overconfidence in deep learning model's predictions\ntranslates to overconfidence in pixel attribution. In this paper, we propose\nthe first approach which incorporates risk estimation into a pixel attribution\nmethod for improved image classification explainability. The proposed method\niteratively applies a classification model with a pixel attribution method to\ncreate a volume of PA maps. This volume is used for the first time, to generate\na pixel-wise distribution of PA values. We introduce a method to generate an\nenhanced PA map by estimating the expectation values of the pixel-wise\ndistributions. In addition, the coefficient of variation (CV) is used to\nestimate pixel-wise risk of this enhanced PA map. Hence, the proposed method\nnot only provides an improved PA map but also produces an estimation of risk on\nthe output PA values. Performance evaluation on probe-based Confocal Laser\nEndomicroscopy (pCLE) data and ImageNet verifies that our improved\nexplainability method outperforms the state-of-the-art.", "published": "2025-07-31 16:30:50", "link": "http://arxiv.org/abs/2507.23709v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniLDiff: Unlocking the Power of Diffusion Priors for All-in-One Image Restoration", "abstract": "All-in-One Image Restoration (AiOIR) has emerged as a promising yet\nchallenging research direction. To address its core challenges, we propose a\nnovel unified image restoration framework based on latent diffusion models\n(LDMs). Our approach structurally integrates low-quality visual priors into the\ndiffusion process, unlocking the powerful generative capacity of diffusion\nmodels for diverse degradations. Specifically, we design a Degradation-Aware\nFeature Fusion (DAFF) module to enable adaptive handling of diverse degradation\ntypes. Furthermore, to mitigate detail loss caused by the high compression and\niterative sampling of LDMs, we design a Detail-Aware Expert Module (DAEM) in\nthe decoder to enhance texture and fine-structure recovery. Extensive\nexperiments across multi-task and mixed degradation settings demonstrate that\nour method consistently achieves state-of-the-art performance, highlighting the\npractical potential of diffusion priors for unified image restoration. Our code\nwill be released.", "published": "2025-07-31 16:02:00", "link": "http://arxiv.org/abs/2507.23685v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "I2V-GS: Infrastructure-to-Vehicle View Transformation with Gaussian Splatting for Autonomous Driving Data Generation", "abstract": "Vast and high-quality data are essential for end-to-end autonomous driving\nsystems. However, current driving data is mainly collected by vehicles, which\nis expensive and inefficient. A potential solution lies in synthesizing data\nfrom real-world images. Recent advancements in 3D reconstruction demonstrate\nphotorealistic novel view synthesis, highlighting the potential of generating\ndriving data from images captured on the road. This paper introduces a novel\nmethod, I2V-GS, to transfer the Infrastructure view To the Vehicle view with\nGaussian Splatting. Reconstruction from sparse infrastructure viewpoints and\nrendering under large view transformations is a challenging problem. We adopt\nthe adaptive depth warp to generate dense training views. To further expand the\nrange of views, we employ a cascade strategy to inpaint warped images, which\nalso ensures inpainting content is consistent across views. To further ensure\nthe reliability of the diffusion model, we utilize the cross-view information\nto perform a confidenceguided optimization. Moreover, we introduce RoadSight, a\nmulti-modality, multi-view dataset from real scenarios in infrastructure views.\nTo our knowledge, I2V-GS is the first framework to generate autonomous driving\ndatasets with infrastructure-vehicle view transformation. Experimental results\ndemonstrate that I2V-GS significantly improves synthesis quality under vehicle\nview, outperforming StreetGaussian in NTA-Iou, NTL-Iou, and FID by 45.7%,\n34.2%, and 14.9%, respectively.", "published": "2025-07-31 15:59:16", "link": "http://arxiv.org/abs/2507.23683v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OmniTraj: Pre-Training on Heterogeneous Data for Adaptive and Zero-Shot Human Trajectory Prediction", "abstract": "While large-scale pre-training has advanced human trajectory prediction, a\ncritical challenge remains: zero-shot transfer to unseen dataset with varying\ntemporal dynamics. State-of-the-art pre-trained models often require\nfine-tuning to adapt to new datasets with different frame rates or observation\nhorizons, limiting their scalability and practical utility. In this work, we\nsystematically investigate this limitation and propose a robust solution. We\nfirst demonstrate that existing data-aware discrete models struggle when\ntransferred to new scenarios with shifted temporal setups. We then isolate the\ntemporal generalization from dataset shift, revealing that a simple, explicit\nconditioning mechanism for temporal metadata is a highly effective solution.\nBased on this insight, we present OmniTraj, a Transformer-based model\npre-trained on a large-scale, heterogeneous dataset. Our experiments show that\nexplicitly conditioning on the frame rate enables OmniTraj to achieve\nstate-of-the-art zero-shot transfer performance, reducing prediction error by\nover 70\\% in challenging cross-setup scenarios. After fine-tuning, OmniTraj\nachieves state-of-the-art results on four datasets, including NBA, JTA,\nWorldPose, and ETH-UCY. The code is publicly available:\nhttps://github.com/vita-epfl/omnitraj", "published": "2025-07-31 15:37:09", "link": "http://arxiv.org/abs/2507.23657v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adaptively Distilled ControlNet: Accelerated Training and Superior Sampling for Medical Image Synthesis", "abstract": "Medical image annotation is constrained by privacy concerns and\nlabor-intensive labeling, significantly limiting the performance and\ngeneralization of segmentation models. While mask-controllable diffusion models\nexcel in synthesis, they struggle with precise lesion-mask alignment. We\npropose \\textbf{Adaptively Distilled ControlNet}, a task-agnostic framework\nthat accelerates training and optimization through dual-model distillation.\nSpecifically, during training, a teacher model, conditioned on mask-image\npairs, regularizes a mask-only student model via predicted noise alignment in\nparameter space, further enhanced by adaptive regularization based on\nlesion-background ratios. During sampling, only the student model is used,\nenabling privacy-preserving medical image generation. Comprehensive evaluations\non two distinct medical datasets demonstrate state-of-the-art performance:\nTransUNet improves mDice/mIoU by 2.4%/4.2% on KiTS19, while SANet achieves\n2.6%/3.5% gains on Polyps, highlighting its effectiveness and superiority. Code\nis available at GitHub.", "published": "2025-07-31 15:32:06", "link": "http://arxiv.org/abs/2507.23652v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Field-Ready AI-based Malaria Diagnosis: A Continual Learning Approach", "abstract": "Malaria remains a major global health challenge, particularly in low-resource\nsettings where access to expert microscopy may be limited. Deep learning-based\ncomputer-aided diagnosis (CAD) systems have been developed and demonstrate\npromising performance on thin blood smear images. However, their clinical\ndeployment may be hindered by limited generalization across sites with varying\nconditions. Yet very few practical solutions have been proposed. In this work,\nwe investigate continual learning (CL) as a strategy to enhance the robustness\nof malaria CAD models to domain shifts. We frame the problem as a\ndomain-incremental learning scenario, where a YOLO-based object detector must\nadapt to new acquisition sites while retaining performance on previously seen\ndomains. We evaluate four CL strategies, two rehearsal-based and two\nregularization-based methods, on real-life conditions thanks to a multi-site\nclinical dataset of thin blood smear images. Our results suggest that CL, and\nrehearsal-based methods in particular, can significantly improve performance.\nThese findings highlight the potential of continual learning to support the\ndevelopment of deployable, field-ready CAD tools for malaria.", "published": "2025-07-31 15:25:49", "link": "http://arxiv.org/abs/2507.23648v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) offer a biologically plausible framework for\nenergy-efficient neuromorphic computing. However, it is a challenge to train\nSNNs due to their non-differentiability, efficiently. Existing gradient\napproximation approaches frequently sacrifice accuracy and face deployment\nlimitations on edge devices due to the substantial computational requirements\nof backpropagation. To address these challenges, we propose a Forward-Forward\n(FF) based gradient approximation-free training framework for Spiking Neural\nNetworks, which treats spiking activations as black-box modules, thereby\neliminating the need for gradient approximation while significantly reducing\ncomputational complexity. Furthermore, we introduce a class-aware complexity\nadaptation mechanism that dynamically optimizes the loss function based on\ninter-class difficulty metrics, enabling efficient allocation of network\nresources across different categories. Experimental results demonstrate that\nour proposed training framework achieves test accuracies of 99.58%, 92.13%, and\n75.64% on the MNIST, Fashion-MNIST, and CIFAR-10 datasets, respectively,\nsurpassing all existing FF-based SNN approaches. Additionally, our proposed\nmethod exhibits significant advantages in terms of memory access and\ncomputational power consumption.", "published": "2025-07-31 15:22:23", "link": "http://arxiv.org/abs/2507.23643v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Medical Image De-Identification Benchmark Challenge", "abstract": "The de-identification (deID) of protected health information (PHI) and\npersonally identifiable information (PII) is a fundamental requirement for\nsharing medical images, particularly through public repositories, to ensure\ncompliance with patient privacy laws. In addition, preservation of non-PHI\nmetadata to inform and enable downstream development of imaging artificial\nintelligence (AI) is an important consideration in biomedical research. The\ngoal of MIDI-B was to provide a standardized platform for benchmarking of DICOM\nimage deID tools based on a set of rules conformant to the HIPAA Safe Harbor\nregulation, the DICOM Attribute Confidentiality Profiles, and best practices in\npreservation of research-critical metadata, as defined by The Cancer Imaging\nArchive (TCIA). The challenge employed a large, diverse, multi-center, and\nmulti-modality set of real de-identified radiology images with synthetic\nPHI/PII inserted.\n  The MIDI-B Challenge consisted of three phases: training, validation, and\ntest. Eighty individuals registered for the challenge. In the training phase,\nwe encouraged participants to tune their algorithms using their in-house or\npublic data. The validation and test phases utilized the DICOM images\ncontaining synthetic identifiers (of 216 and 322 subjects, respectively). Ten\nteams successfully completed the test phase of the challenge. To measure\nsuccess of a rule-based approach to image deID, scores were computed as the\npercentage of correct actions from the total number of required actions. The\nscores ranged from 97.91% to 99.93%. Participants employed a variety of\nopen-source and proprietary tools with customized configurations, large\nlanguage models, and optical character recognition (OCR). In this paper we\nprovide a comprehensive report on the MIDI-B Challenge's design,\nimplementation, results, and lessons learned.", "published": "2025-07-31 14:47:20", "link": "http://arxiv.org/abs/2507.23608v1", "categories": ["cs.CV", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Mamba-based Efficient Spatio-Frequency Motion Perception for Video Camouflaged Object Detection", "abstract": "Existing video camouflaged object detection (VCOD) methods primarily rely on\nspatial appearance features to perceive motion cues for breaking camouflage.\nHowever, the high similarity between foreground and background in VCOD results\nin limited discriminability of spatial appearance features (e.g., color and\ntexture), restricting detection accuracy and completeness. Recent studies\ndemonstrate that frequency features can not only enhance feature representation\nto compensate for appearance limitations but also perceive motion through\ndynamic variations in frequency energy. Furthermore, the emerging state space\nmodel called Mamba, enables efficient perception of motion cues in frame\nsequences due to its linear-time long-sequence modeling capability. Motivated\nby this, we propose a novel visual camouflage Mamba (Vcamba) based on\nspatio-frequency motion perception that integrates frequency and spatial\nfeatures for efficient and accurate VCOD. Specifically, we propose a receptive\nfield visual state space (RFVSS) module to extract multi-scale spatial features\nafter sequence modeling. For frequency learning, we introduce an adaptive\nfrequency component enhancement (AFE) module with a novel frequency-domain\nsequential scanning strategy to maintain semantic consistency. Then we propose\na space-based long-range motion perception (SLMP) module and a frequency-based\nlong-range motion perception (FLMP) module to model spatio-temporal and\nfrequency-temporal sequences in spatial and frequency phase domains. Finally,\nthe space and frequency motion fusion module (SFMF) integrates dual-domain\nfeatures for unified motion representation. Experimental results show that our\nVcamba outperforms state-of-the-art methods across 6 evaluation metrics on 2\ndatasets with lower computation cost, confirming the superiority of Vcamba. Our\ncode is available at: https://github.com/BoydeLi/Vcamba.", "published": "2025-07-31 14:40:37", "link": "http://arxiv.org/abs/2507.23601v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DA-Occ: Efficient 3D Voxel Occupancy Prediction via Directional 2D for Geometric Structure Preservation", "abstract": "Efficient and high-accuracy 3D occupancy prediction is crucial for ensuring\nthe performance of autonomous driving (AD) systems. However, many current\nmethods focus on high accuracy at the expense of real-time processing needs. To\naddress this challenge of balancing accuracy and inference speed, we propose a\ndirectional pure 2D approach. Our method involves slicing 3D voxel features to\npreserve complete vertical geometric information. This strategy compensates for\nthe loss of height cues in Bird's-Eye View (BEV) representations, thereby\nmaintaining the integrity of the 3D geometric structure. By employing a\ndirectional attention mechanism, we efficiently extract geometric features from\ndifferent orientations, striking a balance between accuracy and computational\nefficiency. Experimental results highlight the significant advantages of our\napproach for autonomous driving. On the Occ3D-nuScenes, the proposed method\nachieves an mIoU of 39.3% and an inference speed of 27.7 FPS, effectively\nbalancing accuracy and efficiency. In simulations on edge devices, the\ninference speed reaches 14.8 FPS, further demonstrating the method's\napplicability for real-time deployment in resource-constrained environments.", "published": "2025-07-31 14:39:31", "link": "http://arxiv.org/abs/2507.23599v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction", "abstract": "We present MoGA, a novel method to reconstruct high-fidelity 3D Gaussian\navatars from a single-view image. The main challenge lies in inferring unseen\nappearance and geometric details while ensuring 3D consistency and realism.\nMost previous methods rely on 2D diffusion models to synthesize unseen views;\nhowever, these generated views are sparse and inconsistent, resulting in\nunrealistic 3D artifacts and blurred appearance. To address these limitations,\nwe leverage a generative avatar model, that can generate diverse 3D avatars by\nsampling deformed Gaussians from a learned prior distribution. Due to the\nlimited amount of 3D training data such a 3D model alone cannot capture all\nimage details of unseen identities. Consequently, we integrate it as a prior,\nensuring 3D consistency by projecting input images into its latent space and\nenforcing additional 3D appearance and geometric constraints. Our novel\napproach formulates Gaussian avatar creation as a model inversion process by\nfitting the generative avatar to synthetic views from 2D diffusion models. The\ngenerative avatar provides a meaningful initialization for model fitting,\nenforces 3D regularization, and helps in refining pose estimation. Experiments\nshow that our method surpasses state-of-the-art techniques and generalizes well\nto real-world scenarios. Our Gaussian avatars are also inherently animatable", "published": "2025-07-31 14:36:24", "link": "http://arxiv.org/abs/2507.23597v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MamV2XCalib: V2X-based Target-less Infrastructure Camera Calibration with State Space Model", "abstract": "As cooperative systems that leverage roadside cameras to assist autonomous\nvehicle perception become increasingly widespread, large-scale precise\ncalibration of infrastructure cameras has become a critical issue. Traditional\nmanual calibration methods are often time-consuming, labor-intensive, and may\nrequire road closures. This paper proposes MamV2XCalib, the first V2X-based\ninfrastructure camera calibration method with the assistance of vehicle-side\nLiDAR. MamV2XCalib only requires autonomous vehicles equipped with LiDAR to\ndrive near the cameras to be calibrated in the infrastructure, without the need\nfor specific reference objects or manual intervention. We also introduce a new\ntargetless LiDAR-camera calibration method, which combines multi-scale features\nand a 4D correlation volume to estimate the correlation between vehicle-side\npoint clouds and roadside images. We model the temporal information and\nestimate the rotation angles with Mamba, effectively addressing calibration\nfailures in V2X scenarios caused by defects in the vehicle-side data (such as\nocclusions) and large differences in viewpoint. We evaluate MamV2XCalib on the\nV2X-Seq and TUMTraf-V2X real-world datasets, demonstrating the effectiveness\nand robustness of our V2X-based automatic calibration approach. Compared to\nprevious LiDAR-camera methods designed for calibration on one car, our approach\nachieves better and more stable calibration performance in V2X scenarios with\nfewer parameters. The code is available at\nhttps://github.com/zhuyaoye/MamV2XCalib.", "published": "2025-07-31 14:33:45", "link": "http://arxiv.org/abs/2507.23595v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Gloss: A Hand-Centric Framework for Gloss-Free Sign Language Translation", "abstract": "Sign Language Translation (SLT) is a challenging task that requires bridging\nthe modality gap between visual and linguistic information while capturing\nsubtle variations in hand shapes and movements. To address these challenges, we\nintroduce \\textbf{BeyondGloss}, a novel gloss-free SLT framework that leverages\nthe spatio-temporal reasoning capabilities of Video Large Language Models\n(VideoLLMs). Since existing VideoLLMs struggle to model long videos in detail,\nwe propose a novel approach to generate fine-grained, temporally-aware textual\ndescriptions of hand motion. A contrastive alignment module aligns these\ndescriptions with video features during pre-training, encouraging the model to\nfocus on hand-centric temporal dynamics and distinguish signs more effectively.\nTo further enrich hand-specific representations, we distill fine-grained\nfeatures from HaMeR. Additionally, we apply a contrastive loss between sign\nvideo representations and target language embeddings to reduce the modality gap\nin pre-training. \\textbf{BeyondGloss} achieves state-of-the-art performance on\nthe Phoenix14T and CSL-Daily benchmarks, demonstrating the effectiveness of the\nproposed framework. We will release the code upon acceptance of the paper.", "published": "2025-07-31 14:06:07", "link": "http://arxiv.org/abs/2507.23575v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization", "abstract": "Visual localization is the task of estimating a camera pose in a known\nenvironment. In this paper, we utilize 3D Gaussian Splatting (3DGS)-based\nrepresentations for accurate and privacy-preserving visual localization. We\npropose Gaussian Splatting Feature Fields (GSFFs), a scene representation for\nvisual localization that combines an explicit geometry model (3DGS) with an\nimplicit feature field. We leverage the dense geometric information and\ndifferentiable rasterization algorithm from 3DGS to learn robust feature\nrepresentations grounded in 3D. In particular, we align a 3D scale-aware\nfeature field and a 2D feature encoder in a common embedding space through a\ncontrastive framework. Using a 3D structure-informed clustering procedure, we\nfurther regularize the representation learning and seamlessly convert the\nfeatures to segmentations, which can be used for privacy-preserving visual\nlocalization. Pose refinement, which involves aligning either feature maps or\nsegmentations from a query image with those rendered from the GSFFs scene\nrepresentation, is used to achieve localization. The resulting privacy- and\nnon-privacy-preserving localization pipelines, evaluated on multiple real-world\ndatasets, show state-of-the-art performances.", "published": "2025-07-31 13:58:15", "link": "http://arxiv.org/abs/2507.23569v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection", "abstract": "Monocular 3D object detection is valuable for various applications such as\nrobotics and AR/VR. Existing methods are confined to closed-set settings, where\nthe training and testing sets consist of the same scenes and/or object\ncategories. However, real-world applications often introduce new environments\nand novel object categories, posing a challenge to these methods. In this\npaper, we address monocular 3D object detection in an open-set setting and\nintroduce the first end-to-end 3D Monocular Open-set Object Detector (3D-MOOD).\nWe propose to lift the open-set 2D detection into 3D space through our designed\n3D bounding box head, enabling end-to-end joint training for both 2D and 3D\ntasks to yield better overall performance. We condition the object queries with\ngeometry prior and overcome the generalization for 3D estimation across diverse\nscenes. To further improve performance, we design the canonical image space for\nmore efficient cross-dataset training. We evaluate 3D-MOOD on both closed-set\nsettings (Omni3D) and open-set settings (Omni3D to Argoverse 2, ScanNet), and\nachieve new state-of-the-art results. Code and models are available at\nroyyang0714.github.io/3D-MOOD.", "published": "2025-07-31 13:56:41", "link": "http://arxiv.org/abs/2507.23567v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "User Experience Estimation in Human-Robot Interaction Via Multi-Instance Learning of Multimodal Social Signals", "abstract": "In recent years, the demand for social robots has grown, requiring them to\nadapt their behaviors based on users' states. Accurately assessing user\nexperience (UX) in human-robot interaction (HRI) is crucial for achieving this\nadaptability. UX is a multi-faceted measure encompassing aspects such as\nsentiment and engagement, yet existing methods often focus on these\nindividually. This study proposes a UX estimation method for HRI by leveraging\nmultimodal social signals. We construct a UX dataset and develop a\nTransformer-based model that utilizes facial expressions and voice for\nestimation. Unlike conventional models that rely on momentary observations, our\napproach captures both short- and long-term interaction patterns using a\nmulti-instance learning framework. This enables the model to capture temporal\ndynamics in UX, providing a more holistic representation. Experimental results\ndemonstrate that our method outperforms third-party human evaluators in UX\nestimation.", "published": "2025-07-31 13:34:15", "link": "http://arxiv.org/abs/2507.23544v1", "categories": ["cs.RO", "cs.CV", "cs.HC"], "primary_category": "cs.RO"}
{"title": "JPEG Processing Neural Operator for Backward-Compatible Coding", "abstract": "Despite significant advances in learning-based lossy compression algorithms,\nstandardizing codecs remains a critical challenge. In this paper, we present\nthe JPEG Processing Neural Operator (JPNeO), a next-generation JPEG algorithm\nthat maintains full backward compatibility with the current JPEG format. Our\nJPNeO improves chroma component preservation and enhances reconstruction\nfidelity compared to existing artifact removal methods by incorporating neural\noperators in both the encoding and decoding stages. JPNeO achieves practical\nbenefits in terms of reduced memory usage and parameter count. We further\nvalidate our hypothesis about the existence of a space with high mutual\ninformation through empirical evidence. In summary, the JPNeO functions as a\nhigh-performance out-of-the-box image compression pipeline without changing\nsource coding's protocol. Our source code is available at\nhttps://github.com/WooKyoungHan/JPNeO.", "published": "2025-07-31 13:04:55", "link": "http://arxiv.org/abs/2507.23521v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Hyperbolic Cycle Alignment for Infrared-Visible Image Fusion", "abstract": "Image fusion synthesizes complementary information from multiple sources,\nmitigating the inherent limitations of unimodal imaging systems. Accurate image\nregistration is essential for effective multi-source data fusion. However,\nexisting registration methods, often based on image translation in Euclidean\nspace, fail to handle cross-modal misalignment effectively, resulting in\nsuboptimal alignment and fusion quality. To overcome this limitation, we\nexplore image alignment in non-Euclidean space and propose a Hyperbolic Cycle\nAlignment Network (Hy-CycleAlign). To the best of our knowledge, Hy-CycleAlign\nis the first image registration method based on hyperbolic space. It introduces\na dual-path cross-modal cyclic registration framework, in which a forward\nregistration network aligns cross-modal inputs, while a backward registration\nnetwork reconstructs the original image, forming a closed-loop registration\nstructure with geometric consistency. Additionally, we design a Hyperbolic\nHierarchy Contrastive Alignment (H$^{2}$CA) module, which maps images into\nhyperbolic space and imposes registration constraints, effectively reducing\ninterference caused by modality discrepancies. We further analyze image\nregistration in both Euclidean and hyperbolic spaces, demonstrating that\nhyperbolic space enables more sensitive and effective multi-modal image\nregistration. Extensive experiments on misaligned multi-modal images\ndemonstrate that our method significantly outperforms existing approaches in\nboth image alignment and fusion. Our code will be publicly available.", "published": "2025-07-31 12:45:02", "link": "http://arxiv.org/abs/2507.23508v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Online Estimation of Table-Top Grown Strawberry Mass in Field Conditions with Occlusions", "abstract": "Accurate mass estimation of table-top grown strawberries under field\nconditions remains challenging due to frequent occlusions and pose variations.\nThis study proposes a vision-based pipeline integrating RGB-D sensing and deep\nlearning to enable non-destructive, real-time and online mass estimation. The\nmethod employed YOLOv8-Seg for instance segmentation, Cycle-consistent\ngenerative adversarial network (CycleGAN) for occluded region completion, and\ntilt-angle correction to refine frontal projection area calculations. A\npolynomial regression model then mapped the geometric features to mass.\nExperiments demonstrated mean mass estimation errors of 8.11% for isolated\nstrawberries and 10.47% for occluded cases. CycleGAN outperformed large mask\ninpainting (LaMa) model in occlusion recovery, achieving superior pixel area\nratios (PAR) (mean: 0.978 vs. 1.112) and higher intersection over union (IoU)\nscores (92.3% vs. 47.7% in the [0.9-1] range). This approach addresses critical\nlimitations of traditional methods, offering a robust solution for automated\nharvesting and yield monitoring with complex occlusion patterns.", "published": "2025-07-31 12:10:23", "link": "http://arxiv.org/abs/2507.23487v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Stable-Sim2Real: Exploring Simulation of Real-Captured 3D Data with Two-Stage Depth Diffusion", "abstract": "3D data simulation aims to bridge the gap between simulated and real-captured\n3D data, which is a fundamental problem for real-world 3D visual tasks. Most 3D\ndata simulation methods inject predefined physical priors but struggle to\ncapture the full complexity of real data. An optimal approach involves learning\nan implicit mapping from synthetic to realistic data in a data-driven manner,\nbut progress in this solution has met stagnation in recent studies. This work\nexplores a new solution path of data-driven 3D simulation, called\nStable-Sim2Real, based on a novel two-stage depth diffusion model. The initial\nstage finetunes Stable-Diffusion to generate the residual between the real and\nsynthetic paired depth, producing a stable but coarse depth, where some local\nregions may deviate from realistic patterns. To enhance this, both the\nsynthetic and initial output depth are fed into a second-stage diffusion, where\ndiffusion loss is adjusted to prioritize these distinct areas identified by a\n3D discriminator. We provide a new benchmark scheme to evaluate 3D data\nsimulation methods. Extensive experiments show that training the network with\nthe 3D simulated data derived from our method significantly enhances\nperformance in real-world 3D visual tasks. Moreover, the evaluation\ndemonstrates the high similarity between our 3D simulated data and\nreal-captured patterns. Project page:\nhttps://mutianxu.github.io/stable-sim2real/.", "published": "2025-07-31 12:08:16", "link": "http://arxiv.org/abs/2507.23483v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FastPoint: Accelerating 3D Point Cloud Model Inference via Sample Point Distance Prediction", "abstract": "Deep neural networks have revolutionized 3D point cloud processing, yet\nefficiently handling large and irregular point clouds remains challenging. To\ntackle this problem, we introduce FastPoint, a novel software-based\nacceleration technique that leverages the predictable distance trend between\nsampled points during farthest point sampling. By predicting the distance\ncurve, we can efficiently identify subsequent sample points without\nexhaustively computing all pairwise distances. Our proposal substantially\naccelerates farthest point sampling and neighbor search operations while\npreserving sampling quality and model performance. By integrating FastPoint\ninto state-of-the-art 3D point cloud models, we achieve 2.55x end-to-end\nspeedup on NVIDIA RTX 3090 GPU without sacrificing accuracy.", "published": "2025-07-31 12:02:40", "link": "http://arxiv.org/abs/2507.23480v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Seeing More with Less: Video Capsule Endoscopy with Multi-Task Learning", "abstract": "Video capsule endoscopy has become increasingly important for investigating\nthe small intestine within the gastrointestinal tract. However, a persistent\nchallenge remains the short battery lifetime of such compact sensor edge\ndevices. Integrating artificial intelligence can help overcome this limitation\nby enabling intelligent real-time decision- making, thereby reducing the energy\nconsumption and prolonging the battery life. However, this remains challenging\ndue to data sparsity and the limited resources of the device restricting the\noverall model size. In this work, we introduce a multi-task neural network that\ncombines the functionalities of precise self-localization within the\ngastrointestinal tract with the ability to detect anomalies in the small\nintestine within a single model. Throughout the development process, we\nconsistently restricted the total number of parameters to ensure the\nfeasibility to deploy such model in a small capsule. We report the first\nmulti-task results using the recently published Galar dataset, integrating\nestablished multi-task methods and Viterbi decoding for subsequent time-series\nanalysis. This outperforms current single-task models and represents a\nsignificant ad- vance in AI-based approaches in this field. Our model achieves\nan accu- racy of 93.63% on the localization task and an accuracy of 87.48% on\nthe anomaly detection task. The approach requires only 1 million parameters\nwhile surpassing the current baselines.", "published": "2025-07-31 12:00:25", "link": "http://arxiv.org/abs/2507.23479v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding", "abstract": "Large vision-language models (VLMs) have made significant strides in 2D\nvisual understanding tasks, sparking interest in extending these capabilities\nto 3D scene understanding. However, current 3D VLMs often struggle with robust\nreasoning and generalization due to limitations in high-quality spatial data\nand the static nature of viewpoint assumptions. To address these challenges, we\npropose 3D-R1, a foundation model that enhances the reasoning capabilities of\n3D VLMs. Specifically, we first construct a high-quality synthetic dataset with\nCoT, named Scene-30K, leveraging existing 3D-VL datasets and a data engine\nbased on Gemini 2.5 Pro. It serves as cold-start initialization data for 3D-R1.\nMoreover, we leverage RLHF policy such as GRPO in the reinforcement learning\ntraining process to enhance reasoning capabilities and introduce three reward\nfunctions: a perception reward, a semantic similarity reward and a format\nreward to maintain detection accuracy and answer semantic precision.\nFurthermore, we introduce a dynamic view selection strategy that adaptively\nchooses the most informative perspectives for 3D scene understanding. Extensive\nexperiments demonstrate that 3D-R1 delivers an average improvement of 10%\nacross various 3D scene benchmarks, highlighting its effectiveness in enhancing\nreasoning and generalization in 3D scene understanding. Code:\nhttps://github.com/AIGeeksGroup/3D-R1. Website:\nhttps://aigeeksgroup.github.io/3D-R1.", "published": "2025-07-31 11:59:06", "link": "http://arxiv.org/abs/2507.23478v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes", "abstract": "The widespread application of Unmanned Aerial Vehicles (UAVs) has raised\nserious public safety and privacy concerns, making UAV perception crucial for\nanti-UAV tasks. However, existing UAV tracking datasets predominantly feature\nconspicuous objects and lack diversity in scene complexity and attribute\nrepresentation, limiting their applicability to real-world scenarios. To\novercome these limitations, we present the CST Anti-UAV, a new thermal infrared\ndataset specifically designed for Single Object Tracking (SOT) in Complex\nScenes with Tiny UAVs (CST). It contains 220 video sequences with over 240k\nhigh-quality bounding box annotations, highlighting two key properties: a\nsignificant number of tiny-sized UAV targets and the diverse and complex\nscenes. To the best of our knowledge, CST Anti-UAV is the first dataset to\nincorporate complete manual frame-level attribute annotations, enabling precise\nevaluations under varied challenges. To conduct an in-depth performance\nanalysis for CST Anti-UAV, we evaluate 20 existing SOT methods on the proposed\ndataset. Experimental results demonstrate that tracking tiny UAVs in complex\nenvironments remains a challenge, as the state-of-the-art method achieves only\n35.92% state accuracy, much lower than the 67.69% observed on the Anti-UAV410\ndataset. These findings underscore the limitations of existing benchmarks and\nthe need for further advancements in UAV tracking research. The CST Anti-UAV\nbenchmark is about to be publicly released, which not only fosters the\ndevelopment of more robust SOT methods but also drives innovation in anti-UAV\nsystems.", "published": "2025-07-31 11:53:21", "link": "http://arxiv.org/abs/2507.23473v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adjustable Spatio-Spectral Hyperspectral Image Compression Network", "abstract": "With the rapid growth of hyperspectral data archives in remote sensing (RS),\nthe need for efficient storage has become essential, driving significant\nattention toward learning-based hyperspectral image (HSI) compression. However,\na comprehensive investigation of the individual and joint effects of spectral\nand spatial compression on learning-based HSI compression has not been\nthoroughly examined yet. Conducting such an analysis is crucial for\nunderstanding how the exploitation of spectral, spatial, and joint\nspatio-spectral redundancies affects HSI compression. To address this issue, we\npropose Adjustable Spatio-Spectral Hyperspectral Image Compression Network\n(HyCASS), a learning-based model designed for adjustable HSI compression in\nboth spectral and spatial dimensions. HyCASS consists of six main modules: 1)\nspectral encoder; 2) spatial encoder; 3) compression ratio (CR) adapter\nencoder; 4) CR adapter decoder; 5) spatial decoder; and 6) spectral decoder\nmodule. The modules employ convolutional layers and transformer blocks to\ncapture both short-range and long-range redundancies. Experimental results on\ntwo HSI benchmark datasets demonstrate the effectiveness of our proposed\nadjustable model compared to existing learning-based compression models. Based\non our results, we establish a guideline for effectively balancing spectral and\nspatial compression across different CRs, taking into account the spatial\nresolution of the HSIs. Our code and pre-trained model weights are publicly\navailable at https://git.tu-berlin.de/rsim/hycass .", "published": "2025-07-31 11:26:04", "link": "http://arxiv.org/abs/2507.23447v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification", "abstract": "Art style classification remains a formidable challenge in computational\naesthetics due to the scarcity of expertly labeled datasets and the intricate,\noften nonlinear interplay of stylistic elements. While recent dual-teacher\nself-supervised frameworks reduce reliance on labeled data, their linear\nprojection layers and localized focus struggle to model global compositional\ncontext and complex style-feature interactions. We enhance the dual-teacher\nknowledge distillation framework to address these limitations by replacing\nconventional MLP projection and prediction heads with Kolmogorov-Arnold\nNetworks (KANs). Our approach retains complementary guidance from two teacher\nnetworks, one emphasizing localized texture and brushstroke patterns, the other\ncapturing broader stylistic hierarchies while leveraging KANs' spline-based\nactivations to model nonlinear feature correlations with mathematical\nprecision. Experiments on WikiArt and Pandora18k demonstrate that our approach\noutperforms the base dual teacher architecture in Top-1 accuracy. Our findings\nhighlight the importance of KANs in disentangling complex style manifolds,\nleading to better linear probe accuracy than MLP projections.", "published": "2025-07-31 11:16:00", "link": "http://arxiv.org/abs/2507.23436v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Out-of-Distribution Detection in Medical Imaging via Diffusion Trajectories", "abstract": "In medical imaging, unsupervised out-of-distribution (OOD) detection offers\nan attractive approach for identifying pathological cases with extremely low\nincidence rates. In contrast to supervised methods, OOD-based approaches\nfunction without labels and are inherently robust to data imbalances. Current\ngenerative approaches often rely on likelihood estimation or reconstruction\nerror, but these methods can be computationally expensive, unreliable, and\nrequire retraining if the inlier data changes. These limitations hinder their\nability to distinguish nominal from anomalous inputs efficiently, consistently,\nand robustly. We propose a reconstruction-free OOD detection method that\nleverages the forward diffusion trajectories of a Stein score-based denoising\ndiffusion model (SBDDM). By capturing trajectory curvature via the estimated\nStein score, our approach enables accurate anomaly scoring with only five\ndiffusion steps. A single SBDDM pre-trained on a large, semantically aligned\nmedical dataset generalizes effectively across multiple Near-OOD and Far-OOD\nbenchmarks, achieving state-of-the-art performance while drastically reducing\ncomputational cost during inference. Compared to existing methods, SBDDM\nachieves a relative improvement of up to 10.43% and 18.10% for Near-OOD and\nFar-OOD detection, making it a practical building block for real-time, reliable\ncomputer-aided diagnosis.", "published": "2025-07-31 10:36:58", "link": "http://arxiv.org/abs/2507.23411v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Smart Video Capsule Endoscopy: Raw Image-Based Localization for Enhanced GI Tract Investigation", "abstract": "For many real-world applications involving low-power sensor edge devices deep\nneural networks used for image classification might not be suitable. This is\ndue to their typically large model size and require- ment of operations often\nexceeding the capabilities of such resource lim- ited devices. Furthermore,\ncamera sensors usually capture images with a Bayer color filter applied, which\nare subsequently converted to RGB images that are commonly used for neural\nnetwork training. However, on resource-constrained devices, such conversions\ndemands their share of energy and optimally should be skipped if possible. This\nwork ad- dresses the need for hardware-suitable AI targeting sensor edge\ndevices by means of the Video Capsule Endoscopy, an important medical proce-\ndure for the investigation of the small intestine, which is strongly limited by\nits battery lifetime. Accurate organ classification is performed with a final\naccuracy of 93.06% evaluated directly on Bayer images involv- ing a CNN with\nonly 63,000 parameters and time-series analysis in the form of Viterbi\ndecoding. Finally, the process of capturing images with a camera and raw image\nprocessing is demonstrated with a customized PULPissimo System-on-Chip with a\nRISC-V core and an ultra-low power hardware accelerator providing an\nenergy-efficient AI-based image clas- sification approach requiring just 5.31\n{\\mu}J per image. As a result, it is possible to save an average of 89.9% of\nenergy before entering the small intestine compared to classic video capsules.", "published": "2025-07-31 10:13:39", "link": "http://arxiv.org/abs/2507.23398v1", "categories": ["eess.IV", "cs.AR", "cs.CV"], "primary_category": "eess.IV"}
{"title": "NeRF Is a Valuable Assistant for 3D Gaussian Splatting", "abstract": "We introduce NeRF-GS, a novel framework that jointly optimizes Neural\nRadiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). This framework\nleverages the inherent continuous spatial representation of NeRF to mitigate\nseveral limitations of 3DGS, including sensitivity to Gaussian initialization,\nlimited spatial awareness, and weak inter-Gaussian correlations, thereby\nenhancing its performance. In NeRF-GS, we revisit the design of 3DGS and\nprogressively align its spatial features with NeRF, enabling both\nrepresentations to be optimized within the same scene through shared 3D spatial\ninformation. We further address the formal distinctions between the two\napproaches by optimizing residual vectors for both implicit features and\nGaussian positions to enhance the personalized capabilities of 3DGS.\nExperimental results on benchmark datasets show that NeRF-GS surpasses existing\nmethods and achieves state-of-the-art performance. This outcome confirms that\nNeRF and 3DGS are complementary rather than competing, offering new insights\ninto hybrid approaches that combine 3DGS and NeRF for efficient 3D scene\nrepresentation.", "published": "2025-07-31 09:43:31", "link": "http://arxiv.org/abs/2507.23374v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Prompt Progressive Alignment for Multi-Source Unsupervised Domain Adaptation", "abstract": "Large Vision-Language Models like CLIP have become a powerful foundation for\nUnsupervised Domain Adaptation due to their strong zero-shot generalization.\nState-of-the-art methods typically leverage CLIP to generate pseudo-labels for\nthe target domain, then fine-tune the model to learn domain-invariant features.\nHowever, these methods attempt to align source and target domains using all\npseudo-labeled data simultaneously. This one-shot alignment struggles with\nnoisy, hard-to-classify samples, leading to error propagation and suboptimal\nfeature learning. The problem is even more amplified in the multi-source\nscenario, where diverse domain gaps and varying noise levels across multiple\nsource domains further destabilize the alignment process. To address this\nissue, in this work, we propose a progressive alignment strategy for adapting\nCLIP to unlabeled downstream task. Our method begins by training the model on a\nhigh-confidence subset of target samples, allowing it to first learn a\nwell-aligned representation from the most reliable data. As training\nprogresses, it gradually incorporates more challenging samples, guiding the\nmodel to refine its understanding without being overwhelmed by initial label\nnoise. This progressive approach effectively mitigates confirmation bias and\npromotes a more robust convergence, allowing for the learning of genuinely\ndomain-invariant features. We name our approach MP^2A and test it on three\npopular UDA benchmarks, namely ImageCLEF, Office-Home, and the most challenging\nDomainNet. Experiments showcase that MP^2A achieves state-of-the-art\nperformance when compared with most recent CLIP-based MS-UDA approaches,\ndemonstrating the effectiveness of our approach.", "published": "2025-07-31 09:42:42", "link": "http://arxiv.org/abs/2507.23373v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniEmo: Unifying Emotional Understanding and Generation with Learnable Expert Queries", "abstract": "Emotional understanding and generation are often treated as separate tasks,\nyet they are inherently complementary and can mutually enhance each other. In\nthis paper, we propose the UniEmo, a unified framework that seamlessly\nintegrates these two tasks. The key challenge lies in the abstract nature of\nemotions, necessitating the extraction of visual representations beneficial for\nboth tasks. To address this, we propose a hierarchical emotional understanding\nchain with learnable expert queries that progressively extracts multi-scale\nemotional features, thereby serving as a foundational step for unification.\nSimultaneously, we fuse these expert queries and emotional representations to\nguide the diffusion model in generating emotion-evoking images. To enhance the\ndiversity and fidelity of the generated emotional images, we further introduce\nthe emotional correlation coefficient and emotional condition loss into the\nfusion process. This step facilitates fusion and alignment for emotional\ngeneration guided by the understanding. In turn, we demonstrate that joint\ntraining allows the generation component to provide implicit feedback to the\nunderstanding part. Furthermore, we propose a novel data filtering algorithm to\nselect high-quality and diverse emotional images generated by the well-trained\nmodel, which explicitly feedback into the understanding part. Together, these\ngeneration-driven dual feedback processes enhance the model's understanding\ncapacity. Extensive experiments show that UniEmo significantly outperforms\nstate-of-the-art methods in both emotional understanding and generation tasks.\nThe code for the proposed method is available at\nhttps://github.com/JiuTian-VL/UniEmo.", "published": "2025-07-31 09:39:27", "link": "http://arxiv.org/abs/2507.23372v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VMatcher: State-Space Semi-Dense Local Feature Matching", "abstract": "This paper introduces VMatcher, a hybrid Mamba-Transformer network for\nsemi-dense feature matching between image pairs. Learning-based feature\nmatching methods, whether detector-based or detector-free, achieve\nstate-of-the-art performance but depend heavily on the Transformer's attention\nmechanism, which, while effective, incurs high computational costs due to its\nquadratic complexity. In contrast, Mamba introduces a Selective State-Space\nModel (SSM) that achieves comparable or superior performance with linear\ncomplexity, offering significant efficiency gains. VMatcher leverages a hybrid\napproach, integrating Mamba's highly efficient long-sequence processing with\nthe Transformer's attention mechanism. Multiple VMatcher configurations are\nproposed, including hierarchical architectures, demonstrating their\neffectiveness in setting new benchmarks efficiently while ensuring robustness\nand practicality for real-time applications where rapid inference is crucial.\nSource Code is available at: https://github.com/ayoussf/VMatcher", "published": "2025-07-31 09:39:16", "link": "http://arxiv.org/abs/2507.23371v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Short-LVLM: Compressing and Accelerating Large Vision-Language Models by Pruning Redundant Layers", "abstract": "Although large vision-language models (LVLMs) have demonstrated impressive\ncapabilities in multi-modal understanding and reasoning, their practical\napplications are still limited by massive model parameters and high\ncomputational costs. Recent efforts from natural language processing (NLP) have\nshown the effectiveness of layer pruning, offering a plausible training-free\ncompression solution. However, due to the modality divergence between vision\nand language, it is unclear whether these NLP techniques are still effective in\nLVLMs. In this paper, we empirically prove that directly applying these layer\npruning methods to LVLMs is ineffective. Through extensive experiments, we find\nthat non-essential vision-language (VL) tokens and inter-layer feature gaps\npose critical challenges to pruning layers in LVLMs. Based on these insights,\nwe propose a novel framework Short-LVLM (SVL) that can utilize important VL\ntokens and mitigate the layer-wise feature gaps. Notably, Short-LVLM not only\nachieves a superior trade-off between performance and efficiency but also\nexhibits several potential advantages, i.e., training-free, model-agnostic, and\nhighly compatible. The code for this work is publicly available at\nhttps://github.com/ASGO-MM/Short-LVLM.", "published": "2025-07-31 09:17:53", "link": "http://arxiv.org/abs/2507.23362v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pixel Embedding Method for Tubular Neurite Segmentation", "abstract": "Automatic segmentation of neuronal topology is critical for handling large\nscale neuroimaging data, as it can greatly accelerate neuron annotation and\nanalysis. However, the intricate morphology of neuronal branches and the\nocclusions among fibers pose significant challenges for deep learning based\nsegmentation. To address these issues, we propose an improved framework: First,\nwe introduce a deep network that outputs pixel level embedding vectors and\ndesign a corresponding loss function, enabling the learned features to\neffectively distinguish different neuronal connections within occluded regions.\nSecond, building on this model, we develop an end to end pipeline that directly\nmaps raw neuronal images to SWC formatted neuron structure trees. Finally,\nrecognizing that existing evaluation metrics fail to fully capture segmentation\naccuracy, we propose a novel topological assessment metric to more\nappropriately quantify the quality of neuron segmentation and reconstruction.\nExperiments on our fMOST imaging dataset demonstrate that, compared to several\nclassical methods, our approach significantly reduces the error rate in\nneuronal topology reconstruction.", "published": "2025-07-31 09:11:15", "link": "http://arxiv.org/abs/2507.23359v1", "categories": ["eess.IV", "cs.CV", "q-bio.NC"], "primary_category": "eess.IV"}
{"title": "IN45023 Neural Network Design Patterns in Computer Vision Seminar Report, Summer 2025", "abstract": "This report analyzes the evolution of key design patterns in computer vision\nby examining six influential papers. The analy- sis begins with foundational\narchitectures for image recognition. We review ResNet, which introduced\nresidual connections to overcome the vanishing gradient problem and enable\neffective training of significantly deeper convolutional networks.\nSubsequently, we examine the Vision Transformer (ViT), which established a new\nparadigm by applying the Transformer ar- chitecture to sequences of image\npatches, demonstrating the efficacy of attention-based models for large-scale\nimage recogni- tion. Building on these visual representation backbones, we\ninvestigate generative models. Generative Adversarial Networks (GANs) are\nanalyzed for their novel adversarial training process, which challenges a\ngenerator against a discriminator to learn complex data distributions. Then,\nLatent Diffusion Models (LDMs) are covered, which improve upon prior generative\nmethods by performing a sequential denoising process in a perceptually\ncompressed latent space. LDMs achieve high-fidelity synthesis with greater\ncomputational efficiency, representing the current state-of-the-art for image\ngeneration. Finally, we explore self-supervised learning techniques that reduce\ndependency on labeled data. DINO is a self-distillation framework in which a\nstudent network learns to match the output of a momentum-updated teacher,\nyielding features with strong k-NN classification performance. We conclude with\nMasked Autoencoders (MAE), which utilize an asymmetric encoder-decoder design\nto reconstruct heavily masked inputs, providing a highly scalable and effective\nmethod for pre-training large-scale vision models.", "published": "2025-07-31 09:08:11", "link": "http://arxiv.org/abs/2507.23357v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Who is a Better Talker: Subjective and Objective Quality Assessment for AI-Generated Talking Heads", "abstract": "Speech-driven methods for portraits are figuratively known as \"Talkers\"\nbecause of their capability to synthesize speaking mouth shapes and facial\nmovements. Especially with the rapid development of the Text-to-Image (T2I)\nmodels, AI-Generated Talking Heads (AGTHs) have gradually become an emerging\ndigital human media. However, challenges persist regarding the quality of these\ntalkers and AGTHs they generate, and comprehensive studies addressing these\nissues remain limited. To address this gap, this paper presents the largest\nAGTH quality assessment dataset THQA-10K to date, which selects 12 prominent\nT2I models and 14 advanced talkers to generate AGTHs for 14 prompts. After\nexcluding instances where AGTH generation is unsuccessful, the THQA-10K dataset\ncontains 10,457 AGTHs. Then, volunteers are recruited to subjectively rate the\nAGTHs and give the corresponding distortion categories. In our analysis for\nsubjective experimental results, we evaluate the performance of talkers in\nterms of generalizability and quality, and also expose the distortions of\nexisting AGTHs. Finally, an objective quality assessment method based on the\nfirst frame, Y-T slice and tone-lip consistency is proposed. Experimental\nresults show that this method can achieve state-of-the-art (SOTA) performance\nin AGTH quality assessment. The work is released at\nhttps://github.com/zyj-2000/Talker.", "published": "2025-07-31 08:43:21", "link": "http://arxiv.org/abs/2507.23343v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models", "abstract": "Face detection is a crucial component in many AI-driven applications such as\nsurveillance, biometric authentication, and human-computer interaction.\nHowever, real-world conditions like low-resolution imagery present significant\nchallenges that degrade detection performance. In this study, we systematically\ninvestigate the impact of input resolution on the accuracy and robustness of\nthree prominent deep learning-based face detectors: YOLOv11, YOLOv12, and\nMTCNN. Using the WIDER FACE dataset, we conduct extensive evaluations across\nmultiple image resolutions (160x160, 320x320, and 640x640) and assess each\nmodel's performance using metrics such as precision, recall, mAP50, mAP50-95,\nand inference time. Results indicate that YOLOv11 outperforms YOLOv12 and MTCNN\nin terms of detection accuracy, especially at higher resolutions, while YOLOv12\nexhibits slightly better recall. MTCNN, although competitive in landmark\nlocalization, lags in real-time inference speed. Our findings provide\nactionable insights for selecting resolution-aware face detection models\nsuitable for varying operational constraints.", "published": "2025-07-31 08:41:33", "link": "http://arxiv.org/abs/2507.23341v1", "categories": ["cs.CV", "68T45, 68T07", "I.4.8; I.4.9; I.5.4"], "primary_category": "cs.CV"}
{"title": "MagicRoad: Semantic-Aware 3D Road Surface Reconstruction via Obstacle Inpainting", "abstract": "Road surface reconstruction is essential for autonomous driving, supporting\ncentimeter-accurate lane perception and high-definition mapping in complex\nurban environments.While recent methods based on mesh rendering or 3D Gaussian\nsplatting (3DGS) achieve promising results under clean and static conditions,\nthey remain vulnerable to occlusions from dynamic agents, visual clutter from\nstatic obstacles, and appearance degradation caused by lighting and weather\nchanges. We present a robust reconstruction framework that integrates\nocclusion-aware 2D Gaussian surfels with semantic-guided color enhancement to\nrecover clean, consistent road surfaces. Our method leverages a planar-adapted\nGaussian representation for efficient large-scale modeling, employs\nsegmentation-guided video inpainting to remove both dynamic and static\nforeground objects, and enhances color coherence via semantic-aware correction\nin HSV space. Extensive experiments on urban-scale datasets demonstrate that\nour framework produces visually coherent and geometrically faithful\nreconstructions, significantly outperforming prior methods under real-world\nconditions.", "published": "2025-07-31 08:38:36", "link": "http://arxiv.org/abs/2507.23340v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Contrastive Learning-Driven Traffic Sign Perception: Multi-Modal Fusion of Text and Vision", "abstract": "Traffic sign recognition, as a core component of autonomous driving\nperception systems, directly influences vehicle environmental awareness and\ndriving safety. Current technologies face two significant challenges: first,\nthe traffic sign dataset exhibits a pronounced long-tail distribution,\nresulting in a substantial decline in recognition performance of traditional\nconvolutional networks when processing low-frequency and out-of-distribution\nclasses; second, traffic signs in real-world scenarios are predominantly small\ntargets with significant scale variations, making it difficult to extract\nmulti-scale features.To overcome these issues, we propose a novel two-stage\nframework combining open-vocabulary detection and cross-modal learning. For\ntraffic sign detection, our NanoVerse YOLO model integrates a reparameterizable\nvision-language path aggregation network (RepVL-PAN) and an SPD-Conv module to\nspecifically enhance feature extraction for small, multi-scale targets. For\ntraffic sign classification, we designed a Traffic Sign Recognition Multimodal\nContrastive Learning model (TSR-MCL). By contrasting visual features from a\nVision Transformer with semantic features from a rule-based BERT, TSR-MCL\nlearns robust, frequency-independent representations, effectively mitigating\nclass confusion caused by data imbalance. On the TT100K dataset, our method\nachieves a state-of-the-art 78.4% mAP in the long-tail detection task for\nall-class recognition. The model also obtains 91.8% accuracy and 88.9% recall,\nsignificantly outperforming mainstream algorithms and demonstrating superior\naccuracy and generalization in complex, open-world scenarios.", "published": "2025-07-31 08:23:30", "link": "http://arxiv.org/abs/2507.23331v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Semantic Directions for Feature Augmentation in Domain-Generalized Medical Segmentation", "abstract": "Medical image segmentation plays a crucial role in clinical workflows, but\ndomain shift often leads to performance degradation when models are applied to\nunseen clinical domains. This challenge arises due to variations in imaging\nconditions, scanner types, and acquisition protocols, limiting the practical\ndeployment of segmentation models. Unlike natural images, medical images\ntypically exhibit consistent anatomical structures across patients, with\ndomain-specific variations mainly caused by imaging conditions. This unique\ncharacteristic makes medical image segmentation particularly challenging.\n  To address this challenge, we propose a domain generalization framework\ntailored for medical image segmentation. Our approach improves robustness to\ndomain-specific variations by introducing implicit feature perturbations guided\nby domain statistics. Specifically, we employ a learnable semantic direction\nselector and a covariance-based semantic intensity sampler to modulate\ndomain-variant features while preserving task-relevant anatomical consistency.\nFurthermore, we design an adaptive consistency constraint that is selectively\napplied only when feature adjustment leads to degraded segmentation\nperformance. This constraint encourages the adjusted features to align with the\noriginal predictions, thereby stabilizing feature selection and improving the\nreliability of the segmentation.\n  Extensive experiments on two public multi-center benchmarks show that our\nframework consistently outperforms existing domain generalization approaches,\nachieving robust and generalizable segmentation performance across diverse\nclinical domains.", "published": "2025-07-31 08:14:26", "link": "http://arxiv.org/abs/2507.23326v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World Models", "abstract": "Lane segment topology reasoning provides comprehensive bird's-eye view (BEV)\nroad scene understanding, which can serve as a key perception module in\nplanning-oriented end-to-end autonomous driving systems. Existing lane topology\nreasoning methods often fall short in effectively leveraging temporal\ninformation to enhance detection and reasoning performance. Recently,\nstream-based temporal propagation method has demonstrated promising results by\nincorporating temporal cues at both the query and BEV levels. However, it\nremains limited by over-reliance on historical queries, vulnerability to pose\nestimation failures, and insufficient temporal propagation. To overcome these\nlimitations, we propose FASTopoWM, a novel fast-slow lane segment topology\nreasoning framework augmented with latent world models. To reduce the impact of\npose estimation failures, this unified framework enables parallel supervision\nof both historical and newly initialized queries, facilitating mutual\nreinforcement between the fast and slow systems. Furthermore, we introduce\nlatent query and BEV world models conditioned on the action latent to propagate\nthe state representations from past observations to the current timestep. This\ndesign substantially improves the performance of temporal perception within the\nslow pipeline. Extensive experiments on the OpenLane-V2 benchmark demonstrate\nthat FASTopoWM outperforms state-of-the-art methods in both lane segment\ndetection (37.4% v.s. 33.6% on mAP) and centerline perception (46.3% v.s. 41.5%\non OLS).", "published": "2025-07-31 08:12:56", "link": "http://arxiv.org/abs/2507.23325v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models", "abstract": "Text-to-image diffusion models have demonstrated remarkable capabilities in\ngenerating artistic content by learning from billions of images, including\npopular artworks. However, the fundamental question of how these models\ninternally represent concepts, such as content and style in paintings, remains\nunexplored. Traditional computer vision assumes content and style are\northogonal, but diffusion models receive no explicit guidance about this\ndistinction during training. In this work, we investigate how transformer-based\ntext-to-image diffusion models encode content and style concepts when\ngenerating artworks. We leverage cross-attention heatmaps to attribute pixels\nin generated images to specific prompt tokens, enabling us to isolate image\nregions influenced by content-describing versus style-describing tokens. Our\nfindings reveal that diffusion models demonstrate varying degrees of\ncontent-style separation depending on the specific artistic prompt and style\nrequested. In many cases, content tokens primarily influence object-related\nregions while style tokens affect background and texture areas, suggesting an\nemergent understanding of the content-style distinction. These insights\ncontribute to our understanding of how large-scale generative models internally\nrepresent complex artistic concepts without explicit supervision. We share the\ncode and dataset, together with an exploratory tool for visualizing attention\nmaps at https://github.com/umilISLab/artistic-prompt-interpretation.", "published": "2025-07-31 07:47:01", "link": "http://arxiv.org/abs/2507.23313v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Forgetting of task-specific knowledge in model merging-based continual learning", "abstract": "This paper investigates the linear merging of models in the context of\ncontinual learning (CL). Using controlled visual cues in computer vision\nexperiments, we demonstrate that merging largely preserves or enhances shared\nknowledge, while unshared task-specific knowledge rapidly degrades. We further\nfind that merging models from an incremental training process consistently\noutperforms merging models trained in parallel.", "published": "2025-07-31 07:45:08", "link": "http://arxiv.org/abs/2507.23311v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PriorFusion: Unified Integration of Priors for Robust Road Perception in Autonomous Driving", "abstract": "With the growing interest in autonomous driving, there is an increasing\ndemand for accurate and reliable road perception technologies. In complex\nenvironments without high-definition map support, autonomous vehicles must\nindependently interpret their surroundings to ensure safe and robust\ndecision-making. However, these scenarios pose significant challenges due to\nthe large number, complex geometries, and frequent occlusions of road elements.\nA key limitation of existing approaches lies in their insufficient exploitation\nof the structured priors inherently present in road elements, resulting in\nirregular, inaccurate predictions. To address this, we propose PriorFusion, a\nunified framework that effectively integrates semantic, geometric, and\ngenerative priors to enhance road element perception. We introduce an\ninstance-aware attention mechanism guided by shape-prior features, then\nconstruct a data-driven shape template space that encodes low-dimensional\nrepresentations of road elements, enabling clustering to generate anchor points\nas reference priors. We design a diffusion-based framework that leverages these\nprior anchors to generate accurate and complete predictions. Experiments on\nlarge-scale autonomous driving datasets demonstrate that our method\nsignificantly improves perception accuracy, particularly under challenging\nconditions. Visualization results further confirm that our approach produces\nmore accurate, regular, and coherent predictions of road elements.", "published": "2025-07-31 07:43:19", "link": "http://arxiv.org/abs/2507.23309v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ST-SAM: SAM-Driven Self-Training Framework for Semi-Supervised Camouflaged Object Detection", "abstract": "Semi-supervised Camouflaged Object Detection (SSCOD) aims to reduce reliance\non costly pixel-level annotations by leveraging limited annotated data and\nabundant unlabeled data. However, existing SSCOD methods based on\nTeacher-Student frameworks suffer from severe prediction bias and error\npropagation under scarce supervision, while their multi-network architectures\nincur high computational overhead and limited scalability. To overcome these\nlimitations, we propose ST-SAM, a highly annotation-efficient yet concise\nframework that breaks away from conventional SSCOD constraints. Specifically,\nST-SAM employs Self-Training strategy that dynamically filters and expands\nhigh-confidence pseudo-labels to enhance a single-model architecture, thereby\nfundamentally circumventing inter-model prediction bias. Furthermore, by\ntransforming pseudo-labels into hybrid prompts containing domain-specific\nknowledge, ST-SAM effectively harnesses the Segment Anything Model's potential\nfor specialized tasks to mitigate error accumulation in self-training.\nExperiments on COD benchmark datasets demonstrate that ST-SAM achieves\nstate-of-the-art performance with only 1\\% labeled data, outperforming existing\nSSCOD methods and even matching fully supervised methods. Remarkably, ST-SAM\nrequires training only a single network, without relying on specific models or\nloss functions. This work establishes a new paradigm for annotation-efficient\nSSCOD. Codes will be available at https://github.com/hu-xh/ST-SAM.", "published": "2025-07-31 07:41:30", "link": "http://arxiv.org/abs/2507.23307v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Training-free Geometric Image Editing on Diffusion Models", "abstract": "We tackle the task of geometric image editing, where an object within an\nimage is repositioned, reoriented, or reshaped while preserving overall scene\ncoherence. Previous diffusion-based editing methods often attempt to handle all\nrelevant subtasks in a single step, proving difficult when transformations\nbecome large or structurally complex. We address this by proposing a decoupled\npipeline that separates object transformation, source region inpainting, and\ntarget region refinement. Both inpainting and refinement are implemented using\na training-free diffusion approach, FreeFine. In experiments on our new\nGeoBench benchmark, which contains both 2D and 3D editing scenarios, FreeFine\noutperforms state-of-the-art alternatives in image fidelity, and edit\nprecision, especially under demanding transformations. Code and benchmark are\navailable at: https://github.com/CIawevy/FreeFine", "published": "2025-07-31 07:36:00", "link": "http://arxiv.org/abs/2507.23300v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LED Benchmark: Diagnosing Structural Layout Errors for Document Layout Analysis", "abstract": "Recent advancements in Document Layout Analysis through Large Language Models\nand Multimodal Models have significantly improved layout detection. However,\ndespite these improvements, challenges remain in addressing critical structural\nerrors, such as region merging, splitting, and missing content. Conventional\nevaluation metrics like IoU and mAP, which focus primarily on spatial overlap,\nare insufficient for detecting these errors. To address this limitation, we\npropose Layout Error Detection (LED), a novel benchmark designed to evaluate\nthe structural robustness of document layout predictions. LED defines eight\nstandardized error types, and formulates three complementary tasks: error\nexistence detection, error type classification, and element-wise error type\nclassification. Furthermore, we construct LED-Dataset, a synthetic dataset\ngenerated by injecting realistic structural errors based on empirical\ndistributions from DLA models. Experimental results across a range of LMMs\nreveal that LED effectively differentiates structural understanding\ncapabilities, exposing modality biases and performance trade-offs not visible\nthrough traditional metrics.", "published": "2025-07-31 07:22:49", "link": "http://arxiv.org/abs/2507.23295v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval", "abstract": "Text-Video Retrieval aims to find the most relevant text (or video) candidate\ngiven a video (or text) query from large-scale online databases. Recent work\nleverages multi-modal large language models (MLLMs) to improve retrieval,\nespecially for long or complex query-candidate pairs. However, we observe that\nthe naive application of MLLMs, i.e., retrieval based on candidate likelihood,\nintroduces candidate prior bias, favoring candidates with inherently higher\npriors over those more relevant to the query. To this end, we propose a novel\nretrieval framework, Bidirectional Likelihood Estimation with MLLM (BLiM),\nwhich leverages both query and candidate likelihoods by training the model to\ngenerate text from a given video as well as video features from a given text.\nFurthermore, we introduce Candidate Prior Normalization (CPN), a simple yet\neffective training-free score calibration module designed to mitigate candidate\nprior bias in candidate likelihood. On four Text-Video Retrieval benchmarks,\nour BLiM equipped with CPN outperforms previous state-of-the-art models by 6.4\nR@1 on average, effectively alleviating candidate prior bias and emphasizing\nquery-candidate relevance. Our in-depth analysis across various multi-modal\ntasks beyond retrieval highlights the broad applicability of CPN which enhances\nvisual understanding by reducing reliance on textual priors. Code is available\nat https://github.com/mlvlab/BLiM.", "published": "2025-07-31 06:57:28", "link": "http://arxiv.org/abs/2507.23284v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing", "abstract": "In this paper, we propose UniLIP, which extends CLIP to reconstruction,\ngeneration and editing, thereby building a unified tokenizer upon its\nexceptional comprehension capabilities. Previous CLIP-based unified methods\noften require additional diffusion decoders or quantization to support\nreconstruction and generation tasks, leading to inconsistent reconstruction or\ndegradation of original comprehension performance.In contrast, we introduce a\ntwo-stage training scheme and a self-distillation strategy that progressively\nintegrates reconstruction capabilities into CLIP, allowing it to maintain\noriginal comprehension performance while achieving effective image\nreconstruction. Furthermore, we propose a dual-condition architecture to\nconnect the MLLM and diffusion transformer, using both learnable queries and\nthe last layer multimodal hidden states as joint conditions. This method not\nonly enables the utilization of the MLLM's strong reasoning capabilities in\ngeneration tasks, but also maximizes the exploitation of the rich information\nin UniLIP features during editing tasks. In text-to-image generation tasks,\nUniLIP obtains scores of 0.87 and 0.53 on GenEval and WISE benchmark\nrespectively, surpassing all previous unified models of similar scale. In image\nediting, UniLIP also achieves a score of 3.62 on the ImgEdit Benchmark,\nsurpassing recent state-of-the-art models such as BAGEL and UniWorld-V1. UniLIP\neffectively expand the application scope of CLIP, enabling continuous CLIP\nfeatures to not only serve as the optimal choice for understanding tasks but\nalso achieve highly competitive performance in generation and editing tasks.", "published": "2025-07-31 06:35:03", "link": "http://arxiv.org/abs/2507.23278v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "iLRM: An Iterative Large 3D Reconstruction Model", "abstract": "Feed-forward 3D modeling has emerged as a promising approach for rapid and\nhigh-quality 3D reconstruction. In particular, directly generating explicit 3D\nrepresentations, such as 3D Gaussian splatting, has attracted significant\nattention due to its fast and high-quality rendering, as well as numerous\napplications. However, many state-of-the-art methods, primarily based on\ntransformer architectures, suffer from severe scalability issues because they\nrely on full attention across image tokens from multiple input views, resulting\nin prohibitive computational costs as the number of views or image resolution\nincreases. Toward a scalable and efficient feed-forward 3D reconstruction, we\nintroduce an iterative Large 3D Reconstruction Model (iLRM) that generates 3D\nGaussian representations through an iterative refinement mechanism, guided by\nthree core principles: (1) decoupling the scene representation from input-view\nimages to enable compact 3D representations; (2) decomposing fully-attentional\nmulti-view interactions into a two-stage attention scheme to reduce\ncomputational costs; and (3) injecting high-resolution information at every\nlayer to achieve high-fidelity reconstruction. Experimental results on widely\nused datasets, such as RE10K and DL3DV, demonstrate that iLRM outperforms\nexisting methods in both reconstruction quality and speed. Notably, iLRM\nexhibits superior scalability, delivering significantly higher reconstruction\nquality under comparable computational cost by efficiently leveraging a larger\nnumber of input views.", "published": "2025-07-31 06:33:07", "link": "http://arxiv.org/abs/2507.23277v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting", "abstract": "While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic mapping,\nconventional approaches based on camera sensor, even RGB-D, suffer from\nfundamental limitations such as high computational load, failure in\nenvironments with poor texture or illumination, and short operational ranges.\nLiDAR emerges as a robust alternative, but its integration with 3DGS introduces\nnew challenges, such as the need for exceptional global alignment for\nphotorealistic quality and prolonged optimization times caused by sparse data.\nTo address these challenges, we propose GSFusion, an online\nLiDAR-Inertial-Visual mapping system that ensures high-precision map\nconsistency through a surfel-to-surfel constraint in the global pose-graph\noptimization. To handle sparse data, our system employs a pixel-aware Gaussian\ninitialization strategy for efficient representation and a bounded sigmoid\nconstraint to prevent uncontrolled Gaussian growth. Experiments on public and\nour datasets demonstrate our system outperforms existing 3DGS SLAM systems in\nterms of rendering quality and map-building efficiency.", "published": "2025-07-31 06:15:51", "link": "http://arxiv.org/abs/2507.23273v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "PixNerd: Pixel Neural Field Diffusion", "abstract": "The current success of diffusion transformers heavily depends on the\ncompressed latent space shaped by the pre-trained variational autoencoder(VAE).\nHowever, this two-stage training paradigm inevitably introduces accumulated\nerrors and decoding artifacts. To address the aforementioned problems,\nresearchers return to pixel space at the cost of complicated cascade pipelines\nand increased token complexity. In contrast to their efforts, we propose to\nmodel the patch-wise decoding with neural field and present a single-scale,\nsingle-stage, efficient, end-to-end solution, coined as pixel neural field\ndiffusion~(PixelNerd). Thanks to the efficient neural field representation in\nPixNerd, we directly achieved 2.15 FID on ImageNet $256\\times256$ and 2.84 FID\non ImageNet $512\\times512$ without any complex cascade pipeline or VAE. We also\nextend our PixNerd framework to text-to-image applications. Our PixNerd-XXL/16\nachieved a competitive 0.73 overall score on the GenEval benchmark and 80.9\noverall score on the DPG benchmark.", "published": "2025-07-31 06:07:20", "link": "http://arxiv.org/abs/2507.23268v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Semantic-Aware Threshold for Multi-Label Image Recognition with Partial Labels", "abstract": "Multi-label image recognition with partial labels (MLR-PL) is designed to\ntrain models using a mix of known and unknown labels. Traditional methods rely\non semantic or feature correlations to create pseudo-labels for unidentified\nlabels using pre-set thresholds. This approach often overlooks the varying\nscore distributions across categories, resulting in inaccurate and incomplete\npseudo-labels, thereby affecting performance. In our study, we introduce the\nSemantic-Aware Threshold Learning (SATL) algorithm. This innovative approach\ncalculates the score distribution for both positive and negative samples within\neach category and determines category-specific thresholds based on these\ndistributions. These distributions and thresholds are dynamically updated\nthroughout the learning process. Additionally, we implement a differential\nranking loss to establish a significant gap between the score distributions of\npositive and negative samples, enhancing the discrimination of the thresholds.\nComprehensive experiments and analysis on large-scale multi-label datasets,\nsuch as Microsoft COCO and VG-200, demonstrate that our method significantly\nimproves performance in scenarios with limited labels.", "published": "2025-07-31 05:54:10", "link": "http://arxiv.org/abs/2507.23263v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan Africa using MedNeXt V2 with Deep Supervision", "abstract": "Brain cancer affects millions worldwide, and in nearly every clinical\nsetting, doctors rely on magnetic resonance imaging (MRI) to diagnose and\nmonitor gliomas. However, the current standard for tumor quantification through\nmanual segmentation of multi-parametric MRI is time-consuming, requires expert\nradiologists, and is often infeasible in under-resourced healthcare systems.\nThis problem is especially pronounced in low-income regions, where MRI scanners\nare of lower quality and radiology expertise is scarce, leading to incorrect\nsegmentation and quantification. In addition, the number of acquired MRI scans\nin Africa is typically small. To address these challenges, the BraTS-Lighthouse\n2025 Challenge focuses on robust tumor segmentation in sub-Saharan Africa\n(SSA), where resource constraints and image quality degradation introduce\nsignificant shifts. In this study, we present EMedNeXt -- an enhanced brain\ntumor segmentation framework based on MedNeXt V2 with deep supervision and\noptimized post-processing pipelines tailored for SSA. EMedNeXt introduces three\nkey contributions: a larger region of interest, an improved nnU-Net v2-based\narchitectural skeleton, and a robust model ensembling system. Evaluated on the\nhidden validation set, our solution achieved an average LesionWise DSC of 0.897\nwith an average LesionWise NSD of 0.541 and 0.84 at a tolerance of 0.5 mm and\n1.0 mm, respectively.", "published": "2025-07-31 05:30:19", "link": "http://arxiv.org/abs/2507.23256v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Towards Measuring and Modeling Geometric Structures in Time Series Forecasting via Image Modality", "abstract": "Time Series forecasting is critical in diverse domains such as weather\nforecasting, financial investment, and traffic management. While traditional\nnumerical metrics like mean squared error (MSE) can quantify point-wise\naccuracy, they fail to evaluate the geometric structure of time series data,\nwhich is essential to understand temporal dynamics. To address this issue, we\npropose the time series Geometric Structure Index (TGSI), a novel evaluation\nmetric that transforms time series into images to leverage their inherent\ntwo-dimensional geometric representations. However, since the image\ntransformation process is non-differentiable, TGSI cannot be directly\nintegrated as a training loss. We further introduce the Shape-Aware Temporal\nLoss (SATL), a multi-component loss function operating in the time series\nmodality to bridge this gap and enhance structure modeling during training.\nSATL combines three components: a first-order difference loss that measures\nstructural consistency through the MSE between first-order differences, a\nfrequency domain loss that captures essential periodic patterns using the Fast\nFourier Transform while minimizing noise, and a perceptual feature loss that\nmeasures geometric structure difference in time-series by aligning temporal\nfeatures with geometric structure features through a pre-trained temporal\nfeature extractor and time-series image autoencoder. Experiments across\nmultiple datasets demonstrate that models trained with SATL achieve superior\nperformance in both MSE and the proposed TGSI metrics compared to baseline\nmethods, without additional computational cost during inference.", "published": "2025-07-31 05:21:13", "link": "http://arxiv.org/abs/2507.23253v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Deep Dive into Generic Object Tracking: A Survey", "abstract": "Generic object tracking remains an important yet challenging task in computer\nvision due to complex spatio-temporal dynamics, especially in the presence of\nocclusions, similar distractors, and appearance variations. Over the past two\ndecades, a wide range of tracking paradigms, including Siamese-based trackers,\ndiscriminative trackers, and, more recently, prominent transformer-based\napproaches, have been introduced to address these challenges. While a few\nexisting survey papers in this field have either concentrated on a single\ncategory or widely covered multiple ones to capture progress, our paper\npresents a comprehensive review of all three categories, with particular\nemphasis on the rapidly evolving transformer-based methods. We analyze the core\ndesign principles, innovations, and limitations of each approach through both\nqualitative and quantitative comparisons. Our study introduces a novel\ncategorization and offers a unified visual and tabular comparison of\nrepresentative methods. Additionally, we organize existing trackers from\nmultiple perspectives and summarize the major evaluation benchmarks,\nhighlighting the fast-paced advancements in transformer-based tracking driven\nby their robust spatio-temporal modeling capabilities.", "published": "2025-07-31 05:19:26", "link": "http://arxiv.org/abs/2507.23251v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automated Mapping the Pathways of Cranial Nerve II, III, V, and VII/VIII: A Multi-Parametric Multi-Stage Diffusion Tractography Atlas", "abstract": "Cranial nerves (CNs) play a crucial role in various essential functions of\nthe human brain, and mapping their pathways from diffusion MRI (dMRI) provides\nvaluable preoperative insights into the spatial relationships between\nindividual CNs and key tissues. However, mapping a comprehensive and detailed\nCN atlas is challenging because of the unique anatomical structures of each CN\npair and the complexity of the skull base environment.In this work, we present\nwhat we believe to be the first study to develop a comprehensive diffusion\ntractography atlas for automated mapping of CN pathways in the human brain. The\nCN atlas is generated by fiber clustering by using the streamlines generated by\nmulti-parametric fiber tractography for each pair of CNs. Instead of disposable\nclustering, we explore a new strategy of multi-stage fiber clustering for\nmultiple analysis of approximately 1,000,000 streamlines generated from the 50\nsubjects from the Human Connectome Project (HCP). Quantitative and visual\nexperiments demonstrate that our CN atlas achieves high spatial correspondence\nwith expert manual annotations on multiple acquisition sites, including the HCP\ndataset, the Multi-shell Diffusion MRI (MDM) dataset and two clinical cases of\npituitary adenoma patients. The proposed CN atlas can automatically identify 8\nfiber bundles associated with 5 pairs of CNs, including the optic nerve CN II,\noculomotor nerve CN III, trigeminal nerve CN V and facial-vestibulocochlear\nnerve CN VII/VIII, and its robustness is demonstrated experimentally. This work\ncontributes to the field of diffusion imaging by facilitating more efficient\nand automated mapping the pathways of multiple pairs of CNs, thereby enhancing\nthe analysis and understanding of complex brain structures through\nvisualization of their spatial relationships with nearby anatomy.", "published": "2025-07-31 05:04:32", "link": "http://arxiv.org/abs/2507.23245v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Ambiguity-Guided Learnable Distribution Calibration for Semi-Supervised Few-Shot Class-Incremental Learning", "abstract": "Few-Shot Class-Incremental Learning (FSCIL) focuses on models learning new\nconcepts from limited data while retaining knowledge of previous classes.\nRecently, many studies have started to leverage unlabeled samples to assist\nmodels in learning from few-shot samples, giving rise to the field of\nSemi-supervised Few-shot Class-Incremental Learning (Semi-FSCIL). However,\nthese studies often assume that the source of unlabeled data is only confined\nto novel classes of the current session, which presents a narrow perspective\nand cannot align well with practical scenarios. To better reflect real-world\nscenarios, we redefine Semi-FSCIL as Generalized Semi-FSCIL (GSemi-FSCIL) by\nincorporating both base and all the ever-seen novel classes in the unlabeled\nset. This change in the composition of unlabeled samples poses a new challenge\nfor existing methods, as they struggle to distinguish between unlabeled samples\nfrom base and novel classes. To address this issue, we propose an\nAmbiguity-guided Learnable Distribution Calibration (ALDC) strategy. ALDC\ndynamically uses abundant base samples to correct biased feature distributions\nfor few-shot novel classes. Experiments on three benchmark datasets show that\nour method outperforms existing works, setting new state-of-the-art results.", "published": "2025-07-31 04:29:49", "link": "http://arxiv.org/abs/2507.23237v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Toward Safe, Trustworthy and Realistic Augmented Reality User Experience", "abstract": "As augmented reality (AR) becomes increasingly integrated into everyday life,\nensuring the safety and trustworthiness of its virtual content is critical. Our\nresearch addresses the risks of task-detrimental AR content, particularly that\nwhich obstructs critical information or subtly manipulates user perception. We\ndeveloped two systems, ViDDAR and VIM-Sense, to detect such attacks using\nvision-language models (VLMs) and multimodal reasoning modules. Building on\nthis foundation, we propose three future directions: automated, perceptually\naligned quality assessment of virtual content; detection of multimodal attacks;\nand adaptation of VLMs for efficient and user-centered deployment on AR\ndevices. Overall, our work aims to establish a scalable, human-aligned\nframework for safeguarding AR experiences and seeks feedback on perceptual\nmodeling, multimodal AR content implementation, and lightweight model\nadaptation.", "published": "2025-07-31 03:42:52", "link": "http://arxiv.org/abs/2507.23226v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "YOLO-ROC: A High-Precision and Ultra-Lightweight Model for Real-Time Road Damage Detection", "abstract": "Road damage detection is a critical task for ensuring traffic safety and\nmaintaining infrastructure integrity. While deep learning-based detection\nmethods are now widely adopted, they still face two core challenges: first, the\ninadequate multi-scale feature extraction capabilities of existing networks for\ndiverse targets like cracks and potholes, leading to high miss rates for\nsmall-scale damage; and second, the substantial parameter counts and\ncomputational demands of mainstream models, which hinder their deployment for\nefficient, real-time detection in practical applications. To address these\nissues, this paper proposes a high-precision and lightweight model, YOLO - Road\nOrthogonal Compact (YOLO-ROC). We designed a Bidirectional Multi-scale Spatial\nPyramid Pooling Fast (BMS-SPPF) module to enhance multi-scale feature\nextraction and implemented a hierarchical channel compression strategy to\nreduce computational complexity. The BMS-SPPF module leverages a bidirectional\nspatial-channel attention mechanism to improve the detection of small targets.\nConcurrently, the channel compression strategy reduces the parameter count from\n3.01M to 0.89M and GFLOPs from 8.1 to 2.6. Experiments on the\nRDD2022_China_Drone dataset demonstrate that YOLO-ROC achieves a mAP50 of\n67.6%, surpassing the baseline YOLOv8n by 2.11%. Notably, the mAP50 for the\nsmall-target D40 category improved by 16.8%, and the final model size is only\n2.0 MB. Furthermore, the model exhibits excellent generalization performance on\nthe RDD2022_China_Motorbike dataset.", "published": "2025-07-31 03:35:19", "link": "http://arxiv.org/abs/2507.23225v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Arbitrary-Scale RAW Image Downscaling with Wavelet-based Recurrent Reconstruction", "abstract": "Image downscaling is critical for efficient storage and transmission of\nhigh-resolution (HR) images. Existing learning-based methods focus on\nperforming downscaling within the sRGB domain, which typically suffers from\nblurred details and unexpected artifacts. RAW images, with their unprocessed\nphotonic information, offer greater flexibility but lack specialized\ndownscaling frameworks. In this paper, we propose a wavelet-based recurrent\nreconstruction framework that leverages the information lossless attribute of\nwavelet transformation to fulfill the arbitrary-scale RAW image downscaling in\na coarse-to-fine manner, in which the Low-Frequency Arbitrary-Scale Downscaling\nModule (LASDM) and the High-Frequency Prediction Module (HFPM) are proposed to\npreserve structural and textural integrity of the reconstructed low-resolution\n(LR) RAW images, alongside an energy-maximization loss to align high-frequency\nenergy between HR and LR domain. Furthermore, we introduce the Realistic\nNon-Integer RAW Downscaling (Real-NIRD) dataset, featuring a non-integer\ndownscaling factor of 1.3$\\times$, and incorporate it with publicly available\ndatasets with integer factors (2$\\times$, 3$\\times$, 4$\\times$) for\ncomprehensive benchmarking arbitrary-scale image downscaling purposes.\nExtensive experiments demonstrate that our method outperforms existing\nstate-of-the-art competitors both quantitatively and visually. The code and\ndataset will be released at https://github.com/RenYangSCU/ASRD.", "published": "2025-07-31 03:17:10", "link": "http://arxiv.org/abs/2507.23219v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Confidence-aware agglomeration classification and segmentation of 2D microscopic food crystal images", "abstract": "Food crystal agglomeration is a phenomenon occurs during crystallization\nwhich traps water between crystals and affects food product quality. Manual\nannotation of agglomeration in 2D microscopic images is particularly difficult\ndue to the transparency of water bonding and the limited perspective focusing\non a single slide of the imaged sample. To address this challenge, we first\npropose a supervised baseline model to generate segmentation pseudo-labels for\nthe coarsely labeled classification dataset. Next, an instance classification\nmodel that simultaneously performs pixel-wise segmentation is trained. Both\nmodels are used in the inference stage to combine their respective strengths in\nclassification and segmentation. To preserve crystal properties, a post\nprocessing module is designed and included to both steps. Our method improves\ntrue positive agglomeration classification accuracy and size distribution\npredictions compared to other existing methods. Given the variability in\nconfidence levels of manual annotations, our proposed method is evaluated under\ntwo confidence levels and successfully classifies potential agglomerated\ninstances.", "published": "2025-07-31 03:02:50", "link": "http://arxiv.org/abs/2507.23206v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adversarial-Guided Diffusion for Multimodal LLM Attacks", "abstract": "This paper addresses the challenge of generating adversarial image using a\ndiffusion model to deceive multimodal large language models (MLLMs) into\ngenerating the targeted responses, while avoiding significant distortion of the\nclean image. To address the above challenges, we propose an adversarial-guided\ndiffusion (AGD) approach for adversarial attack MLLMs. We introduce\nadversarial-guided noise to ensure attack efficacy. A key observation in our\ndesign is that, unlike most traditional adversarial attacks which embed\nhigh-frequency perturbations directly into the clean image, AGD injects target\nsemantics into the noise component of the reverse diffusion. Since the added\nnoise in a diffusion model spans the entire frequency spectrum, the adversarial\nsignal embedded within it also inherits this full-spectrum property.\nImportantly, during reverse diffusion, the adversarial image is formed as a\nlinear combination of the clean image and the noise. Thus, when applying\ndefenses such as a simple low-pass filtering, which act independently on each\ncomponent, the adversarial image within the noise component is less likely to\nbe suppressed, as it is not confined to the high-frequency band. This makes AGD\ninherently robust to variety defenses. Extensive experiments demonstrate that\nour AGD outperforms state-of-the-art methods in attack performance as well as\nin model robustness to some defenses.", "published": "2025-07-31 02:57:20", "link": "http://arxiv.org/abs/2507.23202v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Novel Dataset for Flood Detection Robust to Seasonal Changes in Satellite Imagery", "abstract": "This study introduces a novel dataset for segmenting flooded areas in\nsatellite images. After reviewing 77 existing benchmarks utilizing satellite\nimagery, we identified a shortage of suitable datasets for this specific task.\nTo fill this gap, we collected satellite imagery of the 2019 Midwestern USA\nfloods from Planet Explorer by Planet Labs (Image \\c{opyright} 2024 Planet Labs\nPBC). The dataset consists of 10 satellite images per location, each containing\nboth flooded and non-flooded areas. We selected ten locations from each of the\nfive states: Iowa, Kansas, Montana, Nebraska, and South Dakota. The dataset\nensures uniform resolution and resizing during data processing. For evaluating\nsemantic segmentation performance, we tested state-of-the-art models in\ncomputer vision and remote sensing on our dataset. Additionally, we conducted\nan ablation study varying window sizes to capture temporal characteristics.\nOverall, the models demonstrated modest results, suggesting a requirement for\nfuture multimodal and temporal learning strategies. The dataset will be\npublicly available on\n<https://github.com/youngsunjang/SDSU_MidWest_Flood_2019>.", "published": "2025-07-31 02:26:23", "link": "http://arxiv.org/abs/2507.23193v1", "categories": ["cs.CV", "I.4.6; I.2.10; I.5.4"], "primary_category": "cs.CV"}
{"title": "Multi-Modal Motion Retrieval by Learning a Fine-Grained Joint Embedding Space", "abstract": "Motion retrieval is crucial for motion acquisition, offering superior\nprecision, realism, controllability, and editability compared to motion\ngeneration. Existing approaches leverage contrastive learning to construct a\nunified embedding space for motion retrieval from text or visual modality.\nHowever, these methods lack a more intuitive and user-friendly interaction mode\nand often overlook the sequential representation of most modalities for\nimproved retrieval performance. To address these limitations, we propose a\nframework that aligns four modalities -- text, audio, video, and motion --\nwithin a fine-grained joint embedding space, incorporating audio for the first\ntime in motion retrieval to enhance user immersion and convenience. This\nfine-grained space is achieved through a sequence-level contrastive learning\napproach, which captures critical details across modalities for better\nalignment. To evaluate our framework, we augment existing text-motion datasets\nwith synthetic but diverse audio recordings, creating two multi-modal motion\nretrieval datasets. Experimental results demonstrate superior performance over\nstate-of-the-art methods across multiple sub-tasks, including an 10.16%\nimprovement in R@10 for text-to-motion retrieval and a 25.43% improvement in\nR@1 for video-to-motion retrieval on the HumanML3D dataset. Furthermore, our\nresults show that our 4-modal framework significantly outperforms its 3-modal\ncounterpart, underscoring the potential of multi-modal motion retrieval for\nadvancing motion acquisition.", "published": "2025-07-31 01:59:38", "link": "http://arxiv.org/abs/2507.23188v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Nyldon Factorization of Thue-Morse Words and Fibonacci Words", "abstract": "The Nyldon factorization is a string factorization that is a non-decreasing\nproduct of Nyldon words. Nyldon words and Nyldon factorizations are recently\ndefined combinatorial objects inspired by the well-known Lyndon words and\nLyndon factorizations. In this paper, we investigate the Nyldon factorization\nof several words. First, we fully characterize the Nyldon factorizations of the\n(finite) Fibonacci and the (finite) Thue-Morse words. Moreover, we show that\nthere exists a non-decreasing product of Nyldon words that is a factorization\nof the infinite Thue-Morse word.", "published": "2025-07-31 15:37:36", "link": "http://arxiv.org/abs/2507.23659v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "On a better complexity upper bound of Ward-Szabo theorem", "abstract": "Ward and Szab\\'o [WS94] have shown that a complete graph with $N^2$ nodes\nwhose edges are colored by $N$ colors and that has at least two colors contains\na bichromatic triangle. This fact leads us to a total search problem: Given an\nedge-coloring on a complete graph with N2 nodes using at least two colors and\nat most N colors, find a bichromatic triangle. Bourneuf, Folwarczn\\'y,\nHub\\'acek, Rosen, and Schwartzbach [Bou+23] have proven that such a total\nsearch problem, called Ward-Szab\\'o, is PWPP-hard and belongs to the class\nTFNP, a class for total search problems in which the correctness of every\ncandidate solution is efficiently verifiable. However, it is open which TFNP\nsubclass contains Ward-Szab\\'o. This paper will improve the complexity upper\nbound of Ward-Szab\\'o. We prove that Ward-Szab\\'o is in belongs to the\ncomplexity class PPP, a TFNP subclass of problems in which the pigeonhole\nprinciple guarantees the existence of solutions.", "published": "2025-07-31 08:50:40", "link": "http://arxiv.org/abs/2507.23345v1", "categories": ["cs.CC", "cs.DM"], "primary_category": "cs.CC"}
{"title": "Towards LLM-Enhanced Product Line Scoping", "abstract": "The idea of product line scoping is to identify the set of features and\nconfigurations that a product line should include, i.e., offer for\nconfiguration purposes. In this context, a major scoping task is to find a\nbalance between commercial relevance and technical feasibility. Traditional\nproduct line scoping approaches rely on formal feature models and require a\nmanual analysis which can be quite time-consuming. In this paper, we sketch how\nLarge Language Models (LLMs) can be applied to support product line scoping\ntasks with a natural language interaction based scoping process. Using a\nworking example from the smarthome domain, we sketch how LLMs can be applied to\nevaluate different feature model alternatives. We discuss open research\nchallenges regarding the integration of LLMs with product line scoping.", "published": "2025-07-31 10:33:47", "link": "http://arxiv.org/abs/2507.23410v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Your Spending Needs Attention: Modeling Financial Habits with Transformers", "abstract": "Predictive models play a crucial role in the financial industry, enabling\nrisk prediction, fraud detection, and personalized recommendations, where\nslight changes in core model performance can result in billions of dollars in\nrevenue or losses. While financial institutions have access to enormous amounts\nof user data (e.g., bank transactions, in-app events, and customer support\nlogs), leveraging this data effectively remains challenging due to its\ncomplexity and scale. Thus, in many financial institutions, most production\nmodels follow traditional machine learning (ML) approaches by converting\nunstructured data into manually engineered tabular features. Conversely, other\ndomains (e.g., natural language processing) have effectively utilized\nself-supervised learning (SSL) to learn rich representations from raw data,\nremoving the need for manual feature extraction. In this paper, we investigate\nusing transformer-based representation learning models for transaction data,\nhypothesizing that these models, trained on massive data, can provide a novel\nand powerful approach to understanding customer behavior. We propose a new\nmethod enabling the use of SSL with transaction data by adapting\ntransformer-based models to handle both textual and structured attributes. Our\napproach, denoted nuFormer, includes an end-to-end fine-tuning method that\nintegrates user embeddings with existing tabular features. Our experiments\ndemonstrate improvements for large-scale recommendation problems at Nubank.\nNotably, these gains are achieved solely through enhanced representation\nlearning rather than incorporating new data sources.", "published": "2025-07-31 05:56:21", "link": "http://arxiv.org/abs/2507.23267v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Cellular, Cell-less, and Everything in Between: A Unified Framework for Utility Region Analysis in Wireless Networks", "abstract": "We introduce a unified framework for analyzing utility regions of wireless\nnetworks, with a focus on the signal-to-interference-noise-ratio (SINR) and\nachievable rate regions. The framework provides valuable insights into\ninterference patterns of modern network architectures, such as cell-less and\nextremely large MIMO networks, and it generalizes existing characterizations of\nthe weak Pareto boundary. A central contribution is the derivation of\nsufficient conditions that guarantee convexity of the utility regions.\nConvexity is an important property because it ensures that time sharing (or\nuser grouping) cannot simultaneously increase the utility of all users when the\nnetwork operates on the weak Pareto boundary. These sufficient conditions also\nhave two key implications. First, they identify a family of (weighted) sum-rate\nmaximization problems that are inherently convex without any variable\ntransformations, thus paving the way for the development of efficient, provably\noptimal solvers for this family. Second, they provide a rigorous justification\nfor formulating sum-rate maximization problems directly in terms of achievable\nrates, rather than SINR levels. Our theoretical insights also motivate an\nalternative to the concept of favorable propagation in the massive MIMO\nliterature -- one that explicitly accounts for self-interference and the\nbeamforming strategy.", "published": "2025-07-31 16:27:45", "link": "http://arxiv.org/abs/2507.23707v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Cell-Free Massive MIMO SWIPT with Beyond Diagonal Reconfigurable Intelligent Surfaces", "abstract": "We investigate the integration of beyond diagonal reconfigurable intelligent\nsurfaces (BDRISs) into cell free massive multiple input multiple output\n(CFmMIMO) systems to enhance simultaneous wireless information and power\ntransfer (SWIPT). To simultaneously support two groups of users energy\nreceivers (ERs) and information receivers (IRs) without sacrificing time\nfrequency resources, a subset of access points (APs) is dedicated to serving\nERs with the aid of a BDRIS, while the remaining APs focus on supporting IRs. A\nprotective partial zero forcing precoding technique is implemented at the APs\nto manage the non coherent interference between the ERs and IRs. Subsequently,\nclosed form expressions for the spectral efficiency of the IRs and the average\nsum of harvested energy at the ERs are leveraged to formulate a comprehensive\noptimization problem. This problem jointly optimizes the AP selection, AP power\ncontrol, and scattering matrix design at the BDRIS, all based on long term\nstatistical channel state information. This challenging problem is then\neffectively transformed into more tractable forms. To solve these sub problems,\nefficient algorithms are proposed, including a heuristic search for the\nscattering matrix design, as well as successive convex approximation and deep\nreinforcement learning methods for the joint AP mode selection and power\ncontrol design. Numerical results show that a BDRIS with a group or fully\nconnected architecture achieves significant energy harvesting gains over the\nconventional diagonal RIS, especially delivering up to a seven fold increase in\nthe average sum of harvested energy when a heuristic based scattering matrix\ndesign is employed.", "published": "2025-07-31 16:24:28", "link": "http://arxiv.org/abs/2507.23702v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "From Link Diversity to Cross-Band Feedback Collaboration: A New Perspective on Hybrid Optical-RF Systems", "abstract": "We suggest a re-examination of the conventional view that hybrid\noptical-radio frequency (O-RF) systems are primarily diversity-driven networks\nthat switch between RF and optical links for robustness. Instead, we uncover a\nnew architectural opportunity: repurposing the optical downlink to enable\nreal-time feedback channel coding over the RF uplink, where structured decoder\nfeedback is delivered from the access point to guide the transmitter's coding\nstrategy. This insight marks a conceptual paradigm shift from passive link\ndiversity to active cross-band collaboration, where the wideband,\ninterference-free optical wireless communication (OWC) is no longer merely a\ndownlink backup but a functional enabler of uplink reliability. To realize this\nvision, we propose a novel architecture, O-RF with Cross-Band Feedback\n(O-RF-CBF), that exploits the optical downlink feedback to facilitate adaptive\nRF uplink coding. Numerical results reveal that O-RF-CBF achieves significant\nuplink throughput gains over traditional O-RF systems. Our findings highlight\nthat inter-band synergy, not redundancy, is the key to unlocking the full\npotential of hybrid wireless networks.", "published": "2025-07-31 16:03:57", "link": "http://arxiv.org/abs/2507.23686v1", "categories": ["cs.IT", "cs.SY", "eess.SY", "math.IT"], "primary_category": "cs.IT"}
{"title": "Hybrid Generative Semantic and Bit Communications in Satellite Networks: Trade-offs in Latency, Generation Quality, and Computation", "abstract": "As satellite communications play an increasingly important role in future\nwireless networks, the issue of limited link budget in satellite systems has\nattracted significant attention in current research. Although semantic\ncommunications emerge as a promising solution to address these constraints, it\nintroduces the challenge of increased computational resource consumption in\nwireless communications. To address these challenges, we propose a multi-layer\nhybrid bit and generative semantic communication framework which can adapt to\nthe dynamic satellite communication networks. Furthermore, to balance the\nsemantic communication efficiency and performance in satellite-to-ground\ntransmissions, we introduce a novel semantic communication efficiency metric\n(SEM) that evaluates the trade-offs among latency, computational consumption,\nand semantic reconstruction quality in the proposed framework. Moreover, we\nutilize a novel deep reinforcement learning (DRL) algorithm group relative\npolicy optimization (GRPO) to optimize the resource allocation in the proposed\nnetwork. Simulation results demonstrate the flexibility of our proposed\ntransmission framework and the effectiveness of the proposed metric SEM,\nillustrate the relationships among various semantic communication metrics.", "published": "2025-07-31 13:12:24", "link": "http://arxiv.org/abs/2507.23528v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Channel Estimation for 6G Near-Field Wireless Communications: A Comprehensive Survey", "abstract": "The sixth-generation (6G) wireless systems are expected to adopt extremely\nlarge aperture arrays (ELAAs), novel antenna architectures, and operate in\nextremely high-frequency bands to meet growing data demands. ELAAs\nsignificantly increase the number of antennas, enabling finer spatial\nresolution and improved beamforming. At high frequencies, ELAAs shift\ncommunication from the conventional far-field to near-field regime, where\nspherical wavefronts dominate and the channel response depends on both angle\nand distance, increasing channel dimensionality. Conventional far-field channel\nestimation methods, which rely on angular information, struggle in near-field\nscenarios due to increased pilot overhead and computational complexity. This\npaper presents a comprehensive survey of recent advances in near-field channel\nestimation. It first defines the near- and far-field boundary from an\nelectromagnetic perspective and discusses key propagation differences,\nalongside a brief review of ELAA developments. Then, it introduces mainstream\nnear-field channel models and compares them with far-field models. Major\nestimation techniques are reviewed under different configurations\n(single/multi-user, single/multi-carrier), including both direct estimation and\nRIS-assisted cascaded estimation. These techniques reveal trade-offs among\nestimation accuracy, complexity, and overhead. This survey aims to provide\ninsights and foundations for efficient and scalable near-field channel\nestimation in 6G systems, while identifying key challenges and future research\ndirections.", "published": "2025-07-31 13:11:43", "link": "http://arxiv.org/abs/2507.23526v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "From Timestamps to Versions: Version AoI in Single- and Multi-Hop Networks", "abstract": "Timely and informative data dissemination in communication networks is\nessential for enhancing system performance and energy efficiency, as it reduces\nthe transmission of outdated or redundant data. Timeliness metrics, such as Age\nof Information (AoI), effectively quantify data freshness; however, these\nmetrics fail to account for the intrinsic informativeness of the content\nitself. To address this limitation, content-based metrics have been proposed\nthat combine both timeliness and informativeness. Nevertheless, existing\nstudies have predominantly focused on evaluating average metric values, leaving\nthe complete distribution-particularly in multi-hop network scenarios-largely\nunexplored. In this paper, we provide a comprehensive analysis of the\nstationary distribution of the Version Age of Information (VAoI), a\ncontent-based metric, under various scheduling policies, including randomized\nstationary, uniform, and threshold-based policies, with transmission\nconstraints in single-hop and multi-hop networks. We derive closed-form\nexpressions for the stationary distribution and average VAoI under these\nscheduling approaches. Furthermore, for threshold-based scheduling, we\nanalytically determine the optimal threshold value that minimizes VAoI and\nderive the corresponding optimal VAoI in closed form. Numerical evaluations\nverify our analytical findings, providing valuable insights into leveraging\nVAoI in the design of efficient communication networks.", "published": "2025-07-31 11:15:20", "link": "http://arxiv.org/abs/2507.23433v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Exploiting Movable Elements of Intelligent Reflecting Surface for Enhancement of Integrated Sensing and Communication", "abstract": "In this paper, we propose to exploit movable elements of intelligent\nreflecting surface (IRS) to enhance the overall performance of integrated\nsensing and communication (ISAC) systems. Firstly, focusing on a single-user\nscenario, we reveal the function of movable elements by performance analysis,\nand then design a joint beamforming and element position optimization scheme.\nFurther, we extend it to a general multi-user scenario, and also propose an\nelement position optimization scheme according to the derived performance\nexpressions. Finally, simulation results confirm that the movement of IRS\nelements can improve the communication rate and the sensing accuracy, and\nespecially broaden the coverage of ISAC.", "published": "2025-07-31 07:25:16", "link": "http://arxiv.org/abs/2507.23296v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Secure Integrated Sensing and Communication Networks: Stochastic Performance Analysis", "abstract": "This paper analyzes the stochastic security performance of a multiple-input\nmultiple-output (MIMO) integrated sensing and communication (ISAC) system in a\ndownlink scenario. A base station (BS) transmits a multi-functional signal to\nsimultaneously communicate with a user, sense a target's angular location, and\ncounteract eavesdropping threats. The attack model considers a passive\nsingle-antenna communication eavesdropper intercepting communication data, as\nwell as a multi-antenna sensing eavesdropper attempting to infer the target's\nlocation. We also consider a malicious target scenario where the target plays\nthe role of the communication eavesdropper. The BS-user and BS-eavesdroppers\nchannels follow Rayleigh fading, while the target's azimuth angle is uniformly\ndistributed. To evaluate the performance in this random network, we derive the\nergodic secrecy rate (ESR) and the ergodic Cramer-Rao lower bound (CRB), for\ntarget localization, at both the BS and the sensing eavesdropper. This involves\ncomputing the probability density functions (PDFs) of the signal-to-noise ratio\n(SNR) and CRB, leveraging the central limit theorem for tractability. We\ncharacterize the boundary of the CRB-secrecy rate region, and interpret the\nperformance tradeoffs between communication and sensing while guaranteeing a\nlevel of security and privacy in the random ISAC networks.", "published": "2025-07-31 04:13:20", "link": "http://arxiv.org/abs/2507.23234v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Efficient DFT of Zadoff-Chu Sequences using lmFH Pattern", "abstract": "Having established that Zadoff-Chu (ZC) sequences are inherently linear\nmicro-frequency hopping (lmFH) symbols, this paper first presents an intuitive\nand visual exposition of the computation of the DFT and IDFT of ZC sequences\nusing the lmFH pattern. This yields interesting results. Subsequently, an\nalternative form for computing the cumulative sum of ZC sequences using the\nGeneralized Quadratic Gauss Sum is introduced. Furthermore, building on the\nmicro-frequency hopping (mFH) concept, this paper shows that the DFT of ZC\nsequences can be transformed into an lmFH symbol with frequency shift and phase\noffset. Therefore, the DFT of ZC sequences can be computed via cumulative\nfrequency points, similar to the computation of normal mFH symbols.", "published": "2025-07-31 02:50:18", "link": "http://arxiv.org/abs/2507.23200v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Construction of Near-optimal Universal Coding of Integers", "abstract": "Universal Coding of Integers (UCI) is suitable for discrete memoryless\nsources with unknown probability distributions and infinitely countable\nalphabet sizes. The UCI is a class of prefix codes, such that the ratio of the\naverage codeword length to $\\max\\{1, H(P)\\}$ is within a constant expansion\nfactor $K_{\\mathcal{C}}$ for any decreasing probability distribution $P$, where\n$H(P)$ is the entropy of $P$. For any UCI code $\\mathcal{C}$, define \\emph{the\nminimum expansion factor} $K_{\\mathcal{C}}^{*}$ to represent the infimum of the\nset of extension factors of $\\mathcal{C}$. Each $\\mathcal{C}$ has a unique\ncorresponding $K_{\\mathcal{C}}^{*}$, and the smaller $K_{\\mathcal{C}}^{*}$ is,\nthe better the compression performance of $\\mathcal{C}$ is. A class of UCI\n$\\mathcal{C}$ (or family $\\{\\mathcal{C}_i\\}_{i=1}^{\\infty}$) achieving the\nsmallest $K_{\\mathcal{C}}^{*}$ is defined as the \\emph{optimal UCI}. The best\nresult currently is that the range of $C_{\\mathcal{C}}^{*}$ for the optimal UCI\nis $2\\leq C_{\\mathcal{C}}^{*}\\leq 2.5$. In this paper, we prove that there\nexists a class of near-optimal UCIs, called $\\nu$ code, to achieve\n$K_\\nu=2.0386$. This narrows the range of the minimum expansion factor for\noptimal UCI to $2\\leq C_{\\mathcal{C}}^{*}\\leq 2.0386$. Another new class of\nUCI, called $\\Delta\\delta$ code, is specifically constructed. We show that the\n$\\Delta\\delta$ code and $\\nu$ code are currently optimal in terms of minimum\nexpansion factor. In addition, we propose a new proof that shows the minimum\nexpansion factor of the optimal UCI is lower bounded by $2$.", "published": "2025-07-31 01:21:06", "link": "http://arxiv.org/abs/2507.23180v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cyclotomy, cyclotomic cosets and arimetic propeties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$", "abstract": "Arithmetic properties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle\nx^{p^sq^t}-1\\rangle}$ are obtained by using the cyclotomic classes of order 2\nwith respect to $n=p^sq^t$, where $p\\equiv3 \\mathrm{mod} 4$,\n$\\gcd(\\phi(p^s),\\phi(q^t))=2$, $l$ is a primitive root modulo $q^t$ and\n$\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$. The form of these cyclotomic classes\nenables us to further generalize the results obtained in \\cite{ref1}. The\nexplicit expressions of primitive idempotents of minimal ideals in\n$\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ are also obtained.", "published": "2025-07-31 01:19:47", "link": "http://arxiv.org/abs/2507.23179v1", "categories": ["math.NT", "cs.IT", "math.IT"], "primary_category": "math.NT"}
{"title": "Optimal compressed sensing for mixing stochastic processes", "abstract": "Jalali and Poor introduced an asymptotic framework for compressed sensing of\nstochastic processes, demonstrating that any rate strictly greater than the\nmean information dimension serves as an upper bound on the number of random\nlinear measurements required for (universal) almost lossless recovery of\n$\\psi^*$-mixing processes, as measured in the normalized $L^2$ norm. In this\nwork, we show that if the normalized number of random linear measurements is\nstrictly less than the mean information dimension, then almost lossless\nrecovery of a $\\psi^*$-mixing process is impossible by any sequence of\ndecompressors. This establishes the mean information dimension as the\nfundamental limit for compressed sensing in this setting (and, in fact, the\nprecise threshold for the problem). To this end, we introduce a new quantity,\nrelated to techniques from geometric measure theory: the correlation dimension\nrate, which is shown to be a lower bound for compressed sensing of arbitrary\nstationary stochastic processes.", "published": "2025-07-31 01:04:21", "link": "http://arxiv.org/abs/2507.23175v1", "categories": ["cs.IT", "math.DS", "math.IT", "math.PR", "68P30, 94A29, 31E05, 37A35, 60G10"], "primary_category": "cs.IT"}
{"title": "Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity", "abstract": "Agent-based simulations have an enormous potential as tools to evaluate\nsocial policies in a non-invasive way, before these are implemented to\nreal-world populations. However, the recommendations that these computational\napproaches may offer to tackle urgent human development challenges can vary\nsubstantially depending on how we model agents' (people) behaviour and the\ncriteria that we use to measure inequity. In this paper, we integrate the\nconceptual framework of the capability approach (CA), which is explicitly\ndesigned to promote and assess human well-being, to guide the simulation and\nevaluate the effectiveness of policies. We define a reinforcement learning\nenvironment where agents behave to restore their capabilities under the\nconstraints of a specific policy. Working in collaboration with local\nstakeholders, non-profits and domain experts, we apply our model in a case\nstudy to mitigate health inequity among the population experiencing\nhomelessness (PEH) in Barcelona. By doing so, we present the first proof of\nconcept simulation, aligned with the CA for human development, to assess the\nimpact of policies under parliamentary discussion.", "published": "2025-07-31 15:23:05", "link": "http://arxiv.org/abs/2507.23644v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Regularization of Inverse Problems by Filtered Diagonal Frame Decomposition under general source", "abstract": "Let $X$ and $Y$ be Hilbert spaces, and $\\mathbf{K}: \\text{dom} \\mathbf{K}\n\\subset X \\to Y$ a bounded linear operator. This paper addresses the inverse\nproblem $\\mathbf{K}x = y$, where exact data $y$ is replaced by noisy data\n$y^\\delta$ satisfying $\\|y^\\delta - y\\|_Y \\leq \\delta$. Due to the\nill-posedness of such problems, we employ regularization methods to stabilize\nsolutions. While singular value decomposition (SVD) provides a classical\napproach, its computation can be costly and impractical for certain operators.\nWe explore alternatives via Diagonal Frame Decomposition (DFD), generalizing\nSVD-based techniques, and introduce a regularized solution $x^\\delta_\\alpha =\n\\sum_{\\lambda \\in \\Lambda} \\kappa_\\lambda g_\\alpha(\\kappa_\\lambda^2) \\langle\ny^\\delta, v_\\lambda \\rangle \\overline{u}_\\lambda$. Convergence rates and\noptimality are analyzed under a generalized source condition\n$\\mathbf{M}_{\\varphi, E} = \\{ x \\in \\text{dom} \\mathbf{K} : \\sum_{\\lambda \\in\n\\Lambda} [\\varphi(\\kappa_\\lambda^2)]^{-1} |\\langle x, u_\\lambda \\rangle|^2 \\leq\nE^2 \\}$. Key questions include constructing DFD systems, relating DFD and SVD\nsingular values, and extending source conditions. We present theoretical\nresults, including modulus of continuity bounds and convergence rates for a\npriori and a posteriori parameter choices, with applications to polynomial and\nexponentially ill-posed problems.", "published": "2025-07-31 15:29:50", "link": "http://arxiv.org/abs/2507.23651v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "A Multi-Frequency Helmholtz Solver Based on the WaveHoltz Algorithm", "abstract": "We develop and analyze a new approach for simultaneously computing multiple\nsolutions to the Helmholtz equation for different frequencies and different\nforcing functions. The new Multi-Frequency WaveHoltz (MFWH) algorithm is an\nextension of the original WaveHoltz method and both are based on time-filtering\nsolutions to an associated wave equation. With MFWH, the different Helmholtz\nsolutions are computed simultaneously by solving a single wave equation\ncombined with multiple time filters. The MFWH algorithm defines a fixed-point\niteration which can be accelerated with Krylov methods such as GMRES. The\nsolution of the wave equation can be efficiently solved with either explicit\ntime-stepping or implicit time-stepping using as few as five time-steps per\nperiod. When combined with an $O(N)$ solver for the implicit equations, such a\nmultigrid, the scheme has an $O(N)$ solution cost when the frequencies are\nfixed and the number of grid points $N$ increases. High-order accurate\napproximations in space are used together with second-order accurate\napproximations in time. We show how to remove time discretization errors so\nthat the MFWH solutions converge to the corresponding solutions to the\ndiscretized Helmholtz problems. Numerical results are given using second-order\naccurate and fourth-accurate discretizations to confirm the convergence theory.", "published": "2025-07-31 14:52:06", "link": "http://arxiv.org/abs/2507.23613v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Efficient Numerical Strategies for Entropy-Regularized Semi-Discrete Optimal Transport", "abstract": "Semi-discrete optimal transport (SOT), which maps a continuous probability\nmeasure to a discrete one, is a fundamental problem with wide-ranging\napplications. Entropic regularization is often employed to solve the SOT\nproblem, leading to a regularized (RSOT) formulation that can be solved\nefficiently via its convex dual. However, a significant computational challenge\nemerges when the continuous source measure is discretized via the finite\nelement (FE) method to handle complex geometries or densities, such as those\narising from solutions to Partial Differential Equations (PDEs). The evaluation\nof the dual objective function requires dense interactions between the numerous\nsource quadrature points and all target points, creating a severe bottleneck\nfor large-scale problems. This paper presents a cohesive framework of numerical\nstrategies to overcome this challenge. We accelerate the dual objective and\ngradient evaluations by combining distance-based truncation with fast spatial\nqueries using R-trees. For overall convergence, we integrate multilevel\ntechniques based on hierarchies of both the FE source mesh and the discrete\ntarget measure, alongside a robust scheduling strategy for the regularization\nparameter. When unified, these methods drastically reduce the computational\ncost of RSOT, enabling its practical application to complex, large-scale\nscenarios. We provide an open-source C++ implementation of this framework,\nbuilt upon the deal.II finite element library, available at\nhttps://github.com/SemiDiscreteOT/SemiDiscreteOT.", "published": "2025-07-31 14:40:43", "link": "http://arxiv.org/abs/2507.23602v1", "categories": ["math.NA", "cs.NA", "65K10, 49Q22, 65M60, 90C25, 65Y20", "G.1.6; I.3.5; G.4"], "primary_category": "math.NA"}
{"title": "Fitted norm preconditioners for the Hodge Laplacian in mixed form", "abstract": "We use the practical framework for abstract perturbed saddle point problems\nrecently introduced by Hong et al. to analyze the mixed formulation of the\nHodge Laplace problem. We compose two parameter-dependent norms in which the\nuniform continuity and stability of the problem follow. This not only\nguarantees the well-posedness of the corresponding variational formulation on\nthe continuous level, but also of related compatible discrete models.\n  We further simplify the obtained norms and, in both cases, arrive at the same\nnorm-equivalent preconditioner that is easily implementable. The efficiency and\nuniformity of the preconditioner are demonstrated numerically by the fast\nconvergence and uniformly bounded number of preconditioned MINRES iterations\nrequired to solve various instances of Hodge Laplace problems in two and three\nspace dimensions.", "published": "2025-07-31 14:20:45", "link": "http://arxiv.org/abs/2507.23586v1", "categories": ["math.NA", "cs.NA", "65N22, 65F08, 35J05, 58J10, 65N30, 58A14"], "primary_category": "math.NA"}
{"title": "Quantum simulation of Helmholtz equations via Schr{\u00f6}dingerization", "abstract": "The Helmholtz equation is a prototypical model for time-harmonic wave\npropagation. Numerical solutions become increasingly challenging as the wave\nnumber $k$ grows, due to the equation's elliptic yet noncoercive character and\nthe highly oscillatory nature of its solutions, with wavelengths scaling as\n$1/k$. These features lead to strong indefiniteness and large system sizes.\n  We present a quantum algorithm for solving such indefinite problems, built\nupon the Schr\\\"odingerization framework. This approach reformulates linear\ndifferential equations into Schr\\\"odinger-type systems by capturing the steady\nstate of damped dynamics. A warped phase transformation lifts the original\nproblem to a higher-dimensional formulation, making it compatible with quantum\ncomputation. To suppress numerical pollution, the algorithm incorporates\nasymptotic dispersion correction. It achieves a query complexity of\n$\\mathcal{O}(\\kappa^2\\text{polylog}\\varepsilon^{-1})$, where $\\kappa$ is the\ncondition number and $\\varepsilon$ the desired accuracy. For the Helmholtz\nequation, a simple preconditioner further reduces the complexity to\n$\\mathcal{O}(\\kappa\\text{polylog}\\varepsilon^{-1})$. Our constructive extension\nto the quantum setting is broadly applicable to all indefinite problems.", "published": "2025-07-31 13:38:23", "link": "http://arxiv.org/abs/2507.23547v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Rational complex Bezier curves", "abstract": "In this paper we develop the formalism of rational complex Bezier curves.\nThis framework is a simple extension of the CAD paradigm, since it describes\narc of curves in terms of control polygons and weights, which are extended to\ncomplex values. One of the major advantages of this extension is that we may\nmake use of two different groups of projective transformations. Besides the\ngroup of projective transformations of the real plane, we have the group of\ncomplex projective transformations. This allows us to apply useful\ntransformations like the geometric inversion to curves in design. In addition\nto this, the use of the complex formulation allows to lower the degree of the\ncurves in some cases. This can be checked using the resultant of two\npolynomials and provides a simple formula for determining whether a rational\ncubic curve is a conic or not. Examples of application of the formalism to\nclassical curves are included.", "published": "2025-07-31 12:08:50", "link": "http://arxiv.org/abs/2507.23485v1", "categories": ["math.NA", "cs.GR", "cs.NA", "65D17, 68U07"], "primary_category": "math.NA"}
{"title": "The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG Source Localization", "abstract": "EEG Source localization is a critical tool in neuroscience, with applications\nranging from epilepsy diagnosis to cognitive research. It involves solving an\nill-posed inverse problem that lacks a unique solution unless constrained by\nprior knowledge. The Bayesian framework enables the incorporation of such\nknowledge, typically encoded through prior models. Various algorithms have been\nproposed for source localization, and they differ significantly in how prior\nknowledge is incorporated. Some approaches rely on anatomical or functional\nconstraints, while others use statistical distributions or sampling-based\ntechniques. In this landscape, the Standardized Kalman Filter (SKF) represents\na dynamic Bayesian approach that integrates temporal modeling with a Gaussian\nprior structure. It addresses the depth bias, a common limitation in source\nlocalization, through a post-hoc standardization step that equalizes\nsensitivity across cortical depths and makes deep activity detection feasible.\n  This study focuses on the development and optimization of Gaussian prior\nmodels within the SKF framework for simultaneous cortical and sub-cortical\nactivity detection. Synthetic data similar to the P20 / N20 component of the\nsomatosensory evoked potentials (SEP) was used to identify effective prior\nparameter configurations for reconstructing both deep and superficial sources\nunder different noise levels. We also investigated the role of RTS smoothing in\nenhancing source separability. Our results indicate that raising the\nstandardization exponent to 1.25, along with smoothing, significantly improves\ndepth localization accuracy at low noise levels.", "published": "2025-07-31 11:27:02", "link": "http://arxiv.org/abs/2507.23450v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An optimal preconditioner for high-order scheme arising from multi-dimensional Riesz space fractional diffusion equations with variable coefficients", "abstract": "In this paper, we propose an efficient method for solving multi-dimensional\nRiesz space fractional diffusion equations with variable coefficients. The\nCrank-Nicolson (CN) method is used for temporal discretization, while the\nfourth-order fractional centered difference (4FCD) method is employed for\nspatial discretization. Using a novel technique, we show that the CN-4FCD\nscheme for the multi-dimensional case is unconditionally stable and convergent,\nachieving second-order accuracy in time and fourth-order accuracy in space with\nrespect to the discrete L2-norm. Moreover, leveraging the symmetric multi-level\nToeplitz-like structure of the coefficient matrix in the discrete linear\nsystems, we enhance the computational efficiency of the proposed scheme with a\nsine transform-based preconditioner, ensuring a mesh-size-independent\nconvergence rate for the conjugate gradient method. Finally, two numerical\nexamples validate the theoretical analysis and demonstrate the superior\nperformance of the proposed preconditioner compared to existing methods.", "published": "2025-07-31 10:30:28", "link": "http://arxiv.org/abs/2507.23408v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Improved Analysis of Khatri-Rao Random Projections and Applications", "abstract": "Randomization has emerged as a powerful set of tools for large-scale matrix\nand tensor decompositions. Randomized algorithms involve computing sketches\nwith random matrices. A prevalent approach is to take the random matrix as a\nstandard Gaussian random matrix, for which the theory is well developed.\nHowever, this approach has the drawback that the cost of generating and\nmultiplying by the random matrix can be prohibitively expensive. Khatri-Rao\nrandom projections (KRPs), obtained by sketching with Khatri-Rao products of\nrandom matrices, offer a viable alternative and are much cheaper to generate.\nHowever, the theoretical guarantees of using KRPs are much more pessimistic\ncompared to their accuracy observed in practice. We attempt to close this gap\nby obtaining improved analysis of the use of KRPs in matrix and tensor low-rank\ndecompositions. We propose and analyze a new algorithm for low-rank\napproximations of block-structured matrices (e.g., block Hankel) using KRPs. We\nalso develop new algorithms to accelerate tensor computations in the Tucker\nformat using KRPs, and give theoretical guarantees of the resulting low-rank\napproximations. Numerical experiments on synthetic and real-world tensors show\nthe computational benefits of the proposed methods.", "published": "2025-07-31 03:02:52", "link": "http://arxiv.org/abs/2507.23207v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Error analysis of the projected PO method with additive inflation for the partially observed Lorenz 96 model", "abstract": "We consider the filtering problem with the partially observed Lorenz 96\nmodel. Although the accuracy of the 3DVar filter applied to this problem has\nbeen established, that of the EnKF has not yet been. This study aims to\nestablish the error bound of a variant of the EnKF, known as the PO method. By\nintroducing the additive inflation and a projection of the background\ncovariance to the observation space, we establish the error bound of the PO\nmethod. A numerical example validates theoretical findings and shows the\npotential to extend the analysis.", "published": "2025-07-31 02:48:08", "link": "http://arxiv.org/abs/2507.23199v1", "categories": ["math.NA", "cs.NA", "math.DS", "62M20, 62F15, 35R30, 93C55, 65C05"], "primary_category": "math.NA"}
{"title": "$hp$-adaptive finite element simulation of a static anti-plane shear crack in a nonlinear strain-limiting elastic solid", "abstract": "An $hp$-adaptive continuous Galerkin finite element method is developed to\nanalyze a static anti-plane shear crack embedded in a nonlinear,\nstrain-limiting elastic body. The geometrically linear material is described by\na constitutive law relating stress and strain that is algebraically nonlinear.\nIn this investigation, the constitutive relation utilized is \\textit{uniformly\nbounded}, \\textit{monotone}, \\textit{coercive}, and \\textit{Lipschitz\ncontinuous}, ensuring the well-posedness of the mathematical model. The\ngoverning equation, derived from the balance of linear momentum coupled with\nthe nonlinear constitutive relationship, is formulated as a second-order\nquasi-linear elliptic partial differential equation. For a body with an edge\ncrack, this governing equation is augmented with a classical traction-free\nboundary condition on the crack faces. An $hp$-adaptive finite element scheme\nis proposed for the numerical approximation of the resulting boundary value\nproblem. The adaptive strategy is driven by a dual-component error estimation\nscheme: mesh refinement ($h$-adaptivity) is guided by a residual-based a\nposteriori error indicator of the \\textit{Kelly type}, while the local\npolynomial degree ($p$-adaptivity) is adjusted based on an estimator of the\nlocal solution regularity. The performance, accuracy, and convergence\ncharacteristics of the proposed method are demonstrated through numerical\nexperiments. The structure of the regularized crack-tip fields is examined for\nvarious modeling parameters. Furthermore, the presented framework establishes a\nrobust foundation for extension to more complex and computationally demanding\nproblems, including quasi-static and dynamic crack propagation in brittle\nmaterials.", "published": "2025-07-31 02:37:35", "link": "http://arxiv.org/abs/2507.23195v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Identifying Hearing Difficulty Moments in Conversational Audio", "abstract": "Individuals regularly experience Hearing Difficulty Moments in everyday\nconversation. Identifying these moments of hearing difficulty has particular\nsignificance in the field of hearing assistive technology where timely\ninterventions are key for realtime hearing assistance. In this paper, we\npropose and compare machine learning solutions for continuously detecting\nutterances that identify these specific moments in conversational audio. We\nshow that audio language models, through their multimodal reasoning\ncapabilities, excel at this task, significantly outperforming a simple ASR\nhotword heuristic and a more conventional fine-tuning approach with Wav2Vec, an\naudio-only input architecture that is state-of-the-art for automatic speech\nrecognition (ASR).", "published": "2025-07-31 14:26:57", "link": "http://arxiv.org/abs/2507.23590v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Real-time Generation of Various Types of Nodding for Avatar Attentive Listening System", "abstract": "In human dialogue, nonverbal information such as nodding and facial\nexpressions is as crucial as verbal information, and spoken dialogue systems\nare also expected to express such nonverbal behaviors. We focus on nodding,\nwhich is critical in an attentive listening system, and propose a model that\npredicts both its timing and type in real time. The proposed model builds on\nthe voice activity projection (VAP) model, which predicts voice activity from\nboth listener and speaker audio. We extend it to prediction of various types of\nnodding in a continuous and real-time manner unlike conventional models. In\naddition, the proposed model incorporates multi-task learning with verbal\nbackchannel prediction and pretraining on general dialogue data. In the timing\nand type prediction task, the effectiveness of multi-task learning was\nsignificantly demonstrated. We confirmed that reducing the processing rate\nenables real-time operation without a substantial drop in accuracy, and\nintegrated the model into an avatar attentive listening system. Subjective\nevaluations showed that it outperformed the conventional method, which always\ndoes nodding in sync with verbal backchannel. The code and trained models are\navailable at https://github.com/MaAI-Kyoto/MaAI.", "published": "2025-07-31 07:34:32", "link": "http://arxiv.org/abs/2507.23298v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "CUHK-EE Systems for the vTAD Challenge at NCMMSC 2025", "abstract": "This paper presents the Voice Timbre Attribute Detection (vTAD) systems\ndeveloped by the Digital Signal Processing & Speech Technology Laboratory\n(DSP&STL) of the Department of Electronic Engineering (EE) at The Chinese\nUniversity of Hong Kong (CUHK) for the 20th National Conference on\nHuman-Computer Speech Communication (NCMMSC 2025) vTAD Challenge. The proposed\nsystems leverage WavLM-Large embeddings with attentive statistical pooling to\nextract robust speaker representations, followed by two variants of Diff-Net,\ni.e., Feed-Forward Neural Network (FFN) and Squeeze-and-Excitation-enhanced\nResidual FFN (SE-ResFFN), to compare timbre attribute intensities between\nutterance pairs. Experimental results demonstrate that the WavLM-Large+FFN\nsystem generalises better to unseen speakers, achieving 77.96% accuracy and\n21.79% EER, while the WavLM-Large+SE-ResFFN model excels in the 'Seen' setting\nwith 94.42% accuracy and 5.49% EER. These findings highlight a trade-off\nbetween model complexity and generalisation, and underscore the importance of\narchitectural choices in fine-grained speaker modelling. Our analysis also\nreveals the impact of speaker identity, annotation subjectivity, and data\nimbalance on system performance, pointing to future directions for improving\nrobustness and fairness in timbre attribute detection.", "published": "2025-07-31 05:55:16", "link": "http://arxiv.org/abs/2507.23266v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Feature Importance across Domains for Improving Non-Intrusive Speech Intelligibility Prediction in Hearing Aids", "abstract": "Given the critical role of non-intrusive speech intelligibility assessment in\nhearing aids (HA), this paper enhances its performance by introducing Feature\nImportance across Domains (FiDo). We estimate feature importance on spectral\nand time-domain acoustic features as well as latent representations of Whisper.\nImportance weights are calculated per frame, and based on these weights,\nfeatures are projected into new spaces, allowing the model to focus on\nimportant areas early. Next, feature concatenation is performed to combine the\nfeatures before the assessment module processes them. Experimental results show\nthat when FiDo is incorporated into the improved multi-branched speech\nintelligibility model MBI-Net+, RMSE can be reduced by 7.62% (from 26.10 to\n24.11). MBI-Net+ with FiDo also achieves a relative RMSE reduction of 3.98%\ncompared to the best system in the 2023 Clarity Prediction Challenge. These\nresults validate FiDo's effectiveness in enhancing neural speech assessment in\nHA.", "published": "2025-07-31 03:34:55", "link": "http://arxiv.org/abs/2507.23223v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Real-Time Transmission of Uncompressed High-Definition Video Via A VCSEL-Based Optical Wireless Link With Ultra-Low Latency", "abstract": "Real-time transmission of high-resolution video signals in an uncompressed\nand unencrypted format requires an ultra-reliable and low-latency\ncommunications (URLLC) medium with high bandwidth to maintain the quality of\nexperience (QoE) for users. We put forward the design and experimental\ndemonstration of a high-performance laser-based optical wireless communication\n(OWC) system that enables high-definition (HD) video transmission with\nsubmillisecond latencies. The serial digital interface (SDI) output of a camera\nis used to transmit the live video stream over an optical wireless link by\ndirectly modulating the SDI signal on the intensity of a 940 nm vertical cavity\nsurface emitting laser (VCSEL). The proposed SDI over light fidelity (LiFi)\nsystem corroborates error-free transmission of full HD (FHD) and 4K\nultra-high-definition (UHD) resolutions at data rates of 2.97 Gb/s and 5.94\nGb/s, respectively, with a measured end-to-end latency of under 35 ns. Since\nSDI standards support various video formats and VCSELs are high-bandwidth and\nlow-power devices, this presents a scalable and inexpensive solution for\nwireless connectivity between professional broadcast equipment using\noff-the-shelf SDI components.", "published": "2025-07-31 17:34:07", "link": "http://arxiv.org/abs/2507.23746v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On the Achievable Rate of Satellite Quantum Communication Channel using Deep Autoencoder Gaussian Mixture Model", "abstract": "We present a comparative study of the Gaussian mixture model (GMM) and the\nDeep Autoencoder Gaussian Mixture Model (DAGMM) for estimating satellite\nquantum channel capacity, considering hybrid quantum noise (HQN) and\ntransmission constraints. While GMM is simple and interpretable, DAGMM better\ncaptures non-linear variations and noise distributions. Simulations show that\nDAGMM provides tighter capacity bounds and improved clustering. This introduces\nthe Deep Cluster Gaussian Mixture Model (DCGMM) for high-dimensional quantum\ndata analysis in quantum satellite communication.", "published": "2025-07-31 16:13:42", "link": "http://arxiv.org/abs/2507.23695v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Impact of a Lower Limb Exosuit Anchor Points on Energetics and Biomechanics", "abstract": "Anchor point placement is a crucial yet often overlooked aspect of exosuit\ndesign since it determines how forces interact with the human body. This work\nanalyzes the impact of different anchor point positions on gait kinematics,\nmuscular activation and energetic consumption. A total of six experiments were\nconducted with 11 subjects wearing the XoSoft exosuit, which assists hip\nflexion in five configurations. Subjects were instrumented with an IMU-based\nmotion tracking system, EMG sensors, and a mask to measure metabolic\nconsumption. The results show that positioning the knee anchor point on the\nposterior side while keeping the hip anchor on the anterior part can reduce\nmuscle activation in the hip flexors by up to 10.21\\% and metabolic expenditure\nby up to 18.45\\%. Even if the only assisted joint was the hip, all the\nconfigurations introduced changes also in the knee and ankle kinematics.\nOverall, no single configuration was optimal across all subjects, suggesting\nthat a personalized approach is necessary to transmit the assistance forces\noptimally. These findings emphasize that anchor point position does indeed have\na significant impact on exoskeleton effectiveness and efficiency. However,\nthese optimal positions are subject-specific to the exosuit design, and there\nis a strong need for future work to tailor musculoskeletal models to individual\ncharacteristics and validate these results in clinical populations.", "published": "2025-07-31 14:08:25", "link": "http://arxiv.org/abs/2507.23579v1", "categories": ["physics.med-ph", "cs.RO", "eess.SP"], "primary_category": "physics.med-ph"}
{"title": "Multiple-Parameter Graph Fractional Fourier Transform: Theory and Applications", "abstract": "The graph fractional Fourier transform (GFRFT) applies a single global\nfractional order to all graph frequencies, which restricts its adaptability to\ndiverse signal characteristics across the spectral domain. To address this\nlimitation, in this paper, we propose two types of multiple-parameter GFRFTs\n(MPGFRFTs) and establish their corresponding theoretical frameworks. We design\na spectral compression strategy tailored for ultra-low compression ratios,\neffectively preserving essential information even under extreme dimensionality\nreduction. To enhance flexibility, we introduce a learnable order vector scheme\nthat enables adaptive compression and denoising, demonstrating strong\nperformance on both graph signals and images. We explore the application of\nMPGFRFTs to image encryption and decryption. Experimental results validate the\nversatility and superior performance of the proposed MPGFRFT framework across\nvarious graph signal processing tasks.", "published": "2025-07-31 14:01:15", "link": "http://arxiv.org/abs/2507.23570v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Networked Physical Computing: A New Paradigm for Effective Task Completion via Hypergraph Aided Trusted Task-Resource Matching", "abstract": "Due to the diverse physical attributes of computing resources and tasks,\ndeveloping effective mechanisms to facilitate task and resource matching in\ncomplex connected systems for value-oriented task completion has become\nincreasingly challenging. To address the challenge, this paper proposes a\nnetworked physical computing system that integrates the physical attributes of\ncomputing resources and tasks as well as task-specific trust relationships\namong devices to enable value-driven task completion. Specifically, we propose\na state-of-the-art hypergraph-aided trusted task-resource matching\n(TTR-matching) framework to achieve the envisioned physical computing. First, a\ntask-specific trusted physical resource hypergraph is defined, which integrates\ntask-specific trust, the physical attributes of resources, and task types. This\nenables accurate modeling of device collaboration dependencies under specific\ntask types. Next, a task hypergraph is generated to associate the task\ninitiator with the physical attributes of the corresponding tasks. Based on\nthese two hypergraphs, a hypergraph matching algorithm is designed to\nfacilitate task-specific trusted collaborator selection and accurate\ntask-resource matching for value-maximizing task completion. Extensive\nexperimental results demonstrate that the proposed TTR-matching framework\noutperforms comparison algorithms in identifying task-specific trustworthy\ncollaborators and maximizing the average value of task completion.", "published": "2025-07-31 13:45:27", "link": "http://arxiv.org/abs/2507.23556v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "EVMx: An FPGA-Based Smart Contract Processing Unit", "abstract": "Ethereum blockchain uses smart contracts (SCs) to implement decentralized\napplications (dApps). SCs are executed by the Ethereum virtual machine (EVM)\nrunning within an Ethereum client. Moreover, the EVM has been widely adopted by\nother blockchain platforms, including Solana, Cardano, Avalanche, Polkadot, and\nmore. However, the EVM performance is limited by the constraints of the\ngeneral-purpose computer it operates on. This work proposes offloading SC\nexecution onto a dedicated hardware-based EVM. Specifically, EVMx is an\nFPGA-based SC execution engine that benefits from the inherent parallelism and\nhigh-speed processing capabilities of a hardware architecture. Synthesis\nresults demonstrate a reduction in execution time of 61% to 99% for commonly\nused operation codes compared to CPU-based SC execution environments. Moreover,\nthe execution time of Ethereum blocks on EVMx is up to 6x faster compared to\nanalogous works in the literature. These results highlight the potential of the\nproposed architecture to accelerate SC execution and enhance the performance of\nEVM-compatible blockchains.", "published": "2025-07-31 13:01:14", "link": "http://arxiv.org/abs/2507.23518v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "WiRM: Wireless Respiration Monitoring Using Conjugate Multiple Channel State Information and Fast Iterative Filtering in Wi-Fi Systems", "abstract": "Monitoring respiratory health with the use of channel state information (CSI)\nhas shown promising results. Many existing methods focus on monitoring only the\nrespiratory rate, while others focus on monitoring the motion of the chest as a\npatient breathes, which is referred to as the respiratory waveform. This paper\npresents WiRM, a two-staged approach to contactless respiration monitoring. In\nthe first stage, WiRM improves upon existing respiratory rate estimation\ntechniques by using conjugate multiplication for phase sanitisation and\nadaptive multi-trace carving (AMTC) for tracing how the respiratory rate\nchanges over time. When compared against three state-of-the-art methods, WiRM\nhas achieved an average reduction of $38\\%$ in respiratory rate root mean\nsquared error (RMSE). In the second stage, WiRM uses this improved respiratory\nrate estimate to inform the decomposition and selection of the respiratory\nwaveform from the CSI data. Remarkably, WiRM delivers a $178.3\\%$ improvement\nin average absolute correlation with the ground truth respiratory waveform.\nWithin the literature, it is difficult to compare the robustness of existing\nalgorithms in noisy environments. In this paper, we develop a purpose-built\nsimulation toolkit to evaluate the robustness of respiration monitoring\nsolutions under various noise conditions, including thermal, multiplicative,\nand phase noise. Our results show that WiRM demonstrates improved or comparable\nresilience to these common noise sources.", "published": "2025-07-31 10:46:56", "link": "http://arxiv.org/abs/2507.23419v1", "categories": ["cs.ET", "eess.SP"], "primary_category": "cs.ET"}
{"title": "A Secure Full-Duplex Wireless Circulator enabled by Non-Reciprocal Beyond-Diagonal RIS", "abstract": "Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has arisen as a\npromising technology for enhancing wireless communication systems by enabling\nflexible and intelligent wave manipulation. This is achieved through the\ninterconnections among the ports of the impedance network, enabling wave\nreconfiguration when they flow through the surface. Thus, the output wave at\none port depends on waves impinging on neighboring ports, allowing non-local\ncontrol of both phase and magnitude. Non-reciprocal (NR)-BD-RIS further\nenhances this capability by breaking circuit reciprocity and, consequently,\nchannel reciprocity. This feature potentially benefits communication among\nnon-aligned transceivers. This paper introduces a novel application of\nNR-BD-RIS in full-duplex (FD) wireless circulators, where multiple FD devices\ncommunicate via an NR-BD-RIS. This system is particularly beneficial for secure\ntransmission, as it enforces one-way communication among FD devices, suppresses\nsignal from all other users, and thus prevents eavesdropping. In addition, a\nphysics-compliant system model is considered by incorporating structural\nscattering, also known as specular reflection. By accounting for this effect,\nthe advantages of NR-BD-RIS are further validated. Specifically, we formulate\nan all-user sum-rate maximization problem and propose an iterative optimization\nalgorithm that employs block coordinate descent (BCD) and penalty dual\ndecomposition (PDD) methods. Numerical evaluations illustrate that NR-BD-RIS\nconsistently outperforms reciprocal (R)-BD-RIS and conventional diagonal\n(D)-RIS in terms of sum-rate performance, particularly when more than two\nimpinging and reflection directions need to be supported. By analyzing the\npower of signals from all other users and the beampatterns, we show that secure\ntransmission can be achieved.", "published": "2025-07-31 09:57:27", "link": "http://arxiv.org/abs/2507.23381v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "BS-1-to-N: Diffusion-Based Environment-Aware Cross-BS Channel Knowledge Map Generation for Cell-Free Networks", "abstract": "Channel knowledge map (CKM) inference across base stations (BSs) is the key\nto achieving efficient environmentaware communications. This paper proposes an\nenvironmentaware cross-BS CKM inference method called BS-1-to-N based on the\ngenerative diffusion model. To this end, we first design the BS location\nembedding (BSLE) method tailored for cross-BS CKM inference to embed BS\nlocation information in the feature vector of CKM. Further, we utilize the\ncross- and self-attention mechanism for the proposed BS-1-to-N model to\nrespectively learn the relationships between source and target BSs, as well as\nthat among target BSs. Therefore, given the locations of the source and target\nBSs, together with the source CKMs as control conditions, cross-BS CKM\ninference can be performed for an arbitrary number of source and target BSs.\nSpecifically, in architectures with massive distributed nodes like cell-free\nnetworks, traditional methods of sequentially traversing each BS for CKM\nconstruction are prohibitively costly. By contrast, the proposed BS-1-to-N\nmodel is able to achieve efficient CKM inference for a target BS at any\npotential location based on the CKMs of source BSs. This is achieved by\nexploiting the fact that within a given area, different BSs share the same\nwireless environment that leads to their respective CKMs. Therefore, similar to\nmulti-view synthesis, CKMs of different BSs are representations of the same\nwireless environment from different BS locations. By mining the implicit\ncorrelation between CKM and BS location based on the wireless environment, the\nproposed BS-1-to-N method achieves efficient CKM inference across BSs. We\nprovide extensive comparisons of CKM inference between the proposed BS-1-to-N\ngenerative model versus benchmarking schemes, and provide one use case study to\ndemonstrate its practical application for the optimization of BS deployment.", "published": "2025-07-31 04:25:59", "link": "http://arxiv.org/abs/2507.23236v1", "categories": ["eess.SP", "eess.IV"], "primary_category": "eess.SP"}
{"title": "In-Orbit Cosmo-SkyMed antenna pattern estimation by a narrowband sweeper receiver", "abstract": "This paper introduces a novel method for antenna pattern estimation in\nsatellites equipped with Synthetic Aperture Radar (SAR), utilizing a Narrowband\nSweeper Receiver (NSR). By accurately measuring power across individual\nfrequencies within SAR's inherently broadband spectrum, the NSR significantly\nenhances antenna pattern extraction accuracy. Analytical models and practical\nexperiments conducted using the Cosmo-SkyMed satellite validate the receiver's\nperformance, demonstrating superior signal-to-noise ratio (SNR) compared to\nconventional receivers. This research represents a key advancement in SAR\ntechnology, offering a robust framework for future satellite calibration and\nverification methodologies.", "published": "2025-07-31 04:13:21", "link": "http://arxiv.org/abs/2507.23235v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "EMORe: Motion-Robust 5D MRI Reconstruction via Expectation-Maximization-Guided Binning Correction and Outlier Rejection", "abstract": "We propose EMORe, an adaptive reconstruction method designed to enhance\nmotion robustness in free-running, free-breathing self-gated 5D cardiac\nmagnetic resonance imaging (MRI). Traditional self-gating-based motion binning\nfor 5D MRI often results in residual motion artifacts due to inaccuracies in\ncardiac and respiratory signal extraction and sporadic bulk motion,\ncompromising clinical utility. EMORe addresses these issues by integrating\nadaptive inter-bin correction and explicit outlier rejection within an\nexpectation-maximization (EM) framework, whereby the E-step and M-step are\nexecuted alternately until convergence. In the E-step, probabilistic (soft) bin\nassignments are refined by correcting misassignment of valid data and rejecting\nmotion-corrupted data to a dedicated outlier bin. In the M-step, the image\nestimate is improved using the refined soft bin assignments. Validation in a\nsimulated 5D MRXCAT phantom demonstrated EMORe's superior performance compared\nto standard compressed sensing reconstruction, showing significant improvements\nin peak signal-to-noise ratio, structural similarity index, edge sharpness, and\nbin assignment accuracy across varying levels of simulated bulk motion. In vivo\nvalidation in 13 volunteers further confirmed EMORe's robustness, significantly\nenhancing blood-myocardium edge sharpness and reducing motion artifacts\ncompared to compressed sensing, particularly in scenarios with controlled\ncoughing-induced motion. Although EMORe incurs a modest increase in\ncomputational complexity, its adaptability and robust handling of bulk motion\nartifacts significantly enhance the clinical applicability and diagnostic\nconfidence of 5D cardiac MRI.", "published": "2025-07-31 03:35:17", "link": "http://arxiv.org/abs/2507.23224v1", "categories": ["eess.IV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization", "abstract": "Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its inherently on-policy strategy with LLM's immense\naction space and sparse reward. Further, RLVR can lead to the capability\nboundary collapse, narrowing the LLM's problem-solving scope. To address this\nproblem, we propose RL-PLUS, a novel approach that synergizes internal\nexploitation (i.e., Thinking) with external data (i.e., Learning) to achieve\nstronger reasoning capabilities and surpass the boundaries of base models.\nRL-PLUS integrates two core components: Multiple Importance Sampling to address\nfor distributional mismatch from external data, and an Exploration-Based\nAdvantage Function to guide the model towards high-value, unexplored reasoning\npaths. We provide both theoretical analysis and extensive experiments to\ndemonstrate the superiority and generalizability of our approach. The results\nshow that RL-PLUS achieves state-of-the-art performance compared with existing\nRLVR methods on six math reasoning benchmarks and exhibits superior performance\non six out-of-distribution reasoning tasks. It also achieves consistent and\nsignificant gains across diverse model families, with average relative\nimprovements ranging from 21.1\\% to 69.2\\%. Moreover, Pass@k curves across\nmultiple benchmarks indicate that RL-PLUS effectively resolves the capability\nboundary collapse problem.", "published": "2025-07-31 23:55:29", "link": "http://arxiv.org/abs/2508.00222v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform", "abstract": "Wavelet transforms, a powerful mathematical tool, have been widely used in\ndifferent domains, including Signal and Image processing, to unravel intricate\npatterns, enhance data representation, and extract meaningful features from\ndata. Tangible results from their application suggest that Wavelet transforms\ncan be applied to NLP capturing a variety of linguistic and semantic\nproperties. In this paper, we empirically leverage the application of Discrete\nWavelet Transforms (DWT) to word and sentence embeddings. We aim to showcase\nthe capabilities of DWT in analyzing embedding representations at different\nlevels of resolution and compressing them while maintaining their overall\nquality. We assess the effectiveness of DWT embeddings on semantic similarity\ntasks to show how DWT can be used to consolidate important semantic information\nin an embedding vector. We show the efficacy of the proposed paradigm using\ndifferent embedding models, including large language models, on downstream\ntasks. Our results show that DWT can reduce the dimensionality of embeddings by\n50-93% with almost no change in performance for semantic similarity tasks,\nwhile achieving superior accuracy in most downstream tasks. Our findings pave\nthe way for applying DWT to improve NLP applications.", "published": "2025-07-31 23:46:40", "link": "http://arxiv.org/abs/2508.00220v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges", "abstract": "Tables have gained significant attention in large language models (LLMs) and\nmultimodal large language models (MLLMs) due to their complex and flexible\nstructure. Unlike linear text inputs, tables are two-dimensional, encompassing\nformats that range from well-structured database tables to complex,\nmulti-layered spreadsheets, each with different purposes. This diversity in\nformat and purpose has led to the development of specialized methods and tasks,\ninstead of universal approaches, making navigation of table understanding tasks\nchallenging. To address these challenges, this paper introduces key concepts\nthrough a taxonomy of tabular input representations and an introduction of\ntable understanding tasks. We highlight several critical gaps in the field that\nindicate the need for further research: (1) the predominance of\nretrieval-focused tasks that require minimal reasoning beyond mathematical and\nlogical operations; (2) significant challenges faced by models when processing\ncomplex table structures, large-scale tables, length context, or multi-table\nscenarios; and (3) the limited generalization of models across different\ntabular representations and formats.", "published": "2025-07-31 23:41:31", "link": "http://arxiv.org/abs/2508.00217v1", "categories": ["cs.CL", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comparison of Large Language Models for Deployment Requirements", "abstract": "Large Language Models (LLMs), such as Generative Pre-trained Transformers\n(GPTs) are revolutionizing the generation of human-like text, producing\ncontextually relevant and syntactically correct content. Despite challenges\nlike biases and hallucinations, these Artificial Intelligence (AI) models excel\nin tasks, such as content creation, translation, and code generation.\nFine-tuning and novel architectures, such as Mixture of Experts (MoE), address\nthese issues. Over the past two years, numerous open-source foundational and\nfine-tuned models have been introduced, complicating the selection of the\noptimal LLM for researchers and companies regarding licensing and hardware\nrequirements. To navigate the rapidly evolving LLM landscape and facilitate LLM\nselection, we present a comparative list of foundational and domain-specific\nmodels, focusing on features, such as release year, licensing, and hardware\nrequirements. This list is published on GitLab and will be continuously\nupdated.", "published": "2025-07-31 22:03:07", "link": "http://arxiv.org/abs/2508.00185v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI", "abstract": "Clinical decision-making relies on the integrated analysis of medical images\nand the associated clinical reports. While Vision-Language Models (VLMs) can\noffer a unified framework for such tasks, they can exhibit strong biases toward\none modality, frequently overlooking critical visual cues in favor of textual\ninformation. In this work, we introduce Selective Modality Shifting (SMS), a\nperturbation-based approach to quantify a model's reliance on each modality in\nbinary classification tasks. By systematically swapping images or text between\nsamples with opposing labels, we expose modality-specific biases. We assess six\nopen-source VLMs-four generalist models and two fine-tuned for medical data-on\ntwo medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)\nand FairVLMed (scanning laser ophthalmoscopy). By assessing model performance\nand the calibration of every model in both unperturbed and perturbed settings,\nwe reveal a marked dependency on text input, which persists despite the\npresence of complementary visual information. We also perform a qualitative\nattention-based analysis which further confirms that image content is often\novershadowed by text details. Our findings highlight the importance of\ndesigning and evaluating multimodal medical models that genuinely integrate\nvisual and textual cues, rather than relying on single-modality signals.", "published": "2025-07-31 21:35:52", "link": "http://arxiv.org/abs/2508.00171v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs", "abstract": "The releases of powerful open-weight large language models (LLMs) are often\nnot accompanied by access to their full training data. Existing\ninterpretability methods, particularly those based on activations, often\nrequire or assume distributionally similar data. This is a significant\nlimitation when detecting and defending against novel potential threats like\nbackdoors, which are by definition out-of-distribution.\n  In this work, we introduce a new method for understanding, monitoring and\ncontrolling fine-tuned LLMs that interprets weights, rather than activations,\nthereby side stepping the need for data that is distributionally similar to the\nunknown training data. We demonstrate that the top singular vectors of the\nweight difference between a fine-tuned model and its base model correspond to\nnewly acquired behaviors. By monitoring the cosine similarity of activations\nalong these directions, we can detect salient behaviors introduced during\nfine-tuning with high precision.\n  For backdoored models that bypasses safety mechanisms when a secret trigger\nis present, our method stops up to 100% of attacks with a false positive rate\nbelow 1.2%. For models that have undergone unlearning, we detect inference on\nerased topics with accuracy up to 95.42% and can even steer the model to\nrecover \"unlearned\" information. Besides monitoring, our method also shows\npotential for pre-deployment model auditing: by analyzing commercial\ninstruction-tuned models (OLMo, Llama, Qwen), we are able to uncover\nmodel-specific fine-tuning focus including marketing strategies and Midjourney\nprompt generation.\n  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.", "published": "2025-07-31 21:04:12", "link": "http://arxiv.org/abs/2508.00161v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Is neural semantic parsing good at ellipsis resolution, or isn't it?", "abstract": "Neural semantic parsers have shown good overall performance for a variety of\nlinguistic phenomena, reaching semantic matching scores of more than 90%. But\nhow do such parsers perform on strongly context-sensitive phenomena, where\nlarge pieces of semantic information need to be duplicated to form a meaningful\nsemantic representation? A case in point is English verb phrase ellipsis, a\nconstruct where entire verb phrases can be abbreviated by a single auxiliary\nverb. Are the otherwise known as powerful semantic parsers able to deal with\nellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with\ntheir fully resolved meaning representation and used this as a challenge set\nfor a large battery of neural semantic parsers. Although these parsers\nperformed very well on the standard test set, they failed in the instances with\nellipsis. Data augmentation", "published": "2025-07-31 19:23:37", "link": "http://arxiv.org/abs/2508.00121v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality", "abstract": "Long-form factuality evaluation assesses the ability of models to generate\naccurate, comprehensive responses to short prompts. Existing benchmarks often\nlack human verification, leading to potential quality issues. To address this\nlimitation, we introduce FACTORY, a large-scale, human-verified prompt set.\nDeveloped using a model-in-the-loop approach and refined by humans, FACTORY\nincludes challenging prompts that are fact-seeking, answerable, and\nunambiguous. We conduct human evaluations on 6 state-of-the-art language models\nusing FACTORY and existing datasets. Our results show that FACTORY is a\nchallenging benchmark: approximately 40% of the claims made in the responses of\nSOTA models are not factual, compared to only 10% for other datasets. Our\nanalysis identifies the strengths of FACTORY over prior benchmarks, emphasizing\nits reliability and the necessity for models to reason across long-tailed\nfacts.", "published": "2025-07-31 19:00:11", "link": "http://arxiv.org/abs/2508.00109v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Semiotic Complexity and Its Epistemological Implications for Modeling Culture", "abstract": "Greater theorizing of methods in the computational humanities is needed for\nepistemological and interpretive clarity, and therefore the maturation of the\nfield. In this paper, we frame such modeling work as engaging in translation\nwork from a cultural, linguistic domain into a computational, mathematical\ndomain, and back again. Translators benefit from articulating the theory of\ntheir translation process, and so do computational humanists in their work --\nto ensure internal consistency, avoid subtle yet consequential translation\nerrors, and facilitate interpretive transparency. Our contribution in this\npaper is to lay out a particularly consequential dimension of the lack of\ntheorizing and the sorts of translation errors that emerge in our modeling\npractices as a result. Along these lines we introduce the idea of semiotic\ncomplexity as the degree to which the meaning of some text may vary across\ninterpretive lenses, and make the case that dominant modeling practices --\nespecially around evaluation -- commit a translation error by treating\nsemiotically complex data as semiotically simple when it seems\nepistemologically convenient by conferring superficial clarity. We then lay out\nseveral recommendations for researchers to better account for these\nepistemological issues in their own work.", "published": "2025-07-31 18:44:48", "link": "http://arxiv.org/abs/2508.00095v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Do LLMs produce texts with \"human-like\" lexical diversity?", "abstract": "The degree to which LLMs produce writing that is truly human-like remains\nunclear despite the extensive empirical attention that this question has\nreceived. The present study addresses this question from the perspective of\nlexical diversity. Specifically, the study investigates patterns of lexical\ndiversity in LLM-generated texts from four ChatGPT models (-3.5, -4, -o4 mini,\nand -4.5) in comparison with texts written by L1 and L2 English participants (n\n= 240) across four education levels. Six dimensions of lexical diversity were\nmeasured in each text: volume, abundance, variety-repetition, evenness,\ndisparity, and dispersion. Results from one-way MANOVAs, one-way ANOVAS, and\nSupport Vector Machines revealed that the LLM-generated texts differed\nsignificantly from human-written texts for each variable, with ChatGPT-o4 mini\nand -4.5 differing the most. Within these two groups, ChatGPT-4.5 demonstrated\nhigher levels of lexical diversity despite producing fewer tokens. The human\nwriters' lexical diversity did not differ across subgroups (i.e., education,\nlanguage status). Altogether, the results indicate that LLMs do not produce\nhuman-like texts in relation to lexical diversity, and the newer LLMs produce\nless human-like texts than older models. We discuss the implications of these\nresults for language pedagogy and related applications.", "published": "2025-07-31 18:22:11", "link": "http://arxiv.org/abs/2508.00086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Code Generation with LLM-based Agents", "abstract": "Code generation agents powered by large language models (LLMs) are\nrevolutionizing the software development paradigm. Distinct from previous code\ngeneration techniques, code generation agents are characterized by three core\nfeatures. 1) Autonomy: the ability to independently manage the entire workflow,\nfrom task decomposition to coding and debugging. 2) Expanded task scope:\ncapabilities that extend beyond generating code snippets to encompass the full\nsoftware development lifecycle (SDLC). 3) Enhancement of engineering\npracticality: a shift in research emphasis from algorithmic innovation toward\npractical engineering challenges, such as system reliability, process\nmanagement, and tool integration. This domain has recently witnessed rapid\ndevelopment and an explosion in research, demonstrating significant application\npotential. This paper presents a systematic survey of the field of LLM-based\ncode generation agents. We trace the technology's developmental trajectory from\nits inception and systematically categorize its core techniques, including both\nsingle-agent and multi-agent architectures. Furthermore, this survey details\nthe applications of LLM-based agents across the full SDLC, summarizes\nmainstream evaluation benchmarks and metrics, and catalogs representative\ntools. Finally, by analyzing the primary challenges, we identify and propose\nseveral foundational, long-term research directions for the future work of the\nfield.", "published": "2025-07-31 18:17:36", "link": "http://arxiv.org/abs/2508.00083v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems", "abstract": "The discipline of physics stands as a cornerstone of human intellect, driving\nthe evolution of technology and deepening our understanding of the fundamental\nprinciples of the cosmos. Contemporary literature includes some works centered\non the task of solving physics problems - a crucial domain of natural language\nreasoning. In this paper, we evaluate the performance of frontier LLMs in\nsolving physics problems, both mathematical and descriptive. We also employ a\nplethora of inference-time techniques and agentic frameworks to improve the\nperformance of the models. This includes the verification of proposed solutions\nin a cumulative fashion by other, smaller LLM agents, and we perform a\ncomparative analysis of the performance that the techniques entail. There are\nsignificant improvements when the multi-agent framework is applied to problems\nthat the models initially perform poorly on. Furthermore, we introduce a new\nevaluation benchmark for physics problems, ${\\rm P{\\small HYSICS}E{\\small\nVAL}}$, consisting of 19,609 problems sourced from various physics textbooks\nand their corresponding correct solutions scraped from physics forums and\neducational websites. Our code and data are publicly available at\nhttps://github.com/areebuzair/PhysicsEval.", "published": "2025-07-31 18:12:51", "link": "http://arxiv.org/abs/2508.00079v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "abstract": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.", "published": "2025-07-31 17:00:30", "link": "http://arxiv.org/abs/2507.23726v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "abstract": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation.", "published": "2025-07-31 13:53:25", "link": "http://arxiv.org/abs/2507.23565v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "How Far Are AI Scientists from Changing the World?", "abstract": "The emergence of large language models (LLMs) is propelling automated\nscientific discovery to the next level, with LLM-based Artificial Intelligence\n(AI) Scientist systems now taking the lead in scientific research. Several\ninfluential works have already appeared in the field of AI Scientist systems,\nwith AI-generated research papers having been accepted at the ICLR 2025\nworkshop, suggesting that a human-level AI Scientist capable of uncovering\nphenomena previously unknown to humans, may soon become a reality. In this\nsurvey, we focus on the central question: How far are AI scientists from\nchanging the world and reshaping the scientific research paradigm? To answer\nthis question, we provide a prospect-driven review that comprehensively\nanalyzes the current achievements of AI Scientist systems, identifying key\nbottlenecks and the critical components required for the emergence of a\nscientific agent capable of producing ground-breaking discoveries that solve\ngrand challenges. We hope this survey will contribute to a clearer\nunderstanding of limitations of current AI Scientist systems, showing where we\nare, what is missing, and what the ultimate goals for scientific AI should be.", "published": "2025-07-31 06:32:06", "link": "http://arxiv.org/abs/2507.23276v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) offer a biologically plausible framework for\nenergy-efficient neuromorphic computing. However, it is a challenge to train\nSNNs due to their non-differentiability, efficiently. Existing gradient\napproximation approaches frequently sacrifice accuracy and face deployment\nlimitations on edge devices due to the substantial computational requirements\nof backpropagation. To address these challenges, we propose a Forward-Forward\n(FF) based gradient approximation-free training framework for Spiking Neural\nNetworks, which treats spiking activations as black-box modules, thereby\neliminating the need for gradient approximation while significantly reducing\ncomputational complexity. Furthermore, we introduce a class-aware complexity\nadaptation mechanism that dynamically optimizes the loss function based on\ninter-class difficulty metrics, enabling efficient allocation of network\nresources across different categories. Experimental results demonstrate that\nour proposed training framework achieves test accuracies of 99.58%, 92.13%, and\n75.64% on the MNIST, Fashion-MNIST, and CIFAR-10 datasets, respectively,\nsurpassing all existing FF-based SNN approaches. Additionally, our proposed\nmethod exhibits significant advantages in terms of memory access and\ncomputational power consumption.", "published": "2025-07-31 15:22:23", "link": "http://arxiv.org/abs/2507.23643v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation", "abstract": "Imitation learning for robotic manipulation faces a fundamental challenge:\nthe scarcity of large-scale, high-quality robot demonstration data. Recent\nrobotic foundation models often pre-train on cross-embodiment robot datasets to\nincrease data scale, while they face significant limitations as the diverse\nmorphologies and action spaces across different robot embodiments make unified\ntraining challenging. In this paper, we present H-RDT (Human to Robotics\nDiffusion Transformer), a novel approach that leverages human manipulation data\nto enhance robot manipulation capabilities. Our key insight is that large-scale\negocentric human manipulation videos with paired 3D hand pose annotations\nprovide rich behavioral priors that capture natural manipulation strategies and\ncan benefit robotic policy learning. We introduce a two-stage training\nparadigm: (1) pre-training on large-scale egocentric human manipulation data,\nand (2) cross-embodiment fine-tuning on robot-specific data with modular action\nencoders and decoders. Built on a diffusion transformer architecture with 2B\nparameters, H-RDT uses flow matching to model complex action distributions.\nExtensive evaluations encompassing both simulation and real-world experiments,\nsingle-task and multitask scenarios, as well as few-shot learning and\nrobustness assessments, demonstrate that H-RDT outperforms training from\nscratch and existing state-of-the-art methods, including Pi0 and RDT, achieving\nsignificant improvements of 13.9% and 40.5% over training from scratch in\nsimulation and real-world experiments, respectively. The results validate our\ncore hypothesis that human manipulation data can serve as a powerful foundation\nfor learning bimanual robotic manipulation policies.", "published": "2025-07-31 13:06:59", "link": "http://arxiv.org/abs/2507.23523v2", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Training-free Geometric Image Editing on Diffusion Models", "abstract": "We tackle the task of geometric image editing, where an object within an\nimage is repositioned, reoriented, or reshaped while preserving overall scene\ncoherence. Previous diffusion-based editing methods often attempt to handle all\nrelevant subtasks in a single step, proving difficult when transformations\nbecome large or structurally complex. We address this by proposing a decoupled\npipeline that separates object transformation, source region inpainting, and\ntarget region refinement. Both inpainting and refinement are implemented using\na training-free diffusion approach, FreeFine. In experiments on our new\nGeoBench benchmark, which contains both 2D and 3D editing scenarios, FreeFine\noutperforms state-of-the-art alternatives in image fidelity, and edit\nprecision, especially under demanding transformations. Code and benchmark are\navailable at: https://github.com/CIawevy/FreeFine", "published": "2025-07-31 07:36:00", "link": "http://arxiv.org/abs/2507.23300v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Audio Prototypical Network For Controllable Music Recommendation", "abstract": "Traditional recommendation systems represent user preferences in dense\nrepresentations obtained through black-box encoder models. While these models\noften provide strong recommendation performance, they lack interpretability for\nusers, leaving users unable to understand or control the system's modeling of\ntheir preferences. This limitation is especially challenging in music\nrecommendation, where user preferences are highly personal and often evolve\nbased on nuanced qualities like mood, genre, tempo, or instrumentation. In this\npaper, we propose an audio prototypical network for controllable music\nrecommendation. This network expresses user preferences in terms of prototypes\nrepresentative of semantically meaningful features pertaining to musical\nqualities. We show that the model obtains competitive recommendation\nperformance compared to popular baseline models while also providing\ninterpretable and controllable user profiles.", "published": "2025-07-31 22:27:22", "link": "http://arxiv.org/abs/2508.00194v1", "categories": ["cs.IR", "eess.AS"], "primary_category": "cs.IR"}
{"title": "Melody-Lyrics Matching with Contrastive Alignment Loss", "abstract": "The connection between music and lyrics is far beyond semantic bonds.\nConceptual pairs in the two modalities such as rhythm and rhyme, note duration\nand syllabic stress, and structure correspondence, raise a compelling yet\nseldom-explored direction in the field of music information retrieval. In this\npaper, we present melody-lyrics matching (MLM), a new task which retrieves\npotential lyrics for a given symbolic melody from text sources. Rather than\ngenerating lyrics from scratch, MLM essentially exploits the relationships\nbetween melody and lyrics. We propose a self-supervised representation learning\nframework with contrastive alignment loss for melody and lyrics. This has the\npotential to leverage the abundance of existing songs with paired melody and\nlyrics. No alignment annotations are required. Additionally, we introduce\nsylphone, a novel representation for lyrics at syllable-level activated by\nphoneme identity and vowel stress. We demonstrate that our method can match\nmelody with coherent and singable lyrics with empirical results and intuitive\nexamples. We open source code and provide matching examples on the companion\nwebpage: https://github.com/changhongw/mlm.", "published": "2025-07-31 19:23:57", "link": "http://arxiv.org/abs/2508.00123v1", "categories": ["eess.AS", "cs.IR"], "primary_category": "eess.AS"}
{"title": "Cyclotomy, cyclotomic cosets and arithmetic properties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$", "abstract": "Arithmetic properties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle\nx^{p^sq^t}-1\\rangle}$ are obtained by using the cyclotomic classes of order 2\nwith respect to $n=p^sq^t$, where $p\\equiv3 \\mathrm{mod} 4$,\n$\\gcd(\\phi(p^s),\\phi(q^t))=2$, $l$ is a primitive root modulo $q^t$ and\n$\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$. The form of these cyclotomic classes\nenables us to further generalize the results obtained in \\cite{ref1}. The\nexplicit expressions of primitive idempotents of minimal ideals in\n$\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ are also obtained.", "published": "2025-07-31 01:19:47", "link": "http://arxiv.org/abs/2507.23179v2", "categories": ["math.NT", "cs.IT", "math.IT"], "primary_category": "math.NT"}
{"title": "Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design", "abstract": "Hardware-Aware Neural Architecture Search (HW-NAS) is an efficient approach\nto automatically co-optimizing neural network performance and hardware energy\nefficiency, making it particularly useful for the development of Deep Neural\nNetwork accelerators on the edge. However, the extensive search space and high\ncomputational cost pose significant challenges to its practical adoption. To\naddress these limitations, we propose Coflex, a novel HW-NAS framework that\nintegrates the Sparse Gaussian Process (SGP) with multi-objective Bayesian\noptimization. By leveraging sparse inducing points, Coflex reduces the GP\nkernel complexity from cubic to near-linear with respect to the number of\ntraining samples, without compromising optimization performance. This enables\nscalable approximation of large-scale search space, substantially decreasing\ncomputational overhead while preserving high predictive accuracy. We evaluate\nthe efficacy of Coflex across various benchmarks, focusing on\naccelerator-specific architecture. Our experimental results show that Coflex\noutperforms state-of-the-art methods in terms of network accuracy and\nEnergy-Delay-Product, while achieving a computational speed-up ranging from\n1.9x to 9.5x.", "published": "2025-07-31 11:16:46", "link": "http://arxiv.org/abs/2507.23437v2", "categories": ["cs.LG", "I.2.6; C.1.3; C.3"], "primary_category": "cs.LG"}
{"title": "NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions", "abstract": "When numerically evaluating a function's gradient, sparsity detection can\nenable substantial computational speedups through Jacobian coloring and\ncompression. However, sparsity detection techniques for black-box functions are\nlimited, and existing finite-difference-based methods suffer from false\nnegatives due to coincidental zero gradients. These false negatives can\nsilently corrupt gradient calculations, leading to difficult-to-diagnose\nerrors. We introduce NaN-propagation, which exploits the universal\ncontamination property of IEEE 754 Not-a-Number values to trace input-output\ndependencies through floating-point numerical computations. By systematically\ncontaminating inputs with NaN and observing which outputs become NaN, the\nmethod reconstructs conservative sparsity patterns that eliminate a major\nsource of false negatives. We demonstrate this approach on an aerospace wing\nweight model, achieving a 1.52x speedup while uncovering dozens of dependencies\nmissed by conventional methods -- a significant practical improvement since\ngradient computation is often the bottleneck in optimization workflows. The\ntechnique leverages IEEE 754 compliance to work across programming languages\nand math libraries without requiring modifications to existing black-box codes.\nFurthermore, advanced strategies such as NaN payload encoding via direct bit\nmanipulation enable faster-than-linear time complexity, yielding speed\nimprovements over existing black-box sparsity detection methods. Practical\nalgorithms are also proposed to mitigate challenges from branching code\nexecution common in engineering applications.", "published": "2025-07-31 01:48:56", "link": "http://arxiv.org/abs/2507.23186v2", "categories": ["cs.LG", "cs.PL"], "primary_category": "cs.LG"}
{"title": "Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions", "abstract": "We compare two methodologies for calibrating implied volatility surfaces: a\nsecond-order asymptotic expansion method derived via Malliavin calculus, and a\ndata-driven approach based on path signatures from rough path theory. The\nformer, developed in Al\\`os et al. (2015), yields efficient and accurate\ncalibration formulas under the assumption that the asset price follows a\nHeston-type stochastic volatility model. The latter models volatility as a\nlinear functional of the signature of a primary stochastic process, enabling a\nflexible approximation without requiring a specific parametric form.\n  Our numerical experiments show that the signature-based method achieves\ncalibration accuracy comparable to the asymptotic approach when the true\ndynamics are Heston. We then test the model in a more general setting where the\nasset follows a rough Bergomi volatility process-a regime beyond the scope of\nthe asymptotic expansion-and show that the signature approach continues to\ndeliver accurate results. These findings highlight the model-independence,\nrobustness and adaptability of signature-based calibration methods in settings\nwhere volatility exhibits rough or non-Markovian features.", "published": "2025-07-31 10:08:02", "link": "http://arxiv.org/abs/2507.23392v2", "categories": ["q-fin.MF", "math.PR", "60L70, 60H10, 91G20, 91G60, 60G22"], "primary_category": "q-fin.MF"}
{"title": "Reinitializing weights vs units for maintaining plasticity in neural networks", "abstract": "Loss of plasticity is a phenomenon in which a neural network loses its\nability to learn when trained for an extended time on non-stationary data. It\nis a crucial problem to overcome when designing systems that learn continually.\nAn effective technique for preventing loss of plasticity is reinitializing\nparts of the network. In this paper, we compare two different reinitialization\nschemes: reinitializing units vs reinitializing weights. We propose a new\nalgorithm, which we name \\textit{selective weight reinitialization}, for\nreinitializing the least useful weights in a network. We compare our algorithm\nto continual backpropagation and ReDo, two previously proposed algorithms that\nreinitialize units in the network. Through our experiments in continual\nsupervised learning problems, we identify two settings when reinitializing\nweights is more effective at maintaining plasticity than reinitializing units:\n(1) when the network has a small number of units and (2) when the network\nincludes layer normalization. Conversely, reinitializing weights and units are\nequally effective at maintaining plasticity when the network is of sufficient\nsize and does not include layer normalization. We found that reinitializing\nweights maintains plasticity in a wider variety of settings than reinitializing\nunits.", "published": "2025-07-31 23:25:19", "link": "http://arxiv.org/abs/2508.00212v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models", "abstract": "Foundation models (FMs) pretrained on large datasets have become fundamental\nfor various downstream machine learning tasks, in particular in scenarios where\nobtaining perfectly labeled data is prohibitively expensive. In this paper, we\nassume an FM has to be fine-tuned with noisy data and present a two-stage\nframework to ensure robust classification in the presence of label noise\nwithout model retraining. Recent work has shown that simple k-nearest neighbor\n(kNN) approaches using an embedding derived from an FM can achieve good\nperformance even in the presence of severe label noise. Our work is motivated\nby the fact that these methods make use of local geometry. In this paper,\nfollowing a similar two-stage procedure, reliability estimation followed by\nreliability-weighted inference, we show that improved performance can be\nachieved by introducing geometry information. For a given instance, our\nproposed inference uses a local neighborhood of training data, obtained using\nthe non-negative kernel (NNK) neighborhood construction. We propose several\nmethods for reliability estimation that can rely less on distance and local\nneighborhood as the label noise increases. Our evaluation on CIFAR-10 and\nDermaMNIST shows that our methods improve robustness across various noise\nconditions, surpassing standard K-NN approaches and recent\nadaptive-neighborhood baselines.", "published": "2025-07-31 23:01:32", "link": "http://arxiv.org/abs/2508.00202v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes", "abstract": "Stochasticity in language model fine-tuning, often caused by the small batch\nsizes typically used in this regime, can destabilize training by introducing\nlarge oscillations in generation quality. A popular approach to mitigating this\ninstability is to take an Exponential moving average (EMA) of weights\nthroughout training. While EMA reduces stochasticity, thereby smoothing\ntraining, the introduction of bias from old iterates often creates a lag in\noptimization relative to vanilla training. In this work, we propose the\nBias-Corrected Exponential Moving Average (BEMA), a simple and practical\naugmentation of EMA that retains variance-reduction benefits while eliminating\nbias. BEMA is motivated by a simple theoretical model wherein we demonstrate\nprovable acceleration of BEMA over both a standard EMA and vanilla training.\nThrough an extensive suite of experiments on Language Models, we show that BEMA\nleads to significantly improved convergence rates and final performance over\nboth EMA and vanilla training in a variety of standard LM benchmarks, making\nBEMA a practical and theoretically motivated intervention for more stable and\nefficient fine-tuning.", "published": "2025-07-31 21:49:20", "link": "http://arxiv.org/abs/2508.00180v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The SPACE of AI: Real-World Lessons on AI's Impact on Developers", "abstract": "As artificial intelligence (AI) tools become increasingly embedded in\nsoftware development workflows, questions persist about their true impact on\ndeveloper productivity and experience. This paper presents findings from a\nmixed-methods study examining how developers perceive AI's influence across the\ndimensions of the SPACE framework: Satisfaction, Performance, Activity,\nCollaboration and Efficiency. Drawing on survey responses from over 500\ndevelopers and qualitative insights from interviews and observational studies,\nwe find that AI is broadly adopted and widely seen as enhancing productivity,\nparticularly for routine tasks. However, the benefits vary, depending on task\ncomplexity, individual usage patterns, and team-level adoption. Developers\nreport increased efficiency and satisfaction, with less evidence of impact on\ncollaboration. Organizational support and peer learning play key roles in\nmaximizing AI's value. These findings suggest that AI is augmenting developers\nrather than replacing them, and that effective integration depends as much on\nteam culture and support structures as on the tools themselves. We conclude\nwith practical recommendations for teams, organizations and researchers seeking\nto harness AI's potential in software engineering.", "published": "2025-07-31 21:45:54", "link": "http://arxiv.org/abs/2508.00178v1", "categories": ["cs.HC", "cs.AI", "cs.SE"], "primary_category": "cs.HC"}
{"title": "DeformTune: A Deformable XAI Music Prototype for Non-Musicians", "abstract": "Many existing AI music generation tools rely on text prompts, complex\ninterfaces, or instrument-like controls, which may require musical or technical\nknowledge that non-musicians do not possess. This paper introduces DeformTune,\na prototype system that combines a tactile deformable interface with the\nMeasureVAE model to explore more intuitive, embodied, and explainable AI\ninteraction. We conducted a preliminary study with 11 adult participants\nwithout formal musical training to investigate their experience with\nAI-assisted music creation. Thematic analysis of their feedback revealed\nrecurring challenge--including unclear control mappings, limited expressive\nrange, and the need for guidance throughout use. We discuss several design\nopportunities for enhancing explainability of AI, including multimodal feedback\nand progressive interaction support. These findings contribute early insights\ntoward making AI music systems more explainable and empowering for novice\nusers.", "published": "2025-07-31 20:57:59", "link": "http://arxiv.org/abs/2508.00160v1", "categories": ["cs.HC", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power", "abstract": "Power is a key concept in AI safety: power-seeking as an instrumental goal,\nsudden or gradual disempowerment of humans, power balance in human-AI\ninteraction and international AI governance. At the same time, power as the\nability to pursue diverse goals is essential for wellbeing.\n  This paper explores the idea of promoting both safety and wellbeing by\nforcing AI agents explicitly to empower humans and to manage the power balance\nbetween humans and AI agents in a desirable way. Using a principled, partially\naxiomatic approach, we design a parametrizable and decomposable objective\nfunction that represents an inequality- and risk-averse long-term aggregate of\nhuman power. It takes into account humans' bounded rationality and social\nnorms, and, crucially, considers a wide variety of possible human goals.\n  We derive algorithms for computing that metric by backward induction or\napproximating it via a form of multi-agent reinforcement learning from a given\nworld model. We exemplify the consequences of (softly) maximizing this metric\nin a variety of paradigmatic situations and describe what instrumental\nsub-goals it will likely imply. Our cautious assessment is that softly\nmaximizing suitable aggregate metrics of human power might constitute a\nbeneficial objective for agentic AI systems that is safer than direct\nutility-based objectives.", "published": "2025-07-31 20:56:43", "link": "http://arxiv.org/abs/2508.00159v1", "categories": ["cs.AI", "cs.CY", "cs.LG", "econ.TH", "math.OC", "68Txx", "I.2"], "primary_category": "cs.AI"}
{"title": "GEPAR3D: Geometry Prior-Assisted Learning for 3D Tooth Segmentation", "abstract": "Tooth segmentation in Cone-Beam Computed Tomography (CBCT) remains\nchallenging, especially for fine structures like root apices, which is critical\nfor assessing root resorption in orthodontics. We introduce GEPAR3D, a novel\napproach that unifies instance detection and multi-class segmentation into a\nsingle step tailored to improve root segmentation. Our method integrates a\nStatistical Shape Model of dentition as a geometric prior, capturing anatomical\ncontext and morphological consistency without enforcing restrictive adjacency\nconstraints. We leverage a deep watershed method, modeling each tooth as a\ncontinuous 3D energy basin encoding voxel distances to boundaries. This\ninstance-aware representation ensures accurate segmentation of narrow, complex\nroot apices. Trained on publicly available CBCT scans from a single center, our\nmethod is evaluated on external test sets from two in-house and two public\nmedical centers. GEPAR3D achieves the highest overall segmentation performance,\naveraging a Dice Similarity Coefficient (DSC) of 95.0% (+2.8% over the\nsecond-best method) and increasing recall to 95.2% (+9.5%) across all test\nsets. Qualitative analyses demonstrated substantial improvements in root\nsegmentation quality, indicating significant potential for more accurate root\nresorption assessment and enhanced clinical decision-making in orthodontics. We\nprovide the implementation and dataset at https://github.com/tomek1911/GEPAR3D.", "published": "2025-07-31 20:46:58", "link": "http://arxiv.org/abs/2508.00155v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation", "abstract": "Humans can be notoriously imperfect evaluators. They are often biased,\nunreliable, and unfit to define \"ground truth.\" Yet, given the surging need to\nproduce large amounts of training data in educational applications using AI,\ntraditional inter-rater reliability (IRR) metrics like Cohen's kappa remain\ncentral to validating labeled data. IRR remains a cornerstone of many machine\nlearning pipelines for educational data. Take, for example, the classification\nof tutors' moves in dialogues or labeling open responses in machine-graded\nassessments. This position paper argues that overreliance on human IRR as a\ngatekeeper for annotation quality hampers progress in classifying data in ways\nthat are valid and predictive in relation to improving learning. To address\nthis issue, we highlight five examples of complementary evaluation methods,\nsuch as multi-label annotation schemes, expert-based approaches, and\nclose-the-loop validity. We argue that these approaches are in a better\nposition to produce training data and subsequent models that produce improved\nstudent learning and more actionable insights than IRR approaches alone. We\nalso emphasize the importance of external validity, for example, by\nestablishing a procedure of validating tutor moves and demonstrating that it\nworks across many categories of tutor actions (e.g., providing hints). We call\non the field to rethink annotation quality and ground truth--prioritizing\nvalidity and educational impact over consensus alone.", "published": "2025-07-31 20:05:26", "link": "http://arxiv.org/abs/2508.00143v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks", "abstract": "Accurate link-level bicycling volume estimation is essential for sustainable\nurban transportation planning. However, many cities face significant challenges\nof high data sparsity due to limited bicycling count sensor coverage. To\naddress this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning\n(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize\nsensor placement and improve link-level bicycling volume estimation in\ndata-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks\n(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL\nagent, enabling a data-driven strategic selection of sensor locations to\nmaximize estimation performance. Applied to Melbourne's bicycling network,\ncomprising 15,933 road segments with sensor coverage on only 141 road segments\n(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume\nestimation by strategically selecting additional sensor locations in\ndeployments of 50, 100, 200 and 500 sensors. Our framework outperforms\ntraditional heuristic methods for sensor placement such as betweenness\ncentrality, closeness centrality, observed bicycling activity and random\nplacement, across key metrics such as Mean Squared Error (MSE), Root Mean\nSquared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our\nexperiments benchmark INSPIRE-GNN against standard machine learning and deep\nlearning models in the bicycle volume estimation performance, underscoring its\neffectiveness. Our proposed framework provides transport planners actionable\ninsights to effectively expand sensor networks, optimize sensor placement and\nmaximize volume estimation accuracy and reliability of bicycling data for\ninformed transportation planning decisions.", "published": "2025-07-31 20:00:35", "link": "http://arxiv.org/abs/2508.00141v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Your Model Is Unfair, Are You Even Aware? Inverse Relationship Between Comprehension and Trust in Explainability Visualizations of Biased ML Models", "abstract": "Systems relying on ML have become ubiquitous, but so has biased behavior\nwithin them. Research shows that bias significantly affects stakeholders' trust\nin systems and how they use them. Further, stakeholders of different\nbackgrounds view and trust the same systems differently. Thus, how ML models'\nbehavior is explained plays a key role in comprehension and trust. We survey\nexplainability visualizations, creating a taxonomy of design characteristics.\nWe conduct user studies to evaluate five state-of-the-art visualization tools\n(LIME, SHAP, CP, Anchors, and ELI5) for model explainability, measuring how\ntaxonomy characteristics affect comprehension, bias perception, and trust for\nnon-expert ML users. Surprisingly, we find an inverse relationship between\ncomprehension and trust: the better users understand the models, the less they\ntrust them. We investigate the cause and find that this relationship is\nstrongly mediated by bias perception: more comprehensible visualizations\nincrease people's perception of bias, and increased bias perception reduces\ntrust. We confirm this relationship is causal: Manipulating explainability\nvisualizations to control comprehension, bias perception, and trust, we show\nthat visualization design can significantly (p < 0.001) increase comprehension,\nincrease perceived bias, and reduce trust. Conversely, reducing perceived model\nbias, either by improving model fairness or by adjusting visualization design,\nsignificantly increases trust even when comprehension remains high. Our work\nadvances understanding of how comprehension affects trust and systematically\ninvestigates visualization's role in facilitating responsible ML applications.", "published": "2025-07-31 20:00:32", "link": "http://arxiv.org/abs/2508.00140v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Co-Producing AI: Toward an Augmented, Participatory Lifecycle", "abstract": "Despite efforts to mitigate the inherent risks and biases of artificial\nintelligence (AI) algorithms, these algorithms can disproportionately impact\nculturally marginalized groups. A range of approaches has been proposed to\naddress or reduce these risks, including the development of ethical guidelines\nand principles for responsible AI, as well as technical solutions that promote\nalgorithmic fairness. Drawing on design justice, expansive learning theory, and\nrecent empirical work on participatory AI, we argue that mitigating these harms\nrequires a fundamental re-architecture of the AI production pipeline. This\nre-design should center co-production, diversity, equity, inclusion (DEI), and\nmultidisciplinary collaboration. We introduce an augmented AI lifecycle\nconsisting of five interconnected phases: co-framing, co-design,\nco-implementation, co-deployment, and co-maintenance. The lifecycle is informed\nby four multidisciplinary workshops and grounded in themes of distributed\nauthority and iterative knowledge exchange. Finally, we relate the proposed\nlifecycle to several leading ethical frameworks and outline key research\nquestions that remain for scaling participatory governance.", "published": "2025-07-31 19:58:58", "link": "http://arxiv.org/abs/2508.00138v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SHACL Validation under Graph Updates (Extended Paper)", "abstract": "SHACL (SHApe Constraint Language) is a W3C standardized constraint language\nfor RDF graphs. In this paper, we study SHACL validation in RDF graphs under\nupdates. We present a SHACL-based update language that can capture intuitive\nand realistic modifications on RDF graphs and study the problem of static\nvalidation under such updates. This problem asks to verify whether every graph\nthat validates a SHACL specification will still do so after applying a given\nupdate sequence. More importantly, it provides a basis for further services for\nreasoning about evolving RDF graphs. Using a regression technique that embeds\nthe update actions into SHACL constraints, we show that static validation under\nupdates can be reduced to (un)satisfiability of constraints in (a minor\nextension of) SHACL. We analyze the computational complexity of the static\nvalidation problem for SHACL and some key fragments. Finally, we present a\nprototype implementation that performs static validation and other static\nanalysis tasks on SHACL constraints and demonstrate its behavior through\npreliminary experiments.", "published": "2025-07-31 19:58:16", "link": "http://arxiv.org/abs/2508.00137v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images", "abstract": "Gender classification has emerged as a crucial aspect in various fields,\nincluding security, human-machine interaction, surveillance, and advertising.\nNonetheless, the accuracy of this classification can be influenced by factors\nsuch as cosmetics and disguise. Consequently, our study is dedicated to\naddressing this concern by concentrating on gender classification using color\nimages of the periocular region. The periocular region refers to the area\nsurrounding the eye, including the eyelids, eyebrows, and the region between\nthem. It contains valuable visual cues that can be used to extract key features\nfor gender classification. This paper introduces a sophisticated Convolutional\nNeural Network (CNN) model that utilizes color image databases to evaluate the\neffectiveness of the periocular region for gender classification. To validate\nthe model's performance, we conducted tests on two eye datasets, namely CVBL\nand (Female and Male). The recommended architecture achieved an outstanding\naccuracy of 99% on the previously unused CVBL dataset while attaining a\ncommendable accuracy of 96% with a small number of learnable parameters\n(7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of\nour proposed model for gender classification using the periocular region, we\nevaluated its performance through an extensive range of metrics and compared it\nwith other state-of-the-art approaches. The results unequivocally demonstrate\nthe efficacy of our model, thereby suggesting its potential for practical\napplication in domains such as security and surveillance.", "published": "2025-07-31 19:52:03", "link": "http://arxiv.org/abs/2508.00135v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis", "abstract": "In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem\nthat can greatly affect the results of a Multi-Criteria Decision Method against\na particular set of alternatives. It is therefore useful to have a mechanism\nthat allows one to measure the performance of a method on a set of\nalternatives. This idea could be taken further to build a global ranking of the\neffectiveness of different methods to solve a problem. In this paper, we\npresent three tests that detect the presence of Rank Reversals, along with\ntheir implementation in the Scikit-Criteria library. We also address the\ncomplications that arise when implementing these tests for general scenarios\nand the design considerations we made to handle them. We close with a\ndiscussion about how these additions could play a major role in the judgment of\nmulti-criteria decision methods for problem solving.", "published": "2025-07-31 19:31:41", "link": "http://arxiv.org/abs/2508.00129v1", "categories": ["cs.AI", "math.OC"], "primary_category": "cs.AI"}
{"title": "StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection", "abstract": "Liver diseases are a serious health concern in the world, which requires\nprecise and timely diagnosis to enhance the survival chances of patients. The\ncurrent literature implemented numerous machine learning and deep learning\nmodels to classify liver diseases, but most of them had some issues like high\nmisclassification error, poor interpretability, prohibitive computational\nexpense, and lack of good preprocessing strategies. In order to address these\ndrawbacks, we introduced StackLiverNet in this study; an interpretable stacked\nensemble model tailored to the liver disease detection task. The framework uses\nadvanced data preprocessing and feature selection technique to increase model\nrobustness and predictive ability. Random undersampling is performed to deal\nwith class imbalance and make the training balanced. StackLiverNet is an\nensemble of several hyperparameter-optimized base classifiers, whose\ncomplementary advantages are used through a LightGBM meta-model. The provided\nmodel demonstrates excellent performance, with the testing accuracy of 99.89%,\nCohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and\nefficient training and inference speeds that are amenable to clinical practice\n(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local\nInterpretable Model-Agnostic Explanations (LIME) are applied to generate\ntransparent explanations of individual predictions, revealing high\nconcentrations of Alkaline Phosphatase and moderate SGOT as important\nobservations of liver disease. Also, SHAP was used to rank features by their\nglobal contribution to predictions, while the Morris method confirmed the most\ninfluential features through sensitivity analysis.", "published": "2025-07-31 19:13:30", "link": "http://arxiv.org/abs/2508.00117v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence", "abstract": "The uptake of Artificial Intelligence (AI) impacts the way we work, interact,\ndo business, and conduct research. However, organizations struggle to apply AI\nsuccessfully in industrial settings where the focus is on end-to-end\noperational processes. Here, we consider generative, predictive, and\nprescriptive AI and elaborate on the challenges of diagnosing and improving\nsuch processes. We show that AI needs to be grounded using Object-Centric\nProcess Mining (OCPM). Process-related data are structured and\norganization-specific and, unlike text, processes are often highly dynamic.\nOCPM is the missing link connecting data and processes and enables different\nforms of AI. We use the term Process Intelligence (PI) to refer to the\namalgamation of process-centric data-driven techniques able to deal with a\nvariety of object and event types, enabling AI in an organizational context.\nThis paper explains why AI requires PI to improve operational processes and\nhighlights opportunities for successfully combining OCPM and generative,\npredictive, and prescriptive AI.", "published": "2025-07-31 19:11:51", "link": "http://arxiv.org/abs/2508.00116v1", "categories": ["cs.AI", "H.4.1; I.2.1"], "primary_category": "cs.AI"}
{"title": "Hyperproperty-Constrained Secure Reinforcement Learning", "abstract": "Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a\ndomain-specific formal specification language known for its effectiveness in\ncompactly representing security, opacity, and concurrency properties for\nrobotics applications. This paper focuses on HyperTWTL-constrained secure\nreinforcement learning (SecRL). Although temporal logic-constrained safe\nreinforcement learning (SRL) is an evolving research problem with several\nexisting literature, there is a significant research gap in exploring\nsecurity-aware reinforcement learning (RL) using hyperproperties. Given the\ndynamics of an agent as a Markov Decision Process (MDP) and opacity/security\nconstraints formalized as HyperTWTL, we propose an approach for learning\nsecurity-aware optimal policies using dynamic Boltzmann softmax RL while\nsatisfying the HyperTWTL constraints. The effectiveness and scalability of our\nproposed approach are demonstrated using a pick-up and delivery robotic mission\ncase study. We also compare our results with two other baseline RL algorithms,\nshowing that our proposed method outperforms them.", "published": "2025-07-31 18:57:18", "link": "http://arxiv.org/abs/2508.00106v1", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "A Mixed User-Centered Approach to Enable Augmented Intelligence in Intelligent Tutoring Systems: The Case of MathAIde app", "abstract": "Integrating Artificial Intelligence in Education (AIED) aims to enhance\nlearning experiences through technologies like Intelligent Tutoring Systems\n(ITS), offering personalized learning, increased engagement, and improved\nretention rates. However, AIED faces three main challenges: the critical role\nof teachers in the design process, the limitations and reliability of AI tools,\nand the accessibility of technological resources. Augmented Intelligence (AuI)\naddresses these challenges by enhancing human capabilities rather than\nreplacing them, allowing systems to suggest solutions. In contrast, humans\nprovide final assessments, thus improving AI over time. In this sense, this\nstudy focuses on designing, developing, and evaluating MathAIde, an ITS that\ncorrects mathematics exercises using computer vision and AI and provides\nfeedback based on photos of student work. The methodology included\nbrainstorming sessions with potential users, high-fidelity prototyping, A/B\ntesting, and a case study involving real-world classroom environments for\nteachers and students. Our research identified several design possibilities for\nimplementing AuI in ITSs, emphasizing a balance between user needs and\ntechnological feasibility. Prioritization and validation through prototyping\nand testing highlighted the importance of efficiency metrics, ultimately\nleading to a solution that offers pre-defined remediation alternatives for\nteachers. Real-world deployment demonstrated the usefulness of the proposed\nsolution. Our research contributes to the literature by providing a usable,\nteacher-centered design approach that involves teachers in all design phases.\nAs a practical implication, we highlight that the user-centered design approach\nincreases the usefulness and adoption potential of AIED systems, especially in\nresource-limited environments.", "published": "2025-07-31 18:56:01", "link": "http://arxiv.org/abs/2508.00103v1", "categories": ["cs.HC", "cs.AI", "68T01", "H.5.0; I.2.0"], "primary_category": "cs.HC"}
{"title": "Stress-Aware Resilient Neural Training", "abstract": "This paper introduces Stress-Aware Learning, a resilient neural training\nparadigm in which deep neural networks dynamically adjust their optimization\nbehavior - whether under stable training regimes or in settings with uncertain\ndynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)\nDeformation, inspired by structural fatigue in materials science. To\ninstantiate this concept, we propose Plastic Deformation Optimizer, a\nstress-aware mechanism that injects adaptive noise into model parameters\nwhenever an internal stress signal - reflecting stagnation in training loss and\naccuracy - indicates persistent optimization difficulty. This enables the model\nto escape sharp minima and converge toward flatter, more generalizable regions\nof the loss landscape. Experiments across six architectures, four optimizers,\nand seven vision benchmarks demonstrate improved robustness and generalization\nwith minimal computational overhead. The code and 3D visuals will be available\non GitHub: https://github.com/Stress-Aware-Learning/SAL.", "published": "2025-07-31 18:46:19", "link": "http://arxiv.org/abs/2508.00098v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation", "abstract": "The rapid advancement of Vision-Language-Action models has created an urgent\nneed for large-scale, high-quality robot demonstration datasets. Although\nteleoperation is the predominant method for data collection, current approaches\nsuffer from limited scalability, complex setup procedures, and suboptimal data\nquality. This paper presents XRoboToolkit, a cross-platform framework for\nextended reality based robot teleoperation built on the OpenXR standard. The\nsystem features low-latency stereoscopic visual feedback, optimization-based\ninverse kinematics, and support for diverse tracking modalities including head,\ncontroller, hand, and auxiliary motion trackers. XRoboToolkit's modular\narchitecture enables seamless integration across robotic platforms and\nsimulation environments, spanning precision manipulators, mobile robots, and\ndexterous hands. We demonstrate the framework's effectiveness through precision\nmanipulation tasks and validate data quality by training VLA models that\nexhibit robust autonomous performance.", "published": "2025-07-31 18:45:13", "link": "http://arxiv.org/abs/2508.00097v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Punching Bag vs. Punching Person: Motion Transferability in Videos", "abstract": "Action recognition models demonstrate strong generalization, but can they\neffectively transfer high-level motion concepts across diverse contexts, even\nwithin similar distributions? For example, can a model recognize the broad\naction \"punching\" when presented with an unseen variation such as \"punching\nperson\"? To explore this, we introduce a motion transferability framework with\nthree datasets: (1) Syn-TA, a synthetic dataset with 3D object motions; (2)\nKinetics400-TA; and (3) Something-Something-v2-TA, both adapted from natural\nvideo datasets. We evaluate 13 state-of-the-art models on these benchmarks and\nobserve a significant drop in performance when recognizing high-level actions\nin novel contexts. Our analysis reveals: 1) Multimodal models struggle more\nwith fine-grained unknown actions than with coarse ones; 2) The bias-free\nSyn-TA proves as challenging as real-world datasets, with models showing\ngreater performance drops in controlled settings; 3) Larger models improve\ntransferability when spatial cues dominate but struggle with intensive temporal\nreasoning, while reliance on object and background cues hinders generalization.\nWe further explore how disentangling coarse and fine motions can improve\nrecognition in temporally challenging datasets. We believe this study\nestablishes a crucial benchmark for assessing motion transferability in action\nrecognition. Datasets and relevant code:\nhttps://github.com/raiyaan-abdullah/Motion-Transfer.", "published": "2025-07-31 18:19:20", "link": "http://arxiv.org/abs/2508.00085v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Object-Centric Cropping for Visual Few-Shot Classification", "abstract": "In the domain of Few-Shot Image Classification, operating with as little as\none example per class, the presence of image ambiguities stemming from multiple\nobjects or complex backgrounds can significantly deteriorate performance. Our\nresearch demonstrates that incorporating additional information about the local\npositioning of an object within its image markedly enhances classification\nacross established benchmarks. More importantly, we show that a significant\nfraction of the improvement can be achieved through the use of the Segment\nAnything Model, requiring only a pixel of the object of interest to be pointed\nout, or by employing fully unsupervised foreground object extraction methods.", "published": "2025-07-31 23:44:06", "link": "http://arxiv.org/abs/2508.00218v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters", "abstract": "The Segment Anything Model (SAM) has demonstrated impressive generalization\nin prompt-based segmentation. Yet, the potential of semantic text prompts\nremains underexplored compared to traditional spatial prompts like points and\nboxes. This paper introduces SAM-PTx, a parameter-efficient approach for\nadapting SAM using frozen CLIP-derived text embeddings as class-level semantic\nguidance. Specifically, we propose a lightweight adapter design called\nParallel-Text that injects text embeddings into SAM's image encoder, enabling\nsemantics-guided segmentation while keeping most of the original architecture\nfrozen. Our adapter modifies only the MLP-parallel branch of each transformer\nblock, preserving the attention pathway for spatial reasoning. Through\nsupervised experiments and ablations on the COD10K dataset as well as low-data\nsubsets of COCO and ADE20K, we show that incorporating fixed text embeddings as\ninput improves segmentation performance over purely spatial prompt baselines.\nTo our knowledge, this is the first work to use text prompts for segmentation\non the COD10K dataset. These results suggest that integrating semantic\nconditioning into SAM's architecture offers a practical and scalable path for\nefficient adaptation with minimal computational complexity.", "published": "2025-07-31 23:26:39", "link": "http://arxiv.org/abs/2508.00213v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition", "abstract": "Automatic real personality recognition (RPR) aims to evaluate human real\npersonality traits from their expressive behaviours. However, most existing\nsolutions generally act as external observers to infer observers' personality\nimpressions based on target individuals' expressive behaviours, which\nsignificantly deviate from their real personalities and consistently lead to\ninferior recognition performance. Inspired by the association between real\npersonality and human internal cognition underlying the generation of\nexpressive behaviours, we propose a novel RPR approach that efficiently\nsimulates personalised internal cognition from easy-accessible external short\naudio-visual behaviours expressed by the target individual. The simulated\npersonalised cognition, represented as a set of network weights that enforce\nthe personalised network to reproduce the individual-specific facial reactions,\nis further encoded as a novel graph containing two-dimensional node and edge\nfeature matrices, with a novel 2D Graph Neural Network (2D-GNN) proposed for\ninferring real personality traits from it. To simulate real personality-related\ncognition, an end-to-end strategy is designed to jointly train our cognition\nsimulation, 2D graph construction, and personality recognition modules.", "published": "2025-07-31 23:12:09", "link": "http://arxiv.org/abs/2508.00205v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Graph Lineages and Skeletal Graph Products", "abstract": "Graphs, and sequences of growing graphs, can be used to specify the\narchitecture of mathematical models in many fields including machine learning\nand computational science. Here we define structured graph \"lineages\" (ordered\nby level number) that grow in a hierarchical fashion, so that: (1) the number\nof graph vertices and edges increases exponentially in level number; (2)\nbipartite graphs connect successive levels within a graph lineage and, as in\nmultigrid methods, can constrain matrices relating successive levels; (3) using\nprolongation maps within a graph lineage, process-derived distance measures\nbetween graphs at successive levels can be defined; (4) a category of \"graded\ngraphs\" can be defined, and using it low-cost \"skeletal\" variants of standard\nalgebraic graph operations and type constructors (cross product, box product,\ndisjoint sum, and function types) can be derived for graded graphs and hence\nhierarchical graph lineages; (5) these skeletal binary operators have similar\nbut not identical algebraic and category-theoretic properties to their standard\ncounterparts; (6) graph lineages and their skeletal product constructors can\napproach continuum limit objects. Additional space-efficient unary operators on\ngraded graphs are also derived: thickening, which creates a graph lineage of\nmultiscale graphs, and escalation to a graph lineage of search frontiers\n(useful as a generalization of adaptive grids and in defining \"skeletal\"\nfunctions). The result is an algebraic type theory for graded graphs and\n(hierarchical) graph lineages. The approach is expected to be well suited to\ndefining hierarchical model architectures - \"hierarchitectures\" - and local\nsampling, search, or optimization algorithms on them. We demonstrate such\napplication to deep neural networks (including visual and feature scale spaces)\nand to multigrid numerical methods.", "published": "2025-07-31 22:31:34", "link": "http://arxiv.org/abs/2508.00197v1", "categories": ["cs.CV", "cs.LG", "cs.NA", "math.CT", "math.NA"], "primary_category": "cs.CV"}
{"title": "Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs", "abstract": "LiDAR-based 3D sensors provide point clouds, a canonical 3D representation\nused in various scene understanding tasks. Modern LiDARs face key challenges in\nseveral real-world scenarios, such as long-distance or low-albedo objects,\nproducing sparse or erroneous point clouds. These errors, which are rooted in\nthe noisy raw LiDAR measurements, get propagated to downstream perception\nmodels, resulting in potentially severe loss of accuracy. This is because\nconventional 3D processing pipelines do not retain any uncertainty information\nfrom the raw measurements when constructing point clouds.\n  We propose Probabilistic Point Clouds (PPC), a novel 3D scene representation\nwhere each point is augmented with a probability attribute that encapsulates\nthe measurement uncertainty (or confidence) in the raw data. We further\nintroduce inference approaches that leverage PPC for robust 3D object\ndetection; these methods are versatile and can be used as computationally\nlightweight drop-in modules in 3D inference pipelines. We demonstrate, via both\nsimulations and real captures, that PPC-based 3D inference methods outperform\nseveral baselines using LiDAR as well as camera-LiDAR fusion models, across\nchallenging indoor and outdoor scenarios involving small, distant, and\nlow-albedo objects, as well as strong ambient light.\n  Our project webpage is at https://bhavyagoyal.github.io/ppc .", "published": "2025-07-31 21:32:21", "link": "http://arxiv.org/abs/2508.00169v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Computation of Approximately Stable Committees in Approval-based Elections", "abstract": "Approval-based committee selection is a model of significant interest in\nsocial choice theory. In this model, we have a set of voters $\\mathcal{V}$, a\nset of candidates $\\mathcal{C}$, and each voter has a set $A_v \\subset\n\\mathcal{C}$ of approved candidates. For any committee size $K$, the goal is to\nchoose $K$ candidates to represent the voters' preferences. We study a\ncriterion known as \\emph{approximate stability}, where a committee is\n$\\lambda$-approximately-stable if there is no other committee $T$ preferred by\nat least $\\frac{\\lambda|T|}{k} |\\mathcal{V}| $ voters. We prove that a\n$3.65$-approximately stable committee always exists and can be computed\nalgorithmically in this setting. Our approach is based on finding a Lindahl\nequilibrium and sampling from a strongly Rayleigh distribution associated with\nit.", "published": "2025-07-31 19:36:37", "link": "http://arxiv.org/abs/2508.00130v1", "categories": ["cs.GT", "cs.DM"], "primary_category": "cs.GT"}
{"title": "Improved Bounds on Access-Redundancy Tradeoffs in Quantized Linear Computations", "abstract": "Consider the problem of computing quantized linear functions with only a few\nqueries. Formally, given $\\mathbf{x}\\in \\mathbb{R}^k$, our goal is to encode\n$\\mathbf{x}$ as $\\mathbf{c} \\in \\mathbb{R}^n$, for $n > k$, so that for any\n$\\mathbf{w} \\in A^k$, $\\mathbf{w}^T \\mathbf{x}$ can be computed using at most\n$\\ell$ queries to $\\mathbf{c}$. Here, $A$ is some finite set; in this paper we\nfocus on the case where $|A| = 2$.\n  Prior work \\emph{(Ramkumar, Raviv, and Tamo, Trans. IT, 2024)} has given\nconstructions and established impossibility results for this problem. We give\nimproved impossibility results, both for the general problem, and for the\nspecific class of construction (block construction) presented in that work. The\nlatter establishes that the block constructions of prior work are optimal\nwithin that class.\n  We also initiate the study of \\emph{approximate} recovery for this problem,\nwhere the goal is not to recover $\\mathbf{w}^T \\mathbf{x}$ exactly but rather\nto approximate it up to a parameter $\\varepsilon > 0$. We give several\nconstructions, and give constructions for $\\varepsilon = 0.1$ that outperform\nour impossibility result for exact schemes.", "published": "2025-07-31 21:58:31", "link": "http://arxiv.org/abs/2508.00183v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems", "abstract": "Existing web-scale recommendation systems commonly use supervised learning\nmethods that prioritize immediate user feedback. Although reinforcement\nlearning (RL) offers a solution to optimize longer-term goals, such as\nin-session engagement, applying it at web scale is challenging due to the\nextremely large action space and engineering complexity. In this paper, we\nintroduce RecoMind, a simulator-based RL framework designed for the effective\noptimization of session-based goals at web-scale. RecoMind leverages existing\nrecommendation models to establish a simulation environment and to bootstrap\nthe RL policy to optimize immediate user interactions from the outset. This\nmethod integrates well with existing industry pipelines, simplifying the\ntraining and deployment of RL policies. Additionally, RecoMind introduces a\ncustom exploration strategy to efficiently explore web-scale action spaces with\nhundreds of millions of items. We evaluated RecoMind through extensive offline\nsimulations and online A/B testing on a video streaming platform. Both methods\nshowed that the RL policy trained using RecoMind significantly outperforms\ntraditional supervised learning recommendation approaches in in-session user\nsatisfaction. In online A/B tests, the RL policy increased videos watched for\nmore than 10 seconds by 15.81\\% and improved session depth by 4.71\\% for\nsessions with at least 10 interactions. As a result, RecoMind presents a\nsystematic and scalable approach for embedding RL into web-scale recommendation\nsystems, showing great promise for optimizing session-based user satisfaction.", "published": "2025-07-31 23:01:14", "link": "http://arxiv.org/abs/2508.00201v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RL as Regressor: A Reinforcement Learning Approach for Function Approximation", "abstract": "Standard regression techniques, while powerful, are often constrained by\npredefined, differentiable loss functions such as mean squared error. These\nfunctions may not fully capture the desired behavior of a system, especially\nwhen dealing with asymmetric costs or complex, non-differentiable objectives.\nIn this paper, we explore an alternative paradigm: framing regression as a\nReinforcement Learning (RL) problem. We demonstrate this by treating a model's\nprediction as an action and defining a custom reward signal based on the\nprediction error, and we can leverage powerful RL algorithms to perform\nfunction approximation. Through a progressive case study of learning a noisy\nsine wave, we illustrate the development of an Actor-Critic agent, iteratively\nenhancing it with Prioritized Experience Replay, increased network capacity,\nand positional encoding to enable a capable RL agent for this regression task.\nOur results show that the RL framework not only successfully solves the\nregression problem but also offers enhanced flexibility in defining objectives\nand guiding the learning process.", "published": "2025-07-31 21:39:24", "link": "http://arxiv.org/abs/2508.00174v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission", "abstract": "The rapid development of artificial intelligence has driven smart health with\nnext-generation wireless communication technologies, stimulating exciting\napplications in remote diagnosis and intervention. To enable a timely and\neffective response for remote healthcare, efficient transmission of medical\ndata through noisy channels with limited bandwidth emerges as a critical\nchallenge. In this work, we propose a novel diffusion-based semantic\ncommunication framework, namely DiSC-Med, for the medical image transmission,\nwhere medical-enhanced compression and denoising blocks are developed for\nbandwidth efficiency and robustness, respectively. Unlike conventional\npixel-wise communication framework, our proposed DiSC-Med is able to capture\nthe key semantic information and achieve superior reconstruction performance\nwith ultra-high bandwidth efficiency against noisy channels. Extensive\nexperiments on real-world medical datasets validate the effectiveness of our\nframework, demonstrating its potential for robust and efficient telehealth\napplications.", "published": "2025-07-31 21:36:45", "link": "http://arxiv.org/abs/2508.00172v1", "categories": ["cs.LG", "eess.IV"], "primary_category": "cs.LG"}
{"title": "Data-Driven Motion Planning for Uncertain Nonlinear Systems", "abstract": "This paper proposes a data-driven motion-planning framework for nonlinear\nsystems that constructs a sequence of overlapping invariant polytopes. Around\neach randomly sampled waypoint, the algorithm identifies a convex admissible\nregion and solves data-driven linear-matrix-inequality problems to learn\nseveral ellipsoidal invariant sets together with their local state-feedback\ngains. The convex hull of these ellipsoids, still invariant under a\npiece-wise-affine controller obtained by interpolating the gains, is then\napproximated by a polytope. Safe transitions between nodes are ensured by\nverifying the intersection of consecutive convex-hull polytopes and introducing\nan intermediate node for a smooth transition. Control gains are interpolated in\nreal time via simplex-based interpolation, keeping the state inside the\ninvariant polytopes throughout the motion. Unlike traditional approaches that\nrely on system dynamics models, our method requires only data to compute safe\nregions and design state-feedback controllers. The approach is validated\nthrough simulations, demonstrating the effectiveness of the proposed method in\nachieving safe, dynamically feasible paths for complex nonlinear systems.", "published": "2025-07-31 20:41:34", "link": "http://arxiv.org/abs/2508.00154v1", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks", "abstract": "The electrocardiogram (ECG) is an inexpensive and widely available tool for\ncardiac assessment. Despite its standardized format and small file size, the\nhigh complexity and inter-individual variability of ECG signals (typically a\n60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep\nlearning models, especially when only small training datasets are available.\nThis study addresses these challenges by exploring feature generation methods\nfrom representative beat ECGs, focusing on Principal Component Analysis (PCA)\nand Autoencoders to reduce data complexity. We introduce three novel\nVariational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed\nbeta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their\neffectiveness in maintaining signal fidelity and enhancing downstream\nprediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE\nachieved superior signal reconstruction, reducing the mean absolute error (MAE)\nto 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE\nencodings, when combined with traditional ECG summary features, improved the\nprediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an\nholdout test set area under the receiver operating characteristic curve (AUROC)\nof 0.901 with a LGBM classifier. This performance nearly matches the 0.909\nAUROC of state-of-the-art CNN model but requires significantly less\ncomputational resources. Further, the ECG feature extraction-LGBM pipeline\navoids overfitting and retains predictive performance when trained with less\ndata. Our findings demonstrate that these VAE encodings are not only effective\nin simplifying ECG data but also provide a practical solution for applying deep\nlearning in contexts with limited-scale labeled training data.", "published": "2025-07-31 19:37:05", "link": "http://arxiv.org/abs/2508.00131v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Structured Transformations for Stable and Interpretable Neural Computation", "abstract": "Despite their impressive performance, contemporary neural networks often lack\nstructural safeguards that promote stable learning and interpretable behavior.\nIn this work, we introduce a reformulation of layer-level transformations that\ndeparts from the standard unconstrained affine paradigm. Each transformation is\ndecomposed into a structured linear operator and a residual corrective\ncomponent, enabling more disciplined signal propagation and improved training\ndynamics. Our formulation encourages internal consistency and supports stable\ninformation flow across depth, while remaining fully compatible with standard\nlearning objectives and backpropagation. Through a series of synthetic and\nreal-world experiments, we demonstrate that models constructed with these\nstructured transformations exhibit improved gradient conditioning, reduced\nsensitivity to perturbations, and layer-wise robustness. We further show that\nthese benefits persist across architectural scales and training regimes. This\nstudy serves as a foundation for a more principled class of neural\narchitectures that prioritize stability and transparency-offering new tools for\nreasoning about learning behavior without sacrificing expressive power.", "published": "2025-07-31 19:26:45", "link": "http://arxiv.org/abs/2508.00127v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "funOCLUST: Clustering Functional Data with Outliers", "abstract": "Functional data present unique challenges for clustering due to their\ninfinite-dimensional nature and potential sensitivity to outliers. An extension\nof the OCLUST algorithm to the functional setting is proposed to address these\nissues. The approach leverages the OCLUST framework, creating a robust method\nto cluster curves and trim outliers. The methodology is evaluated on both\nsimulated and real-world functional datasets, demonstrating strong performance\nin clustering and outlier identification.", "published": "2025-07-31 19:00:20", "link": "http://arxiv.org/abs/2508.00110v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Partial Floquet Transformation and Model Order Reduction of Linear Time-Periodic Systems", "abstract": "Time-periodic dynamical systems occur commonly both in nature and as\nengineered systems. Large-scale linear time-periodic dynamical systems, for\nexample, may arise through linearization of a nonlinear system about a given\nperiodic solution (possibly as a consequence of a baseline periodic forcing)\nwith subsequent spatial discretization. The potential need to simulate\nresponses to a wide variety of input profiles (viewed as perturbations off a\nbaseline periodic forcing) creates a potent incentive for effective model\nreduction strategies applicable to linear time-periodic (LTP) systems.\nClassical approaches that take into account the underlying time-periodic system\nstructure often utilize the Floquet transform; however, computation of the\nFloquet transform is typically intractable for large order systems. In this\npaper, we develop the notion of a partial Floquet transformation connected to\nselected invariant subspaces of a time-varying differential operator associated\nwith the LTP system. We modify and repurpose the Dominant Pole Algorithm of\nRommes to identify effective invariant subspaces useful for model reduction. We\ndiscuss the construction of associated partial Floquet transformations and\ntime-varying reduction bases with which to produce effective reduced-order LTP\nmodels and illustrate the process on a simple time-periodic system.", "published": "2025-07-31 23:53:42", "link": "http://arxiv.org/abs/2508.00221v1", "categories": ["math.NA", "cs.NA", "math.DS"], "primary_category": "math.NA"}
{"title": "Leveraging Operator Learning to Accelerate Convergence of the Preconditioned Conjugate Gradient Method", "abstract": "We propose a new deflation strategy to accelerate the convergence of the\npreconditioned conjugate gradient(PCG) method for solving parametric\nlarge-scale linear systems of equations. Unlike traditional deflation\ntechniques that rely on eigenvector approximations or recycled Krylov\nsubspaces, we generate the deflation subspaces using operator learning,\nspecifically the Deep Operator Network~(DeepONet). To this aim, we introduce\ntwo complementary approaches for assembling the deflation operators. The first\napproach approximates near-null space vectors of the discrete PDE operator\nusing the basis functions learned by the DeepONet. The second approach directly\nleverages solutions predicted by the DeepONet. To further enhance convergence,\nwe also propose several strategies for prescribing the sparsity pattern of the\ndeflation operator. A comprehensive set of numerical experiments encompassing\nsteady-state, time-dependent, scalar, and vector-valued problems posed on both\nstructured and unstructured geometries is presented and demonstrates the\neffectiveness of the proposed DeepONet-based deflated PCG method, as well as\nits generalization across a wide range of model parameters and problem\nresolutions.", "published": "2025-07-31 18:53:23", "link": "http://arxiv.org/abs/2508.00101v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math.OC", "65M55, 68T05, 49K20"], "primary_category": "math.NA"}
{"title": "Zeroing Diagonals, Conjugate Hollowization, and Characterizing Nondefinite Operators", "abstract": "We prove the conjecture by Damm and Fassbender that, for any pair $L,M$ of\nreal traceless matrices, there exists an orthogonal $V$ such that $V^{-1} L \\,\nV$ is hollow and $V M V^{-1}$ is almost hollow, where a matrix is hollow if and\nonly if its main diagonal consists only of 0s, and a traceless matrix is almost\nhollow if and only if all its main diagonal elements are 0 except, at most, the\nlast two.\n  The claim is a corollary to our considerably more general theorem, as well as\nanother corollary, revealing conditions on $L,M$ under which 0s can be\nintroduced by $V$ to all but the first or first two diagonal elements of\n$V^{-1} L \\, V$ and to all but the last two diagonal elements of $V M V^{-1}$.\n  By setting $L = M$, much is revealed concerning freedom and constraint\ninvolved in introducing 0s to the diagonal of a single operator. From this we\nprove novel characterizations of real traceless matrices, and a stronger\nversion of the seminal theorem by Fillmore that every real matrix is\northogonally similar to a matrix with a constant main diagonal.\n  Our results are contextualized in a characterization and classification of\nnondefinite matrices by, roughly, how many zeros can be introduced to their\ndiagonals, and it what ways.", "published": "2025-07-31 18:45:03", "link": "http://arxiv.org/abs/2508.00096v1", "categories": ["math.NA", "cs.NA", "math.RA", "65F25, 15A21, 15B10, 15A23, 15B99, 15A86"], "primary_category": "math.NA"}
{"title": "AdapDISCOM: An Adaptive Sparse Regression Method for High-Dimensional Multimodal Data With Block-Wise Missingness and Measurement Errors", "abstract": "Multimodal high-dimensional data are increasingly prevalent in biomedical\nresearch, yet they are often compromised by block-wise missingness and\nmeasurement errors, posing significant challenges for statistical inference and\nprediction. We propose AdapDISCOM, a novel adaptive direct sparse regression\nmethod that simultaneously addresses these two pervasive issues. Building on\nthe DISCOM framework, AdapDISCOM introduces modality-specific weighting schemes\nto account for heterogeneity in data structures and error magnitudes across\nmodalities. We establish the theoretical properties of AdapDISCOM, including\nmodel selection consistency and convergence rates under sub-Gaussian and\nheavy-tailed settings, and develop robust and computationally efficient\nvariants (AdapDISCOM-Huber and Fast-AdapDISCOM). Extensive simulations\ndemonstrate that AdapDISCOM consistently outperforms existing methods such as\nDISCOM, SCOM, and CoCoLasso, particularly under heterogeneous contamination and\nheavy-tailed distributions. Finally, we apply AdapDISCOM to Alzheimers Disease\nNeuroimaging Initiative (ADNI) data, demonstrating improved prediction of\ncognitive scores and reliable selection of established biomarkers, even with\nsubstantial missingness and measurement errors. AdapDISCOM provides a flexible,\nrobust, and scalable framework for high-dimensional multimodal data analysis\nunder realistic data imperfections.", "published": "2025-07-31 19:16:48", "link": "http://arxiv.org/abs/2508.00120v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting", "abstract": "This work integrates Bayesian regime detection with conditional neural\nprocesses for 24-hour electricity price prediction in the German market. Our\nmethodology integrates regime detection using a disentangled sticky\nhierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to\ndaily electricity prices. Each identified regime is subsequently modeled by an\nindependent conditional neural process (CNP), trained to learn localized\nmappings from input contexts to 24-dimensional hourly price trajectories, with\nfinal predictions computed as regime-weighted mixtures of these CNP outputs. We\nrigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated\nauto-regressive (LEAR) models by integrating their forecasts into diverse\nbattery storage optimization frameworks, including price arbitrage, risk\nmanagement, grid services, and cost minimization. This operational utility\nassessment revealed complex performance trade-offs: LEAR often yielded superior\nabsolute profits or lower costs, while DNN showed exceptional optimality in\nspecific cost-minimization contexts. Recognizing that raw prediction accuracy\ndoesn't always translate to optimal operational outcomes, we employed TOPSIS as\na comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified\nLEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model\nemerged as the most balanced and preferred solution for 2021, 2022 and 2023.", "published": "2025-07-31 09:12:25", "link": "http://arxiv.org/abs/2508.00040v1", "categories": ["cs.LG", "math.PR", "stat.AP", "stat.ML", "60J20, 68T07"], "primary_category": "cs.LG"}
{"title": "Closed-form Expression for the Power Profile in Wideband Systems with Inter-channel Stimulated Raman Scattering", "abstract": "Wideband systems experience significant inter-channel stimulated Raman\nscattering (ISRS) and channel-dependent losses. Due to the non-uniform\nattenuation profile, the combined effects of ISRS and fiber loss can only be\naccurately estimated using numerical methods. In this work, we present an\napproximate closed-form expression for the channels' power profile accounting\nfor these combined effects. We validate the proposed expression against\nnumerical solutions in the case of CLU transmission, showing high accuracy for\nboth single-span and multi-span fiber-optic links. Additionally, we derive an\ninverse expression, formulated as a function of the output power, which can be\nutilized to target a desired optical signal-to-noise ratio (OSNR) profile\nthrough pre-emphasis of the launched channel powers.", "published": "2025-07-31 18:41:00", "link": "http://arxiv.org/abs/2508.00093v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning", "abstract": "In medical scenarios, effectively retrieving external knowledge and\nleveraging it for rigorous logical reasoning is of significant importance.\nDespite their potential, existing work has predominantly focused on enhancing\neither retrieval or reasoning capabilities of the models in isolation, with\nlittle attention given to their joint optimization, which leads to limited\ncoordination between the two processes. Additionally, current methods rely\nheavily on supervised fine-tuning (SFT), which can cause models to memorize\nexisting problem-solving pathways, thereby restricting their generalization\nability when confronted with novel problem contexts. Furthermore, while some\nstudies have explored to improve retrieval-augmented reasoning in general\ndomains via reinforcement learning, their reward function designs do not\nadequately capture the specific demands of the medical domain. To address these\nchallenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented\n**R**easoning framework driven by progressive **R**einforcement learning. In\nthis framework, we first develop the model's ability to perform logical\nreasoning over medical problems. Subsequently, on the basis of this foundation,\nwe adaptively optimize the retrieval capability to better align with the\ncharacteristics of knowledge corpus and external information utilization\nthroughout the reasoning process. Finally, we conduct joint optimization of the\nmodel's retrieval and reasoning coordination. Extensive experiments indicate\nthat **Med-R$^3$** could achieve state-of-the-art performances, with\nLLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by\n3.93\\% at a comparable parameter scale, while Qwen2.5-14B augmented with\nMed-R$^3$ shows a more substantial gain of 13.53\\%.", "published": "2025-07-31 13:31:01", "link": "http://arxiv.org/abs/2507.23541v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks", "abstract": "While large audio-language models have advanced open-ended audio\nunderstanding, they still fall short of nuanced human-level comprehension. This\ngap persists largely because current benchmarks, limited by data annotations\nand evaluation metrics, fail to reliably distinguish between generic and highly\ndetailed model outputs. To this end, this work introduces MECAT, a Multi-Expert\nConstructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via\na pipeline that integrates analysis from specialized expert models with\nChain-of-Thought large language model reasoning, MECAT provides\nmulti-perspective, fine-grained captions and open-set question-answering pairs.\nThe benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced\nAudio Text Evaluation). This metric penalizes generic terms and rewards\ndetailed descriptions by combining single-sample semantic similarity with\ncross-sample discriminability. A comprehensive evaluation of state-of-the-art\naudio models is also presented, providing new insights into their current\ncapabilities and limitations. The data and code are available at\nhttps://github.com/xiaomi-research/mecat", "published": "2025-07-31 12:47:43", "link": "http://arxiv.org/abs/2507.23511v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection", "abstract": "Liver diseases are a serious health concern in the world, which requires\nprecise and timely diagnosis to enhance the survival chances of patients. The\ncurrent literature implemented numerous machine learning and deep learning\nmodels to classify liver diseases, but most of them had some issues like high\nmisclassification error, poor interpretability, prohibitive computational\nexpense, and lack of good preprocessing strategies. In order to address these\ndrawbacks, we introduced StackLiverNet in this study; an interpretable stacked\nensemble model tailored to the liver disease detection task. The framework uses\nadvanced data preprocessing and feature selection technique to increase model\nrobustness and predictive ability. Random undersampling is performed to deal\nwith class imbalance and make the training balanced. StackLiverNet is an\nensemble of several hyperparameter-optimized base classifiers, whose\ncomplementary advantages are used through a LightGBM meta-model. The provided\nmodel demonstrates excellent performance, with the testing accuracy of 99.89%,\nCohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and\nefficient training and inference speeds that are amenable to clinical practice\n(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local\nInterpretable Model-Agnostic Explanations (LIME) are applied to generate\ntransparent explanations of individual predictions, revealing high\nconcentrations of Alkaline Phosphatase and moderate SGOT as important\nobservations of liver disease. Also, SHAP was used to rank features by their\nglobal contribution to predictions, while the Morris method confirmed the most\ninfluential features through sensitivity analysis.", "published": "2025-07-31 19:13:30", "link": "http://arxiv.org/abs/2508.00117v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Mixed User-Centered Approach to Enable Augmented Intelligence in Intelligent Tutoring Systems: The Case of MathAIde app", "abstract": "Integrating Artificial Intelligence in Education (AIED) aims to enhance\nlearning experiences through technologies like Intelligent Tutoring Systems\n(ITS), offering personalized learning, increased engagement, and improved\nretention rates. However, AIED faces three main challenges: the critical role\nof teachers in the design process, the limitations and reliability of AI tools,\nand the accessibility of technological resources. Augmented Intelligence (AuI)\naddresses these challenges by enhancing human capabilities rather than\nreplacing them, allowing systems to suggest solutions. In contrast, humans\nprovide final assessments, thus improving AI over time. In this sense, this\nstudy focuses on designing, developing, and evaluating MathAIde, an ITS that\ncorrects mathematics exercises using computer vision and AI and provides\nfeedback based on photos of student work. The methodology included\nbrainstorming sessions with potential users, high-fidelity prototyping, A/B\ntesting, and a case study involving real-world classroom environments for\nteachers and students. Our research identified several design possibilities for\nimplementing AuI in ITSs, emphasizing a balance between user needs and\ntechnological feasibility. Prioritization and validation through prototyping\nand testing highlighted the importance of efficiency metrics, ultimately\nleading to a solution that offers pre-defined remediation alternatives for\nteachers. Real-world deployment demonstrated the usefulness of the proposed\nsolution. Our research contributes to the literature by providing a usable,\nteacher-centered design approach that involves teachers in all design phases.\nAs a practical implication, we highlight that the user-centered design approach\nincreases the usefulness and adoption potential of AIED systems, especially in\nresource-limited environments.", "published": "2025-07-31 18:56:01", "link": "http://arxiv.org/abs/2508.00103v2", "categories": ["cs.HC", "cs.AI", "68T01", "H.5.0; I.2.0"], "primary_category": "cs.HC"}
{"title": "Cell-Free Massive MIMO SWIPT with Beyond Diagonal Reconfigurable Intelligent Surfaces", "abstract": "We investigate the integration of beyond diagonal reconfigurable intelligent\nsurfaces (BDRISs) into cell free massive multiple input multiple output\n(CFmMIMO) systems to enhance simultaneous wireless information and power\ntransfer (SWIPT). To simultaneously support two groups of users energy\nreceivers (ERs) and information receivers (IRs) without sacrificing time\nfrequency resources, a subset of access points (APs) is dedicated to serving\nERs with the aid of a BDRIS, while the remaining APs focus on supporting IRs. A\nprotective partial zero forcing precoding technique is implemented at the APs\nto manage the non coherent interference between the ERs and IRs. Subsequently,\nclosed form expressions for the spectral efficiency of the IRs and the average\nsum of harvested energy at the ERs are leveraged to formulate a comprehensive\noptimization problem. This problem jointly optimizes the AP selection, AP power\ncontrol, and scattering matrix design at the BDRIS, all based on long term\nstatistical channel state information. This challenging problem is then\neffectively transformed into more tractable forms. To solve these sub problems,\nefficient algorithms are proposed, including a heuristic search for the\nscattering matrix design, as well as successive convex approximation and deep\nreinforcement learning methods for the joint AP mode selection and power\ncontrol design. Numerical results show that a BDRIS with a group or fully\nconnected architecture achieves significant energy harvesting gains over the\nconventional diagonal RIS, especially delivering up to a seven fold increase in\nthe average sum of harvested energy when a heuristic based scattering matrix\ndesign is employed.", "published": "2025-07-31 16:24:28", "link": "http://arxiv.org/abs/2507.23702v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Secure Integrated Sensing and Communication Networks: Stochastic Performance Analysis", "abstract": "This paper analyzes the stochastic security performance of a multiple-input\nmultiple-output (MIMO) integrated sensing and communication (ISAC) system in a\ndownlink scenario. A base station (BS) transmits a multi-functional signal to\nsimultaneously communicate with a user, sense a target's angular location, and\ncounteract eavesdropping threats. The attack model considers a passive\nsingle-antenna communication eavesdropper intercepting communication data, as\nwell as a multi-antenna sensing eavesdropper attempting to infer the target's\nlocation. We also consider a malicious target scenario where the target plays\nthe role of the communication eavesdropper. The BS-user and BS-eavesdroppers\nchannels follow Rayleigh fading, while the target's azimuth angle is uniformly\ndistributed. To evaluate the performance in this random network, we derive the\nergodic secrecy rate (ESR) and the ergodic Cramer-Rao lower bound (CRB), for\ntarget localization, at both the BS and the sensing eavesdropper. This involves\ncomputing the probability density functions (PDFs) of the signal-to-noise ratio\n(SNR) and CRB, leveraging the central limit theorem for tractability. We\ncharacterize the boundary of the CRB-secrecy rate region, and interpret the\nperformance tradeoffs between communication and sensing while guaranteeing a\nlevel of security and privacy in the random ISAC networks.", "published": "2025-07-31 04:13:20", "link": "http://arxiv.org/abs/2507.23234v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Distributed AI Agents for Cognitive Underwater Robot Autonomy", "abstract": "Achieving robust cognitive autonomy in robots navigating complex,\nunpredictable environments remains a fundamental challenge in robotics. This\npaper presents Underwater Robot Self-Organizing Autonomy (UROSA), a\ngroundbreaking architecture leveraging distributed Large Language Model AI\nagents integrated within the Robot Operating System 2 (ROS 2) framework to\nenable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA\ndecentralises cognition into specialised AI agents responsible for multimodal\nperception, adaptive reasoning, dynamic mission planning, and real-time\ndecision-making. Central innovations include flexible agents dynamically\nadapting their roles, retrieval-augmented generation utilising vector databases\nfor efficient knowledge management, reinforcement learning-driven behavioural\noptimisation, and autonomous on-the-fly ROS 2 node generation for runtime\nfunctional extensibility. Extensive empirical validation demonstrates UROSA's\npromising adaptability and reliability through realistic underwater missions in\nsimulation and real-world deployments, showing significant advantages over\ntraditional rule-based architectures in handling unforeseen scenarios,\nenvironmental uncertainties, and novel mission objectives. This work not only\nadvances underwater autonomy but also establishes a scalable, safe, and\nversatile cognitive robotics framework capable of generalising to a diverse\narray of real-world applications.", "published": "2025-07-31 17:18:55", "link": "http://arxiv.org/abs/2507.23735v2", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Real-time Generation of Various Types of Nodding for Avatar Attentive Listening System", "abstract": "In human dialogue, nonverbal information such as nodding and facial\nexpressions is as crucial as verbal information, and spoken dialogue systems\nare also expected to express such nonverbal behaviors. We focus on nodding,\nwhich is critical in an attentive listening system, and propose a model that\npredicts both its timing and type in real time. The proposed model builds on\nthe voice activity projection (VAP) model, which predicts voice activity from\nboth listener and speaker audio. We extend it to prediction of various types of\nnodding in a continuous and real-time manner unlike conventional models. In\naddition, the proposed model incorporates multi-task learning with verbal\nbackchannel prediction and pretraining on general dialogue data. In the timing\nand type prediction task, the effectiveness of multi-task learning was\nsignificantly demonstrated. We confirmed that reducing the processing rate\nenables real-time operation without a substantial drop in accuracy, and\nintegrated the model into an avatar attentive listening system. Subjective\nevaluations showed that it outperformed the conventional method, which always\ndoes nodding in sync with verbal backchannel. The code and trained models are\navailable at https://github.com/MaAI-Kyoto/MaAI.", "published": "2025-07-31 07:34:32", "link": "http://arxiv.org/abs/2507.23298v2", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "DD-DeepONet: Domain decomposition and DeepONet for solving partial differential equations in three application scenarios", "abstract": "In certain practical engineering applications, there is an urgent need to\nperform repetitive solving of partial differential equations (PDEs) in a short\nperiod. This paper primarily considers three scenarios requiring extensive\nrepetitive simulations. These three scenarios are categorized based on whether\nthe geometry, boundary conditions(BCs), or parameters vary. We introduce the\nDD-DeepONet, a framework with strong scalability, whose core concept involves\ndecomposing complex geometries into simple structures and vice versa. We\nprimarily study complex geometries composed of rectangles and cuboids, which\nhave numerous practical applications. Simultaneously, stretching\ntransformations are applied to simple geometries to solve shape-dependent\nproblems. This work solves several prototypical PDEs in three scenarios,\nincluding Laplace, Poission, N-S, and drift-diffusion equations, demonstrating\nDD-DeepONet's computational potential. Experimental results demonstrate that\nDD-DeepONet reduces training difficulty, requires smaller datasets andVRAMper\nnetwork, and accelerates solution acquisition.", "published": "2025-07-31 23:45:12", "link": "http://arxiv.org/abs/2508.02717v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Spline Shallow Water Moment Equations", "abstract": "Reduced models for free-surface flows are required due to the high\ndimensionality of the underlying incompressible Navier-Stokes equations, which\nneed to fully resolve the flow in vertical direction to compute the surface\nheight. On the other hand, standard reduced models, such as the classical\nShallow Water Equations (SWE), which assume a small depth-to-length ratio and\nuse depth-averaging, do not provide information about the vertical velocity\nprofile variations. As a compromise, a recently proposed moment approach for\nshallow flow using Legendre polynomials as ansatz functions for vertical\nvelocity variations showed the derivation of so-called Shallow Water Moment\nEquations (SWME) that combine low dimensionality with velocity profile\nmodeling. However, only global polynomials are considered so far.\n  This paper introduces Spline Shallow Water Moment Equations (SSWME) where\npiecewise defined spline ansatz functions allow for a flexible representation\nof velocity profiles with lower regularity. The local support of the spline\nbasis functions opens up the possibility of adaptability and greater\nflexibility regarding some typical profile shapes. We systematically derive and\nanalyze hierarchies of SSWME models with different number of basis functions\nand different degrees, before deriving a regularized hyperbolic version by\nperforming a hyperbolic regularization with analytical proof of hyperbolicity\nfor a hierarchy of high-order SSWME models. Numerical simulations show high\naccuracy and robustness of the new models.", "published": "2025-07-31 15:00:15", "link": "http://arxiv.org/abs/2508.02714v1", "categories": ["math.NA", "cs.NA", "math.AP", "physics.flu-dyn", "76D05, 35L65, 65M08, 76M12"], "primary_category": "math.NA"}
{"title": "Precoder Design for User-Centric Network Massive MIMO: A Symplectic Optimization Approach", "abstract": "In this paper, we utilize symplectic optimization to design a precoder for\nuser-centric network (UCN) massive multiple-input multiple-output (MIMO)\nsystems, where a subset of base stations (BSs) serves each user terminal (UT)\ninstead of using all BSs. In UCN massive MIMO systems, the dimension of the\nprecoders is reduced compared to conventional network massive MIMO. It\nsimplifies the implementation of precoders in practical systems. However, the\nmatrix inversion in traditional linear precoders still requires high\ncomputational complexity. To avoid the matrix inversion, we employ the\nsymplectic optimization framework, where optimization problems are solved based\non dissipative Hamiltonian dynamical systems. To better fit symplectic\noptimization, we transform the received model into the real field and\nreformulate the weighted sum-rate (WSR) maximization problem. The objective\nfunction of the optimization problem is viewed as the potential energy of the\ndynamical system. Due to energy dissipation, the continuous dynamical system\nalways converges to a state with minimal potential energy. By discretizing the\ncontinuous system while preserving the symplectic structure, we obtain an\niterative method for the precoder design. The complexity analysis of the\nproposed symplectic method is also provided to show its high computational\nefficiency. Simulation results demonstrate that the proposed precoder design\nbased on symplectic optimization outperforms the weighted minimum mean-square\nerror (WMMSE) precoder in the UCN massive MIMO system.", "published": "2025-07-31 10:44:49", "link": "http://arxiv.org/abs/2508.02713v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physics-guided denoiser network for enhanced additive manufacturing data quality", "abstract": "Modern engineering systems are increasingly equipped with sensors for\nreal-time monitoring and decision-making. However, the data collected by these\nsensors is often noisy and difficult to interpret, limiting its utility for\ncontrol and diagnostics. In this work, we propose a physics-informed denoising\nframework that integrates energy-based model and Fisher score regularization to\njointly reduce data noise and enforce physical consistency with a physics-based\nmodel. The approach is first validated on benchmark problems, including the\nsimple harmonic oscillator, Burgers' equation, and Laplace's equation, across\nvarying noise levels. We then apply the denoising framework to real thermal\nemission data from laser powder bed fusion (LPBF) additive manufacturing\nexperiments, using a trained Physics-Informed Neural Network (PINN) surrogate\nmodel of the LPBF process to guide denoising. Results show that the proposed\nmethod outperforms baseline neural network denoisers, effectively reducing\nnoise under a range of LPBF processing conditions. This physics-guided\ndenoising strategy enables robust, real-time interpretation of low-cost sensor\ndata, facilitating predictive control and improved defect mitigation in\nadditive manufacturing.", "published": "2025-07-31 05:21:02", "link": "http://arxiv.org/abs/2508.02712v1", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "DSBC : Data Science task Benchmarking with Context engineering", "abstract": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.", "published": "2025-07-31 08:32:37", "link": "http://arxiv.org/abs/2507.23336v2", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
