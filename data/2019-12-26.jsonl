{"title": "Amharic-Arabic Neural Machine Translation", "abstract": "Many automatic translation works have been addressed between major European\nlanguage pairs, by taking advantage of large scale parallel corpora, but very\nfew research works are conducted on the Amharic-Arabic language pair due to its\nparallel data scarcity. Two Long Short-Term Memory (LSTM) and Gated Recurrent\nUnits (GRU) based Neural Machine Translation (NMT) models are developed using\nAttention-based Encoder-Decoder architecture which is adapted from the\nopen-source OpenNMT system. In order to perform the experiment, a small\nparallel Quranic text corpus is constructed by modifying the existing\nmonolingual Arabic text and its equivalent translation of Amharic language text\ncorpora available on Tanzile. LSTM and GRU based NMT models and Google\nTranslation system are compared and found that LSTM based OpenNMT outperforms\nGRU based OpenNMT and Google Translation system, with a BLEU score of 12%, 11%,\nand 6% respectively.", "published": "2019-12-26 15:41:35", "link": "http://arxiv.org/abs/1912.13161v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Coursera Corpus Mining and Multistage Fine-Tuning for Improving Lectures\n  Translation", "abstract": "Lectures translation is a case of spoken language translation and there is a\nlack of publicly available parallel corpora for this purpose. To address this,\nwe examine a language independent framework for parallel corpus mining which is\na quick and effective way to mine a parallel corpus from publicly available\nlectures at Coursera. Our approach determines sentence alignments, relying on\nmachine translation and cosine similarity over continuous-space sentence\nrepresentations. We also show how to use the resulting corpora in a multistage\nfine-tuning based domain adaptation for high-quality lectures translation. For\nJapanese--English lectures translation, we extracted parallel data of\napproximately 40,000 lines and created development and test sets through manual\nfiltering for benchmarking translation performance. We demonstrate that the\nmined corpus greatly enhances the quality of translation when used in\nconjunction with out-of-domain parallel corpora via multistage training. This\npaper also suggests some guidelines to gather and clean corpora, mine parallel\nsentences, address noise in the mined data, and create high-quality evaluation\nsplits. For the sake of reproducibility, we will release our code for parallel\ndata creation.", "published": "2019-12-26 01:12:31", "link": "http://arxiv.org/abs/1912.11739v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Text Classification for Azerbaijani Language Using Machine Learning and\n  Embedding", "abstract": "Text classification systems will help to solve the text clustering problem in\nthe Azerbaijani language. There are some text-classification applications for\nforeign languages, but we tried to build a newly developed system to solve this\nproblem for the Azerbaijani language. Firstly, we tried to find out potential\npractice areas. The system will be useful in a lot of areas. It will be mostly\nused in news feed categorization. News websites can automatically categorize\nnews into classes such as sports, business, education, science, etc. The system\nis also used in sentiment analysis for product reviews. For example, the\ncompany shares a photo of a new product on Facebook and the company receives a\nthousand comments for new products. The systems classify the comments into\ncategories like positive or negative. The system can also be applied in\nrecommended systems, spam filtering, etc. Various machine learning techniques\nsuch as Naive Bayes, SVM, Decision Trees have been devised to solve the text\nclassification problem in Azerbaijani language.", "published": "2019-12-26 08:38:49", "link": "http://arxiv.org/abs/1912.13362v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multi-Source Direction-of-Arrival Estimation Using Improved Estimation\n  Consistency Method", "abstract": "We address the problem of estimating direction-of-arrivals (DOAs) for\nmultiple acoustic sources in a reverberant environment using a spherical\nmicrophone array. It is well-known that multi-source DOA estimation is\nchallenging in the presence of room reverberation, environmental noise and\noverlapping sources. In this work, we introduce multiple schemes to improve the\nrobustness of estimation consistency (EC) approach in reverberant and noisy\nconditions through redefined and modified parametric weights. Simulation\nresults show that our proposed methods achieve superior performance compared to\nthe existing EC approach, especially when the sources are spatially close in a\nreverberant environment.", "published": "2019-12-26 05:53:47", "link": "http://arxiv.org/abs/1912.11781v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Attention-based ASR with Lightweight and Dynamic Convolutions", "abstract": "End-to-end (E2E) automatic speech recognition (ASR) with sequence-to-sequence\nmodels has gained attention because of its simple model training compared with\nconventional hidden Markov model based ASR. Recently, several studies report\nthe state-of-the-art E2E ASR results obtained by Transformer. Compared to\nrecurrent neural network (RNN) based E2E models, training of Transformer is\nmore efficient and also achieves better performance on various tasks. However,\nself-attention used in Transformer requires computation quadratic in its input\nlength. In this paper, we propose to apply lightweight and dynamic convolution\nto E2E ASR as an alternative architecture to the self-attention to make the\ncomputational order linear. We also propose joint training with connectionist\ntemporal classification, convolution on the frequency axis, and combination\nwith self-attention. With these techniques, the proposed architectures achieve\nbetter performance than RNN-based E2E model and performance competitive to\nstate-of-the-art Transformer on various ASR benchmarks including\nnoisy/reverberant tasks.", "published": "2019-12-26 07:37:21", "link": "http://arxiv.org/abs/1912.11793v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Score and Lyrics-Free Singing Voice Generation", "abstract": "Generative models for singing voice have been mostly concerned with the task\nof ``singing voice synthesis,'' i.e., to produce singing voice waveforms given\nmusical scores and text lyrics. In this work, we explore a novel yet\nchallenging alternative: singing voice generation without pre-assigned scores\nand lyrics, in both training and inference time. In particular, we outline\nthree such generation schemes, and propose a pipeline to tackle these new\ntasks. Moreover, we implement such models using generative adversarial networks\nand evaluate them both objectively and subjectively.", "published": "2019-12-26 01:45:03", "link": "http://arxiv.org/abs/1912.11747v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
