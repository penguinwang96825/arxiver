{"title": "A Bidirectional Tree Tagging Scheme for Joint Medical Relation\n  Extraction", "abstract": "Joint medical relation extraction refers to extracting triples, composed of\nentities and relations, from the medical text with a single model. One of the\nsolutions is to convert this task into a sequential tagging task. However, in\nthe existing works, the methods of representing and tagging the triples in a\nlinear way failed to the overlapping triples, and the methods of organizing the\ntriples as a graph faced the challenge of large computational effort. In this\npaper, inspired by the tree-like relation structures in the medical text, we\npropose a novel scheme called Bidirectional Tree Tagging (BiTT) to form the\nmedical relation triples into two two binary trees and convert the trees into a\nword-level tags sequence. Based on BiTT scheme, we develop a joint relation\nextraction model to predict the BiTT tags and further extract medical triples\nefficiently. Our model outperforms the best baselines by 2.0\\% and 2.5\\% in F1\nscore on two medical datasets. What's more, the models with our BiTT scheme\nalso obtain promising results in three public datasets of other domains.", "published": "2020-08-31 03:28:18", "link": "http://arxiv.org/abs/2008.13339v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Generic Music Features with Single Layer Feedforward Network\n  using Unsupervised Hebbian Computation", "abstract": "With the ever-increasing number of digital music and vast music track\nfeatures through popular online music streaming software and apps, feature\nrecognition using the neural network is being used for experimentation to\nproduce a wide range of results across a variety of experiments recently.\nThrough this work, the authors extract information on such features from a\npopular open-source music corpus and explored new recognition techniques, by\napplying unsupervised Hebbian learning techniques on their single-layer neural\nnetwork using the same dataset. The authors show the detailed empirical\nfindings to simulate how such an algorithm can help a single layer feedforward\nnetwork in training for music feature learning as patterns. The unsupervised\ntraining algorithm enhances their proposed neural network to achieve an\naccuracy of 90.36% for successful music feature detection. For comparative\nanalysis against similar tasks, authors put their results with the likes of\nseveral previous benchmark works. They further discuss the limitations and\nthorough error analysis of their work. The authors hope to discover and gather\nnew information about this particular classification technique and its\nperformance, and further understand future potential directions and prospects\nthat could improve the art of computational music feature recognition.", "published": "2020-08-31 13:57:31", "link": "http://arxiv.org/abs/2008.13609v1", "categories": ["cs.CL", "68T07", "I.2.4; I.2.6"], "primary_category": "cs.CL"}
{"title": "SemEval-2020 Task 6: Definition extraction from free text with the DEFT\n  corpus", "abstract": "Research on definition extraction has been conducted for well over a decade,\nlargely with significant constraints on the type of definitions considered. In\nthis work, we present DeftEval, a SemEval shared task in which participants\nmust extract definitions from free text using a term-definition pair corpus\nthat reflects the complex reality of definitions in natural language.\nDefinitions and glosses in free text often appear without explicit indicators,\nacross sentences boundaries, or in an otherwise complex linguistic manner.\nDeftEval involved 3 distinct subtasks: 1)Sentence classification, 2) sequence\nlabeling, and 3) relation extraction.", "published": "2020-08-31 15:55:24", "link": "http://arxiv.org/abs/2008.13694v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PNEL: Pointer Network based End-To-End Entity Linking over Knowledge\n  Graphs", "abstract": "Question Answering systems are generally modelled as a pipeline consisting of\na sequence of steps. In such a pipeline, Entity Linking (EL) is often the first\nstep. Several EL models first perform span detection and then entity\ndisambiguation. In such models errors from the span detection phase cascade to\nlater steps and result in a drop of overall accuracy. Moreover, lack of gold\nentity spans in training data is a limiting factor for span detector training.\nHence the movement towards end-to-end EL models began where no separate span\ndetection step is involved. In this work we present a novel approach to\nend-to-end EL by applying the popular Pointer Network model, which achieves\ncompetitive performance. We demonstrate this in our evaluation over three\ndatasets on the Wikidata Knowledge Graph.", "published": "2020-08-31 21:15:28", "link": "http://arxiv.org/abs/2009.00106v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classifier Combination Approach for Question Classification for Bengali\n  Question Answering System", "abstract": "Question classification (QC) is a prime constituent of automated question\nanswering system. The work presented here demonstrates that the combination of\nmultiple models achieve better classification performance than those obtained\nwith existing individual models for the question classification task in\nBengali. We have exploited state-of-the-art multiple model combination\ntechniques, i.e., ensemble, stacking and voting, to increase QC accuracy.\nLexical, syntactic and semantic features of Bengali questions are used for four\nwell-known classifiers, namely Na\\\"{\\i}ve Bayes, kernel Na\\\"{\\i}ve Bayes, Rule\nInduction, and Decision Tree, which serve as our base learners. Single-layer\nquestion-class taxonomy with 8 coarse-grained classes is extended to two-layer\ntaxonomy by adding 69 fine-grained classes. We carried out the experiments both\non single-layer and two-layer taxonomies. Experimental results confirmed that\nclassifier combination approaches outperform single classifier classification\napproaches by 4.02% for coarse-grained question classes. Overall, the stacking\napproach produces the best results for fine-grained classification and achieves\n87.79% of accuracy. The approach presented here could be used in other\nIndo-Aryan or Indic languages to develop a question answering system.", "published": "2020-08-31 13:39:04", "link": "http://arxiv.org/abs/2008.13597v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mapping Researchers with PeopleMap", "abstract": "Discovering research expertise at universities can be a difficult task.\nDirectories routinely become outdated, and few help in visually summarizing\nresearchers' work or supporting the exploration of shared interests among\nresearchers. This results in lost opportunities for both internal and external\nentities to discover new connections, nurture research collaboration, and\nexplore the diversity of research. To address this problem, at Georgia Tech, we\nhave been developing PeopleMap, an open-source interactive web-based tool that\nuses natural language processing (NLP) to create visual maps for researchers\nbased on their research interests and publications. Requiring only the\nresearchers' Google Scholar profiles as input, PeopleMap generates and\nvisualizes embeddings for the researchers, significantly reducing the need for\nmanual curation of publication information. To encourage and facilitate easy\nadoption and extension of PeopleMap, we have open-sourced it under the\npermissive MIT license at https://github.com/poloclub/people-map. PeopleMap has\nreceived positive feedback and enthusiasm for expanding its adoption across\nGeorgia Tech.", "published": "2020-08-31 20:46:27", "link": "http://arxiv.org/abs/2009.00091v1", "categories": ["cs.DL", "cs.CL", "cs.HC"], "primary_category": "cs.DL"}
{"title": "Discovering Bilingual Lexicons in Polyglot Word Embeddings", "abstract": "Bilingual lexicons and phrase tables are critical resources for modern\nMachine Translation systems. Although recent results show that without any seed\nlexicon or parallel data, highly accurate bilingual lexicons can be learned\nusing unsupervised methods, such methods rely on the existence of large, clean\nmonolingual corpora. In this work, we utilize a single Skip-gram model trained\non a multilingual corpus yielding polyglot word embeddings, and present a novel\nfinding that a surprisingly simple constrained nearest-neighbor sampling\ntechnique in this embedding space can retrieve bilingual lexicons, even in\nharsh social media data sets predominantly written in English and Romanized\nHindi and often exhibiting code switching. Our method does not require\nmonolingual corpora, seed lexicons, or any other such resources. Additionally,\nacross three European language pairs, we observe that polyglot word embeddings\nindeed learn a rich semantic representation of words and substantial bilingual\nlexicons can be retrieved using our constrained nearest neighbor sampling. We\ninvestigate potential reasons and downstream applications in settings spanning\nboth clean texts and noisy social media data sets, and in both resource-rich\nand under-resourced language pairs.", "published": "2020-08-31 03:57:50", "link": "http://arxiv.org/abs/2008.13347v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
