{"title": "Gender Representation in Open Source Speech Resources", "abstract": "With the rise of artificial intelligence (AI) and the growing use of\ndeep-learning architectures, the question of ethics, transparency and fairness\nof AI systems has become a central concern within the research community. We\naddress transparency and fairness in spoken language systems by proposing a\nstudy about gender representation in speech resources available through the\nOpen Speech and Language Resource platform. We show that finding gender\ninformation in open source corpora is not straightforward and that gender\nbalance depends on other corpus characteristics (elicited/non elicited speech,\nlow/high resource language, speech task targeted). The paper ends with\nrecommendations about metadata and gender information for researchers in order\nto assure better transparency of the speech systems built using such corpora.", "published": "2020-03-18 10:23:36", "link": "http://arxiv.org/abs/2003.08132v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Pidgin Text Generation By Pivoting English Data and\n  Self-Training", "abstract": "West African Pidgin English is a language that is significantly spoken in\nWest Africa, consisting of at least 75 million speakers. Nevertheless, proper\nmachine translation systems and relevant NLP datasets for pidgin English are\nvirtually absent. In this work, we develop techniques targeted at bridging the\ngap between Pidgin English and English in the context of natural language\ngeneration. %As a proof of concept, we explore the proposed techniques in the\narea of data-to-text generation. By building upon the previously released\nmonolingual Pidgin English text and parallel English data-to-text corpus, we\nhope to build a system that can automatically generate Pidgin English\ndescriptions from structured data. We first train a data-to-English text\ngeneration system, before employing techniques in unsupervised neural machine\ntranslation and self-training to establish the Pidgin-to-English cross-lingual\nalignment. The human evaluation performed on the generated Pidgin texts shows\nthat, though still far from being practically usable, the pivoting +\nself-training technique improves both Pidgin text fluency and relevance.", "published": "2020-03-18 15:27:35", "link": "http://arxiv.org/abs/2003.08272v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "X-Stance: A Multilingual Multi-Target Dataset for Stance Detection", "abstract": "We extract a large-scale stance detection dataset from comments written by\ncandidates of elections in Switzerland. The dataset consists of German, French\nand Italian text, allowing for a cross-lingual evaluation of stance detection.\nIt contains 67 000 comments on more than 150 political issues (targets). Unlike\nstance detection models that have specific target issues, we use the dataset to\ntrain a single model on all the issues. To make learning across targets\npossible, we prepend to each instance a natural question that represents the\ntarget (e.g. \"Do you support X?\"). Baseline results from multilingual BERT show\nthat zero-shot cross-lingual and cross-target transfer of stance detection is\nmoderately successful with this approach.", "published": "2020-03-18 17:58:10", "link": "http://arxiv.org/abs/2003.08385v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Analysis on the Learning Rules of the Skip-Gram Model", "abstract": "To improve the generalization of the representations for natural language\nprocessing tasks, words are commonly represented using vectors, where distances\namong the vectors are related to the similarity of the words. While word2vec,\nthe state-of-the-art implementation of the skip-gram model, is widely used and\nimproves the performance of many natural language processing tasks, its\nmechanism is not yet well understood.\n  In this work, we derive the learning rules for the skip-gram model and\nestablish their close relationship to competitive learning. In addition, we\nprovide the global optimal solution constraints for the skip-gram model and\nvalidate them by experimental results.", "published": "2020-03-18 22:17:48", "link": "http://arxiv.org/abs/2003.08489v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Realistic Re-evaluation of Knowledge Graph Completion Methods: An\n  Experimental Study", "abstract": "In the active research area of employing embedding models for knowledge graph\ncompletion, particularly for the task of link prediction, most prior studies\nused two benchmark datasets FB15k and WN18 in evaluating such models. Most\ntriples in these and other datasets in such studies belong to reverse and\nduplicate relations which exhibit high data redundancy due to semantic\nduplication, correlation or data incompleteness. This is a case of excessive\ndata leakage---a model is trained using features that otherwise would not be\navailable when the model needs to be applied for real prediction. There are\nalso Cartesian product relations for which every triple formed by the Cartesian\nproduct of applicable subjects and objects is a true fact. Link prediction on\nthe aforementioned relations is easy and can be achieved with even better\naccuracy using straightforward rules instead of sophisticated embedding models.\nA more fundamental defect of these models is that the link prediction scenario,\ngiven such data, is non-existent in the real-world. This paper is the first\nsystematic study with the main objective of assessing the true effectiveness of\nembedding models when the unrealistic triples are removed. Our experiment\nresults show these models are much less accurate than what we used to perceive.\nTheir poor accuracy renders link prediction a task without truly effective\nautomated solution. Hence, we call for re-investigation of possible effective\napproaches.", "published": "2020-03-18 01:18:09", "link": "http://arxiv.org/abs/2003.08001v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Selective Attention Encoders by Syntactic Graph Convolutional Networks\n  for Document Summarization", "abstract": "Abstractive text summarization is a challenging task, and one need to design\na mechanism to effectively extract salient information from the source text and\nthen generate a summary. A parsing process of the source text contains critical\nsyntactic or semantic structures, which is useful to generate more accurate\nsummary. However, modeling a parsing tree for text summarization is not trivial\ndue to its non-linear structure and it is harder to deal with a document that\nincludes multiple sentences and their parsing trees. In this paper, we propose\nto use a graph to connect the parsing trees from the sentences in a document\nand utilize the stacked graph convolutional networks (GCNs) to learn the\nsyntactic representation for a document. The selective attention mechanism is\nused to extract salient information in semantic and structural aspect and\ngenerate an abstractive summary. We evaluate our approach on the CNN/Daily Mail\ntext summarization dataset. The experimental results show that the proposed\nGCNs based selective attention approach outperforms the baselines and achieves\nthe state-of-the-art performance on the dataset.", "published": "2020-03-18 01:30:02", "link": "http://arxiv.org/abs/2003.08004v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pre-trained Models for Natural Language Processing: A Survey", "abstract": "Recently, the emergence of pre-trained models (PTMs) has brought natural\nlanguage processing (NLP) to a new era. In this survey, we provide a\ncomprehensive review of PTMs for NLP. We first briefly introduce language\nrepresentation learning and its research progress. Then we systematically\ncategorize existing PTMs based on a taxonomy with four perspectives. Next, we\ndescribe how to adapt the knowledge of PTMs to the downstream tasks. Finally,\nwe outline some potential directions of PTMs for future research. This survey\nis purposed to be a hands-on guide for understanding, using, and developing\nPTMs for various NLP tasks.", "published": "2020-03-18 15:22:51", "link": "http://arxiv.org/abs/2003.08271v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distant Supervision and Noisy Label Learning for Low Resource Named\n  Entity Recognition: A Study on Hausa and Yor\u00f9b\u00e1", "abstract": "The lack of labeled training data has limited the development of natural\nlanguage processing tools, such as named entity recognition, for many languages\nspoken in developing countries. Techniques such as distant and weak supervision\ncan be used to create labeled data in a (semi-) automatic way. Additionally, to\nalleviate some of the negative effects of the errors in automatic annotation,\nnoise-handling methods can be integrated. Pretrained word embeddings are\nanother key component of most neural named entity classifiers. With the advent\nof more complex contextual word embeddings, an interesting trade-off between\nmodel size and performance arises. While these techniques have been shown to\nwork well in high-resource settings, we want to study how they perform in\nlow-resource scenarios. In this work, we perform named entity recognition for\nHausa and Yor\\`ub\\'a, two languages that are widely spoken in several\ndeveloping countries. We evaluate different embedding approaches and show that\ndistant supervision can be successfully leveraged in a realistic low-resource\nscenario where it can more than double a classifier's performance.", "published": "2020-03-18 17:48:35", "link": "http://arxiv.org/abs/2003.08370v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TTTTTackling WinoGrande Schemas", "abstract": "We applied the T5 sequence-to-sequence model to tackle the AI2 WinoGrande\nChallenge by decomposing each example into two input text strings, each\ncontaining a hypothesis, and using the probabilities assigned to the\n\"entailment\" token as a score of the hypothesis. Our first (and only)\nsubmission to the official leaderboard yielded 0.7673 AUC on March 13, 2020,\nwhich is the best known result at this time and beats the previous state of the\nart by over five points.", "published": "2020-03-18 17:56:07", "link": "http://arxiv.org/abs/2003.08380v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Corpus of Adpositional Supersenses for Mandarin Chinese", "abstract": "Adpositions are frequent markers of semantic relations, but they are highly\nambiguous and vary significantly from language to language. Moreover, there is\na dearth of annotated corpora for investigating the cross-linguistic variation\nof adposition semantics, or for building multilingual disambiguation systems.\nThis paper presents a corpus in which all adpositions have been semantically\nannotated in Mandarin Chinese; to the best of our knowledge, this is the first\nChinese corpus to be broadly annotated with adposition semantics. Our approach\nadapts a framework that defined a general set of supersenses according to\nostensibly language-independent semantic criteria, though its development\nfocused primarily on English prepositions (Schneider et al., 2018). We find\nthat the supersense categories are well-suited to Chinese adpositions despite\nsyntactic differences from English. On a Mandarin translation of The Little\nPrince, we achieve high inter-annotator agreement and analyze semantic\ncorrespondences of adposition tokens in bitext.", "published": "2020-03-18 18:59:55", "link": "http://arxiv.org/abs/2003.08437v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Cross Lingual Cross Corpus Speech Emotion Recognition", "abstract": "The majority of existing speech emotion recognition models are trained and\nevaluated on a single corpus and a single language setting. These systems do\nnot perform as well when applied in a cross-corpus and cross-language scenario.\nThis paper presents results for speech emotion recognition for 4 languages in\nboth single corpus and cross corpus setting. Additionally, since multi-task\nlearning (MTL) with gender, naturalness and arousal as auxiliary tasks has\nshown to enhance the generalisation capabilities of the emotion models, this\npaper introduces language ID as another auxiliary task in MTL framework to\nexplore the role of spoken language on emotion recognition which has not been\nstudied yet.", "published": "2020-03-18 00:23:08", "link": "http://arxiv.org/abs/2003.07996v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies", "abstract": "Learning continuous representations of discrete objects such as text, users,\nmovies, and URLs lies at the heart of many applications including language and\nuser modeling. When using discrete objects as input to neural networks, we\noften ignore the underlying structures (e.g., natural groupings and\nsimilarities) and embed the objects independently into individual vectors. As a\nresult, existing methods do not scale to large vocabulary sizes. In this paper,\nwe design a simple and efficient embedding algorithm that learns a small set of\nanchor embeddings and a sparse transformation matrix. We call our method Anchor\n& Transform (ANT) as the embeddings of discrete objects are a sparse linear\ncombination of the anchors, weighted according to the transformation matrix.\nANT is scalable, flexible, and end-to-end trainable. We further provide a\nstatistical interpretation of our algorithm as a Bayesian nonparametric prior\nfor embeddings that encourages sparsity and leverages natural groupings among\nobjects. By deriving an approximate inference algorithm based on Small Variance\nAsymptotics, we obtain a natural extension that automatically learns the\noptimal number of anchors instead of having to tune it as a hyperparameter. On\ntext classification, language modeling, and movie recommendation benchmarks, we\nshow that ANT is particularly suitable for large vocabulary sizes and\ndemonstrates stronger performance with fewer parameters (up to 40x compression)\nas compared to existing compression baselines.", "published": "2020-03-18 13:07:51", "link": "http://arxiv.org/abs/2003.08197v4", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Source DOA Estimation through Pattern Recognition of the Modal\n  Coherence of a Reverberant Soundfield", "abstract": "We propose a novel multi-source direction of arrival (DOA) estimation\ntechnique using a convolutional neural network algorithm which learns the modal\ncoherence patterns of an incident soundfield through measured spherical\nharmonic coefficients. We train our model for individual time-frequency bins in\nthe short-time Fourier transform spectrum by analyzing the unique snapshot of\nmodal coherence for each desired direction. The proposed method is capable of\nestimating simultaneously active multiple sound sources on a $3$D space using a\nsingle-source training scheme. This single-source training scheme reduces the\ntraining time and resource requirements as well as allows the reuse of the same\ntrained model for different multi-source combinations. The method is evaluated\nagainst various simulated and practical noisy and reverberant environments with\nvarying acoustic criteria and found to outperform the baseline methods in terms\nof DOA estimation accuracy. Furthermore, the proposed algorithm allows\nindependent training of azimuth and elevation during a full DOA estimation over\n$3$D space which significantly improves its training efficiency without\naffecting the overall estimation accuracy.", "published": "2020-03-18 05:24:00", "link": "http://arxiv.org/abs/2003.08050v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detecting Replay Attacks Using Multi-Channel Audio: A Neural\n  Network-Based Method", "abstract": "With the rapidly growing number of security-sensitive systems that use voice\nas the primary input, it becomes increasingly important to address these\nsystems' potential vulnerability to replay attacks. Previous efforts to address\nthis concern have focused primarily on single-channel audio. In this paper, we\nintroduce a novel neural network-based replay attack detection model that\nfurther leverages spatial information of multi-channel audio and is able to\nsignificantly improve the replay attack detection performance.", "published": "2020-03-18 13:56:54", "link": "http://arxiv.org/abs/2003.08225v3", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
