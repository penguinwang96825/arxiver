{"title": "SweLL on the rise: Swedish Learner Language corpus for European\n  Reference Level studies", "abstract": "We present a new resource for Swedish, SweLL, a corpus of Swedish Learner\nessays linked to learners' performance according to the Common European\nFramework of Reference (CEFR). SweLL consists of three subcorpora - SpIn,\nSW1203 and Tisus, collected from three different educational establishments.\nThe common metadata for all subcorpora includes age, gender, native languages,\ntime of residence in Sweden, type of written task. Depending on the subcorpus,\nlearner texts may contain additional information, such as text genres, topics,\ngrades. Five of the six CEFR levels are represented in the corpus: A1, A2, B1,\nB2 and C1 comprising in total 339 essays. C2 level is not included since\ncourses at C2 level are not offered. The work flow consists of collection of\nessays and permits, essay digitization and registration, meta-data annotation,\nautomatic linguistic annotation. Inter-rater agreement is presented on the\nbasis of SW1203 subcorpus. The work on SweLL is still ongoing with more than\n100 essays waiting in the pipeline. This article both describes the resource\nand the \"how-to\" behind the compilation of SweLL.", "published": "2016-04-22 09:19:07", "link": "http://arxiv.org/abs/1604.06583v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic verbal aggression detection for Russian and American\n  imageboards", "abstract": "The problem of aggression for Internet communities is rampant. Anonymous\nforums usually called imageboards are notorious for their aggressive and\ndeviant behaviour even in comparison with other Internet communities. This\nstudy is aimed at studying ways of automatic detection of verbal expression of\naggression for the most popular American (4chan.org) and Russian (2ch.hk)\nimageboards. A set of 1,802,789 messages was used for this study. The machine\nlearning algorithm word2vec was applied to detect the state of aggression. A\ndecent result is obtained for English (88%), the results for Russian are yet to\nbe improved.", "published": "2016-04-22 13:25:14", "link": "http://arxiv.org/abs/1604.06648v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting state of aggression in sentences using CNN", "abstract": "In this article we study verbal expression of aggression and its detection\nusing machine learning and neural networks methods. We test our results using\nour corpora of messages from anonymous imageboards. We also compare Random\nforest classifier with convolutional neural network for \"Movie reviews with one\nsentence per review\" corpus.", "published": "2016-04-22 13:33:08", "link": "http://arxiv.org/abs/1604.06650v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dependency Parsing with LSTMs: An Empirical Evaluation", "abstract": "We propose a transition-based dependency parser using Recurrent Neural\nNetworks with Long Short-Term Memory (LSTM) units. This extends the feedforward\nneural network parser of Chen and Manning (2014) and enables modelling of\nentire sequences of shift/reduce transition decisions. On the Google Web\nTreebank, our LSTM parser is competitive with the best feedforward parser on\noverall accuracy and notably achieves more than 3% improvement for long-range\ndependencies, which has proved difficult for previous transition-based parsers\ndue to error propagation and limited context information. Our findings\nadditionally suggest that dropout regularisation on the embedding layer is\ncrucial to improve the LSTM's generalisation.", "published": "2016-04-22 03:20:24", "link": "http://arxiv.org/abs/1604.06529v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Bridging LSTM Architecture and the Neural Dynamics during Reading", "abstract": "Recently, the long short-term memory neural network (LSTM) has attracted wide\ninterest due to its success in many tasks. LSTM architecture consists of a\nmemory cell and three gates, which looks similar to the neuronal networks in\nthe brain. However, there still lacks the evidence of the cognitive\nplausibility of LSTM architecture as well as its working mechanism. In this\npaper, we study the cognitive plausibility of LSTM by aligning its internal\narchitecture with the brain activity observed via fMRI when the subjects read a\nstory. Experiment results show that the artificial memory vector in LSTM can\naccurately predict the observed sequential brain activities, indicating the\ncorrelation between LSTM architecture and the cognitive process of story\nreading.", "published": "2016-04-22 12:51:11", "link": "http://arxiv.org/abs/1604.06635v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Exploiting Deep Semantics and Compositionality of Natural Language for\n  Human-Robot-Interaction", "abstract": "We develop a natural language interface for human robot interaction that\nimplements reasoning about deep semantics in natural language. To realize the\nrequired deep analysis, we employ methods from cognitive linguistics, namely\nthe modular and compositional framework of Embodied Construction Grammar (ECG)\n[Feldman, 2009]. Using ECG, robots are able to solve fine-grained reference\nresolution problems and other issues related to deep semantics and\ncompositionality of natural language. This also includes verbal interaction\nwith humans to clarify commands and queries that are too ambiguous to be\nexecuted safely. We implement our NLU framework as a ROS package and present\nproof-of-concept scenarios with different robots, as well as a survey on the\nstate of the art.", "published": "2016-04-22 15:58:18", "link": "http://arxiv.org/abs/1604.06721v1", "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.AI"}
