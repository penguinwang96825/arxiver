{"title": "FinQA: A Dataset of Numerical Reasoning over Financial Data", "abstract": "The sheer volume of financial statements makes it difficult for humans to\naccess and analyze a business's financials. Robust numerical reasoning likewise\nfaces unique challenges in this domain. In this work, we focus on answering\ndeep questions over financial data, aiming to automate the analysis of a large\ncorpus of financial documents. In contrast to existing tasks on general domain,\nthe finance domain includes complex numerical reasoning and understanding of\nheterogeneous representations. To facilitate analytical progress, we propose a\nnew large-scale dataset, FinQA, with Question-Answering pairs over Financial\nreports, written by financial experts. We also annotate the gold reasoning\nprograms to ensure full explainability. We further introduce baselines and\nconduct comprehensive experiments in our dataset. The results demonstrate that\npopular, large, pre-trained models fall far short of expert humans in acquiring\nfinance knowledge and in complex multi-step numerical reasoning on that\nknowledge. Our dataset -- the first of its kind -- should therefore enable\nsignificant, new community research into complex application domains. The\ndataset and code are publicly available\\url{https://github.com/czyssrs/FinQA}.", "published": "2021-09-01 00:08:14", "link": "http://arxiv.org/abs/2109.00122v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Have Been Learned & What Should Be Learned? An Empirical Study of\n  How to Selectively Augment Text for Classification", "abstract": "Text augmentation techniques are widely used in text classification problems\nto improve the performance of classifiers, especially in low-resource\nscenarios. Whilst lots of creative text augmentation methods have been\ndesigned, they augment the text in a non-selective manner, which means the less\nimportant or noisy words have the same chances to be augmented as the\ninformative words, and thereby limits the performance of augmentation. In this\nwork, we systematically summarize three kinds of role keywords, which have\ndifferent functions for text classification, and design effective methods to\nextract them from the text. Based on these extracted role keywords, we propose\nSTA (Selective Text Augmentation) to selectively augment the text, where the\ninformative, class-indicating words are emphasized but the irrelevant or noisy\nwords are diminished. Extensive experiments on four English and Chinese text\nclassification benchmark datasets demonstrate that STA can substantially\noutperform the non-selective text augmentation methods.", "published": "2021-09-01 04:03:11", "link": "http://arxiv.org/abs/2109.00175v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Predictive Uncertainty under Distributional Shift on Dialogue\n  Dataset", "abstract": "In open-domain dialogues, predictive uncertainties are mainly evaluated in a\ndomain shift setting to cope with out-of-distribution inputs. However, in\nreal-world conversations, there could be more extensive distributional shifted\ninputs than the out-of-distribution. To evaluate this, we first propose two\nmethods, Unknown Word (UW) and Insufficient Context (IC), enabling gradual\ndistributional shifts by corruption on the dialogue dataset. We then\ninvestigate the effect of distributional shifts on accuracy and calibration.\nOur experiments show that the performance of existing uncertainty estimation\nmethods consistently degrades with intensifying the shift. The results suggest\nthat the proposed methods could be useful for evaluating the calibration of\ndialogue systems under distributional shifts.", "published": "2021-09-01 04:55:43", "link": "http://arxiv.org/abs/2109.00186v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dataset for Identification of Homophobia and Transophobia in\n  Multilingual YouTube Comments", "abstract": "The increased proliferation of abusive content on social media platforms has\na negative impact on online users. The dread, dislike, discomfort, or mistrust\nof lesbian, gay, transgender or bisexual persons is defined as\nhomophobia/transphobia. Homophobic/transphobic speech is a type of offensive\nlanguage that may be summarized as hate speech directed toward LGBT+ people,\nand it has been a growing concern in recent years. Online\nhomophobia/transphobia is a severe societal problem that can make online\nplatforms poisonous and unwelcome to LGBT+ people while also attempting to\neliminate equality, diversity, and inclusion. We provide a new hierarchical\ntaxonomy for online homophobia and transphobia, as well as an expert-labelled\ndataset that will allow homophobic/transphobic content to be automatically\nidentified. We educated annotators and supplied them with comprehensive\nannotation rules because this is a sensitive issue, and we previously\ndiscovered that untrained crowdsourcing annotators struggle with diagnosing\nhomophobia due to cultural and other prejudices. The dataset comprises 15,141\nannotated multilingual comments. This paper describes the process of building\nthe dataset, qualitative analysis of data, and inter-annotator agreement. In\naddition, we create baseline models for the dataset. To the best of our\nknowledge, our dataset is the first such dataset created. Warning: This paper\ncontains explicit statements of homophobia, transphobia, stereotypes which may\nbe distressing to some readers.", "published": "2021-09-01 08:05:57", "link": "http://arxiv.org/abs/2109.00227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OptAGAN: Entropy-based finetuning on text VAE-GAN", "abstract": "Transfer learning through large pre-trained models has changed the landscape\nof current applications in natural language processing (NLP). Recently Optimus,\na variational autoencoder (VAE) which combines two pre-trained models, BERT and\nGPT-2, has been released, and its combination with generative adversial\nnetworks (GANs) has been shown to produce novel, yet very human-looking text.\nThe Optimus and GANs combination avoids the troublesome application of GANs to\nthe discrete domain of text, and prevents the exposure bias of standard maximum\nlikelihood methods. We combine the training of GANs in the latent space, with\nthe finetuning of the decoder of Optimus for single word generation. This\napproach lets us model both the high-level features of the sentences, and the\nlow-level word-by-word generation. We finetune using reinforcement learning\n(RL) by exploiting the structure of GPT-2 and by adding entropy-based\nintrinsically motivated rewards to balance between quality and diversity. We\nbenchmark the results of the VAE-GAN model, and show the improvements brought\nby our RL finetuning on three widely used datasets for text generation, with\nresults that greatly surpass the current state-of-the-art for the quality of\nthe generated texts.", "published": "2021-09-01 08:23:19", "link": "http://arxiv.org/abs/2109.00239v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Context and High-Coverage Grammar for Conversational Question\n  Answering over Knowledge Graphs", "abstract": "We tackle the problem of weakly-supervised conversational Question Answering\nover large Knowledge Graphs using a neural semantic parsing approach. We\nintroduce a new Logical Form (LF) grammar that can model a wide range of\nqueries on the graph while remaining sufficiently simple to generate\nsupervision data efficiently. Our Transformer-based model takes a JSON-like\nstructure as input, allowing us to easily incorporate both Knowledge Graph and\nconversational contexts. This structured input is transformed to lists of\nembeddings and then fed to standard attention layers. We validate our approach,\nboth in terms of grammar coverage and LF execution accuracy, on two publicly\navailable datasets, CSQA and ConvQuestions, both grounded in Wikidata. On CSQA,\nour approach increases the coverage from $80\\%$ to $96.2\\%$, and the LF\nexecution accuracy from $70.6\\%$ to $75.6\\%$, with respect to previous\nstate-of-the-art results. On ConvQuestions, we achieve competitive results with\nrespect to the state-of-the-art.", "published": "2021-09-01 09:28:46", "link": "http://arxiv.org/abs/2109.00269v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Discovering Representation Sprachbund For Multilingual Pre-Training", "abstract": "Multilingual pre-trained models have demonstrated their effectiveness in many\nmultilingual NLP tasks and enabled zero-shot or few-shot transfer from\nhigh-resource languages to low resource ones. However, due to significant\ntypological differences and contradictions between some languages, such models\nusually perform poorly on many languages and cross-lingual settings, which\nshows the difficulty of learning a single model to handle massive diverse\nlanguages well at the same time. To alleviate this issue, we present a new\nmultilingual pre-training pipeline. We propose to generate language\nrepresentation from multilingual pre-trained models and conduct linguistic\nanalysis to show that language representation similarity reflect linguistic\nsimilarity from multiple perspectives, including language family, geographical\nsprachbund, lexicostatistics and syntax. Then we cluster all the target\nlanguages into multiple groups and name each group as a representation\nsprachbund. Thus, languages in the same representation sprachbund are supposed\nto boost each other in both pre-training and fine-tuning as they share rich\nlinguistic similarity. We pre-train one multilingual model for each\nrepresentation sprachbund. Experiments are conducted on cross-lingual\nbenchmarks and significant improvements are achieved compared to strong\nbaselines.", "published": "2021-09-01 09:32:06", "link": "http://arxiv.org/abs/2109.00271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "$\\infty$-former: Infinite Memory Transformer", "abstract": "Transformers are unable to model long-term memories effectively, since the\namount of computation they need to perform grows with the context length. While\nvariations of efficient transformers have been proposed, they all have a finite\nmemory capacity and are forced to drop old information. In this paper, we\npropose the $\\infty$-former, which extends the vanilla transformer with an\nunbounded long-term memory. By making use of a continuous-space attention\nmechanism to attend over the long-term memory, the $\\infty$-former's attention\ncomplexity becomes independent of the context length, trading off memory length\nwith precision. In order to control where precision is more important,\n$\\infty$-former maintains \"sticky memories\" being able to model arbitrarily\nlong contexts while keeping the computation budget fixed. Experiments on a\nsynthetic sorting task, language modeling, and document grounded dialogue\ngeneration demonstrate the $\\infty$-former's ability to retain information from\nlong sequences.", "published": "2021-09-01 10:51:58", "link": "http://arxiv.org/abs/2109.00301v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConRPG: Paraphrase Generation using Contexts as Regularizer", "abstract": "A long-standing issue with paraphrase generation is how to obtain reliable\nsupervision signals. In this paper, we propose an unsupervised paradigm for\nparaphrase generation based on the assumption that the probabilities of\ngenerating two sentences with the same meaning given the same context should be\nthe same. Inspired by this fundamental idea, we propose a pipelined system\nwhich consists of paraphrase candidate generation based on contextual language\nmodels, candidate filtering using scoring functions, and paraphrase model\ntraining based on the selected candidates. The proposed paradigm offers merits\nover existing paraphrase generation methods: (1) using the context regularizer\non meanings, the model is able to generate massive amounts of high-quality\nparaphrase pairs; and (2) using human-interpretable scoring functions to select\nparaphrase pairs from candidates, the proposed framework provides a channel for\ndevelopers to intervene with the data generation process, leading to a more\ncontrollable model. Experimental results across different tasks and datasets\ndemonstrate that the effectiveness of the proposed model in both supervised and\nunsupervised setups.", "published": "2021-09-01 12:57:30", "link": "http://arxiv.org/abs/2109.00363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Capturing Stance Dynamics in Social Media: Open Challenges and Research\n  Directions", "abstract": "Social media platforms provide a goldmine for mining public opinion on issues\nof wide societal interest and impact. Opinion mining is a problem that can be\noperationalised by capturing and aggregating the stance of individual social\nmedia posts as supporting, opposing or being neutral towards the issue at hand.\nWhile most prior work in stance detection has investigated datasets that cover\nshort periods of time, interest in investigating longitudinal datasets has\nrecently increased. Evolving dynamics in linguistic and behavioural patterns\nobserved in new data require adapting stance detection systems to deal with the\nchanges. In this survey paper, we investigate the intersection between\ncomputational linguistics and the temporal evolution of human communication in\ndigital media. We perform a critical review of emerging research considering\ndynamics, exploring different semantic and pragmatic factors that impact\nlinguistic data in general, and stance in particular. We further discuss\ncurrent directions in capturing stance dynamics in social media. We discuss the\nchallenges encountered when dealing with stance dynamics, identify open\nchallenges and discuss future directions in three key dimensions: utterance,\ncontext and influence.", "published": "2021-09-01 16:28:24", "link": "http://arxiv.org/abs/2109.00475v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Survey of Low-Resource Machine Translation", "abstract": "We present a survey covering the state of the art in low-resource machine\ntranslation research. There are currently around 7000 languages spoken in the\nworld and almost all language pairs lack significant resources for training\nmachine translation models. There has been increasing interest in research\naddressing the challenge of producing useful translation models when very\nlittle translated training data is available. We present a summary of this\ntopical research field and provide a description of the techniques evaluated by\nresearchers in several recent shared tasks in low-resource MT.", "published": "2021-09-01 16:57:58", "link": "http://arxiv.org/abs/2109.00486v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Knowledge Help General NLU? An Empirical Study", "abstract": "It is often observed in knowledge-centric tasks (e.g., common sense question\nand answering, relation classification) that the integration of external\nknowledge such as entity representation into language models can help provide\nuseful information to boost the performance. However, it is still unclear\nwhether this benefit can extend to general natural language understanding (NLU)\ntasks. In this work, we empirically investigated the contribution of external\nknowledge by measuring the end-to-end performance of language models with\nvarious knowledge integration methods. We find that the introduction of\nknowledge can significantly improve the results on certain tasks while having\nno adverse effects on other tasks. We then employ mutual information to reflect\nthe difference brought by knowledge and a neural interpretation model to reveal\nhow a language model utilizes external knowledge. Our study provides valuable\ninsights and guidance for practitioners to equip NLP models with knowledge.", "published": "2021-09-01 18:17:36", "link": "http://arxiv.org/abs/2109.00563v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DILBERT: Customized Pre-Training for Domain Adaptation withCategory\n  Shift, with an Application to Aspect Extraction", "abstract": "The rise of pre-trained language models has yielded substantial progress in\nthe vast majority of Natural Language Processing (NLP) tasks. However, a\ngeneric approach towards the pre-training procedure can naturally be\nsub-optimal in some cases. Particularly, fine-tuning a pre-trained language\nmodel on a source domain and then applying it to a different target domain,\nresults in a sharp performance decline of the eventual classifier for many\nsource-target domain pairs. Moreover, in some NLP tasks, the output categories\nsubstantially differ between domains, making adaptation even more challenging.\nThis, for example, happens in the task of aspect extraction, where the aspects\nof interest of reviews of, e.g., restaurants or electronic devices may be very\ndifferent. This paper presents a new fine-tuning scheme for BERT, which aims to\naddress the above challenges. We name this scheme DILBERT: Domain Invariant\nLearning with BERT, and customize it for aspect extraction in the unsupervised\ndomain adaptation setting. DILBERT harnesses the categorical information of\nboth the source and the target domains to guide the pre-training process\ntowards a more domain and category invariant representation, thus closing the\ngap between the domains. We show that DILBERT yields substantial improvements\nover state-of-the-art baselines while using a fraction of the unlabeled data,\nparticularly in more challenging domain adaptation setups.", "published": "2021-09-01 18:49:44", "link": "http://arxiv.org/abs/2109.00571v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latin writing styles analysis with Machine Learning: New approach to old\n  questions", "abstract": "In the Middle Ages texts were learned by heart and spread using oral means of\ncommunication from generation to generation. Adaptation of the art of prose and\npoems allowed keeping particular descriptions and compositions characteristic\nfor many literary genres. Taking into account such a specific construction of\nliterature composed in Latin, we can search for and indicate the probability\npatterns of familiar sources of specific narrative texts. Consideration of\nNatural Language Processing tools allowed us the transformation of textual\nobjects into numerical ones and then application of machine learning algorithms\nto extract information from the dataset. We carried out the task consisting of\nthe practical use of those concepts and observation to create a tool for\nanalyzing narrative texts basing on open-source databases. The tool focused on\ncreating specific search tools resources which could enable us detailed\nsearching throughout the text. The main objectives of the study take into\naccount finding similarities between sentences and between documents. Next, we\napplied machine learning algorithms on chosen texts to calculate specific\nfeatures of them (for instance authorship or centuries) and to recognize\nsources of anonymous texts with a certain percentage.", "published": "2021-09-01 20:21:45", "link": "http://arxiv.org/abs/2109.00601v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Point-of-Interest Type Prediction using Text and Images", "abstract": "Point-of-interest (POI) type prediction is the task of inferring the type of\na place from where a social media post was shared. Inferring a POI's type is\nuseful for studies in computational social science including sociolinguistics,\ngeosemiotics, and cultural geography, and has applications in geosocial\nnetworking technologies such as recommendation and visualization systems. Prior\nefforts in POI type prediction focus solely on text, without taking visual\ninformation into account. However in reality, the variety of modalities, as\nwell as their semiotic relationships with one another, shape communication and\ninteractions in social media. This paper presents a study on POI type\nprediction using multimodal information from text and images available at\nposting time. For that purpose, we enrich a currently available data set for\nPOI type prediction with the images that accompany the text messages. Our\nproposed method extracts relevant information from each modality to effectively\ncapture interactions between text and image achieving a macro F1 of 47.21\nacross eight categories significantly outperforming the state-of-the-art method\nfor POI type prediction based on text-only methods. Finally, we provide a\ndetailed analysis to shed light on cross-modal interactions and the limitations\nof our best performing model.", "published": "2021-09-01 20:25:54", "link": "http://arxiv.org/abs/2109.00602v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An unsupervised framework for tracing textual sources of moral change", "abstract": "Morality plays an important role in social well-being, but people's moral\nperception is not stable and changes over time. Recent advances in natural\nlanguage processing have shown that text is an effective medium for informing\nmoral change, but no attempt has been made to quantify the origins of these\nchanges. We present a novel unsupervised framework for tracing textual sources\nof moral change toward entities through time. We characterize moral change with\nprobabilistic topical distributions and infer the source text that exerts\nprominent influence on the moral time course. We evaluate our framework on a\ndiverse set of data ranging from social media to news articles. We show that\nour framework not only captures fine-grained human moral judgments, but also\nidentifies coherent source topics of moral change triggered by historical\nevents. We apply our methodology to analyze the news in the COVID-19 pandemic\nand demonstrate its utility in identifying sources of moral change in\nhigh-impact and real-time social events.", "published": "2021-09-01 20:35:33", "link": "http://arxiv.org/abs/2109.00608v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Unsupervised Method for Building Sentence Simplification Corpora in\n  Multiple Languages", "abstract": "The availability of parallel sentence simplification (SS) is scarce for\nneural SS modelings. We propose an unsupervised method to build SS corpora from\nlarge-scale bilingual translation corpora, alleviating the need for SS\nsupervised corpora. Our method is motivated by the following two findings:\nneural machine translation model usually tends to generate more high-frequency\ntokens and the difference of text complexity levels exists between the source\nand target language of a translation corpus. By taking the pair of the source\nsentences of translation corpus and the translations of their references in a\nbridge language, we can construct large-scale pseudo parallel SS data. Then, we\nkeep these sentence pairs with a higher complexity difference as SS sentence\npairs. The building SS corpora with an unsupervised approach can satisfy the\nexpectations that the aligned sentences preserve the same meanings and have\ndifference in text complexity levels. Experimental results show that SS methods\ntrained by our corpora achieve the state-of-the-art results and significantly\noutperform the results on English benchmark WikiLarge.", "published": "2021-09-01 03:30:06", "link": "http://arxiv.org/abs/2109.00165v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Adapted End-to-End Coreference Resolution System for Anaphoric\n  Identities in Dialogues", "abstract": "We present an effective system adapted from the end-to-end neural coreference\nresolution model, targeting on the task of anaphora resolution in dialogues.\nThree aspects are specifically addressed in our approach, including the support\nof singletons, encoding speakers and turns throughout dialogue interactions,\nand knowledge transfer utilizing existing resources. Despite the simplicity of\nour adaptation strategies, they are shown to bring significant impact to the\nfinal performance, with up to 27 F1 improvement over the baseline. Our final\nsystem ranks the 1st place on the leaderboard of the anaphora resolution track\nin the CRAC 2021 shared task, and achieves the best evaluation results on all\nfour datasets.", "published": "2021-09-01 04:51:29", "link": "http://arxiv.org/abs/2109.00185v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Boosting Cross-Lingual Transfer via Self-Learning with Uncertainty\n  Estimation", "abstract": "Recent multilingual pre-trained language models have achieved remarkable\nzero-shot performance, where the model is only finetuned on one source language\nand directly evaluated on target languages. In this work, we propose a\nself-learning framework that further utilizes unlabeled data of target\nlanguages, combined with uncertainty estimation in the process to select\nhigh-quality silver labels. Three different uncertainties are adapted and\nanalyzed specifically for the cross lingual transfer: Language\nHeteroscedastic/Homoscedastic Uncertainty (LEU/LOU), Evidential Uncertainty\n(EVI). We evaluate our framework with uncertainties on two cross-lingual tasks\nincluding Named Entity Recognition (NER) and Natural Language Inference (NLI)\ncovering 40 languages in total, which outperforms the baselines significantly\nby 10 F1 on average for NER and 2.5 accuracy score for NLI.", "published": "2021-09-01 05:26:46", "link": "http://arxiv.org/abs/2109.00194v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Aligning Cross-lingual Sentence Representations with Dual Momentum\n  Contrast", "abstract": "In this paper, we propose to align sentence representations from different\nlanguages into a unified embedding space, where semantic similarities (both\ncross-lingual and monolingual) can be computed with a simple dot product.\nPre-trained language models are fine-tuned with the translation ranking task.\nExisting work (Feng et al., 2020) uses sentences within the same batch as\nnegatives, which can suffer from the issue of easy negatives. We adapt MoCo (He\net al., 2020) to further improve the quality of alignment. As the experimental\nresults show, the sentence representations produced by our model achieve the\nnew state-of-the-art on several tasks, including Tatoeba en-zh similarity\nsearch (Artetxe and Schwenk, 2019b), BUCC en-zh bitext mining, and semantic\ntextual similarity on 7 datasets.", "published": "2021-09-01 08:48:34", "link": "http://arxiv.org/abs/2109.00253v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Extracting all Aspect-polarity Pairs Jointly in a Text with Relation\n  Extraction Approach", "abstract": "Extracting aspect-polarity pairs from texts is an important task of\nfine-grained sentiment analysis. While the existing approaches to this task\nhave gained many progresses, they are limited at capturing relationships among\naspect-polarity pairs in a text, thus degrading the extraction performance.\nMoreover, the existing state-of-the-art approaches, namely token-based\nse-quence tagging and span-based classification, have their own defects such as\npolarity inconsistency resulted from separately tagging tokens in the former\nand the heterogeneous categorization in the latter where aspect-related and\npolarity-related labels are mixed. In order to remedy the above defects,\nin-spiring from the recent advancements in relation extraction, we propose to\ngenerate aspect-polarity pairs directly from a text with relation extraction\ntechnology, regarding aspect-pairs as unary relations where aspects are\nenti-ties and the corresponding polarities are relations. Based on the\nperspective, we present a position- and aspect-aware sequence2sequence model\nfor joint extraction of aspect-polarity pairs. The model is characterized with\nits ability to capture not only relationships among aspect-polarity pairs in a\ntext through the sequence decoding, but also correlations between an aspect and\nits polarity through the position- and aspect-aware attentions. The\nexperi-ments performed on three benchmark datasets demonstrate that our model\noutperforms the existing state-of-the-art approaches, making significant\nim-provement over them.", "published": "2021-09-01 09:00:39", "link": "http://arxiv.org/abs/2109.00256v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Discourse Analysis of Covid-19 in Persian Twitter Social Networks Using\n  Graph Mining and Natural Language Processing", "abstract": "One of the new scientific ways of understanding discourse dynamics is\nanalyzing the public data of social networks. This research's aim is\nPost-structuralist Discourse Analysis (PDA) of Covid-19 phenomenon (inspired by\nLaclau and Mouffe's Discourse Theory) by using Intelligent Data Mining for\nPersian Society. The examined big data is five million tweets from 160,000\nusers of the Persian Twitter network to compare two discourses. Besides\nanalyzing the tweet texts individually, a social network graph database has\nbeen created based on retweets relationships. We use the VoteRank algorithm to\nintroduce and rank people whose posts become word of mouth, provided that the\ntotal information spreading scope is maximized over the network. These users\nare also clustered according to their word usage pattern (the Gaussian Mixture\nModel is used). The constructed discourse of influential spreaders is compared\nto the most active users. This analysis is done based on Covid-related posts\nover eight episodes. Also, by relying on the statistical content analysis and\npolarity of tweet words, discourse analysis is done for the whole mentioned\nsubpopulations, especially for the top individuals. The most important result\nof this research is that the Twitter subjects' discourse construction is\ngovernment-based rather than community-based. The analyzed Iranian society does\nnot consider itself responsible for the Covid-19 wicked problem, does not\nbelieve in participation, and expects the government to solve all problems. The\nmost active and most influential users' similarity is that political, national,\nand critical discourse construction is the predominant one. In addition to the\nadvantages of its research methodology, it is necessary to pay attention to the\nstudy's limitations. Suggestion for future encounters of Iranian society with\nsimilar crises is given.", "published": "2021-09-01 10:39:20", "link": "http://arxiv.org/abs/2109.00298v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Improving Multimodal Fusion with Hierarchical Mutual Information\n  Maximization for Multimodal Sentiment Analysis", "abstract": "In multimodal sentiment analysis (MSA), the performance of a model highly\ndepends on the quality of synthesized embeddings. These embeddings are\ngenerated from the upstream process called multimodal fusion, which aims to\nextract and combine the input unimodal raw data to produce a richer multimodal\nrepresentation. Previous work either back-propagates the task loss or\nmanipulates the geometric property of feature spaces to produce favorable\nfusion results, which neglects the preservation of critical task-related\ninformation that flows from input to the fusion results. In this work, we\npropose a framework named MultiModal InfoMax (MMIM), which hierarchically\nmaximizes the Mutual Information (MI) in unimodal input pairs (inter-modality)\nand between multimodal fusion result and unimodal input in order to maintain\ntask-related information through multimodal fusion. The framework is jointly\ntrained with the main task (MSA) to improve the performance of the downstream\nMSA task. To address the intractable issue of MI bounds, we further formulate a\nset of computationally simple parametric and non-parametric methods to\napproximate their truth value. Experimental results on the two widely used\ndatasets demonstrate the efficacy of our approach. The implementation of this\nwork is publicly available at\nhttps://github.com/declare-lab/Multimodal-Infomax.", "published": "2021-09-01 14:45:16", "link": "http://arxiv.org/abs/2109.00412v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Masked Adversarial Generation for Neural Machine Translation", "abstract": "Attacking Neural Machine Translation models is an inherently combinatorial\ntask on discrete sequences, solved with approximate heuristics. Most methods\nuse the gradient to attack the model on each sample independently. Instead of\nmechanically applying the gradient, could we learn to produce meaningful\nadversarial attacks ? In contrast to existing approaches, we learn to attack a\nmodel by training an adversarial generator based on a language model. We\npropose the Masked Adversarial Generation (MAG) model, that learns to perturb\nthe translation model throughout the training process. The experiments show\nthat it improves the robustness of machine translation models, while being\nfaster than competing methods.", "published": "2021-09-01 14:56:37", "link": "http://arxiv.org/abs/2109.00417v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ReMeDi: Resources for Multi-domain, Multi-service, Medical Dialogues", "abstract": "Medical dialogue systems (MDSs) aim to assist doctors and patients with a\nrange of professional medical services, i.e., diagnosis, treatment and\nconsultation. The development of MDSs is hindered because of a lack of\nresources. In particular. (1) there is no dataset with large-scale medical\ndialogues that covers multiple medical services and contains fine-grained\nmedical labels (i.e., intents, actions, slots, values), and (2) there is no set\nof established benchmarks for MDSs for multi-domain, multi-service medical\ndialogues. In this paper, we present ReMeDi, a set of resource for medical\ndialogues. ReMeDi consists of two parts, the ReMeDi dataset and the ReMeDi\nbenchmarks. The ReMeDi dataset contains 96,965 conversations between doctors\nand patients, including 1,557 conversations with fine-gained labels. It covers\n843 types of diseases, 5,228 medical entities, and 3 specialties of medical\nservices across 40 domains. To the best of our knowledge, the ReMeDi dataset is\nthe only medical dialogue dataset that covers multiple domains and services,\nand has fine-grained medical labels. The second part of the ReMeDi resources\nconsists of a set of state-of-the-art models for (medical) dialogue generation.\nThe ReMeDi benchmark has the following methods: (1) pretrained models (i.e.,\nBERT-WWM, BERT-MED, GPT2, and MT5) trained, validated, and tested on the ReMeDi\ndataset, and (2) a self-supervised contrastive learning(SCL) method to expand\nthe ReMeDi dataset and enhance the training of the state-of-the-art pretrained\nmodels. We describe the creation of the ReMeDi dataset, the ReMeDi benchmarking\nmethods, and establish experimental results using the ReMeDi benchmarking\nmethods on the ReMeDi dataset for future research to compare against. With this\npaper, we share the dataset, implementations of the benchmarks, and evaluation\nscripts.", "published": "2021-09-01 15:24:54", "link": "http://arxiv.org/abs/2109.00430v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Position Masking for Improved Layout-Aware Document Understanding", "abstract": "Natural language processing for document scans and PDFs has the potential to\nenormously improve the efficiency of business processes. Layout-aware word\nembeddings such as LayoutLM have shown promise for classification of and\ninformation extraction from such documents. This paper proposes a new\npre-training task called that can improve performance of layout-aware word\nembeddings that incorporate 2-D position embeddings. We compare models\npre-trained with only language masking against models pre-trained with both\nlanguage masking and position masking, and we find that position masking\nimproves performance by over 5% on a form understanding task.", "published": "2021-09-01 15:40:15", "link": "http://arxiv.org/abs/2109.00442v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Don't Discard All the Biased Instances: Investigating a Core Assumption\n  in Dataset Bias Mitigation Techniques", "abstract": "Existing techniques for mitigating dataset bias often leverage a biased model\nto identify biased instances. The role of these biased instances is then\nreduced during the training of the main model to enhance its robustness to\nout-of-distribution data. A common core assumption of these techniques is that\nthe main model handles biased instances similarly to the biased model, in that\nit will resort to biases whenever available. In this paper, we show that this\nassumption does not hold in general. We carry out a critical investigation on\ntwo well-known datasets in the domain, MNLI and FEVER, along with two biased\ninstance detection methods, partial-input and limited-capacity models. Our\nexperiments show that in around a third to a half of instances, the biased\nmodel is unable to predict the main model's behavior, highlighted by the\nsignificantly different parts of the input on which they base their decisions.\nBased on a manual validation, we also show that this estimate is highly in line\nwith human interpretation. Our findings suggest that down-weighting of\ninstances detected by bias detection methods, which is a widely-practiced\nprocedure, is an unnecessary waste of training data. We release our code to\nfacilitate reproducibility and future research.", "published": "2021-09-01 10:25:46", "link": "http://arxiv.org/abs/2109.00521v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Text AutoAugment: Learning Compositional Augmentation Policy for Text\n  Classification", "abstract": "Data augmentation aims to enrich training samples for alleviating the\noverfitting issue in low-resource or class-imbalanced situations. Traditional\nmethods first devise task-specific operations such as Synonym Substitute, then\npreset the corresponding parameters such as the substitution rate artificially,\nwhich require a lot of prior knowledge and are prone to fall into the\nsub-optimum. Besides, the number of editing operations is limited in the\nprevious methods, which decreases the diversity of the augmented data and thus\nrestricts the performance gain. To overcome the above limitations, we propose a\nframework named Text AutoAugment (TAA) to establish a compositional and\nlearnable paradigm for data augmentation. We regard a combination of various\noperations as an augmentation policy and utilize an efficient Bayesian\nOptimization algorithm to automatically search for the best policy, which\nsubstantially improves the generalization capability of models. Experiments on\nsix benchmark datasets show that TAA boosts classification accuracy in\nlow-resource and class-imbalanced regimes by an average of 8.8% and 9.7%,\nrespectively, outperforming strong baselines.", "published": "2021-09-01 11:16:21", "link": "http://arxiv.org/abs/2109.00523v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fight Fire with Fire: Fine-tuning Hate Detectors using Large Samples of\n  Generated Hate Speech", "abstract": "Automatic hate speech detection is hampered by the scarcity of labeled\ndatasetd, leading to poor generalization. We employ pretrained language models\n(LMs) to alleviate this data bottleneck. We utilize the GPT LM for generating\nlarge amounts of synthetic hate speech sequences from available labeled\nexamples, and leverage the generated data in fine-tuning large pretrained LMs\non hate detection. An empirical study using the models of BERT, RoBERTa and\nALBERT, shows that this approach improves generalization significantly and\nconsistently within and across data distributions. In fact, we find that\ngenerating relevant labeled hate speech sequences is preferable to using\nout-of-domain, and sometimes also within-domain, human-labeled examples.", "published": "2021-09-01 19:47:01", "link": "http://arxiv.org/abs/2109.00591v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Algorithme de recherche approximative dans un dictionnaire fond\u00e9 sur\n  une distance d'\u00e9dition d\u00e9finie par blocs", "abstract": "We propose an algorithm for approximative dictionary lookup, where altered\nstrings are matched against reference forms. The algorithm makes use of a\ndivergence function between strings -- broadly belonging to the family of edit\ndistances; it finds dictionary entries whose distance to the search string is\nbelow a certain threshold. The divergence function is not the classical edit\ndistance (DL distance); it is adaptable to a particular corpus, and is based on\nelementary alteration costs defined on character blocks, rather than on\nindividual characters.\n  Nous proposons un algorithme de recherche approximative de cha\\^ines dans un\ndictionnaire \\`a partir de formes alt\\'er\\'ees. Cet algorithme est fond\\'e sur\nune fonction de divergence entre cha\\^ines~ -- une sorte de distance\nd'\\'edition: il recherche des entr\\'ees pour lesquelles la distance \\`a la\ncha\\^ine cherch\\'ee est inf\\'erieure \\`a un certain seuil. La fonction\nutilis\\'ee n'est pas la distance d'\\'edition classique (distance DL); elle est\nadapt\\'ee \\`a un corpus, et se fonde sur la prise en compte de co\\^uts\nd'alt\\'eration \\'el\\'ementaires d\\'efinis non pas sur des caract\\`eres, mais\nsur des sous-cha\\^ines (des blocs de caract\\`eres).", "published": "2021-09-01 21:36:20", "link": "http://arxiv.org/abs/2109.00624v1", "categories": ["cs.CL", "cs.IR", "H.3.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "Tree-constrained Pointer Generator for End-to-end Contextual Speech\n  Recognition", "abstract": "Contextual knowledge is important for real-world automatic speech recognition\n(ASR) applications. In this paper, a novel tree-constrained pointer generator\n(TCPGen) component is proposed that incorporates such knowledge as a list of\nbiasing words into both attention-based encoder-decoder and transducer\nend-to-end ASR models in a neural-symbolic way. TCPGen structures the biasing\nwords into an efficient prefix tree to serve as its symbolic input and creates\na neural shortcut between the tree and the final ASR output distribution to\nfacilitate recognising biasing words during decoding. Systems were trained and\nevaluated on the Librispeech corpus where biasing words were extracted at the\nscales of an utterance, a chapter, or a book to simulate different application\nscenarios. Experimental results showed that TCPGen consistently improved word\nerror rates (WERs) compared to the baselines, and in particular, achieved\nsignificant WER reductions on the biasing words. TCPGen is highly efficient: it\ncan handle 5,000 biasing words and distractors and only add a small overhead to\nmemory use and computation cost.", "published": "2021-09-01 21:41:59", "link": "http://arxiv.org/abs/2109.00627v3", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "An Ensemble Approach for Annotating Source Code Identifiers with\n  Part-of-speech Tags", "abstract": "This paper presents an ensemble part-of-speech tagging approach for source\ncode identifiers. Ensemble tagging is a technique that uses machine-learning\nand the output from multiple part-of-speech taggers to annotate natural\nlanguage text at a higher quality than the part-of-speech taggers are able to\nobtain independently. Our ensemble uses three state-of-the-art part-of-speech\ntaggers: SWUM, POSSE, and Stanford. We study the quality of the ensemble's\nannotations on five different types of identifier names: function, class,\nattribute, parameter, and declaration statement at the level of both individual\nwords and full identifier names. We also study and discuss the weaknesses of\nour tagger to promote the future amelioration of these problems through further\nresearch. Our results show that the ensemble achieves 75\\% accuracy at the\nidentifier level and 84-86\\% accuracy at the word level. This is an increase of\n+17\\% points at the identifier level from the closest independent\npart-of-speech tagger.", "published": "2021-09-01 21:49:32", "link": "http://arxiv.org/abs/2109.00629v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Stochastic Transformer Networks with Linear Competing Units: Application\n  to end-to-end SL Translation", "abstract": "Automating sign language translation (SLT) is a challenging real world\napplication. Despite its societal importance, though, research progress in the\nfield remains rather poor. Crucially, existing methods that yield viable\nperformance necessitate the availability of laborious to obtain gloss sequence\ngroundtruth. In this paper, we attenuate this need, by introducing an\nend-to-end SLT model that does not entail explicit use of glosses; the model\nonly needs text groundtruth. This is in stark contrast to existing end-to-end\nmodels that use gloss sequence groundtruth, either in the form of a modality\nthat is recognized at an intermediate model stage, or in the form of a parallel\noutput process, jointly trained with the SLT model. Our approach constitutes a\nTransformer network with a novel type of layers that combines: (i) local\nwinner-takes-all (LWTA) layers with stochastic winner sampling, instead of\nconventional ReLU layers, (ii) stochastic weights with posterior distributions\nestimated via variational inference, and (iii) a weight compression technique\nat inference time that exploits estimated posterior variance to perform\nmassive, almost lossless compression. We demonstrate that our approach can\nreach the currently best reported BLEU-4 score on the PHOENIX 2014T benchmark,\nbut without making use of glosses for model training, and with a memory\nfootprint reduced by more than 70%.", "published": "2021-09-01 15:00:52", "link": "http://arxiv.org/abs/2109.13318v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pattern-based Acquisition of Scientific Entities from Scholarly Article\n  Titles", "abstract": "We describe a rule-based approach for the automatic acquisition of salient\nscientific entities from Computational Linguistics (CL) scholarly article\ntitles. Two observations motivated the approach: (i) noting salient aspects of\nan article's contribution in its title; and (ii) pattern regularities capturing\nthe salient terms that could be expressed in a set of rules. Only those\nlexico-syntactic patterns were selected that were easily recognizable, occurred\nfrequently, and positionally indicated a scientific entity type. The rules were\ndeveloped on a collection of 50,237 CL titles covering all articles in the ACL\nAnthology. In total, 19,799 research problems, 18,111 solutions, 20,033\nresources, 1,059 languages, 6,878 tools, and 21,687 methods were extracted at\nan average precision of 75%.", "published": "2021-09-01 05:59:06", "link": "http://arxiv.org/abs/2109.00199v2", "categories": ["cs.IR", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Exploring deep learning methods for recognizing rare diseases and their\n  clinical manifestations from texts", "abstract": "Although rare diseases are characterized by low prevalence, approximately 300\nmillion people are affected by a rare disease. The early and accurate diagnosis\nof these conditions is a major challenge for general practitioners, who do not\nhave enough knowledge to identify them. In addition to this, rare diseases\nusually show a wide variety of manifestations, which might make the diagnosis\neven more difficult. A delayed diagnosis can negatively affect the patient's\nlife. Therefore, there is an urgent need to increase the scientific and medical\nknowledge about rare diseases. Natural Language Processing (NLP) and Deep\nLearning can help to extract relevant information about rare diseases to\nfacilitate their diagnosis and treatments. The paper explores the use of\nseveral deep learning techniques such as Bidirectional Long Short Term Memory\n(BiLSTM) networks or deep contextualized word representations based on\nBidirectional Encoder Representations from Transformers (BERT) to recognize\nrare diseases and their clinical manifestations (signs and symptoms) in the\nRareDis corpus. This corpus contains more than 5,000 rare diseases and almost\n6,000 clinical manifestations. BioBERT, a domain-specific language\nrepresentation based on BERT and trained on biomedical corpora, obtains the\nbest results. In particular, this model obtains an F1-score of 85.2% for rare\ndiseases, outperforming all the other models.", "published": "2021-09-01 12:35:26", "link": "http://arxiv.org/abs/2109.00343v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Chronic Pain and Language: A Topic Modelling Approach to Personal Pain\n  Descriptions", "abstract": "Chronic pain is recognized as a major health problem, with impacts not only\nat the economic, but also at the social, and individual levels. Being a private\nand subjective experience, it is impossible to externally and impartially\nexperience, describe, and interpret chronic pain as a purely noxious stimulus\nthat would directly point to a causal agent and facilitate its mitigation,\ncontrary to acute pain, the assessment of which is usually straightforward.\nVerbal communication is, thus, key to convey relevant information to health\nprofessionals that would otherwise not be accessible to external entities,\nnamely, intrinsic qualities about the painful experience and the patient. We\npropose and discuss a topic modelling approach to recognize patterns in verbal\ndescriptions of chronic pain, and use these patterns to quantify and qualify\nexperiences of pain. Our approaches allow for the extraction of novel insights\non chronic pain experiences from the obtained topic models and latent spaces.\nWe argue that our results are clinically relevant for the assessment and\nmanagement of chronic pain.", "published": "2021-09-01 14:31:16", "link": "http://arxiv.org/abs/2109.00402v2", "categories": ["cs.CL", "cs.IR", "q-bio.QM", "I.2.7; I.5.3; I.5.4; J.3; J.4"], "primary_category": "cs.CL"}
{"title": "Boosting Search Engines with Interactive Agents", "abstract": "This paper presents first successful steps in designing search agents that\nlearn meta-strategies for iterative query refinement in information-seeking\ntasks. Our approach uses machine reading to guide the selection of refinement\nterms from aggregated search results. Agents are then empowered with simple but\neffective search operators to exert fine-grained and transparent control over\nqueries and search results. We develop a novel way of generating synthetic\nsearch sessions, which leverages the power of transformer-based language models\nthrough (self-)supervised learning. We also present a reinforcement learning\nagent with dynamically constrained actions that learns interactive search\nstrategies from scratch. Our search agents obtain retrieval and answer quality\nperformance comparable to recent neural methods, using only a traditional\nterm-based BM25 ranking function and interpretable discrete reranking and\nfiltering actions.", "published": "2021-09-01 13:11:57", "link": "http://arxiv.org/abs/2109.00527v3", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Improving Adversarial Training of NLP Models", "abstract": "Adversarial training, a method for learning robust deep neural networks,\nconstructs adversarial examples during training. However, recent methods for\ngenerating NLP adversarial examples involve combinatorial search and expensive\nsentence encoders for constraining the generated instances. As a result, it\nremains challenging to use vanilla adversarial training to improve NLP models'\nperformance, and the benefits are mainly uninvestigated. This paper proposes a\nsimple and improved vanilla adversarial training process for NLP models, which\nwe name Attacking to Training (A2T). The core part of A2T is a new and cheaper\nword substitution attack optimized for vanilla adversarial training. We use A2T\nto train BERT and RoBERTa models on IMDB, Rotten Tomatoes, Yelp, and SNLI\ndatasets. Our results empirically show that it is possible to train robust NLP\nmodels using a much cheaper adversary. We demonstrate that vanilla adversarial\ntraining with A2T can improve an NLP model's robustness to the attack it was\noriginally trained with and also defend the model against other types of word\nsubstitution attacks. Furthermore, we show that A2T can improve NLP models'\nstandard accuracy, cross-domain generalization, and interpretability. Code is\navailable at https://github.com/QData/Textattack-A2T .", "published": "2021-09-01 17:14:26", "link": "http://arxiv.org/abs/2109.00544v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WebQA: Multihop and Multimodal QA", "abstract": "Scaling Visual Question Answering (VQA) to the open-domain and multi-hop\nnature of web searches, requires fundamental advances in visual representation\nlearning, knowledge aggregation, and language generation. In this work, we\nintroduce WebQA, a challenging new benchmark that proves difficult for\nlarge-scale state-of-the-art models which lack language groundable visual\nrepresentations for novel objects and the ability to reason, yet trivial for\nhumans. WebQA mirrors the way humans use the web: 1) Ask a question, 2) Choose\nsources to aggregate, and 3) Produce a fluent language response. This is the\nbehavior we should be expecting from IoT devices and digital assistants.\nExisting work prefers to assume that a model can either reason about knowledge\nin images or in text. WebQA includes a secondary text-only QA task to ensure\nimproved visual performance does not come at the cost of language\nunderstanding. Our challenge for the community is to create unified multimodal\nreasoning models that answer questions regardless of the source modality,\nmoving us closer to digital assistants that not only query language knowledge,\nbut also the richer visual online world.", "published": "2021-09-01 19:43:59", "link": "http://arxiv.org/abs/2109.00590v4", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The VoicePrivacy 2020 Challenge: Results and findings", "abstract": "This paper presents the results and analyses stemming from the first\nVoicePrivacy 2020 Challenge which focuses on developing anonymization solutions\nfor speech technology. We provide a systematic overview of the challenge design\nwith an analysis of submitted systems and evaluation results. In particular, we\ndescribe the voice anonymization task and datasets used for system development\nand evaluation. Also, we present different attack models and the associated\nobjective and subjective evaluation metrics. We introduce two anonymization\nbaselines and provide a summary description of the anonymization systems\ndeveloped by the challenge participants. We report objective and subjective\nevaluation results for baseline and submitted systems. In addition, we present\nexperimental results for alternative privacy metrics and attack models\ndeveloped as a part of the post-evaluation analysis. Finally, we summarize our\ninsights and observations that will influence the design of the next\nVoicePrivacy challenge edition and some directions for future voice\nanonymization research.", "published": "2021-09-01 23:40:38", "link": "http://arxiv.org/abs/2109.00648v4", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Problem Learning: Towards the Free Will of Machines", "abstract": "A machine intelligence pipeline usually consists of six components: problem,\nrepresentation, model, loss, optimizer and metric. Researchers have worked hard\ntrying to automate many components of the pipeline. However, one key component\nof the pipeline--problem definition--is still left mostly unexplored in terms\nof automation. Usually, it requires extensive efforts from domain experts to\nidentify, define and formulate important problems in an area. However,\nautomatically discovering research or application problems for an area is\nbeneficial since it helps to identify valid and potentially important problems\nhidden in data that are unknown to domain experts, expand the scope of tasks\nthat we can do in an area, and even inspire completely new findings.\n  This paper describes Problem Learning, which aims at learning to discover and\ndefine valid and ethical problems from data or from the machine's interaction\nwith the environment. We formalize problem learning as the identification of\nvalid and ethical problems in a problem space and introduce several possible\napproaches to problem learning. In a broader sense, problem learning is an\napproach towards the free will of intelligent machines. Currently, machines are\nstill limited to solving the problems defined by humans, without the ability or\nflexibility to freely explore various possible problems that are even unknown\nto humans. Though many machine learning techniques have been developed and\nintegrated into intelligent systems, they still focus on the means rather than\nthe purpose in that machines are still solving human defined problems. However,\nproposing good problems is sometimes even more important than solving problems,\nbecause a good problem can help to inspire new ideas and gain deeper\nunderstandings. The paper also discusses the ethical implications of problem\nlearning under the background of Responsible AI.", "published": "2021-09-01 04:08:09", "link": "http://arxiv.org/abs/2109.00177v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Prior Distribution Design for Music Bleeding-Sound Reduction Based on\n  Nonnegative Matrix Factorization", "abstract": "When we place microphones close to a sound source near other sources in audio\nrecording, the obtained audio signal includes undesired sound from the other\nsources, which is often called cross-talk or bleeding sound. For many audio\napplications including onstage sound reinforcement and sound editing after a\nlive performance, it is important to reduce the bleeding sound in each recorded\nsignal. However, since microphones are spatially apart from each other in this\nsituation, typical phase-aware blind source separation (BSS) methods cannot be\nused. We propose a phase-insensitive method for blind bleeding-sound reduction.\nThis method is based on time-channel nonnegative matrix factorization, which is\na BSS method using only amplitude spectrograms. With the proposed method, we\nintroduce the gamma-distribution-based prior for leakage levels of bleeding\nsounds. Its optimization can be interpreted as maximum a posteriori estimation.\nThe experimental results of music bleeding-sound reduction indicate that the\nproposed method is more effective for bleeding-sound reduction of music signals\ncompared with other BSS methods.", "published": "2021-09-01 08:21:29", "link": "http://arxiv.org/abs/2109.00237v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Separable Temporal Convolution Neural Network with Attention for\n  Small-Footprint Keyword Spotting", "abstract": "Keyword spotting (KWS) on mobile devices generally requires a small memory\nfootprint. However, most current models still maintain a large number of\nparameters in order to ensure good performance. To solve this problem, this\npaper proposes a separable temporal convolution neural network with attention,\nit has a small number of parameters. Through the time convolution combined with\nattention mechanism, a small number of parameters model (32.2K) is implemented\nwhile maintaining high performance. The proposed model achieves 95.7% accuracy\non the Google Speech Commands dataset, which is close to the performance of\nRes15(239K), the state-of-the-art model in KWS at present.", "published": "2021-09-01 09:12:06", "link": "http://arxiv.org/abs/2109.00260v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Embedding and Beamforming: All-neural Causal Beamformer for Multichannel\n  Speech Enhancement", "abstract": "The spatial covariance matrix has been considered to be significant for\nbeamformers. Standing upon the intersection of traditional beamformers and deep\nneural networks, we propose a causal neural beamformer paradigm called\nEmbedding and Beamforming, and two core modules are designed accordingly,\nnamely EM and BM. For EM, instead of estimating spatial covariance matrix\nexplicitly, the 3-D embedding tensor is learned with the network, where both\nspectral and spatial discriminative information can be represented. For BM, a\nnetwork is directly leveraged to derive the beamforming weights so as to\nimplement filter-and-sum operation. To further improve the speech quality, a\npost-processing module is introduced to further suppress the residual noise.\nBased on the DNS-Challenge dataset, we conduct the experiments for multichannel\nspeech enhancement and the results show that the proposed system outperforms\nprevious advanced baselines by a large margin in multiple evaluation metrics.", "published": "2021-09-01 09:19:35", "link": "http://arxiv.org/abs/2109.00265v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Benchmarking and challenges in security and privacy for voice biometrics", "abstract": "For many decades, research in speech technologies has focused upon improving\nreliability. With this now meeting user expectations for a range of diverse\napplications, speech technology is today omni-present. As result, a focus on\nsecurity and privacy has now come to the fore. Here, the research effort is in\nits relative infancy and progress calls for greater, multidisciplinary\ncollaboration with security, privacy, legal and ethical experts among others.\nSuch collaboration is now underway. To help catalyse the efforts, this paper\nprovides a high-level overview of some related research. It targets the\nnon-speech audience and describes the benchmarking methodology that has\nspearheaded progress in traditional research and which now drives recent\nsecurity and privacy initiatives related to voice biometrics. We describe: the\nASVspoof challenge relating to the development of spoofing countermeasures; the\nVoicePrivacy initiative which promotes research in anonymisation for privacy\npreservation.", "published": "2021-09-01 09:41:44", "link": "http://arxiv.org/abs/2109.00281v1", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Mean absorption estimation from room impulse responses using virtually\n  supervised learning", "abstract": "In the context of building acoustics and the acoustic diagnosis of an\nexisting room, this paper introduces and investigates a new approach to\nestimate mean absorption coefficients solely from a room impulse response\n(RIR). This inverse problem is tackled via virtually-supervised learning,\nnamely, the RIR-to-absorption mapping is implicitly learned by regression on a\nsimulated dataset using artificial neural networks. We focus on simple models\nbased on well-understood architectures. The critical choices of geometric,\nacoustic and simulation parameters used to train the models are extensively\ndiscussed and studied, while keeping in mind conditions that are representative\nof the field of building acoustics. Estimation errors from the learned neural\nmodels are compared to those obtained with classical formulas that require\nknowledge of the room's geometry and reverberation times. Extensive comparisons\nmade on a variety of simulated test sets highlight different conditions under\nwhich the learned models can overcome the well-known limitations of the diffuse\nsound field hypothesis underlying these formulas. Results obtained on real RIRs\nmeasured in an acoustically configurable room show that at 1~kHz and above, the\nproposed approach performs comparably to classical models when reverberation\ntimes can be reliably estimated, and continues to work even when they cannot.", "published": "2021-09-01 14:06:20", "link": "http://arxiv.org/abs/2109.00393v1", "categories": ["cs.NE", "cs.SD", "eess.AS", "physics.class-ph"], "primary_category": "cs.NE"}
{"title": "ASVspoof 2021: Automatic Speaker Verification Spoofing and\n  Countermeasures Challenge Evaluation Plan", "abstract": "The automatic speaker verification spoofing and countermeasures (ASVspoof)\nchallenge series is a community-led initiative which aims to promote the\nconsideration of spoofing and the development of countermeasures. ASVspoof 2021\nis the 4th in a series of bi-annual, competitive challenges where the goal is\nto develop countermeasures capable of discriminating between bona fide and\nspoofed or deepfake speech. This document provides a technical description of\nthe ASVspoof 2021 challenge, including details of training, development and\nevaluation data, metrics, baselines, evaluation rules, submission procedures\nand the schedule.", "published": "2021-09-01 15:32:28", "link": "http://arxiv.org/abs/2109.00535v1", "categories": ["eess.AS", "cs.CR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ASVspoof 2021: accelerating progress in spoofed and deepfake speech\n  detection", "abstract": "ASVspoof 2021 is the forth edition in the series of bi-annual challenges\nwhich aim to promote the study of spoofing and the design of countermeasures to\nprotect automatic speaker verification systems from manipulation. In addition\nto a continued focus upon logical and physical access tasks in which there are\na number of advances compared to previous editions, ASVspoof 2021 introduces a\nnew task involving deepfake speech detection. This paper describes all three\ntasks, the new databases for each of them, the evaluation metrics, four\nchallenge baselines, the evaluation platform and a summary of challenge\nresults. Despite the introduction of channel and compression variability which\ncompound the difficulty, results for the logical access and deepfake tasks are\nclose to those from previous ASVspoof editions. Results for the physical access\ntask show the difficulty in detecting attacks in real, variable physical\nspaces. With ASVspoof 2021 being the first edition for which participants were\nnot provided with any matched training or development data and with this\nreflecting real conditions in which the nature of spoofed and deepfake speech\ncan never be predicated with confidence, the results are extremely encouraging\nand demonstrate the substantial progress made in the field in recent years.", "published": "2021-09-01 16:17:31", "link": "http://arxiv.org/abs/2109.00537v1", "categories": ["eess.AS", "cs.CR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Novel Multi-Centroid Template Matching Algorithm and Its Application\n  to Cough Detection", "abstract": "Cough is a major symptom of respiratory-related diseases. There exists a\ntremendous amount of work in detecting coughs from audio but there has been no\neffort to identify coughs from solely inertial measurement unit (IMU). Coughing\ncauses motion across the whole body and especially on the neck and head.\nTherefore, head motion data during coughing captured by a head-worn IMU sensor\ncould be leveraged to detect coughs using a template matching algorithm. In\ntime series template matching problems, K-Nearest Neighbors (KNN) combined with\nelastic distance measurement (esp. Dynamic Time Warping (DTW)) achieves\noutstanding performance. However, it is often regarded as prohibitively\ntime-consuming. Nearest Centroid Classifier is thereafter proposed. But the\naccuracy is comprised of only one centroid obtained for each class.\nCentroid-based Classifier performs clustering and averaging for each cluster,\nbut requires manually setting the number of clusters. We propose a novel\nself-tuning multi-centroid template-matching algorithm, which can automatically\nadjust the number of clusters to balance accuracy and inference time. Through\nexperiments conducted on synthetic datasets and a real-world earbud-based cough\ndataset, we demonstrate the superiority of our proposed algorithm and present\nthe result of cough detection with a single accelerometer sensor on the earbuds\nplatform.", "published": "2021-09-01 21:52:36", "link": "http://arxiv.org/abs/2109.00630v2", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS", "I.5.4; I.5.1"], "primary_category": "cs.SD"}
{"title": "Physiological-Physical Feature Fusion for Automatic Voice Spoofing\n  Detection", "abstract": "Speaker verification systems have been used in many production scenarios in\nrecent years. Unfortunately, they are still highly prone to different kinds of\nspoofing attacks such as voice conversion and speech synthesis, etc. In this\npaper, we propose a new method base on physiological-physical feature fusion to\ndeal with voice spoofing attacks. This method involves feature extraction, a\ndensely connected convolutional neural network with squeeze and excitation\nblock (SE-DenseNet), multi-scale residual neural network with squeeze and\nexcitation block (SE-Res2Net) and feature fusion strategies. We first\npre-trained a convolutional neural network using the speaker's voice and face\nin the video as surveillance signals. It can extract physiological features\nfrom speech. Then we use SE-DenseNet and SE-Res2Net to extract physical\nfeatures. Such a densely connection pattern has high parameter efficiency and\nsqueeze and excitation block can enhance the transmission of the feature.\nFinally, we integrate the two features into the SE-Densenet to identify the\nspoofing attacks. Experimental results on the ASVspoof 2019 data set show that\nour model is effective for voice spoofing detection. In the logical access\nscenario, our model improves the tandem decision cost function (t-DCF) and\nequal error rate (EER) scores by 4% and 7%, respectively, compared with other\nmethods. In the physical access scenario, our model improved t-DCF and EER\nscores by 8% and 10%, respectively.", "published": "2021-09-01 03:32:22", "link": "http://arxiv.org/abs/2109.00913v1", "categories": ["eess.AS", "cs.SD", "eess.IV"], "primary_category": "eess.AS"}
{"title": "You Only Hear Once: A YOLO-like Algorithm for Audio Segmentation and\n  Sound Event Detection", "abstract": "Audio segmentation and sound event detection are crucial topics in machine\nlistening that aim to detect acoustic classes and their respective boundaries.\nIt is useful for audio-content analysis, speech recognition, audio-indexing,\nand music information retrieval. In recent years, most research articles adopt\nsegmentation-by-classification. This technique divides audio into small frames\nand individually performs classification on these frames. In this paper, we\npresent a novel approach called You Only Hear Once (YOHO), which is inspired by\nthe YOLO algorithm popularly adopted in Computer Vision. We convert the\ndetection of acoustic boundaries into a regression problem instead of\nframe-based classification. This is done by having separate output neurons to\ndetect the presence of an audio class and predict its start and end points. The\nrelative improvement for F-measure of YOHO, compared to the state-of-the-art\nConvolutional Recurrent Neural Network, ranged from 1% to 6% across multiple\ndatasets for audio segmentation and sound event detection. As the output of\nYOHO is more end-to-end and has fewer neurons to predict, the speed of\ninference is at least 6 times faster than segmentation-by-classification. In\naddition, as this approach predicts acoustic boundaries directly, the\npost-processing and smoothing is about 7 times faster.", "published": "2021-09-01 12:50:16", "link": "http://arxiv.org/abs/2109.00962v3", "categories": ["eess.AS", "cs.LG", "cs.SD", "I.5.1; I.5.4"], "primary_category": "eess.AS"}
{"title": "Scalable Data Annotation Pipeline for High-Quality Large Speech Datasets\n  Development", "abstract": "This paper introduces a human-in-the-loop (HITL) data annotation pipeline to\ngenerate high-quality, large-scale speech datasets. The pipeline combines human\nand machine advantages to more quickly, accurately, and cost-effectively\nannotate datasets with machine pre-labeling and fully manual auditing. Quality\ncontrol mechanisms such as blind testing, behavior monitoring, and data\nvalidation have been adopted in the annotation pipeline to mitigate potential\nbias introduced by machine-generated labels. Our A/B testing and pilot results\ndemonstrated the HITL pipeline can improve annotation speed and capacity by at\nleast 80% and quality is comparable to or higher than manual double pass\nannotation. We are leveraging this scalable pipeline to create and continuously\ngrow ultra-high volume off-the-shelf (UHV-OTS) speech corpora for multiple\nlanguages, with the capability to expand to 10,000+ hours per language\nannually. Customized datasets can be produced from the UHV-OTS corpora using\ndynamic packaging. UHV-OTS is a long-term Appen project to support commercial\nand academic research data needs in speech processing. Appen will donate a\nnumber of free speech datasets from the UHV-OTS each year to support academic\nand open source community research under the CC-BY-SA license. We are also\nreleasing the code of the data pre-processing and pre-tagging pipeline under\nthe Apache 2.0 license to allow reproduction of the results reported in the\npaper.", "published": "2021-09-01 17:54:17", "link": "http://arxiv.org/abs/2109.01164v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FaVoA: Face-Voice Association Favours Ambiguous Speaker Detection", "abstract": "The strong relation between face and voice can aid active speaker detection\nsystems when faces are visible, even in difficult settings, when the face of a\nspeaker is not clear or when there are several people in the same scene. By\nbeing capable of estimating the frontal facial representation of a person from\nhis/her speech, it becomes easier to determine whether he/she is a potential\ncandidate for being classified as an active speaker, even in challenging cases\nin which no mouth movement is detected from any person in that same scene. By\nincorporating a face-voice association neural network into an existing\nstate-of-the-art active speaker detection model, we introduce FaVoA (Face-Voice\nAssociation Ambiguous Speaker Detector), a neural network model that can\ncorrectly classify particularly ambiguous scenarios. FaVoA not only finds\npositive associations, but helps to rule out non-matching face-voice\nassociations, where a face does not match a voice. Its use of a\ngated-bimodal-unit architecture for the fusion of those models offers a way to\nquantitatively determine how much each modality contributes to the\nclassification.", "published": "2021-09-01 19:08:15", "link": "http://arxiv.org/abs/2109.00577v1", "categories": ["cs.LG", "cs.CV", "cs.SD", "eess.AS", "eess.IV", "I.2.6"], "primary_category": "cs.LG"}
