{"title": "A Novel Bilingual Word Embedding Method for Lexical Translation Using\n  Bilingual Sense Clique", "abstract": "Most of the existing methods for bilingual word embedding only consider\nshallow context or simple co-occurrence information. In this paper, we propose\na latent bilingual sense unit (Bilingual Sense Clique, BSC), which is derived\nfrom a maximum complete sub-graph of pointwise mutual information based graph\nover bilingual corpus. In this way, we treat source and target words equally\nand a separated bilingual projection processing that have to be used in most\nexisting works is not necessary any more. Several dimension reduction methods\nare evaluated to summarize the BSC-word relationship. The proposed method is\nevaluated on bilingual lexicon translation tasks and empirical results show\nthat bilingual sense embedding methods outperform existing bilingual word\nembedding methods.", "published": "2016-07-29 06:28:32", "link": "http://arxiv.org/abs/1607.08692v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Connecting Phrase based Statistical Machine Translation Adaptation", "abstract": "Although more additional corpora are now available for Statistical Machine\nTranslation (SMT), only the ones which belong to the same or similar domains\nwith the original corpus can indeed enhance SMT performance directly. Most of\nthe existing adaptation methods focus on sentence selection. In comparison,\nphrase is a smaller and more fine grained unit for data selection, therefore we\npropose a straightforward and efficient connecting phrase based adaptation\nmethod, which is applied to both bilingual phrase pair and monolingual n-gram\nadaptation. The proposed method is evaluated on IWSLT/NIST data sets, and the\nresults show that phrase based SMT performance are significantly improved (up\nto +1.6 in comparison with phrase based SMT baseline system and +0.9 in\ncomparison with existing methods).", "published": "2016-07-29 06:29:37", "link": "http://arxiv.org/abs/1607.08693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cseq2seq: Cyclic Sequence-to-Sequence Learning", "abstract": "The vanilla sequence-to-sequence learning (seq2seq) reads and encodes a\nsource sequence into a fixed-length vector only once, suffering from its\ninsufficiency in modeling structural correspondence between the source and\ntarget sequence. Instead of handling this insufficiency with a linearly\nweighted attention mechanism, in this paper, we propose to use a recurrent\nneural network (RNN) as an alternative (Cseq2seq-I). During decoding,\nCseq2seq-I cyclically feeds the previous decoding state back to the encoder as\nthe initial state of the RNN, and reencodes source representations to produce\ncontext vectors. We surprisingly find that the introduced RNN succeeds in\ndynamically detecting translationrelated source tokens according to the partial\ntarget sequence. Based on this finding, we further hypothesize that the partial\ntarget sequence can act as a feedback to improve the understanding of the\nsource sequence. To test this hypothesis, we propose cyclic\nsequence-to-sequence learning (Cseq2seq-II) which differs from the seq2seq only\nin the reintroduction of previous decoding state into the same encoder. We\nfurther perform parameter sharing on Cseq2seq-II to reduce parameter redundancy\nand enhance regularization. In particular, we share the weights of the encoder\nand decoder, and two targetside word embeddings, making Cseq2seq-II equivalent\nto a single conditional RNN model, with 31% parameters pruned but even better\nperformance. Cseq2seq-II not only preserves the simplicity of seq2seq but also\nyields comparable and promising results on machine translation tasks.\nExperiments on Chinese- English and English-German translation show that\nCseq2seq achieves significant and consistent improvements over seq2seq and is\nas competitive as the attention-based seq2seq model.", "published": "2016-07-29 08:35:10", "link": "http://arxiv.org/abs/1607.08725v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Authorship Verification - An Approach based on Random Forest", "abstract": "Authorship attribution, being an important problem in many areas in-cluding\ninformation retrieval, computational linguistics, law and journalism etc., has\nbeen identified as a subject of increasingly research interest in the re-cent\nyears. In case of Author Identification task in PAN at CLEF 2015, the main\nfocus was given on cross-genre and cross-topic author verification tasks. We\nhave used several word-based and style-based features to identify the\ndif-ferences between the known and unknown problems of one given set and label\nthe unknown ones accordingly using a Random Forest based classifier.", "published": "2016-07-29 18:22:02", "link": "http://arxiv.org/abs/1607.08885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text authorship identified using the dynamics of word co-occurrence\n  networks", "abstract": "The identification of authorship in disputed documents still requires human\nexpertise, which is now unfeasible for many tasks owing to the large volumes of\ntext and authors in practical applications. In this study, we introduce a\nmethodology based on the dynamics of word co-occurrence networks representing\nwritten texts to classify a corpus of 80 texts by 8 authors. The texts were\ndivided into sections with equal number of linguistic tokens, from which time\nseries were created for 12 topological metrics. The series were proven to be\nstationary (p-value>0.05), which permits to use distribution moments as\nlearning attributes. With an optimized supervised learning procedure using a\nRadial Basis Function Network, 68 out of 80 texts were correctly classified,\ni.e. a remarkable 85% author matching success rate. Therefore, fluctuations in\npurely dynamic network metrics were found to characterize authorship, thus\nopening the way for the description of texts in terms of small evolving\nnetworks. Moreover, the approach introduced allows for comparison of texts with\ndiverse characteristics in a simple, fast fashion.", "published": "2016-07-29 20:33:22", "link": "http://arxiv.org/abs/1608.01965v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SPICE: Semantic Propositional Image Caption Evaluation", "abstract": "There is considerable interest in the task of automatically generating image\ncaptions. However, evaluation is challenging. Existing automatic evaluation\nmetrics are primarily sensitive to n-gram overlap, which is neither necessary\nnor sufficient for the task of simulating human judgment. We hypothesize that\nsemantic propositional content is an important component of human caption\nevaluation, and propose a new automated caption evaluation metric defined over\nscene graphs coined SPICE. Extensive evaluations across a range of models and\ndatasets indicate that SPICE captures human judgments over model-generated\ncaptions better than other automatic metrics (e.g., system-level correlation of\n0.88 with human judgments on the MS COCO dataset, versus 0.43 for CIDEr and\n0.53 for METEOR). Furthermore, SPICE can answer questions such as `which\ncaption-generator best understands colors?' and `can caption-generators count?'", "published": "2016-07-29 14:26:27", "link": "http://arxiv.org/abs/1607.08822v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Labeling of Query Words using Conditional Random Field", "abstract": "This paper describes our approach on Query Word Labeling as an attempt in the\nshared task on Mixed Script Information Retrieval at Forum for Information\nRetrieval Evaluation (FIRE) 2015. The query is written in Roman script and the\nwords were in English or transliterated from Indian regional languages. A total\nof eight Indian languages were present in addition to English. We also\nidentified the Named Entities and special symbols as part of our task. A CRF\nbased machine learning framework was used for labeling the individual words\nwith their corresponding language labels. We used a dictionary based approach\nfor language identification. We also took into account the context of the word\nwhile identifying the language. Our system demonstrated an overall accuracy of\n75.5% for token level language identification. The strict F-measure scores for\nthe identification of token level language labels for Bengali, English and\nHindi are 0.7486, 0.892 and 0.7972 respectively. The overall weighted F-measure\nof our system was 0.7498.", "published": "2016-07-29 18:20:24", "link": "http://arxiv.org/abs/1607.08883v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Personalized Emphasis Framing for Persuasive Message Generation", "abstract": "In this paper, we present a study on personalized emphasis framing which can\nbe used to tailor the content of a message to enhance its appeal to different\nindividuals. With this framework, we directly model content selection decisions\nbased on a set of psychologically-motivated domain-independent personal traits\nincluding personality (e.g., extraversion and conscientiousness) and basic\nhuman values (e.g., self-transcendence and hedonism). We also demonstrate how\nthe analysis results can be used in automated personalized content selection\nfor persuasive message generation.", "published": "2016-07-29 19:16:08", "link": "http://arxiv.org/abs/1607.08898v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "TopicResponse: A Marriage of Topic Modelling and Rasch Modelling for\n  Automatic Measurement in MOOCs", "abstract": "This paper explores the suitability of using automatically discovered topics\nfrom MOOC discussion forums for modelling students' academic abilities. The\nRasch model from psychometrics is a popular generative probabilistic model that\nrelates latent student skill, latent item difficulty, and observed student-item\nresponses within a principled, unified framework. According to scholarly\neducational theory, discovered topics can be regarded as appropriate\nmeasurement items if (1) students' participation across the discovered topics\nis well fit by the Rasch model, and if (2) the topics are interpretable to\nsubject-matter experts as being educationally meaningful. Such Rasch-scaled\ntopics, with associated difficulty levels, could be of potential benefit to\ncurriculum refinement, student assessment and personalised feedback. The\ntechnical challenge that remains, is to discover meaningful topics that\nsimultaneously achieve good statistical fit with the Rasch model. To address\nthis challenge, we combine the Rasch model with non-negative matrix\nfactorisation based topic modelling, jointly fitting both models. We\ndemonstrate the suitability of our approach with quantitative experiments on\ndata from three Coursera MOOCs, and with qualitative survey results on topic\ninterpretability on a Discrete Optimisation MOOC.", "published": "2016-07-29 08:17:45", "link": "http://arxiv.org/abs/1607.08720v2", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Cognitive Science in the era of Artificial Intelligence: A roadmap for\n  reverse-engineering the infant language-learner", "abstract": "During their first years of life, infants learn the language(s) of their\nenvironment at an amazing speed despite large cross cultural variations in\namount and complexity of the available language input. Understanding this\nsimple fact still escapes current cognitive and linguistic theories. Recently,\nspectacular progress in the engineering science, notably, machine learning and\nwearable technology, offer the promise of revolutionizing the study of\ncognitive development. Machine learning offers powerful learning algorithms\nthat can achieve human-like performance on many linguistic tasks. Wearable\nsensors can capture vast amounts of data, which enable the reconstruction of\nthe sensory experience of infants in their natural environment. The project of\n'reverse engineering' language development, i.e., of building an effective\nsystem that mimics infant's achievements appears therefore to be within reach.\nHere, we analyze the conditions under which such a project can contribute to\nour scientific understanding of early language development. We argue that\ninstead of defining a sub-problem or simplifying the data, computational models\nshould address the full complexity of the learning situation, and take as input\nthe raw sensory signals available to infants. This implies that (1) accessible\nbut privacy-preserving repositories of home data be setup and widely shared,\nand (2) models be evaluated at different linguistic levels through a benchmark\nof psycholinguist tests that can be passed by machines and humans alike, (3)\nlinguistically and psychologically plausible learning architectures be scaled\nup to real data using probabilistic/optimization principles from machine\nlearning. We discuss the feasibility of this approach and present preliminary\nresults.", "published": "2016-07-29 08:33:10", "link": "http://arxiv.org/abs/1607.08723v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The DLVHEX System for Knowledge Representation: Recent Advances (System\n  Description)", "abstract": "The DLVHEX system implements the HEX-semantics, which integrates answer set\nprogramming (ASP) with arbitrary external sources. Since its first release ten\nyears ago, significant advancements were achieved. Most importantly, the\nexploitation of properties of external sources led to efficiency improvements\nand flexibility enhancements of the language, and technical improvements on the\nsystem side increased user's convenience. In this paper, we present the current\nstatus of the system and point out the most important recent enhancements over\nearly versions. While existing literature focuses on theoretical aspects and\nspecific components, a bird's eye view of the overall system is missing. In\norder to promote the system for real-world applications, we further present\napplications which were already successfully realized on top of DLVHEX. This\npaper is under consideration for acceptance in Theory and Practice of Logic\nProgramming.", "published": "2016-07-29 16:26:54", "link": "http://arxiv.org/abs/1607.08864v2", "categories": ["cs.CL", "cs.AI", "cs.PL"], "primary_category": "cs.CL"}
