{"title": "Exploiting user-frequency information for mining regionalisms from\n  Social Media texts", "abstract": "The task of detecting regionalisms (expressions or words used in certain\nregions) has traditionally relied on the use of questionnaires and surveys, and\nhas also heavily depended on the expertise and intuition of the surveyor. The\nirruption of Social Media and its microblogging services has produced an\nunprecedented wealth of content, mainly informal text generated by users,\nopening new opportunities for linguists to extend their studies of language\nvariation. Previous work on automatic detection of regionalisms depended mostly\non word frequencies. In this work, we present a novel metric based on\nInformation Theory that incorporates user frequency. We tested this metric on a\ncorpus of Argentinian Spanish tweets in two ways: via manual annotation of the\nrelevance of the retrieved terms, and also as a feature selection method for\ngeolocation of users. In either case, our metric outperformed other techniques\nbased solely in word frequency, suggesting that measuring the amount of users\nthat produce a word is informative. This tool has helped lexicographers\ndiscover several unregistered words of Argentinian Spanish, as well as\ndifferent meanings assigned to registered words.", "published": "2019-07-10 02:43:37", "link": "http://arxiv.org/abs/1907.04492v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lingua Custodia at WMT'19: Attempts to Control Terminology", "abstract": "This paper describes Lingua Custodia's submission to the WMT'19 news shared\ntask for German-to-French on the topic of the EU elections. We report\nexperiments on the adaptation of the terminology of a machine translation\nsystem to a specific topic, aimed at providing more accurate translations of\nspecific entities like political parties and person names, given that the\nshared task provided no in-domain training parallel data dealing with the\nrestricted topic. Our primary submission to the shared task uses\nbacktranslation generated with a type of decoding allowing the insertion of\nconstraints in the output in order to guarantee the correct translation of\nspecific terms that are not necessarily observed in the data.", "published": "2019-07-10 11:14:53", "link": "http://arxiv.org/abs/1907.04618v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Semantic Compositionality with Sememe Knowledge", "abstract": "Semantic compositionality (SC) refers to the phenomenon that the meaning of a\ncomplex linguistic unit can be composed of the meanings of its constituents.\nMost related works focus on using complicated compositionality functions to\nmodel SC while few works consider external knowledge in models. In this paper,\nwe verify the effectiveness of sememes, the minimum semantic units of human\nlanguages, in modeling SC by a confirmatory experiment. Furthermore, we make\nthe first attempt to incorporate sememe knowledge into SC models, and employ\nthe sememeincorporated models in learning representations of multiword\nexpressions, a typical task of SC. In experiments, we implement our models by\nincorporating knowledge from a famous sememe knowledge base HowNet and perform\nboth intrinsic and extrinsic evaluations. Experimental results show that our\nmodels achieve significant performance boost as compared to the baseline\nmethods without considering sememe knowledge. We further conduct quantitative\nanalysis and case studies to demonstrate the effectiveness of applying sememe\nknowledge in modeling SC. All the code and data of this paper can be obtained\non https://github.com/thunlp/Sememe-SC.", "published": "2019-07-10 14:20:43", "link": "http://arxiv.org/abs/1907.04744v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReQA: An Evaluation for End-to-End Answer Retrieval Models", "abstract": "Popular QA benchmarks like SQuAD have driven progress on the task of\nidentifying answer spans within a specific passage, with models now surpassing\nhuman performance. However, retrieving relevant answers from a huge corpus of\ndocuments is still a challenging problem, and places different requirements on\nthe model architecture. There is growing interest in developing scalable answer\nretrieval models trained end-to-end, bypassing the typical document retrieval\nstep. In this paper, we introduce Retrieval Question-Answering (ReQA), a\nbenchmark for evaluating large-scale sentence-level answer retrieval models. We\nestablish baselines using both neural encoding models as well as classical\ninformation retrieval techniques. We release our evaluation code to encourage\nfurther work on this challenging task.", "published": "2019-07-10 15:16:36", "link": "http://arxiv.org/abs/1907.04780v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BAM! Born-Again Multi-Task Networks for Natural Language Understanding", "abstract": "It can be challenging to train multi-task neural networks that outperform or\neven match their single-task counterparts. To help address this, we propose\nusing knowledge distillation where single-task models teach a multi-task model.\nWe enhance this training with teacher annealing, a novel method that gradually\ntransitions the model from distillation to supervised learning, helping the\nmulti-task model surpass its single-task teachers. We evaluate our approach by\nmulti-task fine-tuning BERT on the GLUE benchmark. Our method consistently\nimproves over standard single-task and multi-task training.", "published": "2019-07-10 17:14:47", "link": "http://arxiv.org/abs/1907.04829v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modelling the Socialization of Creative Agents in a Master-Apprentice\n  Setting: The Case of Movie Title Puns", "abstract": "This paper presents work on modelling the social psychological aspect of\nsocialization in the case of a computationally creative master-apprentice\nsystem. In each master-apprentice pair, the master, a genetic algorithm, is\nseen as a parent for its apprentice, which is an NMT based sequence-to-sequence\nmodel. The effect of different parenting styles on the creative output of each\npair is in the focus of this study. This approach brings a novel view point to\ncomputational social creativity, which has mainly focused in the past on\ncomputationally creative agents being on a socially equal level, whereas our\napproach studies the phenomenon in the context of a social hierarchy.", "published": "2019-07-10 23:12:17", "link": "http://arxiv.org/abs/1907.04954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from\n  Wikipedia", "abstract": "We present an approach based on multilingual sentence embeddings to\nautomatically extract parallel sentences from the content of Wikipedia articles\nin 85 languages, including several dialects or low-resource languages. We do\nnot limit the the extraction process to alignments with English, but\nsystematically consider all possible language pairs. In total, we are able to\nextract 135M parallel sentences for 1620 different language pairs, out of which\nonly 34M are aligned with English. This corpus of parallel sentences is freely\navailable at\nhttps://github.com/facebookresearch/LASER/tree/master/tasks/WikiMatrix. To get\nan indication on the quality of the extracted bitexts, we train neural MT\nbaseline systems on the mined data only for 1886 languages pairs, and evaluate\nthem on the TED corpus, achieving strong BLEU scores for many language pairs.\nThe WikiMatrix bitexts seem to be particularly interesting to train MT systems\nbetween distant languages without the need to pivot through English.", "published": "2019-07-10 23:57:30", "link": "http://arxiv.org/abs/1907.05791v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Networks as Explicit Word-Based Rules", "abstract": "Filters of convolutional networks used in computer vision are often\nvisualized as image patches that maximize the response of the filter. We use\nthe same approach to interpret weight matrices in simple architectures for\nnatural language processing tasks. We interpret a convolutional network for\nsentiment classification as word-based rules. Using the rule, we recover the\nperformance of the original model.", "published": "2019-07-10 10:50:22", "link": "http://arxiv.org/abs/1907.04613v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Can Unconditional Language Models Recover Arbitrary Sentences?", "abstract": "Neural network-based generative language models like ELMo and BERT can work\neffectively as general purpose sentence encoders in text classification without\nfurther fine-tuning. Is it possible to adapt them in a similar way for use as\ngeneral-purpose decoders? For this to be possible, it would need to be the case\nthat for any target sentence of interest, there is some continuous\nrepresentation that can be passed to the language model to cause it to\nreproduce that sentence. We set aside the difficult problem of designing an\nencoder that can produce such representations and, instead, ask directly\nwhether such representations exist at all. To do this, we introduce a pair of\neffective, complementary methods for feeding representations into pretrained\nunconditional language models and a corresponding set of methods to map\nsentences into and out of this representation space, the reparametrized\nsentence space. We then investigate the conditions under which a language model\ncan be made to generate a sentence through the identification of a point in\nsuch a space and find that it is possible to recover arbitrary sentences nearly\nperfectly with language models and representations of moderate size without\nmodifying any model parameters.", "published": "2019-07-10 22:13:48", "link": "http://arxiv.org/abs/1907.04944v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Memory Layers with Product Keys", "abstract": "This paper introduces a structured memory which can be easily integrated into\na neural network. The memory is very large by design and significantly\nincreases the capacity of the architecture, by up to a billion parameters with\na negligible computational overhead. Its design and access pattern is based on\nproduct keys, which enable fast and exact nearest neighbor search. The ability\nto increase the number of parameters while keeping the same computational\nbudget lets the overall system strike a better trade-off between prediction\naccuracy and computation efficiency both at training and test time. This memory\nlayer allows us to tackle very large scale language modeling tasks. In our\nexperiments we consider a dataset with up to 30 billion words, and we plug our\nmemory layer in a state-of-the-art transformer-based architecture. In\nparticular, we found that a memory augmented model with only 12 layers\noutperforms a baseline transformer model with 24 layers, while being twice\nfaster at inference time. We release our code for reproducibility purposes.", "published": "2019-07-10 14:52:12", "link": "http://arxiv.org/abs/1907.05242v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantic Parsing with Dual Learning", "abstract": "Semantic parsing converts natural language queries into structured logical\nforms. The paucity of annotated training samples is a fundamental challenge in\nthis field. In this work, we develop a semantic parsing framework with the dual\nlearning algorithm, which enables a semantic parser to make full use of data\n(labeled and even unlabeled) through a dual-learning game. This game between a\nprimal model (semantic parsing) and a dual model (logical form to query) forces\nthem to regularize each other, and can achieve feedback signals from some\nprior-knowledge. By utilizing the prior-knowledge of logical form structures,\nwe propose a novel reward signal at the surface and semantic levels which tends\nto generate complete and reasonable logical forms. Experimental results show\nthat our approach achieves new state-of-the-art performance on ATIS dataset and\ngets competitive performance on Overnight dataset.", "published": "2019-07-10 04:51:44", "link": "http://arxiv.org/abs/1907.05343v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tweets Can Tell: Activity Recognition using Hybrid Long Short-Term\n  Memory Model", "abstract": "This paper presents techniques to detect the \"offline\" activity a person is\nengaged in when she is tweeting (such as dining, shopping or entertainment), in\norder to create a dynamic profile of the user, for uses such as better\ntargeting of advertisements. To this end, we propose a hybrid LSTM model for\nrich contextual learning, along with studies on the effects of applying and\ncombining multiple LSTM based methods with different contextual features. The\nhybrid model is shown to outperform a set of baselines and state-of-the-art\nmethods. Finally, this paper presents an orthogonal validation with a real-case\napplication. Our model generates an offline activity analysis for the followers\nof several well-known accounts, which is quite representative of the expected\ncharacteristics of these accounts.", "published": "2019-07-10 02:29:39", "link": "http://arxiv.org/abs/1908.02551v1", "categories": ["cs.SI", "cs.AI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Interpretable Deep Learning Model for the Detection and Reconstruction\n  of Dysarthric Speech", "abstract": "This paper proposed a novel approach for the detection and reconstruction of\ndysarthric speech. The encoder-decoder model factorizes speech into a\nlow-dimensional latent space and encoding of the input text. We showed that the\nlatent space conveys interpretable characteristics of dysarthria, such as\nintelligibility and fluency of speech. MUSHRA perceptual test demonstrated that\nthe adaptation of the latent space let the model generate speech of improved\nfluency. The multi-task supervised approach for predicting both the probability\nof dysarthric speech and the mel-spectrogram helps improve the detection of\ndysarthria with higher accuracy. This is thanks to a low-dimensional latent\nspace of the auto-encoder as opposed to directly predicting dysarthria from a\nhighly dimensional mel-spectrogram.", "published": "2019-07-10 14:20:02", "link": "http://arxiv.org/abs/1907.04743v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Acoustic Model Optimization Based On Evolutionary Stochastic Gradient\n  Descent with Anchors for Automatic Speech Recognition", "abstract": "Evolutionary stochastic gradient descent (ESGD) was proposed as a\npopulation-based approach that combines the merits of gradient-aware and\ngradient-free optimization algorithms for superior overall optimization\nperformance. In this paper we investigate a variant of ESGD for optimization of\nacoustic models for automatic speech recognition (ASR). In this variant, we\nassume the existence of a well-trained acoustic model and use it as an anchor\nin the parent population whose good \"gene\" will propagate in the evolution to\nthe offsprings. We propose an ESGD algorithm leveraging the anchor models such\nthat it guarantees the best fitness of the population will never degrade from\nthe anchor model. Experiments on 50-hour Broadcast News (BN50) and 300-hour\nSwitchboard (SWB300) show that the ESGD with anchors can further improve the\nloss and ASR performance over the existing well-trained acoustic models.", "published": "2019-07-10 18:38:44", "link": "http://arxiv.org/abs/1907.04882v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for\n  Automatic Speech Recognition", "abstract": "In automatic speech recognition (ASR), wideband (WB) and narrowband (NB)\nspeech signals with different sampling rates typically use separate acoustic\nmodels. Therefore mixed-bandwidth (MB) acoustic modeling has important\npractical values for ASR system deployment. In this paper, we extensively\ninvestigate large-scale MB deep neural network acoustic modeling for ASR using\n1,150 hours of WB data and 2,300 hours of NB data. We study various MB\nstrategies including downsampling, upsampling and bandwidth extension for MB\nacoustic modeling and evaluate their performance on 8 diverse WB and NB test\nsets from various application domains. To deal with the large amounts of\ntraining data, distributed training is carried out on multiple GPUs using\nsynchronous data parallelism.", "published": "2019-07-10 18:52:11", "link": "http://arxiv.org/abs/1907.04887v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Vision-and-Dialog Navigation", "abstract": "Robots navigating in human environments should use language to ask for\nassistance and be able to understand human responses. To study this challenge,\nwe introduce Cooperative Vision-and-Dialog Navigation, a dataset of over 2k\nembodied, human-human dialogs situated in simulated, photorealistic home\nenvironments. The Navigator asks questions to their partner, the Oracle, who\nhas privileged access to the best next steps the Navigator should take\naccording to a shortest path planner. To train agents that search an\nenvironment for a goal location, we define the Navigation from Dialog History\ntask. An agent, given a target object and a dialog history between humans\ncooperating to find that object, must infer navigation actions towards the goal\nin unexplored environments. We establish an initial, multi-modal\nsequence-to-sequence model and demonstrate that looking farther back in the\ndialog history improves performance. Sourcecode and a live interface demo can\nbe found at https://cvdn.dev/", "published": "2019-07-10 23:41:46", "link": "http://arxiv.org/abs/1907.04957v3", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "cs.CL"}
{"title": "A Modular Task-oriented Dialogue System Using a Neural\n  Mixture-of-Experts", "abstract": "End-to-end Task-oriented Dialogue Systems (TDSs) have attracted a lot of\nattention for their superiority (e.g., in terms of global optimization) over\npipeline modularized TDSs. Previous studies on end-to-end TDSs use a\nsingle-module model to generate responses for complex dialogue contexts.\nHowever, no model consistently outperforms the others in all cases. We propose\na neural Modular Task-oriented Dialogue System(MTDS) framework, in which a few\nexpert bots are combined to generate the response for a given dialogue context.\nMTDS consists of a chair bot and several expert bots. Each expert bot is\nspecialized for a particular situation, e.g., one domain, one type of action of\na system, etc. The chair bot coordinates multiple expert bots and adaptively\nselects an expert bot to generate the appropriate response. We further propose\na Token-level Mixture-of-Expert (TokenMoE) model to implement MTDS, where the\nexpert bots predict multiple tokens at each timestamp and the chair bot\ndetermines the final generated token by fully taking into consideration the\noutputs of all expert bots. Both the chair bot and the expert bots are jointly\ntrained in an end-to-end fashion. To verify the effectiveness of TokenMoE, we\ncarry out extensive experiments on a benchmark dataset. Compared with the\nbaseline using a single-module model, our TokenMoE improves the performance by\n8.1% of inform rate and 0.8% of success rate.", "published": "2019-07-10 13:25:50", "link": "http://arxiv.org/abs/1907.05346v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-layer Attention Mechanism for Speech Keyword Recognition", "abstract": "As an important part of speech recognition technology, automatic speech\nkeyword recognition has been intensively studied in recent years. Such\ntechnology becomes especially pivotal under situations with limited\ninfrastructures and computational resources, such as voice command recognition\nin vehicles and robot interaction. At present, the mainstream methods in\nautomatic speech keyword recognition are based on long short-term memory (LSTM)\nnetworks with attention mechanism. However, due to inevitable information\nlosses for the LSTM layer caused during feature extraction, the calculated\nattention weights are biased. In this paper, a novel approach, namely\nMulti-layer Attention Mechanism, is proposed to handle the inaccurate attention\nweights problem. The key idea is that, in addition to the conventional\nattention mechanism, information of layers prior to feature extraction and LSTM\nare introduced into attention weights calculations. Therefore, the attention\nweights are more accurate because the overall model can have more precise and\nfocused areas. We conduct a comprehensive comparison and analysis on the\nkeyword spotting performances on convolution neural network, bi-directional\nLSTM cyclic neural network, and cyclic neural network with the proposed\nattention mechanism on Google Speech Command datasets V2 datasets. Experimental\nresults indicate favorable results for the proposed method and demonstrate the\nvalidity of the proposed method. The proposed multi-layer attention methods can\nbe useful for other researches related to object spotting.", "published": "2019-07-10 06:57:01", "link": "http://arxiv.org/abs/1907.04536v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Explicitly Conditioned Melody Generation: A Case Study with\n  Interdependent RNNs", "abstract": "Deep generative models for symbolic music are typically designed to model\ntemporal dependencies in music so as to predict the next musical event given\nprevious events. In many cases, such models are expected to learn abstract\nconcepts such as harmony, meter, and rhythm from raw musical data without any\nadditional information. In this study, we investigate the effects of explicitly\nconditioning deep generative models with musically relevant information.\nSpecifically, we study the effects of four different conditioning inputs on the\nperformance of a recurrent monophonic melody generation model. Several\ncombinations of these conditioning inputs are used to train different model\nvariants which are then evaluated using three objective evaluation paradigms\nacross two genres of music. The results indicate musically relevant\nconditioning significantly improves learning and performance, and reveal how\nthis information affects learning of musical features related to pitch and\nrhythm. An informal subjective evaluation suggests a corresponding improvement\nin the aesthetic quality of generations.", "published": "2019-07-10 00:05:53", "link": "http://arxiv.org/abs/1907.05208v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LakhNES: Improving multi-instrumental music generation with cross-domain\n  pre-training", "abstract": "We are interested in the task of generating multi-instrumental music scores.\nThe Transformer architecture has recently shown great promise for the task of\npiano score generation; here we adapt it to the multi-instrumental setting.\nTransformers are complex, high-dimensional language models which are capable of\ncapturing long-term structure in sequence data, but require large amounts of\ndata to fit. Their success on piano score generation is partially explained by\nthe large volumes of symbolic data readily available for that domain. We\nleverage the recently-introduced NES-MDB dataset of four-instrument scores from\nan early video game sound synthesis chip (the NES), which we find to be\nwell-suited to training with the Transformer architecture. To further improve\nthe performance of our model, we propose a pre-training technique to leverage\nthe information in a large collection of heterogeneous music, namely the Lakh\nMIDI dataset. Despite differences between the two corpora, we find that this\ntransfer learning procedure improves both quantitative and qualitative\nperformance for our primary task.", "published": "2019-07-10 18:00:04", "link": "http://arxiv.org/abs/1907.04868v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "A Highly Efficient Distributed Deep Learning System For Automatic Speech\n  Recognition", "abstract": "Modern Automatic Speech Recognition (ASR) systems rely on distributed deep\nlearning to for quick training completion. To enable efficient distributed\ntraining, it is imperative that the training algorithms can converge with a\nlarge mini-batch size. In this work, we discovered that Asynchronous\nDecentralized Parallel Stochastic Gradient Descent (ADPSGD) can work with much\nlarger batch size than commonly used Synchronous SGD (SSGD) algorithm. On\ncommonly used public SWB-300 and SWB-2000 ASR datasets, ADPSGD can converge\nwith a batch size 3X as large as the one used in SSGD, thus enable training at\na much larger scale. Further, we proposed a Hierarchical-ADPSGD (H-ADPSGD)\nsystem in which learners on the same computing node construct a super learner\nvia a fast allreduce implementation, and super learners deploy ADPSGD algorithm\namong themselves. On a 64 Nvidia V100 GPU cluster connected via a 100Gb/s\nEthernet network, our system is able to train SWB-2000 to reach a 7.6% WER on\nthe Hub5-2000 Switchboard (SWB) test-set and a 13.2% WER on the Call-home (CH)\ntest-set in 5.2 hours. To the best of our knowledge, this is the fastest ASR\ntraining system that attains this level of model accuracy for SWB-2000 task to\nbe ever reported in the literature.", "published": "2019-07-10 14:32:59", "link": "http://arxiv.org/abs/1907.05701v1", "categories": ["eess.AS", "cs.DC", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
