{"title": "Emotion Recognition From Speech With Recurrent Neural Networks", "abstract": "In this paper the task of emotion recognition from speech is considered.\nProposed approach uses deep recurrent neural network trained on a sequence of\nacoustic features calculated over small speech intervals. At the same time\nspecial probabilistic-nature CTC loss function allows to consider long\nutterances containing both emotional and neutral parts. The effectiveness of\nsuch an approach is shown in two ways. Firstly, the comparison with recent\nadvances in this field is carried out. Secondly, human performance on the same\ntask is measured. Both criteria show the high quality of the proposed method.", "published": "2017-01-27 14:50:36", "link": "http://arxiv.org/abs/1701.08071v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring the Reliability of Hate Speech Annotations: The Case of the\n  European Refugee Crisis", "abstract": "Some users of social media are spreading racist, sexist, and otherwise\nhateful content. For the purpose of training a hate speech detection system,\nthe reliability of the annotations is crucial, but there is no universally\nagreed-upon definition. We collected potentially hateful messages and asked two\ngroups of internet users to determine whether they were hate speech or not,\nwhether they should be banned or not and to rate their degree of offensiveness.\nOne of the groups was shown a definition prior to completing the survey. We\naimed to assess whether hate speech can be annotated reliably, and the extent\nto which existing definitions are in accordance with subjective ratings. Our\nresults indicate that showing users a definition caused them to partially align\ntheir own opinion with the definition but did not improve reliability, which\nwas very low overall. We conclude that the presence of hate speech should\nperhaps not be considered a binary yes-or-no decision, and raters need more\ndetailed instructions for the annotation.", "published": "2017-01-27 17:09:07", "link": "http://arxiv.org/abs/1701.08118v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Evaluation of Dialogue Models", "abstract": "The recent application of RNN encoder-decoder models has resulted in\nsubstantial progress in fully data-driven dialogue systems, but evaluation\nremains a challenge. An adversarial loss could be a way to directly evaluate\nthe extent to which generated dialogue responses sound like they came from a\nhuman. This could reduce the need for human evaluation, while more directly\nevaluating on a generative task. In this work, we investigate this idea by\ntraining an RNN to discriminate a dialogue model's samples from human-generated\nsamples. Although we find some evidence this setup could be viable, we also\nnote that many issues remain in its practical application. We discuss both\naspects and conclude that future work is warranted.", "published": "2017-01-27 21:28:57", "link": "http://arxiv.org/abs/1701.08198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bangla Word Clustering Based on Tri-gram, 4-gram and 5-gram Language\n  Model", "abstract": "In this paper, we describe a research method that generates Bangla word\nclusters on the basis of relating to meaning in language and contextual\nsimilarity. The importance of word clustering is in parts of speech (POS)\ntagging, word sense disambiguation, text classification, recommender system,\nspell checker, grammar checker, knowledge discover and for many others Natural\nLanguage Processing (NLP) applications. In the history of word clustering,\nEnglish and some other languages have already implemented some methods on word\nclustering efficiently. But due to lack of the resources, word clustering in\nBangla has not been still implemented efficiently. Presently, its\nimplementation is in the beginning stage. In some research of word clustering\nin English based on preceding and next five words of a key word they found an\nefficient result. Now, we are trying to implement the tri-gram, 4-gram and\n5-gram model of word clustering for Bangla to observe which one is the best\namong them. We have started our research with quite a large corpus of\napproximate 1 lakh Bangla words. We are using a machine learning technique in\nthis research. We will generate word clusters and analyze the clusters by\ntesting some different threshold values.", "published": "2017-01-27 18:43:31", "link": "http://arxiv.org/abs/1701.08702v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Statistical Analysis on Bangla Newspaper Data to Extract Trending Topic\n  and Visualize Its Change Over Time", "abstract": "Trending topic of newspapers is an indicator to understand the situation of a\ncountry and also a way to evaluate the particular newspaper. This paper\nrepresents a model describing few techniques to select trending topics from\nBangla Newspaper. Topics that are discussed more frequently than other in\nBangla newspaper will be marked and how a very famous topic loses its\nimportance with the change of time and another topic takes its place will be\ndemonstrated. Data from two popular Bangla Newspaper with date and time were\ncollected. Statistical analysis was performed after on these data after\npreprocessing. Popular and most used keywords were extracted from the stream of\nBangla keyword with this analysis. This model can also cluster category wise\nnews trend or a list of news trend in daily or weekly basis with enough data. A\npattern can be found on their news trend too. Comparison among past news trend\nof Bangla newspapers will give a visualization of the situation of Bangladesh.\nThis visualization will be helpful to predict future trending topics of Bangla\nNewspaper.", "published": "2017-01-27 06:30:21", "link": "http://arxiv.org/abs/1701.07955v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Comprehensive Survey on Bengali Phoneme Recognition", "abstract": "Hidden Markov model based various phoneme recognition methods for Bengali\nlanguage is reviewed. Automatic phoneme recognition for Bengali language using\nmultilayer neural network is reviewed. Usefulness of multilayer neural network\nover single layer neural network is discussed. Bangla phonetic feature table\nconstruction and enhancement for Bengali speech recognition is also discussed.\nComparison among these methods is discussed.", "published": "2017-01-27 12:38:47", "link": "http://arxiv.org/abs/1701.08156v2", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "A Comparative Study on Different Types of Approaches to Bengali document\n  Categorization", "abstract": "Document categorization is a technique where the category of a document is\ndetermined. In this paper three well-known supervised learning techniques which\nare Support Vector Machine(SVM), Na\\\"ive Bayes(NB) and Stochastic Gradient\nDescent(SGD) compared for Bengali document categorization. Besides classifier,\nclassification also depends on how feature is selected from dataset. For\nanalyzing those classifier performances on predicting a document against twelve\ncategories several feature selection techniques are also applied in this\narticle namely Chi square distribution, normalized TFIDF (term\nfrequency-inverse document frequency) with word analyzer. So, we attempt to\nexplore the efficiency of those three-classification algorithms by using two\ndifferent feature selection techniques in this article.", "published": "2017-01-27 13:08:08", "link": "http://arxiv.org/abs/1701.08694v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Document Decomposition of Bangla Printed Text", "abstract": "Today all kind of information is getting digitized and along with all this\ndigitization, the huge archive of various kinds of documents is being digitized\ntoo. We know that, Optical Character Recognition is the method through which,\nnewspapers and other paper documents convert into digital resources. But, it is\na fact that this method works on texts only. As a result, if we try to process\nany document which contains non-textual zones, then we will get garbage texts\nas output. That is why; in order to digitize documents properly they should be\nprepossessed carefully. And while preprocessing, segmenting document in\ndifferent regions according to the category properly is most important. But,\nthe Optical Character Recognition processes available for Bangla language have\nno such algorithm that can categorize a newspaper/book page fully. So we worked\nto decompose a document into its several parts like headlines, sub headlines,\ncolumns, images etc. And if the input is skewed and rotated, then the input was\nalso deskewed and de-rotated. To decompose any Bangla document we found out the\nedges of the input image. Then we find out the horizontal and vertical area of\nevery pixel where it lies in. Later on the input image was cut according to\nthese areas. Then we pick each and every sub image and found out their\nheight-width ratio, line height. Then according to these values the sub images\nwere categorized. To deskew the image we found out the skew angle and de skewed\nthe image according to this angle. To de-rotate the image we used the line\nheight, matra line, pixel ratio of matra line.", "published": "2017-01-27 12:54:52", "link": "http://arxiv.org/abs/1701.08706v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
