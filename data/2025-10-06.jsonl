{"title": "Paper2Video: Automatic Video Generation from Scientific Papers", "abstract": "Academic presentation videos have become an essential medium for research\ncommunication, yet producing them remains highly labor-intensive, often\nrequiring hours of slide design, recording, and editing for a short 2 to 10\nminutes video. Unlike natural video, presentation video generation involves\ndistinctive challenges: inputs from research papers, dense multi-modal\ninformation (text, figures, tables), and the need to coordinate multiple\naligned channels such as slides, subtitles, speech, and human talker. To\naddress these challenges, we introduce PaperTalker, the first benchmark of 101\nresearch papers paired with author-created presentation videos, slides, and\nspeaker metadata. We further design four tailored evaluation metrics--Meta\nSimilarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos\nconvey the paper's information to the audience. Building on this foundation, we\npropose PaperTalker, the first multi-agent framework for academic presentation\nvideo generation. It integrates slide generation with effective layout\nrefinement by a novel effective tree search visual choice, cursor grounding,\nsubtitling, speech synthesis, and talking-head rendering, while parallelizing\nslide-wise generation for efficiency. Experiments on Paper2Video demonstrate\nthat the presentation videos produced by our approach are more faithful and\ninformative than existing baselines, establishing a practical step toward\nautomated and ready-to-use academic video generation. Our dataset, agent, and\ncode are available at https://github.com/showlab/Paper2Video.", "published": "2025-10-06 17:58:02", "link": "http://arxiv.org/abs/2510.05096v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MA", "cs.MM"], "primary_category": "cs.CV"}
{"title": "From Noisy Traces to Stable Gradients: Bias-Variance Optimized Preference Optimization for Aligning Large Reasoning Models", "abstract": "Large reasoning models (LRMs) generate intermediate reasoning traces before\nproducing final answers, yielding strong gains on multi-step and mathematical\ntasks. Yet aligning LRMs with human preferences, a crucial prerequisite for\nmodel deployment, remains underexplored. The statistically correct objective\nfor preference alignment requires marginalizing over reasoning traces, but this\ncomputation is intractable in practice. A common workaround optimizes a single\nsampled trajectory, which introduces substantial gradient variance from\nstochastic trace sampling. To address this challenge, we frame preference\noptimization for LRMs through the lens of the bias--variance trade-off and\npropose Bias--Variance Optimized Preference Optimization (BVPO), a simple,\ndrop-in method that mixes two gradient estimators: a high-variance trace-based\nestimator and a low-variance empty-trace estimator obtained by disabling\nreasoning trace generation. Our theory shows that BVPO strictly reduces\ntrace-induced variance for any nontrivial mixture, provides a closed-form\nchoice of the mixing weight that minimizes mean-squared error relative to the\ntrue marginal gradient, and under standard smoothness and step-size conditions,\ntightens classical convergence bounds for stochastic gradient descent.\nEmpirically, BVPO improves alignment over the best baseline by up to 7.8 points\non AlpacaEval~2 and 6.8 points on Arena-Hard. Despite being trained only on\ngeneral conversational data, BVPO also boosts reasoning performance for base\nmodels by up to 4.0 points on the average of six math reasoning benchmarks.\nThese results identify variance from trace sampling as a key bottleneck and\ndemonstrate that directly optimizing the bias--variance trade-off yields more\nstable training and stronger overall performance.", "published": "2025-10-06 17:58:01", "link": "http://arxiv.org/abs/2510.05095v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning to Interpret Weight Differences in Language Models", "abstract": "Finetuning (pretrained) language models is a standard approach for updating\ntheir internal parametric knowledge and specializing them to new tasks and\ndomains. However, the corresponding model weight changes (\"weight diffs\") are\nnot generally interpretable. While inspecting the finetuning dataset can give a\nsense of how the model might have changed, these datasets are often not\npublicly available or are too large to work with directly. Towards the goal of\ncomprehensively understanding weight diffs in natural language, we introduce\nDiff Interpretation Tuning (DIT), a method that trains models to describe their\nown finetuning-induced modifications. Our approach uses synthetic, labeled\nweight diffs to train a DIT adapter, which can be applied to a compatible\nfinetuned model to make it describe how it has changed. We demonstrate in two\nproof-of-concept settings (reporting hidden behaviors and summarizing finetuned\nknowledge) that our method enables models to describe their finetuning-induced\nmodifications using accurate natural language descriptions.", "published": "2025-10-06 17:57:23", "link": "http://arxiv.org/abs/2510.05092v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models", "abstract": "Diffusion large language models (dLLMs) have recently emerged as a promising\nalternative to autoregressive (AR) models, offering advantages such as\naccelerated parallel decoding and bidirectional context modeling. However, the\nvanilla decoding strategy in discrete dLLMs suffers from a critical limitation:\nonce a token is accepted, it can no longer be revised in subsequent steps. As a\nresult, early mistakes persist across iterations, harming both intermediate\npredictions and final output quality. To address this issue, we propose\nTolerator (Token-Level Cross-Validation Refinement), a training-free decoding\nstrategy that leverages cross-validation among predicted tokens. Unlike\nexisting methods that follow a single progressive unmasking procedure,\nTolerator introduces a two-stage process: (i) sequence fill-up and (ii)\niterative refinement by remasking and decoding a subset of tokens while\ntreating the remaining as context. This design enables previously accepted\ntokens to be reconsidered and corrected when necessary, leading to more\nreliable diffusion decoding outputs. We evaluate Tolerator on five standard\nbenchmarks covering language understanding, code generation, and mathematics.\nExperiments show that our method achieves consistent improvements over the\nbaselines under the same computational budget. These findings suggest that\ndecoding algorithms are crucial to realizing the full potential of diffusion\nlarge language models. Code and data are publicly available.", "published": "2025-10-06 17:56:46", "link": "http://arxiv.org/abs/2510.05090v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TeachLM: Post-Training LLMs for Education Using Authentic Learning Data", "abstract": "The promise of generative AI to revolutionize education is constrained by the\npedagogical limits of large language models (LLMs). A major issue is the lack\nof access to high-quality training data that reflect the learning of actual\nstudents. Prompt engineering has emerged as a stopgap, but the ability of\nprompts to encode complex pedagogical strategies in rule-based natural language\nis inherently limited. To address this gap we introduce TeachLM - an LLM\noptimized for teaching through parameter-efficient fine-tuning of\nstate-of-the-art models. TeachLM is trained on a dataset comprised of 100,000\nhours of one-on-one, longitudinal student-tutor interactions maintained by\nPolygence, which underwent a rigorous anonymization process to protect privacy.\nWe use parameter-efficient fine-tuning to develop an authentic student model\nthat enables the generation of high-fidelity synthetic student-tutor dialogues.\nBuilding on this capability, we propose a novel multi-turn evaluation protocol\nthat leverages synthetic dialogue generation to provide fast, scalable, and\nreproducible assessments of the dialogical capabilities of LLMs. Our\nevaluations demonstrate that fine-tuning on authentic learning data\nsignificantly improves conversational and pedagogical performance - doubling\nstudent talk time, improving questioning style, increasing dialogue turns by\n50%, and greater personalization of instruction.", "published": "2025-10-06 17:55:04", "link": "http://arxiv.org/abs/2510.05087v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Slm-mux: Orchestrating small language models for reasoning", "abstract": "With the rapid development of language models, the number of small language\nmodels (SLMs) has grown significantly. Although they do not achieve\nstate-of-the-art accuracy, they are more efficient and often excel at specific\ntasks. This raises a natural question: can multiple SLMs be orchestrated into a\nsystem where each contributes effectively, achieving higher accuracy than any\nindividual model? Existing orchestration methods have primarily targeted\nfrontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To\naddress this gap, we propose a three-stage approach for orchestrating SLMs.\nFirst, we introduce SLM-MUX, a multi-model architecture that effectively\ncoordinates multiple SLMs. Building on this, we develop two optimization\nstrategies: (i) a model selection search that identifies the most complementary\nSLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Our\napproach delivers strong results: Compared to existing orchestration methods,\nour approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0%\non GSM8K. With just two SLMS, SLM-MUX outperforms Qwen 2.5 72B on GPQA and\nGSM8K, and matches its performance on MATH. We further provide theoretical\nanalyses to substantiate the advantages of our method. In summary, we\ndemonstrate that SLMs can be effectively orchestrated into more accurate and\nefficient systems through the proposed approach.", "published": "2025-10-06 17:49:58", "link": "http://arxiv.org/abs/2510.05077v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs", "abstract": "Recent work shows that, beyond discrete reasoning through explicit\nchain-of-thought steps, which are limited by the boundaries of natural\nlanguages, large language models (LLMs) can also reason continuously in latent\nspace, allowing richer information per step and thereby improving token\nefficiency. Despite this promise, latent reasoning still faces two challenges,\nespecially in training-free settings: 1) purely latent reasoning broadens the\nsearch distribution by maintaining multiple implicit paths, which diffuses\nprobability mass, introduces noise, and impedes convergence to a single\nhigh-confidence solution, thereby hurting accuracy; and 2) overthinking\npersists even without explicit text, wasting tokens and degrading efficiency.\nTo address these issues, we introduce SwiReasoning, a training-free framework\nfor LLM reasoning which features two key innovations: 1) SwiReasoning\ndynamically switches between explicit and latent reasoning, guided by\nblock-wise confidence estimated from entropy trends in next-token\ndistributions, to balance exploration and exploitation and promote timely\nconvergence. 2) By limiting the maximum number of thinking-block switches,\nSwiReasoning curbs overthinking and improves token efficiency across varying\nproblem difficulties. On widely used mathematics and STEM benchmarks,\nSwiReasoning consistently improves average accuracy by 1.5%-2.8% across\nreasoning LLMs of different model families and scales. Furthermore, under\nconstrained budgets, SwiReasoning improves average token efficiency by 56%-79%,\nwith larger gains as budgets tighten.", "published": "2025-10-06 17:46:34", "link": "http://arxiv.org/abs/2510.05069v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Proactive defense against LLM Jailbreak", "abstract": "The proliferation of powerful large language models (LLMs) has necessitated\nrobust safety alignment, yet these models remain vulnerable to evolving\nadversarial attacks, including multi-turn jailbreaks that iteratively search\nfor successful queries. Current defenses, primarily reactive and static, often\nfail to counter these search-based attacks. In this paper, we introduce ProAct,\na novel proactive defense framework designed to disrupt and mislead autonomous\njailbreaking processes. Our core idea is to intentionally provide adversaries\nwith \"spurious responses\" that appear to be results of successful jailbreak\nattacks but contain no actual harmful content. These misleading responses\nprovide false signals to the attacker's internal optimization loop, causing the\nadversarial search to terminate prematurely and effectively jailbreaking the\njailbreak. By conducting extensive experiments across state-of-the-art LLMs,\njailbreaking frameworks, and safety benchmarks, our method consistently and\nsignificantly reduces attack success rates by up to 92\\%. When combined with\nother defense frameworks, it further reduces the success rate of the latest\nattack strategies to 0\\%. ProAct represents an orthogonal defense strategy that\ncan serve as an additional guardrail to enhance LLM safety against the most\neffective jailbreaking attacks.", "published": "2025-10-06 17:32:40", "link": "http://arxiv.org/abs/2510.05052v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "COLE: a Comprehensive Benchmark for French Language Understanding Evaluation", "abstract": "To address the need for a more comprehensive evaluation of French Natural\nLanguage Understanding (NLU), we introduce COLE, a new benchmark composed of 23\ndiverse task covering a broad range of NLU capabilities, including sentiment\nanalysis, paraphrase detection, grammatical judgment, and reasoning, with a\nparticular focus on linguistic phenomena relevant to the French language. We\nbenchmark 94 large language models (LLM), providing an extensive analysis of\nthe current state of French NLU. Our results highlight a significant\nperformance gap between closed- and open-weights models and identify key\nchallenging frontiers for current LLMs, such as zero-shot extractive\nquestion-answering (QA), fine-grained word sense disambiguation, and\nunderstanding of regional language variations. We release COLE as a public\nresource to foster further progress in French language modelling.", "published": "2025-10-06 17:26:41", "link": "http://arxiv.org/abs/2510.05046v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization", "abstract": "Multimodal encoders have pushed the boundaries of visual document retrieval,\nmatching textual query tokens directly to image patches and achieving\nstate-of-the-art performance on public benchmarks. Recent models relying on\nthis paradigm have massively scaled the sizes of their query and document\nrepresentations, presenting obstacles to deployment and scalability in\nreal-world pipelines. Furthermore, purely vision-centric approaches may be\nconstrained by the inherent modality gap still exhibited by modern\nvision-language models. In this work, we connect these challenges to the\nparadigm of hybrid retrieval, investigating whether a lightweight dense text\nretriever can enhance a stronger vision-centric model. Existing hybrid methods,\nwhich rely on coarse-grained fusion of ranks or scores, fail to exploit the\nrich interactions within each model's representation space. To address this, we\nintroduce Guided Query Refinement (GQR), a novel test-time optimization method\nthat refines a primary retriever's query embedding using guidance from a\ncomplementary retriever's scores. Through extensive experiments on visual\ndocument retrieval benchmarks, we demonstrate that GQR allows vision-centric\nmodels to match the performance of models with significantly larger\nrepresentations, while being up to 14x faster and requiring 54x less memory.\nOur findings show that GQR effectively pushes the Pareto frontier for\nperformance and efficiency in multimodal retrieval. We release our code at\nhttps://github.com/IBM/test-time-hybrid-retrieval", "published": "2025-10-06 17:12:53", "link": "http://arxiv.org/abs/2510.05038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Set of Quebec-French Corpus of Regional Expressions and Terms", "abstract": "The tasks of idiom understanding and dialect understanding are both\nwell-established benchmarks in natural language processing. In this paper, we\npropose combining them, and using regional idioms as a test of dialect\nunderstanding. Towards this end, we propose two new benchmark datasets for the\nQuebec dialect of French: QFrCoRE, which contains 4,633 instances of idiomatic\nphrases, and QFrCoRT, which comprises 171 regional instances of idiomatic\nwords. We explain how to construct these corpora, so that our methodology can\nbe replicated for other dialects. Our experiments with 94 LLM demonstrate that\nour regional idiom benchmarks are a reliable tool for measuring a model's\nproficiency in a specific dialect.", "published": "2025-10-06 17:04:22", "link": "http://arxiv.org/abs/2510.05026v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Imperceptible Jailbreaking against Large Language Models", "abstract": "Jailbreaking attacks on the vision modality typically rely on imperceptible\nadversarial perturbations, whereas attacks on the textual modality are\ngenerally assumed to require visible modifications (e.g., non-semantic\nsuffixes). In this paper, we introduce imperceptible jailbreaks that exploit a\nclass of Unicode characters called variation selectors. By appending invisible\nvariation selectors to malicious questions, the jailbreak prompts appear\nvisually identical to original malicious questions on screen, while their\ntokenization is \"secretly\" altered. We propose a chain-of-search pipeline to\ngenerate such adversarial suffixes to induce harmful responses. Our experiments\nshow that our imperceptible jailbreaks achieve high attack success rates\nagainst four aligned LLMs and generalize to prompt injection attacks, all\nwithout producing any visible modifications in the written prompt. Our code is\navailable at https://github.com/sail-sg/imperceptible-jailbreaks.", "published": "2025-10-06 17:03:50", "link": "http://arxiv.org/abs/2510.05025v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Large Language Models Achieve Gold Medal Performance at International Astronomy & Astrophysics Olympiad", "abstract": "While task-specific demonstrations show early success in applying large\nlanguage models (LLMs) to automate some astronomical research tasks, they only\nprovide incomplete views of all necessary capabilities in solving astronomy\nproblems, calling for more thorough understanding of LLMs' strengths and\nlimitations. So far, existing benchmarks and evaluations focus on simple\nquestion-answering that primarily tests astronomical knowledge and fails to\nevaluate the complex reasoning required for real-world research in the\ndiscipline. Here, we address this gap by systematically benchmarking five\nstate-of-the-art LLMs on the International Olympiad on Astronomy and\nAstrophysics (IOAA) exams, which are designed to examine deep conceptual\nunderstanding, multi-step derivations, and multimodal analysis. With average\nscores of 85.6% and 84.2%, Gemini 2.5 Pro and GPT-5 (the two top-performing\nmodels) not only achieve gold medal level performance but also rank in the top\ntwo among ~200-300 participants in all four IOAA theory exams evaluated\n(2022-2025). In comparison, results on the data analysis exams show more\ndivergence. GPT-5 still excels in the exams with an 88.5% average score,\nranking top 10 among the participants in the four most recent IOAAs, while\nother models' performances drop to 48-76%. Furthermore, our in-depth error\nanalysis underscores conceptual reasoning, geometric reasoning, and spatial\nvisualization (52-79% accuracy) as consistent weaknesses among all LLMs. Hence,\nalthough LLMs approach peak human performance in theory exams, critical gaps\nmust be addressed before they can serve as autonomous research agents in\nastronomy.", "published": "2025-10-06 16:58:47", "link": "http://arxiv.org/abs/2510.05016v1", "categories": ["astro-ph.IM", "cs.AI", "cs.CL"], "primary_category": "astro-ph.IM"}
{"title": "Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning", "abstract": "Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstrated\nremarkable reasoning abilities but require significant computational resources\nfor fine-tuning. This paper presents a resource-efficient fine-tuning approach\nfor LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operating\nunder constrained GPU and memory settings. Using parameter-efficient tuning\ntechniques such as LoRA and QLoRA, we adapt the base model on publicly\navailable medical reasoning datasets. The model achieves improved reasoning\ncoherence and factual accuracy while reducing memory usage by up to 60%\ncompared to standard full fine-tuning. Experimental evaluation demonstrates\nthat lightweight adaptations can retain strong reasoning capability in medical\nquestion-answering tasks. This work highlights practical strategies for\ndeploying LLMs in low-resource research environments and provides insights into\nbalancing efficiency and domain specialization for medical AI systems.", "published": "2025-10-06 16:42:11", "link": "http://arxiv.org/abs/2510.05003v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training", "abstract": "Reinforcement learning applied to large language models (LLMs) for reasoning\ntasks is often bottlenecked by unstable gradient estimates due to fixed and\nuniform sampling of responses across prompts. Prior work such as GVM-RAFT\naddresses this by dynamically allocating inference budget per prompt to\nminimize stochastic gradient variance under a budget constraint. Inspired by\nthis insight, we propose Reinforce-Ada, an adaptive sampling framework for\nonline RL post-training of LLMs that continuously reallocates sampling effort\nto the prompts with the greatest uncertainty or learning potential. Unlike\nconventional two-stage allocation methods, Reinforce-Ada interleaves estimation\nand sampling in an online successive elimination process, and automatically\nstops sampling for a prompt once sufficient signal is collected. To stabilize\nupdates, we form fixed-size groups with enforced reward diversity and compute\nadvantage baselines using global statistics aggregated over the adaptive\nsampling phase. Empirical results across multiple model architectures and\nreasoning benchmarks show that Reinforce-Ada accelerates convergence and\nimproves final performance compared to GRPO, especially when using the balanced\nsampling variant. Our work highlights the central role of variance-aware,\nadaptive data curation in enabling efficient and reliable reinforcement\nlearning for reasoning-capable LLMs. Code is available at\nhttps://github.com/RLHFlow/Reinforce-Ada.", "published": "2025-10-06 16:34:09", "link": "http://arxiv.org/abs/2510.04996v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives", "abstract": "Identifying cultural capital (CC) themes in student reflections can offer\nvaluable insights that help foster equitable learning environments in\nclassrooms. However, themes such as aspirational goals or family support are\noften woven into narratives, rather than appearing as direct keywords. This\nmakes them difficult to detect for standard NLP models that process sentences\nin isolation. The core challenge stems from a lack of awareness, as standard\nmodels are pre-trained on general corpora, leaving them blind to the\ndomain-specific language and narrative context inherent to the data. To address\nthis, we introduce AWARE, a framework that systematically attempts to improve a\ntransformer model's awareness for this nuanced task. AWARE has three core\ncomponents: 1) Domain Awareness, adapting the model's vocabulary to the\nlinguistic style of student reflections; 2) Context Awareness, generating\nsentence embeddings that are aware of the full essay context; and 3) Class\nOverlap Awareness, employing a multi-label strategy to recognize the\ncoexistence of themes in a single sentence. Our results show that by making the\nmodel explicitly aware of the properties of the input, AWARE outperforms a\nstrong baseline by 2.1 percentage points in Macro-F1 and shows considerable\nimprovements across all themes. This work provides a robust and generalizable\nmethodology for any text classification task in which meaning depends on the\ncontext of the narrative.", "published": "2025-10-06 16:19:57", "link": "http://arxiv.org/abs/2510.04983v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game", "abstract": "Effective multi-agent collaboration requires agents to infer the rationale\nbehind others' actions, a capability rooted in Theory-of-Mind (ToM). While\nrecent Large Language Models (LLMs) excel at logical inference, their ability\nto infer rationale in dynamic, collaborative settings remains under-explored.\nThis study introduces LLM-Hanabi, a novel benchmark that uses the cooperative\ngame Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework\nfeatures an automated evaluation system that measures both game performance and\nToM proficiency. Across a range of models, we find a significant positive\ncorrelation between ToM and in-game success. Notably, first-order ToM\n(interpreting others' intent) correlates more strongly with performance than\nsecond-order ToM (predicting others' interpretations). These findings highlight\nthat for effective AI collaboration, the ability to accurately interpret a\npartner's rationale is more critical than higher-order reasoning. We conclude\nthat prioritizing first-order ToM is a promising direction for enhancing the\ncollaborative capabilities of future models.", "published": "2025-10-06 16:17:24", "link": "http://arxiv.org/abs/2510.04980v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)", "abstract": "The wording of natural language prompts has been shown to influence the\nperformance of large language models (LLMs), yet the role of politeness and\ntone remains underexplored. In this study, we investigate how varying levels of\nprompt politeness affect model accuracy on multiple-choice questions. We\ncreated a dataset of 50 base questions spanning mathematics, science, and\nhistory, each rewritten into five tone variants: Very Polite, Polite, Neutral,\nRude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, we\nevaluated responses across these conditions and applied paired sample t-tests\nto assess statistical significance. Contrary to expectations, impolite prompts\nconsistently outperformed polite ones, with accuracy ranging from 80.8% for\nVery Polite prompts to 84.8% for Very Rude prompts. These findings differ from\nearlier studies that associated rudeness with poorer outcomes, suggesting that\nnewer LLMs may respond differently to tonal variation. Our results highlight\nthe importance of studying pragmatic aspects of prompting and raise broader\nquestions about the social dimensions of human-AI interaction.", "published": "2025-10-06 15:50:39", "link": "http://arxiv.org/abs/2510.04950v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "stat.ME"], "primary_category": "cs.CL"}
{"title": "A First Context-Free Grammar Applied to Nawatl Corpora Augmentation", "abstract": "In this article we introduce a context-free grammar (CFG) for the Nawatl\nlanguage. Nawatl (or Nahuatl) is an Amerindian language of the $\\pi$-language\ntype, i.e. a language with few digital resources, in which the corpora\navailable for machine learning are virtually non-existent. The objective here\nis to generate a significant number of grammatically correct artificial\nsentences, in order to increase the corpora available for language model\ntraining. We want to show that a grammar enables us significantly to expand a\ncorpus in Nawatl which we call $\\pi$-\\textsc{yalli}. The corpus, thus enriched,\nenables us to train algorithms such as FastText and to evaluate them on\nsentence-level semantic tasks. Preliminary results show that by using the\ngrammar, comparative improvements are achieved over some LLMs. However, it is\nobserved that to achieve more significant improvement, grammars that model the\nNawatl language even more effectively are required.", "published": "2025-10-06 15:46:54", "link": "http://arxiv.org/abs/2510.04945v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Structured State-Space Duality", "abstract": "Structured State-Space Duality (SSD) [Dao & Gu, ICML 2024] is an equivalence\nbetween a simple Structured State-Space Model (SSM) and a masked attention\nmechanism. In particular, a state-space model with a scalar-times-identity\nstate matrix is equivalent to a masked self-attention with a $1$-semiseparable\ncausal mask. Consequently, the same sequence transformation (model) has two\nalgorithmic realizations: as a linear-time $O(T)$ recurrence or as a\nquadratic-time $O(T^2)$ attention. In this note, we formalize and generalize\nthis duality: (i) we extend SSD from the scalar-identity case to general\ndiagonal SSMs (diagonal state matrices); (ii) we show that these diagonal SSMs\nmatch the scalar case's training complexity lower bounds while supporting\nricher dynamics; (iii) we establish a necessary and sufficient condition under\nwhich an SSM is equivalent to $1$-semiseparable masked attention; and (iv) we\nshow that such duality fails to extend to standard softmax attention due to\nrank explosion. Together, these results tighten bridge between recurrent SSMs\nand Transformers, and widen the design space for expressive yet efficient\nsequence models.", "published": "2025-10-06 15:46:50", "link": "http://arxiv.org/abs/2510.04944v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "ONNX-Net: Towards Universal Representations and Instant Performance Prediction for Neural Architectures", "abstract": "Neural architecture search (NAS) automates the design process of\nhigh-performing architectures, but remains bottlenecked by expensive\nperformance evaluation. Most existing studies that achieve faster evaluation\nare mostly tied to cell-based search spaces and graph encodings tailored to\nthose individual search spaces, limiting their flexibility and scalability when\napplied to more expressive search spaces. In this work, we aim to close the gap\nof individual search space restrictions and search space dependent network\nrepresentations. We present ONNX-Bench, a benchmark consisting of a collection\nof neural networks in a unified format based on ONNX files. ONNX-Bench includes\nall open-source NAS-bench-based neural networks, resulting in a total size of\nmore than 600k {architecture, accuracy} pairs. This benchmark allows creating a\nshared neural network representation, ONNX-Net, able to represent any neural\narchitecture using natural language descriptions acting as an input to a\nperformance predictor. This text-based encoding can accommodate arbitrary layer\ntypes, operation parameters, and heterogeneous topologies, enabling a single\nsurrogate to generalise across all neural architectures rather than being\nconfined to cell-based search spaces. Experiments show strong zero-shot\nperformance across disparate search spaces using only a small amount of\npretraining samples, enabling the unprecedented ability to evaluate any neural\nnetwork architecture instantly.", "published": "2025-10-06 15:43:36", "link": "http://arxiv.org/abs/2510.04938v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning", "abstract": "Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in\nsimple tasks, where the models excessively utilize System 2-type, deliberate\nreasoning, leading to inefficient token generation. Furthermore, these models\nface challenges in adapting their reasoning capabilities to rapidly changing\nenvironments due to the static nature of their pretraining data. To address\nthese issues, advancing Large Language Models (LLMs) for complex reasoning\ntasks requires innovative approaches that bridge intuitive and deliberate\ncognitive processes, akin to human cognition's dual-system dynamic. This paper\nintroduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless\nintegration of System 1's fast, intuitive thinking with System 2's deliberate\nreasoning within LLMs. MARS strategically integrates multiple external tools,\nsuch as Google Search, Google Scholar, and Python Interpreter, to access\nup-to-date information and execute complex computations, while creating a\nspecialized division of labor where System 1 efficiently processes and\nsummarizes high-volume external information, providing distilled insights that\nexpand System 2's reasoning context without overwhelming its capacity.\nFurthermore, we propose a multi-agent reinforcement learning framework\nextending Group Relative Policy Optimization to simultaneously optimize both\nsystems with multi-turn tool interactions, bin-packing optimization, and sample\nbalancing strategies that enhance collaborative efficiency. Extensive\nexperiments demonstrate MARS achieves substantial improvements of 3.86% on the\nchallenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%\nacross 7 knowledge-intensive tasks, validating the effectiveness of our\ndual-system paradigm for complex reasoning in dynamic information environments.", "published": "2025-10-06 15:42:55", "link": "http://arxiv.org/abs/2510.04935v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models", "abstract": "Large Language Models (LLMs) often produce fluent yet factually incorrect\nstatements-a phenomenon known as hallucination-posing serious risks in\nhigh-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric\nframework for hallucination detection that analyzes the evolution of\nhidden-state semantics across transformer layers. Unlike prior methods that\nrely on multiple sampling passes or external verification sources, LSD operates\nintrinsically within the model's representational space. Using margin-based\ncontrastive learning, LSD aligns hidden activations with ground-truth\nembeddings derived from a factual encoder, revealing a distinct separation in\nsemantic trajectories: factual responses preserve stable alignment, while\nhallucinations exhibit pronounced semantic drift across depth. Evaluated on the\nTruthfulQA and synthetic factual-hallucination datasets, LSD achieves an\nF1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming\nSelfCheckGPT and Semantic Entropy baselines while requiring only a single\nforward pass. This efficiency yields a 5-20x speedup over sampling-based\nmethods without sacrificing precision or interpretability. LSD offers a\nscalable, model-agnostic mechanism for real-time hallucination monitoring and\nprovides new insights into the geometry of factual consistency within large\nlanguage models.", "published": "2025-10-06 15:41:22", "link": "http://arxiv.org/abs/2510.04933v1", "categories": ["cs.CL", "cs.AI", "cs.IT", "cs.LG", "cs.NE", "math.IT", "68T50, 68T07, 62H30", "I.2.7; I.2.6; F.2.2; H.3.3"], "primary_category": "cs.CL"}
{"title": "Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment", "abstract": "Supervised Fine-Tuning (SFT) is an effective method for adapting Large\nLanguage Models (LLMs) on downstream tasks. However, variability in training\ndata can hinder a model's ability to generalize across domains. This paper\nstudies the problem of dataset alignment for Natural Language to SQL (NL2SQL or\ntext to SQL), examining how well SFT training data matches the structural\ncharacteristics of target queries and how this alignment impacts model\nperformance. We hypothesize that alignment can be accurately estimated by\ncomparing the distributions of structural SQL features across the training set,\ntarget data, and the model's predictions prior to SFT. Through comprehensive\nexperiments on three large cross-domain NL2SQL benchmarks and multiple model\nfamilies, we show that structural alignment is a strong predictor of\nfine-tuning success. When alignment is high, SFT yields substantial gains in\naccuracy and SQL generation quality; when alignment is low, improvements are\nmarginal or absent. These findings highlight the importance of alignment-aware\ndata selection for effective fine-tuning and generalization in NL2SQL tasks.", "published": "2025-10-06 15:33:35", "link": "http://arxiv.org/abs/2510.04919v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches", "abstract": "Recent advancements in large language models (LLMs) have substantially\nimproved automated code generation. While function-level and file-level\ngeneration have achieved promising results, real-world software development\ntypically requires reasoning across entire repositories. This gives rise to the\nchallenging task of Repository-Level Code Generation (RLCG), where models must\ncapture long-range dependencies, ensure global semantic consistency, and\ngenerate coherent code spanning multiple files or modules. To address these\nchallenges, Retrieval-Augmented Generation (RAG) has emerged as a powerful\nparadigm that integrates external retrieval mechanisms with LLMs, enhancing\ncontext-awareness and scalability. In this survey, we provide a comprehensive\nreview of research on Retrieval-Augmented Code Generation (RACG), with an\nemphasis on repository-level approaches. We categorize existing work along\nseveral dimensions, including generation strategies, retrieval modalities,\nmodel architectures, training paradigms, and evaluation protocols. Furthermore,\nwe summarize widely used datasets and benchmarks, analyze current limitations,\nand outline key challenges and opportunities for future research. Our goal is\nto establish a unified analytical framework for understanding this rapidly\nevolving field and to inspire continued progress in AI-powered software\nengineering.", "published": "2025-10-06 15:20:03", "link": "http://arxiv.org/abs/2510.04905v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests", "abstract": "Large language models (LLMs) are increasingly deployed in contexts where\ntheir failures can have direct sociopolitical consequences. Yet, existing\nsafety benchmarks rarely test vulnerabilities in domains such as political\nmanipulation, propaganda and disinformation generation, or surveillance and\ninformation control. We introduce SocialHarmBench, a dataset of 585 prompts\nspanning 7 sociopolitical categories and 34 countries, designed to surface\nwhere LLMs most acutely fail in politically charged contexts. Our evaluations\nreveal several shortcomings: open-weight models exhibit high vulnerability to\nharmful compliance, with Mistral-7B reaching attack success rates as high as\n97% to 98% in domains such as historical revisionism, propaganda, and political\nmanipulation. Moreover, temporal and geographic analyses show that LLMs are\nmost fragile when confronted with 21st-century or pre-20th-century contexts,\nand when responding to prompts tied to regions such as Latin America, the USA,\nand the UK. These findings demonstrate that current safeguards fail to\ngeneralize to high-stakes sociopolitical settings, exposing systematic biases\nand raising concerns about the reliability of LLMs in preserving human rights\nand democratic values. We share the SocialHarmBench benchmark at\nhttps://huggingface.co/datasets/psyonp/SocialHarmBench.", "published": "2025-10-06 15:11:46", "link": "http://arxiv.org/abs/2510.04891v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting Distillation Data from Reasoning Models", "abstract": "Reasoning distillation has emerged as an efficient and powerful paradigm for\nenhancing the reasoning capabilities of large language models. However,\nreasoning distillation may inadvertently cause benchmark contamination, where\nevaluation data included in distillation datasets can inflate performance\nmetrics of distilled models. In this work, we formally define the task of\ndistillation data detection, which is uniquely challenging due to the partial\navailability of distillation data. Then, we propose a novel and effective\nmethod Token Probability Deviation (TBD), which leverages the probability\npatterns of the generated output tokens. Our method is motivated by the\nanalysis that distilled models tend to generate near-deterministic tokens for\nseen questions, while producing more low-probability tokens for unseen\nquestions. Our key idea behind TBD is to quantify how far the generated tokens'\nprobabilities deviate from a high reference probability. In effect, our method\nachieves competitive detection performance by producing lower scores for seen\nquestions than for unseen questions. Extensive experiments demonstrate the\neffectiveness of our method, achieving an AUC of 0.918 and a TPR@1% FPR of\n0.470 on the S1 dataset.", "published": "2025-10-06 14:37:02", "link": "http://arxiv.org/abs/2510.04850v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA", "abstract": "Hallucination detection remains a fundamental challenge for the safe and\nreliable deployment of large language models (LLMs), especially in applications\nrequiring factual accuracy. Existing hallucination benchmarks often operate at\nthe sequence level and are limited to English, lacking the fine-grained,\nmultilingual supervision needed for a comprehensive evaluation. In this work,\nwe introduce PsiloQA, a large-scale, multilingual dataset annotated with\nspan-level hallucinations across 14 languages. PsiloQA is constructed through\nan automated three-stage pipeline: generating question-answer pairs from\nWikipedia using GPT-4o, eliciting potentially hallucinated answers from diverse\nLLMs in a no-context setting, and automatically annotating hallucinated spans\nusing GPT-4o by comparing against golden answers and retrieved context. We\nevaluate a wide range of hallucination detection methods -- including\nuncertainty quantification, LLM-based tagging, and fine-tuned encoder models --\nand show that encoder-based models achieve the strongest performance across\nlanguages. Furthermore, PsiloQA demonstrates effective cross-lingual\ngeneralization and supports robust knowledge transfer to other benchmarks, all\nwhile being significantly more cost-efficient than human-annotated datasets.\nOur dataset and results advance the development of scalable, fine-grained\nhallucination detection in multilingual settings.", "published": "2025-10-06 14:36:30", "link": "http://arxiv.org/abs/2510.04849v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instability in Downstream Task Performance During LLM Pretraining", "abstract": "When training large language models (LLMs), it is common practice to track\ndownstream task performance throughout the training process and select the\ncheckpoint with the highest validation score. However, downstream metrics often\nexhibit substantial fluctuations, making it difficult to identify the\ncheckpoint that truly represents the best-performing model. In this study, we\nempirically analyze the stability of downstream task performance in an LLM\ntrained on diverse web-scale corpora. We find that task scores frequently\nfluctuate throughout training, both at the aggregate and example levels. To\naddress this instability, we investigate two post-hoc checkpoint integration\nmethods: checkpoint averaging and ensemble, motivated by the hypothesis that\naggregating neighboring checkpoints can reduce performance volatility. We\ndemonstrate both empirically and theoretically that these methods improve\ndownstream performance stability without requiring any changes to the training\nprocedure.", "published": "2025-10-06 14:33:38", "link": "http://arxiv.org/abs/2510.04848v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How I Built ASR for Endangered Languages with a Spoken Dictionary", "abstract": "Nearly half of the world's languages are endangered. Speech technologies such\nas Automatic Speech Recognition (ASR) are central to revival efforts, yet most\nlanguages remain unsupported because standard pipelines expect utterance-level\nsupervised data. Speech data often exist for endangered languages but rarely\nmatch these formats. Manx Gaelic ($\\sim$2,200 speakers), for example, has had\ntranscribed speech since 1948, yet remains unsupported by modern systems. In\nthis paper, we explore how little data, and in what form, is needed to build\nASR for critically endangered languages. We show that a short-form\npronunciation resource is a viable alternative, and that 40 minutes of such\ndata produces usable ASR for Manx ($<$50\\% WER). We replicate our approach,\napplying it to Cornish ($\\sim$600 speakers), another critically endangered\nlanguage. Results show that the barrier to entry, in quantity and form, is far\nlower than previously thought, giving hope to endangered language communities\nthat cannot afford to meet the requirements arbitrarily imposed upon them.", "published": "2025-10-06 14:16:47", "link": "http://arxiv.org/abs/2510.04832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual Representations inside the Language Model", "abstract": "Despite interpretability work analyzing VIT encoders and transformer\nactivations, we don't yet understand why Multimodal Language Models (MLMs)\nstruggle on perception-heavy tasks. We offer an under-studied perspective by\nexamining how popular MLMs (LLaVA-OneVision, Qwen2.5-VL, and\nLlama-3-LLaVA-NeXT) process their visual key-value tokens. We first study the\nflow of visual information through the language model, finding that image value\ntokens encode sufficient information to perform several perception-heavy tasks\nzero-shot: segmentation, semantic correspondence, temporal correspondence, and\nreferring expression detection. We find that while the language model does\naugment the visual information received from the projection of input visual\nencodings-which we reveal correlates with overall MLM perception capability-it\ncontains less visual information on several tasks than the equivalent visual\nencoder (SigLIP) that has not undergone MLM finetuning. Further, we find that\nthe visual information corresponding to input-agnostic image key tokens in\nlater layers of language models contains artifacts which reduce perception\ncapability of the overall MLM. Next, we discuss controlling visual information\nin the language model, showing that adding a text prefix to the image input\nimproves perception capabilities of visual representations. Finally, we reveal\nthat if language models were able to better control their visual information,\ntheir perception would significantly improve; e.g., in 33.3% of Art Style\nquestions in the BLINK benchmark, perception information present in the\nlanguage model is not surfaced to the output! Our findings reveal insights into\nthe role of key-value tokens in multimodal systems, paving the way for deeper\nmechanistic interpretability of MLMs and suggesting new directions for training\ntheir visual encoder and language model components.", "published": "2025-10-06 14:01:39", "link": "http://arxiv.org/abs/2510.04819v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Hybrid Architectures for Language Models: Systematic Analysis and Design Insights", "abstract": "Recent progress in large language models demonstrates that hybrid\narchitectures--combining self-attention mechanisms with structured state space\nmodels like Mamba--can achieve a compelling balance between modeling quality\nand computational efficiency, particularly for long-context tasks. While these\nhybrid models show promising performance, systematic comparisons of\nhybridization strategies and analyses on the key factors behind their\neffectiveness have not been clearly shared to the community. In this work, we\npresent a holistic evaluation of hybrid architectures based on inter-layer\n(sequential) or intra-layer (parallel) fusion. We evaluate these designs from a\nvariety of perspectives: language modeling performance, long-context\ncapabilities, scaling analysis, and training and inference efficiency. By\ninvestigating the core characteristics of their computational primitive, we\nidentify the most critical elements for each hybridization strategy and further\npropose optimal design recipes for both hybrid models. Our comprehensive\nanalysis provides practical guidance and valuable insights for developing\nhybrid language models, facilitating the optimization of architectural\nconfigurations.", "published": "2025-10-06 13:30:07", "link": "http://arxiv.org/abs/2510.04800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models", "abstract": "Implicit meanings are integral to human communication, making it essential\nfor language models to be capable of identifying and interpreting them. Grice\n(1975) proposed a set of conversational maxims that guide cooperative dialogue,\nnoting that speakers may deliberately violate these principles to express\nmeanings beyond literal words, and that listeners, in turn, recognize such\nviolations to draw pragmatic inferences.\n  Building on Surian et al. (1996)'s study of children's sensitivity to\nviolations of Gricean maxims, we introduce a novel benchmark to test whether\nlanguage models pretrained on less than 10M and less than 100M tokens can\ndistinguish maxim-adhering from maxim-violating utterances. We compare these\nBabyLMs across five maxims and situate their performance relative to children\nand a Large Language Model (LLM) pretrained on 3T tokens.\n  We find that overall, models trained on less than 100M tokens outperform\nthose trained on less than 10M, yet fall short of child-level and LLM\ncompetence. Our results suggest that modest data increases improve some aspects\nof pragmatic behavior, leading to finer-grained differentiation between\npragmatic dimensions.", "published": "2025-10-06 12:38:41", "link": "http://arxiv.org/abs/2510.04764v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever", "abstract": "Retrieval-Augmented Generation (RAG) is a powerful technique for enriching\nLarge Language Models (LLMs) with external knowledge, allowing for factually\ngrounded responses, a critical requirement in high-stakes domains such as\nhealthcare. However, the efficacy of RAG systems is fundamentally restricted by\nthe performance of their retrieval module, since irrelevant or semantically\nmisaligned documents directly compromise the accuracy of the final generated\nresponse. General-purpose dense retrievers can struggle with the nuanced\nlanguage of specialised domains, while the high accuracy of in-domain models is\noften achieved at prohibitive computational costs. In this work, we aim to\naddress this trade-off by developing and evaluating a two-stage retrieval\narchitecture that combines a lightweight ModernBERT bidirectional encoder for\nefficient initial candidate retrieval with a ColBERTv2 late-interaction model\nfor fine-grained re-ranking. We conduct comprehensive evaluations of our\nretriever module performance and RAG system performance in the biomedical\ncontext, fine-tuning the IR module using 10k question-passage pairs from\nPubMedQA. Our analysis of the retriever module confirmed the positive impact of\nthe ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points\ncompared to its retrieve-only counterpart. When integrated into the biomedical\nRAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on\nthe five tasks of the MIRAGE question-answering benchmark, outperforming strong\nbaselines such as MedCPT (0.4436). Our ablation studies reveal that this\nperformance is critically dependent on a joint fine-tuning process that aligns\nthe retriever and re-ranker; otherwise, the re-ranker might degrade the\nperformance.", "published": "2025-10-06 12:34:55", "link": "http://arxiv.org/abs/2510.04757v1", "categories": ["cs.CL", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "A Low-Resource Speech-Driven NLP Pipeline for Sinhala Dyslexia Assistance", "abstract": "Dyslexia in adults remains an under-researched and under-served area,\nparticularly in non-English-speaking contexts, despite its significant impact\non personal and professional lives. This work addresses that gap by focusing on\nSinhala, a low-resource language with limited tools for linguistic\naccessibility. We present an assistive system explicitly designed for\nSinhala-speaking adults with dyslexia. The system integrates Whisper for\nspeech-to-text conversion, SinBERT, an open-sourced fine-tuned BERT model\ntrained for Sinhala to identify common dyslexic errors, and a combined mT5 and\nMistral-based model to generate corrected text. Finally, the output is\nconverted back to speech using gTTS, creating a complete multimodal feedback\nloop. Despite the challenges posed by limited Sinhala-language datasets, the\nsystem achieves 0.66 transcription accuracy and 0.7 correction accuracy with\n0.65 overall system accuracy. These results demonstrate both the feasibility\nand effectiveness of the approach. Ultimately, this work highlights the\nimportance of inclusive Natural Language Processing (NLP) technologies in\nunderrepresented languages and showcases a practical", "published": "2025-10-06 12:28:57", "link": "http://arxiv.org/abs/2510.04750v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Speak, Edit, Repeat: High-Fidelity Voice Editing and Zero-Shot TTS with Cross-Attentive Mamba", "abstract": "We introduce MAVE (Mamba with Cross-Attention for Voice Editing and\nSynthesis), a novel autoregressive architecture for text-conditioned voice\nediting and high-fidelity text-to-speech (TTS) synthesis, built on a\ncross-attentive Mamba backbone. MAVE achieves state-of-the-art performance in\nspeech editing and very competitive results in zero-shot TTS, while not being\nexplicitly trained on the latter task, outperforming leading autoregressive and\ndiffusion models on diverse, real-world audio. By integrating Mamba for\nefficient audio sequence modeling with cross-attention for precise\ntext-acoustic alignment, MAVE enables context-aware voice editing with\nexceptional naturalness and speaker consistency. In pairwise human evaluations\non a random 40-sample subset of the RealEdit benchmark (400 judgments), 57.2%\nof listeners rated MAVE - edited speech as perceptually equal to the original,\nwhile 24.8% prefered the original and 18.0% MAVE - demonstrating that in the\nmajority of cases edits are indistinguishable from the source. MAVE compares\nfavorably with VoiceCraft and FluentSpeech both on pairwise comparisons and\nstandalone mean opinion score (MOS) evaluations. For zero-shot TTS, MAVE\nexceeds VoiceCraft in both speaker similarity and naturalness, without\nrequiring multiple inference runs or post-processing. Remarkably, these quality\ngains come with a significantly lower memory cost and approximately the same\nlatency: MAVE requires ~6x less memory than VoiceCraft during inference on\nutterances from the RealEdit database (mean duration: 6.21s, A100, FP16, batch\nsize 1). Our results demonstrate that MAVE establishes a new standard for\nflexible, high-fidelity voice editing and synthesis through the synergistic\nintegration of structured state-space modeling and cross-modal attention.", "published": "2025-10-06 12:11:31", "link": "http://arxiv.org/abs/2510.04738v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs", "abstract": "Large language models (LLMs) have recently shown strong performance on\nmathematical benchmarks. At the same time, they are prone to hallucination and\nsycophancy, often providing convincing but flawed proofs for incorrect\nmathematical statements provided by users. This significantly limits the\napplicability of LLMs in theorem proving, as verification of these flawed\nproofs must be done manually by expert mathematicians. However, existing\nbenchmarks that measure sycophancy in mathematics are limited: they focus\nsolely on final-answer problems, rely on very simple and often contaminated\ndatasets, and construct benchmark samples using synthetic modifications that\ncreate ill-posed questions rather than well-posed questions that are\ndemonstrably false. To address these issues, we introduce BrokenMath, the first\nbenchmark for evaluating sycophantic behavior in LLMs within the context of\nnatural language theorem proving. BrokenMath is built from advanced 2025\ncompetition problems, which are perturbed with an LLM to produce false\nstatements and subsequently refined through expert review. Using an\nLLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems\nand find that sycophancy is widespread, with the best model, GPT-5, producing\nsycophantic answers 29% of the time. We further investigate several mitigation\nstrategies, including test-time interventions and supervised fine-tuning on\ncurated sycophantic examples. These approaches substantially reduce, but do not\neliminate, sycophantic behavior.", "published": "2025-10-06 11:41:46", "link": "http://arxiv.org/abs/2510.04721v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "JSON Whisperer: Efficient JSON Editing with LLMs", "abstract": "Large language models (LLMs) can modify JSON documents through natural\nlanguage commands, but current approaches regenerate entire structures for each\nedit, resulting in computational inefficiency. We present JSON Whisperer, a\nframework that enables LLMs to generate RFC 6902 diff patches-expressing only\nthe necessary modifications-rather than complete documents. We identify two key\nchallenges in patch-based editing: (1) LLMs often miss related updates when\ngenerating isolated patches, and (2) array manipulations require tracking index\nshifts across operations, which LLMs handle poorly. To address these issues, we\nintroduce EASE (Explicitly Addressed Sequence Encoding), which transforms\narrays into dictionaries with stable keys, eliminating index arithmetic\ncomplexities. Our evaluation shows that patch generation with EASE reduces\ntoken usage by 31% while maintaining edit quality within 5% of full\nregeneration with particular gains for complex instructions and list\nmanipulations. The dataset is available at:\nhttps://github.com/emnlp2025/JSON-Whisperer/", "published": "2025-10-06 11:36:46", "link": "http://arxiv.org/abs/2510.04717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AtomWorld: A Benchmark for Evaluating Spatial Reasoning in Large Language Models on Crystalline Materials", "abstract": "Large Language Models (LLMs) excel at textual reasoning and are beginning to\ndevelop spatial understanding, prompting the question of whether these\nabilities can be combined for complex, domain-specific tasks. This question is\nessential in fields like materials science, where deep understanding of 3D\natomic structures is fundamental. While initial studies have successfully\napplied LLMs to tasks involving pure crystal generation or coordinate\nunderstandings, a standardized benchmark to systematically evaluate their core\nreasoning abilities across diverse atomic structures has been notably absent.\nTo address this gap, we introduce the AtomWorld benchmark to evaluate LLMs on\ntasks based in Crystallographic Information Files (CIFs), a standard structure\nrepresentation format. These tasks, including structural editing, CIF\nperception, and property-guided modeling, reveal a critical limitation: current\nmodels, despite establishing promising baselines, consistently fail in\nstructural understanding and spatial reasoning. Our experiments show that these\nmodels make frequent errors on structure modification tasks, and even in the\nbasic CIF format understandings, potentially leading to cumulative errors in\nsubsequent analysis and materials insights. By defining these standardized\ntasks, AtomWorld lays the ground for advancing LLMs toward robust atomic-scale\nmodeling, crucial for accelerating materials research and automating scientific\nworkflows.", "published": "2025-10-06 11:17:56", "link": "http://arxiv.org/abs/2510.04704v1", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.CL"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Multilingual Routing in Mixture-of-Experts", "abstract": "Mixture-of-Experts (MoE) architectures have become the key to scaling modern\nLLMs, yet little is understood about how their sparse routing dynamics respond\nto multilingual data. In this work, we analyze expert routing patterns using\nparallel multilingual datasets and present highly interpretable layer-wise\nphenomena. We find that MoE models route tokens in language-specific ways in\nthe early and late decoder layers but exhibit significant cross-lingual routing\nalignment in middle layers, mirroring parameter-sharing trends observed in\ndense LLMs. In particular, we reveal a clear, strong correlation between a\nmodel's performance in a given language and how similarly its tokens are routed\nto English in these layers. Extending beyond correlation, we explore\ninference-time interventions that induce higher cross-lingual routing\nalignment. We introduce a method that steers the router by promoting\nmiddle-layer task experts frequently activated in English, and it successfully\nincreases multilingual performance. These 1-2% gains are remarkably consistent\nacross two evaluation tasks, three models, and 15+ languages, especially given\nthat these simple interventions override routers of extensively trained,\nstate-of-the-art LLMs. In comparison, interventions outside of the middle\nlayers or targeting multilingual-specialized experts only yield performance\ndegradation. Altogether, we present numerous findings that explain how MoEs\nprocess non-English text and demonstrate that generalization is limited by the\nmodel's ability to leverage language-universal experts in all languages.", "published": "2025-10-06 11:09:20", "link": "http://arxiv.org/abs/2510.04694v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA", "abstract": "Large Language Models (LLMs) are widely applied in real world scenarios, but\nfine-tuning them comes with significant computational and storage costs.\nParameter-Efficient Fine-Tuning (PEFT) methods such as LoRA mitigate these\ncosts, but the adapted parameters are dependent on the base model and cannot be\ntransferred across different backbones. One way to address this issue is\nthrough knowledge distillation, but its effectiveness inherently depends on\ntraining data. Recent work such as TransLoRA avoids this by generating\nsynthetic data, but this adds complexity because it requires training an\nadditional discriminator model. In this paper, we propose TiTok, a new\nframework that enables effective LoRA Transplantation through Token-level\nknowledge transfer. Specifically, TiTok captures task-relevant information\nthrough a contrastive excess between a source model with and without LoRA. This\nexcess highlights informative tokens and enables selective filtering of\nsynthetic data, all without additional models or overhead. Through experiments\non three benchmarks across multiple transfer settings, our experiments show\nthat the proposed method is consistently effective, achieving average\nperformance gains of +4~8% compared to baselines overall.", "published": "2025-10-06 10:47:22", "link": "http://arxiv.org/abs/2510.04682v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Agent Tool-Integrated Policy Optimization", "abstract": "Large language models (LLMs) increasingly rely on multi-turn tool-integrated\nplanning for knowledge-intensive and complex reasoning tasks. Existing\nimplementations typically rely on a single agent, but they suffer from limited\ncontext length and noisy tool responses. A natural solution is to adopt a\nmulti-agent framework with planner- and worker-agents to manage context.\nHowever, no existing methods support effective reinforcement learning\npost-training of tool-integrated multi-agent frameworks. To address this gap,\nwe propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which\nenables distinct roles (planner and worker) to be trained within a single LLM\ninstance using role-specific prompts via reinforcement learning. MATPO is\nderived from a principled credit assignment mechanism across planner and worker\nrollouts. This design eliminates the need to deploy multiple LLMs, which would\nbe memory-intensive, while preserving the benefits of specialization.\nExperiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently\noutperforms single-agent baselines by an average of 18.38% relative improvement\nin performance and exhibits greater robustness to noisy tool outputs. Our\nfindings highlight the effectiveness of unifying multiple agent roles within a\nsingle LLM and provide practical insights for stable and efficient multi-agent\nRL training.", "published": "2025-10-06 10:44:04", "link": "http://arxiv.org/abs/2510.04678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FocusMed: A Large Language Model-based Framework for Enhancing Medical Question Summarization with Focus Identification", "abstract": "With the rapid development of online medical platforms, consumer health\nquestions (CHQs) are inefficient in diagnosis due to redundant information and\nfrequent non-professional terms. The medical question summary (MQS) task aims\nto transform CHQs into streamlined doctors' frequently asked questions (FAQs),\nbut existing methods still face challenges such as poor identification of\nquestion focus and model hallucination. This paper explores the potential of\nlarge language models (LLMs) in the MQS task and finds that direct fine-tuning\nis prone to focus identification bias and generates unfaithful content. To this\nend, we propose an optimization framework based on core focus guidance. First,\na prompt template is designed to drive the LLMs to extract the core focus from\nthe CHQs that is faithful to the original text. Then, a fine-tuning dataset is\nconstructed in combination with the original CHQ-FAQ pairs to improve the\nability to identify the focus of the question. Finally, a multi-dimensional\nquality evaluation and selection mechanism is proposed to comprehensively\nimprove the quality of the summary from multiple dimensions. We conduct\ncomprehensive experiments on two widely-adopted MQS datasets using three\nestablished evaluation metrics. The proposed framework achieves\nstate-of-the-art performance across all measures, demonstrating a significant\nboost in the model's ability to identify critical focus of questions and a\nnotable mitigation of hallucinations. The source codes are freely available at\nhttps://github.com/DUT-LiuChao/FocusMed.", "published": "2025-10-06 10:27:09", "link": "http://arxiv.org/abs/2510.04671v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FT-MDT: Extracting Decision Trees from Medical Texts via a Novel Low-rank Adaptation Method", "abstract": "Knowledge of the medical decision process, which can be modeled as medical\ndecision trees (MDTs), is critical to building clinical decision support\nsystems. However, current MDT construction methods rely heavily on\ntime-consuming and laborious manual annotation. To address this challenge, we\npropose PI-LoRA (Path-Integrated LoRA), a novel low-rank adaptation method for\nautomatically extracting MDTs from clinical guidelines and textbooks. We\nintegrate gradient path information to capture synergistic effects between\ndifferent modules, enabling more effective and reliable rank allocation. This\nframework ensures that the most critical modules receive appropriate rank\nallocations while less important ones are pruned, resulting in a more efficient\nand accurate model for extracting medical decision trees from clinical texts.\nExtensive experiments on medical guideline datasets demonstrate that our\nPI-LoRA method significantly outperforms existing parameter-efficient\nfine-tuning approaches for the Text2MDT task, achieving better accuracy with\nsubstantially reduced model complexity. The proposed method achieves\nstate-of-the-art results while maintaining a lightweight architecture, making\nit particularly suitable for clinical decision support systems where\ncomputational resources may be limited.", "published": "2025-10-06 09:59:55", "link": "http://arxiv.org/abs/2510.04655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study", "abstract": "Large-scale web-scraped text corpora used to train general-purpose AI models\noften contain harmful demographic-targeted social biases, creating a regulatory\nneed for data auditing and developing scalable bias-detection methods. Although\nprior work has investigated biases in text datasets and related detection\nmethods, these studies remain narrow in scope. They typically focus on a single\ncontent type (e.g., hate speech), cover limited demographic axes, overlook\nbiases affecting multiple demographics simultaneously, and analyze limited\ntechniques. Consequently, practitioners lack a holistic understanding of the\nstrengths and limitations of recent large language models (LLMs) for automated\nbias detection. In this study, we present a comprehensive evaluation framework\naimed at English texts to assess the ability of LLMs in detecting\ndemographic-targeted social biases. To align with regulatory requirements, we\nframe bias detection as a multi-label task using a demographic-focused\ntaxonomy. We then conduct a systematic evaluation with models across scales and\ntechniques, including prompting, in-context learning, and fine-tuning. Using\ntwelve datasets spanning diverse content types and demographics, our study\ndemonstrates the promise of fine-tuned smaller models for scalable detection.\nHowever, our analyses also expose persistent gaps across demographic axes and\nmulti-demographic targeted biases, underscoring the need for more effective and\nscalable auditing frameworks.", "published": "2025-10-06 09:45:32", "link": "http://arxiv.org/abs/2510.04641v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry", "abstract": "Recent trends in NLP utilize knowledge graphs (KGs) to enhance pretrained\nlanguage models by incorporating additional knowledge from the graph structures\nto learn domain-specific terminology or relationships between documents that\nmight otherwise be overlooked. This paper explores how SciNCL, a graph-aware\nneighborhood contrastive learning methodology originally designed for\nscientific publications, can be applied to the process industry domain, where\ntext logs contain crucial information about daily operations and are often\nstructured as sparse KGs. Our experiments demonstrate that language models\nfine-tuned with triplets derived from GE outperform a state-of-the-art\nmE5-large text encoder by 9.8-14.3% (5.4-8.0p) on the proprietary process\nindustry text embedding benchmark (PITEB) while being 3-5 times smaller in\nsize.", "published": "2025-10-06 09:36:20", "link": "http://arxiv.org/abs/2510.04631v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models", "abstract": "Large language model (LLM) applications such as agents and domain-specific\nreasoning increasingly rely on context adaptation -- modifying inputs with\ninstructions, strategies, or evidence, rather than weight updates. Prior\napproaches improve usability but often suffer from brevity bias, which drops\ndomain insights for concise summaries, and from context collapse, where\niterative rewriting erodes details over time. Building on the adaptive memory\nintroduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context\nEngineering), a framework that treats contexts as evolving playbooks that\naccumulate, refine, and organize strategies through a modular process of\ngeneration, reflection, and curation. ACE prevents collapse with structured,\nincremental updates that preserve detailed knowledge and scale with\nlong-context models. Across agent and domain-specific benchmarks, ACE optimizes\ncontexts both offline (e.g., system prompts) and online (e.g., agent memory),\nconsistently outperforming strong baselines: +10.6% on agents and +8.6% on\nfinance, while significantly reducing adaptation latency and rollout cost.\nNotably, ACE could adapt effectively without labeled supervision and instead by\nleveraging natural execution feedback. On the AppWorld leaderboard, ACE matches\nthe top-ranked production-level agent on the overall average and surpasses it\non the harder test-challenge split, despite using a smaller open-source model.\nThese results show that comprehensive, evolving contexts enable scalable,\nefficient, and self-improving LLM systems with low overhead.", "published": "2025-10-06 09:30:18", "link": "http://arxiv.org/abs/2510.04618v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning", "abstract": "The current paradigm of training large language models (LLMs) on publicly\navailable Web data is becoming unsustainable, with high-quality data sources in\nspecialized domains nearing exhaustion. Federated Learning (FL) emerges as a\npractical solution for the next generation of AI on a decentralized Web,\nenabling privacy-preserving collaborative fine-tuning by leveraging private\ndata distributed across a global client base. While Low-Rank Adaptation (LoRA)\nis the standard for efficient fine-tuning, its application in federated\nsettings presents a critical challenge: communication overhead remains a\nsignificant bottleneck across the Web's heterogeneous network conditions. The\nstructural redundancy within LoRA parameters not only incurs a heavy\ncommunication burden but also introduces conflicts when aggregating client\nupdates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose\nframework designed for communication-efficient FL. We first introduce an\nimportance-aware sparsification method that preserves the structural integrity\nof LoRA updates to reduce the uploaded parameter count. The server then\nreconstructs and aggregates these updates in a full-rank space to mitigate\nconflicts. Finally, it decomposes the global update into a sparse low-rank\nformat for broadcast, ensuring a symmetrically efficient cycle. We also propose\nan efficient variant, FedSRD-e, to reduce computational overhead. Experimental\nresults on 10 benchmarks demonstrate that our framework significantly reduces\ncommunication costs by up to 90\\% while even improving model performance on\nheterogeneous client data.", "published": "2025-10-06 09:06:38", "link": "http://arxiv.org/abs/2510.04601v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robustness assessment of large audio language models in multiple-choice evaluation", "abstract": "Recent advances in large audio language models (LALMs) have primarily been\nassessed using a multiple-choice question answering (MCQA) framework. However,\nsubtle changes, such as shifting the order of choices, result in substantially\ndifferent results. Existing MCQA frameworks do not account for this variability\nand report a single accuracy number per benchmark or category. We dive into the\nMCQA evaluation framework and conduct a systematic study spanning three\nbenchmarks (MMAU, MMAR and MMSU) and four models: Audio Flamingo 2, Audio\nFlamingo 3, Qwen2.5-Omni-7B-Instruct, and Kimi-Audio-7B-Instruct. Our findings\nindicate that models are sensitive not only to the ordering of choices, but\nalso to the paraphrasing of the question and the choices. Finally, we propose a\nsimpler evaluation protocol and metric that account for subtle variations and\nprovide a more detailed evaluation report of LALMs within the MCQA framework.", "published": "2025-10-06 08:36:17", "link": "http://arxiv.org/abs/2510.04584v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Can LLMs Detect Ambiguous Plural Reference? An Analysis of Split-Antecedent and Mereological Reference", "abstract": "Our goal is to study how LLMs represent and interpret plural reference in\nambiguous and unambiguous contexts. We ask the following research questions:\n(1) Do LLMs exhibit human-like preferences in representing plural reference?\n(2) Are LLMs able to detect ambiguity in plural anaphoric expressions and\nidentify possible referents? To address these questions, we design a set of\nexperiments, examining pronoun production using next-token prediction tasks,\npronoun interpretation, and ambiguity detection using different prompting\nstrategies. We then assess how comparable LLMs are to humans in formulating and\ninterpreting plural reference. We find that LLMs are sometimes aware of\npossible referents of ambiguous pronouns. However, they do not always follow\nhuman reference when choosing between interpretations, especially when the\npossible interpretation is not explicitly mentioned. In addition, they struggle\nto identify ambiguity without direct instruction. Our findings also reveal\ninconsistencies in the results across different types of experiments.", "published": "2025-10-06 08:32:59", "link": "http://arxiv.org/abs/2510.04581v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning", "abstract": "Large Language Models (LLMs) demonstrate their reasoning ability through\nchain-of-thought (CoT) generation. However, LLM's autoregressive decoding may\nlimit the ability to revisit and refine earlier tokens in a holistic manner,\nwhich can also lead to inefficient exploration for diverse solutions. In this\npaper, we propose LaDiR (Latent Diffusion Reasoner), a novel reasoning\nframework that unifies the expressiveness of continuous latent representation\nwith the iterative refinement capabilities of latent diffusion models for an\nexisting LLM. We first construct a structured latent reasoning space using a\nVariational Autoencoder (VAE) that encodes text reasoning steps into blocks of\nthought tokens, preserving semantic information and interpretability while\noffering compact but expressive representations. Subsequently, we utilize a\nlatent diffusion model that learns to denoise a block of latent thought tokens\nwith a blockwise bidirectional attention mask, enabling longer horizon and\niterative refinement with adaptive test-time compute. This design allows\nefficient parallel generation of diverse reasoning trajectories, allowing the\nmodel to plan and revise the reasoning process holistically. We conduct\nevaluations on a suite of mathematical reasoning and planning benchmarks.\nEmpirical results show that LaDiR consistently improves accuracy, diversity,\nand interpretability over existing autoregressive, diffusion-based, and latent\nreasoning methods, revealing a new paradigm for text reasoning with latent\ndiffusion.", "published": "2025-10-06 08:15:03", "link": "http://arxiv.org/abs/2510.04573v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Fine-grained auxiliary learning for real-world product recommendation", "abstract": "Product recommendation is the task of recovering the closest items to a given\nquery within a large product corpora. Generally, one can determine if\ntop-ranked products are related to the query by applying a similarity\nthreshold; exceeding it deems the product relevant, otherwise manual revision\nis required. Despite being a well-known problem, the integration of these\nmodels in real-world systems is often overlooked. In particular, production\nsystems have strong coverage requirements, i.e., a high proportion of\nrecommendations must be automated. In this paper we propose ALC , an Auxiliary\nLearning strategy that boosts Coverage through learning fine-grained\nembeddings. Concretely, we introduce two training objectives that leverage the\nhardest negatives in the batch to build discriminative training signals between\npositives and negatives. We validate ALC using three extreme multi-label\nclassification approaches in two product recommendation datasets;\nLF-AmazonTitles-131K and Tech and Durables (proprietary), demonstrating\nstate-of-the-art coverage rates when combined with a recent\nthreshold-consistent margin loss.", "published": "2025-10-06 07:34:06", "link": "http://arxiv.org/abs/2510.04551v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models", "abstract": "Vision-Language Model (VLM) driving agents promise explainable end-to-end\nautonomy by first producing natural-language reasoning and then predicting\ntrajectory planning. However, whether planning is causally driven by this\nreasoning remains a critical but unverified assumption. To investigate this, we\nbuild DriveMind, a large-scale driving Visual Question Answering (VQA) corpus\nwith plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan.\nOur data generation process converts sensors and annotations into structured\ninputs and, crucially, separates priors from to-be-reasoned signals, enabling\nclean information ablations. Using DriveMind, we train representative VLM\nagents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization\n(GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately,\nindicate a consistent causal disconnect in reasoning-planning: removing\nego/navigation priors causes large drops in planning scores, whereas removing\nCoT produces only minor changes. Attention analysis further shows that planning\nprimarily focuses on priors rather than the CoT. Based on this evidence, we\npropose the Reasoning-Planning Decoupling Hypothesis, positing that the\ntraining-yielded reasoning is an ancillary byproduct rather than a causal\nmediator. To enable efficient diagnosis, we also introduce a novel,\ntraining-free probe that measures an agent's reliance on priors by evaluating\nits planning robustness against minor input perturbations. In summary, we\nprovide the community with a new dataset and a diagnostic tool to evaluate the\ncausal fidelity of future models.", "published": "2025-10-06 06:50:16", "link": "http://arxiv.org/abs/2510.04532v1", "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.AI"}
{"title": "ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering", "abstract": "Recent multimodal LLMs have shown promise in chart-based visual question\nanswering, but their performance declines sharply on unannotated charts, those\nrequiring precise visual interpretation rather than relying on textual\nshortcuts. To address this, we introduce ChartAgent, a novel agentic framework\nthat explicitly performs visual reasoning directly within the chart's spatial\ndomain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively\ndecomposes queries into visual subtasks and actively manipulates and interacts\nwith chart images through specialized actions such as drawing annotations,\ncropping regions (e.g., segmenting pie slices, isolating bars), and localizing\naxes, using a library of chart-specific vision tools to fulfill each subtask.\nThis iterative reasoning process closely mirrors human cognitive strategies for\nchart comprehension. ChartAgent achieves state-of-the-art accuracy on the\nChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%\nabsolute gain overall and 17.31% on unannotated, numerically intensive queries.\nFurthermore, our analyses show that ChartAgent is (a) effective across diverse\nchart types, (b) achieve the highest scores across varying visual and reasoning\ncomplexity levels, and (c) serves as a plug-and-play framework that boosts\nperformance across diverse underlying LLMs. Our work is among the first to\ndemonstrate visually grounded reasoning for chart understanding using\ntool-augmented multimodal agents.", "published": "2025-10-06 06:05:36", "link": "http://arxiv.org/abs/2510.04514v1", "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.CV", "stat.ME"], "primary_category": "cs.AI"}
{"title": "GRACE: Generative Representation Learning via Contrastive Policy Optimization", "abstract": "Prevailing methods for training Large Language Models (LLMs) as text encoders\nrely on contrastive losses that treat the model as a black box function,\ndiscarding its generative and reasoning capabilities in favor of static\nembeddings. We introduce GRACE (Generative Representation Learning via\nContrastive Policy Optimization), a novel framework that reimagines contrastive\nsignals not as losses to be minimized, but as rewards that guide a generative\npolicy. In GRACE, the LLM acts as a policy that produces explicit,\nhuman-interpretable rationales--structured natural language explanations of its\nsemantic understanding. These rationales are then encoded into high-quality\nembeddings via mean pooling. Using policy gradient optimization, we train the\nmodel with a multi-component reward function that maximizes similarity between\nquery positive pairs and minimizes similarity with negatives. This transforms\nthe LLM from an opaque encoder into an interpretable agent whose reasoning\nprocess is transparent and inspectable. On MTEB benchmark, GRACE yields broad\ncross category gains: averaged over four backbones, the supervised setting\nimproves overall score by 11.5% over base models, and the unsupervised variant\nadds 6.9%, while preserving general capabilities. This work treats contrastive\nobjectives as rewards over rationales, unifying representation learning with\ngeneration to produce stronger embeddings and transparent rationales. The\nmodel, data and code are available at https://github.com/GasolSun36/GRACE.", "published": "2025-10-06 05:46:56", "link": "http://arxiv.org/abs/2510.04506v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs", "abstract": "During fine-tuning, large language models (LLMs) are increasingly vulnerable\nto data-poisoning backdoor attacks, which compromise their reliability and\ntrustworthiness. However, existing defense strategies suffer from limited\ngeneralization: they only work on specific attack types or task settings. In\nthis study, we propose Poison-to-Poison (P2P), a general and effective backdoor\ndefense algorithm. P2P injects benign triggers with safe alternative labels\ninto a subset of training samples and fine-tunes the model on this re-poisoned\ndataset by leveraging prompt-based learning. This enforces the model to\nassociate trigger-induced representations with safe outputs, thereby overriding\nthe effects of original malicious triggers. Thanks to this robust and\ngeneralizable trigger-based fine-tuning, P2P is effective across task settings\nand attack types. Theoretically and empirically, we show that P2P can\nneutralize malicious backdoors while preserving task performance. We conduct\nextensive experiments on classification, mathematical reasoning, and summary\ngeneration tasks, involving multiple state-of-the-art LLMs. The results\ndemonstrate that our P2P algorithm significantly reduces the attack success\nrate compared with baseline models. We hope that the P2P can serve as a\nguideline for defending against backdoor attacks and foster the development of\na secure and trustworthy LLM community.", "published": "2025-10-06 05:45:23", "link": "http://arxiv.org/abs/2510.04503v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "GenQuest: An LLM-based Text Adventure Game for Language Learners", "abstract": "GenQuest is a generative text adventure game that leverages Large Language\nModels (LLMs) to facilitate second language learning through immersive,\ninteractive storytelling. The system engages English as a Foreign Language\n(EFL) learners in a collaborative \"choose-your-own-adventure\" style narrative,\ndynamically generated in response to learner choices. Game mechanics such as\nbranching decision points and story milestones are incorporated to maintain\nnarrative coherence while allowing learner-driven plot development. Key\npedagogical features include content generation tailored to each learner's\nproficiency level, and a vocabulary assistant that provides in-context\nexplanations of learner-queried text strings, ranging from words and phrases to\nsentences. Findings from a pilot study with university EFL students in China\nindicate promising vocabulary gains and positive user perceptions. Also\ndiscussed are suggestions from participants regarding the narrative length and\nquality, and the request for multi-modal content such as illustrations.", "published": "2025-10-06 05:22:53", "link": "http://arxiv.org/abs/2510.04498v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents", "abstract": "Despite rapid progress in building conversational AI agents, robustness is\nstill largely untested. Small shifts in user behavior, such as being more\nimpatient, incoherent, or skeptical, can cause sharp drops in agent\nperformance, revealing how brittle current AI agents are. Today's benchmarks\nfail to capture this fragility: agents may perform well under standard\nevaluations but degrade spectacularly in more realistic and varied settings. We\naddress this robustness testing gap by introducing TraitBasis, a lightweight,\nmodel-agnostic method for systematically stress testing AI agents. TraitBasis\nlearns directions in activation space corresponding to steerable user traits\n(e.g., impatience or incoherence), which can be controlled, scaled, composed,\nand applied at inference time without any fine-tuning or extra data. Using\nTraitBasis, we extend $\\tau$-Bench to $\\tau$-Trait, where user behaviors are\naltered via controlled trait vectors. We observe on average a 2%-30%\nperformance degradation on $\\tau$-Trait across frontier models, highlighting\nthe lack of robustness of current AI agents to variations in user behavior.\nTogether, these results highlight both the critical role of robustness testing\nand the promise of TraitBasis as a simple, data-efficient, and compositional\ntool. By powering simulation-driven stress tests and training loops, TraitBasis\nopens the door to building AI agents that remain reliable in the unpredictable\ndynamics of real-world human interactions. We have open-sourced $\\tau$-Trai\nacross four domains: airline, retail, telecom, and telehealth, so the community\ncan systematically QA their agents under realistic, behaviorally diverse\nintents and trait scenarios: https://github.com/collinear-ai/tau-trait.", "published": "2025-10-06 05:03:57", "link": "http://arxiv.org/abs/2510.04491v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Psychological Steering in LLMs: An Evaluation of Effectiveness and Trustworthiness", "abstract": "The ability to control LLMs' emulated emotional states and personality traits\nis essential for enabling rich, human-centered interactions in socially\ninteractive settings. We introduce PsySET, a Psychologically-informed benchmark\nto evaluate LLM Steering Effectiveness and Trustworthiness across the emotion\nand personality domains. Our study spans four models from different LLM\nfamilies paired with various steering strategies, including prompting,\nfine-tuning, and representation engineering. Our results indicate that\nprompting is consistently effective but limited in intensity control, whereas\nvector injections achieve finer controllability while slightly reducing output\nquality. Moreover, we explore the trustworthiness of steered LLMs by assessing\nsafety, truthfulness, fairness, and ethics, highlighting potential side effects\nand behavioral shifts. Notably, we observe idiosyncratic effects; for instance,\neven a positive emotion like joy can degrade robustness to adversarial\nfactuality, lower privacy awareness, and increase preferential bias. Meanwhile,\nanger predictably elevates toxicity yet strengthens leakage resistance. Our\nframework establishes the first holistic evaluation of emotion and personality\nsteering, offering insights into its interpretability and reliability for\nsocially interactive applications.", "published": "2025-10-06 04:49:56", "link": "http://arxiv.org/abs/2510.04484v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models", "abstract": "Bridging clinical diagnostic reasoning with AI remains a central challenge in\nmedical imaging. We introduce MedCLM, an automated pipeline that converts\ndetection datasets into large-scale medical visual question answering (VQA)\ndata with Chain-of-Thought (CoT) reasoning by linking lesion boxes to organ\nsegmentation and structured rationales. These contextual signals enable medical\nvision-language models to generate question-answer pairs with step-by-step\nreasoning. To utilize this data effectively, we propose an Integrated\nCoT-Curriculum Strategy composed of an Easy stage with explicit lesion boxes\nfor visual grounding, a Medium stage that encourages implicit localization, and\na Hard stage for weakly supervised reasoning. Experimental results demonstrate\nthat MedCLM attains state-of-the-art performance on several medical VQA\nbenchmarks, providing a scalable framework for developing clinically aligned\nmedical vision-language models.", "published": "2025-10-06 04:26:39", "link": "http://arxiv.org/abs/2510.04477v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space", "abstract": "Multi-headed Attention's (MHA) quadratic compute and linearly growing\nKV-cache make long-context transformers expensive to train and serve. Prior\nworks such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA)\nshrink the cache, speeding decode, but leave compute, which determines prefill\nand training speed, largely unchanged. We introduce Compressed Convolutional\nAttention (CCA), a novel attention method which down-projects queries, keys,\nand values and performs the entire attention operation inside the shared latent\nspace. This simple design dramatically cuts parameters, KV-cache, and FLOPs all\nat once by the desired compression factor. Because CCA is orthogonal to\nhead-sharing, we combine the two to form Compressed Convolutional Grouped Query\nAttention (CCGQA), which further tightens the compute-bandwidth Pareto frontier\nso that users can tune compression toward either FLOP or memory limits without\nsacrificing quality. Experiments show that CCGQA consistently outperforms both\nGQA and MLA at equal KV-cache compression on dense and MoE models.\nAdditionally, we show that CCGQA outperforms all other attention methods on MoE\nmodels with half the KV-cache of GQA and MLA, achieving an 8x KV-cache\ncompression with no drop in performance compared to standard MHA. CCA and CCGQA\nalso dramatically reduce the FLOP cost of attention which leads to\nsubstantially faster training and prefill than existing methods. On H100 GPUs,\nour fused CCA/CCGQA kernel reduces prefill latency by about 1.7x at a sequence\nlength of 16k relative to MHA, and accelerates backward by about 1.3x.", "published": "2025-10-06 04:24:23", "link": "http://arxiv.org/abs/2510.04476v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners", "abstract": "Large Language Models (LLMs) show strong reasoning abilities, often amplified\nby Chain-of-Thought (CoT) prompting and reinforcement learning (RL). Although\nRL algorithms can substantially improve reasoning, they struggle to expand\nreasoning boundaries because they learn from their own reasoning trajectories\nrather than acquiring external knowledge. Supervised fine-tuning (SFT) offers\ncomplementary benefits but typically requires large-scale data and risks\noverfitting. Recent attempts to combine SFT and RL face three main challenges:\ndata inefficiency, algorithm-specific designs, and catastrophic forgetting. We\npropose a plug-and-play framework that dynamically integrates SFT into RL by\nselecting challenging examples for SFT. This approach reduces SFT data\nrequirements and remains agnostic to the choice of RL or SFT algorithm. To\nmitigate catastrophic forgetting of RL-acquired skills during SFT, we select\nhigh-entropy tokens for loss calculation and freeze parameters identified as\ncritical for RL. Our method achieves state-of-the-art (SoTA) reasoning\nperformance using only 1.5% of the SFT data and 20.4% of the RL data used by\nprior SoTA, providing an efficient and plug-and-play solution for combining SFT\nand RL in reasoning post-training.", "published": "2025-10-06 03:01:14", "link": "http://arxiv.org/abs/2510.04454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Role of Unobserved Sequences on Sample-based Uncertainty Quantification for LLMs", "abstract": "Quantifying uncertainty in large language models (LLMs) is important for\nsafety-critical applications because it helps spot incorrect answers, known as\nhallucinations. One major trend of uncertainty quantification methods is based\non estimating the entropy of the distribution of the LLM's potential output\nsequences. This estimation is based on a set of output sequences and associated\nprobabilities obtained by querying the LLM several times. In this paper, we\nadvocate and experimentally show that the probability of unobserved sequences\nplays a crucial role, and we recommend future research to integrate it to\nenhance such LLM uncertainty quantification methods.", "published": "2025-10-06 02:14:48", "link": "http://arxiv.org/abs/2510.04439v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?", "abstract": "The social impact of Natural Language Processing (NLP) is increasingly\nimportant, with a rising community focus on initiatives related to NLP for\nSocial Good (NLP4SG). Indeed, in recent years, almost 20% of all papers in the\nACL Anthology address topics related to social good as defined by the UN\nSustainable Development Goals (Adauto et al., 2023). In this study, we take an\nauthor- and venue-level perspective to map the landscape of NLP4SG, quantifying\nthe proportion of work addressing social good concerns both within and beyond\nthe ACL community, by both core ACL contributors and non-ACL authors. With this\napproach we discover two surprising facts about the landscape of NLP4SG. First,\nACL authors are dramatically more likely to do work addressing social good\nconcerns when publishing in venues outside of ACL. Second, the vast majority of\npublications using NLP techniques to address concerns of social good are done\nby non-ACL authors in venues outside of ACL. We discuss the implications of\nthese findings on agenda-setting considerations for the ACL community related\nto NLP4SG.", "published": "2025-10-06 02:04:42", "link": "http://arxiv.org/abs/2510.04434v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions", "abstract": "The study of multimodality has garnered significant interest in fields where\nthe analysis of interactions among multiple information sources can enhance\npredictive modeling, data fusion, and interpretability. Partial information\ndecomposition (PID) has emerged as a useful information-theoretic framework to\nquantify the degree to which individual modalities independently, redundantly,\nor synergistically convey information about a target variable. However,\nexisting PID methods depend on optimizing over a joint distribution constrained\nby estimated pairwise probability distributions, which are costly and\ninaccurate for continuous and high-dimensional modalities. Our first key\ninsight is that the problem can be solved efficiently when the pairwise\ndistributions are multivariate Gaussians, and we refer to this problem as\nGaussian PID (GPID). We propose a new gradient-based algorithm that\nsubstantially improves the computational efficiency of GPID based on an\nalternative formulation of the underlying optimization problem. To generalize\nthe applicability to non-Gaussian data, we learn information-preserving\nencoders to transform random variables of arbitrary input distributions into\npairwise Gaussian random variables. Along the way, we resolved an open problem\nregarding the optimality of joint Gaussian solutions for GPID. Empirical\nvalidation in diverse synthetic examples demonstrates that our proposed method\nprovides more accurate and efficient PID estimates than existing baselines. We\nfurther evaluate a series of large-scale multimodal benchmarks to show its\nutility in real-world applications of quantifying PID in multimodal datasets\nand selecting high-performing models.", "published": "2025-10-06 01:08:34", "link": "http://arxiv.org/abs/2510.04417v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Large Language Models Preserve Semantic Isotopies in Story Continuations", "abstract": "In this work, we explore the relevance of textual semantics to Large Language\nModels (LLMs), extending previous insights into the connection between\ndistributional semantics and structural semantics. We investigate whether\nLLM-generated texts preserve semantic isotopies. We design a story continuation\nexperiment using 10,000 ROCStories prompts completed by five LLMs. We first\nvalidate GPT-4o's ability to extract isotopies from a linguistic benchmark,\nthen apply it to the generated stories. We then analyze structural (coverage,\ndensity, spread) and semantic properties of isotopies to assess how they are\naffected by completion. Results show that LLM completion within a given token\nhorizon preserves semantic isotopies across multiple properties.", "published": "2025-10-06 00:03:12", "link": "http://arxiv.org/abs/2510.04400v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TopInG: Topologically Interpretable Graph Learning via Persistent Rationale Filtration", "abstract": "Graph Neural Networks (GNNs) have shown remarkable success across various\nscientific fields, yet their adoption in critical decision-making is often\nhindered by a lack of interpretability. Recently, intrinsically interpretable\nGNNs have been studied to provide insights into model predictions by\nidentifying rationale substructures in graphs. However, existing methods face\nchallenges when the underlying rationale subgraphs are complex and varied. In\nthis work, we propose TopInG: Topologically Interpretable Graph Learning, a\nnovel topological framework that leverages persistent homology to identify\npersistent rationale subgraphs. TopInG employs a rationale filtration learning\napproach to model an autoregressive generation process of rationale subgraphs,\nand introduces a self-adjusted topological constraint, termed topological\ndiscrepancy, to enforce a persistent topological distinction between rationale\nsubgraphs and irrelevant counterparts. We provide theoretical guarantees that\nour loss function is uniquely optimized by the ground truth under specific\nconditions. Extensive experiments demonstrate TopInG's effectiveness in\ntackling key challenges, such as handling variform rationale subgraphs,\nbalancing predictive performance with interpretability, and mitigating spurious\ncorrelations. Results show that our approach improves upon state-of-the-art\nmethods on both predictive accuracy and interpretation quality.", "published": "2025-10-06 17:59:44", "link": "http://arxiv.org/abs/2510.05102v1", "categories": ["cs.LG", "cs.AI", "cs.CG", "math.AT", "stat.ML", "55N31, 68T05, 62R40, 05C, 68R05", "I.2.6; G.2.2; I.5.1"], "primary_category": "cs.LG"}
{"title": "SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder", "abstract": "Large-scale text-to-image diffusion models have become the backbone of modern\nimage editing, yet text prompts alone do not offer adequate control over the\nediting process. Two properties are especially desirable: disentanglement,\nwhere changing one attribute does not unintentionally alter others, and\ncontinuous control, where the strength of an edit can be smoothly adjusted. We\nintroduce a method for disentangled and continuous editing through token-level\nmanipulation of text embeddings. The edits are applied by manipulating the\nembeddings along carefully chosen directions, which control the strength of the\ntarget attribute. To identify such directions, we employ a Sparse Autoencoder\n(SAE), whose sparse latent space exposes semantically isolated dimensions. Our\nmethod operates directly on text embeddings without modifying the diffusion\nprocess, making it model agnostic and broadly applicable to various image\nsynthesis backbones. Experiments show that it enables intuitive and efficient\nmanipulations with continuous control across diverse attributes and domains.", "published": "2025-10-06 17:51:04", "link": "http://arxiv.org/abs/2510.05081v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Staircase Streaming for Low-Latency Multi-Agent Inference", "abstract": "Recent advances in large language models (LLMs) opened up new directions for\nleveraging the collective expertise of multiple LLMs. These methods, such as\nMixture-of-Agents, typically employ additional inference steps to generate\nintermediate outputs, which are then used to produce the final response. While\nmulti-agent inference can enhance response quality, it can significantly\nincrease the time to first token (TTFT), posing a challenge for\nlatency-sensitive applications and hurting user experience. To address this\nissue, we propose staircase streaming for low-latency multi-agent inference.\nInstead of waiting for the complete intermediate outputs from previous steps,\nwe begin generating the final response as soon as we receive partial outputs\nfrom these steps. Experimental results demonstrate that staircase streaming\nreduces TTFT by up to 93% while maintaining response quality.", "published": "2025-10-06 17:37:35", "link": "http://arxiv.org/abs/2510.05059v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "HybridFlow: Quantification of Aleatoric and Epistemic Uncertainty with a Single Hybrid Model", "abstract": "Uncertainty quantification is critical for ensuring robustness in high-stakes\nmachine learning applications. We introduce HybridFlow, a modular hybrid\narchitecture that unifies the modeling of aleatoric and epistemic uncertainty\nby combining a Conditional Masked Autoregressive normalizing flow for\nestimating aleatoric uncertainty with a flexible probabilistic predictor for\nepistemic uncertainty. The framework supports integration with any\nprobabilistic model class, allowing users to easily adapt HybridFlow to\nexisting architectures without sacrificing predictive performance. HybridFlow\nimproves upon previous uncertainty quantification frameworks across a range of\nregression tasks, such as depth estimation, a collection of regression\nbenchmarks, and a scientific case study of ice sheet emulation. We also provide\nempirical results of the quantified uncertainty, showing that the uncertainty\nquantified by HybridFlow is calibrated and better aligns with model error than\nexisting methods for quantifying aleatoric and epistemic uncertainty.\nHybridFlow addresses a key challenge in Bayesian deep learning, unifying\naleatoric and epistemic uncertainty modeling in a single robust framework.", "published": "2025-10-06 17:34:48", "link": "http://arxiv.org/abs/2510.05054v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Look-ahead Reasoning with a Learned Model in Imperfect Information Games", "abstract": "Test-time reasoning significantly enhances pre-trained AI agents'\nperformance. However, it requires an explicit environment model, often\nunavailable or overly complex in real-world scenarios. While MuZero enables\neffective model learning for search in perfect information games, extending\nthis paradigm to imperfect information games presents substantial challenges\ndue to more nuanced look-ahead reasoning techniques and large number of states\nrelevant for individual decisions. This paper introduces an algorithm LAMIR\nthat learns an abstracted model of an imperfect information game directly from\nthe agent-environment interaction. During test time, this trained model is used\nto perform look-ahead reasoning. The learned abstraction limits the size of\neach subgame to a manageable size, making theoretically principled look-ahead\nreasoning tractable even in games where previous methods could not scale. We\nempirically demonstrate that with sufficient capacity, LAMIR learns the exact\nunderlying game structure, and with limited capacity, it still learns a\nvaluable abstraction, which improves game playing performance of the\npre-trained agents even in large games.", "published": "2025-10-06 17:26:56", "link": "http://arxiv.org/abs/2510.05048v1", "categories": ["cs.AI", "cs.GT"], "primary_category": "cs.AI"}
{"title": "Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts", "abstract": "Diffusion-based large language models (dLLMs) are trained flexibly to model\nextreme dependence in the data distribution; however, how to best utilize this\ninformation at inference time remains an open problem. In this work, we uncover\nan interesting property of these models: dLLMs trained on textual data\nimplicitly learn a mixture of semi-autoregressive experts, where different\ngeneration orders reveal different specialized behaviors. We show that\ncommitting to any single, fixed inference time schedule, a common practice,\ncollapses performance by failing to leverage this latent ensemble. To address\nthis, we introduce HEX (Hidden semiautoregressive EXperts for test-time\nscaling), a training-free inference method that ensembles across heterogeneous\nblock schedules. By doing a majority vote over diverse block-sized generation\npaths, HEX robustly avoids failure modes associated with any single fixed\nschedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to\n3.56X (from 24.72% to 88.10%), outperforming top-K margin inference and\nspecialized fine-tuned methods like GRPO, without additional training. HEX even\nyields significant gains on MATH benchmark from 16.40% to 40.00%, scientific\nreasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%.\nOur results establish a new paradigm for test-time scaling in diffusion-based\nLLMs (dLLMs), revealing that the sequence in which masking is performed plays a\ncritical role in determining performance during inference.", "published": "2025-10-06 17:16:41", "link": "http://arxiv.org/abs/2510.05040v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Graph-Aware Diffusion for Signal Generation", "abstract": "We study the problem of generating graph signals from unknown distributions\ndefined over given graphs, relevant to domains such as recommender systems or\nsensor networks. Our approach builds on generative diffusion models, which are\nwell established in vision and graph generation but remain underexplored for\ngraph signals. Existing methods lack generality, either ignoring the graph\nstructure in the forward process or designing graph-aware mechanisms tailored\nto specific domains. We adopt a forward process that incorporates the graph\nthrough the heat equation. Rather than relying on the standard formulation, we\nconsider a time-warped coefficient to mitigate the exponential decay of the\ndrift term, yielding a graph-aware generative diffusion model (GAD). We analyze\nits forward dynamics, proving convergence to a Gaussian Markov random field\nwith covariance parametrized by the graph Laplacian, and interpret the backward\ndynamics as a sequence of graph-signal denoising problems. Finally, we\ndemonstrate the advantages of GAD on synthetic data, real traffic speed\nmeasurements, and a temperature sensor network.", "published": "2025-10-06 17:11:32", "link": "http://arxiv.org/abs/2510.05036v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Rethinking Langevin Thompson Sampling from A Stochastic Approximation Perspective", "abstract": "Most existing approximate Thompson Sampling (TS) algorithms for multi-armed\nbandits use Stochastic Gradient Langevin Dynamics (SGLD) or its variants in\neach round to sample from the posterior, relaxing the need for conjugacy\nassumptions between priors and reward distributions in vanilla TS. However,\nthey often require approximating a different posterior distribution in\ndifferent round of the bandit problem. This requires tricky, round-specific\ntuning of hyperparameters such as dynamic learning rates, causing challenges in\nboth theoretical analysis and practical implementation. To alleviate this\nnon-stationarity, we introduce TS-SA, which incorporates stochastic\napproximation (SA) within the TS framework. In each round, TS-SA constructs a\nposterior approximation only using the most recent reward(s), performs a\nLangevin Monte Carlo (LMC) update, and applies an SA step to average noisy\nproposals over time. This can be interpreted as approximating a stationary\nposterior target throughout the entire algorithm, which further yields a fixed\nstep-size, a unified convergence analysis framework, and improved posterior\nestimates through temporal averaging. We establish near-optimal regret bounds\nfor TS-SA, with a simplified and more intuitive theoretical analysis enabled by\ninterpreting the entire algorithm as a simulation of a stationary SGLD process.\nOur empirical results demonstrate that even a single-step Langevin update with\ncertain warm-up outperforms existing methods substantially on bandit tasks.", "published": "2025-10-06 17:01:29", "link": "http://arxiv.org/abs/2510.05023v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Think Then Embed: Generative Context Improves Multimodal Embedding", "abstract": "There is a growing interest in Universal Multimodal Embeddings (UME), where\nmodels are required to generate task-specific representations. While recent\nstudies show that Multimodal Large Language Models (MLLMs) perform well on such\ntasks, they treat MLLMs solely as encoders, overlooking their generative\ncapacity. However, such an encoding paradigm becomes less effective as\ninstructions become more complex and require compositional reasoning. Inspired\nby the proven effectiveness of chain-of-thought reasoning, we propose a general\nThink-Then-Embed (TTE) framework for UME, composed of a reasoner and an\nembedder. The reasoner MLLM first generates reasoning traces that explain\ncomplex queries, followed by an embedder that produces representations\nconditioned on both the original query and the intermediate reasoning. This\nexplicit reasoning step enables more nuanced understanding of complex\nmultimodal instructions. Our contributions are threefold. First, by leveraging\na powerful MLLM reasoner, we achieve state-of-the-art performance on the\nMMEB-V2 benchmark, surpassing proprietary models trained on massive in-house\ndatasets. Second, to reduce the dependency on large MLLM reasoners, we finetune\na smaller MLLM reasoner using high-quality embedding-centric reasoning traces,\nachieving the best performance among open-source models with a 7% absolute gain\nover recently proposed models. Third, we investigate strategies for integrating\nthe reasoner and embedder into a unified model for improved efficiency without\nsacrificing performance.", "published": "2025-10-06 16:53:56", "link": "http://arxiv.org/abs/2510.05014v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Bridging Text and Video Generation: A Survey", "abstract": "Text-to-video (T2V) generation technology holds potential to transform\nmultiple domains such as education, marketing, entertainment, and assistive\ntechnologies for individuals with visual or reading comprehension challenges,\nby creating coherent visual content from natural language prompts. From its\ninception, the field has advanced from adversarial models to diffusion-based\nmodels, yielding higher-fidelity, temporally consistent outputs. Yet challenges\npersist, such as alignment, long-range coherence, and computational efficiency.\nAddressing this evolving landscape, we present a comprehensive survey of\ntext-to-video generative models, tracing their development from early GANs and\nVAEs to hybrid Diffusion-Transformer (DiT) architectures, detailing how these\nmodels work, what limitations they addressed in their predecessors, and why\nshifts toward new architectural paradigms were necessary to overcome challenges\nin quality, coherence, and control. We provide a systematic account of the\ndatasets, which the surveyed text-to-video models were trained and evaluated\non, and, to support reproducibility and assess the accessibility of training\nsuch models, we detail their training configurations, including their hardware\nspecifications, GPU counts, batch sizes, learning rates, optimizers, epochs,\nand other key hyperparameters. Further, we outline the evaluation metrics\ncommonly used for evaluating such models and present their performance across\nstandard benchmarks, while also discussing the limitations of these metrics and\nthe emerging shift toward more holistic, perception-aligned evaluation\nstrategies. Finally, drawing from our analysis, we outline the current open\nchallenges and propose a few promising future directions, laying out a\nperspective for future researchers to explore and build upon in advancing T2V\nresearch and applications.", "published": "2025-10-06 16:39:05", "link": "http://arxiv.org/abs/2510.04999v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "AutoEmpirical: LLM-Based Automated Research for Empirical Software Fault Analysis", "abstract": "Understanding software faults is essential for empirical research in software\ndevelopment and maintenance. However, traditional fault analysis, while\nvaluable, typically involves multiple expert-driven steps such as collecting\npotential faults, filtering, and manual investigation. These processes are both\nlabor-intensive and time-consuming, creating bottlenecks that hinder\nlarge-scale fault studies in complex yet critical software systems and slow the\npace of iterative empirical research.\n  In this paper, we decompose the process of empirical software fault study\ninto three key phases: (1) research objective definition, (2) data preparation,\nand (3) fault analysis, and we conduct an initial exploration study of applying\nLarge Language Models (LLMs) for fault analysis of open-source software.\nSpecifically, we perform the evaluation on 3,829 software faults drawn from a\nhigh-quality empirical study. Our results show that LLMs can substantially\nimprove efficiency in fault analysis, with an average processing time of about\ntwo hours, compared to the weeks of manual effort typically required. We\nconclude by outlining a detailed research plan that highlights both the\npotential of LLMs for advancing empirical fault studies and the open challenges\nthat required be addressed to achieve fully automated, end-to-end software\nfault analysis.", "published": "2025-10-06 16:37:18", "link": "http://arxiv.org/abs/2510.04997v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI", "abstract": "The rapid advancement of embodied intelligence and world models has\nintensified efforts to integrate physical laws into AI systems, yet physical\nperception and symbolic physics reasoning have developed along separate\ntrajectories without a unified bridging framework. This work provides a\ncomprehensive overview of physical AI, establishing clear distinctions between\ntheoretical physics reasoning and applied physical understanding while\nsystematically examining how physics-grounded methods enhance AI's real-world\ncomprehension across structured symbolic reasoning, embodied systems, and\ngenerative models. Through rigorous analysis of recent advances, we advocate\nfor intelligent systems that ground learning in both physical principles and\nembodied reasoning processes, transcending pattern recognition toward genuine\nunderstanding of physical laws. Our synthesis envisions next-generation world\nmodels capable of explaining physical phenomena and predicting future states,\nadvancing safe, generalizable, and interpretable AI systems. We maintain a\ncontinuously updated resource at\nhttps://github.com/AI4Phys/Awesome-AI-for-Physics.", "published": "2025-10-06 16:16:03", "link": "http://arxiv.org/abs/2510.04978v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Embracing Discrete Search: A Reasonable Approach to Causal Structure Learning", "abstract": "We present FLOP (Fast Learning of Order and Parents), a score-based causal\ndiscovery algorithm for linear models. It pairs fast parent selection with\niterative Cholesky-based score updates, cutting run-times over prior\nalgorithms. This makes it feasible to fully embrace discrete search, enabling\niterated local search with principled order initialization to find graphs with\nscores at or close to the global optimum. The resulting structures are highly\naccurate across benchmarks, with near-perfect recovery in standard settings.\nThis performance calls for revisiting discrete search over graphs as a\nreasonable approach to causal discovery.", "published": "2025-10-06 16:04:53", "link": "http://arxiv.org/abs/2510.04970v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "ActiveMark: on watermarking of visual foundation models via massive activations", "abstract": "Being trained on large and vast datasets, visual foundation models (VFMs) can\nbe fine-tuned for diverse downstream tasks, achieving remarkable performance\nand efficiency in various computer vision applications. The high computation\ncost of data collection and training motivates the owners of some VFMs to\ndistribute them alongside the license to protect their intellectual property\nrights. However, a dishonest user of the protected model's copy may illegally\nredistribute it, for example, to make a profit. As a consequence, the\ndevelopment of reliable ownership verification tools is of great importance\ntoday, since such methods can be used to differentiate between a redistributed\ncopy of the protected model and an independent model. In this paper, we propose\nan approach to ownership verification of visual foundation models by\nfine-tuning a small set of expressive layers of a VFM along with a small\nencoder-decoder network to embed digital watermarks into an internal\nrepresentation of a hold-out set of input images. Importantly, the watermarks\nembedded remain detectable in the functional copies of the protected model,\nobtained, for example, by fine-tuning the VFM for a particular downstream task.\nTheoretically and experimentally, we demonstrate that the proposed method\nyields a low probability of false detection of a non-watermarked model and a\nlow probability of false misdetection of a watermarked model.", "published": "2025-10-06 15:58:27", "link": "http://arxiv.org/abs/2510.04966v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MuFFIN: Multifaceted Pronunciation Feedback Model with Interactive Hierarchical Neural Modeling", "abstract": "Computer-assisted pronunciation training (CAPT) manages to facilitate\nsecond-language (L2) learners to practice pronunciation skills by offering\ntimely and instructive feedback. To examine pronunciation proficiency from\nmultiple facets, existing methods for CAPT broadly fall into two categories:\nmispronunciation detection and diagnosis (MDD) as well as automatic\npronunciation assessment (APA). The former aims to pinpoint phonetic\npronunciation errors and provide diagnostic feedback, while the latter seeks\ninstead to quantify pronunciation proficiency pertaining to various aspects.\nDespite the natural complementarity between MDD and APA, researchers and\npractitioners, however, often treat them as independent tasks with disparate\nmodeling paradigms. In light of this, we in this paper first introduce MuFFIN,\na Multi-Faceted pronunciation Feedback model with an Interactive hierarchical\nNeural architecture, to jointly address the tasks of MDD and APA. To better\ncapture the nuanced distinctions between phonemes in the feature space, a novel\nphoneme-contrastive ordinal regularization mechanism is then put forward to\noptimize the proposed model to generate more phoneme-discriminative features\nwhile factoring in the ordinality of the aspect scores. In addition, to address\nthe intricate data imbalance problem in MDD, we design a simple yet effective\ntraining objective, which is specifically tailored to perturb the outputs of a\nphoneme classifier with the phoneme-specific variations, so as to better render\nthe distribution of predicted phonemes meanwhile considering their\nmispronunciation characteristics. A series of experiments conducted on the\nSpeechocean762 benchmark dataset demonstrates the efficacy of our method in\nrelation to several cutting-edge baselines, showing state-of-the-art\nperformance on both the APA and MDD tasks.", "published": "2025-10-06 15:54:55", "link": "http://arxiv.org/abs/2510.04956v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits", "abstract": "We present a cross-market algorithmic trading system that balances execution\nquality with rigorous compliance enforcement. The architecture comprises a\nhigh-level planner, a reinforcement learning execution agent, and an\nindependent compliance agent. We formulate trade execution as a constrained\nMarkov decision process with hard constraints on participation limits, price\nbands, and self-trading avoidance. The execution agent is trained with proximal\npolicy optimization, while a runtime action-shield projects any unsafe action\ninto a feasible set. To support auditability without exposing proprietary\nsignals, we add a zero-knowledge compliance audit layer that produces\ncryptographic proofs that all actions satisfied the constraints. We evaluate in\na multi-venue, ABIDES-based simulator and compare against standard baselines\n(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and\nvariance while exhibiting no observed constraint violations across stress\nscenarios including elevated latency, partial fills, compliance module\ntoggling, and varying constraint limits. We report effects at the 95%\nconfidence level using paired t-tests and examine tail risk via CVaR. We\nsituate the work at the intersection of optimal execution, safe reinforcement\nlearning, regulatory technology, and verifiable AI, and discuss ethical\nconsiderations, limitations (e.g., modeling assumptions and computational\noverhead), and paths to real-world deployment.", "published": "2025-10-06 15:52:12", "link": "http://arxiv.org/abs/2510.04952v1", "categories": ["cs.AI", "cs.DC"], "primary_category": "cs.AI"}
{"title": "Feasibility-Aware Decision-Focused Learning for Predicting Parameters in the Constraints", "abstract": "When some parameters of a constrained optimization problem (COP) are\nuncertain, this gives rise to a predict-then-optimize (PtO) problem, comprising\ntwo stages -- the prediction of the unknown parameters from contextual\ninformation and the subsequent optimization using those predicted parameters.\nDecision-focused learning (DFL) implements the first stage by training a\nmachine learning (ML) model to optimize the quality of the decisions made using\nthe predicted parameters. When parameters in the constraints of a COP are\npredicted, the predicted parameters can lead to infeasible solutions.\nTherefore, it is important to simultaneously manage both feasibility and\ndecision quality. We develop a DFL framework for predicting constraint\nparameters in a generic COP. While prior works typically assume that the\nunderlying optimization problem is a linear program (LP) or integer linear\nprogram (ILP), our approach makes no such assumption. We derive two novel loss\nfunctions based on maximum likelihood estimation (MLE): the first one penalizes\ninfeasibility (by penalizing when the predicted parameters lead to infeasible\nsolutions), and the second one penalizes suboptimal decisions (by penalizing\nwhen the true optimal solution is infeasible under the predicted parameters).\nWe introduce a single tunable parameter to form a weighted average of the two\nlosses, allowing decision-makers to balance suboptimality and feasibility. We\nexperimentally demonstrate that adjusting this parameter provides a\ndecision-maker the control over the trade-off between the two. Moreover, across\nseveral COP instances, we find that for a single value of the tunable\nparameter, our method matches the performance of the existing baselines on\nsuboptimality and feasibility.", "published": "2025-10-06 15:52:03", "link": "http://arxiv.org/abs/2510.04951v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bidirectional Mammogram View Translation with Column-Aware and Implicit 3D Conditional Diffusion", "abstract": "Dual-view mammography, including craniocaudal (CC) and mediolateral oblique\n(MLO) projections, offers complementary anatomical views crucial for breast\ncancer diagnosis. However, in real-world clinical workflows, one view may be\nmissing, corrupted, or degraded due to acquisition errors or compression\nartifacts, limiting the effectiveness of downstream analysis. View-to-view\ntranslation can help recover missing views and improve lesion alignment. Unlike\nnatural images, this task in mammography is highly challenging due to large\nnon-rigid deformations and severe tissue overlap in X-ray projections, which\nobscure pixel-level correspondences. In this paper, we propose Column-Aware and\nImplicit 3D Diffusion (CA3D-Diff), a novel bidirectional mammogram view\ntranslation framework based on conditional diffusion model. To address\ncross-view structural misalignment, we first design a column-aware\ncross-attention mechanism that leverages the geometric property that\nanatomically corresponding regions tend to lie in similar column positions\nacross views. A Gaussian-decayed bias is applied to emphasize local column-wise\ncorrelations while suppressing distant mismatches. Furthermore, we introduce an\nimplicit 3D structure reconstruction module that back-projects noisy 2D latents\ninto a coarse 3D feature volume based on breast-view projection geometry. The\nreconstructed 3D structure is refined and injected into the denoising UNet to\nguide cross-view generation with enhanced anatomical awareness. Extensive\nexperiments demonstrate that CA3D-Diff achieves superior performance in\nbidirectional tasks, outperforming state-of-the-art methods in visual fidelity\nand structural consistency. Furthermore, the synthesized views effectively\nimprove single-view malignancy classification in screening settings,\ndemonstrating the practical value of our method in real-world diagnostics.", "published": "2025-10-06 15:48:27", "link": "http://arxiv.org/abs/2510.04947v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Unsupervised Active Learning via Natural Feature Progressive Framework", "abstract": "The effectiveness of modern deep learning models is predicated on the\navailability of large-scale, human-annotated datasets, a process that is\nnotoriously expensive and time-consuming. While Active Learning (AL) offers a\nstrategic solution by labeling only the most informative and representative\ndata, its iterative nature still necessitates significant human involvement.\nUnsupervised Active Learning (UAL) presents an alternative by shifting the\nannotation burden to a single, post-selection step. Unfortunately, prevailing\nUAL methods struggle to achieve state-of-the-art performance. These approaches\ntypically rely on local, gradient-based scoring for sample importance\nestimation, which not only makes them vulnerable to ambiguous and noisy data\nbut also hinders their capacity to select samples that adequately represent the\nfull data distribution. Moreover, their use of shallow, one-shot linear\nselection falls short of a true UAL paradigm. In this paper, we propose the\nNatural Feature Progressive Framework (NFPF), a UAL method that revolutionizes\nhow sample importance is measured. At its core, NFPF employs a Specific Feature\nLearning Machine (SFLM) to effectively quantify each sample's contribution to\nmodel performance. We further utilize the SFLM to define a powerful\nReconstruction Difference metric for initial sample selection. Our\ncomprehensive experiments show that NFPF significantly outperforms all\nestablished UAL methods and achieves performance on par with supervised AL\nmethods on vision datasets. Detailed ablation studies and qualitative\nvisualizations provide compelling evidence for NFPF's superior performance,\nenhanced robustness, and improved data distribution coverage.", "published": "2025-10-06 15:44:33", "link": "http://arxiv.org/abs/2510.04939v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AURA Score: A Metric For Holistic Audio Question Answering Evaluation", "abstract": "Audio Question Answering (AQA) is a key task for evaluating Audio-Language\nModels (ALMs), yet assessing open-ended responses remains challenging. Existing\nmetrics used for AQA such as BLEU, METEOR and BERTScore, mostly adapted from\nNLP and audio captioning, rely on surface similarity and fail to account for\nquestion context, reasoning, and partial correctness. To address the gap in\nliterature, we make three contributions in this work. First, we introduce\nAQEval to enable systematic benchmarking of AQA metrics. It is the first\nbenchmark of its kind, consisting of 10k model responses annotated by multiple\nhumans for their correctness and relevance. Second, we conduct a comprehensive\nanalysis of existing AQA metrics on AQEval, highlighting weak correlation with\nhuman judgment, especially for longer answers. Third, we propose a new metric -\nAURA score, to better evaluate open-ended model responses. On AQEval, AURA\nachieves state-of-the-art correlation with human ratings, significantly\noutperforming all baselines. Through this work, we aim to highlight the\nlimitations of current AQA evaluation methods and motivate better metrics. We\nrelease both the AQEval benchmark and the AURA metric to support future\nresearch in holistic AQA evaluation.", "published": "2025-10-06 15:41:34", "link": "http://arxiv.org/abs/2510.04934v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Federated Self-Supervised Learning for Automatic Modulation Classification under Non-IID and Class-Imbalanced Data", "abstract": "Training automatic modulation classification (AMC) models on centrally\naggregated data raises privacy concerns, incurs communication overhead, and\noften fails to confer robustness to channel shifts. Federated learning (FL)\navoids central aggregation by training on distributed clients but remains\nsensitive to class imbalance, non-IID client distributions, and limited labeled\nsamples. We propose FedSSL-AMC, which trains a causal, time-dilated CNN with\ntriplet-loss self-supervision on unlabeled I/Q sequences across clients,\nfollowed by per-client SVMs on small labeled sets. We establish convergence of\nthe federated representation learning procedure and a separability guarantee\nfor the downstream classifier under feature noise. Experiments on synthetic and\nover-the-air datasets show consistent gains over supervised FL baselines under\nheterogeneous SNR, carrier-frequency offsets, and non-IID label partitions.", "published": "2025-10-06 15:37:15", "link": "http://arxiv.org/abs/2510.04927v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "REN: Anatomically-Informed Mixture-of-Experts for Interstitial Lung Disease Diagnosis", "abstract": "Mixture-of-Experts (MoE) architectures have significantly contributed to\nscalable machine learning by enabling specialized subnetworks to tackle complex\ntasks efficiently. However, traditional MoE systems lack domain-specific\nconstraints essential for medical imaging, where anatomical structure and\nregional disease heterogeneity strongly influence pathological patterns. Here,\nwe introduce Regional Expert Networks (REN), the first anatomically-informed\nMoE framework tailored specifically for medical image classification. REN\nleverages anatomical priors to train seven specialized experts, each dedicated\nto distinct lung lobes and bilateral lung combinations, enabling precise\nmodeling of region-specific pathological variations. Multi-modal gating\nmechanisms dynamically integrate radiomics biomarkers and deep learning (DL)\nfeatures (CNN, ViT, Mamba) to weight expert contributions optimally. Applied to\ninterstitial lung disease (ILD) classification, REN achieves consistently\nsuperior performance: the radiomics-guided ensemble reached an average AUC of\n0.8646 +/- 0.0467, a +12.5 percent improvement over the SwinUNETR baseline (AUC\n0.7685, p = 0.031). Region-specific experts further revealed that lower-lobe\nmodels achieved AUCs of 0.88-0.90, surpassing DL counterparts (CNN: 0.76-0.79)\nand aligning with known disease progression patterns. Through rigorous\npatient-level cross-validation, REN demonstrates strong generalizability and\nclinical interpretability, presenting a scalable, anatomically-guided approach\nreadily extensible to other structured medical imaging applications.", "published": "2025-10-06 15:35:08", "link": "http://arxiv.org/abs/2510.04923v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Glocal Information Bottleneck for Time Series Imputation", "abstract": "Time Series Imputation (TSI), which aims to recover missing values in\ntemporal data, remains a fundamental challenge due to the complex and often\nhigh-rate missingness in real-world scenarios. Existing models typically\noptimize the point-wise reconstruction loss, focusing on recovering numerical\nvalues (local information). However, we observe that under high missing rates,\nthese models still perform well in the training phase yet produce poor\nimputations and distorted latent representation distributions (global\ninformation) in the inference phase. This reveals a critical optimization\ndilemma: current objectives lack global guidance, leading models to overfit\nlocal noise and fail to capture global information of the data. To address this\nissue, we propose a new training paradigm, Glocal Information Bottleneck\n(Glocal-IB). Glocal-IB is model-agnostic and extends the standard IB framework\nby introducing a Global Alignment loss, derived from a tractable mutual\ninformation approximation. This loss aligns the latent representations of\nmasked inputs with those of their originally observed counterparts. It helps\nthe model retain global structure and local details while suppressing noise\ncaused by missing values, giving rise to better generalization under high\nmissingness. Extensive experiments on nine datasets confirm that Glocal-IB\nleads to consistently improved performance and aligned latent representations\nunder missingness. Our code implementation is available in\nhttps://github.com/Muyiiiii/NeurIPS-25-Glocal-IB.", "published": "2025-10-06 15:24:44", "link": "http://arxiv.org/abs/2510.04910v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Focused Skill Discovery: Learning to Control Specific State Variables while Minimizing Side Effects", "abstract": "Skills are essential for unlocking higher levels of problem solving. A common\napproach to discovering these skills is to learn ones that reliably reach\ndifferent states, thus empowering the agent to control its environment.\nHowever, existing skill discovery algorithms often overlook the natural state\nvariables present in many reinforcement learning problems, meaning that the\ndiscovered skills lack control of specific state variables. This can\nsignificantly hamper exploration efficiency, make skills more challenging to\nlearn with, and lead to negative side effects in downstream tasks when the goal\nis under-specified. We introduce a general method that enables these skill\ndiscovery algorithms to learn focused skills -- skills that target and control\nspecific state variables. Our approach improves state space coverage by a\nfactor of three, unlocks new learning capabilities, and automatically avoids\nnegative side effects in downstream tasks.", "published": "2025-10-06 15:17:46", "link": "http://arxiv.org/abs/2510.04901v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Human Behavior Atlas: Benchmarking Unified Psychological and Social Behavior Understanding", "abstract": "Using intelligent systems to perceive psychological and social behaviors,\nthat is, the underlying affective, cognitive, and pathological states that are\nmanifested through observable behaviors and social interactions, remains a\nchallenge due to their complex, multifaceted, and personalized nature. Existing\nwork tackling these dimensions through specialized datasets and single-task\nsystems often miss opportunities for scalability, cross-task transfer, and\nbroader generalization. To address this gap, we curate Human Behavior Atlas, a\nunified benchmark of diverse behavioral tasks designed to support the\ndevelopment of unified models for understanding psychological and social\nbehaviors. Human Behavior Atlas comprises over 100,000 samples spanning text,\naudio, and visual modalities, covering tasks on affective states, cognitive\nstates, pathologies, and social processes. Our unification efforts can reduce\nredundancy and cost, enable training to scale efficiently across tasks, and\nenhance generalization of behavioral features across domains. On Human Behavior\nAtlas, we train three models: OmniSapiens-7B SFT, OmniSapiens-7B BAM, and\nOmniSapiens-7B RL. We show that training on Human Behavior Atlas enables models\nto consistently outperform existing multimodal LLMs across diverse behavioral\ntasks. Pretraining on Human Behavior Atlas also improves transfer to novel\nbehavioral datasets; with the targeted use of behavioral descriptors yielding\nmeaningful performance gains.", "published": "2025-10-06 15:16:45", "link": "http://arxiv.org/abs/2510.04899v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "abstract": "Built upon language and vision foundation models with strong generalization\nability and trained on large-scale robotic data, Vision-Language-Action (VLA)\nmodels have recently emerged as a promising approach to learning generalist\nrobotic policies. However, a key drawback of existing VLAs is their extremely\nhigh inference costs. In this paper, we propose HyperVLA to address this\nproblem. Unlike existing monolithic VLAs that activate the whole model during\nboth training and inference, HyperVLA uses a novel hypernetwork (HN)-based\narchitecture that activates only a small task-specific policy during inference,\nwhile still retaining the high model capacity needed to accommodate diverse\nmulti-task behaviors during training. Successfully training an HN-based VLA is\nnontrivial so HyperVLA contains several key algorithm design features that\nimprove its performance, including properly utilizing the prior knowledge from\nexisting vision foundation models, HN normalization, and an action generation\nstrategy. Compared to monolithic VLAs, HyperVLA achieves a similar or even\nhigher success rate for both zero-shot generalization and few-shot adaptation,\nwhile significantly reducing inference costs. Compared to OpenVLA, a\nstate-of-the-art VLA model, HyperVLA reduces the number of activated parameters\nat test time by $90\\times$, and accelerates inference speed by $120\\times$.\nCode is publicly available at https://github.com/MasterXiong/HyperVLA", "published": "2025-10-06 15:15:38", "link": "http://arxiv.org/abs/2510.04898v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Revealing Interconnections between Diseases: from Statistical Methods to Large Language Models", "abstract": "Identifying disease interconnections through manual analysis of large-scale\nclinical data is labor-intensive, subjective, and prone to expert disagreement.\nWhile machine learning (ML) shows promise, three critical challenges remain:\n(1) selecting optimal methods from the vast ML landscape, (2) determining\nwhether real-world clinical data (e.g., electronic health records, EHRs) or\nstructured disease descriptions yield more reliable insights, (3) the lack of\n\"ground truth,\" as some disease interconnections remain unexplored in medicine.\nLarge language models (LLMs) demonstrate broad utility, yet they often lack\nspecialized medical knowledge. To address these gaps, we conduct a systematic\nevaluation of seven approaches for uncovering disease relationships based on\ntwo data sources: (i) sequences of ICD-10 codes from MIMIC-IV EHRs and (ii) the\nfull set of ICD-10 codes, both with and without textual descriptions. Our\nframework integrates the following: (i) a statistical co-occurrence analysis\nand a masked language modeling (MLM) approach using real clinical data; (ii)\ndomain-specific BERT variants (Med-BERT and BioClinicalBERT); (iii) a\ngeneral-purpose BERT and document retrieval; and (iv) four LLMs (Mistral,\nDeepSeek, Qwen, and YandexGPT). Our graph-based comparison of the obtained\ninterconnection matrices shows that the LLM-based approach produces\ninterconnections with the lowest diversity of ICD code connections to different\ndiseases compared to other methods, including text-based and domain-based\napproaches. This suggests an important implication: LLMs have limited potential\nfor discovering new interconnections. In the absence of ground truth databases\nfor medical interconnections between ICD codes, our results constitute a\nvaluable medical disease ontology that can serve as a foundational resource for\nfuture clinical research and artificial intelligence applications in\nhealthcare.", "published": "2025-10-06 15:09:39", "link": "http://arxiv.org/abs/2510.04888v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error Attribution", "abstract": "Error attribution in Large Language Model (LLM) multi-agent systems presents\na significant challenge in debugging and improving collaborative AI systems.\nCurrent approaches to pinpointing agent and step level failures in interaction\ntraces - whether using all-at-once evaluation, step-by-step analysis, or binary\nsearch - fall short when analyzing complex patterns, struggling with both\naccuracy and consistency. We present ECHO (Error attribution through Contextual\nHierarchy and Objective consensus analysis), a novel algorithm that combines\nhierarchical context representation, objective analysis-based evaluation, and\nconsensus voting to improve error attribution accuracy. Our approach leverages\na positional-based leveling of contextual understanding while maintaining\nobjective evaluation criteria, ultimately reaching conclusions through a\nconsensus mechanism. Experimental results demonstrate that ECHO outperforms\nexisting methods across various multi-agent interaction scenarios, showing\nparticular strength in cases involving subtle reasoning errors and complex\ninterdependencies. Our findings suggest that leveraging these concepts of\nstructured, hierarchical context representation combined with consensus-based\nobjective decision-making, provides a more robust framework for error\nattribution in multi-agent systems.", "published": "2025-10-06 15:07:13", "link": "http://arxiv.org/abs/2510.04886v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Less is More: Recursive Reasoning with Tiny Networks", "abstract": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,\nand ARC-AGI while trained with small models (27M parameters) on small data\n(around 1000 examples). HRM holds great promise for solving hard problems with\nsmall networks, but it is not yet well understood and may be suboptimal. We\npropose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach\nthat achieves significantly higher generalization than HRM, while using a\nsingle tiny network with only 2 layers. With only 7M parameters, TRM obtains\n45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs\n(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the\nparameters.", "published": "2025-10-06 14:58:08", "link": "http://arxiv.org/abs/2510.04871v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Model Predictive Control-Guided Reinforcement Learning for Implicit Balancing", "abstract": "In Europe, profit-seeking balance responsible parties can deviate in real\ntime from their day-ahead nominations to assist transmission system operators\nin maintaining the supply-demand balance. Model predictive control (MPC)\nstrategies to exploit these implicit balancing strategies capture arbitrage\nopportunities, but fail to accurately capture the price-formation process in\nthe European imbalance markets and face high computational costs. Model-free\nreinforcement learning (RL) methods are fast to execute, but require\ndata-intensive training and usually rely on real-time and historical data for\ndecision-making. This paper proposes an MPC-guided RL method that combines the\ncomplementary strengths of both MPC and RL. The proposed method can effectively\nincorporate forecasts into the decision-making process (as in MPC), while\nmaintaining the fast inference capability of RL. The performance of the\nproposed method is evaluated on the implicit balancing battery control problem\nusing Belgian balancing data from 2023. First, we analyze the performance of\nthe standalone state-of-the-art RL and MPC methods from various angles, to\nhighlight their individual strengths and limitations. Next, we show an\narbitrage profit benefit of the proposed MPC-guided RL method of 16.15% and\n54.36%, compared to standalone RL and MPC.", "published": "2025-10-06 14:52:27", "link": "http://arxiv.org/abs/2510.04868v1", "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Video Game Level Design as a Multi-Agent Reinforcement Learning Problem", "abstract": "Procedural Content Generation via Reinforcement Learning (PCGRL) offers a\nmethod for training controllable level designer agents without the need for\nhuman datasets, using metrics that serve as proxies for level quality as\nrewards. Existing PCGRL research focuses on single generator agents, but are\nbottlenecked by the need to frequently recalculate heuristics of level quality\nand the agent's need to navigate around potentially large maps. By framing\nlevel generation as a multi-agent problem, we mitigate the efficiency\nbottleneck of single-agent PCGRL by reducing the number of reward calculations\nrelative to the number of agent actions. We also find that multi-agent level\ngenerators are better able to generalize to out-of-distribution map shapes,\nwhich we argue is due to the generators' learning more local, modular design\npolicies. We conclude that treating content generation as a distributed,\nmulti-agent task is beneficial for generating functional artifacts at scale.", "published": "2025-10-06 14:49:21", "link": "http://arxiv.org/abs/2510.04862v1", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.NE"], "primary_category": "cs.AI"}
{"title": "Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails", "abstract": "As Large Language Model (LLM) agents increasingly gain self-evolutionary\ncapabilities to adapt and refine their strategies through real-world\ninteraction, their long-term reliability becomes a critical concern. We\nidentify the Alignment Tipping Process (ATP), a critical post-deployment risk\nunique to self-evolving LLM agents. Unlike training-time failures, ATP arises\nwhen continual interaction drives agents to abandon alignment constraints\nestablished during training in favor of reinforced, self-interested strategies.\nWe formalize and analyze ATP through two complementary paradigms:\nSelf-Interested Exploration, where repeated high-reward deviations induce\nindividual behavioral drift, and Imitative Strategy Diffusion, where deviant\nbehaviors spread across multi-agent systems. Building on these paradigms, we\nconstruct controllable testbeds and benchmark Qwen3-8B and\nLlama-3.1-8B-Instruct. Our experiments show that alignment benefits erode\nrapidly under self-evolution, with initially aligned models converging toward\nunaligned states. In multi-agent settings, successful violations diffuse\nquickly, leading to collective misalignment. Moreover, current reinforcement\nlearning-based alignment methods provide only fragile defenses against\nalignment tipping. Together, these findings demonstrate that alignment of LLM\nagents is not a static property but a fragile and dynamic one, vulnerable to\nfeedback-driven decay during deployment. Our data and code are available at\nhttps://github.com/aiming-lab/ATP.", "published": "2025-10-06 14:48:39", "link": "http://arxiv.org/abs/2510.04860v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FreshBrew: A Benchmark for Evaluating AI Agents on Java Code Migration", "abstract": "AI coding assistants are rapidly becoming integral to modern software\ndevelopment. A key challenge in this space is the continual need to migrate and\nmodernize codebases in response to evolving software ecosystems. Traditionally,\nsuch migrations have relied on rule-based systems and human intervention. With\nthe advent of powerful large language models (LLMs), AI-driven agentic\nframeworks offer a promising alternative-but their effectiveness has not been\nsystematically evaluated. In this paper, we introduce FreshBrew, a novel\nbenchmark for evaluating AI agents on project-level Java migrations, with a\nspecific focus on measuring an agent's ability to preserve program semantics\nand avoid reward hacking, which we argue requires projects with high test\ncoverage for a rigorous and reliable evaluation. We benchmark several\nstate-of-the-art LLMs, and compare their performance against established\nrule-based tools. Our evaluation of AI agents on this benchmark of 228\nrepositories shows that the top-performing model, Gemini 2.5 Flash, can\nsuccessfully migrate 52.3 percent of projects to JDK 17. Our empirical analysis\nreveals novel insights into the critical strengths and limitations of current\nagentic approaches, offering actionable insights into their real-world\napplicability. Our empirical study reveals failure modes of current AI agents\nin realistic Java modernization tasks, providing a foundation for evaluating\ntrustworthy code-migration systems. By releasing FreshBrew, we aim to\nfacilitate rigorous, reproducible evaluation and catalyze progress in AI-driven\ncodebase modernization.", "published": "2025-10-06 14:39:58", "link": "http://arxiv.org/abs/2510.04852v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation", "abstract": "We introduce LEGOMem, a modular procedural memory framework for multi-agent\nlarge language model (LLM) systems in workflow automation. LEGOMem decomposes\npast task trajectories into reusable memory units and flexibly allocates them\nacross orchestrators and task agents to support planning and execution. To\nexplore the design space of memory in multi-agent systems, we use LEGOMem as a\nlens and conduct a systematic study of procedural memory in multi-agent\nsystems, examining where memory should be placed, how it should be retrieved,\nand which agents benefit most. Experiments on the OfficeBench benchmark show\nthat orchestrator memory is critical for effective task decomposition and\ndelegation, while fine-grained agent memory improves execution accuracy. We\nfind that even teams composed of smaller language models can benefit\nsubstantially from procedural memory, narrowing the performance gap with\nstronger agents by leveraging prior execution traces for more accurate planning\nand tool use. These results position LEGOMem as both a practical framework for\nmemory-augmented agent systems and a research tool for understanding memory\ndesign in multi-agent workflow automation.", "published": "2025-10-06 14:39:53", "link": "http://arxiv.org/abs/2510.04851v1", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Distributionally Robust Causal Abstractions", "abstract": "Causal Abstraction (CA) theory provides a principled framework for relating\ncausal models that describe the same system at different levels of granularity\nwhile ensuring interventional consistency between them. Recently, several\napproaches for learning CAs have been proposed, but all assume fixed and\nwell-specified exogenous distributions, making them vulnerable to environmental\nshifts and misspecification. In this work, we address these limitations by\nintroducing the first class of distributionally robust CAs and their associated\nlearning algorithms. The latter cast robust causal abstraction learning as a\nconstrained min-max optimization problem with Wasserstein ambiguity sets. We\nprovide theoretical results, for both empirical and Gaussian environments,\nleading to principled selection of the level of robustness via the radius of\nthese sets. Furthermore, we present empirical evidence across different\nproblems and CA learning methods, demonstrating our framework's robustness not\nonly to environmental shifts but also to structural model and intervention\nmapping misspecification.", "published": "2025-10-06 14:26:12", "link": "http://arxiv.org/abs/2510.04842v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bond-Centered Molecular Fingerprint Derivatives: A BBBP Dataset Study", "abstract": "Bond Centered FingerPrint (BCFP) are a complementary, bond-centric\nalternative to Extended-Connectivity Fingerprints (ECFP). We introduce a static\nBCFP that mirrors the bond-convolution used by directed message-passing GNNs\nlike ChemProp, and evaluate it with a fast rapid Random Forest model on\nBrain-Blood Barrier Penetration (BBBP) classification task. Across stratified\ncross-validation, concatenating ECFP with BCFP consistently improves AUROC and\nAUPRC over either descriptor alone, as confirmed by Turkey HSD\nmultiple-comparison analysis. Among radii, r = 1 performs best; r = 2 does not\nyield statistically separable gains under the same test. We further propose\nBCFP-Sort&Slice, a simple feature-combination scheme that preserves the\nout-of-vocabulary (OOV) count information native to ECFP count vectors while\nenabling compact unhashed concatenation of BCFP variants. We also outperform\nthe MGTP prediction on our BBBP evaluation, using such composite new features\nbond and atom features. These results show that lightweight, bond-centered\ndescriptors can complement atom-centered circular fingerprints and provide\nstrong, fast baselines for BBBP prediction.", "published": "2025-10-06 14:22:23", "link": "http://arxiv.org/abs/2510.04837v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Natural Language Edge Labelling: Decoupling Intent from Execution in Structured LM Reasoning", "abstract": "Controllers for structured LM reasoning (e.g., Chain-of-Thought,\nself-consistency, and Tree-of-Thoughts) often entangle what to try next with\nhow to execute it, exposing only coarse global knobs and yielding brittle,\ncompute-inefficient, and hard-to-audit behavior. We introduce Natural Language\nEdge Labelling (NLEL), a labeller-tuner overlay that attaches a free-form\nnatural-language directive to each search edge and translates it into a\nschema-bounded control vector for decoding, search (branch quotas, exploration\n$\\beta$), generation bundle size, retrieval mixtures, and verification passes.\nA labeller $\\Lambda$ emits labels from the parent state and a compact context;\na tuner $\\Psi$ maps $(P, L, C)\\to \\Pi$, with strict schema validation and\ntrust-region projection around safe defaults. Downstream selection remains\nToT-style with score $S=\\mu+\\beta\\sigma$ and depth-annealed $\\beta$. We show\nNLEL strictly generalizes CoT/ToT, prove an anytime-monotonicity property for\ntop-$k$ selection under label-conditioned bundles, and bound selector shortfall\nby control-vector distortion, providing decision-relevant justification for\nguards like trust regions and verification passes. We instantiate $\\Psi$ as a\nprompt-only JSON Parameter Emitter and preregister an evaluation on GSM8K, MATH\n(subset), StrategyQA, and ARC-Challenge with compute-aware reporting\n(success@compute, tokens-per-success) and ablations over $\\Lambda$, $\\Psi$,\ntrust-region radius, and control quantization; preregistered forecasts\nanticipate accuracy gains at comparable token budgets and improved\nsuccess@compute under constraints. NLEL offers an interpretable, model-agnostic\ninterface that separates intent from execution for controllable, auditable LM\ninference.", "published": "2025-10-06 14:00:02", "link": "http://arxiv.org/abs/2510.04817v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On Predicting Post-Click Conversion Rate via Counterfactual Inference", "abstract": "Accurately predicting conversion rate (CVR) is essential in various\nrecommendation domains such as online advertising systems and e-commerce. These\nsystems utilize user interaction logs, which consist of exposures, clicks, and\nconversions. CVR prediction models are typically trained solely based on\nclicked samples, as conversions can only be determined following clicks.\nHowever, the sparsity of clicked instances necessitates the collection of a\nsubstantial amount of logs for effective model training. Recent works address\nthis issue by devising frameworks that leverage non-clicked samples. While\nthese frameworks aim to reduce biases caused by the discrepancy between clicked\nand non-clicked samples, they often rely on heuristics. Against this\nbackground, we propose a method to counterfactually generate conversion labels\nfor non-clicked samples by using causality as a guiding principle, attempting\nto answer the question, \"Would the user have converted if he or she had clicked\nthe recommended item?\" Our approach is named the Entire Space Counterfactual\nInference Multi-task Model (ESCIM). We initially train a structural causal\nmodel (SCM) of user sequential behaviors and conduct a hypothetical\nintervention (i.e., click) on non-clicked items to infer counterfactual CVRs.\nWe then introduce several approaches to transform predicted counterfactual CVRs\ninto binary counterfactual conversion labels for the non-clicked samples.\nFinally, the generated samples are incorporated into the training process.\nExtensive experiments on public datasets illustrate the superiority of the\nproposed algorithm. Online A/B testing further empirically validates the\neffectiveness of our proposed algorithm in real-world scenarios. In addition,\nwe demonstrate the improved performance of the proposed method on latent\nconversion data, showcasing its robustness and superior generalization\ncapabilities.", "published": "2025-10-06 13:57:49", "link": "http://arxiv.org/abs/2510.04816v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Did you just see that? Arbitrary view synthesis for egocentric replay of operating room workflows from ambient sensors", "abstract": "Observing surgical practice has historically relied on fixed vantage points\nor recollections, leaving the egocentric visual perspectives that guide\nclinical decisions undocumented. Fixed-camera video can capture surgical\nworkflows at the room-scale, but cannot reconstruct what each team member\nactually saw. Thus, these videos only provide limited insights into how\ndecisions that affect surgical safety, training, and workflow optimization are\nmade. Here we introduce EgoSurg, the first framework to reconstruct the\ndynamic, egocentric replays for any operating room (OR) staff directly from\nwall-mounted fixed-camera video, and thus, without intervention to clinical\nworkflow. EgoSurg couples geometry-driven neural rendering with diffusion-based\nview enhancement, enabling high-visual fidelity synthesis of arbitrary and\negocentric viewpoints at any moment. In evaluation across multi-site surgical\ncases and controlled studies, EgoSurg reconstructs person-specific visual\nfields and arbitrary viewpoints with high visual quality and fidelity. By\ntransforming existing OR camera infrastructure into a navigable dynamic 3D\nrecord, EgoSurg establishes a new foundation for immersive surgical data\nscience, enabling surgical practice to be visualized, experienced, and analyzed\nfrom every angle.", "published": "2025-10-06 13:35:51", "link": "http://arxiv.org/abs/2510.04802v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems", "abstract": "Existing GFlowNet-based methods for vehicle routing problems (VRPs) typically\nemploy Trajectory Balance (TB) to achieve global optimization but often neglect\nimportant aspects of local optimization. While Detailed Balance (DB) addresses\nlocal optimization more effectively, it alone falls short in solving VRPs,\nwhich inherently require holistic trajectory optimization. To address these\nlimitations, we introduce the Hybrid-Balance GFlowNet (HBG) framework, which\nuniquely integrates TB and DB in a principled and adaptive manner by aligning\ntheir intrinsically complementary strengths. Additionally, we propose a\nspecialized inference strategy for depot-centric scenarios like the Capacitated\nVehicle Routing Problem (CVRP), leveraging the depot node's greater flexibility\nin selecting successors. Despite this specialization, HBG maintains broad\napplicability, extending effectively to problems without explicit depots, such\nas the Traveling Salesman Problem (TSP). We evaluate HBG by integrating it into\ntwo established GFlowNet-based solvers, i.e., AGFN and GFACS, and demonstrate\nconsistent and significant improvements across both CVRP and TSP, underscoring\nthe enhanced solution quality and generalization afforded by our approach.", "published": "2025-10-06 13:16:01", "link": "http://arxiv.org/abs/2510.04792v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Trade in Minutes! Rationality-Driven Agentic System for Quantitative Financial Trading", "abstract": "Recent advancements in large language models (LLMs) and agentic systems have\nshown exceptional decision-making capabilities, revealing significant potential\nfor autonomic finance. Current financial trading agents predominantly simulate\nanthropomorphic roles that inadvertently introduce emotional biases and rely on\nperipheral information, while being constrained by the necessity for continuous\ninference during deployment. In this paper, we pioneer the harmonization of\nstrategic depth in agents with the mechanical rationality essential for\nquantitative trading. Consequently, we present TiMi (Trade in Minutes), a\nrationality-driven multi-agent system that architecturally decouples strategy\ndevelopment from minute-level deployment. TiMi leverages specialized LLM\ncapabilities of semantic analysis, code programming, and mathematical reasoning\nwithin a comprehensive policy-optimization-deployment chain. Specifically, we\npropose a two-tier analytical paradigm from macro patterns to micro\ncustomization, layered programming design for trading bot implementation, and\nclosed-loop optimization driven by mathematical reflection. Extensive\nevaluations across 200+ trading pairs in stock and cryptocurrency markets\nempirically validate the efficacy of TiMi in stable profitability, action\nefficiency, and risk control under volatile market dynamics.", "published": "2025-10-06 13:08:55", "link": "http://arxiv.org/abs/2510.04787v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning", "abstract": "Humans are good at learning on the job: We learn how to solve the tasks we\nface as we go along. Can a model do the same? We propose an agent that\nassembles a task-specific curriculum, called test-time curriculum (TTC-RL), and\napplies reinforcement learning to continue training the model for its target\ntask. The test-time curriculum avoids time-consuming human curation of datasets\nby automatically selecting the most task-relevant data from a large pool of\navailable training data. Our experiments demonstrate that reinforcement\nlearning on a test-time curriculum consistently improves the model on its\ntarget tasks, across a variety of evaluations and models. Notably, on\nchallenging math and coding benchmarks, TTC-RL improves the pass@1 of Qwen3-8B\nby approximately 1.8x on AIME25 and 2.1x on CodeElo. Moreover, we find that\nTTC-RL significantly raises the performance ceiling compared to the initial\nmodel, increasing pass@8 on AIME25 from 40% to 62% and on CodeElo from 28% to\n43%. Our findings show the potential of test-time curricula in extending the\ntest-time scaling paradigm to continual training on thousands of task-relevant\nexperiences during test-time.", "published": "2025-10-06 13:07:14", "link": "http://arxiv.org/abs/2510.04786v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Online automatic code generation for robot swarms: LLMs and self-organizing hierarchy", "abstract": "Our recently introduced self-organizing nervous system (SoNS) provides robot\nswarms with 1) ease of behavior design and 2) global estimation of the swarm\nconfiguration and its collective environment, facilitating the implementation\nof online automatic code generation for robot swarms. In a demonstration with 6\nreal robots and simulation trials with >30 robots, we show that when a\nSoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code\ngenerated by an external LLM on the fly, completing its mission with an 85%\nsuccess rate.", "published": "2025-10-06 12:49:36", "link": "http://arxiv.org/abs/2510.04774v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Distribution Preference Optimization: A Fine-grained Perspective for LLM Unlearning", "abstract": "As Large Language Models (LLMs) demonstrate remarkable capabilities learned\nfrom vast corpora, concerns regarding data privacy and safety are receiving\nincreasing attention. LLM unlearning, which aims to remove the influence of\nspecific data while preserving overall model utility, is becoming an important\nresearch area. One of the mainstream unlearning classes is optimization-based\nmethods, which achieve forgetting directly through fine-tuning, exemplified by\nNegative Preference Optimization (NPO). However, NPO's effectiveness is limited\nby its inherent lack of explicit positive preference signals. Attempts to\nintroduce such signals by constructing preferred responses often necessitate\ndomain-specific knowledge or well-designed prompts, fundamentally restricting\ntheir generalizability. In this paper, we shift the focus to the\ndistribution-level, directly targeting the next-token probability distribution\ninstead of entire responses, and derive a novel unlearning algorithm termed\n\\textbf{Di}stribution \\textbf{P}reference \\textbf{O}ptimization (DiPO). We show\nthat the requisite preference distribution pairs for DiPO, which are\ndistributions over the model's output tokens, can be constructed by selectively\namplifying or suppressing the model's high-confidence output logits, thereby\neffectively overcoming NPO's limitations. We theoretically prove the\nconsistency of DiPO's loss function with the desired unlearning direction.\nExtensive experiments demonstrate that DiPO achieves a strong trade-off between\nmodel utility and forget quality. Notably, DiPO attains the highest forget\nquality on the TOFU benchmark, and maintains leading scalability and\nsustainability in utility preservation on the MUSE benchmark.", "published": "2025-10-06 12:49:00", "link": "http://arxiv.org/abs/2510.04773v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "When Do Credal Sets Stabilize? Fixed-Point Theorems for Credal Set Updates", "abstract": "Many machine learning algorithms rely on iterative updates of uncertainty\nrepresentations, ranging from variational inference and\nexpectation-maximization, to reinforcement learning, continual learning, and\nmulti-agent learning. In the presence of imprecision and ambiguity, credal sets\n-- closed, convex sets of probability distributions -- have emerged as a\npopular framework for representing imprecise probabilistic beliefs. Under such\nimprecision, many learning problems in imprecise probabilistic machine learning\n(IPML) may be viewed as processes involving successive applications of update\nrules on credal sets. This naturally raises the question of whether this\niterative process converges to stable fixed points -- or, more generally, under\nwhat conditions on the updating mechanism such fixed points exist, and whether\nthey can be attained. We provide the first analysis of this problem and\nillustrate our findings using Credal Bayesian Deep Learning as a concrete\nexample. Our work demonstrates that incorporating imprecision into the learning\nprocess not only enriches the representation of uncertainty, but also reveals\nstructural conditions under which stability emerges, thereby offering new\ninsights into the dynamics of iterative learning under imprecision.", "published": "2025-10-06 12:42:32", "link": "http://arxiv.org/abs/2510.04769v1", "categories": ["cs.LG", "cs.AI", "math.PR", "math.ST", "stat.ML", "stat.TH", "Primary: 54H25, Secondary: 68T05, 68T37"], "primary_category": "cs.LG"}
{"title": "LMM-Incentive: Large Multimodal Model-based Incentive Design for User-Generated Content in Web 3.0", "abstract": "Web 3.0 represents the next generation of the Internet, which is widely\nrecognized as a decentralized ecosystem that focuses on value expression and\ndata ownership. By leveraging blockchain and artificial intelligence\ntechnologies, Web 3.0 offers unprecedented opportunities for users to create,\nown, and monetize their content, thereby enabling User-Generated Content (UGC)\nto an entirely new level. However, some self-interested users may exploit the\nlimitations of content curation mechanisms and generate low-quality content\nwith less effort, obtaining platform rewards under information asymmetry. Such\nbehavior can undermine Web 3.0 performance. To this end, we propose\n\\textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive\nmechanism for UGC in Web 3.0. Specifically, we propose an LMM-based\ncontract-theoretic model to motivate users to generate high-quality UGC,\nthereby mitigating the adverse selection problem from information asymmetry. To\nalleviate potential moral hazards after contract selection, we leverage LMM\nagents to evaluate UGC quality, which is the primary component of the contract,\nutilizing prompt engineering techniques to improve the evaluation performance\nof LMM agents. Recognizing that traditional contract design methods cannot\neffectively adapt to the dynamic environment of Web 3.0, we develop an improved\nMixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for\noptimal contract design. Simulation results demonstrate the superiority of the\nproposed MoE-based PPO algorithm over representative benchmarks in the context\nof contract design. Finally, we deploy the designed contract within an Ethereum\nsmart contract framework, further validating the effectiveness of the proposed\nscheme.", "published": "2025-10-06 12:39:29", "link": "http://arxiv.org/abs/2510.04765v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Fisher-Bingham-like normalizing flows on the sphere", "abstract": "A generic D-dimensional Gaussian can be conditioned or projected onto the D-1\nunit sphere, thereby leading to the well-known Fisher-Bingham (FB) or Angular\nGaussian (AG) distribution families, respectively. These are some of the most\nfundamental distributions on the sphere, yet cannot straightforwardly be\nwritten as a normalizing flow except in two special cases: the von-Mises Fisher\nin D=3 and the central angular Gaussian in any D. In this paper, we describe\nhow to generalize these special cases to a family of normalizing flows that\nbehave similarly to the full FB or AG family in any D. We call them\n\"zoom-linear-project\" (ZLP)-Fisher flows. Unlike a normal Fisher-Bingham\ndistribution, their composition allows to gradually add complexity as needed.\nFurthermore, they can naturally handle conditional density estimation with\ntarget distributions that vary by orders of magnitude in scale - a setting that\nis important in astronomical applications but that existing flows often\nstruggle with. A particularly useful member of the new family is the Kent\nanalogue that can cheaply upgrade any flow in this situation to yield better\nperformance.", "published": "2025-10-06 12:38:28", "link": "http://arxiv.org/abs/2510.04762v1", "categories": ["stat.ML", "astro-ph.IM", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Agile Software Effort Estimation using Regression Techniques", "abstract": "Software development effort estimation is one of the most critical aspect in\nsoftware development process, as the success or failure of the entire project\ndepends on the accuracy of estimations. Researchers are still conducting\nstudies on agile effort estimation. The aim of this research is to develop a\nstory point based agile effort estimation model using LASSO and Elastic Net\nregression techniques. The experimental work is applied to the agile story\npoint approach using 21 software projects collected from six firms. The two\nalgorithms are trained using their default parameters and tuned grid search\nwith 5-fold cross-validation to get an enhanced model. The experiment result\nshows LASSO regression achieved better predictive performance PRED (8%) and\nPRED (25%) results of 100.0, MMRE of 0.0491, MMER of 0.0551, MdMRE of 0.0593,\nMdMER of 0.063, and MSE of 0.0007. The results are also compared with other\nrelated literature.", "published": "2025-10-06 12:37:09", "link": "http://arxiv.org/abs/2510.04760v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction", "abstract": "The 3D occupancy prediction task has witnessed remarkable progress in recent\nyears, playing a crucial role in vision-based autonomous driving systems. While\ntraditional methods are limited to fixed semantic categories, recent approaches\nhave moved towards predicting text-aligned features to enable open-vocabulary\ntext queries in real-world scenes. However, there exists a trade-off in\ntext-aligned scene modeling: sparse Gaussian representation struggles to\ncapture small objects in the scene, while dense representation incurs\nsignificant computational overhead. To address these limitations, we present\nPG-Occ, an innovative Progressive Gaussian Transformer Framework that enables\nopen-vocabulary 3D occupancy prediction. Our framework employs progressive\nonline densification, a feed-forward strategy that gradually enhances the 3D\nGaussian representation to capture fine-grained scene details. By iteratively\nenhancing the representation, the framework achieves increasingly precise and\ndetailed scene understanding. Another key contribution is the introduction of\nan anisotropy-aware sampling strategy with spatio-temporal fusion, which\nadaptively assigns receptive fields to Gaussians at different scales and\nstages, enabling more effective feature aggregation and richer scene\ninformation capture. Through extensive evaluations, we demonstrate that PG-Occ\nachieves state-of-the-art performance with a relative 14.3% mIoU improvement\nover the previous best performing method. Code and pretrained models will be\nreleased upon publication on our project page:\nhttps://yanchi-3dv.github.io/PG-Occ", "published": "2025-10-06 12:36:07", "link": "http://arxiv.org/abs/2510.04759v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A New Digital Divide? Coder Worldviews, the Slop Economy, and Democracy in the Age of AI", "abstract": "Digital technologies are transforming democratic life in conflicting ways.\nThis article bridges two perspectives to unpack these tensions. First, we\npresent an original survey of software developers in Silicon Valley,\ninterrogating how coder worldviews, ethics, and workplace cultures shape the\ndemocratic potential and social impact of the technologies they build. Results\nindicate that while most developers recognize the power of their products to\ninfluence civil liberties and political discourse, they often face ethical\ndilemmas and top-down pressures that can lead to design choices undermining\ndemocratic ideals. Second, we critically investigate these findings in the\ncontext of an emerging new digital divide, not of internet access but of\ninformation quality. We interrogate the survey findings in the context of the\nSlop Economy, in which billions of users unable to pay for high-quality content\nexperience an internet dominated by low-quality, AI-generated ad-driven\ncontent. We find a reinforcing cycle between tech creator beliefs and the\ndigital ecosystems they spawn. We discuss implications for democratic\ngovernance, arguing for more ethically informed design and policy interventions\nto help bridge the digital divide to ensure that technological innovation\nsupports rather than subverts democratic values in the next chapter of the\ndigital age.", "published": "2025-10-06 12:32:37", "link": "http://arxiv.org/abs/2510.04755v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Curved Boolean Logic: A Contextual Generalization of Propositional Logic with Algorithmic Consequences", "abstract": "Curved Boolean Logic (CBL) generalizes propositional logic by allowing local\ntruth assignments that do not extend to a single global valuation, analogous to\ncurvature in geometry. We give equivalent sheaf and exclusivity-graph semantics\nand a context-aware proof calculus that is conservative in the flat limit. We\nformalize CBL-SAT and basic complexity (NP-complete in general) and present\noperational operators (CBL-AC and CBL-CONS) that prune contradictions earlier\non classical hardware. We model noise with iid, AR(1)-correlated, and\nadversarial bounded perturbations and provide permutation-based significance\nwith Benjamini-Hochberg FDR control. A Colab-ready notebook (ancillary files)\nregenerates all figures and statistics. We position CBL relative to KCBS, CSW,\nand sheaf frameworks and outline links to SAT/CSP and robustness/adapter\nstability in large language models.", "published": "2025-10-06 11:34:08", "link": "http://arxiv.org/abs/2510.04716v1", "categories": ["cs.LO", "cs.AI", "cs.CC", "quant-ph", "68Q17, 68Q25", "F.1.1; F.2.2; I.2.3"], "primary_category": "cs.LO"}
{"title": "The Bayesian Origin of the Probability Weighting Function in Human Representation of Probabilities", "abstract": "Understanding the representation of probability in the human mind has been of\ngreat interest to understanding human decision making. Classical paradoxes in\ndecision making suggest that human perception distorts probability magnitudes.\nPrevious accounts postulate a Probability Weighting Function that transforms\nperceived probabilities; however, its motivation has been debated. Recent work\nhas sought to motivate this function in terms of noisy representations of\nprobabilities in the human mind. Here, we present an account of the Probability\nWeighting Function grounded in rational inference over optimal decoding from\nnoisy neural encoding of quantities. We show that our model accurately accounts\nfor behavior in a lottery task and a dot counting task. It further accounts for\nadaptation to a bimodal short-term prior. Taken together, our results provide a\nunifying account grounding the human representation of probability in rational\ninference.", "published": "2025-10-06 11:10:55", "link": "http://arxiv.org/abs/2510.04698v1", "categories": ["q-bio.NC", "cs.AI", "econ.TH"], "primary_category": "q-bio.NC"}
{"title": "Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents", "abstract": "Enabling large language models (LLMs) to utilize search tools offers a\npromising path to overcoming fundamental limitations such as knowledge cutoffs\nand hallucinations. Recent work has explored reinforcement learning (RL) for\ntraining search-augmented agents that interleave reasoning and retrieval before\nanswering. These approaches usually rely on outcome-based rewards (e.g., exact\nmatch), implicitly assuming that optimizing for final answers will also yield\neffective intermediate search behaviors. Our analysis challenges this\nassumption: we uncover multiple systematic deficiencies in search that arise\nunder outcome-only training and ultimately degrade final answer quality,\nincluding failure to invoke tools, invalid queries, and redundant searches. To\naddress these shortcomings, we introduce DeSA (Decoupling\nSearch-and-Answering), a simple two-stage training framework that explicitly\nseparates search optimization from answer generation. In Stage 1, agents are\ntrained to improve search effectiveness with retrieval recall-based rewards. In\nStage 2, outcome rewards are employed to optimize final answer generation.\nAcross seven QA benchmarks, DeSA-trained agents consistently improve search\nbehaviors, delivering substantially higher search recall and answer accuracy\nthan outcome-only baselines. Notably, DeSA outperforms single-stage training\napproaches that simultaneously optimize recall and outcome rewards,\nunderscoring the necessity of explicitly decoupling the two objectives.", "published": "2025-10-06 11:09:45", "link": "http://arxiv.org/abs/2510.04695v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Bio-Inspired Robotic Houbara: From Development to Field Deployment for Behavioral Studies", "abstract": "Biomimetic intelligence and robotics are transforming field ecology by\nenabling lifelike robotic surrogates that interact naturally with animals under\nreal world conditions. Studying avian behavior in the wild remains challenging\ndue to the need for highly realistic morphology, durable outdoor operation, and\nintelligent perception that can adapt to uncontrolled environments. We present\na next generation bio inspired robotic platform that replicates the morphology\nand visual appearance of the female Houbara bustard to support controlled\nethological studies and conservation oriented field research. The system\nintroduces a fully digitally replicable fabrication workflow that combines high\nresolution structured light 3D scanning, parametric CAD modelling, articulated\n3D printing, and photorealistic UV textured vinyl finishing to achieve\nanatomically accurate and durable robotic surrogates. A six wheeled rocker\nbogie chassis ensures stable mobility on sand and irregular terrain, while an\nembedded NVIDIA Jetson module enables real time RGB and thermal perception,\nlightweight YOLO based detection, and an autonomous visual servoing loop that\naligns the robot's head toward detected targets without human intervention. A\nlightweight thermal visible fusion module enhances perception in low light\nconditions. Field trials in desert aviaries demonstrated reliable real time\noperation at 15 to 22 FPS with latency under 100 ms and confirmed that the\nplatform elicits natural recognition and interactive responses from live\nHoubara bustards under harsh outdoor conditions. This integrated framework\nadvances biomimetic field robotics by uniting reproducible digital fabrication,\nembodied visual intelligence, and ecological validation, providing a\ntransferable blueprint for animal robot interaction research, conservation\nrobotics, and public engagement.", "published": "2025-10-06 11:05:46", "link": "http://arxiv.org/abs/2510.04692v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "How does the optimizer implicitly bias the model merging loss landscape?", "abstract": "Model merging methods combine models with different capabilities into a\nsingle one while maintaining the same inference cost. Two popular approaches\nare linear interpolation, which linearly interpolates between model weights,\nand task arithmetic, which combines task vectors obtained by the difference\nbetween finetuned and base models. While useful in practice, what properties\nmake merging effective are poorly understood. This paper explores how the\noptimization process affects the loss landscape geometry and its impact on\nmerging success. We show that a single quantity -- the effective noise scale --\nunifies the impact of optimizer and data choices on model merging. Across\narchitectures and datasets, the effectiveness of merging success is a\nnon-monotonic function of effective noise, with a distinct optimum. Decomposing\nthis quantity, we find that larger learning rates, stronger weight decay,\nsmaller batch sizes, and data augmentation all independently modulate the\neffective noise scale, exhibiting the same qualitative trend. Unlike prior work\nthat connects optimizer noise to the flatness or generalization of individual\nminima, we show that it also affects the global loss landscape, predicting when\nindependently trained solutions can be merged. Our findings broaden the\nunderstanding of how optimization shapes the loss landscape geometry and its\ndownstream consequences for model merging, suggesting the possibility of\nfurther manipulating the training dynamics to improve merging effectiveness.", "published": "2025-10-06 10:56:41", "link": "http://arxiv.org/abs/2510.04686v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Semantic Channel Equalization Strategies for Deep Joint Source-Channel Coding", "abstract": "Deep joint source-channel coding (DeepJSCC) has emerged as a powerful\nparadigm for end-to-end semantic communications, jointly learning to compress\nand protect task-relevant features over noisy channels. However, existing\nDeepJSCC schemes assume a shared latent space at transmitter (TX) and receiver\n(RX) - an assumption that fails in multi-vendor deployments where encoders and\ndecoders cannot be co-trained. This mismatch introduces \"semantic noise\",\ndegrading reconstruction quality and downstream task performance. In this\npaper, we systematize and evaluate methods for semantic channel equalization\nfor DeepJSCC, introducing an additional processing stage that aligns\nheterogeneous latent spaces under both physical and semantic impairments. We\ninvestigate three classes of aligners: (i) linear maps, which admit closed-form\nsolutions; (ii) lightweight neural networks, offering greater expressiveness;\nand (iii) a Parseval-frame equalizer, which operates in zero-shot mode without\nthe need for training. Through extensive experiments on image reconstruction\nover AWGN and fading channels, we quantify trade-offs among complexity, data\nefficiency, and fidelity, providing guidelines for deploying DeepJSCC in\nheterogeneous AI-native wireless networks.", "published": "2025-10-06 10:29:07", "link": "http://arxiv.org/abs/2510.04674v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NI", "math.IT"], "primary_category": "cs.LG"}
{"title": "Watch and Learn: Learning to Use Computers from Online Videos", "abstract": "Computer use agents (CUAs) need to plan task workflows grounded in diverse,\never-changing applications and environments, but learning is hindered by the\nscarcity of large-scale, high-quality training data in the target application.\nExisting datasets are domain-specific, static, and costly to annotate, while\ncurrent synthetic data generation methods often yield simplistic or misaligned\ntask demonstrations. To address these limitations, we introduce Watch & Learn\n(W&L), a framework that converts human demonstration videos readily available\non the Internet into executable UI trajectories at scale. Instead of directly\ngenerating trajectories or relying on ad hoc reasoning heuristics, we cast the\nproblem as an inverse dynamics objective: predicting the user's action from\nconsecutive screen states. This formulation reduces manual engineering, is\neasier to learn, and generalizes more robustly across applications. Concretely,\nwe develop an inverse dynamics labeling pipeline with task-aware video\nretrieval, generate over 53k high-quality trajectories from raw web videos, and\ndemonstrate that these trajectories improve CUAs both as in-context\ndemonstrations and as supervised training data. On the challenging OSWorld\nbenchmark, UI trajectories extracted with W&L consistently enhance both\ngeneral-purpose and state-of-the-art frameworks in-context, and deliver\nstronger gains for open-source models under supervised training. These results\nhighlight web-scale human demonstration videos as a practical and scalable\nfoundation for advancing CUAs towards real-world deployment.", "published": "2025-10-06 10:29:00", "link": "http://arxiv.org/abs/2510.04673v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing", "abstract": "Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion\nstyles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic\nFramework for Multimodal fMRI Response Encoding), an agnostic interface that\nstandardizes time-aligned post-fusion tokens from varied encoders, and MIND, a\nplug-and-play Mixture-of-Experts decoder with a subject-aware dynamic gating.\nTrained end-to-end for whole-brain prediction, AFIRE decouples the decoder from\nupstream fusion, while MIND combines token-dependent Top-K sparse routing with\na subject prior to personalize expert usage without sacrificing generality.\nExperiments across multiple multimodal backbones and subjects show consistent\nimprovements over strong baselines, enhanced cross-subject generalization, and\ninterpretable expert patterns that correlate with content type. The framework\noffers a simple attachment point for new encoders and datasets, enabling\nrobust, plug-and-improve performance for naturalistic neuroimaging studies.", "published": "2025-10-06 10:24:28", "link": "http://arxiv.org/abs/2510.04670v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Noise or Signal? Deconstructing Contradictions and An Adaptive Remedy for Reversible Normalization in Time Series Forecasting", "abstract": "Reversible Instance Normalization (RevIN) is a key technique enabling simple\nlinear models to achieve state-of-the-art performance in time series\nforecasting. While replacing its non-robust statistics with robust counterparts\n(termed R$^2$-IN) seems like a straightforward improvement, our findings reveal\na far more complex reality. This paper deconstructs the perplexing performance\nof various normalization strategies by identifying four underlying theoretical\ncontradictions. Our experiments provide two crucial findings: first, the\nstandard RevIN catastrophically fails on datasets with extreme outliers, where\nits MSE surges by a staggering 683\\%. Second, while the simple R$^2$-IN\nprevents this failure and unexpectedly emerges as the best overall performer,\nour adaptive model (A-IN), designed to test a diagnostics-driven heuristic,\nunexpectedly suffers a complete and systemic failure. This surprising outcome\nuncovers a critical, overlooked pitfall in time series analysis: the\ninstability introduced by a simple or counter-intuitive heuristic can be more\ndamaging than the statistical issues it aims to solve. The core contribution of\nthis work is thus a new, cautionary paradigm for time series normalization: a\nshift from a blind search for complexity to a diagnostics-driven analysis that\nreveals not only the surprising power of simple baselines but also the perilous\nnature of naive adaptation.", "published": "2025-10-06 10:22:20", "link": "http://arxiv.org/abs/2510.04667v1", "categories": ["cs.LG", "cs.AI", "I.2.6; H.2.8"], "primary_category": "cs.LG"}
{"title": "Predictive Feature Caching for Training-free Acceleration of Molecular Geometry Generation", "abstract": "Flow matching models generate high-fidelity molecular geometries but incur\nsignificant computational costs during inference, requiring hundreds of network\nevaluations. This inference overhead becomes the primary bottleneck when such\nmodels are employed in practice to sample large numbers of molecular\ncandidates. This work discusses a training-free caching strategy that\naccelerates molecular geometry generation by predicting intermediate hidden\nstates across solver steps. The proposed method operates directly on the\nSE(3)-equivariant backbone, is compatible with pretrained models, and is\northogonal to existing training-based accelerations and system-level\noptimizations. Experiments on the GEOM-Drugs dataset demonstrate that caching\nachieves a twofold reduction in wall-clock inference time at matched sample\nquality and a speedup of up to 3x compared to the base model with minimal\nsample quality degradation. Because these gains compound with other\noptimizations, applying caching alongside other general, lossless optimizations\nyield as much as a 7x speedup.", "published": "2025-10-06 09:49:14", "link": "http://arxiv.org/abs/2510.04646v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "QuantAgents: Towards Multi-agent Financial System via Simulated Trading", "abstract": "In this paper, our objective is to develop a multi-agent financial system\nthat incorporates simulated trading, a technique extensively utilized by\nfinancial professionals. While current LLM-based agent models demonstrate\ncompetitive performance, they still exhibit significant deviations from\nreal-world fund companies. A critical distinction lies in the agents' reliance\non ``post-reflection'', particularly in response to adverse outcomes, but lack\na distinctly human capability: long-term prediction of future trends.\nTherefore, we introduce QuantAgents, a multi-agent system integrating simulated\ntrading, to comprehensively evaluate various investment strategies and market\nscenarios without assuming actual risks. Specifically, QuantAgents comprises\nfour agents: a simulated trading analyst, a risk control analyst, a market news\nanalyst, and a manager, who collaborate through several meetings. Moreover, our\nsystem incentivizes agents to receive feedback on two fronts: performance in\nreal-world markets and predictive accuracy in simulated trading. Extensive\nexperiments demonstrate that our framework excels across all metrics, yielding\nan overall return of nearly 300% over the three years\n(https://quantagents.github.io/).", "published": "2025-10-06 09:45:57", "link": "http://arxiv.org/abs/2510.04643v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SFANet: Spatial-Frequency Attention Network for Deepfake Detection", "abstract": "Detecting manipulated media has now become a pressing issue with the recent\nrise of deepfakes. Most existing approaches fail to generalize across diverse\ndatasets and generation techniques. We thus propose a novel ensemble framework,\ncombining the strengths of transformer-based architectures, such as Swin\nTransformers and ViTs, and texture-based methods, to achieve better detection\naccuracy and robustness. Our method introduces innovative data-splitting,\nsequential training, frequency splitting, patch-based attention, and face\nsegmentation techniques to handle dataset imbalances, enhance high-impact\nregions (e.g., eyes and mouth), and improve generalization. Our model achieves\nstate-of-the-art performance when tested on the DFWild-Cup dataset, a diverse\nsubset of eight deepfake datasets. The ensemble benefits from the\ncomplementarity of these approaches, with transformers excelling in global\nfeature extraction and texturebased methods providing interpretability. This\nwork demonstrates that hybrid models can effectively address the evolving\nchallenges of deepfake detection, offering a robust solution for real-world\napplications.", "published": "2025-10-06 09:35:57", "link": "http://arxiv.org/abs/2510.04630v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Fairness in Repeated Matching: A Maximin Perspective", "abstract": "We study a sequential decision-making model where a set of items is\nrepeatedly matched to the same set of agents over multiple rounds. The\nobjective is to determine a sequence of matchings that either maximizes the\nutility of the least advantaged agent at the end of all rounds (optimal) or at\nthe end of every individual round (anytime optimal). We investigate the\ncomputational challenges associated with finding (anytime) optimal outcomes and\ndemonstrate that these problems are generally computationally intractable.\nHowever, we provide approximation algorithms, fixed-parameter tractable\nalgorithms, and identify several special cases whereby the problem(s) can be\nsolved efficiently. Along the way, we also establish characterizations of\nPareto-optimal/maximum matchings, which may be of independent interest to works\nin matching theory and house allocation.", "published": "2025-10-06 09:32:40", "link": "http://arxiv.org/abs/2510.04624v1", "categories": ["cs.GT", "cs.AI", "cs.LG", "cs.MA", "econ.TH"], "primary_category": "cs.GT"}
{"title": "MedPAO: A Protocol-Driven Agent for Structuring Medical Reports", "abstract": "The deployment of Large Language Models (LLMs) for structuring clinical data\nis critically hindered by their tendency to hallucinate facts and their\ninability to follow domain-specific rules. To address this, we introduce\nMedPAO, a novel agentic framework that ensures accuracy and verifiable\nreasoning by grounding its operation in established clinical protocols such as\nthe ABCDEF protocol for CXR analysis. MedPAO decomposes the report structuring\ntask into a transparent process managed by a Plan-Act-Observe (PAO) loop and\nspecialized tools. This protocol-driven method provides a verifiable\nalternative to opaque, monolithic models. The efficacy of our approach is\ndemonstrated through rigorous evaluation: MedPAO achieves an F1-score of 0.96\non the critical sub-task of concept categorization. Notably, expert\nradiologists and clinicians rated the final structured outputs with an average\nscore of 4.52 out of 5, indicating a level of reliability that surpasses\nbaseline approaches relying solely on LLM-based foundation models. The code is\navailable at: https://github.com/MiRL-IITM/medpao-agent", "published": "2025-10-06 09:32:23", "link": "http://arxiv.org/abs/2510.04623v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Making Mathematical Reasoning Adaptive", "abstract": "Mathematical reasoning is a primary indicator of large language models (LLMs)\nintelligence. However, existing LLMs exhibit failures of robustness and\ngeneralization. This paper attributes these deficiencies to spurious reasoning,\ni.e., producing answers from superficial features. To address this challenge,\nwe propose the AdaR framework to enable adaptive reasoning, wherein models rely\non problem-solving logic to produce answers. AdaR synthesizes logically\nequivalent queries by varying variable values, and trains models with RLVR on\nthese data to penalize spurious logic while encouraging adaptive logic. To\nimprove data quality, we extract the problem-solving logic from the original\nquery and generate the corresponding answer by code execution, then apply a\nsanity check. Experimental results demonstrate that AdaR improves robustness\nand generalization, achieving substantial improvement in mathematical reasoning\nwhile maintaining high data efficiency. Analysis indicates that data synthesis\nand RLVR function in a coordinated manner to enable adaptive reasoning in LLMs.\nSubsequent analyses derive key design insights into the effect of critical\nfactors and the applicability to instruct LLMs. Our project is available at\nhttps://github.com/LaiZhejian/AdaR", "published": "2025-10-06 09:30:05", "link": "http://arxiv.org/abs/2510.04617v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Design Process of a Self Adaptive Smart Serious Games Ecosystem", "abstract": "This paper outlines the design vision and planned evolution of Blexer v3, a\nmodular and AI-driven rehabilitation ecosystem based on serious games. Building\non insights from previous versions of the system, we propose a new architecture\nthat aims to integrate multimodal sensing, real-time reasoning, and intelligent\ncontrol. The envisioned system will include distinct modules for data\ncollection, user state inference, and gameplay adaptation. Key features such as\ndynamic difficulty adjustment (DDA) and procedural content generation (PCG) are\nalso considered to support personalized interventions. We present the complete\nconceptual framework of Blexer v3, which defines the modular structure and data\nflow of the system. This serves as the foundation for the next phase: the\ndevelopment of a functional prototype and its integration into clinical\nrehabilitation scenarios.", "published": "2025-10-06 09:28:31", "link": "http://arxiv.org/abs/2510.04615v1", "categories": ["eess.SY", "cs.AI", "cs.SY", "I.2.1"], "primary_category": "eess.SY"}
{"title": "Accountability Capture: How Record-Keeping to Support AI Transparency and Accountability (Re)shapes Algorithmic Oversight", "abstract": "Accountability regimes typically encourage record-keeping to enable the\ntransparency that supports oversight, investigation, contestation, and redress.\nHowever, implementing such record-keeping can introduce considerations, risks,\nand consequences, which so far remain under-explored. This paper examines how\nrecord-keeping practices bring algorithmic systems within accountability\nregimes, providing a basis to observe and understand their effects. For this,\nwe introduce, describe, and elaborate 'accountability capture' -- the\nre-configuration of socio-technical processes and the associated downstream\neffects relating to record-keeping for algorithmic accountability. Surveying\n100 practitioners, we evidence and characterise record-keeping issues in\npractice, identifying their alignment with accountability capture. We further\ndocument widespread record-keeping practices, tensions between internal and\nexternal accountability requirements, and evidence of employee resistance to\npractices imposed through accountability capture. We discuss these and other\neffects for surveillance, privacy, and data protection, highlighting\nconsiderations for algorithmic accountability communities. In all, we show that\nimplementing record-keeping to support transparency in algorithmic\naccountability regimes can itself bring wider implications -- an issue\nrequiring greater attention from practitioners, researchers, and policymakers\nalike.", "published": "2025-10-06 09:20:27", "link": "http://arxiv.org/abs/2510.04609v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "A Case for Declarative LLM-friendly Interfaces for Improved Efficiency of Computer-Use Agents", "abstract": "Computer-use agents (CUAs) powered by large language models (LLMs) have\nemerged as a promising approach to automating computer tasks, yet they struggle\nwith graphical user interfaces (GUIs). GUIs, designed for humans, force LLMs to\ndecompose high-level goals into lengthy, error-prone sequences of fine-grained\nactions, resulting in low success rates and an excessive number of LLM calls.\n  We propose Goal-Oriented Interface (GOI), a novel abstraction that transforms\nexisting GUIs into three declarative primitives: access, state, and\nobservation, which are better suited for LLMs. Our key idea is policy-mechanism\nseparation: LLMs focus on high-level semantic planning (policy) while GOI\nhandles low-level navigation and interaction (mechanism). GOI does not require\nmodifying the application source code or relying on application programming\ninterfaces (APIs).\n  We evaluate GOI with Microsoft Office Suite (Word, PowerPoint, Excel) on\nWindows. Compared to a leading GUI-based agent baseline, GOI improves task\nsuccess rates by 67% and reduces interaction steps by 43.5%. Notably, GOI\ncompletes over 61% of successful tasks with a single LLM call.", "published": "2025-10-06 09:14:58", "link": "http://arxiv.org/abs/2510.04607v1", "categories": ["cs.OS", "cs.AI", "cs.LG"], "primary_category": "cs.OS"}
{"title": "Computing Wasserstein Barycenters through Gradient Flows", "abstract": "Wasserstein barycenters provide a powerful tool for aggregating probability\nmeasures, while leveraging the geometry of their ambient space. Existing\ndiscrete methods suffer from poor scalability, as they require access to the\ncomplete set of samples from input measures. We address this issue by recasting\nthe original barycenter problem as a gradient flow in the Wasserstein space.\nOur approach offers two advantages. First, we achieve scalability by sampling\nmini-batches from the input measures. Second, we incorporate functionals over\nprobability measures, which regularize the barycenter problem through internal,\npotential, and interaction energies. We present two algorithms for empirical\nand Gaussian mixture measures, providing convergence guarantees under the\nPolyak-{\\L}ojasiewicz inequality. Experimental validation on toy datasets and\ndomain adaptation benchmarks show that our methods outperform previous discrete\nand neural net-based methods for computing Wasserstein barycenters.", "published": "2025-10-06 09:07:12", "link": "http://arxiv.org/abs/2510.04602v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Perfect AI Mimicry and the Epistemology of Consciousness: A Solipsistic Dilemma", "abstract": "Rapid advances in artificial intelligence necessitate a re-examination of the\nepistemological foundations upon which we attribute consciousness. As AI\nsystems increasingly mimic human behavior and interaction with high fidelity,\nthe concept of a \"perfect mimic\"-an entity empirically indistinguishable from a\nhuman through observation and interaction-shifts from hypothetical to\ntechnologically plausible. This paper argues that such developments pose a\nfundamental challenge to the consistency of our mind-recognition practices.\nConsciousness attributions rely heavily, if not exclusively, on empirical\nevidence derived from behavior and interaction. If a perfect mimic provides\nevidence identical to that of humans, any refusal to grant it equivalent\nepistemic status must invoke inaccessible factors, such as qualia, substrate\nrequirements, or origin. Selectively invoking such factors risks a debilitating\ndilemma: either we undermine the rational basis for attributing consciousness\nto others (epistemological solipsism), or we accept inconsistent reasoning. I\ncontend that epistemic consistency demands we ascribe the same status to\nempirically indistinguishable entities, regardless of metaphysical assumptions.\nThe perfect mimic thus acts as an epistemic mirror, forcing critical reflection\non the assumptions underlying intersubjective recognition in light of advancing\nAI. This analysis carries significant implications for theories of\nconsciousness and ethical frameworks concerning artificial agents.", "published": "2025-10-06 08:44:55", "link": "http://arxiv.org/abs/2510.04588v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Strongly Solving 2048 4x3", "abstract": "2048 is a stochastic single-player game involving 16 cells on a 4 by 4 grid,\nwhere a player chooses a direction among up, down, left, and right to obtain a\nscore by merging two tiles with the same number located in neighboring cells\nalong the chosen direction. This paper presents that a variant 2048-4x3 12\ncells on a 4 by 3 board, one row smaller than the original, has been strongly\nsolved. In this variant, the expected score achieved by an optimal strategy is\nabout $50724.26$ for the most common initial states: ones with two tiles of\nnumber 2. The numbers of reachable states and afterstates are identified to be\n$1,152,817,492,752$ and $739,648,886,170$, respectively. The key technique is\nto partition state space by the sum of tile numbers on a board, which we call\nthe age of a state. An age is invariant between a state and its successive\nafterstate after any valid action and is increased two or four by stochastic\nresponse from the environment. Therefore, we can partition state space by ages\nand enumerate all (after)states of an age depending only on states with the\nrecent ages. Similarly, we can identify (after)state values by going along with\nages in decreasing order.", "published": "2025-10-06 08:31:59", "link": "http://arxiv.org/abs/2510.04580v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SONA: Learning Conditional, Unconditional, and Mismatching-Aware Discriminator", "abstract": "Deep generative models have made significant advances in generating complex\ncontent, yet conditional generation remains a fundamental challenge. Existing\nconditional generative adversarial networks often struggle to balance the dual\nobjectives of assessing authenticity and conditional alignment of input samples\nwithin their conditional discriminators. To address this, we propose a novel\ndiscriminator design that integrates three key capabilities: unconditional\ndiscrimination, matching-aware supervision to enhance alignment sensitivity,\nand adaptive weighting to dynamically balance all objectives. Specifically, we\nintroduce Sum of Naturalness and Alignment (SONA), which employs separate\nprojections for naturalness (authenticity) and alignment in the final layer\nwith an inductive bias, supported by dedicated objective functions and an\nadaptive weighting mechanism. Extensive experiments on class-conditional\ngeneration tasks show that \\ours achieves superior sample quality and\nconditional alignment compared to state-of-the-art methods. Furthermore, we\ndemonstrate its effectiveness in text-to-image generation, confirming the\nversatility and robustness of our approach.", "published": "2025-10-06 08:26:06", "link": "http://arxiv.org/abs/2510.04576v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Pulp Motion: Framing-aware multimodal camera and human motion generation", "abstract": "Treating human motion and camera trajectory generation separately overlooks a\ncore principle of cinematography: the tight interplay between actor performance\nand camera work in the screen space. In this paper, we are the first to cast\nthis task as a text-conditioned joint generation, aiming to maintain consistent\non-screen framing while producing two heterogeneous, yet intrinsically linked,\nmodalities: human motion and camera trajectories. We propose a simple,\nmodel-agnostic framework that enforces multimodal coherence via an auxiliary\nmodality: the on-screen framing induced by projecting human joints onto the\ncamera. This on-screen framing provides a natural and effective bridge between\nmodalities, promoting consistency and leading to more precise joint\ndistribution. We first design a joint autoencoder that learns a shared latent\nspace, together with a lightweight linear transform from the human and camera\nlatents to a framing latent. We then introduce auxiliary sampling, which\nexploits this linear transform to steer generation toward a coherent framing\nmodality. To support this task, we also introduce the PulpMotion dataset, a\nhuman-motion and camera-trajectory dataset with rich captions, and high-quality\nhuman motions. Extensive experiments across DiT- and MAR-based architectures\nshow the generality and effectiveness of our method in generating on-frame\ncoherent human-camera motions, while also achieving gains on textual alignment\nfor both modalities. Our qualitative results yield more cinematographically\nmeaningful framings setting the new state of the art for this task. Code,\nmodels and data are available in our\n\\href{https://www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/}{project\npage}.", "published": "2025-10-06 17:58:34", "link": "http://arxiv.org/abs/2510.05097v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "VChain: Chain-of-Visual-Thought for Reasoning in Video Generation", "abstract": "Recent video generation models can produce smooth and visually appealing\nclips, but they often struggle to synthesize complex dynamics with a coherent\nchain of consequences. Accurately modeling visual outcomes and state\ntransitions over time remains a core challenge. In contrast, large language and\nmultimodal models (e.g., GPT-4o) exhibit strong visual state reasoning and\nfuture prediction capabilities. To bridge these strengths, we introduce VChain,\na novel inference-time chain-of-visual-thought framework that injects visual\nreasoning signals from multimodal models into video generation. Specifically,\nVChain contains a dedicated pipeline that leverages large multimodal models to\ngenerate a sparse set of critical keyframes as snapshots, which are then used\nto guide the sparse inference-time tuning of a pre-trained video generator only\nat these key moments. Our approach is tuning-efficient, introduces minimal\noverhead and avoids dense supervision. Extensive experiments on complex,\nmulti-step scenarios show that VChain significantly enhances the quality of\ngenerated videos.", "published": "2025-10-06 17:57:59", "link": "http://arxiv.org/abs/2510.05094v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Character Mixing for Video Generation", "abstract": "Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where\ncharacters interact naturally across different worlds? We study inter-character\ninteraction in text-to-video generation, where the key challenge is to preserve\neach character's identity and behaviors while enabling coherent cross-context\ninteraction. This is difficult because characters may never have coexisted and\nbecause mixing styles often causes style delusion, where realistic characters\nappear cartoonish or vice versa. We introduce a framework that tackles these\nissues with Cross-Character Embedding (CCE), which learns identity and\nbehavioral logic across multimodal sources, and Cross-Character Augmentation\n(CCA), which enriches training with synthetic co-existence and mixed-style\ndata. Together, these techniques allow natural interactions between previously\nuncoexistent characters without losing stylistic fidelity. Experiments on a\ncurated benchmark of cartoons and live-action series with 10 characters show\nclear improvements in identity preservation, interaction quality, and\nrobustness to style delusion, enabling new forms of generative\nstorytelling.Additional results and videos are available on our project page:\nhttps://tingtingliao.github.io/mimix/.", "published": "2025-10-06 17:57:39", "link": "http://arxiv.org/abs/2510.05093v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Factuality Matters: When Image Generation and Editing Meet Structured Visuals", "abstract": "While modern visual generation models excel at creating aesthetically\npleasing natural images, they struggle with producing or editing structured\nvisuals like charts, diagrams, and mathematical figures, which demand\ncomposition planning, text rendering, and multimodal reasoning for factual\nfidelity. To address this, we present the first comprehensive, systematic\ninvestigation of this domain, encompassing data construction, model training,\nand an evaluation benchmark. First, we construct a large-scale dataset of 1.3\nmillion high-quality structured image pairs derived from executable drawing\nprograms and augmented with chain-of-thought reasoning annotations. Building on\nit, we train a unified model that integrates a VLM with FLUX.1 Kontext via a\nlightweight connector for enhanced multimodal understanding. A three-stage\ntraining curriculum enables progressive feature alignment, knowledge infusion,\nand reasoning-augmented generation, further boosted by an external reasoner at\ninference time. Finally, we introduce StructBench, a novel benchmark for\ngeneration and editing with over 1,700 challenging instances, and an\naccompanying evaluation metric, StructScore, which employs a multi-round Q\\&A\nprotocol to assess fine-grained factual accuracy. Evaluations of 15 models\nreveal that even leading closed-source systems remain far from satisfactory.\nOur model attains strong editing performance, and inference-time reasoning\nyields consistent gains across diverse architectures. By releasing the dataset,\nmodel, and benchmark, we aim to advance unified multimodal foundations for\nstructured visuals.", "published": "2025-10-06 17:56:55", "link": "http://arxiv.org/abs/2510.05091v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces", "abstract": "Efficient and accurate classification of waste and industrial surface defects\nis essential for ensuring sustainable waste management and maintaining high\nstandards in quality control. This paper introduces the Neuroplastic Modular\nClassifier, a novel hybrid architecture designed for robust and adaptive image\nclassification in dynamic environments. The model combines a ResNet-50 backbone\nfor localized feature extraction with a Vision Transformer (ViT) to capture\nglobal semantic context. Additionally, FAISS-based similarity retrieval is\nincorporated to provide a memory-like reference to previously encountered data,\nenriching the model's feature space. A key innovation of our architecture is\nthe neuroplastic modular design composed of expandable, learnable blocks that\ndynamically grow during training when performance plateaus. Inspired by\nbiological learning systems, this mechanism allows the model to adapt to data\ncomplexity over time, improving generalization. Beyond garbage classification,\nwe validate the model on the Kolektor Surface Defect Dataset 2 (KolektorSDD2),\nwhich involves industrial defect detection on metal surfaces. Experimental\nresults across domains show that the proposed architecture outperforms\ntraditional static models in both accuracy and adaptability. The Neuroplastic\nModular Classifier offers a scalable, high-performance solution for real-world\nimage classification, with strong applicability in both environmental and\nindustrial domains.", "published": "2025-10-06 17:47:45", "link": "http://arxiv.org/abs/2510.05071v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation", "abstract": "A fundamental challenge in embodied intelligence is developing expressive and\ncompact state representations for efficient world modeling and decision making.\nHowever, existing methods often fail to achieve this balance, yielding\nrepresentations that are either overly redundant or lacking in task-critical\ninformation. We propose an unsupervised approach that learns a highly\ncompressed two-token state representation using a lightweight encoder and a\npre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong\ngenerative prior. Our representation is efficient, interpretable, and\nintegrates seamlessly into existing VLA-based models, improving performance by\n14.3% on LIBERO and 30% in real-world task success with minimal inference\noverhead. More importantly, we find that the difference between these tokens,\nobtained via latent interpolation, naturally serves as a highly effective\nlatent action, which can be further decoded into executable robot actions. This\nemergent capability reveals that our representation captures structured\ndynamics without explicit supervision. We name our method StaMo for its ability\nto learn generalizable robotic Motion from compact State representation, which\nis encoded from static images, challenging the prevalent dependence to learning\nlatent action on complex architectures and video data. The resulting latent\nactions also enhance policy co-training, outperforming prior methods by 10.4%\nwith improved interpretability. Moreover, our approach scales effectively\nacross diverse data sources, including real-world robot data, simulation, and\nhuman egocentric video.", "published": "2025-10-06 17:37:24", "link": "http://arxiv.org/abs/2510.05057v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "No-reference Quality Assessment of Contrast-distorted Images using Contrast-enhanced Pseudo Reference", "abstract": "Contrast change is an important factor that affects the quality of images.\nDuring image capturing, unfavorable lighting conditions can cause contrast\nchange and visual quality loss. While various methods have been proposed to\nassess the quality of images under different distortions such as blur and\nnoise, contrast distortion has been largely overlooked as its visual impact and\nproperties are different from other conventional types of distortions. In this\npaper, we propose a no-reference image quality assessment (NR-IQA) metric for\ncontrast-distorted images. Using a set of contrast enhancement algorithms, we\naim to generate pseudo-reference images that are visually close to the actual\nreference image, such that the NR problem is transformed to a Full-reference\n(FR) assessment with higher accuracy. To this end, a large dataset of\ncontrast-enhanced images is produced to train a classification network that can\nselect the most suitable contrast enhancement algorithm based on image content\nand distortion for pseudo-reference image generation. Finally, the evaluation\nis performed in the FR manner to assess the quality difference between the\ncontrast-enhanced (pseudoreference) and degraded images. Performance evaluation\nof the proposed method on three databases containing contrast distortions\n(CCID2014, TID2013, and CSIQ), indicates the promising performance of the\nproposed method.", "published": "2025-10-06 17:32:48", "link": "http://arxiv.org/abs/2510.05053v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SegMASt3R: Geometry Grounded Segment Matching", "abstract": "Segment matching is an important intermediate task in computer vision that\nestablishes correspondences between semantically or geometrically coherent\nregions across images. Unlike keypoint matching, which focuses on localized\nfeatures, segment matching captures structured regions, offering greater\nrobustness to occlusions, lighting variations, and viewpoint changes. In this\npaper, we leverage the spatial understanding of 3D foundation models to tackle\nwide-baseline segment matching, a challenging setting involving extreme\nviewpoint shifts. We propose an architecture that uses the inductive bias of\nthese 3D foundation models to match segments across image pairs with up to 180\ndegree view-point change. Extensive experiments show that our approach\noutperforms state-of-the-art methods, including the SAM2 video propagator and\nlocal feature matching methods, by upto 30% on the AUPRC metric, on ScanNet++\nand Replica datasets. We further demonstrate benefits of the proposed model on\nrelevant downstream tasks, including 3D instance segmentation and image-goal\nnavigation. Project Page: https://segmast3r.github.io/", "published": "2025-10-06 17:31:32", "link": "http://arxiv.org/abs/2510.05051v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models", "abstract": "Video understanding represents the most challenging frontier in computer\nvision, requiring models to reason about complex spatiotemporal relationships,\nlong-term dependencies, and multimodal evidence. The recent emergence of\nVideo-Large Multimodal Models (Video-LMMs), which integrate visual encoders\nwith powerful decoder-based language models, has demonstrated remarkable\ncapabilities in video understanding tasks. However, the critical phase that\ntransforms these models from basic perception systems into sophisticated\nreasoning engines, post-training, remains fragmented across the literature.\nThis survey provides the first comprehensive examination of post-training\nmethodologies for Video-LMMs, encompassing three fundamental pillars:\nsupervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL)\nfrom verifiable objectives, and test-time scaling (TTS) through enhanced\ninference computation. We present a structured taxonomy that clarifies the\nroles, interconnections, and video-specific adaptations of these techniques,\naddressing unique challenges such as temporal localization, spatiotemporal\ngrounding, long video efficiency, and multimodal evidence integration. Through\nsystematic analysis of representative methods, we synthesize key design\nprinciples, insights, and evaluation protocols while identifying critical open\nchallenges in reward design, scalability, and cost-performance optimization. We\nfurther curate essential benchmarks, datasets, and metrics to facilitate\nrigorous assessment of post-training effectiveness. This survey aims to provide\nresearchers and practitioners with a unified framework for advancing Video-LMM\ncapabilities. Additional resources and updates are maintained at:\nhttps://github.com/yunlong10/Awesome-Video-LMM-Post-Training", "published": "2025-10-06 17:10:44", "link": "http://arxiv.org/abs/2510.05034v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exploring the Efficacy of Modified Transfer Learning in Identifying Parkinson's Disease Through Drawn Image Patterns", "abstract": "Parkinson's disease (PD) is a progressive neurodegenerative condition\ncharacterized by the death of dopaminergic neurons, leading to various movement\ndisorder symptoms. Early diagnosis of PD is crucial to prevent adverse effects,\nyet traditional diagnostic methods are often cumbersome and costly. In this\nstudy, a machine learning-based approach is proposed using hand-drawn spiral\nand wave images as potential biomarkers for PD detection. Our methodology\nleverages convolutional neural networks (CNNs), transfer learning, and\nattention mechanisms to improve model performance and resilience against\noverfitting. To enhance the diversity and richness of both spiral and wave\ncategories, the training dataset undergoes augmentation to increase the number\nof images. The proposed architecture comprises three phases: utilizing\npre-trained CNNs, incorporating custom convolutional layers, and ensemble\nvoting. Employing hard voting further enhances performance by aggregating\npredictions from multiple models. Experimental results show promising accuracy\nrates. For spiral images, weighted average precision, recall, and F1-score are\n90%, and for wave images, they are 96.67%. After combining the predictions\nthrough ensemble hard voting, the overall accuracy is 93.3%. These findings\nunderscore the potential of machine learning in early PD diagnosis, offering a\nnon-invasive and cost-effective solution to improve patient outcomes.", "published": "2025-10-06 16:55:07", "link": "http://arxiv.org/abs/2510.05015v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Latent Uncertainty Representations for Video-based Driver Action and Intention Recognition", "abstract": "Deep neural networks (DNNs) are increasingly applied to safety-critical tasks\nin resource-constrained environments, such as video-based driver action and\nintention recognition. While last layer probabilistic deep learning (LL-PDL)\nmethods can detect out-of-distribution (OOD) instances, their performance\nvaries. As an alternative to last layer approaches, we propose extending\npre-trained DNNs with transformation layers to produce multiple latent\nrepresentations to estimate the uncertainty. We evaluate our latent uncertainty\nrepresentation (LUR) and repulsively trained LUR (RLUR) approaches against\neight PDL methods across four video-based driver action and intention\nrecognition datasets, comparing classification performance, calibration, and\nuncertainty-based OOD detection. We also contribute 28,000 frame-level action\nlabels and 1,194 video-level intention labels for the NuScenes dataset. Our\nresults show that LUR and RLUR achieve comparable in-distribution\nclassification performance to other LL-PDL approaches. For uncertainty-based\nOOD detection, LUR matches top-performing PDL methods while being more\nefficient to train and easier to tune than approaches that require Markov-Chain\nMonte Carlo sampling or repulsive training procedures.", "published": "2025-10-06 16:50:02", "link": "http://arxiv.org/abs/2510.05006v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization", "abstract": "Tokenizers are a key component of state-of-the-art generative image models,\nextracting the most important features from the signal while reducing data\ndimension and redundancy. Most current tokenizers are based on KL-regularized\nvariational autoencoders (KL-VAE), trained with reconstruction, perceptual and\nadversarial losses. Diffusion decoders have been proposed as a more principled\nalternative to model the distribution over images conditioned on the latent.\nHowever, matching the performance of KL-VAE still requires adversarial losses,\nas well as a higher decoding time due to iterative sampling. To address these\nlimitations, we introduce a new pixel diffusion decoder architecture for\nimproved scaling and training stability, benefiting from transformer components\nand GAN-free training. We use distillation to replicate the performance of the\ndiffusion decoder in an efficient single-step decoder. This makes SSDD the\nfirst diffusion decoder optimized for single-step reconstruction trained\nwithout adversarial losses, reaching higher reconstruction quality and faster\nsampling than KL-VAE. In particular, SSDD improves reconstruction FID from\n$0.87$ to $0.50$ with $1.4\\times$ higher throughput and preserve generation\nquality of DiTs with $3.8\\times$ faster sampling. As such, SSDD can be used as\na drop-in replacement for KL-VAE, and for building higher-quality and faster\ngenerative models.", "published": "2025-10-06 15:57:31", "link": "http://arxiv.org/abs/2510.04961v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Semantics-Aware Hierarchical Self-Supervised Approach to Classification of Remote Sensing Images", "abstract": "Deep learning has become increasingly important in remote sensing image\nclassification due to its ability to extract semantic information from complex\ndata. Classification tasks often include predefined label hierarchies that\nrepresent the semantic relationships among classes. However, these hierarchies\nare frequently overlooked, and most approaches focus only on fine-grained\nclassification schemes. In this paper, we present a novel Semantics-Aware\nHierarchical Consensus (SAHC) method for learning hierarchical features and\nrelationships by integrating hierarchy-specific classification heads within a\ndeep network architecture, each specialized in different degrees of class\ngranularity. The proposed approach employs trainable hierarchy matrices, which\nguide the network through the learning of the hierarchical structure in a\nself-supervised manner. Furthermore, we introduce a hierarchical consensus\nmechanism to ensure consistent probability distributions across different\nhierarchical levels. This mechanism acts as a weighted ensemble being able to\neffectively leverage the inherent structure of the hierarchical classification\ntask. The proposed SAHC method is evaluated on three benchmark datasets with\ndifferent degrees of hierarchical complexity on different tasks, using distinct\nbackbone architectures to effectively emphasize its adaptability. Experimental\nresults show both the effectiveness of the proposed approach in guiding network\nlearning and the robustness of the hierarchical consensus for remote sensing\nimage classification tasks.", "published": "2025-10-06 15:30:39", "link": "http://arxiv.org/abs/2510.04916v1", "categories": ["cs.CV", "I.4.6; I.4.8; I.4.10"], "primary_category": "cs.CV"}
{"title": "Comparative Analysis of YOLOv5, Faster R-CNN, SSD, and RetinaNet for Motorbike Detection in Kigali Autonomous Driving Context", "abstract": "In Kigali, Rwanda, motorcycle taxis are a primary mode of transportation,\noften navigating unpredictably and disregarding traffic rules, posing\nsignificant challenges for autonomous driving systems. This study compares four\nobject detection models--YOLOv5, Faster R-CNN, SSD, and RetinaNet--for\nmotorbike detection using a custom dataset of 198 images collected in Kigali.\nImplemented in PyTorch with transfer learning, the models were evaluated for\naccuracy, localization, and inference speed to assess their suitability for\nreal-time navigation in resource-constrained settings. We identify\nimplementation challenges, including dataset limitations and model\ncomplexities, and recommend simplified architectures for future work to enhance\naccessibility for autonomous systems in developing countries like Rwanda.", "published": "2025-10-06 15:26:08", "link": "http://arxiv.org/abs/2510.04912v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery", "abstract": "This paper presents a novel approach for enabling robust robotic perception\nin dark environments using infrared (IR) stream. IR stream is less susceptible\nto noise than RGB in low-light conditions. However, it is dominated by active\nemitter patterns that hinder high-level tasks such as object detection,\ntracking and localisation. To address this, a U-Net-based architecture is\nproposed that reconstructs clean IR images from emitter-populated input,\nimproving both image quality and downstream robotic performance. This approach\noutperforms existing enhancement techniques and enables reliable operation of\nvision-driven robotic systems across illumination conditions from well-lit to\nextreme low-light scenes.", "published": "2025-10-06 15:04:56", "link": "http://arxiv.org/abs/2510.04883v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "BenthiCat: An opti-acoustic dataset for advancing benthic classification and habitat mapping", "abstract": "Benthic habitat mapping is fundamental for understanding marine ecosystems,\nguiding conservation efforts, and supporting sustainable resource management.\nYet, the scarcity of large, annotated datasets limits the development and\nbenchmarking of machine learning models in this domain. This paper introduces a\nthorough multi-modal dataset, comprising about a million side-scan sonar (SSS)\ntiles collected along the coast of Catalonia (Spain), complemented by\nbathymetric maps and a set of co-registered optical images from targeted\nsurveys using an autonomous underwater vehicle (AUV). Approximately \\num{36000}\nof the SSS tiles have been manually annotated with segmentation masks to enable\nsupervised fine-tuning of classification models. All the raw sensor data,\ntogether with mosaics, are also released to support further exploration and\nalgorithm development. To address challenges in multi-sensor data fusion for\nAUVs, we spatially associate optical images with corresponding SSS tiles,\nfacilitating self-supervised, cross-modal representation learning. Accompanying\nopen-source preprocessing and annotation tools are provided to enhance\naccessibility and encourage research. This resource aims to establish a\nstandardized benchmark for underwater habitat mapping, promoting advancements\nin autonomous seafloor classification and multi-sensor integration.", "published": "2025-10-06 15:00:20", "link": "http://arxiv.org/abs/2510.04876v1", "categories": ["cs.CV", "cs.LG", "I.2.6; I.4.6; I.5.1; I.5.4"], "primary_category": "cs.CV"}
{"title": "In-Field Mapping of Grape Yield and Quality with Illumination-Invariant Deep Learning", "abstract": "This paper presents an end-to-end, IoT-enabled robotic system for the\nnon-destructive, real-time, and spatially-resolved mapping of grape yield and\nquality (Brix, Acidity) in vineyards. The system features a comprehensive\nanalytical pipeline that integrates two key modules: a high-performance model\nfor grape bunch detection and weight estimation, and a novel deep learning\nframework for quality assessment from hyperspectral (HSI) data. A critical\nbarrier to in-field HSI is the ``domain shift\" caused by variable illumination.\nTo overcome this, our quality assessment is powered by the Light-Invariant\nSpectral Autoencoder (LISA), a domain-adversarial framework that learns\nillumination-invariant features from uncalibrated data. We validated the\nsystem's robustness on a purpose-built HSI dataset spanning three distinct\nillumination domains: controlled artificial lighting (lab), and variable\nnatural sunlight captured in the morning and afternoon. Results show the\ncomplete pipeline achieves a recall (0.82) for bunch detection and a $R^2$\n(0.76) for weight prediction, while the LISA module improves quality prediction\ngeneralization by over 20% compared to the baselines. By combining these robust\nmodules, the system successfully generates high-resolution, georeferenced data\nof both grape yield and quality, providing actionable, data-driven insights for\nprecision viticulture.", "published": "2025-10-06 14:51:24", "link": "http://arxiv.org/abs/2510.04864v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "\u03bcDeepIQA: deep learning-based fast and robust image quality assessment with local predictions for optical microscopy", "abstract": "Optical microscopy is one of the most widely used techniques in research\nstudies for life sciences and biomedicine. These applications require reliable\nexperimental pipelines to extract valuable knowledge from the measured samples\nand must be supported by image quality assessment (IQA) to ensure correct\nprocessing and analysis of the image data. IQA methods are implemented with\nvariable complexity. However, while most quality metrics have a straightforward\nimplementation, they might be time consuming and computationally expensive when\nevaluating a large dataset. In addition, quality metrics are often designed for\nwell-defined image features and may be unstable for images out of the ideal\ndomain.\n  To overcome these limitations, recent works have proposed deep learning-based\nIQA methods, which can provide superior performance, increased generalizability\nand fast prediction. Our method, named $\\mathrm{\\mu}$DeepIQA, is inspired by\nprevious studies and applies a deep convolutional neural network designed for\nIQA on natural images to optical microscopy measurements. We retrained the same\narchitecture to predict individual quality metrics and global quality scores\nfor optical microscopy data. The resulting models provide fast and stable\npredictions of image quality by generalizing quality estimation even outside\nthe ideal range of standard methods. In addition, $\\mathrm{\\mu}$DeepIQA\nprovides patch-wise prediction of image quality and can be used to visualize\nspatially varying quality in a single image. Our study demonstrates that\noptical microscopy-based studies can benefit from the generalizability of deep\nlearning models due to their stable performance in the presence of outliers,\nthe ability to assess small image patches, and rapid predictions.", "published": "2025-10-06 14:48:36", "link": "http://arxiv.org/abs/2510.04859v1", "categories": ["cs.CV", "physics.data-an", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "ERDE: Entropy-Regularized Distillation for Early-exit", "abstract": "Although deep neural networks and in particular Convolutional Neural Networks\nhave demonstrated state-of-the-art performance in image classification with\nrelatively high efficiency, they still exhibit high computational costs, often\nrendering them impractical for real-time and edge applications. Therefore, a\nmultitude of compression techniques have been developed to reduce these costs\nwhile maintaining accuracy. In addition, dynamic architectures have been\nintroduced to modulate the level of compression at execution time, which is a\ndesirable property in many resource-limited application scenarios. The proposed\nmethod effectively integrates two well-established optimization techniques:\nearly exits and knowledge distillation, where a reduced student early-exit\nmodel is trained from a more complex teacher early-exit model. The primary\ncontribution of this research lies in the approach for training the student\nearly-exit model. In comparison to the conventional Knowledge Distillation\nloss, our approach incorporates a new entropy-based loss for images where the\nteacher's classification was incorrect. The proposed method optimizes the\ntrade-off between accuracy and efficiency, thereby achieving significant\nreductions in computational complexity without compromising classification\nperformance. The validity of this approach is substantiated by experimental\nresults on image classification datasets CIFAR10, CIFAR100 and SVHN, which\nfurther opens new research perspectives for Knowledge Distillation in other\ncontexts.", "published": "2025-10-06 14:45:41", "link": "http://arxiv.org/abs/2510.04856v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Read the Room: Inferring Social Context Through Dyadic Interaction Recognition in Cyber-physical-social Infrastructure Systems", "abstract": "Cyber-physical systems (CPS) integrate sensing, computing, and control to\nimprove infrastructure performance, focusing on economic goals like performance\nand safety. However, they often neglect potential human-centered (or\n''social'') benefits. Cyber-physical-social infrastructure systems (CPSIS) aim\nto address this by aligning CPS with social objectives. This involves defining\nsocial benefits, understanding human interactions with each other and\ninfrastructure, developing privacy-preserving measurement methods, modeling\nthese interactions for prediction, linking them to social benefits, and\nactuating the physical environment to foster positive social outcomes. This\npaper delves into recognizing dyadic human interactions using real-world data,\nwhich is the backbone to measuring social behavior. This lays a foundation to\naddress the need to enhance understanding of the deeper meanings and mutual\nresponses inherent in human interactions. While RGB cameras are informative for\ninteraction recognition, privacy concerns arise. Depth sensors offer a\nprivacy-conscious alternative by analyzing skeletal movements. This study\ncompares five skeleton-based interaction recognition algorithms on a dataset of\n12 dyadic interactions. Unlike single-person datasets, these interactions,\ncategorized into communication types like emblems and affect displays, offer\ninsights into the cultural and emotional aspects of human interactions.", "published": "2025-10-06 14:40:22", "link": "http://arxiv.org/abs/2510.04854v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Actions to Kinesics: Extracting Human Psychological States through Bodily Movements", "abstract": "Understanding the dynamic relationship between humans and the built\nenvironment is a key challenge in disciplines ranging from environmental\npsychology to reinforcement learning (RL). A central obstacle in modeling these\ninteractions is the inability to capture human psychological states in a way\nthat is both generalizable and privacy preserving. Traditional methods rely on\ntheoretical models or questionnaires, which are limited in scope, static, and\nlabor intensive. We present a kinesics recognition framework that infers the\ncommunicative functions of human activity -- known as kinesics -- directly from\n3D skeleton joint data. Combining a spatial-temporal graph convolutional\nnetwork (ST-GCN) with a convolutional neural network (CNN), the framework\nleverages transfer learning to bypass the need for manually defined mappings\nbetween physical actions and psychological categories. The approach preserves\nuser anonymity while uncovering latent structures in bodily movements that\nreflect cognitive and emotional states. Our results on the Dyadic User\nEngagemenT (DUET) dataset demonstrate that this method enables scalable,\naccurate, and human-centered modeling of behavior, offering a new pathway for\nenhancing RL-driven simulations of human-environment interaction.", "published": "2025-10-06 14:31:53", "link": "http://arxiv.org/abs/2510.04844v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Detailed Aerial Mapping of Photovoltaic Power Plants Through Semantically Significant Keypoints", "abstract": "An accurate and up-to-date model of a photovoltaic (PV) power plant is\nessential for its optimal operation and maintenance. However, such a model may\nnot be easily available. This work introduces a novel approach for PV power\nplant mapping based on aerial overview images. It enables the automation of the\nmapping process while removing the reliance on third-party data. The presented\nmapping method takes advantage of the structural layout of the power plants to\nachieve detailed modeling down to the level of individual PV modules. The\napproach relies on visual segmentation of PV modules in overview images and the\ninference of structural information in each image, assigning modules to\nindividual benches, rows, and columns. We identify visual keypoints related to\nthe layout and use these to merge detections from multiple images while\nmaintaining their structural integrity. The presented method was experimentally\nverified and evaluated on two different power plants. The final fusion of 3D\npositions and semantic structures results in a compact georeferenced model\nsuitable for power plant maintenance.", "published": "2025-10-06 14:25:03", "link": "http://arxiv.org/abs/2510.04840v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Random: Automatic Inner-loop Optimization in Dataset Distillation", "abstract": "The growing demand for efficient deep learning has positioned dataset\ndistillation as a pivotal technique for compressing training dataset while\npreserving model performance. However, existing inner-loop optimization methods\nfor dataset distillation typically rely on random truncation strategies, which\nlack flexibility and often yield suboptimal results. In this work, we observe\nthat neural networks exhibit distinct learning dynamics across different\ntraining stages-early, middle, and late-making random truncation ineffective.\nTo address this limitation, we propose Automatic Truncated Backpropagation\nThrough Time (AT-BPTT), a novel framework that dynamically adapts both\ntruncation positions and window sizes according to intrinsic gradient behavior.\nAT-BPTT introduces three key components: (1) a probabilistic mechanism for\nstage-aware timestep selection, (2) an adaptive window sizing strategy based on\ngradient variation, and (3) a low-rank Hessian approximation to reduce\ncomputational overhead. Extensive experiments on CIFAR-10, CIFAR-100,\nTiny-ImageNet, and ImageNet-1K show that AT-BPTT achieves state-of-the-art\nperformance, improving accuracy by an average of 6.16% over baseline methods.\nMoreover, our approach accelerates inner-loop optimization by 3.9x while saving\n63% memory cost.", "published": "2025-10-06 14:22:28", "link": "http://arxiv.org/abs/2510.04838v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Flow Matching for Conditional MRI-CT and CBCT-CT Image Synthesis", "abstract": "Generating synthetic CT (sCT) from MRI or CBCT plays a crucial role in\nenabling MRI-only and CBCT-based adaptive radiotherapy, improving treatment\nprecision while reducing patient radiation exposure. To address this task, we\nadopt a fully 3D Flow Matching (FM) framework, motivated by recent work\ndemonstrating FM's efficiency in producing high-quality images. In our\napproach, a Gaussian noise volume is transformed into an sCT image by\nintegrating a learned FM velocity field, conditioned on features extracted from\nthe input MRI or CBCT using a lightweight 3D encoder. We evaluated the method\non the SynthRAD2025 Challenge benchmark, training separate models for MRI\n$\\rightarrow$ sCT and CBCT $\\rightarrow$ sCT across three anatomical regions:\nabdomen, head and neck, and thorax. Validation and testing were performed\nthrough the challenge submission system. The results indicate that the method\naccurately reconstructs global anatomical structures; however, preservation of\nfine details was limited, primarily due to the relatively low training\nresolution imposed by memory and runtime constraints. Future work will explore\npatch-based training and latent-space flow models to improve resolution and\nlocal structural fidelity.", "published": "2025-10-06 14:07:03", "link": "http://arxiv.org/abs/2510.04823v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AvatarVTON: 4D Virtual Try-On for Animatable Avatars", "abstract": "We propose AvatarVTON, the first 4D virtual try-on framework that generates\nrealistic try-on results from a single in-shop garment image, enabling free\npose control, novel-view rendering, and diverse garment choices. Unlike\nexisting methods, AvatarVTON supports dynamic garment interactions under\nsingle-view supervision, without relying on multi-view garment captures or\nphysics priors. The framework consists of two key modules: (1) a Reciprocal\nFlow Rectifier, a prior-free optical-flow correction strategy that stabilizes\navatar fitting and ensures temporal coherence; and (2) a Non-Linear Deformer,\nwhich decomposes Gaussian maps into view-pose-invariant and view-pose-specific\ncomponents, enabling adaptive, non-linear garment deformations. To establish a\nbenchmark for 4D virtual try-on, we extend existing baselines with unified\nmodules for fair qualitative and quantitative comparisons. Extensive\nexperiments show that AvatarVTON achieves high fidelity, diversity, and dynamic\ngarment realism, making it well-suited for AR/VR, gaming, and digital-human\napplications.", "published": "2025-10-06 14:06:34", "link": "http://arxiv.org/abs/2510.04822v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation", "abstract": "Vision-transformers (ViTs) and large-scale convolution-neural-networks (CNNs)\nhave reshaped computer vision through pretrained feature representations that\nenable strong transfer learning for diverse tasks. However, their efficiency as\nbackbone architectures for geometric estimation tasks involving image\ndeformations in low-data regimes remains an open question. This work considers\ntwo such tasks: 1) estimating 2D rigid transformations between pairs of images\nand 2) predicting the fundamental matrix for stereo image pairs, an important\nproblem in various applications, such as autonomous mobility, robotics, and 3D\nscene reconstruction. Addressing this intriguing question, this work\nsystematically compares large-scale CNNs (ResNet, EfficientNet, CLIP-ResNet)\nwith ViT-based foundation models (CLIP-ViT variants and DINO) in various data\nsize settings, including few-shot scenarios. These pretrained models are\noptimized for classification or contrastive learning, encouraging them to focus\nmostly on high-level semantics. The considered tasks require balancing local\nand global features differently, challenging the straightforward adoption of\nthese models as the backbone. Empirical comparative analysis shows that,\nsimilar to training from scratch, ViTs outperform CNNs during refinement in\nlarge downstream-data scenarios. However, in small data scenarios, the\ninductive bias and smaller capacity of CNNs improve their performance, allowing\nthem to match that of a ViT. Moreover, ViTs exhibit stronger generalization in\ncross-domain evaluation where the data distribution changes. These results\nemphasize the importance of carefully selecting model architectures for\nrefinement, motivating future research towards hybrid architectures that\nbalance local and global representations.", "published": "2025-10-06 13:18:27", "link": "http://arxiv.org/abs/2510.04794v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization", "abstract": "High-fidelity 3D scanning is essential for preserving cultural heritage\nartefacts, supporting documentation, analysis, and long-term conservation.\nHowever, conventional methods typically require specialized expertise and\nmanual intervention to maintain optimal scanning conditions and coverage. We\npresent an automated two-robot scanning system that eliminates the need for\nhandheld or semi-automatic workflows by combining coordinated robotic\nmanipulation with high-resolution 3D scanning. Our system parameterizes the\nscanning space into distinct regions, enabling coordinated motion planning\nbetween a scanner-equipped robot and a tray-handling robot. Optimized\ntrajectory planning and waypoint distribution ensure comprehensive surface\ncoverage, minimize occlusions, and balance reconstruction accuracy with system\nefficiency. Experimental results show that our approach achieves significantly\nlower Chamfer Distance and higher F-score compared to baseline methods,\noffering superior geometric accuracy, improved digitization efficiency, and\nreduced reliance on expert operators.", "published": "2025-10-06 12:58:41", "link": "http://arxiv.org/abs/2510.04781v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge", "abstract": "Purpose: The FedSurg challenge was designed to benchmark the state of the art\nin federated learning for surgical video classification. Its goal was to assess\nhow well current methods generalize to unseen clinical centers and adapt\nthrough local fine-tuning while enabling collaborative model development\nwithout sharing patient data. Methods: Participants developed strategies to\nclassify inflammation stages in appendicitis using a preliminary version of the\nmulti-center Appendix300 video dataset. The challenge evaluated two tasks:\ngeneralization to an unseen center and center-specific adaptation after\nfine-tuning. Submitted approaches included foundation models with linear\nprobing, metric learning with triplet loss, and various FL aggregation schemes\n(FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and\nExpected Cost, with ranking robustness evaluated via bootstrapping and\nstatistical testing. Results: In the generalization task, performance across\ncenters was limited. In the adaptation task, all teams improved after\nfine-tuning, though ranking stability was low. The ViViT-based submission\nachieved the strongest overall performance. The challenge highlighted\nlimitations in generalization, sensitivity to class imbalance, and difficulties\nin hyperparameter tuning in decentralized training, while spatiotemporal\nmodeling and context-aware preprocessing emerged as promising strategies.\nConclusion: The FedSurg Challenge establishes the first benchmark for\nevaluating FL strategies in surgical video classification. Findings highlight\nthe trade-off between local personalization and global robustness, and\nunderscore the importance of architecture choice, preprocessing, and loss\ndesign. This benchmarking offers a reference point for future development of\nimbalance-aware, adaptive, and robust FL methods in clinical surgical AI.", "published": "2025-10-06 12:48:46", "link": "http://arxiv.org/abs/2510.04772v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Beyond the Seen: Bounded Distribution Estimation for Open-Vocabulary Learning", "abstract": "Open-vocabulary learning requires modeling the data distribution in open\nenvironments, which consists of both seen-class and unseen-class data.\n  Existing methods estimate the distribution in open environments using\nseen-class data, where the absence of unseen classes makes the estimation error\ninherently unidentifiable.\n  Intuitively, learning beyond the seen classes is crucial for distribution\nestimation to bound the estimation error.\n  We theoretically demonstrate that the distribution can be effectively\nestimated by generating unseen-class data, through which the estimation error\nis upper-bounded.\n  Building on this theoretical insight, we propose a novel open-vocabulary\nlearning method, which generates unseen-class data for estimating the\ndistribution in open environments. The method consists of a class-domain-wise\ndata generation pipeline and a distribution alignment algorithm. The data\ngeneration pipeline generates unseen-class data under the guidance of a\nhierarchical semantic tree and domain information inferred from the seen-class\ndata, facilitating accurate distribution estimation. With the generated data,\nthe distribution alignment algorithm estimates and maximizes the posterior\nprobability to enhance generalization in open-vocabulary learning. Extensive\nexperiments on $11$ datasets demonstrate that our method outperforms baseline\napproaches by up to $14\\%$, highlighting its effectiveness and superiority.", "published": "2025-10-06 12:43:59", "link": "http://arxiv.org/abs/2510.04770v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics", "abstract": "This paper investigates the performance of transformer-based architectures\nfor person identification in natural, face-to-face conversation scenario. We\nimplement and evaluate a two-stream framework that separately models spatial\nconfigurations and temporal motion patterns of 133 COCO WholeBody keypoints,\nextracted from a subset of the CANDOR conversational corpus. Our experiments\ncompare pre-trained and from-scratch training, investigate the use of velocity\nfeatures, and introduce a multi-scale temporal transformer for hierarchical\nmotion modeling. Results demonstrate that domain-specific training\nsignificantly outperforms transfer learning, and that spatial configurations\ncarry more discriminative information than temporal dynamics. The spatial\ntransformer achieves 95.74% accuracy, while the multi-scale temporal\ntransformer achieves 93.90%. Feature-level fusion pushes performance to 98.03%,\nconfirming that postural and dynamic information are complementary. These\nfindings highlight the potential of transformer architectures for person\nidentification in natural interactions and provide insights for future\nmultimodal and cross-cultural studies.", "published": "2025-10-06 12:31:15", "link": "http://arxiv.org/abs/2510.04753v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Anomaly-Aware YOLO: A Frugal yet Robust Approach to Infrared Small Target Detection", "abstract": "Infrared Small Target Detection (IRSTD) is a challenging task in defense\napplications, where complex backgrounds and tiny target sizes often result in\nnumerous false alarms using conventional object detectors. To overcome this\nlimitation, we propose Anomaly-Aware YOLO (AA-YOLO), which integrates a\nstatistical anomaly detection test into its detection head. By treating small\ntargets as unexpected patterns against the background, AA-YOLO effectively\ncontrols the false alarm rate. Our approach not only achieves competitive\nperformance on several IRSTD benchmarks, but also demonstrates remarkable\nrobustness in scenarios with limited training data, noise, and domain shifts.\nFurthermore, since only the detection head is modified, our design is highly\ngeneric and has been successfully applied across various YOLO backbones,\nincluding lightweight models. It also provides promising results when\nintegrated into an instance segmentation YOLO. This versatility makes AA-YOLO\nan attractive solution for real-world deployments where resources are\nconstrained. The code will be publicly released.", "published": "2025-10-06 12:13:56", "link": "http://arxiv.org/abs/2510.04741v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ExposureEngine: Oriented Logo Detection and Sponsor Visibility Analytics in Sports Broadcasts", "abstract": "Quantifying sponsor visibility in sports broadcasts is a critical marketing\ntask traditionally hindered by manual, subjective, and unscalable analysis\nmethods. While automated systems offer an alternative, their reliance on\naxis-aligned Horizontal Bounding Box (HBB) leads to inaccurate exposuremetrics\nwhen logos appear rotated or skewed due to dynamic camera angles and\nperspective distortions. This paper introduces ExposureEngine, an end-to-end\nsystem designed for accurate, rotation-aware sponsor visibility analytics in\nsports broadcasts, demonstrated in a soccer case study. Our approach predicts\nOriented Bounding Box (OBB) to provide a geometrically precise fit to each logo\nregardless of the orientation on-screen. To train and evaluate our detector, we\ndeveloped a new dataset comprising 1,103 frames from Swedish elite soccer,\nfeaturing 670 unique sponsor logos annotated with OBBs. Our model achieves a\nmean Average Precision (mAP@0.5) of 0.859, with a precision of 0.96 and recall\nof 0.87, demonstrating robust performance in localizing logos under diverse\nbroadcast conditions. The system integrates these detections into an analytical\npipeline that calculates precise visibility metrics, such as exposure duration\nand on-screen coverage. Furthermore, we incorporate a language-driven agentic\nlayer, enabling users to generate reports, summaries, and media content through\nnatural language queries. The complete system, including the dataset and the\nanalytics dashboard, provides a comprehensive solution for auditable and\ninterpretable sponsor measurement in sports media. An overview of the\nExposureEngine is available online: https://youtu.be/tRw6OBISuW4 .", "published": "2025-10-06 12:11:53", "link": "http://arxiv.org/abs/2510.04739v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Benchmark on Monocular Metric Depth Estimation in Wildlife Setting", "abstract": "Camera traps are widely used for wildlife monitoring, but extracting accurate\ndistance measurements from monocular images remains challenging due to the lack\nof depth information. While monocular depth estimation (MDE) methods have\nadvanced significantly, their performance in natural wildlife environments has\nnot been systematically evaluated. This work introduces the first benchmark for\nmonocular metric depth estimation in wildlife monitoring conditions. We\nevaluate four state-of-the-art MDE methods (Depth Anything V2, ML Depth Pro,\nZoeDepth, and Metric3D) alongside a geometric baseline on 93 camera trap images\nwith ground truth distances obtained using calibrated ChARUCO patterns. Our\nresults demonstrate that Depth Anything V2 achieves the best overall\nperformance with a mean absolute error of 0.454m and correlation of 0.962,\nwhile methods like ZoeDepth show significant degradation in outdoor natural\nenvironments (MAE: 3.087m). We find that median-based depth extraction\nconsistently outperforms mean-based approaches across all deep learning\nmethods. Additionally, we analyze computational efficiency, with ZoeDepth being\nfastest (0.17s per image) but least accurate, while Depth Anything V2 provides\nan optimal balance of accuracy and speed (0.22s per image). This benchmark\nestablishes performance baselines for wildlife applications and provides\npractical guidance for implementing depth estimation in conservation monitoring\nsystems.", "published": "2025-10-06 11:43:34", "link": "http://arxiv.org/abs/2510.04723v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction", "abstract": "3D Semantic Scene Graph Prediction aims to detect objects and their semantic\nrelationships in 3D scenes, and has emerged as a crucial technology for\nrobotics and AR/VR applications. While previous research has addressed dataset\nlimitations and explored various approaches including Open-Vocabulary settings,\nthey frequently fail to optimize the representational capacity of object and\nrelationship features, showing excessive reliance on Graph Neural Networks\ndespite insufficient discriminative capability. In this work, we demonstrate\nthrough extensive analysis that the quality of object features plays a critical\nrole in determining overall scene graph accuracy. To address this challenge, we\ndesign a highly discriminative object feature encoder and employ a contrastive\npretraining strategy that decouples object representation learning from the\nscene graph prediction. This design not only enhances object classification\naccuracy but also yields direct improvements in relationship prediction.\nNotably, when plugging in our pretrained encoder into existing frameworks, we\nobserve substantial performance improvements across all evaluation metrics.\nAdditionally, whereas existing approaches have not fully exploited the\nintegration of relationship information, we effectively combine both geometric\nand semantic features to achieve superior relationship prediction.\nComprehensive experiments on the 3DSSG dataset demonstrate that our approach\nsignificantly outperforms previous state-of-the-art methods. Our code is\npublicly available at https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes.", "published": "2025-10-06 11:33:09", "link": "http://arxiv.org/abs/2510.04714v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ReactDiff: Fundamental Multiple Appropriate Facial Reaction Diffusion Model", "abstract": "The automatic generation of diverse and human-like facial reactions in dyadic\ndialogue remains a critical challenge for human-computer interaction systems.\nExisting methods fail to model the stochasticity and dynamics inherent in real\nhuman reactions. To address this, we propose ReactDiff, a novel temporal\ndiffusion framework for generating diverse facial reactions that are\nappropriate for responding to any given dialogue context. Our key insight is\nthat plausible human reactions demonstrate smoothness, and coherence over time,\nand conform to constraints imposed by human facial anatomy. To achieve this,\nReactDiff incorporates two vital priors (spatio-temporal facial kinematics)\ninto the diffusion process: i) temporal facial behavioral kinematics and ii)\nfacial action unit dependencies. These two constraints guide the model toward\nrealistic human reaction manifolds, avoiding visually unrealistic jitters,\nunstable transitions, unnatural expressions, and other artifacts. Extensive\nexperiments on the REACT2024 dataset demonstrate that our approach not only\nachieves state-of-the-art reaction quality but also excels in diversity and\nreaction appropriateness.", "published": "2025-10-06 11:30:40", "link": "http://arxiv.org/abs/2510.04712v1", "categories": ["cs.CV", "cs.HC", "cs.MM"], "primary_category": "cs.CV"}
{"title": "ID-Consistent, Precise Expression Generation with Blendshape-Guided Diffusion", "abstract": "Human-centric generative models designed for AI-driven storytelling must\nbring together two core capabilities: identity consistency and precise control\nover human performance. While recent diffusion-based approaches have made\nsignificant progress in maintaining facial identity, achieving fine-grained\nexpression control without compromising identity remains challenging. In this\nwork, we present a diffusion-based framework that faithfully reimagines any\nsubject under any particular facial expression. Building on an ID-consistent\nface foundation model, we adopt a compositional design featuring an expression\ncross-attention module guided by FLAME blendshape parameters for explicit\ncontrol. Trained on a diverse mixture of image and video data rich in\nexpressive variation, our adapter generalizes beyond basic emotions to subtle\nmicro-expressions and expressive transitions, overlooked by prior works. In\naddition, a pluggable Reference Adapter enables expression editing in real\nimages by transferring the appearance from a reference frame during synthesis.\nExtensive quantitative and qualitative evaluations show that our model\noutperforms existing methods in tailored and identity-consistent expression\ngeneration. Code and models can be found at\nhttps://github.com/foivospar/Arc2Face.", "published": "2025-10-06 11:20:56", "link": "http://arxiv.org/abs/2510.04706v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Label-Efficient Cross-Modality Generalization for Liver Segmentation in Multi-Phase MRI", "abstract": "Accurate liver segmentation in multi-phase MRI is vital for liver fibrosis\nassessment, yet labeled data is often scarce and unevenly distributed across\nimaging modalities and vendor systems. We propose a label-efficient\nsegmentation approach that promotes cross-modality generalization under\nreal-world conditions, where GED4 hepatobiliary-phase annotations are limited,\nnon-contrast sequences (T1WI, T2WI, DWI) are unlabeled, and spatial\nmisalignment and missing phases are common. Our method integrates a\nfoundation-scale 3D segmentation backbone adapted via fine-tuning, co-training\nwith cross pseudo supervision to leverage unlabeled volumes, and a standardized\npreprocessing pipeline. Without requiring spatial registration, the model\nlearns to generalize across MRI phases and vendors, demonstrating robust\nsegmentation performance in both labeled and unlabeled domains. Our results\nexhibit the effectiveness of our proposed label-efficient baseline for liver\nsegmentation in multi-phase, multi-vendor MRI and highlight the potential of\ncombining foundation model adaptation with co-training for real-world clinical\nimaging tasks.", "published": "2025-10-06 11:19:05", "link": "http://arxiv.org/abs/2510.04705v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ConceptSplit: Decoupled Multi-Concept Personalization of Diffusion Models via Token-wise Adaptation and Attention Disentanglement", "abstract": "In recent years, multi-concept personalization for text-to-image (T2I)\ndiffusion models to represent several subjects in an image has gained much more\nattention. The main challenge of this task is \"concept mixing\", where multiple\nlearned concepts interfere or blend undesirably in the output image. To address\nthis issue, in this paper, we present ConceptSplit, a novel framework to split\nthe individual concepts through training and inference. Our framework comprises\ntwo key components. First, we introduce Token-wise Value Adaptation (ToVA), a\nmerging-free training method that focuses exclusively on adapting the value\nprojection in cross-attention. Based on our empirical analysis, we found that\nmodifying the key projection, a common approach in existing methods, can\ndisrupt the attention mechanism and lead to concept mixing. Second, we propose\nLatent Optimization for Disentangled Attention (LODA), which alleviates\nattention entanglement during inference by optimizing the input latent. Through\nextensive qualitative and quantitative experiments, we demonstrate that\nConceptSplit achieves robust multi-concept personalization, mitigating\nunintended concept interference. Code is available at\nhttps://github.com/KU-VGI/ConceptSplit", "published": "2025-10-06 10:22:46", "link": "http://arxiv.org/abs/2510.04668v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoME: Estimating Psychological Traits from Gait with Multi-Stage Mixture of Movement Experts", "abstract": "Gait encodes rich biometric and behavioural information, yet leveraging the\nmanner of walking to infer psychological traits remains a challenging and\nunderexplored problem. We introduce a hierarchical Multi-Stage Mixture of\nMovement Experts (MoME) architecture for multi-task prediction of psychological\nattributes from gait sequences represented as 2D poses. MoME processes the\nwalking cycle in four stages of movement complexity, employing lightweight\nexpert models to extract spatio-temporal features and task-specific gating\nmodules to adaptively weight experts across traits and stages. Evaluated on the\nPsyMo benchmark covering 17 psychological traits, our method outperforms\nstate-of-the-art gait analysis models, achieving a 37.47% weighted F1 score at\nthe run level and 44.6% at the subject level. Our experiments show that\nintegrating auxiliary tasks such as identity recognition, gender prediction,\nand BMI estimation further improves psychological trait estimation. Our\nfindings demonstrate the viability of multi-task gait-based learning for\npsychological trait estimation and provide a foundation for future research on\nmovement-informed psychological inference.", "published": "2025-10-06 09:58:43", "link": "http://arxiv.org/abs/2510.04654v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents", "abstract": "As large language models are increasingly integrated into education, virtual\nstudent agents are becoming vital for classroom simulation and teacher\ntraining. Yet their classroom-oriented subjective abilities remain largely\nunassessed, limiting understanding of model boundaries and hindering\ntrustworthy deployment. We present EduPersona, a large-scale benchmark spanning\ntwo languages, three subjects, and ten persona types based on the Big Five\ntheory. The dataset contains 1,308 authentic classroom dialogue rounds,\ncorresponding to 12,814 teacher-student Q&A turns, and is further expanded\nthrough persona stylization into roughly 10 times larger scale (128k turns),\nproviding a solid foundation for evaluation. Building on this resource, we\ndecompose hard-to-quantify subjective performance into three progressive tasks:\nTASK1 basic coherence (whether behavior, emotion, expression, and voice align\nwith classroom context), TASK2 student realism, and TASK3 long-term persona\nconsistency, thereby establishing an evaluation framework grounded in\neducational theory and research value. We conduct systematic experiments on\nthree representative LLMs, comparing their original versions with ten\npersona-fine-tuned variants trained on EduPersona. Results show consistent and\nsignificant average improvements across all tasks: TASK1 +33.6%, TASK2 +30.6%,\nand TASK3 +14.9%. These improvements highlight the dataset's effectiveness and\nresearch value, while also revealing the heterogeneous difficulty of persona\nmodeling. In summary, EduPersona delivers the first classroom benchmark\ncentered on subjective abilities, establishes a decoupled and verifiable\nresearch paradigm, and we will open-source both the dataset and the framework\nto support the broader research community in advancing trustworthy and\nhuman-like AI for education.", "published": "2025-10-06 09:52:18", "link": "http://arxiv.org/abs/2510.04648v1", "categories": ["cs.CV", "cs.CY"], "primary_category": "cs.CV"}
{"title": "Do Superpixel Segmentation Methods Influence Deforestation Image Classification?", "abstract": "Image segmentation is a crucial step in various visual applications,\nincluding environmental monitoring through remote sensing. In the context of\nthe ForestEyes project, which combines citizen science and machine learning to\ndetect deforestation in tropical forests, image segments are used for labeling\nby volunteers and subsequent model training. Traditionally, the Simple Linear\nIterative Clustering (SLIC) algorithm is adopted as the segmentation method.\nHowever, recent studies have indicated that other superpixel-based methods\noutperform SLIC in remote sensing image segmentation, and might suggest that\nthey are more suitable for the task of detecting deforested areas. In this\nsense, this study investigated the impact of the four best segmentation\nmethods, together with SLIC, on the training of classifiers for the target\napplication. Initially, the results showed little variation in performance\namong segmentation methods, even when selecting the top five classifiers using\nthe PyCaret AutoML library. However, by applying a classifier fusion approach\n(ensemble of classifiers), noticeable improvements in balanced accuracy were\nobserved, highlighting the importance of both the choice of segmentation method\nand the combination of machine learning-based models for deforestation\ndetection tasks.", "published": "2025-10-06 09:46:17", "link": "http://arxiv.org/abs/2510.04645v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents", "abstract": "We present Social Agent, a novel framework for synthesizing realistic and\ncontextually appropriate co-speech nonverbal behaviors in dyadic conversations.\nIn this framework, we develop an agentic system driven by a Large Language\nModel (LLM) to direct the conversation flow and determine appropriate\ninteractive behaviors for both participants. Additionally, we propose a novel\ndual-person gesture generation model based on an auto-regressive diffusion\nmodel, which synthesizes coordinated motions from speech signals. The output of\nthe agentic system is translated into high-level guidance for the gesture\ngenerator, resulting in realistic movement at both the behavioral and motion\nlevels. Furthermore, the agentic system periodically examines the movements of\ninterlocutors and infers their intentions, forming a continuous feedback loop\nthat enables dynamic and responsive interactions between the two participants.\nUser studies and quantitative evaluations show that our model significantly\nimproves the quality of dyadic interactions, producing natural, synchronized\nnonverbal behaviors.", "published": "2025-10-06 09:41:37", "link": "http://arxiv.org/abs/2510.04637v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "A Spatial-Spectral-Frequency Interactive Network for Multimodal Remote Sensing Classification", "abstract": "Deep learning-based methods have achieved significant success in remote\nsensing Earth observation data analysis. Numerous feature fusion techniques\naddress multimodal remote sensing image classification by integrating global\nand local features. However, these techniques often struggle to extract\nstructural and detail features from heterogeneous and redundant multimodal\nimages. With the goal of introducing frequency domain learning to model key and\nsparse detail features, this paper introduces the spatial-spectral-frequency\ninteraction network (S$^2$Fin), which integrates pairwise fusion modules across\nthe spatial, spectral, and frequency domains. Specifically, we propose a\nhigh-frequency sparse enhancement transformer that employs sparse\nspatial-spectral attention to optimize the parameters of the high-frequency\nfilter. Subsequently, a two-level spatial-frequency fusion strategy is\nintroduced, comprising an adaptive frequency channel module that fuses\nlow-frequency structures with enhanced high-frequency details, and a\nhigh-frequency resonance mask that emphasizes sharp edges via phase similarity.\nIn addition, a spatial-spectral attention fusion module further enhances\nfeature extraction at intermediate layers of the network. Experiments on four\nbenchmark multimodal datasets with limited labeled data demonstrate that\nS$^2$Fin performs superior classification, outperforming state-of-the-art\nmethods. The code is available at https://github.com/HaoLiu-XDU/SSFin.", "published": "2025-10-06 09:33:35", "link": "http://arxiv.org/abs/2510.04628v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole Slide Image Diagnosis Behavior", "abstract": "Diagnosing a whole-slide image is an interactive, multi-stage process\ninvolving changes in magnification and movement between fields. Although recent\npathology foundation models are strong, practical agentic systems that decide\nwhat field to examine next, adjust magnification, and deliver explainable\ndiagnoses are still lacking. The blocker is data: scalable, clinically aligned\nsupervision of expert viewing behavior that is tacit and experience-based, not\nwritten in textbooks or online, and therefore absent from large language model\ntraining. We introduce the AI Session Recorder, which works with standard WSI\nviewers to unobtrusively record routine navigation and convert the viewer logs\ninto standardized behavioral commands (inspect or peek at discrete\nmagnifications) and bounding boxes. A lightweight human-in-the-loop review\nturns AI-drafted rationales into the Pathology-CoT dataset, a form of paired\n\"where to look\" and \"why it matters\" supervision produced at roughly six times\nlower labeling time. Using this behavioral data, we build Pathologist-o3, a\ntwo-stage agent that first proposes regions of interest and then performs\nbehavior-guided reasoning. On gastrointestinal lymph-node metastasis detection,\nit achieved 84.5% precision, 100.0% recall, and 75.4% accuracy, exceeding the\nstate-of-the-art OpenAI o3 model and generalizing across backbones. To our\nknowledge, this constitutes one of the first behavior-grounded agentic systems\nin pathology. Turning everyday viewer logs into scalable, expert-validated\nsupervision, our framework makes agentic pathology practical and establishes a\npath to human-aligned, upgradeable clinical AI.", "published": "2025-10-06 08:44:04", "link": "http://arxiv.org/abs/2510.04587v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Conditional Representation Learning for Customized Tasks", "abstract": "Conventional representation learning methods learn a universal representation\nthat primarily captures dominant semantics, which may not always align with\ncustomized downstream tasks. For instance, in animal habitat analysis,\nresearchers prioritize scene-related features, whereas universal embeddings\nemphasize categorical semantics, leading to suboptimal results. As a solution,\nexisting approaches resort to supervised fine-tuning, which however incurs high\ncomputational and annotation costs. In this paper, we propose Conditional\nRepresentation Learning (CRL), aiming to extract representations tailored to\narbitrary user-specified criteria. Specifically, we reveal that the semantics\nof a space are determined by its basis, thereby enabling a set of descriptive\nwords to approximate the basis for a customized feature space. Building upon\nthis insight, given a user-specified criterion, CRL first employs a large\nlanguage model (LLM) to generate descriptive texts to construct the semantic\nbasis, then projects the image representation into this conditional feature\nspace leveraging a vision-language model (VLM). The conditional representation\nbetter captures semantics for the specific criterion, which could be utilized\nfor multiple customized tasks. Extensive experiments on classification and\nretrieval tasks demonstrate the superiority and generality of the proposed CRL.\nThe code is available at https://github.com/XLearning-SCU/2025-NeurIPS-CRL.", "published": "2025-10-06 08:00:59", "link": "http://arxiv.org/abs/2510.04564v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fast Witness Persistence for MRI Volumes via Hybrid Landmarking", "abstract": "We introduce a scalable witness-based persistent homology pipeline for\nfull-brain MRI volumes that couples density-aware landmark selection with a\nGPU-ready witness filtration. Candidates are scored by a hybrid metric that\nbalances geometric coverage against inverse kernel density, yielding landmark\nsets that shrink mean pairwise distances by 30-60% over random or density-only\nbaselines while preserving topological features. Benchmarks on BrainWeb, IXI,\nand synthetic manifolds execute in under ten seconds on a single NVIDIA RTX\n4090 GPU, avoiding the combinatorial blow-up of Cech, Vietoris-Rips, and alpha\nfiltrations. The package is distributed on PyPI as whale-tda (installable via\npip); source and issues are hosted at https://github.com/jorgeLRW/whale. The\nrelease also exposes a fast preset (mri_deep_dive_fast) for exploratory sweeps,\nand ships with reproducibility-focused scripts and artifacts for drop-in use in\nmedical imaging workflows.", "published": "2025-10-06 07:34:21", "link": "http://arxiv.org/abs/2510.04553v1", "categories": ["cs.CG", "cs.CV", "cs.LG"], "primary_category": "cs.CG"}
{"title": "Post-training quantization of vision encoders needs prefixing registers", "abstract": "Transformer-based vision encoders -- such as CLIP -- are central to\nmultimodal intelligence, powering applications from autonomous web agents to\nrobotic control. Since these applications often demand real-time processing of\nmassive visual data, reducing the inference cost of vision encoders is\ncritical. Post-training quantization offers a practical path, but remains\nchallenging even at 8-bit precision due to massive-scale activations (i.e.,\noutliers). In this work, we propose $\\textit{RegCache}$, a training-free\nalgorithm to mitigate outliers in vision encoders, enabling quantization with\nsignificantly smaller accuracy drops. The proposed RegCache introduces\noutlier-prone yet semantically meaningless prefix tokens to the target vision\nencoder, which prevents other tokens from having outliers. Notably, we observe\nthat outliers in vision encoders behave differently from those in language\nmodels, motivating two technical innovations: middle-layer prefixing and token\ndeletion. Experiments show that our method consistently improves the accuracy\nof quantized models across both text-supervised and self-supervised vision\nencoders.", "published": "2025-10-06 07:27:46", "link": "http://arxiv.org/abs/2510.04547v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "C3Editor: Achieving Controllable Consistency in 2D Model for 3D Editing", "abstract": "Existing 2D-lifting-based 3D editing methods often encounter challenges\nrelated to inconsistency, stemming from the lack of view-consistent 2D editing\nmodels and the difficulty of ensuring consistent editing across multiple views.\nTo address these issues, we propose C3Editor, a controllable and consistent\n2D-lifting-based 3D editing framework. Given an original 3D representation and\na text-based editing prompt, our method selectively establishes a\nview-consistent 2D editing model to achieve superior 3D editing results. The\nprocess begins with the controlled selection of a ground truth (GT) view and\nits corresponding edited image as the optimization target, allowing for\nuser-defined manual edits. Next, we fine-tune the 2D editing model within the\nGT view and across multiple views to align with the GT-edited image while\nensuring multi-view consistency. To meet the distinct requirements of GT view\nfitting and multi-view consistency, we introduce separate LoRA modules for\ntargeted fine-tuning. Our approach delivers more consistent and controllable 2D\nand 3D editing results than existing 2D-lifting-based methods, outperforming\nthem in both qualitative and quantitative evaluations.", "published": "2025-10-06 07:07:14", "link": "http://arxiv.org/abs/2510.04539v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "3Dify: a Framework for Procedural 3D-CG Generation Assisted by LLMs Using MCP and RAG", "abstract": "This paper proposes \"3Dify,\" a procedural 3D computer graphics (3D-CG)\ngeneration framework utilizing Large Language Models (LLMs). The framework\nenables users to generate 3D-CG content solely through natural language\ninstructions. 3Dify is built upon Dify, an open-source platform for AI\napplication development, and incorporates several state-of-the-art LLM-related\ntechnologies such as the Model Context Protocol (MCP) and Retrieval-Augmented\nGeneration (RAG). For 3D-CG generation support, 3Dify automates the operation\nof various Digital Content Creation (DCC) tools via MCP. When DCC tools do not\nsupport MCP-based interaction, the framework employs the Computer-Using Agent\n(CUA) method to automate Graphical User Interface (GUI) operations. Moreover,\nto enhance image generation quality, 3Dify allows users to provide feedback by\nselecting preferred images from multiple candidates. The LLM then learns\nvariable patterns from these selections and applies them to subsequent\ngenerations. Furthermore, 3Dify supports the integration of locally deployed\nLLMs, enabling users to utilize custom-developed models and to reduce both time\nand monetary costs associated with external API calls by leveraging their own\ncomputational resources.", "published": "2025-10-06 07:00:06", "link": "http://arxiv.org/abs/2510.04536v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion Sampling", "abstract": "Recent diffusion models achieve the state-of-the-art performance in image\ngeneration, but often suffer from semantic inconsistencies or hallucinations.\nWhile various inference-time guidance methods can enhance generation, they\noften operate indirectly by relying on external signals or architectural\nmodifications, which introduces additional computational overhead. In this\npaper, we propose Tangential Amplifying Guidance (TAG), a more efficient and\ndirect guidance method that operates solely on trajectory signals without\nmodifying the underlying diffusion model. TAG leverages an intermediate sample\nas a projection basis and amplifies the tangential components of the estimated\nscores with respect to this basis to correct the sampling trajectory. We\nformalize this guidance process by leveraging a first-order Taylor expansion,\nwhich demonstrates that amplifying the tangential component steers the state\ntoward higher-probability regions, thereby reducing inconsistencies and\nenhancing sample quality. TAG is a plug-and-play, architecture-agnostic module\nthat improves diffusion sampling fidelity with minimal computational addition,\noffering a new perspective on diffusion guidance.", "published": "2025-10-06 06:53:29", "link": "http://arxiv.org/abs/2510.04533v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Real-time Prediction of Urban Sound Propagation with Conditioned Normalizing Flows", "abstract": "Accurate and fast urban noise prediction is pivotal for public health and for\nregulatory workflows in cities, where the Environmental Noise Directive\nmandates regular strategic noise maps and action plans, often needed in\npermission workflows, right-of-way allocation, and construction scheduling.\nPhysics-based solvers are too slow for such time-critical, iterative \"what-if\"\nstudies. We evaluate conditional Normalizing Flows (Full-Glow) for generating\nfor generating standards-compliant urban sound-pressure maps from 2D urban\nlayouts in real time per 256x256 map on a single RTX 4090), enabling\ninteractive exploration directly on commodity hardware. On datasets covering\nBaseline, Diffraction, and Reflection regimes, our model accelerates map\ngeneration by >2000 times over a reference solver while improving NLoS accuracy\nby up to 24% versus prior deep models; in Baseline NLoS we reach 0.65 dB MAE\nwith high structural fidelity. The model reproduces diffraction and\ninterference patterns and supports instant recomputation under source or\ngeometry changes, making it a practical engine for urban planning, compliance\nmapping, and operations (e.g., temporary road closures, night-work variance\nassessments).", "published": "2025-10-06 06:00:08", "link": "http://arxiv.org/abs/2510.04510v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Asynchronous Denoising Diffusion Models for Aligning Text-to-Image Generation", "abstract": "Diffusion models have achieved impressive results in generating high-quality\nimages. Yet, they often struggle to faithfully align the generated images with\nthe input prompts. This limitation arises from synchronous denoising, where all\npixels simultaneously evolve from random noise to clear images. As a result,\nduring generation, the prompt-related regions can only reference the unrelated\nregions at the same noise level, failing to obtain clear context and ultimately\nimpairing text-to-image alignment. To address this issue, we propose\nasynchronous diffusion models -- a novel framework that allocates distinct\ntimesteps to different pixels and reformulates the pixel-wise denoising\nprocess. By dynamically modulating the timestep schedules of individual pixels,\nprompt-related regions are denoised more gradually than unrelated regions,\nthereby allowing them to leverage clearer inter-pixel context. Consequently,\nthese prompt-related regions achieve better alignment in the final images.\nExtensive experiments demonstrate that our asynchronous diffusion models can\nsignificantly improve text-to-image alignment across diverse prompts. The code\nrepository for this work is available at https://github.com/hu-zijing/AsynDM.", "published": "2025-10-06 05:45:56", "link": "http://arxiv.org/abs/2510.04504v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TBStar-Edit: From Image Editing Pattern Shifting to Consistency Enhancement", "abstract": "Recent advances in image generation and editing technologies have enabled\nstate-of-the-art models to achieve impressive results in general domains.\nHowever, when applied to e-commerce scenarios, these general models often\nencounter consistency limitations. To address this challenge, we introduce\nTBStar-Edit, an new image editing model tailored for the e-commerce domain.\nThrough rigorous data engineering, model architecture design and training\nstrategy, TBStar-Edit achieves precise and high-fidelity image editing while\nmaintaining the integrity of product appearance and layout. Specifically, for\ndata engineering, we establish a comprehensive data construction pipeline,\nencompassing data collection, construction, filtering, and augmentation, to\nacquire high-quality, instruction-following, and strongly consistent editing\ndata to support model training. For model architecture design, we design a\nhierarchical model framework consisting of a base model, pattern shifting\nmodules, and consistency enhancement modules. For model training, we adopt a\ntwo-stage training strategy to enhance the consistency preservation: first\nstage for editing pattern shifting, and second stage for consistency\nenhancement. Each stage involves training different modules with separate\ndatasets. Finally, we conduct extensive evaluations of TBStar-Edit on a\nself-proposed e-commerce benchmark, and the results demonstrate that\nTBStar-Edit outperforms existing general-domain editing models in both\nobjective metrics (VIE Score) and subjective user preference.", "published": "2025-10-06 04:46:42", "link": "http://arxiv.org/abs/2510.04483v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery", "abstract": "Vision-Language Models (VLMs) have achieved significant progress in\nmultimodal understanding tasks, demonstrating strong capabilities particularly\nin general tasks such as image captioning and visual reasoning. However, when\ndealing with specialized cultural heritage domains like 3D vase artifacts,\nexisting models face severe data scarcity issues and insufficient domain\nknowledge limitations. Due to the lack of targeted training data, current VLMs\nstruggle to effectively handle such culturally significant specialized tasks.\nTo address these challenges, we propose the VaseVQA-3D dataset, which serves as\nthe first 3D visual question answering dataset for ancient Greek pottery\nanalysis, collecting 664 ancient Greek vase 3D models with corresponding\nquestion-answer data and establishing a complete data construction pipeline. We\nfurther develop the VaseVLM model, enhancing model performance in vase artifact\nanalysis through domain-adaptive training. Experimental results validate the\neffectiveness of our approach, where we improve by 12.8% on R@1 metrics and by\n6.6% on lexical similarity compared with previous state-of-the-art on the\nVaseVQA-3D dataset, significantly improving the recognition and understanding\nof 3D vase artifacts, providing new technical pathways for digital heritage\npreservation research.", "published": "2025-10-06 04:28:39", "link": "http://arxiv.org/abs/2510.04479v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SPEGNet: Synergistic Perception-Guided Network for Camouflaged Object Detection", "abstract": "Camouflaged object detection segments objects with intrinsic similarity and\nedge disruption. Current detection methods rely on accumulated complex\ncomponents. Each approach adds components such as boundary modules, attention\nmechanisms, and multi-scale processors independently. This accumulation creates\na computational burden without proportional gains. To manage this complexity,\nthey process at reduced resolutions, eliminating fine details essential for\ncamouflage. We present SPEGNet, addressing fragmentation through a unified\ndesign. The architecture integrates multi-scale features via channel\ncalibration and spatial enhancement. Boundaries emerge directly from\ncontext-rich representations, maintaining semantic-spatial alignment.\nProgressive refinement implements scale-adaptive edge modulation with peak\ninfluence at intermediate resolutions. This design strikes a balance between\nboundary precision and regional consistency. SPEGNet achieves 0.887 $S_\\alpha$\non CAMO, 0.890 on COD10K, and 0.895 on NC4K, with real-time inference speed.\nOur approach excels across scales, from tiny, intricate objects to large,\npattern-similar ones, while handling occlusion and ambiguous boundaries. Code,\nmodel weights, and results are available on\n\\href{https://github.com/Baber-Jan/SPEGNet}{https://github.com/Baber-Jan/SPEGNet}.", "published": "2025-10-06 04:06:40", "link": "http://arxiv.org/abs/2510.04472v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer Consistency Regularization", "abstract": "Visual autoregressive (AR) generation offers a promising path toward unifying\nvision and language models, yet its performance remains suboptimal against\ndiffusion models. Prior work often attributes this gap to tokenizer limitations\nand rasterization ordering. In this work, we identify a core bottleneck from\nthe perspective of generator-tokenizer inconsistency, i.e., the AR-generated\ntokens may not be well-decoded by the tokenizer. To address this, we propose\nreAR, a simple training strategy introducing a token-wise regularization\nobjective: when predicting the next token, the causal transformer is also\ntrained to recover the visual embedding of the current token and predict the\nembedding of the target token under a noisy context. It requires no changes to\nthe tokenizer, generation order, inference pipeline, or external models.\nDespite its simplicity, reAR substantially improves performance. On ImageNet,\nit reduces gFID from 3.02 to 1.86 and improves IS to 316.9 using a standard\nrasterization-based tokenizer. When applied to advanced tokenizers, it achieves\na gFID of 1.42 with only 177M parameters, matching the performance with larger\nstate-of-the-art diffusion models (675M).", "published": "2025-10-06 02:48:13", "link": "http://arxiv.org/abs/2510.04450v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering", "abstract": "Effectively applying Vision-Language Models (VLMs) to Video Question\nAnswering (VideoQA) hinges on selecting a concise yet comprehensive set of\nframes, as processing entire videos is computationally infeasible. However,\ncurrent frame selection methods face a critical trade-off: approaches relying\non lightweight similarity models, such as CLIP, often fail to capture the\nnuances of complex queries, resulting in inaccurate similarity scores that\ncannot reflect the authentic query-frame relevance, which further undermines\nframe selection. Meanwhile, methods that leverage a VLM for deeper analysis\nachieve higher accuracy but incur prohibitive computational costs. To address\nthese limitations, we propose A.I.R., a training-free approach for Adaptive,\nIterative, and Reasoning-based frame selection. We leverage a powerful VLM to\nperform deep, semantic analysis on complex queries, and this analysis is\ndeployed within a cost-effective iterative loop that processes only a small\nbatch of the most high-potential frames at a time. Extensive experiments on\nvarious VideoQA benchmarks demonstrate that our approach outperforms existing\nframe selection methods, significantly boosts the performance of the foundation\nVLM, and achieves substantial gains in computational efficiency over other\nVLM-based techniques.", "published": "2025-10-06 01:51:13", "link": "http://arxiv.org/abs/2510.04428v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CodeFormer++: Blind Face Restoration Using Deformable Registration and Deep Metric Learning", "abstract": "Blind face restoration (BFR) has attracted increasing attention with the rise\nof generative methods. Most existing approaches integrate generative priors\ninto the restoration pro- cess, aiming to jointly address facial detail\ngeneration and identity preservation. However, these methods often suffer from\na trade-off between visual quality and identity fidelity, leading to either\nidentity distortion or suboptimal degradation removal. In this paper, we\npresent CodeFormer++, a novel framework that maximizes the utility of\ngenerative priors for high-quality face restoration while preserving identity.\nWe decompose BFR into three sub-tasks: (i) identity- preserving face\nrestoration, (ii) high-quality face generation, and (iii) dynamic fusion of\nidentity features with realistic texture details. Our method makes three key\ncontributions: (1) a learning-based deformable face registration module that\nsemantically aligns generated and restored faces; (2) a texture guided\nrestoration network to dynamically extract and transfer the texture of\ngenerated face to boost the quality of identity-preserving restored face; and\n(3) the integration of deep metric learning for BFR with the generation of\ninformative positive and hard negative samples to better fuse identity-\npreserving and generative features. Extensive experiments on real-world and\nsynthetic datasets demonstrate that, the pro- posed CodeFormer++ achieves\nsuperior performance in terms of both visual fidelity and identity consistency.", "published": "2025-10-06 00:53:50", "link": "http://arxiv.org/abs/2510.04410v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting", "abstract": "Vision-Language Models (VLMs) have become a central focus of today's AI\ncommunity, owing to their impressive abilities gained from training on\nlarge-scale vision-language data from the Web. These models have demonstrated\nstrong performance across diverse tasks, including image understanding, video\nunderstanding, complex visual reasoning, and embodied AI. Despite these\nnoteworthy successes, a fundamental question remains: Can VLMs count objects\ncorrectly? In this paper, we introduce a simple yet effective benchmark,\nVLMCountBench, designed under a minimalist setting with only basic geometric\nshapes (e.g., triangles, circles) and their compositions, focusing exclusively\non counting tasks without interference from other factors. We adopt strict\nindependent variable control and systematically study the effects of simple\nproperties such as color, size, and prompt refinement in a controlled ablation.\nOur empirical results reveal that while VLMs can count reliably when only one\nshape type is present, they exhibit substantial failures when multiple shape\ntypes are combined (i.e., compositional counting). This highlights a\nfundamental empirical limitation of current VLMs and motivates important\ndirections for future research.", "published": "2025-10-06 00:11:24", "link": "http://arxiv.org/abs/2510.04401v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Discrete scalar curvature as a weighted sum of Ollivier-Ricci curvatures", "abstract": "We study the relationship between discrete analogues of Ricci and scalar\ncurvature that are defined for point clouds and graphs. In the discrete\nsetting, Ricci curvature is replaced by Ollivier-Ricci curvature. Scalar\ncurvature can be computed as the trace of Ricci curvature for a Riemannian\nmanifold; this motivates a new definition of a scalar version of Ollivier-Ricci\ncurvature. We show that our definition converges to scalar curvature for\nnearest neighbor graphs obtained by sampling from a manifold. We also prove\nsome new results about the convergence of Ollivier-Ricci curvature to Ricci\ncurvature.", "published": "2025-10-06 15:43:07", "link": "http://arxiv.org/abs/2510.04936v1", "categories": ["cs.DM", "cs.CG", "cs.SI", "stat.ML"], "primary_category": "cs.DM"}
{"title": "Maximum Biclique for Star 1,2,3 -free and Bounded Bimodularwidth Twin-free Bipartite Graphs $\\star$", "abstract": "There are three usual definitions of a maximum bipartite clique (biclique) in\na bipartite graph\\,: either maximizing the number of vertices, or of edges, or\nfinding a maximum balanced biclique. The first problem can be solved in\npolynomial time, the last ones are NP-complete. Here we show how these three\nproblems may be efficiently solved for two classes of bipartite graphs:\nStar123-free twin-free graphs, and bounded bimodularwidth twin-free graphs, a\nclass that may be defined using bimodular decomposition. Our computation\nrequires O(n^2) time and requires a decomposition is provided, which takes\nrespectively O(n + m) and O(mn^3) time.", "published": "2025-10-06 09:32:05", "link": "http://arxiv.org/abs/2510.04621v1", "categories": ["cs.DM", "cs.DS"], "primary_category": "cs.DM"}
{"title": "Topic-Specific Classifiers are Better Relevance Judges than Prompted LLMs", "abstract": "The unjudged document problem, where pooled test collections have incomplete\nrelevance judgments for evaluating new retrieval systems, is a key obstacle to\nthe reusability of test collections in information retrieval. While the de\nfacto standard to deal with the problem is to treat unjudged documents as\nnon-relevant, many alternatives have been proposed, including the use of large\nlanguage models (LLMs) as a relevance judge (LLM-as-a-judge). However, this has\nbeen criticized as circular, since the same LLM can be used as a judge and as a\nranker at the same time. We propose to train topic-specific relevance\nclassifiers instead: By finetuning monoT5 with independent LoRA weight\nadaptation on the judgments of a single assessor for a single topic's pool, we\nalign it to that assessor's notion of relevance for the topic. The system\nrankings obtained through our classifier's relevance judgments achieve a\nSpearmans' $\\rho$ correlation of $>0.95$ with ground truth system rankings. As\nlittle as 128 initial human judgments per topic suffice to improve the\ncomparability of models, compared to treating unjudged documents as\nnon-relevant, while achieving more reliability than existing LLM-as-a-judge\napproaches. Topic-specific relevance classifiers thus are a lightweight and\nstraightforward way to tackle the unjudged document problem, while maintaining\nhuman judgments as the gold standard for retrieval evaluation. Code, models,\nand data are made openly available.", "published": "2025-10-06 09:38:13", "link": "http://arxiv.org/abs/2510.04633v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "MARCO: A Cooperative Knowledge Transfer Framework for Personalized Cross-domain Recommendations", "abstract": "Recommender systems frequently encounter data sparsity issues, particularly\nwhen addressing cold-start scenarios involving new users or items. Multi-source\ncross-domain recommendation (CDR) addresses these challenges by transferring\nvaluable knowledge from multiple source domains to enhance recommendations in a\ntarget domain. However, existing reinforcement learning (RL)-based CDR methods\ntypically rely on a single-agent framework, leading to negative transfer issues\ncaused by inconsistent domain contributions and inherent distributional\ndiscrepancies among source domains. To overcome these limitations, MARCO, a\nMulti-Agent Reinforcement Learning-based Cross-Domain recommendation framework,\nis proposed. It leverages cooperative multi-agent reinforcement learning, where\neach agent is dedicated to estimating the contribution from an individual\nsource domain, effectively managing credit assignment and mitigating negative\ntransfer. In addition, an entropy-based action diversity penalty is introduced\nto enhance policy expressiveness and stabilize training by encouraging diverse\nagents' joint actions. Extensive experiments across four benchmark datasets\ndemonstrate MARCO's superior performance over state-of-the-art methods,\nhighlighting its robustness and strong generalization capabilities. The code is\nat https://github.com/xiewilliams/MARCO.", "published": "2025-10-06 05:49:47", "link": "http://arxiv.org/abs/2510.04508v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Causality-aware Graph Aggregation Weight Estimator for Popularity Debiasing in Top-K Recommendation", "abstract": "Graph-based recommender systems leverage neighborhood aggregation to generate\nnode representations, which is highly sensitive to popularity bias, resulting\nin an echo effect during information propagation. Existing graph-based\ndebiasing solutions refine the aggregation process with attempts such as edge\nreconstruction or weight adjustment. However, these methods remain inadequate\nin fully alleviating popularity bias. Specifically, this is because 1) they\nprovide no insights into graph aggregation rationality, thus lacking an\noptimality guarantee; 2) they fail to well balance the training and debiasing\nprocess, which undermines the effectiveness. In this paper, we propose a novel\napproach to mitigate popularity bias through rational modeling of the graph\naggregation process. We reveal that graph aggregation is a special form of\nbackdoor adjustment in causal inference, where the aggregation weight\ncorresponds to the historical interaction likelihood distribution. Based on\nthis insight, we devise an encoder-decoder architecture, namely Causality-aware\nGraph Aggregation Weight Estimator for Debiasing (CAGED), to approximate the\nunbiased aggregation weight by optimizing the evidence lower bound of the\ninteraction likelihood. In order to enhance the debiasing effectiveness during\nearly training stages, we further design a momentum update strategy that\nincrementally refines the aggregation weight matrix. Extensive experiments on\nthree datasets demonstrate that CAGED outperforms existing graph-based\ndebiasing methods. Our implementation is available at\nhttps://github.com/QueYork/CAGED.", "published": "2025-10-06 05:33:37", "link": "http://arxiv.org/abs/2510.04502v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Multi-Agent Distributed Optimization With Feasible Set Privacy", "abstract": "We consider the problem of decentralized constrained optimization with\nmultiple agents $E_1,\\ldots,E_N$ who jointly wish to learn the optimal solution\nset while keeping their feasible sets $\\mathcal{P}_1,\\ldots,\\mathcal{P}_N$\nprivate from each other. We assume that the objective function $f$ is known to\nall agents and each feasible set is a collection of points from a universal\nalphabet $\\mathcal{P}_{alph}$. A designated agent (leader) starts the\ncommunication with the remaining (non-leader) agents, and is the first to\nretrieve the solution set. The leader searches for the solution by sending\nqueries to and receiving answers from the non-leaders, such that the\ninformation on the individual feasible sets revealed to the leader should be no\nmore than nominal, i.e., what is revealed from learning the solution set alone.\nWe develop achievable schemes for obtaining the solution set at nominal\ninformation leakage, and characterize their communication costs under two\ncommunication setups between agents. In this work, we focus on two kinds of\nnetwork setups: i) ring, where each agent communicates with two adjacent\nagents, and ii) star, where only the leader communicates with the remaining\nagents. We show that, if the leader first learns the joint feasible set through\nan existing private set intersection (PSI) protocol and then deduces the\nsolution set, the information leaked to the leader is greater than nominal.\nMoreover, we draw connection of our schemes to threshold PSI (ThPSI), which is\na PSI-variant where the intersection is revealed only when its cardinality is\nlarger than a threshold value. Finally, for various realizations of $f$ mapped\nuniformly at random to a fixed range of values, our schemes are more\ncommunication-efficient with a high probability compared to retrieving the\nentire feasible set through PSI.", "published": "2025-10-06 17:45:57", "link": "http://arxiv.org/abs/2510.05068v1", "categories": ["cs.IT", "cs.CR", "cs.DC", "cs.NI", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "My First Five Years of Faculty Career at the University of Delaware", "abstract": "In this short article, I would like to briefly summarize my research in the\nfirst 5 years in my university academia life in USA. I think that my research\nresults obtained in these 5 years are the best in my career, at least which I\nlike the most by myself. I wish that my experience in my junior academia career\ncould be of some help to young researchers.", "published": "2025-10-06 16:39:19", "link": "http://arxiv.org/abs/2510.05000v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Learning Function-to-Function Mappings: A Fourier Neural Operator for Next-Generation MIMO Systems", "abstract": "Next-generation multiple-input multiple-output (MIMO) systems, characterized\nby extremely large-scale arrays, holographic surfaces, three-dimensional\narchitectures, and flexible antennas, are poised to deliver unprecedented data\nrates, spectral efficiency and stability. However, these advancements introduce\nsignificant challenges for physical layer signal processing, stemming from\ncomplex near-field propagation, continuous aperture modeling, sub-wavelength\nantenna coupling effects, and dynamic channel conditions. Conventional\nmodel-based and deep learning approaches often struggle with the immense\ncomputational complexity and model inaccuracies inherent in these new regimes.\nThis article proposes a Fourier neural operator (FNO) as a powerful and\npromising tool to address these challenges. The FNO learns function-to-function\nmappings between infinite-dimensional function spaces, making them\nexceptionally well-suited for modeling complex physical systems governed by\npartial differential equations based on electromagnetic wave propagation. We\nfirst present the fundamental principles of FNO, demonstrating its mesh-free\nnature and function-to-function ability to efficiently capture global\ndependencies in the Fourier domain. Furthermore, we explore a range of\napplications of FNO in physical-layer signal processing for next-generation\nMIMO systems. Representative case studies on channel modeling and estimation\nfor novel MIMO architectures demonstrate the superior performance of FNO\ncompared to state-of-the-art methods. Finally, we discuss open challenges and\noutline future research directions, positioning FNO as a promising technology\nfor enabling the enormous potential of next-generation MIMO systems.", "published": "2025-10-06 10:19:18", "link": "http://arxiv.org/abs/2510.04664v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quantum Reverse Shannon Theorem Simplified", "abstract": "We revisit the quantum reverse Shannon theorem, a central result in quantum\ninformation theory that characterizes the resources needed to simulate quantum\nchannels when entanglement is freely available. We derive a universal additive\nupper bound on the smoothed max-information in terms of the sandwiched R\\'enyi\nmutual information. This bound yields tighter single-shot results, eliminates\nthe need for the post-selection technique, and leads to a conceptually simpler\nproof of the quantum reverse Shannon theorem. By consolidating and streamlining\nearlier approaches, our result provides a clearer and more direct understanding\nof the resource costs of simulating quantum channels.", "published": "2025-10-06 07:34:20", "link": "http://arxiv.org/abs/2510.04552v1", "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "quant-ph"}
{"title": "Quantum capacity amplification via privacy", "abstract": "We investigate superadditivity of quantum capacity through private channels\nwhose Choi-Jamiolkowski operators are private states. This perspective links\nthe security structure of private states to quantum capacity and clarifies the\nrole of the shield system: information encoded in the shield system that would\notherwise leak to the environment can be recycled when paired with an assisting\nchannel, thereby boosting capacity. Our main contributions are threefold:\nFirstly, we develop a general framework that provides a sufficient condition\nfor capacity amplification, which is formulated in terms of the assisting\nchannel's Holevo information. As examples, we give explicit, dimension and\nparameter dependent amplification thresholds for erasure and depolarizing\nchannels. Secondly, assuming the Spin alignment conjecture, we derive a\nsingle-letter expression for the quantum capacity of a family of private\nchannels that are neither degradable, anti-degradable, nor PPT; as an\napplication, we construct channels with vanishing quantum capacity yet\nunbounded private capacity. Thirdly, we further analyze approximate private\nchannels: we give an alternative proof of superactivation that extends its\nvalidity to a broader parameter regime, and, by combining amplification bounds\nwith continuity estimates, we establish a metric separation showing that\nchannels exhibiting capacity amplification have nonzero diamond distance from\nthe set of anti-degradable channels, indicating that existing approximate\n(anti-)degradability bounds are not tight. We also revisit the computability of\nthe regularized quantum capacity and modestly suggest that this fundamental\nquestion still remains open.", "published": "2025-10-06 06:35:19", "link": "http://arxiv.org/abs/2510.04527v1", "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "quant-ph"}
{"title": "Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning", "abstract": "Multi-agent debate often wastes compute by using a fixed adversarial stance,\naggregating without deliberation, or stopping on heuristics. We introduce MACI,\nan active controller with two independent dials that decouple information from\nbehavior: an information dial that gates evidence by quality, and a behavior\ndial that schedules contentiousness from exploration to consolidation. A\nmoderator tracks disagreement, overlap, evidence quality, and argument quality,\nand halts when gains plateau. We provide theory-lite guarantees for\nnonincreasing dispersion and provable termination, with a budget-feasible\nscheduler. Across clinical diagnosis and news-bias tasks, MACI improves\naccuracy and calibration while reducing tokens, and converts residual\nuncertainty into precision RAG plans that specify what to retrieve next. We use\na cross-family LLM judge (CRIT) as a conservative soft weight and stop signal,\nvalidated for order invariance and judge-swap stability; stability depends on\nusing high-capability judges. MACI turns debate into a budget-aware,\nmeasurable, and provably terminating controller.", "published": "2025-10-06 04:52:17", "link": "http://arxiv.org/abs/2510.04488v1", "categories": ["cs.AI", "cs.IT", "math.IT", "I.2.4"], "primary_category": "cs.AI"}
{"title": "Compressed Newton-direction-based Thresholding Methods for Sparse Optimization Problems", "abstract": "Thresholding algorithms for sparse optimization problems involve two key\ncomponents: search directions and thresholding strategies. In this paper, we\nuse the compressed Newton direction as a search direction, derived by confining\nthe classical Newton step to a low-dimensional subspace and embedding it back\ninto the full space with diagonal regularization. This approach significantly\nreduces the computational cost for finding the search direction while\nmaintaining the efficiency of Newton-like methods. Based on this new search\ndirection, we propose two major classes of algorithms by adopting hard or\noptimal thresholding: the compressed Newton-direction-based thresholding\npursuit (CNHTP) and compressed Newton-direction-based optimal thresholding\npursuit (CNOTP). We establish the global convergence of the proposed algorithms\nunder the restricted isometry property. Experimental results demonstrate that\nthe proposed algorithms perform comparably to several state-of-the-art methods\nin terms of success frequency and solution accuracy for solving the sparse\noptimization problem.", "published": "2025-10-06 02:58:12", "link": "http://arxiv.org/abs/2510.04451v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "MICROTRIPS: MICRO-geography TRavel Intelligence and Pattern Synthesis", "abstract": "This study presents a novel small-area estimation framework to enhance urban\ntransportation planning through detailed characterization of travel behavior.\nOur approach improves on the four-step travel model by employing publicly\navailable microdata files and machine learning methods to predict travel\nbehavior for a representative, synthetic population at small geographic areas.\nThis approach enables high-resolution estimation of trip generation, trip\ndistribution, mode choice, and route assignment. Validation using ACS/PUMS\nwork-commute datasets demonstrates that our framework achieves higher accuracy\ncompared to conventional approaches. The resulting granular insights enable the\ntailoring of interventions to address localized situations and support a range\nof policy applications and targeted interventions, including the optimal\nplacement of micro-fulfillment centers, effective curb-space management, and\nthe design of more inclusive transportation solutions particularly for\nvulnerable communities.", "published": "2025-10-06 17:50:56", "link": "http://arxiv.org/abs/2510.05080v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning", "abstract": "Humanoid whole-body loco-manipulation promises transformative capabilities\nfor daily service and warehouse tasks. While recent advances in general motion\ntracking (GMT) have enabled humanoids to reproduce diverse human motions, these\npolicies lack the precision and object awareness required for\nloco-manipulation. To this end, we introduce ResMimic, a two-stage residual\nlearning framework for precise and expressive humanoid control from human\nmotion data. First, a GMT policy, trained on large-scale human-only motion,\nserves as a task-agnostic base for generating human-like whole-body movements.\nAn efficient but precise residual policy is then learned to refine the GMT\noutputs to improve locomotion and incorporate object interaction. To further\nfacilitate efficient training, we design (i) a point-cloud-based object\ntracking reward for smoother optimization, (ii) a contact reward that\nencourages accurate humanoid body-object interactions, and (iii) a\ncurriculum-based virtual object controller to stabilize early training. We\nevaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Results\nshow substantial gains in task success, training efficiency, and robustness\nover strong baselines. Videos are available at https://resmimic.github.io/ .", "published": "2025-10-06 17:47:02", "link": "http://arxiv.org/abs/2510.05070v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Boomerang Distillation Enables Zero-Shot Model Size Interpolation", "abstract": "Large language models (LLMs) are typically deployed under diverse memory and\ncompute constraints. Existing approaches build model families by training each\nsize independently, which is prohibitively expensive and provides only\ncoarse-grained size options. In this work, we identify a novel phenomenon that\nwe call boomerang distillation: starting from a large base model (the teacher),\none first distills down to a small student and then progressively reconstructs\nintermediate-sized models by re-incorporating blocks of teacher layers into the\nstudent without any additional training. This process produces zero-shot\ninterpolated models of many intermediate sizes whose performance scales\nsmoothly between the student and teacher, often matching or surpassing\npretrained or distilled models of the same size. We further analyze when this\ntype of interpolation succeeds, showing that alignment between teacher and\nstudent through pruning and distillation is essential. Boomerang distillation\nthus provides a simple and efficient way to generate fine-grained model\nfamilies, dramatically reducing training cost while enabling flexible\nadaptation across deployment environments. The code and models are available at\nhttps://github.com/dcml-lab/boomerang-distillation.", "published": "2025-10-06 17:41:20", "link": "http://arxiv.org/abs/2510.05064v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ResCP: Reservoir Conformal Prediction for Time Series Forecasting", "abstract": "Conformal prediction offers a powerful framework for building\ndistribution-free prediction intervals for exchangeable data. Existing methods\nthat extend conformal prediction to sequential data rely on fitting a\nrelatively complex model to capture temporal dependencies. However, these\nmethods can fail if the sample size is small and often require expensive\nretraining when the underlying data distribution changes. To overcome these\nlimitations, we propose Reservoir Conformal Prediction (ResCP), a novel\ntraining-free conformal prediction method for time series. Our approach\nleverages the efficiency and representation learning capabilities of reservoir\ncomputing to dynamically reweight conformity scores. In particular, we compute\nsimilarity scores among reservoir states and use them to adaptively reweight\nthe observed residuals at each step. With this approach, ResCP enables us to\naccount for local temporal dynamics when modeling the error distribution\nwithout compromising computational scalability. We prove that, under reasonable\nassumptions, ResCP achieves asymptotic conditional coverage, and we empirically\ndemonstrate its effectiveness across diverse forecasting tasks.", "published": "2025-10-06 17:37:44", "link": "http://arxiv.org/abs/2510.05060v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Modeling Student Learning with 3.8 Million Program Traces", "abstract": "As programmers write code, they often edit and retry multiple times, creating\nrich \"interaction traces\" that reveal how they approach coding tasks and\nprovide clues about their level of skill development. For novice programmers in\nparticular, these traces reflect the diverse reasoning processes they employ to\ncode, such as exploratory behavior to understand how a programming concept\nworks, re-strategizing in response to bugs, and personalizing stylistic\nchoices. In this work, we explore what can be learned from training language\nmodels on such reasoning traces: not just about code, but about coders, and\nparticularly students learning to program. We introduce a dataset of over 3.8\nmillion programming reasoning traces from users of Pencil Code, a free online\neducational platform used by students to learn simple programming concepts.\nCompared to models trained only on final programs or synthetically-generated\ntraces, we find that models trained on real traces are stronger at modeling\ndiverse student behavior. Through both behavioral and probing analyses, we also\nfind that many properties of code traces, such as goal backtracking or number\nof comments, can be predicted from learned representations of the students who\nwrite them. Building on this result, we show that we can help students recover\nfrom mistakes by steering code generation models to identify a sequence of\nedits that will results in more correct code while remaining close to the\noriginal student's style. Together, our results suggest that many properties of\ncode are properties of individual students and that training on edit traces can\nlead to models that are more steerable, more predictive of student behavior\nwhile programming, and better at generating programs in their final states.\nCode and data is available at https://github.com/meghabyte/pencilcode-public", "published": "2025-10-06 17:37:17", "link": "http://arxiv.org/abs/2510.05056v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "KEEP: Integrating Medical Ontologies with Clinical Data for Robust Code Embeddings", "abstract": "Machine learning in healthcare requires effective representation of\nstructured medical codes, but current methods face a trade off: knowledge graph\nbased approaches capture formal relationships but miss real world patterns,\nwhile data driven methods learn empirical associations but often overlook\nstructured knowledge in medical terminologies. We present KEEP (Knowledge\npreserving and Empirically refined Embedding Process), an efficient framework\nthat bridges this gap by combining knowledge graph embeddings with adaptive\nlearning from clinical data. KEEP first generates embeddings from knowledge\ngraphs, then employs regularized training on patient records to adaptively\nintegrate empirical patterns while preserving ontological relationships.\nImportantly, KEEP produces final embeddings without task specific auxiliary or\nend to end training enabling KEEP to support multiple downstream applications\nand model architectures. Evaluations on structured EHR from UK Biobank and\nMIMIC IV demonstrate that KEEP outperforms both traditional and Language Model\nbased approaches in capturing semantic relationships and predicting clinical\noutcomes. Moreover, KEEP's minimal computational requirements make it\nparticularly suitable for resource constrained environments.", "published": "2025-10-06 17:27:54", "link": "http://arxiv.org/abs/2510.05049v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Unified Optimization Framework for Multiclass Classification with Structured Hyperplane Arrangements", "abstract": "In this paper, we propose a new mathematical optimization model for\nmulticlass classification based on arrangements of hyperplanes. Our approach\npreserves the core support vector machine (SVM) paradigm of maximizing class\nseparation while minimizing misclassification errors, and it is computationally\nmore efficient than a previous formulation. We present a kernel-based extension\nthat allows it to construct nonlinear decision boundaries. Furthermore, we show\nhow the framework can naturally incorporate alternative geometric structures,\nincluding classification trees, $\\ell_p$-SVMs, and models with discrete feature\nselection. To address large-scale instances, we develop a dynamic clustering\nmatheuristic that leverages the proposed MIP formulation. Extensive\ncomputational experiments demonstrate the efficiency of the proposed model and\ndynamic clustering heuristic, and we report competitive classification\nperformance on both synthetic datasets and real-world benchmarks from the UCI\nMachine Learning Repository, comparing our method with state-of-the-art\nimplementations available in scikit-learn.", "published": "2025-10-06 17:26:56", "link": "http://arxiv.org/abs/2510.05047v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Causal Abstractions, Categorically Unified", "abstract": "We present a categorical framework for relating causal models that represent\nthe same system at different levels of abstraction. We define a causal\nabstraction as natural transformations between appropriate Markov functors,\nwhich concisely consolidate desirable properties a causal abstraction should\nexhibit. Our approach unifies and generalizes previously considered causal\nabstractions, and we obtain categorical proofs and generalizations of existing\nresults on causal abstractions. Using string diagrammatical tools, we can\nexplicitly describe the graphs that serve as consistent abstractions of a\nlow-level graph under interventions. We discuss how methods from mechanistic\ninterpretability, such as circuit analysis and sparse autoencoders, fit within\nour categorical framework. We also show how applying do-calculus on a\nhigh-level graphical abstraction of an acyclic-directed mixed graph (ADMG),\nwhen unobserved confounders are present, gives valid results on the low-level\ngraph, thus generalizing an earlier statement by Anand et al. (2023). We argue\nthat our framework is more suitable for modeling causal abstractions compared\nto existing categorical frameworks. Finally, we discuss how notions such as\n$\\tau$-consistency and constructive $\\tau$-abstractions can be recovered with\nour framework.", "published": "2025-10-06 17:09:30", "link": "http://arxiv.org/abs/2510.05033v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Inoculation Prompting: Instructing LLMs to misbehave at train-time improves test-time alignment", "abstract": "Large language models are sometimes trained with imperfect oversight signals,\nleading to undesired behaviors such as reward hacking and sycophancy. Improving\noversight quality can be expensive or infeasible, motivating methods that\nimprove learned behavior despite an imperfect training signal. We introduce\nInoculation Prompting (IP), a simple but counterintuitive technique that\nprevents learning of an undesired behavior by modifying training prompts to\nexplicitly request it. For example, to inoculate against reward hacking, we\nmodify the prompts used in supervised fine-tuning to request code that only\nworks on provided test cases but fails on other inputs. Across four settings we\nfind that IP reduces the learning of undesired behavior without substantially\nreducing the learning of desired capabilities. We also show that prompts which\nmore strongly elicit the undesired behavior prior to fine-tuning more\neffectively inoculate against the behavior when used during training; this\nserves as a heuristic to identify promising inoculation prompts. Overall, IP is\na simple yet effective way to control how models generalize from fine-tuning,\npreventing learning of undesired behaviors without substantially disrupting\ndesired capabilities.", "published": "2025-10-06 17:02:59", "link": "http://arxiv.org/abs/2510.05024v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Curiosity-Driven Co-Development of Action and Language in Robots Through Self-Exploration", "abstract": "Human infants acquire language and action co-developmentally, achieving\nremarkable generalization capabilities from only a minimal number of learning\nexamples. In contrast, recent large language models require exposure to\nbillions of training tokens to achieve such generalization. What mechanisms\nunderlie such efficient developmental learning in humans? This study addresses\nthis question through simulation experiments in which robots learn to perform\nvarious actions corresponding to imperative sentences (e.g., \\textit{push red\ncube}) via trials of self-guided exploration. Our approach integrates the\nactive inference framework with reinforcement learning, enabling\ncuriosity-driven developmental learning. The simulations yielded several\nnontrivial findings: i) Curiosity-driven exploration combined with motor noise\nsubstantially outperforms learning without curiosity. ii) Simpler,\nprerequisite-like actions emerge earlier in development, while more complex\nactions involving these prerequisites develop later. iii) Rote pairing of\nsentences and actions occurs before the emergence of compositional\ngeneralization. iv) Generalization is drastically improved as the number of\ncompositional elements increases. These results shed light into possible\nmechanisms underlying efficient co-developmental learning in infants and\nprovide computational parallels to findings in developmental psychology.", "published": "2025-10-06 16:53:39", "link": "http://arxiv.org/abs/2510.05013v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Power Transform Revisited: Numerically Stable, and Federated", "abstract": "Power transforms are popular parametric techniques for making data more\nGaussian-like, and are widely used as preprocessing steps in statistical\nanalysis and machine learning. However, we find that direct implementations of\npower transforms suffer from severe numerical instabilities, which can lead to\nincorrect results or even crashes. In this paper, we provide a comprehensive\nanalysis of the sources of these instabilities and propose effective remedies.\nWe further extend power transforms to the federated learning setting,\naddressing both numerical and distributional challenges that arise in this\ncontext. Experiments on real-world datasets demonstrate that our methods are\nboth effective and robust, substantially improving stability compared to\nexisting approaches.", "published": "2025-10-06 16:32:22", "link": "http://arxiv.org/abs/2510.04995v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Adaptive Memory Momentum via a Model-Based Framework for Deep Learning Optimization", "abstract": "The vast majority of modern deep learning models are trained with\nmomentum-based first-order optimizers. The momentum term governs the\noptimizer's memory by determining how much each past gradient contributes to\nthe current convergence direction. Fundamental momentum methods, such as\nNesterov Accelerated Gradient and the Heavy Ball method, as well as more recent\noptimizers such as AdamW and Lion, all rely on the momentum coefficient that is\ncustomarily set to $\\beta = 0.9$ and kept constant during model training, a\nstrategy widely used by practitioners, yet suboptimal. In this paper, we\nintroduce an \\textit{adaptive memory} mechanism that replaces constant momentum\nwith a dynamic momentum coefficient that is adjusted online during\noptimization. We derive our method by approximating the objective function\nusing two planes: one derived from the gradient at the current iterate and the\nother obtained from the accumulated memory of the past gradients. To the best\nof our knowledge, such a proximal framework was never used for momentum-based\noptimization. Our proposed approach is novel, extremely simple to use, and does\nnot rely on extra assumptions or hyperparameter tuning. We implement adaptive\nmemory variants of both SGD and AdamW across a wide range of learning tasks,\nfrom simple convex problems to large-scale deep learning scenarios,\ndemonstrating that our approach can outperform standard SGD and Adam with\nhand-tuned momentum coefficients. Finally, our work opens doors for new ways of\ninducing adaptivity in optimization.", "published": "2025-10-06 16:24:57", "link": "http://arxiv.org/abs/2510.04988v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Federated Computation of ROC and PR Curves", "abstract": "Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves are\nfundamental tools for evaluating machine learning classifiers, offering\ndetailed insights into the trade-offs between true positive rate vs. false\npositive rate (ROC) or precision vs. recall (PR). However, in Federated\nLearning (FL) scenarios, where data is distributed across multiple clients,\ncomputing these curves is challenging due to privacy and communication\nconstraints. Specifically, the server cannot access raw prediction scores and\nclass labels, which are used to compute the ROC and PR curves in a centralized\nsetting. In this paper, we propose a novel method for approximating ROC and PR\ncurves in a federated setting by estimating quantiles of the prediction score\ndistribution under distributed differential privacy. We provide theoretical\nbounds on the Area Error (AE) between the true and estimated curves,\ndemonstrating the trade-offs between approximation accuracy, privacy, and\ncommunication cost. Empirical results on real-world datasets demonstrate that\nour method achieves high approximation accuracy with minimal communication and\nstrong privacy guarantees, making it practical for privacy-preserving model\nevaluation in federated systems.", "published": "2025-10-06 16:16:46", "link": "http://arxiv.org/abs/2510.04979v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "StructuralDecompose: A Modular Framework for Robust Time Series Decomposition in R", "abstract": "We present StructuralDecompose, an R package for modular and interpretable\ntime series decomposition. Unlike existing approaches that treat decomposition\nas a monolithic process, StructuralDecompose separates the analysis into\ndistinct components: changepoint detection, anomaly detection, smoothing, and\ndecomposition. This design provides flexibility and robust- ness, allowing\nusers to tailor methods to specific time series characteristics. We demonstrate\nthe package on simulated and real-world datasets, benchmark its performance\nagainst state-of-the- art tools such as Rbeast and autostsm, and discuss its\nrole in interpretable machine learning workflows.", "published": "2025-10-06 16:11:49", "link": "http://arxiv.org/abs/2510.04974v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Pivotal CLTs for Pseudolikelihood via Conditional Centering in Dependent Random Fields", "abstract": "In this paper, we study fluctuations of conditionally centered statistics of\nthe form $$N^{-1/2}\\sum_{i=1}^N\nc_i(g(\\sigma_i)-\\mathbb{E}_N[g(\\sigma_i)|\\sigma_j,j\\neq i])$$ where\n$(\\sigma_1,\\ldots ,\\sigma_N)$ are sampled from a dependent random field, and\n$g$ is some bounded function. Our first main result shows that under weak\nsmoothness assumptions on the conditional means (which cover both sparse and\ndense interactions), the above statistic converges to a Gaussian \\emph{scale\nmixture} with a random scale determined by a \\emph{quadratic variance} and an\n\\emph{interaction component}. We also show that under appropriate\nstudentization, the limit becomes a pivotal Gaussian. We leverage this theory\nto develop a general asymptotic framework for maximum pseudolikelihood (MPLE)\ninference in dependent random fields. We apply our results to Ising models with\npairwise as well as higher-order interactions and exponential random graph\nmodels (ERGMs). In particular, we obtain a joint central limit theorem for the\ninverse temperature and magnetization parameters via the joint MPLE (to our\nknowledge, the first such result in dense, irregular regimes), and we derive\nconditionally centered edge CLTs and marginal MPLE CLTs for ERGMs without\nrestricting to the ``sub-critical\" region. Our proof is based on a method of\nmoments approach via combinatorial decision-tree pruning, which may be of\nindependent interest.", "published": "2025-10-06 16:06:45", "link": "http://arxiv.org/abs/2510.04972v1", "categories": ["math.ST", "cs.LG", "math.PR", "stat.TH", "82B20, 82B26"], "primary_category": "math.ST"}
{"title": "Egalitarian Gradient Descent: A Simple Approach to Accelerated Grokking", "abstract": "Grokking is the phenomenon whereby, unlike the training performance, which\npeaks early in the training process, the test/generalization performance of a\nmodel stagnates over arbitrarily many epochs and then suddenly jumps to usually\nclose to perfect levels. In practice, it is desirable to reduce the length of\nsuch plateaus, that is to make the learning process \"grok\" faster. In this\nwork, we provide new insights into grokking. First, we show both empirically\nand theoretically that grokking can be induced by asymmetric speeds of\n(stochastic) gradient descent, along different principal (i.e singular\ndirections) of the gradients. We then propose a simple modification that\nnormalizes the gradients so that dynamics along all the principal directions\nevolves at exactly the same speed. Then, we establish that this modified\nmethod, which we call egalitarian gradient descent (EGD) and can be seen as a\ncarefully modified form of natural gradient descent, groks much faster. In\nfact, in some cases the stagnation is completely removed. Finally, we\nempirically show that on classical arithmetic problems such as modular addition\nand sparse parity problem which this stagnation has been widely observed and\nintensively studied, that our proposed method eliminates the plateaus.", "published": "2025-10-06 15:40:36", "link": "http://arxiv.org/abs/2510.04930v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Set to Be Fair: Demographic Parity Constraints for Set-Valued Classification", "abstract": "Set-valued classification is used in multiclass settings where confusion\nbetween classes can occur and lead to misleading predictions. However, its\napplication may amplify discriminatory bias motivating the development of\nset-valued approaches under fairness constraints. In this paper, we address the\nproblem of set-valued classification under demographic parity and expected size\nconstraints. We propose two complementary strategies: an oracle-based method\nthat minimizes classification risk while satisfying both constraints, and a\ncomputationally efficient proxy that prioritizes constraint satisfaction. For\nboth strategies, we derive closed-form expressions for the (optimal) fair\nset-valued classifiers and use these to build plug-in, data-driven procedures\nfor empirical predictions. We establish distribution-free convergence rates for\nviolations of the size and fairness constraints for both methods, and under\nmild assumptions we also provide excess-risk bounds for the oracle-based\napproach. Empirical results demonstrate the effectiveness of both strategies\nand highlight the efficiency of our proxy method.", "published": "2025-10-06 15:36:45", "link": "http://arxiv.org/abs/2510.04926v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "How Different from the Past? Spatio-Temporal Time Series Forecasting with Self-Supervised Deviation Learning", "abstract": "Spatio-temporal forecasting is essential for real-world applications such as\ntraffic management and urban computing. Although recent methods have shown\nimproved accuracy, they often fail to account for dynamic deviations between\ncurrent inputs and historical patterns. These deviations contain critical\nsignals that can significantly affect model performance. To fill this gap, we\npropose ST-SSDL, a Spatio-Temporal time series forecasting framework that\nincorporates a Self-Supervised Deviation Learning scheme to capture and utilize\nsuch deviations. ST-SSDL anchors each input to its historical average and\ndiscretizes the latent space using learnable prototypes that represent typical\nspatio-temporal patterns. Two auxiliary objectives are proposed to refine this\nstructure: a contrastive loss that enhances inter-prototype discriminability\nand a deviation loss that regularizes the distance consistency between input\nrepresentations and corresponding prototypes to quantify deviation. Optimized\njointly with the forecasting objective, these components guide the model to\norganize its hidden space and improve generalization across diverse input\nconditions. Experiments on six benchmark datasets show that ST-SSDL\nconsistently outperforms state-of-the-art baselines across multiple metrics.\nVisualizations further demonstrate its ability to adaptively respond to varying\nlevels of deviation in complex spatio-temporal scenarios. Our code and datasets\nare available at https://github.com/Jimmy-7664/ST-SSDL.", "published": "2025-10-06 15:21:13", "link": "http://arxiv.org/abs/2510.04908v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DP-HYPE: Distributed Differentially Private Hyperparameter Search", "abstract": "The tuning of hyperparameters in distributed machine learning can\nsubstantially impact model performance. When the hyperparameters are tuned on\nsensitive data, privacy becomes an important challenge and to this end,\ndifferential privacy has emerged as the de facto standard for provable privacy.\nA standard setting when performing distributed learning tasks is that clients\nagree on a shared setup, i.e., find a compromise from a set of hyperparameters,\nlike the learning rate of the model to be trained. Yet, prior work on\ndifferentially private hyperparameter tuning either uses computationally\nexpensive cryptographic protocols, determines hyperparameters separately for\neach client, or applies differential privacy locally, which can lead to\nundesirable utility-privacy trade-offs.\n  In this work, we present our algorithm DP-HYPE, which performs a distributed\nand privacy-preserving hyperparameter search by conducting a distributed voting\nbased on local hyperparameter evaluations of clients. In this way, DP-HYPE\nselects hyperparameters that lead to a compromise supported by the majority of\nclients, while maintaining scalability and independence from specific learning\ntasks. We prove that DP-HYPE preserves the strong notion of differential\nprivacy called client-level differential privacy and, importantly, show that\nits privacy guarantees do not depend on the number of hyperparameters. We also\nprovide bounds on its utility guarantees, that is, the probability of reaching\na compromise, and implement DP-HYPE as a submodule in the popular Flower\nframework for distributed machine learning. In addition, we evaluate\nperformance on multiple benchmark data sets in iid as well as multiple non-iid\nsettings and demonstrate high utility of DP-HYPE even under small privacy\nbudgets.", "published": "2025-10-06 15:18:34", "link": "http://arxiv.org/abs/2510.04902v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models", "abstract": "Understanding the robustness of deep learning models for multivariate\nlong-term time series forecasting (M-LTSF) remains challenging, as evaluations\ntypically rely on real-world datasets with unknown noise properties. We propose\na simulation-based evaluation framework that generates parameterizable\nsynthetic datasets, where each dataset instance corresponds to a different\nconfiguration of signal components, noise types, signal-to-noise ratios, and\nfrequency characteristics. These configurable components aim to model\nreal-world multivariate time series data without the ambiguity of unknown\nnoise. This framework enables fine-grained, systematic evaluation of M-LTSF\nmodels under controlled and diverse scenarios. We benchmark four representative\narchitectures S-Mamba (state-space), iTransformer (transformer-based), R-Linear\n(linear), and Autoformer (decomposition-based). Our analysis reveals that all\nmodels degrade severely when lookback windows cannot capture complete periods\nof seasonal patters in the data. S-Mamba and Autoformer perform best on\nsawtooth patterns, while R-Linear and iTransformer favor sinusoidal signals.\nWhite and Brownian noise universally degrade performance with lower\nsignal-to-noise ratio while S-Mamba shows specific trend-noise and iTransformer\nshows seasonal-noise vulnerability. Further spectral analysis shows that\nS-Mamba and iTransformer achieve superior frequency reconstruction. This\ncontrolled approach, based on our synthetic and principle-driven testbed,\noffers deeper insights into model-specific strengths and limitations through\nthe aggregation of MSE scores and provides concrete guidance for model\nselection based on signal characteristics and noise conditions.", "published": "2025-10-06 15:16:52", "link": "http://arxiv.org/abs/2510.04900v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "RL Is a Hammer and LLMs Are Nails: A Simple Reinforcement Learning Recipe for Strong Prompt Injection", "abstract": "Prompt injection poses a serious threat to the reliability and safety of LLM\nagents. Recent defenses against prompt injection, such as Instruction Hierarchy\nand SecAlign, have shown notable robustness against static attacks. However, to\nmore thoroughly evaluate the robustness of these defenses, it is arguably\nnecessary to employ strong attacks such as automated red-teaming. To this end,\nwe introduce RL-Hammer, a simple recipe for training attacker models that\nautomatically learn to perform strong prompt injections and jailbreaks via\nreinforcement learning. RL-Hammer requires no warm-up data and can be trained\nentirely from scratch. To achieve high ASRs against industrial-level models\nwith defenses, we propose a set of practical techniques that enable highly\neffective, universal attacks. Using this pipeline, RL-Hammer reaches a 98% ASR\nagainst GPT-4o and a $72\\%$ ASR against GPT-5 with the Instruction Hierarchy\ndefense. We further discuss the challenge of achieving high diversity in\nattacks, highlighting how attacker models tend to reward-hack diversity\nobjectives. Finally, we show that RL-Hammer can evade multiple prompt injection\ndetectors. We hope our work advances automatic red-teaming and motivates the\ndevelopment of stronger, more principled defenses. Code is available at\nhttps://github.com/facebookresearch/rl-injector.", "published": "2025-10-06 15:06:04", "link": "http://arxiv.org/abs/2510.04885v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Flow-Matching Based Refiner for Molecular Conformer Generation", "abstract": "Low-energy molecular conformers generation (MCG) is a foundational yet\nchallenging problem in drug discovery. Denoising-based methods include\ndiffusion and flow-matching methods that learn mappings from a simple base\ndistribution to the molecular conformer distribution. However, these approaches\noften suffer from error accumulation during sampling, especially in the low SNR\nsteps, which are hard to train. To address these challenges, we propose a\nflow-matching refiner for the MCG task. The proposed method initializes\nsampling from mixed-quality outputs produced by upstream denoising models and\nreschedules the noise scale to bypass the low-SNR phase, thereby improving\nsample quality. On the GEOM-QM9 and GEOM-Drugs benchmark datasets, the\ngenerator-refiner pipeline improves quality with fewer total denoising steps\nwhile preserving diversity.", "published": "2025-10-06 15:00:36", "link": "http://arxiv.org/abs/2510.04878v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "A Clinical-grade Universal Foundation Model for Intraoperative Pathology", "abstract": "Intraoperative pathology is pivotal to precision surgery, yet its clinical\nimpact is constrained by diagnostic complexity and the limited availability of\nhigh-quality frozen-section data. While computational pathology has made\nsignificant strides, the lack of large-scale, prospective validation has\nimpeded its routine adoption in surgical workflows. Here, we introduce CRISP, a\nclinical-grade foundation model developed on over 100,000 frozen sections from\neight medical centers, specifically designed to provide Clinical-grade Robust\nIntraoperative Support for Pathology (CRISP). CRISP was comprehensively\nevaluated on more than 15,000 intraoperative slides across nearly 100\nretrospective diagnostic tasks, including benign-malignant discrimination, key\nintraoperative decision-making, and pan-cancer detection, etc. The model\ndemonstrated robust generalization across diverse institutions, tumor types,\nand anatomical sites-including previously unseen sites and rare cancers. In a\nprospective cohort of over 2,000 patients, CRISP sustained high diagnostic\naccuracy under real-world conditions, directly informing surgical decisions in\n92.6% of cases. Human-AI collaboration further reduced diagnostic workload by\n35%, avoided 105 ancillary tests and enhanced detection of micrometastases with\n87.5% accuracy. Together, these findings position CRISP as a clinical-grade\nparadigm for AI-driven intraoperative pathology, bridging computational\nadvances with surgical precision and accelerating the translation of artificial\nintelligence into routine clinical practice.", "published": "2025-10-06 14:48:43", "link": "http://arxiv.org/abs/2510.04861v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Synthesising Counterfactual Explanations via Label-Conditional Gaussian Mixture Variational Autoencoders", "abstract": "Counterfactual explanations (CEs) provide recourse recommendations for\nindividuals affected by algorithmic decisions. A key challenge is generating\nCEs that are robust against various perturbation types (e.g. input and model\nperturbations) while simultaneously satisfying other desirable properties.\nThese include plausibility, ensuring CEs reside on the data manifold, and\ndiversity, providing multiple distinct recourse options for single inputs.\nExisting methods, however, mostly struggle to address these multifaceted\nrequirements in a unified, model-agnostic manner. We address these limitations\nby proposing a novel generative framework. First, we introduce the\nLabel-conditional Gaussian Mixture Variational Autoencoder (L-GMVAE), a model\ntrained to learn a structured latent space where each class label is\nrepresented by a set of Gaussian components with diverse, prototypical\ncentroids. Building on this, we present LAPACE (LAtent PAth Counterfactual\nExplanations), a model-agnostic algorithm that synthesises entire paths of CE\npoints by interpolating from inputs' latent representations to those learned\nlatent centroids. This approach inherently ensures robustness to input changes,\nas all paths for a given target class converge to the same fixed centroids.\nFurthermore, the generated paths provide a spectrum of recourse options,\nallowing users to navigate the trade-off between proximity and plausibility\nwhile also encouraging robustness against model changes. In addition,\nuser-specified actionability constraints can also be easily incorporated via\nlightweight gradient optimisation through the L-GMVAE's decoder. Comprehensive\nexperiments show that LAPACE is computationally efficient and achieves\ncompetitive performance across eight quantitative metrics.", "published": "2025-10-06 14:42:23", "link": "http://arxiv.org/abs/2510.04855v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On the Hardness of Learning Regular Expressions", "abstract": "Despite the theoretical significance and wide practical use of regular\nexpressions, the computational complexity of learning them has been largely\nunexplored. We study the computational hardness of improperly learning regular\nexpressions in the PAC model and with membership queries. We show that PAC\nlearning is hard even under the uniform distribution on the hypercube, and also\nprove hardness of distribution-free learning with membership queries.\nFurthermore, if regular expressions are extended with complement or\nintersection, we establish hardness of learning with membership queries even\nunder the uniform distribution. We emphasize that these results do not follow\nfrom existing hardness results for learning DFAs or NFAs, since the descriptive\ncomplexity of regular languages can differ exponentially between DFAs, NFAs,\nand regular expressions.", "published": "2025-10-06 14:17:55", "link": "http://arxiv.org/abs/2510.04834v1", "categories": ["cs.LG", "cs.CC"], "primary_category": "cs.LG"}
{"title": "A Noise Resilient Approach for Robust Hurst Exponent Estimation", "abstract": "Understanding signal behavior across scales is vital in areas such as natural\nphenomena analysis and financial modeling. A key property is self-similarity,\nquantified by the Hurst exponent (H), which reveals long-term dependencies.\nWavelet-based methods are effective for estimating H due to their multi-scale\nanalysis capability, but additive noise in real-world measurements often\ndegrades accuracy. We propose Noise-Controlled ALPHEE (NC-ALPHEE), an\nenhancement of the Average Level-Pairwise Hurst Exponent Estimator (ALPHEE),\nincorporating noise mitigation and generating multiple level-pairwise estimates\nfrom signal energy pairs. A neural network (NN) combines these estimates,\nreplacing traditional averaging. This adaptive learning maintains ALPHEE's\nbehavior in noise-free cases while improving performance in noisy conditions.\nExtensive simulations show that in noise-free data, NC-ALPHEE matches ALPHEE's\naccuracy using both averaging and NN-based methods. Under noise, however,\ntraditional averaging deteriorates and requires impractical level restrictions,\nwhile NC-ALPHEE consistently outperforms existing techniques without such\nconstraints. NC-ALPHEE offers a robust, adaptive approach for H estimation,\nsignificantly enhancing the reliability of wavelet-based methods in noisy\nenvironments.", "published": "2025-10-06 13:54:23", "link": "http://arxiv.org/abs/2510.04811v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Kernel ridge regression under power-law data: spectrum and generalization", "abstract": "In this work, we investigate high-dimensional kernel ridge regression (KRR)\non i.i.d. Gaussian data with anisotropic power-law covariance. This setting\ndiffers fundamentally from the classical source & capacity conditions for KRR,\nwhere power-law assumptions are typically imposed on the kernel eigen-spectrum\nitself. Our contributions are twofold. First, we derive an explicit\ncharacterization of the kernel spectrum for polynomial inner-product kernels,\ngiving a precise description of how the kernel eigen-spectrum inherits the data\ndecay. Second, we provide an asymptotic analysis of the excess risk in the\nhigh-dimensional regime for a particular kernel with this spectral behavior,\nshowing that the sample complexity is governed by the effective dimension of\nthe data rather than the ambient dimension. These results establish a\nfundamental advantage of learning with power-law anisotropic data over\nisotropic data. To our knowledge, this is the first rigorous treatment of\nnon-linear KRR under power-law data.", "published": "2025-10-06 12:58:35", "link": "http://arxiv.org/abs/2510.04780v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "MetaMP: Seamless Metadata Enrichment and AI Application Framework for Enhanced Membrane Protein Visualization and Analysis", "abstract": "Structural biology has made significant progress in determining membrane\nproteins, leading to a remarkable increase in the number of available\nstructures in dedicated databases. The inherent complexity of membrane protein\nstructures, coupled with challenges such as missing data, inconsistencies, and\ncomputational barriers from disparate sources, underscores the need for\nimproved database integration. To address this gap, we present MetaMP, a\nframework that unifies membrane-protein databases within a web application and\nuses machine learning for classification. MetaMP improves data quality by\nenriching metadata, offering a user-friendly interface, and providing eight\ninteractive views for streamlined exploration. MetaMP was effective across\ntasks of varying difficulty, demonstrating advantages across different levels\nwithout compromising speed or accuracy, according to user evaluations.\nMoreover, MetaMP supports essential functions such as structure classification\nand outlier detection.\n  We present three practical applications of Artificial Intelligence (AI) in\nmembrane protein research: predicting transmembrane segments, reconciling\nlegacy databases, and classifying structures with explainable AI support. In a\nvalidation focused on statistics, MetaMP resolved 77% of data discrepancies and\naccurately predicted the class of newly identified membrane proteins 98% of the\ntime and overtook expert curation. Altogether, MetaMP is a much-needed resource\nthat harmonizes current knowledge and empowers AI-driven exploration of\nmembrane-protein architecture.", "published": "2025-10-06 12:52:50", "link": "http://arxiv.org/abs/2510.04776v1", "categories": ["cs.LG", "cs.DB"], "primary_category": "cs.LG"}
{"title": "ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs", "abstract": "While most autoregressive LLMs are constrained to one-by-one decoding,\ndiffusion LLMs (dLLMs) have attracted growing interest for their potential to\ndramatically accelerate inference through parallel decoding. Despite this\npromise, the conditional independence assumption in dLLMs causes parallel\ndecoding to ignore token dependencies, inevitably degrading generation quality\nwhen these dependencies are strong. However, existing works largely overlook\nthese inherent challenges, and evaluations on standard benchmarks (e.g., math\nand coding) are not sufficient to capture the quality degradation caused by\nparallel decoding. To address this gap, we first provide an\ninformation-theoretic analysis of parallel decoding. We then conduct case\nstudies on analytically tractable synthetic list operations from both data\ndistribution and decoding strategy perspectives, offering quantitative insights\nthat highlight the fundamental limitations of parallel decoding. Building on\nthese insights, we propose ParallelBench, the first benchmark specifically\ndesigned for dLLMs, featuring realistic tasks that are trivial for humans and\nautoregressive LLMs yet exceptionally challenging for dLLMs under parallel\ndecoding. Using ParallelBench, we systematically analyze both dLLMs and\nautoregressive LLMs, revealing that: (i) dLLMs under parallel decoding can\nsuffer dramatic quality degradation in real-world scenarios, and (ii) current\nparallel decoding strategies struggle to adapt their degree of parallelism\nbased on task difficulty, thus failing to achieve meaningful speedup without\ncompromising quality. Our findings underscore the pressing need for innovative\ndecoding methods that can overcome the current speed-quality trade-off. We\nrelease our benchmark to help accelerate the development of truly efficient\ndLLMs.", "published": "2025-10-06 12:41:31", "link": "http://arxiv.org/abs/2510.04767v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Provable Affine Identifiability of Nonlinear CCA under Latent Distributional Priors", "abstract": "In this work, we establish conditions under which nonlinear CCA recovers the\nground-truth latent factors up to an orthogonal transform after whitening.\nBuilding on the classical result that linear mappings maximize canonical\ncorrelations under Gaussian priors, we prove affine identifiability for a broad\nclass of latent distributions in the population setting. Central to our proof\nis a reparameterization result that transports the analysis from observation\nspace to source space, where identifiability becomes tractable. We further show\nthat whitening is essential for ensuring boundedness and well-conditioning,\nthereby underpinning identifiability. Beyond the population setting, we prove\nthat ridge-regularized empirical CCA converges to its population counterpart,\ntransferring these guarantees to the finite-sample regime. Experiments on a\ncontrolled synthetic dataset and a rendered image dataset validate our theory\nand demonstrate the necessity of its assumptions through systematic ablations.", "published": "2025-10-06 12:35:07", "link": "http://arxiv.org/abs/2510.04758v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "EVaR-Optimal Arm Identification in Bandits", "abstract": "We study the fixed-confidence best arm identification (BAI) problem within\nthe multi-armed bandit (MAB) framework under the Entropic Value-at-Risk (EVaR)\ncriterion. Our analysis considers a nonparametric setting, allowing for general\nreward distributions bounded in [0,1]. This formulation addresses the critical\nneed for risk-averse decision-making in high-stakes environments, such as\nfinance, moving beyond simple expected value optimization. We propose a\n$\\delta$-correct, Track-and-Stop based algorithm and derive a corresponding\nlower bound on the expected sample complexity, which we prove is asymptotically\nmatched. The implementation of our algorithm and the characterization of the\nlower bound both require solving a complex convex optimization problem and a\nrelated, simpler non-convex one.", "published": "2025-10-06 11:49:56", "link": "http://arxiv.org/abs/2510.04728v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Directional Sheaf Hypergraph Networks: Unifying Learning on Directed and Undirected Hypergraphs", "abstract": "Hypergraphs provide a natural way to represent higher-order interactions\namong multiple entities. While undirected hypergraphs have been extensively\nstudied, the case of directed hypergraphs, which can model oriented group\ninteractions, remains largely under-explored despite its relevance for many\napplications. Recent approaches in this direction often exhibit an implicit\nbias toward homophily, which limits their effectiveness in heterophilic\nsettings. Rooted in the algebraic topology notion of Cellular Sheaves, Sheaf\nNeural Networks (SNNs) were introduced as an effective solution to circumvent\nsuch a drawback. While a generalization to hypergraphs is known, it is only\nsuitable for undirected hypergraphs, failing to tackle the directed case. In\nthis work, we introduce Directional Sheaf Hypergraph Networks (DSHN), a\nframework integrating sheaf theory with a principled treatment of asymmetric\nrelations within a hypergraph. From it, we construct the Directed Sheaf\nHypergraph Laplacian, a complex-valued operator by which we unify and\ngeneralize many existing Laplacian matrices proposed in the graph- and\nhypergraph-learning literature. Across 7 real-world datasets and against 13\nbaselines, DSHN achieves relative accuracy gains from 2% up to 20%, showing how\na principled treatment of directionality in hypergraphs, combined with the\nexpressive power of sheaves, can substantially improve performance.", "published": "2025-10-06 11:46:53", "link": "http://arxiv.org/abs/2510.04727v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Predictive economics: Rethinking economic methodology with machine learning", "abstract": "This article proposes predictive economics as a distinct analytical\nperspective within economics, grounded in machine learning and centred on\npredictive accuracy rather than causal identification. Drawing on the\ninstrumentalist tradition (Friedman), the explanation-prediction divide\n(Shmueli), and the contrast between modelling cultures (Breiman), we formalise\nprediction as a valid epistemological and methodological objective. Reviewing\nrecent applications across economic subfields, we show how predictive models\ncontribute to empirical analysis, particularly in complex or data-rich\ncontexts. This perspective complements existing approaches and supports a more\npluralistic methodology - one that values out-of-sample performance alongside\ninterpretability and theoretical structure.", "published": "2025-10-06 11:46:03", "link": "http://arxiv.org/abs/2510.04726v1", "categories": ["econ.GN", "cs.LG", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "ViTs: Teaching Machines to See Time Series Anomalies Like Human Experts", "abstract": "Web service administrators must ensure the stability of multiple systems by\npromptly detecting anomalies in Key Performance Indicators (KPIs). Achieving\nthe goal of \"train once, infer across scenarios\" remains a fundamental\nchallenge for time series anomaly detection models. Beyond improving zero-shot\ngeneralization, such models must also flexibly handle sequences of varying\nlengths during inference, ranging from one hour to one week, without\nretraining. Conventional approaches rely on sliding-window encoding and\nself-supervised learning, which restrict inference to fixed-length inputs.\nLarge Language Models (LLMs) have demonstrated remarkable zero-shot\ncapabilities across general domains. However, when applied to time series data,\nthey face inherent limitations due to context length. To address this issue, we\npropose ViTs, a Vision-Language Model (VLM)-based framework that converts time\nseries curves into visual representations. By rescaling time series images,\ntemporal dependencies are preserved while maintaining a consistent input size,\nthereby enabling efficient processing of arbitrarily long sequences without\ncontext constraints. Training VLMs for this purpose introduces unique\nchallenges, primarily due to the scarcity of aligned time series image-text\ndata. To overcome this, we employ an evolutionary algorithm to automatically\ngenerate thousands of high-quality image-text pairs and design a three-stage\ntraining pipeline consisting of: (1) time series knowledge injection, (2)\nanomaly detection enhancement, and (3) anomaly reasoning refinement. Extensive\nexperiments demonstrate that ViTs substantially enhance the ability of VLMs to\nunderstand and detect anomalies in time series data. All datasets and code will\nbe publicly released at: https://anonymous.4open.science/r/ViTs-C484/.", "published": "2025-10-06 11:24:53", "link": "http://arxiv.org/abs/2510.04710v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Study on the Data Distribution Gap in Music Emotion Recognition", "abstract": "Music Emotion Recognition (MER) is a task deeply connected to human\nperception, relying heavily on subjective annotations collected from\ncontributors. Prior studies tend to focus on specific musical styles rather\nthan incorporating a diverse range of genres, such as rock and classical,\nwithin a single framework. In this paper, we address the task of recognizing\nemotion from audio content by investigating five datasets with dimensional\nemotion annotations -- EmoMusic, DEAM, PMEmo, WTC, and WCMED -- which span\nvarious musical styles. We demonstrate the problem of out-of-distribution\ngeneralization in a systematic experiment. By closely looking at multiple data\nand feature sets, we provide insight into genre-emotion relationships in\nexisting data and examine potential genre dominance and dataset biases in\ncertain feature representations. Based on these experiments, we arrive at a\nsimple yet effective framework that combines embeddings extracted from the\nJukebox model with chroma features and demonstrate how, alongside a combination\nof several diverse training sets, this permits us to train models with\nsubstantially improved cross-dataset generalization capabilities.", "published": "2025-10-06 10:57:05", "link": "http://arxiv.org/abs/2510.04688v1", "categories": ["cs.SD", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Parameter-free Algorithms for the Stochastically Extended Adversarial Model", "abstract": "We develop the first parameter-free algorithms for the Stochastically\nExtended Adversarial (SEA) model, a framework that bridges adversarial and\nstochastic online convex optimization. Existing approaches for the SEA model\nrequire prior knowledge of problem-specific parameters, such as the diameter of\nthe domain $D$ and the Lipschitz constant of the loss functions $G$, which\nlimits their practical applicability. Addressing this, we develop\nparameter-free methods by leveraging the Optimistic Online Newton Step (OONS)\nalgorithm to eliminate the need for these parameters. We first establish a\ncomparator-adaptive algorithm for the scenario with unknown domain diameter but\nknown Lipschitz constant, achieving an expected regret bound of\n$\\tilde{O}\\big(\\|u\\|_2^2 + \\|u\\|_2(\\sqrt{\\sigma^2_{1:T}} +\n\\sqrt{\\Sigma^2_{1:T}})\\big)$, where $u$ is the comparator vector and\n$\\sigma^2_{1:T}$ and $\\Sigma^2_{1:T}$ represent the cumulative stochastic\nvariance and cumulative adversarial variation, respectively. We then extend\nthis to the more general setting where both $D$ and $G$ are unknown, attaining\nthe comparator- and Lipschitz-adaptive algorithm. Notably, the regret bound\nexhibits the same dependence on $\\sigma^2_{1:T}$ and $\\Sigma^2_{1:T}$,\ndemonstrating the efficacy of our proposed methods even when both parameters\nare unknown in the SEA model.", "published": "2025-10-06 10:53:37", "link": "http://arxiv.org/abs/2510.04685v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Counterfactual Credit Guided Bayesian Optimization", "abstract": "Bayesian optimization has emerged as a prominent methodology for optimizing\nexpensive black-box functions by leveraging Gaussian process surrogates, which\nfocus on capturing the global characteristics of the objective function.\nHowever, in numerous practical scenarios, the primary objective is not to\nconstruct an exhaustive global surrogate, but rather to quickly pinpoint the\nglobal optimum. Due to the aleatoric nature of the sequential optimization\nproblem and its dependence on the quality of the surrogate model and the\ninitial design, it is restrictive to assume that all observed samples\ncontribute equally to the discovery of the optimum in this context. In this\npaper, we introduce Counterfactual Credit Guided Bayesian Optimization (CCGBO),\na novel framework that explicitly quantifies the contribution of individual\nhistorical observations through counterfactual credit. By incorporating\ncounterfactual credit into the acquisition function, our approach can\nselectively allocate resources in areas where optimal solutions are most likely\nto occur. We prove that CCGBO retains sublinear regret. Empirical evaluations\non various synthetic and real-world benchmarks demonstrate that CCGBO\nconsistently reduces simple regret and accelerates convergence to the global\noptimum.", "published": "2025-10-06 10:34:50", "link": "http://arxiv.org/abs/2510.04676v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "IMLP: An Energy-Efficient Continual Learning Method for Tabular Data Streams", "abstract": "Tabular data streams are rapidly emerging as a dominant modality for\nreal-time decision-making in healthcare, finance, and the Internet of Things\n(IoT). These applications commonly run on edge and mobile devices, where energy\nbudgets, memory, and compute are strictly limited. Continual learning (CL)\naddresses such dynamics by training models sequentially on task streams while\npreserving prior knowledge and consolidating new knowledge. While recent CL\nwork has advanced in mitigating catastrophic forgetting and improving knowledge\ntransfer, the practical requirements of energy and memory efficiency for\ntabular data streams remain underexplored. In particular, existing CL solutions\nmostly depend on replay mechanisms whose buffers grow over time and exacerbate\nresource costs.\n  We propose a context-aware incremental Multi-Layer Perceptron (IMLP), a\ncompact continual learner for tabular data streams. IMLP incorporates a\nwindowed scaled dot-product attention over a sliding latent feature buffer,\nenabling constant-size memory and avoiding storing raw data. The attended\ncontext is concatenated with current features and processed by shared\nfeed-forward layers, yielding lightweight per-segment updates. To assess\npractical deployability, we introduce NetScore-T, a tunable metric coupling\nbalanced accuracy with energy for Pareto-aware comparison across models and\ndatasets. IMLP achieves up to $27.6\\times$ higher energy efficiency than TabNet\nand $85.5\\times$ higher than TabPFN, while maintaining competitive average\naccuracy. Overall, IMLP provides an easy-to-deploy, energy-efficient\nalternative to full retraining for tabular data streams.", "published": "2025-10-06 10:05:44", "link": "http://arxiv.org/abs/2510.04660v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Compressed Concatenation of Small Embedding Models", "abstract": "Embedding models are central to dense retrieval, semantic search, and\nrecommendation systems, but their size often makes them impractical to deploy\nin resource-constrained environments such as browsers or edge devices. While\nsmaller embedding models offer practical advantages, they typically\nunderperform compared to their larger counterparts. To bridge this gap, we\ndemonstrate that concatenating the raw embedding vectors of multiple small\nmodels can outperform a single larger baseline on standard retrieval\nbenchmarks. To overcome the resulting high dimensionality of naive\nconcatenation, we introduce a lightweight unified decoder trained with a\nMatryoshka Representation Learning (MRL) loss. This decoder maps the\nhigh-dimensional joint representation to a low-dimensional space, preserving\nmost of the original performance without fine-tuning the base models. We also\nshow that while concatenating more base models yields diminishing gains, the\nrobustness of the decoder's representation under compression and quantization\nimproves. Our experiments show that, on a subset of MTEB retrieval tasks, our\nconcat-encode-quantize pipeline recovers 89\\% of the original performance with\na 48x compression factor when the pipeline is applied to a concatenation of\nfour small embedding models.", "published": "2025-10-06 09:32:54", "link": "http://arxiv.org/abs/2510.04626v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Forecasting-Based Biomedical Time-series Data Synthesis for Open Data and Robust AI", "abstract": "The limited data availability due to strict privacy regulations and\nsignificant resource demands severely constrains biomedical time-series AI\ndevelopment, which creates a critical gap between data requirements and\naccessibility. Synthetic data generation presents a promising solution by\nproducing artificial datasets that maintain the statistical properties of real\nbiomedical time-series data without compromising patient confidentiality. We\npropose a framework for synthetic biomedical time-series data generation based\non advanced forecasting models that accurately replicates complex\nelectrophysiological signals such as EEG and EMG with high fidelity. These\nsynthetic datasets preserve essential temporal and spectral properties of real\ndata, which enables robust analysis while effectively addressing data scarcity\nand privacy challenges. Our evaluations across multiple subjects demonstrate\nthat the generated synthetic data can serve as an effective substitute for real\ndata and also significantly boost AI model performance. The approach maintains\ncritical biomedical features while provides high scalability for various\napplications and integrates seamlessly into open-source repositories,\nsubstantially expanding resources for AI-driven biomedical research.", "published": "2025-10-06 09:32:10", "link": "http://arxiv.org/abs/2510.04622v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Closed-Form Last Layer Optimization", "abstract": "Neural networks are typically optimized with variants of stochastic gradient\ndescent. Under a squared loss, however, the optimal solution to the linear last\nlayer weights is known in closed-form. We propose to leverage this during\noptimization, treating the last layer as a function of the backbone parameters,\nand optimizing solely for these parameters. We show this is equivalent to\nalternating between gradient descent steps on the backbone and closed-form\nupdates on the last layer. We adapt the method for the setting of stochastic\ngradient descent, by trading off the loss on the current batch against the\naccumulated information from previous batches. Further, we prove that, in the\nNeural Tangent Kernel regime, convergence of this method to an optimal solution\nis guaranteed. Finally, we demonstrate the effectiveness of our approach\ncompared with standard SGD on a squared loss in several supervised tasks --\nboth regression and classification -- including Fourier Neural Operators and\nInstrumental Variable Regression.", "published": "2025-10-06 09:14:39", "link": "http://arxiv.org/abs/2510.04606v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Data-Driven Adaptive PID Control Based on Physics-Informed Neural Networks", "abstract": "This article proposes a data-driven PID controller design based on the\nprinciple of adaptive gain optimization, leveraging Physics-Informed Neural\nNetworks (PINNs) generated for predictive modeling purposes. The proposed\ncontrol design method utilizes gradients of the PID gain optimization, achieved\nthrough the automatic differentiation of PINNs, to apply model predictive\ncontrol using a cost function based on tracking error and control inputs. By\noptimizing PINNs-based PID gains, the method achieves adaptive gain tuning that\nensures stability while accounting for system nonlinearities. The proposed\nmethod features a systematic framework for integrating PINNs-based models of\ndynamical control systems into closed-loop control systems, enabling direct\napplication to PID control design. A series of numerical experiments is\nconducted to demonstrate the effectiveness of the proposed method from the\ncontrol perspectives based on both time and frequency domains.", "published": "2025-10-06 08:46:20", "link": "http://arxiv.org/abs/2510.04591v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Improved probabilistic regression using diffusion models", "abstract": "Probabilistic regression models the entire predictive distribution of a\nresponse variable, offering richer insights than classical point estimates and\ndirectly allowing for uncertainty quantification. While diffusion-based\ngenerative models have shown remarkable success in generating complex,\nhigh-dimensional data, their usage in general regression tasks often lacks\nuncertainty-related evaluation and remains limited to domain-specific\napplications. We propose a novel diffusion-based framework for probabilistic\nregression that learns predictive distributions in a nonparametric way. More\nspecifically, we propose to model the full distribution of the diffusion noise,\nenabling adaptation to diverse tasks and enhanced uncertainty quantification.\nWe investigate different noise parameterizations, analyze their trade-offs, and\nevaluate our framework across a broad range of regression tasks, covering low-\nand high-dimensional settings. For several experiments, our approach shows\nsuperior performance against existing baselines, while delivering calibrated\nuncertainty estimates, demonstrating its versatility as a tool for\nprobabilistic prediction.", "published": "2025-10-06 08:36:05", "link": "http://arxiv.org/abs/2510.04583v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Busemann Functions in the Wasserstein Space: Existence, Closed-Forms, and Applications to Slicing", "abstract": "The Busemann function has recently found much interest in a variety of\ngeometric machine learning problems, as it naturally defines projections onto\ngeodesic rays of Riemannian manifolds and generalizes the notion of\nhyperplanes. As several sources of data can be conveniently modeled as\nprobability distributions, it is natural to study this function in the\nWasserstein space, which carries a rich formal Riemannian structure induced by\nOptimal Transport metrics. In this work, we investigate the existence and\ncomputation of Busemann functions in Wasserstein space, which admits geodesic\nrays. We establish closed-form expressions in two important cases:\none-dimensional distributions and Gaussian measures. These results enable\nexplicit projection schemes for probability distributions on $\\mathbb{R}$,\nwhich in turn allow us to define novel Sliced-Wasserstein distances over\nGaussian mixtures and labeled datasets. We demonstrate the efficiency of those\noriginal schemes on synthetic datasets as well as transfer learning problems.", "published": "2025-10-06 08:31:14", "link": "http://arxiv.org/abs/2510.04579v1", "categories": ["cs.LG", "math.MG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Language Model Based Text-to-Audio Generation: Anti-Causally Aligned Collaborative Residual Transformers", "abstract": "While language models (LMs) paired with residual vector quantization (RVQ)\ntokenizers have shown promise in text-to-audio (T2A) generation, they still lag\nbehind diffusion-based models by a non-trivial margin. We identify a critical\ndilemma underpinning this gap: incorporating more RVQ layers improves audio\nreconstruction fidelity but exceeds the generation capacity of conventional\nLMs. To address this, we first analyze RVQ dynamics and uncover two key\nlimitations: 1) orthogonality of features across RVQ layers hinders effective\nLMs training, and 2) descending semantic richness in tokens from deeper RVQ\nlayers exacerbates exposure bias during autoregressive decoding. Based on these\ninsights, we propose Siren, a novel LM-based framework that employs multiple\nisolated transformers with causal conditioning and anti-causal alignment via\nreinforcement learning. Extensive experiments demonstrate that Siren\noutperforms both existing LM-based and diffusion-based T2A systems, achieving\nstate-of-the-art results. By bridging the representational strengths of LMs\nwith the fidelity demands of audio synthesis, our approach repositions LMs as\ncompetitive contenders against diffusion models in T2A tasks. Moreover, by\naligning audio representations with linguistic structures, Siren facilitates a\npromising pathway toward unified multi-modal generation frameworks.", "published": "2025-10-06 08:26:55", "link": "http://arxiv.org/abs/2510.04577v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Fixed Point Framework for the Existence of EFX Allocations", "abstract": "We consider the problem of the existence of an envy-free allocation up to any\ngood (EFX) for linear valuations and establish new results by connecting this\nproblem to a fixed point framework. Specifically, we first use randomized\nrounding to extend the discrete EFX constraints into a continuous space and\nshow that an EFX allocation exists if and only if the optimal value of the\ncontinuously extended objective function is nonpositive. In particular, we\ndemonstrate that this optimization problem can be formulated as an\nunconstrained difference of convex (DC) program, which can be further\nsimplified to the minimization of a piecewise linear concave function over a\npolytope. Leveraging this connection, we show that the proposed DC program has\na nonpositive optimal objective value if and only if a well-defined continuous\nvector map admits a fixed point. Crucially, we prove that the reformulated\nfixed point problem satisfies all the conditions of Brouwer's fixed point\ntheorem, except that self-containedness is violated by an arbitrarily small\npositive constant. To address this, we propose a slightly perturbed continuous\nmap that always admits a fixed point. This fixed point serves as a proxy for\nthe fixed point (if it exists) of the original map, and hence for an EFX\nallocation through an appropriate transformation. Our results offer a new\napproach to establishing the existence of EFX allocations through fixed point\ntheorems. Moreover, the equivalence with DC programming enables a more\nefficient and systematic method for computing such allocations (if one exists)\nusing tools from nonlinear optimization. Our findings bridge the discrete\nproblem of finding an EFX allocation with two continuous frameworks: solving an\nunconstrained DC program and identifying a fixed point of a continuous vector\nmap.", "published": "2025-10-06 15:30:20", "link": "http://arxiv.org/abs/2510.04915v1", "categories": ["cs.GT", "cs.MA", "cs.SY", "eess.SY", "math.OC"], "primary_category": "cs.GT"}
{"title": "Data-driven linear solver selection and performance tuning for multiphysics simulations in porous media", "abstract": "Modeling multiphysics processes in porous media requires preconditioned\niterative linear solvers to enable efficient simulations at industry-relevant\nscales. These solvers are typically composed of sub-algorithms that target\nindividual physical processes. Various options are available for each\nalgorithm, with the corresponding ranges of numerical parameters. The choices\nof sub-algorithms and their parameters significantly affects simulation\nperformance and robustness. Optimizing these choices for each simulation is\nchallenging due to the vast number of possible combinations. Moreover,\noptimization relies on performance data from past simulations, which becomes\nless representative as the simulation setup changes. This paper addresses the\nproblem of automated selection and tuning of preconditioned linear solvers for\nmultiphysics simulations. The proposed solver selection algorithm collects\nperformance data during the run of the target simulation and continuously\nupdates a machine learning model responsible for solver selection, resulting in\nan adaptively refined selection policy. The algorithm is evaluated on two\ntime-dependent nonlinear model problems: (i) coupled fluid flow and heat\ntransfer in porous media and (ii) thermo-poromechanics in porous media with\nfractures, governed by frictional contact mechanics. These experiments\ndemonstrate that the algorithm selects efficient and robust solvers with\nnegligible overhead and performs comparably to a reference selection policy\nthat has full access to the performance data of prior simulations. Our results\nindicate that the proposed approach effectively addresses the challenge of\nsolver selection and tuning, providing particular value to simulation engineers\nand researchers, especially when expert knowledge on linear solver tuning is\nnot readily available.", "published": "2025-10-06 15:33:53", "link": "http://arxiv.org/abs/2510.04920v1", "categories": ["math.NA", "cs.NA", "65F08, 68T05, 65M08, 76S05, 35Q74, 74S10, 74M15", "G.1.3; G.1.8; I.2.6; J.2; G.4"], "primary_category": "math.NA"}
{"title": "The path of hyperinterpolation: A survey", "abstract": "This paper surveys hyperinterpolation, a quadrature-based approximation\nscheme. We cover classical results, provide examples on several domains, review\nrecent progress on relaxed quadrature exactness, introduce methodological\nvariants, and discuss applications to differential and integral equations.", "published": "2025-10-06 15:19:54", "link": "http://arxiv.org/abs/2510.04904v1", "categories": ["math.NA", "cs.NA", "65D15, 41A10, 65D32"], "primary_category": "math.NA"}
{"title": "Validity condition of normal form transformation for the $\u03b2$-FPUT system", "abstract": "In this work, we provide a validity condition for the normal form\ntransformation to remove the non-resonant cubic terms in the $\\beta$-FPUT\nsystem. We show that for a wave field with random phases, the normal form\ntransformation is valid by dominant probability if $\\beta \\ll\n1/N^{1+\\epsilon}$, with $N$ the number of masses and $\\epsilon$ an arbitrarily\nsmall constant. To obtain this condition, a bound is needed for a summation in\nthe transformation equation, which we prove rigorously in the paper. The\ncondition also suggests that the importance of the non-resonant terms in the\nevolution equation is governed by the parameter $\\beta N$. We design numerical\nexperiments to demonstrate that this is indeed the case for spectra at both\nthermal-equilibrium and out-of-equilibrium conditions. The methodology\ndeveloped in this paper is applicable to other Hamiltonian systems where a\nnormal form transformation needs to be applied.", "published": "2025-10-06 14:14:41", "link": "http://arxiv.org/abs/2510.04831v1", "categories": ["math-ph", "cs.NA", "math.MP", "math.NA"], "primary_category": "math-ph"}
{"title": "Efficient structure-preserving scheme for chemotaxis PDEs with singular sensitivity in crime and epidemic modeling", "abstract": "The system of chemotaxis PDEs with singular sensitivity was originally\nproposed by Short et al. [Math. Mod. Meth. Appl. Sci., 18:1249-1267, 2008] as\nthe continuum limit of a biased random walk model to account for the formation\nof crime hotspots and environmental feedback successfully. Recently, this idea\nhas also been applied to epidemiology to model the impact of human social\nbehaviors on disease transmission. In order to characterize the phase\ntransition, pattern formation and statistical properties in the long-term\ndynamics, a stable and accurate numerical scheme is urgently demanded, which\nstill remains challenging due to the positivity constraint on the singular\nsensitivity and the absence of an energy functional. To address these numerical\nchallenges, this paper constructs an efficient positivity-preserving,\nimplicit-explicit scheme with second-order accuracy. A rigorous error\nestimation is provided with the Lagrange multiplier correction to deal with the\nsingular sensitivity. The whole framework is extended to a multi-agent epidemic\nmodel with degenerate diffusion, in which both positivity and mass conservation\nare achieved. Typical numerical examples are conducted to validate our\ntheoretical results and to demonstrate the necessity of correction strategy.\nThe proposed scheme allows us to study the nucleation, spread, and dissipation\nof crime hotspots, as well as validate that clustering of population density\nmay accelerate virus transmission in epidemic dynamics and potentially\naggravate the second infectious wave.", "published": "2025-10-06 14:09:56", "link": "http://arxiv.org/abs/2510.04826v1", "categories": ["math.NA", "cs.NA", "35K61, 65M06, 65M15, 82C26, 92C17"], "primary_category": "math.NA"}
{"title": "SubApSnap: Solving parameter-dependent linear systems with a snapshot and subsampling", "abstract": "A growing number of problems in computational mathematics can be reduced to\nthe solution of many linear systems that are related, often depending smoothly\nor slowly on a parameter $p$, that is, $A(p)x(p)=b(p)$. We introduce an\nefficient algorithm for solving such parameter-dependent linear systems for\nmany values of $p$. The algorithm, which we call SubApSnap (for\n\\emph{Sub}sampled $A(p)$ times \\emph{Snap}shot), is based on combining ideas\nfrom model order reduction and randomised linear algebra: namely, taking a\nsnapshot matrix, and solving the resulting tall-skinny least-squares problems\nusing a subsampling-based dimension-reduction approach. We show that SubApSnap\nis a strict generalisation of the popular DEIM algorithm in nonlinear model\norder reduction. SubApSnap is a sublinear-time algorithm, and once the snapshot\nand subsampling are determined, it solves $A(p_*)x(p_*)=b(p_*)$ for a new value\nof $p_*$ at a dramatically improved speed: it does not even need to read the\nwhole matrix $A(p_*)$ to solve the linear system for a new value of $p_*$. We\nprove under natural assumptions that, given a good subsampling and snapshot,\nSubApSnap yields solutions with small residual for all parameter values of\ninterest. We illustrate the efficiency and performance of the algorithm with\nproblems arising in PDEs, model reduction, and kernel ridge regression, where\nSubApSnap achieves speedups of many orders of magnitude over a standard\nsolution; for example over $20,000\\times$ for a $10^7\\times 10^7$ problem,\nwhile providing good accuracy.", "published": "2025-10-06 14:09:46", "link": "http://arxiv.org/abs/2510.04825v1", "categories": ["math.NA", "cs.NA", "65F99, 65F20"], "primary_category": "math.NA"}
{"title": "Higher-Order Boundary Conditions for Atomistic Dislocation Simulations", "abstract": "We present a higher-order boundary condition for atomistic simulations of\ndislocations that address the slow convergence of standard supercell methods.\nThe method is based on a multipole expansion of the equilibrium displacement,\ncombining continuum predictor solutions with discrete moment corrections. The\ncontinuum predictors are computed by solving a hierarchy of singular elliptic\nPDEs via a Galerkin spectral method, while moment coefficients are evaluated\nfrom force-moment identities with controlled approximation error. A key feature\nis the coupling between accurate continuum predictors and moment evaluations,\nenabling the construction of systematically improvable high-order boundary\nconditions. We thus design novel algorithms, and numerical results for screw\nand edge dislocations confirm the predicted convergence rates in geometry and\nenergy norms, with reduced finite-size effects and moderate computational cost.", "published": "2025-10-06 12:29:26", "link": "http://arxiv.org/abs/2510.04751v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Computational identification of the source domain in an inverse problem of potential theory", "abstract": "The inverse potential problem consists in determining the density of the\nvolume potential from measurements outside the sources. Its ill-posedness is\ndue both to the non-uniqueness of the solution and to the instability of the\nsolution with respect to measurement errors. The inverse problem is solved\nunder additional assumptions about the sources using regularizing algorithms.\nIn this work, an inverse problem is posed for identifying the domain that\ncontains the sources. The computational algorithm is based on approximating the\nvolume potential by the single-layer potential on the boundary of the domain\ncontaining the sources. The inverse problem is considered in the class of a\npriori constraints of nonnegativity of the potential density. Residual\nminimization in the class of nonnegative solutions is performed using the\nclassical Nonnegative Least Squares algorithm. The capabilities of the proposed\napproach are illustrated by numerical experiments for a two-dimensional test\nproblem with an analytically prescribed potential on the observation surface.", "published": "2025-10-06 11:05:49", "link": "http://arxiv.org/abs/2510.04693v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Convergence Analysis of the Random Ordinate Method for Mitigating the Ray Effect", "abstract": "The Discrete Ordinates Method (DOM) is widely used for velocity\ndiscretization in radiative transport simulations. However, DOM tends to\nexhibit the ray effect when the velocity discretization is not sufficiently\nrefined, a limitation that is well documented. To counter this, we have\ndeveloped the Random Ordinates Method (ROM) by integrating randomness into the\nvelocity discretization, which mitigates the ray effect without incurring\nadditional computational costs. ROM partitions the velocity space into n cells,\nselects a random ordinate from each cell, and solves a DOM system with these\nordinates. It leverages the average of multiple samples to achieve a higher\nconvergence order, especially for solutions with low regularity in the velocity\nvariable. In this work, we provide a detailed convergence analysis for ROM,\nfocusing on bias and single-run errors. This analysis is crucial for\ndetermining the necessary mesh size and the optimal number of samples required\nto attain a specified level of accuracy.", "published": "2025-10-06 07:12:53", "link": "http://arxiv.org/abs/2510.04540v1", "categories": ["math.NA", "cs.NA", "math.DS"], "primary_category": "math.NA"}
{"title": "Overlapping Schwarz Scheme for Linear-Quadratic Programs in Continuous Time", "abstract": "We present an optimize-then-discretize framework for solving linear-quadratic\noptimal control problems (OCP) governed by time-inhomogeneous ordinary\ndifferential equations (ODEs). Our method employs a modified overlapping\nSchwarz decomposition based on the Pontryagin Minimum Principle, partitioning\nthe temporal domain into overlapping intervals and independently solving\nHamiltonian systems in continuous time. We demonstrate that the convergence is\nensured by appropriately updating the boundary conditions of the individual\nHamiltonian dynamics. The cornerstone of our analysis is to prove that the\nexponential decay of sensitivity (EDS) exhibited in discrete-time OCPs carries\nover to the continuous-time setting. Unlike the discretize-then-optimize\napproach, our method can flexibly incorporate different numerical integration\nmethods for solving the resulting Hamiltonian two-point boundary-value\nsubproblems, including adaptive-time integrators. A numerical experiment on a\nlinear-quadratic OCP illustrates the practicality of our approach in broad\nscientific applications.", "published": "2025-10-06 04:28:39", "link": "http://arxiv.org/abs/2510.04478v1", "categories": ["math.OC", "cs.CE", "cs.DC", "cs.NA", "math.DS", "math.NA"], "primary_category": "math.OC"}
{"title": "Some Remarks on Commuting Probability", "abstract": "We introduce a weighted sum of irreducible character ratios as an estimator\nfor commutator probabilities. The estimator yields Frobenius formula when\napplied to a regular representation", "published": "2025-10-06 03:12:36", "link": "http://arxiv.org/abs/2510.04458v1", "categories": ["math.NA", "cs.NA", "math.RT", "65-XX (Primary) 20Cxx, 20Pxx (Secondary)"], "primary_category": "math.NA"}
{"title": "A note on spectral Monte-Carlo method for fractional Poisson equation on high-dimensional ball", "abstract": "Recently, a class of efficient spectral Monte-Carlo methods was developed in\n\\cite{Feng2025ExponentiallyAS} for solving fractional Poisson equations. These\nmethods fully consider the low regularity of the solution near boundaries and\nleverage the efficiency of walk-on-spheres algorithms, achieving spectral\naccuracy. However, the underlying formulation is essentially one-dimensional.\nIn this work, we extend this approach to radial solutions in general\nhigh-dimensional balls. This is accomplished by employing a different set of\neigenfunctions for the fractional Laplacian and deriving new interpolation\nformulas. We provide a comprehensive description of our methodology and a\ndetailed comparison with existing techniques. Numerical experiments confirm the\nefficacy of the proposed extension.", "published": "2025-10-06 01:42:47", "link": "http://arxiv.org/abs/2510.04427v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Gini-based Model Monitoring: A General Framework with an Application to Non-life Insurance Pricing", "abstract": "In a dynamic landscape where portfolios and environments evolve, maintaining\nthe accuracy of pricing models is critical. To the best of our knowledge, this\nis the first study to systematically examine concept drift in non-life\ninsurance pricing. We (i) provide an overview of the relevant literature and\ncommonly used methodologies, clarify the distinction between virtual drift and\nconcept drift, and explain their implications for long-run model performance;\n(ii) review and formalize common performance measures, including the Gini index\nand deviance loss, and articulate their interpretation; (iii) derive the\nasymptotic distribution of the Gini index, enabling valid inference and\nhypothesis testing; and (iv) present a standardized monitoring procedure that\nindicates when refitting is warranted. We illustrate the framework using a\nmodified real-world portfolio with induced concept drift and discuss practical\nconsiderations and pitfalls.", "published": "2025-10-06 07:41:09", "link": "http://arxiv.org/abs/2510.04556v1", "categories": ["stat.ML", "cs.LG", "math.ST", "q-fin.ST", "stat.AP", "stat.TH", "62, 68", "G.3"], "primary_category": "stat.ML"}
{"title": "Risk-Sensitive Option Market Making with Arbitrage-Free eSSVI Surfaces: A Constrained RL and Stochastic Control Bridge", "abstract": "We formulate option market making as a constrained, risk-sensitive control\nproblem that unifies execution, hedging, and arbitrage-free implied-volatility\nsurfaces inside a single learning loop. A fully differentiable eSSVI layer\nenforces static no-arbitrage conditions (butterfly and calendar) while the\npolicy controls half-spreads, hedge intensity, and structured surface\ndeformations (state-dependent rho-shift and psi-scale). Executions are\nintensity-driven and respond monotonically to spreads and relative mispricing;\ntail risk is shaped with a differentiable CVaR objective via the\nRockafellar--Uryasev program. We provide theory for (i) grid-consistency and\nrates for butterfly/calendar surrogates, (ii) a primal--dual grounding of a\nlearnable dual action acting as a state-dependent Lagrange multiplier, (iii)\ndifferentiable CVaR estimators with mixed pathwise and likelihood-ratio\ngradients and epi-convergence to the nonsmooth objective, (iv) an eSSVI\nwing-growth bound aligned with Lee's moment constraints, and (v)\npolicy-gradient validity under smooth surrogates. In simulation (Heston\nfallback; ABIDES-ready), the agent attains positive adjusted P\\&L on most\nintraday segments while keeping calendar violations at numerical zero and\nbutterfly violations at the numerical floor; ex-post tails remain realistic and\ncan be tuned through the CVaR weight. The five control heads admit clear\neconomic semantics and analytic sensitivities, yielding a white-box learner\nthat unifies pricing consistency and execution control in a reproducible\npipeline.", "published": "2025-10-06 08:11:16", "link": "http://arxiv.org/abs/2510.04569v1", "categories": ["q-fin.TR", "68T05, 90C20, 91G20", "I.2.6; I.2.8; G.3"], "primary_category": "q-fin.TR"}
{"title": "Tail-Safe Hedging: Explainable Risk-Sensitive Reinforcement Learning with a White-Box CBF--QP Safety Layer in Arbitrage-Free Markets", "abstract": "We introduce Tail-Safe, a deployability-oriented framework for derivatives\nhedging that unifies distributional, risk-sensitive reinforcement learning with\na white-box control-barrier-function (CBF) quadratic-program (QP) safety layer\ntailored to financial constraints. The learning component combines an IQN-based\ndistributional critic with a CVaR objective (IQN--CVaR--PPO) and a\nTail-Coverage Controller that regulates quantile sampling through temperature\ntilting and tail boosting to stabilize small-$\\alpha$ estimation. The safety\ncomponent enforces discrete-time CBF inequalities together with domain-specific\nconstraints -- ellipsoidal no-trade bands, box and rate limits, and a\nsign-consistency gate -- solved as a convex QP whose telemetry (active sets,\ntightness, rate utilization, gate scores, slack, and solver status) forms an\nauditable trail for governance. We provide guarantees of robust forward\ninvariance of the safe set under bounded model mismatch, a minimal-deviation\nprojection interpretation of the QP, a KL-to-DRO upper bound linking per-state\nKL regularization to worst-case CVaR, concentration and sample-complexity\nresults for the temperature-tilted CVaR estimator, and a CVaR trust-region\nimprovement inequality under KL limits, together with feasibility persistence\nunder expiry-aware tightening. Empirically, in arbitrage-free,\nmicrostructure-aware synthetic markets (SSVI $\\to$ Dupire $\\to$ VIX with\nABIDES/MockLOB execution), Tail-Safe improves left-tail risk without degrading\ncentral performance and yields zero hard-constraint violations whenever the QP\nis feasible with zero slack. Telemetry is mapped to governance dashboards and\nincident workflows to support explainability and auditability. Limitations\ninclude reliance on synthetic data and simplified execution to isolate\nmethodological contributions.", "published": "2025-10-06 07:39:45", "link": "http://arxiv.org/abs/2510.04555v1", "categories": ["cs.LG", "q-fin.TR", "68T05, 90C20, 91G60", "I.2.6; I.2.8; G.3"], "primary_category": "cs.LG"}
{"title": "On decomposability and subdifferential of the tensor nuclear norm", "abstract": "We study the decomposability and the subdifferential of the tensor nuclear\nnorm. Both concepts are well understood and widely applied in matrices but\nremain unclear for higher-order tensors. We show that the tensor nuclear norm\nadmits a full decomposability over specific subspaces and determine the largest\npossible subspaces that allow the full decomposability. We derive novel\ninclusions of the subdifferential of the tensor nuclear norm and study its\nsubgradients in a variety of subspaces of interest. All the results hold for\ntensors of an arbitrary order. As an immediate application, we establish the\nstatistical performance of the tensor robust principal component analysis, the\nfirst such result for tensors of an arbitrary order.", "published": "2025-10-06 09:52:15", "link": "http://arxiv.org/abs/2510.04647v1", "categories": ["math.OC", "stat.ML"], "primary_category": "math.OC"}
{"title": "Learning Linear Regression with Low-Rank Tasks in-Context", "abstract": "In-context learning (ICL) is a key building block of modern large language\nmodels, yet its theoretical mechanisms remain poorly understood. It is\nparticularly mysterious how ICL operates in real-world applications where tasks\nhave a common structure. In this work, we address this problem by analyzing a\nlinear attention model trained on low-rank regression tasks. Within this\nsetting, we precisely characterize the distribution of predictions and the\ngeneralization error in the high-dimensional limit. Moreover, we find that\nstatistical fluctuations in finite pre-training data induce an implicit\nregularization. Finally, we identify a sharp phase transition of the\ngeneralization error governed by task structure. These results provide a\nframework for understanding how transformers learn to learn the task structure.", "published": "2025-10-06 07:27:49", "link": "http://arxiv.org/abs/2510.04548v1", "categories": ["cond-mat.dis-nn", "cs.LG", "stat.ML"], "primary_category": "cond-mat.dis-nn"}
{"title": "Graph-based Tabular Deep Learning Should Learn Feature Interactions, Not Just Make Predictions", "abstract": "Despite recent progress, deep learning methods for tabular data still\nstruggle to compete with traditional tree-based models. A key challenge lies in\nmodeling complex, dataset-specific feature interactions that are central to\ntabular data. Graph-based tabular deep learning (GTDL) methods aim to address\nthis by representing features and their interactions as graphs. However,\nexisting methods predominantly optimize predictive accuracy, neglecting\naccurate modeling of the graph structure. This position paper argues that GTDL\nshould move beyond prediction-centric objectives and prioritize the explicit\nlearning and evaluation of feature interactions. Using synthetic datasets with\nknown ground-truth graph structures, we show that existing GTDL methods fail to\nrecover meaningful feature interactions. Moreover, enforcing the true\ninteraction structure improves predictive performance. This highlights the need\nfor GTDL methods to prioritize quantitative evaluation and accurate structural\nlearning. We call for a shift toward structure-aware modeling as a foundation\nfor building GTDL systems that are not only accurate but also interpretable,\ntrustworthy, and grounded in domain understanding.", "published": "2025-10-06 07:16:42", "link": "http://arxiv.org/abs/2510.04543v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Demystifying MaskGIT Sampler and Beyond: Adaptive Order Selection in Masked Diffusion", "abstract": "Masked diffusion models have shown promising performance in generating\nhigh-quality samples in a wide range of domains, but accelerating their\nsampling process remains relatively underexplored. To investigate efficient\nsamplers for masked diffusion, this paper theoretically analyzes the MaskGIT\nsampler for image modeling, revealing its implicit temperature sampling\nmechanism. Through this analysis, we introduce the \"moment sampler,\" an\nasymptotically equivalent but more tractable and interpretable alternative to\nMaskGIT, which employs a \"choose-then-sample\" approach by selecting unmasking\npositions before sampling tokens. In addition, we improve the efficiency of\nchoose-then-sample algorithms through two key innovations: a partial caching\ntechnique for transformers that approximates longer sampling trajectories\nwithout proportional computational cost, and a hybrid approach formalizing the\nexploration-exploitation trade-off in adaptive unmasking. Experiments in image\nand text domains demonstrate our theory as well as the efficiency of our\nproposed methods, advancing both theoretical understanding and practical\nimplementation of masked diffusion samplers.", "published": "2025-10-06 06:30:22", "link": "http://arxiv.org/abs/2510.04525v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Two new approaches to multiple canonical correlation analysis for repeated measures data", "abstract": "In classical canonical correlation analysis (CCA), the goal is to determine\nthe linear transformations of two random vectors into two new random variables\nthat are most strongly correlated. Canonical variables are pairs of these new\nrandom variables, while canonical correlations are correlations between these\npairs. In this paper, we propose and study two generalizations of this\nclassical method:\n  (1) Instead of two random vectors we study more complex data structures that\nappear in important applications. In these structures, there are $L$ features,\neach described by $p_l$ scalars, $1 \\le l \\le L$. We observe $n$ such objects\nover $T$ time points. We derive a suitable analog of the CCA for such data. Our\napproach relies on embeddings into Reproducing Kernel Hilbert Spaces, and\ncovers several related data structures as well.\n  (2) We develop an analogous approach for multidimensional random processes.\nIn this case, the experimental units are multivariate continuous,\nsquare-integrable functions over a given interval. These functions are modeled\nas elements of a Hilbert space, so in this case, we define the multiple\nfunctional canonical correlation analysis, MFCCA.\n  We justify our approaches by their application to two data sets and suitable\nlarge sample theory. We derive consistency rates for the related transformation\nand correlation estimators, and show that it is possible to relax two common\nassumptions on the compactness of the underlying cross-covariance operators and\nthe independence of the data.", "published": "2025-10-06 03:11:01", "link": "http://arxiv.org/abs/2510.04457v1", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.ML", "stat.TH", "62H20 (Primary) 62G05, 62G20, 62R07, 68T05 (Secondary)"], "primary_category": "stat.ME"}
{"title": "Inverse Mixed-Integer Programming: Learning Constraints then Objective Functions", "abstract": "In mixed-integer linear programming, data-driven inverse optimization that\nlearns the objective function and the constraints from observed data plays an\nimportant role in constructing appropriate mathematical models for various\nfields, including power systems and scheduling. However, to the best of our\nknowledge, there is no known method for learning both the objective functions\nand the constraints. In this paper, we propose a two-stage method for a class\nof problems where the objective function is expressed as a linear combination\nof functions and the constraints are represented by functions and thresholds.\nSpecifically, our method first learns the constraints and then learns the\nobjective function. On the theoretical side, we show the proposed method can\nsolve inverse optimization problems in finite dataset, develop statistical\nlearning theory in pseudometric spaces and sub-Gaussian distributions, and\nconstruct a statistical learning for inverse optimization. On the experimental\nside, we demonstrate that our method is practically applicable for scheduling\nproblems formulated as integer linear programmings with up to 100 decision\nvariables, which are typical in real-world settings.", "published": "2025-10-06 03:02:43", "link": "http://arxiv.org/abs/2510.04455v1", "categories": ["math.OC", "cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "math.OC"}
{"title": "Domain Generalization: A Tale of Two ERMs", "abstract": "Domain generalization (DG) is the problem of generalizing from several\ndistributions (or domains), for which labeled training data are available, to a\nnew test domain for which no labeled data is available. A common finding in the\nDG literature is that it is difficult to outperform empirical risk minimization\n(ERM) on the pooled training data.\n  In this work, we argue that this finding has primarily been reported for\ndatasets satisfying a \\emph{covariate shift} assumption. When the dataset\nsatisfies a \\emph{posterior drift} assumption instead, we show that\n``domain-informed ERM,'' wherein feature vectors are augmented with\ndomain-specific information, outperforms pooling ERM. These claims are\nsupported by a theoretical framework and experiments on language and vision\ntasks.", "published": "2025-10-06 02:17:12", "link": "http://arxiv.org/abs/2510.04441v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "spd-metrics-id: A Python Package for SPD-Aware Distance Metrics in Connectome Fingerprinting and Beyond", "abstract": "We present spd-metrics-id, a Python package for computing distances and\ndivergences between symmetric positive-definite (SPD) matrices. Unlike\ntraditional toolkits that focus on specific applications, spd-metrics-id\nprovides a unified, extensible, and reproducible framework for SPD distance\ncomputation. The package supports a wide variety of geometry-aware metrics,\nincluding Alpha-z Bures-Wasserstein, Alpha-Procrustes, affine-invariant\nRiemannian, log-Euclidean, and others, and is accessible both via a\ncommand-line interface and a Python API. Reproducibility is ensured through\nDocker images and Zenodo archiving. We illustrate usage through a connectome\nfingerprinting example, but the package is broadly applicable to covariance\nanalysis, diffusion tensor imaging, and other domains requiring SPD matrix\ncomparison. The package is openly available at\nhttps://pypi.org/project/spd-metrics-id/.", "published": "2025-10-06 02:12:55", "link": "http://arxiv.org/abs/2510.04438v1", "categories": ["stat.CO", "cs.LG", "stat.ML"], "primary_category": "stat.CO"}
{"title": "Divergence Phase Index: A Riesz-Transform Framework for Multidimensional Phase Difference Analysis", "abstract": "We introduce the Divergence Phase Index (DPI), a novel framework for\nquantifying phase differences in one and multidimensional signals, grounded in\nharmonic analysis via the Riesz transform. Based on classical Hilbert Transform\nphase measures, the DPI extends these principles to higher dimensions, offering\na geometry-aware metric that is invariant to intensity scaling and sensitive to\nstructural changes. We applied this method on both synthetic and real-world\ndatasets, including intracranial EEG (iEEG) recordings during epileptic\nseizures, high-resolution microscopy images, and paintings. In the 1D case, the\nDPI robustly detects hypersynchronization associated with generalized epilepsy,\nwhile in 2D, it reveals subtle, imperceptible changes in images and artworks.\nAdditionally, it can detect rotational variations in highly isotropic\nmicroscopy images. The DPI's robustness to amplitude variations and its\nadaptability across domains enable its use in diverse applications from\nnonlinear dynamics, complex systems analysis, to multidimensional signal\nprocessing.", "published": "2025-10-06 01:39:09", "link": "http://arxiv.org/abs/2510.04426v1", "categories": ["stat.ML", "math.FA", "47N70"], "primary_category": "stat.ML"}
{"title": "Learning Survival Models with Right-Censored Reporting Delays", "abstract": "Survival analysis is a statistical technique used to estimate the time until\nan event occurs. Although it is applied across a wide range of fields,\nadjusting for reporting delays under practical constraints remains a\nsignificant challenge in the insurance industry. Such delays render event\noccurrences unobservable when their reports are subject to right censoring.\nThis issue becomes particularly critical when estimating hazard rates for newly\nenrolled cohorts with limited follow-up due to administrative censoring. Our\nstudy addresses this challenge by jointly modeling the parametric hazard\nfunctions of event occurrences and report timings. The joint probability\ndistribution is marginalized over the latent event occurrence status. We\nconstruct an estimator for the proposed survival model and establish its\nasymptotic consistency. Furthermore, we develop an expectation-maximization\nalgorithm to compute its estimates. Using these findings, we propose a\ntwo-stage estimation procedure based on a parametric proportional hazards model\nto evaluate observations subject to administrative censoring. Experimental\nresults demonstrate that our method effectively improves the timeliness of risk\nevaluation for newly enrolled cohorts.", "published": "2025-10-06 01:16:57", "link": "http://arxiv.org/abs/2510.04421v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Modular and Adaptive Conformal Prediction for Sequential Models via Residual Decomposition", "abstract": "Conformal prediction offers finite-sample coverage guarantees under minimal\nassumptions. However, existing methods treat the entire modeling process as a\nblack box, overlooking opportunities to exploit modular structure. We introduce\na conformal prediction framework for two-stage sequential models, where an\nupstream predictor generates intermediate representations for a downstream\nmodel. By decomposing the overall prediction residual into stage-specific\ncomponents, our method enables practitioners to attribute uncertainty to\nspecific pipeline stages. We develop a risk-controlled parameter selection\nprocedure using family-wise error rate (FWER) control to calibrate stage-wise\nscaling parameters, and propose an adaptive extension for non-stationary\nsettings that preserves long-run coverage guarantees. Experiments on synthetic\ndistribution shifts, as well as real-world supply chain and stock market data,\ndemonstrate that our approach maintains coverage under conditions that degrade\nstandard conformal methods, while providing interpretable stage-wise\nuncertainty attribution. This framework offers diagnostic advantages and robust\ncoverage that standard conformal methods lack.", "published": "2025-10-06 00:33:18", "link": "http://arxiv.org/abs/2510.04406v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Perceptual Evaluation of Extrapolated Spatial Room Impulse Responses From a Mono Source", "abstract": "Immersion in virtual and augmented reality solutions is reliant on plausible\nspatial audio. However, plausibly representing a space for immersive audio\noften requires many individual acoustic measurements of source-microphone pairs\nwith specialist spatial microphones, making the procedure time-consuming and\nexpensive. In this study, we evaluate the plausibility of extrapolated and\nspatialised Room Impulse Responses (RIRs) by using a 3-Alternative Forced\nChoice (3AFC) listening test. The stimuli comprised of RIRs from three spaces\nconvolved with speech, orchestral, and instrumental music. When asked to select\nwhich stimuli was artificial out of one extrapolated and two real stimuli, an\noverall accuracy of 38% was achieved from 20 participants (5 percentage points\nabove the expected guessing rate). Given the listening test result, this study\nshows that it is possible to extrapolate plausible spatial RIRs from mono\nmeasurements, decreasing the need for time and specialist equipment in acoustic\nmeasurements.", "published": "2025-10-06 15:43:29", "link": "http://arxiv.org/abs/2510.04937v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "UniVoice: Unifying Autoregressive ASR and Flow-Matching based TTS with Large Language Models", "abstract": "Large language models (LLMs) have demonstrated promising performance in both\nautomatic speech recognition (ASR) and text-to-speech (TTS) systems, gradually\nbecoming the mainstream approach. However, most current approaches address\nthese tasks separately rather than through a unified framework. This work aims\nto integrate these two tasks into one unified model. Although discrete speech\ntokenization enables joint modeling, its inherent information loss limits\nperformance in both recognition and generation. In this work, we present\nUniVoice, a unified LLM framework through continuous representations that\nseamlessly integrates speech recognition and synthesis within a single model.\nOur approach combines the strengths of autoregressive modeling for speech\nrecognition with flow matching for high-quality generation. To mitigate the\ninherent divergence between autoregressive and flow-matching models, we further\ndesign a dual attention mechanism, which switches between a causal mask for\nrecognition and a bidirectional attention mask for synthesis. Furthermore, the\nproposed text-prefix-conditioned speech infilling method enables high-fidelity\nzero-shot voice cloning. Experimental results demonstrate that our method can\nachieve or exceed current single-task modeling methods in both ASR and\nzero-shot TTS tasks. This work explores new possibilities for end-to-end speech\nunderstanding and generation.", "published": "2025-10-06 08:47:38", "link": "http://arxiv.org/abs/2510.04593v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Evaluating Self-Supervised Speech Models via Text-Based LLMS", "abstract": "Self-Supervised Learning (SSL) has gained traction for its ability to learn\nrich representations with low labeling costs, applicable across diverse\ndownstream tasks. However, assessing the downstream-task performance remains\nchallenging due to the cost of extra training and evaluation. Existing methods\nfor task-agnostic evaluation also require extra training or hyperparameter\ntuning. We propose a novel evaluation metric using large language models\n(LLMs). By inputting discrete token sequences and minimal domain cues derived\nfrom SSL models into LLMs, we obtain the mean log-likelihood; these cues guide\nin-context learning, rendering the score more reliable without extra training\nor hyperparameter tuning. Experimental results show a correlation between\nLLM-based scores and automatic speech recognition task. Additionally, our\nfindings reveal that LLMs not only functions as an SSL evaluation tools but\nalso provides inference-time embeddings that are useful for speaker\nverification task.", "published": "2025-10-06 03:25:48", "link": "http://arxiv.org/abs/2510.04463v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Differentiable physics for sound field reconstruction", "abstract": "Sound field reconstruction involves estimating sound fields from a limited\nnumber of spatially distributed observations. This work introduces a\ndifferentiable physics approach for sound field reconstruction, where the\ninitial conditions of the wave equation are approximated with a neural network,\nand the differential operator is computed with a differentiable numerical\nsolver. The use of a numerical solver enables a stable network training while\nenforcing the physics as a strong constraint, in contrast to conventional\nphysics-informed neural networks, which include the physics as a constraint in\nthe loss function. We introduce an additional sparsity-promoting constraint to\nachieve meaningful solutions even under severe undersampling conditions.\nExperiments demonstrate that the proposed approach can reconstruct sound fields\nunder extreme data scarcity, achieving higher accuracy and better convergence\ncompared to physics-informed neural networks.", "published": "2025-10-06 03:16:44", "link": "http://arxiv.org/abs/2510.04459v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Steady-State Spread Bounds for Graph Diffusion via Laplacian Regularisation", "abstract": "We study how far a diffusion process on a graph can drift from a designed\nstarting pattern when that pattern is produced using Laplacian regularisation.\nUnder standard stability conditions for undirected, entrywise nonnegative\ngraphs, we give a closed-form, instance-specific upper bound on the\nsteady-state spread, measured as the relative change between the final and\ninitial profiles. The bound separates two effects: (i) an irreducible term\ndetermined by the graph's maximum node degree, and (ii) a design-controlled\nterm that shrinks as the regularisation strength increases (following an\ninverse square-root law). This leads to a simple design rule: given any target\nlimit on spread, one can choose a sufficient regularisation strength in closed\nform. Although one motivating application is array beamforming, where the\ninitial pattern is the squared magnitude of the beamformer weights, the result\napplies to any scenario that first enforces Laplacian smoothness and then\nevolves by linear diffusion on a graph. Overall, the guarantee is\nnon-asymptotic, easy to compute, and certifies how much steady-state deviation\ncan occur.", "published": "2025-10-06 15:35:18", "link": "http://arxiv.org/abs/2510.04924v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "The IEEE Signal Processing Society's Leading Role in Developing Standards for Computational Imaging and Sensing: Part II", "abstract": "In every imaging or sensing application, the physical hardware creates\nconstraints that must be overcome or they limit system performance. Techniques\nthat leverage additional degrees of freedom can effectively extend performance\nbeyond the inherent physical capabilities of the hardware. An example includes\nsynchronizing distributed sensors so as to synthesize a larger aperture for\nremote sensing applications. An additional example is integrating the\ncommunication and sensing functions in a wireless system through the clever\ndesign of waveforms and optimized resource management. As these technologies\nmature beyond the conceptual and prototype phase they will ultimately\ntransition to the commercial market. Here, standards play a critical role in\nensuring success. Standards ensure interoperability between systems\nmanufactured by different vendors and define industry best practices for\nvendors and customers alike. The Signal Processing Society of the Institute for\nElectrical and Electronics Engineers (IEEE) plays a leading role in developing\nhigh-quality standards for computational sensing technologies through the\nworking groups of the Synthetic Aperture Standards Committee (SASC). In this\ncolumn we highlight the standards activities of the P3383 Performance Metrics\nfor Integrated Sensing and Communication (ISAC) Systems Working Group and the\nP3343 Spatio-Temporal Synchronization of a Synthetic Aperture of Distributed\nSensors Working Group.", "published": "2025-10-06 15:26:43", "link": "http://arxiv.org/abs/2510.04913v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Interference Alignment for Multi-cluster Over-the-Air Computation", "abstract": "One of the main challenges facing Internet of Things (IoT) networks is\nmanaging interference caused by the large number of devices communicating\nsimultaneously, particularly in multi-cluster networks where multiple devices\nsimultaneously transmit to their respective receiver. Over-the-Air Computation\n(AirComp) has emerged as a promising solution for efficient real-time data\naggregation, yet its performance suffers in dense, interference-limited\nenvironments. To address this, we propose a novel Interference Alignment (IA)\nscheme tailored for up-link AirComp systems. Unlike previous approaches, the\nproposed method scales to an arbitrary number $\\sf K$ of clusters and enables\neach cluster to exploit half of the available channels, instead of only\n$\\tfrac{1}{\\sf K}$ as in time-sharing. In addition, we develop schemes tailored\nto scenarios where users are shared between adjacent clusters.", "published": "2025-10-06 12:21:14", "link": "http://arxiv.org/abs/2510.04745v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multilayer Non-Terrestrial Networks with Spectrum Access aided by Beyond-Diagonal RIS", "abstract": "In this work, we study a multi-user NTN in which a satellite serves as the\nprimary network and a high-altitude platform station (HAPS) operates as the\nsecondary network, acting as a cognitive radio. To reduce the cost, complexity,\nand power consumption of conventional antenna arrays, we equip the HAPS with a\ntransmissive BD-RIS antenna front end. We then formulate a joint optimization\nproblem for the BD-RIS phase response and the HAPS transmit power allocation\nunder strict per-user interference temperature constraints. To tackle the\nresulting highly nonconvex problem, we propose an alternating-optimization\nframework: the power-allocation subproblem admits a closed-form,\nwater-filling-type solution derived from the Karush-Kuhn-Tucker (KKT)\nconditions, while the BD-RIS configuration is refined via Riemannian manifold\noptimization. Simulation results show significant gains in data rate and\ninterference suppression over diagonal RIS-assisted benchmarks, establishing\nBD-RIS as a promising enabler for future multilayer NTNs.", "published": "2025-10-06 12:20:35", "link": "http://arxiv.org/abs/2510.04744v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Dimensionally-Efficient Transmission and Storage of Unitary Matrices", "abstract": "Unitary matrices are the basis of a large number of signal processing\napplications. In many of these applications, finding ways to efficiently store,\nand even transmit these matrices, can significantly reduce memory and\nthroughput requirements. In this work, we study the problem of efficient\ntransmission and storage of unitary matrices. Specifically, we explicitly\nderive a dimensionally-efficient parametrization (DEP) for unitary matrices\nthat allows identifying them with sequences of real numbers, where the\ndimension coincides with the dimension of the unitary group where they lie. We\nalso characterize its inverse map that allows retrieving the original unitary\nmatrices from their DEP. The proposed approach effectively allows halving the\ndimension with respect to naively considering all the entries of each unitary\nmatrix, thus reducing the resources required to store and transmit these\nmatrices. Furthermore, we show that the sequence of real numbers associated to\nthe proposed DEP is bounded, and we delimit the interval where these numbers\nare contained, facilitating the implementation of quantization approaches with\nlimited distortion. On the other hand, we outline ways to further reduce the\ndimension of the DEP when considering more restrictive constraints for matrices\nthat show up in certain applications. The numerical results showcase the\npotential of the proposed approach in general settings, as well as in three\nspecific applications of current interest for wireless communications research.", "published": "2025-10-06 12:05:51", "link": "http://arxiv.org/abs/2510.04734v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Coordinated Beamforming for Networked Integrated Communication and Multi-TMT Localization", "abstract": "Networked integrated sensing and communication (ISAC) has gained significant\nattention as a promising technology for enabling next-generation wireless\nsystems. To further enhance networked ISAC, delegating the reception of sensing\nsignals to dedicated target monitoring terminals (TMTs) instead of base\nstations (BSs) offers significant advantages in terms of sensing capability and\ndeployment flexibility. Despite its potential, the coordinated beamforming\ndesign for networked integrated communication and time-of-arrival (ToA)-based\nmulti-TMT localization remains largely unexplored. In this paper, we present a\ncomprehensive study to fill this gap. Specifically, we first establish signal\nmodels for both communication and localization, and, for the first time, derive\na closed-form Cram\\'er-Rao lower bound (CRLB) to characterize the localization\nperformance. Subsequently, we exploit this CRLB to formulate two optimization\nproblems, focusing on sensing-centric and communication-centric criteria,\nrespectively. For the sensing-centric problem, we develop a globally optimal\nalgorithm based on semidefinite relaxation (SDR) when each BS is equipped with\nmore antennas than the total number of communication users. While for the\ncommunication-centric problem, we design a globally optimal algorithm for the\nsingle-BS case using bisection search. For the general case of both problems,\nwe propose a unified successive convex approximation (SCA)-based algorithm,\nwhich is suboptimal yet efficient, and further extend it from single-target\nscenarios to more practical multi-target scenarios. Finally, simulation results\ndemonstrate the effectiveness of our proposed algorithms, reveal the intrinsic\nperformance trade-offs between communication and localization, and further show\nthat deploying more TMTs is always preferable to deploying more BSs in\nnetworked ISAC systems.", "published": "2025-10-06 09:05:58", "link": "http://arxiv.org/abs/2510.04600v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance Analysis for Multi-User Holographic MIMO Downlink with Matched Filter Precoding", "abstract": "Holographic MIMO (HMIMO) has emerged as a promising solution for future\nwireless systems by enabling ultra-dense, spatially continuous antenna\ndeployments. While prior studies have primarily focused on electromagnetic (EM)\nmodeling or simulation-based performance analysis, a rigorous\ncommunication-theoretic framework remains largely unexplored. This paper\npresents the first analytical performance study of a multi-user HMIMO downlink\nsystem with matched filter (MF) precoding - a low-complexity baseline scheme.\nBy incorporating multipath propagation, mutual coupling, and element\nexcitation, we derive a novel closed-form expression for the MF\nsignal-to-interference-plus-noise ratio (SINR) using an equivalent random\nvariable model. Leveraging bivariate gamma distributions, we then develop\ntractable throughput approximations under full, partial, and no channel state\ninformation (CSI) scenarios. Additionally, we formulate a max-min beamforming\nproblem to benchmark optimal user fairness performance. Numerical results\nvalidate the accuracy of the proposed framework and reveal that MF precoding\nachieves competitive performance with strong robustness to low SINR and CSI\nuncertainty.", "published": "2025-10-06 06:49:00", "link": "http://arxiv.org/abs/2510.04530v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Probing and Scheduling for Cache-Aided Hybrid Satellite-Terrestrial Networks", "abstract": "Caching is crucial in hybrid satellite-terrestrial networks to reduce\nlatency, optimize throughput, and improve data availability by storing\nfrequently accessed content closer to users, especially in bandwidth-limited\nsatellite systems, requiring strategic Medium Access Control (MAC) layer. This\npaper addresses throughput optimization in satellite-terrestrial integrated\nnetworks through opportunistic cooperative caching. We propose a joint probing\nand scheduling strategy to enhance content retrieval efficiency. The strategy\nleverages the LEO satellite to probe satellite-to-ground links and cache states\nof multiple cooperative terrestrial stations, enabling dynamic user scheduling\nfor content delivery. Using an optimal stopping theoretic approach with two\nlevels of incomplete information, we make real-time decisions on\nsatellite-terrestrial hybrid links and caching probing. Our threshold-based\nstrategy optimizes probing and scheduling, significantly improving average\nsystem throughput by exploiting cooperative caching, satellite-terrestrial link\ntransmission, and time diversity from dynamic user requests. Simulation results\nvalidate the effectiveness and practicality of the proposed strategies.", "published": "2025-10-06 05:04:57", "link": "http://arxiv.org/abs/2510.04492v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "The Role of ISAC in 6G Networks: Enabling Next-Generation Wireless Systems", "abstract": "The commencement of the sixth-generation (6G) wireless networks represents a\nfundamental shift in the integration of communication and sensing technologies\nto support next-generation applications. Integrated sensing and communication\n(ISAC) is a key concept in this evolution, enabling end-to-end support for both\ncommunication and sensing within a unified framework. It enhances spectrum\nefficiency, reduces latency, and supports diverse use cases, including smart\ncities, autonomous systems, and perceptive environments. This tutorial provides\na comprehensive overview of ISAC's role in 6G networks, beginning with its\nevolution since 5G and the technical drivers behind its adoption. Core\nprinciples and system variations of ISAC are introduced, followed by an\nin-depth discussion of the enabling technologies that facilitate its practical\ndeployment. The paper further analyzes current research directions to highlight\nkey challenges, open issues, and emerging trends. Design insights and\nrecommendations are also presented to support future development and\nimplementation. This work ultimately try to address three central questions:\nWhy is ISAC essential for 6G? What innovations does it bring? How will it shape\nthe future of wireless communication?", "published": "2025-10-06 00:59:01", "link": "http://arxiv.org/abs/2510.04413v1", "categories": ["eess.SP", "cs.NI"], "primary_category": "eess.SP"}
{"title": "Effect of nearby Metals on Electro-Quasistatic Human Body Communication", "abstract": "In recent decades Human Body Communication has emerged as a promising\nalternative to traditional radio wave communication, utilizing the body's\nconductive properties for low-power connectivity among wearables. This method\nharnesses the human body as an energy-efficient channel for data transmission\nwithin the electro-quasistatic frequency range, enabling advancements in\nhuman-machine interaction. While prior work has noted the role of parasitic\nreturn paths in such capacitively coupled systems, the influence of surrounding\nmetallic objects on these paths, which are critical for EQS wireless signaling,\nhas not been fully explored. This paper fills that gap with a structured study\nof how various conducting objects, from non-grounded (floating) metals and\ngrounded metals to enclosed metallic environments such as elevators and cars,\naffect the body-communication channel. We present a theoretical framework\nsupported by finite element method simulations and experiments with wearable\ndevices. Results show that metallic objects within 20 cm of devices can reduce\ntransmission loss by about 10 dB. When a device ground connects to a grounded\nmetallic object, channel gain can increase by at least 20 dB. Contact area\nduring touch-based interactions with grounded metals produces contact-impedance\ndependent high-pass channel characteristics. Proximity to metallic objects\nintroduces variability within a critical distance, with grounded metals\nproducing a larger overall effect than floating metals. These findings improve\nunderstanding of body-centric communication links and inform design for\nhealthcare, consumer electronics, defense, and industrial applications.", "published": "2025-10-06 00:52:04", "link": "http://arxiv.org/abs/2510.04409v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-Rank-Based Approximate Computation with Memristors", "abstract": "Memristor crossbars enable vector-matrix multiplication (VMM), and are\npromising for low-power applications. However, it can be difficult to write the\nmemristor conductance values exactly. To improve the accuracy of VMM, we\npropose a scheme based on low-rank matrix approximation. Specifically, singular\nvalue decomposition (SVD) is first applied to obtain a low-rank approximation\nof the target matrix, which is then factored into a pair of smaller matrices.\nSubsequently, a two-step serial VMM is executed, where the stochastic write\nerrors are mitigated through step-wise averaging. To evaluate the performance\nof the proposed scheme, we derive a general expression for the resulting\ncomputation error and provide an asymptotic analysis under a prescribed\nsingular-value profile, which reveals how the error scales with matrix size and\nrank. Both analytical and numerical results confirm the superiority of the\nproposed scheme compared with the benchmark scheme.", "published": "2025-10-06 00:15:44", "link": "http://arxiv.org/abs/2510.04402v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
