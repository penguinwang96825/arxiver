{"title": "Natural Language Generation Using Reinforcement Learning with External\n  Rewards", "abstract": "We propose an approach towards natural language generation using a\nbidirectional encoder-decoder which incorporates external rewards through\nreinforcement learning (RL). We use attention mechanism and maximum mutual\ninformation as an initial objective function using RL. Using a two-part\ntraining scheme, we train an external reward analyzer to predict the external\nrewards and then use the predicted rewards to maximize the expected rewards\n(both internal and external). We evaluate the system on two standard dialogue\ncorpora - Cornell Movie Dialog Corpus and Yelp Restaurant Review Corpus. We\nreport standard evaluation metrics including BLEU, ROUGE-L, and perplexity as\nwell as human evaluation to validate our approach.", "published": "2019-11-26 08:46:11", "link": "http://arxiv.org/abs/1911.11404v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Large-scale Dataset for Argument Quality Ranking: Construction and\n  Analysis", "abstract": "Identifying the quality of free-text arguments has become an important task\nin the rapidly expanding field of computational argumentation. In this work, we\nexplore the challenging task of argument quality ranking. To this end, we\ncreated a corpus of 30,497 arguments carefully annotated for point-wise\nquality, released as part of this work. To the best of our knowledge, this is\nthe largest dataset annotated for point-wise argument quality, larger by a\nfactor of five than previously released datasets. Moreover, we address the core\nissue of inducing a labeled score from crowd annotations by performing a\ncomprehensive evaluation of different approaches to this problem. In addition,\nwe analyze the quality dimensions that characterize this dataset. Finally, we\npresent a neural method for argument quality ranking, which outperforms several\nbaselines on our own dataset, as well as previous methods published for another\ndataset.", "published": "2019-11-26 08:53:12", "link": "http://arxiv.org/abs/1911.11408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relevance-Promoting Language Model for Short-Text Conversation", "abstract": "Despite the effectiveness of sequence-to-sequence framework on the task of\nShort-Text Conversation (STC), the issue of under-exploitation of training data\n(i.e., the supervision signals from query text is \\textit{ignored}) still\nremains unresolved. Also, the adopted \\textit{maximization}-based decoding\nstrategies, inclined to generating the generic responses or responses with\nrepetition, are unsuited to the STC task. In this paper, we propose to\nformulate the STC task as a language modeling problem and tailor-make a\ntraining strategy to adapt a language model for response generation. To enhance\ngeneration performance, we design a relevance-promoting transformer language\nmodel, which performs additional supervised source attention after the\nself-attention to increase the importance of informative query tokens in\ncalculating the token-level representation. The model further refines the query\nrepresentation with relevance clues inferred from its multiple references\nduring training. In testing, we adopt a\n\\textit{randomization-over-maximization} strategy to reduce the generation of\ngeneric responses. Experimental results on a large Chinese STC dataset\ndemonstrate the superiority of the proposed model on relevance metrics and\ndiversity metrics.\\footnote{Code available at\nhttps://ai.tencent.com/ailab/nlp/dialogue/.", "published": "2019-11-26 12:17:59", "link": "http://arxiv.org/abs/1911.11489v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Relation Constraints with Neural Relation Extractors", "abstract": "Recent years have seen rapid progress in identifying predefined relationship\nbetween entity pairs using neural networks NNs. However, such models often make\npredictions for each entity pair individually, thus often fail to solve the\ninconsistency among different predictions, which can be characterized by\ndiscrete relation constraints. These constraints are often defined over\ncombinations of entity-relation-entity triples, since there often lack of\nexplicitly well-defined type and cardinality requirements for the relations. In\nthis paper, we propose a unified framework to integrate relation constraints\nwith NNs by introducing a new loss term, ConstraintLoss. Particularly, we\ndevelop two efficient methods to capture how well the local predictions from\nmultiple instance pairs satisfy the relation constraints. Experiments on both\nEnglish and Chinese datasets show that our approach can help NNs learn from\ndiscrete relation constraints to reduce inconsistency among local predictions,\nand outperform popular neural relation extraction NRE models even enhanced with\nextra post-processing. Our source code and datasets will be released at\nhttps://github.com/PKUYeYuan/Constraint-Loss-AAAI-2020.", "published": "2019-11-26 12:29:19", "link": "http://arxiv.org/abs/1911.11493v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation with Explicit Phrase Alignment", "abstract": "While neural machine translation (NMT) has achieved state-of-the-art\ntranslation performance, it is unable to capture the alignment between the\ninput and output during the translation process. The lack of alignment in NMT\nmodels leads to three problems: it is hard to (1) interpret the translation\nprocess, (2) impose lexical constraints, and (3) impose structural constraints.\nTo alleviate these problems, we propose to introduce explicit phrase alignment\ninto the translation process of arbitrary NMT models. The key idea is to build\na search space similar to that of phrase-based statistical machine translation\nfor NMT where phrase alignment is readily available. We design a new decoding\nalgorithm that can easily impose lexical and structural constraints.\nExperiments show that our approach makes the translation process of NMT more\ninterpretable without sacrificing translation quality. In addition, our\napproach achieves significant improvements in lexically and structurally\nconstrained translation tasks.", "published": "2019-11-26 13:28:59", "link": "http://arxiv.org/abs/1911.11520v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Time Series Analysis of Emotional Loading in Central Bank Statements", "abstract": "We examine the affective content of central bank press statements using\nemotion analysis. Our focus is on two major international players, the European\nCentral Bank (ECB) and the US Federal Reserve Bank (Fed), covering a time span\nfrom 1998 through 2019. We reveal characteristic patterns in the emotional\ndimensions of valence, arousal, and dominance and find---despite the commonly\nestablished attitude that emotional wording in central bank communication\nshould be avoided---a correlation between the state of the economy and\nparticularly the dominance dimension in the press releases under scrutiny and,\noverall, an impact of the president in office.", "published": "2019-11-26 13:31:08", "link": "http://arxiv.org/abs/1911.11522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Vietnamese Text-Based Conversational Agent", "abstract": "This paper introduces a Vietnamese text-based conversational agent\narchitecture on specific knowledge domain which is integrated in a question\nanswering system. When the question answering system fails to provide answers\nto users' input, our conversational agent can step in to interact with users to\nprovide answers to users. Experimental results are promising where our\nVietnamese text-based conversational agent achieves positive feedback in a\nstudy conducted in the university academic regulation domain.", "published": "2019-11-26 14:11:50", "link": "http://arxiv.org/abs/1911.11547v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-supervised Bootstrapping of Dialogue State Trackers for Task\n  Oriented Modelling", "abstract": "Dialogue systems benefit greatly from optimizing on detailed annotations,\nsuch as transcribed utterances, internal dialogue state representations and\ndialogue act labels. However, collecting these annotations is expensive and\ntime-consuming, holding back development in the area of dialogue modelling. In\nthis paper, we investigate semi-supervised learning methods that are able to\nreduce the amount of required intermediate labelling. We find that by\nleveraging un-annotated data instead, the amount of turn-level annotations of\ndialogue state can be significantly reduced when building a neural dialogue\nsystem. Our analysis on the MultiWOZ corpus, covering a range of domains and\ntopics, finds that annotations can be reduced by up to 30\\% while maintaining\nequivalent system performance. We also describe and evaluate the first\nend-to-end dialogue model created for the MultiWOZ corpus.", "published": "2019-11-26 16:12:36", "link": "http://arxiv.org/abs/1911.11672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Vietnamese Question Answering System", "abstract": "Question answering systems aim to produce exact answers to users' questions\ninstead of a list of related documents as used by current search engines. In\nthis paper, we propose an ontology-based Vietnamese question answering system\nthat allows users to express their questions in natural language. To the best\nof our knowledge, this is the first attempt to enable users to query an\nontological knowledge base using Vietnamese natural language. Experiments of\nour system on an organizational ontology show promising results.", "published": "2019-11-26 11:44:55", "link": "http://arxiv.org/abs/1911.12267v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Iterative Batch Back-Translation for Neural Machine Translation: A\n  Conceptual Model", "abstract": "An effective method to generate a large number of parallel sentences for\ntraining improved neural machine translation (NMT) systems is the use of\nback-translations of the target-side monolingual data. Recently, iterative\nback-translation has been shown to outperform standard back-translation albeit\non some language pairs. This work proposes the iterative batch back-translation\nthat is aimed at enhancing the standard iterative back-translation and enabling\nthe efficient utilization of more monolingual data. After each iteration,\nimproved back-translations of new sentences are added to the parallel data that\nwill be used to train the final forward model. The work presents a conceptual\nmodel of the proposed approach.", "published": "2019-11-26 05:59:41", "link": "http://arxiv.org/abs/2001.11327v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tracing State-Level Obesity Prevalence from Sentence Embeddings of\n  Tweets: A Feasibility Study", "abstract": "Twitter data has been shown broadly applicable for public health\nsurveillance. Previous public health studies based on Twitter data have largely\nrelied on keyword-matching or topic models for clustering relevant tweets.\nHowever, both methods suffer from the short-length of texts and unpredictable\nnoise that naturally occurs in user-generated contexts. In response, we\nintroduce a deep learning approach that uses hashtags as a form of supervision\nand learns tweet embeddings for extracting informative textual features. In\nthis case study, we address the specific task of estimating state-level obesity\nfrom dietary-related textual features. Our approach yields an estimation that\nstrongly correlates the textual features to government data and outperforms the\nkeyword-matching baseline. The results also demonstrate the potential of\ndiscovering risk factors using the textual features. This method is\ngeneral-purpose and can be applied to a wide range of Twitter-based public\nhealth studies.", "published": "2019-11-26 03:57:15", "link": "http://arxiv.org/abs/1911.11324v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Feature-Rich Part-of-speech Tagging for Morphologically Complex\n  Languages: Application to Bulgarian", "abstract": "We present experiments with part-of-speech tagging for Bulgarian, a Slavic\nlanguage with rich inflectional and derivational morphology. Unlike most\nprevious work, which has used a small number of grammatical categories, we work\nwith 680 morpho-syntactic tags. We combine a large morphological lexicon with\nprior linguistic knowledge and guided learning from a POS-annotated corpus,\nachieving accuracy of 97.98%, which is a significant improvement over the\nstate-of-the-art for Bulgarian.", "published": "2019-11-26 13:05:33", "link": "http://arxiv.org/abs/1911.11503v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Doc2Vec on the PubMed corpus: study of a new approach to generate\n  related articles", "abstract": "PubMed is the biggest and most used bibliographic database worldwide, hosting\nmore than 26M biomedical publications. One of its useful features is the\n\"similar articles\" section, allowing the end-user to find scientific articles\nlinked to the consulted document in term of context. The aim of this study is\nto analyze whether it is possible to replace the statistic model PubMed Related\nArticles (pmra) with a document embedding method. Doc2Vec algorithm was used to\ntrain models allowing to vectorize documents. Six of its parameters were\noptimised by following a grid-search strategy to train more than 1,900 models.\nParameters combination leading to the best accuracy was used to train models on\nabstracts from the PubMed database. Four evaluations tasks were defined to\ndetermine what does or does not influence the proximity between documents for\nboth Doc2Vec and pmra. The two different Doc2Vec architectures have different\nabilities to link documents about a common context. The terminological\nindexing, words and stems contents of linked documents are highly similar\nbetween pmra and Doc2Vec PV-DBOW architecture. These algorithms are also more\nlikely to bring closer documents having a similar size. In contrary, the manual\nevaluation shows much better results for the pmra algorithm. While the pmra\nalgorithm links documents by explicitly using terminological indexing in its\nformula, Doc2Vec does not need a prior indexing. It can infer relations between\ndocuments sharing a similar indexing, without any knowledge about them,\nparticularly regarding the PV-DBOW architecture. In contrary, the human\nevaluation, without any clear agreement between evaluators, implies future\nstudies to better understand this difference between PV-DBOW and pmra\nalgorithm.", "published": "2019-11-26 17:06:02", "link": "http://arxiv.org/abs/1911.11698v1", "categories": ["cs.CL", "cs.IR", "H.3.3, I.2.7", "H.3.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "CONAN: Complementary Pattern Augmentation for Rare Disease Detection", "abstract": "Rare diseases affect hundreds of millions of people worldwide but are hard to\ndetect since they have extremely low prevalence rates (varying from 1/1,000 to\n1/200,000 patients) and are massively underdiagnosed. How do we reliably detect\nrare diseases with such low prevalence rates? How to further leverage patients\nwith possibly uncertain diagnosis to improve detection? In this paper, we\npropose a Complementary pattern Augmentation (CONAN) framework for rare disease\ndetection. CONAN combines ideas from both adversarial training and max-margin\nclassification. It first learns self-attentive and hierarchical embedding for\npatient pattern characterization. Then, we develop a complementary generative\nadversarial networks (GAN) model to generate candidate positive and negative\nsamples from the uncertain patients by encouraging a max-margin between\nclasses. In addition, CONAN has a disease detector that serves as the\ndiscriminator during the adversarial training for identifying rare diseases. We\nevaluated CONAN on two disease detection tasks. For low prevalence inflammatory\nbowel disease (IBD) detection, CONAN achieved .96 precision recall area under\nthe curve (PR-AUC) and 50.1% relative improvement over best baseline. For rare\ndisease idiopathic pulmonary fibrosis (IPF) detection, CONAN achieves .22\nPR-AUC with 41.3% relative improvement over the best baseline.", "published": "2019-11-26 22:18:40", "link": "http://arxiv.org/abs/1911.13232v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Low Rank Factorization for Compact Multi-Head Self-Attention", "abstract": "Effective representation learning from text has been an active area of\nresearch in the fields of NLP and text mining. Attention mechanisms have been\nat the forefront in order to learn contextual sentence representations. Current\nstate-of-the-art approaches for many NLP tasks use large pre-trained language\nmodels such as BERT, XLNet and so on for learning representations. These models\nare based on the Transformer architecture that involves recurrent blocks of\ncomputation consisting of multi-head self-attention and feedforward networks.\nOne of the major bottlenecks largely contributing to the computational\ncomplexity of the Transformer models is the self-attention layer, that is both\ncomputationally expensive and parameter intensive. In this work, we introduce a\nnovel multi-head self-attention mechanism operating on GRUs that is shown to be\ncomputationally cheaper and more parameter efficient than self-attention\nmechanism proposed in Transformers for text classification tasks. The\nefficiency of our approach mainly stems from two optimizations; 1) we use\nlow-rank matrix factorization of the affinity matrix to efficiently get\nmultiple attention distributions instead of having separate parameters for each\nhead 2) attention scores are obtained by querying a global context vector\ninstead of densely querying all the words in the sentence. We evaluate the\nperformance of the proposed model on tasks such as sentiment analysis from\nmovie reviews, predicting business ratings from reviews and classifying news\narticles into topics. We find that the proposed approach matches or outperforms\na series of strong baselines and is more parameter efficient than comparable\nmulti-head approaches. We also perform qualitative analyses to verify that the\nproposed approach is interpretable and captures context-dependent word\nimportance.", "published": "2019-11-26 16:01:51", "link": "http://arxiv.org/abs/1912.00835v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Determine the Quality of News Headlines", "abstract": "Today, most newsreaders read the online version of news articles rather than\ntraditional paper-based newspapers. Also, news media publishers rely heavily on\nthe income generated from subscriptions and website visits made by newsreaders.\nThus, online user engagement is a very important issue for online newspapers.\nMuch effort has been spent on writing interesting headlines to catch the\nattention of online users. On the other hand, headlines should not be\nmisleading (e.g., clickbaits); otherwise, readers would be disappointed when\nreading the content. In this paper, we propose four indicators to determine the\nquality of published news headlines based on their click count and dwell time,\nwhich are obtained by website log analysis. Then, we use soft target\ndistribution of the calculated quality indicators to train our proposed deep\nlearning model which can predict the quality of unpublished news headlines. The\nproposed model not only processes the latent features of both headline and body\nof the article to predict its headline quality but also considers the semantic\nrelation between headline and body as well. To evaluate our model, we use a\nreal dataset from a major Canadian newspaper. Results show our proposed model\noutperforms other state-of-the-art NLP models.", "published": "2019-11-26 00:09:30", "link": "http://arxiv.org/abs/1911.11139v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Few-Shot Knowledge Graph Completion", "abstract": "Knowledge graphs (KGs) serve as useful resources for various natural language\nprocessing applications. Previous KG completion approaches require a large\nnumber of training instances (i.e., head-tail entity pairs) for every relation.\nThe real case is that for most of the relations, very few entity pairs are\navailable. Existing work of one-shot learning limits method generalizability\nfor few-shot scenarios and does not fully use the supervisory information;\nhowever, few-shot KG completion has not been well studied yet. In this work, we\npropose a novel few-shot relation learning model (FSRL) that aims at\ndiscovering facts of new relations with few-shot references. FSRL can\neffectively capture knowledge from heterogeneous graph structure, aggregate\nrepresentations of few-shot references, and match similar entity pairs of\nreference set for every relation. Extensive experiments on two public datasets\ndemonstrate that FSRL outperforms the state-of-the-art.", "published": "2019-11-26 01:01:37", "link": "http://arxiv.org/abs/1911.11298v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CAWA: An Attention-Network for Credit Attribution", "abstract": "Credit attribution is the task of associating individual parts in a document\nwith their most appropriate class labels. It is an important task with\napplications to information retrieval and text summarization. When labeled\ntraining data is available, traditional approaches for sequence tagging can be\nused for credit attribution. However, generating such labeled datasets is\nexpensive and time-consuming. In this paper, we present \"Credit Attribution\nWith Attention (CAWA)\", a neural-network-based approach, that instead of using\nsentence-level labeled data, uses the set of class labels that are associated\nwith an entire document as a source of distant-supervision. CAWA combines an\nattention mechanism with a multilabel classifier into an end-to-end learning\nframework to perform credit attribution. CAWA labels the individual sentences\nfrom the input document using the resultant attention-weights. CAWA improves\nupon the state-of-the-art credit attribution approach by not constraining a\nsentence to belong to just one class, but modeling each sentence as a\ndistribution over all classes, leading to better modeling of\nsemantically-similar classes. Experiments on the credit attribution task on a\nvariety of datasets show that the sentence class labels generated by CAWA\noutperform the competing approaches. Additionally, on the multilabel text\nclassification task, CAWA performs better than the competing credit attribution\napproaches.", "published": "2019-11-26 06:02:33", "link": "http://arxiv.org/abs/1911.11358v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ATCSpeech: a multilingual pilot-controller speech corpus from real Air\n  Traffic Control environment", "abstract": "Automatic Speech Recognition (ASR) is greatly developed in recent years,\nwhich expedites many applications on other fields. For the ASR research, speech\ncorpus is always an essential foundation, especially for the vertical industry,\nsuch as Air Traffic Control (ATC). There are some speech corpora for common\napplications, public or paid. However, for the ATC, it is difficult to collect\nraw speeches from real systems due to safety issues. More importantly, for a\nsupervised learning task like ASR, annotating the transcription is a more\nlaborious work, which hugely restricts the prospect of ASR application. In this\npaper, a multilingual speech corpus (ATCSpeech) from real ATC systems,\nincluding accented Mandarin Chinese and English, is built and released to\nencourage the non-commercial ASR research in ATC domain. The corpus is detailly\nintroduced from the perspective of data amount, speaker gender and role, speech\nquality and other attributions. In addition, the performance of our baseline\nASR models is also reported. A community edition for our speech database can be\napplied and used under a special contrast. To our best knowledge, this is the\nfirst work that aims at building a real and multilingual ASR corpus for the air\ntraffic related research.", "published": "2019-11-26 06:35:08", "link": "http://arxiv.org/abs/1911.11365v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SemEval-2015 Task 3: Answer Selection in Community Question Answering", "abstract": "Community Question Answering (cQA) provides new interesting research\ndirections to the traditional Question Answering (QA) field, e.g., the\nexploitation of the interaction between users and the structure of related\nposts. In this context, we organized SemEval-2015 Task 3 on \"Answer Selection\nin cQA\", which included two subtasks: (a) classifying answers as \"good\", \"bad\",\nor \"potentially relevant\" with respect to the question, and (b) answering a\nYES/NO question with \"yes\", \"no\", or \"unsure\", based on the list of all\nanswers. We set subtask A for Arabic and English on two relatively different\ncQA domains, i.e., the Qatar Living website for English, and a Quran-related\nwebsite for Arabic. We used crowdsourcing on Amazon Mechanical Turk to label a\nlarge English training dataset, which we released to the research community.\nThirteen teams participated in the challenge with a total of 61 submissions: 24\nprimary and 37 contrastive. The best systems achieved an official score\n(macro-averaged F1) of 57.19 and 63.7 for the English subtasks A and B, and\n78.55 for the Arabic subtask A.", "published": "2019-11-26 08:40:49", "link": "http://arxiv.org/abs/1911.11403v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Single Headed Attention RNN: Stop Thinking With Your Head", "abstract": "The leading approaches in language modeling are all obsessed with TV shows of\nmy youth - namely Transformers and Sesame Street. Transformers this,\nTransformers that, and over here a bonfire worth of GPU-TPU-neuromorphic wafer\nscale silicon. We opt for the lazy path of old and proven techniques with a\nfancy crypto inspired acronym: the Single Headed Attention RNN (SHA-RNN). The\nauthor's lone goal is to show that the entire field might have evolved a\ndifferent direction if we had instead been obsessed with a slightly different\nacronym and slightly different result. We take a previously strong language\nmodel based only on boring LSTMs and get it to within a stone's throw of a\nstone's throw of state-of-the-art byte level language model results on enwik8.\nThis work has undergone no intensive hyperparameter optimization and lived\nentirely on a commodity desktop machine that made the author's small studio\napartment far too warm in the midst of a San Franciscan summer. The final\nresults are achievable in plus or minus 24 hours on a single GPU as the author\nis impatient. The attention mechanism is also readily extended to large\ncontexts with minimal computation. Take that Sesame Street.", "published": "2019-11-26 09:45:33", "link": "http://arxiv.org/abs/1911.11423v2", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Word-Class Embeddings for Multiclass Text Classification", "abstract": "Pre-trained word embeddings encode general word semantics and lexical\nregularities of natural language, and have proven useful across many NLP tasks,\nincluding word sense disambiguation, machine translation, and sentiment\nanalysis, to name a few. In supervised tasks such as multiclass text\nclassification (the focus of this article) it seems appealing to enhance word\nrepresentations with ad-hoc embeddings that encode task-specific information.\nWe propose (supervised) word-class embeddings (WCEs), and show that, when\nconcatenated to (unsupervised) pre-trained word embeddings, they substantially\nfacilitate the training of deep-learning models in multiclass classification by\ntopic. We show empirical evidence that WCEs yield a consistent improvement in\nmulticlass classification accuracy, using four popular neural architectures and\nsix widely used and publicly available datasets for multiclass text\nclassification. Our code that implements WCEs is publicly available at\nhttps://github.com/AlexMoreo/word-class-embeddings", "published": "2019-11-26 13:11:00", "link": "http://arxiv.org/abs/1911.11506v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "PIQA: Reasoning about Physical Commonsense in Natural Language", "abstract": "To apply eyeshadow without a brush, should I use a cotton swab or a\ntoothpick? Questions requiring this kind of physical commonsense pose a\nchallenge to today's natural language understanding systems. While recent\npretrained models (such as BERT) have made progress on question answering over\nmore abstract domains - such as news articles and encyclopedia entries, where\ntext is plentiful - in more physical domains, text is inherently limited due to\nreporting bias. Can AI systems learn to reliably answer physical common-sense\nquestions without experiencing the physical world? In this paper, we introduce\nthe task of physical commonsense reasoning and a corresponding benchmark\ndataset Physical Interaction: Question Answering or PIQA. Though humans find\nthe dataset easy (95% accuracy), large pretrained models struggle (77%). We\nprovide analysis about the dimensions of knowledge that existing models lack,\nwhich offers significant opportunities for future research.", "published": "2019-11-26 15:31:46", "link": "http://arxiv.org/abs/1911.11641v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hybrid Text Feature Modeling for Disease Group Prediction using\n  Unstructured Physician Notes", "abstract": "Existing Clinical Decision Support Systems (CDSSs) largely depend on the\navailability of structured patient data and Electronic Health Records (EHRs) to\naid caregivers. However, in case of hospitals in developing countries,\nstructured patient data formats are not widely adopted, where medical\nprofessionals still rely on clinical notes in the form of unstructured text.\nSuch unstructured clinical notes recorded by medical personnel can also be a\npotential source of rich patient-specific information which can be leveraged to\nbuild CDSSs, even for hospitals in developing countries. If such unstructured\nclinical text can be used, the manual and time-consuming process of EHR\ngeneration will no longer be required, with huge person-hours and cost savings.\nIn this paper, we propose a generic ICD9 disease group prediction CDSS built on\nunstructured physician notes modeled using hybrid word embeddings. These word\nembeddings are used to train a deep neural network for effectively predicting\nICD9 disease groups. Experimental evaluation showed that the proposed approach\noutperformed the state-of-the-art disease group prediction model built on\nstructured EHRs by 15% in terms of AUROC and 40% in terms of AUPRC, thus\nproving our hypothesis and eliminating dependency on availability of structured\npatient data.", "published": "2019-11-26 15:55:39", "link": "http://arxiv.org/abs/1911.11657v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Biology and Compositionality: Empirical Considerations for\n  Emergent-Communication Protocols", "abstract": "Significant advances have been made in artificial systems by using biological\nsystems as a guide. However, there is often little interaction between\ncomputational models for emergent communication and biological models of the\nemergence of language. Many researchers in language origins and emergent\ncommunication take compositionality as their primary target for explaining how\nsimple communication systems can become more like natural language. However,\nthere is reason to think that compositionality is the wrong target on the\nbiological side, and so too the wrong target on the machine-learning side. As\nsuch, the purpose of this paper is to explore this claim. This has theoretical\nimplications for language origins research more generally, but the focus here\nwill be the implications for research on emergent communication in computer\nscience and machine learning---specifically regarding the types of programmes\nthat might be expected to work and those which will not. I further suggest an\nalternative approach for future research which focuses on reflexivity, rather\nthan compositionality, as a target for explaining how simple communication\nsystems may become more like natural language. I end by providing some\nreference to the language origins literature that may be of some use to\nresearchers in machine learning.", "published": "2019-11-26 16:07:44", "link": "http://arxiv.org/abs/1911.11668v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Imitation Learning of Robot Policies by Combining Language, Vision and\n  Demonstration", "abstract": "In this work we propose a novel end-to-end imitation learning approach which\ncombines natural language, vision, and motion information to produce an\nabstract representation of a task, which in turn is used to synthesize specific\nmotion controllers at run-time. This multimodal approach enables generalization\nto a wide variety of environmental conditions and allows an end-user to direct\na robot policy through verbal communication. We empirically validate our\napproach with an extensive set of simulations and show that it achieves a high\ntask success rate over a variety of conditions while remaining amenable to\nprobabilistic interpretability.", "published": "2019-11-26 18:27:51", "link": "http://arxiv.org/abs/1911.11744v1", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "A Measure of Similarity in Textual Data Using Spearman's Rank\n  Correlation Coefficient", "abstract": "In the last decade, many diverse advances have occurred in the field of\ninformation extraction from data. Information extraction in its simplest form\ntakes place in computing environments, where structured data can be extracted\nthrough a series of queries. The continuous expansion of quantities of data\nhave therefore provided an opportunity for knowledge extraction (KE) from a\ntextual document (TD). A typical problem of this kind is the extraction of\ncommon characteristics and knowledge from a group of TDs, with the possibility\nto group such similar TDs in a process known as clustering. In this paper we\npresent a technique for such KE among a group of TDs related to the common\ncharacteristics and meaning of their content. Our technique is based on the\nSpearman's Rank Correlation Coefficient (SRCC), for which the conducted\nexperiments have proven to be comprehensive measure to achieve a high-quality\nKE.", "published": "2019-11-26 18:38:59", "link": "http://arxiv.org/abs/1911.11750v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Semi-Supervised Learning for Text Classification by Layer Partitioning", "abstract": "Most recent neural semi-supervised learning algorithms rely on adding small\nperturbation to either the input vectors or their representations. These\nmethods have been successful on computer vision tasks as the images form a\ncontinuous manifold, but are not appropriate for discrete input such as\nsentence. To adapt these methods to text input, we propose to decompose a\nneural network $M$ into two components $F$ and $U$ so that $M = U\\circ F$. The\nlayers in $F$ are then frozen and only the layers in $U$ will be updated during\nmost time of the training. In this way, $F$ serves as a feature extractor that\nmaps the input to high-level representation and adds systematical noise using\ndropout. We can then train $U$ using any state-of-the-art SSL algorithms such\nas $\\Pi$-model, temporal ensembling, mean teacher, etc. Furthermore, this\ngradually unfreezing schedule also prevents a pretrained model from\ncatastrophic forgetting. The experimental results demonstrate that our approach\nprovides improvements when compared to state of the art methods especially on\nshort texts.", "published": "2019-11-26 18:47:48", "link": "http://arxiv.org/abs/1911.11756v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Cross-lingual Multi-speaker Text-to-speech Synthesis for Voice Cloning\n  without Using Parallel Corpus for Unseen Speakers", "abstract": "We investigate a novel cross-lingual multi-speaker text-to-speech synthesis\napproach for generating high-quality native or accented speech for\nnative/foreign seen/unseen speakers in English and Mandarin. The system\nconsists of three separately trained components: an x-vector speaker encoder, a\nTacotron-based synthesizer and a WaveNet vocoder. It is conditioned on 3 kinds\nof embeddings: (1) speaker embedding so that the system can be trained with\nspeech from many speakers will little data from each speaker; (2) language\nembedding with shared phoneme inputs; (3) stress and tone embedding which\nimproves naturalness of synthesized speech, especially for a tonal language\nlike Mandarin. By adjusting the various embeddings, MOS results show that our\nmethod can generate high-quality natural and intelligible native speech for\nnative/foreign seen/unseen speakers. Intelligibility and naturalness of\naccented speech is low as expected. Speaker similarity is good for native\nspeech from native speakers. Interestingly, speaker similarity is also good for\naccented speech from foreign speakers. We also find that normalizing speaker\nembedding x-vectors by L2-norm normalization or whitening improves output\nquality a lot in many cases, and the WaveNet performance seems to be\nlanguage-independent: our WaveNet is trained with Cantonese speech and can be\nused to generate Mandarin and English speech very well.", "published": "2019-11-26 15:01:31", "link": "http://arxiv.org/abs/1911.11601v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A two-step system for sound event localization and detection", "abstract": "Sound event detection and sound event localization requires different\nfeatures from audio input signals. While sound event detection mainly relies on\ntime-frequency patterns to distinguish different event classes, sound event\nlocalization uses magnitude or phase differences between microphones to\nestimate source directions. Therefore, we propose a two-step system to do sound\nevent localization and detection. In the first step, we detect the sound events\nand estimate the directions-of-arrival separately. In the second step, we\ncombine the results of the event detector and direction-of-arrival estimator\ntogether. The obtained results show a significant improvement over the baseline\nsolution for sound event localization and detection in DCASE 2019 task 3\nchallenge. Using the evaluation dataset, the proposed system achieved an F1\nscore of 93.4% for sound event detection and an error of 5.4 degrees for\ndirection-of-arrival estimation, while the winning solution achieved an F1\nscore of 94.7% and an angle error of 3.7 degrees respectively.", "published": "2019-11-26 07:09:25", "link": "http://arxiv.org/abs/1911.11373v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust Estimation of Hypernasality in Dysarthria with Acoustic Model\n  Likelihood Features", "abstract": "Hypernasality is a common characteristic symptom across many motor-speech\ndisorders. For voiced sounds, hypernasality introduces an additional resonance\nin the lower frequencies and, for unvoiced sounds, there is reduced\narticulatory precision due to air escaping through the nasal cavity. However,\nthe acoustic manifestation of these symptoms is highly variable, making\nhypernasality estimation very challenging, both for human specialists and\nautomated systems. Previous work in this area relies on either engineered\nfeatures based on statistical signal processing or machine learning models\ntrained on clinical ratings. Engineered features often fail to capture the\ncomplex acoustic patterns associated with hypernasality, whereas metrics based\non machine learning are prone to overfitting to the small disease-specific\nspeech datasets on which they are trained. Here we propose a new set of\nacoustic features that capture these complementary dimensions. The features are\nbased on two acoustic models trained on a large corpus of healthy speech. The\nfirst acoustic model aims to measure nasal resonance from voiced sounds,\nwhereas the second acoustic model aims to measure articulatory imprecision from\nunvoiced sounds. To demonstrate that the features derived from these acoustic\nmodels are specific to hypernasal speech, we evaluate them across different\ndysarthria corpora. Our results show that the features generalize even when\ntraining on hypernasal speech from one disease and evaluating on hypernasal\nspeech from another disease (e.g. training on Parkinson's disease, evaluation\non Huntington's disease), and when training on neurologically disordered speech\nbut evaluating on cleft palate speech.", "published": "2019-11-26 06:11:21", "link": "http://arxiv.org/abs/1911.11360v4", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Hearing Lips: Improving Lip Reading by Distilling Speech Recognizers", "abstract": "Lip reading has witnessed unparalleled development in recent years thanks to\ndeep learning and the availability of large-scale datasets. Despite the\nencouraging results achieved, the performance of lip reading, unfortunately,\nremains inferior to the one of its counterpart speech recognition, due to the\nambiguous nature of its actuations that makes it challenging to extract\ndiscriminant features from the lip movement videos. In this paper, we propose a\nnew method, termed as Lip by Speech (LIBS), of which the goal is to strengthen\nlip reading by learning from speech recognizers. The rationale behind our\napproach is that the features extracted from speech recognizers may provide\ncomplementary and discriminant clues, which are formidable to be obtained from\nthe subtle movements of the lips, and consequently facilitate the training of\nlip readers. This is achieved, specifically, by distilling multi-granularity\nknowledge from speech recognizers to lip readers. To conduct this cross-modal\nknowledge distillation, we utilize an efficacious alignment scheme to handle\nthe inconsistent lengths of the audios and videos, as well as an innovative\nfiltering strategy to refine the speech recognizer's prediction. The proposed\nmethod achieves the new state-of-the-art performance on the CMLR and LRS2\ndatasets, outperforming the baseline by a margin of 7.66% and 2.75% in\ncharacter error rate, respectively.", "published": "2019-11-26 13:05:07", "link": "http://arxiv.org/abs/1911.11502v1", "categories": ["cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A discriminative condition-aware backend for speaker verification", "abstract": "We present a scoring approach for speaker verification that mimics the\nstandard PLDA-based backend process used in most current speaker verification\nsystems. However, unlike the standard backends, all parameters of the model are\njointly trained to optimize the binary cross-entropy for the speaker\nverification task. We further integrate the calibration stage inside the model,\nmaking the parameters of this stage depend on metadata vectors that represent\nthe conditions of the signals. We show that the proposed backend has excellent\nout-of-the-box calibration performance on most of our test sets, making it an\nideal approach for cases in which the test conditions are not known and\ndevelopment data is not available for training a domain-specific calibration\nmodel.", "published": "2019-11-26 15:14:22", "link": "http://arxiv.org/abs/1911.11622v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Convolutional Composer Classification", "abstract": "This paper investigates end-to-end learnable models for attributing composers\nto musical scores. We introduce several pooled, convolutional architectures for\nthis task and draw connections between our approach and classical learning\napproaches based on global and n-gram features. We evaluate models on a corpus\nof 2,500 scores from the KernScores collection, authored by a variety of\ncomposers spanning the Renaissance era to the early 20th century. This corpus\nhas substantial overlap with the corpora used in several previous, smaller\nstudies; we compare our results on subsets of the corpus to these previous\nworks.", "published": "2019-11-26 18:17:14", "link": "http://arxiv.org/abs/1911.11737v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Improving Polyphonic Music Models with Feature-Rich Encoding", "abstract": "This paper explores sequential modelling of polyphonic music with deep neural\nnetworks. While recent breakthroughs have focussed on network architecture, we\ndemonstrate that the representation of the sequence can make an equally\nsignificant contribution to the performance of the model as measured by\nvalidation set loss. By extracting salient features inherent to the training\ndataset, the model can either be conditioned on these features or trained to\npredict said features as extra components of the sequences being modelled. We\nshow that training a neural network to predict a seemingly more complex\nsequence, with extra features included in the series being modelled, can\nimprove overall model performance significantly. We first introduce TonicNet, a\nGRU-based model trained to initially predict the chord at a given time-step\nbefore then predicting the notes of each voice at that time-step, in contrast\nwith the typical approach of predicting only the notes. We then evaluate\nTonicNet on the canonical JSB Chorales dataset and obtain state-of-the-art\nresults.", "published": "2019-11-26 18:38:30", "link": "http://arxiv.org/abs/1911.11775v3", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML", "68T99"], "primary_category": "cs.SD"}
{"title": "Schr\u00f6dingeRNN: Generative Modeling of Raw Audio as a Continuously\n  Observed Quantum State", "abstract": "We introduce Schr\\\"odingeRNN, a quantum inspired generative model for raw\naudio. Audio data is wave-like and is sampled from a continuous signal.\nAlthough generative modelling of raw audio has made great strides lately,\nrelational inductive biases relevant to these two characteristics are mostly\nabsent from models explored to date. Quantum Mechanics is a natural source of\nprobabilistic models of wave behaviour. Our model takes the form of a\nstochastic Schr\\\"odinger equation describing the continuous time measurement of\na quantum system, and is equivalent to the continuous Matrix Product State\n(cMPS) representation of wavefunctions in one dimensional many-body systems.\nThis constitutes a deep autoregressive architecture in which the systems state\nis a latent representation of the past observations. We test our model on\nsynthetic data sets of stationary and non-stationary signals. This is the first\ntime cMPS are used in machine learning.", "published": "2019-11-26 23:33:46", "link": "http://arxiv.org/abs/1911.11879v1", "categories": ["cs.SD", "cond-mat.stat-mech", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
