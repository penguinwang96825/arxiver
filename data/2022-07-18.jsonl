{"title": "Classifying COVID-19 vaccine narratives", "abstract": "Vaccine hesitancy is widespread, despite the government's information\ncampaigns and the efforts of the World Health Organisation (WHO). Categorising\nthe topics within vaccine-related narratives is crucial to understand the\nconcerns expressed in discussions and identify the specific issues that\ncontribute to vaccine hesitancy. This paper addresses the need for monitoring\nand analysing vaccine narratives online by introducing a novel vaccine\nnarrative classification task, which categorises COVID-19 vaccine claims into\none of seven categories. Following a data augmentation approach, we first\nconstruct a novel dataset for this new classification task, focusing on the\nminority classes. We also make use of fact-checker annotated data. The paper\nalso presents a neural vaccine narrative classifier that achieves an accuracy\nof 84% under cross-validation. The classifier is publicly available for\nresearchers and journalists.", "published": "2022-07-18 11:37:47", "link": "http://arxiv.org/abs/2207.08522v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAD for Robust Reinforcement Learning in Machine Translation", "abstract": "We introduce a new distributed policy gradient algorithm and show that it\noutperforms existing reward-aware training procedures such as REINFORCE,\nminimum risk training (MRT) and proximal policy optimization (PPO) in terms of\ntraining stability and generalization performance when optimizing machine\ntranslation models. Our algorithm, which we call MAD (on account of using the\nmean absolute deviation in the importance weighting calculation), has\ndistributed data generators sampling multiple candidates per source sentence on\nworker nodes, while a central learner updates the policy. MAD depends crucially\non two variance reduction strategies: (1) a conditional reward normalization\nmethod that ensures each source sentence has both positive and negative reward\ntranslation examples and (2) a new robust importance weighting scheme that acts\nas a conditional entropy regularizer. Experiments on a variety of translation\ntasks show that policies learned using the MAD algorithm perform very well when\nusing both greedy decoding and beam search, and that the learned policies are\nsensitive to the specific reward used during training.", "published": "2022-07-18 13:20:22", "link": "http://arxiv.org/abs/2207.08583v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "STT: Soft Template Tuning for Few-Shot Adaptation", "abstract": "Prompt tuning has been an extremely effective tool to adapt a pre-trained\nmodel to downstream tasks. However, standard prompt-based methods mainly\nconsider the case of sufficient data of downstream tasks. It is still unclear\nwhether the advantage can be transferred to the few-shot regime, where only\nlimited data are available for each downstream task. Although some works have\ndemonstrated the potential of prompt-tuning under the few-shot setting, the\nmain stream methods via searching discrete prompts or tuning soft prompts with\nlimited data are still very challenging. Through extensive empirical studies,\nwe find that there is still a gap between prompt tuning and fully fine-tuning\nfor few-shot learning. To bridge the gap, we propose a new prompt-tuning\nframework, called Soft Template Tuning (STT). STT combines manual and auto\nprompts, and treats downstream classification tasks as a masked language\nmodeling task. Comprehensive evaluation on different settings suggests STT can\nclose the gap between fine-tuning and prompt-based methods without introducing\nadditional parameters. Significantly, it can even outperform the time- and\nresource-consuming fine-tuning method on sentiment classification tasks.", "published": "2022-07-18 07:07:22", "link": "http://arxiv.org/abs/2207.08408v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Automated Classification of Attackers' TTPs by combining NLP\n  with ML Techniques", "abstract": "The increasingly sophisticated and growing number of threat actors along with\nthe sheer speed at which cyber attacks unfold, make timely identification of\nattacks imperative to an organisations' security. Consequently, persons\nresponsible for security employ a large variety of information sources\nconcerning emerging attacks, attackers' course of actions or indicators of\ncompromise. However, a vast amount of the needed security information is\navailable in unstructured textual form, which complicates the automated and\ntimely extraction of attackers' Tactics, Techniques and Procedures (TTPs). In\norder to address this problem we systematically evaluate and compare different\nNatural Language Processing (NLP) and machine learning techniques used for\nsecurity information extraction in research. Based on our investigations we\npropose a data processing pipeline that automatically classifies unstructured\ntext according to attackers' tactics and techniques derived from a knowledge\nbase of adversary tactics, techniques and procedures.", "published": "2022-07-18 09:59:21", "link": "http://arxiv.org/abs/2207.08478v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "AlexU-AIC at Arabic Hate Speech 2022: Contrast to Classify", "abstract": "Online presence on social media platforms such as Facebook and Twitter has\nbecome a daily habit for internet users. Despite the vast amount of services\nthe platforms offer for their users, users suffer from cyber-bullying, which\nfurther leads to mental abuse and may escalate to cause physical harm to\nindividuals or targeted groups. In this paper, we present our submission to the\nArabic Hate Speech 2022 Shared Task Workshop (OSACT5 2022) using the associated\nArabic Twitter dataset. The shared task consists of 3 sub-tasks, sub-task A\nfocuses on detecting whether the tweet is offensive or not. Then, For offensive\nTweets, sub-task B focuses on detecting whether the tweet is hate speech or\nnot. Finally, For hate speech Tweets, sub-task C focuses on detecting the\nfine-grained type of hate speech among six different classes. Transformer\nmodels proved their efficiency in classification tasks, but with the problem of\nover-fitting when fine-tuned on a small or an imbalanced dataset. We overcome\nthis limitation by investigating multiple training paradigms such as\nContrastive learning and Multi-task learning along with Classification\nfine-tuning and an ensemble of our top 5 performers. Our proposed solution\nachieved 0.841, 0.817, and 0.476 macro F1-average in sub-tasks A, B, and C\nrespectively.", "published": "2022-07-18 12:33:51", "link": "http://arxiv.org/abs/2207.08557v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GOAL: Towards Benchmarking Few-Shot Sports Game Summarization", "abstract": "Sports game summarization aims to generate sports news based on real-time\ncommentaries. The task has attracted wide research attention but is still\nunder-explored probably due to the lack of corresponding English datasets.\nTherefore, in this paper, we release GOAL, the first English sports game\nsummarization dataset. Specifically, there are 103 commentary-news pairs in\nGOAL, where the average lengths of commentaries and news are 2724.9 and 476.3\nwords, respectively. Moreover, to support the research in the semi-supervised\nsetting, GOAL additionally provides 2,160 unlabeled commentary documents. Based\non our GOAL, we build and evaluate several baselines, including extractive and\nabstractive baselines. The experimental results show the challenges of this\ntask still remain. We hope our work could promote the research of sports game\nsummarization. The dataset has been released at\nhttps://github.com/krystalan/goal.", "published": "2022-07-18 14:29:18", "link": "http://arxiv.org/abs/2207.08635v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MRCLens: an MRC Dataset Bias Detection Toolkit", "abstract": "Many recent neural models have shown remarkable empirical results in Machine\nReading Comprehension, but evidence suggests sometimes the models take\nadvantage of dataset biases to predict and fail to generalize on out-of-sample\ndata. While many other approaches have been proposed to address this issue from\nthe computation perspective such as new architectures or training procedures,\nwe believe a method that allows researchers to discover biases, and adjust the\ndata or the models in an earlier stage will be beneficial. Thus, we introduce\nMRCLens, a toolkit that detects whether biases exist before users train the\nfull model. For the convenience of introducing the toolkit, we also provide a\ncategorization of common biases in MRC.", "published": "2022-07-18 21:05:39", "link": "http://arxiv.org/abs/2207.08943v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Selection Bias Induced Spurious Correlations in Large Language Models", "abstract": "In this work we show how large language models (LLMs) can learn statistical\ndependencies between otherwise unconditionally independent variables due to\ndataset selection bias. To demonstrate the effect, we developed a masked gender\ntask that can be applied to BERT-family models to reveal spurious correlations\nbetween predicted gender pronouns and a variety of seemingly gender-neutral\nvariables like date and location, on pre-trained (unmodified) BERT and RoBERTa\nlarge models. Finally, we provide an online demo, inviting readers to\nexperiment further.", "published": "2022-07-18 23:43:52", "link": "http://arxiv.org/abs/2207.08982v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DHGE: Dual-View Hyper-Relational Knowledge Graph Embedding for Link\n  Prediction and Entity Typing", "abstract": "In the field of representation learning on knowledge graphs (KGs), a\nhyper-relational fact consists of a main triple and several auxiliary\nattribute-value descriptions, which is considered more comprehensive and\nspecific than a triple-based fact. However, currently available\nhyper-relational KG embedding methods in a single view are limited in\napplication because they weaken the hierarchical structure that represents the\naffiliation between entities. To overcome this limitation, we propose a\ndual-view hyper-relational KG structure (DH-KG) that contains a\nhyper-relational instance view for entities and a hyper-relational ontology\nview for concepts that are abstracted hierarchically from the entities. This\npaper defines link prediction and entity typing tasks on DH-KG for the first\ntime and constructs two DH-KG datasets, JW44K-6K, extracted from Wikidata, and\nHTDM based on medical data. Furthermore, we propose DHGE, a DH-KG embedding\nmodel based on GRAN encoders, HGNNs, and joint learning. DHGE outperforms\nbaseline models on DH-KG, according to experimental results. Finally, we\nprovide an example of how this technology can be used to treat hypertension.\nOur model and new datasets are publicly available.", "published": "2022-07-18 12:44:59", "link": "http://arxiv.org/abs/2207.08562v4", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Rethinking Data Augmentation for Robust Visual Question Answering", "abstract": "Data Augmentation (DA) -- generating extra training samples beyond original\ntraining set -- has been widely-used in today's unbiased VQA models to mitigate\nthe language biases. Current mainstream DA strategies are synthetic-based\nmethods, which synthesize new samples by either editing some visual\nregions/words, or re-generating them from scratch. However, these synthetic\nsamples are always unnatural and error-prone. To avoid this issue, a recent DA\nwork composes new augmented samples by randomly pairing pristine images and\nother human-written questions. Unfortunately, to guarantee augmented samples\nhave reasonable ground-truth answers, they manually design a set of heuristic\nrules for several question types, which extremely limits its generalization\nabilities. To this end, we propose a new Knowledge Distillation based Data\nAugmentation for VQA, dubbed KDDAug. Specifically, we first relax the\nrequirements of reasonable image-question pairs, which can be easily applied to\nany question types. Then, we design a knowledge distillation (KD) based answer\nassignment to generate pseudo answers for all composed image-question pairs,\nwhich are robust to both in-domain and out-of-distribution settings. Since\nKDDAug is a model-agnostic DA strategy, it can be seamlessly incorporated into\nany VQA architectures. Extensive ablation studies on multiple backbones and\nbenchmarks have demonstrated the effectiveness and generalization abilities of\nKDDAug.", "published": "2022-07-18 16:30:50", "link": "http://arxiv.org/abs/2207.08739v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Using attention methods to predict judicial outcomes", "abstract": "Legal Judgment Prediction is one of the most acclaimed fields for the\ncombined area of NLP, AI, and Law. By legal prediction we mean an intelligent\nsystems capable to predict specific judicial characteristics, such as judicial\noutcome, a judicial class, predict an specific case. In this research, we have\nused AI classifiers to predict judicial outcomes in the Brazilian legal system.\nFor this purpose, we developed a text crawler to extract data from the official\nBrazilian electronic legal systems. These texts formed a dataset of\nsecond-degree murder and active corruption cases. We applied different\nclassifiers, such as Support Vector Machines and Neural Networks, to predict\njudicial outcomes by analyzing textual features from the dataset. Our research\nshowed that Regression Trees, Gated Recurring Units and Hierarchical Attention\nNetworks presented higher metrics for different subsets. As a final goal, we\nexplored the weights of one of the algorithms, the Hierarchical Attention\nNetworks, to find a sample of the most important words used to absolve or\nconvict defendants.", "published": "2022-07-18 16:24:34", "link": "http://arxiv.org/abs/2207.08823v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "68T50", "I.2.7; J.5"], "primary_category": "cs.LG"}
{"title": "Deep Sequence Models for Text Classification Tasks", "abstract": "The exponential growth of data generated on the Internet in the current\ninformation age is a driving force for the digital economy. Extraction of\ninformation is the major value in an accumulated big data. Big data dependency\non statistical analysis and hand-engineered rules machine learning algorithms\nare overwhelmed with vast complexities inherent in human languages. Natural\nLanguage Processing (NLP) is equipping machines to understand these human\ndiverse and complicated languages. Text Classification is an NLP task which\nautomatically identifies patterns based on predefined or undefined labeled\nsets. Common text classification application includes information retrieval,\nmodeling news topic, theme extraction, sentiment analysis, and spam detection.\nIn texts, some sequences of words depend on the previous or next word sequences\nto make full meaning; this is a challenging dependency task that requires the\nmachine to be able to store some previous important information to impact\nfuture meaning. Sequence models such as RNN, GRU, and LSTM is a breakthrough\nfor tasks with long-range dependencies. As such, we applied these models to\nBinary and Multi-class classification. Results generated were excellent with\nmost of the models performing within the range of 80% and 94%. However, this\nresult is not exhaustive as we believe there is room for improvement if\nmachines are to compete with humans.", "published": "2022-07-18 18:47:18", "link": "http://arxiv.org/abs/2207.08880v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Training Large-Vocabulary Neural Language Models by Private Federated\n  Learning for Resource-Constrained Devices", "abstract": "Federated Learning (FL) is a technique to train models using data distributed\nacross devices. Differential Privacy (DP) provides a formal privacy guarantee\nfor sensitive data. Our goal is to train a large neural network language model\n(NNLM) on compute-constrained devices while preserving privacy using FL and DP.\nHowever, the DP-noise introduced to the model increases as the model size\ngrows, which often prevents convergence. We propose Partial Embedding Updates\n(PEU), a novel technique to decrease noise by decreasing payload size.\nFurthermore, we adopt Low Rank Adaptation (LoRA) and Noise Contrastive\nEstimation (NCE) to reduce the memory demands of large models on\ncompute-constrained devices. This combination of techniques makes it possible\nto train large-vocabulary language models while preserving accuracy and\nprivacy.", "published": "2022-07-18 23:53:17", "link": "http://arxiv.org/abs/2207.08988v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "CTL-MTNet: A Novel CapsNet and Transfer Learning-Based Mixed Task Net\n  for the Single-Corpus and Cross-Corpus Speech Emotion Recognition", "abstract": "Speech Emotion Recognition (SER) has become a growing focus of research in\nhuman-computer interaction. An essential challenge in SER is to extract common\nattributes from different speakers or languages, especially when a specific\nsource corpus has to be trained to recognize the unknown data coming from\nanother speech corpus. To address this challenge, a Capsule Network (CapsNet)\nand Transfer Learning based Mixed Task Net (CTLMTNet) are proposed to deal with\nboth the singlecorpus and cross-corpus SER tasks simultaneously in this paper.\nFor the single-corpus task, the combination of Convolution-Pooling and\nAttention CapsNet module CPAC) is designed by embedding the self-attention\nmechanism to the CapsNet, guiding the module to focus on the important features\nthat can be fed into different capsules. The extracted high-level features by\nCPAC provide sufficient discriminative ability. Furthermore, to handle the\ncross-corpus task, CTL-MTNet employs a Corpus Adaptation Adversarial Module\n(CAAM) by combining CPAC with Margin Disparity Discrepancy (MDD), which can\nlearn the domain-invariant emotion representations through extracting the\nstrong emotion commonness. Experiments including ablation studies and\nvisualizations on both singleand cross-corpus tasks using four well-known SER\ndatasets in different languages are conducted for performance evaluation and\ncomparison. The results indicate that in both tasks the CTL-MTNet showed better\nperformance in all cases compared to a number of state-of-the-art methods. The\nsource code and the supplementary materials are available at:\nhttps://github.com/MLDMXM2017/CTLMTNet", "published": "2022-07-18 09:09:23", "link": "http://arxiv.org/abs/2207.10644v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Human Brains Can't Detect Fake News: A Neuro-Cognitive Study of Textual\n  Disinformation Susceptibility", "abstract": "The spread of digital disinformation (aka \"fake news\") is arguably one of the\nmost significant threats on the Internet which can cause individual and\nsocietal harm of large scales. The susceptibility to fake news attacks hinges\non whether Internet users perceive a fake news article/snippet to be legitimate\nafter reading it. In this paper, we attempt to garner an in-depth understanding\nof users' susceptibility to text-centric fake news attacks via a\nneuro-cognitive methodology. We investigate the neural underpinnings relevant\nto fake/real news through EEG. We run an experiment with human users to pursue\na thorough investigation of users' perception and cognitive processing of\nfake/real news. We analyze the neural activity associated with the fake/real\nnews detection task for different categories of news articles. Our results show\nthere may be no statistically significant or automatically inferable\ndifferences in the way the human brain processes the fake vs. real news, while\nmarked differences are observed when people are subject to (real/fake) news vs.\nresting state and even between some different categories of fake news. This\nneuro-cognitive finding may help to justify users' susceptibility to fake news\nattacks, as also confirmed from the behavioral analysis. In other words, the\nfake news articles may seem almost indistinguishable from the real news\narticles in both behavioral and neural domains. Our work serves to dissect the\nfundamental neural phenomena underlying fake news attacks and explains users'\nsusceptibility to these attacks through the limits of human biology. We believe\nthis could be a notable insight for the researchers and practitioners\nsuggesting the human detection of fake news might be ineffective, which may\nalso have an adverse impact on the design of automated detection approaches\nthat crucially rely upon human labeling of text articles for building training\nmodels", "published": "2022-07-18 04:31:07", "link": "http://arxiv.org/abs/2207.08376v1", "categories": ["cs.CL", "cs.CR", "cs.CY", "cs.HC", "cs.SI"], "primary_category": "cs.CL"}
{"title": "The Vocal Signature of Social Anxiety: Exploration using\n  Hypothesis-Testing and Machine-Learning Approaches", "abstract": "Background - Social anxiety (SA) is a common and debilitating condition,\nnegatively affecting life quality even at sub-diagnostic thresholds. We sought\nto characterize SA's acoustic signature using hypothesis-testing and machine\nlearning (ML) approaches. Methods - Participants formed spontaneous utterances\nresponding to instructions to refuse or consent to commands of alleged peers.\nVocal properties (e.g., intensity and duration) of these utterances were\nanalyzed. Results - Our prediction that, as compared to low-SA (n=31), high-SA\n(n=32) individuals exhibit a less confident vocal speech signature, especially\nwith respect to refusal utterances, was only partially supported by the\nclassical hypothesis-testing approach. However, the results of the ML analyses\nand specifically the decision tree classifier were consistent with such speech\npatterns in SA. Using a Gaussian Process (GP) classifier, we were able to\ndistinguish between high- and low-SA individuals with high (75.6%) accuracy and\ngood (.83 AUC) separability. We also expected and found that vocal properties\ndifferentiated between refusal and consent utterances. Conclusions - Our\nfindings provide further support for the usefulness of ML approach for the\nstudy of psychopathology, highlighting the utility of developing automatic\ntechniques to create behavioral markers of SAD. Clinically, the simplicity and\naccessibility of these procedures may encourage people to seek professional\nhelp.", "published": "2022-07-18 11:55:38", "link": "http://arxiv.org/abs/2207.08534v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Style Transfer of Audio Effects with Differentiable Signal Processing", "abstract": "We present a framework that can impose the audio effects and production style\nfrom one recording to another by example with the goal of simplifying the audio\nproduction process. We train a deep neural network to analyze an input\nrecording and a style reference recording, and predict the control parameters\nof audio effects used to render the output. In contrast to past work, we\nintegrate audio effects as differentiable operators in our framework, perform\nbackpropagation through audio effects, and optimize end-to-end using an\naudio-domain loss. We use a self-supervised training strategy enabling\nautomatic control of audio effects without the use of any labeled or paired\ntraining data. We survey a range of existing and new approaches for\ndifferentiable signal processing, showing how each can be integrated into our\nframework while discussing their trade-offs. We evaluate our approach on both\nspeech and music tasks, demonstrating that our approach generalizes both to\nunseen recordings and even to sample rates different than those seen during\ntraining. Our approach produces convincing production style transfer results\nwith the ability to transform input recordings to produced recordings, yielding\naudio effect control parameters that enable interpretability and user\ninteraction.", "published": "2022-07-18 17:06:19", "link": "http://arxiv.org/abs/2207.08759v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Latent-Domain Predictive Neural Speech Coding", "abstract": "Neural audio/speech coding has recently demonstrated its capability to\ndeliver high quality at much lower bitrates than traditional methods. However,\nexisting neural audio/speech codecs employ either acoustic features or learned\nblind features with a convolutional neural network for encoding, by which there\nare still temporal redundancies within encoded features. This paper introduces\nlatent-domain predictive coding into the VQ-VAE framework to fully remove such\nredundancies and proposes the TF-Codec for low-latency neural speech coding in\nan end-to-end manner. Specifically, the extracted features are encoded\nconditioned on a prediction from past quantized latent frames so that temporal\ncorrelations are further removed. Moreover, we introduce a learnable\ncompression on the time-frequency input to adaptively adjust the attention paid\nto main frequencies and details at different bitrates. A differentiable vector\nquantization scheme based on distance-to-soft mapping and Gumbel-Softmax is\nproposed to better model the latent distributions with rate constraint.\nSubjective results on multilingual speech datasets show that, with low latency,\nthe proposed TF-Codec at 1 kbps achieves significantly better quality than Opus\nat 9 kbps, and TF-Codec at 3 kbps outperforms both EVS at 9.6 kbps and Opus at\n12 kbps. Numerous studies are conducted to demonstrate the effectiveness of\nthese techniques.", "published": "2022-07-18 03:18:08", "link": "http://arxiv.org/abs/2207.08363v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Contrastive Environmental Sound Representation Learning", "abstract": "Machine hearing of the environmental sound is one of the important issues in\nthe audio recognition domain. It gives the machine the ability to discriminate\nbetween the different input sounds that guides its decision making. In this\nwork we exploit the self-supervised contrastive technique and a shallow 1D CNN\nto extract the distinctive audio features (audio representations) without using\nany explicit annotations.We generate representations of a given audio using\nboth its raw audio waveform and spectrogram and evaluate if the proposed\nlearner is agnostic to the type of audio input. We further use canonical\ncorrelation analysis (CCA) to fuse representations from the two types of input\nof a given audio and demonstrate that the fused global feature results in\nrobust representation of the audio signal as compared to the individual\nrepresentations. The evaluation of the proposed technique is done on both\nESC-50 and UrbanSound8K. The results show that the proposed technique is able\nto extract most features of the environmental audio and gives an improvement of\n12.8% and 0.9% on the ESC-50 and UrbanSound8K datasets respectively.", "published": "2022-07-18 16:56:30", "link": "http://arxiv.org/abs/2207.08825v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio Input Generates Continuous Frames to Synthesize Facial Video Using\n  Generative Adiversarial Networks", "abstract": "This paper presents a simple method for speech videos generation based on\naudio: given a piece of audio, we can generate a video of the target face\nspeaking this audio. We propose Generative Adversarial Networks (GAN) with cut\nspeech audio input as condition and use Convolutional Gate Recurrent Unit (GRU)\nin generator and discriminator. Our model is trained by exploiting the short\naudio and the frames in this duration. For training, we cut the audio and\nextract the face in the corresponding frames. We designed a simple encoder and\ncompare the generated frames using GAN with and without GRU. We use GRU for\ntemporally coherent frames and the results show that short audio can produce\nrelatively realistic output results.", "published": "2022-07-18 03:25:56", "link": "http://arxiv.org/abs/2207.08813v1", "categories": ["cs.SD", "cs.CV", "cs.GR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
