{"title": "Silent Hazards of Token Reduction in Vision-Language Models: The Hidden Impact on Consistency", "abstract": "Vision language models (VLMs) have excelled in visual reasoning but often\nincur high computational costs. One key reason is the redundancy of visual\ntokens. Although recent token reduction methods claim to achieve minimal\nperformance loss, our extensive experiments reveal that token reduction can\nsubstantially alter a model's output distribution, leading to changes in\nprediction patterns that standard metrics such as accuracy loss do not fully\ncapture. Such inconsistencies are especially concerning for practical\napplications where system stability is critical. To investigate this\nphenomenon, we analyze how token reduction influences the energy distribution\nof a VLM's internal representations using a lower-rank approximation via\nSingular Value Decomposition (SVD). Our results show that changes in the\nInverse Participation Ratio of the singular value spectrum are strongly\ncorrelated with the model's consistency after token reduction. Based on these\ninsights, we propose LoFi--a training-free visual token reduction method that\nutilizes the leverage score from SVD for token pruning. Experimental\nevaluations demonstrate that LoFi not only reduces computational costs with\nminimal performance degradation but also significantly outperforms\nstate-of-the-art methods in terms of output consistency.", "published": "2025-03-09 22:16:48", "link": "http://arxiv.org/abs/2503.06794v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "On the Mutual Influence of Gender and Occupation in LLM Representations", "abstract": "We examine LLM representations of gender for first names in various\noccupational contexts to study how occupations and the gender perception of\nfirst names in LLMs influence each other mutually. We find that LLMs'\nfirst-name gender representations correlate with real-world gender statistics\nassociated with the name, and are influenced by the co-occurrence of\nstereotypically feminine or masculine occupations. Additionally, we study the\ninfluence of first-name gender representations on LLMs in a downstream\noccupation prediction task and their potential as an internal metric to\nidentify extrinsic model biases. While feminine first-name embeddings often\nraise the probabilities for female-dominated jobs (and vice versa for\nmale-dominated jobs), reliably using these internal gender representations for\nbias detection remains challenging.", "published": "2025-03-09 22:11:30", "link": "http://arxiv.org/abs/2503.06792v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dr Genre: Reinforcement Learning from Decoupled LLM Feedback for Generic Text Rewriting", "abstract": "Generic text rewriting is a prevalent large language model (LLM) application\nthat covers diverse real-world tasks, such as style transfer, fact correction,\nand email editing. These tasks vary in rewriting objectives (e.g., factual\nconsistency vs. semantic preservation), making it challenging to develop a\nunified model that excels across all dimensions. Existing methods often\nspecialize in either a single task or a specific objective, limiting their\ngeneralizability. In this work, we introduce a generic model proficient in\nfactuality, stylistic, and conversational rewriting tasks. To simulate\nreal-world user rewrite requests, we construct a conversational rewrite\ndataset, ChatRewrite, that presents ``natural''-sounding instructions, from raw\nemails using LLMs. Combined with other popular rewrite datasets, including\nLongFact for the factuality rewrite task and RewriteLM for the stylistic\nrewrite task, this forms a broad benchmark for training and evaluating generic\nrewrite models. To align with task-specific objectives, we propose Dr Genre, a\nDecoupled-reward learning framework for Generic rewriting, that utilizes\nobjective-oriented reward models with a task-specific weighting. Evaluation\nshows that \\approach delivers higher-quality rewrites across all targeted\ntasks, improving objectives including instruction following (agreement),\ninternal consistency (coherence), and minimal unnecessary edits (conciseness).", "published": "2025-03-09 21:23:52", "link": "http://arxiv.org/abs/2503.06781v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Effective Human Annotation Assistants, But Not Good Independent Annotators", "abstract": "Event annotation is important for identifying market changes, monitoring\nbreaking news, and understanding sociological trends. Although expert\nannotators set the gold standards, human coding is expensive and inefficient.\nUnlike information extraction experiments that focus on single contexts, we\nevaluate a holistic workflow that removes irrelevant documents, merges\ndocuments about the same event, and annotates the events. Although LLM-based\nautomated annotations are better than traditional TF-IDF-based methods or Event\nSet Curation, they are still not reliable annotators compared to human experts.\nHowever, adding LLMs to assist experts for Event Set Curation can reduce the\ntime and mental effort required for Variable Annotation. When using LLMs to\nextract event variables to assist expert annotators, they agree more with the\nextracted variables than fully automated LLMs for annotation.", "published": "2025-03-09 21:14:14", "link": "http://arxiv.org/abs/2503.06778v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Effectiveness of Zero-shot-CoT in Japanese Prompts", "abstract": "We compare the effectiveness of zero-shot Chain-of-Thought (CoT) prompting in\nJapanese and English using ChatGPT-3.5 and 4o-mini. The technique of zero-shot\nCoT, which involves appending a phrase such as \"Let's think step by step\" to a\nprompt to encourage reasoning before answering, has been shown to offer LLM\nperformance improvements in mathematical and reasoning tasks, particularly in\nEnglish. We investigate how these effects transfer to Japanese using the\nJapanese Multi-task Language Understanding Benchmark (JMMLU) and the Multi-task\nLanguage Understanding Benchmark (MMLU). Our results show that while zero-shot\nCoT prompting can lead to notable performance gains for some prompt categories\nin GPT-3.5, its impact in GPT-4o-mini is associated with significant\nperformance declines. However, for Japanese prompts there remain certain\ncategories, such as college mathematics and abstract algebra, that still\nexhibit improvements, despite the broader trend of diminishing effectiveness in\nmore advanced models.", "published": "2025-03-09 20:42:38", "link": "http://arxiv.org/abs/2503.06765v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models", "abstract": "DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning\ncapabilities in LLMs purely through Reinforcement Learning (RL). Inspired by\nthis breakthrough, we explore how RL can be utilized to enhance the reasoning\ncapability of MLLMs. However, direct training with RL struggles to activate\ncomplex reasoning capabilities such as questioning and reflection in MLLMs, due\nto the absence of substantial high-quality multimodal reasoning data. To\naddress this issue, we propose the reasoning MLLM, Vision-R1, to improve\nmultimodal reasoning capability. Specifically, we first construct a\nhigh-quality multimodal CoT dataset without human annotations by leveraging an\nexisting MLLM and DeepSeek-R1 through modality bridging and data filtering to\nobtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as\ncold-start initialization data for Vision-R1. To mitigate the optimization\nchallenges caused by overthinking after cold start, we propose Progressive\nThinking Suppression Training (PTST) strategy and employ Group Relative Policy\nOptimization (GRPO) with the hard formatting result reward function to\ngradually refine the model's ability to learn correct and complex reasoning\nprocesses on a 10K multimodal math dataset. Comprehensive experiments show our\nmodel achieves an average improvement of $\\sim$6% across various multimodal\nmath reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely\nused MathVista benchmark, which is only 0.4% lower than the leading reasoning\nmodel, OpenAI O1. The datasets and code will be released in:\nhttps://github.com/Osilly/Vision-R1 .", "published": "2025-03-09 20:06:45", "link": "http://arxiv.org/abs/2503.06749v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Green Prompting", "abstract": "Large Language Models (LLMs) have become widely used across various domains\nspanning search engines, code generation, and text creation. However, a major\nconcern associated with their adoption is the high cost of inference, impacting\nboth their sustainability and financial feasibility. In this study, we\nempirically study how different prompt and response characteristics directly\nimpact LLM inference energy cost. We conduct experiments leveraging three\nopen-source transformer-based LLMs across three task types$-$question\nanswering, sentiment analysis, and text generation. For each inference, we\nanalyzed prompt and response characteristics (length, semantic meaning, time\ntaken, energy consumption). Our results demonstrate that even when presented\nwith identical tasks, models generate responses with varying characteristics\nand subsequently exhibit distinct energy consumption patterns. We found that\nprompt length is less significant than the semantic meaning of the task itself.\nIn addition, we identified specific keywords associated with higher or lower\nenergy usage that vary between associated tasks. These findings highlight the\nimportance of prompt design in optimizing inference efficiency. We conclude\nthat the semantic meaning of prompts and certain task-related keywords\nsignificantly impact inference costs, leading the way for deeper exploration\ntowards creating energy-adaptive LLMs.", "published": "2025-03-09 19:49:31", "link": "http://arxiv.org/abs/2503.10666v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Gender Encoding Patterns in Pretrained Language Model Representations", "abstract": "Gender bias in pretrained language models (PLMs) poses significant social and\nethical challenges. Despite growing awareness, there is a lack of comprehensive\ninvestigation into how different models internally represent and propagate such\nbiases. This study adopts an information-theoretic approach to analyze how\ngender biases are encoded within various encoder-based architectures. We focus\non three key aspects: identifying how models encode gender information and\nbiases, examining the impact of bias mitigation techniques and fine-tuning on\nthe encoded biases and their effectiveness, and exploring how model design\ndifferences influence the encoding of biases. Through rigorous and systematic\ninvestigation, our findings reveal a consistent pattern of gender encoding\nacross diverse models. Surprisingly, debiasing techniques often exhibit limited\nefficacy, sometimes inadvertently increasing the encoded bias in internal\nrepresentations while reducing bias in model output distributions. This\nhighlights a disconnect between mitigating bias in output distributions and\naddressing its internal representations. This work provides valuable guidance\nfor advancing bias mitigation strategies and fostering the development of more\nequitable language models.", "published": "2025-03-09 19:17:46", "link": "http://arxiv.org/abs/2503.06734v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Topology of Syntax Networks across Languages", "abstract": "Syntax connects words to each other in very specific ways. Two words are\nsyntactically connected if they depend\n  directly on each other. Syntactic connections usually happen within a\nsentence. Gathering all those connection\n  across several sentences gives birth to syntax networks. Earlier studies in\nthe field have analysed the structure and\n  properties of syntax networks trying to find clusters/phylogenies of\nlanguages that share similar network features.\n  The results obtained in those studies will be put to test in this thesis by\nincreasing both the number of languages\n  and the number of properties considered in the analysis. Besides that,\nlanguage networks of particular languages\n  will be inspected in depth by means of a novel network analysis [25]. Words\n(nodes of the network) will be clustered\n  into topological communities whose members share similar features. The\nproperties of each of these communities\n  will be thoroughly studied along with the Part of Speech (grammatical class)\nof each word. Results across different\n  languages will also be compared in an attempt to discover universally\npreserved structural patterns across syntax\n  networks.", "published": "2025-03-09 18:47:17", "link": "http://arxiv.org/abs/2503.06724v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Delusions of Large Language Models", "abstract": "Large Language Models often generate factually incorrect but plausible\noutputs, known as hallucinations. We identify a more insidious phenomenon, LLM\ndelusion, defined as high belief hallucinations, incorrect outputs with\nabnormally high confidence, making them harder to detect and mitigate. Unlike\nordinary hallucinations, delusions persist with low uncertainty, posing\nsignificant challenges to model reliability. Through empirical analysis across\ndifferent model families and sizes on several Question Answering tasks, we show\nthat delusions are prevalent and distinct from hallucinations. LLMs exhibit\nlower honesty with delusions, which are harder to override via finetuning or\nself reflection. We link delusion formation with training dynamics and dataset\nnoise and explore mitigation strategies such as retrieval augmented generation\nand multi agent debating to mitigate delusions. By systematically investigating\nthe nature, prevalence, and mitigation of LLM delusions, our study provides\ninsights into the underlying causes of this phenomenon and outlines future\ndirections for improving model reliability.", "published": "2025-03-09 17:59:16", "link": "http://arxiv.org/abs/2503.06709v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Alignment for Efficient Tool Calling of Large Language Models", "abstract": "Recent advancements in tool learning have enabled large language models\n(LLMs) to integrate external tools, enhancing their task performance by\nexpanding their knowledge boundaries. However, relying on tools often\nintroduces tradeoffs between performance, speed, and cost, with LLMs sometimes\nexhibiting overreliance and overconfidence in tool usage. This paper addresses\nthe challenge of aligning LLMs with their knowledge boundaries to make more\nintelligent decisions about tool invocation. We propose a multi objective\nalignment framework that combines probabilistic knowledge boundary estimation\nwith dynamic decision making, allowing LLMs to better assess when to invoke\ntools based on their confidence. Our framework includes two methods for\nknowledge boundary estimation, consistency based and absolute estimation, and\ntwo training strategies for integrating these estimates into the model decision\nmaking process. Experimental results on various tool invocation scenarios\ndemonstrate the effectiveness of our framework, showing significant\nimprovements in tool efficiency by reducing unnecessary tool usage.", "published": "2025-03-09 17:55:49", "link": "http://arxiv.org/abs/2503.06708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts", "abstract": "Process-driven dialogue systems, which operate under strict predefined\nprocess constraints, are essential in customer service and equipment\nmaintenance scenarios. Although Large Language Models (LLMs) have shown\nremarkable progress in dialogue and reasoning, they still struggle to solve\nthese strictly constrained dialogue tasks. To address this challenge, we\nconstruct Process Flow Dialogue (PFDial) dataset, which contains 12,705\nhigh-quality Chinese dialogue instructions derived from 440 flowcharts\ncontaining 5,055 process nodes. Based on PlantUML specification, each UML\nflowchart is converted into atomic dialogue units i.e., structured five-tuples.\nExperimental results demonstrate that a 7B model trained with merely 800\nsamples, and a 0.5B model trained on total data both can surpass 90% accuracy.\nAdditionally, the 8B model can surpass GPT-4o up to 43.88% with an average of\n11.00%. We further evaluate models' performance on challenging backward\ntransitions in process flows and conduct an in-depth analysis of various\ndataset formats to reveal their impact on model performance in handling\ndecision and sequential branches. The data is released in\nhttps://github.com/KongLongGeFDU/PFDial.", "published": "2025-03-09 17:43:30", "link": "http://arxiv.org/abs/2503.06706v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models", "abstract": "Advanced reasoning in large language models has achieved remarkable\nperformance on challenging tasks, but the prevailing long-context reasoning\nparadigm faces critical limitations: quadratic computational scaling with\nsequence length, reasoning constrained by maximum context boundaries, and\nperformance degradation beyond pre-training context windows. Existing\napproaches primarily compress reasoning chains without addressing the\nfundamental scaling problem. To overcome these challenges, we introduce\nInftyThink, a paradigm that transforms monolithic reasoning into an iterative\nprocess with intermediate summarization. By interleaving short reasoning\nsegments with concise progress summaries, our approach enables unbounded\nreasoning depth while maintaining bounded computational costs. This creates a\ncharacteristic sawtooth memory pattern that significantly reduces computational\ncomplexity compared to traditional approaches. Furthermore, we develop a\nmethodology for reconstructing long-context reasoning datasets into our\niterative format, transforming OpenR1-Math into 333K training instances.\nExperiments across multiple model architectures demonstrate that our approach\nreduces computational costs while improving performance, with Qwen2.5-Math-7B\nshowing 3-13% improvements across MATH500, AIME24, and GPQA_diamond benchmarks.\nOur work challenges the assumed trade-off between reasoning depth and\ncomputational efficiency, providing a more scalable approach to complex\nreasoning without architectural modifications.", "published": "2025-03-09 16:59:14", "link": "http://arxiv.org/abs/2503.06692v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DependEval: Benchmarking LLMs for Repository Dependency Understanding", "abstract": "While large language models (LLMs) have shown considerable promise in code\ngeneration, real-world software development demands advanced repository-level\nreasoning. This includes understanding dependencies, project structures, and\nmanaging multi-file changes. However, the ability of LLMs to effectively\ncomprehend and handle complex code repositories has yet to be fully explored.\nTo address challenges, we introduce a hierarchical benchmark designed to\nevaluate repository dependency understanding (DependEval). Benchmark is based\non 15,576 repositories collected from real-world websites. It evaluates models\non three core tasks: Dependency Recognition, Repository Construction, and\nMulti-file Editing, across 8 programming languages from actual code\nrepositories. Our evaluation of over 25 LLMs reveals substantial performance\ngaps and provides valuable insights into repository-level code understanding.", "published": "2025-03-09 16:45:22", "link": "http://arxiv.org/abs/2503.06689v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Small Vision-Language Models: A Survey on Compact Architectures and Techniques", "abstract": "The emergence of small vision-language models (sVLMs) marks a critical\nadvancement in multimodal AI, enabling efficient processing of visual and\ntextual data in resource-constrained environments. This survey offers a\ncomprehensive exploration of sVLM development, presenting a taxonomy of\narchitectures - transformer-based, mamba-based, and hybrid - that highlight\ninnovations in compact design and computational efficiency. Techniques such as\nknowledge distillation, lightweight attention mechanisms, and modality\npre-fusion are discussed as enablers of high performance with reduced resource\nrequirements. Through an in-depth analysis of models like TinyGPT-V, MiniGPT-4,\nand VL-Mamba, we identify trade-offs between accuracy, efficiency, and\nscalability. Persistent challenges, including data biases and generalization to\ncomplex tasks, are critically examined, with proposed pathways for addressing\nthem. By consolidating advancements in sVLMs, this work underscores their\ntransformative potential for accessible AI, setting a foundation for future\nresearch into efficient multimodal systems.", "published": "2025-03-09 16:14:46", "link": "http://arxiv.org/abs/2503.10665v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation", "abstract": "Implementing new features in repository-level codebases is a crucial\napplication of code generation models. However, current benchmarks lack a\ndedicated evaluation framework for this capability. To fill this gap, we\nintroduce FEA-Bench, a benchmark designed to assess the ability of large\nlanguage models (LLMs) to perform incremental development within code\nrepositories. We collect pull requests from 83 GitHub repositories and use\nrule-based and intent-based filtering to construct task instances focused on\nnew feature development. Each task instance containing code changes is paired\nwith relevant unit test files to ensure that the solution can be verified. The\nfeature implementation requires LLMs to simultaneously possess code completion\ncapabilities for new components and code editing abilities for other relevant\nparts in the code repository, providing a more comprehensive evaluation method\nof LLMs' automated software engineering capabilities. Experimental results show\nthat LLMs perform significantly worse in the FEA-Bench, highlighting\nconsiderable challenges in such repository-level incremental code development.", "published": "2025-03-09 16:11:57", "link": "http://arxiv.org/abs/2503.06680v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Attention, Please! PixelSHAP Reveals What Vision-Language Models Actually Focus On", "abstract": "Interpretability in Vision-Language Models (VLMs) is crucial for trust,\ndebugging, and decision-making in high-stakes applications. We introduce\nPixelSHAP, a model-agnostic framework extending Shapley-based analysis to\nstructured visual entities. Unlike previous methods focusing on text prompts,\nPixelSHAP applies to vision-based reasoning by systematically perturbing image\nobjects and quantifying their influence on a VLM's response. PixelSHAP requires\nno model internals, operating solely on input-output pairs, making it\ncompatible with open-source and commercial models. It supports diverse\nembedding-based similarity metrics and scales efficiently using optimization\ntechniques inspired by Shapley-based methods. We validate PixelSHAP in\nautonomous driving, highlighting its ability to enhance interpretability. Key\nchallenges include segmentation sensitivity and object occlusion. Our\nopen-source implementation facilitates further research.", "published": "2025-03-09 15:43:55", "link": "http://arxiv.org/abs/2503.06670v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enhancing NLP Robustness and Generalization through LLM-Generated Contrast Sets: A Scalable Framework for Systematic Evaluation and Adversarial Training", "abstract": "Standard NLP benchmarks often fail to capture vulnerabilities stemming from\ndataset artifacts and spurious correlations. Contrast sets address this gap by\nchallenging models near decision boundaries but are traditionally\nlabor-intensive to create and limited in diversity. This study leverages large\nlanguage models to automate the generation of diverse contrast sets. Using the\nSNLI dataset, we created a 3,000-example contrast set to evaluate and improve\nmodel robustness. Fine-tuning on these contrast sets enhanced performance on\nsystematically perturbed examples, maintained standard test accuracy, and\nmodestly improved generalization to novel perturbations. This automated\napproach offers a scalable solution for evaluating and improving NLP models,\naddressing systematic generalization challenges, and advancing robustness in\nreal-world applications.", "published": "2025-03-09 14:52:53", "link": "http://arxiv.org/abs/2503.06648v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating and Aligning Human Economic Risk Preferences in LLMs", "abstract": "Large Language Models (LLMs) are increasingly used in decision-making\nscenarios that involve risk assessment, yet their alignment with human economic\nrationality remains unclear. In this study, we investigate whether LLMs exhibit\nrisk preferences consistent with human expectations across different personas.\nSpecifically, we assess whether LLM-generated responses reflect appropriate\nlevels of risk aversion or risk-seeking behavior based on individual's persona.\nOur results reveal that while LLMs make reasonable decisions in simplified,\npersonalized risk contexts, their performance declines in more complex economic\ndecision-making tasks. To address this, we propose an alignment method designed\nto enhance LLM adherence to persona-specific risk preferences. Our approach\nimproves the economic rationality of LLMs in risk-related applications,\noffering a step toward more human-aligned AI decision-making.", "published": "2025-03-09 14:47:31", "link": "http://arxiv.org/abs/2503.06646v1", "categories": ["econ.GN", "cs.CL", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Is Your Benchmark (Still) Useful? Dynamic Benchmarking for Code Language Models", "abstract": "In this paper, we tackle a critical challenge in model evaluation: how to\nkeep code benchmarks useful when models might have already seen them during\ntraining. We introduce a novel solution, dynamic benchmarking framework, to\naddress this challenge. Given a code understanding or reasoning benchmark, our\nframework dynamically transforms each input, i.e., programs, with various\nsemantic-preserving mutations to build a syntactically new while semantically\nidentical benchmark. We evaluated ten popular language models on our dynamic\nbenchmarks. Our evaluation reveals several interesting or surprising findings:\n(1) all models perform significantly worse than before, (2) the ranking between\nsome models shifts dramatically, and (3) our dynamic benchmarks can resist\nagainst the data contamination problem.", "published": "2025-03-09 14:41:18", "link": "http://arxiv.org/abs/2503.06643v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Revisiting Early Detection of Sexual Predators via Turn-level Optimization", "abstract": "Online grooming is a severe social threat where sexual predators gradually\nentrap child victims with subtle and gradual manipulation. Therefore, timely\nintervention for online grooming is critical for proactive protection. However,\nprevious methods fail to determine the optimal intervention points (i.e., jump\nto conclusions) as they rely on chat-level risk labels by causing weak\nsupervision of risky utterances. For timely detection, we propose speed control\nreinforcement learning (SCoRL) (The code and supplementary materials are\navailable at https://github.com/jinmyeongAN/SCoRL), incorporating a practical\nstrategy derived from luring communication theory (LCT). To capture the\npredator's turn-level entrapment, we use a turn-level risk label based on the\nLCT. Then, we design a novel speed control reward function that balances the\ntrade-off between speed and accuracy based on turn-level risk label; thus,\nSCoRL can identify the optimal intervention moment. In addition, we introduce a\nturn-level metric for precise evaluation, identifying limitations in previously\nused chat-level metrics. Experimental results show that SCoRL effectively\npreempted online grooming, offering a more proactive and timely solution.\nFurther analysis reveals that our method enhances performance while intuitively\nidentifying optimal early intervention points.", "published": "2025-03-09 14:05:27", "link": "http://arxiv.org/abs/2503.06627v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Beyond Decoder-only: Large Language Models Can be Good Encoders for Machine Translation", "abstract": "The field of neural machine translation (NMT) has changed with the advent of\nlarge language models (LLMs). Much of the recent emphasis in natural language\nprocessing (NLP) has been on modeling machine translation and many other\nproblems using a single pre-trained Transformer decoder, while encoder-decoder\narchitectures, which were the standard in earlier NMT models, have received\nrelatively less attention. In this paper, we explore translation models that\nare universal, efficient, and easy to optimize, by marrying the world of LLMs\nwith the world of NMT. We apply LLMs to NMT encoding and leave the NMT decoder\nunchanged. We also develop methods for adapting LLMs to work better with the\nNMT decoder. Furthermore, we construct a new dataset involving multiple tasks\nto assess how well the machine translation system generalizes across various\ntasks. Evaluations on the WMT and our datasets show that results using our\nmethod match or surpass a range of baselines in terms of translation quality,\nbut achieve $2.4 \\sim 6.5 \\times$ inference speedups and a $75\\%$ reduction in\nthe memory footprint of the KV cache. It also demonstrates strong\ngeneralization across a variety of translation-related tasks.", "published": "2025-03-09 12:54:05", "link": "http://arxiv.org/abs/2503.06594v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WildIFEval: Instruction Following in the Wild", "abstract": "Recent LLMs have shown remarkable success in following user instructions, yet\nhandling instructions with multiple constraints remains a significant\nchallenge. In this work, we introduce WildIFEval - a large-scale dataset of 12K\nreal user instructions with diverse, multi-constraint conditions. Unlike prior\ndatasets, our collection spans a broad lexical and topical spectrum of\nconstraints, in natural user prompts. We categorize these constraints into\neight high-level classes to capture their distribution and dynamics in\nreal-world scenarios. Leveraging WildIFEval, we conduct extensive experiments\nto benchmark the instruction-following capabilities of leading LLMs. Our\nfindings reveal that all evaluated models experience performance degradation\nwith an increasing number of constraints. Thus, we show that all models have a\nlarge room for improvement on such tasks. Moreover, we observe that the\nspecific type of constraint plays a critical role in model performance. We\nrelease our dataset to promote further research on instruction-following under\ncomplex, realistic conditions.", "published": "2025-03-09 12:06:29", "link": "http://arxiv.org/abs/2503.06573v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multimodal Programming in Computer Science with Interactive Assistance Powered by Large Language Model", "abstract": "LLM chatbot interfaces allow students to get instant, interactive assistance\nwith homework, but doing so carelessly may not advance educational objectives.\nIn this study, an interactive homework help system based on DeepSeek R1 is\ndeveloped and first implemented for students enrolled in a large computer\nscience beginning programming course. In addition to an assist button in a\nwell-known code editor, our assistant also has a feedback option in our\ncommand-line automatic evaluator. It wraps student work in a personalized\nprompt that advances our educational objectives without offering answers\nstraight away. We have discovered that our assistant can recognize students'\nconceptual difficulties and provide ideas, plans, and template code in\npedagogically appropriate ways. However, among other mistakes, it occasionally\nincorrectly labels the correct student code as incorrect or encourages students\nto use correct-but-lesson-inappropriate approaches, which can lead to long and\nfrustrating journeys for the students. After discussing many development and\ndeployment issues, we provide our conclusions and future actions.", "published": "2025-03-09 10:48:47", "link": "http://arxiv.org/abs/2503.06552v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "BingoGuard: LLM Content Moderation Tools with Risk Levels", "abstract": "Malicious content generated by large language models (LLMs) can pose varying\ndegrees of harm. Although existing LLM-based moderators can detect harmful\ncontent, they struggle to assess risk levels and may miss lower-risk outputs.\nAccurate risk assessment allows platforms with different safety thresholds to\ntailor content filtering and rejection. In this paper, we introduce per-topic\nseverity rubrics for 11 harmful topics and build BingoGuard, an LLM-based\nmoderation system designed to predict both binary safety labels and severity\nlevels. To address the lack of annotations on levels of severity, we propose a\nscalable generate-then-filter framework that first generates responses across\ndifferent severity levels and then filters out low-quality responses. Using\nthis framework, we create BingoGuardTrain, a training dataset with 54,897\nexamples covering a variety of topics, response severity, styles, and\nBingoGuardTest, a test set with 988 examples explicitly labeled based on our\nseverity rubrics that enables fine-grained analysis on model behaviors on\ndifferent severity levels. Our BingoGuard-8B, trained on BingoGuardTrain,\nachieves the state-of-the-art performance on several moderation benchmarks,\nincluding WildGuardTest and HarmBench, as well as BingoGuardTest, outperforming\nbest public models, WildGuard, by 4.3\\%. Our analysis demonstrates that\nincorporating severity levels into training significantly enhances detection\nperformance and enables the model to effectively gauge the severity of harmful\nresponses.", "published": "2025-03-09 10:43:09", "link": "http://arxiv.org/abs/2503.06550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Kr\u00e9yoLID From Language Identification Towards Language Mining", "abstract": "Automatic language identification is frequently framed as a multi-class\nclassification problem. However, when creating digital corpora for less\ncommonly written languages, it may be more appropriate to consider it a data\nmining problem. For these varieties, one knows ahead of time that the vast\nmajority of documents are of little interest. By minimizing resources spent on\nclassifying such documents, we can create corpora much faster and with better\ncoverage than using established pipelines. To demonstrate the effectiveness of\nthe language mining perspective, we introduce a new pipeline and corpora for\nseveral French-based Creoles.", "published": "2025-03-09 10:37:05", "link": "http://arxiv.org/abs/2503.06547v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SafeSpeech: A Comprehensive and Interactive Tool for Analysing Sexist and Abusive Language in Conversations", "abstract": "Detecting toxic language including sexism, harassment and abusive behaviour,\nremains a critical challenge, particularly in its subtle and context-dependent\nforms. Existing approaches largely focus on isolated message-level\nclassification, overlooking toxicity that emerges across conversational\ncontexts. To promote and enable future research in this direction, we introduce\nSafeSpeech, a comprehensive platform for toxic content detection and analysis\nthat bridges message-level and conversation-level insights. The platform\nintegrates fine-tuned classifiers and large language models (LLMs) to enable\nmulti-granularity detection, toxic-aware conversation summarization, and\npersona profiling. SafeSpeech also incorporates explainability mechanisms, such\nas perplexity gain analysis, to highlight the linguistic elements driving\npredictions. Evaluations on benchmark datasets, including EDOS, OffensEval, and\nHatEval, demonstrate the reproduction of state-of-the-art performance across\nmultiple tasks, including fine-grained sexism detection.", "published": "2025-03-09 09:31:17", "link": "http://arxiv.org/abs/2503.06534v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MetaXCR: Reinforcement-Based Meta-Transfer Learning for Cross-Lingual Commonsense Reasoning", "abstract": "Commonsense reasoning (CR) has been studied in many pieces of domain and has\nachieved great progress with the aid of large datasets. Unfortunately, most\nexisting CR datasets are built in English, so most previous work focus on\nEnglish. Furthermore, as the annotation of commonsense reasoning is costly, it\nis impossible to build a large dataset for every novel task. Therefore, there\nare growing appeals for Cross-lingual Low-Resource Commonsense Reasoning, which\naims to leverage diverse existed English datasets to help the model adapt to\nnew cross-lingual target datasets with limited labeled data. In this paper, we\npropose a multi-source adapter for cross-lingual low-resource Commonsense\nReasoning (MetaXCR). In this framework, we first extend meta learning by\nincorporating multiple training datasets to learn a generalized task adapters\nacross different tasks. Then, we further introduce a reinforcement-based\nsampling strategy to help the model sample the source task that is the most\nhelpful to the target task. Finally, we introduce two types of cross-lingual\nmeta-adaption methods to enhance the performance of models on target languages.\nExtensive experiments demonstrate MetaXCR is superior over state-of-the-arts,\nwhile being trained with fewer parameters than other work.", "published": "2025-03-09 09:27:57", "link": "http://arxiv.org/abs/2503.06531v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks", "abstract": "Vision-Language Models (VLMs) have recently shown promising advancements in\nsequential decision-making tasks through task-specific fine-tuning. However,\ncommon fine-tuning methods, such as Supervised Fine-Tuning (SFT) and\nReinforcement Learning (RL) techniques like Proximal Policy Optimization (PPO),\npresent notable limitations: SFT assumes Independent and Identically\nDistributed (IID) data, while PPO focuses on maximizing cumulative rewards.\nThese limitations often restrict solution diversity and hinder generalization\nin multi-step reasoning tasks. To address these challenges, we introduce a\nnovel framework, GFlowVLM, a framework that fine-tune VLMs using Generative\nFlow Networks (GFlowNets) to promote generation of diverse solutions for\ncomplex reasoning tasks. GFlowVLM models the environment as a non-Markovian\ndecision process, allowing it to capture long-term dependencies essential for\nreal-world applications. It takes observations and task descriptions as inputs\nto prompt chain-of-thought (CoT) reasoning which subsequently guides action\nselection. We use task based rewards to fine-tune VLM with GFlowNets. This\napproach enables VLMs to outperform prior fine-tuning methods, including SFT\nand RL. Empirical results demonstrate the effectiveness of GFlowVLM on complex\ntasks such as card games (NumberLine, BlackJack) and embodied planning tasks\n(ALFWorld), showing enhanced training efficiency, solution diversity, and\nstronger generalization capabilities across both in-distribution and\nout-of-distribution scenarios.", "published": "2025-03-09 08:38:10", "link": "http://arxiv.org/abs/2503.06514v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Less is More: Adaptive Program Repair with Bug Localization and Preference Learning", "abstract": "Automated Program Repair (APR) is a task to automatically generate patches\nfor the buggy code. However, most research focuses on generating correct\npatches while ignoring the consistency between the fixed code and the original\nbuggy code. How to conduct adaptive bug fixing and generate patches with\nminimal modifications have seldom been investigated. To bridge this gap, we\nfirst introduce a novel task, namely AdaPR (Adaptive Program Repair). We then\npropose a two-stage approach AdaPatcher (Adaptive Patch Generator) to enhance\nprogram repair while maintaining the consistency. In the first stage, we\nutilize a Bug Locator with self-debug learning to accurately pinpoint bug\nlocations. In the second stage, we train a Program Modifier to ensure\nconsistency between the post-modified fixed code and the pre-modified buggy\ncode. The Program Modifier is enhanced with a location-aware repair learning\nstrategy to generate patches based on identified buggy lines, a hybrid training\nstrategy for selective reference and an adaptive preference learning to\nprioritize fewer changes. The experimental results show that our approach\noutperforms a set of baselines by a large margin, validating the effectiveness\nof our two-stage framework for the newly proposed AdaPR task.", "published": "2025-03-09 08:32:38", "link": "http://arxiv.org/abs/2503.06510v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Semantic Wave Functions: Exploring Meaning in Large Language Models Through Quantum Formalism", "abstract": "Large Language Models (LLMs) encode semantic relationships in\nhigh-dimensional vector embeddings. This paper explores the analogy between LLM\nembedding spaces and quantum mechanics, positing that LLMs operate within a\nquantized semantic space where words and phrases behave as quantum states. To\ncapture nuanced semantic interference effects, we extend the standard\nreal-valued embedding space to the complex domain, drawing parallels to the\ndouble-slit experiment. We introduce a \"semantic wave function\" to formalize\nthis quantum-derived representation and utilize potential landscapes, such as\nthe double-well potential, to model semantic ambiguity. Furthermore, we propose\na complex-valued similarity measure that incorporates both magnitude and phase\ninformation, enabling a more sensitive comparison of semantic representations.\nWe develop a path integral formalism, based on a nonlinear Schr\\\"odinger\nequation with a gauge field and Mexican hat potential, to model the dynamic\nevolution of LLM behavior. This interdisciplinary approach offers a new\ntheoretical framework for understanding and potentially manipulating LLMs, with\nthe goal of advancing both artificial and natural language understanding.", "published": "2025-03-09 08:23:31", "link": "http://arxiv.org/abs/2503.10664v1", "categories": ["cs.CL", "cs.LG", "quant-ph"], "primary_category": "cs.CL"}
{"title": "VisualSimpleQA: A Benchmark for Decoupled Evaluation of Large Vision-Language Models in Fact-Seeking Question Answering", "abstract": "Large vision-language models (LVLMs) have demonstrated remarkable\nachievements, yet the generation of non-factual responses remains prevalent in\nfact-seeking question answering (QA). Current multimodal fact-seeking\nbenchmarks primarily focus on comparing model outputs to ground truth answers,\nproviding limited insights into the performance of modality-specific modules.\nTo bridge this gap, we introduce VisualSimpleQA, a multimodal fact-seeking\nbenchmark with two key features. First, it enables streamlined and decoupled\nevaluation of LVLMs in visual and linguistic modalities. Second, it\nincorporates well-defined difficulty criteria to guide human annotation and\nfacilitates the extraction of a challenging subset, VisualSimpleQA-hard.\nExperiments on 15 LVLMs show that even state-of-the-art models such as GPT-4o\nachieve merely 60%+ correctness in multimodal fact-seeking QA on VisualSimpleQA\nand 30%+ on VisualSimpleQA-hard. Furthermore, the decoupled evaluation across\nthese models highlights substantial opportunities for improvement in both\nvisual and linguistic modules. The dataset is available at\nhttps://huggingface.co/datasets/WYLing/VisualSimpleQA.", "published": "2025-03-09 07:25:32", "link": "http://arxiv.org/abs/2503.06492v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "MoFE: Mixture of Frozen Experts Architecture", "abstract": "We propose the Mixture of Frozen Experts (MoFE) architecture, which\nintegrates Parameter-efficient Fine-tuning (PEFT) and the Mixture of Experts\n(MoE) architecture to enhance both training efficiency and model scalability.\nBy freezing the Feed Forward Network (FFN) layers within the MoE framework,\nMoFE significantly reduces the number of trainable parameters, improving\ntraining efficiency while still allowing for effective knowledge transfer from\nthe expert models. This facilitates the creation of models proficient in\nmultiple domains. We conduct experiments to evaluate the trade-offs between\nperformance and efficiency, compare MoFE with other PEFT methodologies, assess\nthe impact of domain expertise in the constituent models, and determine the\noptimal training strategy. The results show that, although there may be some\ntrade-offs in performance, the efficiency gains are substantial, making MoFE a\nreasonable solution for real-world, resource-constrained environments.", "published": "2025-03-09 07:24:36", "link": "http://arxiv.org/abs/2503.06491v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SKG-LLM: Developing a Mathematical Model for Stroke Knowledge Graph Construction Using Large Language Models", "abstract": "The purpose of this study is to introduce SKG-LLM. A knowledge graph (KG) is\nconstructed from stroke-related articles using mathematical and large language\nmodels (LLMs). SKG-LLM extracts and organizes complex relationships from the\nbiomedical literature, using it to increase the accuracy and depth of KG in\nstroke research. In the proposed method, GPT-4 was used for data\npre-processing, and the extraction of embeddings was also done by GPT-4 in the\nwhole KG construction process. The performance of the proposed model was tested\nwith two evaluation criteria: Precision and Recall. For further validation of\nthe proposed model, GPT-4 was used. Compared with Wikidata and WN18RR, the\nproposed KG-LLM approach performs better, especially in precision and recall.\nBy including GPT-4 in the preprocessing process, the SKG-LLM model achieved a\nprecision score of 0.906 and a recall score of 0.923. Expert reviews further\nimproved the results and increased precision to 0.923 and recall to 0.918. The\nknowledge graph constructed by SKG-LLM contains 2692 nodes and 5012 edges,\nwhich are 13 distinct types of nodes and 24 types of edges.", "published": "2025-03-09 06:25:37", "link": "http://arxiv.org/abs/2503.06475v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "HuixiangDou2: A Robustly Optimized GraphRAG Approach", "abstract": "Large Language Models (LLMs) perform well on familiar queries but struggle\nwith specialized or emerging topics. Graph-based Retrieval-Augmented Generation\n(GraphRAG) addresses this by structuring domain knowledge as a graph for\ndynamic retrieval. However, existing pipelines involve complex engineering\nworkflows, making it difficult to isolate the impact of individual components.\nEvaluating retrieval effectiveness is also challenging due to dataset overlap\nwith LLM pretraining data. In this work, we introduce HuixiangDou2, a robustly\noptimized GraphRAG framework. Specifically, we leverage the effectiveness of\ndual-level retrieval and optimize its performance in a 32k context for maximum\nprecision, and compare logic-based retrieval and dual-level retrieval to\nenhance overall functionality. Our implementation includes comparative\nexperiments on a test set, where Qwen2.5-7B-Instruct initially underperformed.\nWith our approach, the score improved significantly from 60 to 74.5, as\nillustrated in the Figure. Experiments on domain-specific datasets reveal that\ndual-level retrieval enhances fuzzy matching, while logic-form retrieval\nimproves structured reasoning. Furthermore, we propose a multi-stage\nverification mechanism to improve retrieval robustness without increasing\ncomputational cost. Empirical results show significant accuracy gains over\nbaselines, highlighting the importance of adaptive retrieval. To support\nresearch and adoption, we release HuixiangDou2 as an open-source resource\nhttps://github.com/tpoisonooo/huixiangdou2.", "published": "2025-03-09 06:20:24", "link": "http://arxiv.org/abs/2503.06474v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Think Twice, Click Once: Enhancing GUI Grounding via Fast and Slow Systems", "abstract": "Humans can flexibly switch between different modes of thinking based on task\ncomplexity: from rapid intuitive judgments to in-depth analytical\nunderstanding. However, current Graphical User Interface (GUI) grounding\nsystems which locate interface elements based on natural language instructions\nrely solely on immediate prediction without reasoning, struggling to understand\ncomplex interface layouts with nested structures and hierarchical\nrelationships, limiting their effectiveness on complex interfaces. Inspired by\nhuman dual-system cognition, we present Focus, a novel GUI grounding framework\nthat combines fast prediction with systematic analysis. The framework\ndynamically switches between rapid and deliberate processing through an\nadaptive system switching based on task complexity, optimizing both efficiency\nand accuracy. Focus decomposes grounding into progressive stages: interface\nsummarization, visual focused analysis, and precise coordinate prediction. This\nstructured decomposition enables systematic understanding of both interface\nlayouts and visual relationships. Extensive experiments show that Focus\nachieves state-of-the-art performance using only 300K of the training data with\na 2B parameter model compared to existing approaches. Focus demonstrates\nsuperior performance particularly in complex GUI scenarios, achieving 77.4%\naverage accuracy on ScreenSpot and 13.3% on the more challenging\nScreenSpot-Pro. Our analysis reveals the effectiveness of this dual-system\napproach while demonstrating its potential for improving complex GUI\ninteraction scenarios.", "published": "2025-03-09 06:14:17", "link": "http://arxiv.org/abs/2503.06470v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Graph Retrieval-Augmented LLM for Conversational Recommendation Systems", "abstract": "Conversational Recommender Systems (CRSs) have emerged as a transformative\nparadigm for offering personalized recommendations through natural language\ndialogue. However, they face challenges with knowledge sparsity, as users often\nprovide brief, incomplete preference statements. While recent methods have\nintegrated external knowledge sources to mitigate this, they still struggle\nwith semantic understanding and complex preference reasoning. Recent Large\nLanguage Models (LLMs) demonstrate promising capabilities in natural language\nunderstanding and reasoning, showing significant potential for CRSs.\nNevertheless, due to the lack of domain knowledge, existing LLM-based CRSs\neither produce hallucinated recommendations or demand expensive domain-specific\ntraining, which largely limits their applicability. In this work, we present\nG-CRS (Graph Retrieval-Augmented Large Language Model for Conversational\nRecommender Systems), a novel training-free framework that combines graph\nretrieval-augmented generation and in-context learning to enhance LLMs'\nrecommendation capabilities. Specifically, G-CRS employs a two-stage\nretrieve-and-recommend architecture, where a GNN-based graph reasoner first\nidentifies candidate items, followed by Personalized PageRank exploration to\njointly discover potential items and similar user interactions. These retrieved\ncontexts are then transformed into structured prompts for LLM reasoning,\nenabling contextually grounded recommendations without task-specific training.\nExtensive experiments on two public datasets show that G-CRS achieves superior\nrecommendation performance compared to existing methods without requiring\ntask-specific training.", "published": "2025-03-09 03:56:22", "link": "http://arxiv.org/abs/2503.06430v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues", "abstract": "Generative artificial intelligence (AI) has the potential to scale up\npersonalized tutoring through large language models (LLMs). Recent AI tutors\nare adapted for the tutoring task by training or prompting LLMs to follow\neffective pedagogical principles, though they are not trained to maximize\nstudent learning throughout the course of a dialogue. Therefore, they may\nengage with students in a suboptimal way. We address this limitation by\nintroducing an approach to train LLMs to generate tutor utterances that\nmaximize the likelihood of student correctness, while still encouraging the\nmodel to follow good pedagogical practice. Specifically, we generate a set of\ncandidate tutor utterances and score them using (1) an LLM-based student model\nto predict the chance of correct student responses and (2) a pedagogical rubric\nevaluated by GPT-4o. We then use the resulting data to train an open-source\nLLM, Llama 3.1 8B, using direct preference optimization. We show that tutor\nutterances generated by our model lead to significantly higher chances of\ncorrect student responses while maintaining the pedagogical quality of GPT-4o.\nWe also conduct qualitative analyses and a human evaluation to demonstrate that\nour model generates high quality tutor utterances.", "published": "2025-03-09 03:38:55", "link": "http://arxiv.org/abs/2503.06424v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "How LLMs Learn: Tracing Internal Representations with Sparse Autoencoders", "abstract": "Large Language Models (LLMs) demonstrate remarkable multilingual capabilities\nand broad knowledge. However, the internal mechanisms underlying the\ndevelopment of these capabilities remain poorly understood. To investigate\nthis, we analyze how the information encoded in LLMs' internal representations\nevolves during the training process. Specifically, we train sparse autoencoders\nat multiple checkpoints of the model and systematically compare the\ninterpretative results across these stages. Our findings suggest that LLMs\ninitially acquire language-specific knowledge independently, followed by\ncross-linguistic correspondences. Moreover, we observe that after mastering\ntoken-level knowledge, the model transitions to learning higher-level, abstract\nconcepts, indicating the development of more conceptual understanding.", "published": "2025-03-09 02:13:44", "link": "http://arxiv.org/abs/2503.06394v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TI-JEPA: An Innovative Energy-based Joint Embedding Strategy for Text-Image Multimodal Systems", "abstract": "This paper focuses on multimodal alignment within the realm of Artificial\nIntelligence, particularly in text and image modalities. The semantic gap\nbetween the textual and visual modality poses a discrepancy problem towards the\neffectiveness of multi-modalities fusion. Therefore, we introduce Text-Image\nJoint Embedding Predictive Architecture (TI-JEPA), an innovative pre-training\nstrategy that leverages energy-based model (EBM) framework to capture complex\ncross-modal relationships. TI-JEPA combines the flexibility of EBM in\nself-supervised learning to facilitate the compatibility between textual and\nvisual elements. Through extensive experiments across multiple benchmarks, we\ndemonstrate that TI-JEPA achieves state-of-the-art performance on multimodal\nsentiment analysis task (and potentially on a wide range of multimodal-based\ntasks, such as Visual Question Answering), outperforming existing pre-training\nmethodologies. Our findings highlight the potential of using energy-based\nframework in advancing multimodal fusion and suggest significant improvements\nfor downstream applications.", "published": "2025-03-09 01:34:28", "link": "http://arxiv.org/abs/2503.06380v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "General Scales Unlock AI Evaluation with Explanatory and Predictive Power", "abstract": "Ensuring safe and effective use of AI requires understanding and anticipating\nits performance on novel tasks, from advanced scientific challenges to\ntransformed workplace activities. So far, benchmarking has guided progress in\nAI, but it has offered limited explanatory and predictive power for\ngeneral-purpose AI systems, given the low transferability across diverse tasks.\nIn this paper, we introduce general scales for AI evaluation that can explain\nwhat common AI benchmarks really measure, extract ability profiles of AI\nsystems, and predict their performance for new task instances, in- and\nout-of-distribution. Our fully-automated methodology builds on 18 newly-crafted\nrubrics that place instance demands on general scales that do not saturate.\nIllustrated for 15 large language models and 63 tasks, high explanatory power\nis unleashed from inspecting the demand and ability profiles, bringing insights\non the sensitivity and specificity exhibited by different benchmarks, and how\nknowledge, metacognition and reasoning are affected by model size,\nchain-of-thought and distillation. Surprisingly, high predictive power at the\ninstance level becomes possible using these demand levels, providing superior\nestimates over black-box baseline predictors based on embeddings or finetuning,\nespecially in out-of-distribution settings (new tasks and new benchmarks). The\nscales, rubrics, battery, techniques and results presented here represent a\nmajor step for AI evaluation, underpinning the reliable deployment of AI in the\nyears ahead. (Collaborative platform:\nhttps://kinds-of-intelligence-cfi.github.io/ADELE.)", "published": "2025-03-09 01:13:56", "link": "http://arxiv.org/abs/2503.06378v2", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Theoretical and Computational Approaches to Determining Sets of Orders for $(k,g)$-Graphs", "abstract": "The Cage Problem requires for a given pair $k \\geq 3, g \\geq 3$ of integers\nthe determination of the order of a smallest $k$-regular graph of girth $g$. We\naddress a more general version of this problem and look for the\n$(k,g)$-spectrum of orders of $(k,g)$-graphs: the (infinite) list of all orders\nof $(k,g)$-graphs. By establishing these spectra we aim to gain a better\nunderstanding of the structure and properties of $(k,g)$-graphs and hope to use\nthe acquired knowledge in both determining new orders of smallest $k$-regular\ngraphs of girth $g$ as well as developing a set of tools suitable for\nconstructions of extremal graphs with additional requirements. We combine\ntheoretical results with computer-based searches, and determine or determine up\nto a finite list of unresolved cases the $(k,g)$-spectra for parameter pairs\nfor which the orders of the corresponding cages have already been established.", "published": "2025-03-09 06:05:48", "link": "http://arxiv.org/abs/2503.06466v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot", "abstract": "The social robot's open API allows users to customize open-domain\ninteractions. However, it remains inaccessible to those without programming\nexperience. In this work, we introduce AutoMisty, the first multi-agent\ncollaboration framework powered by large language models (LLMs), to enable the\nseamless generation of executable Misty robot code from natural language\ninstructions. AutoMisty incorporates four specialized agent modules to manage\ntask decomposition, assignment, problem-solving, and result synthesis. Each\nagent incorporates a two-layer optimization mechanism, with self-reflection for\niterative refinement and human-in-the-loop for better alignment with user\npreferences. AutoMisty ensures a transparent reasoning process, allowing users\nto iteratively refine tasks through natural language feedback for precise\nexecution. To evaluate AutoMisty's effectiveness, we designed a benchmark task\nset spanning four levels of complexity and conducted experiments in a real\nMisty robot environment. Extensive evaluations demonstrate that AutoMisty not\nonly consistently generates high-quality code but also enables precise code\ncontrol, significantly outperforming direct reasoning with ChatGPT-4o and\nChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly\nreleased through the webpage: https://wangxiaoshawn.github.io/AutoMisty.html", "published": "2025-03-09 22:07:46", "link": "http://arxiv.org/abs/2503.06791v1", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Fully-Decentralized MADDPG with Networked Agents", "abstract": "In this paper, we devise three actor-critic algorithms with decentralized\ntraining for multi-agent reinforcement learning in cooperative, adversarial,\nand mixed settings with continuous action spaces. To this goal, we adapt the\nMADDPG algorithm by applying a networked communication approach between agents.\nWe introduce surrogate policies in order to decentralize the training while\nallowing for local communication during training. The decentralized algorithms\nachieve comparable results to the original MADDPG in empirical tests, while\nreducing computational cost. This is more pronounced with larger numbers of\nagents.", "published": "2025-03-09 20:05:32", "link": "http://arxiv.org/abs/2503.06747v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Beyond Black-Box Benchmarking: Observability, Analytics, and Optimization of Agentic Systems", "abstract": "The rise of agentic AI systems, where agents collaborate to perform diverse\ntasks, poses new challenges with observing, analyzing and optimizing their\nbehavior. Traditional evaluation and benchmarking approaches struggle to handle\nthe non-deterministic, context-sensitive, and dynamic nature of these systems.\nThis paper explores key challenges and opportunities in analyzing and\noptimizing agentic systems across development, testing, and maintenance. We\nexplore critical issues such as natural language variability and unpredictable\nexecution flows, which hinder predictability and control, demanding adaptive\nstrategies to manage input variability and evolving behaviors. Through our user\nstudy, we supported these hypotheses. In particular, we showed a 79% agreement\nthat non deterministic flow of agentic systems acts as a major challenge.\nFinally, we validated our statements empirically advocating the need for moving\nbeyond classical benchmarking. To bridge these gaps, we introduce taxonomies to\npresent expected analytics outcomes and the ways to collect them by extending\nstandard observability frameworks. Building on these foundations, we introduce\nand demonstrate novel approach for benchmarking of agent evaluation systems.\nUnlike traditional \"black box\" performance evaluation approaches, our benchmark\nis built from agent runtime logs as input, and analytics outcome including\ndiscovered flows and issues. By addressing key limitations in existing\nmethodologies, we aim to set the stage for more advanced and holistic\nevaluation strategies, which could foster the development of adaptive,\ninterpretable, and robust agentic AI systems.", "published": "2025-03-09 20:02:04", "link": "http://arxiv.org/abs/2503.06745v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Vision-Based Cooperative MAV-Capturing-MAV", "abstract": "MAV-capturing-MAV (MCM) is one of the few effective methods for physically\ncountering misused or malicious MAVs.This paper presents a vision-based\ncooperative MCM system, where multiple pursuer MAVs equipped with onboard\nvision systems detect, localize, and pursue a target MAV. To enhance\nrobustness, a distributed state estimation and control framework enables the\npursuer MAVs to autonomously coordinate their actions. Pursuer trajectories are\noptimized using Model Predictive Control (MPC) and executed via a low-level\nSO(3) controller, ensuring smooth and stable pursuit. Once the capture\nconditions are satisfied, the pursuer MAVs automatically deploy a flying net to\nintercept the target. These capture conditions are determined based on the\npredicted motion of the net. To enable real-time decision-making, we propose a\nlightweight computational method to approximate the net motion, avoiding the\nprohibitive cost of solving the full net dynamics. The effectiveness of the\nproposed system is validated through simulations and real-world experiments. In\nreal-world tests, our approach successfully captures a moving target traveling\nat 4 meters per second with an acceleration of 1 meter per square second,\nachieving a success rate of 64.7 percent.", "published": "2025-03-09 03:12:45", "link": "http://arxiv.org/abs/2503.06412v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Axes that matter: PCA with a difference", "abstract": "We extend the scope of differential machine learning and introduce a new\nbreed of supervised principal component analysis to reduce dimensionality of\nDerivatives problems. Applications include the specification and calibration of\npricing models, the identification of regression features in least-square\nMonte-Carlo, and the pre-processing of simulated datasets for (differential)\nmachine learning.", "published": "2025-03-09 17:47:25", "link": "http://arxiv.org/abs/2503.06707v2", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Multimodal Emotion Recognition and Sentiment Analysis in Multi-Party Conversation Contexts", "abstract": "Emotion recognition and sentiment analysis are pivotal tasks in speech and\nlanguage processing, particularly in real-world scenarios involving\nmulti-party, conversational data. This paper presents a multimodal approach to\ntackle these challenges on a well-known dataset. We propose a system that\nintegrates four key modalities/channels using pre-trained models: RoBERTa for\ntext, Wav2Vec2 for speech, a proposed FacialNet for facial expressions, and a\nCNN+Transformer architecture trained from scratch for video analysis. Feature\nembeddings from each modality are concatenated to form a multimodal vector,\nwhich is then used to predict emotion and sentiment labels. The multimodal\nsystem demonstrates superior performance compared to unimodal approaches,\nachieving an accuracy of 66.36% for emotion recognition and 72.15% for\nsentiment analysis.", "published": "2025-03-09 23:14:19", "link": "http://arxiv.org/abs/2503.06805v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Why Pre-trained Models Fail: Feature Entanglement in Multi-modal Depression Detection", "abstract": "Depression remains a pressing global mental health issue, driving\nconsiderable research into AI-driven detection approaches. While pre-trained\nmodels, particularly speech self-supervised models (SSL Models), have been\napplied to depression detection, they show unexpectedly poor performance\nwithout extensive data augmentation. Large Language Models (LLMs), despite\ntheir success across various domains, have not been explored in multi-modal\ndepression detection. In this paper, we first establish an LLM-based system to\ninvestigate its potential in this task, uncovering fundamental limitations in\nhandling multi-modal information. Through systematic analysis, we discover that\nthe poor performance of pre-trained models stems from the conflation of\nhigh-level information, where high-level features derived from both content and\nspeech are mixed within pre-trained models model representations, making it\nchallenging to establish effective decision boundaries. To address this, we\npropose an information separation framework that disentangles these features,\nsignificantly improving the performance of both SSL models and LLMs in\ndepression detection. Our experiments validate this finding and demonstrate\nthat the integration of separated features yields substantial improvements over\nexisting approaches, providing new insights for developing more effective\nmulti-modal depression detection systems.", "published": "2025-03-09 13:45:21", "link": "http://arxiv.org/abs/2503.06620v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Heterogeneous bimodal attention fusion for speech emotion recognition", "abstract": "Multi-modal emotion recognition in conversations is a challenging problem due\nto the complex and complementary interactions between different modalities.\nAudio and textual cues are particularly important for understanding emotions\nfrom a human perspective. Most existing studies focus on exploring interactions\nbetween audio and text modalities at the same representation level. However, a\ncritical issue is often overlooked: the heterogeneous modality gap between\nlow-level audio representations and high-level text representations. To address\nthis problem, we propose a novel framework called Heterogeneous Bimodal\nAttention Fusion (HBAF) for multi-level multi-modal interaction in\nconversational emotion recognition. The proposed method comprises three key\nmodules: the uni-modal representation module, the multi-modal fusion module,\nand the inter-modal contrastive learning module. The uni-modal representation\nmodule incorporates contextual content into low-level audio representations to\nbridge the heterogeneous multi-modal gap, enabling more effective fusion. The\nmulti-modal fusion module uses dynamic bimodal attention and a dynamic gating\nmechanism to filter incorrect cross-modal relationships and fully exploit both\nintra-modal and inter-modal interactions. Finally, the inter-modal contrastive\nlearning module captures complex absolute and relative interactions between\naudio and text modalities. Experiments on the MELD and IEMOCAP datasets\ndemonstrate that the proposed HBAF method outperforms existing state-of-the-art\nbaselines.", "published": "2025-03-09 02:50:49", "link": "http://arxiv.org/abs/2503.06405v3", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ProSE: Diffusion Priors for Speech Enhancement", "abstract": "Speech enhancement (SE) is the foundational task of enhancing the clarity and\nquality of speech in the presence of non-stationary additive noise. While\ndeterministic deep learning models have been commonly employed for SE, recent\nresearch indicates that generative models, such as denoising diffusion\nprobabilistic models (DDPMs), have shown promise. However, unlike speech\ngeneration, SE has a strong constraint in generating results in accordance with\nthe underlying ground-truth signal. Additionally, for a wide variety of\napplications, SE systems need to be employed in real-time, and traditional\ndiffusion models (DMs) requiring many iterations of a large model during\ninference are inefficient. To address these issues, we propose ProSE\n(diffusion-based Priors for SE), a novel methodology based on an alternative\nframework for applying diffusion models to SE. Specifically, we first apply\nDDPMs to generate priors in a latent space due to their powerful distribution\nmapping capabilities. The priors are then integrated into a transformer-based\nregression model for SE. The priors guide the regression model in the\nenhancement process. Since the diffusion process is applied to a compact latent\nspace, the diffusion model takes fewer iterations than the traditional DM to\nobtain accurate estimations. Additionally, using a regression model for SE\navoids the distortion issue caused by misaligned details generated by DMs. Our\nexperiments show that ProSE achieves state-of-the-art performance on benchmark\ndatasets with fewer computational costs.", "published": "2025-03-09 00:59:39", "link": "http://arxiv.org/abs/2503.06375v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Adaptive Audio-Visual Speech Recognition via Matryoshka-Based Multimodal LLMs", "abstract": "Audio-Visual Speech Recognition (AVSR) leverages both audio and visual\nmodalities to enhance speech recognition robustness, particularly in noisy\nenvironments. Recent advancements in Large Language Models (LLMs) have\ndemonstrated their effectiveness in speech recognition, including AVSR.\nHowever, due to the significant length of speech representations, direct\nintegration with LLMs imposes substantial computational costs. Prior approaches\naddress this by compressing speech representations before feeding them into\nLLMs. However, higher compression ratios often lead to performance degradation,\nnecessitating a trade-off between computational efficiency and recognition\naccuracy. To address this challenge, we propose Llama-MTSK, the first\nMatryoshka-based Multimodal LLM for AVSR, which enables flexible adaptation of\nthe audio-visual token allocation based on specific computational constraints\nwhile preserving high performance. Our approach, inspired by Matryoshka\nRepresentation Learning, encodes audio-visual representations at multiple\ngranularities within a single model, eliminating the need to train separate\nmodels for different compression levels. Moreover, to efficiently fine-tune the\nLLM, we introduce three LoRA-based Matryoshka strategies using global and\nscale-specific LoRA modules. Extensive evaluations on the two largest AVSR\ndatasets demonstrate that Llama-MTSK achieves state-of-the-art results,\nmatching or surpassing models trained independently at fixed compression\nlevels.", "published": "2025-03-09 00:02:10", "link": "http://arxiv.org/abs/2503.06362v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
