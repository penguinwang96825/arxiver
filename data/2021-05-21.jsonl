{"title": "Boosting Span-based Joint Entity and Relation Extraction via Squence\n  Tagging Mechanism", "abstract": "Span-based joint extraction simultaneously conducts named entity recognition\n(NER) and relation extraction (RE) in text span form. Recent studies have shown\nthat token labels can convey crucial task-specific information and enrich token\nsemantics. However, as far as we know, due to completely abstain from sequence\ntagging mechanism, all prior span-based work fails to use token label\nin-formation. To solve this problem, we pro-pose Sequence Tagging enhanced\nSpan-based Network (STSN), a span-based joint extrac-tion network that is\nenhanced by token BIO label information derived from sequence tag-ging based\nNER. By stacking multiple atten-tion layers in depth, we design a deep neu-ral\narchitecture to build STSN, and each atten-tion layer consists of three basic\nattention units. The deep neural architecture first learns seman-tic\nrepresentations for token labels and span-based joint extraction, and then\nconstructs in-formation interactions between them, which also realizes\nbidirectional information interac-tions between span-based NER and RE.\nFur-thermore, we extend the BIO tagging scheme to make STSN can extract\noverlapping en-tity. Experiments on three benchmark datasets show that our\nmodel consistently outperforms previous optimal models by a large margin,\ncreating new state-of-the-art results.", "published": "2021-05-21 01:10:03", "link": "http://arxiv.org/abs/2105.10080v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training Bi-Encoders for Word Sense Disambiguation", "abstract": "Modern transformer-based neural architectures yield impressive results in\nnearly every NLP task and Word Sense Disambiguation, the problem of discerning\nthe correct sense of a word in a given context, is no exception.\nState-of-the-art approaches in WSD today leverage lexical information along\nwith pre-trained embeddings from these models to achieve results comparable to\nhuman inter-annotator agreement on standard evaluation benchmarks. In the same\nvein, we experiment with several strategies to optimize bi-encoders for this\nspecific task and propose alternative methods of presenting lexical information\nto our model. Through our multi-stage pre-training and fine-tuning pipeline we\nfurther the state of the art in Word Sense Disambiguation.", "published": "2021-05-21 06:06:03", "link": "http://arxiv.org/abs/2105.10146v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Should We Trust This Summary? Bayesian Abstractive Summarization to The\n  Rescue", "abstract": "We explore the notion of uncertainty in the context of modern abstractive\nsummarization models, using the tools of Bayesian Deep Learning. Our approach\napproximates Bayesian inference by first extending state-of-the-art\nsummarization models with Monte Carlo dropout and then using them to perform\nmultiple stochastic forward passes. Based on Bayesian inference we are able to\neffectively quantify uncertainty at prediction time. Having a reliable\nuncertainty measure, we can improve the experience of the end user by filtering\nout generated summaries of high uncertainty. Furthermore, uncertainty\nestimation could be used as a criterion for selecting samples for annotation,\nand can be paired nicely with active learning and human-in-the-loop approaches.\nFinally, Bayesian inference enables us to find a Bayesian summary which\nperforms better than a deterministic one and is more robust to uncertainty. In\npractice, we show that our Variational Bayesian equivalents of BART and PEGASUS\ncan outperform their deterministic counterparts on multiple benchmark datasets.", "published": "2021-05-21 06:36:40", "link": "http://arxiv.org/abs/2105.10155v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Representation for Dialogue Modeling", "abstract": "Although neural models have achieved competitive results in dialogue systems,\nthey have shown limited ability in representing core semantics, such as\nignoring important entities. To this end, we exploit Abstract Meaning\nRepresentation (AMR) to help dialogue modeling. Compared with the textual\ninput, AMR explicitly provides core semantic knowledge and reduces data\nsparsity. We develop an algorithm to construct dialogue-level AMR graphs from\nsentence-level AMRs and explore two ways to incorporate AMRs into dialogue\nsystems. Experimental results on both dialogue understanding and response\ngeneration tasks show the superiority of our model. To our knowledge, we are\nthe first to leverage a formal semantic representation into neural dialogue\nmodeling.", "published": "2021-05-21 07:55:07", "link": "http://arxiv.org/abs/2105.10188v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from My Friends: Few-Shot Personalized Conversation Systems via\n  Social Networks", "abstract": "Personalized conversation models (PCMs) generate responses according to\nspeaker preferences. Existing personalized conversation tasks typically require\nmodels to extract speaker preferences from user descriptions or their\nconversation histories, which are scarce for newcomers and inactive users. In\nthis paper, we propose a few-shot personalized conversation task with an\nauxiliary social network. The task requires models to generate personalized\nresponses for a speaker given a few conversations from the speaker and a social\nnetwork. Existing methods are mainly designed to incorporate descriptions or\nconversation histories. Those methods can hardly model speakers with so few\nconversations or connections between speakers. To better cater for newcomers\nwith few resources, we propose a personalized conversation model (PCM) that\nlearns to adapt to new speakers as well as enabling new speakers to learn from\nresource-rich speakers. Particularly, based on a meta-learning based PCM, we\npropose a task aggregator (TA) to collect other speakers' information from the\nsocial network. The TA provides prior knowledge of the new speaker in its\nmeta-learning. Experimental results show our methods outperform all baselines\nin appropriateness, diversity, and consistency with speakers.", "published": "2021-05-21 12:54:50", "link": "http://arxiv.org/abs/2105.10323v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Multilingual Sentence Embeddings for Parallel Corpus Mining", "abstract": "Existing models of multilingual sentence embeddings require large parallel\ndata resources which are not available for low-resource languages. We propose a\nnovel unsupervised method to derive multilingual sentence embeddings relying\nonly on monolingual data. We first produce a synthetic parallel corpus using\nunsupervised machine translation, and use it to fine-tune a pretrained\ncross-lingual masked language model (XLM) to derive the multilingual sentence\nrepresentations. The quality of the representations is evaluated on two\nparallel corpus mining tasks with improvements of up to 22 F1 points over\nvanilla XLM. In addition, we observe that a single synthetic bilingual corpus\nis able to improve results for other language pairs.", "published": "2021-05-21 15:39:16", "link": "http://arxiv.org/abs/2105.10419v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynaboard: An Evaluation-As-A-Service Platform for Holistic\n  Next-Generation Benchmarking", "abstract": "We introduce Dynaboard, an evaluation-as-a-service framework for hosting\nbenchmarks and conducting holistic model comparison, integrated with the\nDynabench platform. Our platform evaluates NLP models directly instead of\nrelying on self-reported metrics or predictions on a single dataset. Under this\nparadigm, models are submitted to be evaluated in the cloud, circumventing the\nissues of reproducibility, accessibility, and backwards compatibility that\noften hinder benchmarking in NLP. This allows users to interact with uploaded\nmodels in real time to assess their quality, and permits the collection of\nadditional metrics such as memory use, throughput, and robustness, which --\ndespite their importance to practitioners -- have traditionally been absent\nfrom leaderboards. On each task, models are ranked according to the Dynascore,\na novel utility-based aggregation of these statistics, which users can\ncustomize to better reflect their preferences, placing more/less weight on a\nparticular axis of evaluation or dataset. As state-of-the-art NLP models push\nthe limits of traditional benchmarks, Dynaboard offers a standardized solution\nfor a more diverse and comprehensive evaluation of model quality.", "published": "2021-05-21 01:17:52", "link": "http://arxiv.org/abs/2106.06052v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Automatic Comparison of Data Privacy Documents: A Preliminary\n  Experiment on GDPR-like Laws", "abstract": "General Data Protection Regulation (GDPR) becomes a standard law for data\nprotection in many countries. Currently, twelve countries adopt the regulation\nand establish their GDPR-like regulation. However, to evaluate the differences\nand similarities of these GDPR-like regulations is time-consuming and needs a\nlot of manual effort from legal experts. Moreover, GDPR-like regulations from\ndifferent countries are written in their languages leading to a more difficult\ntask since legal experts who know both languages are essential. In this paper,\nwe investigate a simple natural language processing (NLP) approach to tackle\nthe problem. We first extract chunks of information from GDPR-like documents\nand form structured data from natural language. Next, we use NLP methods to\ncompare documents to measure their similarity. Finally, we manually label a\nsmall set of data to evaluate our approach. The empirical result shows that the\nBERT model with cosine similarity outperforms other baselines. Our data and\ncode are publicly available.", "published": "2021-05-21 03:59:29", "link": "http://arxiv.org/abs/2105.10117v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Revisiting the Negative Data of Distantly Supervised Relation Extraction", "abstract": "Distantly supervision automatically generates plenty of training samples for\nrelation extraction. However, it also incurs two major problems: noisy labels\nand imbalanced training data. Previous works focus more on reducing wrongly\nlabeled relations (false positives) while few explore the missing relations\nthat are caused by incompleteness of knowledge base (false negatives).\nFurthermore, the quantity of negative labels overwhelmingly surpasses the\npositive ones in previous problem formulations. In this paper, we first provide\na thorough analysis of the above challenges caused by negative data. Next, we\nformulate the problem of relation extraction into as a positive unlabeled\nlearning task to alleviate false negative problem. Thirdly, we propose a\npipeline approach, dubbed \\textsc{ReRe}, that performs sentence-level relation\ndetection then subject/object extraction to achieve sample-efficient training.\nExperimental results show that the proposed method consistently outperforms\nexisting approaches and remains excellent performance even learned with a large\nquantity of false positive samples.", "published": "2021-05-21 06:44:19", "link": "http://arxiv.org/abs/2105.10158v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Non-Linear Structural Probe", "abstract": "Probes are models devised to investigate the encoding of knowledge -- e.g.\nsyntactic structure -- in contextual representations. Probes are often designed\nfor simplicity, which has led to restrictions on probe design that may not\nallow for the full exploitation of the structure of encoded information; one\nsuch restriction is linearity. We examine the case of a structural probe\n(Hewitt and Manning, 2019), which aims to investigate the encoding of syntactic\nstructure in contextual representations through learning only linear\ntransformations. By observing that the structural probe learns a metric, we are\nable to kernelize it and develop a novel non-linear variant with an identical\nnumber of parameters. We test on 6 languages and find that the radial-basis\nfunction (RBF) kernel, in conjunction with regularization, achieves a\nstatistically significant improvement over the baseline in all languages --\nimplying that at least part of the syntactic knowledge is encoded non-linearly.\nWe conclude by discussing how the RBF kernel resembles BERT's self-attention\nlayers and speculate that this resemblance leads to the RBF-based probe's\nstronger performance.", "published": "2021-05-21 07:53:10", "link": "http://arxiv.org/abs/2105.10185v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rule Augmented Unsupervised Constituency Parsing", "abstract": "Recently, unsupervised parsing of syntactic trees has gained considerable\nattention. A prototypical approach to such unsupervised parsing employs\nreinforcement learning and auto-encoders. However, no mechanism ensures that\nthe learnt model leverages the well-understood language grammar. We propose an\napproach that utilizes very generic linguistic knowledge of the language\npresent in the form of syntactic rules, thus inducing better syntactic\nstructures. We introduce a novel formulation that takes advantage of the\nsyntactic grammar rules and is independent of the base system. We achieve new\nstate-of-the-art results on two benchmarks datasets, MNLI and WSJ. The source\ncode of the paper is available at https://github.com/anshuln/Diora_with_rules.", "published": "2021-05-21 08:06:11", "link": "http://arxiv.org/abs/2105.10193v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pretrained Language Models for Text Generation: A Survey", "abstract": "Text generation has become one of the most important yet challenging tasks in\nnatural language processing (NLP). The resurgence of deep learning has greatly\nadvanced this field by neural generation models, especially the paradigm of\npretrained language models (PLMs). In this paper, we present an overview of the\nmajor advances achieved in the topic of PLMs for text generation. As the\npreliminaries, we present the general task definition and briefly describe the\nmainstream architectures of PLMs for text generation. As the core content, we\ndiscuss how to adapt existing PLMs to model different input data and satisfy\nspecial properties in the generated text. We further summarize several\nimportant fine-tuning strategies for text generation. Finally, we present\nseveral future directions and conclude this paper. Our survey aims to provide\ntext generation researchers a synthesis and pointer to related research.", "published": "2021-05-21 12:27:44", "link": "http://arxiv.org/abs/2105.10311v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fact-driven Logical Reasoning for Machine Reading Comprehension", "abstract": "Recent years have witnessed an increasing interest in training machines with\nreasoning ability, which deeply relies on accurately and clearly presented clue\nforms. The clues are usually modeled as entity-aware knowledge in existing\nstudies. However, those entity-aware clues are primarily focused on\ncommonsense, making them insufficient for tasks that require knowledge of\ntemporary facts or events, particularly in logical reasoning for reading\ncomprehension. To address this challenge, we are motivated to cover both\ncommonsense and temporary knowledge clues hierarchically. Specifically, we\npropose a general formalism of knowledge units by extracting backbone\nconstituents of the sentence, such as the subject-verb-object formed ``facts''.\nWe then construct a supergraph on top of the fact units, allowing for the\nbenefit of sentence-level (relations among fact groups) and entity-level\ninteractions (concepts or actions inside a fact). Experimental results on\nlogical reasoning benchmarks and dialogue modeling datasets show that our\napproach improves the baselines substantially, and it is general across\nbackbone models. Code is available at\n\\url{https://github.com/ozyyshr/FocalReasoner}.", "published": "2021-05-21 13:11:13", "link": "http://arxiv.org/abs/2105.10334v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Functionals in the Clouds: An abstract architecture of serverless\n  Cloud-Native Apps", "abstract": "Cloud Native Application CNApp (as a distributed system) is a collection of\nindependent components (micro-services) interacting via communication\nprotocols. This gives rise to present an abstract architecture of CNApp as\ndynamically re-configurable acyclic directed multi graph where vertices are\nmicroservices, and edges are the protocols. Generic mechanisms for such\nreconfigurations evidently correspond to higher-level functions (functionals).\nThis implies also internal abstract architecture of microservice as a\ncollection of event-triggered serverless functions (including functions\nimplementing the protocols) that are dynamically composed into event-dependent\ndata-flow graphs. Again, generic mechanisms for such compositions correspond to\ncalculus of functionals and relations.", "published": "2021-05-21 15:28:49", "link": "http://arxiv.org/abs/2105.10362v5", "categories": ["cs.CL", "cs.LO", "68M14", "F.4.3; F.1.1"], "primary_category": "cs.CL"}
{"title": "Language Understanding for Field and Service Robots in a Priori Unknown\n  Environments", "abstract": "Contemporary approaches to perception, planning, estimation, and control have\nallowed robots to operate robustly as our remote surrogates in uncertain,\nunstructured environments. This progress now creates an opportunity for robots\nto operate not only in isolation, but also with and alongside humans in our\ncomplex environments. Realizing this opportunity requires an efficient and\nflexible medium through which humans can communicate with collaborative robots.\nNatural language provides one such medium, and through significant progress in\nstatistical methods for natural-language understanding, robots are now able to\ninterpret a diverse array of free-form commands. However, most contemporary\napproaches require a detailed, prior spatial-semantic map of the robot's\nenvironment that models the space of possible referents of an utterance.\nConsequently, these methods fail when robots are deployed in new, previously\nunknown, or partially-observed environments, particularly when mental models of\nthe environment differ between the human operator and the robot. This paper\nprovides a comprehensive description of a novel learning framework that allows\nfield and service robots to interpret and correctly execute natural-language\ninstructions in a priori unknown, unstructured environments. Integral to our\napproach is its use of language as a \"sensor\" -- inferring spatial,\ntopological, and semantic information implicit in the utterance and then\nexploiting this information to learn a distribution over a latent environment\nmodel. We incorporate this distribution in a probabilistic, language grounding\nmodel and infer a distribution over a symbolic representation of the robot's\naction space. We use imitation learning to identify a belief-space policy that\nreasons over the environment and behavior distributions. We evaluate our\nframework through a variety navigation and mobile-manipulation experiments.", "published": "2021-05-21 15:13:05", "link": "http://arxiv.org/abs/2105.10396v2", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "CEREC: A Corpus for Entity Resolution in Email Conversations", "abstract": "We present the first large scale corpus for entity resolution in email\nconversations (CEREC). The corpus consists of 6001 email threads from the Enron\nEmail Corpus containing 36,448 email messages and 60,383 entity coreference\nchains. The annotation is carried out as a two-step process with minimal manual\neffort. Experiments are carried out for evaluating different features and\nperformance of four baselines on the created corpus. For the task of mention\nidentification and coreference resolution, a best performance of 59.2 F1 is\nreported, highlighting the room for improvement. An in-depth qualitative and\nquantitative error analysis is presented to understand the limitations of the\nbaselines considered.", "published": "2021-05-21 23:40:12", "link": "http://arxiv.org/abs/2105.10606v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Have you tried Neural Topic Models? Comparative Analysis of Neural and\n  Non-Neural Topic Models with Application to COVID-19 Twitter Data", "abstract": "Topic models are widely used in studying social phenomena. We conduct a\ncomparative study examining state-of-the-art neural versus non-neural topic\nmodels, performing a rigorous quantitative and qualitative assessment on a\ndataset of tweets about the COVID-19 pandemic. Our results show that not only\ndo neural topic models outperform their classical counterparts on standard\nevaluation metrics, but they also produce more coherent topics, which are of\ngreat benefit when studying complex social problems. We also propose a novel\nregularization term for neural topic models, which is designed to address the\nwell-documented problem of mode collapse, and demonstrate its effectiveness.", "published": "2021-05-21 07:24:09", "link": "http://arxiv.org/abs/2105.10165v1", "categories": ["cs.CL", "cs.CY", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Measuring the impact of spammers on e-mail and Twitter networks", "abstract": "This paper investigates the research question if senders of large amounts of\nirrelevant or unsolicited information - commonly called \"spammers\" - distort\nthe network structure of social networks. Two large social networks are\nanalyzed, the first extracted from the Twitter discourse about a big\ntelecommunication company, and the second obtained from three years of email\ncommunication of 200 managers working for a large multinational company. This\nwork compares network robustness and the stability of centrality and\ninteraction metrics, as well as the use of language, after removing spammers\nand the most and least connected nodes. The results show that spammers do not\nsignificantly alter the structure of the information-carrying network, for most\nof the social indicators. The authors additionally investigate the correlation\nbetween e-mail subject line and content by tracking language sentiment,\nemotionality, and complexity, addressing the cases where collecting email\nbodies is not permitted for privacy reasons. The findings extend the research\nabout robustness and stability of social networks metrics, after the\napplication of graph simplification strategies. The results have practical\nimplication for network analysts and for those company managers who rely on\nnetwork analytics (applied to company emails and social media data) to support\ntheir decision-making processes.", "published": "2021-05-21 10:13:11", "link": "http://arxiv.org/abs/2105.10256v1", "categories": ["cs.SI", "cs.CL", "cs.IR", "I.2.7; J.4; H.4.0; H.3.0"], "primary_category": "cs.SI"}
{"title": "Towards a Universal NLG for Dialogue Systems and Simulators with Future\n  Bridging", "abstract": "In a dialogue system pipeline, a natural language generation (NLG) unit\nconverts the dialogue direction and content to a corresponding natural language\nrealization. A recent trend for dialogue systems is to first pre-train on large\ndatasets and then fine-tune in a supervised manner using datasets annotated\nwith application-specific features. Though novel behaviours can be learned from\ncustom annotation, the required effort severely bounds the quantity of the\ntraining set, and the application-specific nature limits the reuse. In light of\nthe recent success of data-driven approaches, we propose the novel future\nbridging NLG (FBNLG) concept for dialogue systems and simulators. The critical\nstep is for an FBNLG to accept a future user or system utterance to bridge the\npresent context towards. Future bridging enables self supervised training over\nannotation-free datasets, decoupled the training of NLG from the rest of the\nsystem. An FBNLG, pre-trained with massive datasets, is expected to apply in\nclassical or new dialogue scenarios with minimal adaptation effort. We evaluate\na prototype FBNLG to show that future bridging can be a viable approach to a\nuniversal few-shot NLG for task-oriented and chit-chat dialogues.", "published": "2021-05-21 10:37:10", "link": "http://arxiv.org/abs/2105.10267v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Multi-Target Domain Adaptation for Acoustic Scene\n  Classification", "abstract": "It is well known that the mismatch between training (source) and test\n(target) data distribution will significantly decrease the performance of\nacoustic scene classification (ASC) systems. To address this issue, domain\nadaptation (DA) is one solution and many unsupervised DA methods have been\nproposed. These methods focus on a scenario of single source domain to single\ntarget domain. However, we will face such problem that test data comes from\nmultiple target domains. This problem can be addressed by producing one model\nper target domain, but this solution is too costly. In this paper, we propose a\nnovel unsupervised multi-target domain adaption (MTDA) method for ASC, which\ncan adapt to multiple target domains simultaneously and make use of the\nunderlying relation among multiple domains. Specifically, our approach combines\ntraditional adversarial adaptation with two novel discriminator tasks that\nlearns a common subspace shared by all domains. Furthermore, we propose to\ndivide the target domain into the easy-to-adapt and hard-to-adapt domain, which\nenables the system to pay more attention to hard-to-adapt domain in training.\nThe experimental results on the DCASE 2020 Task 1-A dataset and the DCASE 2019\nTask 1-B dataset show that our proposed method significantly outperforms the\nprevious unsupervised DA methods.", "published": "2021-05-21 13:30:31", "link": "http://arxiv.org/abs/2105.10340v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LoopNet: Musical Loop Synthesis Conditioned On Intuitive Musical\n  Parameters", "abstract": "Loops, seamlessly repeatable musical segments, are a cornerstone of modern\nmusic production. Contemporary artists often mix and match various sampled or\npre-recorded loops based on musical criteria such as rhythm, harmony and\ntimbral texture to create compositions. Taking such criteria into account, we\npresent LoopNet, a feed-forward generative model for creating loops conditioned\non intuitive parameters. We leverage Music Information Retrieval (MIR) models\nas well as a large collection of public loop samples in our study and use the\nWave-U-Net architecture to map control parameters to audio. We also evaluate\nthe quality of the generated audio and propose intuitive controls for composers\nto map the ideas in their minds to an audio loop.", "published": "2021-05-21 14:24:34", "link": "http://arxiv.org/abs/2105.10371v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Semi-Supervised Audio Representation Learning for Modeling Beehive\n  Strengths", "abstract": "Honey bees are critical to our ecosystem and food security as a pollinator,\ncontributing 35% of our global agriculture yield. In spite of their importance,\nbeekeeping is exclusively dependent on human labor and experience-derived\nheuristics, while requiring frequent human checkups to ensure the colony is\nhealthy, which can disrupt the colony. Increasingly, pollinator populations are\ndeclining due to threats from climate change, pests, environmental toxicity,\nmaking their management even more critical than ever before in order to ensure\nsustained global food security. To start addressing this pressing challenge, we\ndeveloped an integrated hardware sensing system for beehive monitoring through\naudio and environment measurements, and a hierarchical semi-supervised deep\nlearning model, composed of an audio modeling module and a predictor, to model\nthe strength of beehives. The model is trained jointly on audio reconstruction\nand prediction losses based on human inspections, in order to model both\nlow-level audio features and circadian temporal dynamics. We show that this\nmodel performs well despite limited labels, and can learn an audio embedding\nthat is useful for characterizing different sound profiles of beehives. This is\nthe first instance to our knowledge of applying audio-based deep learning to\nmodel beehives and population size in an observational setting across a large\nnumber of hives.", "published": "2021-05-21 18:59:29", "link": "http://arxiv.org/abs/2105.10536v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
