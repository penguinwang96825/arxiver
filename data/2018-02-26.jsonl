{"title": "Did You Really Just Have a Heart Attack? Towards Robust Detection of\n  Personal Health Mentions in Social Media", "abstract": "Millions of users share their experiences on social media sites, such as\nTwitter, which in turn generate valuable data for public health monitoring,\ndigital epidemiology, and other analyses of population health at global scale.\nThe first, critical, task for these applications is classifying whether a\npersonal health event was mentioned, which we call the (PHM) problem. This task\nis challenging for many reasons, including typically short length of social\nmedia posts, inventive spelling and lexicons, and figurative language,\nincluding hyperbole using diseases like \"heart attack\" or \"cancer\" for\nemphasis, and not as a health self-report. This problem is even more\nchallenging for rarely reported, or frequent but ambiguously expressed\nconditions, such as \"stroke\". To address this problem, we propose a general,\nrobust method for detecting PHMs in social media, which we call WESPAD, that\ncombines lexical, syntactic, word embedding-based, and context-based features.\nWESPAD is able to generalize from few examples by automatically distorting the\nword embedding space to most effectively detect the true health mentions.\nUnlike previously proposed state-of-the-art supervised and deep-learning\ntechniques, WESPAD requires relatively little training data, which makes it\npossible to adapt, with minimal effort, to each new disease and condition. We\nevaluate WESPAD on both an established publicly available Flu detection\nbenchmark, and on a new dataset that we have constructed with mentions of\nmultiple health conditions. Our experiments show that WESPAD outperforms the\nbaselines and state-of-the-art methods, especially in cases when the number and\nproportion of true health mentions in the training data is small.", "published": "2018-02-26 02:08:28", "link": "http://arxiv.org/abs/1802.09130v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Distribution Prediction based on Batch Markov Monte Carlo\n  Simulation with Migration", "abstract": "Language spreading is a complex mechanism that involves issues like culture,\neconomics, migration, population etc. In this paper, we propose a set of\nmethods to model the dynamics of the spreading system. To model the randomness\nof language spreading, we propose the Batch Markov Monte Carlo Simulation with\nMigration(BMMCSM) algorithm, in which each agent is treated as a language\nstack. The agent learns languages and migrates based on the proposed Batch\nMarkov Property according to the transition matrix T and migration matrix M.\nSince population plays a crucial role in language spreading, we also introduce\nthe Mortality and Fertility Mechanism, which controls the birth and death of\nthe simulated agents, into the BMMCSM algorithm. The simulation results of\nBMMCSM show that the numerical and geographic distribution of languages varies\nacross the time. The change of distribution fits the world cultural and\neconomic development trend. Next, when we construct Matrix T, there are some\nentries of T can be directly calculated from historical statistics while some\nentries of T is unknown. Thus, the key to the success of the BMMCSM lies in the\naccurate estimation of transition matrix T by estimating the unknown entries of\nT under the supervision of the known entries. To achieve this, we first\nconstruct a 20 by 20 by 5 factor tensor X to characterize each entry of T. Then\nwe train a Random Forest Regressor on the known entries of T and use the\ntrained regressor to predict the unknown entries. The reason why we choose\nRandom Forest(RF) is that, compared to Single Decision Tree, it conquers the\nproblem of over fitting and the Shapiro test also suggests that the residual of\nRF subjects to the Normal distribution.", "published": "2018-02-26 07:52:30", "link": "http://arxiv.org/abs/1802.09189v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Feed-forward Sequential Memory Networks for Speech Synthesis", "abstract": "The Bidirectional LSTM (BLSTM) RNN based speech synthesis system is among the\nbest parametric Text-to-Speech (TTS) systems in terms of the naturalness of\ngenerated speech, especially the naturalness in prosody. However, the model\ncomplexity and inference cost of BLSTM prevents its usage in many runtime\napplications. Meanwhile, Deep Feed-forward Sequential Memory Networks (DFSMN)\nhas shown its consistent out-performance over BLSTM in both word error rate\n(WER) and the runtime computation cost in speech recognition tasks. Since\nspeech synthesis also requires to model long-term dependencies compared to\nspeech recognition, in this paper, we investigate the Deep-FSMN (DFSMN) in\nspeech synthesis. Both objective and subjective experiments show that, compared\nwith BLSTM TTS method, the DFSMN system can generate synthesized speech with\ncomparable speech quality while drastically reduce model complexity and speech\ngeneration time.", "published": "2018-02-26 08:21:26", "link": "http://arxiv.org/abs/1802.09194v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EiTAKA at SemEval-2018 Task 1: An Ensemble of N-Channels ConvNet and\n  XGboost Regressors for Emotion Analysis of Tweets", "abstract": "This paper describes our system that has been used in Task1 Affect in Tweets.\nWe combine two different approaches. The first one called N-Stream ConvNets,\nwhich is a deep learning approach where the second one is XGboost regresseor\nbased on a set of embedding and lexicons based features. Our system was\nevaluated on the testing sets of the tasks outperforming all other approaches\nfor the Arabic version of valence intensity regression task and valence ordinal\nclassification task.", "published": "2018-02-26 10:20:09", "link": "http://arxiv.org/abs/1802.09233v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Aware Spoken Language Translation Applied to English-Arabic", "abstract": "Spoken Language Translation (SLT) is becoming more widely used and becoming a\ncommunication tool that helps in crossing language barriers. One of the\nchallenges of SLT is the translation from a language without gender agreement\nto a language with gender agreement such as English to Arabic. In this paper,\nwe introduce an approach to tackle such limitation by enabling a Neural Machine\nTranslation system to produce gender-aware translation. We show that NMT system\ncan model the speaker/listener gender information to produce gender-aware\ntranslation. We propose a method to generate data used in adapting a NMT system\nto produce gender-aware. The proposed approach can achieve significant\nimprovement of the translation quality by 2 BLEU points.", "published": "2018-02-26 13:26:43", "link": "http://arxiv.org/abs/1802.09287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Quality Type-aware Annotated Corpus and Lexicon for Harassment\n  Research", "abstract": "Having a quality annotated corpus is essential especially for applied\nresearch. Despite the recent focus of Web science community on researching\nabout cyberbullying, the community dose not still have standard benchmarks. In\nthis paper, we publish first, a quality annotated corpus and second, an\noffensive words lexicon capturing different types type of harassment as (i)\nsexual harassment, (ii) racial harassment, (iii) appearance-related harassment,\n(iv) intellectual harassment, and (v) political harassment.We crawled data from\nTwitter using our offensive lexicon. Then relied on the human judge to annotate\nthe collected tweets w.r.t. the contextual types because using offensive words\nis not sufficient to reliably detect harassment. Our corpus consists of 25,000\nannotated tweets in five contextual types. We are pleased to share this novel\nannotated corpus and the lexicon with the research community. The instruction\nto acquire the corpus has been published on the Git repository.", "published": "2018-02-26 15:59:22", "link": "http://arxiv.org/abs/1802.09416v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMUSE: Multilingual Semantic Parsing for Question Answering over Linked\n  Data", "abstract": "The task of answering natural language questions over RDF data has received\nwide interest in recent years, in particular in the context of the series of\nQALD benchmarks. The task consists of mapping a natural language question to an\nexecutable form, e.g. SPARQL, so that answers from a given KB can be extracted.\nSo far, most systems proposed are i) monolingual and ii) rely on a set of\nhard-coded rules to interpret questions and map them into a SPARQL query. We\npresent the first multilingual QALD pipeline that induces a model from training\ndata for mapping a natural language question into logical form as probabilistic\ninference. In particular, our approach learns to map universal syntactic\ndependency representations to a language-independent logical form based on\nDUDES (Dependency-based Underspecified Discourse Representation Structures)\nthat are then mapped to a SPARQL query as a deterministic second step. Our\nmodel builds on factor graphs that rely on features extracted from the\ndependency graph and corresponding semantic representations. We rely on\napproximate inference techniques, Markov Chain Monte Carlo methods in\nparticular, as well as Sample Rank to update parameters using a ranking\nobjective. Our focus lies on developing methods that overcome the lexical gap\nand present a novel combination of machine translation and word embedding\napproaches for this purpose. As a proof of concept for our approach, we\nevaluate our approach on the QALD-6 datasets for English, German & Spanish.", "published": "2018-02-26 13:50:14", "link": "http://arxiv.org/abs/1802.09296v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Tone Biased MMR Text Summarization", "abstract": "Text summarization is an interesting area for researchers to develop new\ntechniques to provide human like summaries for vast amounts of information.\nSummarization techniques tend to focus on providing accurate representation of\ncontent, and often the tone of the content is ignored. Tone of the content sets\na baseline for how a reader perceives the content. As such being able to\ngenerate summary with tone that is appropriate for the reader is important. In\nour work we implement Maximal Marginal Relevance [MMR] based multi-document\ntext summarization and propose a naive model to change tone of the\nsummarization by setting a bias to specific set of words and restricting other\nwords in the summarization output. This bias towards a specified set of words\nproduces a summary whose tone is same as tone of specified words.", "published": "2018-02-26 16:12:40", "link": "http://arxiv.org/abs/1802.09426v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "The Development of Darwin's Origin of Species", "abstract": "From 1837, when he returned to England aboard the $\\textit{HMS Beagle}$, to\n1860, just after publication of $\\textit{The Origin of Species}$, Charles\nDarwin kept detailed notes of each book he read or wanted to read. His notes\nand manuscripts provide information about decades of individual scientific\npractice. Previously, we trained topic models on the full texts of each\nreading, and applied information-theoretic measures to detect that changes in\nhis reading patterns coincided with the boundaries of his three major\nintellectual projects in the period 1837-1860. In this new work we apply the\nreading model to five additional documents, four of them by Darwin: the first\nedition of $\\textit{The Origin of Species}$, two private essays stating\nintermediate forms of his theory in 1842 and 1844, a third essay of disputed\ndating, and Alfred Russel Wallace's essay, which Darwin received in 1858. We\naddress three historical inquiries, previously treated qualitatively: 1) the\nmythology of \"Darwin's Delay,\" that despite completing an extensive draft in\n1844, Darwin waited until 1859 to publish $\\textit{The Origin of Species}$ due\nto external pressures; 2) the relationship between Darwin and Wallace's\ncontemporaneous theories, especially in light of their joint presentation; and\n3) dating of the \"Outline and Draft\" which was rediscovered in 1975 and\npostulated first as an 1839 draft preceding the Sketch of 1842, then as an\ninterstitial draft between the 1842 and 1844 essays.", "published": "2018-02-26 16:22:14", "link": "http://arxiv.org/abs/1802.09944v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "A Fast Deep Learning Model for Textual Relevance in Biomedical\n  Information Retrieval", "abstract": "Publications in the life sciences are characterized by a large technical\nvocabulary, with many lexical and semantic variations for expressing the same\nconcept. Towards addressing the problem of relevance in biomedical literature\nsearch, we introduce a deep learning model for the relevance of a document's\ntext to a keyword style query. Limited by a relatively small amount of training\ndata, the model uses pre-trained word embeddings. With these, the model first\ncomputes a variable-length Delta matrix between the query and document,\nrepresenting a difference between the two texts, which is then passed through a\ndeep convolution stage followed by a deep feed-forward network to compute a\nrelevance score. This results in a fast model suitable for use in an online\nsearch engine. The model is robust and outperforms comparable state-of-the-art\ndeep learning approaches.", "published": "2018-02-26 21:43:23", "link": "http://arxiv.org/abs/1802.10078v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Data-Driven Source Separation Based on Simplex Analysis", "abstract": "Blind source separation (BSS) is addressed, using a novel data-driven\napproach, based on a well-established probabilistic model. The proposed method\nis specifically designed for separation of multichannel audio mixtures. The\nalgorithm relies on spectral decomposition of the correlation matrix between\ndifferent time frames. The probabilistic model implies that the column space of\nthe correlation matrix is spanned by the probabilities of the various speakers\nacross time. The number of speakers is recovered by the eigenvalue decay, and\nthe eigenvectors form a simplex of the speakers' probabilities. Time frames\ndominated by each of the speakers are identified exploiting convex geometry\ntools on the recovered simplex. The mixing acoustic channels are estimated\nutilizing the identified sets of frames, and a linear umixing is performed to\nextract the individual speakers. The derived simplexes are visually\ndemonstrated for mixtures of 2, 3 and 4 speakers. We also conduct a\ncomprehensive experimental study, showing high separation capabilities in\nvarious reverberation conditions.", "published": "2018-02-26 09:51:26", "link": "http://arxiv.org/abs/1802.09221v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
