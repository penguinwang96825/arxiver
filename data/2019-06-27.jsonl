{"title": "PKUSEG: A Toolkit for Multi-Domain Chinese Word Segmentation", "abstract": "Chinese word segmentation (CWS) is a fundamental step of Chinese natural\nlanguage processing. In this paper, we build a new toolkit, named PKUSEG, for\nmulti-domain word segmentation. Unlike existing single-model toolkits, PKUSEG\ntargets multi-domain word segmentation and provides separate models for\ndifferent domains, such as web, medicine, and tourism. Besides, due to the lack\nof labeled data in many domains, we propose a domain adaptation paradigm to\nintroduce cross-domain semantic knowledge via a translation system. Through\nthis method, we generate synthetic data using a large amount of unlabeled data\nin the target domain and then obtain a word segmentation model for the target\ndomain. We also further refine the performance of the default model with the\nhelp of synthetic data. Experiments show that PKUSEG achieves high performance\non multiple domains. The new toolkit also supports POS tagging and model\ntraining to adapt to various application scenarios. The toolkit is now freely\nand publicly available for the usage of research and industry.", "published": "2019-06-27 06:40:42", "link": "http://arxiv.org/abs/1906.11455v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Morphological Irregularity Correlates with Frequency", "abstract": "We present a study of morphological irregularity. Following recent work, we\ndefine an information-theoretic measure of irregularity based on the\npredictability of forms in a language. Using a neural transduction model, we\nestimate this quantity for the forms in 28 languages. We first present several\nvalidatory and exploratory analyses of irregularity. We then show that our\nanalyses provide evidence for a correlation between irregularity and frequency:\nhigher frequency items are more likely to be irregular and irregular items are\nmore likely be highly frequent. To our knowledge, this result is the first of\nits breadth and confirms longstanding proposals from the linguistics\nliterature. The correlation is more robust when aggregated at the level of\nwhole paradigms--providing support for models of linguistic structure in which\ninflected forms are unified by abstract underlying stems or lexemes. Code is\navailable at https://github.com/shijie-wu/neural-transducer.", "published": "2019-06-27 08:03:02", "link": "http://arxiv.org/abs/1906.11483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inducing Syntactic Trees from BERT Representations", "abstract": "We use the English model of BERT and explore how a deletion of one word in a\nsentence changes representations of other words. Our hypothesis is that\nremoving a reducible word (e.g. an adjective) does not affect the\nrepresentation of other words so much as removing e.g. the main verb, which\nmakes the sentence ungrammatical and of \"high surprise\" for the language model.\nWe estimate reducibilities of individual words and also of longer continuous\nphrases (word n-grams), study their syntax-related properties, and then also\nuse them to induce full dependency trees.", "published": "2019-06-27 09:05:32", "link": "http://arxiv.org/abs/1906.11511v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmotionX-KU: BERT-Max based Contextual Emotion Classifier", "abstract": "We propose a contextual emotion classifier based on a transferable language\nmodel and dynamic max pooling, which predicts the emotion of each utterance in\na dialogue. A representative emotion analysis task, EmotionX, requires to\nconsider contextual information from colloquial dialogues and to deal with a\nclass imbalance problem. To alleviate these problems, our model leverages the\nself-attention based transferable language model and the weighted cross entropy\nloss. Furthermore, we apply post-training and fine-tuning mechanisms to enhance\nthe domain adaptability of our model and utilize several machine learning\ntechniques to improve its performance. We conduct experiments on two\nemotion-labeled datasets named Friends and EmotionPush. As a result, our model\noutperforms the previous state-of-the-art model and also shows competitive\nperformance in the EmotionX 2019 challenge. The code will be available in the\nGithub page.", "published": "2019-06-27 11:46:48", "link": "http://arxiv.org/abs/1906.11565v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple Natural Language Processing Tools for Danish", "abstract": "This technical note describes a set of baseline tools for automatic\nprocessing of Danish text. The tools are machine-learning based, using natural\nlanguage processing models trained over previously annotated documents. They\nare maintained at ITU Copenhagen and will always be freely available.", "published": "2019-06-27 13:15:12", "link": "http://arxiv.org/abs/1906.11608v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compositional Semantic Parsing Across Graphbanks", "abstract": "Most semantic parsers that map sentences to graph-based meaning\nrepresentations are hand-designed for specific graphbanks. We present a\ncompositional neural semantic parser which achieves, for the first time,\ncompetitive accuracies across a diverse range of graphbanks. Incorporating BERT\nembeddings and multi-task learning improves the accuracy further, setting new\nstates of the art on DM, PAS, PSD, AMR 2015 and EDS.", "published": "2019-06-27 15:50:59", "link": "http://arxiv.org/abs/1906.11746v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Impact of Preprocessing on Arabic-English Statistical and Neural\n  Machine Translation", "abstract": "Neural networks have become the state-of-the-art approach for machine\ntranslation (MT) in many languages. While linguistically-motivated tokenization\ntechniques were shown to have significant effects on the performance of\nstatistical MT, it remains unclear if those techniques are well suited for\nneural MT. In this paper, we systematically compare neural and statistical MT\nmodels for Arabic-English translation on data preprecossed by various prominent\ntokenization schemes. Furthermore, we consider a range of data and vocabulary\nsizes and compare their effect on both approaches. Our empirical results show\nthat the best choice of tokenization scheme is largely based on the type of\nmodel and the size of data. We also show that we can gain significant\nimprovements using a system selection that combines the output from neural and\nstatistical MT.", "published": "2019-06-27 15:53:58", "link": "http://arxiv.org/abs/1906.11751v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relating Simple Sentence Representations in Deep Neural Networks and the\n  Brain", "abstract": "What is the relationship between sentence representations learned by deep\nrecurrent models against those encoded by the brain? Is there any\ncorrespondence between hidden layers of these recurrent models and brain\nregions when processing sentences? Can these deep models be used to synthesize\nbrain data which can then be utilized in other extrinsic tasks? We investigate\nthese questions using sentences with simple syntax and semantics (e.g., The\nbone was eaten by the dog.). We consider multiple neural network architectures,\nincluding recently proposed ELMo and BERT. We use magnetoencephalography (MEG)\nbrain recording data collected from human subjects when they were reading these\nsimple sentences.\n  Overall, we find that BERT's activations correlate the best with MEG brain\ndata. We also find that the deep network representation can be used to generate\nbrain data from new sentences to augment existing brain data.\n  To the best of our knowledge, this is the first work showing that the MEG\nbrain recording when reading a word in a sentence can be used to distinguish\nearlier words in the sentence. Our exploration is also the first to use deep\nneural network representations to generate synthetic brain data and to show\nthat it helps in improving subsequent stimuli decoding task accuracy.", "published": "2019-06-27 18:23:27", "link": "http://arxiv.org/abs/1906.11861v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training Models to Extract Treatment Plans from Clinical Notes Using\n  Contents of Sections with Headings", "abstract": "Objective: Using natural language processing (NLP) to find sentences that\nstate treatment plans in a clinical note, would automate plan extraction and\nwould further enable their use in tools that help providers and care managers.\nHowever, as in the most NLP tasks on clinical text, creating gold standard to\ntrain and test NLP models is tedious and expensive. Fortuitously, sometimes but\nnot always clinical notes contain sections with a heading that identifies the\nsection as a plan. Leveraging contents of such labeled sections as a noisy\ntraining data, we assessed accuracy of NLP models trained with the data.\n  Methods: We used common variations of plan headings and rule-based heuristics\nto find plan sections with headings in clinical notes, and we extracted\nsentences from them and formed a noisy training data of plan sentences. We\ntrained Support Vector Machine (SVM) and Convolutional Neural Network (CNN)\nmodels with the data. We measured accuracy of the trained models on the noisy\ndataset using ten-fold cross validation and separately on a set-aside manually\nannotated dataset.\n  Results: About 13% of 117,730 clinical notes contained treatment plans\nsections with recognizable headings in the 1001 longitudinal patient records\nthat were obtained from Cleveland Clinic under an IRB approval. We were able to\nextract and create a noisy training data of 13,492 plan sentences from the\nclinical notes. CNN achieved best F measures, 0.91 and 0.97 in the\ncross-validation and set-aside evaluation experiments respectively. SVM\nslightly underperformed with F measures of 0.89 and 0.96 in the same\nexperiments.\n  Conclusion: Our study showed that the training supervised learning models\nusing noisy plan sentences was effective in identifying them in all clinical\nnotes. More broadly, sections with informal headings in clinical notes can be a\ngood source for generating effective training data.", "published": "2019-06-27 19:40:09", "link": "http://arxiv.org/abs/1906.11930v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Findings of the First Shared Task on Machine Translation Robustness", "abstract": "We share the findings of the first shared task on improving robustness of\nMachine Translation (MT). The task provides a testbed representing challenges\nfacing MT models deployed in the real world, and facilitates new approaches to\nimprove models; robustness to noisy input and domain mismatch. We focus on two\nlanguage pairs (English-French and English-Japanese), and the submitted systems\nare evaluated on a blind test set consisting of noisy comments on Reddit and\nprofessionally sourced translations. As a new task, we received 23 submissions\nby 11 participating teams from universities, companies, national labs, etc. All\nsubmitted systems achieved large improvements over baselines, with the best\nimprovement having +22.33 BLEU. We evaluated submissions by both human judgment\nand automatic evaluation (BLEU), which shows high correlations (Pearson's r =\n0.94 and 0.95). Furthermore, we conducted a qualitative analysis of the\nsubmitted systems using compare-mt, which revealed their salient differences in\nhandling challenges in this task. Such analysis provides additional insights\nwhen there is occasional disagreement between human judgment and BLEU, e.g.\nsystems better at producing colloquial expressions received higher score from\nhuman judgment.", "published": "2019-06-27 20:24:55", "link": "http://arxiv.org/abs/1906.11943v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic expressive capacity with bounded memory", "abstract": "We investigate the capacity of mechanisms for compositional semantic parsing\nto describe relations between sentences and semantic representations.\n  We prove that in order to represent certain relations, mechanisms which are\nsyntactically projective must be able to remember an unbounded number of\nlocations in the semantic representations, where nonprojective mechanisms need\nnot.\n  This is the first result of this kind, and has consequences both for\ngrammar-based and for neural systems.", "published": "2019-06-27 15:54:57", "link": "http://arxiv.org/abs/1906.11752v1", "categories": ["cs.CL", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Lattice-Based Unsupervised Test-Time Adaptation of Neural Network\n  Acoustic Models", "abstract": "Acoustic model adaptation to unseen test recordings aims to reduce the\nmismatch between training and testing conditions. Most adaptation schemes for\nneural network models require the use of an initial one-best transcription for\nthe test data, generated by an unadapted model, in order to estimate the\nadaptation transform. It has been found that adaptation methods using\ndiscriminative objective functions - such as cross-entropy loss - often require\ncareful regularisation to avoid over-fitting to errors in the one-best\ntranscriptions. In this paper we solve this problem by performing\ndiscriminative adaptation using lattices obtained from a first pass decoding,\nan approach that can be readily integrated into the lattice-free maximum mutual\ninformation (LF-MMI) framework. We investigate this approach on three\ntranscription tasks of varying difficulty: TED talks, multi-genre broadcast\n(MGB) and a low-resource language (Somali). We find that our proposed approach\nenables many more parameters to be adapted without over-fitting being observed,\nand is successful even when the initial transcription has a WER in excess of\n50%.", "published": "2019-06-27 09:47:47", "link": "http://arxiv.org/abs/1906.11521v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Gated Embeddings in End-to-End Speech Recognition for\n  Conversational-Context Fusion", "abstract": "We present a novel conversational-context aware end-to-end speech recognizer\nbased on a gated neural network that incorporates\nconversational-context/word/speech embeddings. Unlike conventional speech\nrecognition models, our model learns longer conversational-context information\nthat spans across sentences and is consequently better at recognizing long\nconversations. Specifically, we propose to use the text-based external word\nand/or sentence embeddings (i.e., fastText, BERT) within an end-to-end\nframework, yielding a significant improvement in word error rate with better\nconversational-context representation. We evaluated the models on the\nSwitchboard conversational speech corpus and show that our model outperforms\nstandard end-to-end speech recognition models.", "published": "2019-06-27 13:10:37", "link": "http://arxiv.org/abs/1906.11604v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Encoding Database Schemas with Relation-Aware Self-Attention for\n  Text-to-SQL Parsers", "abstract": "When translating natural language questions into SQL queries to answer\nquestions from a database, we would like our methods to generalize to domains\nand database schemas outside of the training set. To handle complex questions\nand database schemas with a neural encoder-decoder paradigm, it is critical to\nproperly encode the schema as part of the input with the question. In this\npaper, we use relation-aware self-attention within the encoder so that it can\nreason about how the tables and columns in the provided schema relate to each\nother and use this information in interpreting the question. We achieve\nsignificant gains on the recently-released Spider dataset with 42.94% exact\nmatch accuracy, compared to the 18.96% reported in published work.", "published": "2019-06-27 16:52:29", "link": "http://arxiv.org/abs/1906.11790v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Re-annotation of cough events in the AMI corpus", "abstract": "Cough sounds act as an important indicator of an individual's physical\nhealth, often used by medical professionals in diagnosing a patient's ailments.\nIn recent years progress has been made in the area of automatically detecting\ncough events and, in certain cases, automatically identifying the ailment\nassociated with a particular cough sound. Ethical and sensitivity issues\nassociated with audio recordings of coughs makes it more difficult for this\ndata to be made publicly available. However, without the public availability of\na reliable database of cough sounds, developments in the area of audio event\ndetection are likely to be hampered. The purpose of this paper is to spread\nawareness of a database containing a large amount of naturally occurring cough\nsounds that can be used for the implementation, evaluation, and comparison of\nnew machine learning algorithms that allow for audio event detection associated\nwith cough sounds. Using a purpose built GUI designed in MATLAB, the\nre-annotation procedure followed a reusable methodology that allowed for quick\nand efficient importing and marking of audio signals, resulting in a\nre-annotated version of the Augmented Multi-party Interaction (AMI) corpus'\ncough location annotations, with 1369 individual cough events. All cough\nannotations and the re-annotation tool are made available for download and\npublic use.", "published": "2019-06-27 09:05:10", "link": "http://arxiv.org/abs/1906.11509v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Multiple Sound Source Localization with SVD-PHAT", "abstract": "This paper introduces a modification of phase transform on singular value\ndecomposition (SVD-PHAT) to localize multiple sound sources. This work aims to\nimprove localization accuracy and keeps the algorithm complexity low for\nreal-time applications. This method relies on multiple scans of the search\nspace, with projection of each low-dimensional observation onto orthogonal\nsubspaces. We show that this method localizes multiple sound sources more\naccurately than discrete SRP-PHAT, with a reduction in the Root Mean Square\nError up to 0.0395 radians.", "published": "2019-06-27 19:06:55", "link": "http://arxiv.org/abs/1906.11913v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Sensitivity to Haptic-Audio Envelope Asynchrony", "abstract": "We want to understand the human capabilities to perceive amplitude\nsimilarities between a haptic and an audio signal. So, four psychophysical\nexperiments were performed. Three of them measured the asynchrony JND (Just\nNoticeable Difference) at the signals' attack, release and decay, while the\nforth experiment measured the amplitude decrease on the middle of the signal.\nAll the experiments used a combination of the constant stimulus and staircase\nmethods to present two stimuli, while the participants' (N=12) task was to\nidentify which of the two stimuli was synchronized. The audiotactile stimulus\nwas defined using an stereo audio signal with an ADSR (Attack Decay Sustain\nRelease) envelope. The partial results reveal JNDs for temporal asynchrony of:\n54ms for attack, 265ms for decay and 57ms for release. Also the results reveal\nan amplitude decrease JND of 25\\%. Although for decay the results were to\ndisperse, therefore we suspect that the participants were not able to the\nchanges on the haptic signal.", "published": "2019-06-27 11:56:10", "link": "http://arxiv.org/abs/1906.11571v2", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Representation Learning of Music Using Artist, Album, and Track\n  Information", "abstract": "Supervised music representation learning has been performed mainly using\nsemantic labels such as music genres. However, annotating music with semantic\nlabels requires time and cost. In this work, we investigate the use of factual\nmetadata such as artist, album, and track information, which are naturally\nannotated to songs, for supervised music representation learning. The results\nshow that each of the metadata has individual concept characteristics, and\nusing them jointly improves overall performance.", "published": "2019-06-27 16:42:40", "link": "http://arxiv.org/abs/1906.11783v1", "categories": ["cs.IR", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
