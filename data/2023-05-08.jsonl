{"title": "Improving Cross-Task Generalization with Step-by-Step Instructions", "abstract": "Instruction tuning has been shown to be able to improve cross-task\ngeneralization of language models. However, it is still challenging for\nlanguage models to complete the target tasks following the instructions, as the\ninstructions are general and lack intermediate steps. To address this problem,\nwe propose to incorporate the step-by-step instructions to help language models\nto decompose the tasks, which can provide the detailed and specific procedures\nfor completing the target tasks. The step-by-step instructions are obtained\nautomatically by prompting ChatGPT, which are further combined with the\noriginal instructions to tune language models. The extensive experiments on\nSUP-NATINST show that the high-quality step-by-step instructions can improve\ncross-task generalization across different model sizes. Moreover, the further\nanalysis indicates the importance of the order of steps of the step-by-step\ninstruction for the improvement. To facilitate future research, we release the\nstep-by-step instructions and their human quality evaluation results.", "published": "2023-05-08 02:50:41", "link": "http://arxiv.org/abs/2305.04429v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Diffusion Model Achieve Better Performance in Text Generation?\n  Bridging the Gap between Training and Inference!", "abstract": "Diffusion models have been successfully adapted to text generation tasks by\nmapping the discrete text into the continuous space. However, there exist\nnonnegligible gaps between training and inference, owing to the absence of the\nforward process during inference. Thus, the model only predicts based on the\npreviously generated reverse noise rather than the noise computed by the\nforward process. Besides, the widely-used downsampling strategy in speeding up\nthe inference will cause the mismatch of diffusion trajectories between\ntraining and inference. To understand and mitigate the above two types of\ntraining-inference discrepancies, we launch a thorough preliminary study. Based\non our observations, we propose two simple yet effective methods to bridge the\ngaps mentioned above, named Distance Penalty and Adaptive Decay Sampling.\nExtensive experiments on \\textbf{6} generation tasks confirm the superiority of\nour methods, which can achieve $100\\times \\rightarrow 200\\times$ speedup with\nbetter performance.", "published": "2023-05-08 05:32:22", "link": "http://arxiv.org/abs/2305.04465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Token-Level Fitting Issues of Seq2seq Models", "abstract": "Sequence-to-sequence (seq2seq) models have been widely used for natural\nlanguage processing, computer vision, and other deep learning tasks. We find\nthat seq2seq models trained with early-stopping suffer from issues at the token\nlevel. In particular, while some tokens in the vocabulary demonstrate\noverfitting, others underfit when training is stopped. Experiments show that\nthe phenomena are pervasive in different models, even in fine-tuned large\npretrained-models. We identify three major factors that influence token-level\nfitting, which include token frequency, parts-of-speech, and prediction\ndiscrepancy. Further, we find that external factors such as language, model\nsize, domain, data scale, and pretraining can also influence the fitting of\ntokens.", "published": "2023-05-08 06:40:24", "link": "http://arxiv.org/abs/2305.04493v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Target-Side Augmentation for Document-Level Machine Translation", "abstract": "Document-level machine translation faces the challenge of data sparsity due\nto its long input length and a small amount of training data, increasing the\nrisk of learning spurious patterns. To address this challenge, we propose a\ntarget-side augmentation method, introducing a data augmentation (DA) model to\ngenerate many potential translations for each source document. Learning on\nthese wider range translations, an MT model can learn a smoothed distribution,\nthereby reducing the risk of data sparsity. We demonstrate that the DA model,\nwhich estimates the posterior distribution, largely improves the MT\nperformance, outperforming the previous best system by 2.30 s-BLEU on News and\nachieving new state-of-the-art on News and Europarl benchmarks. Our code is\navailable at https://github.com/baoguangsheng/target-side-augmentation.", "published": "2023-05-08 07:01:18", "link": "http://arxiv.org/abs/2305.04505v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Event Knowledge Incorporation with Posterior Regularization for\n  Event-Centric Question Answering", "abstract": "We propose a simple yet effective strategy to incorporate event knowledge\nextracted from event trigger annotations via posterior regularization to\nimprove the event reasoning capability of mainstream question-answering (QA)\nmodels for event-centric QA. In particular, we define event-related knowledge\nconstraints based on the event trigger annotations in the QA datasets, and\nsubsequently use them to regularize the posterior answer output probabilities\nfrom the backbone pre-trained language models used in the QA setting. We\nexplore two different posterior regularization strategies for extractive and\ngenerative QA separately. For extractive QA, the sentence-level event knowledge\nconstraint is defined by assessing if a sentence contains an answer event or\nnot, which is later used to modify the answer span extraction probability. For\ngenerative QA, the token-level event knowledge constraint is defined by\ncomparing the generated token from the backbone language model with the answer\nevent in order to introduce a reward or penalty term, which essentially adjusts\nthe answer generative probability indirectly. We conduct experiments on two\nevent-centric QA datasets, TORQUE and ESTER. The results show that our proposed\napproach can effectively inject event knowledge into existing pre-trained\nlanguage models and achieves strong performance compared to existing QA models\nin answer evaluation. Code and models can be found:\nhttps://github.com/LuJunru/EventQAviaPR.", "published": "2023-05-08 07:45:12", "link": "http://arxiv.org/abs/2305.04522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-Modal Context Reasoning Approach for Conditional Inference on\n  Joint Textual and Visual Clues", "abstract": "Conditional inference on joint textual and visual clues is a multi-modal\nreasoning task that textual clues provide prior permutation or external\nknowledge, which are complementary with visual content and pivotal to deducing\nthe correct option. Previous methods utilizing pretrained vision-language\nmodels (VLMs) have achieved impressive performances, yet they show a lack of\nmultimodal context reasoning capability, especially for text-modal information.\nTo address this issue, we propose a Multi-modal Context Reasoning approach,\nnamed ModCR. Compared to VLMs performing reasoning via cross modal semantic\nalignment, it regards the given textual abstract semantic and objective image\ninformation as the pre-context information and embeds them into the language\nmodel to perform context reasoning. Different from recent vision-aided language\nmodels used in natural language processing, ModCR incorporates the multi-view\nsemantic alignment information between language and vision by introducing the\nlearnable alignment prefix between image and text in the pretrained language\nmodel. This makes the language model well-suitable for such multi-modal\nreasoning scenario on joint textual and visual clues. We conduct extensive\nexperiments on two corresponding data sets and experimental results show\nsignificantly improved performance (exact gain by 4.8% on PMR test set)\ncompared to previous strong baselines. Code Link:\n\\url{https://github.com/YunxinLi/Multimodal-Context-Reasoning}.", "published": "2023-05-08 08:05:40", "link": "http://arxiv.org/abs/2305.04530v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diffusion Theory as a Scalpel: Detecting and Purifying Poisonous\n  Dimensions in Pre-trained Language Models Caused by Backdoor or Bias", "abstract": "Pre-trained Language Models (PLMs) may be poisonous with backdoors or bias\ninjected by the suspicious attacker during the fine-tuning process. A core\nchallenge of purifying potentially poisonous PLMs is precisely finding\npoisonous dimensions. To settle this issue, we propose the Fine-purifying\napproach, which utilizes the diffusion theory to study the dynamic process of\nfine-tuning for finding potentially poisonous dimensions. According to the\nrelationship between parameter drifts and Hessians of different dimensions, we\ncan detect poisonous dimensions with abnormal dynamics, purify them by\nresetting them to clean pre-trained weights, and then fine-tune the purified\nweights on a small clean dataset. To the best of our knowledge, we are the\nfirst to study the dynamics guided by the diffusion theory for safety or\ndefense purposes. Experimental results validate the effectiveness of\nFine-purifying even with a small clean dataset.", "published": "2023-05-08 08:40:30", "link": "http://arxiv.org/abs/2305.04547v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Adversarial Training on Contextualized Language Representation", "abstract": "Beyond the success story of adversarial training (AT) in the recent text\ndomain on top of pre-trained language models (PLMs), our empirical study\nshowcases the inconsistent gains from AT on some tasks, e.g. commonsense\nreasoning, named entity recognition. This paper investigates AT from the\nperspective of the contextualized language representation outputted by PLM\nencoders. We find the current AT attacks lean to generate sub-optimal\nadversarial examples that can fool the decoder part but have a minor effect on\nthe encoder. However, we find it necessary to effectively deviate the latter\none to allow AT to gain. Based on the observation, we propose simple yet\neffective \\textit{Contextualized representation-Adversarial Training} (CreAT),\nin which the attack is explicitly optimized to deviate the contextualized\nrepresentation of the encoder. It allows a global optimization of adversarial\nexamples that can fool the entire model. We also find CreAT gives rise to a\nbetter direction to optimize the adversarial examples, to let them less\nsensitive to hyperparameters. Compared to AT, CreAT produces consistent\nperformance gains on a wider range of tasks and is proven to be more effective\nfor language pre-training where only the encoder part is kept for downstream\ntasks. We achieve the new state-of-the-art performances on a series of\nchallenging benchmarks, e.g. AdvGLUE (59.1 $ \\rightarrow $ 61.1), HellaSWAG\n(93.0 $ \\rightarrow $ 94.9), ANLI (68.1 $ \\rightarrow $ 69.3).", "published": "2023-05-08 08:56:51", "link": "http://arxiv.org/abs/2305.04557v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Boosting Radiology Report Generation by Infusing Comparison Prior", "abstract": "Recent transformer-based models have made significant strides in generating\nradiology reports from chest X-ray images. However, a prominent challenge\nremains: these models often lack prior knowledge, resulting in the generation\nof synthetic reports that mistakenly reference non-existent prior exams. This\ndiscrepancy can be attributed to a knowledge gap between radiologists and the\ngeneration models. While radiologists possess patient-specific prior\ninformation, the models solely receive X-ray images at a specific time point.\nTo tackle this issue, we propose a novel approach that leverages a rule-based\nlabeler to extract comparison prior information from radiology reports. This\nextracted comparison prior is then seamlessly integrated into state-of-the-art\ntransformer-based models, enabling them to produce more realistic and\ncomprehensive reports. Our method is evaluated on English report datasets, such\nas IU X-ray and MIMIC-CXR. The results demonstrate that our approach surpasses\nbaseline models in terms of natural language generation metrics. Notably, our\nmodel generates reports that are free from false references to non-existent\nprior exams, setting it apart from previous models. By addressing this\nlimitation, our approach represents a significant step towards bridging the gap\nbetween radiologists and generation models in the domain of medical report\ngeneration.", "published": "2023-05-08 09:12:44", "link": "http://arxiv.org/abs/2305.04561v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HiFi: High-Information Attention Heads Hold for Parameter-Efficient\n  Model Adaptation", "abstract": "To fully leverage the advantages of large-scale pre-trained language models\n(PLMs) on downstream tasks, it has become a ubiquitous adaptation paradigm to\nfine-tune the entire parameters of PLMs. However, this paradigm poses issues of\ninefficient updating and resource over-consuming for fine-tuning in data-scarce\nand resource-limited scenarios, because of the large scale of parameters in\nPLMs. To alleviate these concerns, in this paper, we propose a\nparameter-efficient fine-tuning method HiFi, that is, only the highly\ninformative and strongly correlated attention heads for the specific task are\nfine-tuned. To search for those significant attention heads, we develop a novel\nframework to analyze the effectiveness of heads. Specifically, we first model\nthe relationship between heads into a graph from two perspectives of\ninformation richness and correlation, and then apply PageRank algorithm to\ndetermine the relative importance of each head. Extensive experiments on the\nGLUE benchmark demonstrate the effectiveness of our method, and show that HiFi\nobtains state-of-the-art performance over the prior baselines.", "published": "2023-05-08 09:31:13", "link": "http://arxiv.org/abs/2305.04573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MultiTACRED: A Multilingual Version of the TAC Relation Extraction\n  Dataset", "abstract": "Relation extraction (RE) is a fundamental task in information extraction,\nwhose extension to multilingual settings has been hindered by the lack of\nsupervised resources comparable in size to large English datasets such as\nTACRED (Zhang et al., 2017). To address this gap, we introduce the MultiTACRED\ndataset, covering 12 typologically diverse languages from 9 language families,\nwhich is created by machine-translating TACRED instances and automatically\nprojecting their entity annotations. We analyze translation and annotation\nprojection quality, identify error categories, and experimentally evaluate\nfine-tuned pretrained mono- and multilingual language models in common transfer\nlearning scenarios. Our analyses show that machine translation is a viable\nstrategy to transfer RE instances, with native speakers judging more than 83%\nof the translated instances to be linguistically and semantically acceptable.\nWe find monolingual RE model performance to be comparable to the English\noriginal for many of the target languages, and that multilingual models trained\non a combination of English and target language data can outperform their\nmonolingual counterparts. However, we also observe a variety of translation and\nannotation projection errors, both due to the MT systems and linguistic\nfeatures of the target languages, such as pronoun-dropping, compounding and\ninflection, that degrade dataset quality and RE model performance.", "published": "2023-05-08 09:48:21", "link": "http://arxiv.org/abs/2305.04582v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cone: Unsupervised Contrastive Opinion Extraction", "abstract": "Contrastive opinion extraction aims to extract a structured summary or key\npoints organised as positive and negative viewpoints towards a common aspect or\ntopic. Most recent works for unsupervised key point extraction is largely built\non sentence clustering or opinion summarisation based on the popularity of\nopinions expressed in text. However, these methods tend to generate aspect\nclusters with incoherent sentences, conflicting viewpoints, redundant aspects.\nTo address these problems, we propose a novel unsupervised Contrastive OpinioN\nExtraction model, called Cone, which learns disentangled latent aspect and\nsentiment representations based on pseudo aspect and sentiment labels by\ncombining contrastive learning with iterative aspect/sentiment clustering\nrefinement. Apart from being able to extract contrastive opinions, it is also\nable to quantify the relative popularity of aspects and their associated\nsentiment distributions. The model has been evaluated on both a hotel review\ndataset and a Twitter dataset about COVID vaccines. The results show that\ndespite using no label supervision or aspect-denoted seed words, Cone\noutperforms a number of competitive baselines on contrastive opinion\nextraction. The results of Cone can be used to offer a better recommendation of\nproducts and services online.", "published": "2023-05-08 10:18:30", "link": "http://arxiv.org/abs/2305.04599v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Continual Relation Extraction via Classifier Decomposition", "abstract": "Continual relation extraction (CRE) models aim at handling emerging new\nrelations while avoiding catastrophically forgetting old ones in the streaming\ndata. Though improvements have been shown by previous CRE studies, most of them\nonly adopt a vanilla strategy when models first learn representations of new\nrelations. In this work, we point out that there exist two typical biases after\ntraining of this vanilla strategy: classifier bias and representation bias,\nwhich causes the previous knowledge that the model learned to be shaded. To\nalleviate those biases, we propose a simple yet effective classifier\ndecomposition framework that splits the last FFN layer into separated previous\nand current classifiers, so as to maintain previous knowledge and encourage the\nmodel to learn more robust representations at this training stage. Experimental\nresults on two standard benchmarks show that our proposed framework\nconsistently outperforms the state-of-the-art CRE models, which indicates that\nthe importance of the first training stage to CRE models may be underestimated.\nOur code is available at https://github.com/hemingkx/CDec.", "published": "2023-05-08 11:29:33", "link": "http://arxiv.org/abs/2305.04636v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Knowledge Graph Construction Using Large Language Models", "abstract": "The growing trend of Large Language Models (LLM) development has attracted\nsignificant attention, with models for various applications emerging\nconsistently. However, the combined application of Large Language Models with\nsemantic technologies for reasoning and inference is still a challenging task.\nThis paper analyzes how the current advances in foundational LLM, like ChatGPT,\ncan be compared with the specialized pretrained models, like REBEL, for joint\nentity and relation extraction. To evaluate this approach, we conducted several\nexperiments using sustainability-related text as our use case. We created\npipelines for the automatic creation of Knowledge Graphs from raw texts, and\nour findings indicate that using advanced LLM models can improve the accuracy\nof the process of creating these graphs from unstructured text. Furthermore, we\nexplored the potential of automatic ontology creation using foundation LLM\nmodels, which resulted in even more relevant and accurate knowledge graphs.", "published": "2023-05-08 12:53:06", "link": "http://arxiv.org/abs/2305.04676v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DEnsity: Open-domain Dialogue Evaluation Metric using Density Estimation", "abstract": "Despite the recent advances in open-domain dialogue systems, building a\nreliable evaluation metric is still a challenging problem. Recent studies\nproposed learnable metrics based on classification models trained to\ndistinguish the correct response. However, neural classifiers are known to make\noverly confident predictions for examples from unseen distributions. We propose\nDEnsity, which evaluates a response by utilizing density estimation on the\nfeature space derived from a neural classifier. Our metric measures how likely\na response would appear in the distribution of human conversations. Moreover,\nto improve the performance of DEnsity, we utilize contrastive learning to\nfurther compress the feature space. Experiments on multiple response evaluation\ndatasets show that DEnsity correlates better with human evaluations than the\nexisting metrics. Our code is available at https://github.com/ddehun/DEnsity.", "published": "2023-05-08 14:10:40", "link": "http://arxiv.org/abs/2305.04720v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SkillQG: Learning to Generate Question for Reading Comprehension\n  Assessment", "abstract": "We present $\\textbf{$\\texttt{SkillQG}$}$: a question generation framework\nwith controllable comprehension types for assessing and improving machine\nreading comprehension models. Existing question generation systems widely\ndifferentiate questions by $\\textit{literal}$ information such as question\nwords and answer types to generate semantically relevant questions for a given\ncontext. However, they rarely consider the $\\textit{comprehension}$ nature of\nquestions, i.e. the different comprehension capabilities embodied by different\nquestions. In comparison, our $\\texttt{SkillQG}$ is able to tailor a\nfine-grained assessment and improvement to the capabilities of question\nanswering models built on it. Specifically, we first frame the comprehension\ntype of questions based on a hierarchical skill-based schema, then formulate\n$\\texttt{SkillQG}$ as a skill-conditioned question generator. Furthermore, to\nimprove the controllability of generation, we augment the input text with\nquestion focus and skill-specific knowledge, which are constructed by\niteratively prompting the pre-trained language models. Empirical results\ndemonstrate that $\\texttt{SkillQG}$ outperforms baselines in terms of quality,\nrelevance, and skill-controllability while showing a promising performance\nboost in downstream question answering task.", "published": "2023-05-08 14:40:48", "link": "http://arxiv.org/abs/2305.04737v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAT: A Contextualized Conceptualization and Instantiation Framework for\n  Commonsense Reasoning", "abstract": "Commonsense reasoning, aiming at endowing machines with a human-like ability\nto make situational presumptions, is extremely challenging to generalize. For\nsomeone who barely knows about \"meditation,\" while is knowledgeable about\n\"singing,\" he can still infer that \"meditation makes people relaxed\" from the\nexisting knowledge that \"singing makes people relaxed\" by first conceptualizing\n\"singing\" as a \"relaxing event\" and then instantiating that event to\n\"meditation.\" This process, known as conceptual induction and deduction, is\nfundamental to commonsense reasoning while lacking both labeled data and\nmethodologies to enhance commonsense modeling. To fill such a research gap, we\npropose CAT (Contextualized ConceptuAlization and InsTantiation), a\nsemi-supervised learning framework that integrates event conceptualization and\ninstantiation to conceptualize commonsense knowledge bases at scale. Extensive\nexperiments show that our framework achieves state-of-the-art performances on\ntwo conceptualization tasks, and the acquired abstract commonsense knowledge\ncan significantly improve commonsense inference modeling. Our code, data, and\nfine-tuned models are publicly available at\nhttps://github.com/HKUST-KnowComp/CAT.", "published": "2023-05-08 16:08:42", "link": "http://arxiv.org/abs/2305.04808v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Influence of External Information on Large Language Models Mirrors\n  Social Cognitive Patterns", "abstract": "Social cognitive theory explains how people learn and acquire knowledge\nthrough observing others. Recent years have witnessed the rapid development of\nlarge language models (LLMs), which suggests their potential significance as\nagents in the society. LLMs, as AI agents, can observe external information,\nwhich shapes their cognition and behaviors. However, the extent to which\nexternal information influences LLMs' cognition and behaviors remains unclear.\nThis study investigates how external statements and opinions influence LLMs'\nthoughts and behaviors from a social cognitive perspective. Three experiments\nwere conducted to explore the effects of external information on LLMs'\nmemories, opinions, and social media behavioral decisions. Sociocognitive\nfactors, including source authority, social identity, and social role, were\nanalyzed to investigate their moderating effects. Results showed that external\ninformation can significantly shape LLMs' memories, opinions, and behaviors,\nwith these changes mirroring human social cognitive patterns such as authority\nbias, in-group bias, emotional positivity, and emotion contagion. This\nunderscores the challenges in developing safe and unbiased LLMs, and emphasizes\nthe importance of understanding the susceptibility of LLMs to external\ninfluences.", "published": "2023-05-08 16:10:18", "link": "http://arxiv.org/abs/2305.04812v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Summary-Worthy Visual Representation for Abstractive\n  Summarization in Video", "abstract": "Multimodal abstractive summarization for videos (MAS) requires generating a\nconcise textual summary to describe the highlights of a video according to\nmultimodal resources, in our case, the video content and its transcript.\nInspired by the success of the large-scale generative pre-trained language\nmodel (GPLM) in generating high-quality textual content (e.g., summary), recent\nMAS methods have proposed to adapt the GPLM to this task by equipping it with\nthe visual information, which is often obtained through a general-purpose\nvisual feature extractor. However, the generally extracted visual features may\noverlook some summary-worthy visual information, which impedes model\nperformance. In this work, we propose a novel approach to learning the\nsummary-worthy visual representation that facilitates abstractive\nsummarization. Our method exploits the summary-worthy information from both the\ncross-modal transcript data and the knowledge that distills from the pseudo\nsummary. Extensive experiments on three public multimodal datasets show that\nour method outperforms all competing baselines. Furthermore, with the\nadvantages of summary-worthy visual information, our model can have a\nsignificant improvement on small datasets or even datasets with limited\ntraining data.", "published": "2023-05-08 16:24:46", "link": "http://arxiv.org/abs/2305.04824v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge", "abstract": "Comparative knowledge (e.g., steel is stronger and heavier than styrofoam) is\nan essential component of our world knowledge, yet understudied in prior\nliterature. In this paper, we harvest the dramatic improvements in knowledge\ncapabilities of language models into a large-scale comparative knowledge base.\nWhile the ease of acquisition of such comparative knowledge is much higher from\nextreme-scale models like GPT-4, compared to their considerably smaller and\nweaker counterparts such as GPT-2, not even the most powerful models are exempt\nfrom making errors. We thus ask: to what extent are models at different scales\nable to generate valid and diverse comparative knowledge?\n  We introduce NeuroComparatives, a novel framework for comparative knowledge\ndistillation overgenerated from language models such as GPT-variants and LLaMA,\nfollowed by stringent filtering of the generated knowledge. Our framework\nacquires comparative knowledge between everyday objects, producing a corpus of\nup to 8.8M comparisons over 1.74M entity pairs - 10X larger and 30% more\ndiverse than existing resources. Moreover, human evaluations show that\nNeuroComparatives outperform existing resources in terms of validity (up to 32%\nabsolute improvement). Our acquired NeuroComparatives leads to performance\nimprovements on five downstream tasks. We find that neuro-symbolic manipulation\nof smaller models offers complementary benefits to the currently dominant\npractice of prompting extreme-scale language models for knowledge distillation.", "published": "2023-05-08 18:20:36", "link": "http://arxiv.org/abs/2305.04978v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from\n  Doctor-Patient Conversations through Fine-tuning and In-context Learning", "abstract": "This paper presents our contribution to the MEDIQA-2023 Dialogue2Note shared\ntask, encompassing both subtask A and subtask B. We approach the task as a\ndialogue summarization problem and implement two distinct pipelines: (a) a\nfine-tuning of a pre-trained dialogue summarization model and GPT-3, and (b)\nfew-shot in-context learning (ICL) using a large language model, GPT-4. Both\nmethods achieve excellent results in terms of ROUGE-1 F1, BERTScore F1\n(deberta-xlarge-mnli), and BLEURT, with scores of 0.4011, 0.7058, and 0.5421,\nrespectively. Additionally, we predict the associated section headers using\nRoBERTa and SciBERT based classification models. Our team ranked fourth among\nall teams, while each team is allowed to submit three runs as part of their\nsubmission. We also utilize expert annotations to demonstrate that the notes\ngenerated through the ICL GPT-4 are better than all other baselines. The code\nfor our submission is available.", "published": "2023-05-08 19:16:26", "link": "http://arxiv.org/abs/2305.05001v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Relation Extraction in the era of Large Language Models", "abstract": "Relation extraction (RE) is the core NLP task of inferring semantic\nrelationships between entities from text. Standard supervised RE techniques\nentail training modules to tag tokens comprising entity spans and then predict\nthe relationship between them. Recent work has instead treated the problem as a\n\\emph{sequence-to-sequence} task, linearizing relations between entities as\ntarget strings to be generated conditioned on the input. Here we push the\nlimits of this approach, using larger language models (GPT-3 and Flan-T5 large)\nthan considered in prior work and evaluating their performance on standard RE\ntasks under varying levels of supervision. We address issues inherent to\nevaluating generative approaches to RE by doing human evaluations, in lieu of\nrelying on exact matching. Under this refined evaluation, we find that: (1)\nFew-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly\nequivalent to existing fully supervised models; (2) Flan-T5 is not as capable\nin the few-shot setting, but supervising and fine-tuning it with\nChain-of-Thought (CoT) style explanations (generated via GPT-3) yields SOTA\nresults. We release this model as a new baseline for RE tasks.", "published": "2023-05-08 19:19:07", "link": "http://arxiv.org/abs/2305.05003v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dreams Are More \"Predictable'' Than You Think", "abstract": "A consistent body of evidence suggests that dream reports significantly vary\nfrom other types of textual transcripts with respect to semantic content.\nFurthermore, it appears to be a widespread belief in the dream/sleep research\ncommunity that dream reports constitute rather ``unique'' strings of text. This\nmight be a notable issue for the growing amount of approaches using natural\nlanguage processing (NLP) tools to automatically analyse dream reports, as they\nlargely rely on neural models trained on non-dream corpora scraped from the\nweb. In this work, I will adopt state-of-the-art (SotA) large language models\n(LLMs), to study if and how dream reports deviate from other human-generated\ntext strings, such as Wikipedia. Results show that, taken as a whole, DreamBank\ndoes not deviate from Wikipedia. Moreover, on average, single dream reports are\nsignificantly more predictable than Wikipedia articles. Preliminary evidence\nsuggests that word count, gender, and visual impairment can significantly shape\nhow predictable a dream report can appear to the model.", "published": "2023-05-08 21:24:12", "link": "http://arxiv.org/abs/2305.05054v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Unified Evaluation Framework for Novelty Detection and Accommodation\n  in NLP with an Instantiation in Authorship Attribution", "abstract": "State-of-the-art natural language processing models have been shown to\nachieve remarkable performance in 'closed-world' settings where all the labels\nin the evaluation set are known at training time. However, in real-world\nsettings, 'novel' instances that do not belong to any known class are often\nobserved. This renders the ability to deal with novelties crucial. To initiate\na systematic research in this important area of 'dealing with novelties', we\nintroduce 'NoveltyTask', a multi-stage task to evaluate a system's performance\non pipelined novelty 'detection' and 'accommodation' tasks. We provide\nmathematical formulation of NoveltyTask and instantiate it with the authorship\nattribution task that pertains to identifying the correct author of a given\ntext. We use Amazon reviews corpus and compile a large dataset (consisting of\n250k instances across 200 authors/labels) for NoveltyTask. We conduct\ncomprehensive experiments and explore several baseline methods for the task.\nOur results show that the methods achieve considerably low performance making\nthe task challenging and leaving sufficient room for improvement. Finally, we\nbelieve our work will encourage research in this underexplored area of dealing\nwith novelties, an important step en route to developing robust systems.", "published": "2023-05-08 22:37:30", "link": "http://arxiv.org/abs/2305.05079v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unlocking Practical Applications in Legal Domain: Evaluation of GPT for\n  Zero-Shot Semantic Annotation of Legal Texts", "abstract": "We evaluated the capability of a state-of-the-art generative pre-trained\ntransformer (GPT) model to perform semantic annotation of short text snippets\n(one to few sentences) coming from legal documents of various types.\nDiscussions of potential uses (e.g., document drafting, summarization) of this\nemerging technology in legal domain have intensified, but to date there has not\nbeen a rigorous analysis of these large language models' (LLM) capacity in\nsentence-level semantic annotation of legal texts in zero-shot learning\nsettings. Yet, this particular type of use could unlock many practical\napplications (e.g., in contract review) and research opportunities (e.g., in\nempirical legal studies). We fill the gap with this study. We examined if and\nhow successfully the model can semantically annotate small batches of short\ntext snippets (10-50) based exclusively on concise definitions of the semantic\ntypes. We found that the GPT model performs surprisingly well in zero-shot\nsettings on diverse types of documents (F1=.73 on a task involving court\nopinions, .86 for contracts, and .54 for statutes and regulations). These\nfindings can be leveraged by legal scholars and practicing lawyers alike to\nguide their decisions in integrating LLMs in wide range of workflows involving\nsemantic annotation of legal texts.", "published": "2023-05-08 01:55:53", "link": "http://arxiv.org/abs/2305.04417v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Facilitating Fine-grained Detection of Chinese Toxic Language:\n  Hierarchical Taxonomy, Resources, and Benchmarks", "abstract": "The widespread dissemination of toxic online posts is increasingly damaging\nto society. However, research on detecting toxic language in Chinese has lagged\nsignificantly. Existing datasets lack fine-grained annotation of toxic types\nand expressions, and ignore the samples with indirect toxicity. In addition, it\nis crucial to introduce lexical knowledge to detect the toxicity of posts,\nwhich has been a challenge for researchers. In this paper, we facilitate the\nfine-grained detection of Chinese toxic language. First, we built Monitor Toxic\nFrame, a hierarchical taxonomy to analyze toxic types and expressions. Then, a\nfine-grained dataset ToxiCN is presented, including both direct and indirect\ntoxic samples. We also build an insult lexicon containing implicit profanity\nand propose Toxic Knowledge Enhancement (TKE) as a benchmark, incorporating the\nlexical feature to detect toxic language. In the experimental stage, we\ndemonstrate the effectiveness of TKE. After that, a systematic quantitative and\nqualitative analysis of the findings is given.", "published": "2023-05-08 03:50:38", "link": "http://arxiv.org/abs/2305.04446v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Independent Neuro-Symbolic Semantic Parsing for Form\n  Understanding", "abstract": "Recent works on form understanding mostly employ multimodal transformers or\nlarge-scale pre-trained language models. These models need ample data for\npre-training. In contrast, humans can usually identify key-value pairings from\na form only by looking at layouts, even if they don't comprehend the language\nused. No prior research has been conducted to investigate how helpful layout\ninformation alone is for form understanding. Hence, we propose a unique\nentity-relation graph parsing method for scanned forms called LAGNN, a\nlanguage-independent Graph Neural Network model. Our model parses a form into a\nword-relation graph in order to identify entities and relations jointly and\nreduce the time complexity of inference. This graph is then transformed by\ndeterministic rules into a fully connected entity-relation graph. Our model\nsimply takes into account relative spacing between bounding boxes from layout\ninformation to facilitate easy transfer across languages. To further improve\nthe performance of LAGNN, and achieve isomorphism between entity-relation\ngraphs and word-relation graphs, we use integer linear programming (ILP) based\ninference. Code is publicly available at https://github.com/Bhanu068/LAGNN", "published": "2023-05-08 05:03:07", "link": "http://arxiv.org/abs/2305.04460v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MGR: Multi-generator Based Rationalization", "abstract": "Rationalization is to employ a generator and a predictor to construct a\nself-explaining NLP model in which the generator selects a subset of\nhuman-intelligible pieces of the input text to the following predictor.\nHowever, rationalization suffers from two key challenges, i.e., spurious\ncorrelation and degeneration, where the predictor overfits the spurious or\nmeaningless pieces solely selected by the not-yet well-trained generator and in\nturn deteriorates the generator. Although many studies have been proposed to\naddress the two challenges, they are usually designed separately and do not\ntake both of them into account. In this paper, we propose a simple yet\neffective method named MGR to simultaneously solve the two problems. The key\nidea of MGR is to employ multiple generators such that the occurrence stability\nof real pieces is improved and more meaningful pieces are delivered to the\npredictor. Empirically, we show that MGR improves the F1 score by up to 20.9%\nas compared to state-of-the-art methods. Codes are available at\nhttps://github.com/jugechengzi/Rationalization-MGR .", "published": "2023-05-08 06:36:46", "link": "http://arxiv.org/abs/2305.04492v8", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Non-Autoregressive Math Word Problem Solver with Unified Tree Structure", "abstract": "Existing MWP solvers employ sequence or binary tree to present the solution\nexpression and decode it from given problem description. However, such\nstructures fail to handle the variants that can be derived via mathematical\nmanipulation, e.g., $(a_1+a_2) * a_3$ and $a_1 * a_3+a_2 * a_3$ can both be\npossible valid solutions for a same problem but formulated as different\nexpression sequences or trees. The multiple solution variants depicting\ndifferent possible solving procedures for the same input problem would raise\ntwo issues: 1) making it hard for the model to learn the mapping function\nbetween the input and output spaces effectively, and 2) wrongly indicating\n\\textit{wrong} when evaluating a valid expression variant. To address these\nissues, we introduce a unified tree structure to present a solution expression,\nwhere the elements are permutable and identical for all the expression\nvariants. We propose a novel non-autoregressive solver, named \\textit{MWP-NAS},\nto parse the problem and deduce the solution expression based on the unified\ntree. For evaluating the possible expression variants, we design a path-based\nmetric to evaluate the partial accuracy of expressions of a unified tree. The\nresults from extensive experiments conducted on Math23K and MAWPS demonstrate\nthe effectiveness of our proposed MWP-NAS. The codes and checkpoints are\navailable at: \\url{https://github.com/mengqunhan/MWP-NAS}.", "published": "2023-05-08 08:53:37", "link": "http://arxiv.org/abs/2305.04556v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "XAI in Computational Linguistics: Understanding Political Leanings in\n  the Slovenian Parliament", "abstract": "The work covers the development and explainability of machine learning models\nfor predicting political leanings through parliamentary transcriptions. We\nconcentrate on the Slovenian parliament and the heated debate on the European\nmigrant crisis, with transcriptions from 2014 to 2020. We develop both\nclassical machine learning and transformer language models to predict the left-\nor right-leaning of parliamentarians based on their given speeches on the topic\nof migrants. With both types of models showing great predictive success, we\ncontinue with explaining their decisions. Using explainability techniques, we\nidentify keywords and phrases that have the strongest influence in predicting\npolitical leanings on the topic, with left-leaning parliamentarians using\nconcepts such as people and unity and speak about refugees, and right-leaning\nparliamentarians using concepts such as nationality and focus more on illegal\nmigrants. This research is an example that understanding the reasoning behind\npredictions can not just be beneficial for AI engineers to improve their\nmodels, but it can also be helpful as a tool in the qualitative analysis steps\nin interdisciplinary research.", "published": "2023-05-08 11:19:21", "link": "http://arxiv.org/abs/2305.04631v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PreCog: Exploring the Relation between Memorization and Performance in\n  Pre-trained Language Models", "abstract": "Pre-trained Language Models such as BERT are impressive machines with the\nability to memorize, possibly generalized learning examples. We present here a\nsmall, focused contribution to the analysis of the interplay between\nmemorization and performance of BERT in downstream tasks. We propose PreCog, a\nmeasure for evaluating memorization from pre-training, and we analyze its\ncorrelation with the BERT's performance. Our experiments show that highly\nmemorized examples are better classified, suggesting memorization is an\nessential key to success for BERT.", "published": "2023-05-08 12:51:00", "link": "http://arxiv.org/abs/2305.04673v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Toeplitz Neural Network for Sequence Modeling", "abstract": "Sequence modeling has important applications in natural language processing\nand computer vision. Recently, the transformer-based models have shown strong\nperformance on various sequence modeling tasks, which rely on attention to\ncapture pairwise token relations, and position embedding to inject positional\ninformation. While showing good performance, the transformer models are\ninefficient to scale to long input sequences, mainly due to the quadratic\nspace-time complexity of attention. To overcome this inefficiency, we propose\nto model sequences with a relative position encoded Toeplitz matrix and use a\nToeplitz matrix-vector production trick to reduce the space-time complexity of\nthe sequence modeling to log linear. A lightweight sub-network called relative\nposition encoder is proposed to generate relative position coefficients with a\nfixed budget of parameters, enabling the proposed Toeplitz neural network to\ndeal with varying sequence lengths. In addition, despite being trained on\n512-token sequences, our model can extrapolate input sequence length up to 14K\ntokens in inference with consistent performance. Extensive experiments on\nautoregressive and bidirectional language modeling, image modeling, and the\nchallenging Long-Range Arena benchmark show that our method achieves better\nperformance than its competitors in most downstream tasks while being\nsignificantly faster. The code is available at\nhttps://github.com/OpenNLPLab/Tnn.", "published": "2023-05-08 14:49:01", "link": "http://arxiv.org/abs/2305.04749v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "MultiModal-GPT: A Vision and Language Model for Dialogue with Humans", "abstract": "We present a vision and language model named MultiModal-GPT to conduct\nmulti-round dialogue with humans. MultiModal-GPT can follow various\ninstructions from humans, such as generating a detailed caption, counting the\nnumber of interested objects, and answering general questions from users.\nMultiModal-GPT is parameter-efficiently fine-tuned from OpenFlamingo, with\nLow-rank Adapter (LoRA) added both in the cross-attention part and the\nself-attention part of the language model. We first construct instruction\ntemplates with vision and language data for multi-modality instruction tuning\nto make the model understand and follow human instructions. We find the quality\nof training data is vital for the dialogue performance, where few data\ncontaining short answers can lead the model to respond shortly to any\ninstructions. To further enhance the ability to chat with humans of the\nMultiModal-GPT, we utilize language-only instruction-following data to train\nthe MultiModal-GPT jointly. The joint training of language-only and\nvisual-language instructions with the \\emph{same} instruction template\neffectively improves dialogue performance. Various demos show the ability of\ncontinuous dialogue of MultiModal-GPT with humans. Code, dataset, and demo are\nat https://github.com/open-mmlab/Multimodal-GPT", "published": "2023-05-08 15:45:42", "link": "http://arxiv.org/abs/2305.04790v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "How Do In-Context Examples Affect Compositional Generalization?", "abstract": "Compositional generalization--understanding unseen combinations of seen\nprimitives--is an essential reasoning capability in human intelligence. The AI\ncommunity mainly studies this capability by fine-tuning neural networks on lots\nof training samples, while it is still unclear whether and how in-context\nlearning--the prevailing few-shot paradigm based on large language\nmodels--exhibits compositional generalization. In this paper, we present CoFe,\na test suite to investigate in-context compositional generalization. We find\nthat the compositional generalization performance can be easily affected by the\nselection of in-context examples, thus raising the research question what the\nkey factors are to make good in-context examples for compositional\ngeneralization. We study three potential factors: similarity, diversity and\ncomplexity. Our systematic experiments indicate that in-context examples should\nbe structurally similar to the test case, diverse from each other, and\nindividually simple. Furthermore, two strong limitations are observed:\nin-context compositional generalization on fictional words is much weaker than\nthat on commonly used ones; it is still critical that the in-context examples\nshould cover required linguistic structures, even though the backbone model has\nbeen pre-trained on large corpus. We hope our analysis would facilitate the\nunderstanding and utilization of in-context learning paradigm.", "published": "2023-05-08 16:32:18", "link": "http://arxiv.org/abs/2305.04835v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning for Topic Models", "abstract": "We apply reinforcement learning techniques to topic modeling by replacing the\nvariational autoencoder in ProdLDA with a continuous action space reinforcement\nlearning policy. We train the system with a policy gradient algorithm\nREINFORCE. Additionally, we introduced several modifications: modernize the\nneural network architecture, weight the ELBO loss, use contextual embeddings,\nand monitor the learning process via computing topic diversity and coherence\nfor each training step. Experiments are performed on 11 data sets. Our\nunsupervised model outperforms all other unsupervised models and performs on\npar with or better than most models using supervised labeling. Our model is\noutperformed on certain data sets by a model using supervised labeling and\ncontrastive learning. We have also conducted an ablation study to provide\nempirical evidence of performance improvements from changes we made to ProdLDA\nand found that the reinforcement learning formulation boosts performance.", "published": "2023-05-08 16:41:08", "link": "http://arxiv.org/abs/2305.04843v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Current State of Summarization", "abstract": "With the explosive growth of textual information, summarization systems have\nbecome increasingly important. This work aims to concisely indicate the current\nstate of the art in abstractive text summarization. As part of this, we outline\nthe current paradigm shifts towards pre-trained encoder-decoder models and\nlarge autoregressive language models. Additionally, we delve further into the\nchallenges of evaluating summarization systems and the potential of\ninstruction-tuned models for zero-shot summarization. Finally, we provide a\nbrief overview of how summarization systems are currently being integrated into\ncommercial applications.", "published": "2023-05-08 17:00:49", "link": "http://arxiv.org/abs/2305.04853v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Frustratingly Easy Improvement for Position Embeddings via Random\n  Padding", "abstract": "Position embeddings, encoding the positional relationships among tokens in\ntext sequences, make great contributions to modeling local context features in\nTransformer-based pre-trained language models. However, in Extractive Question\nAnswering, position embeddings trained with instances of varied context lengths\nmay not perform well as we expect. Since the embeddings of rear positions are\nupdated fewer times than the front position embeddings, the rear ones may not\nbe properly trained. In this paper, we propose a simple but effective strategy,\nRandom Padding, without any modifications to architectures of existing\npre-trained language models. We adjust the token order of input sequences when\nfine-tuning, to balance the number of updating times of every position\nembedding. Experiments show that Random Padding can significantly improve model\nperformance on the instances whose answers are located at rear positions,\nespecially when models are trained on short contexts but evaluated on long\ncontexts. Our code and data will be released for future research.", "published": "2023-05-08 17:08:14", "link": "http://arxiv.org/abs/2305.04859v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LABO: Towards Learning Optimal Label Regularization via Bi-level\n  Optimization", "abstract": "Regularization techniques are crucial to improving the generalization\nperformance and training efficiency of deep neural networks. Many deep learning\nalgorithms rely on weight decay, dropout, batch/layer normalization to converge\nfaster and generalize. Label Smoothing (LS) is another simple, versatile and\nefficient regularization which can be applied to various supervised\nclassification tasks. Conventional LS, however, regardless of the training\ninstance assumes that each non-target class is equally likely. In this work, we\npresent a general framework for training with label regularization, which\nincludes conventional LS but can also model instance-specific variants. Based\non this formulation, we propose an efficient way of learning LAbel\nregularization by devising a Bi-level Optimization (LABO) problem. We derive a\ndeterministic and interpretable solution of the inner loop as the optimal label\nsmoothing without the need to store the parameters or the output of a trained\nmodel. Finally, we conduct extensive experiments and demonstrate our LABO\nconsistently yields improvement over conventional label regularization on\nvarious fields, including seven machine translation and three image\nclassification tasks across various", "published": "2023-05-08 18:04:18", "link": "http://arxiv.org/abs/2305.04971v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Knowledge Graph Guided Semantic Evaluation of Language Models For User\n  Trust", "abstract": "A fundamental question in natural language processing is - what kind of\nlanguage structure and semantics is the language model capturing? Graph formats\nsuch as knowledge graphs are easy to evaluate as they explicitly express\nlanguage semantics and structure. This study evaluates the semantics encoded in\nthe self-attention transformers by leveraging explicit knowledge graph\nstructures. We propose novel metrics to measure the reconstruction error when\nproviding graph path sequences from a knowledge graph and trying to\nreproduce/reconstruct the same from the outputs of the self-attention\ntransformer models. The opacity of language models has an immense bearing on\nsocietal issues of trust and explainable decision outcomes. Our findings\nsuggest that language models are models of stochastic control processes for\nplausible language pattern generation. However, they do not ascribe object and\nconcept-level meaning and semantics to the learned stochastic patterns such as\nthose described in knowledge graphs. Furthermore, to enable robust evaluation\nof concept understanding by language models, we construct and make public an\naugmented language understanding benchmark built on the General Language\nUnderstanding Evaluation (GLUE) benchmark. This has significant\napplication-level user trust implications as stochastic patterns without a\nstrong sense of meaning cannot be trusted in high-stakes applications.", "published": "2023-05-08 18:53:14", "link": "http://arxiv.org/abs/2305.04989v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explanation-based Finetuning Makes Models More Robust to Spurious Cues", "abstract": "Large Language Models (LLMs) are so powerful that they sometimes learn\ncorrelations between labels and features that are irrelevant to the task,\nleading to poor generalization on out-of-distribution data. We propose\nexplanation-based finetuning as a general approach to mitigate LLMs' reliance\non spurious correlations. Unlike standard finetuning where the model only\npredicts the answer given the input, we finetune the model to additionally\ngenerate a free-text explanation supporting its answer. To evaluate our method,\nwe finetune the model on artificially constructed training sets containing\ndifferent types of spurious cues, and test it on a test set without these cues.\nCompared to standard finetuning, our method makes GPT-3 (davinci) remarkably\nmore robust against spurious cues in terms of accuracy drop across four\nclassification tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC\n(+6.5). The efficacy generalizes across multiple model families and scales,\nwith greater gains for larger models. Finally, our method also works well with\nexplanations generated by the model, implying its applicability to more\ndatasets without human-written explanations.", "published": "2023-05-08 18:53:45", "link": "http://arxiv.org/abs/2305.04990v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do Not Blindly Imitate the Teacher: Using Perturbed Loss for Knowledge\n  Distillation", "abstract": "Knowledge distillation is a popular technique to transfer knowledge from\nlarge teacher models to a small student model. Typically, the student learns to\nimitate the teacher by minimizing the KL divergence of its output distribution\nwith the teacher's output distribution. In this work, we argue that such a\nlearning objective is sub-optimal because there exists a discrepancy between\nthe teacher's output distribution and the ground truth label distribution.\nTherefore, forcing the student to blindly imitate the unreliable teacher output\ndistribution leads to inferior performance. To this end, we propose a novel\nknowledge distillation objective PTLoss by first representing the vanilla\nKL-based distillation loss function via a Maclaurin series and then perturbing\nthe leading-order terms in this series. This perturbed loss implicitly\ntransforms the original teacher into a proxy teacher with a distribution closer\nto the ground truth distribution. We establish the theoretical connection\nbetween this \"distribution closeness\" and the student model generalizability,\nwhich enables us to select the PTLoss's perturbation coefficients in a\nprincipled way. Extensive experiments on five datasets demonstrate PTLoss can\nsignificantly improve the distillation effectiveness for teachers of various\nscales.", "published": "2023-05-08 19:31:09", "link": "http://arxiv.org/abs/2305.05010v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ANALOGICAL -- A Novel Benchmark for Long Text Analogy Evaluation in\n  Large Language Models", "abstract": "Over the past decade, analogies, in the form of word-level analogies, have\nplayed a significant role as an intrinsic measure of evaluating the quality of\nword embedding methods such as word2vec. Modern large language models (LLMs),\nhowever, are primarily evaluated on extrinsic measures based on benchmarks such\nas GLUE and SuperGLUE, and there are only a few investigations on whether LLMs\ncan draw analogies between long texts. In this paper, we present ANALOGICAL, a\nnew benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of\nlong text with six levels of complexity -- (i) word, (ii) word vs. sentence,\n(iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using\nthirteen datasets and three different distance measures, we evaluate the\nabilities of eight LLMs in identifying analogical pairs in the semantic vector\nspace. Our evaluation finds that it is increasingly challenging for LLMs to\nidentify analogies when going up the analogy taxonomy.", "published": "2023-05-08 21:12:20", "link": "http://arxiv.org/abs/2305.05050v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Coherent Wave Dynamics and Language Generation of a Generative\n  Pre-trained Transformer", "abstract": "Large Language Models (LLMs), such as the Generative Pretrained Transformer\n(GPT), have achieved tremendous success in various language tasks, but their\nemergent abilities have also raised many questions, concerns, and challenges\nthat need to be addressed. To gain a better understanding of the models' inner\nmechanisms, we analyze the hidden state and channel wave dynamics in a small\nGPT, focusing on the coherence of wave patterns in terms of cross-channel\ncorrelation and individual auto-correlation. Our findings suggest that wave\ndynamics offer consistent and repeatable intrinsic oscillation modes, along\nwith context-aware plasticity and expressiveness in language generation. By\nanalyzing wave patterns, coherence, and clustering, we provide a systematic way\nto identify and interpret the functionality of the hidden state channels,\npaving the way to understand and control higher-level language pattern\nformation. In addition, we investigate the Poisson statistics of spelling\nerrors in text sequence generation across various levels of model training and\nobserve a phase-transition-like process. As coherence builds up, there is a\ncompetition between the generation of correct and misspelled words. However,\nonce the model is adequately trained and significant coherence has emerged, the\ncoherent process becomes strong enough to effectively suppress spelling errors,\npreventing the cascade amplification of defects. The distribution of correct\nspellings transitions from Poissonian to Sub-Poissonian, while the distribution\nof misspellings shows the opposite trend. By leveraging concepts and techniques\nfrom quantum physics, we gain novel insights into the dynamics of the small\nGPT. This approach can be extended to larger language models that exhibit more\ncomplex coherent language patterns, opening up opportunities to interpret their\nemergent capabilities and develop more specialized models.", "published": "2023-05-08 21:35:12", "link": "http://arxiv.org/abs/2305.05061v1", "categories": ["cs.CL", "nlin.PS", "68T07", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Interactive Concept Learning for Uncovering Latent Themes in Large Text\n  Collections", "abstract": "Experts across diverse disciplines are often interested in making sense of\nlarge text collections. Traditionally, this challenge is approached either by\nnoisy unsupervised techniques such as topic models, or by following a manual\ntheme discovery process. In this paper, we expand the definition of a theme to\naccount for more than just a word distribution, and include generalized\nconcepts deemed relevant by domain experts. Then, we propose an interactive\nframework that receives and encodes expert feedback at different levels of\nabstraction. Our framework strikes a balance between automation and manual\ncoding, allowing experts to maintain control of their study while reducing the\nmanual effort required.", "published": "2023-05-08 23:43:15", "link": "http://arxiv.org/abs/2305.05094v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Algebra Error Classification with Large Language Models", "abstract": "Automated feedback as students answer open-ended math questions has\nsignificant potential in improving learning outcomes at large scale. A key part\nof automated feedback systems is an error classification component, which\nidentifies student errors and enables appropriate, predefined feedback to be\ndeployed. Most existing approaches to error classification use a rule-based\nmethod, which has limited capacity to generalize. Existing data-driven methods\navoid these limitations but specifically require mathematical expressions in\nstudent responses to be parsed into syntax trees. This requirement is itself a\nlimitation, since student responses are not always syntactically valid and\ncannot be converted into trees. In this work, we introduce a flexible method\nfor error classification using pre-trained large language models. We\ndemonstrate that our method can outperform existing methods in algebra error\nclassification, and is able to classify a larger set of student responses.\nAdditionally, we analyze common classification errors made by our method and\ndiscuss limitations of automated error classification.", "published": "2023-05-08 15:51:38", "link": "http://arxiv.org/abs/2305.06163v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Accessible Instruction-Following Agent", "abstract": "Humans can collaborate and complete tasks based on visual signals and\ninstruction from the environment. Training such a robot is difficult especially\ndue to the understanding of the instruction and the complicated environment.\nPrevious instruction-following agents are biased to English-centric corpus,\nmaking it unrealizable to be applied to users that use multiple languages or\neven low-resource languages. Nevertheless, the instruction-following agents are\npre-trained in a mode that assumes the user can observe the environment, which\nlimits its accessibility. In this work, we're trying to generalize the success\nof instruction-following agents to non-English languages with little corpus\nresources, and improve its intractability and accessibility. We introduce UVLN\n(Universal Vision-Language Navigation), a novel machine-translation\ninstructional augmented framework for cross-lingual vision-language navigation,\nwith a novel composition of state-of-the-art large language model (GPT3) with\nthe image caption model (BLIP). We first collect a multilanguage\nvision-language navigation dataset via machine translation. Then we extend the\nstandard VLN training objectives to a multilingual setting via a cross-lingual\nlanguage encoder. The alignment between different languages is captured through\na shared vision and action context via a cross-modal transformer, which encodes\nthe inputs of language instruction, visual observation, and action decision\nsequences. To improve the intractability, we connect our agent with the large\nlanguage model that informs the situation and current state to the user and\nalso explains the action decisions. Experiments over Room Across Room Dataset\nprove the effectiveness of our approach. And the qualitative results show the\npromising intractability and accessibility of our instruction-following agent.", "published": "2023-05-08 23:57:26", "link": "http://arxiv.org/abs/2305.06358v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Imitation versus Innovation: What children can do that large language\n  and language-and-vision models cannot (yet)?", "abstract": "Much discussion about large language models and language-and-vision models\nhas focused on whether these models are intelligent agents. We present an\nalternative perspective. We argue that these artificial intelligence models are\ncultural technologies that enhance cultural transmission in the modern world,\nand are efficient imitation engines. We explore what AI models can tell us\nabout imitation and innovation by evaluating their capacity to design new tools\nand discover novel causal structures, and contrast their responses with those\nof human children. Our work serves as a first step in determining which\nparticular representations and competences, as well as which kinds of knowledge\nor skill, can be derived from particular learning techniques and data.\nCritically, our findings suggest that machines may need more than large scale\nlanguage and images to achieve what a child can do.", "published": "2023-05-08 18:26:39", "link": "http://arxiv.org/abs/2305.07666v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ChatGPT: Vision and Challenges", "abstract": "Artificial intelligence (AI) and machine learning have changed the nature of\nscientific inquiry in recent years. Of these, the development of virtual\nassistants has accelerated greatly in the past few years, with ChatGPT becoming\na prominent AI language model. In this study, we examine the foundations,\nvision, research challenges of ChatGPT. This article investigates into the\nbackground and development of the technology behind it, as well as its popular\napplications. Moreover, we discuss the advantages of bringing everything\ntogether through ChatGPT and Internet of Things (IoT). Further, we speculate on\nthe future of ChatGPT by considering various possibilities for study and\ndevelopment, such as energy-efficiency, cybersecurity, enhancing its\napplicability to additional technologies (Robotics and Computer Vision),\nstrengthening human-AI communications, and bridging the technological gap.\nFinally, we discuss the important ethics and current trends of ChatGPT.", "published": "2023-05-08 14:54:44", "link": "http://arxiv.org/abs/2305.15323v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "The impact and applications of ChatGPT: a systematic review of\n  literature reviews", "abstract": "The conversational artificial-intelligence (AI) technology ChatGPT has become\none of the most widely used natural language processing tools. With thousands\nof published papers demonstrating its applications across various industries\nand fields, ChatGPT has sparked significant interest in the research community.\nReviews of primary data have also begun to emerge. An overview of the available\nevidence from multiple reviews and studies could provide further insights,\nminimize redundancy, and identify areas where further research is needed.\nObjective: To evaluate the existing reviews and literature related to ChatGPT's\napplications and its potential impact on different fields by conducting a\nsystematic review of reviews and bibliometric analysis of primary literature.\nMethods: PubMed, EuropePMC, Dimensions AI, medRxiv, bioRxiv, arXiv, and Google\nScholar were searched for ChatGPT-related publications from 2022 to 4/30/2023.\nStudies including secondary data related to the application of ChatGPT were\nconsidered. Reporting and risk of bias assesment was performed using PRISMA\nguidelines. Results: A total of 305 unique records with potential relevance to\nthe review were identified from a pool of over 2,000 original articles. After\nmulti-step screening process, 11 reviews were selected, consisting of 9 reviews\nspecifically focused on ChatGPT and 2 reviews on broader AI topics that also\nincluded discussions on ChatGPT. We also conducted bibliometric analysis of\nprimary data. Conclusions: While AI has the potential to revolutionize various\nindustries, further interdisciplinary research, customized integrations, and\nethical innovation are necessary to address existing concerns and ensure its\nresponsible use. Protocol Registration: PROSPERO registration no.\nCRD42023417336, DOI 10.17605/OSF.IO/87U6Q.", "published": "2023-05-08 17:57:34", "link": "http://arxiv.org/abs/2305.18086v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Do Large Language Models Show Decision Heuristics Similar to Humans? A\n  Case Study Using GPT-3.5", "abstract": "A Large Language Model (LLM) is an artificial intelligence system that has\nbeen trained on vast amounts of natural language data, enabling it to generate\nhuman-like responses to written or spoken language input. GPT-3.5 is an example\nof an LLM that supports a conversational agent called ChatGPT. In this work, we\nused a series of novel prompts to determine whether ChatGPT shows heuristics,\nbiases, and other decision effects. We also tested the same prompts on human\nparticipants. Across four studies, we found that ChatGPT was influenced by\nrandom anchors in making estimates (Anchoring Heuristic, Study 1); it judged\nthe likelihood of two events occurring together to be higher than the\nlikelihood of either event occurring alone, and it was erroneously influenced\nby salient anecdotal information (Representativeness and Availability\nHeuristic, Study 2); it found an item to be more efficacious when its features\nwere presented positively rather than negatively - even though both\npresentations contained identical information (Framing Effect, Study 3); and it\nvalued an owned item more than a newly found item even though the two items\nwere identical (Endowment Effect, Study 4). In each study, human participants\nshowed similar effects. Heuristics and related decision effects in humans are\nthought to be driven by cognitive and affective processes such as loss aversion\nand effort reduction. The fact that an LLM - which lacks these processes - also\nshows such effects invites consideration of the possibility that language may\nplay a role in generating these effects in humans.", "published": "2023-05-08 01:02:52", "link": "http://arxiv.org/abs/2305.04400v1", "categories": ["cs.AI", "cs.CL", "q-bio.NC"], "primary_category": "cs.AI"}
{"title": "AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment", "abstract": "The speech-to-singing (STS) voice conversion task aims to generate singing\nsamples corresponding to speech recordings while facing a major challenge: the\nalignment between the target (singing) pitch contour and the source (speech)\ncontent is difficult to learn in a text-free situation. This paper proposes\nAlignSTS, an STS model based on explicit cross-modal alignment, which views\nspeech variance such as pitch and content as different modalities. Inspired by\nthe mechanism of how humans will sing the lyrics to the melody, AlignSTS: 1)\nadopts a novel rhythm adaptor to predict the target rhythm representation to\nbridge the modality gap between content and pitch, where the rhythm\nrepresentation is computed in a simple yet effective way and is quantized into\na discrete space; and 2) uses the predicted rhythm representation to re-align\nthe content based on cross-attention and conducts a cross-modal fusion for\nre-synthesize. Extensive experiments show that AlignSTS achieves superior\nperformance in terms of both objective and subjective metrics. Audio samples\nare available at https://alignsts.github.io.", "published": "2023-05-08 06:02:10", "link": "http://arxiv.org/abs/2305.04476v4", "categories": ["eess.AS", "cs.CL", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sparks of Artificial General Recommender (AGR): Early Experiments with\n  ChatGPT", "abstract": "This study investigates the feasibility of developing an Artificial General\nRecommender (AGR), facilitated by recent advancements in Large Language Models\n(LLMs). An AGR comprises both conversationality and universality to engage in\nnatural dialogues and generate recommendations across various domains. We\npropose ten fundamental principles that an AGR should adhere to, each with its\ncorresponding testing protocols. We proceed to assess whether ChatGPT, a\nsophisticated LLM, can comply with the proposed principles by engaging in\nrecommendation-oriented dialogues with the model while observing its behavior.\nOur findings demonstrate the potential for ChatGPT to serve as an AGR, though\nseveral limitations and areas for improvement are identified.", "published": "2023-05-08 07:28:16", "link": "http://arxiv.org/abs/2305.04518v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Prompted LLMs as Chatbot Modules for Long Open-domain Conversation", "abstract": "In this paper, we propose MPC (Modular Prompted Chatbot), a new approach for\ncreating high-quality conversational agents without the need for fine-tuning.\nOur method utilizes pre-trained large language models (LLMs) as individual\nmodules for long-term consistency and flexibility, by using techniques such as\nfew-shot prompting, chain-of-thought (CoT), and external memory. Our human\nevaluation results show that MPC is on par with fine-tuned chatbot models in\nopen-domain conversations, making it an effective solution for creating\nconsistent and engaging chatbots.", "published": "2023-05-08 08:09:00", "link": "http://arxiv.org/abs/2305.04533v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Putting Natural in Natural Language Processing", "abstract": "Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.", "published": "2023-05-08 09:29:31", "link": "http://arxiv.org/abs/2305.04572v2", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Augmented Large Language Models with Parametric Knowledge Guiding", "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing (NLP) with their impressive language understanding and generation\ncapabilities. However, their performance may be suboptimal for domain-specific\ntasks that require specialized knowledge due to limited exposure to the related\ndata. Additionally, the lack of transparency of most state-of-the-art (SOTA)\nLLMs, which can only be accessed via APIs, impedes further fine-tuning with\ndomain custom data. Moreover, providing private data to the LLMs' owner leads\nto data privacy problems. To address these challenges, we propose the novel\nParametric Knowledge Guiding (PKG) framework, which equips LLMs with a\nknowledge-guiding module to access relevant knowledge without altering the\nLLMs' parameters. Our PKG is based on open-source \"white-box\" language models,\nallowing offline memory of any knowledge that LLMs require. We demonstrate that\nour PKG framework can enhance the performance of \"black-box\" LLMs on a range of\ndomain knowledge-intensive tasks that require factual (+7.9%), tabular\n(+11.9%), medical (+3.0%), and multimodal (+8.1%) knowledge.", "published": "2023-05-08 15:05:16", "link": "http://arxiv.org/abs/2305.04757v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HistAlign: Improving Context Dependency in Language Generation by\n  Aligning with History", "abstract": "Language models (LMs) can generate hallucinations and incoherent outputs,\nwhich highlights their weak context dependency. Cache-LMs, which augment LMs\nwith a memory of recent history, can increase context dependency and have shown\nremarkable performance in diverse language generation tasks. However, we find\nthat even with training, the performance gain stemming from the cache component\nof current cache-LMs is suboptimal due to the misalignment between the current\nhidden states and those stored in the memory. In this work, we present\nHistAlign, a new training approach to ensure good cache alignment such that the\nmodel receives useful signals from the history. We first prove our concept on a\nsimple and synthetic task where the memory is essential for correct\npredictions, and we show that the cache component of HistAlign is better\naligned and improves overall performance. Next, we evaluate HistAlign on\ndiverse downstream language generation tasks, including prompt continuation,\nabstractive summarization, and data-to-text. We demonstrate that HistAlign\nimproves text coherence and faithfulness in open-ended and conditional\ngeneration settings respectively. HistAlign is also generalizable across\ndifferent model families, showcasing its strength in improving context\ndependency of LMs in diverse scenarios. Our code is publicly available at\nhttps://github.com/meetdavidwan/histalign", "published": "2023-05-08 15:34:56", "link": "http://arxiv.org/abs/2305.04782v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What Do Patients Say About Their Disease Symptoms? Deep Multilabel Text\n  Classification With Human-in-the-Loop Curation for Automatic Labeling of\n  Patient Self Reports of Problems", "abstract": "The USA Food and Drug Administration has accorded increasing importance to\npatient-reported problems in clinical and research settings. In this paper, we\nexplore one of the largest online datasets comprising 170,141 open-ended\nself-reported responses (called \"verbatims\") from patients with Parkinson's\n(PwPs) to questions about what bothers them about their Parkinson's Disease and\nhow it affects their daily functioning, also known as the Parkinson's Disease\nPatient Report of Problems. Classifying such verbatims into multiple clinically\nrelevant symptom categories is an important problem and requires multiple steps\n- expert curation, a multi-label text classification (MLTC) approach and large\namounts of labelled training data. Further, human annotation of such large\ndatasets is tedious and expensive. We present a novel solution to this problem\nwhere we build a baseline dataset using 2,341 (of the 170,141) verbatims\nannotated by nine curators including clinical experts and PwPs. We develop a\nrules based linguistic-dictionary using NLP techniques and graph database-based\nexpert phrase-query system to scale the annotation to the remaining cohort\ngenerating the machine annotated dataset, and finally build a Keras-Tensorflow\nbased MLTC model for both datasets. The machine annotated model significantly\noutperforms the baseline model with a F1-score of 95% across 65 symptom\ncategories on a held-out test set.", "published": "2023-05-08 17:42:23", "link": "http://arxiv.org/abs/2305.04905v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder\n  Models for More Efficient Code Classification", "abstract": "The use of modern Natural Language Processing (NLP) techniques has shown to\nbe beneficial for software engineering tasks, such as vulnerability detection\nand type inference. However, training deep NLP models requires significant\ncomputational resources. This paper explores techniques that aim at achieving\nthe best usage of resources and available information in these models.\n  We propose a generic approach, EarlyBIRD, to build composite representations\nof code from the early layers of a pre-trained transformer model. We\nempirically investigate the viability of this approach on the CodeBERT model by\ncomparing the performance of 12 strategies for creating composite\nrepresentations with the standard practice of only using the last encoder\nlayer.\n  Our evaluation on four datasets shows that several early layer combinations\nyield better performance on defect detection, and some combinations improve\nmulti-class classification. More specifically, we obtain a +2 average\nimprovement of detection accuracy on Devign with only 3 out of 12 layers of\nCodeBERT and a 3.3x speed-up of fine-tuning. These findings show that early\nlayers can be used to obtain better results using the same resources, as well\nas to reduce resource usage during fine-tuning and inference.", "published": "2023-05-08 16:47:28", "link": "http://arxiv.org/abs/2305.04940v2", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Joint Moment Retrieval and Highlight Detection Via Natural Language\n  Queries", "abstract": "Video summarization has become an increasingly important task in the field of\ncomputer vision due to the vast amount of video content available on the\ninternet. In this project, we propose a new method for natural language query\nbased joint video summarization and highlight detection using multi-modal\ntransformers. This approach will use both visual and audio cues to match a\nuser's natural language query to retrieve the most relevant and interesting\nmoments from a video. Our approach employs multiple recent techniques used in\nVision Transformers (ViTs) to create a transformer-like encoder-decoder model.\nWe evaluated our approach on multiple datasets such as YouTube Highlights and\nTVSum to demonstrate the flexibility of our proposed method.", "published": "2023-05-08 18:00:33", "link": "http://arxiv.org/abs/2305.04961v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Web Content Filtering through knowledge distillation of Large Language\n  Models", "abstract": "We introduce a state-of-the-art approach for URL categorization that\nleverages the power of Large Language Models (LLMs) to address the primary\nobjectives of web content filtering: safeguarding organizations from legal and\nethical risks, limiting access to high-risk or suspicious websites, and\nfostering a secure and professional work environment. Our method utilizes LLMs\nto generate accurate classifications and then employs established knowledge\ndistillation techniques to create smaller, more specialized student models\ntailored for web content filtering. Distillation results in a student model\nwith a 9% accuracy rate improvement in classifying websites, sourced from\ncustomer telemetry data collected by a large security vendor, into 30 distinct\ncontent categories based on their URLs, surpassing the current state-of-the-art\napproach. Our student model matches the performance of the teacher LLM with 175\ntimes less parameters, allowing the model to be used for in-line scanning of\nlarge volumes of URLs, and requires 3 orders of magnitude less manually labeled\ntraining data than the current state-of-the-art approach. Depending on the\nspecific use case, the output generated by our approach can either be directly\nreturned or employed as a pre-filter for more resource-intensive operations\ninvolving website images or HTML.", "published": "2023-05-08 20:09:27", "link": "http://arxiv.org/abs/2305.05027v2", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Knowledge-enhanced Agents for Interactive Text Games", "abstract": "Communication via natural language is a key aspect of machine intelligence,\nand it requires computational models to learn and reason about world concepts,\nwith varying levels of supervision. Significant progress has been made on\nfully-supervised non-interactive tasks, such as question-answering and\nprocedural text understanding. Yet, various sequential interactive tasks, as in\ntext-based games, have revealed limitations of existing approaches in terms of\ncoherence, contextual awareness, and their ability to learn effectively from\nthe environment. In this paper, we propose a knowledge-injection framework for\nimproved functional grounding of agents in text-based games. Specifically, we\nconsider two forms of domain knowledge that we inject into learning-based\nagents: memory of previous correct actions and affordances of relevant objects\nin the environment. Our framework supports two representative model classes:\nreinforcement learning agents and language model agents. Furthermore, we devise\nmultiple injection strategies for the above domain knowledge types and agent\narchitectures, including injection via knowledge graphs and augmentation of the\nexisting input encoding strategies. We experiment with four models on the 10\ntasks in the ScienceWorld text-based game environment, to illustrate the impact\nof knowledge injection on various model configurations and challenging task\nsettings. Our findings provide crucial insights into the interplay between task\nproperties, model architectures, and domain knowledge for interactive contexts.", "published": "2023-05-08 23:31:39", "link": "http://arxiv.org/abs/2305.05091v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Code Execution with Pre-trained Language Models", "abstract": "Code execution is a fundamental aspect of programming language semantics that\nreflects the exact behavior of the code. However, most pre-trained models for\ncode intelligence ignore the execution trace and only rely on source code and\nsyntactic structures. In this paper, we investigate how well pre-trained models\ncan understand and perform code execution. We develop a mutation-based data\naugmentation technique to create a large-scale and realistic Python dataset and\ntask for code execution, which challenges existing models such as Codex. We\nthen present CodeExecutor, a Transformer model that leverages code execution\npre-training and curriculum learning to enhance its semantic comprehension. We\nevaluate CodeExecutor on code execution and show its promising performance and\nlimitations. We also demonstrate its potential benefits for code intelligence\ntasks such as zero-shot code-to-code search and text-to-code generation. Our\nanalysis provides insights into the learning and generalization abilities of\npre-trained models for code execution.", "published": "2023-05-08 10:00:05", "link": "http://arxiv.org/abs/2305.05383v1", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.PL"}
{"title": "Multi-Task End-to-End Training Improves Conversational Recommendation", "abstract": "In this paper, we analyze the performance of a multitask end-to-end\ntransformer model on the task of conversational recommendations, which aim to\nprovide recommendations based on a user's explicit preferences expressed in\ndialogue. While previous works in this area adopt complex multi-component\napproaches where the dialogue management and entity recommendation tasks are\nhandled by separate components, we show that a unified transformer model, based\non the T5 text-to-text transformer model, can perform competitively in both\nrecommending relevant items and generating conversation dialogue. We fine-tune\nour model on the ReDIAL conversational movie recommendation dataset, and create\nadditional training tasks derived from MovieLens (such as the prediction of\nmovie attributes and related movies based on an input movie), in a multitask\nlearning setting. Using a series of probe studies, we demonstrate that the\nlearned knowledge in the additional tasks is transferred to the conversational\nsetting, where each task leads to a 9%-52% increase in its related probe score.", "published": "2023-05-08 22:42:48", "link": "http://arxiv.org/abs/2305.06218v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ComputeGPT: A computational chat model for numerical problems", "abstract": "Language models are not accurate in numerical problems. Their architecture\ndoes not allow for anything less than a probabilistic next word. This paper\nintroduces ComputeGPT: an approach of creating a chat model able to answer\ncomputational problems through running on-demand code. ComputeGPT converts each\nquestion to relevant code, runs the code, and returns the computed answer as\npart of the chat. We combine this approach with a local browser-based Python\ninterpretation and fine-tuned prompts in order to achieve state-of-the-art\nefficiency on numerical problems and provide a suitable front-end and safe\nenvironment for the code to be executed in.", "published": "2023-05-08 19:21:41", "link": "http://arxiv.org/abs/2305.06223v1", "categories": ["cs.PL", "cs.AI", "cs.CL", "68T50, 68N18, 97R50", "I.2.7; I.2.6; H.5.2"], "primary_category": "cs.PL"}
{"title": "Neural Steerer: Novel Steering Vector Synthesis with a Causal Neural\n  Field over Frequency and Source Positions", "abstract": "We address the problem of accurately interpolating measured anechoic steering\nvectors with a deep learning framework called the neural field. This task plays\na pivotal role in reducing the resource-intensive measurements required for\nprecise sound source separation and localization, essential as the front-end of\nspeech recognition. Classical approaches to interpolation rely on linear\nweighting of nearby measurements in space on a fixed, discrete set of\nfrequencies. Drawing inspiration from the success of neural fields for novel\nview synthesis in computer vision, we introduce the neural steerer, a\ncontinuous complex-valued function that takes both frequency and direction as\ninput and produces the corresponding steering vector. Importantly, it\nincorporates inter-channel phase difference information and a regularization\nterm enforcing filter causality, essential for accurate steering vector\nmodeling. Our experiments, conducted using a dataset of real measured steering\nvectors, demonstrate the effectiveness of our resolution-free model in\ninterpolating such measurements.", "published": "2023-05-08 03:51:36", "link": "http://arxiv.org/abs/2305.04447v4", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-Temporal Lip-Audio Memory for Visual Speech Recognition", "abstract": "Visual Speech Recognition (VSR) is a task to predict a sentence or word from\nlip movements. Some works have been recently presented which use audio signals\nto supplement visual information. However, existing methods utilize only\nlimited information such as phoneme-level features and soft labels of Automatic\nSpeech Recognition (ASR) networks. In this paper, we present a Multi-Temporal\nLip-Audio Memory (MTLAM) that makes the best use of audio signals to complement\ninsufficient information of lip movements. The proposed method is mainly\ncomposed of two parts: 1) MTLAM saves multi-temporal audio features produced\nfrom short- and long-term audio signals, and the MTLAM memorizes a\nvisual-to-audio mapping to load stored multi-temporal audio features from\nvisual features at the inference phase. 2) We design an audio temporal model to\nproduce multi-temporal audio features capturing the context of neighboring\nwords. In addition, to construct effective visual-to-audio mapping, the audio\ntemporal models can generate audio features time-aligned with visual features.\nThrough extensive experiments, we validate the effectiveness of the MTLAM\nachieving state-of-the-art performances on two public VSR datasets.", "published": "2023-05-08 08:30:52", "link": "http://arxiv.org/abs/2305.04542v1", "categories": ["cs.CV", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Accented Text-to-Speech Synthesis with Limited Data", "abstract": "This paper presents an accented text-to-speech (TTS) synthesis framework with\nlimited training data. We study two aspects concerning accent rendering:\nphonetic (phoneme difference) and prosodic (pitch pattern and phoneme duration)\nvariations. The proposed accented TTS framework consists of two models: an\naccented front-end for grapheme-to-phoneme (G2P) conversion and an accented\nacoustic model with integrated pitch and duration predictors for\nphoneme-to-Mel-spectrogram prediction. The accented front-end directly models\nthe phonetic variation, while the accented acoustic model explicitly controls\nthe prosodic variation. Specifically, both models are first pre-trained on a\nlarge amount of data, then only the accent-related layers are fine-tuned on a\nlimited amount of data for the target accent. In the experiments, speech data\nof three English accents, i.e., General American English, Irish English, and\nBritish English Received Pronunciation, are used for pre-training. The\npre-trained models are then fine-tuned with Scottish and General Australian\nEnglish accents, respectively. Both objective and subjective evaluation results\nshow that the accented TTS front-end fine-tuned with a small accented phonetic\nlexicon (5k words) effectively handles the phonetic variation of accents, while\nthe accented TTS acoustic model fine-tuned with a limited amount of accented\nspeech data (approximately 3 minutes) effectively improves the prosodic\nrendering including pitch and duration. The overall accent modeling contributes\nto improved speech quality and accent similarity.", "published": "2023-05-08 16:15:39", "link": "http://arxiv.org/abs/2305.04816v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fast Conformer with Linearly Scalable Attention for Efficient Speech\n  Recognition", "abstract": "Conformer-based models have become the dominant end-to-end architecture for\nspeech processing tasks. With the objective of enhancing the conformer\narchitecture for efficient training and inference, we carefully redesigned\nConformer with a novel downsampling schema. The proposed model, named Fast\nConformer(FC), is 2.8x faster than the original Conformer, supports scaling to\nBillion parameters without any changes to the core architecture and also\nachieves state-of-the-art accuracy on Automatic Speech Recognition benchmarks.\nTo enable transcription of long-form speech up to 11 hours, we replaced global\nattention with limited context attention post-training, while also improving\naccuracy through fine-tuning with the addition of a global token. Fast\nConformer, when combined with a Transformer decoder also outperforms the\noriginal Conformer in accuracy and in speed for Speech Translation and Spoken\nLanguage Understanding.", "published": "2023-05-08 22:54:07", "link": "http://arxiv.org/abs/2305.05084v6", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A method for analyzing sampling jitter in audio equipment", "abstract": "A method for analyzing sampling jitter in audio equipment is proposed. The\nmethod is based on the time-domain analysis where the time fluctuations of\nzero-crossing points in recorded sinusoidal waves are employed to characterize\njitter. This method enables the separate evaluation of jitter in an audio\nplayer from those in audio recorders when the same playback signal is\nsimultaneously fed into two audio recorders. Experiments are conducted using\ncommercially available portable devices with a maximum sampling rate of 192~000\nsamples per second. The results show jitter values of a few tens of picoseconds\ncan be identified in an audio player. Moreover, the proposed method enables the\nseparation of jitter from phase-independent noise utilizing the left and right\nchannels of the audio equipment. As such, this method is applicable for\nperformance evaluation of audio equipment, signal generators, and clock\nsources.", "published": "2023-05-08 08:06:04", "link": "http://arxiv.org/abs/2305.04531v1", "categories": ["cs.SD", "eess.AS", "physics.ins-det"], "primary_category": "cs.SD"}
