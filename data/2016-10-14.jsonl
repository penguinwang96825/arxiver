{"title": "A Language-independent and Compositional Model for Personality Trait\n  Recognition from Short Texts", "abstract": "Many methods have been used to recognize author personality traits from text,\ntypically combining linguistic feature engineering with shallow learning\nmodels, e.g. linear regression or Support Vector Machines. This work uses\ndeep-learning-based models and atomic features of text, the characters, to\nbuild hierarchical, vectorial word and sentence representations for trait\ninference. This method, applied to a corpus of tweets, shows state-of-the-art\nperformance across five traits and three languages (English, Spanish and\nItalian) compared with prior work in author profiling. The results, supported\nby preliminary visualisation work, are encouraging for the ability to detect\ncomplex human traits.", "published": "2016-10-14 07:14:44", "link": "http://arxiv.org/abs/1610.04345v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Distributional Inclusion Hypothesis for Tensor-based Composition", "abstract": "According to the distributional inclusion hypothesis, entailment between\nwords can be measured via the feature inclusions of their distributional\nvectors. In recent work, we showed how this hypothesis can be extended from\nwords to phrases and sentences in the setting of compositional distributional\nsemantics. This paper focuses on inclusion properties of tensors; its main\ncontribution is a theoretical and experimental analysis of how feature\ninclusion works in different concrete models of verb tensors. We present\nresults for relational, Frobenius, projective, and holistic methods and compare\nthem to the simple vector addition, multiplication, min, and max models. The\ndegrees of entailment thus obtained are evaluated via a variety of existing\nword-based measures, such as Weed's and Clarke's, KL-divergence, APinc,\nbalAPinc, and two of our previously proposed metrics at the phrase/sentence\nlevel. We perform experiments on three entailment datasets, investigating which\nversion of tensor-based composition achieves the highest performance when\ncombined with the sentence-level measures.", "published": "2016-10-14 11:52:19", "link": "http://arxiv.org/abs/1610.04416v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Civique: Using Social Media to Detect Urban Emergencies", "abstract": "We present the Civique system for emergency detection in urban areas by\nmonitoring micro blogs like Tweets. The system detects emergency related\nevents, and classifies them into appropriate categories like \"fire\",\n\"accident\", \"earthquake\", etc. We demonstrate our ideas by classifying Twitter\nposts in real time, visualizing the ongoing event on a map interface and\nalerting users with options to contact relevant authorities, both online and\noffline. We evaluate our classifiers for both the steps, i.e., emergency\ndetection and categorization, and obtain F-scores exceeding 70% and 90%,\nrespectively. We demonstrate Civique using a web interface and on an Android\napplication, in realtime, and show its use for both tweet detection and\nvisualization.", "published": "2016-10-14 09:06:36", "link": "http://arxiv.org/abs/1610.04377v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Simultaneous Learning of Trees and Representations for Extreme\n  Classification and Density Estimation", "abstract": "We consider multi-class classification where the predictor has a hierarchical\nstructure that allows for a very large number of labels both at train and test\ntime. The predictive power of such models can heavily depend on the structure\nof the tree, and although past work showed how to learn the tree structure, it\nexpected that the feature vectors remained static. We provide a novel algorithm\nto simultaneously perform representation learning for the input data and\nlearning of the hierarchi- cal predictor. Our approach optimizes an objec- tive\nfunction which favors balanced and easily- separable multi-way node partitions.\nWe theoret- ically analyze this objective, showing that it gives rise to a\nboosting style property and a bound on classification error. We next show how\nto extend the algorithm to conditional density estimation. We empirically\nvalidate both variants of the al- gorithm on text classification and language\nmod- eling, respectively, and show that they compare favorably to common\nbaselines in terms of accu- racy and running time.", "published": "2016-10-14 22:03:15", "link": "http://arxiv.org/abs/1610.04658v2", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
