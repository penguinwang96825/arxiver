{"title": "Does Manipulating Tokenization Aid Cross-Lingual Transfer? A Study on\n  POS Tagging for Non-Standardized Languages", "abstract": "One of the challenges with finetuning pretrained language models (PLMs) is\nthat their tokenizer is optimized for the language(s) it was pretrained on, but\nbrittle when it comes to previously unseen variations in the data. This can for\ninstance be observed when finetuning PLMs on one language and evaluating them\non data in a closely related language variety with no standardized orthography.\nDespite the high linguistic similarity, tokenization no longer corresponds to\nmeaningful representations of the target data, leading to low performance in,\ne.g., part-of-speech tagging.\n  In this work, we finetune PLMs on seven languages from three different\nfamilies and analyze their zero-shot performance on closely related,\nnon-standardized varieties. We consider different measures for the divergence\nin the tokenization of the source and target data, and the way they can be\nadjusted by manipulating the tokenization during the finetuning step. Overall,\nwe find that the similarity between the percentage of words that get split into\nsubwords in the source and target data (the split word ratio difference) is the\nstrongest predictor for model performance on target data.", "published": "2023-04-20 08:32:34", "link": "http://arxiv.org/abs/2304.10158v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing FOMC Minutes: Accuracy and Constraints of Language Models", "abstract": "This research article analyzes the language used in the official statements\nreleased by the Federal Open Market Committee (FOMC) after its scheduled\nmeetings to gain insights into the impact of FOMC official statements on\nfinancial markets and economic forecasting. The study reveals that the FOMC is\ncareful to avoid expressing emotion in their sentences and follows a set of\ntemplates to cover economic situations. The analysis employs advanced language\nmodeling techniques such as VADER and FinBERT, and a trial test with GPT-4. The\nresults show that FinBERT outperforms other techniques in predicting negative\nsentiment accurately. However, the study also highlights the challenges and\nlimitations of using current NLP techniques to analyze FOMC texts and suggests\nthe potential for enhancing language models and exploring alternative\napproaches.", "published": "2023-04-20 08:54:00", "link": "http://arxiv.org/abs/2304.10164v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Paracrawl for Document-level Neural Machine Translation", "abstract": "Document-level neural machine translation (NMT) has outperformed\nsentence-level NMT on a number of datasets. However, document-level NMT is\nstill not widely adopted in real-world translation systems mainly due to the\nlack of large-scale general-domain training data for document-level NMT. We\nexamine the effectiveness of using Paracrawl for learning document-level\ntranslation. Paracrawl is a large-scale parallel corpus crawled from the\nInternet and contains data from various domains. The official Paracrawl corpus\nwas released as parallel sentences (extracted from parallel webpages) and\ntherefore previous works only used Paracrawl for learning sentence-level\ntranslation. In this work, we extract parallel paragraphs from Paracrawl\nparallel webpages using automatic sentence alignments and we use the extracted\nparallel paragraphs as parallel documents for training document-level\ntranslation models. We show that document-level NMT models trained with only\nparallel paragraphs from Paracrawl can be used to translate real documents from\nTED, News and Europarl, outperforming sentence-level NMT models. We also\nperform a targeted pronoun evaluation and show that document-level models\ntrained with Paracrawl data can help context-aware pronoun translation.", "published": "2023-04-20 11:21:34", "link": "http://arxiv.org/abs/2304.10216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Open Intent Classification with K-center Contrastive Learning\n  and Adjustable Decision Boundary", "abstract": "Open intent classification, which aims to correctly classify the known\nintents into their corresponding classes while identifying the new unknown\n(open) intents, is an essential but challenging task in dialogue systems. In\nthis paper, we introduce novel K-center contrastive learning and adjustable\ndecision boundary learning (CLAB) to improve the effectiveness of open intent\nclassification. First, we pre-train a feature encoder on the labeled training\ninstances, which transfers knowledge from known intents to unknown intents.\nSpecifically, we devise a K-center contrastive learning algorithm to learn\ndiscriminative and balanced intent features, improving the generalization of\nthe model for recognizing open intents. Second, we devise an adjustable\ndecision boundary learning method with expanding and shrinking (ADBES) to\ndetermine the suitable decision conditions. Concretely, we learn a decision\nboundary for each known intent class, which consists of a decision center and\nthe radius of the decision boundary. We then expand the radius of the decision\nboundary to accommodate more in-class instances if the out-of-class instances\nare far from the decision boundary; otherwise, we shrink the radius of the\ndecision boundary. Extensive experiments on three benchmark datasets clearly\ndemonstrate the effectiveness of our method for open intent classification. For\nreproducibility, we submit the code at: https://github.com/lxk00/CLAP", "published": "2023-04-20 11:35:06", "link": "http://arxiv.org/abs/2304.10220v1", "categories": ["cs.CL", "68T01", "I.2.1"], "primary_category": "cs.CL"}
{"title": "Interventional Probing in High Dimensions: An NLI Case Study", "abstract": "Probing strategies have been shown to detect the presence of various\nlinguistic features in large language models; in particular, semantic features\nintermediate to the \"natural logic\" fragment of the Natural Language Inference\ntask (NLI). In the case of natural logic, the relation between the intermediate\nfeatures and the entailment label is explicitly known: as such, this provides a\nripe setting for interventional studies on the NLI models' representations,\nallowing for stronger causal conjectures and a deeper critical analysis of\ninterventional probing methods. In this work, we carry out new and existing\nrepresentation-level interventions to investigate the effect of these semantic\nfeatures on NLI classification: we perform amnesic probing (which removes\nfeatures as directed by learned linear probes) and introduce the mnestic\nprobing variation (which forgets all dimensions except the probe-selected\nones). Furthermore, we delve into the limitations of these methods and outline\nsome pitfalls have been obscuring the effectivity of interventional probing\nstudies.", "published": "2023-04-20 14:34:31", "link": "http://arxiv.org/abs/2304.10346v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-Learning for Cross-Lingual Relation Extraction", "abstract": "Relation Extraction (RE) is a crucial task in Information Extraction, which\nentails predicting relationships between entities within a given sentence.\nHowever, extending pre-trained RE models to other languages is challenging,\nparticularly in real-world scenarios where Cross-Lingual Relation Extraction\n(XRE) is required. Despite recent advancements in Prompt-Learning, which\ninvolves transferring knowledge from Multilingual Pre-trained Language Models\n(PLMs) to diverse downstream tasks, there is limited research on the effective\nuse of multilingual PLMs with prompts to improve XRE. In this paper, we present\na novel XRE algorithm based on Prompt-Tuning, referred to as Prompt-XRE. To\nevaluate its effectiveness, we design and implement several prompt templates,\nincluding hard, soft, and hybrid prompts, and empirically test their\nperformance on competitive multilingual PLMs, specifically mBART. Our extensive\nexperiments, conducted on the low-resource ACE05 benchmark across multiple\nlanguages, demonstrate that our Prompt-XRE algorithm significantly outperforms\nboth vanilla multilingual PLMs and other existing models, achieving\nstate-of-the-art performance in XRE. To further show the generalization of our\nPrompt-XRE on larger data scales, we construct and release a new XRE dataset-\nWMT17-EnZh XRE, containing 0.9M English-Chinese pairs extracted from WMT 2017\nparallel corpus. Experiments on WMT17-EnZh XRE also show the effectiveness of\nour Prompt-XRE against other competitive baselines. The code and newly\nconstructed dataset are freely available at\n\\url{https://github.com/HSU-CHIA-MING/Prompt-XRE}.", "published": "2023-04-20 14:52:06", "link": "http://arxiv.org/abs/2304.10354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CKBP v2: Better Annotation and Reasoning for Commonsense Knowledge Base\n  Population", "abstract": "Commonsense Knowledge Bases (CSKB) Population, which aims at automatically\nexpanding knowledge in CSKBs with external resources, is an important yet hard\ntask in NLP. Fang et al. (2021a) proposed a CSKB Population (CKBP) framework\nwith an evaluation set CKBP v1. However, CKBP v1 relies on crowdsourced\nannotations that suffer from a considerable number of mislabeled answers, and\nthe evaluationset lacks alignment with the external knowledge source due to\nrandom sampling. In this paper, we introduce CKBP v2, a new high-quality CSKB\nPopulation evaluation set that addresses the two aforementioned issues by\nemploying domain experts as annotators and incorporating diversified\nadversarial samples to make the evaluation data more representative. We show\nthat CKBP v2 serves as a challenging and representative evaluation dataset for\nthe CSKB Population task, while its development set aids in selecting a\npopulation model that leads to improved knowledge acquisition for downstream\ncommonsense reasoning. A better population model can also help acquire more\ninformative commonsense knowledge as additional supervision signals for both\ngenerative commonsense inference and zero-shot commonsense question answering.\nSpecifically, the question-answering model based on DeBERTa-v3-large (He et\nal., 2023b) even outperforms powerful large language models in a zero-shot\nsetting, including ChatGPT and GPT-3.5.", "published": "2023-04-20 15:27:29", "link": "http://arxiv.org/abs/2304.10392v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GPT-NER: Named Entity Recognition via Large Language Models", "abstract": "Despite the fact that large-scale Language Models (LLM) have achieved SOTA\nperformances on a variety of NLP tasks, its performance on NER is still\nsignificantly below supervised baselines. This is due to the gap between the\ntwo tasks the NER and LLMs: the former is a sequence labeling task in nature\nwhile the latter is a text-generation model.\n  In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the\ngap by transforming the sequence labeling task to a generation task that can be\neasily adapted by LLMs e.g., the task of finding location entities in the input\ntext \"Columbus is a city\" is transformed to generate the text sequence\n\"@@Columbus## is a city\", where special tokens @@## marks the entity to\nextract. To efficiently address the \"hallucination\" issue of LLMs, where LLMs\nhave a strong inclination to over-confidently label NULL inputs as entities, we\npropose a self-verification strategy by prompting LLMs to ask itself whether\nthe extracted entities belong to a labeled entity tag.\n  We conduct experiments on five widely adopted NER datasets, and GPT-NER\nachieves comparable performances to fully supervised baselines, which is the\nfirst time as far as we are concerned. More importantly, we find that GPT-NER\nexhibits a greater ability in the low-resource and few-shot setups, when the\namount of training data is extremely scarce, GPT-NER performs significantly\nbetter than supervised models. This demonstrates the capabilities of GPT-NER in\nreal-world NER applications where the number of labeled examples is limited.", "published": "2023-04-20 16:17:26", "link": "http://arxiv.org/abs/2304.10428v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Safety Assessment of Chinese Large Language Models", "abstract": "With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.", "published": "2023-04-20 16:27:35", "link": "http://arxiv.org/abs/2304.10436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain-specific Continued Pretraining of Language Models for Capturing\n  Long Context in Mental Health", "abstract": "Pretrained language models have been used in various natural language\nprocessing applications. In the mental health domain, domain-specific language\nmodels are pretrained and released, which facilitates the early detection of\nmental health conditions. Social posts, e.g., on Reddit, are usually long\ndocuments. However, there are no domain-specific pretrained models for\nlong-sequence modeling in the mental health domain. This paper conducts\ndomain-specific continued pretraining to capture the long context for mental\nhealth. Specifically, we train and release MentalXLNet and MentalLongformer\nbased on XLNet and Longformer. We evaluate the mental health classification\nperformance and the long-range ability of these two domain-specific pretrained\nmodels. Our models are released in HuggingFace.", "published": "2023-04-20 16:43:56", "link": "http://arxiv.org/abs/2304.10447v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Plan with Natural Language", "abstract": "Large Language Models (LLMs) have shown remarkable performance in various\nbasic natural language tasks. For completing the complex task, we still need a\nplan for the task to guide LLMs to generate the specific solutions step by\nstep. LLMs can directly generate task plans, but these plans may still contain\nfactual errors or are incomplete. A high-quality task plan contains correct\nstep-by-step solutions for solving all situations and behavioral instructions\nfor avoiding mistakes. To obtain it, we propose the Learning to Plan method,\nwhich involves two phases: (1) In the first learning task plan phase, it\niteratively updates the task plan with new step-by-step solutions and\nbehavioral instructions, which are obtained by prompting LLMs to derive from\ntraining error feedback. (2) In the subsequent test phase, the LLM uses the\nlearned task plan to guide the inference of LLM on the test set. We demonstrate\nthe effectiveness of our method on the five different reasoning type tasks (8\ndatasets). Further, our analysis experiment shows that the task plan learned by\none LLM can directly guide another LLM to improve its performance, which\nreveals a new transfer learning paradigm. We release the code at\n\\url{https://github.com/Eureka6174/LearnNLPlan}", "published": "2023-04-20 17:09:12", "link": "http://arxiv.org/abs/2304.10464v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named\n  Entity Recognition using Knowledge Bases", "abstract": "Named Entity Recognition (NER) is a core natural language processing task in\nwhich pre-trained language models have shown remarkable performance. However,\nstandard benchmarks like CoNLL 2003 do not address many of the challenges that\ndeployed NER systems face, such as having to classify emerging or complex\nentities in a fine-grained way. In this paper we present a novel NER cascade\napproach comprising three steps: first, identifying candidate entities in the\ninput sentence; second, linking the each candidate to an existing knowledge\nbase; third, predicting the fine-grained category for each entity candidate. We\nempirically demonstrate the significance of external knowledge bases in\naccurately classifying fine-grained and emerging entities. Our system exhibits\nrobust performance in the MultiCoNER2 shared task, even in the low-resource\nlanguage setting where we leverage knowledge bases of high-resource languages.", "published": "2023-04-20 20:30:34", "link": "http://arxiv.org/abs/2304.10637v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word Sense Induction with Knowledge Distillation from BERT", "abstract": "Pre-trained contextual language models are ubiquitously employed for language\nunderstanding tasks, but are unsuitable for resource-constrained systems.\nNoncontextual word embeddings are an efficient alternative in these settings.\nSuch methods typically use one vector to encode multiple different meanings of\na word, and incur errors due to polysemy. This paper proposes a two-stage\nmethod to distill multiple word senses from a pre-trained language model (BERT)\nby using attention over the senses of a word in a context and transferring this\nsense information to fit multi-sense embeddings in a skip-gram-like framework.\nWe demonstrate an effective approach to training the sense disambiguation\nmechanism in our model with a distribution over word senses extracted from the\noutput layer embeddings of BERT. Experiments on the contextual word similarity\nand sense induction tasks show that this method is superior to or competitive\nwith state-of-the-art multi-sense embeddings on multiple benchmark data sets,\nand experiments with an embedding-based topic model (ETM) demonstrates the\nbenefits of using this multi-sense embedding in a downstream application.", "published": "2023-04-20 21:05:35", "link": "http://arxiv.org/abs/2304.10642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can ChatGPT Reproduce Human-Generated Labels? A Study of Social\n  Computing Tasks", "abstract": "The release of ChatGPT has uncovered a range of possibilities whereby large\nlanguage models (LLMs) can substitute human intelligence. In this paper, we\nseek to understand whether ChatGPT has the potential to reproduce\nhuman-generated label annotations in social computing tasks. Such an\nachievement could significantly reduce the cost and complexity of social\ncomputing research. As such, we use ChatGPT to relabel five seminal datasets\ncovering stance detection (2x), sentiment analysis, hate speech, and bot\ndetection. Our results highlight that ChatGPT does have the potential to handle\nthese data annotation tasks, although a number of challenges remain. ChatGPT\nobtains an average accuracy 0.609. Performance is highest for the sentiment\nanalysis dataset, with ChatGPT correctly annotating 64.9% of tweets. Yet, we\nshow that performance varies substantially across individual labels. We believe\nthis work can open up new lines of analysis and act as a basis for future\nresearch into the exploitation of ChatGPT for human annotation tasks.", "published": "2023-04-20 08:08:12", "link": "http://arxiv.org/abs/2304.10145v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "On the Independence of Association Bias and Empirical Fairness in\n  Language Models", "abstract": "The societal impact of pre-trained language models has prompted researchers\nto probe them for strong associations between protected attributes and\nvalue-loaded terms, from slur to prestigious job titles. Such work is said to\nprobe models for bias or fairness-or such probes 'into representational biases'\nare said to be 'motivated by fairness'-suggesting an intimate connection\nbetween bias and fairness. We provide conceptual clarity by distinguishing\nbetween association biases (Caliskan et al., 2022) and empirical fairness (Shen\net al., 2022) and show the two can be independent. Our main contribution,\nhowever, is showing why this should not come as a surprise. To this end, we\nfirst provide a thought experiment, showing how association bias and empirical\nfairness can be completely orthogonal. Next, we provide empirical evidence that\nthere is no correlation between bias metrics and fairness metrics across the\nmost widely used language models. Finally, we survey the sociological and\npsychological literature and show how this literature provides ample support\nfor expecting these metrics to be uncorrelated.", "published": "2023-04-20 08:27:21", "link": "http://arxiv.org/abs/2304.10153v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "CoT-MoTE: Exploring ConTextual Masked Auto-Encoder Pre-training with\n  Mixture-of-Textual-Experts for Passage Retrieval", "abstract": "Passage retrieval aims to retrieve relevant passages from large collections\nof the open-domain corpus. Contextual Masked Auto-Encoding has been proven\neffective in representation bottleneck pre-training of a monolithic\ndual-encoder for passage retrieval. Siamese or fully separated dual-encoders\nare often adopted as basic retrieval architecture in the pre-training and\nfine-tuning stages for encoding queries and passages into their latent\nembedding spaces. However, simply sharing or separating the parameters of the\ndual-encoder results in an imbalanced discrimination of the embedding spaces.\nIn this work, we propose to pre-train Contextual Masked Auto-Encoder with\nMixture-of-Textual-Experts (CoT-MoTE). Specifically, we incorporate\ntextual-specific experts for individually encoding the distinct properties of\nqueries and passages. Meanwhile, a shared self-attention layer is still kept\nfor unified attention modeling. Results on large-scale passage retrieval\nbenchmarks show steady improvement in retrieval performances. The quantitive\nanalysis also shows a more balanced discrimination of the latent embedding\nspaces.", "published": "2023-04-20 10:12:09", "link": "http://arxiv.org/abs/2304.10195v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Is augmentation effective to improve prediction in imbalanced text\n  datasets?", "abstract": "Imbalanced datasets present a significant challenge for machine learning\nmodels, often leading to biased predictions. To address this issue, data\naugmentation techniques are widely used in natural language processing (NLP) to\ngenerate new samples for the minority class. However, in this paper, we\nchallenge the common assumption that data augmentation is always necessary to\nimprove predictions on imbalanced datasets. Instead, we argue that adjusting\nthe classifier cutoffs without data augmentation can produce similar results to\noversampling techniques. Our study provides theoretical and empirical evidence\nto support this claim. Our findings contribute to a better understanding of the\nstrengths and limitations of different approaches to dealing with imbalanced\ndata, and help researchers and practitioners make informed decisions about\nwhich methods to use for a given task.", "published": "2023-04-20 13:07:31", "link": "http://arxiv.org/abs/2304.10283v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Improving Speech Translation by Cross-Modal Multi-Grained Contrastive\n  Learning", "abstract": "The end-to-end speech translation (E2E-ST) model has gradually become a\nmainstream paradigm due to its low latency and less error propagation. However,\nit is non-trivial to train such a model well due to the task complexity and\ndata scarcity. The speech-and-text modality differences result in the E2E-ST\nmodel performance usually inferior to the corresponding machine translation\n(MT) model. Based on the above observation, existing methods often use\nsharingmechanisms to carry out implicit knowledge transfer by imposing various\nconstraints. However, the final model often performs worse on the MT task than\nthe MT model trained alone, which means that the knowledge transfer ability of\nthis method is also limited. To deal with these problems, we propose the FCCL\n(Fine- and Coarse- Granularity Contrastive Learning) approach for E2E-ST, which\nmakes explicit knowledge transfer through cross-modal multi-grained contrastive\nlearning. A key ingredient of our approach is applying contrastive learning at\nboth sentence- and frame-level to give the comprehensive guide for extracting\nspeech representations containing rich semantic information.In addition, we\nadopt a simple whitening method to alleviate the representation degeneration in\nthe MT model, which adversely affects contrast learning. Experiments on the\nMuST-C benchmark show that our proposed approach significantly outperforms the\nstate-of-the-art E2E-ST baselines on all eight language pairs. Further analysis\nindicates that FCCL can free up its capacity from learning grammatical\nstructure information and force more layers to learn semantic information.", "published": "2023-04-20 13:41:56", "link": "http://arxiv.org/abs/2304.10309v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DropDim: A Regularization Method for Transformer Networks", "abstract": "We introduceDropDim, a structured dropout method designed for regularizing\nthe self-attention mechanism, which is a key component of the transformer. In\ncontrast to the general dropout method, which randomly drops neurons, DropDim\ndrops part of the embedding dimensions. In this way, the semantic information\ncan be completely discarded. Thus, the excessive coadapting between different\nembedding dimensions can be broken, and the self-attention is forced to encode\nmeaningful featureswith a certain number of embedding dimensions erased.\nExperiments on a wide range of tasks executed on the MUST-C English-Germany\ndataset show that DropDim can effectively improve model performance, reduce\nover-fitting, and show complementary effects with other regularization methods.\nWhen combined with label smoothing, the WER can be reduced from 19.1% to 15.1%\non the ASR task, and the BLEU value can be increased from26.90 to 28.38 on the\nMT task. On the ST task, the model can reach a BLEU score of 22.99, an increase\nby 1.86 BLEU points compared to the strong baseline.", "published": "2023-04-20 13:54:18", "link": "http://arxiv.org/abs/2304.10321v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Phoenix: Democratizing ChatGPT across Languages", "abstract": "This paper presents our efforts to democratize ChatGPT across language. We\nrelease a large language model \"Phoenix\", achieving competitive performance\namong open-source English and Chinese models while excelling in languages with\nlimited resources (covering both Latin and non-Latin languages). We believe\nthis work will be beneficial to make ChatGPT more accessible, especially in\ncountries where people cannot use ChatGPT due to restrictions from OpenAI or\nlocal goverments. Our data, code, and models are available at\nhttps://github.com/FreedomIntelligence/LLMZoo.", "published": "2023-04-20 16:50:04", "link": "http://arxiv.org/abs/2304.10453v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Why Does ChatGPT Fall Short in Providing Truthful Answers?", "abstract": "Recent advancements in large language models, such as ChatGPT, have\ndemonstrated significant potential to impact various aspects of human life.\nHowever, ChatGPT still faces challenges in providing reliable and accurate\nanswers to user questions. To better understand the model's particular\nweaknesses in providing truthful answers, we embark an in-depth exploration of\nopen-domain question answering. Specifically, we undertake a detailed\nexamination of ChatGPT's failures, categorized into: comprehension, factuality,\nspecificity, and inference. We further pinpoint factuality as the most\ncontributing failure and identify two critical abilities associated with\nfactuality: knowledge memorization and knowledge recall. Through experiments\nfocusing on factuality, we propose several potential enhancement strategies.\nOur findings suggest that augmenting the model with granular external knowledge\nand cues for knowledge recall can enhance the model's factuality in answering\nquestions.", "published": "2023-04-20 17:48:43", "link": "http://arxiv.org/abs/2304.10513v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Joint Repetition Suppression and Content Moderation of Large Language\n  Models", "abstract": "Natural language generation (NLG) is one of the most impactful fields in NLP,\nand recent years have witnessed its evolution brought about by large language\nmodels (LLMs). As the key instrument for writing assistance applications, they\nare generally prone to replicating or extending offensive content provided in\nthe input. In low-resource data regime, they can also lead to repetitive\noutputs. Usually, offensive content and repetitions are mitigated with post-hoc\nmethods, including n-gram level blocklists, top-k and nucleus sampling. In this\npaper, we apply non-exact repetition suppression using token and sequence level\nunlikelihood loss, and further explore the framework of unlikelihood training\nobjective in order to jointly endow the model with abilities to avoid\ngenerating offensive words and phrases from the beginning. Finally, with\ncomprehensive experiments, we demonstrate that our proposed methods work\nexceptionally in controlling the repetition and content quality of LLM outputs.", "published": "2023-04-20 19:17:49", "link": "http://arxiv.org/abs/2304.10611v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Meta Semantics: Towards better natural language understanding and\n  reasoning", "abstract": "Natural language understanding is one of the most challenging topics in\nartificial intelligence. Deep neural network methods, particularly large\nlanguage module (LLM) methods such as ChatGPT and GPT-3, have powerful\nflexibility to adopt informal text but are weak on logical deduction and suffer\nfrom the out-of-vocabulary (OOV) problem. On the other hand, rule-based methods\nsuch as Mathematica, Semantic web, and Lean, are excellent in reasoning but\ncannot handle the complex and changeable informal text. Inspired by pragmatics\nand structuralism, we propose two strategies to solve the OOV problem and a\nsemantic model for better natural language understanding and reasoning.", "published": "2023-04-20 22:16:16", "link": "http://arxiv.org/abs/2304.10663v1", "categories": ["cs.CL", "cs.AI", "03B65(Primary) 68T50(Secondary)", "I.2.4; I.2.7"], "primary_category": "cs.CL"}
{"title": "CEIL: A General Classification-Enhanced Iterative Learning Framework for\n  Text Clustering", "abstract": "Text clustering, as one of the most fundamental challenges in unsupervised\nlearning, aims at grouping semantically similar text segments without relying\non human annotations. With the rapid development of deep learning, deep\nclustering has achieved significant advantages over traditional clustering\nmethods. Despite the effectiveness, most existing deep text clustering methods\nrely heavily on representations pre-trained in general domains, which may not\nbe the most suitable solution for clustering in specific target domains. To\naddress this issue, we propose CEIL, a novel Classification-Enhanced Iterative\nLearning framework for short text clustering, which aims at generally promoting\nthe clustering performance by introducing a classification objective to\niteratively improve feature representations. In each iteration, we first adopt\na language model to retrieve the initial text representations, from which the\nclustering results are collected using our proposed Category Disentangled\nContrastive Clustering (CDCC) algorithm. After strict data filtering and\naggregation processes, samples with clean category labels are retrieved, which\nserve as supervision information to update the language model with the\nclassification objective via a prompt learning approach. Finally, the updated\nlanguage model with improved representation ability is used to enhance\nclustering in the next iteration. Extensive experiments demonstrate that the\nCEIL framework significantly improves the clustering performance over\niterations, and is generally effective on various clustering algorithms.\nMoreover, by incorporating CEIL on CDCC, we achieve the state-of-the-art\nclustering performance on a wide range of short text clustering benchmarks\noutperforming other strong baseline methods.", "published": "2023-04-20 14:04:31", "link": "http://arxiv.org/abs/2304.11061v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Indian Sign Language Recognition Using Mediapipe Holistic", "abstract": "Deaf individuals confront significant communication obstacles on a daily\nbasis. Their inability to hear makes it difficult for them to communicate with\nthose who do not understand sign language. Moreover, it presents difficulties\nin educational, occupational, and social contexts. By providing alternative\ncommunication channels, technology can play a crucial role in overcoming these\nobstacles. One such technology that can facilitate communication between deaf\nand hearing individuals is sign language recognition. We will create a robust\nsystem for sign language recognition in order to convert Indian Sign Language\nto text or speech. We will evaluate the proposed system and compare CNN and\nLSTM models. Since there are both static and gesture sign languages, a robust\nmodel is required to distinguish between them. In this study, we discovered\nthat a CNN model captures letters and characters for recognition of static sign\nlanguage better than an LSTM model, but it outperforms CNN by monitoring hands,\nfaces, and pose in gesture sign language phrases and sentences. The creation of\na text-to-sign language paradigm is essential since it will enhance the sign\nlanguage-dependent deaf and hard-of-hearing population's communication skills.\nEven though the sign-to-text translation is just one side of communication, not\nall deaf or hard-of-hearing people are proficient in reading or writing text.\nSome may have difficulty comprehending written language due to educational or\nliteracy issues. Therefore, a text-to-sign language paradigm would allow them\nto comprehend text-based information and participate in a variety of social,\neducational, and professional settings.\n  Keywords: deaf and hard-of-hearing, DHH, Indian sign language, CNN, LSTM,\nstatic and gesture sign languages, text-to-sign language model, MediaPipe\nHolistic, sign language recognition, SLR, SLT", "published": "2023-04-20 12:25:47", "link": "http://arxiv.org/abs/2304.10256v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Decouple Non-parametric Knowledge Distillation For End-to-end Speech\n  Translation", "abstract": "Existing techniques often attempt to make knowledge transfer from a powerful\nmachine translation (MT) to speech translation (ST) model with some elaborate\ntechniques, which often requires transcription as extra input during training.\nHowever, transcriptions are not always available, and how to improve the ST\nmodel performance without transcription, i.e., data efficiency, has rarely been\nstudied in the literature. In this paper, we propose Decoupled Non-parametric\nKnowledge Distillation (DNKD) from data perspective to improve the data\nefficiency. Our method follows the knowledge distillation paradigm. However,\ninstead of obtaining the teacher distribution from a sophisticated MT model, we\nconstruct it from a non-parametric datastore via k-Nearest-Neighbor (kNN)\nretrieval, which removes the dependence on transcription and MT model. Then we\ndecouple the classic knowledge distillation loss into target and non-target\ndistillation to enhance the effect of the knowledge among non-target logits,\nwhich is the prominent \"dark knowledge\". Experiments on MuST-C corpus show\nthat, the proposed method can achieve consistent improvement over the strong\nbaseline without requiring any transcription.", "published": "2023-04-20 13:20:03", "link": "http://arxiv.org/abs/2304.10295v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "\"Can We Detect Substance Use Disorder?\": Knowledge and Time Aware\n  Classification on Social Media from Darkweb", "abstract": "Opioid and substance misuse is rampant in the United States today, with the\nphenomenon known as the \"opioid crisis\". The relationship between substance use\nand mental health has been extensively studied, with one possible relationship\nbeing: substance misuse causes poor mental health. However, the lack of\nevidence on the relationship has resulted in opioids being largely inaccessible\nthrough legal means. This study analyzes the substance use posts on social\nmedia with opioids being sold through crypto market listings. We use the Drug\nAbuse Ontology, state-of-the-art deep learning, and knowledge-aware BERT-based\nmodels to generate sentiment and emotion for the social media posts to\nunderstand users' perceptions on social media by investigating questions such\nas: which synthetic opioids people are optimistic, neutral, or negative about?\nor what kind of drugs induced fear and sorrow? or what kind of drugs people\nlove or are thankful about? or which drugs people think negatively about? or\nwhich opioids cause little to no sentimental reaction. We discuss how we\ncrawled crypto market data and its use in extracting posts for fentanyl,\nfentanyl analogs, and other novel synthetic opioids. We also perform topic\nanalysis associated with the generated sentiments and emotions to understand\nwhich topics correlate with people's responses to various drugs. Additionally,\nwe analyze time-aware neural models built on these features while considering\nhistorical sentiment and emotional activity of posts related to a drug. The\nmost effective model performs well (statistically significant) with\n(macroF1=82.12, recall =83.58) to identify substance use disorder.", "published": "2023-04-20 17:47:13", "link": "http://arxiv.org/abs/2304.10512v1", "categories": ["cs.LG", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "\"HOT\" ChatGPT: The promise of ChatGPT in detecting and discriminating\n  hateful, offensive, and toxic comments on social media", "abstract": "Harmful content is pervasive on social media, poisoning online communities\nand negatively impacting participation. A common approach to address this issue\nis to develop detection models that rely on human annotations. However, the\ntasks required to build such models expose annotators to harmful and offensive\ncontent and may require significant time and cost to complete. Generative AI\nmodels have the potential to understand and detect harmful content. To\ninvestigate this potential, we used ChatGPT and compared its performance with\nMTurker annotations for three frequently discussed concepts related to harmful\ncontent: Hateful, Offensive, and Toxic (HOT). We designed five prompts to\ninteract with ChatGPT and conducted four experiments eliciting HOT\nclassifications. Our results show that ChatGPT can achieve an accuracy of\napproximately 80% when compared to MTurker annotations. Specifically, the model\ndisplays a more consistent classification for non-HOT comments than HOT\ncomments compared to human annotations. Our findings also suggest that ChatGPT\nclassifications align with provided HOT definitions, but ChatGPT classifies\n\"hateful\" and \"offensive\" as subsets of \"toxic.\" Moreover, the choice of\nprompts used to interact with ChatGPT impacts its performance. Based on these\nin-sights, our study provides several meaningful implications for employing\nChatGPT to detect HOT content, particularly regarding the reliability and\nconsistency of its performance, its understand-ing and reasoning of the HOT\nconcept, and the impact of prompts on its performance. Overall, our study\nprovides guidance about the potential of using generative AI models to moderate\nlarge volumes of user-generated content on social media.", "published": "2023-04-20 19:40:51", "link": "http://arxiv.org/abs/2304.10619v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Emotional Expression Detection in Spoken Language Employing Machine\n  Learning Algorithms", "abstract": "There are a variety of features of the human voice that can be classified as\npitch, timbre, loudness, and vocal tone. It is observed in numerous incidents\nthat human expresses their feelings using different vocal qualities when they\nare speaking. The primary objective of this research is to recognize different\nemotions of human beings such as anger, sadness, fear, neutrality, disgust,\npleasant surprise, and happiness by using several MATLAB functions namely,\nspectral descriptors, periodicity, and harmonicity. To accomplish the work, we\nanalyze the CREMA-D (Crowd-sourced Emotional Multimodal Actors Data) & TESS\n(Toronto Emotional Speech Set) datasets of human speech. The audio file\ncontains data that have various characteristics (e.g., noisy, speedy, slow)\nthereby the efficiency of the ML (Machine Learning) models increases\nsignificantly. The EMD (Empirical Mode Decomposition) is utilized for the\nprocess of signal decomposition. Then, the features are extracted through the\nuse of several techniques such as the MFCC, GTCC, spectral centroid, roll-off\npoint, entropy, spread, flux, harmonic ratio, energy, skewness, flatness, and\naudio delta. The data is trained using some renowned ML models namely, Support\nVector Machine, Neural Network, Ensemble, and KNN. The algorithms show an\naccuracy of 67.7%, 63.3%, 61.6%, and 59.0% respectively for the test data and\n77.7%, 76.1%, 99.1%, and 61.2% for the training data. We have conducted\nexperiments using Matlab and the result shows that our model is very prominent\nand flexible than existing similar works.", "published": "2023-04-20 17:57:08", "link": "http://arxiv.org/abs/2304.11040v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "OLISIA: a Cascade System for Spoken Dialogue State Tracking", "abstract": "Though Dialogue State Tracking (DST) is a core component of spoken dialogue\nsystems, recent work on this task mostly deals with chat corpora, disregarding\nthe discrepancies between spoken and written language.In this paper, we propose\nOLISIA, a cascade system which integrates an Automatic Speech Recognition (ASR)\nmodel and a DST model. We introduce several adaptations in the ASR and DST\nmodules to improve integration and robustness to spoken conversations.With\nthese adaptations, our system ranked first in DSTC11 Track 3, a benchmark to\nevaluate spoken DST. We conduct an in-depth analysis of the results and find\nthat normalizing the ASR outputs and adapting the DST inputs through data\naugmentation, along with increasing the pre-trained models size all play an\nimportant role in reducing the performance discrepancy between written and\nspoken conversations.", "published": "2023-04-20 09:30:50", "link": "http://arxiv.org/abs/2304.11073v3", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects", "abstract": "Recent breakthroughs in NLP largely increased the presence of ASR systems in\nour daily lives. However, for many low-resource languages, ASR models still\nneed to be improved due in part to the difficulty of acquiring pertinent data.\nThis project aims to help advance research in ASR models for Swiss German\ndialects, by providing insights about the performance of state-of-the-art ASR\nmodels on recently published Swiss German speech datasets. We propose a novel\nloss that takes into account the semantic distance between the predicted and\nthe ground-truth labels. We outperform current state-of-the-art results by\nfine-tuning OpenAI's Whisper model on Swiss-German datasets.", "published": "2023-04-20 14:42:54", "link": "http://arxiv.org/abs/2304.11075v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MarsEclipse at SemEval-2023 Task 3: Multi-Lingual and Multi-Label\n  Framing Detection with Contrastive Learning", "abstract": "This paper describes our system for SemEval-2023 Task 3 Subtask 2 on Framing\nDetection. We used a multi-label contrastive loss for fine-tuning large\npre-trained language models in a multi-lingual setting, achieving very\ncompetitive results: our system was ranked first on the official test set and\non the official shared task leaderboard for five of the six languages for which\nwe had training data and for which we could perform fine-tuning. Here, we\ndescribe our experimental setup, as well as various ablation studies. The code\nof our system is available at https://github.com/QishengL/SemEval2023", "published": "2023-04-20 18:42:23", "link": "http://arxiv.org/abs/2304.14339v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards a Benchmark for Scientific Understanding in Humans and Machines", "abstract": "Scientific understanding is a fundamental goal of science, allowing us to\nexplain the world. There is currently no good way to measure the scientific\nunderstanding of agents, whether these be humans or Artificial Intelligence\nsystems. Without a clear benchmark, it is challenging to evaluate and compare\ndifferent levels of and approaches to scientific understanding. In this\nRoadmap, we propose a framework to create a benchmark for scientific\nunderstanding, utilizing tools from philosophy of science. We adopt a\nbehavioral notion according to which genuine understanding should be recognized\nas an ability to perform certain tasks. We extend this notion by considering a\nset of questions that can gauge different levels of scientific understanding,\ncovering information retrieval, the capability to arrange information to\nproduce an explanation, and the ability to infer how things would be different\nunder different circumstances. The Scientific Understanding Benchmark (SUB),\nwhich is formed by a set of these tests, allows for the evaluation and\ncomparison of different approaches. Benchmarking plays a crucial role in\nestablishing trust, ensuring quality control, and providing a basis for\nperformance evaluation. By aligning machine and human scientific understanding\nwe can improve their utility, ultimately advancing scientific understanding and\nhelping to discover new insights within machines.", "published": "2023-04-20 14:05:53", "link": "http://arxiv.org/abs/2304.10327v2", "categories": ["cs.AI", "cs.CL", "cs.HC", "hep-ph", "physics.hist-ph"], "primary_category": "cs.AI"}
{"title": "Is Cross-modal Information Retrieval Possible without Training?", "abstract": "Encoded representations from a pretrained deep learning model (e.g., BERT\ntext embeddings, penultimate CNN layer activations of an image) convey a rich\nset of features beneficial for information retrieval. Embeddings for a\nparticular modality of data occupy a high-dimensional space of its own, but it\ncan be semantically aligned to another by a simple mapping without training a\ndeep neural net. In this paper, we take a simple mapping computed from the\nleast squares and singular value decomposition (SVD) for a solution to the\nProcrustes problem to serve a means to cross-modal information retrieval. That\nis, given information in one modality such as text, the mapping helps us locate\na semantically equivalent data item in another modality such as image. Using\noff-the-shelf pretrained deep learning models, we have experimented the\naforementioned simple cross-modal mappings in tasks of text-to-image and\nimage-to-text retrieval. Despite simplicity, our mappings perform reasonably\nwell reaching the highest accuracy of 77% on recall@10, which is comparable to\nthose requiring costly neural net training and fine-tuning. We have improved\nthe simple mappings by contrastive learning on the pretrained models.\nContrastive learning can be thought as properly biasing the pretrained encoders\nto enhance the cross-modal mapping quality. We have further improved the\nperformance by multilayer perceptron with gating (gMLP), a simple neural\narchitecture.", "published": "2023-04-20 02:36:18", "link": "http://arxiv.org/abs/2304.11095v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Towards the Universal Defense for Query-Based Audio Adversarial Attacks", "abstract": "Recently, studies show that deep learning-based automatic speech recognition\n(ASR) systems are vulnerable to adversarial examples (AEs), which add a small\namount of noise to the original audio examples. These AE attacks pose new\nchallenges to deep learning security and have raised significant concerns about\ndeploying ASR systems and devices. The existing defense methods are either\nlimited in application or only defend on results, but not on process. In this\nwork, we propose a novel method to infer the adversary intent and discover\naudio adversarial examples based on the AEs generation process. The insight of\nthis method is based on the observation: many existing audio AE attacks utilize\nquery-based methods, which means the adversary must send continuous and similar\nqueries to target ASR models during the audio AE generation process. Inspired\nby this observation, We propose a memory mechanism by adopting audio\nfingerprint technology to analyze the similarity of the current query with a\ncertain length of memory query. Thus, we can identify when a sequence of\nqueries appears to be suspectable to generate audio AEs. Through extensive\nevaluation on four state-of-the-art audio AE attacks, we demonstrate that on\naverage our defense identify the adversary intent with over 90% accuracy. With\ncareful regard for robustness evaluations, we also analyze our proposed defense\nand its strength to withstand two adaptive attacks. Finally, our scheme is\navailable out-of-the-box and directly compatible with any ensemble of ASR\ndefense models to uncover audio AE attacks effectively without model\nretraining.", "published": "2023-04-20 04:50:02", "link": "http://arxiv.org/abs/2304.10088v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Using Mobile Data and Deep Models to Assess Auditory Verbal\n  Hallucinations", "abstract": "Hallucination is an apparent perception in the absence of real external\nsensory stimuli. An auditory hallucination is a perception of hearing sounds\nthat are not real. A common form of auditory hallucination is hearing voices in\nthe absence of any speakers which is known as Auditory Verbal Hallucination\n(AVH). AVH is fragments of the mind's creation that mostly occur in people\ndiagnosed with mental illnesses such as bipolar disorder and schizophrenia.\nAssessing the valence of hallucinated voices (i.e., how negative or positive\nvoices are) can help measure the severity of a mental illness. We study N=435\nindividuals, who experience hearing voices, to assess auditory verbal\nhallucination. Participants report the valence of voices they hear four times a\nday for a month through ecological momentary assessments with questions that\nhave four answering scales from ``not at all'' to ``extremely''. We collect\nthese self-reports as the valence supervision of AVH events via a mobile\napplication. Using the application, participants also record audio diaries to\ndescribe the content of hallucinated voices verbally. In addition, we passively\ncollect mobile sensing data as contextual signals. We then experiment with how\npredictive these linguistic and contextual cues from the audio diary and mobile\nsensing data are of an auditory verbal hallucination event. Finally, using\ntransfer learning and data fusion techniques, we train a neural net model that\npredicts the valance of AVH with a performance of 54\\% top-1 and 72\\% top-2 F1\nscore.", "published": "2023-04-20 15:37:34", "link": "http://arxiv.org/abs/2304.11049v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
