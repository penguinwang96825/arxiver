{"title": "Collaborative Optimization in Financial Data Mining Through Deep Learning and ResNeXt", "abstract": "This study proposes a multi-task learning framework based on ResNeXt, aiming\nto solve the problem of feature extraction and task collaborative optimization\nin financial data mining. Financial data usually has the complex\ncharacteristics of high dimensionality, nonlinearity, and time series, and is\naccompanied by potential correlations between multiple tasks, making it\ndifficult for traditional methods to meet the needs of data mining. This study\nintroduces the ResNeXt model into the multi-task learning framework and makes\nfull use of its group convolution mechanism to achieve efficient extraction of\nlocal patterns and global features of financial data. At the same time, through\nthe design of task sharing layers and dedicated layers, it is established\nbetween multiple related tasks. Deep collaborative optimization relationships.\nThrough flexible multi-task loss weight design, the model can effectively\nbalance the learning needs of different tasks and improve overall performance.\nExperiments are conducted on a real S&P 500 financial data set, verifying the\nsignificant advantages of the proposed framework in classification and\nregression tasks. The results indicate that, when compared to other\nconventional deep learning models, the proposed method delivers superior\nperformance in terms of accuracy, F1 score, root mean square error, and other\nmetrics, highlighting its outstanding effectiveness and robustness in handling\ncomplex financial data. This research provides an efficient and adaptable\nsolution for financial data mining, and at the same time opens up a new\nresearch direction for the combination of multi-task learning and deep\nlearning, which has important theoretical significance and practical\napplication value.", "published": "2024-12-23 06:14:15", "link": "http://arxiv.org/abs/2412.17314v1", "categories": ["cs.LG", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "Broker-Trader Partial Information Nash-Equilibria", "abstract": "We study partial information Nash equilibrium between a broker and an\ninformed trader. In this setting, the informed trader, who possesses knowledge\nof a trading signal, trades multiple assets with the broker in a dealer market.\nSimultaneously, the broker offloads these assets in a lit exchange where their\nactions impact the asset prices. The broker, however, only observes aggregate\nprices and cannot distinguish between underlying trends and volatility. Both\nthe broker and the informed trader aim to maximize their penalized expected\nwealth. Using convex analysis, we characterize the Nash equilibrium and\ndemonstrate its existence and uniqueness. Furthermore, we establish that this\nequilibrium corresponds to the solution of a nonstandard system of\nforward-backward stochastic differential equations (FBSDEs) that involves the\ntwo differing filtrations. For short enough time horizons, we prove that a\nunique solution of this system exists. Finally, under quite general\nassumptions, we show that the solution to the FBSDE system admits a polynomial\napproximation in the strength of the transient impact to arbitrary order, and\nprove that the error is controlled.", "published": "2024-12-23 16:45:01", "link": "http://arxiv.org/abs/2412.17712v2", "categories": ["q-fin.MF", "math.PR", "q-fin.TR"], "primary_category": "q-fin.MF"}
{"title": "State spaces of multifactor approximations of nonnegative Volterra processes", "abstract": "We show that the state spaces of multifactor Markovian processes, coming from\napproximations of nonnegative Volterra processes, are given by explicit linear\ntransformation of the nonnegative orthant. We demonstrate the usefulness of\nthis result for applications, including simulation schemes and PDE methods for\nnonnegative Volterra processes.", "published": "2024-12-23 12:50:09", "link": "http://arxiv.org/abs/2412.17526v1", "categories": ["math.PR", "q-fin.MF", "60H20, 91-10, 91-08"], "primary_category": "math.PR"}
{"title": "Time Series Feature Redundancy Paradox: An Empirical Study Based on Mortgage Default Prediction", "abstract": "With the widespread application of machine learning in financial risk\nmanagement, conventional wisdom suggests that longer training periods and more\nfeature variables contribute to improved model performance. This paper,\nfocusing on mortgage default prediction, empirically discovers a phenomenon\nthat contradicts traditional knowledge: in time series prediction, increased\ntraining data timespan and additional non-critical features actually lead to\nsignificant deterioration in prediction effectiveness. Using Fannie Mae's\nmortgage data, the study compares predictive performance across different time\nwindow lengths (2012-2022) and feature combinations, revealing that shorter\ntime windows (such as single-year periods) paired with carefully selected key\nfeatures yield superior prediction results. The experimental results indicate\nthat extended time spans may introduce noise from historical data and outdated\nmarket patterns, while excessive non-critical features interfere with the\nmodel's learning of core default factors. This research not only challenges the\ntraditional \"more is better\" approach in data modeling but also provides new\ninsights and practical guidance for feature selection and time window\noptimization in financial risk prediction.", "published": "2024-12-23 21:28:32", "link": "http://arxiv.org/abs/2501.00034v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Learning from Mistakes: Self-correct Adversarial Training for Chinese\n  Unnatural Text Correction", "abstract": "Unnatural text correction aims to automatically detect and correct spelling\nerrors or adversarial perturbation errors in sentences. Existing methods\ntypically rely on fine-tuning or adversarial training to correct errors, which\nhave achieved significant success. However, these methods exhibit poor\ngeneralization performance due to the difference in data distribution between\ntraining data and real-world scenarios, known as the exposure bias problem. In\nthis paper, we propose a self-correct adversarial training framework for\n\\textbf{L}earn\\textbf{I}ng from \\textbf{MI}s\\textbf{T}akes (\\textbf{LIMIT}),\nwhich is a task- and model-independent framework to correct unnatural errors or\nmistakes. Specifically, we fully utilize errors generated by the model that are\nactively exposed during the inference phase, i.e., predictions that are\ninconsistent with the target. This training method not only simulates potential\nerrors in real application scenarios, but also mitigates the exposure bias of\nthe traditional training process. Meanwhile, we design a novel decoding\nintervention strategy to maintain semantic consistency. Extensive experimental\nresults on Chinese unnatural text error correction datasets show that our\nproposed method can correct multiple forms of errors and outperforms the\nstate-of-the-art text correction methods. In addition, extensive results on\nChinese and English datasets validate that LIMIT can serve as a plug-and-play\ndefense module and can extend to new models and datasets without further\ntraining.", "published": "2024-12-23 04:58:58", "link": "http://arxiv.org/abs/2412.17279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Friends-MMC: A Dataset for Multi-modal Multi-party Conversation\n  Understanding", "abstract": "Multi-modal multi-party conversation (MMC) is a less studied yet important\ntopic of research due to that it well fits real-world scenarios and thus\npotentially has more widely-used applications. Compared with the traditional\nmulti-modal conversations, MMC requires stronger character-centered\nunderstanding abilities as there are many interlocutors appearing in both the\nvisual and textual context. To facilitate the study of this problem, we present\nFriends-MMC in this paper, an MMC dataset that contains 24,000+ unique\nutterances paired with video context. To explore the character-centered\nunderstanding of the dialogue, we also annotate the speaker of each utterance,\nthe names and bounding bboxes of faces that appear in the video. Based on this\nFriends-MMC dataset, we further study two fundamental MMC tasks: conversation\nspeaker identification and conversation response prediction, both of which have\nthe multi-party nature with the video or image as visual context. For\nconversation speaker identification, we demonstrate the inefficiencies of\nexisting methods such as pre-trained models, and propose a simple yet effective\nbaseline method that leverages an optimization solver to utilize the context of\ntwo modalities to achieve better performance. For conversation response\nprediction, we fine-tune generative dialogue models on Friend-MMC, and analyze\nthe benefits of speaker information. The code and dataset is publicly available\nat https://github.com/yellow-binary-tree/Friends-MMC and thus we call for more\nattention on modeling speaker information when understanding conversations.", "published": "2024-12-23 05:32:48", "link": "http://arxiv.org/abs/2412.17295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Dual-Perspective Metaphor Detection Framework Using Large Language\n  Models", "abstract": "Metaphor detection, a critical task in natural language processing, involves\nidentifying whether a particular word in a sentence is used metaphorically.\nTraditional approaches often rely on supervised learning models that implicitly\nencode semantic relationships based on metaphor theories. However, these\nmethods often suffer from a lack of transparency in their decision-making\nprocesses, which undermines the reliability of their predictions. Recent\nresearch indicates that LLMs (large language models) exhibit significant\npotential in metaphor detection. Nevertheless, their reasoning capabilities are\nconstrained by predefined knowledge graphs. To overcome these limitations, we\npropose DMD, a novel dual-perspective framework that harnesses both implicit\nand explicit applications of metaphor theories to guide LLMs in metaphor\ndetection and adopts a self-judgment mechanism to validate the responses from\nthe aforementioned forms of guidance. In comparison to previous methods, our\nframework offers more transparent reasoning processes and delivers more\nreliable predictions. Experimental results prove the effectiveness of DMD,\ndemonstrating state-of-the-art performance across widely-used datasets.", "published": "2024-12-23 06:50:04", "link": "http://arxiv.org/abs/2412.17332v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Experimental Evaluation of Japanese Tokenizers for Sentiment-Based\n  Text Classification", "abstract": "This study investigates the performance of three popular tokenization tools:\nMeCab, Sudachi, and SentencePiece, when applied as a preprocessing step for\nsentiment-based text classification of Japanese texts. Using Term\nFrequency-Inverse Document Frequency (TF-IDF) vectorization, we evaluate two\ntraditional machine learning classifiers: Multinomial Naive Bayes and Logistic\nRegression. The results reveal that Sudachi produces tokens closely aligned\nwith dictionary definitions, while MeCab and SentencePiece demonstrate faster\nprocessing speeds. The combination of SentencePiece, TF-IDF, and Logistic\nRegression outperforms the other alternatives in terms of classification\nperformance.", "published": "2024-12-23 07:45:51", "link": "http://arxiv.org/abs/2412.17361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interweaving Memories of a Siamese Large Language Model", "abstract": "Parameter-efficient fine-tuning (PEFT) methods optimize large language models\n(LLMs) by modifying or introducing a small number of parameters to enhance\nalignment with downstream tasks. However, they can result in catastrophic\nforgetting, where LLMs prioritize new knowledge at the expense of comprehensive\nworld knowledge. A promising approach to mitigate this issue is to recall prior\nmemories based on the original knowledge. To this end, we propose a\nmodel-agnostic PEFT framework, IMSM, which Interweaves Memories of a Siamese\nLarge Language Model. Specifically, our siamese LLM is equipped with an\nexisting PEFT method. Given an incoming query, it generates two distinct\nmemories based on the pre-trained and fine-tuned parameters. IMSM then\nincorporates an interweaving mechanism that regulates the contributions of both\noriginal and enhanced memories when generating the next token. This framework\nis theoretically applicable to all open-source LLMs and existing PEFT methods.\nWe conduct extensive experiments across various benchmark datasets, evaluating\nthe performance of popular open-source LLMs using the proposed IMSM, in\ncomparison to both classical and leading PEFT methods. Our findings indicate\nthat IMSM maintains comparable time and space efficiency to backbone PEFT\nmethods while significantly improving performance and effectively mitigating\ncatastrophic forgetting.", "published": "2024-12-23 08:33:47", "link": "http://arxiv.org/abs/2412.17383v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WarriorCoder: Learning from Expert Battles to Augment Code Large\n  Language Models", "abstract": "Despite recent progress achieved by code large language models (LLMs), their\nremarkable abilities are largely dependent on fine-tuning on the high-quality\ndata, posing challenges for data collection and annotation. To address this,\ncurrent methods often design various data flywheels to collect complex code\ninstructions, enabling models to handle more intricate tasks. However, these\napproaches typically rely on off-the-shelf datasets and data augmentation from\na limited set of proprietary LLMs (e.g., Claude, GPT4, and so on), which\nrestricts the diversity of the constructed data and makes it prone to systemic\nbiases. In this paper, we propose WarriorCoder, a novel paradigm learns from\nexpert battles to address these limitations. Specifically, we create an arena\nwhere leading expert code LLMs challenge each other, with evaluations conducted\nby impartial judges. This competitive framework generates novel training data\nfrom scratch, leveraging the strengths of all participants. Experimental\nresults show that WarriorCoder achieves state-of-the-art performance compared\nto previous models of the same size, even without relying on proprietary LLMs.", "published": "2024-12-23 08:47:42", "link": "http://arxiv.org/abs/2412.17395v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Just What You Desire: Constrained Timeline Summarization with\n  Self-Reflection for Enhanced Relevance", "abstract": "Given news articles about an entity, such as a public figure or organization,\ntimeline summarization (TLS) involves generating a timeline that summarizes the\nkey events about the entity. However, the TLS task is too underspecified, since\nwhat is of interest to each reader may vary, and hence there is not a single\nideal or optimal timeline. In this paper, we introduce a novel task, called\nConstrained Timeline Summarization (CTLS), where a timeline is generated in\nwhich all events in the timeline meet some constraint. An example of a\nconstrained timeline concerns the legal battles of Tiger Woods, where only\nevents related to his legal problems are selected to appear in the timeline. We\ncollected a new human-verified dataset of constrained timelines involving 47\nentities and 5 constraints per entity. We propose an approach that employs a\nlarge language model (LLM) to summarize news articles according to a specified\nconstraint and cluster them to identify key events to include in a constrained\ntimeline. In addition, we propose a novel self-reflection method during summary\ngeneration, demonstrating that this approach successfully leads to improved\nperformance.", "published": "2024-12-23 09:17:06", "link": "http://arxiv.org/abs/2412.17408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Contextual Informativeness in Child-Directed Text", "abstract": "To address an important gap in creating children's stories for vocabulary\nenrichment, we investigate the automatic evaluation of how well stories convey\nthe semantics of target vocabulary words, a task with substantial implications\nfor generating educational content. We motivate this task, which we call\nmeasuring contextual informativeness in children's stories, and provide a\nformal task definition as well as a dataset for the task. We further propose a\nmethod for automating the task using a large language model (LLM). Our\nexperiments show that our approach reaches a Spearman correlation of 0.4983\nwith human judgments of informativeness, while the strongest baseline only\nobtains a correlation of 0.3534. An additional analysis shows that the\nLLM-based approach is able to generalize to measuring contextual\ninformativeness in adult-directed text, on which it also outperforms all\nbaselines.", "published": "2024-12-23 09:45:03", "link": "http://arxiv.org/abs/2412.17427v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Silver Bullet or a Compromise for Full Attention? A Comprehensive\n  Study of Gist Token-based Context Compression", "abstract": "In this work, we provide a thorough investigation of gist-based context\ncompression methods to improve long-context processing in large language\nmodels. We focus on two key questions: (1) How well can these methods replace\nfull attention models? and (2) What potential failure patterns arise due to\ncompression? Through extensive experiments, we show that while gist-based\ncompression can achieve near-lossless performance on tasks like\nretrieval-augmented generation and long-document QA, it faces challenges in\ntasks like synthetic recall. Furthermore, we identify three key failure\npatterns: lost by the boundary, lost if surprise, and lost along the way. To\nmitigate these issues, we propose two effective strategies: fine-grained\nautoencoding, which enhances the reconstruction of original token information,\nand segment-wise token importance estimation, which adjusts optimization based\non token dependencies. Our work provides valuable insights into the\nunderstanding of gist token-based context compression and offers practical\nstrategies for improving compression capabilities.", "published": "2024-12-23 11:24:04", "link": "http://arxiv.org/abs/2412.17483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiffusionAttacker: Diffusion-Driven Prompt Manipulation for LLM\n  Jailbreak", "abstract": "Large Language Models (LLMs) are susceptible to generating harmful content\nwhen prompted with carefully crafted inputs, a vulnerability known as LLM\njailbreaking. As LLMs become more powerful, studying jailbreak methods is\ncritical to enhancing security and aligning models with human values.\nTraditionally, jailbreak techniques have relied on suffix addition or prompt\ntemplates, but these methods suffer from limited attack diversity. This paper\nintroduces DiffusionAttacker, an end-to-end generative approach for jailbreak\nrewriting inspired by diffusion models. Our method employs a\nsequence-to-sequence (seq2seq) text diffusion model as a generator,\nconditioning on the original prompt and guiding the denoising process with a\nnovel attack loss. Unlike previous approaches that use autoregressive LLMs to\ngenerate jailbreak prompts, which limit the modification of already generated\ntokens and restrict the rewriting space, DiffusionAttacker utilizes a seq2seq\ndiffusion model, allowing more flexible token modifications. This approach\npreserves the semantic content of the original prompt while producing harmful\ncontent. Additionally, we leverage the Gumbel-Softmax technique to make the\nsampling process from the diffusion model's output distribution differentiable,\neliminating the need for iterative token search. Extensive experiments on\nAdvbench and Harmbench demonstrate that DiffusionAttacker outperforms previous\nmethods across various evaluation metrics, including attack success rate (ASR),\nfluency, and diversity.", "published": "2024-12-23 12:44:54", "link": "http://arxiv.org/abs/2412.17522v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Behind Closed Words: Creating and Investigating the forePLay Annotated\n  Dataset for Polish Erotic Discourse", "abstract": "The surge in online content has created an urgent demand for robust detection\nsystems, especially in non-English contexts where current tools demonstrate\nsignificant limitations. We present forePLay, a novel Polish language dataset\nfor erotic content detection, featuring over 24k annotated sentences with a\nmultidimensional taxonomy encompassing ambiguity, violence, and social\nunacceptability dimensions. Our comprehensive evaluation demonstrates that\nspecialized Polish language models achieve superior performance compared to\nmultilingual alternatives, with transformer-based architectures showing\nparticular strength in handling imbalanced categories. The dataset and\naccompanying analysis establish essential frameworks for developing\nlinguistically-aware content moderation systems, while highlighting critical\nconsiderations for extending such capabilities to morphologically complex\nlanguages.", "published": "2024-12-23 12:58:18", "link": "http://arxiv.org/abs/2412.17533v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain adapted machine translation: What does catastrophic forgetting\n  forget and why?", "abstract": "Neural Machine Translation (NMT) models can be specialized by domain\nadaptation, often involving fine-tuning on a dataset of interest. This process\nrisks catastrophic forgetting: rapid loss of generic translation quality.\nForgetting has been widely observed, with many mitigation methods proposed.\nHowever, the causes of forgetting and the relationship between forgetting and\nadaptation data are under-explored.\n  This paper takes a novel approach to understanding catastrophic forgetting\nduring NMT adaptation by investigating the impact of the data. We provide a\nfirst investigation of what is forgotten, and why. We examine the relationship\nbetween forgetting and the in-domain data, and show that the amount and type of\nforgetting is linked to that data's target vocabulary coverage. Our findings\npave the way toward better informed NMT domain adaptation.", "published": "2024-12-23 12:59:43", "link": "http://arxiv.org/abs/2412.17537v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Query Optimization in Large Language Models", "abstract": "\\textit{Query Optimization} (QO) refers to techniques aimed at enhancing the\nefficiency and quality of Large Language Models (LLMs) in understanding and\nanswering queries, especially complex ones in scenarios like\nRetrieval-Augmented Generation (RAG). Specifically, RAG mitigates the\nlimitations of LLMs by dynamically retrieving and leveraging up-to-date\nrelevant information, which provides a cost-effective solution to the challenge\nof LLMs producing plausible but potentially inaccurate responses. Recently, as\nRAG evolves and incorporates multiple components that influence its\nperformance, QO has emerged as a critical element, playing a pivotal role in\ndetermining the effectiveness of RAG's retrieval stage in accurately sourcing\nthe necessary multiple pieces of evidence to answer queries correctly. In this\npaper, we trace the evolution of QO techniques by summarizing and analyzing\nsignificant studies. Through an organized framework and categorization, we aim\nto consolidate existing QO techniques in RAG, elucidate their technological\nfoundations, and highlight their potential to enhance the versatility and\napplications of LLMs.", "published": "2024-12-23 13:26:04", "link": "http://arxiv.org/abs/2412.17558v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ERUPD -- English to Roman Urdu Parallel Dataset", "abstract": "Bridging linguistic gaps fosters global growth and cultural exchange. This\nstudy addresses the challenges of Roman Urdu -- a Latin-script adaptation of\nUrdu widely used in digital communication -- by creating a novel parallel\ndataset comprising 75,146 sentence pairs. Roman Urdu's lack of standardization,\nphonetic variability, and code-switching with English complicates language\nprocessing. We tackled this by employing a hybrid approach that combines\nsynthetic data generated via advanced prompt engineering with real-world\nconversational data from personal messaging groups. We further refined the\ndataset through a human evaluation phase, addressing linguistic inconsistencies\nand ensuring accuracy in code-switching, phonetic representations, and synonym\nvariability. The resulting dataset captures Roman Urdu's diverse linguistic\nfeatures and serves as a critical resource for machine translation, sentiment\nanalysis, and multilingual education.", "published": "2024-12-23 13:33:09", "link": "http://arxiv.org/abs/2412.17562v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Length Issues in Document-level Machine Translation", "abstract": "Transformer architectures are increasingly effective at processing and\ngenerating very long chunks of texts, opening new perspectives for\ndocument-level machine translation (MT). In this work, we challenge the ability\nof MT systems to handle texts comprising up to several thousands of tokens. We\ndesign and implement a new approach designed to precisely measure the effect of\nlength increments on MT outputs. Our experiments with two representative\narchitectures unambiguously show that (a)~translation performance decreases\nwith the length of the input text; (b)~the position of sentences within the\ndocument matters and translation quality is higher for sentences occurring\nearlier in a document. We further show that manipulating the distribution of\ndocument lengths and of positional embeddings only marginally mitigates such\nproblems. Our results suggest that even though document-level MT is\ncomputationally feasible, it does not yet match the performance of\nsentence-based MT.", "published": "2024-12-23 14:08:45", "link": "http://arxiv.org/abs/2412.17592v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Completions for Fragmented Broca's Aphasic Sentences Using\n  Large Language Models", "abstract": "Broca's aphasia is a type of aphasia characterized by non-fluent, effortful\nand fragmented speech production with relatively good comprehension. Since\ntraditional aphasia treatment methods are often time-consuming,\nlabour-intensive, and do not reflect real-world conversations, applying natural\nlanguage processing based approaches such as Large Language Models (LLMs) could\npotentially contribute to improving existing treatment approaches. To address\nthis issue, we explore the use of sequence-to-sequence LLMs for completing\nfragmented Broca's aphasic sentences. We first generate synthetic Broca's\naphasic data using a rule-based system designed to mirror the linguistic\ncharacteristics of Broca's aphasic speech. Using this synthetic data, we then\nfine-tune four pre-trained LLMs on the task of completing fragmented sentences.\nWe evaluate our fine-tuned models on both synthetic and authentic Broca's\naphasic data. We demonstrate LLMs' capability for reconstructing fragmented\nsentences, with the models showing improved performance with longer input\nutterances. Our result highlights the LLMs' potential in advancing\ncommunication aids for individuals with Broca's aphasia and possibly other\nclinical populations.", "published": "2024-12-23 15:54:15", "link": "http://arxiv.org/abs/2412.17669v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding the Logic of Direct Preference Alignment through Logic", "abstract": "Recent direct preference alignment algorithms (DPA), such as DPO, have shown\ngreat promise in aligning large language models to human preferences. While\nthis has motivated the development of many new variants of the original DPO\nloss, understanding the differences between these recent proposals, as well as\ndeveloping new DPA loss functions, remains difficult given the lack of a\ntechnical and conceptual framework for reasoning about the underlying semantics\nof these algorithms. In this paper, we attempt to remedy this by formalizing\nDPA losses in terms of discrete reasoning problems. Specifically, we ask: Given\nan existing DPA loss, can we systematically derive a symbolic program that\ncharacterizes its semantics? We propose a novel formalism for characterizing\npreference losses for single model and reference model based approaches, and\nidentify symbolic forms for a number of commonly used DPA variants. Further, we\nshow how this formal view of preference learning sheds new light on both the\nsize and structure of the DPA loss landscape, making it possible to not only\nrigorously characterize the relationships between recent loss proposals but\nalso to systematically explore the landscape and derive new loss functions from\nfirst principles. We hope our framework and findings will help provide useful\nguidance to those working on human AI alignment.", "published": "2024-12-23 16:23:13", "link": "http://arxiv.org/abs/2412.17696v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Models to Microtheories: Distilling a Model's Topical Knowledge for\n  Grounded Question Answering", "abstract": "Recent reasoning methods (e.g., chain-of-thought, entailment reasoning) help\nusers understand how language models (LMs) answer a single question, but they\ndo little to reveal the LM's overall understanding, or \"theory,\" about the\nquestion's topic, making it still hard to trust the model. Our goal is to\nmaterialize such theories - here called microtheories (a linguistic analog of\nlogical microtheories) - as a set of sentences encapsulating an LM's core\nknowledge about a topic. These statements systematically work together to\nentail answers to a set of questions to both engender trust and improve\nperformance. Our approach is to first populate a knowledge store with\n(model-generated) sentences that entail answers to training questions and then\ndistill those down to a core microtheory that is concise, general, and\nnon-redundant. We show that, when added to a general corpus (e.g., Wikipedia),\nmicrotheories can supply critical, topical information not necessarily present\nin the corpus, improving both a model's ability to ground its answers to\nverifiable knowledge (i.e., show how answers are systematically entailed by\ndocuments in the corpus, fully grounding up to +8% more answers), and the\naccuracy of those grounded answers (up to +8% absolute). We also show that, in\na human evaluation in the medical domain, our distilled microtheories contain a\nsignificantly higher concentration of topically critical facts than the\nnon-distilled knowledge store. Finally, we show we can quantify the coverage of\na microtheory for a topic (characterized by a dataset) using a notion of\n$p$-relevance. Together, these suggest that microtheories are an efficient\ndistillation of an LM's topic-relevant knowledge, that they can usefully\naugment existing corpora, and can provide both performance gains and an\ninterpretable, verifiable window into the model's knowledge of a topic.", "published": "2024-12-23 16:32:55", "link": "http://arxiv.org/abs/2412.17701v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Editing through Chain-of-Thought", "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross a wide range of natural language processing (NLP) tasks. However,\nkeeping these models up-to-date with evolving world knowledge remains a\nsignificant challenge due to the high costs of frequent retraining. To address\nthis challenge, knowledge editing techniques have emerged to update LLMs with\nnew information without rebuilding the model from scratch. Among these, the\nin-context editing paradigm stands out for its effectiveness in integrating new\nknowledge while preserving the model's original capabilities. Despite its\npotential, existing in-context knowledge editing methods are often\ntask-specific, focusing primarily on multi-hop QA tasks using structured\nknowledge triples. Moreover, their reliance on few-shot prompting for task\ndecomposition makes them unstable and less effective in generalizing across\ndiverse tasks.\n  In response to these limitations, we propose EditCoT, a novel knowledge\nediting framework that flexibly and efficiently updates LLMs across various\ntasks without retraining. EditCoT works by generating a chain-of-thought (CoT)\nfor a given input and then iteratively refining this CoT process using a CoT\neditor based on updated knowledge. We evaluate EditCoT across a diverse range\nof benchmarks, covering multiple languages and tasks. The results demonstrate\nthat our approach achieves state-of-the-art performance while offering superior\ngeneralization, effectiveness, and stability compared to existing methods,\nmarking a significant advancement in the field of knowledge updating. Code and\ndata are available at: https://github.com/bebr2/EditCoT.", "published": "2024-12-23 17:17:50", "link": "http://arxiv.org/abs/2412.17727v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "YuLan-Mini: An Open Data-efficient Language Model", "abstract": "Effective pre-training of large language models (LLMs) has been challenging\ndue to the immense resource demands and the complexity of the technical\nprocesses involved. This paper presents a detailed technical report on\nYuLan-Mini, a highly capable base model with 2.42B parameters that achieves\ntop-tier performance among models of similar parameter scale. Our pre-training\napproach focuses on enhancing training efficacy through three key technical\ncontributions: an elaborate data pipeline combines data cleaning with data\nschedule strategies, a robust optimization method to mitigate training\ninstability, and an effective annealing approach that incorporates targeted\ndata selection and long context training. Remarkably, YuLan-Mini, trained on\n1.08T tokens, achieves performance comparable to industry-leading models that\nrequire significantly more data. To facilitate reproduction, we release the\nfull details of the data composition for each training phase. Project details\ncan be accessed at the following link: https://github.com/RUC-GSAI/YuLan-Mini.", "published": "2024-12-23 17:47:53", "link": "http://arxiv.org/abs/2412.17743v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IITR-CIOL@NLU of Devanagari Script Languages 2025: Multilingual Hate\n  Speech Detection and Target Identification in Devanagari-Scripted Languages", "abstract": "This work focuses on two subtasks related to hate speech detection and target\nidentification in Devanagari-scripted languages, specifically Hindi, Marathi,\nNepali, Bhojpuri, and Sanskrit. Subtask B involves detecting hate speech in\nonline text, while Subtask C requires identifying the specific targets of hate\nspeech, such as individuals, organizations, or communities. We propose the\nMultilingualRobertaClass model, a deep neural network built on the pretrained\nmultilingual transformer model ia-multilingual-transliterated-roberta,\noptimized for classification tasks in multilingual and transliterated contexts.\nThe model leverages contextualized embeddings to handle linguistic diversity,\nwith a classifier head for binary classification. We received 88.40% accuracy\nin Subtask B and 66.11% accuracy in Subtask C, in the test set.", "published": "2024-12-23 19:58:11", "link": "http://arxiv.org/abs/2412.17947v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Path-of-Thoughts: Extracting and Following Paths for Robust Relational\n  Reasoning with Large Language Models", "abstract": "Large language models (LLMs) possess vast semantic knowledge but often\nstruggle with complex reasoning tasks, particularly in relational reasoning\nproblems such as kinship or spatial reasoning. In this paper, we present\nPath-of-Thoughts (PoT), a novel framework designed to tackle relation reasoning\nby decomposing the task into three key stages: graph extraction, path\nidentification, and reasoning. Unlike previous approaches, PoT efficiently\nextracts a task-agnostic graph that identifies crucial entities, relations, and\nattributes within the problem context. Subsequently, PoT identifies relevant\nreasoning chains within the graph corresponding to the posed question,\nfacilitating inference of potential answers. Experimental evaluations on four\nbenchmark datasets, demanding long reasoning chains, demonstrate that PoT\nsurpasses state-of-the-art baselines by a significant margin (maximum 21.3%)\nwithout necessitating fine-tuning or extensive LLM calls. Furthermore, as\nopposed to prior neuro-symbolic methods, PoT exhibits improved resilience\nagainst LLM errors by leveraging the compositional nature of graphs.", "published": "2024-12-23 20:27:12", "link": "http://arxiv.org/abs/2412.17963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Correctness is not Faithfulness in RAG Attributions", "abstract": "Retrieving relevant context is a common approach to reduce hallucinations and\nenhance answer reliability. Explicitly citing source documents allows users to\nverify generated responses and increases trust. Prior work largely evaluates\ncitation correctness - whether cited documents support the corresponding\nstatements. But citation correctness alone is insufficient. To establish trust\nin attributed answers, we must examine both citation correctness and citation\nfaithfulness. In this work, we first disentangle the notions of citation\ncorrectness and faithfulness, which have been applied inconsistently in\nprevious studies. Faithfulness ensures that the model's reliance on cited\ndocuments is genuine, reflecting actual reference use rather than superficial\nalignment with prior beliefs, which we call post-rationalization. We design an\nexperiment that reveals the prevalent issue of post-rationalization, which\nundermines reliable attribution and may result in misplaced trust. Our findings\nsuggest that current attributed answers often lack citation faithfulness (up to\n57 percent of the citations), highlighting the need to evaluate correctness and\nfaithfulness for trustworthy attribution in language models.", "published": "2024-12-23 21:57:11", "link": "http://arxiv.org/abs/2412.18004v1", "categories": ["cs.CL", "68T50 (Primary)", "I.2.7"], "primary_category": "cs.CL"}
{"title": "StructTest: Benchmarking LLMs' Reasoning through Compositional\n  Structured Outputs", "abstract": "The rapid advancement of large language models (LLMs) demands robust,\nunbiased, and scalable evaluation methods. However, human annotations are\ncostly to scale, model-based evaluations are susceptible to stylistic biases,\nand target-answer-based benchmarks are vulnerable to data contamination and\ncheating. To address these limitations, we propose StructTest, a novel\nbenchmark that evaluates LLMs on their ability to follow compositional\ninstructions and generate structured outputs, providing an unbiased,\ncost-effective, and difficult-to-cheat evaluation framework. Assessments are\nconducted deterministically using a rule-based evaluator, which can be easily\nextended to new tasks and datasets. By testing structured outputs across\ndiverse domains including Summarization, Code, HTML, and Math, and evaluating\n17 popular LLMs, we demonstrate that StructTest remains challenging even for\ntop-performing models like Deepseek-V3/R1 and GPT-4o, establishing it as a\nrobust proxy for measuring reasoning capabilities. We believe StructTest offers\na critical and complementary approach to achieving objective and comprehensive\nmodel evaluation.", "published": "2024-12-23 22:08:40", "link": "http://arxiv.org/abs/2412.18011v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Same Company, Same Signal: The Role of Identity in Earnings Call\n  Transcripts", "abstract": "Post-earnings volatility prediction is critical for investors, with previous\nworks often leveraging earnings call transcripts under the assumption that\ntheir rich semantics contribute significantly. To further investigate how\ntranscripts impact volatility, we introduce DEC, a dataset featuring accurate\nvolatility calculations enabled by the previously overlooked beforeAfterMarket\nattribute and dense ticker coverage. Unlike established benchmarks, where each\nticker has only around two earnings, DEC provides 20 earnings records per\nticker. Using DEC, we reveal that post-earnings volatility undergoes\nsignificant shifts, with each ticker displaying a distinct volatility\ndistribution. To leverage historical post-earnings volatility and capture\nticker-specific patterns, we propose two training-free baselines: Post-earnings\nVolatility (PEV) and Same-ticker Post-earnings Volatility (STPEV). These\nbaselines surpass all transcripts-based models on DEC as well as on established\nbenchmarks. Additionally, we demonstrate that current transcript\nrepresentations predominantly capture ticker identity rather than offering\nfinancially meaningful insights specific to each earnings. This is evidenced by\ntwo key observations: earnings representations from the same ticker exhibit\nsignificantly higher similarity compared to those from different tickers, and\npredictions from transcript-based models show strong correlations with prior\npost-earnings volatility.", "published": "2024-12-23 22:49:38", "link": "http://arxiv.org/abs/2412.18029v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Factuality or Fiction? Benchmarking Modern LLMs on Ambiguous QA with\n  Citations", "abstract": "Benchmarking modern large language models (LLMs) on complex and realistic\ntasks is critical to advancing their development. In this work, we evaluate the\nfactual accuracy and citation performance of state-of-the-art LLMs on the task\nof Question Answering (QA) in ambiguous settings with source citations. Using\nthree recently published datasets-DisentQA-DupliCite, DisentQA-ParaCite, and\nAmbigQA-Cite-featuring a range of real-world ambiguities, we analyze the\nperformance of two leading LLMs, GPT-4o-mini and Claude-3.5. Our results show\nthat larger, recent models consistently predict at least one correct answer in\nambiguous contexts but fail to handle cases with multiple valid answers.\nAdditionally, all models perform equally poorly in citation generation, with\ncitation accuracy consistently at 0. However, introducing conflict-aware\nprompting leads to large improvements, enabling models to better address\nmultiple valid answers and improve citation accuracy, while maintaining their\nability to predict correct answers. These findings highlight the challenges and\nopportunities in developing LLMs that can handle ambiguity and provide reliable\nsource citations. Our benchmarking study provides critical insights and sets a\nfoundation for future improvements in trustworthy and interpretable QA systems.", "published": "2024-12-23 23:55:19", "link": "http://arxiv.org/abs/2412.18051v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Generalization and Adaptation Ability of Machine-Generated Text\n  Detectors in Academic Writing", "abstract": "The rising popularity of large language models (LLMs) has raised concerns\nabout machine-generated text (MGT), particularly in academic settings, where\nissues like plagiarism and misinformation are prevalent. As a result,\ndeveloping a highly generalizable and adaptable MGT detection system has become\nan urgent priority. Given that LLMs are most commonly misused in academic\nwriting, this work investigates the generalization and adaptation capabilities\nof MGT detectors in three key aspects specific to academic writing: First, we\nconstruct MGT-Acedemic, a large-scale dataset comprising over 336M tokens and\n749K samples. MGT-Acedemic focuses on academic writing, featuring human-written\ntexts (HWTs) and MGTs across STEM, Humanities, and Social Sciences, paired with\nan extensible code framework for efficient benchmarking. Second, we benchmark\nthe performance of various detectors for binary classification and attribution\ntasks in both in-domain and cross-domain settings. This benchmark reveals the\noften-overlooked challenges of attribution tasks. Third, we introduce a novel\nattribution task where models have to adapt to new classes over time without\n(or with very limited) access to prior training data in both few-shot and\nmany-shot scenarios. We implement eight different adapting techniques to\nimprove the performance and highlight the inherent complexity of the task. Our\nfindings provide insights into the generalization and adaptation ability of MGT\ndetectors across diverse scenarios and lay the foundation for building robust,\nadaptive detection systems. The code framework is available at\nhttps://github.com/Y-L-LIU/MGTBench-2.0.", "published": "2024-12-23 03:30:34", "link": "http://arxiv.org/abs/2412.17242v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Unlocking Cross-Lingual Sentiment Analysis through Emoji Interpretation:\n  A Multimodal Generative AI Approach", "abstract": "Emojis have become ubiquitous in online communication, serving as a universal\nmedium to convey emotions and decorative elements. Their widespread use\ntranscends language and cultural barriers, enhancing understanding and\nfostering more inclusive interactions. While existing work gained valuable\ninsight into emojis understanding, exploring emojis' capability to serve as a\nuniversal sentiment indicator leveraging large language models (LLMs) has not\nbeen thoroughly examined. Our study aims to investigate the capacity of emojis\nto serve as reliable sentiment markers through LLMs across languages and\ncultures. We leveraged the multimodal capabilities of ChatGPT to explore the\nsentiments of various representations of emojis and evaluated how well\nemoji-conveyed sentiment aligned with text sentiment on a multi-lingual dataset\ncollected from 32 countries. Our analysis reveals that the accuracy of\nLLM-based emoji-conveyed sentiment is 81.43%, underscoring emojis' significant\npotential to serve as a universal sentiment marker. We also found a consistent\ntrend that the accuracy of sentiment conveyed by emojis increased as the number\nof emojis grew in text. The results reinforce the potential of emojis to serve\nas global sentiment indicators, offering insight into fields such as\ncross-lingual and cross-cultural sentiment analysis on social media platforms.\nCode: https://github.com/ResponsibleAILab/emoji-universal-sentiment.", "published": "2024-12-23 03:57:45", "link": "http://arxiv.org/abs/2412.17255v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LegalAgentBench: Evaluating LLM Agents in Legal Domain", "abstract": "With the increasing intelligence and autonomy of LLM agents, their potential\napplications in the legal domain are becoming increasingly apparent. However,\nexisting general-domain benchmarks cannot fully capture the complexity and\nsubtle nuances of real-world judicial cognition and decision-making. Therefore,\nwe propose LegalAgentBench, a comprehensive benchmark specifically designed to\nevaluate LLM Agents in the Chinese legal domain. LegalAgentBench includes 17\ncorpora from real-world legal scenarios and provides 37 tools for interacting\nwith external knowledge. We designed a scalable task construction framework and\ncarefully annotated 300 tasks. These tasks span various types, including\nmulti-hop reasoning and writing, and range across different difficulty levels,\neffectively reflecting the complexity of real-world legal scenarios. Moreover,\nbeyond evaluating final success, LegalAgentBench incorporates keyword analysis\nduring intermediate processes to calculate progress rates, enabling more\nfine-grained evaluation. We evaluated eight popular LLMs, highlighting the\nstrengths, limitations, and potential areas for improvement of existing models\nand methods. LegalAgentBench sets a new benchmark for the practical application\nof LLMs in the legal domain, with its code and data available at\n\\url{https://github.com/CSHaitao/LegalAgentBench}.", "published": "2024-12-23 04:02:46", "link": "http://arxiv.org/abs/2412.17259v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Assessing Human Editing Effort on LLM-Generated Texts via\n  Compression-Based Edit Distance", "abstract": "Assessing the extent of human edits on texts generated by Large Language\nModels (LLMs) is crucial to understanding the human-AI interactions and\nimproving the quality of automated text generation systems. Existing edit\ndistance metrics, such as Levenshtein, BLEU, ROUGE, and TER, often fail to\naccurately measure the effort required for post-editing, especially when edits\ninvolve substantial modifications, such as block operations. In this paper, we\nintroduce a novel compression-based edit distance metric grounded in the\nLempel-Ziv-77 algorithm, designed to quantify the amount of post-editing\napplied to LLM-generated texts. Our method leverages the properties of text\ncompression to measure the informational difference between the original and\nedited texts. Through experiments on real-world human edits datasets, we\ndemonstrate that our proposed metric is highly correlated with actual edit time\nand effort. We also show that LLMs exhibit an implicit understanding of editing\nspeed, that aligns well with our metric. Furthermore, we compare our metric\nwith existing ones, highlighting its advantages in capturing complex edits with\nlinear computational efficiency. Our code and data are available at:\nhttps://github.com/NDV-tiime/CompressionDistance", "published": "2024-12-23 06:29:25", "link": "http://arxiv.org/abs/2412.17321v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MineAgent: Towards Remote-Sensing Mineral Exploration with Multimodal\n  Large Language Models", "abstract": "Remote-sensing mineral exploration is critical for identifying economically\nviable mineral deposits, yet it poses significant challenges for multimodal\nlarge language models (MLLMs). These include limitations in domain-specific\ngeological knowledge and difficulties in reasoning across multiple\nremote-sensing images, further exacerbating long-context issues. To address\nthese, we present MineAgent, a modular framework leveraging hierarchical\njudging and decision-making modules to improve multi-image reasoning and\nspatial-spectral integration. Complementing this, we propose MineBench, a\nbenchmark specific for evaluating MLLMs in domain-specific mineral exploration\ntasks using geological and hyperspectral data. Extensive experiments\ndemonstrate the effectiveness of MineAgent, highlighting its potential to\nadvance MLLMs in remote-sensing mineral exploration.", "published": "2024-12-23 07:08:14", "link": "http://arxiv.org/abs/2412.17339v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Boosting LLM via Learning from Data Iteratively and Selectively", "abstract": "Datasets nowadays are generally constructed from multiple sources and using\ndifferent synthetic techniques, making data de-noising and de-duplication\ncrucial before being used for post-training. In this work, we propose to\nperform instruction tuning by iterative data selection (\\ApproachName{}). We\nmeasure the quality of a sample from complexity and diversity simultaneously.\nInstead of calculating the complexity score once for all before fine-tuning, we\nhighlight the importance of updating this model-specific score during\nfine-tuning to accurately accommodate the dynamic changes of the model. On the\nother hand, the diversity score is defined on top of the samples' responses\nunder the consideration of their informativeness. IterIT integrates the\nstrengths of both worlds by iteratively updating the complexity score for the\ntop-ranked samples and greedily selecting the ones with the highest\ncomplexity-diversity score. Experiments on multiple instruction-tuning data\ndemonstrate consistent improvements of IterIT over strong baselines. Moreover,\nour approach also generalizes well to domain-specific scenarios and different\nbackbone models. All resources will be available at\nhttps://github.com/JiaQiSJTU/IterIT.", "published": "2024-12-23 08:01:24", "link": "http://arxiv.org/abs/2412.17365v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Developmental Predictive Coding Model for Early Infancy Mono and\n  Bilingual Vocal Continual Learning", "abstract": "Understanding how infants perceive speech sounds and language structures is\nstill an open problem. Previous research in artificial neural networks has\nmainly focused on large dataset-dependent generative models, aiming to\nreplicate language-related phenomena such as ''perceptual narrowing''. In this\npaper, we propose a novel approach using a small-sized generative neural\nnetwork equipped with a continual learning mechanism based on predictive coding\nfor mono-and bilingual speech sound learning (referred to as language sound\nacquisition during ''critical period'') and a compositional optimization\nmechanism for generation where no learning is involved (later infancy sound\nimitation). Our model prioritizes interpretability and demonstrates the\nadvantages of online learning: Unlike deep networks requiring substantial\noffline training, our model continuously updates with new data, making it\nadaptable and responsive to changing inputs. Through experiments, we\ndemonstrate that if second language acquisition occurs during later infancy,\nthe challenges associated with learning a foreign language after the critical\nperiod amplify, replicating the perceptual narrowing effect.", "published": "2024-12-23 10:23:47", "link": "http://arxiv.org/abs/2412.17456v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Survey on LLM-based Multi-Agent System: Recent Advances and New\n  Frontiers in Application", "abstract": "LLM-based Multi-Agent Systems ( LLM-MAS ) have become a research hotspot\nsince the rise of large language models (LLMs). However, with the continuous\ninflux of new related works, the existing reviews struggle to capture them\ncomprehensively. This paper presents a comprehensive survey of these studies.\nWe first discuss the definition of LLM-MAS, a framework encompassing much of\nprevious work. We provide an overview of the various applications of LLM-MAS in\n(i) solving complex tasks, (ii) simulating specific scenarios, and (iii)\nevaluating generative agents. Building on previous studies, we also highlight\nseveral challenges and propose future directions for research in this field.", "published": "2024-12-23 11:11:51", "link": "http://arxiv.org/abs/2412.17481v2", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "DRT: Deep Reasoning Translation via Long Chain-of-Thought", "abstract": "Recently, O1-like models have emerged as representative examples,\nillustrating the effectiveness of long chain-of-thought (CoT) in reasoning\ntasks such as math and coding tasks. In this paper, we introduce DRT, an\nattempt to bring the success of long CoT to neural machine translation (MT).\nSpecifically, in view of the literature books that might involve similes and\nmetaphors, translating these texts to a target language is very difficult in\npractice due to cultural differences. In such cases, literal translation often\nfails to convey the intended meaning effectively. Even for professional human\ntranslators, considerable thought must be given to preserving semantics\nthroughout the translation process. To simulate LLMs' long thought ability in\nMT, we first mine sentences containing similes or metaphors from existing\nliterature books, and then develop a multi-agent framework to translate these\nsentences via long thought. In the multi-agent framework, a translator is used\nto iteratively translate the source sentence under the suggestions provided by\nan advisor. To ensure the effectiveness of the long thoughts, an evaluator is\nalso employed to quantify the translation quality in each round. In this way,\nwe collect tens of thousands of long-thought MT data, which is used to train\nour DRT. Using Qwen2.5 and LLama-3.1 as the backbones, DRT models can learn the\nthought process during machine translation, and outperform vanilla LLMs as well\nas LLMs which are simply fine-tuning on the paired sentences without long\nthought, showing its effectiveness.", "published": "2024-12-23 11:55:33", "link": "http://arxiv.org/abs/2412.17498v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Resource-Aware Arabic LLM Creation: Model Adaptation, Integration, and\n  Multi-Domain Testing", "abstract": "This paper presents a novel approach to fine-tuning the Qwen2-1.5B model for\nArabic language processing using Quantized Low-Rank Adaptation (QLoRA) on a\nsystem with only 4GB VRAM. We detail the process of adapting this large\nlanguage model to the Arabic domain, using diverse datasets including Bactrian,\nOpenAssistant, and Wikipedia Arabic corpora. Our methodology involves custom\ndata preprocessing, model configuration, and training optimization techniques\nsuch as gradient accumulation and mixed-precision training. We address specific\nchallenges in Arabic NLP, including morphological complexity, dialectal\nvariations, and diacritical mark handling. Experimental results over 10,000\ntraining steps show significant performance improvements, with the final loss\nconverging to 0.1083. We provide comprehensive analysis of GPU memory usage,\ntraining dynamics, and model evaluation across various Arabic language tasks,\nincluding text classification, question answering, and dialect identification.\nThe fine-tuned model demonstrates robustness to input perturbations and\nimproved handling of Arabic-specific linguistic phenomena. This research\ncontributes to multilingual AI by demonstrating a resource-efficient approach\nfor creating specialized language models, potentially democratizing access to\nadvanced NLP technologies for diverse linguistic communities. Our work paves\nthe way for future research in low-resource language adaptation and efficient\nfine-tuning of large language models.", "published": "2024-12-23 13:08:48", "link": "http://arxiv.org/abs/2412.17548v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of Document-Level Embedding Methods for Similarity\n  Scoring on Shakespeare Sonnets and Taylor Swift Lyrics", "abstract": "This study evaluates the performance of TF-IDF weighting, averaged Word2Vec\nembeddings, and BERT embeddings for document similarity scoring across two\ncontrasting textual domains. By analysing cosine similarity scores, the\nmethods' strengths and limitations are highlighted. The findings underscore\nTF-IDF's reliance on lexical overlap and Word2Vec's superior semantic\ngeneralisation, particularly in cross-domain comparisons. BERT demonstrates\nlower performance in challenging domains, likely due to insufficient\ndomainspecific fine-tuning.", "published": "2024-12-23 13:20:06", "link": "http://arxiv.org/abs/2412.17552v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "LiveIdeaBench: Evaluating LLMs' Scientific Creativity and Idea\n  Generation with Minimal Context", "abstract": "While Large Language Models (LLMs) have demonstrated remarkable capabilities\nin scientific tasks, existing evaluation frameworks primarily assess their\nperformance using rich contextual inputs, overlooking their ability to generate\nnovel ideas from minimal information. We introduce LiveIdeaBench, a\ncomprehensive benchmark that evaluates LLMs' scientific creativity and\ndivergent thinking capabilities using single-keyword prompts. Drawing from\nGuilford's creativity theory, our framework employs a dynamic panel of\nstate-of-the-art LLMs to assess generated ideas across four key dimensions:\noriginality, feasibility, fluency, and flexibility. Through extensive\nexperimentation with 20 leading models across 1,180 keywords spanning 18\nscientific domains, we reveal that scientific creative ability shows distinct\npatterns from general intelligence metrics. Notably, our results demonstrate\nthat models like QwQ-32B-preview achieve comparable creative performance to\ntop-tier models like o1-preview, despite significant gaps in their general\nintelligence scores. These findings highlight the importance of specialized\nevaluation frameworks for scientific creativity and suggest that the\ndevelopment of creative capabilities in LLMs may follow different trajectories\nthan traditional problem-solving abilities.", "published": "2024-12-23 14:13:44", "link": "http://arxiv.org/abs/2412.17596v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tracking the Feature Dynamics in LLM Training: A Mechanistic Study", "abstract": "Understanding training dynamics and feature evolution is crucial for the\nmechanistic interpretability of large language models (LLMs). Although sparse\nautoencoders (SAEs) have been used to identify features within LLMs, a clear\npicture of how these features evolve during training remains elusive. In this\nstudy, we: (1) introduce SAE-Track, a novel method to efficiently obtain a\ncontinual series of SAEs; (2) mechanistically investigate feature formation and\ndevelop a progress measure for it ; and (3) analyze and visualize feature drift\nduring training. Our work provides new insights into the dynamics of features\nin LLMs, enhancing our understanding of training mechanisms and feature\nevolution.", "published": "2024-12-23 14:58:37", "link": "http://arxiv.org/abs/2412.17626v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Language Model Safety: A Holistic Survey", "abstract": "The rapid development and deployment of large language models (LLMs) have\nintroduced a new frontier in artificial intelligence, marked by unprecedented\ncapabilities in natural language understanding and generation. However, the\nincreasing integration of these models into critical applications raises\nsubstantial safety concerns, necessitating a thorough examination of their\npotential risks and associated mitigation strategies.\n  This survey provides a comprehensive overview of the current landscape of LLM\nsafety, covering four major categories: value misalignment, robustness to\nadversarial attacks, misuse, and autonomous AI risks. In addition to the\ncomprehensive review of the mitigation methodologies and evaluation resources\non these four aspects, we further explore four topics related to LLM safety:\nthe safety implications of LLM agents, the role of interpretability in\nenhancing LLM safety, the technology roadmaps proposed and abided by a list of\nAI companies and institutes for LLM safety, and AI governance aimed at LLM\nsafety with discussions on international cooperation, policy proposals, and\nprospective regulatory directions.\n  Our findings underscore the necessity for a proactive, multifaceted approach\nto LLM safety, emphasizing the integration of technical solutions, ethical\nconsiderations, and robust governance frameworks. This survey is intended to\nserve as a foundational resource for academy researchers, industry\npractitioners, and policymakers, offering insights into the challenges and\nopportunities associated with the safe integration of LLMs into society.\nUltimately, it seeks to contribute to the safe and beneficial development of\nLLMs, aligning with the overarching goal of harnessing AI for societal\nadvancement and well-being. A curated list of related papers has been publicly\navailable at https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.", "published": "2024-12-23 16:11:27", "link": "http://arxiv.org/abs/2412.17686v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF\n  for Conversational QA over KGs with RAG", "abstract": "Conversational question answering (ConvQA) is a convenient means of searching\nover RDF knowledge graphs (KGs), where a prevalent approach is to translate\nnatural language questions to SPARQL queries. However, SPARQL has certain\nshortcomings: (i) it is brittle for complex intents and conversational\nquestions, and (ii) it is not suitable for more abstract needs. Instead, we\npropose a novel two-pronged system where we fuse: (i) SQL-query results over a\ndatabase automatically derived from the KG, and (ii) text-search results over\nverbalizations of KG facts. Our pipeline supports iterative retrieval: when the\nresults of any branch are found to be unsatisfactory, the system can\nautomatically opt for further rounds. We put everything together in a retrieval\naugmented generation (RAG) setup, where an LLM generates a coherent response\nfrom accumulated search results. We demonstrate the superiority of our proposed\nsystem over several baselines on a knowledge graph of BMW automobiles.", "published": "2024-12-23 16:16:30", "link": "http://arxiv.org/abs/2412.17690v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Chumor 2.0: Towards Benchmarking Chinese Humor Understanding", "abstract": "Existing humor datasets and evaluations predominantly focus on English,\nleaving limited resources for culturally nuanced humor in non-English languages\nlike Chinese. To address this gap, we construct Chumor, the first Chinese humor\nexplanation dataset that exceeds the size of existing humor datasets. Chumor is\nsourced from Ruo Zhi Ba, a Chinese Reddit-like platform known for sharing\nintellectually challenging and culturally specific jokes. We test ten LLMs\nthrough direct and chain-of-thought prompting, revealing that Chumor poses\nsignificant challenges to existing LLMs, with their accuracy slightly above\nrandom and far below human. In addition, our analysis highlights that\nhuman-annotated humor explanations are significantly better than those\ngenerated by GPT-4o and ERNIE-4-turbo. We release Chumor at\nhttps://huggingface.co/datasets/dnaihao/Chumor, our project page is at\nhttps://dnaihao.github.io/Chumor-dataset/, our leaderboard is at\nhttps://huggingface.co/spaces/dnaihao/Chumor, and our codebase is at\nhttps://github.com/dnaihao/Chumor-dataset.", "published": "2024-12-23 17:19:58", "link": "http://arxiv.org/abs/2412.17729v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fourier Position Embedding: Enhancing Attention's Periodic Extension for\n  Length Generalization", "abstract": "Extending the context length of Language Models (LMs) by improving Rotary\nPosition Embedding (RoPE) has become a trend. While existing works mainly\naddress RoPE's limitations within attention mechanism, this paper provides an\nanalysis across nearly all parts of LMs, uncovering their adverse effects on\nlength generalization for RoPE-based attention. Using Discrete Signal\nProcessing theory, we show that RoPE enables periodic attention by implicitly\nachieving Non-Uniform Discrete Fourier Transform. However, this periodicity is\nundermined by the spectral damage caused by: 1) linear layers and activation\nfunctions outside of attention; 2) insufficiently trained frequency components\nbrought by time-domain truncation. Building on our observations, we propose\nFourier Position Embedding (FoPE), which enhances attention's frequency-domain\nproperties to improve both its periodic extension and length generalization.\nFoPE constructs Fourier Series and zero-outs the destructive frequency\ncomponents, increasing model robustness against the spectrum damage.\nExperiments across various model scales show that, within varying context\nwindows, FoPE can maintain a more stable perplexity and a more consistent\naccuracy in a needle-in-haystack task compared to RoPE and ALiBi. Several\nanalyses and ablations bring further support to our method and theoretical\nmodeling.", "published": "2024-12-23 17:44:01", "link": "http://arxiv.org/abs/2412.17739v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "In Case You Missed It: ARC 'Challenge' Is Not That Challenging", "abstract": "ARC Challenge appears more difficult than ARC Easy for modern LLMs primarily\ndue to an evaluation setup that prevents direct comparison of answer choices\nrather than inherent complexity. Although some researchers have quietly shifted\nto a more appropriate scheme over the last year, the implications of this\nchange have yet to be widely acknowledged. We highlight this overlooked shift,\nshow how similar evaluation practices falsely imply reasoning deficits in other\nbenchmarks, and demonstrate that fairer methods dramatically reduce performance\ngaps (e.g. on SIQA) and even yield superhuman results (OpenBookQA). In doing\nso, we reveal how evaluation shapes perceived difficulty and offer guidelines\nto ensure that multiple-choice evaluations accurately reflect actual model\ncapabilities.", "published": "2024-12-23 18:14:36", "link": "http://arxiv.org/abs/2412.17758v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ResearchTown: Simulator of Human Research Community", "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in\nscientific domains, yet a fundamental question remains unanswered: Can we\nsimulate human research communities with LLMs? Addressing this question can\ndeepen our understanding of the processes behind idea brainstorming and inspire\nthe automatic discovery of novel scientific insights. In this work, we propose\nResearchTown, a multi-agent framework for research community simulation. Within\nthis framework, the human research community is simplified and modeled as an\nagent-data graph, where researchers and papers are represented as agent-type\nand data-type nodes, respectively, and connected based on their collaboration\nrelationships. We also introduce TextGNN, a text-based inference framework that\nmodels various research activities (e.g., paper reading, paper writing, and\nreview writing) as special forms of a unified message-passing process on the\nagent-data graph. To evaluate the quality of the research simulation, we\npresent ResearchBench, a benchmark that uses a node-masking prediction task for\nscalable and objective assessment based on similarity. Our experiments reveal\nthree key findings: (1) ResearchTown can provide a realistic simulation of\ncollaborative research activities, including paper writing and review writing;\n(2) ResearchTown can maintain robust simulation with multiple researchers and\ndiverse papers; (3) ResearchTown can generate interdisciplinary research ideas\nthat potentially inspire novel research directions.", "published": "2024-12-23 18:26:53", "link": "http://arxiv.org/abs/2412.17767v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Text-Rich Visual Comprehension: An Information Theory\n  Perspective", "abstract": "Recent Large Vision-Language Models (LVLMs) have shown promising reasoning\ncapabilities on text-rich images from charts, tables, and documents. However,\nthe abundant text within such images may increase the model's sensitivity to\nlanguage. This raises the need to evaluate LVLM performance on cross-lingual\ntext-rich visual inputs, where the language in the image differs from the\nlanguage of the instructions. To address this, we introduce XT-VQA\n(Cross-Lingual Text-Rich Visual Question Answering), a benchmark designed to\nassess how LVLMs handle language inconsistency between image text and\nquestions. XT-VQA integrates five existing text-rich VQA datasets and a newly\ncollected dataset, XPaperQA, covering diverse scenarios that require faithful\nrecognition and comprehension of visual information despite language\ninconsistency. Our evaluation of prominent LVLMs on XT-VQA reveals a\nsignificant drop in performance for cross-lingual scenarios, even for models\nwith multilingual capabilities. A mutual information analysis suggests that\nthis performance gap stems from cross-lingual questions failing to adequately\nactivate relevant visual information. To mitigate this issue, we propose\nMVCL-MI (Maximization of Vision-Language Cross-Lingual Mutual Information),\nwhere a visual-text cross-lingual alignment is built by maximizing mutual\ninformation between the model's outputs and visual information. This is\nachieved by distilling knowledge from monolingual to cross-lingual settings\nthrough KL divergence minimization, where monolingual output logits serve as a\nteacher. Experimental results on the XT-VQA demonstrate that MVCL-MI\neffectively reduces the visual-text cross-lingual performance disparity while\npreserving the inherent capabilities of LVLMs, shedding new light on the\npotential practice for improving LVLMs. Codes are available at:\nhttps://github.com/Stardust-y/XTVQA.git", "published": "2024-12-23 18:48:04", "link": "http://arxiv.org/abs/2412.17787v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The Power of Adaptation: Boosting In-Context Learning through Adaptive\n  Prompting", "abstract": "Large Language Models (LLMs) have demonstrated exceptional abilities across a\nbroad range of language-related tasks, including generating solutions to\ncomplex reasoning problems. An effective technique to enhance LLM performance\nis in-context learning, which encourages a step-by-step reasoning process by\nincluding explanatory examples to guide the model's responses. However,\nselecting appropriate exemplars for the model poses a challenge, as each\ndataset demands a distinct set of exemplars to enable the LLM to learn\neffectively and perform well on the test set. Current studies often rely on\nuncertainty- or diversity-based selection strategies to select exemplars for\nannotation and to improve model learning. However, these studies typically\nemploy a non-adaptive approach, selecting a set of exemplars all at once. We\nargue that this non-adaptive strategy may result in a set of exemplars with\nhigh redundancy in terms of the knowledge covered, ultimately reducing their\noverall informativeness. To address this limitation, we propose\n\\textsc{Adaptive-Prompt}, a novel method that adaptively selects exemplars by\nleveraging model feedback from previously chosen exemplars. Experimental\nresults show that \\textsc{Adaptive-Prompt} significantly enhances LLM\nperformance across a variety of reasoning tasks.", "published": "2024-12-23 15:49:43", "link": "http://arxiv.org/abs/2412.17891v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VITRO: Vocabulary Inversion for Time-series Representation Optimization", "abstract": "Although LLMs have demonstrated remarkable capabilities in processing and\ngenerating textual data, their pre-trained vocabularies are ill-suited for\ncapturing the nuanced temporal dynamics and patterns inherent in time series.\nThe discrete, symbolic nature of natural language tokens, which these\nvocabularies are designed to represent, does not align well with the\ncontinuous, numerical nature of time series data. To address this fundamental\nlimitation, we propose VITRO. Our method adapts textual inversion optimization\nfrom the vision-language domain in order to learn a new time series per-dataset\nvocabulary that bridges the gap between the discrete, semantic nature of\nnatural language and the continuous, numerical nature of time series data. We\nshow that learnable time series-specific pseudo-word embeddings represent time\nseries data better than existing general language model vocabularies, with\nVITRO-enhanced methods achieving state-of-the-art performance in long-term\nforecasting across most datasets.", "published": "2024-12-23 19:24:51", "link": "http://arxiv.org/abs/2412.17921v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BenCzechMark : A Czech-centric Multitask and Multimetric Benchmark for\n  Large Language Models with Duel Scoring Mechanism", "abstract": "We present BenCzechMark (BCM), the first comprehensive Czech language\nbenchmark designed for large language models, offering diverse tasks, multiple\ntask formats, and multiple evaluation metrics. Its scoring system is grounded\nin statistical significance theory and uses aggregation across tasks inspired\nby social preference theory. Our benchmark encompasses 50 challenging tasks,\nwith corresponding test datasets, primarily in native Czech, with 11 newly\ncollected ones. These tasks span 8 categories and cover diverse domains,\nincluding historical Czech news, essays from pupils or language learners, and\nspoken word.\n  Furthermore, we collect and clean BUT-Large Czech Collection, the largest\npublicly available clean Czech language corpus, and use it for (i)\ncontamination analysis, (ii) continuous pretraining of the first Czech-centric\n7B language model, with Czech-specific tokenization. We use our model as a\nbaseline for comparison with publicly available multilingual models. Lastly, we\nrelease and maintain a leaderboard, with existing 44 model submissions, where\nnew model submissions can be made at\nhttps://huggingface.co/spaces/CZLC/BenCzechMark.", "published": "2024-12-23 19:45:20", "link": "http://arxiv.org/abs/2412.17933v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explainability in Neural Networks for Natural Language Processing Tasks", "abstract": "Neural networks are widely regarded as black-box models, creating significant\nchallenges in understanding their inner workings, especially in natural\nlanguage processing (NLP) applications. To address this opacity, model\nexplanation techniques like Local Interpretable Model-Agnostic Explanations\n(LIME) have emerged as essential tools for providing insights into the behavior\nof these complex systems. This study leverages LIME to interpret a multi-layer\nperceptron (MLP) neural network trained on a text classification task. By\nanalyzing the contribution of individual features to model predictions, the\nLIME approach enhances interpretability and supports informed decision-making.\nDespite its effectiveness in offering localized explanations, LIME has\nlimitations in capturing global patterns and feature interactions. This\nresearch highlights the strengths and shortcomings of LIME and proposes\ndirections for future work to achieve more comprehensive interpretability in\nneural NLP models.", "published": "2024-12-23 23:09:56", "link": "http://arxiv.org/abs/2412.18036v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Aligning AI Research with the Needs of Clinical Coding Workflows: Eight\n  Recommendations Based on US Data Analysis and Critical Review", "abstract": "Clinical coding is crucial for healthcare billing and data analysis. Manual\nclinical coding is labour-intensive and error-prone, which has motivated\nresearch towards full automation of the process. However, our analysis, based\non US English electronic health records and automated coding research using\nthese records, shows that widely used evaluation methods are not aligned with\nreal clinical contexts. For example, evaluations that focus on the top 50 most\ncommon codes are an oversimplification, as there are thousands of codes used in\npractice. This position paper aims to align AI coding research more closely\nwith practical challenges of clinical coding. Based on our analysis, we offer\neight specific recommendations, suggesting ways to improve current evaluation\nmethods. Additionally, we propose new AI-based methods beyond automated coding,\nsuggesting alternative approaches to assist clinical coders in their workflows.", "published": "2024-12-23 23:39:05", "link": "http://arxiv.org/abs/2412.18043v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Recent Developments in Deep Learning-based Author Name Disambiguation", "abstract": "Author Name Disambiguation (AND) is a critical task for digital libraries\naiming to link existing authors with their respective publications. Due to the\nlack of persistent identifiers used by researchers and the presence of\nintrinsic linguistic challenges, such as homonymy, the development of Deep\nLearning algorithms to address this issue has become widespread. Many AND deep\nlearning methods have been developed, and surveys exist comparing the\napproaches in terms of techniques, complexity, performance. However, none\nexplicitly addresses AND methods in the context of deep learning in the latest\nyears (i.e. timeframe 2016-2024). In this paper, we provide a systematic review\nof state-of-the-art AND techniques based on deep learning, highlighting recent\nimprovements, challenges, and open issues in the field. We find that DL methods\nhave significantly impacted AND by enabling the integration of structured and\nunstructured data, and hybrid approaches effectively balance supervised and\nunsupervised learning.", "published": "2024-12-23 19:27:31", "link": "http://arxiv.org/abs/2503.13448v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Brain-to-Text Benchmark '24: Lessons Learned", "abstract": "Speech brain-computer interfaces aim to decipher what a person is trying to\nsay from neural activity alone, restoring communication to people with\nparalysis who have lost the ability to speak intelligibly. The Brain-to-Text\nBenchmark '24 and associated competition was created to foster the advancement\nof decoding algorithms that convert neural activity to text. Here, we summarize\nthe lessons learned from the competition ending on June 1, 2024 (the top 4\nentrants also presented their experiences in a recorded webinar). The largest\nimprovements in accuracy were achieved using an ensembling approach, where the\noutput of multiple independent decoders was merged using a fine-tuned large\nlanguage model (an approach used by all 3 top entrants). Performance gains were\nalso found by improving how the baseline recurrent neural network (RNN) model\nwas trained, including by optimizing learning rate scheduling and by using a\ndiphone training objective. Improving upon the model architecture itself proved\nmore difficult, however, with attempts to use deep state space models or\ntransformers not yet appearing to offer a benefit over the RNN baseline. The\nbenchmark will remain open indefinitely to support further work towards\nincreasing the accuracy of brain-to-text algorithms.", "published": "2024-12-23 02:44:35", "link": "http://arxiv.org/abs/2412.17227v1", "categories": ["cs.CL", "cs.LG", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "B-STaR: Monitoring and Balancing Exploration and Exploitation in\n  Self-Taught Reasoners", "abstract": "In the absence of extensive human-annotated data for complex reasoning tasks,\nself-improvement -- where models are trained on their own outputs -- has\nemerged as a primary method for enhancing performance. However, the critical\nfactors underlying the mechanism of these iterative self-improving methods\nremain poorly understood, such as under what conditions self-improvement is\neffective, and what are the bottlenecks in the current iterations. In this\nwork, we identify and propose methods to monitor two pivotal factors in this\niterative process: (1) the model's ability to generate sufficiently diverse\nresponses (exploration); and (2) the effectiveness of external rewards in\ndistinguishing high-quality candidates from lower-quality ones (exploitation).\nUsing mathematical reasoning as a case study, we begin with a quantitative\nanalysis to track the dynamics of exploration and exploitation, discovering\nthat a model's exploratory capabilities rapidly deteriorate over iterations,\nand the effectiveness of exploiting external rewards diminishes as well.\nMotivated by these findings, we introduce B-STaR, a Self-Taught Reasoning\nframework that autonomously adjusts configurations across iterations to Balance\nexploration and exploitation, thereby optimizing the self-improving\neffectiveness based on the current policy model and available rewards. Our\nexperiments on mathematical reasoning, coding, and commonsense reasoning\ndemonstrate that B-STaR not only enhances the model's exploratory capabilities\nthroughout training but also achieves a more effective balance between\nexploration and exploitation, leading to superior performance.", "published": "2024-12-23 03:58:34", "link": "http://arxiv.org/abs/2412.17256v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "CodeV: Issue Resolving with Visual Data", "abstract": "Large Language Models (LLMs) have advanced rapidly in recent years, with\ntheir applications in software engineering expanding to more complex\nrepository-level tasks. GitHub issue resolving is a key challenge among these\ntasks. While recent approaches have made progress on this task, they focus on\ntextual data within issues, neglecting visual data. However, this visual data\nis crucial for resolving issues as it conveys additional knowledge that text\nalone cannot. We propose CodeV, the first approach to leveraging visual data to\nenhance the issue-resolving capabilities of LLMs. CodeV resolves each issue by\nfollowing a two-phase process: data processing and patch generation. To\nevaluate CodeV, we construct a benchmark for visual issue resolving, namely\nVisual SWE-bench. Through extensive experiments, we demonstrate the\neffectiveness of CodeV, as well as provide valuable insights into leveraging\nvisual data to resolve GitHub issues.", "published": "2024-12-23 06:17:11", "link": "http://arxiv.org/abs/2412.17315v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Fast Gradient Computation for RoPE Attention in Almost Linear Time", "abstract": "The Rotary Position Embedding (RoPE) mechanism has become a powerful\nenhancement to the Transformer architecture, which enables models to capture\ntoken relationships when encoding positional information. However, the RoPE\nmechanisms make the computations of attention mechanisms more complicated,\nwhich makes efficient algorithms challenging. Earlier research introduced\nalmost linear time, i.e., $n^{1+o(1)}$ where $n$ is the number of input tokens,\nalgorithms for the forward computation under specific parameter settings.\nHowever, achieving a subquadratic time algorithm for other parameter regimes\nremains impossible unless the widely accepted Strong Exponential Time\nHypothesis (SETH) is disproven. In this work, we develop the first almost\nlinear time algorithm for backward computations in the RoPE-based attention\nunder bounded entries. Our approach builds on recent advancements in fast RoPE\nattention computations, utilizing a novel combination of the polynomial method\nand the Fast Fourier Transform. Furthermore, we show that with lower bounds\nderived from the SETH, the bounded entry condition is necessary for\nsubquadratic performance.", "published": "2024-12-23 06:20:22", "link": "http://arxiv.org/abs/2412.17316v2", "categories": ["cs.LG", "cs.AI", "cs.CC", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Three-Class Text Sentiment Analysis Based on LSTM", "abstract": "Sentiment analysis is a crucial task in natural language processing (NLP)\nwith applications in public opinion monitoring, market research, and beyond.\nThis paper introduces a three-class sentiment classification method for Weibo\ncomments using Long Short-Term Memory (LSTM) networks to discern positive,\nneutral, and negative sentiments. LSTM, as a deep learning model, excels at\ncapturing long-distance dependencies in text data, providing significant\nadvantages over traditional machine learning approaches. Through preprocessing\nand feature extraction from Weibo comment texts, our LSTM model achieves\nprecise sentiment prediction. Experimental results demonstrate superior\nperformance, achieving an accuracy of 98.31% and an F1 score of 98.28%, notably\noutperforming conventional models and other deep learning methods. This\nunderscores the effectiveness of LSTM in capturing nuanced sentiment\ninformation within text, thereby enhancing classification accuracy. Despite its\nstrengths, the LSTM model faces challenges such as high computational\ncomplexity and slower processing times for lengthy texts. Moreover, complex\nemotional expressions like sarcasm and humor pose additional difficulties.\nFuture work could explore combining pre-trained models or advancing feature\nengineering techniques to further improve both accuracy and practicality.\nOverall, this study provides an effective solution for sentiment analysis on\nWeibo comments.", "published": "2024-12-23 07:21:07", "link": "http://arxiv.org/abs/2412.17347v1", "categories": ["cs.CL", "cs.CE", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Diving into Self-Evolving Training for Multimodal Reasoning", "abstract": "Reasoning ability is essential for Large Multimodal Models (LMMs). In the\nabsence of multimodal chain-of-thought annotated data, self-evolving training,\nwhere the model learns from its own outputs, has emerged as an effective and\nscalable approach for enhancing reasoning abilities. Despite its growing usage,\na comprehensive understanding of self-evolving training, particularly in the\ncontext of multimodal reasoning, remains limited. In this paper, we delve into\nthe intricacies of self-evolving training for multimodal reasoning, pinpointing\nthree key factors: Training Method, Reward Model, and Prompt Variation. We\nsystematically examine each factor and explore how various configurations\naffect the training's effectiveness. Our analysis leads to a set of best\npractices for each factor, aimed at optimizing multimodal reasoning.\nFurthermore, we explore the Self-Evolution Dynamics during training and the\nimpact of automatic balancing mechanisms in boosting performance. After all the\ninvestigations, we present a final recipe for self-evolving training in\nmultimodal reasoning, encapsulating these design choices into a framework we\ncall MSTaR (Multimodal Self-evolving Training for Reasoning), which is\nuniversally effective for models with different sizes on various benchmarks,\ne.g., surpassing the pre-evolved model significantly on 5 multimodal reasoning\nbenchmarks without using additional human annotations, as demonstrated on\nMiniCPM-V-2.5 (8B), Phi-3.5-Vision (4B) and InternVL2 (2B). We believe this\nstudy fills a significant gap in the understanding of self-evolving training\nfor multimodal reasoning and offers a robust framework for future research. Our\npolicy and reward models, as well as the collected data, is released to\nfacilitate further investigation in multimodal reasoning.", "published": "2024-12-23 10:18:41", "link": "http://arxiv.org/abs/2412.17451v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CiteBART: Learning to Generate Citations for Local Citation\n  Recommendation", "abstract": "Local citation recommendation (LCR) suggests a set of papers for a citation\nplaceholder within a given context. The task has evolved as generative\napproaches have become more promising than the traditional pre-fetch and\nre-rank-based state-of-the-art approaches. This paper introduces\ncitation-specific pre-training within an encoder-decoder architecture, where\nauthor-date citation tokens are masked to learn to reconstruct them to fulfill\nLCR. There are two variants for this pre-training. In the local context-only\nbase scheme (CiteBART-Base), the citation token in a local context is masked to\nlearn to predict the citation. The global version (CiteBART-Global) extends the\nlocal context with the citing paper's title and abstract to enrich the learning\nsignal. CiteBART-Global achieves state-of-the-art performance on LCR benchmarks\nexcept for the FullTextPeerRead dataset, which is quite small to see the\nadvantage of generative pre-training. The effect is significant in the larger\nbenchmarks, e.g., Refseer and ArXiv., with the Refseer benchmark-trained model\nemerging as the best-performing model. We perform comprehensive experiments,\nincluding an ablation study, a qualitative analysis, and a taxonomy of\nhallucinations with detailed statistics. Our analyses confirm that\nCiteBART-Global has a cross-dataset generalization capability; the macro\nhallucination rate (MaHR) at the top-3 predictions is 4\\%, and when the\nground-truth is in the top-k prediction list, the hallucination tendency in the\nother predictions drops significantly.", "published": "2024-12-23 12:58:30", "link": "http://arxiv.org/abs/2412.17534v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "RepoTransBench: A Real-World Benchmark for Repository-Level Code\n  Translation", "abstract": "Repository-level code translation refers to translating an entire code\nrepository from one programming language to another while preserving the\nfunctionality of the source repository. Many benchmarks have been proposed to\nevaluate the performance of such code translators. However, previous benchmarks\nmostly provide fine-grained samples, focusing at either code snippet, function,\nor file-level code translation. Such benchmarks do not accurately reflect\nreal-world demands, where entire repositories often need to be translated,\ninvolving longer code length and more complex functionalities. To address this\ngap, we propose a new benchmark, named RepoTransBench, which is a real-world\nrepository-level code translation benchmark with an automatically executable\ntest suite. We conduct experiments on RepoTransBench to evaluate the\ntranslation performance of 11 advanced LLMs. We find that the Success@1 score\n(test success in one attempt) of the best-performing LLM is only 7.33%. To\nfurther explore the potential of LLMs for repository-level code translation, we\nprovide LLMs with error-related feedback to perform iterative debugging and\nobserve an average 7.09% improvement on Success@1. However, even with this\nimprovement, the Success@1 score of the best-performing LLM is only 21%, which\nmay not meet the need for reliable automatic repository-level code translation.\nFinally, we conduct a detailed error analysis and highlight current LLMs'\ndeficiencies in repository-level code translation, which could provide a\nreference for further improvements.", "published": "2024-12-23 17:52:10", "link": "http://arxiv.org/abs/2412.17744v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Deliberation in Latent Space via Differentiable Cache Augmentation", "abstract": "Techniques enabling large language models (LLMs) to \"think more\" by\ngenerating and attending to intermediate reasoning steps have shown promise in\nsolving complex problems. However, the standard approaches generate sequences\nof discrete tokens immediately before responding, and so they can incur\nsignificant latency costs and be challenging to optimize. In this work, we\ndemonstrate that a frozen LLM can be augmented with an offline coprocessor that\noperates on the model's key-value (kv) cache. This coprocessor augments the\ncache with a set of latent embeddings designed to improve the fidelity of\nsubsequent decoding. We train this coprocessor using the language modeling loss\nfrom the decoder on standard pretraining data, while keeping the decoder itself\nfrozen. This approach enables the model to learn, in an end-to-end\ndifferentiable fashion, how to distill additional computation into its\nkv-cache. Because the decoder remains unchanged, the coprocessor can operate\noffline and asynchronously, and the language model can function normally if the\ncoprocessor is unavailable or if a given cache is deemed not to require extra\ncomputation. We show experimentally that when a cache is augmented, the decoder\nachieves lower perplexity on numerous subsequent tokens. Furthermore, even\nwithout any task-specific training, our experiments demonstrate that cache\naugmentation consistently reduces perplexity and improves performance across a\nrange of reasoning-intensive tasks.", "published": "2024-12-23 18:02:25", "link": "http://arxiv.org/abs/2412.17747v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language\n  Models", "abstract": "Causal reasoning capabilities are essential for large language models (LLMs)\nin a wide range of applications, such as education and healthcare. But there is\nstill a lack of benchmarks for a better understanding of such capabilities.\nCurrent LLM benchmarks are mainly based on conversational tasks, academic math\ntests, and coding tests. Such benchmarks evaluate LLMs in well-regularized\nsettings, but they are limited in assessing the skills and abilities to solve\nreal-world problems. In this work, we provide a benchmark, named by CARL-GT,\nwhich evaluates CAusal Reasoning capabilities of large Language models using\nGraphs and Tabular data. The benchmark has a diverse range of tasks for\nevaluating LLMs from causal graph reasoning, knowledge discovery, and\ndecision-making aspects. In addition, effective zero-shot learning prompts are\ndeveloped for the tasks. In our experiments, we leverage the benchmark for\nevaluating open-source LLMs and provide a detailed comparison of LLMs for\ncausal reasoning abilities. We found that LLMs are still weak in casual\nreasoning, especially with tabular data to discover new insights. Furthermore,\nwe investigate and discuss the relationships of different benchmark tasks by\nanalyzing the performance of LLMs. The experimental results show that LLMs have\ndifferent strength over different tasks and that their performance on tasks in\ndifferent categories, i.e., causal graph reasoning, knowledge discovery, and\ndecision-making, shows stronger correlation than tasks in the same category.", "published": "2024-12-23 20:34:32", "link": "http://arxiv.org/abs/2412.17970v1", "categories": ["cs.CL", "cs.LG", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Theoretical Constraints on the Expressive Power of $\\mathsf{RoPE}$-based\n  Tensor Attention Transformers", "abstract": "Tensor Attention extends traditional attention mechanisms by capturing\nhigh-order correlations across multiple modalities, addressing the limitations\nof classical matrix-based attention. Meanwhile, Rotary Position Embedding\n($\\mathsf{RoPE}$) has shown superior performance in encoding positional\ninformation in long-context scenarios, significantly enhancing transformer\nmodels' expressiveness. Despite these empirical successes, the theoretical\nlimitations of these technologies remain underexplored. In this study, we\nanalyze the circuit complexity of Tensor Attention and $\\mathsf{RoPE}$-based\nTensor Attention, showing that with polynomial precision, constant-depth\nlayers, and linear or sublinear hidden dimension, they cannot solve fixed\nmembership problems or $(A_{F,r})^*$ closure problems, under the assumption\nthat $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$. These findings highlight a gap between\nthe empirical performance and theoretical constraints of Tensor Attention and\n$\\mathsf{RoPE}$-based Tensor Attention Transformers, offering insights that\ncould guide the development of more theoretically grounded approaches to\nTransformer model design and scaling.", "published": "2024-12-23 23:26:07", "link": "http://arxiv.org/abs/2412.18040v1", "categories": ["cs.LG", "cs.AI", "cs.CC", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Highly Optimized Kernels and Fine-Grained Codebooks for LLM Inference on\n  Arm CPUs", "abstract": "Large language models (LLMs) have transformed the way we think about language\nunderstanding and generation, enthralling both researchers and developers.\nHowever, deploying LLMs for inference has been a significant challenge due to\ntheir unprecedented size and resource requirements. While quantizing model\nweights to sub-byte precision has emerged as a promising solution to ease\nmemory pressure, the group quantization formats commonly used for LLM\nquantization have significant compute overheads and a resource-intensive\ndequantization process. As a result, a higher proportion of compute\ninstructions do not perform multiplies, i.e., real work, rendering them\nunsuitable for meeting the required latency requirements for LLMs deployed on\ncommodity CPUs. In this work, we propose a set of highly optimized kernels to\naccelerate LLM inference and unleash the full potential of CPUs, particularly\nArm CPUs. These kernels amortize the cost of loading the operands and the cost\nof weight unpacking across multiple output rows. This, along with the\nintroduction of an optimized interleaved group data layout for weights and\ndecompression path optimizations to reduce unnecessary operations and\ndequantization overhead while maximizing the use of vector and matrix multiply\noperations, significantly improves the efficiency of MAC operations.\nFurthermore, we present a groupwise non-uniform codebook-based quantization\nmethod for ultra-low-precision quantization of LLMs to better match non-uniform\npatterns in their weight distributions, demonstrating better throughput during\ntoken generation while ensuring better quality than the state-of-the-art.\nApplying these improvements to 4-bit LLMs results in a 3-3.2x improvement in\nprompt processing and a 2x improvement in autoregressive decoding on Arm CPUs,\ncompared to LLaMA.cpp-based solution. The optimized kernels are available at\nhttps://github.com/ggerganov/llama.cpp.", "published": "2024-12-23 03:44:29", "link": "http://arxiv.org/abs/2501.00032v1", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Emoji Retrieval from Gibberish or Garbled Social Media Text: A Novel\n  Methodology and A Case Study", "abstract": "Emojis are widely used across social media platforms but are often lost in\nnoisy or garbled text, posing challenges for data analysis and machine\nlearning. Conventional preprocessing approaches recommend removing such text,\nrisking the loss of emojis and their contextual meaning. This paper proposes a\nthree-step reverse-engineering methodology to retrieve emojis from garbled text\nin social media posts. The methodology also identifies reasons for the\ngeneration of such text during social media data mining. To evaluate its\neffectiveness, the approach was applied to 509,248 Tweets about the Mpox\noutbreak, a dataset referenced in about 30 prior works that failed to retrieve\nemojis from garbled text. Our method retrieved 157,748 emojis from 76,914\nTweets. Improvements in text readability and coherence were demonstrated\nthrough metrics such as Flesch Reading Ease, Flesch-Kincaid Grade Level,\nColeman-Liau Index, Automated Readability Index, Dale-Chall Readability Score,\nText Standard, and Reading Time. Additionally, the frequency of individual\nemojis and their patterns of usage in these Tweets were analyzed, and the\nresults are presented.", "published": "2024-12-23 23:44:13", "link": "http://arxiv.org/abs/2412.18046v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.CY", "cs.LG", "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"], "primary_category": "cs.SI"}
{"title": "A Multimodal Emotion Recognition System: Integrating Facial Expressions,\n  Body Movement, Speech, and Spoken Language", "abstract": "Traditional psychological evaluations rely heavily on human observation and\ninterpretation, which are prone to subjectivity, bias, fatigue, and\ninconsistency. To address these limitations, this work presents a multimodal\nemotion recognition system that provides a standardised, objective, and\ndata-driven tool to support evaluators, such as psychologists, psychiatrists,\nand clinicians. The system integrates recognition of facial expressions,\nspeech, spoken language, and body movement analysis to capture subtle emotional\ncues that are often overlooked in human evaluations. By combining these\nmodalities, the system provides more robust and comprehensive emotional state\nassessment, reducing the risk of mis- and overdiagnosis. Preliminary testing in\na simulated real-world condition demonstrates the system's potential to provide\nreliable emotional insights to improve the diagnostic accuracy. This work\nhighlights the promise of automated multimodal analysis as a valuable\ncomplement to traditional psychological evaluation practices, with applications\nin clinical and therapeutic settings.", "published": "2024-12-23 19:00:34", "link": "http://arxiv.org/abs/2412.17907v1", "categories": ["cs.HC", "cs.CL", "cs.CV", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Domain-Incremental Learning for Audio Classification", "abstract": "In this work, we propose a method for domain-incremental learning for audio\nclassification from a sequence of datasets recorded in different acoustic\nconditions. Fine-tuning a model on a sequence of evolving domains or datasets\nleads to forgetting of previously learned knowledge. On the other hand,\nfreezing all the layers of the model leads to the model not adapting to the new\ndomain. In this work, our novel dynamic network architecture keeps the shared\nhomogeneous acoustic characteristics of domains, and learns the domain-specific\nacoustic characteristics in incremental steps. Our approach achieves a good\nbalance between retaining the knowledge of previously learned domains and\nacquiring the knowledge of the new domain. We demonstrate the effectiveness of\nthe proposed method on incremental learning of single-label classification of\nacoustic scenes from European cities and Korea, and multi-label classification\nof audio recordings from Audioset and FSD50K datasets. The proposed approach\nlearns to classify acoustic scenes incrementally with an average accuracy of\n71.9% for the order: European cities -> Korea, and 83.4% for Korea -> European\ncities. In a multi-label audio classification setup, it achieves an average\nlwlrap of 47.5% for Audioset -> FSD50K and 40.7% for FSD50K -> Audioset.", "published": "2024-12-23 09:41:04", "link": "http://arxiv.org/abs/2412.17424v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "UME: Upcycling Mixture-of-Experts for Scalable and Efficient Automatic\n  Speech Recognition", "abstract": "Recent advancements in scaling up models have significantly improved\nperformance in Automatic Speech Recognition (ASR) tasks. However, training\nlarge ASR models from scratch remains costly. To address this issue, we\nintroduce UME, a novel method that efficiently Upcycles pretrained dense ASR\ncheckpoints into larger Mixture-of-Experts (MoE) architectures. Initially,\nfeed-forward networks are converted into MoE layers. By reusing the pretrained\nweights, we establish a robust foundation for the expanded model, significantly\nreducing optimization time. Then, layer freezing and expert balancing\nstrategies are employed to continue training the model, further enhancing\nperformance. Experiments on a mixture of 170k-hour Mandarin and English\ndatasets show that UME: 1) surpasses the pretrained baseline by a margin of\n11.9% relative error rate reduction while maintaining comparable latency; 2)\nreduces training time by up to 86.7% and achieves superior accuracy compared to\ntraining models of the same size from scratch.", "published": "2024-12-23 12:08:37", "link": "http://arxiv.org/abs/2412.17507v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Trainingless Adaptation of Pretrained Models for Environmental Sound\n  Classification", "abstract": "Deep neural network (DNN)-based models for environmental sound classification\nare not robust against a domain to which training data do not belong, that is,\nout-of-distribution or unseen data. To utilize pretrained models for the unseen\ndomain, adaptation methods, such as finetuning and transfer learning, are used\nwith rich computing resources, e.g., the graphical processing unit (GPU).\nHowever, it is becoming more difficult to keep up with research trends for\nthose who have poor computing resources because state-of-the-art models are\nbecoming computationally resource-intensive. In this paper, we propose a\ntrainingless adaptation method for pretrained models for environmental sound\nclassification. To introduce the trainingless adaptation method, we first\npropose an operation of recovering time--frequency-ish (TF-ish) structures in\nintermediate layers of DNN models. We then propose the trainingless frequency\nfiltering method for domain adaptation, which is not a gradient-based\noptimization widely used. The experiments conducted using the ESC-50 dataset\nshow that the proposed adaptation method improves the classification accuracy\nby 20.40 percentage points compared with the conventional method.", "published": "2024-12-23 01:50:28", "link": "http://arxiv.org/abs/2412.17212v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Investigating Prosodic Signatures via Speech Pre-Trained Models for\n  Audio Deepfake Source Attribution", "abstract": "In this work, we investigate various state-of-the-art (SOTA) speech\npre-trained models (PTMs) for their capability to capture prosodic signatures\nof the generative sources for audio deepfake source attribution (ADSD). These\nprosodic characteristics can be considered one of major signatures for ADSD,\nwhich is unique to each source. So better is the PTM at capturing prosodic\nsigns better the ADSD performance. We consider various SOTA PTMs that have\nshown top performance in different prosodic tasks for our experiments on\nbenchmark datasets, ASVSpoof 2019 and CFAD. x-vector (speaker recognition PTM)\nattains the highest performance in comparison to all the PTMs considered\ndespite consisting lowest model parameters. This higher performance can be due\nto its speaker recognition pre-training that enables it for capturing unique\nprosodic characteristics of the sources in a better way. Further, motivated\nfrom tasks such as audio deepfake detection and speech recognition, where\nfusion of PTMs representations lead to improved performance, we explore the\nsame and propose FINDER for effective fusion of such representations. With\nfusion of Whisper and x-vector representations through FINDER, we achieved the\ntopmost performance in comparison to all the individual PTMs as well as\nbaseline fusion techniques and attaining SOTA performance.", "published": "2024-12-23 18:53:15", "link": "http://arxiv.org/abs/2412.17796v1", "categories": ["eess.AS", "cs.SD", "68T45", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Are audio DeepFake detection models polyglots?", "abstract": "Since the majority of audio DeepFake (DF) detection methods are trained on\nEnglish-centric datasets, their applicability to non-English languages remains\nlargely unexplored. In this work, we present a benchmark for the multilingual\naudio DF detection challenge by evaluating various adaptation strategies. Our\nexperiments focus on analyzing models trained on English benchmark datasets, as\nwell as intra-linguistic (same-language) and cross-linguistic adaptation\napproaches. Our results indicate considerable variations in detection efficacy,\nhighlighting the difficulties of multilingual settings. We show that limiting\nthe dataset to English negatively impacts the efficacy, while stressing the\nimportance of the data in the target language.", "published": "2024-12-23 19:32:53", "link": "http://arxiv.org/abs/2412.17924v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multiple Consistency-guided Test-Time Adaptation for Contrastive\n  Audio-Language Models with Unlabeled Audio", "abstract": "One fascinating aspect of pre-trained Audio-Language Models (ALMs) learning\nis their impressive zero-shot generalization capability and test-time\nadaptation (TTA) methods aiming to improve domain performance without\nannotations. However, previous test time adaptation (TTA) methods for ALMs in\nzero-shot classification tend to be stuck in incorrect model predictions. In\norder to further boost the performance, we propose multiple guidance on prompt\nlearning without annotated labels. First, guidance of consistency on both\ncontext tokens and domain tokens of ALMs is set. Second, guidance of both\nconsistency across multiple augmented views of each single test sample and\ncontrastive learning across different test samples is set. Third, we propose a\ncorresponding end-end learning framework for the proposed test-time adaptation\nmethod without annotated labels. We extensively evaluate our approach on 12\ndownstream tasks across domains, our proposed adaptation method leads to 4.41%\n(max 7.50%) average zero-shot performance improvement in comparison with the\nstate-of-the-art models.", "published": "2024-12-23 05:53:52", "link": "http://arxiv.org/abs/2412.17306v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music", "abstract": "In this work, we introduce VERSA, a unified and standardized evaluation\ntoolkit designed for various speech, audio, and music signals. The toolkit\nfeatures a Pythonic interface with flexible configuration and dependency\ncontrol, making it user-friendly and efficient. With full installation, VERSA\noffers 65 metrics with 729 metric variations based on different configurations.\nThese metrics encompass evaluations utilizing diverse external resources,\nincluding matching and non-matching reference audio, text transcriptions, and\ntext captions. As a lightweight yet comprehensive toolkit, VERSA is versatile\nto support the evaluation of a wide range of downstream scenarios. To\ndemonstrate its capabilities, this work highlights example use cases for VERSA,\nincluding audio coding, speech synthesis, speech enhancement, singing\nsynthesis, and music generation. The toolkit is available at\nhttps://github.com/wavlab-speech/versa.", "published": "2024-12-23 15:53:21", "link": "http://arxiv.org/abs/2412.17667v2", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Investigation on the Potential of KAN in Speech Enhancement", "abstract": "High-fidelity speech enhancement often requires sophisticated modeling to\ncapture intricate, multiscale patterns. Standard activation functions, while\nintroducing nonlinearity, lack the flexibility to fully address this\ncomplexity. Kolmogorov-Arnold Networks (KAN), an emerging methodology that\nemploys learnable activation functions on graph edges, present a promising\nalternative. This work investigates two novel KAN variants based on rational\nand radial basis functions for speech enhancement. We integrate the rational\nvariant into the 1D CNN blocks of Demucs and the GRU-Transformer blocks of\nMP-SENet, while the radial variant is adapted to the 2D CNN-based decoders of\nMP-SENet. Experiments on the VoiceBank-DEMAND dataset show that replacing\nstandard activations with KAN-based activations improves speech quality across\nboth the time-domain and time-frequency domain methods with minimal impact on\nmodel size and FLOP, underscoring KAN's potential to improve speech enhancement\nmodels.", "published": "2024-12-23 18:38:32", "link": "http://arxiv.org/abs/2412.17778v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
