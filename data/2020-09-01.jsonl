{"title": "Extracting Semantic Concepts and Relations from Scientific Publications\n  by Using Deep Learning", "abstract": "With the large volume of unstructured data that increases constantly on the\nweb, the motivation of representing the knowledge in this data in the\nmachine-understandable form is increased. Ontology is one of the major\ncornerstones of representing the information in a more meaningful way on the\nsemantic Web. The current ontology repositories are quite limited either for\ntheir scope or for currentness. In addition, the current ontology extraction\nsystems have many shortcomings and drawbacks, such as using a small dataset,\ndepending on a large amount predefined patterns to extract semantic relations,\nand extracting a very few types of relations. The aim of this paper is to\nintroduce a proposal of automatically extracting semantic concepts and\nrelations from scientific publications. This paper suggests new types of\nsemantic relations and points out of using deep learning (DL) models for\nsemantic relation extraction.", "published": "2020-09-01 10:19:18", "link": "http://arxiv.org/abs/2009.00331v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Summary-Source Proposition-level Alignment: Task, Datasets and\n  Supervised Baseline", "abstract": "Aligning sentences in a reference summary with their counterparts in source\ndocuments was shown as a useful auxiliary summarization task, notably for\ngenerating training data for salience detection. Despite its assessed utility,\nthe alignment step was mostly approached with heuristic unsupervised methods,\ntypically ROUGE-based, and was never independently optimized or evaluated. In\nthis paper, we propose establishing summary-source alignment as an explicit\ntask, while introducing two major novelties: (1) applying it at the more\naccurate proposition span level, and (2) approaching it as a supervised\nclassification task. To that end, we created a novel training dataset for\nproposition-level alignment, derived automatically from available summarization\nevaluation data. In addition, we crowdsourced dev and test datasets, enabling\nmodel development and proper evaluation. Utilizing these data, we present a\nsupervised proposition alignment baseline model, showing improved\nalignment-quality over the unsupervised approach.", "published": "2020-09-01 17:27:12", "link": "http://arxiv.org/abs/2009.00590v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Assignment of Radiology Examination Protocols Using\n  Pre-trained Language Models with Knowledge Distillation", "abstract": "Selecting radiology examination protocol is a repetitive, and time-consuming\nprocess. In this paper, we present a deep learning approach to automatically\nassign protocols to computer tomography examinations, by pre-training a\ndomain-specific BERT model ($BERT_{rad}$). To handle the high data imbalance\nacross exam protocols, we used a knowledge distillation approach that\nup-sampled the minority classes through data augmentation. We compared\nclassification performance of the described approach with the statistical\nn-gram models using Support Vector Machine (SVM), Gradient Boosting Machine\n(GBM), and Random Forest (RF) classifiers, as well as the Google's\n$BERT_{base}$ model. SVM, GBM and RF achieved macro-averaged F1 scores of 0.45,\n0.45, and 0.6 while $BERT_{base}$ and $BERT_{rad}$ achieved 0.61 and 0.63.\nKnowledge distillation improved overall performance on the minority classes,\nachieving a F1 score of 0.66.", "published": "2020-09-01 20:57:41", "link": "http://arxiv.org/abs/2009.00694v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hearings and mishearings: decrypting the spoken word", "abstract": "We propose a model of the speech perception of individual words in the\npresence of mishearings. This phenomenological approach is based on concepts\nused in linguistics, and provides a formalism that is universal across\nlanguages. We put forward an efficient two-parameter form for the word length\ndistribution, and introduce a simple representation of mishearings, which we\nuse in our subsequent modelling of word recognition. In a context-free\nscenario, word recognition often occurs via anticipation when, part-way into a\nword, we can correctly guess its full form. We give a quantitative estimate of\nthis anticipation threshold when no mishearings occur, in terms of model\nparameters. As might be expected, the whole anticipation effect disappears when\nthere are sufficiently many mishearings. Our global approach to the problem of\nspeech perception is in the spirit of an optimisation problem. We show for\ninstance that speech perception is easy when the word length is less than a\nthreshold, to be identified with a static transition, and hard otherwise. We\nextend this to the dynamics of word recognition, proposing an intuitive\napproach highlighting the distinction between individual, isolated mishearings\nand clusters of contiguous mishearings. At least in some parameter range, a\ndynamical transition is manifest well before the static transition is reached,\nas is the case for many other examples of complex systems.", "published": "2020-09-01 13:58:51", "link": "http://arxiv.org/abs/2009.00429v1", "categories": ["cs.CL", "cond-mat.stat-mech"], "primary_category": "cs.CL"}
{"title": "Twitter Corpus of the #BlackLivesMatter Movement And Counter Protests:\n  2013 to 2021", "abstract": "Black Lives Matter (BLM) is a decentralized social movement protesting\nviolence against Black individuals and communities, with a focus on police\nbrutality. The movement gained significant attention following the killings of\nAhmaud Arbery, Breonna Taylor, and George Floyd in 2020. The #BlackLivesMatter\nsocial media hashtag has come to represent the grassroots movement, with\nsimilar hashtags counter protesting the BLM movement, such as #AllLivesMatter,\nand #BlueLivesMatter. We introduce a data set of 63.9 million tweets from 13.0\nmillion users from over 100 countries which contain one of the following\nkeywords: BlackLivesMatter, AllLivesMatter, and BlueLivesMatter. This data set\ncontains all currently available tweets from the beginning of the BLM movement\nin 2013 to 2021. We summarize the data set and show temporal trends in use of\nboth the BlackLivesMatter keyword and keywords associated with counter\nmovements. Additionally, for each keyword, we create and release a set of\nLatent Dirichlet Allocation (LDA) topics (i.e., automatically clustered groups\nof semantically co-occuring words) to aid researchers in identifying linguistic\npatterns across the three keywords.", "published": "2020-09-01 17:37:39", "link": "http://arxiv.org/abs/2009.00596v3", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Document Similarity from Vector Space Densities", "abstract": "We propose a computationally light method for estimating similarities between\ntext documents, which we call the density similarity (DS) method. The method is\nbased on a word embedding in a high-dimensional Euclidean space and on kernel\nregression, and takes into account semantic relations among words. We find that\nthe accuracy of this method is virtually the same as that of a state-of-the-art\nmethod, while the gain in speed is very substantial. Additionally, we introduce\ngeneralized versions of the top-k accuracy metric and of the Jaccard metric of\nagreement between similarity models.", "published": "2020-09-01 19:28:51", "link": "http://arxiv.org/abs/2009.00672v1", "categories": ["cs.CL", "cs.DS", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Text Modular Networks: Learning to Decompose Tasks in the Language of\n  Existing Models", "abstract": "We propose a general framework called Text Modular Networks(TMNs) for\nbuilding interpretable systems that learn to solve complex tasks by decomposing\nthem into simpler ones solvable by existing models. To ensure solvability of\nsimpler tasks, TMNs learn the textual input-output behavior (i.e., language) of\nexisting models through their datasets. This differs from prior\ndecomposition-based approaches which, besides being designed specifically for\neach complex task, produce decompositions independent of existing sub-models.\nSpecifically, we focus on Question Answering (QA) and show how to train a\nnext-question generator to sequentially produce sub-questions targeting\nappropriate sub-models, without additional human annotation. These\nsub-questions and answers provide a faithful natural language explanation of\nthe model's reasoning. We use this framework to build ModularQA, a system that\ncan answer multi-hop reasoning questions by decomposing them into sub-questions\nanswerable by a neural factoid single-span QA model and a symbolic calculator.\nOur experiments show that ModularQA is more versatile than existing explainable\nsystems for DROP and HotpotQA datasets, is more robust than state-of-the-art\nblackbox (uninterpretable) systems, and generates more understandable and\ntrustworthy explanations compared to prior work.", "published": "2020-09-01 23:45:42", "link": "http://arxiv.org/abs/2009.00751v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generalisation of Cyberbullying Detection", "abstract": "Cyberbullying is a problem in today's ubiquitous online communities.\nFiltering it out of online conversations has proven a challenge, and efforts\nhave led to the creation of many different datasets, all offered as resources\nto train classifiers. Through these datasets, we will explore the variety of\ndefinitions of cyberbullying behaviors and the impact of these differences on\nthe portability of one classifier to another community. By analyzing the\nsimilarities between datasets, we also gain insight on the generalization power\nof the classifiers trained from them. A study of ensemble models combining\nthese classifiers will help us understand how they interact with each other.", "published": "2020-09-01 14:57:17", "link": "http://arxiv.org/abs/2009.01046v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake\n  Claim Classification", "abstract": "The rampant integration of social media in our every day lives and culture\nhas given rise to fast and easier access to the flow of information than ever\nin human history. However, the inherently unsupervised nature of social media\nplatforms has also made it easier to spread false information and fake news.\nFurthermore, the high volume and velocity of information flow in such platforms\nmake manual supervision and control of information propagation infeasible. This\npaper aims to address this issue by proposing a novel deep learning approach\nfor automated detection of false short-text claims on social media. We first\nintroduce Sentimental LIAR, which extends the LIAR dataset of short claims by\nadding features based on sentiment and emotion analysis of claims. Furthermore,\nwe propose a novel deep learning architecture based on the BERT-Base language\nmodel for classification of claims as genuine or fake. Our results demonstrate\nthat the proposed architecture trained on Sentimental LIAR can achieve an\naccuracy of 70%, which is an improvement of ~30% over previously reported\nresults for the LIAR benchmark.", "published": "2020-09-01 02:48:11", "link": "http://arxiv.org/abs/2009.01047v2", "categories": ["cs.CL", "cs.LG", "cs.SI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "MALCOM: Generating Malicious Comments to Attack Neural Fake News\n  Detection Models", "abstract": "In recent years, the proliferation of so-called \"fake news\" has caused much\ndisruptions in society and weakened the news ecosystem. Therefore, to mitigate\nsuch problems, researchers have developed state-of-the-art models to\nauto-detect fake news on social media using sophisticated data science and\nmachine learning techniques. In this work, then, we ask \"what if adversaries\nattempt to attack such detection models?\" and investigate related issues by (i)\nproposing a novel threat model against fake news detectors, in which\nadversaries can post malicious comments toward news articles to mislead fake\nnews detectors, and (ii) developing MALCOM, an end-to-end adversarial comment\ngeneration framework to achieve such an attack. Through a comprehensive\nevaluation, we demonstrate that about 94% and 93.5% of the time on average\nMALCOM can successfully mislead five of the latest neural detection models to\nalways output targeted real and fake news labels. Furthermore, MALCOM can also\nfool black box fake news detectors to always output real news labels 90% of the\ntime on average. We also compare our attack model with four baselines across\ntwo real-world datasets, not only on attack performance but also on generated\nquality, coherency, transferability, and robustness.", "published": "2020-09-01 01:26:01", "link": "http://arxiv.org/abs/2009.01048v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Analysis of memory in LSTM-RNNs for source separation", "abstract": "Long short-term memory recurrent neural networks (LSTM-RNNs) are considered\nstate-of-the art in many speech processing tasks. The recurrence in the\nnetwork, in principle, allows any input to be remembered for an indefinite\ntime, a feature very useful for sequential data like speech. However, very\nlittle is known about which information is actually stored in the LSTM and for\nhow long. We address this problem by using a memory reset approach which allows\nus to evaluate network performance depending on the allowed memory time span.\nWe apply this approach to the task of multi-speaker source separation, but it\ncan be used for any task using RNNs. We find a strong performance effect of\nshort-term (shorter than 100 milliseconds) linguistic processes. Only speaker\ncharacteristics are kept in the memory for longer than 400 milliseconds.\nFurthermore, we confirm that performance-wise it is sufficient to implement\nlonger memory in deeper layers. Finally, in a bidirectional model, the backward\nmodels contributes slightly more to the separation performance than the forward\nmodel.", "published": "2020-09-01 16:31:32", "link": "http://arxiv.org/abs/2009.00551v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Neural Architecture Search For Keyword Spotting", "abstract": "Deep neural networks have recently become a popular solution to keyword\nspotting systems, which enable the control of smart devices via voice. In this\npaper, we apply neural architecture search to search for convolutional neural\nnetwork models that can help boost the performance of keyword spotting based on\nfeatures extracted from acoustic signals while maintaining an acceptable memory\nfootprint. Specifically, we use differentiable architecture search techniques\nto search for operators and their connections in a predefined cell search\nspace. The found cells are then scaled up in both depth and width to achieve\ncompetitive performance. We evaluated the proposed method on Google's Speech\nCommands Dataset and achieved a state-of-the-art accuracy of over 97% on the\nsetting of 12-class utterance classification commonly reported in the\nliterature.", "published": "2020-09-01 01:11:41", "link": "http://arxiv.org/abs/2009.00165v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
