{"title": "News Headline Grouping as a Challenging NLU Task", "abstract": "Recent progress in Natural Language Understanding (NLU) has seen the latest\nmodels outperform human performance on many standard tasks. These impressive\nresults have led the community to introspect on dataset limitations, and\niterate on more nuanced challenges. In this paper, we introduce the task of\nHeadLine Grouping (HLG) and a corresponding dataset (HLGD) consisting of 20,056\npairs of news headlines, each labeled with a binary judgement as to whether the\npair belongs within the same group. On HLGD, human annotators achieve high\nperformance of around 0.9 F-1, while current state-of-the art Transformer\nmodels only reach 0.75 F-1, opening the path for further improvements. We\nfurther propose a novel unsupervised Headline Generator Swap model for the task\nof HeadLine Grouping that achieves within 3 F-1 of the best supervised model.\nFinally, we analyze high-performing models with consistency tests, and find\nthat models are not consistent in their predictions, revealing modeling limits\nof current architectures.", "published": "2021-05-12 01:40:49", "link": "http://arxiv.org/abs/2105.05391v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Commonsense Knowledge Graph in Pretrained Models for\n  Social Commonsense Tasks", "abstract": "Pretrained language models have excelled at many NLP tasks recently; however,\ntheir social intelligence is still unsatisfactory. To enable this, machines\nneed to have a more general understanding of our complicated world and develop\nthe ability to perform commonsense reasoning besides fitting the specific\ndownstream tasks. External commonsense knowledge graphs (KGs), such as\nConceptNet, provide rich information about words and their relationships. Thus,\ntowards general commonsense learning, we propose two approaches to\n\\emph{implicitly} and \\emph{explicitly} infuse such KGs into pretrained\nlanguage models. We demonstrate our proposed methods perform well on SocialIQA,\na social commonsense reasoning task, in both limited and full training data\nregimes.", "published": "2021-05-12 06:45:26", "link": "http://arxiv.org/abs/2105.05457v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probabilistic modeling of rational communication with conditionals", "abstract": "While a large body of work has scrutinized the meaning of conditional\nsentences, considerably less attention has been paid to formal models of their\npragmatic use and interpretation. Here, we take a probabilistic approach to\npragmatic reasoning about indicative conditionals which flexibly integrates\ngradient beliefs about richly structured world states. We model listeners'\nupdate of their prior beliefs about the causal structure of the world and the\njoint probabilities of the consequent and antecedent based on assumptions about\nthe speaker's utterance production protocol. We show that, when supplied with\nnatural contextual assumptions, our model uniformly explains a number of\ninferences attested in the literature, including epistemic inferences,\nconditional perfection and the dependency between antecedent and consequent of\na conditional. We argue that this approach also helps explain three puzzles\nintroduced by Douven (2012) about updating with conditionals: depending on the\nutterance context, the listener's belief in the antecedent may increase,\ndecrease or remain unchanged.", "published": "2021-05-12 08:21:25", "link": "http://arxiv.org/abs/2105.05502v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OCHADAI-KYOTO at SemEval-2021 Task 1: Enhancing Model Generalization and\n  Robustness for Lexical Complexity Prediction", "abstract": "We propose an ensemble model for predicting the lexical complexity of words\nand multiword expressions (MWEs). The model receives as input a sentence with a\ntarget word or MWEand outputs its complexity score. Given that a key challenge\nwith this task is the limited size of annotated data, our model relies on\npretrained contextual representations from different state-of-the-art\ntransformer-based language models (i.e., BERT and RoBERTa), and on a variety of\ntraining methods for further enhancing model generalization and\nrobustness:multi-step fine-tuning and multi-task learning, and adversarial\ntraining. Additionally, we propose to enrich contextual representations by\nadding hand-crafted features during training. Our model achieved competitive\nresults and ranked among the top-10 systems in both sub-tasks.", "published": "2021-05-12 09:27:46", "link": "http://arxiv.org/abs/2105.05535v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "!Qu\u00e9 maravilla! Multimodal Sarcasm Detection in Spanish: a Dataset and\n  a Baseline", "abstract": "We construct the first ever multimodal sarcasm dataset for Spanish. The\naudiovisual dataset consists of sarcasm annotated text that is aligned with\nvideo and audio. The dataset represents two varieties of Spanish, a Latin\nAmerican variety and a Peninsular Spanish variety, which ensures a wider\ndialectal coverage for this global language. We present several models for\nsarcasm detection that will serve as baselines in the future research. Our\nresults show that results with text only (89%) are worse than when combining\ntext with audio (91.9%). Finally, the best results are obtained when combining\nall the modalities: text, audio and video (93.1%).", "published": "2021-05-12 09:43:11", "link": "http://arxiv.org/abs/2105.05542v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Supporting Land Reuse of Former Open Pit Mining Sites using Text\n  Classification and Active Learning", "abstract": "Open pit mines left many regions worldwide inhospitable or uninhabitable. To\nput these regions back into use, entire stretches of land must be\nrenaturalized. For the sustainable subsequent use or transfer to a new primary\nuse, many contaminated sites and soil information have to be permanently\nmanaged. In most cases, this information is available in the form of expert\nreports in unstructured data collections or file folders, which in the best\ncase are digitized. Due to size and complexity of the data, it is difficult for\na single person to have an overview of this data in order to be able to make\nreliable statements. This is one of the most important obstacles to the rapid\ntransfer of these areas to after-use. An information-based approach to this\nissue supports fulfilling several Sustainable Development Goals regarding\nenvironment issues, health and climate action. We use a stack of Optical\nCharacter Recognition, Text Classification, Active Learning and Geographic\nInformation System Visualization to effectively mine and visualize this\ninformation. Subsequently, we link the extracted information to geographic\ncoordinates and visualize them using a Geographic Information System. Active\nLearning plays a vital role because our dataset provides no training data. In\ntotal, we process nine categories and actively learn their representation in\nour dataset. We evaluate the OCR, Active Learning and Text Classification\nseparately to report the performance of the system. Active Learning and text\nclassification results are twofold: Whereas our categories about restrictions\nwork sufficient ($>$.85 F1), the seven topic-oriented categories were\ncomplicated for human coders and hence the results achieved mediocre evaluation\nscores ($<$.70 F1).", "published": "2021-05-12 10:18:14", "link": "http://arxiv.org/abs/2105.05557v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BertGCN: Transductive Text Classification by Combining GCN and BERT", "abstract": "In this work, we propose BertGCN, a model that combines large scale\npretraining and transductive learning for text classification. BertGCN\nconstructs a heterogeneous graph over the dataset and represents documents as\nnodes using BERT representations. By jointly training the BERT and GCN modules\nwithin BertGCN, the proposed model is able to leverage the advantages of both\nworlds: large-scale pretraining which takes the advantage of the massive amount\nof raw data and transductive learning which jointly learns representations for\nboth training data and unlabeled test data by propagating label influence\nthrough graph convolution. Experiments show that BertGCN achieves SOTA\nperformances on a wide range of text classification datasets. Code is available\nat https://github.com/ZeroRin/BertGCN.", "published": "2021-05-12 15:20:01", "link": "http://arxiv.org/abs/2105.05727v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Kleister: Key Information Extraction Datasets Involving Long Documents\n  with Complex Layouts", "abstract": "The relevance of the Key Information Extraction (KIE) task is increasingly\nimportant in natural language processing problems. But there are still only a\nfew well-defined problems that serve as benchmarks for solutions in this area.\nTo bridge this gap, we introduce two new datasets (Kleister NDA and Kleister\nCharity). They involve a mix of scanned and born-digital long formal\nEnglish-language documents. In these datasets, an NLP system is expected to\nfind or infer various types of entities by employing both textual and\nstructural layout features. The Kleister Charity dataset consists of 2,788\nannual financial reports of charity organizations, with 61,643 unique pages and\n21,612 entities to extract. The Kleister NDA dataset has 540 Non-disclosure\nAgreements, with 3,229 unique pages and 2,160 entities to extract. We provide\nseveral state-of-the-art baseline systems from the KIE domain (Flair, BERT,\nRoBERTa, LayoutLM, LAMBERT), which show that our datasets pose a strong\nchallenge to existing models. The best model achieved an 81.77% and an 83.57%\nF1-score on respectively the Kleister NDA and the Kleister Charity datasets. We\nshare the datasets to encourage progress on more in-depth and complex\ninformation extraction tasks.", "published": "2021-05-12 17:08:01", "link": "http://arxiv.org/abs/2105.05796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Black or White but never neutral: How readers perceive identity from\n  yellow or skin-toned emoji", "abstract": "Research in sociology and linguistics shows that people use language not only\nto express their own identity but to understand the identity of others. Recent\nwork established a connection between expression of identity and emoji usage on\nsocial media, through use of emoji skin tone modifiers. Motivated by that\nfinding, this work asks if, as with language, readers are sensitive to such\nacts of self-expression and use them to understand the identity of authors. In\nbehavioral experiments (n=488), where text and emoji content of social media\nposts were carefully controlled before being presented to participants, we find\nin the affirmative -- emoji are a salient signal of author identity. That\nsignal is distinct from, and complementary to, the one encoded in language.\nParticipant groups (based on self-identified ethnicity) showed no differences\nin how they perceive this signal, except in the case of the default yellow\nemoji. While both groups associate this with a White identity, the effect was\nstronger in White participants. Our finding that emoji can index social\nvariables will have experimental applications for researchers but also\nimplications for designers: supposedly ``neutral`` defaults may be more\nrepresentative of some users than others.", "published": "2021-05-12 18:23:51", "link": "http://arxiv.org/abs/2105.05887v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Go Beyond Plain Fine-tuning: Improving Pretrained Models for Social\n  Commonsense", "abstract": "Pretrained language models have demonstrated outstanding performance in many\nNLP tasks recently. However, their social intelligence, which requires\ncommonsense reasoning about the current situation and mental states of others,\nis still developing. Towards improving language models' social intelligence, we\nfocus on the Social IQA dataset, a task requiring social and emotional\ncommonsense reasoning. Building on top of the pretrained RoBERTa and GPT2\nmodels, we propose several architecture variations and extensions, as well as\nleveraging external commonsense corpora, to optimize the model for Social IQA.\nOur proposed system achieves competitive results as those top-ranking models on\nthe leaderboard. This work demonstrates the strengths of pretrained language\nmodels, and provides viable ways to improve their performance for a particular\ntask.", "published": "2021-05-12 19:18:02", "link": "http://arxiv.org/abs/2105.05913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Designing Multimodal Datasets for NLP Challenges", "abstract": "In this paper, we argue that the design and development of multimodal\ndatasets for natural language processing (NLP) challenges should be enhanced in\ntwo significant respects: to more broadly represent commonsense semantic\ninferences; and to better reflect the dynamics of actions and events, through a\nsubstantive alignment of textual and visual information. We identify challenges\nand tasks that are reflective of linguistic and cognitive competencies that\nhumans have when speaking and reasoning, rather than merely the performance of\nsystems on isolated tasks. We introduce the distinction between challenge-based\ntasks and competence-based performance, and describe a diagnostic dataset,\nRecipe-to-Video Questions (R2VQ), designed for testing competence-based\ncomprehension over a multimodal recipe collection (http://r2vq.org/). The\ncorpus contains detailed annotation supporting such inferencing tasks and\nfacilitating a rich set of question families that we use to evaluate NLP\nsystems.", "published": "2021-05-12 23:02:46", "link": "http://arxiv.org/abs/2105.05999v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's The Latest? A Question-driven News Chatbot", "abstract": "This work describes an automatic news chatbot that draws content from a\ndiverse set of news articles and creates conversations with a user about the\nnews. Key components of the system include the automatic organization of news\narticles into topical chatrooms, integration of automatically generated\nquestions into the conversation, and a novel method for choosing which\nquestions to present which avoids repetitive suggestions. We describe the\nalgorithmic framework and present the results of a usability study that shows\nthat news readers using the system successfully engage in multi-turn\nconversations about specific news stories.", "published": "2021-05-12 01:41:20", "link": "http://arxiv.org/abs/2105.05392v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Could you give me a hint? Generating inference graphs for defeasible\n  reasoning", "abstract": "Defeasible reasoning is the mode of reasoning where conclusions can be\noverturned by taking into account new evidence. A commonly used method in\ncognitive science and logic literature is to handcraft argumentation supporting\ninference graphs. While humans find inference graphs very useful for reasoning,\nconstructing them at scale is difficult. In this paper, we automatically\ngenerate such inference graphs through transfer learning from another NLP task\nthat shares the kind of reasoning that inference graphs support. Through\nautomated metrics and human evaluation, we find that our method generates\nmeaningful graphs for the defeasible inference task. Human accuracy on this\ntask improves by 20% by consulting the generated graphs. Our findings open up\nexciting new research avenues for cases where machine reasoning can help human\nreasoning. (A dataset of 230,000 influence graphs for each defeasible query is\nlocated at: https://tinyurl.com/defeasiblegraphs.)", "published": "2021-05-12 04:04:10", "link": "http://arxiv.org/abs/2105.05418v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UIUC_BioNLP at SemEval-2021 Task 11: A Cascade of Neural Models for\n  Structuring Scholarly NLP Contributions", "abstract": "We propose a cascade of neural models that performs sentence classification,\nphrase recognition, and triple extraction to automatically structure the\nscholarly contributions of NLP publications. To identify the most important\ncontribution sentences in a paper, we used a BERT-based classifier with\npositional features (Subtask 1). A BERT-CRF model was used to recognize and\ncharacterize relevant phrases in contribution sentences (Subtask 2). We\ncategorized the triples into several types based on whether and how their\nelements were expressed in text, and addressed each type using separate\nBERT-based classifiers as well as rules (Subtask 3). Our system was officially\nranked second in Phase 1 evaluation and first in both parts of Phase 2\nevaluation. After fixing a submission error in Pharse 1, our approach yields\nthe best results overall. In this paper, in addition to a system description,\nwe also provide further analysis of our results, highlighting its strengths and\nlimitations. We make our code publicly available at\nhttps://github.com/Liu-Hy/nlp-contrib-graph.", "published": "2021-05-12 05:24:35", "link": "http://arxiv.org/abs/2105.05435v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Evaluating Gender Bias in Natural Language Inference", "abstract": "Gender-bias stereotypes have recently raised significant ethical concerns in\nnatural language processing. However, progress in detection and evaluation of\ngender bias in natural language understanding through inference is limited and\nrequires further investigation. In this work, we propose an evaluation\nmethodology to measure these biases by constructing a challenge task that\ninvolves pairing gender-neutral premises against a gender-specific hypothesis.\nWe use our challenge task to investigate state-of-the-art NLI models on the\npresence of gender stereotypes using occupations. Our findings suggest that\nthree models (BERT, RoBERTa, BART) trained on MNLI and SNLI datasets are\nsignificantly prone to gender-induced prediction errors. We also find that\ndebiasing techniques such as augmenting the training dataset to ensure a\ngender-balanced dataset can help reduce such bias in certain cases.", "published": "2021-05-12 09:41:51", "link": "http://arxiv.org/abs/2105.05541v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "OutFlip: Generating Out-of-Domain Samples for Unknown Intent Detection\n  with Natural Language Attack", "abstract": "Out-of-domain (OOD) input detection is vital in a task-oriented dialogue\nsystem since the acceptance of unsupported inputs could lead to an incorrect\nresponse of the system. This paper proposes OutFlip, a method to generate\nout-of-domain samples using only in-domain training dataset automatically. A\nwhite-box natural language attack method HotFlip is revised to generate\nout-of-domain samples instead of adversarial examples. Our evaluation results\nshowed that integrating OutFlip-generated out-of-domain samples into the\ntraining dataset could significantly improve an intent classification model's\nout-of-domain detection performance.", "published": "2021-05-12 11:38:34", "link": "http://arxiv.org/abs/2105.05601v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Priberam Labs at the NTCIR-15 SHINRA2020-ML: Classification Task", "abstract": "Wikipedia is an online encyclopedia available in 285 languages. It composes\nan extremely relevant Knowledge Base (KB), which could be leveraged by\nautomatic systems for several purposes. However, the structure and organisation\nof such information are not prone to automatic parsing and understanding and it\nis, therefore, necessary to structure this knowledge. The goal of the current\nSHINRA2020-ML task is to leverage Wikipedia pages in order to categorise their\ncorresponding entities across 268 hierarchical categories, belonging to the\nExtended Named Entity (ENE) ontology. In this work, we propose three distinct\nmodels based on the contextualised embeddings yielded by Multilingual BERT. We\nexplore the performances of a linear layer with and without explicit usage of\nthe ontology's hierarchy, and a Gated Recurrent Units (GRU) layer. We also test\nseveral pooling strategies to leverage BERT's embeddings and selection criteria\nbased on the labels' scores. We were able to achieve good performance across a\nlarge variety of languages, including those not seen during the fine-tuning\nprocess (zero-shot languages).", "published": "2021-05-12 11:49:19", "link": "http://arxiv.org/abs/2105.05605v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Priberam at MESINESP Multi-label Classification of Medical Texts Task", "abstract": "Medical articles provide current state of the art treatments and diagnostics\nto many medical practitioners and professionals. Existing public databases such\nas MEDLINE contain over 27 million articles, making it difficult to extract\nrelevant content without the use of efficient search engines. Information\nretrieval tools are crucial in order to navigate and provide meaningful\nrecommendations for articles and treatments. Classifying these articles into\nbroader medical topics can improve the retrieval of related articles. The set\nof medical labels considered for the MESINESP task is on the order of several\nthousands of labels (DeCS codes), which falls under the extreme multi-label\nclassification problem. The heterogeneous and highly hierarchical structure of\nmedical topics makes the task of manually classifying articles extremely\nlaborious and costly. It is, therefore, crucial to automate the process of\nclassification. Typical machine learning algorithms become computationally\ndemanding with such a large number of labels and achieving better recall on\nsuch datasets becomes an unsolved problem.\n  This work presents Priberam's participation at the BioASQ task Mesinesp. We\naddress the large multi-label classification problem through the use of four\ndifferent models: a Support Vector Machine (SVM), a customised search engine\n(Priberam Search), a BERT based classifier, and a SVM-rank ensemble of all the\nprevious models. Results demonstrate that all three individual models perform\nwell and the best performance is achieved by their ensemble, granting Priberam\nthe 6th place in the present challenge and making it the 2nd best team.", "published": "2021-05-12 12:14:16", "link": "http://arxiv.org/abs/2105.05614v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLP for Climate Policy: Creating a Knowledge Platform for Holistic and\n  Effective Climate Action", "abstract": "Climate change is a burning issue of our time, with the Sustainable\nDevelopment Goal (SDG) 13 of the United Nations demanding global climate\naction. Realizing the urgency, in 2015 in Paris, world leaders signed an\nagreement committing to taking voluntary action to reduce carbon emissions.\nHowever, the scale, magnitude, and climate action processes vary globally,\nespecially between developed and developing countries. Therefore, from\nparliament to social media, the debates and discussions on climate change\ngather data from wide-ranging sources essential to the policy design and\nimplementation. The downside is that we do not currently have the mechanisms to\npool the worldwide dispersed knowledge emerging from the structured and\nunstructured data sources.\n  The paper thematically discusses how NLP techniques could be employed in\nclimate policy research and contribute to society's good at large. In\nparticular, we exemplify symbiosis of NLP and Climate Policy Research via four\nmethodologies. The first one deals with the major topics related to climate\npolicy using automated content analysis. We investigate the opinions\n(sentiments) of major actors' narratives towards climate policy in the second\nmethodology. The third technique explores the climate actors' beliefs towards\npro or anti-climate orientation. Finally, we discuss developing a Climate\nKnowledge Graph.\n  The present theme paper further argues that creating a knowledge platform\nwould help in the formulation of a holistic climate policy and effective\nclimate action. Such a knowledge platform would integrate the policy actors'\nvaried opinions from different social sectors like government, business, civil\nsociety, and the scientific community. The research outcome will add value to\neffective climate action because policymakers can make informed decisions by\nlooking at the diverse public opinion on a comprehensive platform.", "published": "2021-05-12 12:30:02", "link": "http://arxiv.org/abs/2105.05621v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Reliable are Model Diagnostics?", "abstract": "In the pursuit of a deeper understanding of a model's behaviour, there is\nrecent impetus for developing suites of probes aimed at diagnosing models\nbeyond simple metrics like accuracy or BLEU. This paper takes a step back and\nasks an important and timely question: how reliable are these diagnostics in\nproviding insight into models and training setups? We critically examine three\nrecent diagnostic tests for pre-trained language models, and find that\nlikelihood-based and representation-based model diagnostics are not yet as\nreliable as previously assumed. Based on our empirical findings, we also\nformulate recommendations for practitioners and researchers.", "published": "2021-05-12 13:20:20", "link": "http://arxiv.org/abs/2105.05641v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Encoding Explanatory Knowledge for Zero-shot Science Question Answering", "abstract": "This paper describes N-XKT (Neural encoding based on eXplanatory Knowledge\nTransfer), a novel method for the automatic transfer of explanatory knowledge\nthrough neural encoding mechanisms. We demonstrate that N-XKT is able to\nimprove accuracy and generalization on science Question Answering (QA).\nSpecifically, by leveraging facts from background explanatory knowledge\ncorpora, the N-XKT model shows a clear improvement on zero-shot QA.\nFurthermore, we show that N-XKT can be fine-tuned on a target QA dataset,\nenabling faster convergence and more accurate results. A systematic analysis is\nconducted to quantitatively analyze the performance of the N-XKT model and the\nimpact of different categories of knowledge on the zero-shot generalization\ntask.", "published": "2021-05-12 15:42:50", "link": "http://arxiv.org/abs/2105.05737v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Building a Question and Answer System for News Domain", "abstract": "This project attempts to build a Question- Answering system in the News\nDomain, where Passages will be News articles, and anyone can ask a Question\nagainst it. We have built a span-based model using an Attention mechanism,\nwhere the model predicts the answer to a question as to the position of the\nstart and end tokens in a paragraph. For training our model, we have used the\nStanford Question and Answer (SQuAD 2.0) dataset[1]. To do well on SQuAD 2.0,\nsystems must not only answer questions when possible but also determine when no\nanswer is supported by the paragraph and abstain from answering. Our model\narchitecture comprises three layers- Embedding Layer, RNN Layer, and the\nAttention Layer. For the Embedding layer, we used GloVe and the Universal\nSentence Encoder. For the RNN Layer, we built variations of the RNN Layer\nincluding bi-LSTM and Stacked LSTM and we built an Attention Layer using a\nContext to Question Attention and also improvised on the innovative\nBidirectional Attention Layer. Our best performing model which uses GloVe\nEmbedding combined with Bi-LSTM and Context to Question Attention achieved an\nF1 Score and EM of 33.095 and 33.094 respectively. We also leveraged transfer\nlearning and built a Transformer based model using BERT. The BERT-based model\nachieved an F1 Score and EM of 57.513 and 49.769 respectively. We concluded\nthat the BERT model is superior in all aspects of answering various types of\nquestions.", "published": "2021-05-12 15:56:21", "link": "http://arxiv.org/abs/2105.05744v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MATE-KD: Masked Adversarial TExt, a Companion to Knowledge Distillation", "abstract": "The advent of large pre-trained language models has given rise to rapid\nprogress in the field of Natural Language Processing (NLP). While the\nperformance of these models on standard benchmarks has scaled with size,\ncompression techniques such as knowledge distillation have been key in making\nthem practical. We present, MATE-KD, a novel text-based adversarial training\nalgorithm which improves the performance of knowledge distillation. MATE-KD\nfirst trains a masked language model based generator to perturb text by\nmaximizing the divergence between teacher and student logits. Then using\nknowledge distillation a student is trained on both the original and the\nperturbed training samples. We evaluate our algorithm, using BERT-based models,\non the GLUE benchmark and demonstrate that MATE-KD outperforms competitive\nadversarial learning and data augmentation baselines. On the GLUE test set our\n6 layer RoBERTa based model outperforms BERT-Large.", "published": "2021-05-12 19:11:34", "link": "http://arxiv.org/abs/2105.05912v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Better than BERT but Worse than Baseline", "abstract": "This paper compares BERT-SQuAD and Ab3P on the Abbreviation Definition\nIdentification (ADI) task. ADI inputs a text and outputs short forms\n(abbreviations/acronyms) and long forms (expansions). BERT with reranking\nimproves over BERT without reranking but fails to reach the Ab3P rule-based\nbaseline. What is BERT missing? Reranking introduces two new features:\ncharmatch and freq. The first feature identifies opportunities to take\nadvantage of character constraints in acronyms and the second feature\nidentifies opportunities to take advantage of frequency constraints across\ndocuments.", "published": "2021-05-12 19:18:26", "link": "http://arxiv.org/abs/2105.05915v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analysing The Impact Of Linguistic Features On Cross-Lingual Transfer", "abstract": "There is an increasing amount of evidence that in cases with little or no\ndata in a target language, training on a different language can yield\nsurprisingly good results. However, currently there are no established\nguidelines for choosing the training (source) language. In attempt to solve\nthis issue we thoroughly analyze a state-of-the-art multilingual model and try\nto determine what impacts good transfer between languages. As opposed to the\nmajority of multilingual NLP literature, we don't only train on English, but on\na group of almost 30 languages. We show that looking at particular syntactic\nfeatures is 2-4 times more helpful in predicting the performance than an\naggregated syntactic similarity. We find out that the importance of syntactic\nfeatures strongly differs depending on the downstream task - no single feature\nis a good performance predictor for all NLP tasks. As a result, one should not\nexpect that for a target language $L_1$ there is a single language $L_2$ that\nis the best choice for any NLP task (for instance, for Bulgarian, the best\nsource language is French on POS tagging, Russian on NER and Thai on NLI). We\ndiscuss the most important linguistic features affecting the transfer quality\nusing statistical and machine learning methods.", "published": "2021-05-12 21:22:58", "link": "http://arxiv.org/abs/2105.05975v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Lexically Constrained Neural Machine Translation with\n  Source-Conditioned Masked Span Prediction", "abstract": "Accurate terminology translation is crucial for ensuring the practicality and\nreliability of neural machine translation (NMT) systems. To address this,\nlexically constrained NMT explores various methods to ensure pre-specified\nwords and phrases appear in the translation output. However, in many cases,\nthose methods are studied on general domain corpora, where the terms are mostly\nuni- and bi-grams (>98%). In this paper, we instead tackle a more challenging\nsetup consisting of domain-specific corpora with much longer n-gram and highly\nspecialized terms. Inspired by the recent success of masked span prediction\nmodels, we propose a simple and effective training strategy that achieves\nconsistent improvements on both terminology and sentence-level translation for\nthree domain-specific corpora in two language pairs.", "published": "2021-05-12 08:11:33", "link": "http://arxiv.org/abs/2105.05498v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"Alexa, what do you do for fun?\" Characterizing playful requests with\n  virtual assistants", "abstract": "Virtual assistants such as Amazon's Alexa, Apple's Siri, Google Home, and\nMicrosoft's Cortana, are becoming ubiquitous in our daily lives and\nsuccessfully help users in various daily tasks, such as making phone calls or\nplaying music. Yet, they still struggle with playful utterances, which are not\nmeant to be interpreted literally. Examples include jokes or absurd requests or\nquestions such as, \"Are you afraid of the dark?\", \"Who let the dogs out?\", or\n\"Order a zillion gummy bears\". Today, virtual assistants often return\nirrelevant answers to such utterances, except for hard-coded ones addressed by\ncanned replies.\n  To address the challenge of automatically detecting playful utterances, we\nfirst characterize the different types of playful human-virtual assistant\ninteraction. We introduce a taxonomy of playful requests rooted in theories of\nhumor and refined by analyzing real-world traffic from Alexa. We then focus on\none node, personification, where users refer to the virtual assistant as a\nperson (\"What do you do for fun?\"). Our conjecture is that understanding such\nutterances will improve user experience with virtual assistants. We conducted a\nWizard-of-Oz user study and showed that endowing virtual assistant s with the\nability to identify humorous opportunities indeed has the potential to increase\nuser satisfaction. We hope this work will contribute to the understanding of\nthe landscape of the problem and inspire novel ideas and techniques towards the\nvision of giving virtual assistants a sense of humor.", "published": "2021-05-12 10:48:00", "link": "http://arxiv.org/abs/2105.05571v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.HC"}
{"title": "Discrete representations in neural models of spoken language", "abstract": "The distributed and continuous representations used by neural networks are at\nodds with representations employed in linguistics, which are typically\nsymbolic. Vector quantization has been proposed as a way to induce discrete\nneural representations that are closer in nature to their linguistic\ncounterparts. However, it is not clear which metrics are the best-suited to\nanalyze such discrete representations. We compare the merits of four commonly\nused metrics in the context of weakly supervised models of spoken language. We\ncompare the results they show when applied to two different models, while\nsystematically studying the effect of the placement and size of the\ndiscretization layer. We find that different evaluation regimes can give\ninconsistent results. While we can attribute them to the properties of the\ndifferent metrics in most cases, one point of concern remains: the use of\nminimal pairs of phoneme triples as stimuli disadvantages larger discrete unit\ninventories, unlike metrics applied to complete utterances. Furthermore, while\nin general vector quantization induces representations that correlate with\nunits posited in linguistics, the strength of this correlation is only\nmoderate.", "published": "2021-05-12 11:02:02", "link": "http://arxiv.org/abs/2105.05582v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and\n  Semantic Embedding", "abstract": "Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent\nentities, relations, and others) between two KGs. The existing methods can be\ndivided into the embedding-based models, and the conventional reasoning and\nlexical matching based systems. The former compute the similarity of entities\nvia their cross-KG embeddings, but they usually rely on an ideal supervised\nlearning setting for good performance and lack appropriate reasoning to avoid\nlogically wrong mappings; while the latter address the reasoning issue but are\npoor at utilizing the KG graph structures and the entity contexts. In this\nstudy, we aim at combining the above two solutions and thus propose an\niterative framework named PRASE which is based on probabilistic reasoning and\nsemantic embedding. It learns the KG embeddings via entity mappings from a\nprobabilistic reasoning system named PARIS, and feeds the resultant entity\nmappings and embeddings back into PARIS for augmentation. The PRASE framework\nis compatible with different embedding-based models, and our experiments on\nmultiple datasets have demonstrated its state-of-the-art performance.", "published": "2021-05-12 11:27:46", "link": "http://arxiv.org/abs/2105.05596v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Conversational Negation using Worldly Context in Compositional\n  Distributional Semantics", "abstract": "We propose a framework to model an operational conversational negation by\napplying worldly context (prior knowledge) to logical negation in compositional\ndistributional semantics. Given a word, our framework can create its negation\nthat is similar to how humans perceive negation. The framework corrects logical\nnegation to weight meanings closer in the entailment hierarchy more than\nmeanings further apart. The proposed framework is flexible to accommodate\ndifferent choices of logical negations, compositions, and worldly context\ngeneration. In particular, we propose and motivate a new logical negation using\nmatrix inverse.\n  We validate the sensibility of our conversational negation framework by\nperforming experiments, leveraging density matrices to encode graded entailment\ninformation. We conclude that the combination of subtraction negation and\nphaser in the basis of the negated word yields the highest Pearson correlation\nof 0.635 with human ratings.", "published": "2021-05-12 16:04:36", "link": "http://arxiv.org/abs/2105.05748v1", "categories": ["cs.CL", "math.CT", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Stacked Acoustic-and-Textual Encoding: Integrating the Pre-trained\n  Models into Speech Translation Encoders", "abstract": "Encoder pre-training is promising in end-to-end Speech Translation (ST),\ngiven the fact that speech-to-translation data is scarce. But ST encoders are\nnot simple instances of Automatic Speech Recognition (ASR) or Machine\nTranslation (MT) encoders. For example, we find that ASR encoders lack the\nglobal context representation, which is necessary for translation, whereas MT\nencoders are not designed to deal with long but locally attentive acoustic\nsequences. In this work, we propose a Stacked Acoustic-and-Textual Encoding\n(SATE) method for speech translation. Our encoder begins with processing the\nacoustic sequence as usual, but later behaves more like an MT encoder for a\nglobal representation of the input sequence. In this way, it is straightforward\nto incorporate the pre-trained models into the system. Also, we develop an\nadaptor module to alleviate the representation inconsistency between the\npre-trained ASR encoder and MT encoder, and develop a multi-teacher knowledge\ndistillation method to preserve the pre-training knowledge. Experimental\nresults on the LibriSpeech En-Fr and MuST-C En-De ST tasks show that our method\nachieves state-of-the-art BLEU scores of 18.3 and 25.2. To our knowledge, we\nare the first to develop an end-to-end ST system that achieves comparable or\neven better BLEU performance than the cascaded ST counterpart when large-scale\nASR and MT data is available.", "published": "2021-05-12 16:09:53", "link": "http://arxiv.org/abs/2105.05752v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Forecasting election results by studying brand importance in online news", "abstract": "This study uses the semantic brand score, a novel measure of brand importance\nin big textual data, to forecast elections based on online news. About 35,000\nonline news articles were transformed into networks of co-occurring words and\nanalyzed by combining methods and tools from social network analysis and text\nmining. Forecasts made for four voting events in Italy provided consistent\nresults across different voting systems: a general election, a referendum, and\na municipal election in two rounds. This work contributes to the research on\nelectoral forecasting by focusing on predictions based on online big data; it\noffers new perspectives regarding the textual analysis of online news through a\nmethodology which is relatively fast and easy to apply. This study also\nsuggests the existence of a link between the brand importance of political\ncandidates and parties and electoral results.", "published": "2021-05-12 16:30:33", "link": "http://arxiv.org/abs/2105.05762v1", "categories": ["cs.SI", "cs.CL", "physics.soc-ph", "H.0; J.4; I.2.7"], "primary_category": "cs.SI"}
{"title": "The Semantic Brand Score", "abstract": "The Semantic Brand Score (SBS) is a new measure of brand importance\ncalculated on text data, combining methods of social network and semantic\nanalysis. This metric is flexible as it can be used in different contexts and\nacross products, markets and languages. It is applicable not only to brands,\nbut also to multiple sets of words. The SBS, described together with its three\ndimensions of brand prevalence, diversity and connectivity, represents a\ncontribution to the research on brand equity and on word co-occurrence\nnetworks. It can be used to support decision-making processes within companies;\nfor example, it can be applied to forecast a company's stock price or to assess\nbrand importance with respect to competitors. On the one side, the SBS relates\nto familiar constructs of brand equity, on the other, it offers new\nperspectives for effective strategic management of brands in the era of big\ndata.", "published": "2021-05-12 16:54:57", "link": "http://arxiv.org/abs/2105.05781v1", "categories": ["cs.CL", "cs.SI", "physics.soc-ph", "I.2.7; H.0; J.4"], "primary_category": "cs.CL"}
{"title": "The Greedy and Recursive Search for Morphological Productivity", "abstract": "As children acquire the knowledge of their language's morphology, they\ninvariably discover the productive processes that can generalize to new words.\nMorphological learning is made challenging by the fact that even fully\nproductive rules have exceptions, as in the well-known case of English past\ntense verbs, which features the -ed rule against the irregular verbs. The\nTolerance Principle is a recent proposal that provides a precise threshold of\nexceptions that a productive rule can withstand. Its empirical application so\nfar, however, requires the researcher to fully specify rules defined over a set\nof words. We propose a greedy search model that automatically hypothesizes\nrules and evaluates their productivity over a vocabulary. When the search for\nbroader productivity fails, the model recursively subdivides the vocabulary and\ncontinues the search for productivity over narrower rules. Trained on\npsychologically realistic data from child-directed input, our model displays\ndevelopmental patterns observed in child morphology acquisition, including the\nnotoriously complex case of German noun pluralization. It also produces\nresponses to nonce words that, despite receiving only a fraction of the\ntraining data, are more similar to those of human subjects than current neural\nnetwork models' responses are.", "published": "2021-05-12 17:02:32", "link": "http://arxiv.org/abs/2105.05790v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Playing Codenames with Language Graphs and Word Embeddings", "abstract": "Although board games and video games have been studied for decades in\nartificial intelligence research, challenging word games remain relatively\nunexplored. Word games are not as constrained as games like chess or poker.\nInstead, word game strategy is defined by the players' understanding of the way\nwords relate to each other. The word game Codenames provides a unique\nopportunity to investigate common sense understanding of relationships between\nwords, an important open challenge. We propose an algorithm that can generate\nCodenames clues from the language graph BabelNet or from any of several\nembedding methods - word2vec, GloVe, fastText or BERT. We introduce a new\nscoring function that measures the quality of clues, and we propose a weighting\nterm called DETECT that incorporates dictionary-based word representations and\ndocument frequency to improve clue selection. We develop BabelNet-Word\nSelection Framework (BabelNet-WSF) to improve BabelNet clue quality and\novercome the computational barriers that previously prevented leveraging\nlanguage graphs for Codenames. Extensive experiments with human evaluators\ndemonstrate that our proposed innovations yield state-of-the-art performance,\nwith up to 102.8% improvement in precision@2 in some cases. Overall, this work\nadvances the formal study of word games and approaches for common sense\nlanguage understanding.", "published": "2021-05-12 18:23:03", "link": "http://arxiv.org/abs/2105.05885v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Spelling Correction with Denoising Transformer", "abstract": "We present a novel method of performing spelling correction on short input\nstrings, such as search queries or individual words. At its core lies a\nprocedure for generating artificial typos which closely follow the error\npatterns manifested by humans. This procedure is used to train the production\nspelling correction model based on a transformer architecture. This model is\ncurrently served in the HubSpot product search. We show that our approach to\ntypo generation is superior to the widespread practice of adding noise, which\nignores human patterns. We also demonstrate how our approach may be extended to\nresource-scarce settings and train spelling correction models for Arabic,\nGreek, Russian, and Setswana languages, without using any labeled data.", "published": "2021-05-12 21:35:18", "link": "http://arxiv.org/abs/2105.05977v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual Offensive Language Identification for Low-resource\n  Languages", "abstract": "Offensive content is pervasive in social media and a reason for concern to\ncompanies and government organizations. Several studies have been recently\npublished investigating methods to detect the various forms of such content\n(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of\nthese studies deal with English partially because most annotated datasets\navailable contain English data. In this paper, we take advantage of available\nEnglish datasets by applying cross-lingual contextual word embeddings and\ntransfer learning to make predictions in low-resource languages. We project\npredictions on comparable data in Arabic, Bengali, Danish, Greek, Hindi,\nSpanish, and Turkish. We report results of 0.8415 F1 macro for Bengali in\nTRAC-2 shared task, 0.8532 F1 macro for Danish and 0.8701 F1 macro for Greek in\nOffensEval 2020, 0.8568 F1 macro for Hindi in HASOC 2019 shared task and 0.7513\nF1 macro for Spanish in in SemEval-2019 Task 5 (HatEval) showing that our\napproach compares favourably to the best systems submitted to recent shared\ntasks on these three languages. Additionally, we report competitive performance\non Arabic, and Turkish using the training and development sets of OffensEval\n2020 shared task. The results for all languages confirm the robustness of\ncross-lingual contextual embeddings and transfer learning for this task.", "published": "2021-05-12 22:50:16", "link": "http://arxiv.org/abs/2105.05996v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Conscious AI", "abstract": "Recent advances in artificial intelligence (AI) have achieved human-scale\nspeed and accuracy for classification tasks. In turn, these capabilities have\nmade AI a viable replacement for many human activities that at their core\ninvolve classification, such as basic mechanical and analytical tasks in\nlow-level service jobs. Current systems do not need to be conscious to\nrecognize patterns and classify them. However, for AI to progress to more\ncomplicated tasks requiring intuition and empathy, it must develop capabilities\nsuch as metathinking, creativity, and empathy akin to human self-awareness or\nconsciousness. We contend that such a paradigm shift is possible only through a\nfundamental shift in the state of artificial intelligence toward consciousness,\na shift similar to what took place for humans through the process of natural\nselection and evolution. As such, this paper aims to theoretically explore the\nrequirements for the emergence of consciousness in AI. It also provides a\nprincipled understanding of how conscious AI can be detected and how it might\nbe manifested in contrast to the dominant paradigm that seeks to ultimately\ncreate machines that are linguistically indistinguishable from humans.", "published": "2021-05-12 15:53:44", "link": "http://arxiv.org/abs/2105.07879v2", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Ensemble Making Few-Shot Learning Stronger", "abstract": "Few-shot learning has been proposed and rapidly emerging as a viable means\nfor completing various tasks. Many few-shot models have been widely used for\nrelation learning tasks. However, each of these models has a shortage of\ncapturing a certain aspect of semantic features, for example, CNN on long-range\ndependencies part, Transformer on local features. It is difficult for a single\nmodel to adapt to various relation learning, which results in the high variance\nproblem. Ensemble strategy could be competitive on improving the accuracy of\nfew-shot relation extraction and mitigating high variance risks. This paper\nexplores an ensemble approach to reduce the variance and introduces fine-tuning\nand feature attention strategies to calibrate relation-level features. Results\non several few-shot relation learning tasks show that our model significantly\noutperforms the previous state-of-the-art models.", "published": "2021-05-12 17:11:10", "link": "http://arxiv.org/abs/2105.11904v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Statistical Model for Melody Reduction", "abstract": "A commonly-cited reason for the poor performance of automatic chord\nestimation (ACE) systems within music information retrieval (MIR) is that\nnon-chord tones (i.e., notes outside the supporting harmony) contribute to\nerror during the labeling process. Despite the prevalence of machine learning\napproaches in MIR, there are cases where alternative approaches provide a\nsimpler alternative while allowing for insights into musicological practices.\nIn this project, we present a statistical model for predicting chord tones\nbased on music theory rules. Our model is currently focused on predicting chord\ntones in classical music, since composition in this style is highly\nconstrained, theoretically making the placement of chord tones highly\npredictable. Indeed, music theorists have labeling systems for every variety of\nnon-chord tone, primarily classified by the note's metric position and\nintervals of approach and departure. Using metric position, duration, and\nmelodic intervals as predictors, we build a statistical model for predicting\nchord tones using the TAVERN dataset. While our probabilistic approach is\nsimilar to other efforts in the domain of automatic harmonic analysis, our\nfocus is on melodic reduction rather than predicting harmony. However, we hope\nto pursue applications for ACE in the future. Finally, we implement our melody\nreduction model using an existing symbolic visualization tool, to assist with\nmelody reduction and non-chord tone identification for computational musicology\nresearchers and music theorists.", "published": "2021-05-12 01:10:35", "link": "http://arxiv.org/abs/2105.05385v1", "categories": ["cs.SD", "cs.IR", "eess.AS", "stat.AP"], "primary_category": "cs.SD"}
{"title": "StutterNet: Stuttering Detection Using Time Delay Neural Network", "abstract": "This paper introduces StutterNet, a novel deep learning based stuttering\ndetection capable of detecting and identifying various types of disfluencies.\nMost of the existing work in this domain uses automatic speech recognition\n(ASR) combined with language models for stuttering detection. Compared to the\nexisting work, which depends on the ASR module, our method relies solely on the\nacoustic signal. We use a time-delay neural network (TDNN) suitable for\ncapturing contextual aspects of the disfluent utterances. We evaluate our\nsystem on the UCLASS stuttering dataset consisting of more than 100 speakers.\nOur method achieves promising results and outperforms the state-of-the-art\nresidual neural network based method. The number of trainable parameters of the\nproposed method is also substantially less due to the parameter sharing scheme\nof TDNN.", "published": "2021-05-12 11:36:01", "link": "http://arxiv.org/abs/2105.05599v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Global Structure-Aware Drum Transcription Based on Self-Attention\n  Mechanisms", "abstract": "This paper describes an automatic drum transcription (ADT) method that\ndirectly estimates a tatum-level drum score from a music signal, in contrast to\nmost conventional ADT methods that estimate the frame-level onset probabilities\nof drums. To estimate a tatum-level score, we propose a deep transcription\nmodel that consists of a frame-level encoder for extracting the latent features\nfrom a music signal and a tatum-level decoder for estimating a drum score from\nthe latent features pooled at the tatum level. To capture the global repetitive\nstructure of drum scores, which is difficult to learn with a recurrent neural\nnetwork (RNN), we introduce a self-attention mechanism with tatum-synchronous\npositional encoding into the decoder. To mitigate the difficulty of training\nthe self-attention-based model from an insufficient amount of paired data and\nimprove the musical naturalness of the estimated scores, we propose a\nregularized training method that uses a global structure-aware masked language\n(score) model with a self-attention mechanism pretrained from an extensive\ncollection of drum scores. Experimental results showed that the proposed\nregularized model outperformed the conventional RNN-based model in terms of the\ntatum-level error rate and the frame-level F-measure, even when only a limited\namount of paired data was available so that the non-regularized model\nunderperformed the RNN-based model.", "published": "2021-05-12 17:04:16", "link": "http://arxiv.org/abs/2105.05791v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Attention-based Neural Beamforming Layers for Multi-channel Speech\n  Recognition", "abstract": "Attention-based beamformers have recently been shown to be effective for\nmulti-channel speech recognition. However, they are less capable at capturing\nlocal information. In this work, we propose a 2D Conv-Attention module which\ncombines convolution neural networks with attention for beamforming. We apply\nself- and cross-attention to explicitly model the correlations within and\nbetween the input channels. The end-to-end 2D Conv-Attention model is compared\nwith a multi-head self-attention and superdirective-based neural beamformers.\nWe train and evaluate on an in-house multi-channel dataset. The results show a\nrelative improvement of 3.8% in WER by the proposed model over the baseline\nneural beamformer.", "published": "2021-05-12 19:32:24", "link": "http://arxiv.org/abs/2105.05920v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
