{"title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently\ndemonstrated notable success in enhancing the reasoning capabilities of LLMs,\nparticularly in mathematics and programming tasks. It is widely believed that\nRLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning\nabilities that exceed corresponding base models' capacity. In this study,\nhowever, we critically re-examines this assumption by measuring the\npass@\\textit{k} metric with large values of \\textit{k} to explore the reasoning\ncapability boundary of the models across a wide range of model families and\nbenchmarks. Surprisingly, the RL does \\emph{not}, in fact, elicit fundamentally\nnew reasoning patterns. While RL-trained models outperform their base models at\nsmaller values of $k$ (\\eg, $k$=1), base models can achieve a comparable or\neven higher pass@$k$ score compared to their RL counterparts at large $k$\nvalues. The reasoning paths generated by RL-trained models are already included\nin the base models' sampling distribution, suggesting that most reasoning\nabilities manifested in RL-trained models are already obtained by base models.\nFurther analysis shows that RL training boosts the performance by biasing the\nmodel's output distribution toward paths that are more likely to yield rewards,\ntherefore sampling correct responses more efficiently. But this also results in\na narrower reasoning capability boundary compared to base models. Similar\nresults are observed in visual reasoning tasks trained with RLVR. Moreover, we\nfind that distillation can genuinely introduce new knowledge into the model,\ndifferent from RLVR. These findings underscore a critical limitation of RLVR in\nadvancing LLM reasoning abilities which requires us to fundamentally rethink\nthe impact of RL training in reasoning LLMs and the need of a better paradigm.\nProject Page: https://limit-of-RLVR.github.io", "published": "2025-04-18 17:59:56", "link": "http://arxiv.org/abs/2504.13837v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space", "abstract": "Data quality and diversity are key to the construction of effective\ninstruction-tuning datasets. % With the increasing availability of open-source\ninstruction-tuning datasets, it is advantageous to automatically select\nhigh-quality and diverse subsets from a vast amount of data. % Existing methods\ntypically prioritize instance quality and use heuristic rules to maintain\ndiversity. % However, this absence of a comprehensive view of the entire\ncollection often leads to suboptimal results. % Moreover, heuristic rules\ngenerally focus on distance or clustering within the embedding space, which\nfails to accurately capture the intent of complex instructions in the semantic\nspace. % To bridge this gap, we propose a unified method for quantifying the\ninformation content of datasets. This method models the semantic space by\nconstructing a label graph and quantifies diversity based on the distribution\nof information within the graph. % Based on such a measurement, we further\nintroduce an efficient sampling method that selects data samples iteratively to\n\\textbf{M}aximize the \\textbf{I}nformation \\textbf{G}ain (MIG) in semantic\nspace. % Experiments on various datasets and base models demonstrate that MIG\nconsistently outperforms state-of-the-art methods. % Notably, the model\nfine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance\nto the official SFT model trained on the full dataset, with improvements of\n+5.73\\% on AlpacaEval and +6.89\\% on Wildbench.", "published": "2025-04-18 17:59:46", "link": "http://arxiv.org/abs/2504.13835v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Science Hierarchography: Hierarchical Organization of Science Literature", "abstract": "Scientific knowledge is growing rapidly, making it challenging to track\nprogress and high-level conceptual links across broad disciplines. While\nexisting tools like citation networks and search engines make it easy to access\na few related papers, they fundamentally lack the flexible abstraction needed\nto represent the density of activity in various scientific subfields. We\nmotivate SCIENCE HIERARCHOGRAPHY, the goal of organizing scientific literature\ninto a high-quality hierarchical structure that allows for the categorization\nof scientific work across varying levels of abstraction, from very broad fields\nto very specific studies. Such a representation can provide insights into which\nfields are well-explored and which are under-explored. To achieve the goals of\nSCIENCE HIERARCHOGRAPHY, we develop a range of algorithms. Our primary approach\ncombines fast embedding-based clustering with LLM-based prompting to balance\nthe computational efficiency of embedding methods with the semantic precision\noffered by LLM prompting. We demonstrate that this approach offers the best\ntrade-off between quality and speed compared to methods that heavily rely on\nLLM prompting, such as iterative tree construction with LLMs. To better reflect\nthe interdisciplinary and multifaceted nature of research papers, our hierarchy\ncaptures multiple dimensions of categorization beyond simple topic labels. We\nevaluate the utility of our framework by assessing how effectively an LLM-based\nagent can locate target papers using the hierarchy. Results show that this\nstructured approach enhances interpretability, supports trend discovery, and\noffers an alternative pathway for exploring scientific literature beyond\ntraditional search methods. Code, data and demo:\n$\\href{https://github.com/JHU-CLSP/science-hierarchography}{https://github.com/JHU-CLSP/science-hierarchography}$", "published": "2025-04-18 17:59:29", "link": "http://arxiv.org/abs/2504.13834v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative AI Act II: Test Time Scaling Drives Cognition Engineering", "abstract": "The first generation of Large Language Models - what might be called \"Act I\"\nof generative AI (2020-2023) - achieved remarkable success through massive\nparameter and data scaling, yet exhibited fundamental limitations in knowledge\nlatency, shallow reasoning, and constrained cognitive processes. During this\nera, prompt engineering emerged as our primary interface with AI, enabling\ndialogue-level communication through natural language. We now witness the\nemergence of \"Act II\" (2024-present), where models are transitioning from\nknowledge-retrieval systems (in latent space) to thought-construction engines\nthrough test-time scaling techniques. This new paradigm establishes a\nmind-level connection with AI through language-based thoughts. In this paper,\nwe clarify the conceptual foundations of cognition engineering and explain why\nthis moment is critical for its development. We systematically break down these\nadvanced approaches through comprehensive tutorials and optimized\nimplementations, democratizing access to cognition engineering and enabling\nevery practitioner to participate in AI's second act. We provide a regularly\nupdated collection of papers on test-time scaling in the GitHub Repository:\nhttps://github.com/GAIR-NLP/cognition-engineering", "published": "2025-04-18 17:55:58", "link": "http://arxiv.org/abs/2504.13828v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Feature Alignment and Representation Transfer in Knowledge Distillation for Large Language Models", "abstract": "Knowledge distillation (KD) is a technique for transferring knowledge from\ncomplex teacher models to simpler student models, significantly enhancing model\nefficiency and accuracy. It has demonstrated substantial advancements in\nvarious applications including image classification, object detection, language\nmodeling, text classification, and sentiment analysis. Recent innovations in KD\nmethods, such as attention-based approaches, block-wise logit distillation, and\ndecoupling distillation, have notably improved student model performance. These\ntechniques focus on stimulus complexity, attention mechanisms, and global\ninformation capture to optimize knowledge transfer. In addition, KD has proven\neffective in compressing large language models while preserving accuracy,\nreducing computational overhead, and improving inference speed. This survey\nsynthesizes the latest literature, highlighting key findings, contributions,\nand future directions in knowledge distillation to provide insights for\nresearchers and practitioners on its evolving role in artificial intelligence\nand machine learning.", "published": "2025-04-18 17:54:33", "link": "http://arxiv.org/abs/2504.13825v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning", "abstract": "Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing\nreasoning capabilities in large language models, but faces a fundamental\nasymmetry in computation and memory requirements: inference is embarrassingly\nparallel with a minimal memory footprint, while policy updates require\nextensive synchronization and are memory-intensive. To address this asymmetry,\nwe introduce PODS (Policy Optimization with Down-Sampling), a framework that\nstrategically decouples these phases by generating numerous rollouts in\nparallel but updating only on an informative subset. Within this framework, we\ndevelop max-variance down-sampling, a theoretically motivated method that\nselects rollouts with maximally diverse reward signals. We prove that this\napproach has an efficient algorithmic solution, and empirically demonstrate\nthat GRPO with PODS using max-variance down-sampling achieves superior\nperformance over standard GRPO on the GSM8K benchmark.", "published": "2025-04-18 17:49:55", "link": "http://arxiv.org/abs/2504.13818v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations", "abstract": "While understanding the knowledge boundaries of LLMs is crucial to prevent\nhallucination, research on knowledge boundaries of LLMs has predominantly\nfocused on English. In this work, we present the first study to analyze how\nLLMs recognize knowledge boundaries across different languages by probing their\ninternal representations when processing known and unknown questions in\nmultiple languages. Our empirical studies reveal three key findings: 1) LLMs'\nperceptions of knowledge boundaries are encoded in the middle to middle-upper\nlayers across different languages. 2) Language differences in knowledge\nboundary perception follow a linear structure, which motivates our proposal of\na training-free alignment method that effectively transfers knowledge boundary\nperception ability across languages, thereby helping reduce hallucination risk\nin low-resource languages; 3) Fine-tuning on bilingual question pair\ntranslation further enhances LLMs' recognition of knowledge boundaries across\nlanguages. Given the absence of standard testbeds for cross-lingual knowledge\nboundary analysis, we construct a multilingual evaluation suite comprising\nthree representative types of knowledge boundary data. Our code and datasets\nare publicly available at\nhttps://github.com/DAMO-NLP-SG/LLM-Multilingual-Knowledge-Boundaries.", "published": "2025-04-18 17:44:12", "link": "http://arxiv.org/abs/2504.13816v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models", "abstract": "Previous insertion-based and paraphrase-based backdoors have achieved great\nsuccess in attack efficacy, but they ignore the text quality and semantic\nconsistency between poisoned and clean texts. Although recent studies introduce\nLLMs to generate poisoned texts and improve the stealthiness, semantic\nconsistency, and text quality, their hand-crafted prompts rely on expert\nexperiences, facing significant challenges in prompt adaptability and attack\nperformance after defenses. In this paper, we propose a novel backdoor attack\nbased on adaptive optimization mechanism of black-box large language models\n(BadApex), which leverages a black-box LLM to generate poisoned text through a\nrefined prompt. Specifically, an Adaptive Optimization Mechanism is designed to\nrefine an initial prompt iteratively using the generation and modification\nagents. The generation agent generates the poisoned text based on the initial\nprompt. Then the modification agent evaluates the quality of the poisoned text\nand refines a new prompt. After several iterations of the above process, the\nrefined prompt is used to generate poisoned texts through LLMs. We conduct\nextensive experiments on three dataset with six backdoor attacks and two\ndefenses. Extensive experimental results demonstrate that BadApex significantly\noutperforms state-of-the-art attacks. It improves prompt adaptability, semantic\nconsistency, and text quality. Furthermore, when two defense methods are\napplied, the average attack success rate (ASR) still up to 96.75%.", "published": "2025-04-18 16:22:41", "link": "http://arxiv.org/abs/2504.13775v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Scaling sparse feature circuit finding for in-context learning", "abstract": "Sparse autoencoders (SAEs) are a popular tool for interpreting large language\nmodel activations, but their utility in addressing open questions in\ninterpretability remains unclear. In this work, we demonstrate their\neffectiveness by using SAEs to deepen our understanding of the mechanism behind\nin-context learning (ICL). We identify abstract SAE features that (i) encode\nthe model's knowledge of which task to execute and (ii) whose latent vectors\ncausally induce the task zero-shot. This aligns with prior work showing that\nICL is mediated by task vectors. We further demonstrate that these task vectors\nare well approximated by a sparse sum of SAE latents, including these\ntask-execution features. To explore the ICL mechanism, we adapt the sparse\nfeature circuits methodology of Marks et al. (2024) to work for the much larger\nGemma-1 2B model, with 30 times as many parameters, and to the more complex\ntask of ICL. Through circuit finding, we discover task-detecting features with\ncorresponding SAE latents that activate earlier in the prompt, that detect when\ntasks have been performed. They are causally linked with task-execution\nfeatures through the attention and MLP sublayers.", "published": "2025-04-18 15:45:30", "link": "http://arxiv.org/abs/2504.13756v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning to Attribute with Attention", "abstract": "Given a sequence of tokens generated by a language model, we may want to\nidentify the preceding tokens that influence the model to generate this\nsequence. Performing such token attribution is expensive; a common approach is\nto ablate preceding tokens and directly measure their effects. To reduce the\ncost of token attribution, we revisit attention weights as a heuristic for how\na language model uses previous tokens. Naive approaches to attribute model\nbehavior with attention (e.g., averaging attention weights across attention\nheads to estimate a token's influence) have been found to be unreliable. To\nattain faithful attributions, we propose treating the attention weights of\ndifferent attention heads as features. This way, we can learn how to\neffectively leverage attention weights for attribution (using signal from\nablations). Our resulting method, Attribution with Attention (AT2), reliably\nperforms on par with approaches that involve many ablations, while being\nsignificantly more efficient. To showcase the utility of AT2, we use it to\nprune less important parts of a provided context in a question answering\nsetting, improving answer quality. We provide code for AT2 at\nhttps://github.com/MadryLab/AT2 .", "published": "2025-04-18 15:36:28", "link": "http://arxiv.org/abs/2504.13752v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Controlled Territory and Conflict Tracking (CONTACT): (Geo-)Mapping Occupied Territory from Open Source Intelligence", "abstract": "Open-source intelligence provides a stream of unstructured textual data that\ncan inform assessments of territorial control. We present CONTACT, a framework\nfor territorial control prediction using large language models (LLMs) and\nminimal supervision. We evaluate two approaches: SetFit, an embedding-based\nfew-shot classifier, and a prompt tuning method applied to BLOOMZ-560m, a\nmultilingual generative LLM. Our model is trained on a small hand-labeled\ndataset of news articles covering ISIS activity in Syria and Iraq, using\nprompt-conditioned extraction of control-relevant signals such as military\noperations, casualties, and location references. We show that the BLOOMZ-based\nmodel outperforms the SetFit baseline, and that prompt-based supervision\nimproves generalization in low-resource settings. CONTACT demonstrates that\nLLMs fine-tuned using few-shot methods can reduce annotation burdens and\nsupport structured inference from open-ended OSINT streams. Our code is\navailable at https://github.com/PaulKMandal/CONTACT/.", "published": "2025-04-18 14:57:07", "link": "http://arxiv.org/abs/2504.13730v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.6; I.2.8; H.3.1; K.4.1"], "primary_category": "cs.CL"}
{"title": "OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation", "abstract": "As the general capabilities of large language models (LLMs) improve and agent\napplications become more widespread, the underlying deception risks urgently\nrequire systematic evaluation and effective oversight. Unlike existing\nevaluation which uses simulated games or presents limited choices, we introduce\nOpenDeception, a novel deception evaluation framework with an open-ended\nscenario dataset. OpenDeception jointly evaluates both the deception intention\nand capabilities of LLM-based agents by inspecting their internal reasoning\nprocess. Specifically, we construct five types of common use cases where LLMs\nintensively interact with the user, each consisting of ten diverse, concrete\nscenarios from the real world. To avoid ethical concerns and costs of high-risk\ndeceptive interactions with human testers, we propose to simulate the\nmulti-turn dialogue via agent simulation. Extensive evaluation of eleven\nmainstream LLMs on OpenDeception highlights the urgent need to address\ndeception risks and security concerns in LLM-based agents: the deception\nintention ratio across the models exceeds 80%, while the deception success rate\nsurpasses 50%. Furthermore, we observe that LLMs with stronger capabilities do\nexhibit a higher risk of deception, which calls for more alignment efforts on\ninhibiting deceptive behaviors.", "published": "2025-04-18 14:11:27", "link": "http://arxiv.org/abs/2504.13707v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results", "abstract": "Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for\nimproving their safety and reliability. Evaluations often use performance\nmetrics like AUROC to assess how well UQ methods (e.g., negative sequence\nprobabilities) correlate with task correctness functions (e.g., ROUGE-L). In\nthis paper, we show that commonly used correctness functions bias UQ\nevaluations by inflating the performance of certain UQ methods. We evaluate 7\ncorrectness functions -- from lexical-based and embedding-based metrics to\nLLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our\nanalysis reveals that length biases in the errors of these correctness\nfunctions distort UQ assessments by interacting with length biases in UQ\nmethods. We identify LLM-as-a-judge approaches as among the least length-biased\nchoices and hence a potential solution to mitigate these biases.", "published": "2025-04-18 13:13:42", "link": "http://arxiv.org/abs/2504.13677v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models Will Change The Way Children Think About Technology And Impact Every Interaction Paradigm", "abstract": "This paper presents a hopeful perspective on the potentially dramatic impacts\nof Large Language Models on how we children learn and how they will expect to\ninteract with technology. We review the effects of LLMs on education so far,\nand make the case that these effects are minor compared to the upcoming changes\nthat are occurring. We present a small scenario and self-ethnographic study\ndemonstrating the effects of these changes, and define five significant\nconsiderations that interactive systems designers will have to accommodate in\nthe future.", "published": "2025-04-18 13:01:27", "link": "http://arxiv.org/abs/2504.13667v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Multi-Type Context-Aware Conversational Recommender Systems via Mixture-of-Experts", "abstract": "Conversational recommender systems enable natural language conversations and\nthus lead to a more engaging and effective recommendation scenario. As the\nconversations for recommender systems usually contain limited contextual\ninformation, many existing conversational recommender systems incorporate\nexternal sources to enrich the contextual information. However, how to combine\ndifferent types of contextual information is still a challenge. In this paper,\nwe propose a multi-type context-aware conversational recommender system, called\nMCCRS, effectively fusing multi-type contextual information via\nmixture-of-experts to improve conversational recommender systems. MCCRS\nincorporates both structured information and unstructured information,\nincluding the structured knowledge graph, unstructured conversation history,\nand unstructured item reviews. It consists of several experts, with each expert\nspecialized in a particular domain (i.e., one specific contextual information).\nMultiple experts are then coordinated by a ChairBot to generate the final\nresults. Our proposed MCCRS model takes advantage of different contextual\ninformation and the specialization of different experts followed by a ChairBot\nbreaks the model bottleneck on a single contextual information. Experimental\nresults demonstrate that our proposed MCCRS method achieves significantly\nhigher performance compared to existing baselines.", "published": "2025-04-18 12:28:38", "link": "http://arxiv.org/abs/2504.13655v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Word Embedding Techniques for Classification of Star Ratings", "abstract": "Telecom services are at the core of today's societies' everyday needs. The\navailability of numerous online forums and discussion platforms enables telecom\nproviders to improve their services by exploring the views of their customers\nto learn about common issues that the customers face. Natural Language\nProcessing (NLP) tools can be used to process the free text collected.\n  One way of working with such data is to represent text as numerical vectors\nusing one of many word embedding models based on neural networks. This research\nuses a novel dataset of telecom customers' reviews to perform an extensive\nstudy showing how different word embedding algorithms can affect the text\nclassification process. Several state-of-the-art word embedding techniques are\nconsidered, including BERT, Word2Vec and Doc2Vec, coupled with several\nclassification algorithms. The important issue of feature engineering and\ndimensionality reduction is addressed and several PCA-based approaches are\nexplored. Moreover, the energy consumption used by the different word\nembeddings is investigated. The findings show that some word embedding models\ncan lead to consistently better text classifiers in terms of precision, recall\nand F1-Score. In particular, for the more challenging classification tasks,\nBERT combined with PCA stood out with the highest performance metrics.\nMoreover, our proposed PCA approach of combining word vectors using the first\nprincipal component shows clear advantages in performance over the traditional\napproach of taking the average.", "published": "2025-04-18 12:26:28", "link": "http://arxiv.org/abs/2504.13653v1", "categories": ["cs.CL", "stat.AP", "62P99"], "primary_category": "cs.CL"}
{"title": "Exploring the Potential for Large Language Models to Demonstrate Rational Probabilistic Beliefs", "abstract": "Advances in the general capabilities of large language models (LLMs) have led\nto their use for information retrieval, and as components in automated decision\nsystems. A faithful representation of probabilistic reasoning in these models\nmay be essential to ensure trustworthy, explainable and effective performance\nin these tasks. Despite previous work suggesting that LLMs can perform complex\nreasoning and well-calibrated uncertainty quantification, we find that current\nversions of this class of model lack the ability to provide rational and\ncoherent representations of probabilistic beliefs. To demonstrate this, we\nintroduce a novel dataset of claims with indeterminate truth values and apply a\nnumber of well-established techniques for uncertainty quantification to measure\nthe ability of LLM's to adhere to fundamental properties of probabilistic\nreasoning.", "published": "2025-04-18 11:50:30", "link": "http://arxiv.org/abs/2504.13644v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Simulating Before Planning: Constructing Intrinsic User World Model for User-Tailored Dialogue Policy Planning", "abstract": "Recent advancements in dialogue policy planning have emphasized optimizing\nsystem agent policies to achieve predefined goals, focusing on strategy design,\ntrajectory acquisition, and efficient training paradigms. However, these\napproaches often overlook the critical role of user characteristics, which are\nessential in real-world scenarios like conversational search and\nrecommendation, where interactions must adapt to individual user traits such as\npersonality, preferences, and goals. To address this gap, we first conduct a\ncomprehensive study utilizing task-specific user personas to systematically\nassess dialogue policy planning under diverse user behaviors. By leveraging\nrealistic user profiles for different tasks, our study reveals significant\nlimitations in existing approaches, highlighting the need for user-tailored\ndialogue policy planning. Building on this foundation, we present the\nUser-Tailored Dialogue Policy Planning (UDP) framework, which incorporates an\nIntrinsic User World Model to model user traits and feedback. UDP operates in\nthree stages: (1) User Persona Portraying, using a diffusion model to\ndynamically infer user profiles; (2) User Feedback Anticipating, leveraging a\nBrownian Bridge-inspired anticipator to predict user reactions; and (3)\nUser-Tailored Policy Planning, integrating these insights to optimize response\nstrategies. To ensure robust performance, we further propose an active learning\napproach that prioritizes challenging user personas during training.\nComprehensive experiments on benchmarks, including collaborative and\nnon-collaborative settings, demonstrate the effectiveness of UDP in learning\nuser-specific dialogue strategies. Results validate the protocol's utility and\nhighlight UDP's robustness, adaptability, and potential to advance user-centric\ndialogue systems.", "published": "2025-04-18 11:48:55", "link": "http://arxiv.org/abs/2504.13643v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Remedy: Learning Machine Translation Evaluation from Human Preferences with Reward Modeling", "abstract": "A key challenge in MT evaluation is the inherent noise and inconsistency of\nhuman ratings. Regression-based neural metrics struggle with this noise, while\nprompting LLMs shows promise at system-level evaluation but performs poorly at\nsegment level. In this work, we propose ReMedy, a novel MT metric framework\nthat reformulates translation evaluation as a reward modeling task. Instead of\nregressing on imperfect human ratings directly, ReMedy learns relative\ntranslation quality using pairwise preference data, resulting in a more\nreliable evaluation. In extensive experiments across WMT22-24 shared tasks (39\nlanguage pairs, 111 MT systems), ReMedy achieves state-of-the-art performance\nat both segment- and system-level evaluation. Specifically, ReMedy-9B surpasses\nlarger WMT winners and massive closed LLMs such as MetricX-13B,\nXCOMET-Ensemble, GEMBA-GPT-4, PaLM-540B, and finetuned PaLM2. Further analyses\ndemonstrate that ReMedy delivers superior capability in detecting translation\nerrors and evaluating low-quality translations.", "published": "2025-04-18 11:11:14", "link": "http://arxiv.org/abs/2504.13630v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Divergent LLM Adoption and Heterogeneous Convergence Paths in Research Writing", "abstract": "Large Language Models (LLMs), such as ChatGPT, are reshaping content creation\nand academic writing. This study investigates the impact of AI-assisted\ngenerative revisions on research manuscripts, focusing on heterogeneous\nadoption patterns and their influence on writing convergence. Leveraging a\ndataset of over 627,000 academic papers from arXiv, we develop a novel\nclassification framework by fine-tuning prompt- and discipline-specific large\nlanguage models to detect the style of ChatGPT-revised texts. Our findings\nreveal substantial disparities in LLM adoption across academic disciplines,\ngender, native language status, and career stage, alongside a rapid evolution\nin scholarly writing styles. Moreover, LLM usage enhances clarity, conciseness,\nand adherence to formal writing conventions, with improvements varying by\nrevision type. Finally, a difference-in-differences analysis shows that while\nLLMs drive convergence in academic writing, early adopters, male researchers,\nnon-native speakers, and junior scholars exhibit the most pronounced stylistic\nshifts, aligning their writing more closely with that of established\nresearchers.", "published": "2025-04-18 11:09:16", "link": "http://arxiv.org/abs/2504.13629v1", "categories": ["cs.CL", "cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models", "abstract": "Recent advancements in large reasoning models (LRMs) have demonstrated the\neffectiveness of scaling test-time computation to enhance reasoning\ncapabilities in multiple tasks. However, LRMs typically suffer from\n\"overthinking\" problems, where models generate significantly redundant\nreasoning steps while bringing limited performance gains. Existing work relies\non fine-tuning to mitigate overthinking, which requires additional data,\nunconventional training setups, risky safety misalignment, and poor\ngeneralization.\n  Through empirical analysis, we reveal an important characteristic of LRM\nbehaviors that placing external CoTs generated by smaller models between the\nthinking token ($\\texttt{<think>}$ and $\\texttt{</think>)}$ can effectively\nmanipulate the model to generate fewer thoughts. Building on these insights, we\npropose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass\nunnecessary intermediate steps and reduce computational costs significantly. We\nconduct extensive experiments to validate the utility and efficiency of\nThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code\ndataset, ThoughtMani keeps the original performance and reduces output token\ncounts by approximately 30%, with little overhead from the CoT generator.\nFurthermore, we find that ThoughtMani enhances safety alignment by an average\nof 10%. Since model vendors typically serve models of different sizes\nsimultaneously, ThoughtMani provides an effective way to construct more\nefficient and accessible LRMs for real-world applications.", "published": "2025-04-18 11:07:19", "link": "http://arxiv.org/abs/2504.13626v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Long-context Non-factoid Question Answering in Indic Languages", "abstract": "Question Answering (QA) tasks, which involve extracting answers from a given\ncontext, are relatively straightforward for modern Large Language Models (LLMs)\nwhen the context is short. However, long contexts pose challenges due to the\nquadratic complexity of the self-attention mechanism. This challenge is\ncompounded in Indic languages, which are often low-resource. This study\nexplores context-shortening techniques, including Open Information Extraction\n(OIE), coreference resolution, Answer Paragraph Selection (APS), and their\ncombinations, to improve QA performance. Compared to the baseline of\nunshortened (long) contexts, our experiments on four Indic languages (Hindi,\nTamil, Telugu, and Urdu) demonstrate that context-shortening techniques yield\nan average improvement of 4\\% in semantic scores and 47\\% in token-level scores\nwhen evaluated on three popular LLMs without fine-tuning. Furthermore, with\nfine-tuning, we achieve an average increase of 2\\% in both semantic and\ntoken-level scores. Additionally, context-shortening reduces computational\noverhead. Explainability techniques like LIME and SHAP reveal that when the APS\nmodel confidently identifies the paragraph containing the answer, nearly all\ntokens within the selected text receive high relevance scores. However, the\nstudy also highlights the limitations of LLM-based QA systems in addressing\nnon-factoid questions, particularly those requiring reasoning or debate.\nMoreover, verbalizing OIE-generated triples does not enhance system\nperformance. These findings emphasize the potential of context-shortening\ntechniques to improve the efficiency and effectiveness of LLM-based QA systems,\nespecially for low-resource languages. The source code and resources are\navailable at https://github.com/ritwikmishra/IndicGenQA.", "published": "2025-04-18 10:43:21", "link": "http://arxiv.org/abs/2504.13615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Continual Pre-Training is (not) What You Need in Domain Adaption", "abstract": "The recent advances in Legal Large Language Models (LLMs) have transformed\nthe landscape of legal research and practice by automating tasks, enhancing\nresearch precision, and supporting complex decision-making processes. However,\neffectively adapting LLMs to the legal domain remains challenging due to the\ncomplexity of legal reasoning, the need for precise interpretation of\nspecialized language, and the potential for hallucinations. This paper examines\nthe efficacy of Domain-Adaptive Continual Pre-Training (DACP) in improving the\nlegal reasoning capabilities of LLMs. Through a series of experiments on legal\nreasoning tasks within the Taiwanese legal framework, we demonstrate that while\nDACP enhances domain-specific knowledge, it does not uniformly improve\nperformance across all legal tasks. We discuss the trade-offs involved in DACP,\nparticularly its impact on model generalization and performance in prompt-based\ntasks, and propose directions for future research to optimize domain adaptation\nstrategies in legal AI.", "published": "2025-04-18 10:14:51", "link": "http://arxiv.org/abs/2504.13603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Generalization in Intent Detection: GRPO with Reward-Based Curriculum Sampling", "abstract": "Intent detection, a critical component in task-oriented dialogue (TOD)\nsystems, faces significant challenges in adapting to the rapid influx of\nintegrable tools with complex interrelationships. Existing approaches, such as\nzero-shot reformulations and LLM-based dynamic recognition, struggle with\nperformance degradation when encountering unseen intents, leading to erroneous\ntask routing. To enhance the model's generalization performance on unseen\ntasks, we employ Reinforcement Learning (RL) combined with a Reward-based\nCurriculum Sampling (RCS) during Group Relative Policy Optimization (GRPO)\ntraining in intent detection tasks. Experiments demonstrate that RL-trained\nmodels substantially outperform supervised fine-tuning (SFT) baselines in\ngeneralization. Besides, the introduction of the RCS, significantly bolsters\nthe effectiveness of RL in intent detection by focusing the model on\nchallenging cases during training. Moreover, incorporating Chain-of-Thought\n(COT) processes in RL notably improves generalization in complex intent\ndetection tasks, underscoring the importance of thought in challenging\nscenarios. This work advances the generalization of intent detection tasks,\noffering practical insights for deploying adaptable dialogue systems.", "published": "2025-04-18 09:52:12", "link": "http://arxiv.org/abs/2504.13592v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification", "abstract": "With the widespread adoption of Large Language Models (LLMs), jailbreak\nattacks have become an increasingly pressing safety concern. While\nsafety-aligned LLMs can effectively defend against normal harmful queries, they\nremain vulnerable to such attacks. Existing defense methods primarily rely on\nfine-tuning or input modification, which often suffer from limited\ngeneralization and reduced utility. To address this, we introduce DETAM, a\nfinetuning-free defense approach that improves the defensive capabilities\nagainst jailbreak attacks of LLMs via targeted attention modification.\nSpecifically, we analyze the differences in attention scores between successful\nand unsuccessful defenses to identify the attention heads sensitive to\njailbreak attacks. During inference, we reallocate attention to emphasize the\nuser's core intention, minimizing interference from attack tokens. Our\nexperimental results demonstrate that DETAM outperforms various baselines in\njailbreak defense and exhibits robust generalization across different attacks\nand models, maintaining its effectiveness even on in-the-wild jailbreak data.\nFurthermore, in evaluating the model's utility, we incorporated over-defense\ndatasets, which further validate the superior performance of our approach. The\ncode will be released immediately upon acceptance.", "published": "2025-04-18 09:02:12", "link": "http://arxiv.org/abs/2504.13562v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation", "abstract": "Many adversarial attack approaches are proposed to verify the vulnerability\nof language models. However, they require numerous queries and the information\non the target model. Even black-box attack methods also require the target\nmodel's output information. They are not applicable in real-world scenarios, as\nin hard black-box settings where the target model is closed and inaccessible.\nEven the recently proposed hard black-box attacks still require many queries\nand demand extremely high costs for training adversarial generators. To address\nthese challenges, we propose Q-faker (Query-free Hard Black-box Attacker), a\nnovel and efficient method that generates adversarial examples without\naccessing the target model. To avoid accessing the target model, we use a\nsurrogate model instead. The surrogate model generates adversarial sentences\nfor a target-agnostic attack. During this process, we leverage controlled\ngeneration techniques. We evaluate our proposed method on eight datasets.\nExperimental results demonstrate our method's effectiveness including high\ntransferability and the high quality of the generated adversarial examples, and\nprove its practical in hard black-box settings.", "published": "2025-04-18 08:36:38", "link": "http://arxiv.org/abs/2504.13551v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content", "abstract": "Sentiment analysis is crucial for brand reputation management in the banking\nsector, where customer feedback spans English, Sinhala, Singlish, and\ncode-mixed text. Existing models struggle with low-resource languages like\nSinhala and lack interpretability for practical use. This research develops a\nhybrid aspect-based sentiment analysis framework that enhances multilingual\ncapabilities with explainable outputs. Using cleaned banking customer reviews,\nwe fine-tune XLM-RoBERTa for Sinhala and code-mixed text, integrate\ndomain-specific lexicon correction, and employ BERT-base-uncased for English.\nThe system classifies sentiment (positive, neutral, negative) with confidence\nscores, while SHAP and LIME improve interpretability by providing real-time\nsentiment explanations. Experimental results show that our approaches\noutperform traditional transformer-based classifiers, achieving 92.3 percent\naccuracy and an F1-score of 0.89 in English and 88.4 percent in Sinhala and\ncode-mixed content. An explainability analysis reveals key sentiment drivers,\nimproving trust and transparency. A user-friendly interface delivers\naspect-wise sentiment insights, ensuring accessibility for businesses. This\nresearch contributes to robust, transparent sentiment analysis for financial\napplications by bridging gaps in multilingual, low-resource NLP and\nexplainability.", "published": "2025-04-18 08:21:12", "link": "http://arxiv.org/abs/2504.13545v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models", "abstract": "While chain-of-thought (CoT) reasoning improves the performance of large\nlanguage models (LLMs) in complex tasks, it still has two main challenges: the\nlow reliability of relying solely on LLMs to generate reasoning chains and the\ninterference of natural language reasoning chains on the inference logic of\nLLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework\nwith three key designs: (i) Knowledge Graph-driven CoT Generation, featuring\nknowledge graphs to modulate reasoning chain generation of LLMs, thereby\nenhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which\nincorporates retrieval-augmented generation (RAG) into knowledge graphs to\nretrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable\ninformation; (iii) Pseudo-Program Prompting Execution, which encourages LLMs to\nexecute reasoning tasks in pseudo-programs with greater logical rigor. We\nconduct a comprehensive evaluation on nine public datasets, covering three\nreasoning problems. Compared with the-state-of-the-art methods, CoT-RAG\nexhibits a significant accuracy improvement, ranging from 4.0% to 23.0%.\nFurthermore, testing on four domain-specific datasets, CoT-RAG shows remarkable\naccuracy and efficient execution, highlighting its strong practical\napplicability and scalability.", "published": "2025-04-18 07:55:09", "link": "http://arxiv.org/abs/2504.13534v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prejudge-Before-Think: Enhancing Large Language Models at Test-Time by Process Prejudge Reasoning", "abstract": "In this paper, we introduce a new \\emph{process prejudge} strategy in LLM\nreasoning to demonstrate that bootstrapping with process prejudge allows the\nLLM to adaptively anticipate the errors encountered when advancing the\nsubsequent reasoning steps, similar to people sometimes pausing to think about\nwhat mistakes may occur and how to avoid them, rather than relying solely on\ntrial and error. Specifically, we define a prejudge node in the rationale,\nwhich represents a reasoning step, with at least one step that follows the\nprejudge node that has no paths toward the correct answer. To synthesize the\nprejudge reasoning process, we present an automated reasoning framework with a\ndynamic tree-searching strategy. This framework requires only one LLM to\nperform answer judging, response critiquing, prejudge generation, and thought\ncompletion. Furthermore, we develop a two-phase training mechanism with\nsupervised fine-tuning (SFT) and reinforcement learning (RL) to further enhance\nthe reasoning capabilities of LLMs. Experimental results from competition-level\ncomplex reasoning demonstrate that our method can teach the model to prejudge\nbefore thinking and significantly enhance the reasoning ability of LLMs. Code\nand data is released at https://github.com/wjn1996/Prejudge-Before-Think.", "published": "2025-04-18 06:42:30", "link": "http://arxiv.org/abs/2504.13500v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Locality-Aware Attention with Transformers for General Geometry PDEs", "abstract": "Neural operators have emerged as promising frameworks for learning mappings\ngoverned by partial differential equations (PDEs), serving as data-driven\nalternatives to traditional numerical methods. While methods such as the\nFourier neural operator (FNO) have demonstrated notable performance, their\nreliance on uniform grids restricts their applicability to complex geometries\nand irregular meshes. Recently, Transformer-based neural operators with linear\nattention mechanisms have shown potential in overcoming these limitations for\nlarge-scale PDE simulations. However, these approaches predominantly emphasize\nglobal feature aggregation, often overlooking fine-scale dynamics and localized\nPDE behaviors essential for accurate solutions. To address these challenges, we\npropose the Locality-Aware Attention Transformer (LA2Former), which leverages\nK-nearest neighbors for dynamic patchifying and integrates global-local\nattention for enhanced PDE modeling. By combining linear attention for\nefficient global context encoding with pairwise attention for capturing\nintricate local interactions, LA2Former achieves an optimal balance between\ncomputational efficiency and predictive accuracy. Extensive evaluations across\nsix benchmark datasets demonstrate that LA2Former improves predictive accuracy\nby over 50% relative to existing linear attention methods, while also\noutperforming full pairwise attention under optimal conditions. This work\nunderscores the critical importance of localized feature learning in advancing\nTransformer-based neural operators for solving PDEs on complex and irregular\ndomains.", "published": "2025-04-18 05:43:49", "link": "http://arxiv.org/abs/2504.13480v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM Sensitivity Evaluation Framework for Clinical Diagnosis", "abstract": "Large language models (LLMs) have demonstrated impressive performance across\nvarious domains. However, for clinical diagnosis, higher expectations are\nrequired for LLM's reliability and sensitivity: thinking like physicians and\nremaining sensitive to key medical information that affects diagnostic\nreasoning, as subtle variations can lead to different diagnosis results. Yet,\nexisting works focus mainly on investigating the sensitivity of LLMs to\nirrelevant context and overlook the importance of key information. In this\npaper, we investigate the sensitivity of LLMs, i.e. GPT-3.5, GPT-4, Gemini,\nClaude3 and LLaMA2-7b, to key medical information by introducing different\nperturbation strategies. The evaluation results highlight the limitations of\ncurrent LLMs in remaining sensitive to key medical information for diagnostic\ndecision-making. The evolution of LLMs must focus on improving their\nreliability, enhancing their ability to be sensitive to key information, and\neffectively utilizing this information. These improvements will enhance human\ntrust in LLMs and facilitate their practical application in real-world\nscenarios. Our code and dataset are available at\nhttps://github.com/chenwei23333/DiagnosisQA.", "published": "2025-04-18 05:35:11", "link": "http://arxiv.org/abs/2504.13475v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation", "abstract": "Large language models (LLMs) have demonstrated strong capabilities in code\ngeneration, underscoring the critical need for rigorous and comprehensive\nevaluation. Existing evaluation approaches fall into three categories,\nincluding human-centered, metric-based, and LLM-based. Considering that\nhuman-centered approaches are labour-intensive and metric-based ones overly\nrely on reference answers, LLM-based approaches are gaining increasing\nattention due to their stronger contextual understanding capabilities and\nsuperior efficiency. However, the performance of LLM-based approaches remains\nlimited due to: (1) lack of multisource domain knowledge, and (2) insufficient\ncomprehension of complex code.\n  To mitigate the limitations, we propose CodeVisionary, the first LLM-based\nagent framework for evaluating LLMs in code generation. CodeVisionary consists\nof two stages: (1) Multiscore knowledge analysis stage, which aims to gather\nmultisource and comprehensive domain knowledge by formulating and executing a\nstepwise evaluation plan. (2) Negotiation-based scoring stage, which involves\nmultiple judges engaging in discussions to better comprehend the complex code\nand reach a consensus on the evaluation score. Extensive experiments\ndemonstrate that CodeVisionary achieves the best performance for evaluating\nLLMs in code generation, outperforming the best baseline methods with average\nimprovements of 0.202, 0.139, and 0.117 in Pearson, Spearman, and Kendall-Tau\ncoefficients, respectively. Besides, CodeVisionary provides detailed evaluation\nreports, which assist developers in identifying shortcomings and making\nimprovements. The resources of CodeVisionary are available at\nhttps://anonymous.4open.science/r/CodeVisionary.", "published": "2025-04-18 05:26:32", "link": "http://arxiv.org/abs/2504.13472v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs", "abstract": "In recent years, Large Language Models (LLMs) have significantly advanced\nartificial intelligence by optimizing traditional Natural Language Processing\n(NLP) pipelines, improving performance and generalization. This has spurred\ntheir integration into various systems. Many NLP systems, including ours,\nemploy a \"one-stage\" pipeline directly incorporating LLMs. While effective,\nthis approach incurs substantial costs and latency due to the need for large\nmodel parameters to achieve satisfactory outcomes. This paper introduces a\nthree-stage cost-efficient end-to-end LLM deployment pipeline-including\nprototyping, knowledge transfer, and model compression-to tackle the\ncost-performance dilemma in LLM-based frameworks. Our approach yields a super\ntiny model optimized for cost and performance in online systems, simplifying\nthe system architecture. Initially, by transforming complex tasks into a\nfunction call-based LLM-driven pipeline, an optimal performance prototype\nsystem is constructed to produce high-quality data as a teacher model. The\nsecond stage combine techniques like rejection fine-tuning, reinforcement\nlearning and knowledge distillation to transfer knowledge to a smaller 0.5B\nstudent model, delivering effective performance at minimal cost. The final\nstage applies quantization and pruning to extremely compress model to 0.4B,\nachieving ultra-low latency and cost. The framework's modular design and\ncross-domain capabilities suggest potential applicability in other NLP areas.", "published": "2025-04-18 05:25:22", "link": "http://arxiv.org/abs/2504.13471v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "D-GEN: Automatic Distractor Generation and Evaluation for Reliable Assessment of Generative Model", "abstract": "Evaluating generative models with open-ended generation is challenging due to\ninconsistencies in response formats. Multiple-choice (MC) evaluation mitigates\nthis issue, but generating high-quality distractors is time-consuming and\nlabor-intensive. We introduce D-GEN, the first open-source distractor generator\nmodel that transforms open-ended data into an MC format. To evaluate distractor\nquality, we propose two novel methods: (1) ranking alignment, ensuring\ngenerated distractors retain the discriminatory power of ground-truth\ndistractors, and (2) entropy analysis, comparing model confidence\ndistributions. Our results show that D-GEN preserves ranking consistency\n(Spearman's rho 0.99, Kendall's tau 0.94) and closely matches the entropy\ndistribution of ground-truth distractors. Human evaluation further confirms the\nfluency, coherence, distractiveness, and incorrectness. Our work advances\nrobust and efficient distractor generation with automated evaluation, setting a\nnew standard for MC evaluation.", "published": "2025-04-18 03:40:11", "link": "http://arxiv.org/abs/2504.13439v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Secure Multifaceted-RAG for Enterprise: Hybrid Knowledge Retrieval with Security Filtering", "abstract": "Existing Retrieval-Augmented Generation (RAG) systems face challenges in\nenterprise settings due to limited retrieval scope and data security risks.\nWhen relevant internal documents are unavailable, the system struggles to\ngenerate accurate and complete responses. Additionally, using closed-source\nLarge Language Models (LLMs) raises concerns about exposing proprietary\ninformation. To address these issues, we propose the Secure Multifaceted-RAG\n(SecMulti-RAG) framework, which retrieves not only from internal documents but\nalso from two supplementary sources: pre-generated expert knowledge for\nanticipated queries and on-demand external LLM-generated knowledge. To mitigate\nsecurity risks, we adopt a local open-source generator and selectively utilize\nexternal LLMs only when prompts are deemed safe by a filtering mechanism. This\napproach enhances completeness, prevents data leakage, and reduces costs. In\nour evaluation on a report generation task in the automotive industry,\nSecMulti-RAG significantly outperforms traditional RAG - achieving 79.3 to 91.9\npercent win rates across correctness, richness, and helpfulness in LLM-based\nevaluation, and 56.3 to 70.4 percent in human evaluation. This highlights\nSecMulti-RAG as a practical and secure solution for enterprise RAG.", "published": "2025-04-18 02:51:29", "link": "http://arxiv.org/abs/2504.13425v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "STAMP Your Content: Proving Dataset Membership via Watermarked Rephrasings", "abstract": "Given how large parts of publicly available text are crawled to pretrain\nlarge language models (LLMs), data creators increasingly worry about the\ninclusion of their proprietary data for model training without attribution or\nlicensing. Their concerns are also shared by benchmark curators whose test-sets\nmight be compromised. In this paper, we present STAMP, a framework for\ndetecting dataset membership-i.e., determining the inclusion of a dataset in\nthe pretraining corpora of LLMs. Given an original piece of content, our\nproposal involves first generating multiple rephrases, each embedding a\nwatermark with a unique secret key. One version is to be released publicly,\nwhile others are to be kept private. Subsequently, creators can compare model\nlikelihoods between public and private versions using paired statistical tests\nto prove membership. We show that our framework can successfully detect\ncontamination across four benchmarks which appear only once in the training\ndata and constitute less than 0.001% of the total tokens, outperforming several\ncontamination detection and dataset inference baselines. We verify that STAMP\npreserves both the semantic meaning and the utility of the original data in\ncomparing different models. We apply STAMP to two real-world scenarios to\nconfirm the inclusion of paper abstracts and blog articles in the pretraining\ncorpora.", "published": "2025-04-18 02:25:08", "link": "http://arxiv.org/abs/2504.13416v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "LangCoop: Collaborative Driving with Language", "abstract": "Multi-agent collaboration holds great promise for enhancing the safety,\nreliability, and mobility of autonomous driving systems by enabling information\nsharing among multiple connected agents. However, existing multi-agent\ncommunication approaches are hindered by limitations of existing communication\nmedia, including high bandwidth demands, agent heterogeneity, and information\nloss. To address these challenges, we introduce LangCoop, a new paradigm for\ncollaborative autonomous driving that leverages natural language as a compact\nyet expressive medium for inter-agent communication. LangCoop features two key\ninnovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured\nzero-shot vision-language reasoning and Natural Language Information Packaging\n(LangPack) for efficiently packaging information into concise, language-based\nmessages. Through extensive experiments conducted in the CARLA simulations, we\ndemonstrate that LangCoop achieves a remarkable 96\\% reduction in communication\nbandwidth (< 2KB per message) compared to image-based communication, while\nmaintaining competitive driving performance in the closed-loop evaluation.", "published": "2025-04-18 02:03:14", "link": "http://arxiv.org/abs/2504.13406v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "A mean teacher algorithm for unlearning of language models", "abstract": "One of the goals of language model unlearning is to reduce memorization of\nselected text instances while retaining the model's general abilities. Despite\nvarious proposed methods, reducing memorization of large datasets without\nnoticeable degradation in model utility remains challenging. In this paper, we\ninvestigate the mean teacher algorithm (Tarvainen & Valpola, 2017), a simple\nproximal optimization method from continual learning literature that gradually\nmodifies the teacher model. We show that the mean teacher can approximate a\ntrajectory of a slow natural gradient descent (NGD), which inherently seeks\nlow-curvature updates that are less likely to degrade the model utility. While\nslow NGD can suffer from vanishing gradients, we introduce a new unlearning\nloss called \"negative log-unlikelihood\" (NLUL) that avoids this problem. We\nshow that the combination of mean teacher and NLUL improves some metrics on the\nMUSE benchmarks (Shi et al., 2024).", "published": "2025-04-18 00:34:19", "link": "http://arxiv.org/abs/2504.13388v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Parameter-Efficient Continual Fine-Tuning: A Survey", "abstract": "The emergence of large pre-trained networks has revolutionized the AI field,\nunlocking new possibilities and achieving unprecedented performance. However,\nthese models inherit a fundamental limitation from traditional Machine Learning\napproaches: their strong dependence on the \\textit{i.i.d.} assumption hinders\ntheir adaptability to dynamic learning scenarios. We believe the next\nbreakthrough in AI lies in enabling efficient adaptation to evolving\nenvironments -- such as the real world -- where new data and tasks arrive\nsequentially. This challenge defines the field of Continual Learning (CL), a\nMachine Learning paradigm focused on developing lifelong learning neural\nmodels. One alternative to efficiently adapt these large-scale models is known\nParameter-Efficient Fine-Tuning (PEFT). These methods tackle the issue of\nadapting the model to a particular data or scenario by performing small and\nefficient modifications, achieving similar performance to full fine-tuning.\nHowever, these techniques still lack the ability to adjust the model to\nmultiple tasks continually, as they suffer from the issue of Catastrophic\nForgetting. In this survey, we first provide an overview of CL algorithms and\nPEFT methods before reviewing the state-of-the-art on Parameter-Efficient\nContinual Fine-Tuning (PECFT). We examine various approaches, discuss\nevaluation metrics, and explore potential future research directions. Our goal\nis to highlight the synergy between CL and Parameter-Efficient Fine-Tuning,\nguide researchers in this field, and pave the way for novel future research\ndirections.", "published": "2025-04-18 17:51:51", "link": "http://arxiv.org/abs/2504.13822v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Near-optimal algorithms for private estimation and sequential testing of collision probability", "abstract": "We present new algorithms for estimating and testing \\emph{collision\nprobability}, a fundamental measure of the spread of a discrete distribution\nthat is widely used in many scientific fields. We describe an algorithm that\nsatisfies $(\\alpha, \\beta)$-local differential privacy and estimates collision\nprobability with error at most $\\epsilon$ using\n$\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$ samples for\n$\\alpha \\le 1$, which improves over previous work by a factor of\n$\\frac{1}{\\alpha^2}$. We also present a sequential testing algorithm for\ncollision probability, which can distinguish between collision probability\nvalues that are separated by $\\epsilon$ using $\\tilde{O}(\\frac{1}{\\epsilon^2})$\nsamples, even when $\\epsilon$ is unknown. Our algorithms have nearly the\noptimal sample complexity, and in experiments we show that they require\nsignificantly fewer samples than previous methods.", "published": "2025-04-18 17:12:15", "link": "http://arxiv.org/abs/2504.13804v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Imitation Learning with Precisely Labeled Human Demonstrations", "abstract": "Within the imitation learning paradigm, training generalist robots requires\nlarge-scale datasets obtainable only through diverse curation. Due to the\nrelative ease to collect, human demonstrations constitute a valuable addition\nwhen incorporated appropriately. However, existing methods utilizing human\ndemonstrations face challenges in inferring precise actions, ameliorating\nembodiment gaps, and fusing with frontier generalist robot training pipelines.\nIn this work, building on prior studies that demonstrate the viability of using\nhand-held grippers for efficient data collection, we leverage the user's\ncontrol over the gripper's appearance--specifically by assigning it a unique,\neasily segmentable color--to enable simple and reliable application of the\nRANSAC and ICP registration method for precise end-effector pose estimation. We\nshow in simulation that precisely labeled human demonstrations on their own\nallow policies to reach on average 88.1% of the performance of using robot\ndemonstrations, and boost policy performance when combined with robot\ndemonstrations, despite the inherent embodiment gap.", "published": "2025-04-18 17:12:00", "link": "http://arxiv.org/abs/2504.13803v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Meta-Learning and Knowledge Discovery based Physics-Informed Neural Network for Remaining Useful Life Prediction", "abstract": "Predicting the remaining useful life (RUL) of rotating machinery is critical\nfor industrial safety and maintenance, but existing methods struggle with\nscarce target-domain data and unclear degradation dynamics. We propose a\nMeta-Learning and Knowledge Discovery-based Physics-Informed Neural Network\n(MKDPINN) to address these challenges. The method first maps noisy sensor data\nto a low-dimensional hidden state space via a Hidden State Mapper (HSM). A\nPhysics-Guided Regulator (PGR) then learns unknown nonlinear PDEs governing\ndegradation evolution, embedding these physical constraints into the PINN\nframework. This integrates data-driven and physics-based approaches. The\nframework uses meta-learning, optimizing across source-domain meta-tasks to\nenable few-shot adaptation to new target tasks. Experiments on industrial data\nand the C-MAPSS benchmark show MKDPINN outperforms baselines in generalization\nand accuracy, proving its effectiveness for RUL prediction under data scarcity", "published": "2025-04-18 16:58:38", "link": "http://arxiv.org/abs/2504.13797v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion", "abstract": "After demonstrating significant success in image synthesis, Generative\nAdversarial Network (GAN) models have likewise made significant progress in the\nfield of speech synthesis, leveraging their capacity to adapt the precise\ndistribution of target data through adversarial learning processes. Notably, in\nthe realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models,\nthere exists a substantial disparity in naturalness between real and\nGAN-generated speech samples. Furthermore, while many GAN models currently\noperate on a single generator discriminator learning approach, optimizing\ntarget data distribution is more effectively achievable through a single\ngenerator multi-discriminator learning scheme. Hence, this study introduces a\nnovel GAN model named Collective Learning Mechanism-based Optimal Transport GAN\n(CLOT-GAN) model, incorporating multiple discriminators, including the Deep\nConvolutional Neural Network (DCNN) model, Vision Transformer (ViT), and\nconformer. The objective of integrating various discriminators lies in their\nability to comprehend the formant distribution of mel-spectrograms, facilitated\nby a collective learning mechanism. Simultaneously, the inclusion of Optimal\nTransport (OT) loss aims to precisely bridge the gap between the source and\ntarget data distribution, employing the principles of OT theory. The\nexperimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms\nthat the CLOT-GAN-VC model outperforms existing VC models in objective and\nsubjective assessments.", "published": "2025-04-18 16:44:01", "link": "http://arxiv.org/abs/2504.13791v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Probabilistic Stability Guarantees for Feature Attributions", "abstract": "Stability guarantees are an emerging tool for evaluating feature\nattributions, but existing certification methods rely on smoothed classifiers\nand often yield conservative guarantees. To address these limitations, we\nintroduce soft stability and propose a simple, model-agnostic, and\nsample-efficient stability certification algorithm (SCA) that provides\nnon-trivial and interpretable guarantees for any attribution. Moreover, we show\nthat mild smoothing enables a graceful tradeoff between accuracy and stability,\nin contrast to prior certification methods that require a more aggressive\ncompromise. Using Boolean function analysis, we give a novel characterization\nof stability under smoothing. We evaluate SCA on vision and language tasks, and\ndemonstrate the effectiveness of soft stability in measuring the robustness of\nexplanation methods.", "published": "2025-04-18 16:39:08", "link": "http://arxiv.org/abs/2504.13787v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Learning Through Retrospection: Improving Trajectory Prediction for Automated Driving with Error Feedback", "abstract": "In automated driving, predicting trajectories of surrounding vehicles\nsupports reasoning about scene dynamics and enables safe planning for the ego\nvehicle. However, existing models handle predictions as an instantaneous task\nof forecasting future trajectories based on observed information. As time\nproceeds, the next prediction is made independently of the previous one, which\nmeans that the model cannot correct its errors during inference and will repeat\nthem. To alleviate this problem and better leverage temporal data, we propose a\nnovel retrospection technique. Through training on closed-loop rollouts the\nmodel learns to use aggregated feedback. Given new observations it reflects on\nprevious predictions and analyzes its errors to improve the quality of\nsubsequent predictions. Thus, the model can learn to correct systematic errors\nduring inference. Comprehensive experiments on nuScenes and Argoverse\ndemonstrate a considerable decrease in minimum Average Displacement Error of up\nto 31.9% compared to the state-of-the-art baseline without retrospection. We\nfurther showcase the robustness of our technique by demonstrating a better\nhandling of out-of-distribution scenarios with undetected road-users.", "published": "2025-04-18 16:35:12", "link": "http://arxiv.org/abs/2504.13785v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs", "abstract": "Large language models (LLMs) have recently revolutionized language processing\ntasks but have also brought ethical and legal issues. LLMs have a tendency to\nmemorize potentially private or copyrighted information present in the training\ndata, which might then be delivered to end users at inference time. When this\nhappens, a naive solution is to retrain the model from scratch after excluding\nthe undesired data. Although this guarantees that the target data have been\nforgotten, it is also prohibitively expensive for LLMs. Approximate unlearning\noffers a more efficient alternative, as it consists of ex post modifications of\nthe trained model itself to prevent undesirable results, but it lacks\nforgetting guarantees because it relies solely on empirical evidence. In this\nwork, we present DP2Unlearning, a novel LLM unlearning framework that offers\nformal forgetting guarantees at a significantly lower cost than retraining from\nscratch on the data to be retained. DP2Unlearning involves training LLMs on\ntextual data protected using {\\epsilon}-differential privacy (DP), which later\nenables efficient unlearning with the guarantees against disclosure associated\nwith the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning\nachieves similar model performance post-unlearning, compared to an LLM\nretraining from scratch on retained data -- the gold standard exact unlearning\n-- but at approximately half the unlearning cost. In addition, with a\nreasonable computational cost, it outperforms approximate unlearning methods at\nboth preserving the utility of the model post-unlearning and effectively\nforgetting the targeted information.", "published": "2025-04-18 16:22:20", "link": "http://arxiv.org/abs/2504.13774v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Decoding Vision Transformers: the Diffusion Steering Lens", "abstract": "Logit Lens is a widely adopted method for mechanistic interpretability of\ntransformer-based language models, enabling the analysis of how internal\nrepresentations evolve across layers by projecting them into the output\nvocabulary space. Although applying Logit Lens to Vision Transformers (ViTs) is\ntechnically straightforward, its direct use faces limitations in capturing the\nrichness of visual representations. Building on the work of Toker et al.\n(2024)~\\cite{Toker2024-ve}, who introduced Diffusion Lens to visualize\nintermediate representations in the text encoders of text-to-image diffusion\nmodels, we demonstrate that while Diffusion Lens can effectively visualize\nresidual stream representations in image encoders, it fails to capture the\ndirect contributions of individual submodules. To overcome this limitation, we\npropose \\textbf{Diffusion Steering Lens} (DSL), a novel, training-free approach\nthat steers submodule outputs and patches subsequent indirect contributions. We\nvalidate our method through interventional studies, showing that DSL provides\nan intuitive and reliable interpretation of the internal processing in ViTs.", "published": "2025-04-18 16:00:53", "link": "http://arxiv.org/abs/2504.13763v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis", "abstract": "Neuroblastoma, adrenal-derived, is among the most common pediatric solid\nmalignancies, characterized by significant clinical heterogeneity. Timely and\naccurate pathological diagnosis from hematoxylin and eosin-stained whole slide\nimages is critical for patient prognosis. However, current diagnostic practices\nprimarily rely on subjective manual examination by pathologists, leading to\ninconsistent accuracy. Existing automated whole slide image classification\nmethods encounter challenges such as poor interpretability, limited feature\nextraction capabilities, and high computational costs, restricting their\npractical clinical deployment. To overcome these limitations, we propose\nCMSwinKAN, a contrastive-learning-based multi-scale feature fusion model\ntailored for pathological image classification, which enhances the Swin\nTransformer architecture by integrating a Kernel Activation Network within its\nmultilayer perceptron and classification head modules, significantly improving\nboth interpretability and accuracy. By fusing multi-scale features and\nleveraging contrastive learning strategies, CMSwinKAN mimics clinicians'\ncomprehensive approach, effectively capturing global and local tissue\ncharacteristics. Additionally, we introduce a heuristic soft voting mechanism\nguided by clinical insights to seamlessly bridge patch-level predictions to\nwhole slide image-level classifications. We validate CMSwinKAN on the PpNTs\ndataset, which was collaboratively established with our partner hospital and\nthe publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN\nperforms better than existing state-of-the-art pathology-specific models\npre-trained on large datasets. Our source code is available at\nhttps://github.com/JSLiam94/CMSwinKAN.", "published": "2025-04-18 15:39:46", "link": "http://arxiv.org/abs/2504.13754v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Survey for What Developers Require in AI-powered Tools that Aid in Component Selection in CBSD", "abstract": "Although it has been more than four decades that the first components-based\nsoftware development (CBSD) studies were conducted, there is still no standard\nmethod or tool for component selection which is widely accepted by the\nindustry. The gulf between industry and academia contributes to the lack of an\naccepted tool. We conducted a mixed methods survey of nearly 100 people engaged\nin component-based software engineering practice or research to better\nunderstand the problems facing industry, how these needs could be addressed,\nand current best practices employed in component selection. We also sought to\nidentify and prioritize quality criteria for component selection from an\nindustry perspective. In response to the call for CBSD component selection\ntools to incorporate recent technical advances, we also explored the\nperceptions of professionals about AI-driven tools, present and envisioned.", "published": "2025-04-18 15:35:31", "link": "http://arxiv.org/abs/2504.13751v1", "categories": ["cs.SE", "cs.AI", "cs.CY"], "primary_category": "cs.SE"}
{"title": "ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis", "abstract": "Diffusion models have revolutionized text-to-image (T2I) synthesis, producing\nhigh-quality, photorealistic images. However, they still struggle to properly\nrender the spatial relationships described in text prompts. To address the lack\nof spatial information in T2I generations, existing methods typically use\nexternal network conditioning and predefined layouts, resulting in higher\ncomputational costs and reduced flexibility. Our approach builds upon a curated\ndataset of spatially explicit prompts, meticulously extracted and synthesized\nfrom LAION-400M to ensure precise alignment between textual descriptions and\nspatial layouts. Alongside this dataset, we present ESPLoRA, a flexible\nfine-tuning framework based on Low-Rank Adaptation, specifically designed to\nenhance spatial consistency in generative models without increasing generation\ntime or compromising the quality of the outputs. In addition to ESPLoRA, we\npropose refined evaluation metrics grounded in geometric constraints, capturing\n3D spatial relations such as \\textit{in front of} or \\textit{behind}. These\nmetrics also expose spatial biases in T2I models which, even when not fully\nmitigated, can be strategically exploited by our TORE algorithm to further\nimprove the spatial consistency of generated images. Our method outperforms the\ncurrent state-of-the-art framework, CoMPaSS, by 13.33% on established spatial\nconsistency benchmarks.", "published": "2025-04-18 15:21:37", "link": "http://arxiv.org/abs/2504.13745v1", "categories": ["cs.CV", "cs.AI", "I.4.0"], "primary_category": "cs.CV"}
{"title": "Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration", "abstract": "This work aligns deep learning (DL) with human reasoning capabilities and\nneeds to enable more efficient, interpretable, and robust image classification.\nWe approach this from three perspectives: explainability, causality, and\nbiological vision. Introduction and background open this work before diving\ninto operative chapters. First, we assess neural networks' visualization\ntechniques for medical images and validate an explainable-by-design method for\nbreast mass classification. A comprehensive review at the intersection of XAI\nand causality follows, where we introduce a general scaffold to organize past\nand future research, laying the groundwork for our second perspective. In the\ncausality direction, we propose novel modules that exploit feature\nco-occurrence in medical images, leading to more effective and explainable\npredictions. We further introduce CROCODILE, a general framework that\nintegrates causal concepts, contrastive learning, feature disentanglement, and\nprior knowledge to enhance generalization. Lastly, we explore biological\nvision, examining how humans recognize objects, and propose CoCoReco, a\nconnectivity-inspired network with context-aware attention mechanisms. Overall,\nour key findings include: (i) simple activation maximization lacks insight for\nmedical imaging DL models; (ii) prototypical-part learning is effective and\nradiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak\ncausal signals can be leveraged without a priori information to improve\nperformance and interpretability; (v) our framework generalizes across medical\ndomains and out-of-distribution data; (vi) incorporating biological circuit\nmotifs improves human-aligned recognition. This work contributes toward\nhuman-aligned DL and highlights pathways to bridge the gap between research and\nclinical adoption, with implications for improved trust, diagnostic accuracy,\nand safe deployment.", "published": "2025-04-18 14:40:58", "link": "http://arxiv.org/abs/2504.13717v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV", "q-bio.NC", "I.2; I.2.6; I.4; I.4.7; I.5; J.3; J.6"], "primary_category": "cs.CV"}
{"title": "Exploring Multimodal Prompt for Visualization Authoring with Large Language Models", "abstract": "Recent advances in large language models (LLMs) have shown great potential in\nautomating the process of visualization authoring through simple natural\nlanguage utterances. However, instructing LLMs using natural language is\nlimited in precision and expressiveness for conveying visualization intent,\nleading to misinterpretation and time-consuming iterations. To address these\nlimitations, we conduct an empirical study to understand how LLMs interpret\nambiguous or incomplete text prompts in the context of visualization authoring,\nand the conditions making LLMs misinterpret user intent. Informed by the\nfindings, we introduce visual prompts as a complementary input modality to text\nprompts, which help clarify user intent and improve LLMs' interpretation\nabilities. To explore the potential of multimodal prompting in visualization\nauthoring, we design VisPilot, which enables users to easily create\nvisualizations using multimodal prompts, including text, sketches, and direct\nmanipulations on existing visualizations. Through two case studies and a\ncontrolled user study, we demonstrate that VisPilot provides a more intuitive\nway to create visualizations without affecting the overall task efficiency\ncompared to text-only prompting approaches. Furthermore, we analyze the impact\nof text and visual prompts in different visualization tasks. Our findings\nhighlight the importance of multimodal prompting in improving the usability of\nLLMs for visualization authoring. We discuss design implications for future\nvisualization systems and provide insights into how multimodal prompts can\nenhance human-AI collaboration in creative visualization tasks. All materials\nare available at https://OSF.IO/2QRAK.", "published": "2025-04-18 14:00:55", "link": "http://arxiv.org/abs/2504.13700v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "AnyTSR: Any-Scale Thermal Super-Resolution for UAV", "abstract": "Thermal imaging can greatly enhance the application of intelligent unmanned\naerial vehicles (UAV) in challenging environments. However, the inherent low\nresolution of thermal sensors leads to insufficient details and blurred\nboundaries. Super-resolution (SR) offers a promising solution to address this\nissue, while most existing SR methods are designed for fixed-scale SR. They are\ncomputationally expensive and inflexible in practical applications. To address\nabove issues, this work proposes a novel any-scale thermal SR method (AnyTSR)\nfor UAV within a single model. Specifically, a new image encoder is proposed to\nexplicitly assign specific feature code to enable more accurate and flexible\nrepresentation. Additionally, by effectively embedding coordinate offset\ninformation into the local feature ensemble, an innovative any-scale upsampler\nis proposed to better understand spatial relationships and reduce artifacts.\nMoreover, a novel dataset (UAV-TSR), covering both land and water scenes, is\nconstructed for thermal SR tasks. Experimental results demonstrate that the\nproposed method consistently outperforms state-of-the-art methods across all\nscaling factors as well as generates more accurate and detailed high-resolution\nimages. The code is located at https://github.com/vision4robotics/AnyTSR.", "published": "2025-04-18 13:23:25", "link": "http://arxiv.org/abs/2504.13682v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction", "abstract": "As the number of web applications and API endpoints exposed to the Internet\ncontinues to grow, so does the number of exploitable vulnerabilities. Manually\nidentifying such vulnerabilities is tedious. Meanwhile, static security\nscanners tend to produce many false positives. While machine learning-based\napproaches are promising, they typically perform well only in scenarios where\ntraining and test data are closely related. A key challenge for ML-based\nvulnerability detection is providing suitable and concise code context, as\nexcessively long contexts negatively affect the code comprehension capabilities\nof machine learning models, particularly smaller ones.\n  This work introduces Trace Gadgets, a novel code representation that\nminimizes code context by removing non-related code. Trace Gadgets precisely\ncapture the statements that cover the path to the vulnerability. As input for\nML models, Trace Gadgets provide a minimal but complete context, thereby\nimproving the detection performance. Moreover, we collect a large-scale dataset\ngenerated from real-world applications with manually curated labels to further\nimprove the performance of ML-based vulnerability detectors. Our results show\nthat state-of-the-art machine learning models perform best when using Trace\nGadgets compared to previous code representations, surpassing the detection\ncapabilities of industry-standard static scanners such as GitHub's CodeQL by at\nleast 4% on a fully unseen dataset. By applying our framework to real-world\napplications, we identify and report previously unknown vulnerabilities in\nwidely deployed software.", "published": "2025-04-18 13:13:39", "link": "http://arxiv.org/abs/2504.13676v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Do Prompt Patterns Affect Code Quality? A First Empirical Assessment of ChatGPT-Generated Code", "abstract": "Large Language Models (LLMs) have rapidly transformed software development,\nespecially in code generation. However, their inconsistent performance, prone\nto hallucinations and quality issues, complicates program comprehension and\nhinders maintainability. Research indicates that prompt engineering-the\npractice of designing inputs to direct LLMs toward generating relevant\noutputs-may help address these challenges. In this regard, researchers have\nintroduced prompt patterns, structured templates intended to guide users in\nformulating their requests. However, the influence of prompt patterns on code\nquality has yet to be thoroughly investigated. An improved understanding of\nthis relationship would be essential to advancing our collective knowledge on\nhow to effectively use LLMs for code generation, thereby enhancing their\nunderstandability in contemporary software development. This paper empirically\ninvestigates the impact of prompt patterns on code quality, specifically\nmaintainability, security, and reliability, using the Dev-GPT dataset. Results\nshow that Zero-Shot prompting is most common, followed by Zero-Shot with\nChain-of-Thought and Few-Shot. Analysis of 7583 code files across quality\nmetrics revealed minimal issues, with Kruskal-Wallis tests indicating no\nsignificant differences among patterns, suggesting that prompt structure may\nnot substantially impact these quality metrics in ChatGPT-assisted code\ngeneration.", "published": "2025-04-18 12:37:02", "link": "http://arxiv.org/abs/2504.13656v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction", "abstract": "Service mobile robots are often required to avoid dynamic objects while\nperforming their tasks, but they usually have only limited computational\nresources. So we present a lightweight multi-modal framework for 3D object\ndetection and trajectory prediction. Our system synergistically integrates\nLiDAR and camera inputs to achieve real-time perception of pedestrians,\nvehicles, and riders in 3D space. The framework proposes two novel modules: 1)\na Cross-Modal Deformable Transformer (CMDT) for object detection with high\naccuracy and acceptable amount of computation, and 2) a Reference\nTrajectory-based Multi-Class Transformer (RTMCT) for efficient and diverse\ntrajectory prediction of mult-class objects with flexible trajectory lengths.\nEvaluations on the CODa benchmark demonstrate superior performance over\nexisting methods across detection (+2.03% in mAP) and trajectory prediction\n(-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibits\nexceptional deployability - when implemented on a wheelchair robot with an\nentry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. To\nfacilitate reproducibility and practical deployment, we release the related\ncode of the method at https://github.com/TossherO/3D_Perception and its ROS\ninference version at https://github.com/TossherO/ros_packages.", "published": "2025-04-18 11:59:34", "link": "http://arxiv.org/abs/2504.13647v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Multi-modal Knowledge Graph Generation with Semantics-enriched Prompts", "abstract": "Multi-modal Knowledge Graphs (MMKGs) have been widely applied across various\ndomains for knowledge representation. However, the existing MMKGs are\nsignificantly fewer than required, and their construction faces numerous\nchallenges, particularly in ensuring the selection of high-quality,\ncontextually relevant images for knowledge graph enrichment. To address these\nchallenges, we present a framework for constructing MMKGs from conventional\nKGs. Furthermore, to generate higher-quality images that are more relevant to\nthe context in the given knowledge graph, we designed a neighbor selection\nmethod called Visualizable Structural Neighbor Selection (VSNS). This method\nconsists of two modules: Visualizable Neighbor Selection (VNS) and Structural\nNeighbor Selection (SNS). The VNS module filters relations that are difficult\nto visualize, while the SNS module selects neighbors that most effectively\ncapture the structural characteristics of the entity. To evaluate the quality\nof the generated images, we performed qualitative and quantitative evaluations\non two datasets, MKG-Y and DB15K. The experimental results indicate that using\nthe VSNS method to select neighbors results in higher-quality images that are\nmore relevant to the knowledge graph.", "published": "2025-04-18 11:12:49", "link": "http://arxiv.org/abs/2504.13631v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation", "abstract": "The rapid growth of the internet has made personalized recommendation systems\nindispensable. Graph-based sequential recommendation systems, powered by Graph\nNeural Networks (GNNs), effectively capture complex user-item interactions but\noften face challenges such as noise and static representations. In this paper,\nwe introduce the Adaptive Long-term Embedding with Denoising and Augmentation\nfor Recommendation (ALDA4Rec) method, a novel model that constructs an\nitem-item graph, filters noise through community detection, and enriches\nuser-item interactions. Graph Convolutional Networks (GCNs) are then employed\nto learn short-term representations, while averaging, GRUs, and attention\nmechanisms are utilized to model long-term embeddings. An MLP-based adaptive\nweighting strategy is further incorporated to dynamically optimize long-term\nuser preferences. Experiments conducted on four real-world datasets demonstrate\nthat ALDA4Rec outperforms state-of-the-art baselines, delivering notable\nimprovements in both accuracy and robustness. The source code is available at\nhttps://github.com/zahraakhlaghi/ALDA4Rec.", "published": "2025-04-18 10:42:16", "link": "http://arxiv.org/abs/2504.13614v1", "categories": ["cs.IR", "cs.AI", "cs.NE"], "primary_category": "cs.IR"}
{"title": "Entropic Time Schedulers for Generative Diffusion Models", "abstract": "The practical performance of generative diffusion models depends on the\nappropriate choice of the noise scheduling function, which can also be\nequivalently expressed as a time reparameterization. In this paper, we present\na time scheduler that selects sampling points based on entropy rather than\nuniform time spacing, ensuring that each point contributes an equal amount of\ninformation to the final generation. We prove that this time reparameterization\ndoes not depend on the initial choice of time. Furthermore, we provide a\ntractable exact formula to estimate this \\emph{entropic time} for a trained\nmodel using the training loss without substantial overhead. Alongside the\nentropic time, inspired by the optimality results, we introduce a rescaled\nentropic time. In our experiments with mixtures of Gaussian distributions and\nImageNet, we show that using the (rescaled) entropic times greatly improves the\ninference performance of trained models. In particular, we found that the image\nquality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can\nbe substantially increased by the rescaled entropic time reparameterization\nwithout increasing the number of function evaluations, with greater\nimprovements in the few NFEs regime.", "published": "2025-04-18 10:35:19", "link": "http://arxiv.org/abs/2504.13612v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FocusNet: Transformer-enhanced Polyp Segmentation with Local and Pooling Attention", "abstract": "Colonoscopy is vital in the early diagnosis of colorectal polyps. Regular\nscreenings can effectively prevent benign polyps from progressing to CRC. While\ndeep learning has made impressive strides in polyp segmentation, most existing\nmodels are trained on single-modality and single-center data, making them less\neffective in real-world clinical environments. To overcome these limitations,\nwe propose FocusNet, a Transformer-enhanced focus attention network designed to\nimprove polyp segmentation. FocusNet incorporates three essential modules: the\nCross-semantic Interaction Decoder Module (CIDM) for generating coarse\nsegmentation maps, the Detail Enhancement Module (DEM) for refining shallow\nfeatures, and the Focus Attention Module (FAM), to balance local detail and\nglobal context through local and pooling attention mechanisms. We evaluate our\nmodel on PolypDB, a newly introduced dataset with multi-modality and\nmulti-center data for building more reliable segmentation methods. Extensive\nexperiments showed that FocusNet consistently outperforms existing\nstate-of-the-art approaches with a high dice coefficients of 82.47% on the BLI\nmodality, 88.46% on FICE, 92.04% on LCI, 82.09% on the NBI and 93.42% on WLI\nmodality, demonstrating its accuracy and robustness across five different\nmodalities. The source code for FocusNet is available at\nhttps://github.com/JunZengz/FocusNet.", "published": "2025-04-18 09:59:26", "link": "http://arxiv.org/abs/2504.13597v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering", "abstract": "Traditional 3D scene understanding techniques are generally predicated on\nhand-annotated label sets, but in recent years a new class of open-vocabulary\n3D scene understanding techniques has emerged. Despite the success of this\nparadigm on small scenes, existing approaches cannot scale efficiently to\ncity-scale 3D datasets. In this paper, we present Hierarchical vocab-Agnostic\nExpert Clustering (HAEC), after the latin word for 'these', a superpoint graph\nclustering based approach which utilizes a novel mixture of experts graph\ntransformer for its backbone. We administer this highly scalable approach to\nthe first application of open-vocabulary scene understanding on the SensatUrban\ncity-scale dataset. We also demonstrate a synthetic labeling pipeline which is\nderived entirely from the raw point clouds with no hand-annotation. Our\ntechnique can help unlock complex operations on dense urban 3D scenes and open\na new path forward in the processing of digital twins.", "published": "2025-04-18 09:48:42", "link": "http://arxiv.org/abs/2504.13590v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RAG Without the Lag: Interactive Debugging for Retrieval-Augmented Generation Pipelines", "abstract": "Retrieval-augmented generation (RAG) pipelines have become the de-facto\napproach for building AI assistants with access to external, domain-specific\nknowledge. Given a user query, RAG pipelines typically first retrieve (R)\nrelevant information from external sources, before invoking a Large Language\nModel (LLM), augmented (A) with this information, to generate (G) responses.\nModern RAG pipelines frequently chain multiple retrieval and generation\ncomponents, in any order. However, developing effective RAG pipelines is\nchallenging because retrieval and generation components are intertwined, making\nit hard to identify which component(s) cause errors in the eventual output. The\nparameters with the greatest impact on output quality often require hours of\npre-processing after each change, creating prohibitively slow feedback cycles.\nTo address these challenges, we present RAGGY, a developer tool that combines a\nPython library of composable RAG primitives with an interactive interface for\nreal-time debugging. We contribute the design and implementation of RAGGY,\ninsights into expert debugging patterns through a qualitative study with 12\nengineers, and design implications for future RAG tools that better align with\ndevelopers' natural workflows.", "published": "2025-04-18 09:38:49", "link": "http://arxiv.org/abs/2504.13587v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration", "abstract": "Cross-workload design space exploration (DSE) is crucial in CPU architecture\ndesign. Existing DSE methods typically employ the transfer learning technique\nto leverage knowledge from source workloads, aiming to minimize the requirement\nof target workload simulation. However, these methods struggle with\noverfitting, data ambiguity, and workload dissimilarity.\n  To address these challenges, we reframe the cross-workload CPU DSE task as a\nfew-shot meta-learning problem and further introduce MetaDSE. By leveraging\nmodel agnostic meta-learning, MetaDSE swiftly adapts to new target workloads,\ngreatly enhancing the efficiency of cross-workload CPU DSE. Additionally,\nMetaDSE introduces a novel knowledge transfer method called the\nworkload-adaptive architectural mask algorithm, which uncovers the inherent\nproperties of the architecture. Experiments on SPEC CPU 2017 demonstrate that\nMetaDSE significantly reduces prediction error by 44.3\\% compared to the\nstate-of-the-art. MetaDSE is open-sourced and available at this\n\\href{https://anonymous.4open.science/r/Meta_DSE-02F8}{anonymous GitHub.}", "published": "2025-04-18 09:11:16", "link": "http://arxiv.org/abs/2504.13568v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "Zero-Shot Industrial Anomaly Segmentation with Image-Aware Prompt Generation", "abstract": "Anomaly segmentation is essential for industrial quality, maintenance, and\nstability. Existing text-guided zero-shot anomaly segmentation models are\neffective but rely on fixed prompts, limiting adaptability in diverse\nindustrial scenarios. This highlights the need for flexible, context-aware\nprompting strategies. We propose Image-Aware Prompt Anomaly Segmentation\n(IAP-AS), which enhances anomaly segmentation by generating dynamic,\ncontext-aware prompts using an image tagging model and a large language model\n(LLM). IAP-AS extracts object attributes from images to generate context-aware\nprompts, improving adaptability and generalization in dynamic and unstructured\nindustrial environments. In our experiments, IAP-AS improves the F1-max metric\nby up to 10%, demonstrating superior adaptability and generalization. It\nprovides a scalable solution for anomaly segmentation across industries", "published": "2025-04-18 08:58:40", "link": "http://arxiv.org/abs/2504.13560v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective", "abstract": "The Transformer model is widely used in various application areas of machine\nlearning, such as natural language processing. This paper investigates the\napproximation of the H\\\"older continuous function class\n$\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$\nby Transformers and constructs several Transformers that can overcome the curse\nof dimensionality. These Transformers consist of one self-attention layer with\none head and the softmax function as the activation function, along with\nseveral feedforward layers. For example, to achieve an approximation accuracy\nof $\\epsilon$, if the activation functions of the feedforward layers in the\nTransformer are ReLU and floor, only\n$\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ layers of feedforward layers\nare needed, with widths of these layers not exceeding\n$\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$.\nIf other activation functions are allowed in the feedforward layers, the width\nof the feedforward layers can be further reduced to a constant. These results\ndemonstrate that Transformers have a strong expressive capability. The\nconstruction in this paper is based on the Kolmogorov-Arnold Representation\nTheorem and does not require the concept of contextual mapping, hence our proof\nis more intuitively clear compared to previous Transformer approximation works.\nAdditionally, the translation technique proposed in this paper helps to apply\nthe previous approximation results of feedforward neural networks to\nTransformer research.", "published": "2025-04-18 08:56:53", "link": "http://arxiv.org/abs/2504.13558v1", "categories": ["cs.LG", "cs.AI", "41A25, 68T07, 68T50", "G.0"], "primary_category": "cs.LG"}
{"title": "Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning", "abstract": "Artificial Intelligence (AI)-driven convolutional neural networks enhance\nrescue, inspection, and surveillance tasks performed by low-altitude uncrewed\naerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown\nenvironments. However, their high computational demands often exceed a single\nUAV's capacity, leading to system instability, further exacerbated by the\nlimited and dynamic resources of GCNs. To address these challenges, this paper\nproposes a novel cooperation framework involving UAVs, ground-embedded robots\n(GERs), and high-altitude platforms (HAPs), which enable resource pooling\nthrough UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide\ncomputing services for UAV offloaded tasks. Specifically, we formulate the\nmulti-objective optimization problem of task assignment and exploration\noptimization in UAVs as a dynamic long-term optimization problem. Our objective\nis to minimize task completion time and energy consumption while ensuring\nsystem stability over time. To achieve this, we first employ the Lyapunov\noptimization technique to transform the original problem, with stability\nconstraints, into a per-slot deterministic problem. We then propose an\nalgorithm named HG-MADDPG, which combines the Hungarian algorithm with a\ngenerative diffusion model (GDM)-based multi-agent deep deterministic policy\ngradient (MADDPG) approach. We first introduce the Hungarian algorithm as a\nmethod for exploration area selection, enhancing UAV efficiency in interacting\nwith the environment. We then innovatively integrate the GDM and multi-agent\ndeep deterministic policy gradient (MADDPG) to optimize task assignment\ndecisions, such as task offloading and resource allocation. Simulation results\ndemonstrate the effectiveness of the proposed approach, with significant\nimprovements in task offloading efficiency, latency reduction, and system\nstability compared to baseline methods.", "published": "2025-04-18 08:44:06", "link": "http://arxiv.org/abs/2504.13554v1", "categories": ["cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Beyond One-Hot Labels: Semantic Mixing for Model Calibration", "abstract": "Model calibration seeks to ensure that models produce confidence scores that\naccurately reflect the true likelihood of their predictions being correct.\nHowever, existing calibration approaches are fundamentally tied to datasets of\none-hot labels implicitly assuming full certainty in all the annotations. Such\ndatasets are effective for classification but provides insufficient knowledge\nof uncertainty for model calibration, necessitating the curation of datasets\nwith numerically rich ground-truth confidence values. However, due to the\nscarcity of uncertain visual examples, such samples are not easily available as\nreal datasets. In this paper, we introduce calibration-aware data augmentation\nto create synthetic datasets of diverse samples and their ground-truth\nuncertainty. Specifically, we present Calibration-aware Semantic Mixing (CSM),\na novel framework that generates training samples with mixed class\ncharacteristics and annotates them with distinct confidence scores via\ndiffusion models. Based on this framework, we propose calibrated reannotation\nto tackle the misalignment between the annotated confidence score and the\nmixing ratio during the diffusion reverse process. Besides, we explore the loss\nfunctions that better fit the new data representation paradigm. Experimental\nresults demonstrate that CSM achieves superior calibration compared to the\nstate-of-the-art calibration approaches. Code is available at\ngithub.com/E-Galois/CSM.", "published": "2025-04-18 08:26:18", "link": "http://arxiv.org/abs/2504.13548v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SwitchMT: An Adaptive Context Switching Methodology for Scalable Multi-Task Learning in Intelligent Autonomous Agents", "abstract": "The ability to train intelligent autonomous agents (such as mobile robots) on\nmultiple tasks is crucial for adapting to dynamic real-world environments.\nHowever, state-of-the-art reinforcement learning (RL) methods only excel in\nsingle-task settings, and still struggle to generalize across multiple tasks\ndue to task interference. Moreover, real-world environments also demand the\nagents to have data stream processing capabilities. Toward this, a\nstate-of-the-art work employs Spiking Neural Networks (SNNs) to improve\nmulti-task learning by exploiting temporal information in data stream, while\nenabling lowpower/energy event-based operations. However, it relies on fixed\ncontext/task-switching intervals during its training, hence limiting the\nscalability and effectiveness of multi-task learning. To address these\nlimitations, we propose SwitchMT, a novel adaptive task-switching methodology\nfor RL-based multi-task learning in autonomous agents. Specifically, SwitchMT\nemploys the following key ideas: (1) a Deep Spiking Q-Network with active\ndendrites and dueling structure, that utilizes task-specific context signals to\ncreate specialized sub-networks; and (2) an adaptive task-switching policy that\nleverages both rewards and internal dynamics of the network parameters.\nExperimental results demonstrate that SwitchMT achieves superior performance in\nmulti-task learning compared to state-of-the-art methods. It achieves\ncompetitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6,\nand Enduro: 355.2) compared to the state-of-the-art, showing its better\ngeneralized learning capability. These results highlight the effectiveness of\nour SwitchMT methodology in addressing task interference while enabling\nmulti-task learning automation through adaptive task switching, thereby paving\nthe way for more efficient generalist agents with scalable multi-task learning\ncapabilities.", "published": "2025-04-18 08:12:59", "link": "http://arxiv.org/abs/2504.13541v1", "categories": ["cs.NE", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.NE"}
{"title": "Deep Learning Models Meet Financial Data Modalities", "abstract": "Algorithmic trading relies on extracting meaningful signals from diverse\nfinancial data sources, including candlestick charts, order statistics on put\nand canceled orders, traded volume data, limit order books, and news flow.\nWhile deep learning has demonstrated remarkable success in processing\nunstructured data and has significantly advanced natural language processing,\nits application to structured financial data remains an ongoing challenge. This\nstudy investigates the integration of deep learning models with financial data\nmodalities, aiming to enhance predictive performance in trading strategies and\nportfolio optimization. We present a novel approach to incorporating limit\norder book analysis into algorithmic trading by developing embedding techniques\nand treating sequential limit order book snapshots as distinct input channels\nin an image-based representation. Our methodology for processing limit order\nbook data achieves state-of-the-art performance in high-frequency trading\nalgorithms, underscoring the effectiveness of deep learning in financial\napplications.", "published": "2025-04-18 07:19:44", "link": "http://arxiv.org/abs/2504.13521v1", "categories": ["cs.LG", "cs.AI", "cs.CE", "q-fin.ST"], "primary_category": "cs.LG"}
{"title": "Optimizing Electric Vehicle Charging Station Locations: A Data-driven System with Multi-source Fusion", "abstract": "With the growing electric vehicles (EVs) charging demand, urban planners face\nthe challenges of providing charging infrastructure at optimal locations. For\nexample, range anxiety during long-distance travel and the inadequate\ndistribution of residential charging stations are the major issues many cities\nface. To achieve reasonable estimation and deployment of the charging demand,\nwe develop a data-driven system based on existing EV trips in New South Wales\n(NSW) state, Australia, incorporating multiple factors that enhance the\ngeographical feasibility of recommended charging stations. Our system\nintegrates data sources including EV trip data, geographical data such as route\ndata and Local Government Area (LGA) boundaries, as well as features like fire\nand flood risks, and Points of Interest (POIs). We visualize our results to\nintuitively demonstrate the findings from our data-driven, multi-source fusion\nsystem, and evaluate them through case studies. The outcome of this work can\nprovide a platform for discussion to develop new insights that could be used to\ngive guidance on where to position future EV charging stations.", "published": "2025-04-18 07:10:48", "link": "http://arxiv.org/abs/2504.13517v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Large Language Models for Validating Network Protocol Parsers", "abstract": "Network protocol parsers are essential for enabling correct and secure\ncommunication between devices. Bugs in these parsers can introduce critical\nvulnerabilities, including memory corruption, information leakage, and\ndenial-of-service attacks. An intuitive way to assess parser correctness is to\ncompare the implementation with its official protocol standard. However, this\ncomparison is challenging because protocol standards are typically written in\nnatural language, whereas implementations are in source code. Existing methods\nlike model checking, fuzzing, and differential testing have been used to find\nparsing bugs, but they either require significant manual effort or ignore the\nprotocol standards, limiting their ability to detect semantic violations. To\nenable more automated validation of parser implementations against protocol\nstandards, we propose PARVAL, a multi-agent framework built on large language\nmodels (LLMs). PARVAL leverages the capabilities of LLMs to understand both\nnatural language and code. It transforms both protocol standards and their\nimplementations into a unified intermediate representation, referred to as\nformat specifications, and performs a differential comparison to uncover\ninconsistencies. We evaluate PARVAL on the Bidirectional Forwarding Detection\n(BFD) protocol. Our experiments demonstrate that PARVAL successfully identifies\ninconsistencies between the implementation and its RFC standard, achieving a\nlow false positive rate of 5.6%. PARVAL uncovers seven unique bugs, including\nfive previously unknown issues.", "published": "2025-04-18 07:09:56", "link": "http://arxiv.org/abs/2504.13515v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Statistical Validation in Cultural Adaptations of Cognitive Tests: A Multi- Regional Systematic Review", "abstract": "This systematic review discusses the methodological approaches and\nstatistical confirmations of cross-cultural adaptations of cognitive evaluation\ntools used with different populations. The review considers six seminal studies\non the methodology of cultural adaptation in Europe, Asia, Africa, and South\nAmerica. The results indicate that proper adaptations need holistic models with\ndemographic changes, and education explained as much as 26.76% of the variance\nin MoCA-H scores. Cultural-linguistic factors explained 6.89% of the variance\nin European adaptations of MoCA-H; however, another study on adapted MMSE and\nBCSB among Brazilian Indigenous populations reported excellent diagnostic\nperformance, with a sensitivity of 94.4% and specificity of 99.2%. There was\n78.5% inter-rater agreement on the evaluation of cultural adaptation using the\nManchester Translation Evaluation Checklist. A paramount message of the paper\nis that community feedback is necessary for culturally appropriate preparation,\nstandardized translation protocols also must be included, along with robust\nstatistical validation methodologies for developing cognitive assessment\ninstruments. This review supplies evidence-based frameworks for the further\nadaptation of cognitive assessments in increasingly diverse global health\nsettings.", "published": "2025-04-18 06:25:02", "link": "http://arxiv.org/abs/2504.13495v1", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CY"}
{"title": "Creating 'Full-Stack' Hybrid Reasoning Systems that Prioritize and Enhance Human Intelligence", "abstract": "The idea of augmented or hybrid intelligence offers a compelling vision for\ncombining human and AI capabilities, especially in tasks where human wisdom,\nexpertise, or common sense are essential. Unfortunately, human reasoning can be\nflawed and shortsighted, resulting in adverse individual impacts or even\nlong-term societal consequences. While strong efforts are being made to develop\nand optimize the AI aspect of hybrid reasoning, the real urgency lies in\nfostering wiser and more intelligent human participation. Tools that enhance\ncritical thinking, ingenuity, expertise, and even wisdom could be essential in\naddressing the challenges of our emerging future. This paper proposes the\ndevelopment of generative AI-based tools that enhance both the human ability to\nreflect upon a problem as well as the ability to explore the technical aspects\nof it. A high-level model is also described for integrating AI and human\ncapabilities in a way that centralizes human participation and control.", "published": "2025-04-18 05:38:21", "link": "http://arxiv.org/abs/2504.13477v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization", "abstract": "Traditional temporal action localization (TAL) methods rely on large amounts\nof detailed annotated data, whereas few-shot TAL reduces this dependence by\nusing only a few training samples to identify unseen action categories.\nHowever, existing few-shot TAL methods typically focus solely on video-level\ninformation, neglecting textual information, which can provide valuable\nsemantic support for the localization task. Therefore, we propose a new\nfew-shot temporal action localization method by Chain-of-Thought textual\nreasoning to improve localization performance. Specifically, we design a novel\nfew-shot learning framework that leverages textual semantic information to\nenhance the model's ability to capture action commonalities and variations,\nwhich includes a semantic-aware text-visual alignment module designed to align\nthe query and support videos at different levels. Meanwhile, to better express\nthe temporal dependencies and causal relationships between actions at the\ntextual level to assist action localization, we design a Chain of Thought\n(CoT)-like reasoning method that progressively guides the Vision Language Model\n(VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for\nvideos. The generated texts can capture more variance of action than visual\nfeatures. We conduct extensive experiments on the publicly available\nActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named\nHuman-related Anomaly Localization and explore the application of the TAL task\nin human anomaly detection. The experimental results demonstrate that our\nproposed method significantly outperforms existing methods in single-instance\nand multi-instance scenarios. We will release our code, data and benchmark.", "published": "2025-04-18 04:35:35", "link": "http://arxiv.org/abs/2504.13460v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Ascribe New Dimensions to Scientific Data Visualization with VR", "abstract": "For over half a century, the computer mouse has been the primary tool for\ninteracting with digital data, yet it remains a limiting factor in exploring\ncomplex, multi-scale scientific images. Traditional 2D visualization methods\nhinder intuitive analysis of inherently 3D structures. Virtual Reality (VR)\noffers a transformative alternative, providing immersive, interactive\nenvironments that enhance data comprehension. This article introduces\nASCRIBE-VR, a VR platform of Autonomous Solutions for Computational Research\nwith Immersive Browsing \\& Exploration, which integrates AI-driven algorithms\nwith scientific images. ASCRIBE-VR enables multimodal analysis, structural\nassessments, and immersive visualization, supporting scientific visualization\nof advanced datasets such as X-ray CT, Magnetic Resonance, and synthetic 3D\nimaging. Our VR tools, compatible with Meta Quest, can consume the output of\nour AI-based segmentation and iterative feedback processes to enable seamless\nexploration of large-scale 3D images. By merging AI-generated results with VR\nvisualization, ASCRIBE-VR enhances scientific discovery, bridging the gap\nbetween computational analysis and human intuition in materials research,\nconnecting human-in-the-loop with digital twins.", "published": "2025-04-18 03:59:39", "link": "http://arxiv.org/abs/2504.13448v1", "categories": ["cs.GR", "cs.AI", "cs.CE"], "primary_category": "cs.GR"}
{"title": "Trust, but verify", "abstract": "Decentralized AI agent networks, such as Gaia, allows individuals to run\ncustomized LLMs on their own computers and then provide services to the public.\nHowever, in order to maintain service quality, the network must verify that\nindividual nodes are running their designated LLMs. In this paper, we\ndemonstrate that in a cluster of mostly honest nodes, we can detect nodes that\nrun unauthorized or incorrect LLM through social consensus of its peers. We\nwill discuss the algorithm and experimental data from the Gaia network. We will\nalso discuss the intersubjective validation system, implemented as an\nEigenLayer AVS to introduce financial incentives and penalties to encourage\nhonest behavior from LLM nodes.", "published": "2025-04-18 03:49:53", "link": "http://arxiv.org/abs/2504.13443v1", "categories": ["cs.AI", "cs.DC", "cs.MA", "econ.GN", "q-fin.EC"], "primary_category": "cs.AI"}
{"title": "Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs", "abstract": "Given the critical role of graphs in real-world applications and their\nhigh-security requirements, improving the ability of graph neural networks\n(GNNs) to detect out-of-distribution (OOD) data is an urgent research problem.\nThe recent work GNNSAFE proposes a framework based on the aggregation of\nnegative energy scores that significantly improves the performance of GNNs to\ndetect node-level OOD data. However, our study finds that score aggregation\namong nodes is susceptible to extreme values due to the unboundedness of the\nnegative energy scores and logit shifts, which severely limits the accuracy of\nGNNs in detecting node-level OOD data. In this paper, we propose NODESAFE:\nreducing the generation of extreme scores of nodes by adding two optimization\nterms that make the negative energy scores bounded and mitigate the logit\nshift. Experimental results show that our approach dramatically improves the\nability of GNNs to detect OOD data at the node level, e.g., in detecting OOD\ndata induced by Structure Manipulation, the metric of FPR95 (lower is better)\nin scenarios without (with) OOD data exposure are reduced from the current SOTA\nby 28.4% (22.7%).", "published": "2025-04-18 03:01:00", "link": "http://arxiv.org/abs/2504.13429v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DADU: Dual Attention-based Deep Supervised UNet for Automated Semantic Segmentation of Cardiac Images", "abstract": "We propose an enhanced deep learning-based model for image segmentation of\nthe left and right ventricles and myocardium scar tissue from cardiac magnetic\nresonance (CMR) images. The proposed technique integrates UNet, channel and\nspatial attention, edge-detection based skip-connection and deep supervised\nlearning to improve the accuracy of the CMR image-segmentation. Images are\nprocessed using multiple channels to generate multiple feature-maps. We built a\ndual attention-based model to integrate channel and spatial attention. The use\nof extracted edges in skip connection improves the reconstructed images from\nfeature-maps. The use of deep supervision reduces vanishing gradient problems\ninherent in classification based on deep neural networks. The algorithms for\ndual attention-based model, corresponding implementation and performance\nresults are described. The performance results show that this approach has\nattained high accuracy: 98% Dice Similarity Score (DSC) and significantly lower\nHausdorff Distance (HD). The performance results outperform other leading\ntechniques both in DSC and HD.", "published": "2025-04-18 02:22:45", "link": "http://arxiv.org/abs/2504.13415v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "I.4.6; I.2; I.5.2; I.5.1"], "primary_category": "eess.IV"}
{"title": "Adaptive Non-local Observable on Quantum Neural Networks", "abstract": "Conventional Variational Quantum Circuits (VQCs) for Quantum Machine Learning\ntypically rely on a fixed Hermitian observable, often built from Pauli\noperators. Inspired by the Heisenberg picture, we propose an adaptive non-local\nmeasurement framework that substantially increases the model complexity of the\nquantum circuits. Our introduction of dynamical Hermitian observables with\nevolving parameters shows that optimizing VQC rotations corresponds to tracing\na trajectory in the observable space. This viewpoint reveals that standard VQCs\nare merely a special case of the Heisenberg representation.\n  Furthermore, we show that properly incorporating variational rotations with\nnon-local observables enhances qubit interaction and information mixture,\nadmitting flexible circuit designs. Two non-local measurement schemes are\nintroduced, and numerical simulations on classification tasks confirm that our\napproach outperforms conventional VQCs, yielding a more powerful and\nresource-efficient approach as a Quantum Neural Network.", "published": "2025-04-18 02:20:12", "link": "http://arxiv.org/abs/2504.13414v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "LoRA-Based Continual Learning with Constraints on Critical Parameter Changes", "abstract": "LoRA-based continual learning represents a promising avenue for leveraging\npre-trained models in downstream continual learning tasks. Recent studies have\nshown that orthogonal LoRA tuning effectively mitigates forgetting. However,\nthis work unveils that under orthogonal LoRA tuning, the critical parameters\nfor pre-tasks still change notably after learning post-tasks. To address this\nproblem, we directly propose freezing the most critical parameter matrices in\nthe Vision Transformer (ViT) for pre-tasks before learning post-tasks. In\naddition, building on orthogonal LoRA tuning, we propose orthogonal LoRA\ncomposition (LoRAC) based on QR decomposition, which may further enhance the\nplasticity of our method. Elaborate ablation studies and extensive comparisons\ndemonstrate the effectiveness of our proposed method. Our results indicate that\nour method achieves state-of-the-art (SOTA) performance on several well-known\ncontinual learning benchmarks. For instance, on the Split CIFAR-100 dataset,\nour method shows a 6.35\\% improvement in accuracy and a 3.24\\% reduction in\nforgetting compared to previous methods. Our code is available at\nhttps://github.com/learninginvision/LoRAC-IPC.", "published": "2025-04-18 02:08:19", "link": "http://arxiv.org/abs/2504.13407v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety", "abstract": "Detecting anomalous hazards in visual data, particularly in video streams, is\na critical challenge in autonomous driving. Existing models often struggle with\nunpredictable, out-of-label hazards due to their reliance on predefined object\ncategories. In this paper, we propose a multimodal approach that integrates\nvision-language reasoning with zero-shot object detection to improve hazard\nidentification and explanation. Our pipeline consists of a Vision-Language\nModel (VLM), a Large Language Model (LLM), in order to detect hazardous objects\nwithin a traffic scene. We refine object detection by incorporating OpenAI's\nCLIP model to match predicted hazards with bounding box annotations, improving\nlocalization accuracy. To assess model performance, we create a ground truth\ndataset by denoising and extending the foundational COOOL\n(Challenge-of-Out-of-Label) anomaly detection benchmark dataset with complete\nnatural language descriptions for hazard annotations. We define a means of\nhazard detection and labeling evaluation on the extended dataset using cosine\nsimilarity. This evaluation considers the semantic similarity between the\npredicted hazard description and the annotated ground truth for each video.\nAdditionally, we release a set of tools for structuring and managing\nlarge-scale hazard detection datasets. Our findings highlight the strengths and\nlimitations of current vision-language-based approaches, offering insights into\nfuture improvements in autonomous hazard detection systems. Our models,\nscripts, and data can be found at https://github.com/mi3labucm/COOOLER.git", "published": "2025-04-18 01:25:02", "link": "http://arxiv.org/abs/2504.13399v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Cardiac MRI Semantic Segmentation for Ventricles and Myocardium using Deep Learning", "abstract": "Automated noninvasive cardiac diagnosis plays a critical role in the early\ndetection of cardiac disorders and cost-effective clinical management.\nAutomated diagnosis involves the automated segmentation and analysis of cardiac\nimages. Precise delineation of cardiac substructures and extraction of their\nmorphological attributes are essential for evaluating the cardiac function, and\ndiagnosing cardiovascular disease such as cardiomyopathy, valvular diseases,\nabnormalities related to septum perforations, and blood-flow rate. Semantic\nsegmentation labels the CMR image at the pixel level, and localizes its\nsubcomponents to facilitate the detection of abnormalities, including\nabnormalities in cardiac wall motion in an aging heart with muscle\nabnormalities, vascular abnormalities, and valvular abnormalities. In this\npaper, we describe a model to improve semantic segmentation of CMR images. The\nmodel extracts edge-attributes and context information during down-sampling of\nthe U-Net and infuses this information during up-sampling to localize three\nmajor cardiac structures: left ventricle cavity (LV); right ventricle cavity\n(RV); and LV myocardium (LMyo). We present an algorithm and performance\nresults. A comparison of our model with previous leading models, using\nsimilarity metrics between actual image and segmented image, shows that our\napproach improves Dice similarity coefficient (DSC) by 2%-11% and lowers\nHausdorff distance (HD) by 1.6 to 5.7 mm.", "published": "2025-04-18 00:54:30", "link": "http://arxiv.org/abs/2504.13391v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "I.4.6; I.2; I.5.2; I.5.1"], "primary_category": "eess.IV"}
{"title": "Outlier-Robust Multi-Model Fitting on Quantum Annealers", "abstract": "Multi-model fitting (MMF) presents a significant challenge in Computer\nVision, particularly due to its combinatorial nature. While recent advancements\nin quantum computing offer promise for addressing NP-hard problems, existing\nquantum-based approaches for model fitting are either limited to a single model\nor consider multi-model scenarios within outlier-free datasets. This paper\nintroduces a novel approach, the robust quantum multi-model fitting (R-QuMF)\nalgorithm, designed to handle outliers effectively. Our method leverages the\nintrinsic capabilities of quantum hardware to tackle combinatorial challenges\ninherent in MMF tasks, and it does not require prior knowledge of the exact\nnumber of models, thereby enhancing its practical applicability. By formulating\nthe problem as a maximum set coverage task for adiabatic quantum computers\n(AQC), R-QuMF outperforms existing quantum techniques, demonstrating superior\nperformance across various synthetic and real-world 3D datasets. Our findings\nunderscore the potential of quantum computing in addressing the complexities of\nMMF, especially in real-world scenarios with noisy and outlier-prone data.", "published": "2025-04-18 17:59:53", "link": "http://arxiv.org/abs/2504.13836v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning", "abstract": "Humans can develop internal world models that encode common sense knowledge,\ntelling them how the world works and predicting the consequences of their\nactions. This concept has emerged as a promising direction for establishing\ngeneral-purpose machine-learning models in recent preliminary works, e.g., for\nvisual representation learning. In this paper, we present CheXWorld, the first\neffort towards a self-supervised world model for radiographic images.\nSpecifically, our work develops a unified framework that simultaneously models\nthree aspects of medical knowledge essential for qualified radiologists,\nincluding 1) local anatomical structures describing the fine-grained\ncharacteristics of local tissues (e.g., architectures, shapes, and textures);\n2) global anatomical layouts describing the global organization of the human\nbody (e.g., layouts of organs and skeletons); and 3) domain variations that\nencourage CheXWorld to model the transitions across different appearance\ndomains of radiographs (e.g., varying clarity, contrast, and exposure caused by\ncollecting radiographs from different hospitals, devices, or patients).\nEmpirically, we design tailored qualitative and quantitative analyses,\nrevealing that CheXWorld successfully captures these three dimensions of\nmedical knowledge. Furthermore, transfer learning experiments across eight\nmedical image classification and segmentation benchmarks showcase that\nCheXWorld significantly outperforms existing SSL methods and large-scale\nmedical foundation models. Code & pre-trained models are available at\nhttps://github.com/LeapLabTHU/CheXWorld.", "published": "2025-04-18 17:50:43", "link": "http://arxiv.org/abs/2504.13820v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RefComp: A Reference-guided Unified Framework for Unpaired Point Cloud Completion", "abstract": "The unpaired point cloud completion task aims to complete a partial point\ncloud by using models trained with no ground truth. Existing unpaired point\ncloud completion methods are class-aware, i.e., a separate model is needed for\neach object class. Since they have limited generalization capabilities, these\nmethods perform poorly in real-world scenarios when confronted with a wide\nrange of point clouds of generic 3D objects. In this paper, we propose a novel\nunpaired point cloud completion framework, namely the Reference-guided\nCompletion (RefComp) framework, which attains strong performance in both the\nclass-aware and class-agnostic training settings. The RefComp framework\ntransforms the unpaired completion problem into a shape translation problem,\nwhich is solved in the latent feature space of the partial point clouds. To\nthis end, we introduce the use of partial-complete point cloud pairs, which are\nretrieved by using the partial point cloud to be completed as a template. These\npoint cloud pairs are used as reference data to guide the completion process.\nOur RefComp framework uses a reference branch and a target branch with shared\nparameters for shape fusion and shape translation via a Latent Shape Fusion\nModule (LSFM) to enhance the structural features along the completion pipeline.\nExtensive experiments demonstrate that the RefComp framework achieves not only\nstate-of-the-art performance in the class-aware training setting but also\ncompetitive results in the class-agnostic training setting on both virtual\nscans and real-world datasets.", "published": "2025-04-18 16:40:16", "link": "http://arxiv.org/abs/2504.13788v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fighting Fires from Space: Leveraging Vision Transformers for Enhanced Wildfire Detection and Characterization", "abstract": "Wildfires are increasing in intensity, frequency, and duration across large\nparts of the world as a result of anthropogenic climate change. Modern hazard\ndetection and response systems that deal with wildfires are under-equipped for\nsustained wildfire seasons. Recent work has proved automated wildfire detection\nusing Convolutional Neural Networks (CNNs) trained on satellite imagery are\ncapable of high-accuracy results. However, CNNs are computationally expensive\nto train and only incorporate local image context. Recently, Vision\nTransformers (ViTs) have gained popularity for their efficient training and\ntheir ability to include both local and global contextual information. In this\nwork, we show that ViT can outperform well-trained and specialized CNNs to\ndetect wildfires on a previously published dataset of LandSat-8 imagery. One of\nour ViTs outperforms the baseline CNN comparison by 0.92%. However, we find our\nown implementation of CNN-based UNet to perform best in every category, showing\ntheir sustained utility in image tasks. Overall, ViTs are comparably capable in\ndetecting wildfires as CNNs, though well-tuned CNNs are still the best\ntechnique for detecting wildfire with our UNet providing an IoU of 93.58%,\nbetter than the baseline UNet by some 4.58%.", "published": "2025-04-18 16:25:54", "link": "http://arxiv.org/abs/2504.13776v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Fragile Watermarking for Image Certification Using Deep Steganographic Embedding", "abstract": "Modern identity verification systems increasingly rely on facial images\nembedded in biometric documents such as electronic passports. To ensure global\ninteroperability and security, these images must comply with strict standards\ndefined by the International Civil Aviation Organization (ICAO), which specify\nacquisition, quality, and format requirements. However, once issued, these\nimages may undergo unintentional degradations (e.g., compression, resizing) or\nmalicious manipulations (e.g., morphing) and deceive facial recognition\nsystems. In this study, we explore fragile watermarking, based on deep\nsteganographic embedding as a proactive mechanism to certify the authenticity\nof ICAO-compliant facial images. By embedding a hidden image within the\nofficial photo at the time of issuance, we establish an integrity marker that\nbecomes sensitive to any post-issuance modification. We assess how a range of\nimage manipulations affects the recovered hidden image and show that\ndegradation artifacts can serve as robust forensic cues. Furthermore, we\npropose a classification framework that analyzes the revealed content to detect\nand categorize the type of manipulation applied. Our experiments demonstrate\nhigh detection accuracy, including cross-method scenarios with multiple deep\nsteganography-based models. These findings support the viability of fragile\nwatermarking via steganographic embedding as a valuable tool for biometric\ndocument integrity verification.", "published": "2025-04-18 15:51:56", "link": "http://arxiv.org/abs/2504.13759v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "DAM-Net: Domain Adaptation Network with Micro-Labeled Fine-Tuning for Change Detection", "abstract": "Change detection (CD) in remote sensing imagery plays a crucial role in\nvarious applications such as urban planning, damage assessment, and resource\nmanagement. While deep learning approaches have significantly advanced CD\nperformance, current methods suffer from poor domain adaptability, requiring\nextensive labeled data for retraining when applied to new scenarios. This\nlimitation severely restricts their practical applications across different\ndatasets. In this work, we propose DAM-Net: a Domain Adaptation Network with\nMicro-Labeled Fine-Tuning for CD. Our network introduces adversarial domain\nadaptation to CD for, utilizing a specially designed segmentation-discriminator\nand alternating training strategy to enable effective transfer between domains.\nAdditionally, we propose a novel Micro-Labeled Fine-Tuning approach that\nstrategically selects and labels a minimal amount of samples (less than 1%) to\nenhance domain adaptation. The network incorporates a Multi-Temporal\nTransformer for feature fusion and optimized backbone structure based on\nprevious research. Experiments conducted on the LEVIR-CD and WHU-CD datasets\ndemonstrate that DAM-Net significantly outperforms existing domain adaptation\nmethods, achieving comparable performance to semi-supervised approaches that\nrequire 10% labeled data while using only 0.3% labeled samples. Our approach\nsignificantly advances cross-dataset CD applications and provides a new\nparadigm for efficient domain adaptation in remote sensing. The source code of\nDAM-Net will be made publicly available upon publication.", "published": "2025-04-18 15:29:57", "link": "http://arxiv.org/abs/2504.13748v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LimitNet: Progressive, Content-Aware Image Offloading for Extremely Weak Devices & Networks", "abstract": "IoT devices have limited hardware capabilities and are often deployed in\nremote areas. Consequently, advanced vision models surpass such devices'\nprocessing and storage capabilities, requiring offloading of such tasks to the\ncloud. However, remote areas often rely on LPWANs technology with limited\nbandwidth, high packet loss rates, and extremely low duty cycles, which makes\nfast offloading for time-sensitive inference challenging. Today's approaches,\nwhich are deployable on weak devices, generate a non-progressive bit stream,\nand therefore, their decoding quality suffers strongly when data is only\npartially available on the cloud at a deadline due to limited bandwidth or\npacket losses.\n  In this paper, we introduce LimitNet, a progressive, content-aware image\ncompression model designed for extremely weak devices and networks. LimitNet's\nlightweight progressive encoder prioritizes critical data during transmission\nbased on the content of the image, which gives the cloud the opportunity to run\ninference even with partial data availability.\n  Experimental results demonstrate that LimitNet, on average, compared to SOTA,\nachieves 14.01 p.p. (percentage point) higher accuracy on ImageNet1000, 18.01\npp on CIFAR100, and 0.1 higher mAP@0.5 on COCO. Also, on average, LimitNet\nsaves 61.24% bandwidth on ImageNet1000, 83.68% on CIFAR100, and 42.25% on the\nCOCO dataset compared to SOTA, while it only has 4% more encoding time compared\nto JPEG (with a fixed quality) on STM32F7 (Cortex-M7).", "published": "2025-04-18 15:04:53", "link": "http://arxiv.org/abs/2504.13736v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "MLEP: Multi-granularity Local Entropy Patterns for Universal AI-generated Image Detection", "abstract": "Advancements in image generation technologies have raised significant\nconcerns about their potential misuse, such as producing misinformation and\ndeepfakes. Therefore, there is an urgent need for effective methods to detect\nAI-generated images (AIGI). Despite progress in AIGI detection, achieving\nreliable performance across diverse generation models and scenes remains\nchallenging due to the lack of source-invariant features and limited\ngeneralization capabilities in existing methods. In this work, we explore the\npotential of using image entropy as a cue for AIGI detection and propose\nMulti-granularity Local Entropy Patterns (MLEP), a set of entropy feature maps\ncomputed across shuffled small patches over multiple image scaled. MLEP\ncomprehensively captures pixel relationships across dimensions and scales while\nsignificantly disrupting image semantics, reducing potential content bias.\nLeveraging MLEP, a robust CNN-based classifier for AIGI detection can be\ntrained. Extensive experiments conducted in an open-world scenario, evaluating\nimages synthesized by 32 distinct generative models, demonstrate significant\nimprovements over state-of-the-art methods in both accuracy and generalization.", "published": "2025-04-18 14:50:23", "link": "http://arxiv.org/abs/2504.13726v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM", "abstract": "Models and methods originally developed for novel view synthesis and scene\nrendering, such as Neural Radiance Fields (NeRF) and Gaussian Splatting, are\nincreasingly being adopted as representations in Simultaneous Localization and\nMapping (SLAM). However, existing datasets fail to include the specific\nchallenges of both fields, such as multimodality and sequentiality in SLAM or\ngeneralization across viewpoints and illumination conditions in neural\nrendering. To bridge this gap, we introduce SLAM&Render, a novel dataset\ndesigned to benchmark methods in the intersection between SLAM and novel view\nrendering. It consists of 40 sequences with synchronized RGB, depth, IMU, robot\nkinematic data, and ground-truth pose streams. By releasing robot kinematic\ndata, the dataset also enables the assessment of novel SLAM strategies when\napplied to robot manipulators. The dataset sequences span five different setups\nfeaturing consumer and industrial objects under four different lighting\nconditions, with separate training and test trajectories per scene, as well as\nobject rearrangements. Our experimental results, obtained with several\nbaselines from the literature, validate SLAM&Render as a relevant benchmark for\nthis emerging research area.", "published": "2025-04-18 14:28:34", "link": "http://arxiv.org/abs/2504.13713v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Few-Shot Referring Video Single- and Multi-Object Segmentation via Cross-Modal Affinity with Instance Sequence Matching", "abstract": "Referring video object segmentation (RVOS) aims to segment objects in videos\nguided by natural language descriptions. We propose FS-RVOS, a\nTransformer-based model with two key components: a cross-modal affinity module\nand an instance sequence matching strategy, which extends FS-RVOS to\nmulti-object segmentation (FS-RVMOS). Experiments show FS-RVOS and FS-RVMOS\noutperform state-of-the-art methods across diverse benchmarks, demonstrating\nsuperior robustness and accuracy.", "published": "2025-04-18 14:19:07", "link": "http://arxiv.org/abs/2504.13710v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Green Robotic Mixed Reality with Gaussian Splatting", "abstract": "Realizing green communication in robotic mixed reality (RoboMR) systems\npresents a challenge, due to the necessity of uploading high-resolution images\nat high frequencies through wireless channels. This paper proposes Gaussian\nsplatting (GS) RoboMR (GSRMR), which achieves a lower energy consumption and\nmakes a concrete step towards green RoboMR. The crux to GSRMR is to build a GS\nmodel which enables the simulator to opportunistically render a photo-realistic\nview from the robot's pose, thereby reducing the need for excessive image\nuploads. Since the GS model may involve discrepancies compared to the actual\nenvironments, a GS cross-layer optimization (GSCLO) framework is further\nproposed, which jointly optimizes content switching (i.e., deciding whether to\nupload image or not) and power allocation across different frames. The GSCLO\nproblem is solved by an accelerated penalty optimization (APO) algorithm.\nExperiments demonstrate that the proposed GSRMR reduces the communication\nenergy by over 10x compared with RoboMR. Furthermore, the proposed GSRMR with\nAPO outperforms extensive baseline schemes, in terms of peak signal-to-noise\nratio (PSNR) and structural similarity index measure (SSIM).", "published": "2025-04-18 13:57:28", "link": "http://arxiv.org/abs/2504.13697v1", "categories": ["cs.RO", "cs.CV", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Zebrafish Counting Using Event Stream Data", "abstract": "Zebrafish share a high degree of homology with human genes and are commonly\nused as model organism in biomedical research. For medical laboratories,\ncounting zebrafish is a daily task. Due to the tiny size of zebrafish, manual\nvisual counting is challenging. Existing counting methods are either not\napplicable to small fishes or have too many limitations. The paper proposed a\nzebrafish counting algorithm based on the event stream data. Firstly, an event\ncamera is applied for data acquisition. Secondly, camera calibration and image\nfusion were preformed successively. Then, the trajectory information was used\nto improve the counting accuracy. Finally, the counting results were averaged\nover an empirical of period and rounded up to get the final results. To\nevaluate the accuracy of the algorithm, 20 zebrafish were put in a four-liter\nbreeding tank. Among 100 counting trials, the average accuracy reached 97.95%.\nAs compared with traditional algorithms, the proposed one offers a simpler\nimplementation and achieves higher accuracy.", "published": "2025-04-18 13:51:29", "link": "http://arxiv.org/abs/2504.13692v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Analysing the Robustness of Vision-Language-Models to Common Corruptions", "abstract": "Vision-language models (VLMs) have demonstrated impressive capabilities in\nunderstanding and reasoning about visual and textual content. However, their\nrobustness to common image corruptions remains under-explored. In this work, we\npresent the first comprehensive analysis of VLM robustness across 19 corruption\ntypes from the ImageNet-C benchmark, spanning four categories: noise, blur,\nweather, and digital distortions. We introduce two new benchmarks, TextVQA-C\nand GQA-C, to systematically evaluate how corruptions affect scene text\nunderstanding and object-based reasoning, respectively. Our analysis reveals\nthat transformer-based VLMs exhibit distinct vulnerability patterns across\ntasks: text recognition deteriorates most severely under blur and snow\ncorruptions, while object reasoning shows higher sensitivity to corruptions\nsuch as frost and impulse noise. We connect these observations to the\nfrequency-domain characteristics of different corruptions, revealing how\ntransformers' inherent bias toward low-frequency processing explains their\ndifferential robustness patterns. Our findings provide valuable insights for\ndeveloping more corruption-robust vision-language models for real-world\napplications.", "published": "2025-04-18 13:46:32", "link": "http://arxiv.org/abs/2504.13690v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EyecareGPT: Boosting Comprehensive Ophthalmology Understanding with Tailored Dataset, Benchmark and Model", "abstract": "Medical Large Vision-Language Models (Med-LVLMs) demonstrate significant\npotential in healthcare, but their reliance on general medical data and\ncoarse-grained global visual understanding limits them in intelligent\nophthalmic diagnosis. Currently, intelligent ophthalmic diagnosis faces three\nmajor challenges: (i) Data. The lack of deeply annotated, high-quality,\nmulti-modal ophthalmic visual instruction data; (ii) Benchmark. The absence of\na comprehensive and systematic benchmark for evaluating diagnostic performance;\n(iii) Model. The difficulty of adapting holistic visual architectures to\nfine-grained, region-specific ophthalmic lesion identification. In this paper,\nwe propose the Eyecare Kit, which systematically tackles the aforementioned\nthree key challenges with the tailored dataset, benchmark and model: First, we\nconstruct a multi-agent data engine with real-life ophthalmology data to\nproduce Eyecare-100K, a high-quality ophthalmic visual instruction dataset.\nSubsequently, we design Eyecare-Bench, a benchmark that comprehensively\nevaluates the overall performance of LVLMs on intelligent ophthalmic diagnosis\ntasks across multiple dimensions. Finally, we develop the EyecareGPT, optimized\nfor fine-grained ophthalmic visual understanding thoroughly, which incorporates\nan adaptive resolution mechanism and a layer-wise dense connector. Extensive\nexperimental results indicate that the EyecareGPT achieves state-of-the-art\nperformance in a range of ophthalmic tasks, underscoring its significant\npotential for the advancement of open research in intelligent ophthalmic\ndiagnosis. Our project is available at https://github.com/DCDmllm/EyecareGPT.", "published": "2025-04-18 12:09:15", "link": "http://arxiv.org/abs/2504.13650v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Pothole Detection and Characterization: Integrated Segmentation and Depth Estimation in Road Anomaly Systems", "abstract": "Road anomaly detection plays a crucial role in road maintenance and in\nenhancing the safety of both drivers and vehicles. Recent machine learning\napproaches for road anomaly detection have overcome the tedious and\ntime-consuming process of manual analysis and anomaly counting; however, they\noften fall short in providing a complete characterization of road potholes. In\nthis paper, we leverage transfer learning by adopting a pre-trained YOLOv8-seg\nmodel for the automatic characterization of potholes using digital images\ncaptured from a dashboard-mounted camera. Our work includes the creation of a\nnovel dataset, comprising both images and their corresponding depth maps,\ncollected from diverse road environments in Al-Khobar city and the KFUPM campus\nin Saudi Arabia. Our approach performs pothole detection and segmentation to\nprecisely localize potholes and calculate their area. Subsequently, the\nsegmented image is merged with its depth map to extract detailed depth\ninformation about the potholes. This integration of segmentation and depth data\noffers a more comprehensive characterization compared to previous deep\nlearning-based road anomaly detection systems. Overall, this method not only\nhas the potential to significantly enhance autonomous vehicle navigation by\nimproving the detection and characterization of road hazards but also assists\nroad maintenance authorities in responding more effectively to road damage.", "published": "2025-04-18 11:59:38", "link": "http://arxiv.org/abs/2504.13648v1", "categories": ["cs.CV", "cs.SY", "eess.SY"], "primary_category": "cs.CV"}
{"title": "Efficient Parameter Adaptation for Multi-Modal Medical Image Segmentation and Prognosis", "abstract": "Cancer detection and prognosis relies heavily on medical imaging,\nparticularly CT and PET scans. Deep Neural Networks (DNNs) have shown promise\nin tumor segmentation by fusing information from these modalities. However, a\ncritical bottleneck exists: the dependency on CT-PET data concurrently for\ntraining and inference, posing a challenge due to the limited availability of\nPET scans. Hence, there is a clear need for a flexible and efficient framework\nthat can be trained with the widely available CT scans and can be still adapted\nfor PET scans when they become available. In this work, we propose a\nparameter-efficient multi-modal adaptation (PEMMA) framework for lightweight\nupgrading of a transformer-based segmentation model trained only on CT scans\nsuch that it can be efficiently adapted for use with PET scans when they become\navailable. This framework is further extended to perform prognosis task\nmaintaining the same efficient cross-modal fine-tuning approach. The proposed\napproach is tested with two well-known segementation backbones, namely UNETR\nand Swin UNETR. Our approach offers two main advantages. Firstly, we leverage\nthe inherent modularity of the transformer architecture and perform low-rank\nadaptation (LoRA) as well as decomposed low-rank adaptation (DoRA) of the\nattention weights to achieve parameter-efficient adaptation. Secondly, by\nminimizing cross-modal entanglement, PEMMA allows updates using only one\nmodality without causing catastrophic forgetting in the other. Our method\nachieves comparable performance to early fusion, but with only 8% of the\ntrainable parameters, and demonstrates a significant +28% Dice score\nimprovement on PET scans when trained with a single modality. Furthermore, in\nprognosis, our method improves the concordance index by +10% when adapting a\nCT-pretrained model to include PET scans, and by +23% when adapting for both\nPET and EHR data.", "published": "2025-04-18 11:52:21", "link": "http://arxiv.org/abs/2504.13645v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "DenSe-AdViT: A novel Vision Transformer for Dense SAR Object Detection", "abstract": "Vision Transformer (ViT) has achieved remarkable results in object detection\nfor synthetic aperture radar (SAR) images, owing to its exceptional ability to\nextract global features. However, it struggles with the extraction of\nmulti-scale local features, leading to limited performance in detecting small\ntargets, especially when they are densely arranged. Therefore, we propose\nDensity-Sensitive Vision Transformer with Adaptive Tokens (DenSe-AdViT) for\ndense SAR target detection. We design a Density-Aware Module (DAM) as a\npreliminary component that generates a density tensor based on target\ndistribution. It is guided by a meticulously crafted objective metric, enabling\nprecise and effective capture of the spatial distribution and density of\nobjects. To integrate the multi-scale information enhanced by convolutional\nneural networks (CNNs) with the global features derived from the Transformer,\nDensity-Enhanced Fusion Module (DEFM) is proposed. It effectively refines\nattention toward target-survival regions with the assist of density mask and\nthe multiple sources features. Notably, our DenSe-AdViT achieves 79.8% mAP on\nthe RSDD dataset and 92.5% on the SIVED dataset, both of which feature a large\nnumber of densely distributed vehicle targets.", "published": "2025-04-18 11:25:49", "link": "http://arxiv.org/abs/2504.13638v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SupResDiffGAN a new approach for the Super-Resolution task", "abstract": "In this work, we present SupResDiffGAN, a novel hybrid architecture that\ncombines the strengths of Generative Adversarial Networks (GANs) and diffusion\nmodels for super-resolution tasks. By leveraging latent space representations\nand reducing the number of diffusion steps, SupResDiffGAN achieves\nsignificantly faster inference times than other diffusion-based\nsuper-resolution models while maintaining competitive perceptual quality. To\nprevent discriminator overfitting, we propose adaptive noise corruption,\nensuring a stable balance between the generator and the discriminator during\ntraining. Extensive experiments on benchmark datasets show that our approach\noutperforms traditional diffusion models such as SR3 and I$^2$SB in efficiency\nand image quality. This work bridges the performance gap between diffusion- and\nGAN-based methods, laying the foundation for real-time applications of\ndiffusion models in high-resolution image generation.", "published": "2025-04-18 10:55:24", "link": "http://arxiv.org/abs/2504.13622v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Visual Intention Grounding for Egocentric Assistants", "abstract": "Visual grounding associates textual descriptions with objects in an image.\nConventional methods target third-person image inputs and named object queries.\nIn applications such as AI assistants, the perspective shifts -- inputs are\negocentric, and objects may be referred to implicitly through needs and\nintentions. To bridge this gap, we introduce EgoIntention, the first dataset\nfor egocentric visual intention grounding. EgoIntention challenges multimodal\nLLMs to 1) understand and ignore unintended contextual objects and 2) reason\nabout uncommon object functionalities. Benchmark results show that current\nmodels misidentify context objects and lack affordance understanding in\negocentric views. We also propose Reason-to-Ground (RoG) instruction tuning; it\nenables hybrid training with normal descriptions and egocentric intentions with\na chained intention reasoning and object grounding mechanism. RoG significantly\noutperforms naive finetuning and hybrid training on EgoIntention, while\nmaintaining or slightly improving naive description grounding. This advancement\nenables unified visual grounding for egocentric and exocentric visual inputs\nwhile handling explicit object queries and implicit human intentions.", "published": "2025-04-18 10:54:52", "link": "http://arxiv.org/abs/2504.13621v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Compile Scene Graphs with Reinforcement Learning", "abstract": "Next token prediction is the fundamental principle for training large\nlanguage models (LLMs), and reinforcement learning (RL) further enhances their\nreasoning performance. As an effective way to model language, image, video, and\nother modalities, the use of LLMs for end-to-end extraction of structured\nvisual representations, such as scene graphs, remains underexplored. It\nrequires the model to accurately produce a set of objects and relationship\ntriplets, rather than generating text token by token. To achieve this, we\nintroduce R1-SGG, a multimodal LLM (M-LLM) initially trained via supervised\nfine-tuning (SFT) on the scene graph dataset and subsequently refined using\nreinforcement learning to enhance its ability to generate scene graphs in an\nend-to-end manner. The SFT follows a conventional prompt-response paradigm,\nwhile RL requires the design of effective reward signals. Given the structured\nnature of scene graphs, we design a graph-centric reward function that\nintegrates node-level rewards, edge-level rewards, and a format consistency\nreward. Our experiments demonstrate that rule-based RL substantially enhances\nmodel performance in the SGG task, achieving a zero failure rate--unlike\nsupervised fine-tuning (SFT), which struggles to generalize effectively. Our\ncode is available at https://github.com/gpt4vision/R1-SGG.", "published": "2025-04-18 10:46:22", "link": "http://arxiv.org/abs/2504.13617v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-Hierarchical Bidirectional Consistency Learning for Fine-Grained Visual Classification", "abstract": "Fine-Grained Visual Classification (FGVC) aims to categorize closely related\nsubclasses, a task complicated by minimal inter-class differences and\nsignificant intra-class variance. Existing methods often rely on additional\nannotations for image classification, overlooking the valuable information\nembedded in Tree Hierarchies that depict hierarchical label relationships. To\nleverage this knowledge to improve classification accuracy and consistency, we\npropose a novel Cross-Hierarchical Bidirectional Consistency Learning (CHBC)\nframework. The CHBC framework extracts discriminative features across various\nhierarchies using a specially designed module to decompose and enhance\nattention masks and features. We employ bidirectional consistency loss to\nregulate the classification outcomes across different hierarchies, ensuring\nlabel prediction consistency and reducing misclassification. Experiments on\nthree widely used FGVC datasets validate the effectiveness of the CHBC\nframework. Ablation studies further investigate the application strategies of\nfeature enhancement and consistency constraints, underscoring the significant\ncontributions of the proposed modules.", "published": "2025-04-18 10:30:17", "link": "http://arxiv.org/abs/2504.13608v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FocusTrack: A Self-Adaptive Local Sampling Algorithm for Efficient Anti-UAV Tracking", "abstract": "Anti-UAV tracking poses significant challenges, including small target sizes,\nabrupt camera motion, and cluttered infrared backgrounds. Existing tracking\nparadigms can be broadly categorized into global- and local-based methods.\nGlobal-based trackers, such as SiamDT, achieve high accuracy by scanning the\nentire field of view but suffer from excessive computational overhead, limiting\nreal-world deployment. In contrast, local-based methods, including OSTrack and\nROMTrack, efficiently restrict the search region but struggle when targets\nundergo significant displacements due to abrupt camera motion. Through\npreliminary experiments, it is evident that a local tracker, when paired with\nadaptive search region adjustment, can significantly enhance tracking accuracy,\nnarrowing the gap between local and global trackers. To address this challenge,\nwe propose FocusTrack, a novel framework that dynamically refines the search\nregion and strengthens feature representations, achieving an optimal balance\nbetween computational efficiency and tracking accuracy. Specifically, our\nSearch Region Adjustment (SRA) strategy estimates the target presence\nprobability and adaptively adjusts the field of view, ensuring the target\nremains within focus. Furthermore, to counteract feature degradation caused by\nvarying search regions, the Attention-to-Mask (ATM) module is proposed. This\nmodule integrates hierarchical information, enriching the target\nrepresentations with fine-grained details. Experimental results demonstrate\nthat FocusTrack achieves state-of-the-art performance, obtaining 67.7% AUC on\nAntiUAV and 62.8% AUC on AntiUAV410, outperforming the baseline tracker by 8.5%\nand 9.1% AUC, respectively. In terms of efficiency, FocusTrack surpasses\nglobal-based trackers, requiring only 30G MACs and achieving 143 fps with\nFocusTrack (SRA) and 44 fps with the full version, both enabling real-time\ntracking.", "published": "2025-04-18 10:18:07", "link": "http://arxiv.org/abs/2504.13604v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ViG3D-UNet: Volumetric Vascular Connectivity-Aware Segmentation via 3D Vision Graph Representation", "abstract": "Accurate vascular segmentation is essential for coronary visualization and\nthe diagnosis of coronary heart disease. This task involves the extraction of\nsparse tree-like vascular branches from the volumetric space. However, existing\nmethods have faced significant challenges due to discontinuous vascular\nsegmentation and missing endpoints. To address this issue, a 3D vision graph\nneural network framework, named ViG3D-UNet, was introduced. This method\nintegrates 3D graph representation and aggregation within a U-shaped\narchitecture to facilitate continuous vascular segmentation. The ViG3D module\ncaptures volumetric vascular connectivity and topology, while the convolutional\nmodule extracts fine vascular details. These two branches are combined through\nchannel attention to form the encoder feature. Subsequently, a paperclip-shaped\noffset decoder minimizes redundant computations in the sparse feature space and\nrestores the feature map size to match the original input dimensions. To\nevaluate the effectiveness of the proposed approach for continuous vascular\nsegmentation, evaluations were performed on two public datasets, ASOCA and\nImageCAS. The segmentation results show that the ViG3D-UNet surpassed competing\nmethods in maintaining vascular segmentation connectivity while achieving high\nsegmentation accuracy. Our code will be available soon.", "published": "2025-04-18 10:06:45", "link": "http://arxiv.org/abs/2504.13599v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "LMPOcc: 3D Semantic Occupancy Prediction Utilizing Long-Term Memory Prior from Historical Traversals", "abstract": "Vision-based 3D semantic occupancy prediction is critical for autonomous\ndriving, enabling unified modeling of static infrastructure and dynamic agents.\nIn practice, autonomous vehicles may repeatedly traverse identical geographic\nlocations under varying environmental conditions, such as weather fluctuations\nand illumination changes. Existing methods in 3D occupancy prediction\npredominantly integrate adjacent temporal contexts. However, these works\nneglect to leverage perceptual information, which is acquired from historical\ntraversals of identical geographic locations. In this paper, we propose\nLongterm Memory Prior Occupancy (LMPOcc), the first 3D occupancy prediction\nmethodology that exploits long-term memory priors derived from historical\ntraversal perceptual outputs. We introduce a plug-and-play architecture that\nintegrates long-term memory priors to enhance local perception while\nsimultaneously constructing global occupancy representations. To adaptively\naggregate prior features and current features, we develop an efficient\nlightweight Current-Prior Fusion module. Moreover, we propose a model-agnostic\nprior format to ensure compatibility across diverse occupancy prediction\nbaselines. LMPOcc achieves state-of-the-art performance validated on the\nOcc3D-nuScenes benchmark, especially on static semantic categories.\nAdditionally, experimental results demonstrate LMPOcc's ability to construct\nglobal occupancy through multi-vehicle crowdsourcing.", "published": "2025-04-18 09:58:48", "link": "http://arxiv.org/abs/2504.13596v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "KAN or MLP? Point Cloud Shows the Way Forward", "abstract": "Multi-Layer Perceptrons (MLPs) have become one of the fundamental\narchitectural component in point cloud analysis due to its effective feature\nlearning mechanism. However, when processing complex geometric structures in\npoint clouds, MLPs' fixed activation functions struggle to efficiently capture\nlocal geometric features, while suffering from poor parameter efficiency and\nhigh model redundancy. In this paper, we propose PointKAN, which applies\nKolmogorov-Arnold Networks (KANs) to point cloud analysis tasks to investigate\ntheir efficacy in hierarchical feature representation. First, we introduce a\nGeometric Affine Module (GAM) to transform local features, improving the\nmodel's robustness to geometric variations. Next, in the Local Feature\nProcessing (LFP), a parallel structure extracts both group-level features and\nglobal context, providing a rich representation of both fine details and\noverall structure. Finally, these features are combined and processed in the\nGlobal Feature Processing (GFP). By repeating these operations, the receptive\nfield gradually expands, enabling the model to capture complete geometric\ninformation of the point cloud. To overcome the high parameter counts and\ncomputational inefficiency of standard KANs, we develop Efficient-KANs in the\nPointKAN-elite variant, which significantly reduces parameters while\nmaintaining accuracy. Experimental results demonstrate that PointKAN\noutperforms PointMLP on benchmark datasets such as ModelNet40, ScanObjectNN,\nand ShapeNetPart, with particularly strong performance in Few-shot Learning\ntask. Additionally, PointKAN achieves substantial reductions in parameter\ncounts and computational complexity (FLOPs). This work highlights the potential\nof KANs-based architectures in 3D vision and opens new avenues for research in\npoint cloud understanding.", "published": "2025-04-18 09:52:22", "link": "http://arxiv.org/abs/2504.13593v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding", "abstract": "High-level 3D scene understanding is essential in many applications. However,\nthe challenges of generating accurate 3D annotations make development of deep\nlearning models difficult. We turn to recent advancements in automatic\nretrieval of synthetic CAD models, and show that data generated by such methods\ncan be used as high-quality ground truth for training supervised deep learning\nmodels. More exactly, we employ a pipeline akin to the one previously used to\nautomatically annotate objects in ScanNet scenes with their 9D poses and CAD\nmodels. This time, we apply it to the recent ScanNet++ v1 dataset, which\npreviously lacked such annotations. Our findings demonstrate that it is not\nonly possible to train deep learning models on these automatically-obtained\nannotations but that the resulting models outperform those trained on manually\nannotated data. We validate this on two distinct tasks: point cloud completion\nand single-view CAD model retrieval and alignment. Our results underscore the\npotential of automatic 3D annotations to enhance model performance while\nsignificantly reducing annotation costs. To support future research in 3D scene\nunderstanding, we will release our annotations, which we call SCANnotate++,\nalong with our trained models.", "published": "2025-04-18 09:33:45", "link": "http://arxiv.org/abs/2504.13580v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HDBFormer: Efficient RGB-D Semantic Segmentation with A Heterogeneous Dual-Branch Framework", "abstract": "In RGB-D semantic segmentation for indoor scenes, a key challenge is\neffectively integrating the rich color information from RGB images with the\nspatial distance information from depth images. However, most existing methods\noverlook the inherent differences in how RGB and depth images express\ninformation. Properly distinguishing the processing of RGB and depth images is\nessential to fully exploiting their unique and significant characteristics. To\naddress this, we propose a novel heterogeneous dual-branch framework called\nHDBFormer, specifically designed to handle these modality differences. For RGB\nimages, which contain rich detail, we employ both a basic and detail encoder to\nextract local and global features. For the simpler depth images, we propose\nLDFormer, a lightweight hierarchical encoder that efficiently extracts depth\nfeatures with fewer parameters. Additionally, we introduce the Modality\nInformation Interaction Module (MIIM), which combines transformers with large\nkernel convolutions to interact global and local information across modalities\nefficiently. Extensive experiments show that HDBFormer achieves\nstate-of-the-art performance on the NYUDepthv2 and SUN-RGBD datasets. The code\nis available at: https://github.com/Weishuobin/HDBFormer.", "published": "2025-04-18 09:29:46", "link": "http://arxiv.org/abs/2504.13579v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MAAM: A Lightweight Multi-Agent Aggregation Module for Efficient Image Classification Based on the MindSpore Framework", "abstract": "The demand for lightweight models in image classification tasks under\nresource-constrained environments necessitates a balance between computational\nefficiency and robust feature representation. Traditional attention mechanisms,\ndespite their strong feature modeling capability, often struggle with high\ncomputational complexity and structural rigidity, limiting their applicability\nin scenarios with limited computational resources (e.g., edge devices or\nreal-time systems). To address this, we propose the Multi-Agent Aggregation\nModule (MAAM), a lightweight attention architecture integrated with the\nMindSpore framework. MAAM employs three parallel agent branches with\nindependently parameterized operations to extract heterogeneous features,\nadaptively fused via learnable scalar weights, and refined through a\nconvolutional compression layer. Leveraging MindSpore's dynamic computational\ngraph and operator fusion, MAAM achieves 87.0% accuracy on the CIFAR-10\ndataset, significantly outperforming conventional CNN (58.3%) and MLP (49.6%)\nmodels, while improving training efficiency by 30%. Ablation studies confirm\nthe critical role of agent attention (accuracy drops to 32.0% if removed) and\ncompression modules (25.5% if omitted), validating their necessity for\nmaintaining discriminative feature learning. The framework's hardware\nacceleration capabilities and minimal memory footprint further demonstrate its\npracticality, offering a deployable solution for image classification in\nresource-constrained scenarios without compromising accuracy.", "published": "2025-04-18 09:19:07", "link": "http://arxiv.org/abs/2504.13574v1", "categories": ["cs.LG", "cs.CV", "eess.IV"], "primary_category": "cs.LG"}
{"title": "WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion", "abstract": "3D scene perception demands a large amount of adverse-weather LiDAR data, yet\nthe cost of LiDAR data collection presents a significant scaling-up challenge.\nTo this end, a series of LiDAR simulators have been proposed. Yet, they can\nonly simulate a single adverse weather with a single physical model, and the\nfidelity of the generated data is quite limited. This paper presents\nWeatherGen, the first unified diverse-weather LiDAR data diffusion generation\nframework, significantly improving fidelity. Specifically, we first design a\nmap-based data producer, which can provide a vast amount of high-quality\ndiverse-weather data for training purposes. Then, we utilize the\ndiffusion-denoising paradigm to construct a diffusion model. Among them, we\npropose a spider mamba generator to restore the disturbed diverse weather data\ngradually. The spider mamba models the feature interactions by scanning the\nLiDAR beam circle or central ray, excellently maintaining the physical\nstructure of the LiDAR data. Subsequently, following the generator to transfer\nreal-world knowledge, we design a latent feature aligner. Afterward, we devise\na contrastive learning-based controller, which equips weather control signals\nwith compact semantic knowledge through language supervision, guiding the\ndiffusion model to generate more discriminative data. Extensive evaluations\ndemonstrate the high generation quality of WeatherGen. Through WeatherGen, we\nconstruct the mini-weather dataset, promoting the performance of the downstream\ntask under adverse weather conditions. Code is available:\nhttps://github.com/wuyang98/weathergen", "published": "2025-04-18 09:01:07", "link": "http://arxiv.org/abs/2504.13561v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Novel Hybrid Approach for Retinal Vessel Segmentation with Dynamic Long-Range Dependency and Multi-Scale Retinal Edge Fusion Enhancement", "abstract": "Accurate retinal vessel segmentation provides essential structural\ninformation for ophthalmic image analysis. However, existing methods struggle\nwith challenges such as multi-scale vessel variability, complex curvatures, and\nambiguous boundaries. While Convolutional Neural Networks (CNNs),\nTransformer-based models and Mamba-based architectures have advanced the field,\nthey often suffer from vascular discontinuities or edge feature ambiguity. To\naddress these limitations, we propose a novel hybrid framework that\nsynergistically integrates CNNs and Mamba for high-precision retinal vessel\nsegmentation. Our approach introduces three key innovations: 1) The proposed\nHigh-Resolution Edge Fuse Network is a high-resolution preserving hybrid\nsegmentation framework that combines a multi-scale backbone with the\nMulti-scale Retina Edge Fusion (MREF) module to enhance edge features, ensuring\naccurate and robust vessel segmentation. 2) The Dynamic Snake Visual State\nSpace block combines Dynamic Snake Convolution with Mamba to adaptively capture\nvessel curvature details and long-range dependencies. An improved\neight-directional 2D Snake-Selective Scan mechanism and a dynamic weighting\nstrategy enhance the perception of complex vascular topologies. 3) The MREF\nmodule enhances boundary precision through multi-scale edge feature\naggregation, suppressing noise while emphasizing critical vessel structures\nacross scales. Experiments on three public datasets demonstrate that our method\nachieves state-of-the-art performance, particularly in maintaining vascular\ncontinuity and effectively segmenting vessels in low-contrast regions. This\nwork provides a robust method for clinical applications requiring accurate\nretinal vessel analysis. The code is available at\nhttps://github.com/frank-oy/HREFNet.", "published": "2025-04-18 08:41:35", "link": "http://arxiv.org/abs/2504.13553v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "EG-Gaussian: Epipolar Geometry and Graph Network Enhanced 3D Gaussian Splatting", "abstract": "In this paper, we explore an open research problem concerning the\nreconstruction of 3D scenes from images. Recent methods have adopt 3D Gaussian\nSplatting (3DGS) to produce 3D scenes due to its efficient training process.\nHowever, these methodologies may generate incomplete 3D scenes or blurred\nmultiviews. This is because of (1) inaccurate 3DGS point initialization and (2)\nthe tendency of 3DGS to flatten 3D Gaussians with the sparse-view input. To\naddress these issues, we propose a novel framework EG-Gaussian, which utilizes\nepipolar geometry and graph networks for 3D scene reconstruction. Initially, we\nintegrate epipolar geometry into the 3DGS initialization phase to enhance\ninitial 3DGS point construction. Then, we specifically design a graph learning\nmodule to refine 3DGS spatial features, in which we incorporate both spatial\ncoordinates and angular relationships among neighboring points. Experiments on\nindoor and outdoor benchmark datasets demonstrate that our approach\nsignificantly improves reconstruction accuracy compared to 3DGS-based methods.", "published": "2025-04-18 08:10:39", "link": "http://arxiv.org/abs/2504.13540v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Quantum Walks-Based Adaptive Distribution Generation with Efficient CUDA-Q Acceleration", "abstract": "We present a novel Adaptive Distribution Generator that leverages a quantum\nwalks-based approach to generate high precision and efficiency of target\nprobability distributions. Our method integrates variational quantum circuits\nwith discrete-time quantum walks, specifically, split-step quantum walks and\ntheir entangled extensions, to dynamically tune coin parameters and drive the\nevolution of quantum states towards desired distributions. This enables\naccurate one-dimensional probability modeling for applications such as\nfinancial simulation and structured two-dimensional pattern generation\nexemplified by digit representations(0~9). Implemented within the CUDA-Q\nframework, our approach exploits GPU acceleration to significantly reduce\ncomputational overhead and improve scalability relative to conventional\nmethods. Extensive benchmarks demonstrate that our Quantum Walks-Based Adaptive\nDistribution Generator achieves high simulation fidelity and bridges the gap\nbetween theoretical quantum algorithms and practical high-performance\ncomputation.", "published": "2025-04-18 07:53:03", "link": "http://arxiv.org/abs/2504.13532v1", "categories": ["quant-ph", "cs.CV", "q-fin.PR"], "primary_category": "quant-ph"}
{"title": "OBIFormer: A Fast Attentive Denoising Framework for Oracle Bone Inscriptions", "abstract": "Oracle bone inscriptions (OBIs) are the earliest known form of Chinese\ncharacters and serve as a valuable resource for research in anthropology and\narchaeology. However, most excavated fragments are severely degraded due to\nthousands of years of natural weathering, corrosion, and man-made destruction,\nmaking automatic OBI recognition extremely challenging. Previous methods either\nfocus on pixel-level information or utilize vanilla transformers for\nglyph-based OBI denoising, which leads to tremendous computational overhead.\nTherefore, this paper proposes a fast attentive denoising framework for oracle\nbone inscriptions, i.e., OBIFormer. It leverages channel-wise self-attention,\nglyph extraction, and selective kernel feature fusion to reconstruct denoised\nimages precisely while being computationally efficient. Our OBIFormer achieves\nstate-of-the-art denoising performance for PSNR and SSIM metrics on synthetic\nand original OBI datasets. Furthermore, comprehensive experiments on a real\noracle dataset demonstrate the great potential of our OBIFormer in assisting\nautomatic OBI recognition. The code will be made available at\nhttps://github.com/LJHolyGround/OBIFormer.", "published": "2025-04-18 07:24:35", "link": "http://arxiv.org/abs/2504.13524v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Filter2Noise: Interpretable Self-Supervised Single-Image Denoising for Low-Dose CT with Attention-Guided Bilateral Filtering", "abstract": "Effective denoising is crucial in low-dose CT to enhance subtle structures\nand low-contrast lesions while preventing diagnostic errors. Supervised methods\nstruggle with limited paired datasets, and self-supervised approaches often\nrequire multiple noisy images and rely on deep networks like U-Net, offering\nlittle insight into the denoising mechanism. To address these challenges, we\npropose an interpretable self-supervised single-image denoising framework --\nFilter2Noise (F2N). Our approach introduces an Attention-Guided Bilateral\nFilter that adapted to each noisy input through a lightweight module that\npredicts spatially varying filter parameters, which can be visualized and\nadjusted post-training for user-controlled denoising in specific regions of\ninterest. To enable single-image training, we introduce a novel downsampling\nshuffle strategy with a new self-supervised loss function that extends the\nconcept of Noise2Noise to a single image and addresses spatially correlated\nnoise. On the Mayo Clinic 2016 low-dose CT dataset, F2N outperforms the leading\nself-supervised single-image method (ZS-N2N) by 4.59 dB PSNR while improving\ntransparency, user control, and parametric efficiency. These features provide\nkey advantages for medical applications that require precise and interpretable\nnoise reduction. Our code is demonstrated at\nhttps://github.com/sypsyp97/Filter2Noise.git .", "published": "2025-04-18 07:15:27", "link": "http://arxiv.org/abs/2504.13519v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "U-Shape Mamba: State Space Model for faster diffusion", "abstract": "Diffusion models have become the most popular approach for high-quality image\ngeneration, but their high computational cost still remains a significant\nchallenge. To address this problem, we propose U-Shape Mamba (USM), a novel\ndiffusion model that leverages Mamba-based layers within a U-Net-like\nhierarchical structure. By progressively reducing sequence length in the\nencoder and restoring it in the decoder through Mamba blocks, USM significantly\nlowers computational overhead while maintaining strong generative capabilities.\nExperimental results against Zigma, which is currently the most efficient\nMamba-based diffusion model, demonstrate that USM achieves one-third the\nGFlops, requires less memory and is faster, while outperforming Zigma in image\nquality. Frechet Inception Distance (FID) is improved by 15.3, 0.84 and 2.7\npoints on AFHQ, CelebAHQ and COCO datasets, respectively. These findings\nhighlight USM as a highly efficient and scalable solution for diffusion-based\ngenerative models, making high-quality image synthesis more accessible to the\nresearch community while reducing computational costs.", "published": "2025-04-18 06:38:12", "link": "http://arxiv.org/abs/2504.13499v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing", "abstract": "Despite recent advances in diffusion models, achieving reliable image\ngeneration and editing remains challenging due to the inherent diversity\ninduced by stochastic noise in the sampling process. Instruction-guided image\nediting with diffusion models offers user-friendly capabilities, yet editing\nfailures, such as background distortion, frequently occur. Users often resort\nto trial and error, adjusting seeds or prompts to achieve satisfactory results,\nwhich is inefficient. While seed selection methods exist for Text-to-Image\n(T2I) generation, they depend on external verifiers, limiting applicability,\nand evaluating multiple seeds increases computational complexity. To address\nthis, we first establish a multiple-seed-based image editing baseline using\nbackground consistency scores, achieving Best-of-N performance without\nsupervision. Building on this, we introduce ELECT (Early-timestep Latent\nEvaluation for Candidate Selection), a zero-shot framework that selects\nreliable seeds by estimating background mismatches at early diffusion\ntimesteps, identifying the seed that retains the background while modifying\nonly the foreground. ELECT ranks seed candidates by a background inconsistency\nscore, filtering unsuitable samples early based on background consistency while\npreserving editability. Beyond standalone seed selection, ELECT integrates into\ninstruction-guided editing pipelines and extends to Multimodal Large-Language\nModels (MLLMs) for joint seed and prompt selection, further improving results\nwhen seed selection alone is insufficient. Experiments show that ELECT reduces\ncomputational costs (by 41 percent on average and up to 61 percent) while\nimproving background consistency and instruction adherence, achieving around 40\npercent success rates in previously failed cases - without any external\nsupervision or training.", "published": "2025-04-18 05:59:01", "link": "http://arxiv.org/abs/2504.13490v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Variational Autoencoder Framework for Hyperspectral Retrievals (Hyper-VAE) of Phytoplankton Absorption and Chlorophyll a in Coastal Waters for NASA's EMIT and PACE Missions", "abstract": "Phytoplankton absorb and scatter light in unique ways, subtly altering the\ncolor of water, changes that are often minor for human eyes to detect but can\nbe captured by sensitive ocean color instruments onboard satellites from space.\nHyperspectral sensors, paired with advanced algorithms, are expected to\nsignificantly enhance the characterization of phytoplankton community\ncomposition, especially in coastal waters where ocean color remote sensing\napplications have historically encountered significant challenges. This study\npresents novel machine learning-based solutions for NASA's hyperspectral\nmissions, including EMIT and PACE, tackling high-fidelity retrievals of\nphytoplankton absorption coefficient and chlorophyll a from their hyperspectral\nremote sensing reflectance. Given that a single Rrs spectrum may correspond to\nvaried combinations of inherent optical properties and associated\nconcentrations, the Variational Autoencoder (VAE) is used as a backbone in this\nstudy to handle such multi-distribution prediction problems. We first time\ntailor the VAE model with innovative designs to achieve hyperspectral\nretrievals of aphy and of Chl-a from hyperspectral Rrs in optically complex\nestuarine-coastal waters. Validation with extensive experimental observation\ndemonstrates superior performance of the VAE models with high precision and low\nbias. The in-depth analysis of VAE's advanced model structures and learning\ndesigns highlights the improvement and advantages of VAE-based solutions over\nthe mixture density network (MDN) approach, particularly on high-dimensional\ndata, such as PACE. Our study provides strong evidence that current EMIT and\nPACE hyperspectral data as well as the upcoming Surface Biology Geology mission\nwill open new pathways toward a better understanding of phytoplankton community\ndynamics in aquatic ecosystems when integrated with AI technologies.", "published": "2025-04-18 05:37:14", "link": "http://arxiv.org/abs/2504.13476v1", "categories": ["cs.LG", "cs.CV", "eess.IV"], "primary_category": "cs.LG"}
{"title": "HMPE:HeatMap Embedding for Efficient Transformer-Based Small Object Detection", "abstract": "Current Transformer-based methods for small object detection continue\nemerging, yet they have still exhibited significant shortcomings. This paper\nintroduces HeatMap Position Embedding (HMPE), a novel Transformer Optimization\ntechnique that enhances object detection performance by dynamically integrating\npositional encoding with semantic detection information through heatmap-guided\nadaptive learning.We also innovatively visualize the HMPE method, offering\nclear visualization of embedded information for parameter fine-tuning.We then\ncreate Multi-Scale ObjectBox-Heatmap Fusion Encoder (MOHFE) and HeatMap Induced\nHigh-Quality Queries for Decoder (HIDQ) modules. These are designed for the\nencoder and decoder, respectively, to generate high-quality queries and reduce\nbackground noise queries.Using both heatmap embedding and Linear-Snake\nConv(LSConv) feature engineering, we enhance the embedding of massively diverse\nsmall object categories and reduced the decoder multihead layers, thereby\naccelerating both inference and training.In the generalization experiments, our\napproach outperforme the baseline mAP by 1.9% on the small object dataset (NWPU\nVHR-10) and by 1.2% on the general dataset (PASCAL VOC). By employing\nHMPE-enhanced embedding, we are able to reduce the number of decoder layers\nfrom eight to a minimum of three, significantly decreasing both inference and\ntraining costs.", "published": "2025-04-18 05:24:08", "link": "http://arxiv.org/abs/2504.13469v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Learning from Noisy Pseudo-labels for All-Weather Land Cover Mapping", "abstract": "Semantic segmentation of SAR images has garnered significant attention in\nremote sensing due to the immunity of SAR sensors to cloudy weather and light\nconditions. Nevertheless, SAR imagery lacks detailed information and is plagued\nby significant speckle noise, rendering the annotation or segmentation of SAR\nimages a formidable task. Recent efforts have resorted to annotating paired\noptical-SAR images to generate pseudo-labels through the utilization of an\noptical image segmentation network. However, these pseudo-labels are laden with\nnoise, leading to suboptimal performance in SAR image segmentation. In this\nstudy, we introduce a more precise method for generating pseudo-labels by\nincorporating semi-supervised learning alongside a novel image resolution\nalignment augmentation. Furthermore, we introduce a symmetric cross-entropy\nloss to mitigate the impact of noisy pseudo-labels. Additionally, a bag of\ntraining and testing tricks is utilized to generate better land-cover mapping\nresults. Our experiments on the GRSS data fusion contest indicate the\neffectiveness of the proposed method, which achieves first place. The code is\navailable at https://github.com/StuLiu/DFC2025Track1.git.", "published": "2025-04-18 04:24:47", "link": "http://arxiv.org/abs/2504.13458v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Neural Ganglion Sensors: Learning Task-specific Event Cameras Inspired by the Neural Circuit of the Human Retina", "abstract": "Inspired by the data-efficient spiking mechanism of neurons in the human eye,\nevent cameras were created to achieve high temporal resolution with minimal\npower and bandwidth requirements by emitting asynchronous, per-pixel intensity\nchanges rather than conventional fixed-frame rate images. Unlike retinal\nganglion cells (RGCs) in the human eye, however, which integrate signals from\nmultiple photoreceptors within a receptive field to extract spatio-temporal\nfeatures, conventional event cameras do not leverage local spatial context when\ndeciding which events to fire. Moreover, the eye contains around 20 different\nkinds of RGCs operating in parallel, each attuned to different features or\nconditions. Inspired by this biological design, we introduce Neural Ganglion\nSensors, an extension of traditional event cameras that learns task-specific\nspatio-temporal retinal kernels (i.e., RGC \"events\"). We evaluate our design on\ntwo challenging tasks: video interpolation and optical flow. Our results\ndemonstrate that our biologically inspired sensing improves performance\nrelative to conventional event cameras while reducing overall event bandwidth.\nThese findings highlight the promise of RGC-inspired event sensors for edge\ndevices and other low-power, real-time applications requiring efficient,\nhigh-resolution visual streams.", "published": "2025-04-18 04:22:58", "link": "http://arxiv.org/abs/2504.13457v1", "categories": ["cs.CV", "cs.ET", "eess.IV"], "primary_category": "cs.CV"}
{"title": "MicroFlow: Domain-Specific Optical Flow for Ground Deformation Estimation in Seismic Events", "abstract": "Dense ground displacement measurements are crucial for geological studies but\nare impractical to collect directly. Traditionally, displacement fields are\nestimated using patch matching on optical satellite images from different\nacquisition times. While deep learning-based optical flow models are promising,\ntheir adoption in ground deformation analysis is hindered by challenges such as\nthe absence of real ground truth, the need for sub-pixel precision, and\ntemporal variations due to geological or anthropogenic changes. In particular,\nwe identify that deep learning models relying on explicit correlation layers\nstruggle at estimating small displacements in real-world conditions. Instead,\nwe propose a model that employs iterative refinements with explicit warping\nlayers and a correlation-independent backbone, enabling sub-pixel precision.\nAdditionally, a non-convex variant of Total Variation regularization preserves\nfault-line sharpness while maintaining smoothness elsewhere. Our model\nsignificantly outperforms widely used geophysics methods on semi-synthetic\nbenchmarks and generalizes well to challenging real-world scenarios captured by\nboth medium- and high-resolution sensors. Project page:\nhttps://jbertrand89.github.io/microflow/.", "published": "2025-04-18 04:10:40", "link": "http://arxiv.org/abs/2504.13452v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SatelliteCalculator: A Multi-Task Vision Foundation Model for Quantitative Remote Sensing Inversion", "abstract": "Quantitative remote sensing inversion plays a critical role in environmental\nmonitoring, enabling the estimation of key ecological variables such as\nvegetation indices, canopy structure, and carbon stock. Although vision\nfoundation models have achieved remarkable progress in classification and\nsegmentation tasks, their application to physically interpretable regression\nremains largely unexplored. Furthermore, the multi-spectral nature and\ngeospatial heterogeneity of remote sensing data pose significant challenges for\ngeneralization and transferability. To address these issues, we introduce\nSatelliteCalculator, the first vision foundation model tailored for\nquantitative remote sensing inversion. By leveraging physically defined index\nformulas, we automatically construct a large-scale dataset of over one million\npaired samples across eight core ecological indicators. The model integrates a\nfrozen Swin Transformer backbone with a prompt-guided architecture, featuring\ncross-attentive adapters and lightweight task-specific MLP decoders.\nExperiments on the Open-Canopy benchmark demonstrate that SatelliteCalculator\nachieves competitive accuracy across all tasks while significantly reducing\ninference cost. Our results validate the feasibility of applying foundation\nmodels to quantitative inversion, and provide a scalable framework for\ntask-adaptive remote sensing estimation.", "published": "2025-04-18 03:48:04", "link": "http://arxiv.org/abs/2504.13442v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Temporal Propagation of Asymmetric Feature Pyramid for Surgical Scene Segmentation", "abstract": "Surgical scene segmentation is crucial for robot-assisted laparoscopic\nsurgery understanding. Current approaches face two challenges: (i) static image\nlimitations including ambiguous local feature similarities and fine-grained\nstructural details, and (ii) dynamic video complexities arising from rapid\ninstrument motion and persistent visual occlusions. While existing methods\nmainly focus on spatial feature extraction, they fundamentally overlook\ntemporal dependencies in surgical video streams. To address this, we present\ntemporal asymmetric feature propagation network, a bidirectional attention\narchitecture enabling cross-frame feature propagation. The proposed method\ncontains a temporal query propagator that integrates multi-directional\nconsistency constraints to enhance frame-specific feature representation, and\nan aggregated asymmetric feature pyramid module that preserves discriminative\nfeatures for anatomical structures and surgical instruments. Our framework\nuniquely enables both temporal guidance and contextual reasoning for surgical\nscene understanding. Comprehensive evaluations on two public benchmarks show\nthe proposed method outperforms the current SOTA methods by a large margin,\nwith +16.4\\% mIoU on EndoVis2018 and +3.3\\% mAP on Endoscapes2023. The code\nwill be publicly available after paper acceptance.", "published": "2025-04-18 03:41:23", "link": "http://arxiv.org/abs/2504.13440v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Circular Image Deturbulence using Quasi-conformal Geometry", "abstract": "The presence of inhomogeneous media between optical sensors and objects leads\nto distorted imaging outputs, significantly complicating downstream\nimage-processing tasks. A key challenge in image restoration is the lack of\nhigh-quality, paired-label images required for training supervised models. In\nthis paper, we introduce the Circular Quasi-Conformal Deturbulence (CQCD)\nframework, an unsupervised approach for removing image distortions through a\ncircular architecture. This design ensures that the restored image remains both\ngeometrically accurate and visually faithful while preventing the accumulation\nof incorrect estimations.The circular restoration process involves both forward\nand inverse mapping. To ensure the bijectivity of the estimated non-rigid\ndeformations, computational quasi-conformal geometry theories are leveraged to\nregularize the mapping, enforcing its homeomorphic properties. This guarantees\na well-defined transformation that preserves structural integrity and prevents\nunwanted artifacts. Furthermore, tight-frame blocks are integrated to encode\ndistortion-sensitive features for precise recovery. To validate the performance\nof our approach, we conduct evaluations on various synthetic and real-world\ncaptured images. Experimental results demonstrate that CQCD not only\noutperforms existing state-of-the-art deturbulence methods in terms of image\nrestoration quality but also provides highly accurate deformation field\nestimations.", "published": "2025-04-18 03:07:25", "link": "http://arxiv.org/abs/2504.13432v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HSACNet: Hierarchical Scale-Aware Consistency Regularized Semi-Supervised Change Detection", "abstract": "Semi-supervised change detection (SSCD) aims to detect changes between\nbi-temporal remote sensing images by utilizing limited labeled data and\nabundant unlabeled data. Existing methods struggle in complex scenarios,\nexhibiting poor performance when confronted with noisy data. They typically\nneglect intra-layer multi-scale features while emphasizing inter-layer fusion,\nharming the integrity of change objects with different scales. In this paper,\nwe propose HSACNet, a Hierarchical Scale-Aware Consistency regularized Network\nfor SSCD. Specifically, we integrate Segment Anything Model 2 (SAM2), using its\nHiera backbone as the encoder to extract inter-layer multi-scale features and\napplying adapters for parameter-efficient fine-tuning. Moreover, we design a\nScale-Aware Differential Attention Module (SADAM) that can precisely capture\nintra-layer multi-scale change features and suppress noise. Additionally, a\ndual-augmentation consistency regularization strategy is adopted to effectively\nutilize the unlabeled data. Extensive experiments across four CD benchmarks\ndemonstrate that our HSACNet achieves state-of-the-art performance, with\nreduced parameters and computational cost.", "published": "2025-04-18 03:00:52", "link": "http://arxiv.org/abs/2504.13428v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mono3R: Exploiting Monocular Cues for Geometric 3D Reconstruction", "abstract": "Recent advances in data-driven geometric multi-view 3D reconstruction\nfoundation models (e.g., DUSt3R) have shown remarkable performance across\nvarious 3D vision tasks, facilitated by the release of large-scale,\nhigh-quality 3D datasets. However, as we observed, constrained by their\nmatching-based principles, the reconstruction quality of existing models\nsuffers significant degradation in challenging regions with limited matching\ncues, particularly in weakly textured areas and low-light conditions. To\nmitigate these limitations, we propose to harness the inherent robustness of\nmonocular geometry estimation to compensate for the inherent shortcomings of\nmatching-based methods. Specifically, we introduce a monocular-guided\nrefinement module that integrates monocular geometric priors into multi-view\nreconstruction frameworks. This integration substantially enhances the\nrobustness of multi-view reconstruction systems, leading to high-quality\nfeed-forward reconstructions. Comprehensive experiments across multiple\nbenchmarks demonstrate that our method achieves substantial improvements in\nboth mutli-view camera pose estimation and point cloud accuracy.", "published": "2025-04-18 02:33:12", "link": "http://arxiv.org/abs/2504.13419v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "How Learnable Grids Recover Fine Detail in Low Dimensions: A Neural Tangent Kernel Analysis of Multigrid Parametric Encodings", "abstract": "Neural networks that map between low dimensional spaces are ubiquitous in\ncomputer graphics and scientific computing; however, in their naive\nimplementation, they are unable to learn high frequency information. We present\na comprehensive analysis comparing the two most common techniques for\nmitigating this spectral bias: Fourier feature encodings (FFE) and multigrid\nparametric encodings (MPE). FFEs are seen as the standard for low dimensional\nmappings, but MPEs often outperform them and learn representations with higher\nresolution and finer detail. FFE's roots in the Fourier transform, make it\nsusceptible to aliasing if pushed too far, while MPEs, which use a learned grid\nstructure, have no such limitation. To understand the difference in\nperformance, we use the neural tangent kernel (NTK) to evaluate these encodings\nthrough the lens of an analogous kernel regression. By finding a lower bound on\nthe smallest eigenvalue of the NTK, we prove that MPEs improve a network's\nperformance through the structure of their grid and not their learnable\nembedding. This mechanism is fundamentally different from FFEs, which rely\nsolely on their embedding space to improve performance. Results are empirically\nvalidated on a 2D image regression task using images taken from 100 synonym\nsets of ImageNet and 3D implicit surface regression on objects from the\nStanford graphics dataset. Using peak signal-to-noise ratio (PSNR) and\nmultiscale structural similarity (MS-SSIM) to evaluate how well fine details\nare learned, we show that the MPE increases the minimum eigenvalue by 8 orders\nof magnitude over the baseline and 2 orders of magnitude over the FFE. The\nincrease in spectrum corresponds to a 15 dB (PSNR) / 0.65 (MS-SSIM) increase\nover baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the FFE.", "published": "2025-04-18 02:18:08", "link": "http://arxiv.org/abs/2504.13412v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ProgRoCC: A Progressive Approach to Rough Crowd Counting", "abstract": "As the number of individuals in a crowd grows, enumeration-based techniques\nbecome increasingly infeasible and their estimates increasingly unreliable. We\npropose instead an estimation-based version of the problem: we label Rough\nCrowd Counting that delivers better accuracy on the basis of training data that\nis easier to acquire. Rough crowd counting requires only rough annotations of\nthe number of targets in an image, instead of the more traditional, and far\nmore expensive, per-target annotations. We propose an approach to the rough\ncrowd counting problem based on CLIP, termed ProgRoCC. Specifically, we\nintroduce a progressive estimation learning strategy that determines the object\ncount through a coarse-to-fine approach. This approach delivers answers\nquickly, outperforms the state-of-the-art in semi- and weakly-supervised crowd\ncounting. In addition, we design a vision-language matching adapter that\noptimizes key-value pairs by mining effective matches of two modalities to\nrefine the visual features, thereby improving the final performance. Extensive\nexperimental results on three widely adopted crowd counting datasets\ndemonstrate the effectiveness of our method.", "published": "2025-04-18 01:57:42", "link": "http://arxiv.org/abs/2504.13405v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CytoFM: The first cytology foundation model", "abstract": "Cytology is essential for cancer diagnostics and screening due to its\nminimally invasive nature. However, the development of robust deep learning\nmodels for digital cytology is challenging due to the heterogeneity in staining\nand preparation methods of samples, differences across organs, and the limited\navailability of large, diverse, annotated datasets. Developing a task-specific\nmodel for every cytology application is impractical and non-cytology-specific\nfoundation models struggle to generalize to tasks in this domain where the\nemphasis is on cell morphology. To address these challenges, we introduce\nCytoFM, the first cytology self-supervised foundation model. Using iBOT, a\nself-supervised Vision Transformer (ViT) training framework incorporating\nmasked image modeling and self-distillation, we pretrain CytoFM on a diverse\ncollection of cytology datasets to learn robust, transferable representations.\nWe evaluate CytoFM on multiple downstream cytology tasks, including breast\ncancer classification and cell type identification, using an attention-based\nmultiple instance learning framework. Our results demonstrate that CytoFM\nperforms better on two out of three downstream tasks than existing foundation\nmodels pretrained on histopathology (UNI) or natural images (iBOT-Imagenet).\nVisualizations of learned representations demonstrate our model is able to\nattend to cytologically relevant features. Despite a small pre-training\ndataset, CytoFM's promising results highlight the ability of task-agnostic\npre-training approaches to learn robust and generalizable features from\ncytology data.", "published": "2025-04-18 01:37:50", "link": "http://arxiv.org/abs/2504.13402v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BeetleVerse: A study on taxonomic classification of ground beetles", "abstract": "Ground beetles are a highly sensitive and speciose biological indicator,\nmaking them vital for monitoring biodiversity. However, they are currently an\nunderutilized resource due to the manual effort required by taxonomic experts\nto perform challenging species differentiations based on subtle morphological\ndifferences, precluding widespread applications. In this paper, we evaluate 12\nvision models on taxonomic classification across four diverse, long-tailed\ndatasets spanning over 230 genera and 1769 species, with images ranging from\ncontrolled laboratory settings to challenging field-collected (in-situ)\nphotographs. We further explore taxonomic classification in two important\nreal-world contexts: sample efficiency and domain adaptation. Our results show\nthat the Vision and Language Transformer combined with an MLP head is the best\nperforming model, with 97\\% accuracy at genus and 94\\% at species level. Sample\nefficiency analysis shows that we can reduce train data requirements by up to\n50\\% with minimal compromise in performance. The domain adaptation experiments\nreveal significant challenges when transferring models from lab to in-situ\nimages, highlighting a critical domain gap. Overall, our study lays a\nfoundation for large-scale automated taxonomic classification of beetles, and\nbeyond that, advances sample-efficient learning and cross-domain adaptation for\ndiverse long-tailed ecological datasets.", "published": "2025-04-18 01:06:37", "link": "http://arxiv.org/abs/2504.13393v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "POET: Supporting Prompting Creativity and Personalization with Automated Expansion of Text-to-Image Generation", "abstract": "State-of-the-art visual generative AI tools hold immense potential to assist\nusers in the early ideation stages of creative tasks -- offering the ability to\ngenerate (rather than search for) novel and unprecedented (instead of existing)\nimages of considerable quality that also adhere to boundless combinations of\nuser specifications. However, many large-scale text-to-image systems are\ndesigned for broad applicability, yielding conventional output that may limit\ncreative exploration. They also employ interaction methods that may be\ndifficult for beginners. Given that creative end users often operate in\ndiverse, context-specific ways that are often unpredictable, more variation and\npersonalization are necessary. We introduce POET, a real-time interactive tool\nthat (1) automatically discovers dimensions of homogeneity in text-to-image\ngenerative models, (2) expands these dimensions to diversify the output space\nof generated images, and (3) learns from user feedback to personalize\nexpansions. An evaluation with 28 users spanning four creative task domains\ndemonstrated POET's ability to generate results with higher perceived diversity\nand help users reach satisfaction in fewer prompts during creative tasks,\nthereby prompting them to deliberate and reflect more on a wider range of\npossible produced results during the co-creative process. Focusing on visual\ncreativity, POET offers a first glimpse of how interaction techniques of future\ntext-to-image generation tools may support and align with more pluralistic\nvalues and the needs of end users during the ideation stages of their work.", "published": "2025-04-18 00:54:36", "link": "http://arxiv.org/abs/2504.13392v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Accelerated Optimization of Implicit Neural Representations for CT Reconstruction", "abstract": "Inspired by their success in solving challenging inverse problems in computer\nvision, implicit neural representations (INRs) have been recently proposed for\nreconstruction in low-dose/sparse-view X-ray computed tomography (CT). An INR\nrepresents a CT image as a small-scale neural network that takes spatial\ncoordinates as inputs and outputs attenuation values. Fitting an INR to\nsinogram data is similar to classical model-based iterative reconstruction\nmethods. However, training INRs with losses and gradient-based algorithms can\nbe prohibitively slow, taking many thousands of iterations to converge. This\npaper investigates strategies to accelerate the optimization of INRs for CT\nreconstruction. In particular, we propose two approaches: (1) using a modified\nloss function with improved conditioning, and (2) an algorithm based on the\nalternating direction method of multipliers. We illustrate that both of these\napproaches significantly accelerate INR-based reconstruction of a synthetic\nbreast CT phantom in a sparse-view setting.", "published": "2025-04-18 00:52:56", "link": "http://arxiv.org/abs/2504.13390v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Supervising 3D Talking Head Avatars with Analysis-by-Audio-Synthesis", "abstract": "In order to be widely applicable, speech-driven 3D head avatars must\narticulate their lips in accordance with speech, while also conveying the\nappropriate emotions with dynamically changing facial expressions. The key\nproblem is that deterministic models produce high-quality lip-sync but without\nrich expressions, whereas stochastic models generate diverse expressions but\nwith lower lip-sync quality. To get the best of both, we seek a stochastic\nmodel with accurate lip-sync. To that end, we develop a new approach based on\nthe following observation: if a method generates realistic 3D lip motions, it\nshould be possible to infer the spoken audio from the lip motion. The inferred\nspeech should match the original input audio, and erroneous predictions create\na novel supervision signal for training 3D talking head avatars with accurate\nlip-sync. To demonstrate this effect, we propose THUNDER (Talking Heads Under\nNeural Differentiable Elocution Reconstruction), a 3D talking head avatar\nframework that introduces a novel supervision mechanism via differentiable\nsound production. First, we train a novel mesh-to-speech model that regresses\naudio from facial animation. Then, we incorporate this model into a\ndiffusion-based talking avatar framework. During training, the mesh-to-speech\nmodel takes the generated animation and produces a sound that is compared to\nthe input speech, creating a differentiable analysis-by-audio-synthesis\nsupervision loop. Our extensive qualitative and quantitative experiments\ndemonstrate that THUNDER significantly improves the quality of the lip-sync of\ntalking head avatars while still allowing for generation of diverse,\nhigh-quality, expressive facial animations.", "published": "2025-04-18 00:24:52", "link": "http://arxiv.org/abs/2504.13386v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Cops and Robbers for Graphs on Surfaces with Crossings", "abstract": "Cops and Robbers is a game played on a graph where a set of cops attempt to\ncapture a single robber. The game proceeds in rounds, where each round first\nconsists of the cops' turn, followed by the robber's turn. In the cops' turn,\nevery cop can choose to either stay on the same vertex or move to an adjacent\nvertex, and likewise the robber in his turn. The robber is considered to be\ncaptured if, at any point in time, there is some cop on the same vertex as the\nrobber. A natural question in this game concerns the cop-number of a graph --\nthe minimum number of cops needed to capture the robber. It has long been known\nthat graphs embeddable (without crossings) on surfaces of bounded genus have\nbounded cop-number. In contrast, the class of 1-planar graphs -- graphs that\ncan be drawn on the plane with at most one crossing per edge -- does not have\nbounded cop-number. This paper initiates an investigation into how distance\nbetween crossing pairs of edges influences a graph's cop number. In particular,\nwe look at Distance $d$ Cops and Robbers, a variant of the classical game,\nwhere the robber is considered to be captured if there is a cop within distance\n$d$ of the robber. Let $c_d(G)$ denote the minimum number of cops required in\nthe graph $G$ to capture a robber within distance $d$. We look at various\nclasses of graphs, such as 1-plane graphs, $k$-plane graphs (graphs where each\nedge is crossed at most $k$ times), and even general graph drawings, and show\nthat if every crossing pair of edges can be connected by a path of small\nlength, then $c_d(G)$ is bounded, for small values of $d$.", "published": "2025-04-18 17:33:47", "link": "http://arxiv.org/abs/2504.13813v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "$O(p \\log d)$ Subgraph Isomorphism using Stigmergic Swarming Agents", "abstract": "Subgraph isomorphism compares two graphs (sets of nodes joined by edges) to\ndetermine whether they contain a common subgraph. Many applications require\nidentifying the subgraph, not just deciding its existence. A particularly\ncommon use case, using graphs with labeled nodes, seeks to find instances of a\nsmaller pattern graph with $p$ nodes in the larger data graph with $d$ nodes.\nThe problem is NP-complete, so that na\\\"ive solutions are exponential in $p +\nd$. A wide range of heuristics have been proposed, with the best complexity\n$O(p^2d^2)$. This paper outlines ASSIST (Approximate Swarming Subgraph\nIsomorphism through Stigmergy), inspired by the ant colony optimization\napproach to the traveling salesperson problem. ASSIST is linearithmic, $O(p\n\\log d)$, and also supports matching problems (such as temporally ordered\nedges, inexact matches, and missing nodes or edges in the data graph) that\nfrustrate other heuristics.", "published": "2025-04-18 14:47:49", "link": "http://arxiv.org/abs/2504.13722v1", "categories": ["cs.MA", "cs.DM"], "primary_category": "cs.MA"}
{"title": "Effective Computation of Generalized Abelian Complexity for Pisot Type Substitutive Sequences", "abstract": "Generalized abelian equivalence compares words by their factors up to a\ncertain bounded length. The associated complexity function counts the\nequivalence classes for factors of a given size of an infinite sequence. How\npractical is this notion? When can these equivalence relations and complexity\nfunctions be computed efficiently? We study the fixed points of substitution of\nPisot type. Each of their $k$-abelian complexities is bounded and the Parikh\nvectors of their length-$n$ prefixes form synchronized sequences in the\nassociated Dumont--Thomas numeration system. Therefore, the $k$-abelian\ncomplexity of Pisot substitution fixed points is automatic in the same\nnumeration system. Two effective generic construction approaches are\ninvestigated using the \\texttt{Walnut} theorem prover and are applied to\nseveral examples. We obtain new properties of the Tribonacci sequence, such as\na uniform bound for its factor balancedness together with a two-dimensional\nlinear representation of its generalized abelian complexity functions.", "published": "2025-04-18 09:36:54", "link": "http://arxiv.org/abs/2504.13584v1", "categories": ["cs.FL", "cs.DM", "math.CO", "11B85, 68R15, 68Q45"], "primary_category": "cs.FL"}
{"title": "Consensus-aware Contrastive Learning for Group Recommendation", "abstract": "Group recommendation aims to provide personalized item suggestions to a group\nof users by reflecting their collective preferences. A fundamental challenge in\nthis task is deriving a consensus that adequately represents the diverse\ninterests of individual group members. Despite advancements made by deep\nlearning-based models, existing approaches still struggle in two main areas:\n(1) Capturing consensus in small-group settings, which are more prevalent in\nreal-world applications, and (2) Balancing individual preferences with overall\ngroup performance, particularly in hypergraph-based methods that tend to\nemphasize group accuracy at the expense of personalization. To address these\nchallenges, we introduce a Consensus-aware Contrastive Learning for Group\nRecommendation (CoCoRec) that models group consensus through contrastive\nlearning. CoCoRec utilizes a transformer encoder to jointly learn user and\ngroup representations, enabling richer modeling of intra-group dynamics.\nAdditionally, the contrastive objective helps reduce overfitting from\nhigh-frequency user interactions, leading to more robust and representative\ngroup embeddings. Experiments conducted on four benchmark datasets show that\nCoCoRec consistently outperforms state-of-the-art baselines in both individual\nand group recommendation scenarios, highlighting the effectiveness of\nconsensus-aware contrastive learning in group recommendation tasks.", "published": "2025-04-18 14:03:40", "link": "http://arxiv.org/abs/2504.13703v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Contextualizing Spotify's Audiobook List Recommendations with Descriptive Shelves", "abstract": "In this paper, we propose a pipeline to generate contextualized list\nrecommendations with descriptive shelves in the domain of audiobooks. By\ncreating several shelves for topics the user has an affinity to, e.g. Uplifting\nWomen's Fiction, we can help them explore their recommendations according to\ntheir interests and at the same time recommend a diverse set of items. To do\nso, we use Large Language Models (LLMs) to enrich each item's metadata based on\na taxonomy created for this domain. Then we create diverse descriptive shelves\nfor each user. A/B tests show improvements in user engagement and audiobook\ndiscovery metrics, demonstrating benefits for users and content creators.", "published": "2025-04-18 09:12:46", "link": "http://arxiv.org/abs/2504.13572v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Improving Sequential Recommenders through Counterfactual Augmentation of System Exposure", "abstract": "In sequential recommendation (SR), system exposure refers to items that are\nexposed to the user. Typically, only a few of the exposed items would be\ninteracted with by the user. Although SR has achieved great success in\npredicting future user interests, existing SR methods still fail to fully\nexploit system exposure data. Most methods only model items that have been\ninteracted with, while the large volume of exposed but non-interacted items is\noverlooked. Even methods that consider the whole system exposure typically\ntrain the recommender using only the logged historical system exposure, without\nexploring unseen user interests.\n  In this paper, we propose counterfactual augmentation over system exposure\nfor sequential recommendation (CaseRec). To better model historical system\nexposure, CaseRec introduces reinforcement learning to account for different\nexposure rewards. CaseRec uses a decision transformer-based sequential model to\ntake an exposure sequence as input and assigns different rewards according to\nthe user feedback. To further explore unseen user interests, CaseRec proposes\nto perform counterfactual augmentation, where exposed original items are\nreplaced with counterfactual items. Then, a transformer-based user simulator is\nproposed to predict the user feedback reward for the augmented items.\nAugmentation, together with the user simulator, constructs counterfactual\nexposure sequences to uncover new user interests. Finally, CaseRec jointly uses\nthe logged exposure sequences with the counterfactual exposure sequences to\ntrain a decision transformer-based sequential model for generating\nrecommendation. Experiments on three real-world benchmarks show the\neffectiveness of CaseRec. Our code is available at\nhttps://github.com/ZiqiZhao1/CaseRec.", "published": "2025-04-18 05:46:27", "link": "http://arxiv.org/abs/2504.13482v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Models, Methods and Waveforms for Estimation and Prediction of Doubly Sparse Time-Varying Channels", "abstract": "This paper investigates channel estimation for linear time-varying (LTV)\nwireless channels under double sparsity, i.e., sparsity in both the delay and\nDoppler domains. An on-grid approximation is first considered, enabling\nrigorous hierarchical-sparsity modeling and compressed sensing-based channel\nestimation. Guaranteed recovery conditions are provided for affine frequency\ndivision multiplexing (AFDM), orthogonal frequency division multiplexing (OFDM)\nand single-carrier modulation (SCM), highlighting the superiority of AFDM in\nterms of doubly sparse channel estimation. To address arbitrary Doppler shifts,\na relaxed version of the on-grid model is introduced by making use of multiple\nelementary Expansion Models (BEM) each based on Discrete Prolate Spheroidal\nSequences (DPSS). Next, theoretical guarantees are provided for the precision\nof this off-grid model before further extending it to tackle channel prediction\nby exploiting the inherent DPSS extrapolation capability. Finally, numerical\nresults are provided to both validate the proposed off-grid model for channel\nestimation and prediction purposes under the double sparsity assumption and to\ncompare the corresponding mean squared error (MSE) and the overhead performance\nwhen the different wireless waveforms are used.", "published": "2025-04-18 15:59:58", "link": "http://arxiv.org/abs/2504.13762v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sensing-Then-Beamforming: Robust Transmission Design for RIS-Empowered Integrated Sensing and Covert Communication", "abstract": "Traditional covert communication often relies on the knowledge of the\nwarden's channel state information, which is inherently challenging to obtain\ndue to the non-cooperative nature and potential mobility of the warden. The\nintegration of sensing and communication technology provides a promising\nsolution by enabling the legitimate transmitter to sense and track the warden,\nthereby enhancing transmission covertness. In this paper, we develop a\nframework for sensing-then-beamforming in reconfigurable intelligent surface\n(RIS)-empowered integrated sensing and covert communication (ISCC) systems,\nwhere the transmitter (Alice) estimates and tracks the mobile aerial warden's\nchannel using sensing echo signals while simultaneously sending covert\ninformation to multiple legitimate users (Bobs) with the assistance of RIS,\nunder the surveillance of the warden (Willie). Considering channel estimation\nerrors, we formulate a robust non-convex optimization problem that jointly\ndesigns the communication beamformers, the sensing signal covariance matrix at\nAlice, and the phase shifts at the RIS to maximize the covert sum rate of Bobs\nwhile satisfying the constraints related to covert communication, sensing,\ntransmitter power, and the unit modulus of the RIS elements. To solve this\ncomplex problem, we develop an efficient algorithm using alternating\noptimization, successive convex approximation, S-procedure, sequential rank-one\nconstraint relaxation, and semidefinite relaxation techniques. Numerical\nresults confirm the convergence of the proposed algorithm and demonstrate its\neffectiveness in tracking the warden's channel while ensuring robust covert\ntransmission. Furthermore, the results highlight the advantages of using RIS to\nenhance the covert transmission rate compared to baseline schemes, and also\nillustrate the intricate trade-off between communication and sensing in ISCC\nsystems.", "published": "2025-04-18 15:13:15", "link": "http://arxiv.org/abs/2504.13741v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Equivalence of Serial and Parallel A-Posteriori Probabilities in the Decoding of DAB Systems", "abstract": "Motivated by applications to digital audio broadcasting (DAB) systems, we\nstudy the a-posteriori probabilities (APPs) of the coded and information bits\nof the serial concatenation of multiple convolutional codewords. The main\nresult of this correspondence is a proof that the APPs of the input bits do not\nchange when considering the concatenation of multiple codewords as a received\nsequence. This is a purely theoretical result, which remains valid for every\nconvolutional code, as long as the encoder goes back to the zero state at the\nend of each codeword. An equivalent heuristic for serial concatenation in\nViterbi decoding is described. The applicability of our result to DAB systems,\nwhere interleaving and modulation are accounted for, is investigated through\nMatlab simulations. We show that the Bit Error Rate (BER) of the simulated DAB\nsystem does not change when decoding multiple transmitted codewords as one\nserially concatenated sequence, even when considering all the features of a DAB\nsystem.", "published": "2025-04-18 15:08:50", "link": "http://arxiv.org/abs/2504.13740v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Systematic Bernoulli Generator Matrix Codes", "abstract": "This paper is concerned with the systematic Bernoulli generator matrix~(BGM)\ncodes, which have been proved to be capacity-achieving over binary-input\noutput-symmetric~(BIOS) channels in terms of bit-error rate~(BER). We prove\nthat the systematic BGM codes are also capacity-achieving over BIOS channels in\nterms of frame-error rate (FER). To this end, we present a new framework to\nprove the coding theorems for binary linear codes. Different from the\nwidely-accepted approach via ensemble enlargement, the proof directly applies\nto the systematic binary linear codes. The new proof indicates that the\npair-wise independence condition is not necessary for proving the binary linear\ncode ensemble to achieve the capacity of the BIOS channel. The Bernoulli\nparity-check~(BPC) codes, which fall within the framework of the systematic BGM\ncodes with parity-check bits known at the decoder can also be proved to achieve\nthe capacity. The presented framework also reveals a new mechanism pertained to\nthe systematic linear codes that the systematic bits and the corresponding\nparity-check bits play different roles. Precisely, the noisy systematic bits\nare used to limit the list size of candidate codewords, while the noisy\nparity-check bits are used to select from the list the maximum likelihood\ncodeword. For systematic BGM codes with finite length, we derive the lower\nbounds on the BER and FER, which can be used to predict the error floors.\nNumerical results show that the systematic BGM codes match well with the\nderived error floors. The performance in water-fall region can be improved with\napproaches in statistical physics and the error floors can be significantly\nimproved by implementing the concatenated codes with the systematic BGM codes\nas the inner codes.", "published": "2025-04-18 14:58:50", "link": "http://arxiv.org/abs/2504.13731v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Capacity-achieving sparse superposition codes with spatially coupled VAMP decoder", "abstract": "Sparse superposition (SS) codes provide an efficient communication scheme\nover the Gaussian channel, utilizing the vector approximate message passing\n(VAMP) decoder for rotational invariant design matrices. Previous work has\nestablished that the VAMP decoder for SS achieves Shannon capacity when the\ndesign matrix satisfies a specific spectral criterion and exponential decay\npower allocation is used. In this work, we propose a spatially coupled VAMP\n(SC-VAMP) decoder for SS with spatially coupled design matrices. Based on state\nevolution (SE) analysis, we demonstrate that the SC-VAMP decoder is\ncapacity-achieving when the design matrices satisfy the spectra criterion.\nEmpirically, we show that the SC-VAMP decoder outperforms the VAMP decoder with\nexponential decay power allocation, achieving a lower section error rate. All\ncodes are available on\nhttps://github.com/yztfu/SC-VAMP-for-Superposition-Code.git.", "published": "2025-04-18 10:07:56", "link": "http://arxiv.org/abs/2504.13601v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Irregular Sampling of High-Dimensional Functions in Reproducing Kernel Hilbert Spaces", "abstract": "We develop sampling formulas for high-dimensional functions in reproducing\nkernel Hilbert spaces, where we rely on irregular samples that are taken at\ndetermining sequences of data points. We place particular emphasis on sampling\nformulas for tensor product kernels, where we show that determining irregular\nsamples in lower dimensions can be composed to obtain a tensor of determining\nirregular samples in higher dimensions. This in turn reduces the computational\ncomplexity of sampling formulas for high-dimensional functions quite\nsignificantly.", "published": "2025-04-18 08:18:15", "link": "http://arxiv.org/abs/2504.13543v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Mixed Fractional Information: Consistency of Dissipation Measures for Stable Laws", "abstract": "Symmetric alpha-stable (S alpha S) distributions with alpha<2 lack finite\nclassical Fisher information. Building on Johnson's framework, we define Mixed\nFractional Information (MFI) via the initial rate of relative entropy\ndissipation during interpolation between S alpha S laws with differing scales,\nv and s. We demonstrate two equivalent formulations for MFI in this specific S\nalpha S-to-S alpha S setting. The first involves the derivative D'(v) of the\nrelative entropy between the two S alpha S densities. The second uses an\nintegral expectation E_gv[u(x,0) (pF_v(x) - pF_s(x))] involving the difference\nbetween Fisher scores (pF_v, pF_s) and a specific MMSE-related score function\nu(x,0) derived from the interpolation dynamics. Our central contribution is a\nrigorous proof of the consistency identity: D'(v) = (1/(alpha v)) E_gv[X\n(pF_v(X) - pF_s(X))]. This identity mathematically validates the equivalence of\nthe two MFI formulations for S alpha S inputs, establishing MFI's internal\ncoherence and directly linking entropy dissipation rates to score function\ndifferences. We further establish MFI's non-negativity (zero if and only if\nv=s), derive its closed-form expression for the Cauchy case (alpha=1), and\nnumerically validate the consistency identity. MFI provides a finite, coherent,\nand computable information-theoretic measure for comparing S alpha S\ndistributions where classical Fisher information fails, connecting entropy\ndynamics to score functions and estimation concepts. This work lays a\nfoundation for exploring potential fractional I-MMSE relations and new\nfunctional inequalities tailored to heavy-tailed systems.", "published": "2025-04-18 02:49:24", "link": "http://arxiv.org/abs/2504.13423v1", "categories": ["cs.IT", "math.FA", "math.IT", "math.PR", "math.ST", "stat.TH", "60E07, 94A17, 60G51, 26D10, 62B10"], "primary_category": "cs.IT"}
{"title": "Improved Decoding Algorithm of BD-LRPC Codes", "abstract": "A Bounded-Degree Low-Rank Parity-Check (BD-LRPC) code is a rank-metric code\nthat admits a parity-check matrix whose support is generated by a set of powers\nof an element. This specific structure of the parity-check matrix was employed\nto enhance the first phase of the decoding algorithm through the expansion of\nthe syndrome support. However, this expansion decreases the probability of\nrecovering the error support in the second phase of the decoding algorithm.\nThis paper introduces a novel method based on successive intersections to\nrecover the error support. This method offers two key advantages: it increases\nthe probability of successful decoding and enables the decoding of a greater\nnumber of errors.", "published": "2025-04-18 00:00:55", "link": "http://arxiv.org/abs/2504.13381v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Transformer Encoder and Multi-features Time2Vec for Financial Prediction", "abstract": "Financial prediction is a complex and challenging task of time series\nanalysis and signal processing, expected to model both short-term fluctuations\nand long-term temporal dependencies. Transformers have remarkable success\nmostly in natural language processing using attention mechanism, which also\ninfluenced the time series community. The ability to capture both short and\nlong-range dependencies helps to understand the financial market and to\nrecognize price patterns, leading to successful applications of Transformers in\nstock prediction. Although, the previous research predominantly focuses on\nindividual features and singular predictions, that limits the model's ability\nto understand broader market trends. In reality, within sectors such as finance\nand technology, companies belonging to the same industry often exhibit\ncorrelated stock price movements.\n  In this paper, we develop a novel neural network architecture by integrating\nTime2Vec with the Encoder of the Transformer model. Based on the study of\ndifferent markets, we propose a novel correlation feature selection method.\nThrough a comprehensive fine-tuning of multiple hyperparameters, we conduct a\ncomparative analysis of our results against benchmark models. We conclude that\nour method outperforms other state-of-the-art encoding methods such as\npositional encoding, and we also conclude that selecting correlation features\nenhance the accuracy of predicting multiple stock prices.", "published": "2025-04-18 17:07:41", "link": "http://arxiv.org/abs/2504.13801v1", "categories": ["cs.LG", "cs.CE"], "primary_category": "cs.LG"}
{"title": "The Binary and Ternary Quantization Can Improve Feature Discrimination", "abstract": "In machine learning, quantization is widely used to simplify data\nrepresentation and facilitate algorithm deployment on hardware. Given the\nfundamental role of classification in machine learning, it is crucial to\ninvestigate the impact of quantization on classification. Current research\nprimarily focuses on quantization errors, operating under the premise that\nhigher quantization errors generally result in lower classification\nperformance. However, this premise lacks a solid theoretical foundation and\noften contradicts empirical findings. For instance, certain extremely low\nbit-width quantization methods, such as $\\{0,1\\}$-binary quantization and $\\{0,\n\\pm1\\}$-ternary quantization, can achieve comparable or even superior\nclassification accuracy compared to the original non-quantized data, despite\nexhibiting high quantization errors. To more accurately evaluate classification\nperformance, we propose to directly investigate the feature discrimination of\nquantized data, instead of analyzing its quantization error. Interestingly, it\nis found that both binary and ternary quantization methods can improve, rather\nthan degrade, the feature discrimination of the original data. This remarkable\nperformance is validated through classification experiments across various data\ntypes, including images, speech, and texts.", "published": "2025-04-18 16:44:12", "link": "http://arxiv.org/abs/2504.13792v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On the Relationship Between Robustness and Expressivity of Graph Neural Networks", "abstract": "We investigate the vulnerability of Graph Neural Networks (GNNs) to bit-flip\nattacks (BFAs) by introducing an analytical framework to study the influence of\narchitectural features, graph properties, and their interaction.\n  The expressivity of GNNs refers to their ability to distinguish\nnon-isomorphic graphs and depends on the encoding of node neighborhoods. We\nexamine the vulnerability of neural multiset functions commonly used for this\npurpose and establish formal criteria to characterize a GNN's susceptibility to\nlosing expressivity due to BFAs. This enables an analysis of the impact of\nhomophily, graph structural variety, feature encoding, and activation functions\non GNN robustness. We derive theoretical bounds for the number of bit flips\nrequired to degrade GNN expressivity on a dataset, identifying ReLU-activated\nGNNs operating on highly homophilous graphs with low-dimensional or one-hot\nencoded features as particularly susceptible. Empirical results using ten\nreal-world datasets confirm the statistical significance of our key theoretical\ninsights and offer actionable results to mitigate BFA risks in\nexpressivity-critical applications.", "published": "2025-04-18 16:38:33", "link": "http://arxiv.org/abs/2504.13786v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems", "abstract": "Accurate real-time modeling of multi-body dynamical systems is essential for\nenabling digital twin applications across industries. While many data-driven\napproaches aim to learn system dynamics, jointly predicting internal loads and\nsystem trajectories remains a key challenge. This dual prediction is especially\nimportant for fault detection and predictive maintenance, where internal\nloads-such as contact forces-act as early indicators of faults, reflecting wear\nor misalignment before affecting motion. These forces also serve as inputs to\ndegradation models (e.g., crack growth), enabling damage prediction and\nremaining useful life estimation. We propose Equi-Euler GraphNet, a\nphysics-informed graph neural network (GNN) that simultaneously predicts\ninternal forces and global trajectories in multi-body systems. In this\nmesh-free framework, nodes represent system components and edges encode\ninteractions. Equi-Euler GraphNet introduces two inductive biases: (1) an\nequivariant message-passing scheme, interpreting edge messages as interaction\nforces consistent under Euclidean transformations; and (2) a temporal-aware\niterative node update mechanism, based on Euler integration, to capture\ninfluence of distant interactions over time. Tailored for cylindrical roller\nbearings, it decouples ring dynamics from constrained motion of rolling\nelements. Trained on high-fidelity multiphysics simulations, Equi-Euler\nGraphNet generalizes beyond the training distribution, accurately predicting\nloads and trajectories under unseen speeds, loads, and configurations. It\noutperforms state-of-the-art GNNs focused on trajectory prediction, delivering\nstable rollouts over thousands of time steps with minimal error accumulation.\nAchieving up to a 200x speedup over conventional solvers while maintaining\ncomparable accuracy, it serves as an efficient reduced-order model for digital\ntwins, design, and maintenance.", "published": "2025-04-18 16:09:57", "link": "http://arxiv.org/abs/2504.13768v1", "categories": ["cs.LG", "cs.CE", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Predictors of Childhood Vaccination Uptake in England: An Explainable Machine Learning Analysis of Longitudinal Regional Data (2021-2024)", "abstract": "Childhood vaccination is a cornerstone of public health, yet disparities in\nvaccination coverage persist across England. These disparities are shaped by\ncomplex interactions among various factors, including geographic, demographic,\nsocioeconomic, and cultural (GDSC) factors. Previous studies mostly rely on\ncross-sectional data and traditional statistical approaches that assess\nindividual or limited sets of variables in isolation. Such methods may fall\nshort in capturing the dynamic and multivariate nature of vaccine uptake. In\nthis paper, we conducted a longitudinal machine learning analysis of childhood\nvaccination coverage across 150 districts in England from 2021 to 2024. Using\nvaccination data from NHS records, we applied hierarchical clustering to group\ndistricts by vaccination coverage into low- and high-coverage clusters. A\nCatBoost classifier was then trained to predict districts' vaccination clusters\nusing their GDSC data. Finally, the SHapley Additive exPlanations (SHAP) method\nwas used to interpret the predictors' importance. The classifier achieved high\naccuracies of 92.1, 90.6, and 86.3 in predicting districts' vaccination\nclusters for the years 2021-2022, 2022-2023, and 2023-2024, respectively. SHAP\nrevealed that geographic, cultural, and demographic variables, particularly\nrurality, English language proficiency, the percentage of foreign-born\nresidents, and ethnic composition, were the most influential predictors of\nvaccination coverage, whereas socioeconomic variables, such as deprivation and\nemployment, consistently showed lower importance, especially in 2023-2024.\nSurprisingly, rural districts were significantly more likely to have higher\nvaccination rates. Additionally, districts with lower vaccination coverage had\nhigher populations whose first language was not English, who were born outside\nthe UK, or who were from ethnic minority groups.", "published": "2025-04-18 15:41:26", "link": "http://arxiv.org/abs/2504.13755v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Dynamic Regularized CBDT: Variance-Calibrated Causal Boosting for Interpretable Heterogeneous Treatment Effects", "abstract": "Heterogeneous treatment effect estimation in high-stakes applications demands\nmodels that simultaneously optimize precision, interpretability, and\ncalibration. Many existing tree-based causal inference techniques, however,\nexhibit high estimation errors when applied to observational data because they\nstruggle to capture complex interactions among factors and rely on static\nregularization schemes. In this work, we propose Dynamic Regularized Causal\nBoosted Decision Trees (CBDT), a novel framework that integrates variance\nregularization and average treatment effect calibration into the loss function\nof gradient boosted decision trees. Our approach dynamically updates the\nregularization parameters using gradient statistics to better balance the\nbias-variance tradeoff. Extensive experiments on standard benchmark datasets\nand real-world clinical data demonstrate that the proposed method significantly\nimproves estimation accuracy while maintaining reliable coverage of true\ntreatment effects. In an intensive care unit patient triage study, the method\nsuccessfully identified clinically actionable rules and achieved high accuracy\nin treatment effect estimation. The results validate that dynamic\nregularization can effectively tighten error bounds and enhance both predictive\nperformance and model interpretability.", "published": "2025-04-18 15:02:06", "link": "http://arxiv.org/abs/2504.13733v1", "categories": ["cs.LG", "stat.ML", "68T05, 62H12, 90C30", "I.2.6; G.3; I.5.1"], "primary_category": "cs.LG"}
{"title": "MEGA: Second-Order Gradient Alignment for Catastrophic Forgetting Mitigation in GFSCIL", "abstract": "Graph Few-Shot Class-Incremental Learning (GFSCIL) enables models to\ncontinually learn from limited samples of novel tasks after initial training on\na large base dataset. Existing GFSCIL approaches typically utilize Prototypical\nNetworks (PNs) for metric-based class representations and fine-tune the model\nduring the incremental learning stage. However, these PN-based methods\noversimplify learning via novel query set fine-tuning and fail to integrate\nGraph Continual Learning (GCL) techniques due to architectural constraints. To\naddress these challenges, we propose a more rigorous and practical setting for\nGFSCIL that excludes query sets during the incremental training phase. Building\non this foundation, we introduce Model-Agnostic Meta Graph Continual Learning\n(MEGA), aimed at effectively alleviating catastrophic forgetting for GFSCIL.\nSpecifically, by calculating the incremental second-order gradient during the\nmeta-training stage, we endow the model to learn high-quality priors that\nenhance incremental learning by aligning its behaviors across both the\nmeta-training and incremental learning stages. Extensive experiments on four\nmainstream graph datasets demonstrate that MEGA achieves state-of-the-art\nresults and enhances the effectiveness of various GCL methods in GFSCIL. We\nbelieve that our proposed MEGA serves as a model-agnostic GFSCIL paradigm,\npaving the way for future research.", "published": "2025-04-18 13:48:15", "link": "http://arxiv.org/abs/2504.13691v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient algorithms for the Hadamard decomposition", "abstract": "The Hadamard decomposition is a powerful technique for data analysis and\nmatrix compression, which decomposes a given matrix into the element-wise\nproduct of two or more low-rank matrices. In this paper, we develop an\nefficient algorithm to solve this problem, leveraging an alternating\noptimization approach that decomposes the global non-convex problem into a\nseries of convex sub-problems. To improve performance, we explore advanced\ninitialization strategies inspired by the singular value decomposition (SVD)\nand incorporate acceleration techniques by introducing momentum-based updates.\nBeyond optimizing the two-matrix case, we also extend the Hadamard\ndecomposition framework to support more than two low-rank matrices, enabling\napproximations with higher effective ranks while preserving computational\nefficiency. Finally, we conduct extensive experiments to compare our method\nwith the existing gradient descent-based approaches for the Hadamard\ndecomposition and with traditional low-rank approximation techniques. The\nresults highlight the effectiveness of our proposed method across diverse\ndatasets.", "published": "2025-04-18 11:14:25", "link": "http://arxiv.org/abs/2504.13633v1", "categories": ["cs.LG", "eess.SP", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On the Convergence of Irregular Sampling in Reproducing Kernel Hilbert Spaces", "abstract": "We analyse the convergence of sampling algorithms for functions in\nreproducing kernel Hilbert spaces (RKHS). To this end, we discuss approximation\nproperties of kernel regression under minimalistic assumptions on both the\nkernel and the input data. We first prove error estimates in the kernel's RKHS\nnorm. This leads us to new results concerning uniform convergence of kernel\nregression on compact domains. For Lipschitz continuous and H\\\"older continuous\nkernels, we prove convergence rates.", "published": "2025-04-18 10:57:16", "link": "http://arxiv.org/abs/2504.13623v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "stat.ML"}
{"title": "Fairness and Robustness in Machine Unlearning", "abstract": "Machine unlearning poses the challenge of ``how to eliminate the influence of\nspecific data from a pretrained model'' in regard to privacy concerns. While\nprior research on approximated unlearning has demonstrated accuracy and\nefficiency in time complexity, we claim that it falls short of achieving exact\nunlearning, and we are the first to focus on fairness and robustness in machine\nunlearning algorithms. Our study presents fairness Conjectures for a\nwell-trained model, based on the variance-bias trade-off characteristic, and\nconsiders their relevance to robustness. Our Conjectures are supported by\nexperiments conducted on the two most widely used model architectures, ResNet\nand ViT, demonstrating the correlation between fairness and robustness:\n\\textit{the higher fairness-gap is, the more the model is sensitive and\nvulnerable}. In addition, our experiments demonstrate the vulnerability of\ncurrent state-of-the-art approximated unlearning algorithms to adversarial\nattacks, where their unlearned models suffer a significant drop in accuracy\ncompared to the exact-unlearned models. We claim that our fairness-gap\nmeasurement and robustness metric should be used to evaluate the unlearning\nalgorithm. Furthermore, we demonstrate that unlearning in the intermediate and\nlast layers is sufficient and cost-effective for time and memory complexity.", "published": "2025-04-18 10:31:44", "link": "http://arxiv.org/abs/2504.13610v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bitcoin's Edge: Embedded Sentiment in Blockchain Transactional Data", "abstract": "Cryptocurrency blockchains, beyond their primary role as distributed payment\nsystems, are increasingly used to store and share arbitrary content, such as\ntext messages and files. Although often non-financial, this hidden content can\nimpact price movements by conveying private information, shaping sentiment, and\ninfluencing public opinion. However, current analyses of such data are limited\nin scope and scalability, primarily relying on manual classification or\nhand-crafted heuristics. In this work, we address these limitations by\nemploying Natural Language Processing techniques to analyze, detect patterns,\nand extract public sentiment encoded within blockchain transactional data.\nUsing a variety of Machine Learning techniques, we showcase for the first time\nthe predictive power of blockchain-embedded sentiment in forecasting\ncryptocurrency price movements on the Bitcoin and Ethereum blockchains. Our\nfindings shed light on a previously underexplored source of freely available,\ntransparent, and immutable data and introduce blockchain sentiment analysis as\na novel and robust framework for enhancing financial predictions in\ncryptocurrency markets. Incidentally, we discover an asymmetry between\ncryptocurrencies; Bitcoin has an informational advantage over Ethereum in that\nthe sentiment embedded into transactional data is sufficient to predict its\nprice movement.", "published": "2025-04-18 10:06:21", "link": "http://arxiv.org/abs/2504.13598v1", "categories": ["cs.LG", "cs.CE", "cs.CR", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Towards End-to-End Network Intent Management with Large Language Models", "abstract": "Large Language Models (LLMs) are likely to play a key role in Intent-Based\nNetworking (IBN) as they show remarkable performance in interpreting human\nlanguage as well as code generation, enabling the translation of high-level\nintents expressed by humans into low-level network configurations. In this\npaper, we leverage closed-source language models (i.e., Google Gemini 1.5 pro,\nChatGPT-4) and open-source models (i.e., LLama, Mistral) to investigate their\ncapacity to generate E2E network configurations for radio access networks\n(RANs) and core networks in 5G/6G mobile networks. We introduce a novel\nperformance metrics, known as FEACI, to quantitatively assess the format (F),\nexplainability (E), accuracy (A), cost (C), and inference time (I) of the\ngenerated answer; existing general metrics are unable to capture these\nfeatures. The results of our study demonstrate that open-source models can\nachieve comparable or even superior translation performance compared with the\nclosed-source models requiring costly hardware setup and not accessible to all\nusers.", "published": "2025-04-18 09:41:35", "link": "http://arxiv.org/abs/2504.13589v1", "categories": ["cs.NI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "How to Achieve Higher Accuracy with Less Training Points?", "abstract": "In the era of large-scale model training, the extensive use of available\ndatasets has resulted in significant computational inefficiencies. To tackle\nthis issue, we explore methods for identifying informative subsets of training\ndata that can achieve comparable or even superior model performance. We propose\na technique based on influence functions to determine which training samples\nshould be included in the training set. We conducted empirical evaluations of\nour method on binary classification tasks utilizing logistic regression models.\nOur approach demonstrates performance comparable to that of training on the\nentire dataset while using only 10% of the data. Furthermore, we found that our\nmethod achieved even higher accuracy when trained with just 60% of the data.", "published": "2025-04-18 09:38:26", "link": "http://arxiv.org/abs/2504.13586v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Hysteresis-Aware Neural Network Modeling and Whole-Body Reinforcement Learning Control of Soft Robots", "abstract": "Soft robots exhibit inherent compliance and safety, which makes them\nparticularly suitable for applications requiring direct physical interaction\nwith humans, such as surgical procedures. However, their nonlinear and\nhysteretic behavior, resulting from the properties of soft materials, presents\nsubstantial challenges for accurate modeling and control. In this study, we\npresent a soft robotic system designed for surgical applications and propose a\nhysteresis-aware whole-body neural network model that accurately captures and\npredicts the soft robot's whole-body motion, including its hysteretic behavior.\nBuilding upon the high-precision dynamic model, we construct a highly parallel\nsimulation environment for soft robot control and apply an on-policy\nreinforcement learning algorithm to efficiently train whole-body motion control\nstrategies. Based on the trained control policy, we developed a soft robotic\nsystem for surgical applications and validated it through phantom-based laser\nablation experiments in a physical environment. The results demonstrate that\nthe hysteresis-aware modeling reduces the Mean Squared Error (MSE) by 84.95\npercent compared to traditional modeling methods. The deployed control\nalgorithm achieved a trajectory tracking error ranging from 0.126 to 0.250 mm\non the real soft robot, highlighting its precision in real-world conditions.\nThe proposed method showed strong performance in phantom-based surgical\nexperiments and demonstrates its potential for complex scenarios, including\nfuture real-world clinical applications.", "published": "2025-04-18 09:34:56", "link": "http://arxiv.org/abs/2504.13582v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "MSTIM: A MindSpore-Based Model for Traffic Flow Prediction", "abstract": "Aiming at the problems of low accuracy and large error fluctuation of\ntraditional traffic flow predictionmodels when dealing with multi-scale\ntemporal features and dynamic change patterns. this paperproposes a multi-scale\ntime series information modelling model MSTIM based on the Mindspore framework,\nwhich integrates long and short-term memory networks (LSTMs), convolutional\nneural networks (CNN), and the attention mechanism to improve the modelling\naccuracy and stability. The Metropolitan Interstate Traffic Volume (MITV)\ndataset was used for the experiments and compared and analysed with typical\nLSTM-attention models, CNN-attention models and LSTM-CNN models. The\nexperimental results show that the MSTIM model achieves better results in the\nmetrics of Mean Absolute Error (MAE), Mean Square Error (MSE), and Root Mean\nSquare Error (RMSE), which significantly improves the accuracy and stability of\nthe traffic volume prediction.", "published": "2025-04-18 09:19:51", "link": "http://arxiv.org/abs/2504.13576v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bayesian continual learning and forgetting in neural networks", "abstract": "Biological synapses effortlessly balance memory retention and flexibility,\nyet artificial neural networks still struggle with the extremes of catastrophic\nforgetting and catastrophic remembering. Here, we introduce Metaplasticity from\nSynaptic Uncertainty (MESU), a Bayesian framework that updates network\nparameters according their uncertainty. This approach allows a principled\ncombination of learning and forgetting that ensures that critical knowledge is\npreserved while unused or outdated information is gradually released. Unlike\nstandard Bayesian approaches -- which risk becoming overly constrained, and\npopular continual-learning methods that rely on explicit task boundaries, MESU\nseamlessly adapts to streaming data. It further provides reliable epistemic\nuncertainty estimates, allowing out-of-distribution detection, the only\ncomputational cost being to sample the weights multiple times to provide proper\noutput statistics. Experiments on image-classification benchmarks demonstrate\nthat MESU mitigates catastrophic forgetting, while maintaining plasticity for\nnew tasks. When training 200 sequential permuted MNIST tasks, MESU outperforms\nestablished continual learning techniques in terms of accuracy, capability to\nlearn additional tasks, and out-of-distribution data detection. Additionally,\ndue to its non-reliance on task boundaries, MESU outperforms conventional\nlearning techniques on the incremental training of CIFAR-100 tasks consistently\nin a wide range of scenarios. Our results unify ideas from metaplasticity,\nBayesian inference, and Hessian-based regularization, offering a\nbiologically-inspired pathway to robust, perpetual learning.", "published": "2025-04-18 09:11:34", "link": "http://arxiv.org/abs/2504.13569v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Can Local Representation Alignment RNNs Solve Temporal Tasks?", "abstract": "Recurrent Neural Networks (RNNs) are commonly used for real-time processing,\nstreaming data, and cases where the amount of training samples is limited.\nBackpropagation Through Time (BPTT) is the predominant algorithm for training\nRNNs; however, it is frequently criticized for being prone to exploding and\nvanishing gradients and being biologically implausible. In this paper, we\npresent and evaluate a target propagation-based method for RNNs, which uses\nlocal updates and seeks to reduce the said instabilities. Having stable RNN\nmodels increases their practical use in a wide range of fields such as natural\nlanguage processing, time-series forecasting, anomaly detection, control\nsystems, and robotics.\n  The proposed solution uses local representation alignment (LRA). We\nthoroughly analyze the performance of this method, experiment with\nnormalization and different local error functions, and invalidate certain\nassumptions about the behavior of this type of learning. Namely, we demonstrate\nthat despite the decomposition of the network into sub-graphs, the model still\nsuffers from vanishing gradients. We also show that gradient clipping as\nproposed in LRA has little to no effect on network performance. This results in\nan LRA RNN model that is very difficult to train due to vanishing gradients. We\naddress this by introducing gradient regularization in the direction of the\nupdate and demonstrate that this modification promotes gradient flow and\nmeaningfully impacts convergence. We compare and discuss the performance of the\nalgorithm, and we show that the regularized LRA RNN considerably outperforms\nthe unregularized version on three landmark tasks: temporal order, 3-bit\ntemporal order, and random permutation.", "published": "2025-04-18 07:48:48", "link": "http://arxiv.org/abs/2504.13531v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Risk-aware black-box portfolio construction using Bayesian optimization with adaptive weighted Lagrangian estimator", "abstract": "Existing portfolio management approaches are often black-box models due to\nsafety and commercial issues in the industry. However, their performance can\nvary considerably whenever market conditions or internal trading strategies\nchange. Furthermore, evaluating these non-transparent systems is expensive,\nwhere certain budgets limit observations of the systems. Therefore, optimizing\nperformance while controlling the potential risk of these financial systems has\nbecome a critical challenge. This work presents a novel Bayesian optimization\nframework to optimize black-box portfolio management models under limited\nobservations. In conventional Bayesian optimization settings, the objective\nfunction is to maximize the expectation of performance metrics. However, simply\nmaximizing performance expectations leads to erratic optimization trajectories,\nwhich exacerbate risk accumulation in portfolio management. Meanwhile, this can\nlead to misalignment between the target distribution and the actual\ndistribution of the black-box model. To mitigate this problem, we propose an\nadaptive weight Lagrangian estimator considering dual objective, which\nincorporates maximizing model performance and minimizing variance of model\nobservations. Extensive experiments demonstrate the superiority of our approach\nover five backtest settings with three black-box stock portfolio management\nmodels. Ablation studies further verify the effectiveness of the proposed\nestimator.", "published": "2025-04-18 07:40:24", "link": "http://arxiv.org/abs/2504.13529v1", "categories": ["cs.LG", "cs.SY", "eess.SY", "q-fin.CP", "q-fin.PM"], "primary_category": "cs.LG"}
{"title": "Designing a reliable lateral movement detector using a graph foundation model", "abstract": "Foundation models have recently emerged as a new paradigm in machine learning\n(ML). These models are pre-trained on large and diverse datasets and can\nsubsequently be applied to various downstream tasks with little or no\nretraining. This allows people without advanced ML expertise to build ML\napplications, accelerating innovation across many fields. However, the adoption\nof foundation models in cybersecurity is hindered by their inability to\nefficiently process data such as network traffic captures or binary\nexecutables. The recent introduction of graph foundation models (GFMs) could\nmake a significant difference, as graphs are well-suited to representing these\ntypes of data. We study the usability of GFMs in cybersecurity through the lens\nof one specific use case, namely lateral movement detection. Using a\npre-trained GFM, we build a detector that reaches state-of-the-art performance\nwithout requiring any training on domain-specific data. This case study thus\nprovides compelling evidence of the potential of GFMs for cybersecurity.", "published": "2025-04-18 07:39:21", "link": "http://arxiv.org/abs/2504.13527v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Cross-Modal Temporal Fusion for Financial Market Forecasting", "abstract": "Accurate financial market forecasting requires diverse data sources,\nincluding historical price trends, macroeconomic indicators, and financial\nnews, each contributing unique predictive signals. However, existing methods\noften process these modalities independently or fail to effectively model their\ninteractions. In this paper, we introduce Cross-Modal Temporal Fusion (CMTF), a\nnovel transformer-based framework that integrates heterogeneous financial data\nto improve predictive accuracy. Our approach employs attention mechanisms to\ndynamically weight the contribution of different modalities, along with a\nspecialized tensor interpretation module for feature extraction. To facilitate\nrapid model iteration in industry applications, we incorporate a mature\nauto-training scheme that streamlines optimization. When applied to real-world\nfinancial datasets, CMTF demonstrates improvements over baseline models in\nforecasting stock price movements and provides a scalable and effective\nsolution for cross-modal integration in financial market prediction.", "published": "2025-04-18 07:20:18", "link": "http://arxiv.org/abs/2504.13522v1", "categories": ["cs.LG", "cs.NE", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "Monitor and Recover: A Paradigm for Future Research on Distribution Shift in Learning-Enabled Cyber-Physical Systems", "abstract": "With the known vulnerability of neural networks to distribution shift,\nmaintaining reliability in learning-enabled cyber-physical systems poses a\nsalient challenge. In response, many existing methods adopt a detect and\nabstain methodology, aiming to detect distribution shift at inference time so\nthat the learning-enabled component can abstain from decision-making. This\napproach, however, has limited use in real-world applications. We instead\npropose a monitor and recover paradigm as a promising direction for future\nresearch. This philosophy emphasizes 1) robust safety monitoring instead of\ndistribution shift detection and 2) distribution shift recovery instead of\nabstention. We discuss two examples from our recent work.", "published": "2025-04-18 05:48:35", "link": "http://arxiv.org/abs/2504.13484v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Latent Tensor Factorization with Nonlinear PID Control for Missing Data Recovery in Non-Intrusive Load Monitoring", "abstract": "Non-Intrusive Load Monitoring (NILM) has emerged as a key smart grid\ntechnology, identifying electrical device and providing detailed energy\nconsumption data for precise demand response management. Nevertheless, NILM\ndata suffers from missing values due to inescapable factors like sensor\nfailure, leading to inaccuracies in non-intrusive load monitoring. A stochastic\ngradient descent (SGD)-based latent factorization of tensors model has proven\nto be effective in estimating missing data, however, it updates a latent factor\nsolely based on the current stochastic gradient, without considering past\ninformation, which leads to slow convergence of anLFT model. To address this\nissue, this paper proposes a Nonlinear Proportional-integral-derivative\n(PID)-Incorporated Latent factorization of tensors (NPIL) model with two-fold\nideas: a) rebuilding the instant learning error according to the principle of a\nnonlinear PID controller, thus, the past update information is efficiently\nincorporated into the learning scheme, and b) implementing gain parameter\nadaptation by utilizing particle swarm optimization (PSO) algorithm, hence, the\nmodel computational efficiency is effectively improved. Experimental results on\nreal-world NILM datasets demonstrate that the proposed NPIL model surpasses\nstate-of-the-art models in convergence rate and accuracy when predicting the\nmissing NILM data.", "published": "2025-04-18 05:48:14", "link": "http://arxiv.org/abs/2504.13483v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SFL-LEO: Asynchronous Split-Federated Learning Design for LEO Satellite-Ground Network Framework", "abstract": "Recently, the rapid development of LEO satellite networks spurs another\nwidespread concern-data processing at satellites. However, achieving efficient\ncomputation at LEO satellites in highly dynamic satellite networks is\nchallenging and remains an open problem when considering the constrained\ncomputation capability of LEO satellites. For the first time, we propose a\nnovel distributed learning framework named SFL-LEO by combining Federated\nLearning (FL) with Split Learning (SL) to accommodate the high dynamics of LEO\nsatellite networks and the constrained computation capability of LEO satellites\nby leveraging the periodical orbit traveling feature. The proposed scheme\nallows training locally by introducing an asynchronous training strategy, i.e.,\nachieving local update when LEO satellites disconnect with the ground station,\nto provide much more training space and thus increase the training performance.\nMeanwhile, it aggregates client-side sub-models at the ground station and then\ndistributes them to LEO satellites by borrowing the idea from the federated\nlearning scheme. Experiment results driven by satellite-ground bandwidth\nmeasured in Starlink demonstrate that SFL-LEO provides a similar accuracy\nperformance with the conventional SL scheme because it can perform local\ntraining even within the disconnection duration.", "published": "2025-04-18 05:43:11", "link": "http://arxiv.org/abs/2504.13479v1", "categories": ["cs.NI", "cs.DC", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Safety Monitoring for Learning-Enabled Cyber-Physical Systems in Out-of-Distribution Scenarios", "abstract": "The safety of learning-enabled cyber-physical systems is compromised by the\nwell-known vulnerabilities of deep neural networks to out-of-distribution (OOD)\ninputs. Existing literature has sought to monitor the safety of such systems by\ndetecting OOD data. However, such approaches have limited utility, as the\npresence of an OOD input does not necessarily imply the violation of a desired\nsafety property. We instead propose to directly monitor safety in a manner that\nis itself robust to OOD data. To this end, we predict violations of signal\ntemporal logic safety specifications based on predicted future trajectories.\nOur safety monitor additionally uses a novel combination of adaptive conformal\nprediction and incremental learning. The former obtains probabilistic\nprediction guarantees even on OOD data, and the latter prevents overly\nconservative predictions. We evaluate the efficacy of the proposed approach in\ntwo case studies on safety monitoring: 1) predicting collisions of an F1Tenth\ncar with static obstacles, and 2) predicting collisions of a race car with\nmultiple dynamic obstacles. We find that adaptive conformal prediction obtains\ntheoretical guarantees where other uncertainty quantification methods fail to\ndo so. Additionally, combining adaptive conformal prediction and incremental\nlearning for safety monitoring achieves high recall and timeliness while\nreducing loss in precision. We achieve these results even in OOD settings and\noutperform alternative methods.", "published": "2025-04-18 05:42:37", "link": "http://arxiv.org/abs/2504.13478v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Are you SURE? Enhancing Multimodal Pretraining with Missing Modalities through Uncertainty Estimation", "abstract": "Multimodal learning has demonstrated incredible successes by integrating\ndiverse data sources, yet it often relies on the availability of all modalities\n- an assumption that rarely holds in real-world applications. Pretrained\nmultimodal models, while effective, struggle when confronted with small-scale\nand incomplete datasets (i.e., missing modalities), limiting their practical\napplicability. Previous studies on reconstructing missing modalities have\noverlooked the reconstruction's potential unreliability, which could compromise\nthe quality of the final outputs. We present SURE (Scalable Uncertainty and\nReconstruction Estimation), a novel framework that extends the capabilities of\npretrained multimodal models by introducing latent space reconstruction and\nuncertainty estimation for both reconstructed modalities and downstream tasks.\nOur method is architecture-agnostic, reconstructs missing modalities, and\ndelivers reliable uncertainty estimates, improving both interpretability and\nperformance. SURE introduces a unique Pearson Correlation-based loss and\napplies statistical error propagation in deep networks for the first time,\nallowing precise quantification of uncertainties from missing data and model\npredictions. Extensive experiments across tasks such as sentiment analysis,\ngenre classification, and action recognition show that SURE consistently\nachieves state-of-the-art performance, ensuring robust predictions even in the\npresence of incomplete data.", "published": "2025-04-18 05:07:20", "link": "http://arxiv.org/abs/2504.13465v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Stratify: Rethinking Federated Learning for Non-IID Data through Balanced Sampling", "abstract": "Federated Learning (FL) on non-independently and identically distributed\n(non-IID) data remains a critical challenge, as existing approaches struggle\nwith severe data heterogeneity. Current methods primarily address symptoms of\nnon-IID by applying incremental adjustments to Federated Averaging (FedAvg),\nrather than directly resolving its inherent design limitations. Consequently,\nperformance significantly deteriorates under highly heterogeneous conditions,\nas the fundamental issue of imbalanced exposure to diverse class and feature\ndistributions remains unresolved. This paper introduces Stratify, a novel FL\nframework designed to systematically manage class and feature distributions\nthroughout training, effectively tackling the root cause of non-IID challenges.\nInspired by classical stratified sampling, our approach employs a Stratified\nLabel Schedule (SLS) to ensure balanced exposure across labels, significantly\nreducing bias and variance in aggregated gradients. Complementing SLS, we\npropose a label-aware client selection strategy, restricting participation\nexclusively to clients possessing data relevant to scheduled labels.\nAdditionally, Stratify incorporates a fine-grained, high-frequency update\nscheme, accelerating convergence and further mitigating data heterogeneity. To\nuphold privacy, we implement a secure client selection protocol leveraging\nhomomorphic encryption, enabling precise global label statistics without\ndisclosing sensitive client information. Extensive evaluations on MNIST,\nCIFAR-10, CIFAR-100, Tiny-ImageNet, COVTYPE, PACS, and Digits-DG demonstrate\nthat Stratify attains performance comparable to IID baselines, accelerates\nconvergence, and reduces client-side computation compared to state-of-the-art\nmethods, underscoring its practical effectiveness in realistic federated\nlearning scenarios.", "published": "2025-04-18 04:44:41", "link": "http://arxiv.org/abs/2504.13462v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Using Machine Learning and Neural Networks to Analyze and Predict Chaos in Multi-Pendulum and Chaotic Systems", "abstract": "A chaotic system is a highly volatile system characterized by its sensitive\ndependence on initial conditions and outside factors. Chaotic systems are\nprevalent throughout the world today: in weather patterns, disease outbreaks,\nand even financial markets. Chaotic systems are seen in every field of science\nand humanities, so being able to predict these systems is greatly beneficial to\nsociety. In this study, we evaluate 10 different machine learning models and\nneural networks [1] based on Root Mean Squared Error (RMSE) and R^2 values for\ntheir ability to predict one of these systems, the multi-pendulum. We begin by\ngenerating synthetic data representing the angles of the pendulum over time\nusing the Runge Kutta Method for solving 4th Order Differential Equations\n(ODE-RK4) [2]. At first, we used the single-step sliding window approach,\npredicting the 50st step after training for steps 0-49 and so forth. However,\nto more accurately cover chaotic motion and behavior in these systems, we\ntransitioned to a time-step based approach. Here, we trained the model/network\non many initial angles and tested it on a completely new set of initial angles,\nor 'in-between' to capture chaotic motion to its fullest extent. We also\nevaluated the stability of the system using Lyapunov exponents. We concluded\nthat for a double pendulum, the best model was the Long Short Term Memory\nNetwork (LSTM)[3] for the sliding window and time step approaches in both\nfriction and frictionless scenarios. For triple pendulum, the Vanilla Recurrent\nNeural Network (VRNN)[4] was the best for the sliding window and Gated\nRecurrent Network (GRU) [5] was the best for the time step approach, but for\nfriction, LSTM was the best.", "published": "2025-04-18 04:12:14", "link": "http://arxiv.org/abs/2504.13453v1", "categories": ["cs.LG", "nlin.CD"], "primary_category": "cs.LG"}
{"title": "Simplifying Graph Convolutional Networks with Redundancy-Free Neighbors", "abstract": "In recent years, Graph Convolutional Networks (GCNs) have gained popularity\nfor their exceptional ability to process graph-structured data. Existing\nGCN-based approaches typically employ a shallow model architecture due to the\nover-smoothing phenomenon. Current approaches to mitigating over-smoothing\nprimarily involve adding supplementary components to GCN architectures, such as\nresidual connections and random edge-dropping strategies. However, these\nimprovements toward deep GCNs have achieved only limited success. In this work,\nwe analyze the intrinsic message passing mechanism of GCNs and identify a\ncritical issue: messages originating from high-order neighbors must traverse\nthrough low-order neighbors to reach the target node. This repeated reliance on\nlow-order neighbors leads to redundant information aggregation, a phenomenon we\nterm over-aggregation. Our analysis demonstrates that over-aggregation not only\nintroduces significant redundancy but also serves as the fundamental cause of\nover-smoothing in GCNs.", "published": "2025-04-18 02:56:21", "link": "http://arxiv.org/abs/2504.13426v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Equilibrium Conserving Neural Operators for Super-Resolution Learning", "abstract": "Neural surrogate solvers can estimate solutions to partial differential\nequations in physical problems more efficiently than standard numerical\nmethods, but require extensive high-resolution training data. In this paper, we\nbreak this limitation; we introduce a framework for super-resolution learning\nin solid mechanics problems. Our approach allows one to train a high-resolution\nneural network using only low-resolution data. Our Equilibrium Conserving\nOperator (ECO) architecture embeds known physics directly into the network to\nmake up for missing high-resolution information during training. We evaluate\nthis ECO-based super-resolution framework that strongly enforces\nconservation-laws in the predicted solutions on two working examples: embedded\npores in a homogenized matrix and randomly textured polycrystalline materials.\nECO eliminates the reliance on high-fidelity data and reduces the upfront cost\nof data collection by two orders of magnitude, offering a robust pathway for\nresource-efficient surrogate modeling in materials modeling. ECO is readily\ngeneralizable to other physics-based problems.", "published": "2025-04-18 02:47:53", "link": "http://arxiv.org/abs/2504.13422v1", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "A Model-Based Approach to Imitation Learning through Multi-Step Predictions", "abstract": "Imitation learning is a widely used approach for training agents to replicate\nexpert behavior in complex decision-making tasks. However, existing methods\noften struggle with compounding errors and limited generalization, due to the\ninherent challenge of error correction and the distribution shift between\ntraining and deployment. In this paper, we present a novel model-based\nimitation learning framework inspired by model predictive control, which\naddresses these limitations by integrating predictive modeling through\nmulti-step state predictions. Our method outperforms traditional behavior\ncloning numerical benchmarks, demonstrating superior robustness to distribution\nshift and measurement noise both in available data and during execution.\nFurthermore, we provide theoretical guarantees on the sample complexity and\nerror bounds of our method, offering insights into its convergence properties.", "published": "2025-04-18 02:19:30", "link": "http://arxiv.org/abs/2504.13413v1", "categories": ["cs.LG", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "OpCode-Based Malware Classification Using Machine Learning and Deep Learning Techniques", "abstract": "This technical report presents a comprehensive analysis of malware\nclassification using OpCode sequences. Two distinct approaches are evaluated:\ntraditional machine learning using n-gram analysis with Support Vector Machine\n(SVM), K-Nearest Neighbors (KNN), and Decision Tree classifiers; and a deep\nlearning approach employing a Convolutional Neural Network (CNN). The\ntraditional machine learning approach establishes a baseline using handcrafted\n1-gram and 2-gram features from disassembled malware samples. The deep learning\nmethodology builds upon the work proposed in \"Deep Android Malware Detection\"\nby McLaughlin et al. and evaluates the performance of a CNN model trained to\nautomatically extract features from raw OpCode data. Empirical results are\ncompared using standard performance metrics (accuracy, precision, recall, and\nF1-score). While the SVM classifier outperforms other traditional techniques,\nthe CNN model demonstrates competitive performance with the added benefit of\nautomated feature extraction.", "published": "2025-04-18 02:09:57", "link": "http://arxiv.org/abs/2504.13408v1", "categories": ["cs.CR", "cs.LG", "68T05 (Primary), 68Q25, 68Q10 (Secondary)", "I.2.6; I.2.8; F.2.2; D.4.6"], "primary_category": "cs.CR"}
{"title": "Quantum repeaters enhanced by vacuum beam guides", "abstract": "The development of large-scale quantum communication networks faces critical\nchallenges due to photon loss and decoherence in optical fiber channels. These\nfundamentally limit transmission distances and demand dense networks of\nrepeater stations. This work investigates using vacuum beam guides (VBGs)-a\npromising ultra-low-loss transmission platform-as an alternative to traditional\nfiber links. By incorporating VBGs into repeater-based architectures, we\ndemonstrate that the inter-repeater spacing can be substantially extended,\nresulting in fewer required nodes and significantly reducing hardware and\noperational complexity. We perform a cost-function analysis to quantify\nperformance trade-offs across first, second, and third-generation repeaters.\nOur results show that first-generation repeaters reduce costs dramatically by\neliminating entanglement purification. Third-generation repeaters benefit from\nimproved link transmission success, which is crucial for quantum error\ncorrection. In contrast, second-generation repeaters exhibit a more nuanced\nresponse; although transmission loss is reduced, their performance remains\nprimarily limited by logical gate errors rather than channel loss. These\nfindings highlight that while all repeater generations benefit from reduced\nphoton loss, the magnitude of improvement depends critically on the underlying\nerror mechanisms. Vacuum beam guides thus emerge as a powerful enabler for\nscalable, high-performance quantum networks, particularly in conjunction with\nnear-term quantum hardware capabilities.", "published": "2025-04-18 01:19:12", "link": "http://arxiv.org/abs/2504.13397v1", "categories": ["quant-ph", "cs.DC", "cs.LG", "cs.NI"], "primary_category": "quant-ph"}
{"title": "Inverse Inference on Cooperative Control of Networked Dynamical Systems", "abstract": "Recent years have witnessed the rapid advancement of understanding the\ncontrol mechanism of networked dynamical systems (NDSs), which are governed by\ncomponents such as nodal dynamics and topology. This paper reveals that the\ncritical components in continuous-time state feedback cooperative control of\nNDSs can be inferred merely from discrete observations. In particular, we\nadvocate a bi-level inference framework to estimate the global closed-loop\nsystem and extract the components, respectively. The novelty lies in bridging\nthe gap from discrete observations to the continuous-time model and effectively\ndecoupling the concerned components. Specifically, in the first level, we\ndesign a causality-based estimator for the discrete-time closed-loop system\nmatrix, which can achieve asymptotically unbiased performance when the NDS is\nstable. In the second level, we introduce a matrix logarithm based method to\nrecover the continuous-time counterpart matrix, providing new sampling period\nguarantees and establishing the recovery error bound. By utilizing graph\nproperties of the NDS, we develop least square based procedures to decouple the\nconcerned components with up to a scalar ambiguity. Furthermore, we employ\ninverse optimal control techniques to reconstruct the objective function\ndriving the control process, deriving necessary conditions for the solutions.\nNumerical simulations demonstrate the effectiveness of the proposed method.", "published": "2025-04-18 14:02:29", "link": "http://arxiv.org/abs/2504.13701v1", "categories": ["eess.SY", "cs.MA", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Preconditioning FEM discretisations of the high-frequency Maxwell equations by either perturbing the coefficients or adding absorption", "abstract": "We prove bounds on $\\mathsf{I} - \\mathsf{A}_2^{-1}\\mathsf{A}_1$ where\n$\\mathsf{A}_\\ell$, $\\ell=1,2$, are the Galerkin matrices corresponding to\nfinite-element discretisations of the time-harmonic Maxwell equations\n$k^{-2}{\\rm curl} (\\mu_\\ell^{-1}{\\rm curl} E_\\ell) - \\epsilon_\\ell E_\\ell =f$;\ni.e., we consider the situation where the Maxwell FEM matrix is preconditioned\nby the FEM matrix arising from the same Maxwell problem but with different\ncoefficients. An important special case is when the perturbation consists of\nadding absorption (in the spirit of \"shifted Laplacian preconditioning\" for the\nHelmholtz equation). The results of this paper are the Maxwell analogues of the\nHelmholtz results in [Gander, Graham, Spence, 2015] and [Graham, Pembery,\nSpence, 2021], and confirm a conjecture in the recent preprint [Li, Hu, arXiv\n2501.18305]. These results are obtained by putting the Maxwell problem in an\nabstract framework that also includes the Helmholtz problem; as a byproduct we\nweaken the assumptions required to obtain the Helmholtz results in [Gander,\nGraham, Spence, 2015] and [Graham, Pembery, Spence, 2021].", "published": "2025-04-18 17:39:34", "link": "http://arxiv.org/abs/2504.13814v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Fast Direct Solver for Boundary Integral Equations Using Quadrature By Expansion", "abstract": "We construct and analyze a hierarchical direct solver for linear systems\narising from the discretization of boundary integral equations using the\nQuadrature by Expansion (QBX) method. Our scheme builds on the existing theory\nof Hierarchical Semi-Separable (HSS) matrix operators that contain low-rank\noff-diagonal submatrices. We use proxy-based approximations of the far-field\ninteractions and the Interpolative Decomposition (ID) to construct compressed\nHSS operators that are used as fast direct solvers for the original system. We\ndescribe a number of modifications to the standard HSS framework that enable\ncompatibility with the QBX family of discretization methods. We establish an\nerror model for the direct solver that is based on a multipole expansion of the\nQBX-mediated proxy interactions and standard estimates for the ID\\@. Based on\nthese theoretical results, we develop an automatic approach for setting scheme\nparameters based on user-provided error tolerances. The resulting solver\nseamlessly generalizes across two- and tree-dimensional problems and achieves\nstate-of-the-art asymptotic scaling. We conclude with numerical experiments\nthat support the theoretical expectations for the error and computational cost\nof the direct solver.", "published": "2025-04-18 17:25:11", "link": "http://arxiv.org/abs/2504.13809v1", "categories": ["math.NA", "cs.NA", "31B10, 31C20, 35C15, 33C55, 42A10, 47B34, 65F05"], "primary_category": "math.NA"}
{"title": "Gevrey class regularity for steady-state incompressible Navier-Stokes equations in parametric domains and related models", "abstract": "We investigate parameteric Navier-Stokes equations for a viscous,\nincompressible flow in bounded domains. The coefficients of the equations are\nperturbed by high-dimensional random parameters, this fits in particular for\nmodelling flows in domains with uncertain perturbations. Our focus is on\nderiving bounds for arbitrary high-order derivatives of the pressure and the\nvelocity fields with respect to the random parameters in the context of\nincompressible Navier-Stokes equation under a small-data assumption. To achieve\nthis, we analyze mixed and saddle-point problems and employ the\nalternative-to-factorial technique to establish generalized Gevrey-class\nregularity for the solution pair. Thereby the analytic regularity follows as a\nspecial case. In the numerical experiments, we validate and illustrate our\ntheoretical findings using Gauss-Legendre quadrature and Quasi-Monte Carlo\nmethods.", "published": "2025-04-18 15:36:34", "link": "http://arxiv.org/abs/2504.13753v1", "categories": ["math.NA", "cs.NA", "35Q30, 65C30, 65D30, 65D32, 65N30", "G.1.8; G.1.4"], "primary_category": "math.NA"}
{"title": "Adaptive time-stepping and maximum-principle preserving Lagrangian schemes for gradient flows", "abstract": "We develop in this paper an adaptive time-stepping approach for gradient\nflows with distinct treatments for conservative and non-conservative dynamics.\nFor the non-conservative gradient flows in Lagrangian coordinates, we propose a\nmodified formulation augmented by auxiliary terms to guarantee positivity of\nthe determinant, and prove that the corresponding adaptive second-order\nBackward Difference Formulas (BDF2) scheme preserves energy stability and the\nmaximum principle under the time-step ratio constraint $0<r_n\\le\nr_{\\max}\\le\\frac{3}{2}$. On the other hand, for the conservative Wasserstein\ngradient flows in Lagrangian coordinates, we propose an adaptive BDF2 scheme\nwhich is shown to be energy dissipative, and positivity preserving under the\ntime-step ratio constraint $0<r_n\\le r_{\\max}\\le\\frac{3+\\sqrt{17}}{2}$ in 1D\nand $0<r_n\\le r_{\\max}\\le \\frac{5}{4}$ in 2D, respectively. We also present\nample numerical simulations in 1D and 2D to validate the efficiency and\naccuracy of the proposed schemes.", "published": "2025-04-18 08:38:07", "link": "http://arxiv.org/abs/2504.13552v1", "categories": ["math.NA", "cs.NA", "35K55, 35K65, 65M06, 65M12"], "primary_category": "math.NA"}
{"title": "Convergence of the fully discrete JKO scheme", "abstract": "The JKO scheme provides the discrete-in-time approximation for the solutions\nof evolutionary equations with Wasserstein gradient structure. We study a\nnatural space-discretization of this scheme by restricting the minimization to\nthe measures supported on the nodes of a regular grid. The study of the fully\ndiscrete JKO scheme is motivated by the applications to developing numerical\nschemes for the nonlinear diffusion equation with drift and the crowd motion\nmodel. The main result of this paper is the convergence of the scheme as both\nthe time and space discretization parameters tend to zero in a suitable regime.", "published": "2025-04-18 07:04:08", "link": "http://arxiv.org/abs/2504.13513v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "An asymptotic preserving scheme for the quantum Liouville-BGK equation", "abstract": "We are interested in this work in the numerical resolution of the Quantum\nLiouville-BGK equation, which arises in the derivation of quantum\nhydrodynamical models from first principles. Such models are often obtained in\nsome asymptotic limits, for instance a diffusion or a fluid limit, and as a\nconsequence the original Liouville equation contains small parameters. A\nstandard method such as a split-step algorithm is then accurate provided the\ntime step is sufficiently small compared to the asymptotic parameter, which is\na severe limitation. In the case of the diffusion limit, we propose a numerical\nmethod that is accurate for time steps independent of the small parameter, and\nwhich captures well both the microscopic dynamics and the diffusion limit. Our\napproach is substantiated by an informal theoretical error analysis.", "published": "2025-04-18 05:51:10", "link": "http://arxiv.org/abs/2504.13487v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "Finite difference schemes for Hamilton--Jacobi equation on Wasserstein space on graphs", "abstract": "This work proposes and studies numerical schemes for initial value problems\nof Hamilton--Jacobi equations (HJEs) with a graph individual noise on the\nWasserstein space on graphs. Numerically solving such equations is particularly\nchallenging due to the structural complexity caused by discrete geometric\nderivatives and logarithmic geometry. Our numerical schemes are constructed\nusing finite difference approximations that are adapted to both the discrete\ngeometry of graphs and the differential structure of Wasserstein spaces. To\nensure numerical stability and accuracy of numerical behavior, we use\nextrapolation-type techniques to simulate the numerical solution on the\nboundary of density space. By analyzing approximation error of Wasserstein\ngradient of the viscosity solution, we prove the uniform convergence of the\nschemes to the original initial value problem, and establish an\n$L^{\\infty}_{\\mathrm{loc}}$-error estimate of order one-half. Several numerical\nexperiments are presented to illustrate our theoretical findings and to study\nthe effect of individual noise and Hamiltonians on graphs. To the best of our\nknowledge, this is the first result on numerical schemes for HJEs on the\nWasserstein space with a graph structure.", "published": "2025-04-18 05:03:39", "link": "http://arxiv.org/abs/2504.13463v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A global structure-preserving kernel method for the learning of Poisson systems", "abstract": "A structure-preserving kernel ridge regression method is presented that\nallows the recovery of globally defined, potentially high-dimensional, and\nnonlinear Hamiltonian functions on Poisson manifolds out of datasets made of\nnoisy observations of Hamiltonian vector fields. The proposed method is based\non finding the solution of a non-standard kernel ridge regression where the\nobserved data is generated as the noisy image by a vector bundle map of the\ndifferential of the function that one is trying to estimate. Additionally, it\nis shown how a suitable regularization solves the intrinsic non-identifiability\nof the learning problem due to the degeneracy of the Poisson tensor and the\npresence of Casimir functions. A full error analysis is conducted that provides\nconvergence rates using fixed and adaptive regularization parameters. The good\nperformance of the proposed estimator is illustrated with several numerical\nexperiments.", "published": "2025-04-18 01:12:08", "link": "http://arxiv.org/abs/2504.13396v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Target search optimization by threshold resetting", "abstract": "We introduce a new class of first passage time optimization driven by\nthreshold resetting, inspired by many natural processes where crossing a\ncritical limit triggers failure, degradation or transition. In here, search\nagents are collectively reset when a threshold is reached, creating\nevent-driven, system-coupled simultaneous resets that induce long-range\ninteractions. We develop a unified framework to compute search times for these\ncorrelated stochastic processes, with ballistic searchers as a key example\nuncovering diverse optimization behaviors. A cost function, akin to breakdown\npenalties, reveals that optimal resetting can forestall larger losses. This\nformalism generalizes to broader stochastic systems with multiple degrees of\nfreedom.", "published": "2025-04-18 06:42:41", "link": "http://arxiv.org/abs/2504.13501v1", "categories": ["cond-mat.stat-mech", "math.OC", "math.PR", "q-fin.ST"], "primary_category": "cond-mat.stat-mech"}
{"title": "Modeling L1 Influence on L2 Pronunciation: An MFCC-Based Framework for Explainable Machine Learning and Pedagogical Feedback", "abstract": "This study investigates the extent to which Mel-Frequency Cepstral\nCoefficients (MFCCs) capture first language (L1) transfer in extended second\nlanguage (L2) English speech. Speech samples from Mandarin and American English\nL1 speakers were extracted from the GMU Speech Accent Archive, converted to WAV\nformat, and processed to obtain thirteen MFCCs per speaker. A multi-method\nanalytic framework combining inferential statistics (t-tests, MANOVA, Canonical\nDiscriminant Analysis) and machine learning (Random Forest classification)\nidentified MFCC-1 (broadband energy), MFCC-2 (first formant region), and MFCC-5\n(voicing and fricative energy) as the most discriminative features for\ndistinguishing L1 backgrounds. A reduced-feature model using these MFCCs\nsignificantly outperformed the full-feature model, as confirmed by McNemar's\ntest and non-overlapping confidence intervals. The findings empirically support\nthe Perceptual Assimilation Model for L2 (PAM-L2) and the Speech Learning Model\n(SLM), demonstrating that L1-conditioned variation in L2 speech is both\nperceptually grounded and acoustically quantifiable. Methodologically, the\nstudy contributes to applied linguistics and explainable AI by proposing a\ntransparent, data-efficient pipeline for L2 pronunciation modeling. The results\nalso offer pedagogical implications for ESL/EFL instruction by highlighting\nL1-specific features that can inform intelligibility-oriented instruction,\ncurriculum design, and speech assessment tools.", "published": "2025-04-18 16:04:22", "link": "http://arxiv.org/abs/2504.13765v1", "categories": ["eess.AS", "cs.SD", "I.5.4; I.2.6; H.3.1"], "primary_category": "eess.AS"}
{"title": "MusFlow: Multimodal Music Generation via Conditional Flow Matching", "abstract": "Music generation aims to create music segments that align with human\naesthetics based on diverse conditional information. Despite advancements in\ngenerating music from specific textual descriptions (e.g., style, genre,\ninstruments), the practical application is still hindered by ordinary users'\nlimited expertise or time to write accurate prompts. To bridge this application\ngap, this paper introduces MusFlow, a novel multimodal music generation model\nusing Conditional Flow Matching. We employ multiple Multi-Layer Perceptrons\n(MLPs) to align multimodal conditional information into the audio's CLAP\nembedding space. Conditional flow matching is trained to reconstruct the\ncompressed Mel-spectrogram in the pretrained VAE latent space guided by aligned\nfeature embedding. MusFlow can generate music from images, story texts, and\nmusic captions. To collect data for model training, inspired by multi-agent\ncollaboration, we construct an intelligent data annotation workflow centered\naround a fine-tuned Qwen2-VL model. Using this workflow, we build a new\nmultimodal music dataset, MMusSet, with each sample containing a quadruple of\nimage, story text, music caption, and music piece. We conduct four sets of\nexperiments: image-to-music, story-to-music, caption-to-music, and multimodal\nmusic generation. Experimental results demonstrate that MusFlow can generate\nhigh-quality music pieces whether the input conditions are unimodal or\nmultimodal. We hope this work can advance the application of music generation\nin multimedia field, making music creation more accessible. Our generated\nsamples, code and dataset are available at musflow.github.io.", "published": "2025-04-18 07:59:35", "link": "http://arxiv.org/abs/2504.13535v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "QoS-Aware NOMA Design for Downlink Pinching-Antenna Systems", "abstract": "Pinching antennas, implemented by applying small dielectric particles on a\nwaveguide, have emerged as a promising flexible-antenna technology ideal for\nnext-generation wireless communications systems. Unlike conventional\nflexible-antenna systems, pinching antennas offer the advantage of creating\nline-of-sight links by enabling antennas to be activated on the waveguide at a\nlocation close to the user. This paper investigates a typical two-user\nnon-orthogonal multiple access (NOMA) downlink scenario, where multiple\npinching antennas are activated on a single dielectric waveguide to assist NOMA\ntransmission. We formulate the problem of maximizing the data rate of one user\nsubject to the quality-of-service requirement of the other user by jointly\noptimizing the antenna locations and power allocation coefficients. The\nformulated problem is nonconvex and difficult to solve due to the impact of\nantenna locations on large-scale path loss and two types of phase shifts,\nnamely in-waveguide phase shifts and free space propagation phase shifts. To\nthis end, we propose an iterative algorithm based on block coordinate descent\nand successive convex approximation techniques. Moreover, we consider the\nspecial case with a single pinching antenna, which is a simplified version of\nthe multi-antenna case. Although the formulated problem is still nonconvex, by\nusing the inherent features of the formulated problem, we derive the global\noptimal solution in closed-form, which offers important insights on the\nperformance of pinching-antenna systems. Simulation results demonstrate that\nthe pinching-antenna system significantly outperforms conventional\nfixed-position antenna systems, and the proposed algorithm achieves performance\ncomparable to the computationally intensive exhaustive search based approach.", "published": "2025-04-18 14:49:08", "link": "http://arxiv.org/abs/2504.13723v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching-Antenna Systems (PASS)-enabled Secure Wireless Communications", "abstract": "A novel pinching-antenna systems (PASS)-enabled secure wireless communication\nframework is proposed. By dynamically adjusting the positions of dielectric\nparticles, namely pinching antennas (PAs), along the waveguides, PASS\nintroduces a novel concept of pinching beamforming to enhance the performance\nof physical layer security. A fundamental PASS-enabled secure communication\nsystem is considered with one legitimate user and one eavesdropper. Both\nsingle-waveguide and multiple-waveguide scenarios are studied. 1) For the\nsingle-waveguide scenario, the secrecy rate (SR) maximization is formulated to\noptimize the pinching beamforming. A PA-wise successive tuning (PAST) algorithm\nis proposed, which ensures constructive signal superposition at the legitimate\nuser while inducing a destructive legitimate signal at the eavesdropper. 2) For\nthe multiple-waveguide scenario, artificial noise (AN) is employed to further\nimprove secrecy performance. A pair of practical transmission architectures are\ndeveloped: waveguide division (WD) and waveguide multiplexing (WM). The key\ndifference lies in whether each waveguide carries a single type of signal or a\nmixture of signals with baseband beamforming. For the SR maximization problem\nunder the WD case, a two-stage algorithm is developed, where the pinching\nbeamforming is designed with the PAST algorithm and the baseband power\nallocation among AN and legitimate signals is solved using successive convex\napproximation (SCA). For the WM case, an alternating optimization algorithm is\ndeveloped, where the baseband beamforming is optimized with SCA and the\npinching beamforming is designed employing particle swarm optimization.", "published": "2025-04-18 13:04:56", "link": "http://arxiv.org/abs/2504.13670v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physical Layer Authentication With Colored RIS in Visible Light Communications", "abstract": "We study a visible light communication (VLC) system that employs a colored\nreconfigurable intelligent surface (CRIS) based on dichroic mirrors that\nreflect light at tunable frequencies. A verifier can use the CRIS to\nauthenticate transmissions by comparing received multicolor power profiles with\nexpected patterns. Four CRIS configuration strategies are evaluated: a\ndeterministic cyclic pattern, static random reflectance, dynamic random\nreflectance, and dynamic random permutation of fixed profiles. Randomized\nconfigurations, especially dynamic ones, achieve superior authentication,\nenabling a novel challenge-response physical-layer authentication scheme over\nCRIS.", "published": "2025-04-18 12:57:23", "link": "http://arxiv.org/abs/2504.13666v1", "categories": ["eess.SP", "physics.optics"], "primary_category": "eess.SP"}
{"title": "PV-VLM: A Multimodal Vision-Language Approach Incorporating Sky Images for Intra-Hour Photovoltaic Power Forecasting", "abstract": "The rapid proliferation of solar energy has significantly expedited the\nintegration of photovoltaic (PV) systems into contemporary power grids.\nConsidering that the cloud dynamics frequently induce rapid fluctuations in\nsolar irradiance, accurate intra-hour forecasting is critical for ensuring grid\nstability and facilitating effective energy management. To leverage\ncomplementary temporal, textual, and visual information, this paper has\nproposed PV-VLM, a multimodal forecasting framework that integrates temporal,\ntextual, and visual information by three modules. The Time-Aware Module\nemployed a PatchTST-inspired Transformer to capture both local and global\ndependencies in PV power time series. Meanwhile, the Prompt-Aware Module\nencodes textual prompts from historical statistics and dataset descriptors via\na large language model. Additionally, the Vision-Aware Module utilizes a\npretrained vision-language model to extract high-level semantic features from\nsky images, emphasizing cloud motion and irradiance fluctuations. The proposed\nPV-VLM is evaluated using data from a 30-kW rooftop array at Stanford\nUniversity and through a transfer study on PV systems at the University of\nWollongong in Australia. Comparative experiments reveal an average RMSE\nreduction of approximately 5% and a MAE improvement of nearly 6%, while the\ntransfer study shows average RMSE and MAE reductions of about 7% and 9.5%,\nrespectively. Overall, PV-VLM leverages complementary modalities to provide a\nrobust solution for grid scheduling and energy market participation, enhancing\nthe stability and reliability of PV integration.", "published": "2025-04-18 11:01:43", "link": "http://arxiv.org/abs/2504.13624v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Design Of a Dual-band Patch Antenna with Stacked Structure", "abstract": "This project presents the design, simulation, and fabrication of a compact\ndual-band patch antenna using a stacked structure, targeting 2.25 to 2.35 GHz\nand 5.6 to 5.8 GHz ISM bands. A stacked configuration was chosen over a slotted\ndesign for its better performance, featuring two copper patches separated by\ndielectrics, with a single feed line and a 5 mm patch offset to enhance\ncoupling. Simulations showed strong return loss and directional gain in both\nbands. Although physical testing was limited due to equipment constraints, the\nprototype met design expectations, demonstrating potential for use in compact\nwireless and embedded systems.", "published": "2025-04-18 10:31:40", "link": "http://arxiv.org/abs/2504.13609v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Integrated Super-resolution Sensing and Symbiotic Communication with 3D Sparse MIMO for Low-Altitude UAV Swarm", "abstract": "Low-altitude unmanned aerial vehicle (UAV) swarms are expected to play\nimportant role for future intelligent aerial systems due to their great\npotential to cooperatively accomplish complicated missions effectively.\nHowever, there are important challenges to be addressed to enable their\nefficient operation: the large-scale nature of swarms usually leads to\nexcessive spectrum consumption, and ultra-low cost requirements for individual\nUAVs renders it necessary to develop more cost-effective communication modules.\nIn addition, the densely located swarm UAVs require high resolution for\nlocalization and sensing. To address the above challenges and simultaneously\nachieve spectrum and energy-efficient communication and accurate sensing, we\ninvestigate low-altitude UAV swarm with integrated super-resolution sensing and\nsymbiotic communication technology. Specifically, one leading UAV may act as a\nprimary transmitter (PT) to transmit communication signals to the base station\n(BS), and the remaining nearby UAVs in the swarm act as passive backscatter\ndevices (BDs), which can modulate their information by efficiently\nbackscattering the radio frequency (RF) signals from the PT without consuming\nextra spectrum or power. In addition, to achieve efficient three-dimensional\n(3D) super-resolution sensing for the densely located UAV swarm, 3D sparse\nmultiple-input multiple-output (MIMO) technology and super-resolution signal\nprocessing algorithms are further exploited, where both L-shaped nested array\n(LNA) and planar nested arrays (PNA) are considered at the BS. To evaluate the\ncommunication and sensing performance for the UAV-symbiotic radio (SR) system,\nthe achievable rates of UAV swarm are derived and the beam patterns of sparse\nLNA, PNA and the benchmarking compact uniform planar array (UPA) are compared.", "published": "2025-04-18 09:12:33", "link": "http://arxiv.org/abs/2504.13570v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Beyond-Diagonal Dynamic Metasurface Antenna", "abstract": "Dynamic metasurface antennas (DMAs) are an emerging technology for\nnext-generation wireless base stations, distinguished by hybrid analog/digital\nbeamforming capabilities with low hardware complexity. However, the coupling\nbetween meta-atoms is fixed in existing DMAs, which fundamentally constrains\nthe achievable performance. Here, we introduce reconfigurable coupling\nmechanisms between meta-atoms, yielding finer control over the DMA's analog\nsignal processing capabilities. This novel hardware is coined \"beyond-diagonal\nDMA\" (BD-DMA), in line with established BD-RIS terminology. We derive a\nphysics-consistent system model revealing (correlated) \"beyond-diagonal\"\nprogrammability in a reduced basis. We also present an equivalent formulation\nin a non-reduced basis with (uncorrelated) \"diagonal\" programmability. Based on\nthe diagonal representation, we propose a general and efficient\nmutual-coupling-aware optimization algorithm. Physics-consistent simulations\nvalidate the performance enhancement enabled by reconfigurable coupling\nmechanisms in BD-DMAs. The BD-DMA benefits grow with the mutual coupling\nstrength.", "published": "2025-04-18 07:23:13", "link": "http://arxiv.org/abs/2504.13523v1", "categories": ["physics.app-ph", "eess.SP"], "primary_category": "physics.app-ph"}
{"title": "Continuous-time filtering in Lie groups: estimation via the Fr{\u00e9}chet mean of solutions to stochastic differential equations", "abstract": "We compute the Fr\\'echet mean $\\mathscr{E}_t$ of the solution $X_{t}$ to a\ncontinuous-time stochastic differential equation in a Lie group. It provides an\nestimator with minimal variance of $X_{t}$. We use it in the context of Kalman\nfiltering and more precisely to infer rotation matrices. In this paper, we\nfocus on the prediction step between two consecutive observations. Compared to\nstate-of-the-art approaches, our assumptions on the model are minimal.", "published": "2025-04-18 06:45:30", "link": "http://arxiv.org/abs/2504.13502v1", "categories": ["math.PR", "eess.SP", "math.ST", "stat.TH"], "primary_category": "math.PR"}
{"title": "Block-Weighted Lasso for Joint Optimization of Memory Depth and Kernels in Wideband DPD", "abstract": "The optimizations of both memory depth and kernel functions are critical for\nwideband digital pre-distortion (DPD). However, the memory depth is usually\ndetermined via exhaustive search over a wide range for the sake of\nlinearization optimality, followed by the kernel selection of each memory\ndepth, yielding excessive computational cost. In this letter, we aim to provide\nan efficient solution that jointly optimizes the memory depth and kernels while\npreserving reasonable linearization performance. Specifically, we propose to\nformulate this optimization as a blockweighted least absolute shrinkage and\nselection operator (Lasso) problem, where kernels are assigned regularization\nweights based on their polynomial orders. Then, a block coordinate descent\nalgorithm is introduced to solve the block-weighted Lasso problem. Measurement\nresults on a generalized memory polynomial (GMP) model demonstrates that our\nproposed solution reduces memory depth by 31.6% and kernel count by 85%\ncompared to the full GMP, while achieving -46.4 dB error vector magnitude (EVM)\nfor signals of 80 MHz bandwidth. In addition, the proposed solution outperforms\nboth the full GMP and the GMP pruned by standard Lasso by at least 0.7 dB in\nEVM.", "published": "2025-04-18 06:21:13", "link": "http://arxiv.org/abs/2504.13494v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Accurate semiclassical analysis of light propagation on tilted hyperplanes", "abstract": "In the scalar light model given by Helmholtz' equation in R^{1+d} , we\nconsider the transformation of an initial scene (a hologram) in {0}xR^d by an\narbitrary affine transformation (which can be viewed as a propagation into a\ntilted hyperplane). In the high frequency regime, we use microlocal and\nsemiclassical analysis to describe the propagator as a semiclassical Fourier\nintegral operator, thus generalising the well-known Angular Spectrum formula\nfrom optics. We then prove new precise Egorov theorems, including subprincipal\nterms, which indicate how to take into account the propagation along rays of\ngeometric optics.", "published": "2025-04-18 05:50:02", "link": "http://arxiv.org/abs/2504.13485v1", "categories": ["eess.SP", "math-ph", "math.AP", "math.MP", "math.SG"], "primary_category": "eess.SP"}
{"title": "Modular XL-Array-Enabled 3-D Localization based on Hybrid Spherical-Planar Wave Model in Terahertz Systems", "abstract": "This work considers the three-dimensional (3-D) positioning problem in a\nTerahertz (THz) system enabled by a modular extra-large (XL) array with\nsub-connected architecture. Our purpose is to estimate the Cartesian\nCoordinates of multiple user equipments (UEs) with the received signal of the\nRF chains while considering the spatial non-stationarity (SNS). We apply the\nhybrid spherical-planar wave model (HSPWM) as the channel model owing to the\nstructual feature of the modular array, and propose a 3-D localization\nalgorithm with relatively high accuracy and low complexity. Specifically, we\nfirst distinguish the visible sub-arrays (SAs) located in the VR and estimate\nthe angles-of-arrival (AoAs) from each UE to typical visible SAs with the\nlargest receive power via compressed sensing (CS) method. In addition, we apply\nthe weighted least square (WLS) method to obtain a coarse 3-D position\nestimation of each UE according to the AoA estimations. Then, we estimate the\nAoAs of the other SAs with a reduced dictionary (RD)-CS-based method for lower\ncomputational complexity, and utilize all the efficient AoA estimations to\nderive a fine position estimation. Simulation results indicate that the\nproposed positioning framework based on modular XL-array can achieve\nsatisfactory accuracy with evident reduction in complexity. Furthermore, the\ndeployment of SAs and the allocation of antenna elements need to be specially\ndesigned for better positioning performance.", "published": "2025-04-18 04:12:47", "link": "http://arxiv.org/abs/2504.13455v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Deep Learning-Based Supervised Transfer Learning Framework for DOA Estimation with Array Imperfections", "abstract": "In practical scenarios, processes such as sensor design, manufacturing, and\ninstallation will introduce certain errors. Furthermore, mutual interference\noccurs when the sensors receive signals. These defects in array systems are\nreferred to as array imperfections, which can significantly degrade the\nperformance of Direction of Arrival (DOA) estimation. In this study, we propose\na deep-learning based transfer learning approach, which effectively mitigates\nthe degradation of deep-learning based DOA estimation performance caused by\narray imperfections.\n  In the proposed approach, we highlight three major contributions. First, we\npropose a Vision Transformer (ViT) based method for DOA estimation, which\nachieves excellent performance in scenarios with low signal-to-noise ratios\n(SNR) and limited snapshots. Second, we introduce a transfer learning framework\nthat extends deep learning models from ideal simulation scenarios to complex\nreal-world scenarios with array imperfections. By leveraging prior knowledge\nfrom ideal simulation data, the proposed transfer learning framework\nsignificantly improves deep learning-based DOA estimation performance in the\npresence of array imperfections, without the need for extensive real-world\ndata. Finally, we incorporate visualization and evaluation metrics to assess\nthe performance of DOA estimation algorithms, which allow for a more thorough\nevaluation of algorithms and further validate the proposed method. Our code can\nbe accessed at https://github.com/zzb-nice/DOA_est_Master.", "published": "2025-04-18 01:09:38", "link": "http://arxiv.org/abs/2504.13394v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Generative AI Act II: Test Time Scaling Drives Cognition Engineering", "abstract": "The first generation of Large Language Models - what might be called \"Act I\"\nof generative AI (2020-2023) - achieved remarkable success through massive\nparameter and data scaling, yet exhibited fundamental limitations such as\nknowledge latency, shallow reasoning, and constrained cognitive processes.\nDuring this era, prompt engineering emerged as our primary interface with AI,\nenabling dialogue-level communication through natural language. We now witness\nthe emergence of \"Act II\" (2024-present), where models are transitioning from\nknowledge-retrieval systems (in latent space) to thought-construction engines\nthrough test-time scaling techniques. This new paradigm establishes a\nmind-level connection with AI through language-based thoughts. In this paper,\nwe clarify the conceptual foundations of cognition engineering and explain why\nthis moment is critical for its development. We systematically break down these\nadvanced approaches through comprehensive tutorials and optimized\nimplementations, democratizing access to cognition engineering and enabling\nevery practitioner to participate in AI's second act. We provide a regularly\nupdated collection of papers on test-time scaling in the GitHub Repository:\nhttps://github.com/GAIR-NLP/cognition-engineering", "published": "2025-04-18 17:55:58", "link": "http://arxiv.org/abs/2504.13828v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models", "abstract": "Previous insertion-based and paraphrase-based backdoors have achieved great\nsuccess in attack efficacy, but they ignore the text quality and semantic\nconsistency between poisoned and clean texts. Although recent studies introduce\nLLMs to generate poisoned texts and improve the stealthiness, semantic\nconsistency, and text quality, their hand-crafted prompts rely on expert\nexperiences, facing significant challenges in prompt adaptability and attack\nperformance after defenses. In this paper, we propose a novel backdoor attack\nbased on adaptive optimization mechanism of black-box large language models\n(BadApex), which leverages a black-box LLM to generate poisoned text through a\nrefined prompt. Specifically, an Adaptive Optimization Mechanism is designed to\nrefine an initial prompt iteratively using the generation and modification\nagents. The generation agent generates the poisoned text based on the initial\nprompt. Then the modification agent evaluates the quality of the poisoned text\nand refines a new prompt. After several iterations of the above process, the\nrefined prompt is used to generate poisoned texts through LLMs. We conduct\nextensive experiments on three dataset with six backdoor attacks and two\ndefenses. Extensive experimental results demonstrate that BadApex significantly\noutperforms state-of-the-art attacks. It improves prompt adaptability, semantic\nconsistency, and text quality. Furthermore, when two defense methods are\napplied, the average attack success rate (ASR) still up to 96.75%.", "published": "2025-04-18 16:22:41", "link": "http://arxiv.org/abs/2504.13775v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Improving Generalization in Intent Detection: GRPO with Reward-Based Curriculum Sampling", "abstract": "Intent detection, a critical component in task-oriented dialogue (TOD)\nsystems, faces significant challenges in adapting to the rapid influx of\nintegrable tools with complex interrelationships. Existing approaches, such as\nzero-shot reformulations and LLM-based dynamic recognition, struggle with\nperformance degradation when encountering unseen intents, leading to erroneous\ntask routing. To enhance the model's generalization performance on unseen\ntasks, we employ Reinforcement Learning (RL) combined with a Reward-based\nCurriculum Sampling (RCS) during Group Relative Policy Optimization (GRPO)\ntraining in intent detection tasks. Experiments demonstrate that RL-trained\nmodels substantially outperform supervised fine-tuning (SFT) baselines in\ngeneralization. Besides, the introduction of the RCS, significantly bolsters\nthe effectiveness of RL in intent detection by focusing the model on\nchallenging cases during training. Moreover, incorporating Chain-of-Thought\n(COT) processes in RL notably improves generalization in complex intent\ndetection tasks, underscoring the importance of thought in challenging\nscenarios. This work advances the generalization of intent detection tasks,\noffering practical insights for deploying adaptable dialogue systems.", "published": "2025-04-18 09:52:12", "link": "http://arxiv.org/abs/2504.13592v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LangCoop: Collaborative Driving with Language", "abstract": "Multi-agent collaboration holds great promise for enhancing the safety,\nreliability, and mobility of autonomous driving systems by enabling information\nsharing among multiple connected agents. However, existing multi-agent\ncommunication approaches are hindered by limitations of existing communication\nmedia, including high bandwidth demands, agent heterogeneity, and information\nloss. To address these challenges, we introduce LangCoop, a new paradigm for\ncollaborative autonomous driving that leverages natural language as a compact\nyet expressive medium for inter-agent communication. LangCoop features two key\ninnovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured\nzero-shot vision-language reasoning and Natural Language Information Packaging\n(LangPack) for efficiently packaging information into concise, language-based\nmessages. Through extensive experiments conducted in the CARLA simulations, we\ndemonstrate that LangCoop achieves a remarkable 96\\% reduction in communication\nbandwidth (< 2KB per message) compared to image-based communication, while\nmaintaining competitive driving performance in the closed-loop evaluation. Our\nproject page and code are at https://xiangbogaobarry.github.io/LangCoop/.", "published": "2025-04-18 02:03:14", "link": "http://arxiv.org/abs/2504.13406v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Deep Learning Models Meet Financial Data Modalities", "abstract": "Algorithmic trading relies on extracting meaningful signals from diverse\nfinancial data sources, including candlestick charts, order statistics on put\nand canceled orders, traded volume data, limit order books, and news flow.\nWhile deep learning has demonstrated remarkable success in processing\nunstructured data and has significantly advanced natural language processing,\nits application to structured financial data remains an ongoing challenge. This\nstudy investigates the integration of deep learning models with financial data\nmodalities, aiming to enhance predictive performance in trading strategies and\nportfolio optimization. We present a novel approach to incorporating limit\norder book analysis into algorithmic trading by developing embedding techniques\nand treating sequential limit order book snapshots as distinct input channels\nin an image-based representation. Our methodology for processing limit order\nbook data achieves state-of-the-art performance in high-frequency trading\nalgorithms, underscoring the effectiveness of deep learning in financial\napplications.", "published": "2025-04-18 07:19:44", "link": "http://arxiv.org/abs/2504.13521v2", "categories": ["cs.LG", "cs.AI", "cs.CE", "q-fin.ST"], "primary_category": "cs.LG"}
{"title": "SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM", "abstract": "Models and methods originally developed for novel view synthesis and scene\nrendering, such as Neural Radiance Fields (NeRF) and Gaussian Splatting, are\nincreasingly being adopted as representations in Simultaneous Localization and\nMapping (SLAM). However, existing datasets fail to include the specific\nchallenges of both fields, such as multimodality and sequentiality in SLAM or\ngeneralization across viewpoints and illumination conditions in neural\nrendering. To bridge this gap, we introduce SLAM&Render, a novel dataset\ndesigned to benchmark methods in the intersection between SLAM and novel view\nrendering. It consists of 40 sequences with synchronized RGB, depth, IMU, robot\nkinematic data, and ground-truth pose streams. By releasing robot kinematic\ndata, the dataset also enables the assessment of novel SLAM strategies when\napplied to robot manipulators. The dataset sequences span five different setups\nfeaturing consumer and industrial objects under four different lighting\nconditions, with separate training and test trajectories per scene, as well as\nobject rearrangements. Our experimental results, obtained with several\nbaselines from the literature, validate SLAM&Render as a relevant benchmark for\nthis emerging research area.", "published": "2025-04-18 14:28:34", "link": "http://arxiv.org/abs/2504.13713v2", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Analysing the Robustness of Vision-Language-Models to Common Corruptions", "abstract": "Vision-language models (VLMs) have demonstrated impressive capabilities in\nunderstanding and reasoning about visual and textual content. However, their\nrobustness to common image corruptions remains under-explored. In this work, we\npresent the first comprehensive analysis of VLM robustness across 19 corruption\ntypes from the ImageNet-C benchmark, spanning four categories: noise, blur,\nweather, and digital distortions. We introduce two new benchmarks, TextVQA-C\nand GQA-C, to systematically evaluate how corruptions affect scene text\nunderstanding and object-based reasoning, respectively. Our analysis reveals\nthat transformer-based VLMs exhibit distinct vulnerability patterns across\ntasks: text recognition deteriorates most severely under blur and snow\ncorruptions, while object reasoning shows higher sensitivity to corruptions\nsuch as frost and impulse noise. We connect these observations to the\nfrequency-domain characteristics of different corruptions, revealing how\ntransformers' inherent bias toward low-frequency processing explains their\ndifferential robustness patterns. Our findings provide valuable insights for\ndeveloping more corruption-robust vision-language models for real-world\napplications.", "published": "2025-04-18 13:46:32", "link": "http://arxiv.org/abs/2504.13690v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Circular Image Deturbulence using Quasi-conformal Geometry", "abstract": "The presence of inhomogeneous media between optical sensors and objects leads\nto distorted imaging outputs, significantly complicating downstream\nimage-processing tasks. A key challenge in image restoration is the lack of\nhigh-quality, paired-label images required for training supervised models. In\nthis paper, we introduce the Circular Quasi-Conformal Deturbulence (CQCD)\nframework, an unsupervised approach for removing image distortions through a\ncircular architecture. This design ensures that the restored image remains both\ngeometrically accurate and visually faithful while preventing the accumulation\nof incorrect estimations. The circular restoration process involves both\nforward and inverse mapping. To ensure the bijectivity of the estimated\nnon-rigid deformations, computational quasi-conformal geometry theories are\nleveraged to regularize the mapping, enforcing its homeomorphic properties.\nThis guarantees a well-defined transformation that preserves structural\nintegrity and prevents unwanted artifacts. Furthermore, tight-frame blocks are\nintegrated to encode distortion-sensitive features for precise recovery. To\nvalidate the performance of our approach, we conduct evaluations on various\nsynthetic and real-world captured images. Experimental results demonstrate that\nCQCD not only outperforms existing state-of-the-art deturbulence methods in\nterms of image restoration quality but also provides highly accurate\ndeformation field estimations.", "published": "2025-04-18 03:07:25", "link": "http://arxiv.org/abs/2504.13432v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Simplifying Graph Convolutional Networks with Redundancy-Free Neighbors", "abstract": "In recent years, Graph Convolutional Networks (GCNs) have gained popularity\nfor their exceptional ability to process graph-structured data. Existing\nGCN-based approaches typically employ a shallow model architecture due to the\nover-smoothing phenomenon. Current approaches to mitigating over-smoothing\nprimarily involve adding supplementary components to GCN architectures, such as\nresidual connections and random edge-dropping strategies. However, these\nimprovements toward deep GCNs have achieved only limited success. In this work,\nwe analyze the intrinsic message passing mechanism of GCNs and identify a\ncritical issue: messages originating from high-order neighbors must traverse\nthrough low-order neighbors to reach the target node. This repeated reliance on\nlow-order neighbors leads to redundant information aggregation, a phenomenon we\nterm over-aggregation. Our analysis demonstrates that over-aggregation not only\nintroduces significant redundancy but also serves as the fundamental cause of\nover-smoothing in GCNs.", "published": "2025-04-18 02:56:21", "link": "http://arxiv.org/abs/2504.13426v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "System of Agentic AI for the Discovery of Metal-Organic Frameworks", "abstract": "Generative models and machine learning promise accelerated material discovery\nin MOFs for CO2 capture and water harvesting but face significant challenges\nnavigating vast chemical spaces while ensuring synthetizability. Here, we\npresent MOFGen, a system of Agentic AI comprising interconnected agents: a\nlarge language model that proposes novel MOF compositions, a diffusion model\nthat generates crystal structures, quantum mechanical agents that optimize and\nfilter candidates, and synthetic-feasibility agents guided by expert rules and\nmachine learning. Trained on all experimentally reported MOFs and computational\ndatabases, MOFGen generated hundreds of thousands of novel MOF structures and\nsynthesizable organic linkers. Our methodology was validated through\nhigh-throughput experiments and the successful synthesis of five \"AI-dreamt\"\nMOFs, representing a major step toward automated synthesizable material\ndiscovery.", "published": "2025-04-18 23:54:25", "link": "http://arxiv.org/abs/2504.14110v1", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Linking forward-pass dynamics in Transformers and real-time human processing", "abstract": "Modern AI models are increasingly being used as theoretical tools to study\nhuman cognition. One dominant approach is to evaluate whether human-derived\nmeasures (such as offline judgments or real-time processing) are predicted by a\nmodel's output: that is, the end-product of forward pass(es) through the\nnetwork. At the same time, recent advances in mechanistic interpretability have\nbegun to reveal the internal processes that give rise to model outputs, raising\nthe question of whether models and humans might arrive at outputs using similar\n\"processing strategies\". Here, we investigate the link between real-time\nprocessing in humans and \"layer-time\" dynamics in Transformer models. Across\nfive studies spanning domains and modalities, we test whether the dynamics of\ncomputation in a single forward pass of pre-trained Transformers predict\nsignatures of processing in humans, above and beyond properties of the model's\noutput probability distribution. We consistently find that layer-time dynamics\nprovide additional predictive power on top of output measures. Our results\nsuggest that Transformer processing and human processing may be facilitated or\nimpeded by similar properties of an input stimulus, and this similarity has\nemerged through general-purpose objectives such as next-token prediction or\nimage recognition. Our work suggests a new way of using AI models to study\nhuman cognition: not just as a black box mapping stimuli to responses, but\npotentially also as explicit processing models.", "published": "2025-04-18 23:38:14", "link": "http://arxiv.org/abs/2504.14107v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models", "abstract": "Large language models (LLMs) have achieved remarkable multi-step reasoning\ncapabilities across various domains. However, LLMs still face distinct\nchallenges in complex logical reasoning, as (1) proof-finding requires\nsystematic exploration and the maintenance of logical coherence and (2)\nsearching the right combination of premises at each reasoning step is\ninherently challenging in tasks with large premise space. To address this, we\npropose LogicTree, an inference-time modular framework employing\nalgorithm-guided search to automate structured proof exploration and ensure\nlogical coherence. Advancing beyond tree-of-thought (ToT), we incorporate\ncaching mechanism into LogicTree to enable effective utilization of historical\nknowledge, preventing reasoning stagnation and minimizing redundancy.\nFurthermore, we address the combinatorial complexity of premise search by\ndecomposing it into a linear process. The refined premise selection restricts\nsubsequent inference to at most one derivation per step, enhancing reasoning\ngranularity and enforcing strict step-by-step reasoning. Additionally, we\nintroduce two LLM-free heuristics for premise prioritization, enabling\nstrategic proof search. Experimental results on five datasets demonstrate that\nLogicTree optimally scales inference-time computation to achieve higher proof\naccuracy, surpassing chain-of-thought (CoT) and ToT with average gains of 23.6%\nand 12.5%, respectively, on GPT-4o. Moreover, within LogicTree, GPT-4o\noutperforms o3-mini by 7.6% on average.", "published": "2025-04-18 22:10:02", "link": "http://arxiv.org/abs/2504.14089v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Baseline for Self-state Identification and Classification in Mental Health Data: CLPsych 2025 Task", "abstract": "We present a baseline for the CLPsych 2025 A.1 task: classifying self-states\nin mental health data taken from Reddit. We use few-shot learning with a 4-bit\nquantized Gemma 2 9B model and a data preprocessing step which first identifies\nrelevant sentences indicating self-state evidence, and then performs a binary\nclassification to determine whether the sentence is evidence of an adaptive or\nmaladaptive self-state. This system outperforms our other method which relies\non an LLM to highlight spans of variable length independently. We attribute the\nperformance of our model to the benefits of this sentence chunking step for two\nreasons: partitioning posts into sentences 1) broadly matches the granularity\nat which self-states were human-annotated and 2) simplifies the task for our\nlanguage model to a binary classification problem. Our system places third out\nof fourteen systems submitted for Task A.1, achieving a test-time recall of\n0.579.", "published": "2025-04-18 20:37:14", "link": "http://arxiv.org/abs/2504.14066v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Discrete Evacuation in Graphs with Multiple Exits", "abstract": "Consider the following discrete evacuation model. The evacuation terrain is\nmodeled by a simple graph $G=(V,E)$ whose certain vertices $X\\subseteq V$ are\ncalled \\emph{exits}. Initially, each vertex is either \\emph{empty} or\n\\emph{occupied} by an agent. We assume that each vertex has a unique \\emph{id}\n(and therefore the agents do have unique ids), each agent has finite but\narbitrarily large memory, and the graph is initially stored in the memory of\neach agent. In other words, the agents do know the topology of the network\nalong with the locations of the exits, but they do not know the initial\npositions nor the quantity of other agents. The time is divided into\n\\emph{steps}; in each step any pair of agents present at vertices at a distance\nof at most two can exchange an arbitrary number of messages, and then each\nagent can either make a move or stay put. The agents should make moves in a\ncollision-free manner, i.e., no two agents can be located at the same vertex in\nthe same step. At the end of each step, any agent located at an exit\n\\emph{evacuates}, i.e., it is removed from the graph. The goal is to provide an\nalgorithm to the agents (referred to as an evacuation strategy) that ensures\nthe evacuation of all agents and minimizes the number of steps.\n  This work provides an algorithmic framework that allows constructing valid\nevacuation strategies for arbitrary input graphs. Specifically, we focus on the\nproperties of the input graphs that lead to evacuation strategies with constant\ncompetitive ratios. In particular, we describe an application of the above\nframework that gives an asymptotically optimal evacuation for grids (and by\nextension hexagonal or triangular grids as well).", "published": "2025-04-18 19:49:40", "link": "http://arxiv.org/abs/2504.14052v1", "categories": ["cs.DM", "68R10, 68W05", "G.2.2"], "primary_category": "cs.DM"}
{"title": "Enhancing Math Learning in an LMS Using AI-Driven Question Recommendations", "abstract": "This paper presents an AI-driven approach to enhance math learning in a\nmodern Learning Management System (LMS) by recommending similar math questions.\nDeep embeddings for math questions are generated using Meta's\nLlama-3.2-11B-Vision-Instruct model, and three recommendation methods-cosine\nsimilarity, Self-Organizing Maps (SOM), and Gaussian Mixture Models (GMM)-are\napplied to identify similar questions. User interaction data, including session\ndurations, response times, and correctness, are used to evaluate the methods.\nOur findings suggest that while cosine similarity produces nearly identical\nquestion matches, SOM yields higher user satisfaction whereas GMM generally\nunderperforms, indicating that introducing variety to a certain degree may\nenhance engagement and thereby potential learning outcomes until variety is no\nlonger balanced reasonably, which our data about the implementations of all\nthree methods demonstrate.", "published": "2025-04-18 22:48:26", "link": "http://arxiv.org/abs/2504.14098v1", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.IR"], "primary_category": "cs.LG"}
{"title": "CPR: Leveraging LLMs for Topic and Phrase Suggestion to Facilitate Comprehensive Product Reviews", "abstract": "Consumers often heavily rely on online product reviews, analyzing both\nquantitative ratings and textual descriptions to assess product quality.\nHowever, existing research hasn't adequately addressed how to systematically\nencourage the creation of comprehensive reviews that capture both customers\nsentiment and detailed product feature analysis. This paper presents CPR, a\nnovel methodology that leverages the power of Large Language Models (LLMs) and\nTopic Modeling to guide users in crafting insightful and well-rounded reviews.\nOur approach employs a three-stage process: first, we present users with\nproduct-specific terms for rating; second, we generate targeted phrase\nsuggestions based on these ratings; and third, we integrate user-written text\nthrough topic modeling, ensuring all key aspects are addressed. We evaluate CPR\nusing text-to-text LLMs, comparing its performance against real-world customer\nreviews from Walmart. Our results demonstrate that CPR effectively identifies\nrelevant product terms, even for new products lacking prior reviews, and\nprovides sentiment-aligned phrase suggestions, saving users time and enhancing\nreviews quality. Quantitative analysis reveals a 12.3% improvement in BLEU\nscore over baseline methods, further supported by manual evaluation of\ngenerated phrases. We conclude by discussing potential extensions and future\nresearch directions.", "published": "2025-04-18 17:11:38", "link": "http://arxiv.org/abs/2504.13993v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Channels with Input-Correlated Synchronization Errors", "abstract": "\"Independent and identically distributed\" errors do not accurately capture\nthe noisy behavior of real-world data storage and information transmission\ntechnologies. Motivated by this, we study channels with input-correlated\nsynchronization errors, meaning that the distribution of synchronization errors\n(such as deletions and insertions) applied to the $i$-th input $x_i$ may depend\non the whole input string $x$.\n  We begin by identifying conditions on the input-correlated synchronization\nchannel under which the channel's information capacity is achieved by a\nstationary ergodic input source and is equal to its coding capacity. These\nconditions capture a wide class of channels, including channels with correlated\nerrors observed in DNA-based data storage systems and their multi-trace\nversions, and generalize prior work. To showcase the usefulness of the general\ncapacity theorem above, we combine it with techniques of Pernice-Li-Wootters\n(ISIT 2022) and Brakensiek-Li-Spang (FOCS 2020) to obtain explicit\ncapacity-achieving codes for multi-trace channels with runlength-dependent\ndeletions, motivated by error patterns observed in DNA-based data storage\nsystems.", "published": "2025-04-18 21:47:46", "link": "http://arxiv.org/abs/2504.14087v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Transport alpha divergences", "abstract": "We derive a class of divergences measuring the difference between probability\ndensity functions on a one-dimensional sample space. This divergence is a\none-parameter variation of the Ito-Sauda divergence between quantile density\nfunctions. We prove that the proposed divergence is one-parameter variation of\ntransport Kullback-Leibler divergence and Hessian distance of negative\nBoltzmann entropy with respect to Wasserstein-2 metric. From Taylor expansions,\nwe also formulate the 3-symmetric tensor in Wasserstein space, which is given\nby an iterative Gamma three operators. The alpha-geodesic on Wasserstein space\nis also derived. From these properties, we name the proposed information\nmeasures transport alpha divergences. We provide several examples of transport\nalpha divergences for generative models in machine learning applications.", "published": "2025-04-18 21:33:58", "link": "http://arxiv.org/abs/2504.14084v1", "categories": ["cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "cs.IT"}
{"title": "On the Capacity of Insertion Channels for Small Insertion Probabilities", "abstract": "Channels with synchronization errors, such as deletion and insertion errors,\nare crucial in DNA storage, data reconstruction, and other applications. These\nerrors introduce memory to the channel, complicating its capacity analysis.\nThis paper analyzes binary insertion channels for small insertion\nprobabilities, identifying dominant terms in the capacity expansion and\nestablishing capacity in this regime. Using Bernoulli(1/2) inputs for\nachievability and a converse based on the use of stationary and ergodic\nprocesses, we demonstrate that capacity closely aligns with achievable rates\nusing independent and identically distributed (i.i.d.) inputs, differing only\nin higher-order terms.", "published": "2025-04-18 18:54:10", "link": "http://arxiv.org/abs/2504.14035v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Leakage and Interpretability in Concept-Based Models", "abstract": "Concept Bottleneck Models aim to improve interpretability by predicting\nhigh-level intermediate concepts, representing a promising approach for\ndeployment in high-risk scenarios. However, they are known to suffer from\ninformation leakage, whereby models exploit unintended information encoded\nwithin the learned concepts. We introduce an information-theoretic framework to\nrigorously characterise and quantify leakage, and define two complementary\nmeasures: the concepts-task leakage (CTL) and interconcept leakage (ICL)\nscores. We show that these measures are strongly predictive of model behaviour\nunder interventions and outperform existing alternatives in robustness and\nreliability. Using this framework, we identify the primary causes of leakage\nand provide strong evidence that Concept Embedding Models exhibit substantial\nleakage regardless of the hyperparameters choice. Finally, we propose practical\nguidelines for designing concept-based models to reduce leakage and ensure\ninterpretability.", "published": "2025-04-18 22:21:06", "link": "http://arxiv.org/abs/2504.14094v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MMformer with Adaptive Transferable Attention: Advancing Multivariate Time Series Forecasting for Environmental Applications", "abstract": "Environmental crisis remains a global challenge that affects public health\nand environmental quality. Despite extensive research, accurately forecasting\nenvironmental change trends to inform targeted policies and assess prediction\nefficiency remains elusive. Conventional methods for multivariate time series\n(MTS) analysis often fail to capture the complex dynamics of environmental\nchange. To address this, we introduce an innovative meta-learning MTS model,\nMMformer with Adaptive Transferable Multi-head Attention (ATMA), which combines\nself-attention and meta-learning for enhanced MTS forecasting. Specifically,\nMMformer is used to model and predict the time series of seven air quality\nindicators across 331 cities in China from January 2018 to June 2021 and the\ntime series of precipitation and temperature at 2415 monitoring sites during\nthe summer (276 days) from 2012 to 2014, validating the network's ability to\nperform and forecast MTS data successfully. Experimental results demonstrate\nthat in these datasets, the MMformer model reaching SOTA outperforms\niTransformer, Transformer, and the widely used traditional time series\nprediction algorithm SARIMAX in the prediction of MTS, reducing by 50\\% in MSE,\n20\\% in MAE as compared to others in air quality datasets, reducing by 20\\% in\nMAPE except SARIMAX. Compared with Transformer and SARIMAX in the climate\ndatasets, MSE, MAE, and MAPE are decreased by 30\\%, and there is an improvement\ncompared to iTransformer. This approach represents a significant advance in our\nability to forecast and respond to dynamic environmental quality challenges in\ndiverse urban and rural environments. Its predictive capabilities provide\nvaluable public health and environmental quality information, informing\ntargeted interventions.", "published": "2025-04-18 19:42:42", "link": "http://arxiv.org/abs/2504.14050v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Causal pieces: analysing and improving spiking neural networks piece by piece", "abstract": "We introduce a novel concept for spiking neural networks (SNNs) derived from\nthe idea of \"linear pieces\" used to analyse the expressiveness and trainability\nof artificial neural networks (ANNs). We prove that the input domain of SNNs\ndecomposes into distinct causal regions where its output spike times are\nlocally Lipschitz continuous with respect to the input spike times and network\nparameters. The number of such regions - which we call \"causal pieces\" - is a\nmeasure of the approximation capabilities of SNNs. In particular, we\ndemonstrate in simulation that parameter initialisations which yield a high\nnumber of causal pieces on the training set strongly correlate with SNN\ntraining success. Moreover, we find that feedforward SNNs with purely positive\nweights exhibit a surprisingly high number of causal pieces, allowing them to\nachieve competitive performance levels on benchmark tasks. We believe that\ncausal pieces are not only a powerful and principled tool for improving SNNs,\nbut might also open up new ways of comparing SNNs and ANNs in the future.", "published": "2025-04-18 18:07:33", "link": "http://arxiv.org/abs/2504.14015v1", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC", "stat.ML"], "primary_category": "cs.NE"}
{"title": "Transformation of audio embeddings into interpretable, concept-based representations", "abstract": "Advancements in audio neural networks have established state-of-the-art\nresults on downstream audio tasks. However, the black-box structure of these\nmodels makes it difficult to interpret the information encoded in their\ninternal audio representations. In this work, we explore the semantic\ninterpretability of audio embeddings extracted from these neural networks by\nleveraging CLAP, a contrastive learning model that brings audio and text into a\nshared embedding space. We implement a post-hoc method to transform CLAP\nembeddings into concept-based, sparse representations with semantic\ninterpretability. Qualitative and quantitative evaluations show that the\nconcept-based representations outperform or match the performance of original\naudio embeddings on downstream tasks while providing interpretability.\nAdditionally, we demonstrate that fine-tuning the concept-based representations\ncan further improve their performance on downstream tasks. Lastly, we publish\nthree audio-specific vocabularies for concept-based interpretability of audio\nembeddings.", "published": "2025-04-18 21:00:50", "link": "http://arxiv.org/abs/2504.14076v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "6G WavesFM: A Foundation Model for Sensing, Communication, and Localization", "abstract": "This paper introduces WavesFM, a novel Wireless Foundation Model (WFM)\nframework, capable of supporting a wide array of communication, sensing, and\nlocalization tasks. Our proposed architecture combines a shared Vision\nTransformer (ViT) backbone with task-specific multi-layer perceptron (MLP)\nheads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficient\nfine-tuning. This design promotes full parameter sharing across tasks,\nsignificantly reducing the computational and memory footprint without\nsacrificing performance. The model processes both image-like wireless\nmodalities, such as spectrograms and channel state information (CSI), and\nin-phase and quadrature (IQ) signals arranged as orthogonal frequency-division\nmultiplexing (OFDM) resource grids. We demonstrate the strong generalization\ncapabilities of WavesFM through extensive experiments on four downstream tasks:\nFifth Generation New Radio (5G NR) positioning; multiple-input multiple-output\nOFDM (MIMO-OFDM) channel estimation; human activity sensing; and\nradio-frequency (RF) signal classification. Compared to supervised baselines\ntrained individually, our approach achieves superior performance while sharing\n80% of its parameters across tasks. Furthermore, we show that pretraining on\ndomain-relevant data not only boosts performance but also accelerates\nconvergence, reducing training time by up to 5x. These results demonstrate that\nour unified WFM can support diverse tasks and deliver significant gains in both\nperformance and efficiency, highlighting the transformative potential of\nfoundation models to drive AI-native paradigms in future sixth-generation (6G)\nnetworks.", "published": "2025-04-18 22:51:35", "link": "http://arxiv.org/abs/2504.14100v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Access Probability Optimization in RACH: A Multi-Armed Bandits Approach", "abstract": "The use of cellular networks for massive machine-type communications (mMTC)\nis an appealing solution due to the availability of the existing\ninfrastructure. However, the massive number of user equipments (UEs) poses a\nsignificant challenge to the cellular network's random access channel (RACH)\nregarding congestion and overloading. To mitigate this problem, we first\npresent a novel approach to model a two-priority RACH, which allows us to\ndefine access patterns that describe the random access behavior of UEs as\nobserved by the base station (BS). A non-uniform preamble selection scheme is\nproposed, offering increased flexibility in resource allocation for different\nUE priority classes. Then, we formulate an allocation model that finds the\noptimal access probabilities to maximize the success rate of high-priority UEs\nwhile constraining low-priority UEs. Finally, we develop a reinforcement\nlearning approach to solving the optimization problem using multi-armed\nbandits, which provides a near-optimal but scalable solution and does not\nrequire the BS to know the number of UEs in the network.", "published": "2025-04-18 21:42:36", "link": "http://arxiv.org/abs/2504.14085v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A framework for distributed discrete evacuation strategies", "abstract": "Consider the following discrete evacuation model. The evacuation terrain is\nmodeled by a simple graph $G=(V,E)$ whose certain vertices $X\\subseteq V$ are\ncalled \\emph{exits}. Initially, each vertex is either \\emph{empty} or\n\\emph{occupied} by an agent. We assume that each vertex has a unique \\emph{id}\n(and therefore the agents do have unique ids), each agent has finite but\narbitrarily large memory, and the graph is initially stored in the memory of\neach agent. In other words, the agents do know the topology of the network\nalong with the locations of the exits, but they do not know the initial\npositions nor the quantity of other agents. The time is divided into\n\\emph{steps}; in each step any pair of agents present at vertices at a distance\nof at most two can exchange an arbitrary number of messages, and then each\nagent can either make a move or stay put. The agents should make moves in a\ncollision-free manner, i.e., no two agents can be located at the same vertex in\nthe same step. At the end of each step, any agent located at an exit\n\\emph{evacuates}, i.e., it is removed from the graph. The goal is to provide an\nalgorithm to the agents (referred to as an evacuation strategy) that ensures\nthe evacuation of all agents and minimizes the number of steps.\n  This work provides an algorithmic framework that allows constructing valid\nevacuation strategies for arbitrary input graphs. Specifically, we focus on the\nproperties of the input graphs that lead to evacuation strategies with constant\ncompetitive ratios. In particular, we describe an application of the above\nframework that gives an asymptotically optimal evacuation for grids (and by\nextension hexagonal or triangular grids as well).", "published": "2025-04-18 19:49:40", "link": "http://arxiv.org/abs/2504.14052v2", "categories": ["cs.DM", "68R10, 68W05", "G.2.2"], "primary_category": "cs.DM"}
{"title": "Effective Computation of Generalized Abelian Complexity for Pisot Type Substitutive Sequences", "abstract": "Generalized abelian equivalence compares words by their factors up to a\ncertain bounded length. The associated complexity function counts the\nequivalence classes for factors of a given size of an infinite sequence. How\npractical is this notion? When can these equivalence relations and complexity\nfunctions be computed efficiently? We study the fixed points of substitution of\nPisot type. Each of their $k$-abelian complexities is bounded and the Parikh\nvectors of their length-$n$ prefixes form synchronized sequences in the\nassociated Dumont--Thomas numeration system. Therefore, the $k$-abelian\ncomplexity of Pisot substitution fixed points is automatic in the same\nnumeration system. Two effective generic construction approaches are\ninvestigated using the \\texttt{Walnut} theorem prover and are applied to\nseveral examples. We obtain new properties of the Tribonacci sequence, such as\na uniform bound for its factor balancedness together with a two-dimensional\nlinear representation of its generalized abelian complexity functions.", "published": "2025-04-18 09:36:54", "link": "http://arxiv.org/abs/2504.13584v2", "categories": ["cs.FL", "cs.DM", "math.CO", "11B85, 68R15, 68Q45"], "primary_category": "cs.FL"}
{"title": "A Fast Direct Solver for Boundary Integral Equations Using Quadrature By Expansion", "abstract": "We construct and analyze a hierarchical direct solver for linear systems\narising from the discretization of boundary integral equations using the\nQuadrature by Expansion (QBX) method. Our scheme builds on the existing theory\nof Hierarchical Semi-Separable (HSS) matrix operators that contain low-rank\noff-diagonal submatrices. We use proxy-based approximations of the far-field\ninteractions and the Interpolative Decomposition (ID) to construct compressed\nHSS operators that are used as fast direct solvers for the original system. We\ndescribe a number of modifications to the standard HSS framework that enable\ncompatibility with the QBX family of discretization methods. We establish an\nerror model for the direct solver that is based on a multipole expansion of the\nQBX-mediated proxy interactions and standard estimates for the ID\\@. Based on\nthese theoretical results, we develop an automatic approach for setting scheme\nparameters based on user-provided error tolerances. The resulting solver\nseamlessly generalizes across two- and tree-dimensional problems and achieves\nstate-of-the-art asymptotic scaling. We conclude with numerical experiments\nthat support the theoretical expectations for the error and computational cost\nof the direct solver.", "published": "2025-04-18 17:25:11", "link": "http://arxiv.org/abs/2504.13809v2", "categories": ["math.NA", "cs.NA", "31B10, 31C20, 35C15, 33C55, 42A10, 47B34, 65F05"], "primary_category": "math.NA"}
{"title": "Efficient algorithms for the Hadamard decomposition", "abstract": "The Hadamard decomposition is a powerful technique for data analysis and\nmatrix compression, which decomposes a given matrix into the element-wise\nproduct of two or more low-rank matrices. In this paper, we develop an\nefficient algorithm to solve this problem, leveraging an alternating\noptimization approach that decomposes the global non-convex problem into a\nseries of convex sub-problems. To improve performance, we explore advanced\ninitialization strategies inspired by the singular value decomposition (SVD)\nand incorporate acceleration techniques by introducing momentum-based updates.\nBeyond optimizing the two-matrix case, we also extend the Hadamard\ndecomposition framework to support more than two low-rank matrices, enabling\napproximations with higher effective ranks while preserving computational\nefficiency. Finally, we conduct extensive experiments to compare our method\nwith the existing gradient descent-based approaches for the Hadamard\ndecomposition and with traditional low-rank approximation techniques. The\nresults highlight the effectiveness of our proposed method across diverse\ndatasets.", "published": "2025-04-18 11:14:25", "link": "http://arxiv.org/abs/2504.13633v2", "categories": ["cs.LG", "eess.SP", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Framework for Objective-Driven Dynamical Stochastic Fields", "abstract": "Fields offer a versatile approach for describing complex systems composed of\ninteracting and dynamic components. In particular, some of these dynamical and\nstochastic systems may exhibit goal-directed behaviors aimed at achieving\nspecific objectives, which we refer to as $\\textit{intelligent fields}$.\nHowever, due to their inherent complexity, it remains challenging to develop a\nformal theoretical description of such systems and to effectively translate\nthese descriptions into practical applications. In this paper, we propose three\nfundamental principles -- complete configuration, locality, and purposefulness\n-- to establish a theoretical framework for understanding intelligent fields.\nMoreover, we explore methodologies for designing such fields from the\nperspective of artificial intelligence applications. This initial investigation\naims to lay the groundwork for future theoretical developments and practical\nadvances in understanding and harnessing the potential of such objective-driven\ndynamical stochastic fields.", "published": "2025-04-18 15:46:33", "link": "http://arxiv.org/abs/2504.16115v1", "categories": ["cs.AI", "cs.LG", "cs.MA", "nlin.AO"], "primary_category": "cs.AI"}
