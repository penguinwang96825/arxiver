{"title": "Leveraging Acoustic and Linguistic Embeddings from Pretrained speech and\n  language Models for Intent Classification", "abstract": "Intent classification is a task in spoken language understanding. An intent\nclassification system is usually implemented as a pipeline process, with a\nspeech recognition module followed by text processing that classifies the\nintents. There are also studies of end-to-end system that takes acoustic\nfeatures as input and classifies the intents directly. Such systems don't take\nadvantage of relevant linguistic information, and suffer from limited training\ndata. In this work, we propose a novel intent classification framework that\nemploys acoustic features extracted from a pretrained speech recognition system\nand linguistic features learned from a pretrained language model. We use\nknowledge distillation technique to map the acoustic embeddings towards\nlinguistic embeddings. We perform fusion of both acoustic and linguistic\nembeddings through cross-attention approach to classify intents. With the\nproposed method, we achieve 90.86% and 99.07% accuracy on ATIS and Fluent\nspeech corpus, respectively.", "published": "2021-02-15 07:20:06", "link": "http://arxiv.org/abs/2102.07370v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAPGN: MAsked Pointer-Generator Network for sequence-to-sequence\n  pre-training", "abstract": "This paper presents a self-supervised learning method for pointer-generator\nnetworks to improve spoken-text normalization. Spoken-text normalization that\nconverts spoken-style text into style normalized text is becoming an important\ntechnology for improving subsequent processing such as machine translation and\nsummarization. The most successful spoken-text normalization method to date is\nsequence-to-sequence (seq2seq) mapping using pointer-generator networks that\npossess a copy mechanism from an input sequence. However, these models require\na large amount of paired data of spoken-style text and style normalized text,\nand it is difficult to prepare such a volume of data. In order to construct\nspoken-text normalization model from the limited paired data, we focus on\nself-supervised learning which can utilize unpaired text data to improve\nseq2seq models. Unfortunately, conventional self-supervised learning methods do\nnot assume that pointer-generator networks are utilized. Therefore, we propose\na novel self-supervised learning method, MAsked Pointer-Generator Network\n(MAPGN). The proposed method can effectively pre-train the pointer-generator\nnetwork by learning to fill masked tokens using the copy mechanism. Our\nexperiments demonstrate that MAPGN is more effective for pointer-generator\nnetworks than the conventional self-supervised learning methods in two\nspoken-text normalization tasks.", "published": "2021-02-15 07:44:25", "link": "http://arxiv.org/abs/2102.07380v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond the English Web: Zero-Shot Cross-Lingual and Lightweight\n  Monolingual Classification of Registers", "abstract": "We explore cross-lingual transfer of register classification for web\ndocuments. Registers, that is, text varieties such as blogs or news are one of\nthe primary predictors of linguistic variation and thus affect the automatic\nprocessing of language. We introduce two new register annotated corpora,\nFreCORE and SweCORE, for French and Swedish. We demonstrate that deep\npre-trained language models perform strongly in these languages and outperform\nprevious state-of-the-art in English and Finnish. Specifically, we show 1) that\nzero-shot cross-lingual transfer from the large English CORE corpus can match\nor surpass previously published monolingual models, and 2) that lightweight\nmonolingual classification requiring very little training data can reach or\nsurpass our zero-shot performance. We further analyse classification results\nfinding that certain registers continue to pose challenges in particular for\ncross-lingual transfer.", "published": "2021-02-15 08:40:08", "link": "http://arxiv.org/abs/2102.07396v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DOBF: A Deobfuscation Pre-Training Objective for Programming Languages", "abstract": "Recent advances in self-supervised learning have dramatically improved the\nstate of the art on a wide variety of tasks. However, research in language\nmodel pre-training has mostly focused on natural languages, and it is unclear\nwhether models like BERT and its variants provide the best pre-training when\napplied to other modalities, such as source code. In this paper, we introduce a\nnew pre-training objective, DOBF, that leverages the structural aspect of\nprogramming languages and pre-trains a model to recover the original version of\nobfuscated source code. We show that models pre-trained with DOBF significantly\noutperform existing approaches on multiple downstream tasks, providing relative\nimprovements of up to 13% in unsupervised code translation, and 24% in natural\nlanguage code search. Incidentally, we found that our pre-trained model is able\nto de-obfuscate fully obfuscated source files, and to suggest descriptive\nvariable names.", "published": "2021-02-15 11:50:47", "link": "http://arxiv.org/abs/2102.07492v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalization Strategies for End-to-End Speech Recognition Systems", "abstract": "The recognition of personalized content, such as contact names, remains a\nchallenging problem for end-to-end speech recognition systems. In this work, we\ndemonstrate how first and second-pass rescoring strategies can be leveraged\ntogether to improve the recognition of such words. Following previous work, we\nuse a shallow fusion approach to bias towards recognition of personalized\ncontent in the first-pass decoding. We show that such an approach can improve\npersonalized content recognition by up to 16% with minimum degradation on the\ngeneral use case. We describe a fast and scalable algorithm that enables our\nbiasing models to remain at the word-level, while applying the biasing at the\nsubword level. This has the advantage of not requiring the biasing models to be\ndependent on any subword symbol table. We also describe a novel second-pass\nde-biasing approach: used in conjunction with a first-pass shallow fusion that\noptimizes on oracle WER, we can achieve an additional 14% improvement on\npersonalized content recognition, and even improve accuracy for the general use\ncase by up to 2.5%.", "published": "2021-02-15 18:36:13", "link": "http://arxiv.org/abs/2102.07739v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How COVID-19 Is Changing Our Language : Detecting Semantic Shift in\n  Twitter Word Embeddings", "abstract": "Words are malleable objects, influenced by events that are reflected in\nwritten texts. Situated in the global outbreak of COVID-19, our research aims\nat detecting semantic shifts in social media language triggered by the health\ncrisis. With COVID-19 related big data extracted from Twitter, we train\nseparate word embedding models for different time periods after the outbreak.\nWe employ an alignment-based approach to compare these embeddings with a\ngeneral-purpose Twitter embedding unrelated to COVID-19. We also compare our\ntrained embeddings among them to observe diachronic evolution. Carrying out\ncase studies on a set of words chosen by topic detection, we verify that our\nalignment approach is valid. Finally, we quantify the size of global semantic\nshift by a stability measure based on back-and-forth rotational alignment.", "published": "2021-02-15 20:29:00", "link": "http://arxiv.org/abs/2102.07836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MATCH: Metadata-Aware Text Classification in A Large Hierarchy", "abstract": "Multi-label text classification refers to the problem of assigning each given\ndocument its most relevant labels from the label set. Commonly, the metadata of\nthe given documents and the hierarchy of the labels are available in real-world\napplications. However, most existing studies focus on only modeling the text\ninformation, with a few attempts to utilize either metadata or hierarchy\nsignals, but not both of them. In this paper, we bridge the gap by formalizing\nthe problem of metadata-aware text classification in a large label hierarchy\n(e.g., with tens of thousands of labels). To address this problem, we present\nthe MATCH solution -- an end-to-end framework that leverages both metadata and\nhierarchy information. To incorporate metadata, we pre-train the embeddings of\ntext and metadata in the same space and also leverage the fully-connected\nattentions to capture the interrelations between them. To leverage the label\nhierarchy, we propose different ways to regularize the parameters and output\nprobability of each child label by its parents. Extensive experiments on two\nmassive text datasets with large-scale label hierarchies demonstrate the\neffectiveness of MATCH over state-of-the-art deep learning baselines.", "published": "2021-02-15 05:23:08", "link": "http://arxiv.org/abs/2102.07349v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prompt Programming for Large Language Models: Beyond the Few-Shot\n  Paradigm", "abstract": "Prevailing methods for mapping large generative language models to supervised\ntasks may fail to sufficiently probe models' novel capabilities. Using GPT-3 as\na case study, we show that 0-shot prompts can significantly outperform few-shot\nprompts. We suggest that the function of few-shot examples in these cases is\nbetter described as locating an already learned task rather than meta-learning.\nThis analysis motivates rethinking the role of prompts in controlling and\nevaluating powerful language models. In this work, we discuss methods of prompt\nprogramming, emphasizing the usefulness of considering prompts through the lens\nof natural language. We explore techniques for exploiting the capacity of\nnarratives and cultural anchors to encode nuanced intentions and techniques for\nencouraging deconstruction of a problem into components before producing a\nverdict. Informed by this more encompassing theory of prompt programming, we\nalso introduce the idea of a metaprompt that seeds the model to generate its\nown natural language prompts for a range of tasks. Finally, we discuss how\nthese more general methods of interacting with language models can be\nincorporated into existing and future benchmarks and practical applications.", "published": "2021-02-15 05:27:55", "link": "http://arxiv.org/abs/2102.07350v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improved Customer Transaction Classification using Semi-Supervised\n  Knowledge Distillation", "abstract": "In pickup and delivery services, transaction classification based on customer\nprovided free text is a challenging problem. It involves the association of a\nwide variety of customer inputs to a fixed set of categories while adapting to\nthe various customer writing styles. This categorization is important for the\nbusiness: it helps understand the market needs and trends, and also assist in\nbuilding a personalized experience for different segments of the customers.\nHence, it is vital to capture these category information trends at scale, with\nhigh precision and recall. In this paper, we focus on a specific use-case where\na single category drives each transaction. We propose a cost-effective\ntransaction classification approach based on semi-supervision and knowledge\ndistillation frameworks. The approach identifies the category of a transaction\nusing free text input given by the customer. We use weak labelling and notice\nthat the performance gains are similar to that of using human-annotated\nsamples. On a large internal dataset and on 20Newsgroup dataset, we see that\nRoBERTa performs the best for the categorization tasks. Further, using an\nALBERT model (it has 33x fewer parameters vis-a-vis parameters of RoBERTa),\nwith RoBERTa as the Teacher, we see a performance similar to that of RoBERTa\nand better performance over unadapted ALBERT. This framework, with ALBERT as a\nstudent and RoBERTa as teacher, is further referred to as R-ALBERT in this\npaper. The model is in production and is used by business to understand\nchanging trends and take appropriate decisions.", "published": "2021-02-15 16:16:42", "link": "http://arxiv.org/abs/2102.07635v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"From What I see, this makes sense\": Seeing meaning in algorithmic\n  results", "abstract": "In this workshop paper, we use an empirical example from our ongoing\nfieldwork, to showcase the complexity and situatedness of the process of making\nsense of algorithmic results; i.e. how to evaluate, validate, and contextualize\nalgorithmic outputs. So far, in our research work, we have focused on such\nsense-making processes in data analytic learning environments such as\nclassrooms and training workshops. Multiple moments in our fieldwork suggest\nthat meaning, in data analytics, is constructed through an iterative and\nreflexive dialogue between data, code, assumptions, prior knowledge, and\nalgorithmic results. A data analytic result is nothing short of a\nsociotechnical accomplishment - one in which it is extremely difficult, if not\nat times impossible, to clearly distinguish between 'human' and 'technical'\nforms of data analytic work. We conclude this paper with a set of questions\nthat we would like to explore further in this workshop.", "published": "2021-02-15 20:50:11", "link": "http://arxiv.org/abs/2102.07844v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Meta Back-translation", "abstract": "Back-translation is an effective strategy to improve the performance of\nNeural Machine Translation~(NMT) by generating pseudo-parallel data. However,\nseveral recent works have found that better translation quality of the\npseudo-parallel data does not necessarily lead to better final translation\nmodels, while lower-quality but more diverse data often yields stronger\nresults. In this paper, we propose a novel method to generate pseudo-parallel\ndata from a pre-trained back-translation model. Our method is a meta-learning\nalgorithm which adapts a pre-trained back-translation model so that the\npseudo-parallel data it generates would train a forward-translation model to do\nwell on a validation set. In our evaluations in both the standard datasets WMT\nEn-De'14 and WMT En-Fr'14, as well as a multilingual translation setting, our\nmethod leads to significant improvements over strong baselines. Our code will\nbe made available.", "published": "2021-02-15 20:58:32", "link": "http://arxiv.org/abs/2102.07847v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fast End-to-End Speech Recognition via Non-Autoregressive Models and\n  Cross-Modal Knowledge Transferring from BERT", "abstract": "Attention-based encoder-decoder (AED) models have achieved promising\nperformance in speech recognition. However, because the decoder predicts text\ntokens (such as characters or words) in an autoregressive manner, it is\ndifficult for an AED model to predict all tokens in parallel. This makes the\ninference speed relatively slow. We believe that because the encoder already\ncaptures the whole speech utterance, which has the token-level relationship\nimplicitly, we can predict a token without explicitly autoregressive language\nmodeling. When the prediction of a token does not rely on other tokens, the\nparallel prediction of all tokens in the sequence is realizable. Based on this\nidea, we propose a non-autoregressive speech recognition model called LASO\n(Listen Attentively, and Spell Once). The model consists of an encoder, a\ndecoder, and a position dependent summarizer (PDS). The three modules are based\non basic attention blocks. The encoder extracts high-level representations from\nthe speech. The PDS uses positional encodings corresponding to tokens to\nconvert the acoustic representations into token-level representations. The\ndecoder further captures token-level relationships with the self-attention\nmechanism. At last, the probability distribution on the vocabulary is computed\nfor each token position. Therefore, speech recognition is re-formulated as a\nposition-wise classification problem. Further, we propose a cross-modal\ntransfer learning method to refine semantics from a large-scale pre-trained\nlanguage model BERT for improving the performance.", "published": "2021-02-15 15:18:59", "link": "http://arxiv.org/abs/2102.07594v6", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Overview of the TREC 2020 deep learning track", "abstract": "This is the second year of the TREC Deep Learning Track, with the goal of\nstudying ad hoc ranking in the large training data regime. We again have a\ndocument retrieval task and a passage retrieval task, each with hundreds of\nthousands of human-labeled training queries. We evaluate using single-shot\nTREC-style evaluation, to give us a picture of which ranking methods work best\nwhen large data is available, with much more comprehensive relevance labeling\non the small number of test queries. This year we have further evidence that\nrankers with BERT-style pretraining outperform other rankers in the large data\nregime.", "published": "2021-02-15 16:47:00", "link": "http://arxiv.org/abs/2102.07662v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Within-Document Event Coreference with BERT-Based Contextualized\n  Representations", "abstract": "Event coreference continues to be a challenging problem in information\nextraction. With the absence of any external knowledge bases for events,\ncoreference becomes a clustering task that relies on effective representations\nof the context in which event mentions appear. Recent advances in\ncontextualized language representations have proven successful in many tasks,\nhowever, their use in event linking been limited. Here we present a three part\napproach that (1) uses representations derived from a pretrained BERT model to\n(2) train a neural classifier to (3) drive a simple clustering algorithm to\ncreate coreference chains. We achieve state of the art results with this model\non two standard datasets for within-document event coreference task and\nestablish a new standard on a third newer dataset.", "published": "2021-02-15 21:12:43", "link": "http://arxiv.org/abs/2102.09600v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Modulation-Domain Loss for Neural-Network-based Real-time Speech\n  Enhancement", "abstract": "We describe a modulation-domain loss function for deep-learning-based speech\nenhancement systems. Learnable spectro-temporal receptive fields (STRFs) were\nadapted to optimize for a speaker identification task. The learned STRFs were\nthen used to calculate a weighted mean-squared error (MSE) in the modulation\ndomain for training a speech enhancement system. Experiments showed that adding\nthe modulation-domain MSE to the MSE in the spectro-temporal domain\nsubstantially improved the objective prediction of speech quality and\nintelligibility for real-time speech enhancement systems without incurring\nadditional computation during inference.", "published": "2021-02-15 04:03:53", "link": "http://arxiv.org/abs/2102.07330v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Representation Learning For Speech Recognition Using Feedback Based\n  Relevance Weighting", "abstract": "In this work, we propose an acoustic embedding based approach for\nrepresentation learning in speech recognition. The proposed approach involves\ntwo stages comprising of acoustic filterbank learning from raw waveform,\nfollowed by modulation filterbank learning. In each stage, a relevance\nweighting operation is employed that acts as a feature selection module. In\nparticular, the relevance weighting network receives embeddings of the model\noutputs from the previous time instants as feedback. The proposed relevance\nweighting scheme allows the respective feature representations to be adaptively\nselected before propagation to the higher layers. The application of the\nproposed approach for the task of speech recognition on Aurora-4 and CHiME-3\ndatasets gives significant performance improvements over baseline systems on\nraw waveform signal as well as those based on mel representations (average\nrelative improvement of 15% over the mel baseline on Aurora-4 dataset and 7% on\nCHiME-3 dataset).", "published": "2021-02-15 08:20:57", "link": "http://arxiv.org/abs/2102.07390v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "On training targets for noise-robust voice activity detection", "abstract": "The task of voice activity detection (VAD) is an often required module in\nvarious speech processing, analysis and classification tasks. While\nstate-of-the-art neural network based VADs can achieve great results, they\noften exceed computational budgets and real-time operating requirements. In\nthis work, we propose a computationally efficient real-time VAD network that\nachieves state-of-the-art results on several public real recording datasets. We\ninvestigate different training targets for the VAD and show that using the\nsegmental voice-to-noise ratio (VNR) is a better and more noise-robust training\ntarget than the clean speech level based VAD. We also show that multi-target\ntraining improves the performance further.", "published": "2021-02-15 10:37:14", "link": "http://arxiv.org/abs/2102.07445v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "I-vector Based Within Speaker Voice Quality Identification on connected\n  speech", "abstract": "Voice disorders affect a large portion of the population, especially heavy\nvoice users such as teachers or call-center workers. Most voice disorders can\nbe treated effectively with behavioral voice therapy, which teaches patients to\nreplace problematic, habituated voice production mechanics with optimal voice\nproduction technique(s), yielding improved voice quality. However, treatment\noften fails because patients have difficulty differentiating their habitual\nvoice from the target technique independently, when clinician feedback is\nunavailable between therapy sessions. Therefore, with the long term aim to\nextend clinician feedback to extra-clinical settings, we built two systems that\nautomatically differentiate various voice qualities produced by the same\nindividual. We hypothesized that 1) a system based on i-vectors could classify\nthese qualities as if they represent different speakers and 2) such a system\nwould outperform one based on traditional voice signal processing algorithms.\nTraining recordings were provided by thirteen amateur actors, each producing 5\nperceptually different voice qualities in connected speech: normal, breathy,\nfry, twang, and hyponasal. As hypothesized, the i-vector system outperformed\nthe acoustic measure system in classification accuracy (i.e. 97.5\\% compared to\n77.2\\%, respectively). Findings are expected because the i-vector system maps\nfeatures to an integrated space which better represents each voice quality than\nthe 22-feature space of the baseline system. Therefore, an i-vector based\nsystem has potential for clinical application in voice therapy and voice\ntraining.", "published": "2021-02-15 02:26:32", "link": "http://arxiv.org/abs/2102.07307v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PeriodNet: A non-autoregressive waveform generation model with a\n  structure separating periodic and aperiodic components", "abstract": "We propose PeriodNet, a non-autoregressive (non-AR) waveform generation model\nwith a new model structure for modeling periodic and aperiodic components in\nspeech waveforms. The non-AR waveform generation models can generate speech\nwaveforms parallelly and can be used as a speech vocoder by conditioning an\nacoustic feature. Since a speech waveform contains periodic and aperiodic\ncomponents, both components should be appropriately modeled to generate a\nhigh-quality speech waveform. However, it is difficult to decompose the\ncomponents from a natural speech waveform in advance. To address this issue, we\npropose a parallel model and a series model structure separating periodic and\naperiodic components. The features of our proposed models are that explicit\nperiodic and aperiodic signals are taken as input, and external\nperiodic/aperiodic decomposition is not needed in training. Experiments using a\nsinging voice corpus show that our proposed structure improves the naturalness\nof the generated waveform. We also show that the speech waveforms with a pitch\noutside of the training data range can be generated with more naturalness.", "published": "2021-02-15 19:00:08", "link": "http://arxiv.org/abs/2102.07786v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
