{"title": "Scheduled Policy Optimization for Natural Language Communication with\n  Intelligent Agents", "abstract": "We investigate the task of learning to follow natural language instructions\nby jointly reasoning with visual observations and language inputs. In contrast\nto existing methods which start with learning from demonstrations (LfD) and\nthen use reinforcement learning (RL) to fine-tune the model parameters, we\npropose a novel policy optimization algorithm which dynamically schedules\ndemonstration learning and RL. The proposed training paradigm provides\nefficient exploration and better generalization beyond existing methods.\nComparing to existing ensemble models, the best single model based on our\nproposed method tremendously decreases the execution error by over 50% on a\nblock-world environment. To further illustrate the exploration strategy of our\nRL algorithm, We also include systematic studies on the evolution of policy\nentropy during training.", "published": "2018-06-16 05:17:32", "link": "http://arxiv.org/abs/1806.06187v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Study of Semi-supervised Approaches to Improving English-Mandarin\n  Code-Switching Speech Recognition", "abstract": "In this paper, we present our overall efforts to improve the performance of a\ncode-switching speech recognition system using semi-supervised training methods\nfrom lexicon learning to acoustic modeling, on the South East Asian\nMandarin-English (SEAME) data. We first investigate semi-supervised lexicon\nlearning approach to adapt the canonical lexicon, which is meant to alleviate\nthe heavily accented pronunciation issue within the code-switching conversation\nof the local area. As a result, the learned lexicon yields improved\nperformance. Furthermore, we attempt to use semi-supervised training to deal\nwith those transcriptions that are highly mismatched between human transcribers\nand ASR system. Specifically, we conduct semi-supervised training assuming\nthose poorly transcribed data as unsupervised data. We found the\nsemi-supervised acoustic modeling can lead to improved results. Finally, to\nmake up for the limitation of the conventional n-gram language models due to\ndata sparsity issue, we perform lattice rescoring using neural network language\nmodels, and significant WER reduction is obtained.", "published": "2018-06-16 07:18:22", "link": "http://arxiv.org/abs/1806.06200v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GILE: A Generalized Input-Label Embedding for Text Classification", "abstract": "Neural text classification models typically treat output labels as\ncategorical variables which lack description and semantics. This forces their\nparametrization to be dependent on the label set size, and, hence, they are\nunable to scale to large label sets and generalize to unseen ones. Existing\njoint input-label text models overcome these issues by exploiting label\ndescriptions, but they are unable to capture complex label relationships, have\nrigid parametrization, and their gains on unseen labels happen often at the\nexpense of weak performance on the labels seen during training. In this paper,\nwe propose a new input-label model which generalizes over previous such models,\naddresses their limitations and does not compromise performance on seen labels.\nThe model consists of a joint non-linear input-label embedding with\ncontrollable capacity and a joint-space-dependent classification unit which is\ntrained with cross-entropy loss to optimize classification performance. We\nevaluate models on full-resource and low- or zero-resource text classification\nof multilingual news and biomedical text with a large label set. Our model\noutperforms monolingual and multilingual models which do not leverage label\nsemantics and previous joint input-label space models in both scenarios.", "published": "2018-06-16 10:47:41", "link": "http://arxiv.org/abs/1806.06219v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation of sentence embeddings in downstream and linguistic probing\n  tasks", "abstract": "Despite the fast developmental pace of new sentence embedding methods, it is\nstill challenging to find comprehensive evaluations of these different\ntechniques. In the past years, we saw significant improvements in the field of\nsentence embeddings and especially towards the development of universal\nsentence encoders that could provide inductive transfer to a wide variety of\ndownstream tasks. In this work, we perform a comprehensive evaluation of recent\nmethods using a wide variety of downstream and linguistic feature probing\ntasks. We show that a simple approach using bag-of-words with a recently\nintroduced language model for deep context-dependent word embeddings proved to\nyield better results in many tasks when compared to sentence encoders trained\non entailment datasets. We also show, however, that we are still far away from\na universal encoder that can perform consistently across several downstream\ntasks.", "published": "2018-06-16 16:07:49", "link": "http://arxiv.org/abs/1806.06259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Sentiment Analysis using Hierarchical Fusion with Context\n  Modeling", "abstract": "Multimodal sentiment analysis is a very actively growing field of research. A\npromising area of opportunity in this field is to improve the multimodal fusion\nmechanism. We present a novel feature fusion strategy that proceeds in a\nhierarchical fashion, first fusing the modalities two in two and only then\nfusing all three modalities. On multimodal sentiment analysis of individual\nutterances, our strategy outperforms conventional concatenation of features by\n1%, which amounts to 5% reduction in error rate. On utterance-level multimodal\nsentiment analysis of multi-utterance video clips, for which current\nstate-of-the-art techniques incorporate contextual information from other\nutterances of the same clip, our hierarchical fusion gives up to 2.4% (almost\n10% error rate reduction) over currently used concatenation. The implementation\nof our method is publicly available in the form of open-source code.", "published": "2018-06-16 12:05:24", "link": "http://arxiv.org/abs/1806.06228v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Learning Factorized Multimodal Representations", "abstract": "Learning multimodal representations is a fundamentally complex research\nproblem due to the presence of multiple heterogeneous sources of information.\nAlthough the presence of multiple modalities provides additional valuable\ninformation, there are two key challenges to address when learning from\nmultimodal data: 1) models must learn the complex intra-modal and cross-modal\ninteractions for prediction and 2) models must be robust to unexpected missing\nor noisy modalities during testing. In this paper, we propose to optimize for a\njoint generative-discriminative objective across multimodal data and labels. We\nintroduce a model that factorizes representations into two sets of independent\nfactors: multimodal discriminative and modality-specific generative factors.\nMultimodal discriminative factors are shared across all modalities and contain\njoint multimodal features required for discriminative tasks such as sentiment\nprediction. Modality-specific generative factors are unique for each modality\nand contain the information required for generating data. Experimental results\nshow that our model is able to learn meaningful multimodal representations that\nachieve state-of-the-art or competitive performance on six multimodal datasets.\nOur model demonstrates flexible generative capabilities by conditioning on\nindependent factors and can reconstruct missing modalities without\nsignificantly impacting performance. Lastly, we interpret our factorized\nrepresentations to understand the interactions that influence multimodal\nlearning.", "published": "2018-06-16 03:48:50", "link": "http://arxiv.org/abs/1806.06176v3", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Offline Extraction of Indic Regional Language from Natural Scene Image\n  using Text Segmentation and Deep Convolutional Sequence", "abstract": "Regional language extraction from a natural scene image is always a\nchallenging proposition due to its dependence on the text information extracted\nfrom Image. Text Extraction on the other hand varies on different lighting\ncondition, arbitrary orientation, inadequate text information, heavy background\ninfluence over text and change of text appearance. This paper presents a novel\nunified method for tackling the above challenges. The proposed work uses an\nimage correction and segmentation technique on the existing Text Detection\nPipeline an Efficient and Accurate Scene Text Detector (EAST). EAST uses\nstandard PVAnet architecture to select features and non maximal suppression to\ndetect text from image. Text recognition is done using combined architecture of\nMaxOut convolution neural network (CNN) and Bidirectional long short term\nmemory (LSTM) network. After recognizing text using the Deep Learning based\napproach, the native Languages are translated to English and tokenized using\nstandard Text Tokenizers. The tokens that very likely represent a location is\nused to find the Global Positioning System (GPS) coordinates of the location\nand subsequently the regional languages spoken in that location is extracted.\nThe proposed method is tested on a self generated dataset collected from\nGovernment of India dataset and experimented on Standard Dataset to evaluate\nthe performance of the proposed technique. Comparative study with a few\nstate-of-the-art methods on text detection, recognition and extraction of\nregional language from images shows that the proposed method outperforms the\nexisting methods.", "published": "2018-06-16 08:31:06", "link": "http://arxiv.org/abs/1806.06208v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Biased Embeddings from Wild Data: Measuring, Understanding and Removing", "abstract": "Many modern Artificial Intelligence (AI) systems make use of data embeddings,\nparticularly in the domain of Natural Language Processing (NLP). These\nembeddings are learnt from data that has been gathered \"from the wild\" and have\nbeen found to contain unwanted biases. In this paper we make three\ncontributions towards measuring, understanding and removing this problem. We\npresent a rigorous way to measure some of these biases, based on the use of\nword lists created for social psychology applications; we observe how gender\nbias in occupations reflects actual gender bias in the same occupations in the\nreal world; and finally we demonstrate how a simple projection can\nsignificantly reduce the effects of embedding bias. All this is part of an\nongoing effort to understand how trust can be built into AI systems.", "published": "2018-06-16 21:46:59", "link": "http://arxiv.org/abs/1806.06301v1", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
