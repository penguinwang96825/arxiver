{"title": "Combining Financial Data and News Articles for Stock Price Movement Prediction Using Large Language Models", "abstract": "Predicting financial markets and stock price movements requires analyzing a\ncompany's performance, historic price movements, industry-specific events\nalongside the influence of human factors such as social media and press\ncoverage. We assume that financial reports (such as income statements, balance\nsheets, and cash flow statements), historical price data, and recent news\narticles can collectively represent aforementioned factors. We combine\nfinancial data in tabular format with textual news articles and employ\npre-trained Large Language Models (LLMs) to predict market movements. Recent\nresearch in LLMs has demonstrated that they are able to perform both tabular\nand text classification tasks, making them our primary model to classify the\nmulti-modal data. We utilize retrieval augmentation techniques to retrieve and\nattach relevant chunks of news articles to financial metrics related to a\ncompany and prompt the LLMs in zero, two, and four-shot settings. Our dataset\ncontains news articles collected from different sources, historic stock price,\nand financial report data for 20 companies with the highest trading volume\nacross different industries in the stock market. We utilized recently released\nlanguage models for our LLM-based classifier, including GPT- 3 and 4, and\nLLaMA- 2 and 3 models. We introduce an LLM-based classifier capable of\nperforming classification tasks using combination of tabular (structured) and\ntextual (unstructured) data. By using this model, we predicted the movement of\na given stock's price in our dataset with a weighted F1-score of 58.5% and\n59.1% and Matthews Correlation Coefficient of 0.175 for both 3-month and\n6-month periods.", "published": "2024-11-02 21:53:20", "link": "http://arxiv.org/abs/2411.01368v1", "categories": ["cs.IR", "q-fin.CP"], "primary_category": "cs.IR"}
{"title": "FinBERT-BiLSTM: A Deep Learning Model for Predicting Volatile Cryptocurrency Market Prices Using Market Sentiment Dynamics", "abstract": "Time series forecasting is a key tool in financial markets, helping to\npredict asset prices and guide investment decisions. In highly volatile\nmarkets, such as cryptocurrencies like Bitcoin (BTC) and Ethereum (ETH),\nforecasting becomes more difficult due to extreme price fluctuations driven by\nmarket sentiment, technological changes, and regulatory shifts. Traditionally,\nforecasting relied on statistical methods, but as markets became more complex,\ndeep learning models like LSTM, Bi-LSTM, and the newer FinBERT-LSTM emerged to\ncapture intricate patterns. Building upon recent advancements and addressing\nthe volatility inherent in cryptocurrency markets, we propose a hybrid model\nthat combines Bidirectional Long Short-Term Memory (Bi-LSTM) networks with\nFinBERT to enhance forecasting accuracy for these assets. This approach fills a\nkey gap in forecasting volatile financial markets by blending advanced time\nseries models with sentiment analysis, offering valuable insights for investors\nand analysts navigating unpredictable markets.", "published": "2024-11-02 14:43:06", "link": "http://arxiv.org/abs/2411.12748v1", "categories": ["q-fin.TR", "cs.LG"], "primary_category": "q-fin.TR"}
{"title": "TabVer: Tabular Fact Verification with Natural Logic", "abstract": "Fact verification on tabular evidence incentivises the use of symbolic\nreasoning models where a logical form is constructed (e.g. a LISP-style\nprogram), providing greater verifiability than fully neural approaches.\nHowever, these systems typically rely on well-formed tables, restricting their\nuse in many scenarios. An emerging symbolic reasoning paradigm for textual\nevidence focuses on natural logic inference, which constructs proofs by\nmodelling set-theoretic relations between a claim and its evidence in natural\nlanguage. This approach provides flexibility and transparency but is less\ncompatible with tabular evidence since the relations do not extend to\narithmetic functions. We propose a set-theoretic interpretation of numerals and\narithmetic functions in the context of natural logic, enabling the integration\nof arithmetic expressions in deterministic proofs. We leverage large language\nmodels to generate arithmetic expressions by generating questions about salient\nparts of a claim which are answered by executing appropriate functions on\ntables. In a few-shot setting on FEVEROUS, we achieve an accuracy of 71.4,\noutperforming both fully neural and symbolic reasoning models by 3.4 points.\nWhen evaluated on TabFact without any further training, our method remains\ncompetitive with an accuracy lead of 0.5 points.", "published": "2024-11-02 00:36:34", "link": "http://arxiv.org/abs/2411.01093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Consistency Falls Short! The Adverse Effects of Positional Bias on\n  Long-Context Problems", "abstract": "Self-consistency (SC) has been demonstrated to enhance the performance of\nlarge language models (LLMs) across various tasks and domains involving short\ncontent. However, does this evidence support its effectiveness for long-context\nproblems?\n  We challenge the assumption that SC's benefits generalize to long-context\nsettings, where LLMs often struggle with position bias--a systematic tendency\nto over-rely on specific context regions-which hinders their ability to utilize\ninformation effectively from all parts of their context. Through comprehensive\nexperimentation with varying state-of-the-art models and tasks, we find that SC\nnot only fails to improve but actively degrades performance on long-context\ntasks. This degradation appears driven by persistent position bias, worsening\nwith longer context lengths and smaller model sizes, but invariant to prompt\nformat or task type. Unlike short-context tasks, where SC diversifies reasoning\npaths, long-context SC amplifies positional errors. These comprehensive results\nprovide valuable insight into the limitations of current LLMs in long-context\nunderstanding and highlight the need for more sophisticated approaches.", "published": "2024-11-02 01:52:42", "link": "http://arxiv.org/abs/2411.01101v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do LLMs Know to Respect Copyright Notice?", "abstract": "Prior study shows that LLMs sometimes generate content that violates\ncopyright. In this paper, we study another important yet underexplored problem,\ni.e., will LLMs respect copyright information in user input, and behave\naccordingly? The research problem is critical, as a negative answer would imply\nthat LLMs will become the primary facilitator and accelerator of copyright\ninfringement behavior. We conducted a series of experiments using a diverse set\nof language models, user prompts, and copyrighted materials, including books,\nnews articles, API documentation, and movie scripts. Our study offers a\nconservative evaluation of the extent to which language models may infringe\nupon copyrights when processing user input containing protected material. This\nresearch emphasizes the need for further investigation and the importance of\nensuring LLMs respect copyright regulations when handling user input to prevent\nunauthorized use or reproduction of protected content. We also release a\nbenchmark dataset serving as a test bed for evaluating infringement behaviors\nby LLMs and stress the need for future alignment.", "published": "2024-11-02 04:45:21", "link": "http://arxiv.org/abs/2411.01136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dictionary Insertion Prompting for Multilingual Reasoning on\n  Multilingual Large Language Models", "abstract": "As current training data for Large Language Models (LLMs) are dominated by\nEnglish corpus, they are English-centric and they present impressive\nperformance on English reasoning tasks.\\footnote{This paper primarily studies\nEnglish-centric models, but our method could be universal by using the centric\nlanguage in the dictionary for non-English-centric LLMs.} Yet, they usually\nsuffer from lower performance in other languages. There are about 7,000\nlanguages over the world, and many are low-resourced on English-centric LLMs.\nFor the sake of people who primarily speak these languages, it is especially\nurgent to enable our LLMs in those languages. Model training is usually\neffective, but computationally expensive and requires experienced NLP\npractitioners. This paper presents a novel and simple yet effective method\ncalled \\textbf{D}ictionary \\textbf{I}nsertion \\textbf{P}rompting\n(\\textbf{DIP}). When providing a non-English prompt, DIP looks up a word\ndictionary and inserts words' English counterparts into the prompt for LLMs. It\nthen enables better translation into English and better English model thinking\nsteps which leads to obviously better results. We experiment with about 200\nlanguages from FLORES-200. Since there are no adequate datasets, we use the\nNLLB translator to create synthetic multilingual benchmarks from the existing 4\nEnglish reasoning benchmarks such as GSM8K and AQuA. Despite the simplicity and\ncomputationally lightweight, we surprisingly found the effectiveness of DIP on\nmath and commonsense reasoning tasks on multiple open-source and close-source\nLLMs.\\footnote{Our dictionaries, code, and synthetic benchmarks will be\nopen-sourced to facilitate future research.}", "published": "2024-11-02 05:10:50", "link": "http://arxiv.org/abs/2411.01141v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset\n  for Security Research", "abstract": "This research addresses command-line embedding in cybersecurity, a field\nobstructed by the lack of comprehensive datasets due to privacy and regulation\nconcerns. We propose the first dataset of similar command lines, named CyPHER,\nfor training and unbiased evaluation. The training set is generated using a set\nof large language models (LLMs) comprising 28,520 similar command-line pairs.\nOur testing dataset consists of 2,807 similar command-line pairs sourced from\nauthentic command-line data.\n  In addition, we propose a command-line embedding model named CmdCaliper,\nenabling the computation of semantic similarity with command lines. Performance\nevaluations demonstrate that the smallest version of CmdCaliper (30 million\nparameters) suppresses state-of-the-art (SOTA) sentence embedding models with\nten times more parameters across various tasks (e.g., malicious command-line\ndetection and similar command-line retrieval).\n  Our study explores the feasibility of data generation using LLMs in the\ncybersecurity domain. Furthermore, we release our proposed command-line\ndataset, embedding models' weights and all program codes to the public. This\nadvancement paves the way for more effective command-line embedding for future\nresearchers.", "published": "2024-11-02 08:30:45", "link": "http://arxiv.org/abs/2411.01176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and\n  Cross-Cultural Embedding Models and Benchmarks", "abstract": "We introduce {\\bf Swan}, a family of embedding models centred around the\nArabic language, addressing both small-scale and large-scale use cases. Swan\nincludes two variants: Swan-Small, based on ARBERTv2, and Swan-Large, built on\nArMistral, a pretrained Arabic large language model. To evaluate these models,\nwe propose ArabicMTEB, a comprehensive benchmark suite that assesses\ncross-lingual, multi-dialectal, multi-domain, and multi-cultural Arabic text\nembedding performance, covering eight diverse tasks and spanning 94 datasets.\nSwan-Large achieves state-of-the-art results, outperforming\nMultilingual-E5-large in most Arabic tasks, while the Swan-Small consistently\nsurpasses Multilingual-E5-base. Our extensive evaluations demonstrate that Swan\nmodels are both dialectally and culturally aware, excelling across various\nArabic domains while offering significant monetary efficiency. This work\nsignificantly advances the field of Arabic language modelling and provides\nvaluable resources for future research and applications in Arabic natural\nlanguage processing. Our models and benchmark are available at our GitHub page:\n\\href{https://github.com/UBC-NLP/swan}{https://github.com/UBC-NLP/swan}", "published": "2024-11-02 09:39:49", "link": "http://arxiv.org/abs/2411.01192v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One Arrow, Many Targets: Probing LLMs for Multi-Attribute Controllable\n  Text Summarization", "abstract": "Text summarization is a well-established task within the natural language\nprocessing (NLP) community. However, the focus on controllable summarization\ntailored to user requirements is gaining traction only recently. While several\nefforts explore controllability in text summarization, the investigation of\nMulti-Attribute Controllable Summarization (MACS) remains limited. This work\naddresses this gap by examining the MACS task through the lens of large\nlanguage models (LLMs), using various learning paradigms, particularly low-rank\nadapters. We experiment with different popular adapter fine-tuning strategies\nto assess the effectiveness of the resulting models in retaining cues and\npatterns associated with multiple controllable attributes. Additionally, we\npropose and evaluate a novel hierarchical adapter fusion technique to integrate\nlearnings from two distinct controllable attributes. Subsquently, we present\nour findings, discuss the challenges encountered, and suggest potential avenues\nfor advancing the MACS task.", "published": "2024-11-02 11:07:25", "link": "http://arxiv.org/abs/2411.01213v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "$B^4$: A Black-Box Scrubbing Attack on LLM Watermarks", "abstract": "Watermarking has emerged as a prominent technique for LLM-generated content\ndetection by embedding imperceptible patterns. Despite supreme performance, its\nrobustness against adversarial attacks remains underexplored. Previous work\ntypically considers a grey-box attack setting, where the specific type of\nwatermark is already known. Some even necessitates knowledge about\nhyperparameters of the watermarking method. Such prerequisites are unattainable\nin real-world scenarios. Targeting at a more realistic black-box threat model\nwith fewer assumptions, we here propose $B^4$, a black-box scrubbing attack on\nwatermarks. Specifically, we formulate the watermark scrubbing attack as a\nconstrained optimization problem by capturing its objectives with two\ndistributions, a Watermark Distribution and a Fidelity Distribution. This\noptimization problem can be approximately solved using two proxy distributions.\nExperimental results across 12 different settings demonstrate the superior\nperformance of $B^4$ compared with other baselines.", "published": "2024-11-02 12:01:44", "link": "http://arxiv.org/abs/2411.01222v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PMoL: Parameter Efficient MoE for Preference Mixing of LLM Alignment", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been proven to be an\neffective method for preference alignment of large language models (LLMs) and\nis widely used in the post-training process of LLMs. However, RLHF struggles\nwith handling multiple competing preferences. This leads to a decrease in the\nalignment of LLMs with human preferences. To address this issue, we propose\nPreference Mixture of LoRAs (PMoL) from the perspective of model architecture,\nwhich can adapt to any number of preferences to mix. PMoL combines Mixture of\nExperts (MoE) and Low Rank Adaptor (LoRA). This architecture is innovatively\napplied to the research of preference alignment and has achieved significant\nperformance improvement. The expert group soft loss is used to enable MoE with\nthe ability to mix preferences. Through comprehensive evaluation by the reward\nmodel and GPT-4o, the experiment results show that PMoL has superior preference\nmixing capabilities compared to baseline methods. PMoL achieves better\npreference alignment with lower training costs.", "published": "2024-11-02 13:51:14", "link": "http://arxiv.org/abs/2411.01245v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLP and Education: using semantic similarity to evaluate filled gaps in\n  a large-scale Cloze test in the classroom", "abstract": "This study examines the applicability of the Cloze test, a widely used tool\nfor assessing text comprehension proficiency, while highlighting its challenges\nin large-scale implementation. To address these limitations, an automated\ncorrection approach was proposed, utilizing Natural Language Processing (NLP)\ntechniques, particularly word embeddings (WE) models, to assess semantic\nsimilarity between expected and provided answers. Using data from Cloze tests\nadministered to students in Brazil, WE models for Brazilian Portuguese (PT-BR)\nwere employed to measure the semantic similarity of the responses. The results\nwere validated through an experimental setup involving twelve judges who\nclassified the students' answers. A comparative analysis between the WE models'\nscores and the judges' evaluations revealed that GloVe was the most effective\nmodel, demonstrating the highest correlation with the judges' assessments. This\nstudy underscores the utility of WE models in evaluating semantic similarity\nand their potential to enhance large-scale Cloze test assessments. Furthermore,\nit contributes to educational assessment methodologies by offering a more\nefficient approach to evaluating reading proficiency.", "published": "2024-11-02 15:22:26", "link": "http://arxiv.org/abs/2411.01280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Multimodal Large Language Model Think Analogically?", "abstract": "Analogical reasoning, particularly in multimodal contexts, is the foundation\nof human perception and creativity. Multimodal Large Language Model (MLLM) has\nrecently sparked considerable discussion due to its emergent capabilities. In\nthis paper, we delve into the multimodal analogical reasoning capability of\nMLLM. Specifically, we explore two facets: \\textit{MLLM as an explainer} and\n\\textit{MLLM as a predictor}. In \\textit{MLLM as an explainer}, we primarily\nfocus on whether MLLM can deeply comprehend multimodal analogical reasoning\nproblems. We propose a unified prompt template and a method for harnessing the\ncomprehension capabilities of MLLM to augment existing models. In \\textit{MLLM\nas a predictor}, we aim to determine whether MLLM can directly solve multimodal\nanalogical reasoning problems. The experiments show that our approach\noutperforms existing methods on popular datasets, providing preliminary\nevidence for the analogical reasoning capability of MLLM.", "published": "2024-11-02 16:59:49", "link": "http://arxiv.org/abs/2411.01307v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMREx: AMR for Explainable Fact Verification", "abstract": "With the advent of social media networks and the vast amount of information\ncirculating through them, automatic fact verification is an essential component\nto prevent the spread of misinformation. It is even more useful to have fact\nverification systems that provide explanations along with their classifications\nto ensure accurate predictions. To address both of these requirements, we\nimplement AMREx, an Abstract Meaning Representation (AMR)-based veracity\nprediction and explanation system for fact verification using a combination of\nSmatch, an AMR evaluation metric to measure meaning containment and textual\nsimilarity, and demonstrate its effectiveness in producing partially\nexplainable justifications using two community standard fact verification\ndatasets, FEVER and AVeriTeC. AMREx surpasses the AVeriTec baseline accuracy\nshowing the effectiveness of our approach for real-world claim verification. It\nfollows an interpretable pipeline and returns an explainable AMR node mapping\nto clarify the system's veracity predictions when applicable. We further\ndemonstrate that AMREx output can be used to prompt LLMs to generate\nnatural-language explanations using the AMR mappings as a guide to lessen the\nprobability of hallucinations.", "published": "2024-11-02 19:14:19", "link": "http://arxiv.org/abs/2411.01343v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Infant Agent: A Tool-Integrated, Logic-Driven Agent with Cost-Effective\n  API Usage", "abstract": "Despite the impressive capabilities of large language models (LLMs), they\ncurrently exhibit two primary limitations,\n\\textbf{\\uppercase\\expandafter{\\romannumeral 1}}: They struggle to\n\\textbf{autonomously solve the real world engineering problem}.\n\\textbf{\\uppercase\\expandafter{\\romannumeral 2}}: They remain\n\\textbf{challenged in reasoning through complex logic problems}. To address\nthese challenges, we developed the \\textsc{Infant Agent}, integrating\ntask-aware functions, operators, a hierarchical management system, and a memory\nretrieval mechanism. Together, these components enable large language models to\nsustain extended reasoning processes and handle complex, multi-step tasks\nefficiently, all while significantly reducing API costs. Using the\n\\textsc{Infant Agent}, GPT-4o's accuracy on the SWE-bench-lite dataset rises\nfrom $\\mathbf{0.33\\%}$ to $\\mathbf{30\\%}$, and in the AIME-2024 mathematics\ncompetition, it increases GPT-4o's accuracy from $\\mathbf{13.3\\%}$ to\n$\\mathbf{37\\%}$.", "published": "2024-11-02 02:48:37", "link": "http://arxiv.org/abs/2411.01114v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Transfer Learning for Finetuning Large Language Models", "abstract": "As the landscape of large language models expands, efficiently finetuning for\nspecific tasks becomes increasingly crucial. At the same time, the landscape of\nparameter-efficient finetuning methods rapidly expands. Consequently,\npractitioners face a multitude of complex choices when searching for an optimal\nfinetuning pipeline for large language models. To reduce the complexity for\npractitioners, we investigate transfer learning for finetuning large language\nmodels and aim to transfer knowledge about configurations from related\nfinetuning tasks to a new task. In this work, we transfer learn finetuning by\nmeta-learning performance and cost surrogate models for grey-box\nmeta-optimization from a new meta-dataset. Counter-intuitively, we propose to\nrely only on transfer learning for new datasets. Thus, we do not use\ntask-specific Bayesian optimization but prioritize knowledge transferred from\nrelated tasks over task-specific feedback. We evaluate our method on eight\nsynthetic question-answer datasets and a meta-dataset consisting of 1,800 runs\nof finetuning Microsoft's Phi-3. Our transfer learning is superior to\nzero-shot, default finetuning, and meta-optimization baselines. Our results\ndemonstrate the transferability of finetuning to adapt large language models\nmore effectively.", "published": "2024-11-02 09:43:12", "link": "http://arxiv.org/abs/2411.01195v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PRIMO: Progressive Induction for Multi-hop Open Rule Generation", "abstract": "Open rule refer to the implication from premise atoms to hypothesis atoms,\nwhich captures various relations between instances in the real world. Injecting\nopen rule knowledge into the machine helps to improve the performance of\ndownstream tasks such as dialogue and relation extraction. Existing approaches\nfocus on single-hop open rule generation, ignoring multi-hop scenarios, leading\nto logical inconsistencies between premise and hypothesis atoms, as well as\nsemantic duplication of generated rule atoms. To address these issues, we\npropose a progressive multi-stage open rule generation method called PRIMO. We\nintroduce ontology information during the rule generation stage to reduce\nambiguity and improve rule accuracy. PRIMO constructs a multi-stage structure\nconsisting of generation, extraction, and ranking modules to fully leverage the\nlatent knowledge within the language model across multiple dimensions.\nFurthermore, we employ reinforcement learning from human feedback to further\noptimize model, enhancing the model's understanding of commonsense knowledge.\nExperiments show that compared to baseline models, PRIMO significantly improves\nrule quality and diversity while reducing the repetition rate of rule atoms.", "published": "2024-11-02 10:33:50", "link": "http://arxiv.org/abs/2411.01205v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diversidade lingu\u00edstica e inclus\u00e3o digital: desafios para uma ia\n  brasileira", "abstract": "Linguistic diversity is a human attribute which, with the advance of\ngenerative AIs, is coming under threat. This paper, based on the contributions\nof sociolinguistics, examines the consequences of the variety selection bias\nimposed by technological applications and the vicious circle of preserving a\nvariety that becomes dominant and standardized because it has linguistic\ndocumentation to feed the large language models for machine learning.", "published": "2024-11-02 14:17:33", "link": "http://arxiv.org/abs/2411.01259v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "An Innovative CGL-MHA Model for Sarcasm Sentiment Recognition Using the\n  MindSpore Framework", "abstract": "The pervasive use of the Internet and social media introduces significant\nchallenges to automated sentiment analysis, particularly for sarcastic\nexpressions in user-generated content. Sarcasm conveys negative emotions\nthrough ostensibly positive or exaggerated language, complicating its detection\nwithin natural language processing tasks. To address this, we propose an\ninnovative sarcasm detection model integrating Convolutional Neural Networks\n(CNN), Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), and\nMulti-Head Attention mechanisms. The CNN component captures local n-gram\nfeatures, while GRU and LSTM layers model sequential dependencies and\ncontextual information. Multi-Head Attention enhances the model's focus on\nrelevant parts of the input, improving interpretability. Experiments on two\nsarcasm detection datasets, Headlines and Riloff, demonstrate that the model\nachieves an accuracy of 81.20% and an F1 score of 80.77% on Headlines, and an\naccuracy of 79.72% with an F1 score of 61.39% on Riloff, outperforming\ntraditional models. These results validate the effectiveness of our hybrid\napproach for sarcasm detection in social media texts.", "published": "2024-11-02 14:33:47", "link": "http://arxiv.org/abs/2411.01264v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Varco Arena: A Tournament Approach to Reference-Free Benchmarking Large\n  Language Models", "abstract": "Most existing benchmarking approaches for evaluating the output quality of\nlarge language models (LLMs) rely on comparing LLM responses to predefined\nreferences. Such methods, based on static datasets, quickly become outdated as\nLLM capabilities and use cases evolve. In this work, we introduce VARCO\nArena--a novel, cost-effective, and robust benchmarking approach that leverages\na single-elimination tournament structure to minimize the number of required\ncomparisons while eliminating the need for static references or costly human\nannotations. We validate our approach through two experiments: (i) a simulation\nstudy that examines its robustness under various conditions, and (ii) an\nempirical evaluation using publicly available benchmark prompts. In both\nexperiments, VARCO Arena consistently outperforms current LLM benchmarking\npractices, achieving stronger correlations with human-established Elo ratings.\nOur results demonstrate that VARCO Arena not only produces reliable LLM\nrankings but also provides a scalable, adaptable solution for qualitative\nevaluation across diverse, customized use cases.", "published": "2024-11-02 15:23:28", "link": "http://arxiv.org/abs/2411.01281v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Artificial Intelligence Driven Course Generation: A Case Study Using\n  ChatGPT", "abstract": "This study explores Artificial Intelligence use, specifically ChatGPT, in\ncreating educational content. The study aims to elaborate on using ChatGPT to\ncreate course materials. The main objective is to assess the efficiency,\nquality, and impact of AI-driven course generation, and to create a Multimedia\nDatabases course as a case study. The study highlights the potential of AI to\nrevolutionize educational content creation, making it more accessible,\npersonalized, and efficient. The course content was generated in less than one\nday through iterative methods, using prompts for translation, content\nexpansion, practical examples, assignments, supplementary materials, and LaTeX\nformatting. Each part was verified immediately after generation to ensure\naccuracy. Post-generation analysis with Detectia and Turnitin showed similarity\nrates of 8.7% and 13%, indicating high originality. Experts and university\ncommittees reviewed and approved the course, with English university teachers\npraising its language quality. ChatGPT also created a well-structured and\ndiversified exam for the module. Key findings reveal significant time\nefficiency, comprehensive content coverage, and high flexibility. The study\nunderscores AI's transformative potential in education, addressing challenges\nrelated to data privacy, technology dependence, content accuracy, and\nalgorithmic biases. The conclusions emphasize the need for collaboration\nbetween educators, policymakers, and technology developers to harness AI's\nbenefits in education fully.", "published": "2024-11-02 21:59:02", "link": "http://arxiv.org/abs/2411.01369v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Online and Offline Evaluations of Collaborative Filtering and Content\n  Based Recommender Systems", "abstract": "Recommender systems are widely used AI applications designed to help users\nefficiently discover relevant items. The effectiveness of such systems is tied\nto the satisfaction of both users and providers. However, user satisfaction is\ncomplex and cannot be easily framed mathematically using information retrieval\nand accuracy metrics. While many studies evaluate accuracy through offline\ntests, a growing number of researchers argue that online evaluation methods\nsuch as A/B testing are better suited for this purpose. We have employed a\nvariety of algorithms on different types of datasets divergent in size and\nsubject, producing recommendations in various platforms, including media\nstreaming services, digital publishing websites, e-commerce systems, and news\nbroadcasting networks. Notably, our target websites and datasets are in Persian\n(Farsi) language.\n  This study provides a comparative analysis of a large-scale recommender\nsystem that has been operating for the past year across about 70 websites in\nIran, processing roughly 300 requests per second collectively. The system\nemploys user-based and item-based recommendations using content-based,\ncollaborative filtering, trend-based methods, and hybrid approaches. Through\nboth offline and online evaluations, we aim to identify where these algorithms\nperform most efficiently and determine the best method for our specific needs,\nconsidering the dataset and system scale. Our methods of evaluation include\nmanual evaluation, offline tests including accuracy and ranking metrics like\nhit-rate@k and nDCG, and online tests consisting of click-through rate (CTR).\nAdditionally we analyzed and proposed methods to address cold-start and\npopularity bias.", "published": "2024-11-02 20:05:31", "link": "http://arxiv.org/abs/2411.01354v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "TODO: Enhancing LLM Alignment with Ternary Preferences", "abstract": "Aligning large language models (LLMs) with human intent is critical for\nenhancing their performance across a variety of tasks. Standard alignment\ntechniques, such as Direct Preference Optimization (DPO), often rely on the\nbinary Bradley-Terry (BT) model, which can struggle to capture the complexities\nof human preferences -- particularly in the presence of noisy or inconsistent\nlabels and frequent ties. To address these limitations, we introduce the\nTie-rank Oriented Bradley-Terry model (TOBT), an extension of the BT model that\nexplicitly incorporates ties, enabling more nuanced preference representation.\nBuilding on this, we propose Tie-rank Oriented Direct Preference Optimization\n(TODO), a novel alignment algorithm that leverages TOBT's ternary ranking\nsystem to improve preference alignment. In evaluations on Mistral-7B and Llama\n3-8B models, TODO consistently outperforms DPO in modeling preferences across\nboth in-distribution and out-of-distribution datasets. Additional assessments\nusing MT Bench and benchmarks such as Piqa, ARC-c, and MMLU further demonstrate\nTODO's superior alignment performance. Notably, TODO also shows strong results\nin binary preference alignment, highlighting its versatility and potential for\nbroader integration into LLM alignment. The implementation details can be found\nin https://github.com/XXares/TODO.", "published": "2024-11-02 14:36:03", "link": "http://arxiv.org/abs/2411.02442v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Unlocking the Archives: Using Large Language Models to Transcribe\n  Handwritten Historical Documents", "abstract": "This study demonstrates that Large Language Models (LLMs) can transcribe\nhistorical handwritten documents with significantly higher accuracy than\nspecialized Handwritten Text Recognition (HTR) software, while being faster and\nmore cost-effective. We introduce an open-source software tool called\nTranscription Pearl that leverages these capabilities to automatically\ntranscribe and correct batches of handwritten documents using commercially\navailable multimodal LLMs from OpenAI, Anthropic, and Google. In tests on a\ndiverse corpus of 18th/19th century English language handwritten documents,\nLLMs achieved Character Error Rates (CER) of 5.7 to 7% and Word Error Rates\n(WER) of 8.9 to 15.9%, improvements of 14% and 32% respectively over\nspecialized state-of-the-art HTR software like Transkribus. Most significantly,\nwhen LLMs were then used to correct those transcriptions as well as texts\ngenerated by conventional HTR software, they achieved near-human levels of\naccuracy, that is CERs as low as 1.8% and WERs of 3.5%. The LLMs also completed\nthese tasks 50 times faster and at approximately 1/50th the cost of proprietary\nHTR programs. These results demonstrate that when LLMs are incorporated into\nsoftware tools like Transcription Pearl, they provide an accessible, fast, and\nhighly accurate method for mass transcription of historical handwritten\ndocuments, significantly streamlining the digitization process.", "published": "2024-11-02 00:16:29", "link": "http://arxiv.org/abs/2411.03340v1", "categories": ["cs.CV", "cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms\n  Behind Attacks", "abstract": "While `jailbreaks' have been central to research on the safety and\nreliability of LLMs (large language models), the underlying mechanisms behind\nthese attacks are not well understood. Some prior works have used linear\nmethods to analyze jailbreak prompts or model refusal. Here, however, we\ncompare linear and nonlinear methods to study the features in prompts that\ncontribute to successful jailbreaks. We do this by probing for jailbreak\nsuccess based only on the portions of the latent representations corresponding\nto prompt tokens. First, we introduce a dataset of 10,800 jailbreak attempts\nfrom 35 attack methods. We then show that different jailbreaking methods work\nvia different nonlinear features in prompts. Specifically, we find that while\nprobes can distinguish between successful and unsuccessful jailbreaking prompts\nwith a high degree of accuracy, they often transfer poorly to held-out attack\nmethods. We also show that nonlinear probes can be used to mechanistically\njailbreak the LLM by guiding the design of adversarial latent perturbations.\nThese mechanistic jailbreaks are able to jailbreak Gemma-7B-IT more reliably\nthan 34 of the 35 techniques that it was trained on. Ultimately, our results\nsuggest that jailbreaks cannot be thoroughly understood in terms of universal\nor linear prompt features alone.", "published": "2024-11-02 17:29:47", "link": "http://arxiv.org/abs/2411.03343v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Fish-Speech: Leveraging Large Language Models for Advanced Multilingual\n  Text-to-Speech Synthesis", "abstract": "Text-to-Speech (TTS) systems face ongoing challenges in processing complex\nlinguistic features, handling polyphonic expressions, and producing\nnatural-sounding multilingual speech - capabilities that are crucial for future\nAI applications. In this paper, we present Fish-Speech, a novel framework that\nimplements a serial fast-slow Dual Autoregressive (Dual-AR) architecture to\nenhance the stability of Grouped Finite Scalar Vector Quantization (GFSQ) in\nsequence generation tasks. This architecture improves codebook processing\nefficiency while maintaining high-fidelity outputs, making it particularly\neffective for AI interactions and voice cloning.\n  Fish-Speech leverages Large Language Models (LLMs) for linguistic feature\nextraction, eliminating the need for traditional grapheme-to-phoneme (G2P)\nconversion and thereby streamlining the synthesis pipeline and enhancing\nmultilingual support. Additionally, we developed FF-GAN through GFSQ to achieve\nsuperior compression ratios and near 100\\% codebook utilization.\n  Our approach addresses key limitations of current TTS systems while providing\na foundation for more sophisticated, context-aware speech synthesis.\nExperimental results show that Fish-Speech significantly outperforms baseline\nmodels in handling complex linguistic scenarios and voice cloning tasks,\ndemonstrating its potential to advance TTS technology in AI applications. The\nimplementation is open source at\n\\href{https://github.com/fishaudio/fish-speech}{https://github.com/fishaudio/fish-speech}.", "published": "2024-11-02 07:04:02", "link": "http://arxiv.org/abs/2411.01156v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging LLM and Text-Queried Separation for Noise-Robust Sound Event\n  Detection", "abstract": "Sound Event Detection (SED) is challenging in noisy environments where\noverlapping sounds obscure target events. Language-queried audio source\nseparation (LASS) aims to isolate the target sound events from a noisy clip.\nHowever, this approach can fail when the exact target sound is unknown,\nparticularly in noisy test sets, leading to reduced performance. To address\nthis issue, we leverage the capabilities of large language models (LLMs) to\nanalyze and summarize acoustic data. By using LLMs to identify and select\nspecific noise types, we implement a noise augmentation method for noise-robust\nfine-tuning. The fine-tuned model is applied to predict clip-wise event\npredictions as text queries for the LASS model. Our studies demonstrate that\nthe proposed method improves SED performance in noisy environments. This work\nrepresents an early application of LLMs in noise-robust SED and suggests a\npromising direction for handling overlapping events in SED. Codes and\npretrained models are available at\nhttps://github.com/apple-yinhan/Noise-robust-SED.", "published": "2024-11-02 08:16:23", "link": "http://arxiv.org/abs/2411.01174v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Music Foundation Model as Generic Booster for Music Downstream Tasks", "abstract": "We demonstrate the efficacy of using intermediate representations from a\nsingle foundation model to enhance various music downstream tasks. We introduce\nSoniDo, a music foundation model (MFM) designed to extract hierarchical\nfeatures from target music samples. By leveraging hierarchical intermediate\nfeatures, SoniDo constrains the information granularity, leading to improved\nperformance across various downstream tasks including both understanding and\ngenerative tasks. We specifically evaluated this approach on representative\ntasks such as music tagging, music transcription, music source separation, and\nmusic mixing. Our results reveal that the features extracted from foundation\nmodels provide valuable enhancements in training downstream task models. This\nhighlights the capability of using features extracted from music foundation\nmodels as a booster for downstream tasks. Our approach not only benefits\nexisting task-specific models but also supports music downstream tasks\nconstrained by data scarcity. This paves the way for more effective and\naccessible music processing solutions.", "published": "2024-11-02 04:44:27", "link": "http://arxiv.org/abs/2411.01135v2", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
