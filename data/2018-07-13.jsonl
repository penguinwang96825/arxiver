{"title": "A Multi-sentiment-resource Enhanced Attention Network for Sentiment\n  Classification", "abstract": "Deep learning approaches for sentiment classification do not fully exploit\nsentiment linguistic knowledge. In this paper, we propose a\nMulti-sentiment-resource Enhanced Attention Network (MEAN) to alleviate the\nproblem by integrating three kinds of sentiment linguistic knowledge (e.g.,\nsentiment lexicon, negation words, intensity words) into the deep neural\nnetwork via attention mechanisms. By using various types of sentiment\nresources, MEAN utilizes sentiment-relevant information from different\nrepresentation subspaces, which makes it more effective to capture the overall\nsemantics of the sentiment, negation and intensity words for sentiment\nprediction. The experimental results demonstrate that MEAN has robust\nsuperiority over strong competitors.", "published": "2018-07-13 10:01:19", "link": "http://arxiv.org/abs/1807.04990v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-task dialog act and sentiment recognition on Mastodon", "abstract": "Because of license restrictions, it often becomes impossible to strictly\nreproduce most research results on Twitter data already a few months after the\ncreation of the corpus. This situation worsened gradually as time passes and\ntweets become inaccessible. This is a critical issue for reproducible and\naccountable research on social media. We partly solve this challenge by\nannotating a new Twitter-like corpus from an alternative large social medium\nwith licenses that are compatible with reproducible experiments: Mastodon. We\nmanually annotate both dialogues and sentiments on this corpus, and train a\nmulti-task hierarchical recurrent network on joint sentiment and dialog act\nrecognition. We experimentally demonstrate that transfer learning may be\nefficiently achieved between both tasks, and further analyze some specific\ncorrelations between sentiments and dialogues on social media. Both the\nannotated corpus and deep network are released with an open-source license.", "published": "2018-07-13 11:26:42", "link": "http://arxiv.org/abs/1807.05013v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Losses and New Resources for Fine-grained Entity Typing and\n  Linking", "abstract": "Extraction from raw text to a knowledge base of entities and fine-grained\ntypes is often cast as prediction into a flat set of entity and type labels,\nneglecting the rich hierarchies over types and entities contained in curated\nontologies. Previous attempts to incorporate hierarchical structure have\nyielded little benefit and are restricted to shallow ontologies. This paper\npresents new methods using real and complex bilinear mappings for integrating\nhierarchical information, yielding substantial improvement over flat\npredictions in entity linking and fine-grained entity typing, and achieving new\nstate-of-the-art results for end-to-end models on the benchmark FIGER dataset.\nWe also present two new human-annotated datasets containing wide and deep\nhierarchies which we will release to the community to encourage further\nresearch in this direction: MedMentions, a collection of PubMed abstracts in\nwhich 246k mentions have been mapped to the massive UMLS ontology; and TypeNet,\nwhich aligns Freebase types with the WordNet hierarchy to obtain nearly 2k\nentity types. In experiments on all three datasets we show substantial gains\nfrom hierarchy-aware training.", "published": "2018-07-13 15:15:41", "link": "http://arxiv.org/abs/1807.05127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low-Resource Text Classification using Domain-Adversarial Learning", "abstract": "Deep learning techniques have recently shown to be successful in many natural\nlanguage processing tasks forming state-of-the-art systems. They require,\nhowever, a large amount of annotated data which is often missing. This paper\nexplores the use of domain-adversarial learning as a regularizer to avoid\noverfitting when training domain invariant features for deep, complex neural\nnetworks in low-resource and zero-resource settings in new target domains or\nlanguages. In case of new languages, we show that monolingual word vectors can\nbe directly used for training without prealignment. Their projection into a\ncommon space can be learnt ad-hoc at training time reaching the final\nperformance of pretrained multilingual word vectors.", "published": "2018-07-13 17:30:32", "link": "http://arxiv.org/abs/1807.05195v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "New/s/leak 2.0 - Multilingual Information Extraction and Visualization\n  for Investigative Journalism", "abstract": "Investigative journalism in recent years is confronted with two major\nchallenges: 1) vast amounts of unstructured data originating from large text\ncollections such as leaks or answers to Freedom of Information requests, and 2)\nmulti-lingual data due to intensified global cooperation and communication in\npolitics, business and civil society. Faced with these challenges, journalists\nare increasingly cooperating in international networks. To support such\ncollaborations, we present the new version of new/s/leak 2.0, our open-source\nsoftware for content-based searching of leaks. It includes three novel main\nfeatures: 1) automatic language detection and language-dependent information\nextraction for 40 languages, 2) entity and keyword visualization for efficient\nexploration, and 3) decentral deployment for analysis of confidential data from\nvarious formats. We illustrate the new analysis capabilities with an exemplary\ncase study.", "published": "2018-07-13 15:51:31", "link": "http://arxiv.org/abs/1807.05151v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Image Classification for Arabic: Assessing the Accuracy of Direct\n  English to Arabic Translations", "abstract": "Image classification is an ongoing research challenge. Most of the available\nresearch focuses on image classification for the English language, however\nthere is very little research on image classification for the Arabic language.\nExpanding image classification to Arabic has several applications. The present\nstudy investigated a method for generating Arabic labels for images of objects.\nThe method used in this study involved a direct English to Arabic translation\nof the labels that are currently available on ImageNet, a database commonly\nused in image classification research. The purpose of this study was to test\nthe accuracy of this method. In this study, 2,887 labeled images were randomly\nselected from ImageNet. All of the labels were translated from English to\nArabic using Google Translate. The accuracy of the translations was evaluated.\nResults indicated that that 65.6% of the Arabic labels were accurate. This\nstudy makes three important contributions to the image classification\nliterature: (1) it determined the baseline level of accuracy for algorithms\nthat provide Arabic labels for images, (2) it provided 1,895 images that are\ntagged with accurate Arabic labels, and (3) provided the accuracy of\ntranslations of image labels from English to Arabic.", "published": "2018-07-13 17:44:20", "link": "http://arxiv.org/abs/1807.05206v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Ultra-Fine Entity Typing", "abstract": "We introduce a new entity typing task: given a sentence with an entity\nmention, the goal is to predict a set of free-form phrases (e.g. skyscraper,\nsongwriter, or criminal) that describe appropriate types for the target entity.\nThis formulation allows us to use a new type of distant supervision at large\nscale: head words, which indicate the type of the noun phrases they appear in.\nWe show that these ultra-fine types can be crowd-sourced, and introduce new\nevaluation sets that are much more diverse and fine-grained than existing\nbenchmarks. We present a model that can predict open types, and is trained\nusing a multitask objective that pools our new head-word supervision with prior\nsupervision from entity linking. Experimental results demonstrate that our\nmodel is effective in predicting entity types at varying granularity; it\nachieves state of the art performance on an existing fine-grained entity typing\nbenchmark, and sets baselines for our newly-introduced datasets. Our data and\nmodel can be downloaded from: http://nlp.cs.washington.edu/entity_type", "published": "2018-07-13 04:19:03", "link": "http://arxiv.org/abs/1807.04905v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hybrid CTC-Attention based End-to-End Speech Recognition using Subword\n  Units", "abstract": "In this paper, we present an end-to-end automatic speech recognition system,\nwhich successfully employs subword units in a hybrid CTC-Attention based\nsystem. The subword units are obtained by the byte-pair encoding (BPE)\ncompression algorithm. Compared to using words as modeling units, using\ncharacters or subword units does not suffer from the out-of-vocabulary (OOV)\nproblem. Furthermore, using subword units further offers a capability in\nmodeling longer context than using characters. We evaluate different systems\nover the LibriSpeech 1000h dataset. The subword-based hybrid CTC-Attention\nsystem obtains 6.8% word error rate (WER) on the test_clean subset without any\ndictionary or external language model. This represents a significant\nimprovement (a 12.8% WER relative reduction) over the character-based hybrid\nCTC-Attention system.", "published": "2018-07-13 09:06:07", "link": "http://arxiv.org/abs/1807.04978v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Enhanced Representation for Implicit Discourse Relation Recognition", "abstract": "Implicit discourse relation recognition is a challenging task as the relation\nprediction without explicit connectives in discourse parsing needs\nunderstanding of text spans and cannot be easily derived from surface features\nfrom the input sentence pairs. Thus, properly representing the text is very\ncrucial to this task. In this paper, we propose a model augmented with\ndifferent grained text representations, including character, subword, word,\nsentence, and sentence pair levels. The proposed deeper model is evaluated on\nthe benchmark treebank and achieves state-of-the-art accuracy with greater than\n48% in 11-way and $F_1$ score greater than 50% in 4-way classifications for the\nfirst time according to our best knowledge.", "published": "2018-07-13 15:57:39", "link": "http://arxiv.org/abs/1807.05154v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analysis Acoustic Features for Acoustic Scene Classification and Score\n  fusion of multi-classification systems applied to DCASE 2016 challenge", "abstract": "This paper describes an acoustic scene classification method which achieved\nthe 4th ranking result in the IEEE AASP challenge of Detection and\nClassification of Acoustic Scenes and Events 2016. In order to accomplish the\nensuing task, several methods are explored in three aspects: feature\nextraction, feature transformation, and score fusion for final decision. In the\npart of feature extraction, several features are investigated for effective\nacoustic scene classification. For resolving the issue that the same sound can\nbe heard in different places, a feature transformation is applied for better\nseparation for classification. From these, several systems based on different\nfeature sets are devised for classification. The final result is determined by\nfusing the individual systems. The method is demonstrated and validated by the\nexperiment conducted using the Challenge database.", "published": "2018-07-13 08:26:54", "link": "http://arxiv.org/abs/1807.04970v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
