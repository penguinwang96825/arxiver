{"title": "BioBERT: a pre-trained biomedical language representation model for\n  biomedical text mining", "abstract": "Biomedical text mining is becoming increasingly important as the number of\nbiomedical documents rapidly grows. With the progress in natural language\nprocessing (NLP), extracting valuable information from biomedical literature\nhas gained popularity among researchers, and deep learning has boosted the\ndevelopment of effective biomedical text mining models. However, directly\napplying the advancements in NLP to biomedical text mining often yields\nunsatisfactory results due to a word distribution shift from general domain\ncorpora to biomedical corpora. In this article, we investigate how the recently\nintroduced pre-trained language model BERT can be adapted for biomedical\ncorpora. We introduce BioBERT (Bidirectional Encoder Representations from\nTransformers for Biomedical Text Mining), which is a domain-specific language\nrepresentation model pre-trained on large-scale biomedical corpora. With almost\nthe same architecture across tasks, BioBERT largely outperforms BERT and\nprevious state-of-the-art models in a variety of biomedical text mining tasks\nwhen pre-trained on biomedical corpora. While BERT obtains performance\ncomparable to that of previous state-of-the-art models, BioBERT significantly\noutperforms them on the following three representative biomedical text mining\ntasks: biomedical named entity recognition (0.62% F1 score improvement),\nbiomedical relation extraction (2.80% F1 score improvement) and biomedical\nquestion answering (12.24% MRR improvement). Our analysis results show that\npre-training BERT on biomedical corpora helps it to understand complex\nbiomedical texts. We make the pre-trained weights of BioBERT freely available\nat https://github.com/naver/biobert-pretrained, and the source code for\nfine-tuning BioBERT available at https://github.com/dmis-lab/biobert.", "published": "2019-01-25 05:57:24", "link": "http://arxiv.org/abs/1901.08746v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context in Neural Machine Translation: A Review of Models and\n  Evaluations", "abstract": "This review paper discusses how context has been used in neural machine\ntranslation (NMT) in the past two years (2017-2018). Starting with a brief\nretrospect on the rapid evolution of NMT models, the paper then reviews studies\nthat evaluate NMT output from various perspectives, with emphasis on those\nanalyzing limitations of the translation of contextual phenomena. In a\nsubsequent version, the paper will then present the main methods that were\nproposed to leverage context for improving translation quality, and\ndistinguishes methods that aim to improve the translation of specific phenomena\nfrom those that consider a wider unstructured context.", "published": "2019-01-25 23:25:18", "link": "http://arxiv.org/abs/1901.09115v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing Partisan Traits of News Text Attributions", "abstract": "On the topic of journalistic integrity, the current state of accurate,\nimpartial news reporting has garnered much debate in context to the 2016 US\nPresidential Election. In pursuit of computational evaluation of news text, the\nstatements (attributions) ascribed by media outlets to sources provide a common\ncategory of evidence on which to operate. In this paper, we develop an approach\nto compare partisan traits of news text attributions and apply it to\ncharacterize differences in statements ascribed to candidate, Hilary Clinton,\nand incumbent President, Donald Trump. In doing so, we present a model trained\non over 600 in-house annotated attributions to identify each candidate with\naccuracy > 88%. Finally, we discuss insights from its performance for future\nresearch.", "published": "2019-01-25 01:47:13", "link": "http://arxiv.org/abs/1902.02179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing of Term Clustering Frameworks for Modular Ontology Learning", "abstract": "This paper aims to use term clustering to build a modular ontology according\nto core ontology from domain-specific text. The acquisition of semantic\nknowledge focuses on noun phrase appearing with the same syntactic roles in\nrelation to a verb or its preposition combination in a sentence. The\nconstruction of this co-occurrence matrix from context helps to build feature\nspace of noun phrases, which is then transformed to several encoding\nrepresentations including feature selection and dimensionality reduction. In\naddition, the content has also been presented with the construction of word\nvectors. These representations are clustered respectively with K-Means and\nAffinity Propagation (AP) methods, which differentiate into the term clustering\nframeworks. Due to the randomness of K-Means, iteration efforts are adopted to\nfind the optimal parameter. The frameworks are evaluated extensively where AP\nshows dominant effectiveness for co-occurred terms and NMF encoding technique\nis salient by its promising facilities in feature compression.", "published": "2019-01-25 15:04:02", "link": "http://arxiv.org/abs/1901.09037v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Emergent Linguistic Phenomena in Multi-Agent Communication Games", "abstract": "In this work, we propose a computational framework in which agents equipped\nwith communication capabilities simultaneously play a series of referential\ngames, where agents are trained using deep reinforcement learning. We\ndemonstrate that the framework mirrors linguistic phenomena observed in natural\nlanguage: i) the outcome of contact between communities is a function of inter-\nand intra-group connectivity; ii) linguistic contact either converges to the\nmajority protocol, or in balanced cases leads to novel creole languages of\nlower complexity; and iii) a linguistic continuum emerges where neighboring\nlanguages are more mutually intelligible than farther removed languages. We\nconclude that intricate properties of language evolution need not depend on\ncomplex evolved linguistic capabilities, but can emerge from simple social\nexchanges between perceptually-enabled agents playing communication games.", "published": "2019-01-25 01:18:04", "link": "http://arxiv.org/abs/1901.08706v2", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Misleading Metadata Detection on YouTube", "abstract": "YouTube is the leading social media platform for sharing videos. As a result,\nit is plagued with misleading content that includes staged videos presented as\nreal footages from an incident, videos with misrepresented context and videos\nwhere audio/video content is morphed. We tackle the problem of detecting such\nmisleading videos as a supervised classification task. We develop UCNet - a\ndeep network to detect fake videos and perform our experiments on two datasets\n- VAVD created by us and publicly available FVC [8]. We achieve a macro\naveraged F-score of 0.82 while training and testing on a 70:30 split of FVC,\nwhile the baseline model scores 0.36. We find that the proposed model\ngeneralizes well when trained on one dataset and tested on the other.", "published": "2019-01-25 07:09:14", "link": "http://arxiv.org/abs/1901.08759v1", "categories": ["cs.CL", "cs.CV", "eess.IV"], "primary_category": "cs.CL"}
{"title": "Word Embeddings: A Survey", "abstract": "This work lists and describes the main recent strategies for building\nfixed-length, dense and distributed representations for words, based on the\ndistributional hypothesis. These representations are now commonly called word\nembeddings and, in addition to encoding surprisingly good syntactic and\nsemantic information, have been proven useful as extra features in many\ndownstream NLP tasks.", "published": "2019-01-25 20:31:02", "link": "http://arxiv.org/abs/1901.09069v2", "categories": ["cs.CL", "cs.LG", "stat.ML", "A.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "On Learning Meaningful Code Changes via Neural Machine Translation", "abstract": "Recent years have seen the rise of Deep Learning (DL) techniques applied to\nsource code. Researchers have exploited DL to automate several development and\nmaintenance tasks, such as writing commit messages, generating comments and\ndetecting vulnerabilities among others. One of the long lasting dreams of\napplying DL to source code is the possibility to automate non-trivial coding\nactivities. While some steps in this direction have been taken (e.g., learning\nhow to fix bugs), there is still a glaring lack of empirical evidence on the\ntypes of code changes that can be learned and automatically applied by DL. Our\ngoal is to make this first important step by quantitatively and qualitatively\ninvestigating the ability of a Neural Machine Translation (NMT) model to learn\nhow to automatically apply code changes implemented by developers during pull\nrequests. We train and experiment with the NMT model on a set of 236k pairs of\ncode components before and after the implementation of the changes provided in\nthe pull requests. We show that, when applied in a narrow enough context (i.e.,\nsmall/medium-sized pairs of methods before/after the pull request changes), NMT\ncan automatically replicate the changes implemented by developers during pull\nrequests in up to 36% of the cases. Moreover, our qualitative analysis shows\nthat the model is capable of learning and replicating a wide variety of\nmeaningful code changes, especially refactorings and bug-fixing activities. Our\nresults pave the way for novel research in the area of DL on code, such as the\nautomatic learning and applications of refactoring.", "published": "2019-01-25 22:12:39", "link": "http://arxiv.org/abs/1901.09102v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "LOCATA challenge: speaker localization with a planar array", "abstract": "This document describes our submission to the 2018 LOCalization And TrAcking\n(LOCATA) challenge (Tasks 1, 3, 5). We estimate the 3D position of a speaker\nusing the Global Coherence Field (GCF) computed from multiple microphone pairs\nof a DICIT planar array. One of the main challenges when using such an array\nwith omnidirectional microphones is the front-back ambiguity, which is\nparticularly evident in Task 5. We address this challenge by post-processing\nthe peaks of the GCF and exploiting the attenuation introduced by the frame of\nthe array. Moreover, the intermittent nature of speech and the changing\norientation of the speaker make localization difficult. For Tasks 3 and 5, we\nalso employ a Particle Filter (PF) that favors the spatio-temporal continuity\nof the localization results.", "published": "2019-01-25 17:00:56", "link": "http://arxiv.org/abs/1901.08983v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unsupervised speech representation learning using WaveNet autoencoders", "abstract": "We consider the task of unsupervised extraction of meaningful latent\nrepresentations of speech by applying autoencoding neural networks to speech\nwaveforms. The goal is to learn a representation able to capture high level\nsemantic content from the signal, e.g.\\ phoneme identities, while being\ninvariant to confounding low level details in the signal such as the underlying\npitch contour or background noise. Since the learned representation is tuned to\ncontain only phonetic content, we resort to using a high capacity WaveNet\ndecoder to infer information discarded by the encoder from previous samples.\nMoreover, the behavior of autoencoder models depends on the kind of constraint\nthat is applied to the latent representation. We compare three variants: a\nsimple dimensionality reduction bottleneck, a Gaussian Variational Autoencoder\n(VAE), and a discrete Vector Quantized VAE (VQ-VAE). We analyze the quality of\nlearned representations in terms of speaker independence, the ability to\npredict phonetic content, and the ability to accurately reconstruct individual\nspectrogram frames. Moreover, for discrete encodings extracted using the\nVQ-VAE, we measure the ease of mapping them to phonemes. We introduce a\nregularization scheme that forces the representations to focus on the phonetic\ncontent of the utterance and report performance comparable with the top entries\nin the ZeroSpeech 2017 unsupervised acoustic unit discovery task.", "published": "2019-01-25 10:10:12", "link": "http://arxiv.org/abs/1901.08810v2", "categories": ["cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
