{"title": "Detecting Fallacies in Climate Misinformation: A Technocognitive\n  Approach to Identifying Misleading Argumentation", "abstract": "Misinformation about climate change is a complex societal issue requiring\nholistic, interdisciplinary solutions at the intersection between technology\nand psychology. One proposed solution is a \"technocognitive\" approach,\ninvolving the synthesis of psychological and computer science research.\nPsychological research has identified that interventions in response to\nmisinformation require both fact-based (e.g., factual explanations) and\ntechnique-based (e.g., explanations of misleading techniques) content. However,\nlittle progress has been made on documenting and detecting fallacies in climate\nmisinformation. In this study, we apply a previously developed critical\nthinking methodology for deconstructing climate misinformation, in order to\ndevelop a dataset mapping different types of climate misinformation to\nreasoning fallacies. This dataset is used to train a model to detect fallacies\nin climate misinformation. Our study shows F1 scores that are 2.5 to 3.5 better\nthan previous works. The fallacies that are easiest to detect include fake\nexperts and anecdotal arguments, while fallacies that require background\nknowledge, such as oversimplification, misrepresentation, and slothful\ninduction, are relatively more difficult to detect. This research lays the\ngroundwork for development of solutions where automatically detected climate\nmisinformation can be countered with generative technique-based corrections.", "published": "2024-05-14 01:01:44", "link": "http://arxiv.org/abs/2405.08254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and\n  Detailed Benchmark", "abstract": "This paper presents a new tool learning dataset Seal-Tools, which contains\nself-instruct API-like tools. Seal-Tools not only offers a large number of\ntools, but also includes instances which demonstrate the practical application\nof tools. Seeking to generate data on a large scale while ensuring reliability,\nwe propose a self-instruct method to generate tools and instances, allowing\nprecise control over the process. Moreover, our Seal-Tools contains hard\ninstances that call multiple tools to complete the job, among which some are\nnested tool callings. For precise and comprehensive evaluation, we use strict\nformat control and design three metrics from different dimensions. Therefore,\nSeal-Tools can serve as a new benchmark to evaluate the tool-calling ability of\nLLMs. Finally, we evaluate several prevalent LLMs and our finetuned model on\nSeal-Tools. The results show that current systems are far from perfect. The\ncode, data and experiment results are available at\nhttps://github.com/fairyshine/Seal-Tools .", "published": "2024-05-14 06:50:19", "link": "http://arxiv.org/abs/2405.08355v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stylometric Watermarks for Large Language Models", "abstract": "The rapid advancement of large language models (LLMs) has made it\nincreasingly difficult to distinguish between text written by humans and\nmachines. Addressing this, we propose a novel method for generating watermarks\nthat strategically alters token probabilities during generation. Unlike\nprevious works, this method uniquely employs linguistic features such as\nstylometry. Concretely, we introduce acrostica and sensorimotor norms to LLMs.\nFurther, these features are parameterized by a key, which is updated every\nsentence. To compute this key, we use semantic zero shot classification, which\nenhances resilience. In our evaluation, we find that for three or more\nsentences, our method achieves a false positive and false negative rate of\n0.02. For the case of a cyclic translation attack, we observe similar results\nfor seven or more sentences. This research is of particular of interest for\nproprietary LLMs to facilitate accountability and prevent societal harm.", "published": "2024-05-14 07:54:54", "link": "http://arxiv.org/abs/2405.08400v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating the 'Autoencoder Behavior' in Speech Self-Supervised\n  Models: a focus on HuBERT's Pretraining", "abstract": "Self-supervised learning has shown great success in Speech Recognition.\nHowever, it has been observed that finetuning all layers of the learned model\nleads to lower performance compared to resetting top layers. This phenomenon is\nattributed to the ''autoencoder'' behavior: top layers contain information\ncloser to the input and are less suitable for tasks that require linguistic\ninformation, such as Speech Recognition.To better our understanding of this\nbehavior, we propose to study the evolution of high-level information within\nthe model during pretraining. We focus on the HuBERT model, which exhibits a\nless pronounced ''autoencoder'' behavior. By experimentally exploring various\nfactors that may have an impact, we aim to improve the training procedure and\nenhance the top layers of HuBERT for high-level tasks.Furthermore, our\nexperiments demonstrate that these improvements in the training procedure\nresult in faster convergence and competitive performance on downstream tasks.", "published": "2024-05-14 07:55:37", "link": "http://arxiv.org/abs/2405.08402v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alignment Helps Make the Most of Multimodal Data", "abstract": "When studying political communication, combining the information from text,\naudio, and video signals promises to reflect the richness of human\ncommunication more comprehensively than confining it to individual modalities\nalone. However, its heterogeneity, connectedness, and interaction are\nchallenging to address when modeling such multimodal data. We argue that\naligning the respective modalities can be an essential step in entirely using\nthe potential of multimodal data because it informs the model with human\nunderstanding. Taking care of the data-generating process of multimodal data,\nour framework proposes four principles to organize alignment and, thus, address\nthe challenges of multimodal data. We illustrate the utility of these\nprinciples by analyzing how German MPs address members of the far-right AfD in\ntheir speeches and predicting the tone of video advertising in the context of\nthe 2020 US presidential race. Our paper offers important insights to all keen\nto analyze multimodal data effectively.", "published": "2024-05-14 09:20:59", "link": "http://arxiv.org/abs/2405.08454v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Gender-Inclusive Machine Translation with Neomorphemes and\n  Large Language Models", "abstract": "Machine translation (MT) models are known to suffer from gender bias,\nespecially when translating into languages with extensive gendered morphology.\nAccordingly, they still fall short in using gender-inclusive language, also\nrepresentative of non-binary identities. In this paper, we look at\ngender-inclusive neomorphemes, neologistic elements that avoid binary gender\nmarkings as an approach towards fairer MT. In this direction, we explore\nprompting techniques with large language models (LLMs) to translate from\nEnglish into Italian using neomorphemes. So far, this area has been\nunder-explored due to its novelty and the lack of publicly available evaluation\nresources. We fill this gap by releasing Neo-GATE, a resource designed to\nevaluate gender-inclusive en-it translation with neomorphemes. With Neo-GATE,\nwe assess four LLMs of different families and sizes and different prompt\nformats, identifying strengths and weaknesses of each on this novel task for\nMT.", "published": "2024-05-14 10:02:50", "link": "http://arxiv.org/abs/2405.08477v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Less More? Quality, Quantity and Context in Idiom Processing with\n  Natural Language Models", "abstract": "Compositionality in language models presents a problem when processing\nidiomatic expressions, as their meaning often cannot be directly derived from\ntheir individual parts. Although fine-tuning and other optimization strategies\ncan be used to improve representations of idiomatic expressions, this depends\non the availability of relevant data. We present the Noun Compound Synonym\nSubstitution in Books - NCSSB - datasets, which are created by substitution of\nsynonyms of potentially idiomatic English noun compounds in public domain book\ntexts. We explore the trade-off between data quantity and quality when training\nmodels for idiomaticity detection, in conjunction with contextual information\nobtained locally (from the surrounding sentences) or externally (through\nlanguage resources). Performance on an idiomaticity detection task indicates\nthat dataset quality is a stronger factor for context-enriched models, but that\nquantity also plays a role in models without context inclusion strategies.", "published": "2024-05-14 10:54:20", "link": "http://arxiv.org/abs/2405.08497v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure", "abstract": "The SemEval task on Argument Reasoning in Civil Procedure is challenging in\nthat it requires understanding legal concepts and inferring complex arguments.\nCurrently, most Large Language Models (LLM) excelling in the legal realm are\nprincipally purposed for classification tasks, hence their reasoning rationale\nis subject to contention. The approach we advocate involves using a powerful\nteacher-LLM (ChatGPT) to extend the training dataset with explanations and\ngenerate synthetic data. The resulting data are then leveraged to fine-tune a\nsmall student-LLM. Contrary to previous work, our explanations are not directly\nderived from the teacher's internal knowledge. Instead they are grounded in\nauthentic human analyses, therefore delivering a superior reasoning signal.\nAdditionally, a new `mutation' method generates artificial data instances\ninspired from existing ones. We are publicly releasing the explanations as an\nextension to the original dataset, along with the synthetic dataset and the\nprompts that were used to generate both. Our system ranked 15th in the SemEval\ncompetition. It outperforms its own teacher and can produce explanations\naligned with the original human analyses, as verified by legal experts.", "published": "2024-05-14 11:04:16", "link": "http://arxiv.org/abs/2405.08502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysing Cross-Speaker Convergence in Face-to-Face Dialogue through the\n  Lens of Automatically Detected Shared Linguistic Constructions", "abstract": "Conversation requires a substantial amount of coordination between dialogue\nparticipants, from managing turn taking to negotiating mutual understanding.\nPart of this coordination effort surfaces as the reuse of linguistic behaviour\nacross speakers, a process often referred to as alignment. While the presence\nof linguistic alignment is well documented in the literature, several questions\nremain open, including the extent to which patterns of reuse across speakers\nhave an impact on the emergence of labelling conventions for novel referents.\nIn this study, we put forward a methodology for automatically detecting shared\nlemmatised constructions -- expressions with a common lexical core used by both\nspeakers within a dialogue -- and apply it to a referential communication\ncorpus where participants aim to identify novel objects for which no\nestablished labels exist. Our analyses uncover the usage patterns of shared\nconstructions in interaction and reveal that features such as their frequency\nand the amount of different constructions used for a referent are associated\nwith the degree of object labelling convergence the participants exhibit after\nsocial interaction. More generally, the present study shows that automatically\ndetected shared constructions offer a useful level of analysis to investigate\nthe dynamics of reference negotiation in dialogue.", "published": "2024-05-14 12:34:25", "link": "http://arxiv.org/abs/2405.08546v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking the adaptive relationship between Encoder Layers and Decoder\n  Layers", "abstract": "This article explores the adaptive relationship between Encoder Layers and\nDecoder Layers using the SOTA model Helsinki-NLP/opus-mt-de-en, which\ntranslates German to English. The specific method involves introducing a\nbias-free fully connected layer between the Encoder and Decoder, with different\ninitializations of the layer's weights, and observing the outcomes of\nfine-tuning versus retraining. Four experiments were conducted in total. The\nresults suggest that directly modifying the pre-trained model structure for\nfine-tuning yields suboptimal performance. However, upon observing the outcomes\nof the experiments with retraining, this structural adjustment shows\nsignificant potential.", "published": "2024-05-14 13:05:16", "link": "http://arxiv.org/abs/2405.08570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey of Large Language Models and Multimodal Large\n  Language Models in Medicine", "abstract": "Since the release of ChatGPT and GPT-4, large language models (LLMs) and\nmultimodal large language models (MLLMs) have attracted widespread attention\nfor their exceptional capabilities in understanding, reasoning, and generation,\nintroducing transformative paradigms for integrating artificial intelligence\ninto medicine. This survey provides a comprehensive overview of the\ndevelopment, principles, application scenarios, challenges, and future\ndirections of LLMs and MLLMs in medicine. Specifically, it begins by examining\nthe paradigm shift, tracing the transition from traditional models to LLMs and\nMLLMs, and highlighting the unique advantages of these LLMs and MLLMs in\nmedical applications. Next, the survey reviews existing medical LLMs and MLLMs,\nproviding detailed guidance on their construction and evaluation in a clear and\nsystematic manner. Subsequently, to underscore the substantial value of LLMs\nand MLLMs in healthcare, the survey explores five promising applications in the\nfield. Finally, the survey addresses the challenges confronting medical LLMs\nand MLLMs and proposes practical strategies and future directions for their\nintegration into medicine. In summary, this survey offers a comprehensive\nanalysis of the technical methodologies and practical clinical applications of\nmedical LLMs and MLLMs, with the goal of bridging the gap between these\nadvanced technologies and clinical practice, thereby fostering the evolution of\nthe next generation of intelligent healthcare systems.", "published": "2024-05-14 13:42:05", "link": "http://arxiv.org/abs/2405.08603v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-Assisted Rule Based Machine Translation for Low/No-Resource\n  Languages", "abstract": "We propose a new paradigm for machine translation that is particularly useful\nfor no-resource languages (those without any publicly available bilingual or\nmonolingual corpora): LLM-RBMT (LLM-Assisted Rule Based Machine Translation).\nUsing the LLM-RBMT paradigm, we design the first language\neducation/revitalization-oriented machine translator for Owens Valley Paiute\n(OVP), a critically endangered Indigenous American language for which there is\nvirtually no publicly available data. We present a detailed evaluation of the\ntranslator's components: a rule-based sentence builder, an OVP to English\ntranslator, and an English to OVP translator. We also discuss the potential of\nthe paradigm, its limitations, and the many avenues for future research that it\nopens up.", "published": "2024-05-14 23:41:44", "link": "http://arxiv.org/abs/2405.08997v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Decoupling and Aggregating Framework for Joint Extraction of Entities\n  and Relations", "abstract": "Named Entity Recognition and Relation Extraction are two crucial and\nchallenging subtasks in the field of Information Extraction. Despite the\nsuccesses achieved by the traditional approaches, fundamental research\nquestions remain open. First, most recent studies use parameter sharing for a\nsingle subtask or shared features for both two subtasks, ignoring their\nsemantic differences. Second, information interaction mainly focuses on the two\nsubtasks, leaving the fine-grained informtion interaction among the\nsubtask-specific features of encoding subjects, relations, and objects\nunexplored. Motivated by the aforementioned limitations, we propose a novel\nmodel to jointly extract entities and relations. The main novelties are as\nfollows: (1) We propose to decouple the feature encoding process into three\nparts, namely encoding subjects, encoding objects, and encoding relations.\nThanks to this, we are able to use fine-grained subtask-specific features. (2)\nWe propose novel inter-aggregation and intra-aggregation strategies to enhance\nthe information interaction and construct individual fine-grained\nsubtask-specific features, respectively. The experimental results demonstrate\nthat our model outperforms several previous state-of-the-art models. Extensive\nadditional experiments further confirm the effectiveness of our model.", "published": "2024-05-14 04:27:16", "link": "http://arxiv.org/abs/2405.08311v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent\n  Recognition: A New Task, Dataset and Baseline", "abstract": "Stickers are increasingly used in social media to express sentiment and\nintent. When finding typing troublesome, people often use a sticker instead.\nDespite the significant impact of stickers on sentiment analysis and intent\nrecognition, little research has been conducted. To address this gap, we\npropose a new task: Multimodal chat Sentiment Analysis and Intent Recognition\ninvolving Stickers (MSAIRS). Additionally, we introduce a novel multimodal\ndataset containing Chinese chat records and stickers excerpted from several\nmainstream social media platforms. Our dataset includes paired data with the\nsame text but different stickers, and various stickers consisting of the same\nimages with different texts, allowing us to better understand the impact of\nstickers on chat sentiment and intent. We also propose an effective multimodal\njoint model, MMSAIR, for our task, which is validated on our datasets and\nindicates that visual information of stickers counts. Our dataset and code will\nbe publicly available.", "published": "2024-05-14 08:42:49", "link": "http://arxiv.org/abs/2405.08427v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is Your LLM Outdated? A Deep Look at Temporal Generalization", "abstract": "The rapid advancement of Large Language Models (LLMs) has led to the\ndevelopment of benchmarks that consider temporal dynamics, however, there\nremains a gap in understanding how well these models can generalize across\ntemporal contexts due to the inherent dynamic nature of language and\ninformation. This paper introduces the concept of temporal generalization in\nLLMs, including bias in past and future generalizations. Then we introduce\nFreshBench, a new evaluation framework that employs fresh text and event\nprediction for assessing LLMs' temporal adaptability, ensuring the evaluation\nprocess free from data leakage and subjective bias. The experiment shows\nsignificant temporal biases and a decline in performance over time. Our\nfindings reveal that powerful models, while initially superior, tend to decline\nmore rapidly in future generalization. Additionally, powerful open-source\nmodels demonstrate better long-term adaptability compared to their\nclosed-source counterparts. Our code is available at\nhttps://github.com/FreedomIntelligence/FreshBench.", "published": "2024-05-14 09:31:31", "link": "http://arxiv.org/abs/2405.08460v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Challenges and Opportunities in Text Generation Explainability", "abstract": "The necessity for interpretability in natural language processing (NLP) has\nrisen alongside the growing prominence of large language models. Among the\nmyriad tasks within NLP, text generation stands out as a primary objective of\nautoregressive models. The NLP community has begun to take a keen interest in\ngaining a deeper understanding of text generation, leading to the development\nof model-agnostic explainable artificial intelligence (xAI) methods tailored to\nthis task. The design and evaluation of explainability methods are non-trivial\nsince they depend on many factors involved in the text generation process,\ne.g., the autoregressive model and its stochastic nature. This paper outlines\n17 challenges categorized into three groups that arise during the development\nand assessment of attribution-based explainability methods. These challenges\nencompass issues concerning tokenization, defining explanation similarity,\ndetermining token importance and prediction change metrics, the level of human\nintervention required, and the creation of suitable test datasets. The paper\nillustrates how these challenges can be intertwined, showcasing new\nopportunities for the community. These include developing probabilistic\nword-level explainability methods and engaging humans in the explainability\npipeline, from the data design to the final evaluation, to draw robust\nconclusions on xAI methods.", "published": "2024-05-14 09:44:52", "link": "http://arxiv.org/abs/2405.08468v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GPT-3.5 for Grammatical Error Correction", "abstract": "This paper investigates the application of GPT-3.5 for Grammatical Error\nCorrection (GEC) in multiple languages in several settings: zero-shot GEC,\nfine-tuning for GEC, and using GPT-3.5 to re-rank correction hypotheses\ngenerated by other GEC models. In the zero-shot setting, we conduct automatic\nevaluations of the corrections proposed by GPT-3.5 using several methods:\nestimating grammaticality with language models (LMs), the Scribendi test, and\ncomparing the semantic embeddings of sentences. GPT-3.5 has a known tendency to\nover-correct erroneous sentences and propose alternative corrections. For\nseveral languages, such as Czech, German, Russian, Spanish, and Ukrainian,\nGPT-3.5 substantially alters the source sentences, including their semantics,\nwhich presents significant challenges for evaluation with reference-based\nmetrics. For English, GPT-3.5 demonstrates high recall, generates fluent\ncorrections, and generally preserves sentence semantics. However, human\nevaluation for both English and Russian reveals that, despite its strong\nerror-detection capabilities, GPT-3.5 struggles with several error types,\nincluding punctuation mistakes, tense errors, syntactic dependencies between\nwords, and lexical compatibility at the sentence level.", "published": "2024-05-14 09:51:09", "link": "http://arxiv.org/abs/2405.08469v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Transformers with Dynamically Composable Multi-Head Attention", "abstract": "Multi-Head Attention (MHA) is a key component of Transformer. In MHA,\nattention heads work independently, causing problems such as low-rank\nbottleneck of attention score matrices and head redundancy. We propose\nDynamically Composable Multi-Head Attention (DCMHA), a parameter and\ncomputation efficient attention architecture that tackles the shortcomings of\nMHA and increases the expressive power of the model by dynamically composing\nattention heads. At the core of DCMHA is a $\\it{Compose}$ function that\ntransforms the attention score and weight matrices in an input-dependent way.\nDCMHA can be used as a drop-in replacement of MHA in any transformer\narchitecture to obtain the corresponding DCFormer. DCFormer significantly\noutperforms Transformer on different architectures and model scales in language\nmodeling, matching the performance of models with ~1.7x-2.0x compute. For\nexample, DCPythia-6.9B outperforms open source Pythia-12B on both pretraining\nperplexity and downstream task evaluation. The code and models are available at\nhttps://github.com/Caiyun-AI/DCFormer.", "published": "2024-05-14 12:41:11", "link": "http://arxiv.org/abs/2405.08553v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Unseen Targets of Hate -- A Systematic Review of Hateful\n  Communication Datasets", "abstract": "Machine learning (ML)-based content moderation tools are essential to keep\nonline spaces free from hateful communication. Yet, ML tools can only be as\ncapable as the quality of the data they are trained on allows them. While there\nis increasing evidence that they underperform in detecting hateful\ncommunications directed towards specific identities and may discriminate\nagainst them, we know surprisingly little about the provenance of such bias. To\nfill this gap, we present a systematic review of the datasets for the automated\ndetection of hateful communication introduced over the past decade, and unpack\nthe quality of the datasets in terms of the identities that they embody: those\nof the targets of hateful communication that the data curators focused on, as\nwell as those unintentionally included in the datasets. We find, overall, a\nskewed representation of selected target identities and mismatches between the\ntargets that research conceptualizes and ultimately includes in datasets. Yet,\nby contextualizing these findings in the language and location of origin of the\ndatasets, we highlight a positive trend towards the broadening and\ndiversification of this research space.", "published": "2024-05-14 12:50:33", "link": "http://arxiv.org/abs/2405.08562v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "ALMol: Aligned Language-Molecule Translation LLMs through Offline\n  Preference Contrastive Optimisation", "abstract": "The field of chemistry and Artificial Intelligence (AI) intersection is an\narea of active research that aims to accelerate scientific discovery. The\nintegration of large language models (LLMs) with scientific modalities has\nshown significant promise in this endeavour. However, challenges persist in\neffectively addressing training efficacy and the out-of-distribution problem,\nparticularly as existing approaches rely on larger models and datasets. In this\ncontext, we focus on machine language-molecule translation and deploy a novel\ntraining approach called contrastive preference optimisation, which avoids\ngenerating translations that are merely adequate but not perfect. To ensure\ngeneralisability and mitigate memorisation effects, we conduct experiments\nusing only 10% of the data. Our results demonstrate that our models achieve up\nto a 32% improvement compared to counterpart models. Finally, we introduce a\nfine-grained, domain-agnostic evaluation method to assess hallucination in LLMs\nand promote responsible use.", "published": "2024-05-14 13:59:24", "link": "http://arxiv.org/abs/2405.08619v3", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Thinking Tokens for Language Modeling", "abstract": "How much is 56 times 37? Language models often make mistakes in these types\nof difficult calculations. This is usually explained by their inability to\nperform complex reasoning. Since language models rely on large training sets\nand great memorization capability, naturally they are not equipped to run\ncomplex calculations. However, one can argue that humans also cannot perform\nthis calculation immediately and require a considerable amount of time to\nconstruct the solution. In order to enhance the generalization capability of\nlanguage models, and as a parallel to human behavior, we propose to use special\n'thinking tokens' which allow the model to perform much more calculations\nwhenever a complex problem is encountered.", "published": "2024-05-14 14:21:43", "link": "http://arxiv.org/abs/2405.08644v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Targeted Augmentation for Low-Resource Event Extraction", "abstract": "Addressing the challenge of low-resource information extraction remains an\nongoing issue due to the inherent information scarcity within limited training\nexamples. Existing data augmentation methods, considered potential solutions,\nstruggle to strike a balance between weak augmentation (e.g., synonym\naugmentation) and drastic augmentation (e.g., conditional generation without\nproper guidance). This paper introduces a novel paradigm that employs targeted\naugmentation and back validation to produce augmented examples with enhanced\ndiversity, polarity, accuracy, and coherence. Extensive experimental results\ndemonstrate the effectiveness of the proposed paradigm. Furthermore, identified\nlimitations are discussed, shedding light on areas for future improvement.", "published": "2024-05-14 16:15:31", "link": "http://arxiv.org/abs/2405.08729v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Text to Context: An Entailment Approach for News Stakeholder\n  Classification", "abstract": "Navigating the complex landscape of news articles involves understanding the\nvarious actors or entities involved, referred to as news stakeholders. These\nstakeholders, ranging from policymakers to opposition figures, citizens, and\nmore, play pivotal roles in shaping news narratives. Recognizing their\nstakeholder types, reflecting their roles, political alignments, social\nstanding, and more, is paramount for a nuanced comprehension of news content.\nDespite existing works focusing on salient entity extraction, coverage\nvariations, and political affiliations through social media data, the automated\ndetection of stakeholder roles within news content remains an underexplored\ndomain. In this paper, we bridge this gap by introducing an effective approach\nto classify stakeholder types in news articles. Our method involves\ntransforming the stakeholder classification problem into a natural language\ninference task, utilizing contextual information from news articles and\nexternal knowledge to enhance the accuracy of stakeholder type detection.\nMoreover, our proposed model showcases efficacy in zero-shot settings, further\nextending its applicability to diverse news contexts.", "published": "2024-05-14 16:35:21", "link": "http://arxiv.org/abs/2405.08751v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation\n  of Non-Literal Intent Resolution in LLMs", "abstract": "Humans often express their communicative intents indirectly or non-literally,\nwhich requires their interlocutors -- human or AI -- to understand beyond the\nliteral meaning of words. While most existing work has focused on\ndiscriminative evaluations, we present a new approach to generatively evaluate\nlarge language models' (LLMs') intention understanding by examining their\nresponses to non-literal utterances. Ideally, an LLM should respond in line\nwith the true intention of a non-literal utterance, not its literal\ninterpretation. Our findings show that LLMs struggle to generate pragmatically\nrelevant responses to non-literal language, achieving only 50-55% accuracy on\naverage. While explicitly providing oracle intentions significantly improves\nperformance (e.g., 75% for Mistral-Instruct), this still indicates challenges\nin leveraging given intentions to produce appropriate responses. Using\nchain-of-thought to make models spell out intentions yields much smaller gains\n(60% for Mistral-Instruct). These findings suggest that LLMs are not yet\neffective pragmatic interlocutors, highlighting the need for better approaches\nfor modeling intentions and utilizing them for pragmatic generation.", "published": "2024-05-14 16:48:56", "link": "http://arxiv.org/abs/2405.08760v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Refinement of an Epilepsy Dictionary through Human Annotation of\n  Health-related posts on Instagram", "abstract": "We used a dictionary built from biomedical terminology extracted from various\nsources such as DrugBank, MedDRA, MedlinePlus, TCMGeneDIT, to tag more than 8\nmillion Instagram posts by users who have mentioned an epilepsy-relevant drug\nat least once, between 2010 and early 2016. A random sample of 1,771 posts with\n2,947 term matches was evaluated by human annotators to identify\nfalse-positives. OpenAI's GPT series models were compared against human\nannotation. Frequent terms with a high false-positive rate were removed from\nthe dictionary. Analysis of the estimated false-positive rates of the annotated\nterms revealed 8 ambiguous terms (plus synonyms) used in Instagram posts, which\nwere removed from the original dictionary. To study the effect of removing\nthose terms, we constructed knowledge networks using the refined and the\noriginal dictionaries and performed an eigenvector-centrality analysis on both\nnetworks. We show that the refined dictionary thus produced leads to a\nsignificantly different rank of important terms, as measured by their\neigenvector-centrality of the knowledge networks. Furthermore, the most\nimportant terms obtained after refinement are of greater medical relevance. In\naddition, we show that OpenAI's GPT series models fare worse than human\nannotators in this task.", "published": "2024-05-14 17:27:59", "link": "http://arxiv.org/abs/2405.08784v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Amplifying Aspect-Sentence Awareness: A Novel Approach for Aspect-Based\n  Sentiment Analysis", "abstract": "Aspect-Based Sentiment Analysis (ABSA) is increasingly crucial in Natural\nLanguage Processing (NLP) for applications such as customer feedback analysis\nand product recommendation systems. ABSA goes beyond traditional sentiment\nanalysis by extracting sentiments related to specific aspects mentioned in the\ntext; existing attention-based models often need help to effectively connect\naspects with context due to language complexity and multiple sentiment\npolarities in a single sentence. Recent research underscores the value of\nintegrating syntactic information, such as dependency trees, to understand\nlong-range syntactic relationships better and link aspects with context.\nDespite these advantages, challenges persist, including sensitivity to parsing\nerrors and increased computational complexity when combining syntactic and\nsemantic information. To address these issues, we propose Amplifying\nAspect-Sentence Awareness (A3SN), a novel technique designed to enhance ABSA\nthrough amplifying aspect-sentence awareness attention. Following the\ntransformer's standard process, our innovative approach incorporates multi-head\nattention mechanisms to augment the model with sentence and aspect semantic\ninformation. We added another multi-head attention module: amplify\naspect-sentence awareness attention. By doubling its focus between the sentence\nand aspect, we effectively highlighted aspect importance within the sentence\ncontext. This enables accurate capture of subtle relationships and\ndependencies. Additionally, gated fusion integrates feature representations\nfrom multi-head and amplified aspect-sentence awareness attention mechanisms,\nwhich is essential for ABSA. Experimental results across three benchmark\ndatasets demonstrate A3SN's effectiveness and outperform state-of-the-art\n(SOTA) baseline models.", "published": "2024-05-14 10:29:59", "link": "http://arxiv.org/abs/2405.13013v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "QCRD: Quality-guided Contrastive Rationale Distillation for Large\n  Language Models", "abstract": "The deployment of large language models (LLMs) faces considerable challenges\nconcerning resource constraints and inference efficiency. Recent research has\nincreasingly focused on smaller, task-specific models enhanced by distilling\nknowledge from LLMs. However, prior studies have often overlooked the diversity\nand quality of knowledge, especially the untapped potential of negative\nknowledge. Constructing effective negative knowledge remains severely\nunderstudied. In this paper, we introduce a novel framework called\nquality-guided contrastive rationale distillation aimed at enhancing reasoning\ncapabilities through contrastive knowledge learning. For positive knowledge, we\nenrich its diversity through temperature sampling and employ self-consistency\nfor further denoising and refinement. For negative knowledge, we propose an\ninnovative self-adversarial approach that generates low-quality rationales by\nsampling previous iterations of smaller language models, embracing the idea\nthat one can learn from one's own weaknesses. A contrastive loss is developed\nto distill both positive and negative knowledge into smaller language models,\nwhere an online-updating discriminator is integrated to assess qualities of\nrationales and assign them appropriate weights, optimizing the training\nprocess. Through extensive experiments across multiple reasoning tasks, we\ndemonstrate that our method consistently outperforms existing distillation\ntechniques, yielding higher-quality rationales.", "published": "2024-05-14 13:07:10", "link": "http://arxiv.org/abs/2405.13014v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assisted Debate Builder with Large Language Models", "abstract": "We introduce ADBL2, an assisted debate builder tool. It is based on the\ncapability of large language models to generalise and perform relation-based\nargument mining in a wide-variety of domains. It is the first open-source tool\nthat leverages relation-based mining for (1) the verification of\npre-established relations in a debate and (2) the assisted creation of new\narguments by means of large language models. ADBL2 is highly modular and can\nwork with any open-source large language models that are used as plugins. As a\nby-product, we also provide the first fine-tuned Mistral-7B large language\nmodel for relation-based argument mining, usable by ADBL2, which outperforms\nexisting approaches for this task with an overall F1-score of 90.59% across all\ndomains.", "published": "2024-05-14 13:42:12", "link": "http://arxiv.org/abs/2405.13015v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Evolution of Darija Open Dataset: Introducing Version 2", "abstract": "Darija Open Dataset (DODa) represents an open-source project aimed at\nenhancing Natural Language Processing capabilities for the Moroccan dialect,\nDarija. With approximately 100,000 entries, DODa stands as the largest\ncollaborative project of its kind for Darija-English translation. The dataset\nfeatures semantic and syntactic categorizations, variations in spelling, verb\nconjugations across multiple tenses, as well as tens of thousands of translated\nsentences. The dataset includes entries written in both Latin and Arabic\nalphabets, reflecting the linguistic variations and preferences found in\ndifferent sources and applications. The availability of such dataset is\ncritical for developing applications that can accurately understand and\ngenerate Darija, thus supporting the linguistic needs of the Moroccan community\nand potentially extending to similar dialects in neighboring regions. This\npaper explores the strategic importance of DODa, its current achievements, and\nthe envisioned future enhancements that will continue to promote its use and\nexpansion in the global NLP landscape.", "published": "2024-05-14 15:08:32", "link": "http://arxiv.org/abs/2405.13016v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SpeechVerse: A Large-scale Generalizable Audio Language Model", "abstract": "Large language models (LLMs) have shown incredible proficiency in performing\ntasks that require semantic understanding of natural language instructions.\nRecently, many works have further expanded this capability to perceive\nmultimodal audio and text inputs, but their capabilities are often limited to\nspecific fine-tuned tasks such as automatic speech recognition and translation.\nWe therefore develop SpeechVerse, a robust multi-task training and curriculum\nlearning framework that combines pre-trained speech and text foundation models\nvia a small set of learnable parameters, while keeping the pre-trained models\nfrozen during training. The models are instruction finetuned using continuous\nlatent representations extracted from the speech foundation model to achieve\noptimal zero-shot performance on a diverse range of speech processing tasks\nusing natural language instructions. We perform extensive benchmarking that\nincludes comparing our model performance against traditional baselines across\nseveral datasets and tasks. Furthermore, we evaluate the model's capability for\ngeneralized instruction following by testing on out-of-domain datasets, novel\nprompts, and unseen tasks. Our empirical experiments reveal that our multi-task\nSpeechVerse model is even superior to conventional task-specific baselines on 9\nout of the 11 tasks.", "published": "2024-05-14 03:33:31", "link": "http://arxiv.org/abs/2405.08295v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Computational Thought Experiments for a More Rigorous Philosophy and\n  Science of the Mind", "abstract": "We offer philosophical motivations for a method we call Virtual World\nCognitive Science (VW CogSci), in which researchers use virtual embodied agents\nthat are embedded in virtual worlds to explore questions in the field of\nCognitive Science. We focus on questions about mental and linguistic\nrepresentation and the ways that such computational modeling can add rigor to\nphilosophical thought experiments, as well as the terminology used in the\nscientific study of such representations. We find that this method forces\nresearchers to take a god's-eye view when describing dynamical relationships\nbetween entities in minds and entities in an environment in a way that\neliminates the need for problematic talk of belief and concept types, such as\nthe belief that cats are silly, and the concept CAT, while preserving belief\nand concept tokens in individual cognizers' minds. We conclude with some\nfurther key advantages of VW CogSci for the scientific study of mental and\nlinguistic representation and for Cognitive Science more broadly.", "published": "2024-05-14 03:58:19", "link": "http://arxiv.org/abs/2405.08304v2", "categories": ["cs.CL", "cs.AI", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large\n  Language Models", "abstract": "Integrated Speech and Large Language Models (SLMs) that can follow speech\ninstructions and generate relevant text responses have gained popularity\nlately. However, the safety and robustness of these models remains largely\nunclear. In this work, we investigate the potential vulnerabilities of such\ninstruction-following speech-language models to adversarial attacks and\njailbreaking. Specifically, we design algorithms that can generate adversarial\nexamples to jailbreak SLMs in both white-box and black-box attack settings\nwithout human involvement. Additionally, we propose countermeasures to thwart\nsuch jailbreaking attacks. Our models, trained on dialog data with speech\ninstructions, achieve state-of-the-art performance on spoken question-answering\ntask, scoring over 80% on both safety and helpfulness metrics. Despite safety\nguardrails, experiments on jailbreaking demonstrate the vulnerability of SLMs\nto adversarial perturbations and transfer attacks, with average attack success\nrates of 90% and 10% respectively when evaluated on a dataset of carefully\ndesigned harmful questions spanning 12 different toxic categories. However, we\ndemonstrate that our proposed countermeasures reduce the attack success\nsignificantly.", "published": "2024-05-14 04:51:23", "link": "http://arxiv.org/abs/2405.08317v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction\n  with Error Categorization and LLM Ensembles", "abstract": "This paper describes our approach to the MEDIQA-CORR shared task, which\ninvolves error detection and correction in clinical notes curated by medical\nprofessionals. This task involves handling three subtasks: detecting the\npresence of errors, identifying the specific sentence containing the error, and\ncorrecting it. Through our work, we aim to assess the capabilities of Large\nLanguage Models (LLMs) trained on a vast corpora of internet data that contain\nboth factual and unreliable information. We propose to comprehensively address\nall subtasks together, and suggest employing a unique prompt-based in-context\nlearning strategy. We will evaluate its efficacy in this specialized task\ndemanding a combination of general reasoning and medical knowledge. In medical\nsystems where prediction errors can have grave consequences, we propose\nleveraging self-consistency and ensemble methods to enhance error correction\nand error detection performance.", "published": "2024-05-14 07:16:36", "link": "http://arxiv.org/abs/2405.08373v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Falcon 7b for Software Mention Detection in Scholarly Documents", "abstract": "This paper aims to tackle the challenge posed by the increasing integration\nof software tools in research across various disciplines by investigating the\napplication of Falcon-7b for the detection and classification of software\nmentions within scholarly texts. Specifically, the study focuses on solving\nSubtask I of the Software Mention Detection in Scholarly Publications (SOMD),\nwhich entails identifying and categorizing software mentions from academic\nliterature. Through comprehensive experimentation, the paper explores different\ntraining strategies, including a dual-classifier approach, adaptive sampling,\nand weighted loss scaling, to enhance detection accuracy while overcoming the\ncomplexities of class imbalance and the nuanced syntax of scholarly writing.\nThe findings highlight the benefits of selective labelling and adaptive\nsampling in improving the model's performance. However, they also indicate that\nintegrating multiple strategies does not necessarily result in cumulative\nimprovements. This research offers insights into the effective application of\nlarge language models for specific tasks such as SOMD, underlining the\nimportance of tailored approaches to address the unique challenges presented by\nacademic text analysis.", "published": "2024-05-14 11:37:26", "link": "http://arxiv.org/abs/2405.08514v1", "categories": ["cs.LG", "cs.CL", "cs.DL"], "primary_category": "cs.LG"}
{"title": "PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation\n  using Ensemble LLMs", "abstract": "This paper presents our approach to the EHRSQL-2024 shared task, which aims\nto develop a reliable Text-to-SQL system for electronic health records. We\npropose two approaches that leverage large language models (LLMs) for prompting\nand fine-tuning to generate EHRSQL queries. In both techniques, we concentrate\non bridging the gap between the real-world knowledge on which LLMs are trained\nand the domain specific knowledge required for the task. The paper provides the\nresults of each approach individually, demonstrating that they achieve high\nexecution accuracy. Additionally, we show that an ensemble approach further\nenhances generation reliability by reducing errors. This approach secured us\n2nd place in the shared task competition. The methodologies outlined in this\npaper are designed to be transferable to domain-specific Text-to-SQL problems\nthat emphasize both accuracy and reliability.", "published": "2024-05-14 07:16:56", "link": "http://arxiv.org/abs/2405.08839v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Large Language Models for Human-Machine Collaborative Particle\n  Accelerator Tuning through Natural Language", "abstract": "Autonomous tuning of particle accelerators is an active and challenging field\nof research with the goal of enabling novel accelerator technologies\ncutting-edge high-impact applications, such as physics discovery, cancer\nresearch and material sciences. A key challenge with autonomous accelerator\ntuning remains that the most capable algorithms require an expert in\noptimisation, machine learning or a similar field to implement the algorithm\nfor every new tuning task. In this work, we propose the use of large language\nmodels (LLMs) to tune particle accelerators. We demonstrate on a\nproof-of-principle example the ability of LLMs to successfully and autonomously\ntune a particle accelerator subsystem based on nothing more than a natural\nlanguage prompt from the operator, and compare the performance of our LLM-based\nsolution to state-of-the-art optimisation algorithms, such as Bayesian\noptimisation (BO) and reinforcement learning-trained optimisation (RLO). In\ndoing so, we also show how LLMs can perform numerical optimisation of a highly\nnon-linear real-world objective function. Ultimately, this work represents yet\nanother complex task that LLMs are capable of solving and promises to help\naccelerate the deployment of autonomous tuning algorithms to the day-to-day\noperations of particle accelerators.", "published": "2024-05-14 18:05:44", "link": "http://arxiv.org/abs/2405.08888v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.acc-ph"], "primary_category": "cs.CL"}
{"title": "Self-supervised vision-langage alignment of deep learning\n  representations for bone X-rays analysis", "abstract": "This paper proposes leveraging vision-language pretraining on bone X-rays\npaired with French reports to address downstream tasks of interest on bone\nradiography. A practical processing pipeline is introduced to anonymize and\nprocess French medical reports. Pretraining then consists in the\nself-supervised alignment of visual and textual embedding spaces derived from\ndeep model encoders. The resulting image encoder is then used to handle various\ndownstream tasks, including quantification of osteoarthritis, estimation of\nbone age on pediatric wrists, bone fracture and anomaly detection. Our approach\ndemonstrates competitive performance on downstream tasks, compared to\nalternatives requiring a significantly larger amount of human expert\nannotations. Our work stands as the first study to integrate French reports to\nshape the embedding space devoted to bone X-Rays representations, capitalizing\non the large quantity of paired images and reports data available in an\nhospital. By relying on generic vision-laguage deep models in a\nlanguage-specific scenario, it contributes to the deployement of vision models\nfor wider healthcare applications.", "published": "2024-05-14 19:53:20", "link": "http://arxiv.org/abs/2405.08932v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Challenges in Deploying Long-Context Transformers: A Theoretical Peak\n  Performance Analysis", "abstract": "Transformer-based long context generative models power emerging AI\napplications like hour-long video understanding and project-level coding agent.\nDeploying long context transformers (e.g., 100K to 10M tokens) is prohibitively\nexpensive compared to short context (e.g., 4K tokens) model variants. Reducing\nthe cost of long-context transformers is becoming a pressing research and\nengineering challenge starting from the year of 2024. This work describes a\nconcurrent programming framework for quantitatively analyzing the efficiency\nchallenges in serving multiple long-context requests under limited size of GPU\nhigh-bandwidth memory (HBM) regime. We give a detailed analysis of how all\nadditional computational costs, compared to 4K context, trace back to\n\\textit{one single source: the large size of the KV cache}. We use a 34B\nGPT-3.5 level model of 50K context on A100 NVLink as a running example, and\ndescribe how its large KV cache causes four types of deployment challenges: (1)\nprefilling long inputs takes much longer compute time and GPU memory than short\ninputs; (2) after prefilling, the large KV cache residing on the GPU HBM\nsubstantially restricts the number of concurrent users being served; (3) during\ndecoding, repeatedly reading the KV cache from HBM to SM largely increases\nlatency; (4) when KV cache memory overflows, swapping it from HBM to DDR causes\nsignificant context switching latency. We use this framework to analyze\nexisting works and identify possibilities of combining them to build end-to-end\nsystems. Overall, this work offers a foundational framework for analyzing long\ncontext transformer deployment and identifies directions towards reducing the\ninference cost of 1M context to be as cheap as 4K.", "published": "2024-05-14 20:17:22", "link": "http://arxiv.org/abs/2405.08944v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "What is it for a Machine Learning Model to Have a Capability?", "abstract": "What can contemporary machine learning (ML) models do? Given the\nproliferation of ML models in society, answering this question matters to a\nvariety of stakeholders, both public and private. The evaluation of models'\ncapabilities is rapidly emerging as a key subfield of modern ML, buoyed by\nregulatory attention and government grants. Despite this, the notion of an ML\nmodel possessing a capability has not been interrogated: what are we saying\nwhen we say that a model is able to do something? And what sorts of evidence\nbear upon this question? In this paper, we aim to answer these questions, using\nthe capabilities of large language models (LLMs) as a running example. Drawing\non the large philosophical literature on abilities, we develop an account of ML\nmodels' capabilities which can be usefully applied to the nascent science of\nmodel evaluation. Our core proposal is a conditional analysis of model\nabilities (CAMA): crudely, a machine learning model has a capability to X just\nwhen it would reliably succeed at doing X if it 'tried'. The main contribution\nof the paper is making this proposal precise in the context of ML, resulting in\nan operationalisation of CAMA applicable to LLMs. We then put CAMA to work,\nshowing that it can help make sense of various features of ML model evaluation\npractice, as well as suggest procedures for performing fair inter-model\ncomparisons.", "published": "2024-05-14 23:03:52", "link": "http://arxiv.org/abs/2405.08989v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Sonos Voice Control Bias Assessment Dataset: A Methodology for\n  Demographic Bias Assessment in Voice Assistants", "abstract": "Recent works demonstrate that voice assistants do not perform equally well\nfor everyone, but research on demographic robustness of speech technologies is\nstill scarce. This is mainly due to the rarity of large datasets with\ncontrolled demographic tags. This paper introduces the Sonos Voice Control Bias\nAssessment Dataset, an open dataset composed of voice assistant requests for\nNorth American English in the music domain (1,038 speakers, 166 hours, 170k\naudio samples, with 9,040 unique labelled transcripts) with a controlled\ndemographic diversity (gender, age, dialectal region and ethnicity). We also\nrelease a statistical demographic bias assessment methodology, at the\nunivariate and multivariate levels, tailored to this specific use case and\nleveraging spoken language understanding metrics rather than transcription\naccuracy, which we believe is a better proxy for user experience. To\ndemonstrate the capabilities of this dataset and statistical method to detect\ndemographic bias, we consider a pair of state-of-the-art Automatic Speech\nRecognition and Spoken Language Understanding models. Results show\nstatistically significant differences in performance across age, dialectal\nregion and ethnicity. Multivariate tests are crucial to shed light on mixed\neffects between dialectal region, gender and age.", "published": "2024-05-14 12:53:32", "link": "http://arxiv.org/abs/2405.19342v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Prompt-driven Task Planning Method for Multi-drones based on Large\n  Language Model", "abstract": "With the rapid development of drone technology, the application of\nmulti-drones is becoming increasingly widespread in various fields. However,\nthe task planning technology for multi-drones still faces challenges such as\nthe complexity of remote operation and the convenience of human-machine\ninteraction. To address these issues, this paper proposes a prompt-driven task\nplanning method for multi-drones based on large language models. By introducing\nthe Prompt technique, appropriate prompt information is provided for the\nmulti-drone system.", "published": "2024-05-14 12:24:39", "link": "http://arxiv.org/abs/2406.00006v1", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Navigating LLM Ethics: Advancements, Challenges, and Future Directions", "abstract": "This study addresses ethical issues surrounding Large Language Models (LLMs)\nwithin the field of artificial intelligence. It explores the common ethical\nchallenges posed by both LLMs and other AI systems, such as privacy and\nfairness, as well as ethical challenges uniquely arising from LLMs. It\nhighlights challenges such as hallucination, verifiable accountability, and\ndecoding censorship complexity, which are unique to LLMs and distinct from\nthose encountered in traditional AI systems. The study underscores the need to\ntackle these complexities to ensure accountability, reduce biases, and enhance\ntransparency in the influential role that LLMs play in shaping information\ndissemination. It proposes mitigation strategies and future directions for LLM\nethics, advocating for interdisciplinary collaboration. It recommends ethical\nframeworks tailored to specific domains and dynamic auditing systems adapted to\ndiverse contexts. This roadmap aims to guide responsible development and\nintegration of LLMs, envisioning a future where ethical considerations govern\nAI advancements in society.", "published": "2024-05-14 15:03:05", "link": "http://arxiv.org/abs/2406.18841v4", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "When Large Language Models Meet Optical Networks: Paving the Way for\n  Automation", "abstract": "Since the advent of GPT, large language models (LLMs) have brought about\nrevolutionary advancements in all walks of life. As a superior natural language\nprocessing (NLP) technology, LLMs have consistently achieved state-of-the-art\nperformance on numerous areas. However, LLMs are considered to be\ngeneral-purpose models for NLP tasks, which may encounter challenges when\napplied to complex tasks in specialized fields such as optical networks. In\nthis study, we propose a framework of LLM-empowered optical networks,\nfacilitating intelligent control of the physical layer and efficient\ninteraction with the application layer through an LLM-driven agent (AI-Agent)\ndeployed in the control layer. The AI-Agent can leverage external tools and\nextract domain knowledge from a comprehensive resource library specifically\nestablished for optical networks. This is achieved through user input and\nwell-crafted prompts, enabling the generation of control instructions and\nresult representations for autonomous operation and maintenance in optical\nnetworks. To improve LLM's capability in professional fields and stimulate its\npotential on complex tasks, the details of performing prompt engineering,\nestablishing domain knowledge library, and implementing complex tasks are\nillustrated in this study. Moreover, the proposed framework is verified on two\ntypical tasks: network alarm analysis and network performance optimization. The\ngood response accuracies and sematic similarities of 2,400 test situations\nexhibit the great potential of LLM in optical networks.", "published": "2024-05-14 10:46:33", "link": "http://arxiv.org/abs/2405.17441v2", "categories": ["cs.NI", "cs.AI", "cs.CL", "cs.SY", "eess.SY"], "primary_category": "cs.NI"}
{"title": "Neural Speech Coding for Real-time Communications using Constant Bitrate\n  Scalar Quantization", "abstract": "Neural audio coding has emerged as a vivid research direction by promising\ngood audio quality at very low bitrates unachievable by classical coding\ntechniques. Here, end-to-end trainable autoencoder-like models represent the\nstate of the art, where a discrete representation in the bottleneck of the\nautoencoder is learned. This allows for efficient transmission of the input\naudio signal. The learned discrete representation of neural codecs is typically\ngenerated by applying a quantizer to the output of the neural encoder. In\nalmost all state-of-the-art neural audio coding approaches, this quantizer is\nrealized as a Vector Quantizer (VQ) and a lot of effort has been spent to\nalleviate drawbacks of this quantization technique when used together with a\nneural audio coder. In this paper, we propose and analyze simple alternatives\nto VQ, which are based on projected Scalar Quantization (SQ). These\nquantization techniques do not need any additional losses, scheduling\nparameters or codebook storage thereby simplifying the training of neural audio\ncodecs. For real-time speech communication applications, these neural codecs\nare required to operate at low complexity, low latency and at low bitrates. We\naddress those challenges by proposing a new causal network architecture that is\nbased on SQ and a Short-Time Fourier Transform (STFT) representation. The\nproposed method performs particularly well in the very low complexity and low\nbitrate regime.", "published": "2024-05-14 08:23:30", "link": "http://arxiv.org/abs/2405.08417v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Robust Audio Deepfake Detection: A Evolving Benchmark for\n  Continual Learning", "abstract": "The rise of advanced large language models such as GPT-4, GPT-4o, and the\nClaude family has made fake audio detection increasingly challenging.\nTraditional fine-tuning methods struggle to keep pace with the evolving\nlandscape of synthetic speech, necessitating continual learning approaches that\ncan adapt to new audio while retaining the ability to detect older types.\nContinual learning, which acts as an effective tool for detecting newly emerged\ndeepfake audio while maintaining performance on older types, lacks a\nwell-constructed and user-friendly evaluation framework. To address this gap,\nwe introduce EVDA, a benchmark for evaluating continual learning methods in\ndeepfake audio detection. EVDA includes classic datasets from the Anti-Spoofing\nVoice series, Chinese fake audio detection series, and newly generated deepfake\naudio from models like GPT-4 and GPT-4o. It supports various continual learning\ntechniques, such as Elastic Weight Consolidation (EWC), Learning without\nForgetting (LwF), and recent methods like Regularized Adaptive Weight\nModification (RAWM) and Radian Weight Modification (RWM). Additionally, EVDA\nfacilitates the development of robust algorithms by providing an open interface\nfor integrating new continual learning methods", "published": "2024-05-14 13:37:13", "link": "http://arxiv.org/abs/2405.08596v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A tunable binaural audio telepresence system capable of balancing\n  immersive and enhanced modes", "abstract": "Binaural Audio Telepresence (BAT) aims to encode the acoustic scene at the\nfar end into binaural signals for the user at the near end. BAT encompasses an\nimmense range of applications that can vary between two extreme modes of\nImmersive BAT (I-BAT) and Enhanced BAT (E-BAT). With I-BAT, our goal is to\npreserve the full ambience as if we were at the far end, while with E-BAT, our\ngoal is to enhance the far-end conversation with significantly improved speech\nquality and intelligibility. To this end, this paper presents a tunable BAT\nsystem to vary between these two AT modes with a desired application-specific\nbalance. Microphone signals are converted into binaural signals with prescribed\nambience factor. A novel Spatial COherence REpresentation (SCORE) is proposed\nas an input feature for model training so that the network remains robust to\ndifferent array setups. Experimental results demonstrated the superior\nperformance of the proposed BAT, even when the array configurations were not\nincluded in the training phase.", "published": "2024-05-14 16:30:32", "link": "http://arxiv.org/abs/2405.08742v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Cluster-to-Predict Affect Contours from Speech", "abstract": "Continuous emotion recognition (CER) aims to track the dynamic changes in a\nperson's emotional state over time. This paper proposes a novel approach to\ntranslating CER into a prediction problem of dynamic affect-contour clusters\nfrom speech, where the affect-contour is defined as the contour of annotated\naffect attributes in a temporal window. Our approach defines a\ncluster-to-predict (C2P) framework that learns affect-contour clusters, which\nare predicted from speech with higher precision. To achieve this, C2P runs an\nunsupervised iterative optimization process to learn affect-contour clusters by\nminimizing both clustering loss and speech-driven affect-contour prediction\nloss. Our objective findings demonstrate the value of speech-driven clustering\nfor both arousal and valence attributes. Experiments conducted on the RECOLA\ndataset yielded promising classification results, with F1 scores of 0.84 for\narousal and 0.75 for valence in our four-class speech-driven affect-contour\nprediction model.", "published": "2024-05-14 12:34:30", "link": "http://arxiv.org/abs/2406.02569v1", "categories": ["eess.AS", "cs.HC"], "primary_category": "eess.AS"}
{"title": "Abnormal Respiratory Sound Identification Using Audio-Spectrogram Vision\n  Transformer", "abstract": "Respiratory disease, the third leading cause of deaths globally, is\nconsidered a high-priority ailment requiring significant research on\nidentification and treatment. Stethoscope-recorded lung sounds and artificial\nintelligence-powered devices have been used to identify lung disorders and aid\nspecialists in making accurate diagnoses. In this study, audio-spectrogram\nvision transformer (AS-ViT), a new approach for identifying abnormal\nrespiration sounds, was developed. The sounds of the lungs are converted into\nvisual representations called spectrograms using a technique called short-time\nFourier transform (STFT). These images are then analyzed using a model called\nvision transformer to identify different types of respiratory sounds. The\nclassification was carried out using the ICBHI 2017 database, which includes\nvarious types of lung sounds with different frequencies, noise levels, and\nbackgrounds. The proposed AS-ViT method was evaluated using three metrics and\nachieved 79.1% and 59.8% for 60:40 split ratio and 86.4% and 69.3% for 80:20\nsplit ratio in terms of unweighted average recall and overall scores\nrespectively for respiratory sound detection, surpassing previous\nstate-of-the-art results.", "published": "2024-05-14 06:31:38", "link": "http://arxiv.org/abs/2405.08342v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Investigating Design Choices in Joint-Embedding Predictive Architectures\n  for General Audio Representation Learning", "abstract": "This paper addresses the problem of self-supervised general-purpose audio\nrepresentation learning. We explore the use of Joint-Embedding Predictive\nArchitectures (JEPA) for this task, which consists of splitting an input\nmel-spectrogram into two parts (context and target), computing neural\nrepresentations for each, and training the neural network to predict the target\nrepresentations from the context representations. We investigate several design\nchoices within this framework and study their influence through extensive\nexperiments by evaluating our models on various audio classification\nbenchmarks, including environmental sounds, speech and music downstream tasks.\nWe focus notably on which part of the input data is used as context or target\nand show experimentally that it significantly impacts the model's quality. In\nparticular, we notice that some effective design choices in the image domain\nlead to poor performance on audio, thus highlighting major differences between\nthese two modalities.", "published": "2024-05-14 15:00:09", "link": "http://arxiv.org/abs/2405.08679v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PolyGlotFake: A Novel Multilingual and Multimodal DeepFake Dataset", "abstract": "With the rapid advancement of generative AI, multimodal deepfakes, which\nmanipulate both audio and visual modalities, have drawn increasing public\nconcern. Currently, deepfake detection has emerged as a crucial strategy in\ncountering these growing threats. However, as a key factor in training and\nvalidating deepfake detectors, most existing deepfake datasets primarily focus\non the visual modal, and the few that are multimodal employ outdated\ntechniques, and their audio content is limited to a single language, thereby\nfailing to represent the cutting-edge advancements and globalization trends in\ncurrent deepfake technologies. To address this gap, we propose a novel,\nmultilingual, and multimodal deepfake dataset: PolyGlotFake. It includes\ncontent in seven languages, created using a variety of cutting-edge and popular\nText-to-Speech, voice cloning, and lip-sync technologies. We conduct\ncomprehensive experiments using state-of-the-art detection methods on\nPolyGlotFake dataset. These experiments demonstrate the dataset's significant\nchallenges and its practical value in advancing research into multimodal\ndeepfake detection.", "published": "2024-05-14 06:40:05", "link": "http://arxiv.org/abs/2405.08838v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "68T45", "I.4.9"], "primary_category": "cs.SD"}
