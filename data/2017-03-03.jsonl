{"title": "Exponential Moving Average Model in Parallel Speech Recognition Training", "abstract": "As training data rapid growth, large-scale parallel training with multi-GPUs\ncluster is widely applied in the neural network model learning currently.We\npresent a new approach that applies exponential moving average method in\nlarge-scale parallel training of neural network model. It is a non-interference\nstrategy that the exponential moving average model is not broadcasted to\ndistributed workers to update their local models after model synchronization in\nthe training process, and it is implemented as the final model of the training\nsystem. Fully-connected feed-forward neural networks (DNNs) and deep\nunidirectional Long short-term memory (LSTM) recurrent neural networks (RNNs)\nare successfully trained with proposed method for large vocabulary continuous\nspeech recognition on Shenma voice search data in Mandarin. The character error\nrate (CER) of Mandarin speech recognition further degrades than\nstate-of-the-art approaches of parallel training.", "published": "2017-03-03 03:14:28", "link": "http://arxiv.org/abs/1703.01024v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Task-Completion Neural Dialogue Systems", "abstract": "One of the major drawbacks of modularized task-completion dialogue systems is\nthat each module is trained individually, which presents several challenges.\nFor example, downstream modules are affected by earlier modules, and the\nperformance of the entire system is not robust to the accumulated errors. This\npaper presents a novel end-to-end learning framework for task-completion\ndialogue systems to tackle such issues. Our neural dialogue system can directly\ninteract with a structured database to assist users in accessing information\nand accomplishing certain tasks. The reinforcement learning based dialogue\nmanager offers robust capabilities to handle noises caused by other components\nof the dialogue system. Our experiments in a movie-ticket booking domain show\nthat our end-to-end system not only outperforms modularized dialogue system\nbaselines for both objective and subjective evaluation, but also is robust to\nnoises as demonstrated by several systematic experiments with different error\ngranularity and rates specific to the language understanding module.", "published": "2017-03-03 01:29:11", "link": "http://arxiv.org/abs/1703.01008v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
