{"title": "Emergent AI-Assisted Discourse: Case Study of a Second Language Writer\n  Authoring with ChatGPT", "abstract": "The rapid proliferation of ChatGPT has incited debates regarding its impact\non human writing. Amid concerns about declining writing standards, this study\ninvestigates the role of ChatGPT in facilitating academic writing, especially\namong language learners. Using a case study approach, this study examines the\nexperiences of Kailing, a doctoral student, who integrates ChatGPT throughout\ntheir academic writing process. The study employs activity theory as a lens for\nunderstanding writing with generative AI tools and data analyzed includes\nsemi-structured interviews, writing samples, and GPT logs. Results indicate\nthat Kailing effectively collaborates with ChatGPT across various writing\nstages while preserving her distinct authorial voice and agency. This\nunderscores the potential of AI tools such as ChatGPT to enhance academic\nwriting for language learners without overshadowing individual authenticity.\nThis case study offers a critical exploration of how ChatGPT is utilized in the\nacademic writing process and the preservation of a student's authentic voice\nwhen engaging with the tool.", "published": "2023-10-17 00:22:10", "link": "http://arxiv.org/abs/2310.10903v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TEQ: Trainable Equivalent Transformation for Quantization of LLMs", "abstract": "As large language models (LLMs) become more prevalent, there is a growing\nneed for new and improved quantization methods that can meet the\ncomputationalast layer demands of these modern architectures while maintaining\nthe accuracy. In this paper, we present TEQ, a trainable equivalent\ntransformation that preserves the FP32 precision of the model output while\ntaking advantage of low-precision quantization, especially 3 and 4 bits\nweight-only quantization. The training process is lightweight, requiring only\n1K steps and fewer than 0.1 percent of the original model's trainable\nparameters. Furthermore, the transformation does not add any computational\noverhead during inference. Our results are on-par with the state-of-the-art\n(SOTA) methods on typical LLMs. Our approach can be combined with other methods\nto achieve even better performance. The code is available at\nhttps://github.com/intel/neural-compressor.", "published": "2023-10-17 02:42:34", "link": "http://arxiv.org/abs/2310.10944v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models can Contrastively Refine their Generation for\n  Better Sentence Representation Learning", "abstract": "Recently, large language models (LLMs) have emerged as a groundbreaking\ntechnology and their unparalleled text generation capabilities have sparked\ninterest in their application to the fundamental sentence representation\nlearning task. Existing methods have explored utilizing LLMs as data annotators\nto generate synthesized data for training contrastive learning based sentence\nembedding models such as SimCSE. However, since contrastive learning models are\nsensitive to the quality of sentence pairs, the effectiveness of these methods\nis largely influenced by the content generated from LLMs, highlighting the need\nfor more refined generation in the context of sentence representation learning.\nBuilding upon this premise, we propose MultiCSR, a multi-level contrastive\nsentence representation learning framework that decomposes the process of\nprompting LLMs to generate a corpus for training base sentence embedding models\ninto three stages (i.e., sentence generation, sentence pair construction,\nin-batch training) and refines the generated content at these three distinct\nstages, ensuring only high-quality sentence pairs are utilized to train a base\ncontrastive learning model. Our extensive experiments reveal that MultiCSR\nenables a less advanced LLM to surpass the performance of ChatGPT, while\napplying it to ChatGPT achieves better state-of-the-art results. Comprehensive\nanalyses further underscore the potential of our framework in various\napplication scenarios and achieving better sentence representation learning\nwith LLMs.", "published": "2023-10-17 03:21:43", "link": "http://arxiv.org/abs/2310.10962v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instructive Dialogue Summarization with Query Aggregations", "abstract": "Conventional dialogue summarization methods directly generate summaries and\ndo not consider user's specific interests. This poses challenges in cases where\nthe users are more focused on particular topics or aspects. With the\nadvancement of instruction-finetuned language models, we introduce\ninstruction-tuning to dialogues to expand the capability set of dialogue\nsummarization models. To overcome the scarcity of instructive dialogue\nsummarization data, we propose a three-step approach to synthesize high-quality\nquery-based summarization triples. This process involves summary-anchored query\ngeneration, query filtering, and query-based summary generation. By training a\nunified model called InstructDS (Instructive Dialogue Summarization) on three\nsummarization datasets with multi-purpose instructive triples, we expand the\ncapability of dialogue summarization models. We evaluate our method on four\ndatasets, including dialogue summarization and dialogue reading comprehension.\nExperimental results show that our approach outperforms the state-of-the-art\nmodels and even models with larger sizes. Additionally, our model exhibits\nhigher generalizability and faithfulness, as confirmed by human subjective\nevaluations.", "published": "2023-10-17 04:03:00", "link": "http://arxiv.org/abs/2310.10981v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reading Order Matters: Information Extraction from Visually-rich\n  Documents by Token Path Prediction", "abstract": "Recent advances in multimodal pre-trained models have significantly improved\ninformation extraction from visually-rich documents (VrDs), in which named\nentity recognition (NER) is treated as a sequence-labeling task of predicting\nthe BIO entity tags for tokens, following the typical setting of NLP. However,\nBIO-tagging scheme relies on the correct order of model inputs, which is not\nguaranteed in real-world NER on scanned VrDs where text are recognized and\narranged by OCR systems. Such reading order issue hinders the accurate marking\nof entities by BIO-tagging scheme, making it impossible for sequence-labeling\nmethods to predict correct named entities. To address the reading order issue,\nwe introduce Token Path Prediction (TPP), a simple prediction head to predict\nentity mentions as token sequences within documents. Alternative to token\nclassification, TPP models the document layout as a complete directed graph of\ntokens, and predicts token paths within the graph as entities. For better\nevaluation of VrD-NER systems, we also propose two revised benchmark datasets\nof NER on scanned documents which can reflect real-world scenarios. Experiment\nresults demonstrate the effectiveness of our method, and suggest its potential\nto be a universal solution to various information extraction tasks on\ndocuments.", "published": "2023-10-17 06:08:55", "link": "http://arxiv.org/abs/2310.11016v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Automatic Evaluation Methods based on a Decoder-based LLM for\n  Text Generation", "abstract": "Automatic evaluation of text generation is essential for improving the\naccuracy of generation tasks. In light of the current trend towards\nincreasingly larger decoder-based language models, we investigate automatic\nevaluation methods based on such models for text generation. This paper\ncompares various methods, including tuning with encoder-based models and large\nlanguage models under equal conditions, on two different tasks, machine\ntranslation evaluation and semantic textual similarity, in two languages,\nJapanese and English. Experimental results show that compared to the tuned\nencoder-based models, the tuned decoder-based models perform poorly. The\nanalysis of the causes for this suggests that the decoder-based models focus on\nsurface word sequences and do not capture meaning. It is also revealed that\nin-context learning of very large decoder-based models such as ChatGPT makes it\ndifficult to identify fine-grained semantic differences.", "published": "2023-10-17 06:53:00", "link": "http://arxiv.org/abs/2310.11026v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Experimenting AI Technologies for Disinformation Combat: the IDMO\n  Project", "abstract": "The Italian Digital Media Observatory (IDMO) project, part of a European\ninitiative, focuses on countering disinformation and fake news. This report\noutlines contributions from Rai-CRITS to the project, including: (i) the\ncreation of novel datasets for testing technologies (ii) development of an\nautomatic model for categorizing Pagella Politica verdicts to facilitate\nbroader analysis (iii) creation of an automatic model for recognizing textual\nentailment with exceptional accuracy on the FEVER dataset (iv) assessment using\nGPT-4 to detecting content treatment style (v) a game to raise awareness about\nfake news at national events.", "published": "2023-10-17 09:27:43", "link": "http://arxiv.org/abs/2310.11097v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Quo Vadis of the Relationship between Language and Large Language\n  Models", "abstract": "In the field of Artificial (General) Intelligence (AI), the several recent\nadvancements in Natural language processing (NLP) activities relying on Large\nLanguage Models (LLMs) have come to encourage the adoption of LLMs as\nscientific models of language. While the terminology employed for the\ncharacterization of LLMs favors their embracing as such, it is not clear that\nthey are in a place to offer insights into the target system they seek to\nrepresent. After identifying the most important theoretical and empirical risks\nbrought about by the adoption of scientific models that lack transparency, we\ndiscuss LLMs relating them to every scientific model's fundamental components:\nthe object, the medium, the meaning and the user. We conclude that, at their\ncurrent stage of development, LLMs hardly offer any explanations for language,\nand then we provide an outlook for more informative future research directions\non this topic.", "published": "2023-10-17 10:54:24", "link": "http://arxiv.org/abs/2310.11146v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing\n  Interactive Machine Translation Systems", "abstract": "We present IMTLab, an open-source end-to-end interactive machine translation\n(IMT) system platform that enables researchers to quickly build IMT systems\nwith state-of-the-art models, perform an end-to-end evaluation, and diagnose\nthe weakness of systems. IMTLab treats the whole interactive translation\nprocess as a task-oriented dialogue with a human-in-the-loop setting, in which\nhuman interventions can be explicitly incorporated to produce high-quality,\nerror-free translations. To this end, a general communication interface is\ndesigned to support the flexible IMT architectures and user policies. Based on\nthe proposed design, we construct a simulated and real interactive environment\nto achieve end-to-end evaluation and leverage the framework to systematically\nevaluate previous IMT systems. Our simulated and manual experiments show that\nthe prefix-constrained decoding approach still gains the lowest editing cost in\nthe end-to-end evaluation, while BiTIIMT achieves comparable editing cost with\na better interactive experience.", "published": "2023-10-17 11:29:04", "link": "http://arxiv.org/abs/2310.11163v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text\n  Processing", "abstract": "English and Chinese, known as resource-rich languages, have witnessed the\nstrong development of transformer-based language models for natural language\nprocessing tasks. Although Vietnam has approximately 100M people speaking\nVietnamese, several pre-trained models, e.g., PhoBERT, ViBERT, and vELECTRA,\nperformed well on general Vietnamese NLP tasks, including POS tagging and named\nentity recognition. These pre-trained language models are still limited to\nVietnamese social media tasks. In this paper, we present the first monolingual\npre-trained language model for Vietnamese social media texts, ViSoBERT, which\nis pre-trained on a large-scale corpus of high-quality and diverse Vietnamese\nsocial media texts using XLM-R architecture. Moreover, we explored our\npre-trained model on five important natural language downstream tasks on\nVietnamese social media texts: emotion recognition, hate speech detection,\nsentiment analysis, spam reviews detection, and hate speech spans detection.\nOur experiments demonstrate that ViSoBERT, with far fewer parameters, surpasses\nthe previous state-of-the-art models on multiple Vietnamese social media tasks.\nOur ViSoBERT model is available only for research purposes.", "published": "2023-10-17 11:34:50", "link": "http://arxiv.org/abs/2310.11166v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using\n  Large Language Models", "abstract": "While large language models (LLMs) have made considerable advancements in\nunderstanding and generating unstructured text, their application in structured\ndata remains underexplored. Particularly, using LLMs for complex reasoning\ntasks on knowledge graphs (KGs) remains largely untouched. To address this, we\npropose KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing\nKGs. KG-GPT comprises three steps: Sentence Segmentation, Graph Retrieval, and\nInference, each aimed at partitioning sentences, retrieving relevant graph\ncomponents, and deriving logical conclusions, respectively. We evaluate KG-GPT\nusing KG-based fact verification and KGQA benchmarks, with the model showing\ncompetitive and robust performance, even outperforming several fully-supervised\nmodels. Our work, therefore, marks a significant step in unifying structured\nand unstructured data processing within the realm of LLMs.", "published": "2023-10-17 12:51:35", "link": "http://arxiv.org/abs/2310.11220v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Watermarking LLMs with Weight Quantization", "abstract": "Abuse of large language models reveals high risks as large language models\nare being deployed at an astonishing speed. It is important to protect the\nmodel weights to avoid malicious usage that violates licenses of open-source\nlarge language models. This paper proposes a novel watermarking strategy that\nplants watermarks in the quantization process of large language models without\npre-defined triggers during inference. The watermark works when the model is\nused in the fp32 mode and remains hidden when the model is quantized to int8,\nin this way, the users can only inference the model without further supervised\nfine-tuning of the model. We successfully plant the watermark into open-source\nlarge language model weights including GPT-Neo and LLaMA. We hope our proposed\nmethod can provide a potential direction for protecting model weights in the\nera of large language model applications.", "published": "2023-10-17 13:06:59", "link": "http://arxiv.org/abs/2310.11237v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Utilizing Weak Supervision To Generate Indonesian Conservation Dataset", "abstract": "Weak supervision has emerged as a promising approach for rapid and\nlarge-scale dataset creation in response to the increasing demand for\naccelerated NLP development. By leveraging labeling functions, weak supervision\nallows practitioners to generate datasets quickly by creating learned label\nmodels that produce soft-labeled datasets. This paper aims to show how such an\napproach can be utilized to build an Indonesian NLP dataset from conservation\nnews text. We construct two types of datasets: multi-class classification and\nsentiment classification. We then provide baseline experiments using various\npretrained language models. These baseline results demonstrate test\nperformances of 59.79% accuracy and 55.72% F1-score for sentiment\nclassification, 66.87% F1-score-macro, 71.5% F1-score-micro, and 83.67% ROC-AUC\nfor multi-class classification. Additionally, we release the datasets and\nlabeling functions used in this work for further research and exploration.", "published": "2023-10-17 13:23:18", "link": "http://arxiv.org/abs/2310.11258v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "xMEN: A Modular Toolkit for Cross-Lingual Medical Entity Normalization", "abstract": "Objective: To improve performance of medical entity normalization across many\nlanguages, especially when fewer language resources are available compared to\nEnglish.\n  Materials and Methods: We introduce xMEN, a modular system for cross-lingual\nmedical entity normalization, which performs well in both low- and\nhigh-resource scenarios. When synonyms in the target language are scarce for a\ngiven terminology, we leverage English aliases via cross-lingual candidate\ngeneration. For candidate ranking, we incorporate a trainable cross-encoder\nmodel if annotations for the target task are available. We also evaluate\ncross-encoders trained in a weakly supervised manner based on\nmachine-translated datasets from a high resource domain. Our system is publicly\navailable as an extensible Python toolkit.\n  Results: xMEN improves the state-of-the-art performance across a wide range\nof multilingual benchmark datasets. Weakly supervised cross-encoders are\neffective when no training data is available for the target task. Through the\ncompatibility of xMEN with the BigBIO framework, it can be easily used with\nexisting and prospective datasets.\n  Discussion: Our experiments show the importance of balancing the output of\ngeneral-purpose candidate generators with subsequent trainable re-rankers,\nwhich we achieve through a rank regularization term in the loss function of the\ncross-encoder. However, error analysis reveals that multi-word expressions and\nother complex entities are still challenging.\n  Conclusion: xMEN exhibits strong performance for medical entity normalization\nin multiple languages, even when no labeled data and few terminology aliases\nfor the target language are available. Its configuration system and evaluation\nmodules enable reproducible benchmarks. Models and code are available online at\nthe following URL: https://github.com/hpi-dhc/xmen", "published": "2023-10-17 13:53:57", "link": "http://arxiv.org/abs/2310.11275v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChapGTP, ILLC's Attempt at Raising a BabyLM: Improving Data Efficiency\n  by Automatic Task Formation", "abstract": "We present the submission of the ILLC at the University of Amsterdam to the\nBabyLM challenge (Warstadt et al., 2023), in the strict-small track. Our final\nmodel, ChapGTP, is a masked language model that was trained for 200 epochs,\naided by a novel data augmentation technique called Automatic Task Formation.\nWe discuss in detail the performance of this model on the three evaluation\nsuites: BLiMP, (Super)GLUE, and MSGS. Furthermore, we present a wide range of\nmethods that were ultimately not included in the model, but may serve as\ninspiration for training LMs in low-resource settings.", "published": "2023-10-17 14:06:06", "link": "http://arxiv.org/abs/2310.11282v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for\n  Zero-Shot Commonsense Question Answering", "abstract": "Zero-shot commonsense Question-Answering (QA) requires models to reason about\ngeneral situations beyond specific benchmarks. State-of-the-art approaches\nfine-tune language models on QA pairs constructed from CommonSense Knowledge\nBases (CSKBs) to equip the models with more commonsense knowledge in a QA\ncontext. However, current QA synthesis protocols may introduce noise from the\nCSKBs and generate ungrammatical questions and false negative options, which\nimpede the model's ability to generalize. To address these issues, we propose\nQADYNAMICS, a training dynamics-driven framework for QA diagnostics and\nrefinement. Our approach analyzes the training dynamics of each QA pair at both\nthe question level and option level, discarding machine-detectable artifacts by\nremoving uninformative QA pairs and mislabeled or false-negative options.\nExtensive experiments demonstrate the effectiveness of our approach, which\noutperforms all baselines while using only 33% of the synthetic data, even\nincluding LLMs such as ChatGPT. Moreover, expert evaluations confirm that our\nframework significantly improves the quality of QA synthesis. Our codes and\nmodel checkpoints are available at\nhttps://github.com/HKUST-KnowComp/QaDynamics.", "published": "2023-10-17 14:27:34", "link": "http://arxiv.org/abs/2310.11303v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Neural Machine Translation with Semantic Units", "abstract": "Conventional neural machine translation (NMT) models typically use subwords\nand words as the basic units for model input and comprehension. However,\ncomplete words and phrases composed of several tokens are often the fundamental\nunits for expressing semantics, referred to as semantic units. To address this\nissue, we propose a method Semantic Units for Machine Translation (SU4MT) which\nmodels the integral meanings of semantic units within a sentence, and then\nleverages them to provide a new perspective for understanding the sentence.\nSpecifically, we first propose Word Pair Encoding (WPE), a phrase extraction\nmethod to help identify the boundaries of semantic units. Next, we design an\nAttentive Semantic Fusion (ASF) layer to integrate the semantics of multiple\nsubwords into a single vector: the semantic unit representation. Lastly, the\nsemantic-unit-level sentence representation is concatenated to the token-level\none, and they are combined as the input of encoder. Experimental results\ndemonstrate that our method effectively models and leverages\nsemantic-unit-level information and outperforms the strong baselines. The code\nis available at https://github.com/ictnlp/SU4MT.", "published": "2023-10-17 15:55:31", "link": "http://arxiv.org/abs/2310.11360v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Disentangling the Linguistic Competence of Privacy-Preserving BERT", "abstract": "Differential Privacy (DP) has been tailored to address the unique challenges\nof text-to-text privatization. However, text-to-text privatization is known for\ndegrading the performance of language models when trained on perturbed text.\nEmploying a series of interpretation techniques on the internal representations\nextracted from BERT trained on perturbed pre-text, we intend to disentangle at\nthe linguistic level the distortion induced by differential privacy.\nExperimental results from a representational similarity analysis indicate that\nthe overall similarity of internal representations is substantially reduced.\nUsing probing tasks to unpack this dissimilarity, we find evidence that\ntext-to-text privatization affects the linguistic competence across several\nformalisms, encoding localized properties of words while falling short at\nencoding the contextual relationships between spans of words.", "published": "2023-10-17 16:00:26", "link": "http://arxiv.org/abs/2310.11363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VECHR: A Dataset for Explainable and Robust Classification of\n  Vulnerability Type in the European Court of Human Rights", "abstract": "Recognizing vulnerability is crucial for understanding and implementing\ntargeted support to empower individuals in need. This is especially important\nat the European Court of Human Rights (ECtHR), where the court adapts\nConvention standards to meet actual individual needs and thus ensures effective\nhuman rights protection. However, the concept of vulnerability remains elusive\nat the ECtHR and no prior NLP research has dealt with it. To enable future\nresearch in this area, we present VECHR, a novel expert-annotated multi-label\ndataset comprising of vulnerability type classification and explanation\nrationale. We benchmark the performance of state-of-the-art models on VECHR\nfrom both prediction and explainability perspectives. Our results demonstrate\nthe challenging nature of the task with lower prediction performance and\nlimited agreement between models and experts. Further, we analyze the\nrobustness of these models in dealing with out-of-domain (OOD) data and observe\noverall limited performance. Our dataset poses unique challenges offering\nsignificant room for improvement regarding performance, explainability, and\nrobustness.", "published": "2023-10-17 16:05:52", "link": "http://arxiv.org/abs/2310.11368v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models\n  for Emotion Recognition in Conversations", "abstract": "Large language models (LLMs) and their variants have shown extraordinary\nefficacy across numerous downstream natural language processing (NLP) tasks,\nwhich has presented a new vision for the development of NLP. Despite their\nremarkable performance in natural language generating (NLG), LLMs lack a\ndistinct focus on the emotion understanding domain. As a result, using LLMs for\nemotion recognition may lead to suboptimal and inadequate precision. Another\nlimitation of LLMs is that they are typical trained without leveraging\nmulti-modal information. To overcome these limitations, we propose DialogueLLM,\na context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA\nmodels with 13,638 multi-modal (i.e., texts and videos) emotional dialogues.\nThe visual information is considered as the supplementary knowledge to\nconstruct high-quality instructions. We offer a comprehensive evaluation of our\nproposed model on three benchmarking emotion recognition in conversations (ERC)\ndatasets and compare the results against the SOTA baselines and other SOTA\nLLMs. Additionally, DialogueLLM-7B can be easily trained using LoRA on a 40GB\nA100 GPU in 5 hours, facilitating reproducibility for other researchers.", "published": "2023-10-17 16:15:34", "link": "http://arxiv.org/abs/2310.11374v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Translation Hypothesis Ensembling with Large\n  Language Models", "abstract": "Large language models (LLMs) are becoming a one-fits-many solution, but they\nsometimes hallucinate or produce unreliable output. In this paper, we\ninvestigate how hypothesis ensembling can improve the quality of the generated\ntext for the specific problem of LLM-based machine translation. We experiment\nwith several techniques for ensembling hypotheses produced by LLMs such as\nChatGPT, LLaMA, and Alpaca. We provide a comprehensive study along multiple\ndimensions, including the method to generate hypotheses (multiple prompts,\ntemperature-based sampling, and beam search) and the strategy to produce the\nfinal translation (instruction-based, quality-based reranking, and minimum\nBayes risk (MBR) decoding). Our results show that MBR decoding is a very\neffective method, that translation quality can be improved using a small number\nof samples, and that instruction tuning has a strong impact on the relation\nbetween the diversity of the hypotheses and the sampling temperature.", "published": "2023-10-17 17:40:21", "link": "http://arxiv.org/abs/2310.11430v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BitNet: Scaling 1-bit Transformers for Large Language Models", "abstract": "The increasing size of large language models has posed challenges for\ndeployment and raised concerns about environmental impact due to high energy\nconsumption. In this work, we introduce BitNet, a scalable and stable 1-bit\nTransformer architecture designed for large language models. Specifically, we\nintroduce BitLinear as a drop-in replacement of the nn.Linear layer in order to\ntrain 1-bit weights from scratch. Experimental results on language modeling\nshow that BitNet achieves competitive performance while substantially reducing\nmemory footprint and energy consumption, compared to state-of-the-art 8-bit\nquantization methods and FP16 Transformer baselines. Furthermore, BitNet\nexhibits a scaling law akin to full-precision Transformers, suggesting its\npotential for effective scaling to even larger language models while\nmaintaining efficiency and performance benefits.", "published": "2023-10-17 17:59:15", "link": "http://arxiv.org/abs/2310.11453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VeRA: Vector-based Random Matrix Adaptation", "abstract": "Low-rank adapation (LoRA) is a popular method that reduces the number of\ntrainable parameters when finetuning large language models, but still faces\nacute storage challenges when scaling to even larger models or deploying\nnumerous per-user or per-task adapted models. In this work, we present\nVector-based Random Matrix Adaptation (VeRA), which significantly reduces the\nnumber of trainable parameters compared to LoRA, yet maintains the same\nperformance. It achieves this by using a single pair of low-rank matrices\nshared across all layers and learning small scaling vectors instead. We\ndemonstrate its effectiveness on the GLUE and E2E benchmarks, image\nclassification tasks, and show its application in instruction-tuning of 7B and\n13B language models.", "published": "2023-10-17 17:59:46", "link": "http://arxiv.org/abs/2310.11454v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalized Soups: Personalized Large Language Model Alignment via\n  Post-hoc Parameter Merging", "abstract": "While Reinforcement Learning from Human Feedback (RLHF) aligns Large Language\nModels (LLMs) with general, aggregate human preferences, it is suboptimal for\nlearning diverse, individual perspectives. In this work, we study Reinforcement\nLearning from Personalized Human Feedback (RLPHF) problem, wherein LLMs are\naligned to multiple (sometimes conflicting) preferences by modeling alignment\nas a Multi-Objective Reinforcement Learning (MORL) problem. Compared to strong\nsingle-objective baselines, we show that we can achieve personalized alignment\nby decomposing preferences into multiple dimensions. These dimensions are\ndefined based on personalizations that are declared as desirable by the user.\nIn this work, we show that they can be efficiently trained independently in a\ndistributed manner and combined effectively post-hoc through parameter merging.\nThe code is available at https://github.com/joeljang/RLPHF.", "published": "2023-10-17 20:22:13", "link": "http://arxiv.org/abs/2310.11564v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BasahaCorpus: An Expanded Linguistic Resource for Readability Assessment\n  in Central Philippine Languages", "abstract": "Current research on automatic readability assessment (ARA) has focused on\nimproving the performance of models in high-resource languages such as English.\nIn this work, we introduce and release BasahaCorpus as part of an initiative\naimed at expanding available corpora and baseline models for readability\nassessment in lower resource languages in the Philippines. We compiled a corpus\nof short fictional narratives written in Hiligaynon, Minasbate, Karay-a, and\nRinconada -- languages belonging to the Central Philippine family tree subgroup\n-- to train ARA models using surface-level, syllable-pattern, and n-gram\noverlap features. We also propose a new hierarchical cross-lingual modeling\napproach that takes advantage of a language's placement in the family tree to\nincrease the amount of available training data. Our study yields encouraging\nresults that support previous work showcasing the efficacy of cross-lingual\nmodels in low-resource settings, as well as similarities in highly informative\nlinguistic features for mutually intelligible languages.", "published": "2023-10-17 21:05:20", "link": "http://arxiv.org/abs/2310.11584v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NuclearQA: A Human-Made Benchmark for Language Models for the Nuclear\n  Domain", "abstract": "As LLMs have become increasingly popular, they have been used in almost every\nfield. But as the application for LLMs expands from generic fields to narrow,\nfocused science domains, there exists an ever-increasing gap in ways to\nevaluate their efficacy in those fields. For the benchmarks that do exist, a\nlot of them focus on questions that don't require proper understanding of the\nsubject in question. In this paper, we present NuclearQA, a human-made\nbenchmark of 100 questions to evaluate language models in the nuclear domain,\nconsisting of a varying collection of questions that have been specifically\ndesigned by experts to test the abilities of language models. We detail our\napproach and show how the mix of several types of questions makes our benchmark\nuniquely capable of evaluating models in the nuclear domain. We also present\nour own evaluation metric for assessing LLM's performances due to the\nlimitations of existing ones. Our experiments on state-of-the-art models\nsuggest that even the best LLMs perform less than satisfactorily on our\nbenchmark, demonstrating the scientific knowledge gap of existing LLMs.", "published": "2023-10-17 01:27:20", "link": "http://arxiv.org/abs/2310.10920v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Enhanced Transformer Architecture for Natural Language Processing", "abstract": "Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.", "published": "2023-10-17 01:59:07", "link": "http://arxiv.org/abs/2310.10930v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Intent Detection and Slot Filling for Home Assistants: Dataset and\n  Analysis for Bangla and Sylheti", "abstract": "As voice assistants cement their place in our technologically advanced\nsociety, there remains a need to cater to the diverse linguistic landscape,\nincluding colloquial forms of low-resource languages. Our study introduces the\nfirst-ever comprehensive dataset for intent detection and slot filling in\nformal Bangla, colloquial Bangla, and Sylheti languages, totaling 984 samples\nacross 10 unique intents. Our analysis reveals the robustness of large language\nmodels for tackling downstream tasks with inadequate data. The GPT-3.5 model\nachieves an impressive F1 score of 0.94 in intent detection and 0.51 in slot\nfilling for colloquial Bangla.", "published": "2023-10-17 02:12:12", "link": "http://arxiv.org/abs/2310.10935v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MASON-NLP at eRisk 2023: Deep Learning-Based Detection of Depression\n  Symptoms from Social Media Texts", "abstract": "Depression is a mental health disorder that has a profound impact on people's\nlives. Recent research suggests that signs of depression can be detected in the\nway individuals communicate, both through spoken words and written texts. In\nparticular, social media posts are a rich and convenient text source that we\nmay examine for depressive symptoms. The Beck Depression Inventory (BDI)\nQuestionnaire, which is frequently used to gauge the severity of depression, is\none instrument that can aid in this study. We can narrow our study to only\nthose symptoms since each BDI question is linked to a particular depressive\nsymptom. It's important to remember that not everyone with depression exhibits\nall symptoms at once, but rather a combination of them. Therefore, it is\nextremely useful to be able to determine if a sentence or a piece of\nuser-generated content is pertinent to a certain condition. With this in mind,\nthe eRisk 2023 Task 1 was designed to do exactly that: assess the relevance of\ndifferent sentences to the symptoms of depression as outlined in the BDI\nquestionnaire. This report is all about how our team, Mason-NLP, participated\nin this subtask, which involved identifying sentences related to different\ndepression symptoms. We used a deep learning approach that incorporated\nMentalBERT, RoBERTa, and LSTM. Despite our efforts, the evaluation results were\nlower than expected, underscoring the challenges inherent in ranking sentences\nfrom an extensive dataset about depression, which necessitates both appropriate\nmethodological choices and significant computational resources. We anticipate\nthat future iterations of this shared task will yield improved results as our\nunderstanding and techniques evolve.", "published": "2023-10-17 02:34:34", "link": "http://arxiv.org/abs/2310.10941v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Computing the optimal keyboard through a geometric analysis of the\n  English language", "abstract": "In the context of a group project for the course COMSW4995 002 - Geometric\nData Analysis, we bring our attention to the design of fast-typing keyboards.\nLeveraging some geometric tools in an optimization framework allowed us to\npropose novel keyboard layouts that offer a faster typing.", "published": "2023-10-17 03:05:42", "link": "http://arxiv.org/abs/2310.10956v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Iterative Shallow Fusion of Backward Language Model for End-to-End\n  Speech Recognition", "abstract": "We propose a new shallow fusion (SF) method to exploit an external backward\nlanguage model (BLM) for end-to-end automatic speech recognition (ASR). The BLM\nhas complementary characteristics with a forward language model (FLM), and the\neffectiveness of their combination has been confirmed by rescoring ASR\nhypotheses as post-processing. In the proposed SF, we iteratively apply the BLM\nto partial ASR hypotheses in the backward direction (i.e., from the possible\nnext token to the start symbol) during decoding, substituting the newly\ncalculated BLM scores for the scores calculated at the last iteration. To\nenhance the effectiveness of this iterative SF (ISF), we train a partial\nsentence-aware BLM (PBLM) using reversed text data including partial sentences,\nconsidering the framework of ISF. In experiments using an attention-based\nencoder-decoder ASR system, we confirmed that ISF using the PBLM shows\ncomparable performance with SF using the FLM. By performing ISF, early pruning\nof prospective hypotheses can be prevented during decoding, and we can obtain a\nperformance improvement compared to applying the PBLM as post-processing.\nFinally, we confirmed that, by combining SF and ISF, further performance\nimprovement can be obtained thanks to the complementarity of the FLM and PBLM.", "published": "2023-10-17 05:44:10", "link": "http://arxiv.org/abs/2310.11010v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Learning from Red Teaming: Gender Bias Provocation and Mitigation in\n  Large Language Models", "abstract": "Recently, researchers have made considerable improvements in dialogue systems\nwith the progress of large language models (LLMs) such as ChatGPT and GPT-4.\nThese LLM-based chatbots encode the potential biases while retaining\ndisparities that can harm humans during interactions. The traditional biases\ninvestigation methods often rely on human-written test cases. However, these\ntest cases are usually expensive and limited. In this work, we propose a\nfirst-of-its-kind method that automatically generates test cases to detect\nLLMs' potential gender bias. We apply our method to three well-known LLMs and\nfind that the generated test cases effectively identify the presence of biases.\nTo address the biases identified, we propose a mitigation strategy that uses\nthe generated test cases as demonstrations for in-context learning to\ncircumvent the need for parameter fine-tuning. The experimental results show\nthat LLMs generate fairer responses with the proposed approach.", "published": "2023-10-17 08:56:04", "link": "http://arxiv.org/abs/2310.11079v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding writing style in social media with a supervised\n  contrastively pre-trained transformer", "abstract": "Online Social Networks serve as fertile ground for harmful behavior, ranging\nfrom hate speech to the dissemination of disinformation. Malicious actors now\nhave unprecedented freedom to misbehave, leading to severe societal unrest and\ndire consequences, as exemplified by events such as the Capitol assault during\nthe US presidential election and the Antivaxx movement during the COVID-19\npandemic. Understanding online language has become more pressing than ever.\nWhile existing works predominantly focus on content analysis, we aim to shift\nthe focus towards understanding harmful behaviors by relating content to their\nrespective authors. Numerous novel approaches attempt to learn the stylistic\nfeatures of authors in texts, but many of these approaches are constrained by\nsmall datasets or sub-optimal training losses. To overcome these limitations,\nwe introduce the Style Transformer for Authorship Representations (STAR),\ntrained on a large corpus derived from public sources of 4.5 x 10^6 authored\ntexts involving 70k heterogeneous authors. Our model leverages Supervised\nContrastive Loss to teach the model to minimize the distance between texts\nauthored by the same individual. This author pretext pre-training task yields\ncompetitive performance at zero-shot with PAN challenges on attribution and\nclustering. Additionally, we attain promising results on PAN verification\nchallenges using a single dense layer, with our model serving as an embedding\nencoder. Finally, we present results from our test partition on Reddit. Using a\nsupport base of 8 documents of 512 tokens, we can discern authors from sets of\nup to 1616 authors with at least 80\\% accuracy. We share our pre-trained model\nat huggingface (https://huggingface.co/AIDA-UPM/star) and our code is available\nat (https://github.com/jahuerta92/star)", "published": "2023-10-17 09:01:17", "link": "http://arxiv.org/abs/2310.11081v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Probing the Creativity of Large Language Models: Can models produce\n  divergent semantic association?", "abstract": "Large language models possess remarkable capacity for processing language,\nbut it remains unclear whether these models can further generate creative\ncontent. The present study aims to investigate the creative thinking of large\nlanguage models through a cognitive perspective. We utilize the divergent\nassociation task (DAT), an objective measurement of creativity that asks models\nto generate unrelated words and calculates the semantic distance between them.\nWe compare the results across different models and decoding strategies. Our\nfindings indicate that: (1) When using the greedy search strategy, GPT-4\noutperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level.\n(2) Stochastic sampling and temperature scaling are effective to obtain higher\nDAT scores for models except GPT-4, but face a trade-off between creativity and\nstability. These results imply that advanced large language models have\ndivergent semantic associations, which is a fundamental process underlying\ncreativity.", "published": "2023-10-17 11:23:32", "link": "http://arxiv.org/abs/2310.11158v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Medical Text Simplification: Optimizing for Readability with\n  Unlikelihood Training and Reranked Beam Search Decoding", "abstract": "Text simplification has emerged as an increasingly useful application of AI\nfor bridging the communication gap in specialized fields such as medicine,\nwhere the lexicon is often dominated by technical jargon and complex\nconstructs. Despite notable progress, methods in medical simplification\nsometimes result in the generated text having lower quality and diversity. In\nthis work, we explore ways to further improve the readability of text\nsimplification in the medical domain. We propose (1) a new unlikelihood loss\nthat encourages generation of simpler terms and (2) a reranked beam search\ndecoding method that optimizes for simplicity, which achieve better performance\non readability metrics on three datasets. This study's findings offer promising\navenues for improving text simplification in the medical field.", "published": "2023-10-17 12:14:03", "link": "http://arxiv.org/abs/2310.11191v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Explain Themselves? A Study of LLM-Generated\n  Self-Explanations", "abstract": "Large language models (LLMs) such as ChatGPT have demonstrated superior\nperformance on a variety of natural language processing (NLP) tasks including\nsentiment analysis, mathematical reasoning and summarization. Furthermore,\nsince these models are instruction-tuned on human conversations to produce\n\"helpful\" responses, they can and often will produce explanations along with\nthe response, which we call self-explanations. For example, when analyzing the\nsentiment of a movie review, the model may output not only the positivity of\nthe sentiment, but also an explanation (e.g., by listing the sentiment-laden\nwords such as \"fantastic\" and \"memorable\" in the review). How good are these\nautomatically generated self-explanations? In this paper, we investigate this\nquestion on the task of sentiment analysis and for feature attribution\nexplanation, one of the most commonly studied settings in the interpretability\nliterature (for pre-ChatGPT models). Specifically, we study different ways to\nelicit the self-explanations, evaluate their faithfulness on a set of\nevaluation metrics, and compare them to traditional explanation methods such as\nocclusion or LIME saliency maps. Through an extensive set of experiments, we\nfind that ChatGPT's self-explanations perform on par with traditional ones, but\nare quite different from them according to various agreement metrics, meanwhile\nbeing much cheaper to produce (as they are generated along with the\nprediction). In addition, we identified several interesting characteristics of\nthem, which prompt us to rethink many current model interpretability practices\nin the era of ChatGPT(-like) LLMs.", "published": "2023-10-17 12:34:32", "link": "http://arxiv.org/abs/2310.11207v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RealBehavior: A Framework for Faithfully Characterizing Foundation\n  Models' Human-like Behavior Mechanisms", "abstract": "Reports of human-like behaviors in foundation models are growing, with\npsychological theories providing enduring tools to investigate these behaviors.\nHowever, current research tends to directly apply these human-oriented tools\nwithout verifying the faithfulness of their outcomes. In this paper, we\nintroduce a framework, RealBehavior, which is designed to characterize the\nhumanoid behaviors of models faithfully. Beyond simply measuring behaviors, our\nframework assesses the faithfulness of results based on reproducibility,\ninternal and external consistency, and generalizability. Our findings suggest\nthat a simple application of psychological tools cannot faithfully characterize\nall human-like behaviors. Moreover, we discuss the impacts of aligning models\nwith human and social values, arguing for the necessity of diversifying\nalignment objectives to prevent the creation of models with restricted\ncharacteristics.", "published": "2023-10-17 12:58:17", "link": "http://arxiv.org/abs/2310.11227v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Entity Matching using Large Language Models", "abstract": "Entity matching is the task of deciding whether two entity descriptions refer\nto the same real-world entity. Entity matching is a central step in most data\nintegration pipelines. Many state-of-the-art entity matching methods rely on\npre-trained language models (PLMs) such as BERT or RoBERTa. Two major drawbacks\nof these models for entity matching are that (i) the models require significant\namounts of task-specific training data and (ii) the fine-tuned models are not\nrobust concerning out-of-distribution entities. This paper investigates using\ngenerative large language models (LLMs) as a less task-specific training\ndata-dependent and more robust alternative to PLM-based matchers. The study\ncovers hosted and open-source LLMs which can be run locally. We evaluate these\nmodels in a zero-shot scenario and a scenario where task-specific training data\nis available. We compare different prompt designs and the prompt sensitivity of\nthe models. We show that there is no single best prompt but that the prompt\nneeds to be tuned for each model/dataset combination. We further investigate\n(i) the selection of in-context demonstrations, (ii) the generation of matching\nrules, as well as (iii) fine-tuning LLMs using the same pool of training data.\nOur experiments show that the best LLMs require no or only a few training\nexamples to perform comparably to PLMs that were fine-tuned using thousands of\nexamples. LLM-based matchers further exhibit higher robustness to unseen\nentities. We show that GPT4 can generate structured explanations for matching\ndecisions and can automatically identify potential causes of matching errors by\nanalyzing explanations of wrong decisions. We demonstrate that the model can\ngenerate meaningful textual descriptions of the identified error classes, which\ncan help data engineers to improve entity matching pipelines.", "published": "2023-10-17 13:12:32", "link": "http://arxiv.org/abs/2310.11244v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Utilising a Large Language Model to Annotate Subject Metadata: A Case\n  Study in an Australian National Research Data Catalogue", "abstract": "In support of open and reproducible research, there has been a rapidly\nincreasing number of datasets made available for research. As the availability\nof datasets increases, it becomes more important to have quality metadata for\ndiscovering and reusing them. Yet, it is a common issue that datasets often\nlack quality metadata due to limited resources for data curation. Meanwhile,\ntechnologies such as artificial intelligence and large language models (LLMs)\nare progressing rapidly. Recently, systems based on these technologies, such as\nChatGPT, have demonstrated promising capabilities for certain data curation\ntasks. This paper proposes to leverage LLMs for cost-effective annotation of\nsubject metadata through the LLM-based in-context learning. Our method employs\nGPT-3.5 with prompts designed for annotating subject metadata, demonstrating\npromising performance in automatic metadata annotation. However, models based\non in-context learning cannot acquire discipline-specific rules, resulting in\nlower performance in several categories. This limitation arises from the\nlimited contextual information available for subject inference. To the best of\nour knowledge, we are introducing, for the first time, an in-context learning\nmethod that harnesses large language models for automated subject metadata\nannotation.", "published": "2023-10-17 14:52:33", "link": "http://arxiv.org/abs/2310.11318v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The effect of stemming and lemmatization on Portuguese fake news text\n  classification", "abstract": "With the popularization of the internet, smartphones and social media,\ninformation is being spread quickly and easily way, which implies bigger\ntraffic of information in the world, but there is a problem that is harming\nsociety with the dissemination of fake news. With a bigger flow of information,\nsome people are trying to disseminate deceptive information and fake news. The\nautomatic detection of fake news is a challenging task because to obtain a good\nresult is necessary to deal with linguistics problems, especially when we are\ndealing with languages that not have been comprehensively studied yet, besides\nthat, some techniques can help to reach a good result when we are dealing with\ntext data, although, the motivation of detecting this deceptive information it\nis in the fact that the people need to know which information is true and\ntrustful and which one is not. In this work, we present the effect the\npre-processing methods such as lemmatization and stemming have on fake news\nclassification, for that we designed some classifier models applying different\npre-processing techniques. The results show that the pre-processing step is\nimportant to obtain betters results, the stemming and lemmatization techniques\nare interesting methods and need to be more studied to develop techniques\nfocused on the Portuguese language so we can reach better results.", "published": "2023-10-17 15:26:40", "link": "http://arxiv.org/abs/2310.11344v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism\n  with Neural Networks", "abstract": "In the realm of deep learning, the self-attention mechanism has substantiated\nits pivotal role across a myriad of tasks, encompassing natural language\nprocessing and computer vision. Despite achieving success across diverse\napplications, the traditional self-attention mechanism primarily leverages\nlinear transformations for the computation of query, key, and value (QKV),\nwhich may not invariably be the optimal choice under specific circumstances.\nThis paper probes into a novel methodology for QKV computation-implementing a\nspecially-designed neural network structure for the calculation. Utilizing a\nmodified Marian model, we conducted experiments on the IWSLT 2017\nGerman-English translation task dataset and juxtaposed our method with the\nconventional approach. The experimental results unveil a significant\nenhancement in BLEU scores with our method. Furthermore, our approach also\nmanifested superiority when training the Roberta model with the Wikitext-103\ndataset, reflecting a notable reduction in model perplexity compared to its\noriginal counterpart. These experimental outcomes not only validate the\nefficacy of our method but also reveal the immense potential in optimizing the\nself-attention mechanism through neural network-based QKV computation, paving\nthe way for future research and practical applications. The source code and\nimplementation details for our proposed method can be accessed at\nhttps://github.com/ocislyjrti/NeuralAttention.", "published": "2023-10-17 17:06:26", "link": "http://arxiv.org/abs/2310.11398v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic News Summerization", "abstract": "Natural Language Processing is booming with its applications in the real\nworld, one of which is Text Summarization for large texts including news\narticles. This research paper provides an extensive comparative evaluation of\nextractive and abstractive approaches for news text summarization, with an\nemphasis on the ROUGE score analysis. The study employs the CNN-Daily Mail\ndataset, which consists of news articles and human-generated reference\nsummaries. The evaluation employs ROUGE scores to assess the efficacy and\nquality of generated summaries. After Evaluation, we integrate the\nbest-performing models on a web application to assess their real-world\ncapabilities and user experience.", "published": "2023-10-17 18:38:03", "link": "http://arxiv.org/abs/2310.11520v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-stage Large Language Model Correction for Speech Recognition", "abstract": "In this paper, we investigate the usage of large language models (LLMs) to\nimprove the performance of competitive speech recognition systems. Different\nfrom previous LLM-based ASR error correction methods, we propose a novel\nmulti-stage approach that utilizes uncertainty estimation of ASR outputs and\nreasoning capability of LLMs. Specifically, the proposed approach has two\nstages: the first stage is about ASR uncertainty estimation and exploits N-best\nlist hypotheses to identify less reliable transcriptions; The second stage\nworks on these identified transcriptions and performs LLM-based corrections.\nThis correction task is formulated as a multi-step rule-based LLM reasoning\nprocess, which uses explicitly written rules in prompts to decompose the task\ninto concrete reasoning steps. Our experimental results demonstrate the\neffectiveness of the proposed method by showing 10% ~ 20% relative improvement\nin WER over competitive ASR systems -- across multiple test domains and in\nzero-shot settings.", "published": "2023-10-17 19:02:40", "link": "http://arxiv.org/abs/2310.11532v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Alexpaca: Learning Factual Clarification Question Generation Without\n  Examples", "abstract": "Real-life tasks such as giving legal or technical advice often lack complete\ncontext at the outset and can have disparate answers depending thereon. The\nability to derive missing factual information by asking clarifying questions\n(ACQ) is an important element of real-life collaboration on such reasoning\ntasks. Existing factual clarification question challenges evaluate generations\nbased on word overlap or human evaluations. Recent work explores generating a\nresponse to the clarifying question then evaluating its utility directly. So\nfar, these tasks are limited to disambiguating the user's intent rather than\nconcrete facts about the situation. The factual domain presents unique\nchallenges since responses to clarification questions must be factually true\nfor accurate evaluation. To enable evaluation of factual domain clarification\nquestion generation, We present a new task that focuses on the ability to\nelicit missing information in multi-hop reasoning tasks. The task,\nHotpotQA-FLM, can be evaluated automatically, making it convenient for\nbenchmarking language models. We observe that humans outperform GPT-4 by a\nlarge margin, while Llama 3 8B Instruct does not even beat the dummy baseline\nin some metrics. Finally, we find by fine-tuning Llama 3 8B Instruct on its own\ngenerations, filtered via rejection sampling, we can improve information\nrecovery by 27.6 percent.", "published": "2023-10-17 20:40:59", "link": "http://arxiv.org/abs/2310.11571v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evidence of interrelated cognitive-like capabilities in large language\n  models: Indications of artificial general intelligence or achievement?", "abstract": "Large language models (LLMs) are advanced artificial intelligence (AI)\nsystems that can perform a variety of tasks commonly found in human\nintelligence tests, such as defining words, performing calculations, and\nengaging in verbal reasoning. There are also substantial individual differences\nin LLM capacities. Given the consistent observation of a positive manifold and\ngeneral intelligence factor in human samples, along with group-level factors\n(e.g., crystallized intelligence), we hypothesized that LLM test scores may\nalso exhibit positive intercorrelations, which could potentially give rise to\nan artificial general ability (AGA) factor and one or more group-level factors.\nBased on a sample of 591 LLMs and scores from 12 tests aligned with fluid\nreasoning (Gf), domain-specific knowledge (Gkn), reading/writing (Grw), and\nquantitative knowledge (Gq), we found strong empirical evidence for a positive\nmanifold and a general factor of ability. Additionally, we identified a\ncombined Gkn/Grw group-level factor. Finally, the number of LLM parameters\ncorrelated positively with both general factor of ability and Gkn/Grw factor\nscores, although the effects showed diminishing returns. We interpreted our\nresults to suggest that LLMs, like human cognitive abilities, may share a\ncommon underlying efficiency in processing information and solving problems,\nthough whether LLMs manifest primarily achievement/expertise rather than\nintelligence remains to be determined. Finally, while models with greater\nnumbers of parameters exhibit greater general cognitive-like abilities, akin to\nthe connection between greater neuronal density and human general intelligence,\nother characteristics must also be involved.", "published": "2023-10-17 22:42:12", "link": "http://arxiv.org/abs/2310.11616v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learn Your Tokens: Word-Pooled Tokenization for Language Modeling", "abstract": "Language models typically tokenize text into subwords, using a deterministic,\nhand-engineered heuristic of combining characters into longer surface-level\nstrings such as 'ing' or whole words. Recent literature has repeatedly shown\nthe limitations of such a tokenization strategy, particularly for documents not\nwritten in English and for representing numbers. On the other extreme,\nbyte/character-level language models are much less restricted but suffer from\nincreased sequence description lengths and a subsequent quadratic expansion in\nself-attention computation. Recent attempts to compress and limit these context\nlengths with fixed size convolutions is helpful but completely ignores the word\nboundary. This paper considers an alternative 'learn your tokens' scheme which\nutilizes the word boundary to pool bytes/characters into word representations,\nwhich are fed to the primary language model, before again decoding individual\ncharacters/bytes per word in parallel. We find that our moderately expressive\nand moderately fast end-to-end tokenizer outperform by over 300% both subwords\nand byte/character models over the intrinsic language modeling metric of\nnext-word prediction across datasets. It particularly outshines on rare words,\noutperforming by a factor of 30! We extensively study the language modeling\nsetup for all three categories of tokenizers and theoretically analyze how our\nend-to-end models can also be a strong trade-off in efficiency and robustness.", "published": "2023-10-17 23:34:39", "link": "http://arxiv.org/abs/2310.11628v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Compositional preference models for aligning LMs", "abstract": "As language models (LMs) become more capable, it is increasingly important to\nalign them with human preferences. However, the dominant paradigm for training\nPreference Models (PMs) for that purpose suffers from fundamental limitations,\nsuch as lack of transparency and scalability, along with susceptibility to\noverfitting the preference dataset. We propose Compositional Preference Models\n(CPMs), a novel PM framework that decomposes one global preference assessment\ninto several interpretable features, obtains scalar scores for these features\nfrom a prompted LM, and aggregates these scores using a logistic regression\nclassifier. Through these simple steps, CPMs allow to control which properties\nof the preference data are used to train the preference model and to build it\nbased on features that are believed to underlie the human preference judgment.\nOur experiments show that CPMs not only improve generalization and are more\nrobust to overoptimization than standard PMs, but also that best-of-n samples\nobtained using CPMs tend to be preferred over samples obtained using\nconventional PMs. Overall, our approach demonstrates the benefits of endowing\nPMs with priors about which features determine human preferences while relying\non LM capabilities to extract those features in a scalable and robust way.", "published": "2023-10-17 01:31:59", "link": "http://arxiv.org/abs/2310.13011v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "H2O Open Ecosystem for State-of-the-art Large Language Models", "abstract": "Large Language Models (LLMs) represent a revolution in AI. However, they also\npose many significant risks, such as the presence of biased, private,\ncopyrighted or harmful text. For this reason we need open, transparent and safe\nsolutions. We introduce a complete open-source ecosystem for developing and\ntesting LLMs. The goal of this project is to boost open alternatives to\nclosed-source approaches. We release h2oGPT, a family of fine-tuned LLMs of\ndiverse sizes. We also introduce H2O LLM Studio, a framework and no-code GUI\ndesigned for efficient fine-tuning, evaluation, and deployment of LLMs using\nthe most recent state-of-the-art techniques. Our code and models are fully\nopen-source. We believe this work helps to boost AI development and make it\nmore accessible, efficient and trustworthy. The demo is available at:\nhttps://gpt.h2o.ai/", "published": "2023-10-17 09:40:58", "link": "http://arxiv.org/abs/2310.13012v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Spatial HuBERT: Self-supervised Spatial Speech Representation Learning\n  for a Single Talker from Multi-channel Audio", "abstract": "Self-supervised learning has been used to leverage unlabelled data, improving\naccuracy and generalisation of speech systems through the training of\nrepresentation models. While many recent works have sought to produce effective\nrepresentations across a variety of acoustic domains, languages, modalities and\neven simultaneous speakers, these studies have all been limited to\nsingle-channel audio recordings. This paper presents Spatial HuBERT, a\nself-supervised speech representation model that learns both acoustic and\nspatial information pertaining to a single speaker in a potentially noisy\nenvironment by using multi-channel audio inputs. Spatial HuBERT learns\nrepresentations that outperform state-of-the-art single-channel speech\nrepresentations on a variety of spatial downstream tasks, particularly in\nreverberant and noisy environments. We also demonstrate the utility of the\nrepresentations learned by Spatial HuBERT on a speech localisation downstream\ntask. Along with this paper, we publicly release a new dataset of 100 000\nsimulated first-order ambisonics room impulse responses.", "published": "2023-10-17 01:31:59", "link": "http://arxiv.org/abs/2310.10922v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A State-Vector Framework for Dataset Effects", "abstract": "The impressive success of recent deep neural network (DNN)-based systems is\nsignificantly influenced by the high-quality datasets used in training.\nHowever, the effects of the datasets, especially how they interact with each\nother, remain underexplored. We propose a state-vector framework to enable\nrigorous studies in this direction. This framework uses idealized probing test\nresults as the bases of a vector space. This framework allows us to quantify\nthe effects of both standalone and interacting datasets. We show that the\nsignificant effects of some commonly-used language understanding datasets are\ncharacteristic and are concentrated on a few linguistic dimensions.\nAdditionally, we observe some ``spill-over'' effects: the datasets could impact\nthe models along dimensions that may seem unrelated to the intended tasks. Our\nstate-vector framework paves the way for a systematic understanding of the\ndataset effects, a crucial component in responsible and robust model\ndevelopment.", "published": "2023-10-17 03:05:06", "link": "http://arxiv.org/abs/2310.10955v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EXMODD: An EXplanatory Multimodal Open-Domain Dialogue dataset", "abstract": "The need for high-quality data has been a key issue hindering the research of\ndialogue tasks. Recent studies try to build datasets through manual, web\ncrawling, and large pre-trained models. However, man-made data is expensive and\ndata collected from the internet often includes generic responses, meaningless\nstatements, and toxic dialogues. Automatic data generation through large models\nis a cost-effective method, but for open-domain multimodal dialogue tasks,\nthere are still three drawbacks: 1) There is currently no open-source large\nmodel that can accept multimodal input; 2) The content generated by the model\nlacks interpretability; 3) The generated data is usually difficult to quality\ncontrol and require extensive resource to collect. To alleviate the significant\nhuman and resource expenditure in data collection, we propose a Multimodal Data\nConstruction Framework (MDCF). MDCF designs proper prompts to spur the\nlarge-scale pre-trained language model to generate well-formed and satisfactory\ncontent. Additionally, MDCF also automatically provides explanation for a given\nimage and its corresponding dialogue, which can provide a certain degree of\ninterpretability and facilitate manual follow-up quality inspection. Based on\nthis, we release an Explanatory Multimodal Open-Domain dialogue dataset\n(EXMODD). Experiments indicate a positive correlation between the model's\nability to generate accurate understandings and high-quality responses. Our\ncode and data can be found at https://github.com/poplpr/EXMODD.", "published": "2023-10-17 03:28:29", "link": "http://arxiv.org/abs/2310.10967v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Correction Focused Language Model Training for Speech Recognition", "abstract": "Language models (LMs) have been commonly adopted to boost the performance of\nautomatic speech recognition (ASR) particularly in domain adaptation tasks.\nConventional way of LM training treats all the words in corpora equally,\nresulting in suboptimal improvements in ASR performance. In this work, we\nintroduce a novel correction focused LM training approach which aims to\nprioritize ASR fallible words. The word-level ASR fallibility score,\nrepresenting the likelihood of ASR mis-recognition, is defined and shaped as a\nprior word distribution to guide the LM training. To enable correction focused\ntraining with text-only corpora, large language models (LLMs) are employed as\nfallibility score predictors and text generators through multi-task\nfine-tuning. Experimental results for domain adaptation tasks demonstrate the\neffectiveness of our proposed method. Compared with conventional LMs,\ncorrection focused training achieves up to relatively 5.5% word error rate\n(WER) reduction in sufficient text scenarios. In insufficient text scenarios,\nLM training with LLM-generated text achieves up to relatively 13% WER\nreduction, while correction focused training further obtains up to relatively\n6% WER reduction.", "published": "2023-10-17 05:10:39", "link": "http://arxiv.org/abs/2310.11003v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Lyricist-Singer Entropy Affects Lyric-Lyricist Classification\n  Performance", "abstract": "Although lyrics represent an essential component of music, few music\ninformation processing studies have been conducted on the characteristics of\nlyricists. Because these characteristics may be valuable for musical\napplications, such as recommendations, they warrant further study. We\nconsidered a potential method that extracts features representing the\ncharacteristics of lyricists from lyrics. Because these features must be\nidentified prior to extraction, we focused on lyricists with easily\nidentifiable features. We believe that it is desirable for singers to perform\nunique songs that share certain characteristics specific to the singer.\nAccordingly, we hypothesized that lyricists account for the unique\ncharacteristics of the singers they write lyrics for. In other words,\nlyric-lyricist classification performance or the ease of capturing the features\nof a lyricist from the lyrics may depend on the variety of singers. In this\nstudy, we observed a relationship between lyricist-singer entropy or the\nvariety of singers associated with a single lyricist and lyric-lyricist\nclassification performance. As an example, the lyricist-singer entropy is\nminimal when the lyricist writes lyrics for only one singer. In our\nexperiments, we grouped lyricists among five groups in terms of lyricist-singer\nentropy and assessed the lyric-lyricist classification performance within each\ngroup. Consequently, the best F1 score was obtained for the group with the\nlowest lyricist-singer entropy. Our results suggest that further analyses of\nthe features contributing to lyric-lyricist classification performance on the\nlowest lyricist-singer entropy group may improve the feature extraction task\nfor lyricists.", "published": "2023-10-17 07:02:26", "link": "http://arxiv.org/abs/2310.11035v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation", "abstract": "This paper describes our submission to the SemEval-2023 for Task 6 on\nLegalEval: Understanding Legal Texts. Our submission concentrated on three\nsubtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment\nPrediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation\n(CJPE) for Task-C2. We conducted various experiments on these subtasks and\npresented the results in detail, including data statistics and methodology. It\nis worth noting that legal tasks, such as those tackled in this research, have\nbeen gaining importance due to the increasing need to automate legal analysis\nand support. Our team obtained competitive rankings of 15$^{th}$, 11$^{th}$,\nand 1$^{st}$ in Task-B, Task-C1, and Task-C2, respectively, as reported on the\nleaderboard.", "published": "2023-10-17 07:35:11", "link": "http://arxiv.org/abs/2310.11049v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Denevil: Towards Deciphering and Navigating the Ethical Values of Large\n  Language Models via Instruction Learning", "abstract": "Large Language Models (LLMs) have made unprecedented breakthroughs, yet their\nincreasing integration into everyday life might raise societal risks due to\ngenerated unethical content. Despite extensive study on specific issues like\nbias, the intrinsic values of LLMs remain largely unexplored from a moral\nphilosophy perspective. This work delves into ethical values utilizing Moral\nFoundation Theory. Moving beyond conventional discriminative evaluations with\npoor reliability, we propose DeNEVIL, a novel prompt generation algorithm\ntailored to dynamically exploit LLMs' value vulnerabilities and elicit the\nviolation of ethics in a generative manner, revealing their underlying value\ninclinations. On such a basis, we construct MoralPrompt, a high-quality dataset\ncomprising 2,397 prompts covering 500+ value principles, and then benchmark the\nintrinsic values across a spectrum of LLMs. We discovered that most models are\nessentially misaligned, necessitating further ethical value alignment. In\nresponse, we develop VILMO, an in-context alignment method that substantially\nenhances the value compliance of LLM outputs by learning to generate\nappropriate value instructions, outperforming existing competitors. Our methods\nare suitable for black-box and open-source models, offering a promising initial\nstep in studying the ethical values of LLMs.", "published": "2023-10-17 07:42:40", "link": "http://arxiv.org/abs/2310.11053v3", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System", "abstract": "Arabic is a complex language with many varieties and dialects spoken by over\n450 millions all around the world. Due to the linguistic diversity and\nvariations, it is challenging to build a robust and generalized ASR system for\nArabic. In this work, we address this gap by developing and demoing a system,\ndubbed VoxArabica, for dialect identification (DID) as well as automatic speech\nrecognition (ASR) of Arabic. We train a wide range of models such as HuBERT\n(DID), Whisper, and XLS-R (ASR) in a supervised setting for Arabic DID and ASR\ntasks. Our DID models are trained to identify 17 different dialects in addition\nto MSA. We finetune our ASR models on MSA, Egyptian, Moroccan, and mixed data.\nAdditionally, for the remaining dialects in ASR, we provide the option to\nchoose various models such as Whisper and MMS in a zero-shot setting. We\nintegrate these models into a single web interface with diverse features such\nas audio recording, file upload, model selection, and the option to raise flags\nfor incorrect outputs. Overall, we believe VoxArabica will be useful for a wide\nrange of audiences concerned with Arabic research. Our system is currently\nrunning at https://cdce-206-12-100-168.ngrok.io/.", "published": "2023-10-17 08:33:02", "link": "http://arxiv.org/abs/2310.11069v4", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained\n  Language Models", "abstract": "Document-level relation extraction aims at inferring structured human\nknowledge from textual documents. State-of-the-art methods for this task use\npre-trained language models (LMs) via fine-tuning, yet fine-tuning is\ncomputationally expensive and cannot adapt to new relation types or new LMs. As\na remedy, we leverage the generalization capabilities of pre-trained LMs and\npresent a novel framework for document-level in-context few-shot relation\nextraction. Our framework has three strengths: it eliminates the need (1) for\nnamed entity recognition and (2) for human annotations of documents, and (3) it\ncan be updated to new LMs without re-training. We evaluate our framework using\nDocRED, the largest publicly available dataset for document-level relation\nextraction, and demonstrate that our framework achieves state-of-the-art\nperformance. We further show that our framework actually performs much better\nthan the original labels from the development set of DocRED. Finally, we\nconduct an extensive benchmark demonstrating the effectiveness of our\nframework, achieving state-of-the-art results across six relation extraction\ndatasets and outperforming more than 30 baseline methods. Unlike our framework,\nthe baseline methods have large computational overhead (e.g., from\nfine-tuning). To the best of our knowledge, we are the first to reformulate the\ndocument-level relation extraction task as a tailored in-context few-shot\nlearning paradigm.", "published": "2023-10-17 09:10:27", "link": "http://arxiv.org/abs/2310.11085v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Long-form Simultaneous Speech Translation: Thesis Proposal", "abstract": "Simultaneous speech translation (SST) aims to provide real-time translation\nof spoken language, even before the speaker finishes their sentence.\nTraditionally, SST has been addressed primarily by cascaded systems that\ndecompose the task into subtasks, including speech recognition, segmentation,\nand machine translation. However, the advent of deep learning has sparked\nsignificant interest in end-to-end (E2E) systems. Nevertheless, a major\nlimitation of most approaches to E2E SST reported in the current literature is\nthat they assume that the source speech is pre-segmented into sentences, which\nis a significant obstacle for practical, real-world applications. This thesis\nproposal addresses end-to-end simultaneous speech translation, particularly in\nthe long-form setting, i.e., without pre-segmentation. We present a survey of\nthe latest advancements in E2E SST, assess the primary obstacles in SST and its\nrelevance to long-form scenarios, and suggest approaches to tackle these\nchallenges.", "published": "2023-10-17 10:44:05", "link": "http://arxiv.org/abs/2310.11141v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code\n  Completion", "abstract": "Code completion models have made significant progress in recent years, yet\ncurrent popular evaluation datasets, such as HumanEval and MBPP, predominantly\nfocus on code completion tasks within a single file. This over-simplified\nsetting falls short of representing the real-world software development\nscenario where repositories span multiple files with numerous cross-file\ndependencies, and accessing and understanding cross-file context is often\nrequired to complete the code correctly.\n  To fill in this gap, we propose CrossCodeEval, a diverse and multilingual\ncode completion benchmark that necessitates an in-depth cross-file contextual\nunderstanding to complete the code accurately. CrossCodeEval is built on a\ndiverse set of real-world, open-sourced, permissively-licensed repositories in\nfour popular programming languages: Python, Java, TypeScript, and C#. To create\nexamples that strictly require cross-file context for accurate completion, we\npropose a straightforward yet efficient static-analysis-based approach to\npinpoint the use of cross-file context within the current file.\n  Extensive experiments on state-of-the-art code language models like CodeGen\nand StarCoder demonstrate that CrossCodeEval is extremely challenging when the\nrelevant cross-file context is absent, and we see clear improvements when\nadding these context into the prompt. However, despite such improvements, the\npinnacle of performance remains notably unattained even with the\nhighest-performing model, indicating that CrossCodeEval is also capable of\nassessing model's capability in leveraging extensive context to make better\ncode completion. Finally, we benchmarked various methods in retrieving\ncross-file context, and show that CrossCodeEval can also be used to measure the\ncapability of code retrievers.", "published": "2023-10-17 13:18:01", "link": "http://arxiv.org/abs/2310.11248v2", "categories": ["cs.LG", "cs.CL", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Revealing the Unwritten: Visual Investigation of Beam Search Trees to\n  Address Language Model Prompting Challenges", "abstract": "The growing popularity of generative language models has amplified interest\nin interactive methods to guide model outputs. Prompt refinement is considered\none of the most effective means to influence output among these methods. We\nidentify several challenges associated with prompting large language models,\ncategorized into data- and model-specific, linguistic, and socio-linguistic\nchallenges. A comprehensive examination of model outputs, including runner-up\ncandidates and their corresponding probabilities, is needed to address these\nissues. The beam search tree, the prevalent algorithm to sample model outputs,\ncan inherently supply this information. Consequently, we introduce an\ninteractive visual method for investigating the beam search tree, facilitating\nanalysis of the decisions made by the model during generation. We\nquantitatively show the value of exposing the beam search tree and present five\ndetailed analysis scenarios addressing the identified challenges. Our\nmethodology validates existing results and offers additional insights.", "published": "2023-10-17 13:20:16", "link": "http://arxiv.org/abs/2310.11252v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "H.5.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Emulating Human Cognitive Processes for Expert-Level Medical\n  Question-Answering with Large Language Models", "abstract": "In response to the pressing need for advanced clinical problem-solving tools\nin healthcare, we introduce BooksMed, a novel framework based on a Large\nLanguage Model (LLM). BooksMed uniquely emulates human cognitive processes to\ndeliver evidence-based and reliable responses, utilizing the GRADE (Grading of\nRecommendations, Assessment, Development, and Evaluations) framework to\neffectively quantify evidence strength. For clinical decision-making to be\nappropriately assessed, an evaluation metric that is clinically aligned and\nvalidated is required. As a solution, we present ExpertMedQA, a multispecialty\nclinical benchmark comprised of open-ended, expert-level clinical questions,\nand validated by a diverse group of medical professionals. By demanding an\nin-depth understanding and critical appraisal of up-to-date clinical\nliterature, ExpertMedQA rigorously evaluates LLM performance. BooksMed\noutperforms existing state-of-the-art models Med-PaLM 2, Almanac, and ChatGPT\nin a variety of medical scenarios. Therefore, a framework that mimics human\ncognitive stages could be a useful tool for providing reliable and\nevidence-based responses to clinical inquiries.", "published": "2023-10-17 13:39:26", "link": "http://arxiv.org/abs/2310.11266v1", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt\n  Design or: How I learned to start worrying about prompt formatting", "abstract": "As large language models (LLMs) are adopted as a fundamental component of\nlanguage technologies, it is crucial to accurately characterize their\nperformance. Because choices in prompt design can strongly influence model\nbehavior, this design process is critical in effectively using any modern\npre-trained generative language model. In this work, we focus on LLM\nsensitivity to a quintessential class of meaning-preserving design choices:\nprompt formatting. We find that several widely used open-source LLMs are\nextremely sensitive to subtle changes in prompt formatting in few-shot\nsettings, with performance differences of up to 76 accuracy points when\nevaluated using LLaMA-2-13B. Sensitivity remains even when increasing model\nsize, the number of few-shot examples, or performing instruction tuning. Our\nanalysis suggests that work evaluating LLMs with prompting-based methods would\nbenefit from reporting a range of performance across plausible prompt formats,\ninstead of the currently-standard practice of reporting performance on a single\nformat. We also show that format performance only weakly correlates between\nmodels, which puts into question the methodological validity of comparing\nmodels with an arbitrarily chosen, fixed prompt format. To facilitate\nsystematic analysis we propose FormatSpread, an algorithm that rapidly\nevaluates a sampled set of plausible prompt formats for a given task, and\nreports the interval of expected performance without accessing model weights.\nFurthermore, we present a suite of analyses that characterize the nature of\nthis sensitivity, including exploring the influence of particular atomic\nperturbations and the internal representation of particular formats.", "published": "2023-10-17 15:03:30", "link": "http://arxiv.org/abs/2310.11324v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Robust Wake-Up Word Detection by Two-stage Multi-resolution Ensembles", "abstract": "Voice-based interfaces rely on a wake-up word mechanism to initiate\ncommunication with devices. However, achieving a robust, energy-efficient, and\nfast detection remains a challenge. This paper addresses these real production\nneeds by enhancing data with temporal alignments and using detection based on\ntwo phases with multi-resolution. It employs two models: a lightweight\non-device model for real-time processing of the audio stream and a verification\nmodel on the server-side, which is an ensemble of heterogeneous architectures\nthat refine detection. This scheme allows the optimization of two operating\npoints. To protect privacy, audio features are sent to the cloud instead of raw\naudio. The study investigated different parametric configurations for feature\nextraction to select one for on-device detection and another for the\nverification model. Furthermore, thirteen different audio classifiers were\ncompared in terms of performance and inference time. The proposed ensemble\noutperforms our stronger classifier in every noise condition.", "published": "2023-10-17 16:22:18", "link": "http://arxiv.org/abs/2310.11379v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V", "abstract": "We present Set-of-Mark (SoM), a new visual prompting method, to unleash the\nvisual grounding abilities of large multimodal models (LMMs), such as GPT-4V.\nAs illustrated in Fig. 1 (right), we employ off-the-shelf interactive\nsegmentation models, such as SEEM/SAM, to partition an image into regions at\ndifferent levels of granularity, and overlay these regions with a set of marks\ne.g., alphanumerics, masks, boxes. Using the marked image as input, GPT-4V can\nanswer the questions that require visual grounding. We perform a comprehensive\nempirical study to validate the effectiveness of SoM on a wide range of\nfine-grained vision and multimodal tasks. For example, our experiments show\nthat GPT-4V with SoM in zero-shot setting outperforms the state-of-the-art\nfully-finetuned referring expression comprehension and segmentation model on\nRefCOCOg. Code for SoM prompting is made public at:\nhttps://github.com/microsoft/SoM.", "published": "2023-10-17 17:51:31", "link": "http://arxiv.org/abs/2310.11441v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Functional Invariants to Watermark Large Transformers", "abstract": "The rapid growth of transformer-based models increases the concerns about\ntheir integrity and ownership insurance. Watermarking addresses this issue by\nembedding a unique identifier into the model, while preserving its performance.\nHowever, most existing approaches require to optimize the weights to imprint\nthe watermark signal, which is not suitable at scale due to the computational\ncost. This paper explores watermarks with virtually no computational cost,\napplicable to a non-blind white-box setting (assuming access to both the\noriginal and watermarked networks). They generate functionally equivalent\ncopies by leveraging the models' invariance, via operations like dimension\npermutations or scaling/unscaling. This enables to watermark models without any\nchange in their outputs and remains stealthy. Experiments demonstrate the\neffectiveness of the approach and its robustness against various model\ntransformations (fine-tuning, quantization, pruning), making it a practical\nsolution to protect the integrity of large models.", "published": "2023-10-17 17:56:18", "link": "http://arxiv.org/abs/2310.11446v2", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from\n  a Parametric Perspective", "abstract": "Large Language Models (LLMs) inherently encode a wealth of knowledge within\ntheir parameters through pre-training on extensive corpora. While prior\nresearch has delved into operations on these parameters to manipulate the\nunderlying implicit knowledge (encompassing detection, editing, and merging),\nthere remains an ambiguous understanding regarding their transferability across\nmodels with varying scales. In this paper, we seek to empirically investigate\nknowledge transfer from larger to smaller models through a parametric\nperspective. To achieve this, we employ sensitivity-based techniques to extract\nand align knowledge-specific parameters between different LLMs. Moreover, the\nLoRA module is used as the intermediary mechanism for injecting the extracted\nknowledge into smaller models. Evaluations across four benchmarks validate the\nefficacy of our proposed method. Our findings highlight the critical factors\ncontributing to the process of parametric knowledge transfer, underscoring the\ntransferability of model parameters across LLMs of different scales. Project\nwebsite: https://maszhongming.github.io/ParaKnowTransfer.", "published": "2023-10-17 17:58:34", "link": "http://arxiv.org/abs/2310.11451v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations", "abstract": "Recent work has aimed to capture nuances of human behavior by using LLMs to\nsimulate responses from particular demographics in settings like social science\nexperiments and public opinion surveys. However, there are currently no\nestablished ways to discuss or evaluate the quality of such LLM simulations.\nMoreover, there is growing concern that these LLM simulations are flattened\ncaricatures of the personas that they aim to simulate, failing to capture the\nmultidimensionality of people and perpetuating stereotypes. To bridge these\ngaps, we present CoMPosT, a framework to characterize LLM simulations using\nfour dimensions: Context, Model, Persona, and Topic. We use this framework to\nmeasure open-ended LLM simulations' susceptibility to caricature, defined via\ntwo criteria: individuation and exaggeration. We evaluate the level of\ncaricature in scenarios from existing work on LLM simulations. We find that for\nGPT-4, simulations of certain demographics (political and marginalized groups)\nand topics (general, uncontroversial) are highly susceptible to caricature.", "published": "2023-10-17 18:00:25", "link": "http://arxiv.org/abs/2310.11501v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Self-RAG: Learning to Retrieve, Generate, and Critique through\n  Self-Reflection", "abstract": "Despite their remarkable capabilities, large language models (LLMs) often\nproduce responses containing factual inaccuracies due to their sole reliance on\nthe parametric knowledge they encapsulate. Retrieval-Augmented Generation\n(RAG), an ad hoc approach that augments LMs with retrieval of relevant\nknowledge, decreases such issues. However, indiscriminately retrieving and\nincorporating a fixed number of retrieved passages, regardless of whether\nretrieval is necessary, or passages are relevant, diminishes LM versatility or\ncan lead to unhelpful response generation. We introduce a new framework called\nSelf-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's\nquality and factuality through retrieval and self-reflection. Our framework\ntrains a single arbitrary LM that adaptively retrieves passages on-demand, and\ngenerates and reflects on retrieved passages and its own generations using\nspecial tokens, called reflection tokens. Generating reflection tokens makes\nthe LM controllable during the inference phase, enabling it to tailor its\nbehavior to diverse task requirements. Experiments show that Self-RAG (7B and\n13B parameters) significantly outperforms state-of-the-art LLMs and\nretrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG\noutperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA,\nreasoning and fact verification tasks, and it shows significant gains in\nimproving factuality and citation accuracy for long-form generations relative\nto these models.", "published": "2023-10-17 18:18:32", "link": "http://arxiv.org/abs/2310.11511v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Group Preference Optimization: Few-Shot Alignment of Large Language\n  Models", "abstract": "Many applications of large language models (LLMs), ranging from chatbots to\ncreative writing, require nuanced subjective judgments that can differ\nsignificantly across different groups. Existing alignment algorithms can be\nexpensive to align for each group, requiring prohibitive amounts of\ngroup-specific preference data and computation for real-world use cases. We\nintroduce Group Preference Optimization (GPO), an alignment framework that\nsteers language models to preferences of individual groups in a few-shot\nmanner. In GPO, we augment the base LLM with an independent transformer module\ntrained to predict the preferences of a group for the LLM generations. For\nfew-shot learning, we parameterize this module as an in-context autoregressive\ntransformer and train it via meta-learning on several groups. We empirically\nvalidate the efficacy of GPO through rigorous evaluations using LLMs with\nvaried sizes on three human opinion adaptation tasks. These tasks involve\nadapting to the preferences of US demographic groups, global countries, and\nindividual users. Our results demonstrate that GPO not only aligns models more\naccurately but also requires fewer group-specific preferences, and less\ntraining and inference computing resources, outperforming existing strategies\nsuch as in-context steering and fine-tuning methods.", "published": "2023-10-17 18:41:57", "link": "http://arxiv.org/abs/2310.11523v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and\n  Phonetic Domains for Speech Representation Learning", "abstract": "In this paper, we present a methodology for linguistic feature extraction,\nfocusing particularly on automatically syllabifying words in multiple\nlanguages, with a design to be compatible with a forced-alignment tool, the\nMontreal Forced Aligner (MFA). In both the textual and phonetic domains, our\nmethod focuses on the extraction of phonetic transcriptions from text, stress\nmarks, and a unified automatic syllabification (in text and phonetic domains).\nThe system was built with open-source components and resources. Through an\nablation study, we demonstrate the efficacy of our approach in automatically\nsyllabifying words from several languages (English, French and Spanish).\nAdditionally, we apply the technique to the transcriptions of the CMU ARCTIC\ndataset, generating valuable annotations available\nonline\\footnote{\\url{https://github.com/noetits/MUST_P-SRL}} that are ideal for\nspeech representation learning, speech unit discovery, and disentanglement of\nspeech factors in several speech-related fields.", "published": "2023-10-17 19:27:23", "link": "http://arxiv.org/abs/2310.11541v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Eliciting Human Preferences with Language Models", "abstract": "Language models (LMs) can be directed to perform target tasks by using\nlabeled examples or natural language prompts. But selecting examples or writing\nprompts for can be challenging--especially in tasks that involve unusual edge\ncases, demand precise articulation of nebulous preferences, or require an\naccurate mental model of LM behavior. We propose to use *LMs themselves* to\nguide the task specification process. In this paper, we introduce **Generative\nActive Task Elicitation (GATE)**: a learning framework in which models elicit\nand infer intended behavior through free-form, language-based interaction with\nusers. We study GATE in three domains: email validation, content\nrecommendation, and moral reasoning. In preregistered experiments, we show that\nLMs prompted to perform GATE (e.g., by generating open-ended questions or\nsynthesizing informative edge cases) elicit responses that are often more\ninformative than user-written prompts or labels. Users report that interactive\ntask elicitation requires less effort than prompting or example labeling and\nsurfaces novel considerations not initially anticipated by users. Our findings\nsuggest that LM-driven elicitation can be a powerful tool for aligning models\nto complex human preferences and values.", "published": "2023-10-17 21:11:21", "link": "http://arxiv.org/abs/2310.11589v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automated Evaluation of Personalized Text Generation using Large\n  Language Models", "abstract": "Personalized text generation presents a specialized mechanism for delivering\ncontent that is specific to a user's personal context. While the research\nprogress in this area has been rapid, evaluation still presents a challenge.\nTraditional automated metrics such as BLEU and ROUGE primarily measure lexical\nsimilarity to human-written references, and are not able to distinguish\npersonalization from other subtle semantic aspects, thus falling short of\ncapturing the nuances of personalized generated content quality. On the other\nhand, human judgments are costly to obtain, especially in the realm of\npersonalized evaluation. Inspired by these challenges, we explore the use of\nlarge language models (LLMs) for evaluating personalized text generation, and\nexamine their ability to understand nuanced user context. We present AuPEL, a\nnovel evaluation method that distills three major semantic aspects of the\ngenerated text: personalization, quality and relevance, and automatically\nmeasures these aspects. To validate the effectiveness of AuPEL, we design\ncarefully controlled experiments and compare the accuracy of the evaluation\njudgments made by LLMs versus that of judgements made by human annotators, and\nconduct rigorous analyses of the consistency and sensitivity of the proposed\nmetric. We find that, compared to existing evaluation metrics, AuPEL not only\ndistinguishes and ranks models based on their personalization abilities more\naccurately, but also presents commendable consistency and efficiency for this\ntask. Our work suggests that using LLMs as the evaluators of personalized text\ngeneration is superior to traditional text similarity metrics, even though\ninteresting new challenges still remain.", "published": "2023-10-17 21:35:06", "link": "http://arxiv.org/abs/2310.11593v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generative error correction for code-switching speech recognition using\n  large language models", "abstract": "Code-switching (CS) speech refers to the phenomenon of mixing two or more\nlanguages within the same sentence. Despite the recent advances in automatic\nspeech recognition (ASR), CS-ASR is still a challenging task ought to the\ngrammatical structure complexity of the phenomenon and the data scarcity of\nspecific training corpus. In this work, we propose to leverage large language\nmodels (LLMs) and lists of hypotheses generated by an ASR to address the CS\nproblem. Specifically, we first employ multiple well-trained ASR models for\nN-best hypotheses generation, with the aim of increasing the diverse and\ninformative elements in the set of hypotheses. Next, we utilize the LLMs to\nlearn the hypotheses-to-transcription (H2T) mapping by adding a trainable\nlow-rank adapter. Such a generative error correction (GER) method directly\npredicts the accurate transcription according to its expert linguistic\nknowledge and N-best hypotheses, resulting in a paradigm shift from the\ntraditional language model rescoring or error correction techniques.\nExperimental evidence demonstrates that GER significantly enhances CS-ASR\naccuracy, in terms of reduced mixed error rate (MER). Furthermore, LLMs show\nremarkable data efficiency for H2T learning, providing a potential solution to\nthe data scarcity problem of CS-ASR in low-resource languages.", "published": "2023-10-17 14:49:48", "link": "http://arxiv.org/abs/2310.13013v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Large Language Model Prediction Capabilities: Evidence from a Real-World\n  Forecasting Tournament", "abstract": "Accurately predicting the future would be an important milestone in the\ncapabilities of artificial intelligence. However, research on the ability of\nlarge language models to provide probabilistic predictions about future events\nremains nascent. To empirically test this ability, we enrolled OpenAI's\nstate-of-the-art large language model, GPT-4, in a three-month forecasting\ntournament hosted on the Metaculus platform. The tournament, running from July\nto October 2023, attracted 843 participants and covered diverse topics\nincluding Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict.\nFocusing on binary forecasts, we show that GPT-4's probabilistic forecasts are\nsignificantly less accurate than the median human-crowd forecasts. We find that\nGPT-4's forecasts did not significantly differ from the no-information\nforecasting strategy of assigning a 50% probability to every question. We\nexplore a potential explanation, that GPT-4 might be predisposed to predict\nprobabilities close to the midpoint of the scale, but our data do not support\nthis hypothesis. Overall, we find that GPT-4 significantly underperforms in\nreal-world predictive tasks compared to median human-crowd forecasts. A\npotential explanation for this underperformance is that in real-world\nforecasting tournaments, the true answers are genuinely unknown at the time of\nprediction; unlike in other benchmark tasks like professional exams or time\nseries forecasting, where strong performance may at least partly be due to the\nanswers being memorized from the training data. This makes real-world\nforecasting tournaments an ideal environment for testing the generalized\nreasoning and prediction capabilities of artificial intelligence going forward.", "published": "2023-10-17 17:58:17", "link": "http://arxiv.org/abs/2310.13014v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Audio-AdapterFusion: A Task-ID-free Approach for Efficient and\n  Non-Destructive Multi-task Speech Recognition", "abstract": "Adapters are an efficient, composable alternative to full fine-tuning of\npre-trained models and help scale the deployment of large ASR models to many\ntasks. In practice, a task ID is commonly prepended to the input during\ninference to route to single-task adapters for the specified task. However, one\nmajor limitation of this approach is that the task ID may not be known during\ninference, rendering it unsuitable for most multi-task settings. To address\nthis, we propose three novel task-ID-free methods to combine single-task\nadapters in multi-task ASR and investigate two learning algorithms for\ntraining. We evaluate our methods on 10 test sets from 4 diverse ASR tasks and\nshow that our methods are non-destructive and parameter-efficient. While only\nupdating 17% of the model parameters, our methods can achieve an 8% mean WER\nimprovement relative to full fine-tuning and are on-par with task-ID adapter\nrouting.", "published": "2023-10-17 21:21:40", "link": "http://arxiv.org/abs/2310.13015v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Language Models as Zero-Shot Trajectory Generators", "abstract": "Large Language Models (LLMs) have recently shown promise as high-level\nplanners for robots when given access to a selection of low-level skills.\nHowever, it is often assumed that LLMs do not possess sufficient knowledge to\nbe used for the low-level trajectories themselves. In this work, we address\nthis assumption thoroughly, and investigate if an LLM (GPT-4) can directly\npredict a dense sequence of end-effector poses for manipulation tasks, when\ngiven access to only object detection and segmentation vision models. We\ndesigned a single, task-agnostic prompt, without any in-context examples,\nmotion primitives, or external trajectory optimisers. Then we studied how well\nit can perform across 30 real-world language-based tasks, such as \"open the\nbottle cap\" and \"wipe the plate with the sponge\", and we investigated which\ndesign choices in this prompt are the most important. Our conclusions raise the\nassumed limit of LLMs for robotics, and we reveal for the first time that LLMs\ndo indeed possess an understanding of low-level robot control sufficient for a\nrange of common tasks, and that they can additionally detect failures and then\nre-plan trajectories accordingly. Videos, prompts, and code are available at:\nhttps://www.robot-learning.uk/language-models-trajectory-generators.", "published": "2023-10-17 21:57:36", "link": "http://arxiv.org/abs/2310.11604v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "A High Fidelity and Low Complexity Neural Audio Coding", "abstract": "Audio coding is an essential module in the real-time communication system.\nNeural audio codecs can compress audio samples with a low bitrate due to the\nstrong modeling and generative capabilities of deep neural networks. To address\nthe poor high-frequency expression and high computational cost and storage\nconsumption, we proposed an integrated framework that utilizes a neural network\nto model wide-band components and adopts traditional signal processing to\ncompress high-band components according to psychological hearing knowledge.\nInspired by auditory perception theory, a perception-based loss function is\ndesigned to improve harmonic modeling. Besides, generative adversarial network\n(GAN) compression is proposed for the first time for neural audio codecs. Our\nmethod is superior to prior advanced neural codecs across subjective and\nobjective metrics and allows real-time inference on desktop and mobile.", "published": "2023-10-17 04:30:37", "link": "http://arxiv.org/abs/2310.10992v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Advanced accent/dialect identification and accentedness assessment with\n  multi-embedding models and automatic speech recognition", "abstract": "Accurately classifying accents and assessing accentedness in non-native\nspeakers are both challenging tasks due to the complexity and diversity of\naccent and dialect variations. In this study, embeddings from advanced\npre-trained language identification (LID) and speaker identification (SID)\nmodels are leveraged to improve the accuracy of accent classification and\nnon-native accentedness assessment. Findings demonstrate that employing\npre-trained LID and SID models effectively encodes accent/dialect information\nin speech. Furthermore, the LID and SID encoded accent information complement\nan end-to-end accent identification (AID) model trained from scratch. By\nincorporating all three embeddings, the proposed multi-embedding AID system\nachieves superior accuracy in accent identification. Next, we investigate\nleveraging automatic speech recognition (ASR) and accent identification models\nto explore accentedness estimation. The ASR model is an end-to-end\nconnectionist temporal classification (CTC) model trained exclusively with\nen-US utterances. The ASR error rate and en-US output of the AID model are\nleveraged as objective accentedness scores. Evaluation results demonstrate a\nstrong correlation between the scores estimated by the two models.\nAdditionally, a robust correlation between the objective accentedness scores\nand subjective scores based on human perception is demonstrated, providing\nevidence for the reliability and validity of utilizing AID-based and ASR-based\nsystems for accentedness assessment in non-native speech.", "published": "2023-10-17 05:13:46", "link": "http://arxiv.org/abs/2310.11004v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Leveraging Diverse Semantic-based Audio Pretrained Models for Singing\n  Voice Conversion", "abstract": "Singing Voice Conversion (SVC) is a technique that enables any singer to\nperform any song. To achieve this, it is essential to obtain speaker-agnostic\nrepresentations from the source audio, which poses a significant challenge. A\ncommon solution involves utilizing a semantic-based audio pretrained model as a\nfeature extractor. However, the degree to which the extracted features can meet\nthe SVC requirements remains an open question. This includes their capability\nto accurately model melody and lyrics, the speaker-independency of their\nunderlying acoustic information, and their robustness for in-the-wild acoustic\nenvironments. In this study, we investigate the knowledge within classical\nsemantic-based pretrained models in much detail. We discover that the knowledge\nof different models is diverse and can be complementary for SVC. Based on the\nabove, we design a Singing Voice Conversion framework based on Diverse\nSemantic-based Feature Fusion (DSFF-SVC). Experimental results demonstrate that\nDSFF-SVC can be generalized and improve various existing SVC models,\nparticularly in challenging real-world conversion tasks. Our demo website is\navailable at https://diversesemanticsvc.github.io/.", "published": "2023-10-17 11:26:28", "link": "http://arxiv.org/abs/2310.11160v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "High-Fidelity Noise Reduction with Differentiable Signal Processing", "abstract": "Noise reduction techniques based on deep learning have demonstrated\nimpressive performance in enhancing the overall quality of recorded speech.\nWhile these approaches are highly performant, their application in audio\nengineering can be limited due to a number of factors. These include operation\nonly on speech without support for music, lack of real-time capability, lack of\ninterpretable control parameters, operation at lower sample rates, and a\ntendency to introduce artifacts. On the other hand, signal processing-based\nnoise reduction algorithms offer fine-grained control and operation on a broad\nrange of content, however, they often require manual operation to achieve the\nbest results. To address the limitations of both approaches, in this work we\nintroduce a method that leverages a signal processing-based denoiser that when\ncombined with a neural network controller, enables fully automatic and\nhigh-fidelity noise reduction on both speech and music signals. We evaluate our\nproposed method with objective metrics and a perceptual listening test. Our\nevaluation reveals that speech enhancement models can be extended to music,\nhowever training the model to remove only stationary noise is critical.\nFurthermore, our proposed approach achieves performance on par with the deep\nlearning models, while being significantly more efficient and introducing fewer\nartifacts in some cases. Listening examples are available online at\nhttps://tape.it/research/denoiser .", "published": "2023-10-17 16:02:07", "link": "http://arxiv.org/abs/2310.11364v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Serenade: A Model for Human-in-the-loop Automatic Chord Estimation", "abstract": "Computational harmony analysis is important for MIR tasks such as automatic\nsegmentation, corpus analysis and automatic chord label estimation. However,\nrecent research into the ambiguous nature of musical harmony, causing limited\ninter-rater agreement, has made apparent that there is a glass ceiling for\ncommon metrics such as accuracy. Commonly, these issues are addressed either in\nthe training data itself by creating majority-rule annotations or during the\ntraining phase by learning soft targets. We propose a novel alternative\napproach in which a human and an autoregressive model together co-create a\nharmonic annotation for an audio track. After automatically generating harmony\npredictions, a human sparsely annotates parts with low model confidence and the\nmodel then adjusts its predictions following human guidance. We evaluate our\nmodel on a dataset of popular music and we show that, with this\nhuman-in-the-loop approach, harmonic analysis performance improves over a\nmodel-only approach. The human contribution is amplified by the second,\nconstrained prediction of the model.", "published": "2023-10-17 11:31:29", "link": "http://arxiv.org/abs/2310.11165v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Zipformer: A faster and better encoder for automatic speech recognition", "abstract": "The Conformer has become the most popular encoder model for automatic speech\nrecognition (ASR). It adds convolution modules to a transformer to learn both\nlocal and global dependencies. In this work we describe a faster, more\nmemory-efficient, and better-performing transformer, called Zipformer. Modeling\nchanges include: 1) a U-Net-like encoder structure where middle stacks operate\nat lower frame rates; 2) reorganized block structure with more modules, within\nwhich we re-use attention weights for efficiency; 3) a modified form of\nLayerNorm called BiasNorm allows us to retain some length information; 4) new\nactivation functions SwooshR and SwooshL work better than Swish. We also\npropose a new optimizer, called ScaledAdam, which scales the update by each\ntensor's current scale to keep the relative change about the same, and also\nexplictly learns the parameter scale. It achieves faster convergence and better\nperformance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and\nWenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer\nover other state-of-the-art ASR models. Our code is publicly available at\nhttps://github.com/k2-fsa/icefall.", "published": "2023-10-17 13:01:10", "link": "http://arxiv.org/abs/2310.11230v4", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "End-to-End real time tracking of children's reading with pointer network", "abstract": "In this work, we explore how a real time reading tracker can be built\nefficiently for children's voices. While previously proposed reading trackers\nfocused on ASR-based cascaded approaches, we propose a fully end-to-end model\nmaking it less prone to lags in voice tracking. We employ a pointer network\nthat directly learns to predict positions in the ground truth text conditioned\non the streaming speech. To train this pointer network, we generate ground\ntruth training signals by using forced alignment between the read speech and\nthe text being read on the training set. Exploring different forced alignment\nmodels, we find a neural attention based model is at least as close in\nalignment accuracy to the Montreal Forced Aligner, but surprisingly is a better\ntraining signal for the pointer network. Our results are reported on one adult\nspeech data (TIMIT) and two children's speech datasets (CMU Kids and Reading\nRaces). Our best model can accurately track adult speech with 87.8% accuracy\nand the much harder and disfluent children's speech with 77.1% accuracy on CMU\nKids data and a 65.3% accuracy on the Reading Races dataset.", "published": "2023-10-17 16:12:18", "link": "http://arxiv.org/abs/2310.11486v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
