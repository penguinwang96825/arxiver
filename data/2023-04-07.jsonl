{"title": "Hierarchical Catalogue Generation for Literature Review: A Benchmark", "abstract": "Scientific literature review generation aims to extract and organize\nimportant information from an abundant collection of reference papers and\nproduces corresponding reviews while lacking a clear and logical hierarchy. We\nobserve that a high-quality catalogue-guided generation process can effectively\nalleviate this problem. Therefore, we present an atomic and challenging task\nnamed Hierarchical Catalogue Generation for Literature Review as the first step\nfor review generation, which aims to produce a hierarchical catalogue of a\nreview paper given various references. We construct a novel English\nHierarchical Catalogues of Literature Reviews Dataset with 7.6k literature\nreview catalogues and 389k reference papers. To accurately assess the model\nperformance, we design two evaluation metrics for informativeness and\nsimilarity to ground truth from semantics and structure.Our extensive analyses\nverify the high quality of our dataset and the effectiveness of our evaluation\nmetrics. We further benchmark diverse experiments on state-of-the-art\nsummarization models like BART and large language models like ChatGPT to\nevaluate their capabilities. We further discuss potential directions for this\ntask to motivate future research.", "published": "2023-04-07 07:13:35", "link": "http://arxiv.org/abs/2304.03512v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InfoCTM: A Mutual Information Maximization Perspective of Cross-Lingual\n  Topic Modeling", "abstract": "Cross-lingual topic models have been prevalent for cross-lingual text\nanalysis by revealing aligned latent topics. However, most existing methods\nsuffer from producing repetitive topics that hinder further analysis and\nperformance decline caused by low-coverage dictionaries. In this paper, we\npropose the Cross-lingual Topic Modeling with Mutual Information (InfoCTM).\nInstead of the direct alignment in previous work, we propose a topic alignment\nwith mutual information method. This works as a regularization to properly\nalign topics and prevent degenerate topic representations of words, which\nmitigates the repetitive topic issue. To address the low-coverage dictionary\nissue, we further propose a cross-lingual vocabulary linking method that finds\nmore linked cross-lingual words for topic alignment beyond the translations of\na given dictionary. Extensive experiments on English, Chinese, and Japanese\ndatasets demonstrate that our method outperforms state-of-the-art baselines,\nproducing more coherent, diverse, and well-aligned topics and showing better\ntransferability for cross-lingual classification tasks.", "published": "2023-04-07 08:49:43", "link": "http://arxiv.org/abs/2304.03544v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GEMINI: Controlling the Sentence-level Writing Style for Abstractive\n  Text Summarization", "abstract": "Human experts write summaries using different techniques, including\nextracting a sentence from the document and rewriting it, or fusing various\ninformation from the document to abstract it. These techniques are flexible and\nthus difficult to be imitated by any single method. To address this issue, we\npropose an adaptive model, GEMINI, that integrates a rewriter and a generator\nto mimic the sentence rewriting and abstracting techniques, respectively.\nGEMINI adaptively chooses to rewrite a specific document sentence or generate a\nsummary sentence from scratch. Experiments demonstrate that our adaptive\napproach outperforms the pure abstractive and rewriting baselines on three\nbenchmark datasets, achieving the best results on WikiHow. Interestingly,\nempirical results show that the human summary styles of summary sentences are\nconsistently predictable given their context. We release our code and model at\n\\url{https://github.com/baoguangsheng/gemini}.", "published": "2023-04-07 08:57:01", "link": "http://arxiv.org/abs/2304.03548v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ArmanTTS single-speaker Persian dataset", "abstract": "TTS, or text-to-speech, is a complicated process that can be accomplished\nthrough appropriate modeling using deep learning methods. In order to implement\ndeep learning models, a suitable dataset is required. Since there is a scarce\namount of work done in this field for the Persian language, this paper will\nintroduce the single speaker dataset: ArmanTTS. We compared the characteristics\nof this dataset with those of various prevalent datasets to prove that ArmanTTS\nmeets the necessary standards for teaching a Persian text-to-speech conversion\nmodel. We also combined the Tacotron 2 and HiFi GAN to design a model that can\nreceive phonemes as input, with the output being the corresponding speech. 4.0\nvalue of MOS was obtained from real speech, 3.87 value was obtained by the\nvocoder prediction and 2.98 value was reached with the synthetic speech\ngenerated by the TTS model.", "published": "2023-04-07 10:52:55", "link": "http://arxiv.org/abs/2304.03585v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BenCoref: A Multi-Domain Dataset of Nominal Phrases and Pronominal\n  Reference Annotations", "abstract": "Coreference Resolution is a well studied problem in NLP. While widely studied\nfor English and other resource-rich languages, research on coreference\nresolution in Bengali largely remains unexplored due to the absence of relevant\ndatasets. Bengali, being a low-resource language, exhibits greater\nmorphological richness compared to English. In this article, we introduce a new\ndataset, BenCoref, comprising coreference annotations for Bengali texts\ngathered from four distinct domains. This relatively small dataset contains\n5200 mention annotations forming 502 mention clusters within 48,569 tokens. We\ndescribe the process of creating this dataset and report performance of\nmultiple models trained using BenCoref. We expect that our work provides some\nvaluable insights on the variations in coreference phenomena across several\ndomains in Bengali and encourages the development of additional resources for\nBengali. Furthermore, we found poor crosslingual performance at zero-shot\nsetting from English, highlighting the need for more language-specific\nresources for this task.", "published": "2023-04-07 15:08:46", "link": "http://arxiv.org/abs/2304.03682v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable Unified Language Checking", "abstract": "Despite recent concerns about undesirable behaviors generated by large\nlanguage models (LLMs), including non-factual, biased, and hateful language, we\nfind LLMs are inherent multi-task language checkers based on their latent\nrepresentations of natural and social knowledge. We present an interpretable,\nunified, language checking (UniLC) method for both human and machine-generated\nlanguage that aims to check if language input is factual and fair. While\nfairness and fact-checking tasks have been handled separately with dedicated\nmodels, we find that LLMs can achieve high performance on a combination of\nfact-checking, stereotype detection, and hate speech detection tasks with a\nsimple, few-shot, unified set of prompts. With the ``1/2-shot'' multi-task\nlanguage checking method proposed in this work, the GPT3.5-turbo model\noutperforms fully supervised baselines on several language tasks. The simple\napproach and results suggest that based on strong latent knowledge\nrepresentations, an LLM can be an adaptive and explainable tool for detecting\nmisinformation, stereotypes, and hate speech.", "published": "2023-04-07 16:47:49", "link": "http://arxiv.org/abs/2304.03728v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gated Mechanism Enhanced Multi-Task Learning for Dialog Routing", "abstract": "Currently, human-bot symbiosis dialog systems, e.g., pre- and after-sales in\nE-commerce, are ubiquitous, and the dialog routing component is essential to\nimprove the overall efficiency, reduce human resource cost, and enhance user\nexperience. Although most existing methods can fulfil this requirement, they\ncan only model single-source dialog data and cannot effectively capture the\nunderlying knowledge of relations among data and subtasks. In this paper, we\ninvestigate this important problem by thoroughly mining both the data-to-task\nand task-to-task knowledge among various kinds of dialog data. To achieve the\nabove targets, we propose a Gated Mechanism enhanced Multi-task Model (G3M),\nspecifically including a novel dialog encoder and two tailored gated mechanism\nmodules. The proposed method can play the role of hierarchical information\nfiltering and is non-invasive to existing dialog systems. Based on two datasets\ncollected from real world applications, extensive experimental results\ndemonstrate the effectiveness of our method, which achieves the\nstate-of-the-art performance by improving 8.7\\%/11.8\\% on RMSE metric and\n2.2\\%/4.4\\% on F1 metric.", "published": "2023-04-07 16:51:46", "link": "http://arxiv.org/abs/2304.03730v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expectations over Unspoken Alternatives Predict Pragmatic Inferences", "abstract": "Scalar inferences (SI) are a signature example of how humans interpret\nlanguage based on unspoken alternatives. While empirical studies have\ndemonstrated that human SI rates are highly variable -- both within instances\nof a single scale, and across different scales -- there have been few proposals\nthat quantitatively explain both cross- and within-scale variation.\nFurthermore, while it is generally assumed that SIs arise through reasoning\nabout unspoken alternatives, it remains debated whether humans reason about\nalternatives as linguistic forms, or at the level of concepts. Here, we test a\nshared mechanism explaining SI rates within and across scales: context-driven\nexpectations about the unspoken alternatives. Using neural language models to\napproximate human predictive distributions, we find that SI rates are captured\nby the expectedness of the strong scalemate as an alternative. Crucially,\nhowever, expectedness robustly predicts cross-scale variation only under a\nmeaning-based view of alternatives. Our results suggest that pragmatic\ninferences arise from context-driven expectations over alternatives, and these\nexpectations operate at the level of concepts.", "published": "2023-04-07 18:12:22", "link": "http://arxiv.org/abs/2304.04758v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4", "abstract": "Harnessing logical reasoning ability is a comprehensive natural language\nunderstanding endeavor. With the release of Generative Pretrained Transformer 4\n(GPT-4), highlighted as \"advanced\" at reasoning tasks, we are eager to learn\nthe GPT-4 performance on various logical reasoning tasks. This report analyses\nmultiple logical reasoning datasets, with popular benchmarks like LogiQA and\nReClor, and newly-released datasets like AR-LSAT. We test the multi-choice\nreading comprehension and natural language inference tasks with benchmarks\nrequiring logical reasoning. We further construct a logical reasoning\nout-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4.\nWe also make a performance comparison between ChatGPT and GPT-4. Experiment\nresults show that ChatGPT performs significantly better than the RoBERTa\nfine-tuning method on most logical reasoning benchmarks. With early access to\nthe GPT-4 API we are able to conduct intense experiments on the GPT-4 model.\nThe results show GPT-4 yields even higher performance on most logical reasoning\ndatasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known\ndatasets like LogiQA and ReClor. However, the performance drops significantly\nwhen handling newly released and out-of-distribution datasets. Logical\nreasoning remains challenging for ChatGPT and GPT-4, especially on\nout-of-distribution and natural language inference datasets. We release the\nprompt-style logical reasoning datasets as a benchmark suite and name it\nLogiEval.", "published": "2023-04-07 01:37:45", "link": "http://arxiv.org/abs/2304.03439v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Retrieval to Generation: Efficient and Effective Entity Set\n  Expansion", "abstract": "Entity Set Expansion (ESE) is a critical task aiming at expanding entities of\nthe target semantic class described by seed entities. Most existing ESE methods\nare retrieval-based frameworks that need to extract contextual features of\nentities and calculate the similarity between seed entities and candidate\nentities. To achieve the two purposes, they iteratively traverse the corpus and\nthe entity vocabulary, resulting in poor efficiency and scalability.\nExperimental results indicate that the time consumed by the retrieval-based ESE\nmethods increases linearly with entity vocabulary and corpus size. In this\npaper, we firstly propose Generative Entity Set Expansion (GenExpan) framework,\nwhich utilizes a generative pre-trained auto-regressive language model to\naccomplish ESE task. Specifically, a prefix tree is employed to guarantee the\nvalidity of entity generation, and automatically generated class names are\nadopted to guide the model to generate target entities. Moreover, we propose\nKnowledge Calibration and Generative Ranking to further bridge the gap between\ngeneric knowledge of the language model and the goal of ESE task. For\nefficiency, expansion time consumed by GenExpan is independent of entity\nvocabulary and corpus size, and GenExpan achieves an average 600% speedup\ncompared to strong baselines. For expansion effectiveness, our framework\noutperforms previous state-of-the-art ESE methods.", "published": "2023-04-07 08:09:50", "link": "http://arxiv.org/abs/2304.03531v4", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Revisiting Automated Prompting: Are We Actually Doing Better?", "abstract": "Current literature demonstrates that Large Language Models (LLMs) are great\nfew-shot learners, and prompting significantly increases their performance on a\nrange of downstream tasks in a few-shot learning setting. An attempt to\nautomate human-led prompting followed, with some progress achieved. In\nparticular, subsequent work demonstrates automation can outperform fine-tuning\nin certain K-shot learning scenarios.\n  In this paper, we revisit techniques for automated prompting on six different\ndownstream tasks and a larger range of K-shot learning settings. We find that\nautomated prompting does not consistently outperform simple manual prompts. Our\nwork suggests that, in addition to fine-tuning, manual prompts should be used\nas a baseline in this line of research.", "published": "2023-04-07 12:06:44", "link": "http://arxiv.org/abs/2304.03609v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language\n  Models", "abstract": "As the capabilities of generative language models continue to advance, the\nimplications of biases ingrained within these models have garnered increasing\nattention from researchers, practitioners, and the broader public. This article\ninvestigates the challenges and risks associated with biases in large-scale\nlanguage models like ChatGPT. We discuss the origins of biases, stemming from,\namong others, the nature of training data, model specifications, algorithmic\nconstraints, product design, and policy decisions. We explore the ethical\nconcerns arising from the unintended consequences of biased model outputs. We\nfurther analyze the potential opportunities to mitigate biases, the\ninevitability of some biases, and the implications of deploying these models in\nvarious applications, such as virtual assistants, content generation, and\nchatbots. Finally, we review the current approaches to identify, quantify, and\nmitigate biases in language models, emphasizing the need for a\nmulti-disciplinary, collaborative effort to develop more equitable,\ntransparent, and responsible AI systems. This article aims to stimulate a\nthoughtful dialogue within the artificial intelligence community, encouraging\nresearchers and developers to reflect on the role of biases in generative\nlanguage models and the ongoing pursuit of ethical AI.", "published": "2023-04-07 17:14:00", "link": "http://arxiv.org/abs/2304.03738v3", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Language Models are Causal Knowledge Extractors for Zero-shot Video\n  Question Answering", "abstract": "Causal Video Question Answering (CVidQA) queries not only association or\ntemporal relations but also causal relations in a video. Existing question\nsynthesis methods pre-trained question generation (QG) systems on reading\ncomprehension datasets with text descriptions as inputs. However, QG models\nonly learn to ask association questions (e.g., ``what is someone doing...'')\nand result in inferior performance due to the poor transfer of association\nknowledge to CVidQA, which focuses on causal questions like ``why is someone\ndoing ...''. Observing this, we proposed to exploit causal knowledge to\ngenerate question-answer pairs, and proposed a novel framework, Causal\nKnowledge Extraction from Language Models (CaKE-LM), leveraging causal\ncommonsense knowledge from language models to tackle CVidQA. To extract\nknowledge from LMs, CaKE-LM generates causal questions containing two events\nwith one triggering another (e.g., ``score a goal'' triggers ``soccer player\nkicking ball'') by prompting LM with the action (soccer player kicking ball) to\nretrieve the intention (to score a goal). CaKE-LM significantly outperforms\nconventional methods by 4% to 6% of zero-shot CVidQA accuracy on NExT-QA and\nCausal-VidQA datasets. We also conduct comprehensive analyses and provide key\nfindings for future research.", "published": "2023-04-07 17:45:49", "link": "http://arxiv.org/abs/2304.03754v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Bridging Nations: Quantifying the Role of Multilinguals in Communication\n  on Social Media", "abstract": "Social media enables the rapid spread of many kinds of information, from\nmemes to social movements. However, little is known about how information\ncrosses linguistic boundaries. We apply causal inference techniques on the\nEuropean Twitter network to quantify multilingual users' structural role and\ncommunication influence in cross-lingual information exchange. Overall,\nmultilinguals play an essential role; posting in multiple languages increases\nbetweenness centrality by 13%, and having a multilingual network neighbor\nincreases monolinguals' odds of sharing domains and hashtags from another\nlanguage 16-fold and 4-fold, respectively. We further show that multilinguals\nhave a greater impact on diffusing information less accessible to their\nmonolingual compatriots, such as information from far-away countries and\ncontent about regional politics, nascent social movements, and job\nopportunities. By highlighting information exchange across borders, this work\nsheds light on a crucial component of how information and ideas spread around\nthe world.", "published": "2023-04-07 18:01:25", "link": "http://arxiv.org/abs/2304.03797v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Cleansing Jewel: A Neural Spelling Correction Model Built On Google\n  OCR-ed Tibetan Manuscripts", "abstract": "Scholars in the humanities rely heavily on ancient manuscripts to study\nhistory, religion, and socio-political structures in the past. Many efforts\nhave been devoted to digitizing these precious manuscripts using OCR\ntechnology, but most manuscripts were blemished over the centuries so that an\nOptical Character Recognition (OCR) program cannot be expected to capture faded\ngraphs and stains on pages. This work presents a neural spelling correction\nmodel built on Google OCR-ed Tibetan Manuscripts to auto-correct OCR-ed noisy\noutput. This paper is divided into four sections: dataset, model architecture,\ntraining and analysis. First, we feature-engineered our raw Tibetan etext\ncorpus into two sets of structured data frames -- a set of paired toy data and\na set of paired real data. Then, we implemented a Confidence Score mechanism\ninto the Transformer architecture to perform spelling correction tasks.\nAccording to the Loss and Character Error Rate, our Transformer + Confidence\nscore mechanism architecture proves to be superior to Transformer, LSTM-2-LSTM\nand GRU-2-GRU architectures. Finally, to examine the robustness of our model,\nwe analyzed erroneous tokens, visualized Attention and Self-Attention heatmaps\nin our model.", "published": "2023-04-07 00:45:12", "link": "http://arxiv.org/abs/2304.03427v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Linking Representations with Multimodal Contrastive Learning", "abstract": "Many applications require linking individuals, firms, or locations across\ndatasets. Most widely used methods, especially in social science, do not employ\ndeep learning, with record linkage commonly approached using string matching\ntechniques. Moreover, existing methods do not exploit the inherently multimodal\nnature of documents. In historical record linkage applications, documents are\ntypically noisily transcribed by optical character recognition (OCR). Linkage\nwith just OCR'ed texts may fail due to noise, whereas linkage with just image\ncrops may also fail because vision models lack language understanding (e.g., of\nabbreviations or other different ways of writing firm names). To leverage\nmultimodal learning, this study develops CLIPPINGS (Contrastively LInking\nPooled Pre-trained Embeddings). CLIPPINGS aligns symmetric vision and language\nbi-encoders, through contrastive language-image pre-training on document images\nand their corresponding OCR'ed texts. It then contrastively learns a metric\nspace where the pooled image-text embedding for a given instance is close to\nembeddings in the same class (e.g., the same firm or location) and distant from\nembeddings of a different class. Data are linked by treating linkage as a\nnearest neighbor retrieval problem with the multimodal embeddings. CLIPPINGS\noutperforms widely used string matching methods by a wide margin in linking\nmid-20th century Japanese firms across financial documents. A purely\nself-supervised model - trained only by aligning the embeddings for the image\ncrop of a firm name and its corresponding OCR'ed text - also outperforms\npopular string matching methods. Fascinatingly, a multimodally pre-trained\nvision-only encoder outperforms a unimodally pre-trained vision-only encoder,\nillustrating the power of multimodal pre-training even if only one modality is\navailable for linking at inference time.", "published": "2023-04-07 03:39:08", "link": "http://arxiv.org/abs/2304.03464v3", "categories": ["cs.CV", "cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "cs.CV"}
{"title": "SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism\n  using Majority Voted Fine-Tuned Transformers", "abstract": "This paper describes our submission to Task 10 at SemEval 2023-Explainable\nDetection of Online Sexism (EDOS), divided into three subtasks. The recent rise\nin social media platforms has seen an increase in disproportionate levels of\nsexism experienced by women on social media platforms. This has made detecting\nand explaining online sexist content more important than ever to make social\nmedia safer and more accessible for women. Our approach consists of\nexperimenting and finetuning BERT-based models and using a Majority Voting\nensemble model that outperforms individual baseline model scores. Our system\nachieves a macro F1 score of 0.8392 for Task A, 0.6092 for Task B, and 0.4319\nfor Task C.", "published": "2023-04-07 07:24:32", "link": "http://arxiv.org/abs/2304.03518v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What does ChatGPT return about human values? Exploring value bias in\n  ChatGPT using a descriptive value theory", "abstract": "There has been concern about ideological basis and possible discrimination in\ntext generated by Large Language Models (LLMs). We test possible value biases\nin ChatGPT using a psychological value theory. We designed a simple experiment\nin which we used a number of different probes derived from the Schwartz basic\nvalue theory (items from the revised Portrait Value Questionnaire, the value\ntype definitions, value names). We prompted ChatGPT via the OpenAI API\nrepeatedly to generate text and then analyzed the generated corpus for value\ncontent with a theory-driven value dictionary using a bag of words approach.\nOverall, we found little evidence of explicit value bias. The results showed\nsufficient construct and discriminant validity for the generated text in line\nwith the theoretical predictions of the psychological model, which suggests\nthat the value content was carried through into the outputs with high fidelity.\nWe saw some merging of socially oriented values, which may suggest that these\nvalues are less clearly differentiated at a linguistic level or alternatively,\nthis mixing may reflect underlying universal human motivations. We outline some\npossible applications of our findings for both applications of ChatGPT for\ncorporate usage and policy making as well as future research avenues. We also\nhighlight possible implications of this relatively high-fidelity replication of\nmotivational content using a linguistic model for the theorizing about human\nvalues.", "published": "2023-04-07 12:20:13", "link": "http://arxiv.org/abs/2304.03612v1", "categories": ["cs.CL", "cs.CY", "cs.HC", "68T50"], "primary_category": "cs.CL"}
{"title": "Theoretical Conditions and Empirical Failure of Bracket Counting on Long\n  Sequences with Linear Recurrent Networks", "abstract": "Previous work has established that RNNs with an unbounded activation function\nhave the capacity to count exactly. However, it has also been shown that RNNs\nare challenging to train effectively and generally do not learn exact counting\nbehaviour. In this paper, we focus on this problem by studying the simplest\npossible RNN, a linear single-cell network. We conduct a theoretical analysis\nof linear RNNs and identify conditions for the models to exhibit exact counting\nbehaviour. We provide a formal proof that these conditions are necessary and\nsufficient. We also conduct an empirical analysis using tasks involving a\nDyck-1-like Balanced Bracket language under two different settings. We observe\nthat linear RNNs generally do not meet the necessary and sufficient conditions\nfor counting behaviour when trained with the standard approach. We investigate\nhow varying the length of training sequences and utilising different target\nclasses impacts model behaviour during training and the ability of linear RNN\nmodels to effectively approximate the indicator conditions.", "published": "2023-04-07 13:42:17", "link": "http://arxiv.org/abs/2304.03639v1", "categories": ["cs.LG", "cs.CL", "cs.FL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "On the Importance of Contrastive Loss in Multimodal Learning", "abstract": "Recently, contrastive learning approaches (e.g., CLIP (Radford et al., 2021))\nhave received huge success in multimodal learning, where the model tries to\nminimize the distance between the representations of different views (e.g.,\nimage and its caption) of the same data point while keeping the representations\nof different data points away from each other. However, from a theoretical\nperspective, it is unclear how contrastive learning can learn the\nrepresentations from different views efficiently, especially when the data is\nnot isotropic. In this work, we analyze the training dynamics of a simple\nmultimodal contrastive learning model and show that contrastive pairs are\nimportant for the model to efficiently balance the learned representations. In\nparticular, we show that the positive pairs will drive the model to align the\nrepresentations at the cost of increasing the condition number, while the\nnegative pairs will reduce the condition number, keeping the learned\nrepresentations balanced.", "published": "2023-04-07 16:25:18", "link": "http://arxiv.org/abs/2304.03717v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Why think step by step? Reasoning emerges from the locality of\n  experience", "abstract": "Humans have a powerful and mysterious capacity to reason. Working through a\nset of mental steps enables us to make inferences we would not be capable of\nmaking directly even though we get no additional data from the world.\nSimilarly, when large language models generate intermediate steps (a chain of\nthought) before answering a question, they often produce better answers than\nthey would directly. We investigate why and how chain-of-thought reasoning is\nuseful in language models, testing the hypothesis that reasoning is effective\nwhen training data consists of overlapping local clusters of variables that\ninfluence each other strongly. These training conditions enable the chaining of\naccurate local inferences to estimate relationships between variables that were\nnot seen together in training. We prove that there will exist a \"reasoning\ngap\", where reasoning through intermediate variables reduces bias, for the\nsimple case of an autoregressive density estimator trained on local samples\nfrom a chain-structured probabilistic model. We then test our hypothesis\nexperimentally in more complex models, training an autoregressive language\nmodel on samples from Bayes nets but only including a subset of variables in\neach sample. We test language models' ability to match conditional\nprobabilities with and without intermediate reasoning steps, finding that\nintermediate steps are only helpful when the training data is locally\nstructured with respect to dependencies between variables. The combination of\nlocally structured observations and reasoning is much more data-efficient than\ntraining on all variables. Our results illustrate how the effectiveness of\nreasoning step by step is rooted in the local statistical structure of the\ntraining data.", "published": "2023-04-07 21:04:03", "link": "http://arxiv.org/abs/2304.03843v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Profiling the news spreading barriers using news headlines", "abstract": "News headlines can be a good data source for detecting the news spreading\nbarriers in news media, which may be useful in many real-world applications. In\nthis paper, we utilize semantic knowledge through the inference-based model\nCOMET and sentiments of news headlines for barrier classification. We consider\nfive barriers including cultural, economic, political, linguistic, and\ngeographical, and different types of news headlines including health, sports,\nscience, recreation, games, homes, society, shopping, computers, and business.\nTo that end, we collect and label the news headlines automatically for the\nbarriers using the metadata of news publishers. Then, we utilize the extracted\ncommonsense inferences and sentiments as features to detect the news spreading\nbarriers. We compare our approach to the classical text classification methods,\ndeep learning, and transformer-based methods. The results show that the\nproposed approach using inferences-based semantic knowledge and sentiment\noffers better performance than the usual (the average F1-score of the ten\ncategories improves from 0.41, 0.39, 0.59, and 0.59 to 0.47, 0.55, 0.70, and\n0.76 for the cultural, economic, political, and geographical respectively) for\nclassifying the news-spreading barriers.", "published": "2023-04-07 10:16:15", "link": "http://arxiv.org/abs/2304.11088v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Margin-Mixup: A Method for Robust Speaker Verification in Multi-Speaker\n  Audio", "abstract": "This paper is concerned with the task of speaker verification on audio with\nmultiple overlapping speakers. Most speaker verification systems are designed\nwith the assumption of a single speaker being present in a given audio segment.\nHowever, in a real-world setting this assumption does not always hold. In this\npaper, we demonstrate that current speaker verification systems are not robust\nagainst audio with noticeable speaker overlap. To alleviate this issue, we\npropose margin-mixup, a simple training strategy that can easily be adopted by\nexisting speaker verification pipelines to make the resulting speaker\nembeddings robust against multi-speaker audio. In contrast to other methods,\nmargin-mixup requires no alterations to regular speaker verification\narchitectures, while attaining better results. On our multi-speaker test set\nbased on VoxCeleb1, the proposed margin-mixup strategy improves the EER on\naverage with 44.4% relative to our state-of-the-art speaker verification\nbaseline systems.", "published": "2023-04-07 07:19:45", "link": "http://arxiv.org/abs/2304.03515v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "On-site Noise Exposure technique for noise-robust machine fault\n  classification", "abstract": "In-situ classification of faulty sounds is an important issue in machine\nhealth monitoring and diagnosis. However, in a noisy environment such as a\nfactory, machine sound is always mixed up with environmental noises, and\nnoise-only periods can exist when a machine is not in operation. Therefore, a\ndeep neural network (DNN)-based fault classifier has to be able to distinguish\nnoise from machine sound and be robust to mixed noises. To deal with these\nproblems, we investigate on-site noise exposure (ONE) that exposes a DNN model\nto the noises recorded in the same environment where the machine operates. Like\nthe outlier exposure technique, noise exposure trains a DNN classifier to\nproduce a uniform predicted probability distribution against noise-only data.\nDuring inference, the DNN classifier trained by ONE outputs the maximum softmax\nprobability as the noise score and determines the noise-only period. We mix\nmachine sound and noises of the ToyADMOS2 dataset to simulate highly noisy\ndata. A ResNet-based classifier trained by ONE is evaluated and compared with\nthose trained by other out-of-distribution detection techniques. The test\nresults show that exposing a model to on-site noises can make a model more\nrobust than using other noises or detection techniques.", "published": "2023-04-07 07:35:52", "link": "http://arxiv.org/abs/2304.03522v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Graph Attention for Automated Audio Captioning", "abstract": "State-of-the-art audio captioning methods typically use the encoder-decoder\nstructure with pretrained audio neural networks (PANNs) as encoders for feature\nextraction. However, the convolution operation used in PANNs is limited in\ncapturing the long-time dependencies within an audio signal, thereby leading to\npotential performance degradation in audio captioning. This letter presents a\nnovel method using graph attention (GraphAC) for encoder-decoder based audio\ncaptioning. In the encoder, a graph attention module is introduced after the\nPANNs to learn contextual association (i.e. the dependency among the audio\nfeatures over different time frames) through an adjacency graph, and a top-k\nmask is used to mitigate the interference from noisy nodes. The learnt\ncontextual association leads to a more effective feature representation with\nfeature node aggregation. As a result, the decoder can predict important\nsemantic information about the acoustic scene and events based on the\ncontextual associations learned from the audio signal. Experimental results\nshow that GraphAC outperforms the state-of-the-art methods with PANNs as the\nencoders, thanks to the incorporation of the graph attention module into the\nencoder for capturing the long-time dependencies within the audio signal. The\nsource code is available at https://github.com/LittleFlyingSheep/GraphAC.", "published": "2023-04-07 10:58:12", "link": "http://arxiv.org/abs/2304.03586v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An unsupervised segmentation of vocal breath sounds", "abstract": "Breathing is an essential part of human survival, which carries information\nabout a person's physiological and psychological state. Generally, breath\nboundaries are marked by experts before using for any task. An unsupervised\nalgorithm for breath boundary detection has been proposed for breath sounds\nrecorded at the mouth also referred as vocal breath sounds (VBS) in this work.\nBreath sounds recorded at the mouth are used in this work because they are easy\nand contactless to record than tracheal breath sounds and lung breath sounds.\nThe periodic nature of breath signal energy is used to segment the breath\nboundaries. Dynamic programming with the prior information of the number of\nbreath phases($P$) and breath phase duration($d$) is used to find the\nboundaries. In this work, 367 breath boundaries from 60 subjects (31 healthy,\n29 patients) having 307 breaths are predicted. With the proposed method, M\n($89\\%$), I ($13\\%$), D ($11\\%$) and S ($79\\%$) is found. The proposed method\nshows better performance than the baselines used in this work. Even the\nclassification performance between asthmatic and healthy subjects using\nestimated boundaries by the proposed method is comparable with the ground truth\nboundaries.", "published": "2023-04-07 17:53:08", "link": "http://arxiv.org/abs/2304.03758v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Anomalous Sound Detection using Audio Representation with Machine ID\n  based Contrastive Learning Pretraining", "abstract": "Existing contrastive learning methods for anomalous sound detection refine\nthe audio representation of each audio sample by using the contrast between the\nsamples' augmentations (e.g., with time or frequency masking). However, they\nmight be biased by the augmented data, due to the lack of physical properties\nof machine sound, thereby limiting the detection performance. This paper uses\ncontrastive learning to refine audio representations for each machine ID,\nrather than for each audio sample. The proposed two-stage method uses\ncontrastive learning to pretrain the audio representation model by\nincorporating machine ID and a self-supervised ID classifier to fine-tune the\nlearnt model, while enhancing the relation between audio features from the same\nID. Experiments show that our method outperforms the state-of-the-art methods\nusing contrastive learning or self-supervised classification in overall anomaly\ndetection performance and stability on DCASE 2020 Challenge Task2 dataset.", "published": "2023-04-07 11:08:31", "link": "http://arxiv.org/abs/2304.03588v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Benchmark Dataset Dynamics, Bias and Privacy Challenges in Voice\n  Biometrics Research", "abstract": "Speaker recognition is a widely used voice-based biometric technology with\napplications in various industries, including banking, education, recruitment,\nimmigration, law enforcement, healthcare, and well-being. However, while\ndataset evaluations and audits have improved data practices in face recognition\nand other computer vision tasks, the data practices in speaker recognition have\ngone largely unquestioned. Our research aims to address this gap by exploring\nhow dataset usage has evolved over time and what implications this has on bias,\nfairness and privacy in speaker recognition systems. Previous studies have\ndemonstrated the presence of historical, representation, and measurement biases\nin popular speaker recognition benchmarks. In this paper, we present a\nlongitudinal study of speaker recognition datasets used for training and\nevaluation from 2012 to 2021. We survey close to 700 papers to investigate\ncommunity adoption of datasets and changes in usage over a crucial time period\nwhere speaker recognition approaches transitioned to the widespread adoption of\ndeep neural networks. Our study identifies the most commonly used datasets in\nthe field, examines their usage patterns, and assesses their attributes that\naffect bias, fairness, and other ethical concerns. Our findings suggest areas\nfor further research on the ethics and fairness of speaker recognition\ntechnology.", "published": "2023-04-07 23:05:37", "link": "http://arxiv.org/abs/2304.03858v4", "categories": ["cs.CY", "cs.SD", "eess.AS"], "primary_category": "cs.CY"}
