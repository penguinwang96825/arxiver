{"title": "Meta-path Augmented Response Generation", "abstract": "We propose a chatbot, namely Mocha to make good use of relevant entities when\ngenerating responses. Augmented with meta-path information, Mocha is able to\nmention proper entities following the conversation flow.", "published": "2018-11-02 01:06:14", "link": "http://arxiv.org/abs/1811.00693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence Generation with Guider Network", "abstract": "Sequence generation with reinforcement learning (RL) has received significant\nattention recently. However, a challenge with such methods is the sparse-reward\nproblem in the RL training process, in which a scalar guiding signal is often\nonly available after an entire sequence has been generated. This type of sparse\nreward tends to ignore the global structural information of a sequence, causing\ngeneration of sequences that are semantically inconsistent. In this paper, we\npresent a model-based RL approach to overcome this issue. Specifically, we\npropose a novel guider network to model the sequence-generation environment,\nwhich can assist next-word prediction and provide intermediate rewards for\ngenerator optimization. Extensive experiments show that the proposed method\nleads to improved performance for both unconditional and conditional\nsequence-generation tasks.", "published": "2018-11-02 01:21:17", "link": "http://arxiv.org/abs/1811.00696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math\n  Word Problems", "abstract": "Solving math word problems is a challenging task that requires accurate\nnatural language understanding to bridge natural language texts and math\nexpressions. Motivated by the intuition about how human generates the equations\ngiven the problem texts, this paper presents a neural approach to automatically\nsolve math word problems by operating symbols according to their semantic\nmeanings in texts. This paper views the process of generating equation as a\nbridge between the semantic world and the symbolic world, where the proposed\nneural math solver is based on an encoder-decoder framework. In the proposed\nmodel, the encoder is designed to understand the semantics of problems, and the\ndecoder focuses on tracking semantic meanings of the generated symbols and then\ndeciding which symbol to generate next. The preliminary experiments are\nconducted in a dataset Math23K, and our model significantly outperforms both\nthe state-of-the-art single model and the best non-retrieval-based model over\nabout 10% accuracy, demonstrating the effectiveness of bridging the symbolic\nand semantic worlds from math word problems.", "published": "2018-11-02 03:04:21", "link": "http://arxiv.org/abs/1811.00720v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving the Robustness of Speech Translation", "abstract": "Although neural machine translation (NMT) has achieved impressive progress\nrecently, it is usually trained on the clean parallel data set and hence cannot\nwork well when the input sentence is the production of the automatic speech\nrecognition (ASR) system due to the enormous errors in the source. To solve\nthis problem, we propose a simple but effective method to improve the\nrobustness of NMT in the case of speech translation. We simulate the noise\nexisting in the realistic output of the ASR system and inject them into the\nclean parallel data so that NMT can work under similar word distributions\nduring training and testing. Besides, we also incorporate the Chinese Pinyin\nfeature which is easy to get in speech translation to further improve the\ntranslation performance. Experiment results show that our method has a more\nstable performance and outperforms the baseline by an average of 3.12 BLEU on\nmultiple noisy test sets, even while achieves a generalization improvement on\nthe WMT'17 Chinese-English test set.", "published": "2018-11-02 03:56:42", "link": "http://arxiv.org/abs/1811.00728v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Abstractive Summarization of Reddit Posts with Multi-level Memory\n  Networks", "abstract": "We address the problem of abstractive summarization in two directions:\nproposing a novel dataset and a new model. First, we collect Reddit TIFU\ndataset, consisting of 120K posts from the online discussion forum Reddit. We\nuse such informal crowd-generated posts as text source, in contrast with\nexisting datasets that mostly use formal documents as source such as news\narticles. Thus, our dataset could less suffer from some biases that key\nsentences usually locate at the beginning of the text and favorable summary\ncandidates are already inside the text in similar forms. Second, we propose a\nnovel abstractive summarization model named multi-level memory networks (MMN),\nequipped with multi-level memory to store the information of text from\ndifferent levels of abstraction. With quantitative evaluation and user studies\nvia Amazon Mechanical Turk, we show the Reddit TIFU dataset is highly\nabstractive and the MMN outperforms the state-of-the-art summarization models.", "published": "2018-11-02 08:59:19", "link": "http://arxiv.org/abs/1811.00783v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Training of End-to-end Speech Recognition Using a\n  Criticizing Language Model", "abstract": "In this paper we proposed a novel Adversarial Training (AT) approach for\nend-to-end speech recognition using a Criticizing Language Model (CLM). In this\nway the CLM and the automatic speech recognition (ASR) model can challenge and\nlearn from each other iteratively to improve the performance. Since the CLM\nonly takes the text as input, huge quantities of unpaired text data can be\nutilized in this approach within end-to-end training. Moreover, AT can be\napplied to any end-to-end ASR model using any deep-learning-based language\nmodeling frameworks, and compatible with any existing end-to-end decoding\nmethod. Initial results with an example experimental setup demonstrated the\nproposed approach is able to gain consistent improvements efficiently from\nauxiliary text data under different scenarios.", "published": "2018-11-02 09:10:24", "link": "http://arxiv.org/abs/1811.00787v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Progress and Tradeoffs in Neural Language Models", "abstract": "In recent years, we have witnessed a dramatic shift towards techniques driven\nby neural networks for a variety of NLP tasks. Undoubtedly, neural language\nmodels (NLMs) have reduced perplexity by impressive amounts. This progress,\nhowever, comes at a substantial cost in performance, in terms of inference\nlatency and energy consumption, which is particularly of concern in deployments\non mobile devices. This paper, which examines the quality-performance tradeoff\nof various language modeling techniques, represents to our knowledge the first\nto make this observation. We compare state-of-the-art NLMs with \"classic\"\nKneser-Ney (KN) LMs in terms of energy usage, latency, perplexity, and\nprediction accuracy using two standard benchmarks. On a Raspberry Pi, we find\nthat orders of increase in latency and energy usage correspond to less change\nin perplexity, while the difference is much less pronounced on a desktop.", "published": "2018-11-02 15:46:52", "link": "http://arxiv.org/abs/1811.00942v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Image Chat: Engaging Grounded Conversations", "abstract": "To achieve the long-term goal of machines being able to engage humans in\nconversation, our models should captivate the interest of their speaking\npartners. Communication grounded in images, whereby a dialogue is conducted\nbased on a given photo, is a setup naturally appealing to humans (Hu et al.,\n2014). In this work we study large-scale architectures and datasets for this\ngoal. We test a set of neural architectures using state-of-the-art image and\ntext representations, considering various ways to fuse the components. To test\nsuch models, we collect a dataset of grounded human-human conversations, where\nspeakers are asked to play roles given a provided emotional mood or style, as\nthe use of such traits is also a key factor in engagingness (Guo et al., 2019).\nOur dataset, Image-Chat, consists of 202k dialogues over 202k images using 215\npossible style traits. Automatic metrics and human evaluations of engagingness\nshow the efficacy of our approach; in particular, we obtain state-of-the-art\nperformance on the existing IGC task, and our best performing model is almost\non par with humans on the Image-Chat test set (preferred 47.7% of the time).", "published": "2018-11-02 15:54:15", "link": "http://arxiv.org/abs/1811.00945v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving the Coverage and the Generalization Ability of Neural Word\n  Sense Disambiguation through Hypernymy and Hyponymy Relationships", "abstract": "In Word Sense Disambiguation (WSD), the predominant approach generally\ninvolves a supervised system trained on sense annotated corpora. The limited\nquantity of such corpora however restricts the coverage and the performance of\nthese systems. In this article, we propose a new method that solves these\nissues by taking advantage of the knowledge present in WordNet, and especially\nthe hypernymy and hyponymy relationships between synsets, in order to reduce\nthe number of different sense tags that are necessary to disambiguate all words\nof the lexical database. Our method leads to state of the art results on most\nWSD evaluation tasks, while improving the coverage of supervised systems,\nreducing the training time and the size of the models, without additional\ntraining data. In addition, we exhibit results that significantly outperform\nthe state of the art when our method is combined with an ensembling technique\nand the addition of the WordNet Gloss Tagged as training corpus.", "published": "2018-11-02 16:20:13", "link": "http://arxiv.org/abs/1811.00960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Response Ranking for Social Conversation: A Data-Efficient\n  Approach", "abstract": "The overall objective of 'social' dialogue systems is to support engaging,\nentertaining, and lengthy conversations on a wide variety of topics, including\nsocial chit-chat. Apart from raw dialogue data, user-provided ratings are the\nmost common signal used to train such systems to produce engaging responses. In\nthis paper we show that social dialogue systems can be trained effectively from\nraw unannotated data. Using a dataset of real conversations collected in the\n2017 Alexa Prize challenge, we developed a neural ranker for selecting 'good'\nsystem responses to user utterances, i.e. responses which are likely to lead to\nlong and engaging conversations. We show that (1) our neural ranker\nconsistently outperforms several strong baselines when trained to optimise for\nuser ratings; (2) when trained on larger amounts of data and only using\nconversation length as the objective, the ranker performs better than the one\ntrained using ratings -- ultimately reaching a Precision@1 of 0.87. This\nadvance will make data collection for social conversational agents simpler and\nless expensive in the future.", "published": "2018-11-02 16:31:22", "link": "http://arxiv.org/abs/1811.00967v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Simple Attention-Based Representation Learning for Ranking Short Social\n  Media Posts", "abstract": "This paper explores the problem of ranking short social media posts with\nrespect to user queries using neural networks. Instead of starting with a\ncomplex architecture, we proceed from the bottom up and examine the\neffectiveness of a simple, word-level Siamese architecture augmented with\nattention-based mechanisms for capturing semantic \"soft\" matches between query\nand post tokens. Extensive experiments on datasets from the TREC Microblog\nTracks show that our simple models not only achieve better effectiveness than\nexisting approaches that are far more complex or exploit a more diverse set of\nrelevance signals, but are also much faster. Implementations of our samCNN\n(Simple Attention-based Matching CNN) models are shared with the community to\nsupport future work.", "published": "2018-11-02 17:57:42", "link": "http://arxiv.org/abs/1811.01013v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting Compositional Models for Knowledge Base Completion Using\n  Gradient Representations", "abstract": "Neural models of Knowledge Base data have typically employed compositional\nrepresentations of graph objects: entity and relation embeddings are\nsystematically combined to evaluate the truth of a candidate Knowedge Base\nentry. Using a model inspired by Harmonic Grammar, we propose to tokenize\ntriplet embeddings by subjecting them to a process of optimization with respect\nto learned well-formedness conditions on Knowledge Base triplets. The resulting\nmodel, known as Gradient Graphs, leads to sizable improvements when implemented\nas a companion to compositional models. Also, we show that the\n\"supracompositional\" triplet token embeddings it produces have interpretable\nproperties that prove helpful in performing inference on the resulting triplet\nrepresentations.", "published": "2018-11-02 19:20:53", "link": "http://arxiv.org/abs/1811.01062v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting Neural Response Generation with Context-Aware Topical\n  Attention", "abstract": "Sequence-to-Sequence (Seq2Seq) models have witnessed a notable success in\ngenerating natural conversational exchanges. Notwithstanding the syntactically\nwell-formed responses generated by these neural network models, they are prone\nto be acontextual, short and generic. In this work, we introduce a Topical\nHierarchical Recurrent Encoder Decoder (THRED), a novel, fully data-driven,\nmulti-turn response generation system intended to produce contextual and\ntopic-aware responses. Our model is built upon the basic Seq2Seq model by\naugmenting it with a hierarchical joint attention mechanism that incorporates\ntopical concepts and previous interactions into the response generation. To\ntrain our model, we provide a clean and high-quality conversational dataset\nmined from Reddit comments. We evaluate THRED on two novel automated metrics,\ndubbed Semantic Similarity and Response Echo Index, as well as with human\nevaluation. Our experiments demonstrate that the proposed model is able to\ngenerate more diverse and contextually relevant responses compared to the\nstrong baselines.", "published": "2018-11-02 19:38:18", "link": "http://arxiv.org/abs/1811.01063v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation into Language Varieties", "abstract": "Both research and commercial machine translation have so far neglected the\nimportance of properly handling the spelling, lexical and grammar divergences\noccurring among language varieties. Notable cases are standard national\nvarieties such as Brazilian and European Portuguese, and Canadian and European\nFrench, which popular online machine translation services are not keeping\ndistinct. We show that an evident side effect of modeling such varieties as\nunique classes is the generation of inconsistent translations. In this work, we\ninvestigate the problem of training neural machine translation from English to\nspecific pairs of language varieties, assuming both labeled and unlabeled\nparallel texts, and low-resource conditions. We report experiments from English\nto two pairs of dialects, EuropeanBrazilian Portuguese and European-Canadian\nFrench, and two pairs of standardized varieties, Croatian-Serbian and\nIndonesian-Malay. We show significant BLEU score improvements over baseline\nsystems when translation into similar languages is learned as a multilingual\ntask with shared representations.", "published": "2018-11-02 19:41:44", "link": "http://arxiv.org/abs/1811.01064v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence Encoders on STILTs: Supplementary Training on Intermediate\n  Labeled-data Tasks", "abstract": "Pretraining sentence encoders with language modeling and related unsupervised\ntasks has recently been shown to be very effective for language understanding\ntasks. By supplementing language model-style pretraining with further training\non data-rich supervised tasks, such as natural language inference, we obtain\nadditional performance improvements on the GLUE benchmark. Applying\nsupplementary training on BERT (Devlin et al., 2018), we attain a GLUE score of\n81.8---the state of the art (as of 02/24/2019) and a 1.4 point improvement over\nBERT. We also observe reduced variance across random restarts in this setting.\nOur approach yields similar improvements when applied to ELMo (Peters et al.,\n2018a) and Radford et al. (2018)'s model. In addition, the benefits of\nsupplementary training are particularly pronounced in data-constrained regimes,\nas we show in experiments with artificially limited training data.", "published": "2018-11-02 21:04:24", "link": "http://arxiv.org/abs/1811.01088v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Value-based Search in Execution Space for Mapping Instructions to\n  Programs", "abstract": "Training models to map natural language instructions to programs given target\nworld supervision only requires searching for good programs at training time.\nSearch is commonly done using beam search in the space of partial programs or\nprogram trees, but as the length of the instructions grows finding a good\nprogram becomes difficult. In this work, we propose a search algorithm that\nuses the target world state, known at training time, to train a critic network\nthat predicts the expected reward of every search state. We then score search\nstates on the beam by interpolating their expected reward with the likelihood\nof programs represented by the search state. Moreover, we search not in the\nspace of programs but in a more compressed state of program executions,\naugmented with recent entities and actions. On the SCONE dataset, we show that\nour algorithm dramatically improves performance on all three domains compared\nto standard beam search and other baselines.", "published": "2018-11-02 21:14:46", "link": "http://arxiv.org/abs/1811.01090v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prior Knowledge Integration for Neural Machine Translation using\n  Posterior Regularization", "abstract": "Although neural machine translation has made significant progress recently,\nhow to integrate multiple overlapping, arbitrary prior knowledge sources\nremains a challenge. In this work, we propose to use posterior regularization\nto provide a general framework for integrating prior knowledge into neural\nmachine translation. We represent prior knowledge sources as features in a\nlog-linear model, which guides the learning process of the neural translation\nmodel. Experiments on Chinese-English translation show that our approach leads\nto significant improvements.", "published": "2018-11-02 21:33:40", "link": "http://arxiv.org/abs/1811.01100v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Task Representations as Weak Supervision for Model Agnostic\n  Cross-Lingual Transfer", "abstract": "Natural language processing is heavily Anglo-centric, while the demand for\nmodels that work in languages other than English is greater than ever. Yet, the\ntask of transferring a model from one language to another can be expensive in\nterms of annotation costs, engineering time and effort. In this paper, we\npresent a general framework for easily and effectively transferring neural\nmodels from English to other languages. The framework, which relies on task\nrepresentations as a form of weak supervision, is model and task agnostic,\nmeaning that many existing neural architectures can be ported to other\nlanguages with minimal effort. The only requirement is unlabeled parallel data,\nand a loss defined over task representations. We evaluate our framework by\ntransferring an English sentiment classifier to three different languages. On a\nbattery of tests, we show that our models outperform a number of strong\nbaselines and rival state-of-the-art results, which rely on more complex\napproaches and significantly more resources and data. Additionally, we find\nthat the framework proposed in this paper is able to capture semantically rich\nand meaningful representations across languages, despite the lack of direct\nsupervision.", "published": "2018-11-02 22:52:22", "link": "http://arxiv.org/abs/1811.01115v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bi-Directional Differentiable Input Reconstruction for Low-Resource\n  Neural Machine Translation", "abstract": "We aim to better exploit the limited amounts of parallel text available in\nlow-resource settings by introducing a differentiable reconstruction loss for\nneural machine translation (NMT). This loss compares original inputs to\nreconstructed inputs, obtained by back-translating translation hypotheses into\nthe input language. We leverage differentiable sampling and bi-directional NMT\nto train models end-to-end, without introducing additional parameters. This\napproach achieves small but consistent BLEU improvements on four language pairs\nin both translation directions, and outperforms an alternative differentiable\nreconstruction strategy based on hidden states.", "published": "2018-11-02 22:55:04", "link": "http://arxiv.org/abs/1811.01116v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Transfer VQA Dataset", "abstract": "Acquiring a large vocabulary is an important aspect of human intelligence.\nOnecommon approach for human to populating vocabulary is to learn words\nduringreading or listening, and then use them in writing or speaking. This\nability totransfer from input to output is natural for human, but it is\ndifficult for machines.Human spontaneously performs this knowledge transfer in\ncomplicated multimodaltasks, such as Visual Question Answering (VQA). In order\nto approach human-levelArtificial Intelligence, we hope to equip machines with\nsuch ability. Therefore, toaccelerate this research, we propose a newzero-shot\ntransfer VQA(ZST-VQA)dataset by reorganizing the existing VQA v1.0 dataset in\nthe way that duringtraining, some words appear only in one module (i.e.\nquestions) but not in theother (i.e. answers). In this setting, an intelligent\nmodel should understand andlearn the concepts from one module (i.e. questions),\nand at test time, transfer themto the other (i.e. predict the concepts as\nanswers). We conduct evaluation on thisnew dataset using three existing\nstate-of-the-art VQA neural models. Experimentalresults show a significant drop\nin performance on this dataset, indicating existingmethods do not address the\nzero-shot transfer problem. Besides, our analysis findsthat this may be caused\nby the implicit bias learned during training.", "published": "2018-11-02 01:02:49", "link": "http://arxiv.org/abs/1811.00692v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "An Empirical Exploration of Curriculum Learning for Neural Machine\n  Translation", "abstract": "Machine translation systems based on deep neural networks are expensive to\ntrain. Curriculum learning aims to address this issue by choosing the order in\nwhich samples are presented during training to help train better models faster.\nWe adopt a probabilistic view of curriculum learning, which lets us flexibly\nevaluate the impact of curricula design, and perform an extensive exploration\non a German-English translation task. Results show that it is possible to\nimprove convergence time at no loss in translation quality. However, results\nare highly sensitive to the choice of sample difficulty criteria, curriculum\nschedule and other hyperparameters.", "published": "2018-11-02 05:05:26", "link": "http://arxiv.org/abs/1811.00739v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Survey on Natural Language Processing for Fake News Detection", "abstract": "Fake news detection is a critical yet challenging problem in Natural Language\nProcessing (NLP). The rapid rise of social networking platforms has not only\nyielded a vast increase in information accessibility but has also accelerated\nthe spread of fake news. Thus, the effect of fake news has been growing,\nsometimes extending to the offline world and threatening public safety. Given\nthe massive amount of Web content, automatic fake news detection is a practical\nNLP problem useful to all online content providers, in order to reduce the\nhuman time and effort to detect and prevent the spread of fake news. In this\npaper, we describe the challenges involved in fake news detection and also\ndescribe related tasks. We systematically review and compare the task\nformulations, datasets and NLP solutions that have been developed for this\ntask, and also discuss the potentials and limitations of them. Based on our\ninsights, we outline promising research directions, including more\nfine-grained, detailed, fair, and practical detection models. We also highlight\nthe difference between fake news detection and other related tasks, and the\nimportance of NLP solutions for fake news detection.", "published": "2018-11-02 08:10:21", "link": "http://arxiv.org/abs/1811.00770v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Bayesian Approach for Sequence Tagging with Crowds", "abstract": "Current methods for sequence tagging, a core task in NLP, are data hungry,\nwhich motivates the use of crowdsourcing as a cheap way to obtain labelled\ndata. However, annotators are often unreliable and current aggregation methods\ncannot capture common types of span annotation errors. To address this, we\npropose a Bayesian method for aggregating sequence tags that reduces errors by\nmodelling sequential dependencies between the annotations as well as the\nground-truth labels. By taking a Bayesian approach, we account for uncertainty\nin the model due to both annotator errors and the lack of data for modelling\nannotators who complete few tasks. We evaluate our model on crowdsourced data\nfor named entity recognition, information extraction and argument mining,\nshowing that our sequential model outperforms the previous state of the art. We\nalso find that our approach can reduce crowdsourcing costs through more\neffective active learning, as it better captures uncertainty in the sequence\nlabels when there are few annotations.", "published": "2018-11-02 08:50:11", "link": "http://arxiv.org/abs/1811.00780v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Combining Long Short Term Memory and Convolutional Neural Network for\n  Cross-Sentence n-ary Relation Extraction", "abstract": "We propose in this paper a combined model of Long Short Term Memory and\nConvolutional Neural Networks (LSTM-CNN) that exploits word embeddings and\npositional embeddings for cross-sentence n-ary relation extraction. The\nproposed model brings together the properties of both LSTMs and CNNs, to\nsimultaneously exploit long-range sequential information and capture most\ninformative features, essential for cross-sentence n-ary relation extraction.\nThe LSTM-CNN model is evaluated on standard dataset on cross-sentence n-ary\nrelation extraction, where it significantly outperforms baselines such as CNNs,\nLSTMs and also a combined CNN-LSTM model. The paper also shows that the\nLSTM-CNN model outperforms the current state-of-the-art methods on\ncross-sentence n-ary relation extraction.", "published": "2018-11-02 13:22:19", "link": "http://arxiv.org/abs/1811.00845v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Importance of Search and Evaluation Strategies in Neural Dialogue\n  Modeling", "abstract": "We investigate the impact of search strategies in neural dialogue modeling.\nWe first compare two standard search algorithms, greedy and beam search, as\nwell as our newly proposed iterative beam search which produces a more diverse\nset of candidate responses. We evaluate these strategies in realistic full\nconversations with humans and propose a model-based Bayesian calibration to\naddress annotator bias. These conversations are analyzed using two automatic\nmetrics: log-probabilities assigned by the model and utterance diversity. Our\nexperiments reveal that better search algorithms lead to higher rated\nconversations. However, finding the optimal selection mechanism to choose from\na more diverse set of candidates is still an open question.", "published": "2018-11-02 14:54:50", "link": "http://arxiv.org/abs/1811.00907v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Learning of Interpretable Dialog Models", "abstract": "Recently several deep learning based models have been proposed for end-to-end\nlearning of dialogs. While these models can be trained from data without the\nneed for any additional annotations, it is hard to interpret them. On the other\nhand, there exist traditional state based dialog systems, where the states of\nthe dialog are discrete and hence easy to interpret. However these states need\nto be handcrafted and annotated in the data. To achieve the best of both\nworlds, we propose Latent State Tracking Network (LSTN) using which we learn an\ninterpretable model in unsupervised manner. The model defines a discrete latent\nvariable at each turn of the conversation which can take a finite set of\nvalues. Since these discrete variables are not present in the training data, we\nuse EM algorithm to train our model in unsupervised manner. In the experiments,\nwe show that LSTN can help achieve interpretability in dialog models without\nmuch decrease in performance compared to end-to-end approaches.", "published": "2018-11-02 17:56:23", "link": "http://arxiv.org/abs/1811.01012v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Unsupervised Hyperalignment for Multilingual Word Embeddings", "abstract": "We consider the problem of aligning continuous word representations, learned\nin multiple languages, to a common space. It was recently shown that, in the\ncase of two languages, it is possible to learn such a mapping without\nsupervision. This paper extends this line of work to the problem of aligning\nmultiple languages to a common space. A solution is to independently map all\nlanguages to a pivot language. Unfortunately, this degrades the quality of\nindirect word translation. We thus propose a novel formulation that ensures\ncomposable mappings, leading to better alignments. We evaluate our method by\njointly aligning word vectors in eleven languages, showing consistent\nimprovement with indirect mappings while maintaining competitive performance on\ndirect word translation.", "published": "2018-11-02 23:30:54", "link": "http://arxiv.org/abs/1811.01124v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploiting Explicit Paths for Multi-hop Reading Comprehension", "abstract": "We propose a novel, path-based reasoning approach for the multi-hop reading\ncomprehension task where a system needs to combine facts from multiple passages\nto answer a question. Although inspired by multi-hop reasoning over knowledge\ngraphs, our proposed approach operates directly over unstructured text. It\ngenerates potential paths through passages and scores them without any direct\npath supervision. The proposed model, named PathNet, attempts to extract\nimplicit relations from text through entity pair representations, and compose\nthem to encode each path. To capture additional context, PathNet also composes\nthe passage representations along each path to compute a passage-based\nrepresentation. Unlike previous approaches, our model is then able to explain\nits reasoning via these explicit paths through the passages. We show that our\napproach outperforms prior models on the multi-hop Wikihop dataset, and also\ncan be generalized to apply to the OpenBookQA dataset, matching\nstate-of-the-art performance.", "published": "2018-11-02 23:48:46", "link": "http://arxiv.org/abs/1811.01127v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transductive Learning with String Kernels for Cross-Domain Text\n  Classification", "abstract": "For many text classification tasks, there is a major problem posed by the\nlack of labeled data in a target domain. Although classifiers for a target\ndomain can be trained on labeled text data from a related source domain, the\naccuracy of such classifiers is usually lower in the cross-domain setting.\nRecently, string kernels have obtained state-of-the-art results in various text\nclassification tasks such as native language identification or automatic essay\nscoring. Moreover, classifiers based on string kernels have been found to be\nrobust to the distribution gap between different domains. In this paper, we\nformally describe an algorithm composed of two simple yet effective\ntransductive learning approaches to further improve the results of string\nkernels in cross-domain settings. By adapting string kernels to the test set\nwithout using the ground-truth test labels, we report significantly better\naccuracy rates in cross-domain English polarity classification.", "published": "2018-11-02 08:05:36", "link": "http://arxiv.org/abs/1811.01734v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training Neural Speech Recognition Systems with Synthetic Speech\n  Augmentation", "abstract": "Building an accurate automatic speech recognition (ASR) system requires a\nlarge dataset that contains many hours of labeled speech samples produced by a\ndiverse set of speakers. The lack of such open free datasets is one of the main\nissues preventing advancements in ASR research. To address this problem, we\npropose to augment a natural speech dataset with synthetic speech. We train\nvery large end-to-end neural speech recognition models using the LibriSpeech\ndataset augmented with synthetic speech. These new models achieve state of the\nart Word Error Rate (WER) for character-level based models without an external\nlanguage model.", "published": "2018-11-02 02:15:46", "link": "http://arxiv.org/abs/1811.00707v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Dirichlet belief networks for topic structure learning", "abstract": "Recently, considerable research effort has been devoted to developing deep\narchitectures for topic models to learn topic structures. Although several deep\nmodels have been proposed to learn better topic proportions of documents, how\nto leverage the benefits of deep structures for learning word distributions of\ntopics has not yet been rigorously studied. Here we propose a new multi-layer\ngenerative process on word distributions of topics, where each layer consists\nof a set of topics and each topic is drawn from a mixture of the topics of the\nlayer above. As the topics in all layers can be directly interpreted by words,\nthe proposed model is able to discover interpretable topic hierarchies. As a\nself-contained module, our model can be flexibly adapted to different kinds of\ntopic models to improve their modelling accuracy and interpretability.\nExtensive experiments on text corpora demonstrate the advantages of the\nproposed model.", "published": "2018-11-02 02:54:39", "link": "http://arxiv.org/abs/1811.00717v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Comparison of Classification Algorithms Used Medical Documents\n  Categorization", "abstract": "Volume of text based documents have been increasing day by day. Medical\ndocuments are located within this growing text documents. In this study, the\ntechniques used for text classification applied on medical documents and\nevaluated classification performance. Used data sets are multi class and multi\nlabelled. Chi Square (CHI) technique was used for feature selection also SMO,\nNB, C4.5, RF and KNN algorithms was used for classification. The aim of this\nstudy, success of various classifiers is evaluated on multi class and multi\nlabel data sets consisting of medical documents. The first 400 features, while\nthe most successful in the KNN classifier, feature number 400 and after the SMO\nhas become the most successful classifier.", "published": "2018-11-02 14:08:53", "link": "http://arxiv.org/abs/1811.00869v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense\n  Knowledge", "abstract": "When answering a question, people often draw upon their rich world knowledge\nin addition to the particular context. Recent work has focused primarily on\nanswering questions given some relevant document or context, and required very\nlittle general background. To investigate question answering with prior\nknowledge, we present CommonsenseQA: a challenging new dataset for commonsense\nquestion answering. To capture common sense beyond associations, we extract\nfrom ConceptNet (Speer et al., 2017) multiple target concepts that have the\nsame semantic relation to a single source concept. Crowd-workers are asked to\nauthor multiple-choice questions that mention the source concept and\ndiscriminate in turn between each of the target concepts. This encourages\nworkers to create questions with complex semantics that often require prior\nknowledge. We create 12,247 questions through this procedure and demonstrate\nthe difficulty of our task with a large number of strong baselines. Our best\nbaseline is based on BERT-large (Devlin et al., 2018) and obtains 56% accuracy,\nwell below human performance, which is 89%.", "published": "2018-11-02 15:34:29", "link": "http://arxiv.org/abs/1811.00937v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analysing Dropout and Compounding Errors in Neural Language Models", "abstract": "This paper carries out an empirical analysis of various dropout techniques\nfor language modelling, such as Bernoulli dropout, Gaussian dropout, Curriculum\nDropout, Variational Dropout and Concrete Dropout. Moreover, we propose an\nextension of variational dropout to concrete dropout and curriculum dropout\nwith varying schedules. We find these extensions to perform well when compared\nto standard dropout approaches, particularly variational curriculum dropout\nwith a linear schedule. Largest performance increases are made when applying\ndropout on the decoder layer. Lastly, we analyze where most of the errors occur\nat test time as a post-analysis step to determine if the well-known problem of\ncompounding errors is apparent and to what end do the proposed methods mitigate\nthis issue for each dataset. We report results on a 2-hidden layer LSTM, GRU\nand Highway network with embedding dropout, dropout on the gated hidden layers\nand the output projection layer for each model. We report our results on\nPenn-TreeBank and WikiText-2 word-level language modelling datasets, where the\nformer reduces the long-tail distribution through preprocessing and one which\npreserves rare words in the training and test set.", "published": "2018-11-02 17:31:53", "link": "http://arxiv.org/abs/1811.00998v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "On Evaluating the Generalization of LSTM Models in Formal Languages", "abstract": "Recurrent Neural Networks (RNNs) are theoretically Turing-complete and\nestablished themselves as a dominant model for language processing. Yet, there\nstill remains an uncertainty regarding their language learning capabilities. In\nthis paper, we empirically evaluate the inductive learning capabilities of Long\nShort-Term Memory networks, a popular extension of simple RNNs, to learn simple\nformal languages, in particular $a^nb^n$, $a^nb^nc^n$, and $a^nb^nc^nd^n$. We\ninvestigate the influence of various aspects of learning, such as training data\nregimes and model capacity, on the generalization to unobserved samples. We\nfind striking differences in model performances under different training\nsettings and highlight the need for careful analysis and assessment when making\nclaims about the learning capabilities of neural network models.", "published": "2018-11-02 17:37:39", "link": "http://arxiv.org/abs/1811.01001v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.6; F.4.3"], "primary_category": "cs.CL"}
{"title": "Cycle-consistency training for end-to-end speech recognition", "abstract": "This paper presents a method to train end-to-end automatic speech recognition\n(ASR) models using unpaired data. Although the end-to-end approach can\neliminate the need for expert knowledge such as pronunciation dictionaries to\nbuild ASR systems, it still requires a large amount of paired data, i.e.,\nspeech utterances and their transcriptions. Cycle-consistency losses have been\nrecently proposed as a way to mitigate the problem of limited paired data.\nThese approaches compose a reverse operation with a given transformation, e.g.,\ntext-to-speech (TTS) with ASR, to build a loss that only requires unsupervised\ndata, speech in this example. Applying cycle consistency to ASR models is not\ntrivial since fundamental information, such as speaker traits, are lost in the\nintermediate text bottleneck. To solve this problem, this work presents a loss\nthat is based on the speech encoder state sequence instead of the raw speech\nsignal. This is achieved by training a Text-To-Encoder model and defining a\nloss based on the encoder reconstruction error. Experimental results on the\nLibriSpeech corpus show that the proposed cycle-consistency training reduced\nthe word error rate by 14.7% from an initial model trained with 100-hour paired\ndata, using an additional 360 hours of audio data without transcriptions. We\nalso investigate the use of text-only data mainly for language modeling to\nfurther improve the performance in the unpaired data training scenario.", "published": "2018-11-02 06:32:58", "link": "http://arxiv.org/abs/1811.01690v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The Knowref Coreference Corpus: Removing Gender and Number Cues for\n  Difficult Pronominal Anaphora Resolution", "abstract": "We introduce a new benchmark for coreference resolution and NLI, Knowref,\nthat targets common-sense understanding and world knowledge. Previous\ncoreference resolution tasks can largely be solved by exploiting the number and\ngender of the antecedents, or have been handcrafted and do not reflect the\ndiversity of naturally occurring text. We present a corpus of over 8,000\nannotated text passages with ambiguous pronominal anaphora. These instances are\nboth challenging and realistic. We show that various coreference systems,\nwhether rule-based, feature-rich, or neural, perform significantly worse on the\ntask than humans, who display high inter-annotator agreement. To explain this\nperformance gap, we show empirically that state-of-the art models often fail to\ncapture context, instead relying on the gender or number of candidate\nantecedents to make a decision. We then use problem-specific insights to\npropose a data-augmentation trick called antecedent switching to alleviate this\ntendency in models. Finally, we show that antecedent switching yields promising\nresults on other tasks as well: we use it to achieve state-of-the-art results\non the GAP coreference task.", "published": "2018-11-02 16:41:26", "link": "http://arxiv.org/abs/1811.01747v3", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Acoustic Features Fusion using Attentive Multi-channel Deep Architecture", "abstract": "In this paper, we present a novel deep fusion architecture for audio\nclassification tasks. The multi-channel model presented is formed using deep\nconvolution layers where different acoustic features are passed through each\nchannel. To enable dissemination of information across the channels, we\nintroduce attention feature maps that aid in the alignment of frames. The\noutput of each channel is merged using interaction parameters that non-linearly\naggregate the representative features. Finally, we evaluate the performance of\nthe proposed architecture on three benchmark datasets:- DCASE-2016 and LITIS\nRouen (acoustic scene recognition), and CHiME-Home (tagging). Our experimental\nresults suggest that the architecture presented outperforms the standard\nbaselines and achieves outstanding performance on the task of acoustic scene\nrecognition and audio tagging.", "published": "2018-11-02 15:31:22", "link": "http://arxiv.org/abs/1811.00936v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unifying Isolated and Overlapping Audio Event Detection with Multi-Label\n  Multi-Task Convolutional Recurrent Neural Networks", "abstract": "We propose a multi-label multi-task framework based on a convolutional\nrecurrent neural network to unify detection of isolated and overlapping audio\nevents. The framework leverages the power of convolutional recurrent neural\nnetwork architectures; convolutional layers learn effective features over which\nhigher recurrent layers perform sequential modelling. Furthermore, the output\nlayer is designed to handle arbitrary degrees of event overlap. At each time\nstep in the recurrent output sequence, an output triple is dedicated to each\nevent category of interest to jointly model event occurrence and temporal\nboundaries. That is, the network jointly determines whether an event of this\ncategory occurs, and when it occurs, by estimating onset and offset positions\nat each recurrent time step. We then introduce three sequential losses for\nnetwork training: multi-label classification loss, distance estimation loss,\nand confidence loss. We demonstrate good generalization on two datasets:\nITC-Irst for isolated audio event detection, and TUT-SED-Synthetic-2016 for\noverlapping audio event detection.", "published": "2018-11-02 21:16:54", "link": "http://arxiv.org/abs/1811.01092v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond Equal-Length Snippets: How Long is Sufficient to Recognize an\n  Audio Scene?", "abstract": "Due to the variability in characteristics of audio scenes, some scenes can\nnaturally be recognized earlier than others. In this work, rather than using\nequal-length snippets for all scene categories, as is common in the literature,\nwe study to which temporal extent an audio scene can be reliably recognized\ngiven state-of-the-art models. Moreover, as model fusion with deep network\nensemble is prevalent in audio scene classification, we further study whether,\nand if so, when model fusion is necessary for this task. To achieve these\ngoals, we employ two single-network systems relying on a convolutional neural\nnetwork and a recurrent neural network for classification as well as early\nfusion and late fusion of these networks. Experimental results on the\nLITIS-Rouen dataset show that some scenes can be reliably recognized with a few\nseconds while other scenes require significantly longer durations. In addition,\nmodel fusion is shown to be the most beneficial when the signal length is\nshort.", "published": "2018-11-02 21:22:58", "link": "http://arxiv.org/abs/1811.01095v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
