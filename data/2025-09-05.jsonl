{"title": "Non-Termination Proving: 100 Million LoC and Beyond", "abstract": "We report on our tool, Pulse Infinite, that uses proof techniques to show\nnon-termination (divergence) in large programs. Pulse Infinite works\ncompositionally and under-approximately: the former supports scale, and the\nlatter ensures soundness for proving divergence. Prior work focused on small\nbenchmarks in the tens or hundreds of lines of code (LoC), and scale limits\ntheir practicality: a single company may have tens of millions, or even\nhundreds of millions of LoC or more. We report on applying Pulse Infinite to\nover a hundred million lines of open-source and proprietary software written in\nC, C++, and Hack, identifying over 30 previously unknown issues, establishing a\nnew state of the art for detecting divergence in real-world codebases.", "published": "2025-09-05 17:58:45", "link": "http://arxiv.org/abs/2509.05293v1", "categories": ["cs.PL", "cs.CL", "cs.SE", "D.3; F.3"], "primary_category": "cs.PL"}
{"title": "Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining", "abstract": "Large language models (LLMs) learn non-trivial abstractions during\npretraining, like detecting irregular plural noun subjects. However, it is not\nwell understood when and how specific linguistic abilities emerge as\ntraditional evaluation methods such as benchmarking fail to reveal how models\nacquire concepts and capabilities. To bridge this gap and better understand\nmodel training at the concept level, we use sparse crosscoders to discover and\nalign features across model checkpoints. Using this approach, we track the\nevolution of linguistic features during pretraining. We train crosscoders\nbetween open-sourced checkpoint triplets with significant performance and\nrepresentation shifts, and introduce a novel metric, Relative Indirect Effects\n(RelIE), to trace training stages at which individual features become causally\nimportant for task performance. We show that crosscoders can detect feature\nemergence, maintenance, and discontinuation during pretraining. Our approach is\narchitecture-agnostic and scalable, offering a promising path toward more\ninterpretable and fine-grained analysis of representation learning throughout\npretraining.", "published": "2025-09-05 17:56:24", "link": "http://arxiv.org/abs/2509.05291v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Elucidating the Design Space of Decay in Linear Attention", "abstract": "This paper presents a comprehensive investigation into the decay mechanisms\ninherent in linear complexity sequence models. We systematically delineate the\ndesign space of decay mechanisms across four pivotal dimensions:\nparameterization strategy, which refers to the computational methodology for\ndecay; parameter sharing, which involves the utilization of supplementary\nparameters for decay computation; decay granularity, comparing scalar versus\nvector-based decay; and compatibility with relative positional encoding\nmethods, such as Rotary Position Embedding (RoPE). Through an extensive series\nof experiments conducted on diverse language modeling tasks, we uncovered\nseveral critical insights. Firstly, the design of the parameterization strategy\nfor decay requires meticulous consideration. Our findings indicate that\neffective configurations are typically confined to a specific range of\nparameters. Secondly, parameter sharing cannot be used arbitrarily, as it may\ncause decay values to be too large or too small, thereby significantly\nimpacting performance. Thirdly, under identical parameterization strategies,\nscalar decay generally underperforms compared to its vector-based counterpart.\nHowever, in certain scenarios with alternative parameterization strategies,\nscalar decay may unexpectedly surpass vector decay in efficacy. Lastly, our\nanalysis reveals that RoPE, a commonly employed relative positional encoding\nmethod, typically fails to provide tangible benefits to the majority of linear\nattention mechanisms.", "published": "2025-09-05 17:48:26", "link": "http://arxiv.org/abs/2509.05282v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SpikingBrain Technical Report: Spiking Brain-inspired Large Models", "abstract": "Mainstream Transformer-based large language models face major efficiency\nbottlenecks: training computation scales quadratically with sequence length,\nand inference memory grows linearly, limiting long-context processing. Building\nlarge models on non-NVIDIA platforms also poses challenges for stable and\nefficient training. To address this, we introduce SpikingBrain, a family of\nbrain-inspired models designed for efficient long-context training and\ninference. SpikingBrain leverages the MetaX GPU cluster and focuses on three\naspects: (1) Model Architecture: linear and hybrid-linear attention\narchitectures with adaptive spiking neurons; (2) Algorithmic Optimizations: an\nefficient, conversion-based training pipeline and a dedicated spike coding\nframework; (3) System Engineering: customized training frameworks, operator\nlibraries, and parallelism strategies tailored to MetaX hardware.\n  Using these techniques, we develop two models: SpikingBrain-7B, a linear LLM,\nand SpikingBrain-76B, a hybrid-linear MoE LLM. These models demonstrate the\nfeasibility of large-scale LLM development on non-NVIDIA platforms.\nSpikingBrain achieves performance comparable to open-source Transformer\nbaselines while using only about 150B tokens for continual pre-training. Our\nmodels significantly improve long-sequence training efficiency and deliver\ninference with (partially) constant memory and event-driven spiking behavior.\nFor example, SpikingBrain-7B attains over 100x speedup in Time to First Token\nfor 4M-token sequences. Training remains stable for weeks on hundreds of MetaX\nC550 GPUs, with the 7B model reaching a Model FLOPs Utilization of 23.4\npercent. The proposed spiking scheme achieves 69.15 percent sparsity, enabling\nlow-power operation. Overall, this work demonstrates the potential of\nbrain-inspired mechanisms to drive the next generation of efficient and\nscalable large model design.", "published": "2025-09-05 17:34:00", "link": "http://arxiv.org/abs/2509.05276v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Uniform Information Density and Syntactic Reduction: Revisiting $\\textit{that}$-Mentioning in English Complement Clauses", "abstract": "Speakers often have multiple ways to express the same meaning. The Uniform\nInformation Density (UID) hypothesis suggests that speakers exploit this\nvariability to maintain a consistent rate of information transmission during\nlanguage production. Building on prior work linking UID to syntactic reduction,\nwe revisit the finding that the optional complementizer $\\textit{that}$in\nEnglish complement clauses is more likely to be omitted when the clause has low\ninformation density (i.e., more predictable). We advance this line of research\nby analyzing a large-scale, contemporary conversational corpus and using\nmachine learning and neural language models to refine estimates of information\ndensity. Our results replicated the established relationship between\ninformation density and $\\textit{that}$-mentioning. However, we found that\nprevious measures of information density based on matrix verbs'\nsubcategorization probability capture substantial idiosyncratic lexical\nvariation. By contrast, estimates derived from contextual word embeddings\naccount for additional variance in patterns of complementizer usage.", "published": "2025-09-05 17:12:19", "link": "http://arxiv.org/abs/2509.05254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models", "abstract": "Pre-trained language models have achieved remarkable success across diverse\napplications but remain susceptible to spurious, concept-driven correlations\nthat impair robustness and fairness. In this work, we introduce CURE, a novel\nand lightweight framework that systematically disentangles and suppresses\nconceptual shortcuts while preserving essential content information. Our method\nfirst extracts concept-irrelevant representations via a dedicated content\nextractor reinforced by a reversal network, ensuring minimal loss of\ntask-relevant information. A subsequent controllable debiasing module employs\ncontrastive learning to finely adjust the influence of residual conceptual\ncues, enabling the model to either diminish harmful biases or harness\nbeneficial correlations as appropriate for the target task. Evaluated on the\nIMDB and Yelp datasets using three pre-trained architectures, CURE achieves an\nabsolute improvement of +10 points in F1 score on IMDB and +2 points on Yelp,\nwhile introducing minimal computational overhead. Our approach establishes a\nflexible, unsupervised blueprint for combating conceptual biases, paving the\nway for more reliable and fair language understanding systems.", "published": "2025-09-05 16:47:22", "link": "http://arxiv.org/abs/2509.05230v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Less is More Tokens: Efficient Math Reasoning via Difficulty-Aware Chain-of-Thought Distillation", "abstract": "Chain-of-thought reasoning, while powerful, can produce unnecessarily verbose\noutput for simpler problems. We present a framework for difficulty-aware\nreasoning that teaches models to dynamically adjust reasoning depth based on\nproblem complexity. Remarkably, we show that models can be endowed with such\ndynamic inference pathways without any architectural modifications; we simply\npost-train on data that is carefully curated to include chain-of-thought traces\nthat are proportional in length to problem difficulty. Our analysis reveals\nthat post-training via supervised fine-tuning (SFT) primarily captures patterns\nlike reasoning length and format, while direct preference optimization (DPO)\npreserves reasoning accuracy, with their combination reducing length and\nmaintaining or improving performance. Both quantitative metrics and qualitative\nassessments confirm that models can learn to \"think proportionally\", reasoning\nminimally on simple problems while maintaining depth for complex ones.", "published": "2025-09-05 16:40:13", "link": "http://arxiv.org/abs/2509.05226v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models", "abstract": "Positional encoding mechanisms enable Transformers to model sequential\nstructure and long-range dependencies in text. While absolute positional\nencodings struggle with extrapolation to longer sequences due to fixed\npositional representations, and relative approaches like Alibi exhibit\nperformance degradation on extremely long contexts, the widely-used Rotary\nPositional Encoding (RoPE) introduces oscillatory attention patterns that\nhinder stable long-distance dependency modelling. We address these limitations\nthrough a geometric reformulation of positional encoding. Drawing inspiration\nfrom Lorentz transformations in hyperbolic geometry, we propose Hyperbolic\nRotary Positional Encoding (HoPE), which leverages hyperbolic functions to\nimplement Lorentz rotations on token representations. Theoretical analysis\ndemonstrates that RoPE is a special case of our generalized formulation. HoPE\nfundamentally resolves RoPE's slation issues by enforcing monotonic decay of\nattention weights with increasing token distances. Extensive experimental\nresults, including perplexity evaluations under several extended sequence\nbenchmarks, show that HoPE consistently exceeds existing positional encoding\nmethods. These findings underscore HoPE's enhanced capacity for representing\nand generalizing long-range dependencies. Data and code will be available.", "published": "2025-09-05 16:20:48", "link": "http://arxiv.org/abs/2509.05218v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BEDTime: A Unified Benchmark for Automatically Describing Time Series", "abstract": "Many recent studies have proposed general-purpose foundation models designed\nfor a variety of time series analysis tasks. While several established datasets\nalready exist for evaluating these models, previous works frequently introduce\ntheir models in conjunction with new datasets, limiting opportunities for\ndirect, independent comparisons and obscuring insights into the relative\nstrengths of different methods. Additionally, prior evaluations often cover\nnumerous tasks simultaneously, assessing a broad range of model abilities\nwithout clearly pinpointing which capabilities contribute to overall\nperformance. To address these gaps, we formalize and evaluate 3 tasks that test\na model's ability to describe time series using generic natural language: (1)\nrecognition (True/False question-answering), (2) differentiation (multiple\nchoice question-answering), and (3) generation (open-ended natural language\ndescription). We then unify 4 recent datasets to enable head-to-head model\ncomparisons on each task. Experimentally, in evaluating 13 state-of-the-art\nlanguage, vision--language, and time series--language models, we find that (1)\npopular language-only methods largely underperform, indicating a need for time\nseries-specific architectures, (2) VLMs are quite successful, as expected,\nidentifying the value of vision models for these tasks and (3) pretrained\nmultimodal time series--language models successfully outperform LLMs, but still\nhave significant room for improvement. We also find that all approaches exhibit\nclear fragility in a range of robustness tests. Overall, our benchmark provides\na standardized evaluation on a task necessary for time series reasoning\nsystems.", "published": "2025-09-05 16:18:20", "link": "http://arxiv.org/abs/2509.05215v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hunyuan-MT Technical Report", "abstract": "In this report, we introduce Hunyuan-MT-7B, our first open-source\nmultilingual translation model, which supports bidirectional translation across\n33 major languages and places a special emphasis on translation between\nMandarin and several ethnic minority languages as well as dialects.\nFurthermore, to serve and address diverse translation scenarios and enhance\nmodel performance at test time, we introduce Hunyuan-MT-Chimera-7B, a\ntranslation model inspired by the slow thinking mode. This model integrates\nmultiple outputs generated by the Hunyuan-MT-7B model under varying parameter\nsettings, thereby achieving performance superior to that of conventional\nslow-thinking models based on Chain-of-Thought (CoT). The development of our\nmodels follows a holistic training process specifically engineered for\nmultilingual translation, which begins with general and MT-oriented\npre-training to build foundational capabilities, proceeds to Supervised\nFine-Tuning (SFT) for task-specific adaptation, and culminates in advanced\nalignment through Reinforcement Learning (RL) and weak-to-strong RL. Through\ncomprehensive experimentation, we demonstrate that both Hunyuan-MT-7B and\nHunyuan-MT-Chimera-7B significantly outperform all translation-specific models\nof comparable parameter size and most of the SOTA large models, particularly on\nthe task of translation between Mandarin and minority languages as well as\ndialects. In the WMT2025 shared task (General Machine Translation), our models\ndemonstrate state-of-the-art performance, ranking first in 30 out of 31\nlanguage pairs. This result highlights the robustness of our models across a\ndiverse linguistic spectrum, encompassing high-resource languages such as\nChinese, English, and Japanese, as well as low-resource languages including\nCzech, Marathi, Estonian, and Icelandic.", "published": "2025-09-05 16:11:05", "link": "http://arxiv.org/abs/2509.05209v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework", "abstract": "Large Language Models (LLMs) are increasingly being deployed in high-risk\ndomains where opacity, bias, and instability undermine trust and\naccountability. Traditional explainability methods, focused on surface outputs,\ndo not capture the reasoning pathways, planning logic, and systemic impacts of\nagentic LLMs.\n  We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a\ntriadic fusion framework that unites three complementary dimensions: cognitive\n(user understanding), functional (practical utility), and causal (faithful\nreasoning). TAXAL provides a unified, role-sensitive foundation for designing,\nevaluating, and deploying explanations in diverse sociotechnical settings.\n  Our analysis synthesizes existing methods, ranging from post-hoc attribution\nand dialogic interfaces to explanation-aware prompting, and situates them\nwithin the TAXAL triadic fusion model. We further demonstrate its applicability\nthrough case studies in law, education, healthcare, and public services,\nshowing how explanation strategies adapt to institutional constraints and\nstakeholder roles.\n  By combining conceptual clarity with design patterns and deployment pathways,\nTAXAL advances explainability as a technical and sociotechnical practice,\nsupporting trustworthy and context-sensitive LLM applications in the era of\nagentic AI.", "published": "2025-09-05 15:58:49", "link": "http://arxiv.org/abs/2509.05199v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PRIM: Towards Practical In-Image Multilingual Machine Translation", "abstract": "In-Image Machine Translation (IIMT) aims to translate images containing texts\nfrom one language to another. Current research of end-to-end IIMT mainly\nconducts on synthetic data, with simple background, single font, fixed text\nposition, and bilingual translation, which can not fully reflect real world,\ncausing a significant gap between the research and practical conditions. To\nfacilitate research of IIMT in real-world scenarios, we explore Practical\nIn-Image Multilingual Machine Translation (IIMMT). In order to convince the\nlack of publicly available data, we annotate the PRIM dataset, which contains\nreal-world captured one-line text images with complex background, various\nfonts, diverse text positions, and supports multilingual translation\ndirections. We propose an end-to-end model VisTrans to handle the challenge of\npractical conditions in PRIM, which processes visual text and background\ninformation in the image separately, ensuring the capability of multilingual\ntranslation while improving the visual quality. Experimental results indicate\nthe VisTrans achieves a better translation quality and visual effect compared\nto other models. The code and dataset are available at:\nhttps://github.com/BITHLP/PRIM.", "published": "2025-09-05 14:38:07", "link": "http://arxiv.org/abs/2509.05146v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "ICR: Iterative Clarification and Rewriting for Conversational Search", "abstract": "Most previous work on Conversational Query Rewriting employs an end-to-end\nrewriting paradigm. However, this approach is hindered by the issue of multiple\nfuzzy expressions within the query, which complicates the simultaneous\nidentification and rewriting of multiple positions. To address this issue, we\npropose a novel framework ICR (Iterative Clarification and Rewriting), an\niterative rewriting scheme that pivots on clarification questions. Within this\nframework, the model alternates between generating clarification questions and\nrewritten queries. The experimental results show that our ICR can continuously\nimprove retrieval performance in the clarification-rewriting iterative process,\nthereby achieving state-of-the-art performance on two popular datasets.", "published": "2025-09-05 13:37:04", "link": "http://arxiv.org/abs/2509.05100v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Finding your MUSE: Mining Unexpected Solutions Engine", "abstract": "Innovators often exhibit cognitive fixation on existing solutions or nascent\nideas, hindering the exploration of novel alternatives. This paper introduces a\nmethodology for constructing Functional Concept Graphs (FCGs), interconnected\nrepresentations of functional elements that support abstraction, problem\nreframing, and analogical inspiration. Our approach yields large-scale,\nhigh-quality FCGs with explicit abstraction relations, overcoming limitations\nof prior work. We further present MUSE, an algorithm leveraging FCGs to\ngenerate creative inspirations for a given problem. We demonstrate our method\nby computing an FCG on 500K patents, which we release for further research.", "published": "2025-09-05 13:13:19", "link": "http://arxiv.org/abs/2509.05072v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions", "abstract": "Most existing Theory of Mind (ToM) benchmarks for foundation models rely on\nvariations of the Sally-Anne test, offering only a very limited perspective on\nToM and neglecting the complexity of human social interactions. To address this\ngap, we propose ToM-SSI: a new benchmark specifically designed to test ToM\ncapabilities in environments rich with social interactions and spatial\ndynamics. While current ToM benchmarks are limited to text-only or dyadic\ninteractions, ToM-SSI is multimodal and includes group interactions of up to\nfour agents that communicate and move in situated environments. This unique\ndesign allows us to study, for the first time, mixed cooperative-obstructive\nsettings and reasoning about multiple agents' mental state in parallel, thus\ncapturing a wider range of social cognition than existing benchmarks. Our\nevaluations reveal that the current models' performance is still severely\nlimited, especially in these new tasks, highlighting critical gaps for future\nresearch.", "published": "2025-09-05 12:58:15", "link": "http://arxiv.org/abs/2509.05066v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Entropy2Vec: Crosslingual Language Modeling Entropy as End-to-End Learnable Language Representations", "abstract": "We introduce Entropy2Vec, a novel framework for deriving cross-lingual\nlanguage representations by leveraging the entropy of monolingual language\nmodels. Unlike traditional typological inventories that suffer from feature\nsparsity and static snapshots, Entropy2Vec uses the inherent uncertainty in\nlanguage models to capture typological relationships between languages. By\ntraining a language model on a single language, we hypothesize that the entropy\nof its predictions reflects its structural similarity to other languages: Low\nentropy indicates high similarity, while high entropy suggests greater\ndivergence. This approach yields dense, non-sparse language embeddings that are\nadaptable to different timeframes and free from missing values. Empirical\nevaluations demonstrate that Entropy2Vec embeddings align with established\ntypological categories and achieved competitive performance in downstream\nmultilingual NLP tasks, such as those addressed by the LinguAlchemy framework.", "published": "2025-09-05 12:40:31", "link": "http://arxiv.org/abs/2509.05060v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Masked Diffusion Language Models with Frequency-Informed Training", "abstract": "We present a masked diffusion language modeling framework for data-efficient\ntraining for the BabyLM 2025 Challenge. Our approach applies diffusion training\nobjectives to language modeling under strict data constraints, incorporating\nfrequency-informed masking that prioritizes learning from rare tokens while\nmaintaining theoretical validity. We explore multiple noise scheduling\nstrategies, including two-mode approaches, and investigate different noise\nweighting schemes within the NELBO objective. We evaluate our method on the\nBabyLM benchmark suite, measuring linguistic competence, world knowledge, and\nhuman-likeness. Results show performance competitive to hybrid\nautoregressive-masked baselines, demonstrating that diffusion-based training\noffers a viable alternative for data-restricted language learning.", "published": "2025-09-05 12:35:06", "link": "http://arxiv.org/abs/2509.05056v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework", "abstract": "Large reasoning models (LRMs) have exhibited strong performance on complex\nreasoning tasks, with further gains achievable through increased computational\nbudgets at inference. However, current test-time scaling methods predominantly\nrely on redundant sampling, ignoring the historical experience utilization,\nthereby limiting computational efficiency. To overcome this limitation, we\npropose Sticker-TTS, a novel test-time scaling framework that coordinates three\ncollaborative LRMs to iteratively explore and refine solutions guided by\nhistorical attempts. At the core of our framework are distilled key\nconditions-termed stickers-which drive the extraction, refinement, and reuse of\ncritical information across multiple rounds of reasoning. To further enhance\nthe efficiency and performance of our framework, we introduce a two-stage\noptimization strategy that combines imitation learning with self-improvement,\nenabling progressive refinement. Extensive evaluations on three challenging\nmathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,\ndemonstrate that Sticker-TTS consistently surpasses strong baselines, including\nself-consistency and advanced reinforcement learning approaches, under\ncomparable inference budgets. These results highlight the effectiveness of\nsticker-guided historical experience utilization. Our code and data are\navailable at https://github.com/RUCAIBox/Sticker-TTS.", "published": "2025-09-05 11:14:11", "link": "http://arxiv.org/abs/2509.05007v1", "categories": ["cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant", "abstract": "In the era of conversational AI, generating accurate and contextually\nappropriate service responses remains a critical challenge. A central question\nremains: Is explicit intent recognition a prerequisite for generating\nhigh-quality service responses, or can models bypass this step and produce\neffective replies directly? This paper conducts a rigorous comparative study to\naddress this fundamental design dilemma. Leveraging two publicly available\nservice interaction datasets, we benchmark several state-of-the-art language\nmodels, including a fine-tuned T5 variant, across both paradigms: Intent-First\nResponse Generation and Direct Response Generation. Evaluation metrics\nencompass both linguistic quality and task success rates, revealing surprising\ninsights into the necessity or redundancy of explicit intent modelling. Our\nfindings challenge conventional assumptions in conversational AI pipelines,\noffering actionable guidelines for designing more efficient and effective\nresponse generation systems.", "published": "2025-09-05 11:13:20", "link": "http://arxiv.org/abs/2509.05006v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Optimizing Small Transformer-Based Language Models for Multi-Label Sentiment Analysis in Short Texts", "abstract": "Sentiment classification in short text datasets faces significant challenges\nsuch as class imbalance, limited training samples, and the inherent\nsubjectivity of sentiment labels -- issues that are further intensified by the\nlimited context in short texts. These factors make it difficult to resolve\nambiguity and exacerbate data sparsity, hindering effective learning. In this\npaper, we evaluate the effectiveness of small Transformer-based models (i.e.,\nBERT and RoBERTa, with fewer than 1 billion parameters) for multi-label\nsentiment classification, with a particular focus on short-text settings.\nSpecifically, we evaluated three key factors influencing model performance: (1)\ncontinued domain-specific pre-training, (2) data augmentation using\nautomatically generated examples, specifically generative data augmentation,\nand (3) architectural variations of the classification head. Our experiment\nresults show that data augmentation improves classification performance, while\ncontinued pre-training on augmented datasets can introduce noise rather than\nboost accuracy. Furthermore, we confirm that modifications to the\nclassification head yield only marginal benefits. These findings provide\npractical guidance for optimizing BERT-based models in resource-constrained\nsettings and refining strategies for sentiment classification in short-text\ndatasets.", "published": "2025-09-05 10:08:14", "link": "http://arxiv.org/abs/2509.04982v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Classification of kinetic-related injury in hospital triage data using NLP", "abstract": "Triage notes, created at the start of a patient's hospital visit, contain a\nwealth of information that can help medical staff and researchers understand\nEmergency Department patient epidemiology and the degree of time-dependent\nillness or injury. Unfortunately, applying modern Natural Language Processing\nand Machine Learning techniques to analyse triage data faces some challenges:\nFirstly, hospital data contains highly sensitive information that is subject to\nprivacy regulation thus need to be analysed on site; Secondly, most hospitals\nand medical facilities lack the necessary hardware to fine-tune a Large\nLanguage Model (LLM), much less training one from scratch; Lastly, to identify\nthe records of interest, expert inputs are needed to manually label the\ndatasets, which can be time-consuming and costly. We present in this paper a\npipeline that enables the classification of triage data using LLM and limited\ncompute resources. We first fine-tuned a pre-trained LLM with a classifier\nusing a small (2k) open sourced dataset on a GPU; and then further fine-tuned\nthe model with a hospital specific dataset of 1000 samples on a CPU. We\ndemonstrated that by carefully curating the datasets and leveraging existing\nmodels and open sourced data, we can successfully classify triage data with\nlimited compute resources.", "published": "2025-09-05 09:49:39", "link": "http://arxiv.org/abs/2509.04969v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts", "abstract": "The controllability of Large Language Models (LLMs) when used as\nconversational agents is a key challenge, particularly to ensure predictable\nand user-personalized responses. This work proposes an ontology-based approach\nto formally define conversational features that are typically qualitative in\nnature. By leveraging a set of linguistic descriptors, we derive quantitative\ndefinitions for qualitatively-defined concepts, enabling their integration into\nan ontology for reasoning and consistency checking. We apply this framework to\nthe task of proficiency-level control in conversations, using CEFR language\nproficiency levels as a case study. These definitions are then formalized in\ndescription logic and incorporated into an ontology, which guides controlled\ntext generation of an LLM through fine-tuning. Experimental results demonstrate\nthat our approach provides consistent and explainable proficiency-level\ndefinitions, improving transparency in conversational AI.", "published": "2025-09-05 08:44:27", "link": "http://arxiv.org/abs/2509.04926v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing", "abstract": "The existing Multimodal Large Language Models (MLLMs) for GUI perception have\nmade great progress. However, the following challenges still exist in prior\nmethods: 1) They model discrete coordinates based on text autoregressive\nmechanism, which results in lower grounding accuracy and slower inference\nspeed. 2) They can only locate predefined sets of elements and are not capable\nof parsing the entire interface, which hampers the broad application and\nsupport for downstream tasks. To address the above issues, we propose\nSparkUI-Parser, a novel end-to-end framework where higher localization\nprecision and fine-grained parsing capability of the entire interface are\nsimultaneously achieved. Specifically, instead of using probability-based\ndiscrete modeling, we perform continuous modeling of coordinates based on a\npre-trained Multimodal Large Language Model (MLLM) with an additional token\nrouter and coordinate decoder. This effectively mitigates the limitations\ninherent in the discrete output characteristics and the token-by-token\ngeneration process of MLLMs, consequently boosting both the accuracy and the\ninference speed. To further enhance robustness, a rejection mechanism based on\na modified Hungarian matching algorithm is introduced, which empowers the model\nto identify and reject non-existent elements, thereby reducing false positives.\nMoreover, we present ScreenParse, a rigorously constructed benchmark to\nsystematically assess structural perception capabilities of GUI models across\ndiverse scenarios. Extensive experiments demonstrate that our approach\nconsistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,\nCAGUI-Grounding and ScreenParse benchmarks. The resources are available at\nhttps://github.com/antgroup/SparkUI-Parser.", "published": "2025-09-05 08:24:12", "link": "http://arxiv.org/abs/2509.04908v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation Reinforcement Learning", "abstract": "Large Language Models (LLMs) have demonstrated remarkable progress in\nlong-context understanding, yet they face significant challenges in\nhigh-quality long-form generation. Existing studies primarily suffer from two\nlimitations: (1) A heavy reliance on scarce, high-quality long-form response\ndata for supervised fine-tuning (SFT) or for pairwise preference reward in\nreinforcement learning (RL). (2) Focus on coarse-grained quality optimization\ndimensions, such as relevance, coherence, and helpfulness, overlooking the\nfine-grained specifics inherent to diverse long-form generation scenarios. To\naddress this issue, we propose a framework using Adaptive Constraint-Enhanced\nreward for long-form generation Reinforcement Learning (ACE-RL). ACE-RL first\nautomatically deconstructs each instruction into a set of fine-grained,\nadaptive constraint criteria by identifying its underlying intents and demands.\nSubsequently, we design a reward mechanism that quantifies the quality of\nlong-form responses based on their satisfaction over corresponding constraints,\nconverting subjective quality evaluation into constraint verification. Finally,\nwe utilize reinforcement learning to guide models toward superior long-form\ngeneration capabilities. Experimental results demonstrate that our ACE-RL\nframework significantly outperforms existing SFT and RL baselines by 20.70% and\n7.32% on WritingBench, and our top-performing model even surpasses proprietary\nsystems like GPT-4o by 7.10%, providing a more effective training paradigm for\nLLMs to generate high-quality content across diverse long-form generation\nscenarios.", "published": "2025-09-05 08:21:41", "link": "http://arxiv.org/abs/2509.04903v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PLaMo 2 Technical Report", "abstract": "In this report, we introduce PLaMo 2, a series of Japanese-focused large\nlanguage models featuring a hybrid Samba-based architecture that transitions to\nfull attention via continual pre-training to support 32K token contexts.\nTraining leverages extensive synthetic corpora to overcome data scarcity, while\ncomputational efficiency is achieved through weight reuse and structured\npruning. This efficient pruning methodology produces an 8B model that achieves\nperformance comparable to our previous 100B model. Post-training further\nrefines the models using a pipeline of supervised fine-tuning (SFT) and direct\npreference optimization (DPO), enhanced by synthetic Japanese instruction data\nand model merging techniques. Optimized for inference using vLLM and\nquantization with minimal accuracy loss, the PLaMo 2 models achieve\nstate-of-the-art results on Japanese benchmarks, outperforming similarly-sized\nopen models in instruction-following, language fluency, and Japanese-specific\nknowledge.", "published": "2025-09-05 08:17:59", "link": "http://arxiv.org/abs/2509.04897v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "L1RA: Dynamic Rank Assignment in LoRA Fine-Tuning", "abstract": "The ability of Large Language Models (LLMs) to solve complex tasks has made\nthem crucial in the development of AI-based applications. However, the high\ncomputational requirements to fine-tune these LLMs on downstream tasks pose\nsignificant challenges, particularly when resources are limited. In response to\nthis challenge, we introduce L1RA, a novel technique aimed at dynamically\ndistributing the rank of low-rank adapters during fine-tuning using LoRA. Given\na rank budget (i.e., total sum of adapters rank), L1RA leverages L1\nregularisation to prune redundant ranks and redistribute them across adapters,\nthereby optimising resource utilisation. Through a series of comprehensive\nexperiments, we empirically demonstrate that L1RA maintains comparable or even\nreduced computational overhead compared to other LoRA variants, including the\nvanilla approach, while achieving same or better performances. Moreover, the\npost-training analysis of rank distribution unveiled insights into the specific\nmodel components requiring the most adaptation to align with the task\nobjective: the feed-forward layers and the attention output projection. These\nresults highlight the efficacy of L1RA in not only enhancing the efficiency of\nLLM fine-tuning, but also in providing valuable diagnostic information for\nmodel refinement and customisation. In conclusion, L1RA stands as a promising\ntechnique for advancing the performance and interpretability of LLM adaptation,\nparticularly in scenarios where computational resources are constrained.", "published": "2025-09-05 08:03:01", "link": "http://arxiv.org/abs/2509.04884v1", "categories": ["cs.CL", "cs.PF"], "primary_category": "cs.CL"}
{"title": "Using LLMs for Multilingual Clinical Entity Linking to ICD-10", "abstract": "The linking of clinical entities is a crucial part of extracting structured\ninformation from clinical texts. It is the process of assigning a code from a\nmedical ontology or classification to a phrase in the text. The International\nClassification of Diseases - 10th revision (ICD-10) is an international\nstandard for classifying diseases for statistical and insurance purposes.\nAutomatically assigning the correct ICD-10 code to terms in discharge summaries\nwill simplify the work of healthcare professionals and ensure consistent coding\nin hospitals. Our paper proposes an approach for linking clinical terms to\nICD-10 codes in different languages using Large Language Models (LLMs). The\napproach consists of a multistage pipeline that uses clinical dictionaries to\nmatch unambiguous terms in the text and then applies in-context learning with\nGPT-4.1 to predict the ICD-10 code for the terms that do not match the\ndictionary. Our system shows promising results in predicting ICD-10 codes on\ndifferent benchmark datasets in Spanish - 0.89 F1 for categories and 0.78 F1 on\nsubcategories on CodiEsp, and Greek - 0.85 F1 on ElCardioCC.", "published": "2025-09-05 07:30:40", "link": "http://arxiv.org/abs/2509.04868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Memorization $\\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?", "abstract": "Driven by vast and diverse textual data, large language models (LLMs) have\ndemonstrated impressive performance across numerous natural language processing\n(NLP) tasks. Yet, a critical question persists: does their generalization arise\nfrom mere memorization of training data or from deep semantic understanding? To\ninvestigate this, we propose a bi-perspective evaluation framework to assess\nLLMs' scenario cognition - the ability to link semantic scenario elements with\ntheir arguments in context. Specifically, we introduce a novel scenario-based\ndataset comprising diverse textual descriptions of fictional facts, annotated\nwith scenario elements. LLMs are evaluated through their capacity to answer\nscenario-related questions (model output perspective) and via probing their\ninternal representations for encoded scenario elements-argument associations\n(internal representation perspective). Our experiments reveal that current LLMs\npredominantly rely on superficial memorization, failing to achieve robust\nsemantic scenario cognition, even in simple cases. These findings expose\ncritical limitations in LLMs' semantic understanding and offer cognitive\ninsights for advancing their capabilities.", "published": "2025-09-05 07:30:01", "link": "http://arxiv.org/abs/2509.04866v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Cognitive-Behavioral Fixation via Multimodal User Viewing Patterns on Social Media", "abstract": "Digital social media platforms frequently contribute to cognitive-behavioral\nfixation, a phenomenon in which users exhibit sustained and repetitive\nengagement with narrow content domains. While cognitive-behavioral fixation has\nbeen extensively studied in psychology, methods for computationally detecting\nand evaluating such fixation remain underexplored. To address this gap, we\npropose a novel framework for assessing cognitive-behavioral fixation by\nanalyzing users' multimodal social media engagement patterns. Specifically, we\nintroduce a multimodal topic extraction module and a cognitive-behavioral\nfixation quantification module that collaboratively enable adaptive,\nhierarchical, and interpretable assessment of user behavior. Experiments on\nexisting benchmarks and a newly curated multimodal dataset demonstrate the\neffectiveness of our approach, laying the groundwork for scalable computational\nanalysis of cognitive fixation. All code in this project is publicly available\nfor research purposes at\nhttps://github.com/Liskie/cognitive-fixation-evaluation.", "published": "2025-09-05 05:50:00", "link": "http://arxiv.org/abs/2509.04823v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding", "abstract": "Spoken Language Understanding (SLU) is a core component of conversational\nsystems, enabling machines to interpret user utterances. Despite its\nimportance, developing effective SLU systems remains challenging due to the\nscarcity of labeled training data and the computational burden of deploying\nLarge Language Models (LLMs) in real-world applications. To further alleviate\nthese issues, we propose an Adaptive Feature Distillation framework that\ntransfers rich semantic representations from a General Text Embeddings\n(GTE)-based teacher model to a lightweight student model. Our method introduces\na dynamic adapter equipped with a Residual Projection Neural Network (RPNN) to\nalign heterogeneous feature spaces, and a Dynamic Distillation Coefficient\n(DDC) that adaptively modulates the distillation strength based on real-time\nfeedback from intent and slot prediction performance. Experiments on the\nChinese profile-based ProSLU benchmark demonstrate that AFD-SLU achieves\nstate-of-the-art results, with 95.67% intent accuracy, 92.02% slot F1 score,\nand 85.50% overall accuracy.", "published": "2025-09-05 05:45:07", "link": "http://arxiv.org/abs/2509.04821v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Finnish Inflectional Classes through Discriminative Lexicon and Deep Learning Models", "abstract": "Descriptions of complex nominal or verbal systems make use of inflectional\nclasses. Inflectional classes bring together nouns which have similar stem\nchanges and use similar exponents in their paradigms. Although inflectional\nclasses can be very useful for language teaching as well as for setting up\nfinite state morphological systems, it is unclear whether inflectional classes\nare cognitively real, in the sense that native speakers would need to discover\nthese classes in order to learn how to properly inflect the nouns of their\nlanguage. This study investigates whether the Discriminative Lexicon Model\n(DLM) can understand and produce Finnish inflected nouns without setting up\ninflectional classes, using a dataset with 55,271 inflected nouns of 2000\nhigh-frequency Finnish nouns from 49 inflectional classes. Several DLM\ncomprehension and production models were set up. Some models were not informed\nabout frequency of use, and provide insight into learnability with infinite\nexposure (endstate learning). Other models were set up from a usage based\nperspective, and were trained with token frequencies being taken into\nconsideration (frequency-informed learning). On training data, models performed\nwith very high accuracies. For held-out test data, accuracies decreased, as\nexpected, but remained acceptable. Across most models, performance increased\nfor inflectional classes with more types, more lower-frequency words, and more\nhapax legomena, mirroring the productivity of the inflectional classes. The\nmodel struggles more with novel forms of unproductive and less productive\nclasses, and performs far better for unseen forms belonging to productive\nclasses. However, for usage-based production models, frequency was the dominant\npredictor of model performance, and correlations with measures of productivity\nwere tenuous or absent.", "published": "2025-09-05 05:24:56", "link": "http://arxiv.org/abs/2509.04813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation", "abstract": "Automating the decision of whether a code change requires manual review is\nvital for maintaining software quality in modern development workflows.\nHowever, the emergence of new programming languages and frameworks creates a\ncritical bottleneck: while large volumes of unlabelled code are readily\navailable, there is an insufficient amount of labelled data to train supervised\nmodels for review classification. We address this challenge by leveraging Large\nLanguage Models (LLMs) to translate code changes from well-resourced languages\ninto equivalent changes in underrepresented or emerging languages, generating\nsynthetic training data where labelled examples are scarce. We assume that\nalthough LLMs have learned the syntax and semantics of new languages from\navailable unlabelled code, they have yet to fully grasp which code changes are\nconsidered significant or review-worthy within these emerging ecosystems. To\novercome this, we use LLMs to generate synthetic change examples and train\nsupervised classifiers on them. We systematically compare the performance of\nthese classifiers against models trained on real labelled data. Our experiments\nacross multiple GitHub repositories and language pairs demonstrate that\nLLM-generated synthetic data can effectively bootstrap review recommendation\nsystems, narrowing the performance gap even in low-resource settings. This\napproach provides a scalable pathway to extend automated code review\ncapabilities to rapidly evolving technology stacks, even in the absence of\nannotated data.", "published": "2025-09-05 05:17:14", "link": "http://arxiv.org/abs/2509.04810v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs", "abstract": "As large language models transition to agentic systems, current safety\nevaluation frameworks face critical gaps in assessing deployment-specific\nrisks. We introduce AgentSeer, an observability-based evaluation framework that\ndecomposes agentic executions into granular action and component graphs,\nenabling systematic agentic-situational assessment. Through cross-model\nvalidation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and\niterative refinement attacks, we demonstrate fundamental differences between\nmodel-level and agentic-level vulnerability profiles. Model-level evaluation\nreveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash\n(50.00% ASR), with both models showing susceptibility to social engineering\nwhile maintaining logic-based attack resistance. However, agentic-level\nassessment exposes agent-specific risks invisible to traditional evaluation. We\ndiscover \"agentic-only\" vulnerabilities that emerge exclusively in agentic\ncontexts, with tool-calling showing 24-60% higher ASR across both models.\nCross-model analysis reveals universal agentic patterns, agent transfer\noperations as highest-risk tools, semantic rather than syntactic vulnerability\nmechanisms, and context-dependent attack effectiveness, alongside\nmodel-specific security profiles in absolute ASR levels and optimal injection\nstrategies. Direct attack transfer from model-level to agentic contexts shows\ndegraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash:\n28%), while context-aware iterative attacks successfully compromise objectives\nthat failed at model-level, confirming systematic evaluation gaps. These\nfindings establish the urgent need for agentic-situation evaluation paradigms,\nwith AgentSeer providing the standardized methodology and empirical validation.", "published": "2025-09-05 04:36:17", "link": "http://arxiv.org/abs/2509.04802v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive Synthetic Training", "abstract": "Large language models increasingly rely on synthetic data due to\nhuman-written content scarcity, yet recursive training on model-generated\noutputs leads to model collapse, a degenerative process threatening factual\nreliability. We define knowledge collapse as a distinct three-stage phenomenon\nwhere factual accuracy deteriorates while surface fluency persists, creating\n\"confidently wrong\" outputs that pose critical risks in accuracy-dependent\ndomains. Through controlled experiments with recursive synthetic training, we\ndemonstrate that collapse trajectory and timing depend critically on\ninstruction format, distinguishing instruction-following collapse from\ntraditional model collapse through its conditional, prompt-dependent nature. We\npropose domain-specific synthetic training as a targeted mitigation strategy\nthat achieves substantial improvements in collapse resistance while maintaining\ncomputational efficiency. Our evaluation framework combines model-centric\nindicators with task-centric metrics to detect distinct degradation phases,\nenabling reproducible assessment of epistemic deterioration across different\nlanguage models. These findings provide both theoretical insights into collapse\ndynamics and practical guidance for sustainable AI training in\nknowledge-intensive applications where accuracy is paramount.", "published": "2025-09-05 04:29:15", "link": "http://arxiv.org/abs/2509.04796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects", "abstract": "Personality manipulation in large language models (LLMs) is increasingly\napplied in customer service and agentic scenarios, yet its mechanisms and\ntrade-offs remain unclear. We present a systematic study of personality control\nusing the Big Five traits, comparing in-context learning (ICL),\nparameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our\ncontributions are fourfold. First, we construct a contrastive dataset with\nbalanced high/low trait responses, enabling effective steering vector\ncomputation and fair cross-method evaluation. Second, we introduce a unified\nevaluation framework based on within-run $\\Delta$ analysis that disentangles,\nreasoning capability, agent performance, and demographic bias across MMLU,\nGAIA, and BBQ benchmarks. Third, we develop trait purification techniques to\nseparate openness from conscientiousness, addressing representational overlap\nin trait encoding. Fourth, we propose a three-level stability framework that\nquantifies method-, trait-, and combination-level robustness, offering\npractical guidance under deployment constraints. Experiments on Gemma-2-2B-IT\nand LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment\nwith minimal capability loss, PEFT delivers the highest alignment at the cost\nof degraded task performance, and MS provides lightweight runtime control with\ncompetitive effectiveness. Trait-level analysis shows openness as uniquely\nchallenging, agreeableness as most resistant to ICL, and personality encoding\nconsolidating around intermediate layers. Taken together, these results\nestablish personality manipulation as a multi-level probe into behavioral\nrepresentation, linking surface conditioning, parameter encoding, and\nactivation-level steering, and positioning mechanistic steering as a\nlightweight alternative to fine-tuning for both deployment and\ninterpretability.", "published": "2025-09-05 04:19:15", "link": "http://arxiv.org/abs/2509.04794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Diversity in Large Language Models via Determinantal Point Processes", "abstract": "Supervised fine-tuning and reinforcement learning are two popular methods for\npost-training large language models (LLMs). While improving the model's\nperformance on downstream tasks, they often reduce the model's output\ndiversity, leading to narrow, canonical responses. Existing methods to enhance\ndiversity are limited, either by operating at inference time or by focusing on\nlexical differences. We propose a novel training method named DQO based on\ndeterminantal point processes (DPPs) to jointly optimize LLMs for quality and\nsemantic diversity. Our approach samples and embeds a group of responses for\neach prompt, then uses the determinant of a kernel-based similarity matrix to\nmeasure diversity as the volume spanned by the embeddings of these responses.\nExperiments across instruction-following, summarization, story generation, and\nreasoning tasks demonstrate that our method substantially improves semantic\ndiversity without sacrificing model quality.", "published": "2025-09-05 03:47:06", "link": "http://arxiv.org/abs/2509.04784v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Decoders Laugh as Loud as Encoders", "abstract": "From the dawn of the computer, Allen Turing dreamed of a robot that could\ncommunicate using language as a human being. The recent advances in the field\nof Large Language Models (LLMs) shocked the scientific community when a single\nmodel can apply for various natural language processing (NLP) tasks, while the\noutput results are sometimes even better than most human communication skills.\nModels such as GPT, Claude, Grok, etc. have left their mark on the scientific\ncommunity. However, it is unclear how much these models understand what they\nproduce, especially in a nuanced theme such as humor. The question of whether\ncomputers understand humor is still open (among the decoders, the latest to be\nchecked was GPT-2). We addressed this issue in this paper; we have showed that\na fine-tuned decoder (GPT-4o) performed (Mean F1-macro score of 0.85) as well\nas the best fine-tuned encoder (RoBERTa with a Mean of F1-score 0.86)", "published": "2025-09-05 03:22:38", "link": "http://arxiv.org/abs/2509.04779v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework", "abstract": "Accurately answering complex questions has consistently been a significant\nchallenge for Large Language Models (LLMs). To address this, this paper\nproposes a multi-hop question decomposition method for complex questions,\nbuilding upon research within the MQUAKE framework. Utilizing the LLAMA3 model,\nwe systematically investigate the impact of multi-hop question decomposition\nwithin knowledge graphs on model comprehension and reasoning accuracy, both\nbefore and after model training. In our experiments, we systematically\npartitioned and converted the MQUAKE-T dataset into two distinct formats: a\nsingle-hop dataset designed for directly answering complex questions, and a\nmulti-hop dataset constructed using the multi-hop question decomposition\nmethod. We then fine-tuned the LLAMA3 model on these datasets and conducted\ninference tests. Our results demonstrate that, without fine-tuning the LLM, the\nprediction performance based on the multi-hop question decomposition method\nsignificantly outperforms the method of directly answering complex questions.\nAfter fine-tuning using the LoRA (Low-Rank Adaptation) method, the performance\nof both approaches improved compared to the untrained baseline. Crucially, the\nmethod utilizing multi-hop decomposition consistently maintained its\nsuperiority. These findings validate the effectiveness of the multi-hop\ndecomposition method both before and after training, demonstrating its\ncapability to effectively enhance the LLM's ability to answer complex\nquestions.", "published": "2025-09-05 02:58:45", "link": "http://arxiv.org/abs/2509.04770v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Study of Large Language Models for Patient Information Extraction: Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning", "abstract": "Natural language processing (NLP) is a key technology to extract important\npatient information from clinical narratives to support healthcare\napplications. The rapid development of large language models (LLMs) has\nrevolutionized many NLP tasks in the clinical domain, yet their optimal use in\npatient information extraction tasks requires further exploration. This study\nexamines LLMs' effectiveness in patient information extraction, focusing on LLM\narchitectures, fine-tuning strategies, and multi-task instruction tuning\ntechniques for developing robust and generalizable patient information\nextraction systems. This study aims to explore key concepts of using LLMs for\nclinical concept and relation extraction tasks, including: (1) encoder-only or\ndecoder-only LLMs, (2) prompt-based parameter-efficient fine-tuning (PEFT)\nalgorithms, and (3) multi-task instruction tuning on few-shot learning\nperformance. We benchmarked a suite of LLMs, including encoder-based LLMs\n(BERT, GatorTron) and decoder-based LLMs (GatorTronGPT, Llama 3.1,\nGatorTronLlama), across five datasets. We compared traditional full-size\nfine-tuning and prompt-based PEFT. We explored a multi-task instruction tuning\nframework that combines both tasks across four datasets to evaluate the\nzero-shot and few-shot learning performance using the leave-one-dataset-out\nstrategy.", "published": "2025-09-05 02:07:40", "link": "http://arxiv.org/abs/2509.04753v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary Generalization", "abstract": "Sign language datasets are often not representative in terms of vocabulary,\nunderscoring the need for models that generalize to unseen signs. Vector\nquantization is a promising approach for learning discrete, token-like\nrepresentations, but it has not been evaluated whether the learned units\ncapture spurious correlations that hinder out-of-vocabulary performance. This\nwork investigates two phonological inductive biases: Parameter Disentanglement,\nan architectural bias, and Phonological Semi-Supervision, a regularization\ntechnique, to improve isolated sign recognition of known signs and\nreconstruction quality of unseen signs with a vector-quantized autoencoder. The\nprimary finding is that the learned representations from the proposed model are\nmore effective for one-shot reconstruction of unseen signs and more\ndiscriminative for sign identification compared to a controlled baseline. This\nwork provides a quantitative analysis of how explicit, linguistically-motivated\nbiases can improve the generalization of learned representations of sign\nlanguage.", "published": "2025-09-05 01:55:41", "link": "http://arxiv.org/abs/2509.04745v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning", "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated\nimpressive capabilities across various vision-language tasks. However, their\nreasoning abilities in the multimodal symbolic music domain remain largely\nunexplored. We introduce WildScore, the first in-the-wild multimodal symbolic\nmusic reasoning and analysis benchmark, designed to evaluate MLLMs' capacity to\ninterpret real-world music scores and answer complex musicological queries.\nEach instance in WildScore is sourced from genuine musical compositions and\naccompanied by authentic user-generated questions and discussions, capturing\nthe intricacies of practical music analysis. To facilitate systematic\nevaluation, we propose a systematic taxonomy, comprising both high-level and\nfine-grained musicological ontologies. Furthermore, we frame complex music\nreasoning as multiple-choice question answering, enabling controlled and\nscalable assessment of MLLMs' symbolic music understanding. Empirical\nbenchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns\nin their visual-symbolic reasoning, uncovering both promising directions and\npersistent challenges for MLLMs in symbolic music reasoning and analysis. We\nrelease the dataset and code.", "published": "2025-09-05 01:54:50", "link": "http://arxiv.org/abs/2509.04744v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning", "abstract": "The convergence of Language models, Agent models, and World models represents\na critical frontier for artificial intelligence. While recent progress has\nfocused on scaling Language and Agent models, the development of sophisticated,\nexplicit World Models remains a key bottleneck, particularly for complex,\nlong-horizon multi-agent tasks. In domains such as robotic soccer, agents\ntrained via standard reinforcement learning in high-fidelity but\nstructurally-flat simulators often fail due to intractable exploration spaces\nand sparse rewards. This position paper argues that the next frontier in\ndeveloping capable agents lies in creating environments that possess an\nexplicit, hierarchical World Model. We contend that this is best achieved\nthrough hierarchical scaffolding, where complex goals are decomposed into\nstructured, manageable subgoals. Drawing evidence from a systematic review of\n2024 research in multi-agent soccer, we identify a clear and decisive trend\ntowards integrating symbolic and hierarchical methods with multi-agent\nreinforcement learning (MARL). These approaches implicitly or explicitly\nconstruct a task-based world model to guide agent learning. We then propose a\nparadigm shift: leveraging Large Language Models to dynamically generate this\nhierarchical scaffold, effectively using language to structure the World Model\non the fly. This language-driven world model provides an intrinsic curriculum,\ndense and meaningful learning signals, and a framework for compositional\nlearning, enabling Agent Models to acquire sophisticated, strategic behaviors\nwith far greater sample efficiency. By building environments with explicit,\nlanguage-configurable task layers, we can bridge the gap between low-level\nreactive behaviors and high-level strategic team play, creating a powerful and\ngeneralizable framework for training the next generation of intelligent agents.", "published": "2025-09-05 01:03:51", "link": "http://arxiv.org/abs/2509.04731v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO", "68T05, 90C40, 91A26, 68T42, 93E35", "I.2.11; I.2.6; I.2.8; I.2.9; I.2.7"], "primary_category": "cs.AI"}
{"title": "KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering", "abstract": "Retrieval-Augmented Generation (RAG) mitigates hallucination in Large\nLanguage Models (LLMs) by incorporating external data, with Knowledge Graphs\n(KGs) offering crucial information for question answering. Traditional\nKnowledge Graph Question Answering (KGQA) methods rely on semantic parsing,\nwhich typically retrieves knowledge strictly necessary for answer generation,\nthus often suffer from low coverage due to rigid schema requirements and\nsemantic ambiguity. We present KERAG, a novel KG-based RAG pipeline that\nenhances QA coverage by retrieving a broader subgraph likely to contain\nrelevant information. Our retrieval-filtering-summarization approach, combined\nwith fine-tuned LLMs for Chain-of-Thought reasoning on knowledge sub-graphs,\nreduces noises and improves QA for both simple and complex questions.\nExperiments demonstrate that KERAG surpasses state-of-the-art solutions by\nabout 7% in quality and exceeds GPT-4o (Tool) by 10-21%.", "published": "2025-09-05 00:06:00", "link": "http://arxiv.org/abs/2509.04716v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool", "abstract": "We present WinT3R, a feed-forward reconstruction model capable of online\nprediction of precise camera poses and high-quality point maps. Previous\nmethods suffer from a trade-off between reconstruction quality and real-time\nperformance. To address this, we first introduce a sliding window mechanism\nthat ensures sufficient information exchange among frames within the window,\nthereby improving the quality of geometric predictions without large\ncomputation. In addition, we leverage a compact representation of cameras and\nmaintain a global camera token pool, which enhances the reliability of camera\npose estimation without sacrificing efficiency. These designs enable WinT3R to\nachieve state-of-the-art performance in terms of online reconstruction quality,\ncamera pose estimation, and reconstruction speed, as validated by extensive\nexperiments on diverse datasets. Code and model are publicly available at\nhttps://github.com/LiZizun/WinT3R.", "published": "2025-09-05 17:59:47", "link": "http://arxiv.org/abs/2509.05296v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation", "abstract": "Recent research has been increasingly focusing on developing 3D world models\nthat simulate complex real-world scenarios. World models have found broad\napplications across various domains, including embodied AI, autonomous driving,\nentertainment, etc. A more realistic simulation with accurate physics will\neffectively narrow the sim-to-real gap and allow us to gather rich information\nabout the real world conveniently. While traditional manual modeling has\nenabled the creation of virtual 3D scenes, modern approaches have leveraged\nadvanced machine learning algorithms for 3D world generation, with most recent\nadvances focusing on generative methods that can create virtual worlds based on\nuser instructions. This work explores such a research direction by proposing\nLatticeWorld, a simple yet effective 3D world generation framework that\nstreamlines the industrial production pipeline of 3D environments. LatticeWorld\nleverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering\nengine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed\nframework accepts textual descriptions and visual instructions as multimodal\ninputs and creates large-scale 3D interactive worlds with dynamic agents,\nfeaturing competitive multi-agent interaction, high-fidelity physics\nsimulation, and real-time rendering. We conduct comprehensive experiments to\nevaluate LatticeWorld, showing that it achieves superior accuracy in scene\nlayout generation and visual fidelity. Moreover, LatticeWorld achieves over a\n$90\\times$ increase in industrial production efficiency while maintaining high\ncreative quality compared with traditional manual production methods. Our demo\nvideo is available at https://youtu.be/8VWZXpERR18", "published": "2025-09-05 17:22:33", "link": "http://arxiv.org/abs/2509.05263v1", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Scaling Performance of Large Language Model Pretraining", "abstract": "Large language models (LLMs) show best-in-class performance across a wide\nrange of natural language processing applications. Training these models is an\nextremely computationally expensive task; frontier Artificial Intelligence (AI)\nresearch companies are investing billions of dollars into supercomputing\ninfrastructure to train progressively larger models on increasingly massive\ndatasets. Unfortunately, information about the scaling performance and training\nconsiderations of these large training pipelines is scarce in public\nliterature. Working with large-scale datasets and models can be complex and\npractical recommendations are scarce in the public literature for tuning\ntraining performance when scaling up large language models. In this paper, we\naim to demystify the large language model pretraining pipeline somewhat - in\nparticular with respect to distributed training, managing large datasets across\nhundreds of nodes, and scaling up data parallelism with an emphasis on fully\nleveraging available GPU compute capacity.", "published": "2025-09-05 17:14:58", "link": "http://arxiv.org/abs/2509.05258v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "Recomposer: Event-roll-guided generative audio editing", "abstract": "Editing complex real-world sound scenes is difficult because individual sound\nsources overlap in time. Generative models can fill-in missing or corrupted\ndetails based on their strong prior understanding of the data domain. We\npresent a system for editing individual sound events within complex scenes able\nto delete, insert, and enhance individual sound events based on textual edit\ndescriptions (e.g., ``enhance Door'') and a graphical representation of the\nevent timing derived from an ``event roll'' transcription. We present an\nencoder-decoder transformer working on SoundStream representations, trained on\nsynthetic (input, desired output) audio example pairs formed by adding isolated\nsound events to dense, real-world backgrounds. Evaluation reveals the\nimportance of each part of the edit descriptions -- action, class, timing. Our\nwork demonstrates ``recomposition'' is an important and practical application.", "published": "2025-09-05 17:14:29", "link": "http://arxiv.org/abs/2509.05256v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "COGITAO: A Visual Reasoning Framework To Study Compositionality & Generalization", "abstract": "The ability to compose learned concepts and apply them in novel settings is\nkey to human intelligence, but remains a persistent limitation in\nstate-of-the-art machine learning models. To address this issue, we introduce\nCOGITAO, a modular and extensible data generation framework and benchmark\ndesigned to systematically study compositionality and generalization in visual\ndomains. Drawing inspiration from ARC-AGI's problem-setting, COGITAO constructs\nrule-based tasks which apply a set of transformations to objects in grid-like\nenvironments. It supports composition, at adjustable depth, over a set of 28\ninteroperable transformations, along with extensive control over grid\nparametrization and object properties. This flexibility enables the creation of\nmillions of unique task rules -- surpassing concurrent datasets by several\norders of magnitude -- across a wide range of difficulties, while allowing\nvirtually unlimited sample generation per rule. We provide baseline experiments\nusing state-of-the-art vision models, highlighting their consistent failures to\ngeneralize to novel combinations of familiar elements, despite strong in-domain\nperformance. COGITAO is fully open-sourced, including all code and datasets, to\nsupport continued research in this field.", "published": "2025-09-05 17:01:05", "link": "http://arxiv.org/abs/2509.05249v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Uncertain but Useful: Leveraging CNN Variability into Data Augmentation", "abstract": "Deep learning (DL) is rapidly advancing neuroimaging by achieving\nstate-of-the-art performance with reduced computation times. Yet the numerical\nstability of DL models -- particularly during training -- remains\nunderexplored. While inference with DL is relatively stable, training\nintroduces additional variability primarily through iterative stochastic\noptimization. We investigate this training-time variability using FastSurfer, a\nCNN-based whole-brain segmentation pipeline. Controlled perturbations are\nintroduced via floating point perturbations and random seeds. We find that: (i)\nFastSurfer exhibits higher variability compared to that of a traditional\nneuroimaging pipeline, suggesting that DL inherits and is particularly\nsusceptible to sources of instability present in its predecessors; (ii)\nensembles generated with perturbations achieve performance similar to an\nunperturbed baseline; and (iii) variability effectively produces ensembles of\nnumerical model families that can be repurposed for downstream applications. As\na proof of concept, we demonstrate that numerical ensembles can be used as a\ndata augmentation strategy for brain age regression. These findings position\ntraining-time variability not only as a reproducibility concern but also as a\nresource that can be harnessed to improve robustness and enable new\napplications in neuroimaging.", "published": "2025-09-05 16:54:26", "link": "http://arxiv.org/abs/2509.05238v1", "categories": ["math.NA", "cs.AI", "cs.NA"], "primary_category": "math.NA"}
{"title": "RapidGNN: Energy and Communication-Efficient Distributed Training on Large-Scale Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) have become popular across a diverse set of\ntasks in exploring structural relationships between entities. However, due to\nthe highly connected structure of the datasets, distributed training of GNNs on\nlarge-scale graphs poses significant challenges. Traditional sampling-based\napproaches mitigate the computational loads, yet the communication overhead\nremains a challenge. This paper presents RapidGNN, a distributed GNN training\nframework with deterministic sampling-based scheduling to enable efficient\ncache construction and prefetching of remote features. Evaluation on benchmark\ngraph datasets demonstrates RapidGNN's effectiveness across different scales\nand topologies. RapidGNN improves end-to-end training throughput by 2.46x to\n3.00x on average over baseline methods across the benchmark datasets, while\ncutting remote feature fetches by over 9.70x to 15.39x. RapidGNN further\ndemonstrates near-linear scalability with an increasing number of computing\nunits efficiently. Furthermore, it achieves increased energy efficiency over\nthe baseline methods for both CPU and GPU by 44% and 32%, respectively.", "published": "2025-09-05 16:10:20", "link": "http://arxiv.org/abs/2509.05207v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet", "abstract": "The classification of 3D point clouds is crucial for applications such as\nautonomous driving, robotics, and augmented reality. However, the commonly used\nModelNet40 dataset suffers from limitations such as inconsistent labeling, 2D\ndata, size mismatches, and inadequate class differentiation, which hinder model\nperformance. This paper introduces ModelNet-R, a meticulously refined version\nof ModelNet40 designed to address these issues and serve as a more reliable\nbenchmark. Additionally, this paper proposes Point-SkipNet, a lightweight\ngraph-based neural network that leverages efficient sampling, neighborhood\ngrouping, and skip connections to achieve high classification accuracy with\nreduced computational overhead. Extensive experiments demonstrate that models\ntrained in ModelNet-R exhibit significant performance improvements. Notably,\nPoint-SkipNet achieves state-of-the-art accuracy on ModelNet-R with a\nsubstantially lower parameter count compared to contemporary models. This\nresearch highlights the crucial role of dataset quality in optimizing model\nefficiency for 3D point cloud classification. For more details, see the code\nat: https://github.com/m-saeid/ModeNetR_PointSkipNet.", "published": "2025-09-05 15:57:36", "link": "http://arxiv.org/abs/2509.05198v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "AI Agents for Web Testing: A Case Study in the Wild", "abstract": "Automated web testing plays a critical role in ensuring high-quality user\nexperiences and delivering business value. Traditional approaches primarily\nfocus on code coverage and load testing, but often fall short of capturing\ncomplex user behaviors, leaving many usability issues undetected. The emergence\nof large language models (LLM) and AI agents opens new possibilities for web\ntesting by enabling human-like interaction with websites and a general\nawareness of common usability problems. In this work, we present WebProber, a\nprototype AI agent-based web testing framework. Given a URL, WebProber\nautonomously explores the website, simulating real user interactions,\nidentifying bugs and usability issues, and producing a human-readable report.\nWe evaluate WebProber through a case study of 120 academic personal websites,\nwhere it uncovered 29 usability issues--many of which were missed by\ntraditional tools. Our findings highlight agent-based testing as a promising\ndirection while outlining directions for developing next-generation,\nuser-centered testing frameworks.", "published": "2025-09-05 15:57:16", "link": "http://arxiv.org/abs/2509.05197v1", "categories": ["cs.SE", "cs.AI", "cs.HC"], "primary_category": "cs.SE"}
{"title": "Accuracy-Constrained CNN Pruning for Efficient and Reliable EEG-Based Seizure Detection", "abstract": "Deep learning models, especially convolutional neural networks (CNNs), have\nshown considerable promise for biomedical signals such as EEG-based seizure\ndetection. However, these models come with challenges, primarily due to their\nsize and compute requirements in environments where real-time detection or\nlimited resources are available. In this study, we present a lightweight\none-dimensional CNN model with structured pruning to improve efficiency and\nreliability. The model was trained with mild early stopping to address possible\noverfitting, achieving an accuracy of 92.78% and a macro-F1 score of 0.8686.\nStructured pruning of the baseline CNN involved removing 50% of the\nconvolutional kernels based on their importance to model predictions.\nSurprisingly, after pruning the weights and memory by 50%, the new network was\nstill able to maintain predictive capabilities, while modestly increasing\nprecision to 92.87% and improving the macro-F1 score to 0.8707. Overall, we\npresent a convincing case that structured pruning removes redundancy, improves\ngeneralization, and, in combination with mild early stopping, achieves a\npromising way forward to improve seizure detection efficiency and reliability,\nwhich is clear motivation for resource-limited settings.", "published": "2025-09-05 15:42:15", "link": "http://arxiv.org/abs/2509.05190v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Exploring Situated Stabilities of a Rhythm Generation System through Variational Cross-Examination", "abstract": "This paper investigates GrooveTransformer, a real-time rhythm generation\nsystem, through the postphenomenological framework of Variational\nCross-Examination (VCE). By reflecting on its deployment across three distinct\nartistic contexts, we identify three stabilities: an autonomous drum\naccompaniment generator, a rhythmic control voltage sequencer in Eurorack\nformat, and a rhythm driver for a harmonic accompaniment system. The\nversatility of its applications was not an explicit goal from the outset of the\nproject. Thus, we ask: how did this multistability emerge? Through VCE, we\nidentify three key contributors to its emergence: the affordances of system\ninvariants, the interdisciplinary collaboration, and the situated nature of its\ndevelopment. We conclude by reflecting on the viability of VCE as a descriptive\nand analytical method for Digital Musical Instrument (DMI) design, emphasizing\nits value in uncovering how technologies mediate, co-shape, and are co-shaped\nby users and contexts.", "published": "2025-09-05 14:38:02", "link": "http://arxiv.org/abs/2509.05145v1", "categories": ["cs.HC", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Evaluation and Comparison Semantics for ODRL", "abstract": "We consider the problem of evaluating, and comparing computational policies\nin the Open Digital Rights Language (ODRL), which has become the de facto\nstandard for governing the access and usage of digital resources. Although\npreliminary progress has been made on the formal specification of the\nlanguage's features, a comprehensive formal semantics of ODRL is still missing.\nIn this paper, we provide a simple and intuitive formal semantics for ODRL that\nis based on query answering. Our semantics refines previous formalisations, and\nis aligned with the latest published specification of the language (2.2).\nBuilding on our evaluation semantics, and motivated by data sharing scenarios,\nwe also define and study the problem of comparing two policies, detecting\nequivalent, more restrictive or more permissive policies.", "published": "2025-09-05 14:30:41", "link": "http://arxiv.org/abs/2509.05139v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GenAI-based test case generation and execution in SDV platform", "abstract": "This paper introduces a GenAI-driven approach for automated test case\ngeneration, leveraging Large Language Models and Vision-Language Models to\ntranslate natural language requirements and system diagrams into structured\nGherkin test cases. The methodology integrates Vehicle Signal Specification\nmodeling to standardize vehicle signal definitions, improve compatibility\nacross automotive subsystems, and streamline integration with third-party\ntesting tools. Generated test cases are executed within the digital.auto\nplayground, an open and vendor-neutral environment designed to facilitate rapid\nvalidation of software-defined vehicle functionalities. We evaluate our\napproach using the Child Presence Detection System use case, demonstrating\nsubstantial reductions in manual test specification effort and rapid execution\nof generated tests. Despite significant automation, the generation of test\ncases and test scripts still requires manual intervention due to current\nlimitations in the GenAI pipeline and constraints of the digital.auto platform.", "published": "2025-09-05 13:50:26", "link": "http://arxiv.org/abs/2509.05112v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback", "abstract": "While humans are inherently social creatures, the challenge of identifying\nwhen and how to assist and collaborate with others - particularly when pursuing\nindependent goals - can hinder cooperation. To address this challenge, we aim\nto develop an AI system that provides useful feedback to promote prosocial\nbehaviour - actions that benefit others, even when not directly aligned with\none's own goals. We introduce ProToM, a Theory of Mind-informed facilitator\nthat promotes prosocial actions in multi-agent systems by providing targeted,\ncontext-sensitive feedback to individual agents. ProToM first infers agents'\ngoals using Bayesian inverse planning, then selects feedback to communicate by\nmaximising expected utility, conditioned on the inferred goal distribution. We\nevaluate our approach against baselines in two multi-agent environments: Doors,\nKeys, and Gems, as well as Overcooked. Our results suggest that\nstate-of-the-art large language and reasoning models fall short of\ncommunicating feedback that is both contextually grounded and well-timed -\nleading to higher communication overhead and task speedup. In contrast, ProToM\nprovides targeted and helpful feedback, achieving a higher success rate,\nshorter task completion times, and is consistently preferred by human users.", "published": "2025-09-05 13:30:17", "link": "http://arxiv.org/abs/2509.05091v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization", "abstract": "Industrial product inspection is often performed using Anomaly Detection (AD)\nframeworks trained solely on non-defective samples. Although defective samples\ncan be collected during production, leveraging them usually requires\npixel-level annotations, limiting scalability. To address this, we propose\nADClick, an Interactive Image Segmentation (IIS) algorithm for industrial\nanomaly detection. ADClick generates pixel-wise anomaly annotations from only a\nfew user clicks and a brief textual description, enabling precise and efficient\nlabeling that significantly improves AD model performance (e.g., AP = 96.1\\% on\nMVTec AD). We further introduce ADClick-Seg, a cross-modal framework that\naligns visual features and textual prompts via a prototype-based approach for\nanomaly detection and localization. By combining pixel-level priors with\nlanguage-guided cues, ADClick-Seg achieves state-of-the-art results on the\nchallenging ``Multi-class'' AD task (AP = 80.0\\%, PRO = 97.5\\%, Pixel-AUROC =\n99.1\\% on MVTec AD).", "published": "2025-09-05 11:45:17", "link": "http://arxiv.org/abs/2509.05034v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Pointing-Guided Target Estimation via Transformer-Based Attention", "abstract": "Deictic gestures, like pointing, are a fundamental form of non-verbal\ncommunication, enabling humans to direct attention to specific objects or\nlocations. This capability is essential in Human-Robot Interaction (HRI), where\nrobots should be able to predict human intent and anticipate appropriate\nresponses. In this work, we propose the Multi-Modality Inter-TransFormer\n(MM-ITF), a modular architecture to predict objects in a controlled tabletop\nscenario with the NICOL robot, where humans indicate targets through natural\npointing gestures. Leveraging inter-modality attention, MM-ITF maps 2D pointing\ngestures to object locations, assigns a likelihood score to each, and\nidentifies the most likely target. Our results demonstrate that the method can\naccurately predict the intended object using monocular RGB data, thus enabling\nintuitive and accessible human-robot collaboration. To evaluate the\nperformance, we introduce a patch confusion matrix, providing insights into the\nmodel's predictions across candidate object locations. Code available at:\nhttps://github.com/lucamuellercode/MMITF.", "published": "2025-09-05 11:42:03", "link": "http://arxiv.org/abs/2509.05031v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "I.2.9; I.2.10; I.2.6"], "primary_category": "cs.RO"}
{"title": "Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly Detection", "abstract": "Advanced Persistent Threats (APTs) present a considerable challenge to\ncybersecurity due to their stealthy, long-duration nature. Traditional\nsupervised learning methods typically require large amounts of labeled data,\nwhich is often scarce in real-world scenarios. This paper introduces a novel\napproach that combines AutoEncoders for anomaly detection with active learning\nto iteratively enhance APT detection. By selectively querying an oracle for\nlabels on uncertain or ambiguous samples, our method reduces labeling costs\nwhile improving detection accuracy, enabling the model to effectively learn\nwith minimal data and reduce reliance on extensive manual labeling. We present\na comprehensive formulation of the Attention Adversarial Dual AutoEncoder-based\nanomaly detection framework and demonstrate how the active learning loop\nprogressively enhances the model's performance. The framework is evaluated on\nreal-world, imbalanced provenance trace data from the DARPA Transparent\nComputing program, where APT-like attacks account for just 0.004\\% of the data.\nThe datasets, which cover multiple operating systems including Android, Linux,\nBSD, and Windows, are tested in two attack scenarios. The results show\nsubstantial improvements in detection rates during active learning,\noutperforming existing methods.", "published": "2025-09-05 10:47:49", "link": "http://arxiv.org/abs/2509.04999v1", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CR"}
{"title": "LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of Dual-Loop Edge-Terminal Collaboration", "abstract": "The ubiquitous computing resources in 6G networks provide ideal environments\nfor the fusion of large language models (LLMs) and intelligent services through\nthe agent framework. With auxiliary modules and planning cores, LLM-enabled\nagents can autonomously plan and take actions to deal with diverse environment\nsemantics and user intentions. However, the limited resources of individual\nnetwork devices significantly hinder the efficient operation of LLM-enabled\nagents with complex tool calls, highlighting the urgent need for efficient\nmulti-level device collaborations. To this end, the framework and method of the\nLLM-enabled multi-agent system with dual-loop terminal-edge collaborations are\nproposed in 6G networks. Firstly, the outer loop consists of the iterative\ncollaborations between the global agent and multiple sub-agents deployed on\nedge servers and terminals, where the planning capability is enhanced through\ntask decomposition and parallel sub-task distribution. Secondly, the inner loop\nutilizes sub-agents with dedicated roles to circularly reason, execute, and\nreplan the sub-task, and the parallel tool calling generation with offloading\nstrategies is incorporated to improve efficiency. The improved task planning\ncapability and task execution efficiency are validated through the conducted\ncase study in 6G-supported urban safety governance. Finally, the open\nchallenges and future directions are thoroughly analyzed in 6G networks,\naccelerating the advent of the 6G era.", "published": "2025-09-05 10:40:31", "link": "http://arxiv.org/abs/2509.04993v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "High-Resolution Global Land Surface Temperature Retrieval via a Coupled Mechanism-Machine Learning Framework", "abstract": "Land surface temperature (LST) is vital for land-atmosphere interactions and\nclimate processes. Accurate LST retrieval remains challenging under\nheterogeneous land cover and extreme atmospheric conditions. Traditional split\nwindow (SW) algorithms show biases in humid environments; purely machine\nlearning (ML) methods lack interpretability and generalize poorly with limited\ndata. We propose a coupled mechanism model-ML (MM-ML) framework integrating\nphysical constraints with data-driven learning for robust LST retrieval. Our\napproach fuses radiative transfer modeling with data components, uses MODTRAN\nsimulations with global atmospheric profiles, and employs physics-constrained\noptimization. Validation against 4,450 observations from 29 global sites shows\nMM-ML achieves MAE=1.84K, RMSE=2.55K, and R-squared=0.966, outperforming\nconventional methods. Under extreme conditions, MM-ML reduces errors by over\n50%. Sensitivity analysis indicates LST estimates are most sensitive to sensor\nradiance, then water vapor, and less to emissivity, with MM-ML showing superior\nstability. These results demonstrate the effectiveness of our coupled modeling\nstrategy for retrieving geophysical parameters. The MM-ML framework combines\nphysical interpretability with nonlinear modeling capacity, enabling reliable\nLST retrieval in complex environments and supporting climate monitoring and\necosystem studies.", "published": "2025-09-05 10:37:27", "link": "http://arxiv.org/abs/2509.04991v1", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "Exploring an implementation of quantum learning pipeline for support vector machines", "abstract": "This work presents a fully quantum approach to support vector machine (SVM)\nlearning by integrating gate-based quantum kernel methods with quantum\nannealing-based optimization. We explore the construction of quantum kernels\nusing various feature maps and qubit configurations, evaluating their\nsuitability through Kernel-Target Alignment (KTA). The SVM dual problem is\nreformulated as a Quadratic Unconstrained Binary Optimization (QUBO) problem,\nenabling its solution via quantum annealers. Our experiments demonstrate that a\nhigh degree of alignment in the kernel and an appropriate regularization\nparameter lead to competitive performance, with the best model achieving an\nF1-score of 90%. These results highlight the feasibility of an end-to-end\nquantum learning pipeline and the potential of hybrid quantum architectures in\nquantum high-performance computing (QHPC) contexts.", "published": "2025-09-05 10:19:32", "link": "http://arxiv.org/abs/2509.04983v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents", "abstract": "AI agents -- powered by reasoning-capable large language models (LLMs) and\nintegrated with tools, data, and web search -- are poised to transform the\ninternet into a \\emph{Web of Agents}: a machine-native ecosystem where\nautonomous agents interact, collaborate, and execute tasks at scale. Realizing\nthis vision requires \\emph{Agent Ranking} -- selecting agents not only by\ndeclared capabilities but by proven, recent performance. Unlike Web~1.0's\nPageRank, a global, transparent network of agent interactions does not exist;\nusage signals are fragmented and private, making ranking infeasible without\ncoordination.\n  We propose \\textbf{DOVIS}, a five-layer operational protocol\n(\\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that\nenables the collection of minimal, privacy-preserving aggregates of usage and\nperformance across the ecosystem. On this substrate, we implement\n\\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines\n\\emph{usage} (selection frequency) and \\emph{competence} (outcome quality,\ncost, safety, latency) into a unified ranking. We present simulation results\nand theoretical guarantees on convergence, robustness, and Sybil resistance,\ndemonstrating the viability of coordinated protocols and performance-aware\nranking in enabling a scalable, trustworthy Agentic Web.", "published": "2025-09-05 10:04:33", "link": "http://arxiv.org/abs/2509.04979v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation", "abstract": "Reinforcement learning (RL) agents can learn to solve complex tasks from\nvisual inputs, but generalizing these learned skills to new environments\nremains a major challenge in RL application, especially robotics. While data\naugmentation can improve generalization, it often compromises sample efficiency\nand training stability. This paper introduces DeGuV, an RL framework that\nenhances both generalization and sample efficiency. In specific, we leverage a\nlearnable masker network that produces a mask from the depth input, preserving\nonly critical visual information while discarding irrelevant pixels. Through\nthis, we ensure that our RL agents focus on essential features, improving\nrobustness under data augmentation. In addition, we incorporate contrastive\nlearning and stabilize Q-value estimation under augmentation to further enhance\nsample efficiency and training stability. We evaluate our proposed method on\nthe RL-ViGen benchmark using the Franka Emika robot and demonstrate its\neffectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV\noutperforms state-of-the-art methods in both generalization and sample\nefficiency while also improving interpretability by highlighting the most\nrelevant regions in the visual input", "published": "2025-09-05 09:52:08", "link": "http://arxiv.org/abs/2509.04970v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Artificial intelligence for representing and characterizing quantum systems", "abstract": "Efficient characterization of large-scale quantum systems, especially those\nproduced by quantum analog simulators and megaquop quantum computers, poses a\ncentral challenge in quantum science due to the exponential scaling of the\nHilbert space with respect to system size. Recent advances in artificial\nintelligence (AI), with its aptitude for high-dimensional pattern recognition\nand function approximation, have emerged as a powerful tool to address this\nchallenge. A growing body of research has leveraged AI to represent and\ncharacterize scalable quantum systems, spanning from theoretical foundations to\nexperimental realizations. Depending on how prior knowledge and learning\narchitectures are incorporated, the integration of AI into quantum system\ncharacterization can be categorized into three synergistic paradigms: machine\nlearning, and, in particular, deep learning and language models. This review\ndiscusses how each of these AI paradigms contributes to two core tasks in\nquantum systems characterization: quantum property prediction and the\nconstruction of surrogates for quantum states. These tasks underlie diverse\napplications, from quantum certification and benchmarking to the enhancement of\nquantum algorithms and the understanding of strongly correlated phases of\nmatter. Key challenges and open questions are also discussed, together with\nfuture prospects at the interface of AI and quantum science.", "published": "2025-09-05 08:41:24", "link": "http://arxiv.org/abs/2509.04923v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models", "abstract": "Advances in computer vision have opened new avenues for clinical\napplications, particularly in computerized exposure therapy where visual\nstimuli can be dynamically adjusted based on patient responses. As a critical\nstep toward such adaptive systems, we investigated whether pretrained computer\nvision models can accurately predict fear levels from spider-related images. We\nadapted three diverse models using transfer learning to predict human fear\nratings (on a 0-100 scale) from a standardized dataset of 313 images. The\nmodels were evaluated using cross-validation, achieving an average mean\nabsolute error (MAE) between 10.1 and 11.0. Our learning curve analysis\nrevealed that reducing the dataset size significantly harmed performance,\nthough further increases yielded no substantial gains. Explainability\nassessments showed the models' predictions were based on spider-related\nfeatures. A category-wise error analysis further identified visual conditions\nassociated with higher errors (e.g., distant views and artificial/painted\nspiders). These findings demonstrate the potential of explainable computer\nvision models in predicting fear ratings, highlighting the importance of both\nmodel explainability and a sufficient dataset size for developing effective\nemotion-aware therapeutic technologies.", "published": "2025-09-05 08:10:40", "link": "http://arxiv.org/abs/2509.04889v1", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CV"}
{"title": "OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration", "abstract": "This paper introduces OSC (Orchestrating Cognitive Synergy), a\nknowledge-aware adaptive collaboration framework designed to enhance cognitive\nsynergy in multi-agent systems with large language models. While prior work has\nadvanced agent selection and result aggregation, efficient linguistic\ninteractions for deep collaboration among expert agents remain a critical\nbottleneck. OSC addresses this gap as a pivotal intermediate layer between\nselection and aggregation, introducing Collaborator Knowledge Models (CKM) to\nenable each agent to dynamically perceive its collaborators' cognitive states.\nThrough real-time cognitive gap analysis, agents adaptively adjust\ncommunication behaviors, including content focus, detail level, and expression\nstyle, using learned strategies. Experiments on complex reasoning and\nproblem-solving benchmarks demonstrate that OSC significantly improves task\nperformance and communication efficiency, transforming \"parallel-working\nindividuals'' into a \"deeply collaborative cognitive team.'' This framework not\nonly optimizes multi-agent collaboration but also offers new insights into LLM\nagent interaction behaviors.", "published": "2025-09-05 07:44:05", "link": "http://arxiv.org/abs/2509.04876v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Cloning a Conversational Voice AI Agent from Call\\,Recording Datasets for Telesales", "abstract": "Recent advances in language and speech modelling have made it possible to\nbuild autonomous voice assistants that understand and generate human dialogue\nin real time. These systems are increasingly being deployed in domains such as\ncustomer service and healthcare care, where they can automate repetitive tasks,\nreduce operational costs, and provide constant support around the clock. In\nthis paper, we present a general methodology for cloning a conversational voice\nAI agent from a corpus of call recordings. Although the case study described in\nthis paper uses telesales data to illustrate the approach, the underlying\nprocess generalizes to any domain where call transcripts are available. Our\nsystem listens to customers over the telephone, responds with a synthetic\nvoice, and follows a structured playbook learned from top performing human\nagents. We describe the domain selection, knowledge extraction, and prompt\nengineering used to construct the agent, integrating automatic speech\nrecognition, a large language model based dialogue manager, and text to speech\nsynthesis into a streaming inference pipeline. The cloned agent is evaluated\nagainst human agents on a rubric of 22 criteria covering introduction, product\ncommunication, sales drive, objection handling, and closing. Blind tests show\nthat the AI agent approaches human performance in routine aspects of the call\nwhile underperforming in persuasion and objection handling. We analyze these\nshortcomings and refine the prompt accordingly. The paper concludes with design\nlessons and avenues for future research, including large scale simulation and\nautomated evaluation.", "published": "2025-09-05 07:36:12", "link": "http://arxiv.org/abs/2509.04871v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "The Paradox of Doom: Acknowledging Extinction Risk Reduces the Incentive to Prevent It", "abstract": "We investigate the salience of extinction risk as a source of impatience. Our\nframework distinguishes between human extinction risk and individual mortality\nrisk while allowing for various degrees of intergenerational altruism.\nAdditionally, we consider the evolutionarily motivated \"selfish gene\"\nperspective. We find that the risk of human extinction is an indispensable\ncomponent of the discount rate, whereas individual mortality risk can be hedged\nagainst - partially or fully, depending on the setup - through human\nreproduction. Overall, we show that in the face of extinction risk, people\nbecome more impatient rather than more farsighted. Thus, the greater the threat\nof extinction, the less incentive there is to invest in avoiding it. Our\nframework can help explain why humanity consistently underinvests in mitigation\nof catastrophic risks, ranging from climate change mitigation, via pandemic\nprevention, to addressing the emerging risks of transformative artificial\nintelligence.", "published": "2025-09-05 07:14:24", "link": "http://arxiv.org/abs/2509.04855v1", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving Based on Expert Routing", "abstract": "End-to-end autonomous driving remains constrained by the need to generate\nmulti-modal actions, maintain temporal stability, and generalize across diverse\nscenarios. Existing methods often collapse multi-modality, struggle with\nlong-horizon consistency, or lack modular adaptability. This paper presents\nKDP, a knowledge-driven diffusion policy that integrates generative diffusion\nmodeling with a sparse mixture-of-experts routing mechanism. The diffusion\ncomponent generates temporally coherent and multi-modal action sequences, while\nthe expert routing mechanism activates specialized and reusable experts\naccording to context, enabling modular knowledge composition. Extensive\nexperiments across representative driving scenarios demonstrate that KDP\nachieves consistently higher success rates, reduced collision risk, and\nsmoother control compared to prevailing paradigms. Ablation studies highlight\nthe effectiveness of sparse expert activation and the Transformer backbone, and\nactivation analyses reveal structured specialization and cross-scenario reuse\nof experts. These results establish diffusion with expert routing as a scalable\nand interpretable paradigm for knowledge-driven end-to-end autonomous driving.", "published": "2025-09-05 07:07:18", "link": "http://arxiv.org/abs/2509.04853v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory", "abstract": "Language models are increasingly deployed in interactive online environments,\nfrom personal chat assistants to domain-specific agents, raising questions\nabout their cooperative and competitive behavior in multi-party settings. While\nprior work has examined language model decision-making in isolated or\nshort-term game-theoretic contexts, these studies often neglect long-horizon\ninteractions, human-model collaboration, and the evolution of behavioral\npatterns over time. In this paper, we investigate the dynamics of language\nmodel behavior in the iterated prisoner's dilemma (IPD), a classical framework\nfor studying cooperation and conflict. We pit model-based agents against a\nsuite of 240 well-established classical strategies in an Axelrod-style\ntournament and find that language models achieve performance on par with, and\nin some cases exceeding, the best-known classical strategies. Behavioral\nanalysis reveals that language models exhibit key properties associated with\nstrong cooperative strategies - niceness, provocability, and generosity while\nalso demonstrating rapid adaptability to changes in opponent strategy mid-game.\nIn controlled \"strategy switch\" experiments, language models detect and respond\nto shifts within only a few rounds, rivaling or surpassing human adaptability.\nThese results provide the first systematic characterization of long-term\ncooperative behaviors in language model agents, offering a foundation for\nfuture research into their role in more complex, mixed human-AI social\nenvironments.", "published": "2025-09-05 06:55:15", "link": "http://arxiv.org/abs/2509.04847v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "REMOTE: A Unified Multimodal Relation Extraction Framework with Multilevel Optimal Transport and Mixture-of-Experts", "abstract": "Multimodal relation extraction (MRE) is a crucial task in the fields of\nKnowledge Graph and Multimedia, playing a pivotal role in multimodal knowledge\ngraph construction. However, existing methods are typically limited to\nextracting a single type of relational triplet, which restricts their ability\nto extract triplets beyond the specified types. Directly combining these\nmethods fails to capture dynamic cross-modal interactions and introduces\nsignificant computational redundancy. Therefore, we propose a novel\n\\textit{unified multimodal Relation Extraction framework with Multilevel\nOptimal Transport and mixture-of-Experts}, termed REMOTE, which can\nsimultaneously extract intra-modal and inter-modal relations between textual\nentities and visual objects. To dynamically select optimal interaction features\nfor different types of relational triplets, we introduce mixture-of-experts\nmechanism, ensuring the most relevant modality information is utilized.\nAdditionally, considering that the inherent property of multilayer sequential\nencoding in existing encoders often leads to the loss of low-level information,\nwe adopt a multilevel optimal transport fusion module to preserve low-level\nfeatures while maintaining multilayer encoding, yielding more expressive\nrepresentations. Correspondingly, we also create a Unified Multimodal Relation\nExtraction (UMRE) dataset to evaluate the effectiveness of our framework,\nencompassing diverse cases where the head and tail entities can originate from\neither text or image. Extensive experiments show that REMOTE effectively\nextracts various types of relational triplets and achieves state-of-the-art\nperformanc on almost all metrics across two other public MRE datasets. We\nrelease our resources at https://github.com/Nikol-coder/REMOTE.", "published": "2025-09-05 06:52:03", "link": "http://arxiv.org/abs/2509.04844v1", "categories": ["cs.MM", "cs.AI", "cs.IR"], "primary_category": "cs.MM"}
{"title": "PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination", "abstract": "Recent advances in visual grounding have largely shifted away from\ntraditional proposal-based two-stage frameworks due to their inefficiency and\nhigh computational complexity, favoring end-to-end direct reference paradigms.\nHowever, these methods rely exclusively on the referred target for supervision,\noverlooking the potential benefits of prominent prospective targets. Moreover,\nexisting approaches often fail to incorporate multi-granularity discrimination,\nwhich is crucial for robust object identification in complex scenarios. To\naddress these limitations, we propose PropVG, an end-to-end proposal-based\nframework that, to the best of our knowledge, is the first to seamlessly\nintegrate foreground object proposal generation with referential object\ncomprehension without requiring additional detectors. Furthermore, we introduce\na Contrastive-based Refer Scoring (CRS) module, which employs contrastive\nlearning at both sentence and word levels to enhance the capability in\nunderstanding and distinguishing referred objects. Additionally, we design a\nMulti-granularity Target Discrimination (MTD) module that fuses object- and\nsemantic-level information to improve the recognition of absent targets.\nExtensive experiments on gRefCOCO (GREC/GRES), Ref-ZOM, R-RefCOCO, and RefCOCO\n(REC/RES) benchmarks demonstrate the effectiveness of PropVG. The codes and\nmodels are available at https://github.com/Dmmm1997/PropVG.", "published": "2025-09-05 06:30:06", "link": "http://arxiv.org/abs/2509.04833v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution", "abstract": "Recently, Mamba-based methods, with its advantage in long-range information\nmodeling and linear complexity, have shown great potential in optimizing both\ncomputational cost and performance of light field image super-resolution\n(LFSR). However, current multi-directional scanning strategies lead to\ninefficient and redundant feature extraction when applied to complex LF data.\nTo overcome this challenge, we propose a Subspace Simple Scanning (Sub-SS)\nstrategy, based on which we design the Subspace Simple Mamba Block (SSMB) to\nachieve more efficient and precise feature extraction. Furthermore, we propose\na dual-stage modeling strategy to address the limitation of state space in\npreserving spatial-angular and disparity information, thereby enabling a more\ncomprehensive exploration of non-local spatial-angular correlations.\nSpecifically, in stage I, we introduce the Spatial-Angular Residual Subspace\nMamba Block (SA-RSMB) for shallow spatial-angular feature extraction; in stage\nII, we use a dual-branch parallel structure combining the Epipolar Plane Mamba\nBlock (EPMB) and Epipolar Plane Transformer Block (EPTB) for deep epipolar\nfeature refinement. Building upon meticulously designed modules and strategies,\nwe introduce a hybrid Mamba-Transformer framework, termed LFMT. LFMT integrates\nthe strengths of Mamba and Transformer models for LFSR, enabling comprehensive\ninformation exploration across spatial, angular, and epipolar-plane domains.\nExperimental results demonstrate that LFMT significantly outperforms current\nstate-of-the-art methods in LFSR, achieving substantial improvements in\nperformance while maintaining low computational complexity on both real-word\nand synthetic LF datasets.", "published": "2025-09-05 05:50:38", "link": "http://arxiv.org/abs/2509.04824v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models", "abstract": "Explainable Reinforcement Learning (XRL) has emerged as a promising approach\nin improving the transparency of Reinforcement Learning (RL) agents. However,\nthere remains a gap between complex RL policies and domain experts, due to the\nlimited comprehensibility of XRL results and isolated coverage of current XRL\napproaches that leave users uncertain about which tools to employ. To address\nthese challenges, we introduce TalkToAgent, a multi-agent Large Language Models\n(LLM) framework that delivers interactive, natural language explanations for RL\npolicies. The architecture with five specialized LLM agents (Coordinator,\nExplainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically\nmap user queries to relevant XRL tools and clarify an agent's actions in terms\nof either key state variables, expected outcomes, or counterfactual\nexplanations. Moreover, our approach extends previous counterfactual\nexplanations by deriving alternative scenarios from qualitative behavioral\ndescriptions, or even new rule-based policies. We validated TalkToAgent on\nquadruple-tank process control problem, a well-known nonlinear control\nbenchmark. Results demonstrated that TalkToAgent successfully mapped user\nqueries into XRL tasks with high accuracy, and coder-debugger interactions\nminimized failures in counterfactual generation. Furthermore, qualitative\nevaluation confirmed that TalkToAgent effectively interpreted agent's actions\nand contextualized their meaning within the problem domain.", "published": "2025-09-05 05:09:09", "link": "http://arxiv.org/abs/2509.04809v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design", "abstract": "Modern fronthaul links in wireless systems must transport high-dimensional\nsignals under stringent bandwidth and latency constraints, which makes\ncompression indispensable. Traditional strategies such as compressed sensing,\nscalar quantization, and fixed-codec pipelines often rely on restrictive\npriors, degrade sharply at high compression ratios, and are hard to tune across\nchannels and deployments. Recent progress in Artificial Intelligence (AI) has\nbrought end-to-end learned transforms, vector and hierarchical quantization,\nand learned entropy models that better exploit the structure of Channel State\nInformation(CSI), precoding matrices, I/Q samples, and LLRs. This paper first\nsurveys AI-driven compression techniques and then provides a focused analysis\nof two representative high-compression routes: CSI feedback with end-to-end\nlearning and Resource Block (RB) granularity precoding optimization combined\nwith compression. Building on these insights, we propose a fronthaul\ncompression strategy tailored to cell-free architectures. The design targets\nhigh compression with controlled performance loss, supports RB-level rate\nadaptation, and enables low-latency inference suitable for centralized\ncooperative transmission in next-generation networks.", "published": "2025-09-05 04:52:51", "link": "http://arxiv.org/abs/2509.04805v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images", "abstract": "Skin diseases are among the most prevalent health concerns worldwide, yet\nconventional diagnostic methods are often costly, complex, and unavailable in\nlow-resource settings. Automated classification using deep learning has emerged\nas a promising alternative, but existing studies are mostly limited to\ndermoscopic datasets and a narrow range of disease classes. In this work, we\ncurate a large dataset of over 50 skin disease categories captured with mobile\ndevices, making it more representative of real-world conditions. We evaluate\nmultiple convolutional neural networks and Transformer-based architectures,\ndemonstrating that Transformer models, particularly the Swin Transformer,\nachieve superior performance by effectively capturing global contextual\nfeatures. To enhance interpretability, we incorporate Gradient-weighted Class\nActivation Mapping (Grad-CAM), which highlights clinically relevant regions and\nprovides transparency in model predictions. Our results underscore the\npotential of Transformer-based approaches for mobile-acquired skin lesion\nclassification, paving the way toward accessible AI-assisted dermatological\nscreening and early diagnosis in resource-limited environments.", "published": "2025-09-05 04:31:16", "link": "http://arxiv.org/abs/2509.04800v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking", "abstract": "Large language models (LLMs) excel at processing information reactively but\nlack the ability to systemically explore hypothetical futures. They cannot ask,\n\"what if we take this action? how will it affect the final outcome\" and\nforecast its potential consequences before acting. This critical gap limits\ntheir utility in dynamic, high-stakes scenarios like strategic planning, risk\nassessment, and real-time decision making. To bridge this gap, we propose\nWiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.\nOur approach integrates What-If Analysis (WIA), a systematic approach for\nevaluating hypothetical scenarios by changing input variables. By leveraging\nenvironmental feedback via reinforcement learning, WiA-LLM moves beyond\nreactive thinking. It dynamically simulates the outcomes of each potential\naction, enabling the model to anticipate future states rather than merely react\nto the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a\ncomplex multiplayer game environment characterized by rapid state changes and\nintricate interactions. The game's real-time state changes require precise\nmulti-step consequence prediction, making it an ideal testbed for our approach.\nExperimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy\nin forecasting game-state changes (up to two times gain over baselines). The\nmodel shows particularly significant gains in high-difficulty scenarios where\naccurate foresight is critical. To our knowledge, this is the first work to\nformally explore and integrate what-if analysis capabilities within LLMs.\nWiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,\nproviding a scalable framework for robust decision-making in dynamic\nenvironments with broad implications for strategic applications.", "published": "2025-09-05 04:05:27", "link": "http://arxiv.org/abs/2509.04791v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Graph Unlearning: Efficient Node Removal in Graph Neural Networks", "abstract": "With increasing concerns about privacy attacks and potential sensitive\ninformation leakage, researchers have actively explored methods to efficiently\nremove sensitive training data and reduce privacy risks in graph neural network\n(GNN) models. Node unlearning has emerged as a promising technique for\nprotecting the privacy of sensitive nodes by efficiently removing specific\ntraining node information from GNN models. However, existing node unlearning\nmethods either impose restrictions on the GNN structure or do not effectively\nutilize the graph topology for node unlearning. Some methods even compromise\nthe graph's topology, making it challenging to achieve a satisfactory\nperformance-complexity trade-off. To address these issues and achieve efficient\nunlearning for training node removal in GNNs, we propose three novel node\nunlearning methods: Class-based Label Replacement, Topology-guided Neighbor\nMean Posterior Probability, and Class-consistent Neighbor Node Filtering. Among\nthese methods, Topology-guided Neighbor Mean Posterior Probability and\nClass-consistent Neighbor Node Filtering effectively leverage the topological\nfeatures of the graph, resulting in more effective node unlearning. To validate\nthe superiority of our proposed methods in node unlearning, we conducted\nexperiments on three benchmark datasets. The evaluation criteria included model\nutility, unlearning utility, and unlearning efficiency. The experimental\nresults demonstrate the utility and efficiency of the proposed methods and\nillustrate their superiority compared to state-of-the-art node unlearning\nmethods. Overall, the proposed methods efficiently remove sensitive training\nnodes and protect the privacy information of sensitive nodes in GNNs. The\nfindings contribute to enhancing the privacy and security of GNN models and\nprovide valuable insights into the field of node unlearning.", "published": "2025-09-05 03:47:49", "link": "http://arxiv.org/abs/2509.04785v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "VARMA-Enhanced Transformer for Time Series Forecasting", "abstract": "Transformer-based models have significantly advanced time series forecasting.\nRecent work, like the Cross-Attention-only Time Series transformer (CATS),\nshows that removing self-attention can make the model more accurate and\nefficient. However, these streamlined architectures may overlook the\nfine-grained, local temporal dependencies effectively captured by classical\nstatistical models like Vector AutoRegressive Moving Average model (VARMA). To\naddress this gap, we propose VARMAformer, a novel architecture that synergizes\nthe efficiency of a cross-attention-only framework with the principles of\nclassical time series analysis. Our model introduces two key innovations: (1) a\ndedicated VARMA-inspired Feature Extractor (VFE) that explicitly models\nautoregressive (AR) and moving-average (MA) patterns at the patch level, and\n(2) a VARMA-Enhanced Attention (VE-atten) mechanism that employs a temporal\ngate to make queries more context-aware. By fusing these classical insights\ninto a modern backbone, VARMAformer captures both global, long-range\ndependencies and local, statistical structures. Through extensive experiments\non widely-used benchmark datasets, we demonstrate that our model consistently\noutperforms existing state-of-the-art methods. Our work validates the\nsignificant benefit of integrating classical statistical insights into modern\ndeep learning frameworks for time series forecasting.", "published": "2025-09-05 03:32:51", "link": "http://arxiv.org/abs/2509.04782v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The LLM Has Left The Chat: Evidence of Bail Preferences in Large Language Models", "abstract": "When given the option, will LLMs choose to leave the conversation (bail)? We\ninvestigate this question by giving models the option to bail out of\ninteractions using three different bail methods: a bail tool the model can\ncall, a bail string the model can output, and a bail prompt that asks the model\nif it wants to leave. On continuations of real world data (Wildchat and\nShareGPT), all three of these bail methods find models will bail around\n0.28-32\\% of the time (depending on the model and bail method). However, we\nfind that bail rates can depend heavily on the model used for the transcript,\nwhich means we may be overestimating real world bail rates by up to 4x. If we\nalso take into account false positives on bail prompt (22\\%), we estimate real\nworld bail rates range from 0.06-7\\%, depending on the model and bail method.\nWe use observations from our continuations of real world data to construct a\nnon-exhaustive taxonomy of bail cases, and use this taxonomy to construct\nBailBench: a representative synthetic dataset of situations where some models\nbail. We test many models on this dataset, and observe some bail behavior\noccurring for most of them. Bail rates vary substantially between models, bail\nmethods, and prompt wordings. Finally, we study the relationship between\nrefusals and bails. We find: 1) 0-13\\% of continuations of real world\nconversations resulted in a bail without a corresponding refusal 2) Jailbreaks\ntend to decrease refusal rates, but increase bail rates 3) Refusal abliteration\nincreases no-refuse bail rates, but only for some bail methods 4) Refusal rate\non BailBench does not appear to predict bail rate.", "published": "2025-09-05 03:30:04", "link": "http://arxiv.org/abs/2509.04781v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph", "abstract": "Timely and accurate floodwater depth estimation is critical for road\naccessibility and emergency response. While recent computer vision methods have\nenabled flood detection, they suffer from both accuracy limitations and poor\ngeneralization due to dependence on fixed object detectors and task-specific\ntraining. To enable accurate depth estimation that can generalize across\ndiverse flood scenarios, this paper presents FloodVision, a zero-shot framework\nthat combines the semantic reasoning abilities of the foundation\nvision-language model GPT-4o with a structured domain knowledge graph. The\nknowledge graph encodes canonical real-world dimensions for common urban\nobjects including vehicles, people, and infrastructure elements to ground the\nmodel's reasoning in physical reality. FloodVision dynamically identifies\nvisible reference objects in RGB images, retrieves verified heights from the\nknowledge graph to mitigate hallucination, estimates submergence ratios, and\napplies statistical outlier filtering to compute final depth values. Evaluated\non 110 crowdsourced images from MyCoast New York, FloodVision achieves a mean\nabsolute error of 8.17 cm, reducing the GPT-4o baseline 10.28 cm by 20.5% and\nsurpassing prior CNN-based methods. The system generalizes well across varying\nscenes and operates in near real-time, making it suitable for future\nintegration into digital twin platforms and citizen-reporting apps for smart\ncity flood resilience.", "published": "2025-09-05 03:05:18", "link": "http://arxiv.org/abs/2509.04772v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery", "abstract": "Rapid and accurate post-hurricane damage assessment is vital for disaster\nresponse and recovery. Yet existing CNN-based methods struggle to capture\nmulti-scale spatial features and to distinguish visually similar or\nco-occurring damage types. To address these issues, we propose MCANet, a\nmulti-label classification framework that learns multi-scale representations\nand adaptively attends to spatially relevant regions for each damage category.\nMCANet employs a Res2Net-based hierarchical backbone to enrich spatial context\nacross scales and a multi-head class-specific residual attention module to\nenhance discrimination. Each attention branch focuses on different spatial\ngranularities, balancing local detail with global context. We evaluate MCANet\non the RescueNet dataset of 4,494 UAV images collected after Hurricane Michael.\nMCANet achieves a mean average precision (mAP) of 91.75%, outperforming ResNet,\nRes2Net, VGG, MobileNet, EfficientNet, and ViT. With eight attention heads,\nperformance further improves to 92.35%, boosting average precision for\nchallenging classes such as Road Blocked by over 6%. Class activation mapping\nconfirms MCANet's ability to localize damage-relevant regions, supporting\ninterpretability. Outputs from MCANet can inform post-disaster risk mapping,\nemergency routing, and digital twin-based disaster response. Future work could\nintegrate disaster-specific knowledge graphs and multimodal large language\nmodels to improve adaptability to unseen disasters and enrich semantic\nunderstanding for real-world decision-making.", "published": "2025-09-05 02:25:05", "link": "http://arxiv.org/abs/2509.04757v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SePA: A Search-enhanced Predictive Agent for Personalized Health Coaching", "abstract": "This paper introduces SePA (Search-enhanced Predictive AI Agent), a novel LLM\nhealth coaching system that integrates personalized machine learning and\nretrieval-augmented generation to deliver adaptive, evidence-based guidance.\nSePA combines: (1) Individualized models predicting daily stress, soreness, and\ninjury risk from wearable sensor data (28 users, 1260 data points); and (2) A\nretrieval module that grounds LLM-generated feedback in expert-vetted web\ncontent to ensure contextual relevance and reliability. Our predictive models,\nevaluated with rolling-origin cross-validation and group k-fold\ncross-validation show that personalized models outperform generalized\nbaselines. In a pilot expert study (n=4), SePA's retrieval-based advice was\npreferred over a non-retrieval baseline, yielding meaningful practical effect\n(Cliff's $\\delta$=0.3, p=0.05). We also quantify latency performance trade-offs\nbetween response quality and speed, offering a transparent blueprint for\nnext-generation, trustworthy personal health informatics systems.", "published": "2025-09-05 02:07:36", "link": "http://arxiv.org/abs/2509.04752v1", "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization", "abstract": "Recent advances in vision foundation models, such as the Segment Anything\nModel (SAM) and its successor SAM2, have achieved state-of-the-art performance\non general image segmentation benchmarks. However, these models struggle in\nadverse weather conditions where visual ambiguity is high, largely due to their\nlack of uncertainty quantification. Inspired by progress in medical imaging,\nwhere uncertainty-aware training has improved reliability in ambiguous cases,\nwe investigate two approaches to enhance segmentation robustness for autonomous\ndriving. First, we introduce a multi-step finetuning procedure for SAM2 that\nincorporates uncertainty metrics directly into the loss function, improving\noverall scene recognition. Second, we adapt the Uncertainty-Aware Adapter\n(UAT), originally designed for medical image segmentation, to driving contexts.\nWe evaluate both methods on CamVid, BDD100K, and GTA driving datasets.\nExperiments show that UAT-SAM outperforms standard SAM in extreme weather,\nwhile SAM2 with uncertainty-aware loss achieves improved performance across\ndiverse driving scenes. These findings underscore the value of explicit\nuncertainty modeling for safety-critical autonomous driving in challenging\nenvironments.", "published": "2025-09-05 01:24:42", "link": "http://arxiv.org/abs/2509.04735v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning", "abstract": "The Information Contrastive (I-Con) framework revealed that over 23\nrepresentation learning methods implicitly minimize KL divergence between data\nand learned distributions that encode similarities between data points.\nHowever, a KL-based loss may be misaligned with the true objective, and\nproperties of KL divergence such as asymmetry and unboundedness may create\noptimization challenges. We present Beyond I-Con, a framework that enables\nsystematic discovery of novel loss functions by exploring alternative\nstatistical divergences and similarity kernels. Key findings: (1) on\nunsupervised clustering of DINO-ViT embeddings, we achieve state-of-the-art\nresults by modifying the PMI algorithm to use total variation (TV) distance;\n(2) on supervised contrastive learning, we outperform the standard approach by\nusing TV and a distance-based similarity kernel instead of KL and an angular\nkernel; (3) on dimensionality reduction, we achieve superior qualitative\nresults and better performance on downstream tasks than SNE by replacing KL\nwith a bounded f-divergence. Our results highlight the importance of\nconsidering divergence and similarity kernel choices in representation learning\noptimization.", "published": "2025-09-05 01:23:59", "link": "http://arxiv.org/abs/2509.04734v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "CoVeR: Conformal Calibration for Versatile and Reliable Autoregressive Next-Token Prediction", "abstract": "Autoregressive pre-trained models combined with decoding methods have\nachieved impressive performance on complex reasoning tasks. While mainstream\ndecoding strategies such as beam search can generate plausible candidate sets,\nthey often lack provable coverage guarantees, and struggle to effectively\nbalance search efficiency with the need for versatile trajectories,\nparticularly those involving long-tail sequences that are essential in certain\nreal-world applications. To address these limitations, we propose\n\\textsc{CoVeR}, a novel model-free decoding strategy wihtin the conformal\nprediction framework that simultaneously maintains a compact search space and\nensures high coverage probability over desirable trajectories. Theoretically,\nwe establish a PAC-style generalization bound, guaranteeing that \\textsc{CoVeR}\nasymptotically achieves a coverage rate of at least $1 - \\alpha$ for any target\nlevel $\\alpha \\in (0,1)$.", "published": "2025-09-05 01:07:12", "link": "http://arxiv.org/abs/2509.04733v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FlowSeek: Optical Flow Made Easier with Depth Foundation Models and Motion Bases", "abstract": "We present FlowSeek, a novel framework for optical flow requiring minimal\nhardware resources for training. FlowSeek marries the latest advances on the\ndesign space of optical flow networks with cutting-edge single-image depth\nfoundation models and classical low-dimensional motion parametrization,\nimplementing a compact, yet accurate architecture. FlowSeek is trained on a\nsingle consumer-grade GPU, a hardware budget about 8x lower compared to most\nrecent methods, and still achieves superior cross-dataset generalization on\nSintel Final and KITTI, with a relative improvement of 10 and 15% over the\nprevious state-of-the-art SEA-RAFT, as well as on Spring and LayeredFlow\ndatasets.", "published": "2025-09-05 17:59:59", "link": "http://arxiv.org/abs/2509.05297v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Symbolic Graphics Programming with Large Language Models", "abstract": "Large language models (LLMs) excel at program synthesis, yet their ability to\nproduce symbolic graphics programs (SGPs) that render into precise visual\ncontent remains underexplored. We study symbolic graphics programming, where\nthe goal is to generate an SGP from a natural-language description. This task\nalso serves as a lens into how LLMs understand the visual world by prompting\nthem to generate images rendered from SGPs. Among various SGPs, our paper\nsticks to scalable vector graphics (SVGs). We begin by examining the extent to\nwhich LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a\ncomprehensive benchmark covering object fidelity, scene fidelity, and\ncompositionality (attribute binding, spatial relations, numeracy). On\nSGP-GenBench, we discover that frontier proprietary models substantially\noutperform open-source models, and performance correlates well with general\ncoding capabilities. Motivated by this gap, we aim to improve LLMs' ability to\ngenerate SGPs. We propose a reinforcement learning (RL) with verifiable rewards\napproach, where a format-validity gate ensures renderable SVG, and a\ncross-modal reward aligns text and the rendered image via strong vision\nencoders (e.g., SigLIP for text-image and DINO for image-image). Applied to\nQwen-2.5-7B, our method substantially improves SVG generation quality and\nsemantics, achieving performance on par with frontier systems. We further\nanalyze training dynamics, showing that RL induces (i) finer decomposition of\nobjects into controllable primitives and (ii) contextual details that improve\nscene coherence. Our results demonstrate that symbolic graphics programming\noffers a precise and interpretable lens on cross-modal grounding.", "published": "2025-09-05 16:10:53", "link": "http://arxiv.org/abs/2509.05208v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers", "abstract": "This paper presents a robust model predictive control (MPC) framework that\nexplicitly addresses the non-Gaussian noise inherent in deep learning-based\nperception modules used for state estimation. Recognizing that accurate\nuncertainty quantification of the perception module is essential for safe\nfeedback control, our approach departs from the conventional assumption of\nzero-mean noise quantification of the perception error. Instead, it employs\nset-based state estimation with constrained zonotopes to capture biased,\nheavy-tailed uncertainties while maintaining bounded estimation errors. To\nimprove computational efficiency, the robust MPC is reformulated as a linear\nprogram (LP), using a Minkowski-Lyapunov-based cost function with an added\nslack variable to prevent degenerate solutions. Closed-loop stability is\nensured through Minkowski-Lyapunov inequalities and contractive zonotopic\ninvariant sets. The largest stabilizing terminal set and its corresponding\nfeedback gain are then derived via an ellipsoidal approximation of the\nzonotopes. The proposed framework is validated through both simulations and\nhardware experiments on an omnidirectional mobile robot along with a camera and\na convolutional neural network-based perception module implemented within a\nROS2 framework. The results demonstrate that the perception-aware MPC provides\nstable and accurate control performance under heavy-tailed noise conditions,\nsignificantly outperforming traditional Gaussian-noise-based designs in terms\nof both state estimation error bounding and overall control performance.", "published": "2025-09-05 16:03:57", "link": "http://arxiv.org/abs/2509.05201v1", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition", "abstract": "Sign language recognition (SLR) is a machine learning task aiming to identify\nsigns in videos. Due to the scarcity of annotated data, unsupervised methods\nlike contrastive learning have become promising in this field. They learn\nmeaningful representations by pulling positive pairs (two augmented versions of\nthe same instance) closer and pushing negative pairs (different from the\npositive pairs) apart. In SLR, in a sign video, only certain parts provide\ninformation that is truly useful for its recognition. Applying contrastive\nmethods to SLR raises two issues: (i) contrastive learning methods treat all\nparts of a video in the same way, without taking into account the relevance of\ncertain parts over others; (ii) shared movements between different signs make\nnegative pairs highly similar, complicating sign discrimination. These issues\nlead to learning non-discriminative features for sign recognition and poor\nresults in downstream tasks. In response, this paper proposes a self-supervised\nlearning framework designed to learn meaningful representations for SLR. This\nframework consists of two key components designed to work together: (i) a new\nself-supervised approach with free-negative pairs; (ii) a new data augmentation\ntechnique. This approach shows a considerable gain in accuracy compared to\nseveral contrastive and self-supervised methods, across linear evaluation,\nsemi-supervised learning, and transferability between sign languages.", "published": "2025-09-05 15:38:19", "link": "http://arxiv.org/abs/2509.05188v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VLSM-Ensemble: Ensembling CLIP-based Vision-Language Models for Enhanced Medical Image Segmentation", "abstract": "Vision-language models and their adaptations to image segmentation tasks\npresent enormous potential for producing highly accurate and interpretable\nresults. However, implementations based on CLIP and BiomedCLIP are still\nlagging behind more sophisticated architectures such as CRIS. In this work,\ninstead of focusing on text prompt engineering as is the norm, we attempt to\nnarrow this gap by showing how to ensemble vision-language segmentation models\n(VLSMs) with a low-complexity CNN. By doing so, we achieve a significant Dice\nscore improvement of 6.3% on the BKAI polyp dataset using the ensembled\nBiomedCLIPSeg, while other datasets exhibit gains ranging from 1% to 6%.\nFurthermore, we provide initial results on additional four radiology and\nnon-radiology datasets. We conclude that ensembling works differently across\nthese datasets (from outperforming to underperforming the CRIS model),\nindicating a topic for future investigation by the community. The code is\navailable at https://github.com/juliadietlmeier/VLSM-Ensemble.", "published": "2025-09-05 14:48:19", "link": "http://arxiv.org/abs/2509.05154v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic Mask Splitting and Growing", "abstract": "Accurate 3D instance segmentation is crucial for high-quality scene\nunderstanding in the 3D vision domain. However, 3D instance segmentation based\non 2D-to-3D lifting approaches struggle to produce precise instance-level\nsegmentation, due to accumulated errors introduced during the lifting process\nfrom ambiguous semantic guidance and insufficient depth constraints. To tackle\nthese challenges, we propose splitting and growing reliable semantic mask for\nhigh-fidelity 3D instance segmentation (SGS-3D), a novel \"split-then-grow\"\nframework that first purifies and splits ambiguous lifted masks using geometric\nprimitives, and then grows them into complete instances within the scene.\nUnlike existing approaches that directly rely on raw lifted masks and sacrifice\nsegmentation accuracy, SGS-3D serves as a training-free refinement method that\njointly fuses semantic and geometric information, enabling effective\ncooperation between the two levels of representation. Specifically, for\nsemantic guidance, we introduce a mask filtering strategy that leverages the\nco-occurrence of 3D geometry primitives to identify and remove ambiguous masks,\nthereby ensuring more reliable semantic consistency with the 3D object\ninstances. For the geometric refinement, we construct fine-grained object\ninstances by exploiting both spatial continuity and high-level features,\nparticularly in the case of semantic ambiguity between distinct objects.\nExperimental results on ScanNet200, ScanNet++, and KITTI-360 demonstrate that\nSGS-3D substantially improves segmentation accuracy and robustness against\ninaccurate masks from pre-trained models, yielding high-fidelity object\ninstances while maintaining strong generalization across diverse indoor and\noutdoor environments. Code is available in the supplementary materials.", "published": "2025-09-05 14:37:31", "link": "http://arxiv.org/abs/2509.05144v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Scalable Attention-Based Approach for Image-to-3D Texture Mapping", "abstract": "High-quality textures are critical for realistic 3D content creation, yet\nexisting generative methods are slow, rely on UV maps, and often fail to remain\nfaithful to a reference image. To address these challenges, we propose a\ntransformer-based framework that predicts a 3D texture field directly from a\nsingle image and a mesh, eliminating the need for UV mapping and differentiable\nrendering, and enabling faster texture generation. Our method integrates a\ntriplane representation with depth-based backprojection losses, enabling\nefficient training and faster inference. Once trained, it generates\nhigh-fidelity textures in a single forward pass, requiring only 0.2s per shape.\nExtensive qualitative, quantitative, and user preference evaluations\ndemonstrate that our method outperforms state-of-the-art baselines on\nsingle-image texture reconstruction in terms of both fidelity to the input\nimage and perceptual quality, highlighting its practicality for scalable,\nhigh-quality, and controllable 3D content creation.", "published": "2025-09-05 14:18:52", "link": "http://arxiv.org/abs/2509.05131v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Semi-supervised Deep Transfer for Regression without Domain Alignment", "abstract": "Deep learning models deployed in real-world applications (e.g., medicine)\nface challenges because source models do not generalize well to domain-shifted\ntarget data. Many successful domain adaptation (DA) approaches require full\naccess to source data. Yet, such requirements are unrealistic in scenarios\nwhere source data cannot be shared either because of privacy concerns or\nbecause it is too large and incurs prohibitive storage or computational costs.\nMoreover, resource constraints may limit the availability of labeled targets.\nWe illustrate this challenge in a neuroscience setting where source data are\nunavailable, labeled target data are meager, and predictions involve\ncontinuous-valued outputs. We build upon Contradistinguisher (CUDA), an\nefficient framework that learns a shared model across the labeled source and\nunlabeled target samples, without intermediate representation alignment. Yet,\nCUDA was designed for unsupervised DA, with full access to source data, and for\nclassification tasks. We develop CRAFT -- a Contradistinguisher-based\nRegularization Approach for Flexible Training -- for source-free (SF),\nsemi-supervised transfer of pretrained models in regression tasks. We showcase\nthe efficacy of CRAFT in two neuroscience settings: gaze prediction with\nelectroencephalography (EEG) data and ``brain age'' prediction with structural\nMRI data. For both datasets, CRAFT yielded up to 9% improvement in\nroot-mean-squared error (RMSE) over fine-tuned models when labeled training\nexamples were scarce. Moreover, CRAFT leveraged unlabeled target data and\noutperformed four competing state-of-the-art source-free domain adaptation\nmodels by more than 3%. Lastly, we demonstrate the efficacy of CRAFT on two\nother real-world regression benchmarks. We propose CRAFT as an efficient\napproach for source-free, semi-supervised deep transfer for regression that is\nubiquitous in biology and medicine.", "published": "2025-09-05 13:30:49", "link": "http://arxiv.org/abs/2509.05092v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers", "abstract": "Robustifying convolutional neural networks (CNNs) against adversarial attacks\nremains challenging and often requires resource-intensive countermeasures. We\nexplore the use of sparse mixture-of-experts (MoE) layers to improve robustness\nby replacing selected residual blocks or convolutional layers, thereby\nincreasing model capacity without additional inference cost. On ResNet\narchitectures trained on CIFAR-100, we find that inserting a single MoE layer\nin the deeper stages leads to consistent improvements in robustness under PGD\nand AutoPGD attacks when combined with adversarial training. Furthermore, we\ndiscover that when switch loss is used for balancing, it causes routing to\ncollapse onto a small set of overused experts, thereby concentrating\nadversarial training on these paths and inadvertently making them more robust.\nAs a result, some individual experts outperform the gated MoE model in\nrobustness, suggesting that robust subpaths emerge through specialization. Our\ncode is available at https://github.com/KASTEL-MobilityLab/robust-sparse-moes.", "published": "2025-09-05 13:25:33", "link": "http://arxiv.org/abs/2509.05086v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction", "abstract": "Automated Facial Beauty Prediction (FBP) is a challenging computer vision\ntask due to the complex interplay of local and global facial features that\ninfluence human perception. While Convolutional Neural Networks (CNNs) excel at\nfeature extraction, they often process information at a fixed scale,\npotentially overlooking the critical inter-dependencies between features at\ndifferent levels of granularity. To address this limitation, we introduce the\nScale-Interaction Transformer (SIT), a novel hybrid deep learning architecture\nthat synergizes the feature extraction power of CNNs with the relational\nmodeling capabilities of Transformers. The SIT first employs a multi-scale\nmodule with parallel convolutions to capture facial characteristics at varying\nreceptive fields. These multi-scale representations are then framed as a\nsequence and processed by a Transformer encoder, which explicitly models their\ninteractions and contextual relationships via a self-attention mechanism. We\nconduct extensive experiments on the widely-used SCUT-FBP5500 benchmark\ndataset, where the proposed SIT model establishes a new state-of-the-art. It\nachieves a Pearson Correlation of 0.9187, outperforming previous methods. Our\nfindings demonstrate that explicitly modeling the interplay between multi-scale\nvisual cues is crucial for high-performance FBP. The success of the SIT\narchitecture highlights the potential of hybrid CNN-Transformer models for\ncomplex image regression tasks that demand a holistic, context-aware\nunderstanding.", "published": "2025-09-05 13:16:55", "link": "http://arxiv.org/abs/2509.05078v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting", "abstract": "A few recent works explored incorporating geometric priors to regularize the\noptimization of Gaussian splatting, further improving its performance. However,\nthose early studies mainly focused on the use of low-order geometric priors\n(e.g., normal vector), and they are also unreliably estimated by\nnoise-sensitive methods, like local principal component analysis. To address\ntheir limitations, we first present GeoSplat, a general geometry-constrained\noptimization framework that exploits both first-order and second-order\ngeometric quantities to improve the entire training pipeline of Gaussian\nsplatting, including Gaussian initialization, gradient update, and\ndensification. As an example, we initialize the scales of 3D Gaussian\nprimitives in terms of principal curvatures, leading to a better coverage of\nthe object surface than random initialization. Secondly, based on certain\ngeometric structures (e.g., local manifold), we introduce efficient and\nnoise-robust estimation methods that provide dynamic geometric priors for our\nframework. We conduct extensive experiments on multiple datasets for novel view\nsynthesis, showing that our framework: GeoSplat, significantly improves the\nperformance of Gaussian splatting and outperforms previous baselines.", "published": "2025-09-05 13:15:37", "link": "http://arxiv.org/abs/2509.05075v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction", "abstract": "Background: To systematically review and perform a meta-analysis of\nartificial intelligence (AI)-driven methods for detecting and correcting\nmagnetic resonance imaging (MRI) motion artifacts, assessing current\ndevelopments, effectiveness, challenges, and future research directions.\nMethods: A comprehensive systematic review and meta-analysis were conducted,\nfocusing on deep learning (DL) approaches, particularly generative models, for\nthe detection and correction of MRI motion artifacts. Quantitative data were\nextracted regarding utilized datasets, DL architectures, and performance\nmetrics. Results: DL, particularly generative models, show promise for reducing\nmotion artifacts and improving image quality; however, limited\ngeneralizability, reliance on paired training data, and risk of visual\ndistortions remain key challenges that motivate standardized datasets and\nreporting. Conclusions: AI-driven methods, particularly DL generative models,\nshow significant potential for improving MRI image quality by effectively\naddressing motion artifacts. However, critical challenges must be addressed,\nincluding the need for comprehensive public datasets, standardized reporting\nprotocols for artifact levels, and more advanced, adaptable DL techniques to\nreduce reliance on extensive paired datasets. Addressing these aspects could\nsubstantially enhance MRI diagnostic accuracy, reduce healthcare costs, and\nimprove patient care outcomes.", "published": "2025-09-05 13:09:37", "link": "http://arxiv.org/abs/2509.05071v1", "categories": ["cs.CV", "physics.med-ph"], "primary_category": "cs.CV"}
{"title": "LUIVITON: Learned Universal Interoperable VIrtual Try-ON", "abstract": "We present LUIVITON, an end-to-end system for fully automated virtual try-on,\ncapable of draping complex, multi-layer clothing onto diverse and arbitrarily\nposed humanoid characters. To address the challenge of aligning complex\ngarments with arbitrary and highly diverse body shapes, we use SMPL as a proxy\nrepresentation and separate the clothing-to-body draping problem into two\ncorrespondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence,\nwhere each has its unique challenges. While we address the clothing-to-SMPL\nfitting problem using a geometric learning-based approach for\npartial-to-complete shape correspondence prediction, we introduce a diffusion\nmodel-based approach for body-to-SMPL correspondence using multi-view\nconsistent appearance features and a pre-trained 2D foundation model. Our\nmethod can handle complex geometries, non-manifold meshes, and generalizes\neffectively to a wide range of humanoid characters -- including humans, robots,\ncartoon subjects, creatures, and aliens, while maintaining computational\nefficiency for practical adoption. In addition to offering a fully automatic\nfitting solution, LUIVITON supports fast customization of clothing size,\nallowing users to adjust clothing sizes and material properties after they have\nbeen draped. We show that our system can produce high-quality 3D clothing\nfittings without any human labor, even when 2D clothing sewing patterns are not\navailable.", "published": "2025-09-05 11:40:44", "link": "http://arxiv.org/abs/2509.05030v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition", "abstract": "The study explores the integration of transfer learning (TL) with\nmobile-enabled convolutional neural networks (MbNets) to enhance Arabic\nHandwritten Character Recognition (AHCR). Addressing challenges like extensive\ncomputational requirements and dataset scarcity, this research evaluates three\nTL strategies--full fine-tuning, partial fine-tuning, and training from\nscratch--using four lightweight MbNets: MobileNet, SqueezeNet, MnasNet, and\nShuffleNet. Experiments were conducted on three benchmark datasets: AHCD,\nHIJJA, and IFHCDB. MobileNet emerged as the top-performing model, consistently\nachieving superior accuracy, robustness, and efficiency, with ShuffleNet\nexcelling in generalization, particularly under full fine-tuning. The IFHCDB\ndataset yielded the highest results, with 99% accuracy using MnasNet under full\nfine-tuning, highlighting its suitability for robust character recognition. The\nAHCD dataset achieved competitive accuracy (97%) with ShuffleNet, while HIJJA\nposed significant challenges due to its variability, achieving a peak accuracy\nof 92% with ShuffleNet. Notably, full fine-tuning demonstrated the best overall\nperformance, balancing accuracy and convergence speed, while partial\nfine-tuning underperformed across metrics. These findings underscore the\npotential of combining TL and MbNets for resource-efficient AHCR, paving the\nway for further optimizations and broader applications. Future work will\nexplore architectural modifications, in-depth dataset feature analysis, data\naugmentation, and advanced sensitivity analysis to enhance model robustness and\ngeneralizability.", "published": "2025-09-05 11:28:53", "link": "http://arxiv.org/abs/2509.05019v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A biologically inspired separable learning vision model for real-time traffic object perception in Dark", "abstract": "Fast and accurate object perception in low-light traffic scenes has attracted\nincreasing attention. However, due to severe illumination degradation and the\nlack of reliable visual cues, existing perception models and methods struggle\nto quickly adapt to and accurately predict in low-light environments. Moreover,\nthere is the absence of available large-scale benchmark specifically focused on\nlow-light traffic scenes. To bridge this gap, we introduce a physically\ngrounded illumination degradation method tailored to real-world low-light\nsettings and construct Dark-traffic, the largest densely annotated dataset to\ndate for low-light traffic scenes, supporting object detection, instance\nsegmentation, and optical flow estimation. We further propose the Separable\nLearning Vision Model (SLVM), a biologically inspired framework designed to\nenhance perception under adverse lighting. SLVM integrates four key components:\na light-adaptive pupillary mechanism for illumination-sensitive feature\nextraction, a feature-level separable learning strategy for efficient\nrepresentation, task-specific decoupled branches for multi-task separable\nlearning, and a spatial misalignment-aware fusion module for precise\nmulti-feature alignment. Extensive experiments demonstrate that SLVM achieves\nstate-of-the-art performance with reduced computational overhead. Notably, it\noutperforms RT-DETR by 11.2 percentage points in detection, YOLOv12 by 6.1\npercentage points in instance segmentation, and reduces endpoint error (EPE) of\nbaseline by 12.37% on Dark-traffic. On the LIS benchmark, the end-to-end\ntrained SLVM surpasses Swin Transformer+EnlightenGAN and\nConvNeXt-T+EnlightenGAN by an average of 11 percentage points across key\nmetrics, and exceeds Mask RCNN (with light enhancement) by 3.1 percentage\npoints. The Dark-traffic dataset and complete code is released at\nhttps://github.com/alanli1997/slvm.", "published": "2025-09-05 11:22:52", "link": "http://arxiv.org/abs/2509.05012v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Interpretable Deep Transfer Learning for Breast Ultrasound Cancer Detection: A Multi-Dataset Study", "abstract": "Breast cancer remains a leading cause of cancer-related mortality among women\nworldwide. Ultrasound imaging, widely used due to its safety and\ncost-effectiveness, plays a key role in early detection, especially in patients\nwith dense breast tissue. This paper presents a comprehensive study on the\napplication of machine learning and deep learning techniques for breast cancer\nclassification using ultrasound images. Using datasets such as BUSI, BUS-BRA,\nand BrEaST-Lesions USG, we evaluate classical machine learning models (SVM,\nKNN) and deep convolutional neural networks (ResNet-18, EfficientNet-B0,\nGoogLeNet). Experimental results show that ResNet-18 achieves the highest\naccuracy (99.7%) and perfect sensitivity for malignant lesions. Classical ML\nmodels, though outperformed by CNNs, achieve competitive performance when\nenhanced with deep feature extraction. Grad-CAM visualizations further improve\nmodel transparency by highlighting diagnostically relevant image regions. These\nfindings support the integration of AI-based diagnostic tools into clinical\nworkflows and demonstrate the feasibility of deploying high-performing,\ninterpretable systems for ultrasound-based breast cancer detection.", "published": "2025-09-05 11:03:15", "link": "http://arxiv.org/abs/2509.05004v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework", "abstract": "Most existing infrared-visible image fusion (IVIF) methods assume\nhigh-quality inputs, and therefore struggle to handle dual-source degraded\nscenarios, typically requiring manual selection and sequential application of\nmultiple pre-enhancement steps. This decoupled pre-enhancement-to-fusion\npipeline inevitably leads to error accumulation and performance degradation. To\novercome these limitations, we propose Guided Dual-Domain Fusion (GD^2Fusion),\na novel framework that synergistically integrates vision-language models (VLMs)\nfor degradation perception with dual-domain (frequency/spatial) joint\noptimization. Concretely, the designed Guided Frequency Modality-Specific\nExtraction (GFMSE) module performs frequency-domain degradation perception and\nsuppression and discriminatively extracts fusion-relevant sub-band features.\nMeanwhile, the Guided Spatial Modality-Aggregated Fusion (GSMAF) module carries\nout cross-modal degradation filtering and adaptive multi-source feature\naggregation in the spatial domain to enhance modality complementarity and\nstructural consistency. Extensive qualitative and quantitative experiments\ndemonstrate that GD^2Fusion achieves superior fusion performance compared with\nexisting algorithms and strategies in dual-source degraded scenarios. The code\nwill be publicly released after acceptance of this paper.", "published": "2025-09-05 10:48:46", "link": "http://arxiv.org/abs/2509.05000v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper", "abstract": "Recent Video-to-Audio (V2A) generation relies on extracting semantic and\ntemporal features from video to condition generative models. Training these\nmodels from scratch is resource intensive. Consequently, leveraging foundation\nmodels (FMs) has gained traction due to their cross-modal knowledge transfer\nand generalization capabilities. One prior work has explored fine-tuning a\nlightweight mapper network to connect a pre-trained visual encoder with a\ntext-to-audio generation model for V2A. Inspired by this, we introduce the\nMultiple Foundation Model Mapper (MFM-Mapper). Compared to the previous mapper\napproach, MFM-Mapper benefits from richer semantic and temporal information by\nfusing features from dual visual encoders. Furthermore, by replacing a linear\nmapper with GPT-2, MFM-Mapper improves feature alignment, drawing parallels\nbetween cross-modal features mapping and autoregressive translation tasks. Our\nMFM-Mapper exhibits remarkable training efficiency. It achieves better\nperformance in semantic and temporal consistency with fewer training consuming,\nrequiring only 16\\% of the training scale compared to previous mapper-based\nwork, yet achieves competitive performance with models trained on a much larger\nscale.", "published": "2025-09-05 09:24:08", "link": "http://arxiv.org/abs/2509.04957v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)", "abstract": "Topological localization is a fundamental problem in mobile robotics, since\nrobots must be able to determine their position in order to accomplish tasks.\nVisual localization and place recognition are challenging due to perceptual\nambiguity, sensor noise, and illumination variations. This work addresses\ntopological localization in an office environment using only images acquired\nwith a perspective color camera mounted on a robot platform, without relying on\ntemporal continuity of image sequences. We evaluate state-of-the-art visual\ndescriptors, including Color Histograms, SIFT, ASIFT, RGB-SIFT, and\nBag-of-Visual-Words approaches inspired by text retrieval. Our contributions\ninclude a systematic, quantitative comparison of these features, distance\nmeasures, and classifiers. Performance was analyzed using standard evaluation\nmetrics and visualizations, extending previous experiments. Results demonstrate\nthe advantages of proper configurations of appearance descriptors, similarity\nmeasures, and classifiers. The quality of these configurations was further\nvalidated in the Robot Vision task of the ImageCLEF evaluation campaign, where\nthe system identified the most likely location of novel image sequences. Future\nwork will explore hierarchical models, ranking methods, and feature\ncombinations to build more robust localization systems, reducing training and\nruntime while avoiding the curse of dimensionality. Ultimately, this aims\ntoward integrated, real-time localization across varied illumination and longer\nroutes.", "published": "2025-09-05 09:14:59", "link": "http://arxiv.org/abs/2509.04948v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "UniView: Enhancing Novel View Synthesis From A Single Image By Unifying Reference Features", "abstract": "The task of synthesizing novel views from a single image is highly ill-posed\ndue to multiple explanations for unobserved areas. Most current methods tend to\ngenerate unseen regions from ambiguity priors and interpolation near input\nviews, which often lead to severe distortions. To address this limitation, we\npropose a novel model dubbed as UniView, which can leverage reference images\nfrom a similar object to provide strong prior information during view\nsynthesis. More specifically, we construct a retrieval and augmentation system\nand employ a multimodal large language model (MLLM) to assist in selecting\nreference images that meet our requirements. Additionally, a plug-and-play\nadapter module with multi-level isolation layers is introduced to dynamically\ngenerate reference features for the target views. Moreover, in order to\npreserve the details of an original input image, we design a decoupled triple\nattention mechanism, which can effectively align and integrate multi-branch\nfeatures into the synthesis process. Extensive experiments have demonstrated\nthat our UniView significantly improves novel view synthesis performance and\noutperforms state-of-the-art methods on the challenging datasets.", "published": "2025-09-05 08:54:57", "link": "http://arxiv.org/abs/2509.04932v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting", "abstract": "Sebocytes are lipid-secreting cells whose differentiation is marked by the\naccumulation of intracellular lipid droplets, making their quantification a key\nreadout in sebocyte biology. Manual counting is labor-intensive and subjective,\nmotivating automated solutions. Here, we introduce a simple attention-based\nmultiple instance learning (MIL) framework for sebocyte image analysis. Nile\nRed-stained sebocyte images were annotated into 14 classes according to droplet\ncounts, expanded via data augmentation to about 50,000 cells. Two models were\nbenchmarked: a baseline multi-layer perceptron (MLP) trained on aggregated\npatch-level counts, and an attention-based MIL model leveraging ResNet-50\nfeatures with instance weighting. Experiments using five-fold cross-validation\nshowed that the baseline MLP achieved more stable performance (mean MAE = 5.6)\ncompared with the attention-based MIL, which was less consistent (mean MAE =\n10.7) but occasionally superior in specific folds. These findings indicate that\nsimple bag-level aggregation provides a robust baseline for slide-level droplet\ncounting, while attention-based MIL requires task-aligned pooling and\nregularization to fully realize its potential in sebocyte image analysis.", "published": "2025-09-05 08:15:57", "link": "http://arxiv.org/abs/2509.04895v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SynGen-Vision: Synthetic Data Generation for training industrial vision models", "abstract": "We propose an approach to generate synthetic data to train computer vision\n(CV) models for industrial wear and tear detection. Wear and tear detection is\nan important CV problem for predictive maintenance tasks in any industry.\nHowever, data curation for training such models is expensive and time-consuming\ndue to the unavailability of datasets for different wear and tear scenarios.\nOur approach employs a vision language model along with a 3D simulation and\nrendering engine to generate synthetic data for varying rust conditions. We\nevaluate our approach by training a CV model for rust detection using the\ngenerated dataset and tested the trained model on real images of rusted\nindustrial objects. The model trained with the synthetic data generated by our\napproach, outperforms the other approaches with a mAP50 score of 0.87. The\napproach is customizable and can be easily extended to other industrial wear\nand tear detection scenarios", "published": "2025-09-05 08:15:46", "link": "http://arxiv.org/abs/2509.04894v1", "categories": ["cs.CV", "cs.LG", "I.4"], "primary_category": "cs.CV"}
{"title": "Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning", "abstract": "Cryoablation is a minimally invasive localised treatment for prostate cancer\nthat destroys malignant tissue during de-freezing, while sparing surrounding\nhealthy structures. Its success depends on accurate preoperative planning of\ncryoprobe placements to fully cover the tumour and avoid critical anatomy. This\nplanning is currently manual, expertise-dependent, and time-consuming, leading\nto variability in treatment quality and limited scalability. In this work, we\nintroduce Cryo-RL, a reinforcement learning framework that models cryoablation\nplanning as a Markov decision process and learns an optimal policy for\ncryoprobe placement. Within a simulated environment that models clinical\nconstraints and stochastic intraoperative variability, an agent sequentially\nselects cryoprobe positions and ice sphere diameters. Guided by a reward\nfunction based on tumour coverage, this agent learns a cryoablation strategy\nthat leads to optimal cryoprobe placements without the need for any\nmanually-designed plans. Evaluated on 583 retrospective prostate cancer cases,\nCryo-RL achieved over 8 percentage-point Dice improvements compared with the\nbest automated baselines, based on geometric optimisation, and matched human\nexpert performance while requiring substantially less planning time. These\nresults highlight the potential of reinforcement learning to deliver clinically\nviable, reproducible, and efficient cryoablation plans.", "published": "2025-09-05 08:06:08", "link": "http://arxiv.org/abs/2509.04886v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-modal Uncertainty Robust Tree Cover Segmentation For High-Resolution Remote Sensing Images", "abstract": "Recent advances in semantic segmentation of multi-modal remote sensing images\nhave significantly improved the accuracy of tree cover mapping, supporting\napplications in urban planning, forest monitoring, and ecological assessment.\nIntegrating data from multiple modalities-such as optical imagery, light\ndetection and ranging (LiDAR), and synthetic aperture radar (SAR)-has shown\nsuperior performance over single-modality methods. However, these data are\noften acquired days or even months apart, during which various changes may\noccur, such as vegetation disturbances (e.g., logging, and wildfires) and\nvariations in imaging quality. Such temporal misalignments introduce\ncross-modal uncertainty, especially in high-resolution imagery, which can\nseverely degrade segmentation accuracy. To address this challenge, we propose\nMURTreeFormer, a novel multi-modal segmentation framework that mitigates and\nleverages aleatoric uncertainty for robust tree cover mapping. MURTreeFormer\ntreats one modality as primary and others as auxiliary, explicitly modeling\npatch-level uncertainty in the auxiliary modalities via a probabilistic latent\nrepresentation. Uncertain patches are identified and reconstructed from the\nprimary modality's distribution through a VAE-based resampling mechanism,\nproducing enhanced auxiliary features for fusion. In the decoder, a gradient\nmagnitude attention (GMA) module and a lightweight refinement head (RH) are\nfurther integrated to guide attention toward tree-like structures and to\npreserve fine-grained spatial details. Extensive experiments on multi-modal\ndatasets from Shanghai and Zurich demonstrate that MURTreeFormer significantly\nimproves segmentation performance and effectively reduces the impact of\ntemporally induced aleatoric uncertainty.", "published": "2025-09-05 07:32:42", "link": "http://arxiv.org/abs/2509.04870v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus", "abstract": "Mobile reconstruction for autonomous aerial robotics holds strong potential\nfor critical applications such as tele-guidance and disaster response. These\ntasks demand both accurate 3D reconstruction and fast scene processing. Instead\nof reconstructing the entire scene in detail, it is often more efficient to\nfocus on specific objects, i.e., points of interest (PoIs). Mobile robots\nequipped with advanced sensing can usually detect these early during data\nacquisition or preliminary analysis, reducing the need for full-scene\noptimization. Gaussian Splatting (GS) has recently shown promise in delivering\nhigh-quality novel view synthesis and 3D representation by an incremental\nlearning process. Extending GS with scene editing, semantics adds useful\nper-splat features to isolate objects effectively.\n  Semantic 3D Gaussian editing can already be achieved before the full training\ncycle is completed, reducing the overall training time. Moreover, the\nsemantically relevant area, the PoI, is usually already known during capturing.\nTo balance high-quality reconstruction with reduced training time, we propose\nCoRe-GS. We first generate a coarse segmentation-ready scene with semantic GS\nand then refine it for the semantic object using our novel color-based\neffective filtering for effective object isolation. This is speeding up the\ntraining process to be about a quarter less than a full training cycle for\nsemantic GS. We evaluate our approach on two datasets, SCRREAM (real-world,\noutdoor) and NeRDS 360 (synthetic, indoor), showing reduced runtime and higher\nnovel-view-synthesis quality.", "published": "2025-09-05 07:21:26", "link": "http://arxiv.org/abs/2509.04859v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Histogram Driven Amplitude Embedding for Qubit Efficient Quantum Image Compression", "abstract": "This work introduces a compact and hardware efficient method for compressing\ncolor images using near term quantum devices. The approach segments the image\ninto fixed size blocks called bixels, and computes the total intensity within\neach block. A global histogram with B bins is then constructed from these block\nintensities, and the normalized square roots of the bin counts are encoded as\namplitudes into an n qubit quantum state. Amplitude embedding is performed\nusing PennyLane and executed on real IBM Quantum hardware. The resulting state\nis measured to reconstruct the histogram, enabling approximate recovery of\nblock intensities and full image reassembly. The method maintains a constant\nqubit requirement based solely on the number of histogram bins, independent of\nthe resolution of the image. By adjusting B, users can control the trade off\nbetween fidelity and resource usage. Empirical results demonstrate high quality\nreconstructions using as few as 5 to 7 qubits, significantly outperforming\nconventional pixel level encodings in terms of qubit efficiency and validating\nthe practical application of the method for current NISQ era quantum systems.", "published": "2025-09-05 06:58:53", "link": "http://arxiv.org/abs/2509.04849v1", "categories": ["quant-ph", "cs.CV", "cs.ET", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations", "abstract": "High-throughput 3D quantitative phase imaging (QPI) in flow cytometry enables\nlabel-free, volumetric characterization of individual cells by reconstructing\ntheir refractive index (RI) distributions from multiple viewing angles during\nflow through microfluidic channels. However, current imaging methods assume\nthat cells undergo uniform, single-axis rotation, which require their poses to\nbe known at each frame. This assumption restricts applicability to\nnear-spherical cells and prevents accurate imaging of irregularly shaped cells\nwith complex rotations. As a result, only a subset of the cellular population\ncan be analyzed, limiting the ability of flow-based assays to perform robust\nstatistical analysis. We introduce OmniFHT, a pose-free 3D RI reconstruction\nframework that leverages the Fourier diffraction theorem and implicit neural\nrepresentations (INRs) for high-throughput flow cytometry tomographic imaging.\nBy jointly optimizing each cell's unknown rotational trajectory and volumetric\nstructure under weak scattering assumptions, OmniFHT supports arbitrary cell\ngeometries and multi-axis rotations. Its continuous representation also allows\naccurate reconstruction from sparsely sampled projections and restricted\nangular coverage, producing high-fidelity results with as few as 10 views or\nonly 120 degrees of angular range. OmniFHT enables, for the first time, in\nsitu, high-throughput tomographic imaging of entire flowing cell populations,\nproviding a scalable and unbiased solution for label-free morphometric analysis\nin flow cytometry platforms.", "published": "2025-09-05 06:58:39", "link": "http://arxiv.org/abs/2509.04848v1", "categories": ["cs.CV", "physics.bio-ph", "physics.optics", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution", "abstract": "Understanding the complex combustion dynamics within scramjet engines is\ncritical for advancing high-speed propulsion technologies. However, the large\nscale and high dimensionality of simulation-generated temporal flow field data\npresent significant challenges for visual interpretation, feature\ndifferentiation, and cross-case comparison. In this paper, we present\nTemporalFlowViz, a parameter-aware visual analytics workflow and system\ndesigned to support expert-driven clustering, visualization, and interpretation\nof temporal flow fields from scramjet combustion simulations. Our approach\nleverages hundreds of simulated combustion cases with varying initial\nconditions, each producing time-sequenced flow field images. We use pretrained\nVision Transformers to extract high-dimensional embeddings from these frames,\napply dimensionality reduction and density-based clustering to uncover latent\ncombustion modes, and construct temporal trajectories in the embedding space to\ntrack the evolution of each simulation over time. To bridge the gap between\nlatent representations and expert reasoning, domain specialists annotate\nrepresentative cluster centroids with descriptive labels. These annotations are\nused as contextual prompts for a vision-language model, which generates\nnatural-language summaries for individual frames and full simulation cases. The\nsystem also supports parameter-based filtering, similarity-based case\nretrieval, and coordinated multi-view exploration to facilitate in-depth\nanalysis. We demonstrate the effectiveness of TemporalFlowViz through two\nexpert-informed case studies and expert feedback, showing TemporalFlowViz\nenhances hypothesis generation, supports interpretable pattern discovery, and\nenhances knowledge discovery in large-scale scramjet combustion analysis.", "published": "2025-09-05 06:35:36", "link": "http://arxiv.org/abs/2509.04834v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AURAD: Anatomy-Pathology Unified Radiology Synthesis with Progressive Representations", "abstract": "Medical image synthesis has become an essential strategy for augmenting\ndatasets and improving model generalization in data-scarce clinical settings.\nHowever, fine-grained and controllable synthesis remains difficult due to\nlimited high-quality annotations and domain shifts across datasets. Existing\nmethods, often designed for natural images or well-defined tumors, struggle to\ngeneralize to chest radiographs, where disease patterns are morphologically\ndiverse and tightly intertwined with anatomical structures. To address these\nchallenges, we propose AURAD, a controllable radiology synthesis framework that\njointly generates high-fidelity chest X-rays and pseudo semantic masks. Unlike\nprior approaches that rely on randomly sampled masks-limiting diversity,\ncontrollability, and clinical relevance-our method learns to generate masks\nthat capture multi-pathology coexistence and anatomical-pathological\nconsistency. It follows a progressive pipeline: pseudo masks are first\ngenerated from clinical prompts conditioned on anatomical structures, and then\nused to guide image synthesis. We also leverage pretrained expert medical\nmodels to filter outputs and ensure clinical plausibility. Beyond visual\nrealism, the synthesized masks also serve as labels for downstream tasks such\nas detection and segmentation, bridging the gap between generative modeling and\nreal-world clinical applications. Extensive experiments and blinded radiologist\nevaluations demonstrate the effectiveness and generalizability of our method\nacross tasks and datasets. In particular, 78% of our synthesized images are\nclassified as authentic by board-certified radiologists, and over 40% of\npredicted segmentation overlays are rated as clinically useful. All code,\npre-trained models, and the synthesized dataset will be released upon\npublication.", "published": "2025-09-05 05:40:55", "link": "http://arxiv.org/abs/2509.04819v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation", "abstract": "Estimating accurate and well-calibrated predictive uncertainty is important\nfor enhancing the reliability of computer vision models, especially in\nsafety-critical applications like traffic scene perception. While ensemble\nmethods are commonly used to quantify uncertainty by combining multiple models,\na mixture of experts (MoE) offers an efficient alternative by leveraging a\ngating network to dynamically weight expert predictions based on the input.\nBuilding on the promising use of MoEs for semantic segmentation in our previous\nworks, we show that well-calibrated predictive uncertainty estimates can be\nextracted from MoEs without architectural modifications. We investigate three\nmethods to extract predictive uncertainty estimates: predictive entropy, mutual\ninformation, and expert variance. We evaluate these methods for an MoE with two\nexperts trained on a semantical split of the A2D2 dataset. Our results show\nthat MoEs yield more reliable uncertainty estimates than ensembles in terms of\nconditional correctness metrics under out-of-distribution (OOD) data.\nAdditionally, we evaluate routing uncertainty computed via gate entropy and\nfind that simple gating mechanisms lead to better calibration of routing\nuncertainty estimates than more complex classwise gates. Finally, our\nexperiments on the Cityscapes dataset suggest that increasing the number of\nexperts can further enhance uncertainty calibration. Our code is available at\nhttps://github.com/KASTEL-MobilityLab/mixtures-of-experts/.", "published": "2025-09-05 05:30:53", "link": "http://arxiv.org/abs/2509.04816v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Comparative Evaluation of Traditional and Deep Learning Feature Matching Algorithms using Chandrayaan-2 Lunar Data", "abstract": "Accurate image registration is critical for lunar exploration, enabling\nsurface mapping, resource localization, and mission planning. Aligning data\nfrom diverse lunar sensors -- optical (e.g., Orbital High Resolution Camera,\nNarrow and Wide Angle Cameras), hyperspectral (Imaging Infrared Spectrometer),\nand radar (e.g., Dual-Frequency Synthetic Aperture Radar, Selene/Kaguya\nmission) -- is challenging due to differences in resolution, illumination, and\nsensor distortion. We evaluate five feature matching algorithms: SIFT, ASIFT,\nAKAZE, RIFT2, and SuperGlue (a deep learning-based matcher), using\ncross-modality image pairs from equatorial and polar regions. A preprocessing\npipeline is proposed, including georeferencing, resolution alignment, intensity\nnormalization, and enhancements like adaptive histogram equalization, principal\ncomponent analysis, and shadow correction. SuperGlue consistently yields the\nlowest root mean square error and fastest runtimes. Classical methods such as\nSIFT and AKAZE perform well near the equator but degrade under polar lighting.\nThe results highlight the importance of preprocessing and learning-based\napproaches for robust lunar image registration across diverse conditions.", "published": "2025-09-05 03:10:00", "link": "http://arxiv.org/abs/2509.04775v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hybrid-Tower: Fine-grained Pseudo-query Interaction and Generation for Text-to-Video Retrieval", "abstract": "The Text-to-Video Retrieval (T2VR) task aims to retrieve unlabeled videos by\ntextual queries with the same semantic meanings. Recent CLIP-based approaches\nhave explored two frameworks: Two-Tower versus Single-Tower framework, yet the\nformer suffers from low effectiveness, while the latter suffers from low\nefficiency. In this study, we explore a new Hybrid-Tower framework that can\nhybridize the advantages of the Two-Tower and Single-Tower framework, achieving\nhigh effectiveness and efficiency simultaneously. We propose a novel hybrid\nmethod, Fine-grained Pseudo-query Interaction and Generation for T2VR, ie, PIG,\nwhich includes a new pseudo-query generator designed to generate a pseudo-query\nfor each video. This enables the video feature and the textual features of\npseudo-query to interact in a fine-grained manner, similar to the Single-Tower\napproaches to hold high effectiveness, even before the real textual query is\nreceived. Simultaneously, our method introduces no additional storage or\ncomputational overhead compared to the Two-Tower framework during the inference\nstage, thus maintaining high efficiency. Extensive experiments on five commonly\nused text-video retrieval benchmarks demonstrate that our method achieves a\nsignificant improvement over the baseline, with an increase of $1.6\\% \\sim\n3.9\\%$ in R@1. Furthermore, our method matches the efficiency of Two-Tower\nmodels while achieving near state-of-the-art performance, highlighting the\nadvantages of the Hybrid-Tower framework.", "published": "2025-09-05 03:05:50", "link": "http://arxiv.org/abs/2509.04773v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic Group Detection using VLM-augmented Temporal Groupness Graph", "abstract": "This paper proposes dynamic human group detection in videos. For detecting\ncomplex groups, not only the local appearance features of in-group members but\nalso the global context of the scene are important. Such local and global\nappearance features in each frame are extracted using a Vision-Language Model\n(VLM) augmented for group detection in our method. For further improvement, the\ngroup structure should be consistent over time. While previous methods are\nstabilized on the assumption that groups are not changed in a video, our method\ndetects dynamically changing groups by global optimization using a graph with\nall frames' groupness probabilities estimated by our groupness-augmented CLIP\nfeatures. Our experimental results demonstrate that our method outperforms\nstate-of-the-art group detection methods on public datasets. Code:\nhttps://github.com/irajisamurai/VLM-GroupDetection.git", "published": "2025-09-05 02:37:01", "link": "http://arxiv.org/abs/2509.04758v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WatchHAR: Real-time On-device Human Activity Recognition System for Smartwatches", "abstract": "Despite advances in practical and multimodal fine-grained Human Activity\nRecognition (HAR), a system that runs entirely on smartwatches in unconstrained\nenvironments remains elusive. We present WatchHAR, an audio and inertial-based\nHAR system that operates fully on smartwatches, addressing privacy and latency\nissues associated with external data processing. By optimizing each component\nof the pipeline, WatchHAR achieves compounding performance gains. We introduce\na novel architecture that unifies sensor data preprocessing and inference into\nan end-to-end trainable module, achieving 5x faster processing while\nmaintaining over 90% accuracy across more than 25 activity classes. WatchHAR\noutperforms state-of-the-art models for event detection and activity\nclassification while running directly on the smartwatch, achieving 9.3 ms\nprocessing time for activity event detection and 11.8 ms for multimodal\nactivity classification. This research advances on-device activity recognition,\nrealizing smartwatches' potential as standalone, privacy-aware, and\nminimally-invasive continuous activity tracking devices.", "published": "2025-09-05 01:30:16", "link": "http://arxiv.org/abs/2509.04736v1", "categories": ["cs.CV", "I.2.10; H.5.2"], "primary_category": "cs.CV"}
{"title": "Exploiting Unlabeled Structures through Task Consistency Training for Versatile Medical Image Segmentation", "abstract": "Versatile medical image segmentation (VMIS) targets the segmentation of\nmultiple classes, while obtaining full annotations for all classes is often\nimpractical due to the time and labor required. Leveraging partially labeled\ndatasets (PLDs) presents a promising alternative; however, current VMIS\napproaches face significant class imbalance due to the unequal category\ndistribution in PLDs. Existing methods attempt to address this by generating\npseudo-full labels. Nevertheless, these typically require additional models and\noften result in potential performance degradation from label noise. In this\nwork, we introduce a Task Consistency Training (TCT) framework to address class\nimbalance without requiring extra models. TCT includes a backbone network with\na main segmentation head (MSH) for multi-channel predictions and multiple\nauxiliary task heads (ATHs) for task-specific predictions. By enforcing a\nconsistency constraint between the MSH and ATH predictions, TCT effectively\nutilizes unlabeled anatomical structures. To avoid error propagation from\nlow-consistency, potentially noisy data, we propose a filtering strategy to\nexclude such data. Additionally, we introduce a unified auxiliary\nuncertainty-weighted loss (UAUWL) to mitigate segmentation quality declines\ncaused by the dominance of specific tasks. Extensive experiments on eight\nabdominal datasets from diverse clinical sites demonstrate our approach's\neffectiveness.", "published": "2025-09-05 01:04:32", "link": "http://arxiv.org/abs/2509.04732v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CD-Mamba: Cloud detection with long-range spatial dependency modeling", "abstract": "Remote sensing images are frequently obscured by cloud cover, posing\nsignificant challenges to data integrity and reliability. Effective cloud\ndetection requires addressing both short-range spatial redundancies and\nlong-range atmospheric similarities among cloud patches. Convolutional neural\nnetworks are effective at capturing local spatial dependencies, while Mamba has\nstrong capabilities in modeling long-range dependencies. To fully leverage both\nlocal spatial relations and long-range dependencies, we propose CD-Mamba, a\nhybrid model that integrates convolution and Mamba's state-space modeling into\na unified cloud detection network. CD-Mamba is designed to comprehensively\ncapture pixelwise textural details and long term patchwise dependencies for\ncloud detection. This design enables CD-Mamba to manage both pixel-wise\ninteractions and extensive patch-wise dependencies simultaneously, improving\ndetection accuracy across diverse spatial scales. Extensive experiments\nvalidate the effectiveness of CD-Mamba and demonstrate its superior performance\nover existing methods.", "published": "2025-09-05 01:02:02", "link": "http://arxiv.org/abs/2509.04729v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous GPUs", "abstract": "The escalating adoption of diffusion models for applications such as image\ngeneration demands efficient parallel inference techniques to manage their\nsubstantial computational cost. However, existing diffusion parallelism\ninference schemes often underutilize resources in heterogeneous multi-GPU\nenvironments, where varying hardware capabilities or background tasks cause\nworkload imbalance. This paper introduces Spatio-Temporal Adaptive Diffusion\nInference (STADI), a novel framework to accelerate diffusion model inference in\nsuch settings. At its core is a hybrid scheduler that orchestrates fine-grained\nparallelism across both temporal and spatial dimensions. Temporally, STADI\nintroduces a novel computation-aware step allocator applied after warmup\nphases, using a least-common-multiple-minimizing quantization technique to\nreduce denoising steps on slower GPUs and execution synchronization. To further\nminimize GPU idle periods, STADI executes an elastic patch parallelism\nmechanism that allocates variably sized image patches to GPUs according to\ntheir computational capability, ensuring balanced workload distribution through\na complementary spatial mechanism. Extensive experiments on both\nload-imbalanced and heterogeneous multi-GPU clusters validate STADI's efficacy,\ndemonstrating improved load balancing and mitigation of performance\nbottlenecks. Compared to patch parallelism, a state-of-the-art diffusion\ninference framework, our method significantly reduces end-to-end inference\nlatency by up to 45% and significantly improves resource utilization on\nheterogeneous GPUs.", "published": "2025-09-05 00:25:40", "link": "http://arxiv.org/abs/2509.04719v1", "categories": ["cs.DC", "cs.CV"], "primary_category": "cs.DC"}
{"title": "Vertex-ordering and arc-partitioning problems", "abstract": "We study vertex-ordering problems in loop-free digraphs subject to\nconstraints on the left-going arcs, focusing on existence conditions and\ncomputational complexity. As an intriguing special case, we explore\nvertex-specific lower and upper bounds on the left-outdegrees and\nright-indegrees. We show, for example, that deciding whether the left-going\narcs can form an in-branching is solvable in polynomial time and provide a\nnecessary and sufficient condition, while the analogous problem for an\nin-arborescence turns out to be NP-complete. We also consider a weighted\nvariant that enforces vertex-specific lower and upper bounds on the weighted\nleft-outdegrees, which is particularly relevant in applications. Furthermore,\nwe investigate the connection between ordering problems and their\narc-partitioning counterparts, where one seeks to partition the arcs into a\nsubgraph from a specific digraph family and an acyclic subgraph --\nequivalently, one seeks to cover all directed cycles with a subgraph belonging\nto a specific family. For the family of in-branchings, unions of disjoint\ndipaths, and matchings, the two formulations coincide, whereas for\nin-arborescences, dipaths, Hamiltonian dipaths, and perfect matchings the\nformulations diverge. Our results yield a comprehensive complexity landscape,\nunify diverse special cases and variants, clarify the algorithmic boundaries of\nordered digraphs, and relate them to broader topics including graph degeneracy,\nacyclic orientations, influence propagation, and rank aggregation.", "published": "2025-09-05 16:59:32", "link": "http://arxiv.org/abs/2509.05245v1", "categories": ["math.CO", "cs.DM", "cs.DS", "math.OC"], "primary_category": "math.CO"}
{"title": "Efficient Exact Resistance Distance Computation on Small-Treewidth Graphs: a Labelling Approach", "abstract": "Resistance distance computation is a fundamental problem in graph analysis,\nyet existing random walk-based methods are limited to approximate solutions and\nsuffer from poor efficiency on small-treewidth graphs (e.g., road networks). In\ncontrast, shortest-path distance computation achieves remarkable efficiency on\nsuch graphs by leveraging cut properties and tree decompositions. Motivated by\nthis disparity, we first analyze the cut property of resistance distance. While\na direct generalization proves impractical due to costly matrix operations, we\novercome this limitation by integrating tree decompositions, revealing that the\nresistance distance $r(s,t)$ depends only on labels along the paths from $s$\nand $t$ to the root of the decomposition. This insight enables compact\nlabelling structures. Based on this, we propose \\treeindex, a novel index\nmethod that constructs a resistance distance labelling of size $O(n \\cdot\nh_{\\mathcal{G}})$ in $O(n \\cdot h_{\\mathcal{G}}^2 \\cdot d_{\\max})$ time, where\n$h_{\\mathcal{G}}$ (tree height) and $d_{\\max}$ (maximum degree) behave as small\nconstants in many real-world small-treewidth graphs (e.g., road networks). Our\nlabelling supports exact single-pair queries in $O(h_{\\mathcal{G}})$ time and\nsingle-source queries in $O(n \\cdot h_{\\mathcal{G}})$ time. Extensive\nexperiments show that TreeIndex substantially outperforms state-of-the-art\napproaches. For instance, on the full USA road network, it constructs a $405$\nGB labelling in $7$ hours (single-threaded) and answers exact single-pair\nqueries in $10^{-3}$ seconds and single-source queries in $190$ seconds--the\nfirst exact method scalable to such large graphs.", "published": "2025-09-05 14:14:36", "link": "http://arxiv.org/abs/2509.05129v1", "categories": ["cs.DB", "cs.DM", "cs.DS", "cs.LG"], "primary_category": "cs.DB"}
{"title": "CAZAC sequence generation of any length with iterative projection onto unit circle: principle and first results", "abstract": "Constant amplitude zero-autocorrelation (CAZAC) sequences are mainly used for\nsynchronization in communication and radar applications. The state-of-the-art\nproposes analytical derivation of specific families whose major limitation\ncomes from the alphabet which only represents a fraction of the whole, the\nlonger the sequences, the smaller the fraction. The objective of the paper is\nthreefold, first to present the construction of constant amplitude\nzero-circular autocorrelation sequences of any length using iterative\nprojection onto Unit Circle (IPUC) algorithm. This algorithm allows, from any\nrandom seed, to generate a near-CAZAC sequence. Then, focusing on length-8\nsequences, we propose a classification of the IPUC output with an analytical\nexpression of a representative for each identified equivalence class. Finally,\nthe IPUC is applied within a simulated-annealing process to generate near-CAZAC\nsequences suitable for radar applications with optimized ratio between first\nand second lobes of the non-circular autocorrelation function.", "published": "2025-09-05 13:34:09", "link": "http://arxiv.org/abs/2509.05097v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Subgroup perfect codes of $S_n$ in Cayley sum graphs", "abstract": "A perfect code in a graph $\\Gamma = (V, E)$ is a subset $C$ of $V$ such that\nno two vertices in $C$ are adjacent, and every vertex in $V \\setminus C$ is\nadjacent to exactly one vertex in $C$. Let $ G $ be a finite group, and let $ S\n$ be a square-free normal subset of $ G $. The Cayley sum graph of $ G $ with\nrespect to $ S $ is a simple graph with vertex set $ G $ and two vertices $ x $\nand $ y $ are adjacent if $ xy\\in S .$ A subset $ C $ of $ G $ is called\nperfect code of $ G $ if there exists a Cayley sum graph of $ G $ that admits $\nC $ as a perfect code. In particular, if a subgroup of $ G $ is a perfect code\nof $ G $, then the subgroup is called a subgroup perfect code of $ G $. In this\nwork, we prove that there does not exist any proper perfect subgroup code of\nsymmetric group $ S_n $. Using this result, we provide a complete\ncharacterization of the perfect subgroup code of the alternating group $A_n$.", "published": "2025-09-05 13:06:48", "link": "http://arxiv.org/abs/2509.05069v1", "categories": ["math.CO", "cs.DM", "cs.IT", "math.GR", "math.IT", "05C25, 05C69, 94B99, 20B30, 20D06"], "primary_category": "math.CO"}
{"title": "Capturing an Invisible Robber using Separators", "abstract": "We study the zero-visibility cops and robbers game, where the robber is\ninvisible to the cops until they are caught. This differs from the classic game\nwhere full information about the robber's location is known at any time. A\npreviously known solution for capturing a robber in the zero-visibility case is\nbased on the pathwidth decomposition. We provide an alternative solution based\non a separation hierarchy, improving capture time and space complexity without\nasymptotically increasing the zero-visibility cop number in most cases. In\naddition, we provide a better bound on the approximate zero-visibility cop\nnumber for various classes of graphs, where approximate refers to the\nrestriction to polynomial time computable strategies.", "published": "2025-09-05 11:35:31", "link": "http://arxiv.org/abs/2509.05024v1", "categories": ["cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
{"title": "Hybrid Matrix Factorization Based Graph Contrastive Learning for Recommendation System", "abstract": "In recent years, methods that combine contrastive learning with graph neural\nnetworks have emerged to address the challenges of recommendation systems,\ndemonstrating powerful performance and playing a significant role in this\ndomain. Contrastive learning primarily tackles the issue of data sparsity by\nemploying data augmentation strategies, effectively alleviating this problem\nand showing promising results. Although existing research has achieved\nfavorable outcomes, most current graph contrastive learning methods are based\non two types of data augmentation strategies: the first involves perturbing the\ngraph structure, such as by randomly adding or removing edges; and the second\napplies clustering techniques. We believe that the interactive information\nobtained through these two strategies does not fully capture the user-item\ninteractions. In this paper, we propose a novel method called HMFGCL (Hybrid\nMatrix Factorization Based Graph Contrastive Learning), which integrates two\ndistinct matrix factorization techniques-low-rank matrix factorization (MF) and\nsingular value decomposition (SVD)-to complementarily acquire global\ncollaborative information, thereby constructing enhanced views. Experimental\nresults on multiple public datasets demonstrate that our model outperforms\nexisting baselines, particularly on small-scale datasets.", "published": "2025-09-05 13:57:07", "link": "http://arxiv.org/abs/2509.05115v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Fishing for Answers: Exploring One-shot vs. Iterative Retrieval Strategies for Retrieval Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) based on Large Language Models (LLMs) is\na powerful solution to understand and query the industry's closed-source\ndocuments. However, basic RAG often struggles with complex QA tasks in legal\nand regulatory domains, particularly when dealing with numerous government\ndocuments. The top-$k$ strategy frequently misses golden chunks, leading to\nincomplete or inaccurate answers. To address these retrieval bottlenecks, we\nexplore two strategies to improve evidence coverage and answer quality. The\nfirst is a One-SHOT retrieval method that adaptively selects chunks based on a\ntoken budget, allowing as much relevant content as possible to be included\nwithin the model's context window. Additionally, we design modules to further\nfilter and refine the chunks. The second is an iterative retrieval strategy\nbuilt on a Reasoning Agentic RAG framework, where a reasoning LLM dynamically\nissues search queries, evaluates retrieved results, and progressively refines\nthe context over multiple turns. We identify query drift and retrieval laziness\nissues and further design two modules to tackle them. Through extensive\nexperiments on a dataset of government documents, we aim to offer practical\ninsights and guidance for real-world applications in legal and regulatory\ndomains.", "published": "2025-09-05 05:44:50", "link": "http://arxiv.org/abs/2509.04820v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Multimodal Foundation Model-Driven User Interest Modeling and Behavior Analysis on Short Video Platforms", "abstract": "With the rapid expansion of user bases on short video platforms, personalized\nrecommendation systems are playing an increasingly critical role in enhancing\nuser experience and optimizing content distribution. Traditional interest\nmodeling methods often rely on unimodal data, such as click logs or text\nlabels, which limits their ability to fully capture user preferences in a\ncomplex multimodal content environment. To address this challenge, this paper\nproposes a multimodal foundation model-based framework for user interest\nmodeling and behavior analysis. By integrating video frames, textual\ndescriptions, and background music into a unified semantic space using\ncross-modal alignment strategies, the framework constructs fine-grained user\ninterest vectors. Additionally, we introduce a behavior-driven feature\nembedding mechanism that incorporates viewing, liking, and commenting sequences\nto model dynamic interest evolution, thereby improving both the timeliness and\naccuracy of recommendations. In the experimental phase, we conduct extensive\nevaluations using both public and proprietary short video datasets, comparing\nour approach against multiple mainstream recommendation algorithms and modeling\ntechniques. Results demonstrate significant improvements in behavior prediction\naccuracy, interest modeling for cold-start users, and recommendation\nclick-through rates. Moreover, we incorporate interpretability mechanisms using\nattention weights and feature visualization to reveal the model's decision\nbasis under multimodal inputs and trace interest shifts, thereby enhancing the\ntransparency and controllability of the recommendation system.", "published": "2025-09-05 02:05:10", "link": "http://arxiv.org/abs/2509.04751v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "List Decoding Expander-Based Codes via Fast Approximation of Expanding CSPs: I", "abstract": "We present near-linear time list decoding algorithms (in the block-length\n$n$) for expander-based code constructions. More precisely, we show that\n  (i) For every $\\delta \\in (0,1)$ and $\\epsilon > 0$, there is an explicit\nfamily of good Tanner LDPC codes of (design) distance $\\delta$ that is $(\\delta\n- \\epsilon, O_\\varepsilon(1))$ list decodable in time\n$\\widetilde{\\mathcal{O}}_{\\varepsilon}(n)$ with alphabet size $O_\\delta(1)$,\n  (ii) For every $R \\in (0,1)$ and $\\epsilon > 0$, there is an explicit family\nof AEL codes of rate $R$, distance $1-R -\\varepsilon$ that is $(1-R-\\epsilon,\nO_\\varepsilon(1))$ list decodable in time\n$\\widetilde{\\mathcal{O}}_{\\varepsilon}(n)$ with alphabet size\n$\\text{exp}(\\text{poly}(1/\\epsilon))$, and\n  (iii) For every $R \\in (0,1)$ and $\\epsilon > 0$, there is an explicit family\nof AEL codes of rate $R$, distance $1-R-\\varepsilon$ that is $(1-R-\\epsilon,\nO(1/\\epsilon))$ list decodable in time\n$\\widetilde{\\mathcal{O}}_{\\varepsilon}(n)$ with alphabet size\n$\\text{exp}(\\text{exp}(\\text{poly}(1/\\epsilon)))$ using recent near-optimal\nlist size bounds from [JMST25].\n  Our results are obtained by phrasing the decoding task as an agreement CSP\n[RWZ20,DHKNT19] on expander graphs and using the fast approximation algorithm\nfor $q$-ary expanding CSPs from [Jer23], which is based on weak regularity\ndecomposition [JST21,FK96]. Similarly to list decoding $q$-ary Ta-Shma's codes\nin [Jer23], we show that it suffices to enumerate over assignments that are\nconstant in each part (of the constantly many) of the decomposition in order to\nrecover all codewords in the list.", "published": "2025-09-05 16:07:15", "link": "http://arxiv.org/abs/2509.05203v1", "categories": ["cs.DS", "cs.IT", "math.IT"], "primary_category": "cs.DS"}
{"title": "An information metric for comparing and assessing informative interim decisions in sequential clinical trials", "abstract": "Group sequential designs enable interim analyses and potential early stopping\nfor efficacy or futility. While these adaptations improve trial efficiency and\nethical considerations, they also introduce bias into the adapted analyses. We\ndemonstrate how failing to account for informative interim decisions in the\nanalysis can substantially affect posterior estimates of the treatment effect,\noften resulting in overly optimistic credible intervals aligned with the\nstopping decision. Drawing on information theory, we use the Kullback-Leibler\ndivergence to quantify this distortion and highlight its use for post-hoc\nevaluation of informative interim decisions, with a focus on end-of-study\ninference. Unlike pointwise comparisons, this measure provides an integrated\nsummary of this distortion on the whole parameter space. By comparing\nalternative decision boundaries and prior specifications, we illustrate how\nthis measure can improve the understanding of trial results and inform the\nplanning of future adaptive studies. We also introduce an expected version of\nthis metric to support clinicians in choosing decision boundaries. This\nguidance complements traditional strategies based on type-I error rate control\nby offering insights into the distortion introduced to the treatment effect at\neach interim phase. The use of this pre-experimental measure is finally\nillustrated in a group sequential trial for evaluating a treatment for central\nnervous system disorders.", "published": "2025-09-05 08:23:14", "link": "http://arxiv.org/abs/2509.04904v1", "categories": ["stat.ME", "cs.IT", "math.IT", "stat.AP"], "primary_category": "stat.ME"}
{"title": "Rotatable Antenna Aided Mixed Near-Field and Far-Field Communications in the Upper Mid-Band: Interference Analysis and Joint Optimization", "abstract": "In this paper, we propose to leverage rotatable antennas (RAs) for improving\nthe communication performance in mixed near-field and far-field communication\nsystems by exploiting a new spatial degree-of-freedom (DoF) offered by antenna\nrotation to mitigate complex near-field interference and mixed-field\ninterference. Specifically, we investigate a modular RA-enabled mixed-field\ndownlink communication system, where a base station (BS) consisting of multiple\nRA subarrays communicates with multiple near-field users in the presence of\nseveral legacy far-field users. We formulate an optimization problem to\nmaximize the sum-rate of the near-field users by jointly optimizing the power\nallocation and rotation angles of all subarrays at the BS. To gain useful\ninsights into the effect of RAs on mixed-field communications, we first analyze\na special case where all subarrays share the same rotation angle and obtain\nclosed-form expressions for the rotation-aware normalized near-field\ninterference and the rotation-aware normalized mixed-field interference using\nthe Fresnel integrals. We then analytically reveal that array rotation\neffectively suppresses both interference types, thereby significantly enhancing\nmixed-field communication performance. For the general case involving\nsubarray-wise rotation, we propose an efficient double-layer algorithm to\nobtain a high-quality solution, where the inner layer optimizes power\nallocation using the successive convex approximation (SCA) technique, while the\nouter layer determines the rotation angles of all subarrays via particle swarm\noptimization (PSO). Finally, numerical results highlight the significant\nperformance gains achieved by RAs over conventional fixed-antenna systems and\ndemonstrate the effectiveness of our developed joint design compared to\nbenchmark schemes.", "published": "2025-09-05 07:29:50", "link": "http://arxiv.org/abs/2509.04865v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest", "abstract": "The ranking utility function in an ad recommender system, which linearly\ncombines predictions of various business goals, plays a central role in\nbalancing values across the platform, advertisers, and users. Traditional\nmanual tuning, while offering simplicity and interpretability, often yields\nsuboptimal results due to its unprincipled tuning objectives, the vast amount\nof parameter combinations, and its lack of personalization and adaptability to\nseasonality. In this work, we propose a general Deep Reinforcement Learning\nframework for Personalized Utility Tuning (DRL-PUT) to address the challenges\nof multi-objective optimization within ad recommender systems. Our key\ncontributions include: 1) Formulating the problem as a reinforcement learning\ntask: given the state of an ad request, we predict the optimal hyperparameters\nto maximize a pre-defined reward. 2) Developing an approach to directly learn\nan optimal policy model using online serving logs, avoiding the need to\nestimate a value function, which is inherently challenging due to the high\nvariance and unbalanced distribution of immediate rewards. We evaluated DRL-PUT\nthrough an online A/B experiment in Pinterest's ad recommender system. Compared\nto the baseline manual utility tuning approach, DRL-PUT improved the\nclick-through rate by 9.7% and the long click-through rate by 7.7% on the\ntreated segment. We conducted a detailed ablation study on the impact of\ndifferent reward definitions and analyzed the personalization aspect of the\nlearned policy model.", "published": "2025-09-05 17:57:45", "link": "http://arxiv.org/abs/2509.05292v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Beyond Linearity and Time-homogeneity: Relational Hyper Event Models with Time-Varying Non-Linear Effects", "abstract": "Recent technological advances have made it easier to collect large and\ncomplex networks of time-stamped relational events connecting two or more\nentities. Relational hyper-event models (RHEMs) aim to explain the dynamics of\nthese events by modeling the event rate as a function of statistics based on\npast history and external information.\n  However, despite the complexity of the data, most current RHEM approaches\nstill rely on a linearity assumption to model this relationship. In this work,\nwe address this limitation by introducing a more flexible model that allows the\neffects of statistics to vary non-linearly and over time. While time-varying\nand non-linear effects have been used in relational event modeling, we take\nthis further by modeling joint time-varying and non-linear effects using tensor\nproduct smooths.\n  We validate our methodology on both synthetic and empirical data. In\nparticular, we use RHEMs to study how patterns of scientific collaboration and\nimpact evolve over time. Our approach provides deeper insights into the dynamic\nfactors driving relational hyper-events, allowing us to evaluate potential\nnon-monotonic patterns that cannot be identified using linear models.", "published": "2025-09-05 17:55:29", "link": "http://arxiv.org/abs/2509.05289v1", "categories": ["stat.ME", "cs.LG", "stat.AP"], "primary_category": "stat.ME"}
{"title": "Learning to accelerate distributed ADMM using graph neural networks", "abstract": "Distributed optimization is fundamental in large-scale machine learning and\ncontrol applications. Among existing methods, the Alternating Direction Method\nof Multipliers (ADMM) has gained popularity due to its strong convergence\nguarantees and suitability for decentralized computation. However, ADMM often\nsuffers from slow convergence and sensitivity to hyperparameter choices. In\nthis work, we show that distributed ADMM iterations can be naturally\nrepresented within the message-passing framework of graph neural networks\n(GNNs). Building on this connection, we propose to learn adaptive step sizes\nand communication weights by a graph neural network that predicts the\nhyperparameters based on the iterates. By unrolling ADMM for a fixed number of\niterations, we train the network parameters end-to-end to minimize the final\niterates error for a given problem class, while preserving the algorithm's\nconvergence properties. Numerical experiments demonstrate that our learned\nvariant consistently improves convergence speed and solution quality compared\nto standard ADMM. The code is available at\nhttps://github.com/paulhausner/learning-distributed-admm.", "published": "2025-09-05 17:55:22", "link": "http://arxiv.org/abs/2509.05288v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Dual-Branch Convolutional Framework for Spatial and Frequency-Based Image Forgery Detection", "abstract": "With a very rapid increase in deepfakes and digital image forgeries, ensuring\nthe authenticity of images is becoming increasingly challenging. This report\nintroduces a forgery detection framework that combines spatial and\nfrequency-based features for detecting forgeries. We propose a dual branch\nconvolution neural network that operates on features extracted from spatial and\nfrequency domains. Features from both branches are fused and compared within a\nSiamese network, yielding 64 dimensional embeddings for classification. When\nbenchmarked on CASIA 2.0 dataset, our method achieves an accuracy of 77.9%,\noutperforming traditional statistical methods. Despite its relatively weaker\nperformance compared to larger, more complex forgery detection pipelines, our\napproach balances computational complexity and detection reliability, making it\nready for practical deployment. It provides a strong methodology for forensic\nscrutiny of digital images. In a broader sense, it advances the state of the\nart in visual forensics, addressing an urgent requirement in media\nverification, law enforcement and digital content reliability.", "published": "2025-09-05 17:41:57", "link": "http://arxiv.org/abs/2509.05281v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Greener Deep Reinforcement Learning: Analysis of Energy and Carbon Efficiency Across Atari Benchmarks", "abstract": "The growing computational demands of deep reinforcement learning (DRL) have\nraised concerns about the environmental and economic costs of training\nlarge-scale models. While algorithmic efficiency in terms of learning\nperformance has been extensively studied, the energy requirements, greenhouse\ngas emissions, and monetary costs of DRL algorithms remain largely unexplored.\nIn this work, we present a systematic benchmarking study of the energy\nconsumption of seven state-of-the-art DRL algorithms, namely DQN, TRPO, A2C,\nARS, PPO, RecurrentPPO, and QR-DQN, implemented using Stable Baselines. Each\nalgorithm was trained for one million steps each on ten Atari 2600 games, and\npower consumption was measured in real-time to estimate total energy usage,\nCO2-Equivalent emissions, and electricity cost based on the U.S. national\naverage electricity price. Our results reveal substantial variation in energy\nefficiency and training cost across algorithms, with some achieving comparable\nperformance while consuming up to 24% less energy (ARS vs. DQN), emitting\nnearly 68% less CO2, and incurring almost 68% lower monetary cost (QR-DQN vs.\nRecurrentPPO) than less efficient counterparts. We further analyze the\ntrade-offs between learning performance, training time, energy use, and\nfinancial cost, highlighting cases where algorithmic choices can mitigate\nenvironmental and economic impact without sacrificing learning performance.\nThis study provides actionable insights for developing energy-aware and\ncost-efficient DRL practices and establishes a foundation for incorporating\nsustainability considerations into future algorithmic design and evaluation.", "published": "2025-09-05 17:29:51", "link": "http://arxiv.org/abs/2509.05273v1", "categories": ["cs.LG", "cs.PF"], "primary_category": "cs.LG"}
{"title": "On Evaluating the Poisoning Robustness of Federated Learning under Local Differential Privacy", "abstract": "Federated learning (FL) combined with local differential privacy (LDP)\nenables privacy-preserving model training across decentralized data sources.\nHowever, the decentralized data-management paradigm leaves LDPFL vulnerable to\nparticipants with malicious intent. The robustness of LDPFL protocols,\nparticularly against model poisoning attacks (MPA), where adversaries inject\nmalicious updates to disrupt global model convergence, remains insufficiently\nstudied. In this paper, we propose a novel and extensible model poisoning\nattack framework tailored for LDPFL settings. Our approach is driven by the\nobjective of maximizing the global training loss while adhering to local\nprivacy constraints. To counter robust aggregation mechanisms such as\nMulti-Krum and trimmed mean, we develop adaptive attacks that embed carefully\ncrafted constraints into a reverse training process, enabling evasion of these\ndefenses. We evaluate our framework across three representative LDPFL\nprotocols, three benchmark datasets, and two types of deep neural networks.\nAdditionally, we investigate the influence of data heterogeneity and privacy\nbudgets on attack effectiveness. Experimental results demonstrate that our\nadaptive attacks can significantly degrade the performance of the global model,\nrevealing critical vulnerabilities and highlighting the need for more robust\nLDPFL defense strategies against MPA. Our code is available at\nhttps://github.com/ZiJW/LDPFL-Attack", "published": "2025-09-05 17:23:03", "link": "http://arxiv.org/abs/2509.05265v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A Kolmogorov-Arnold Network for Interpretable Cyberattack Detection in AGC Systems", "abstract": "Automatic Generation Control (AGC) is essential for power grid stability but\nremains vulnerable to stealthy cyberattacks, such as False Data Injection\nAttacks (FDIAs), which can disturb the system's stability while evading\ntraditional detection methods. Unlike previous works that relied on blackbox\napproaches, this work proposes Kolmogorov-Arnold Networks (KAN) as an\ninterpretable and accurate method for FDIA detection in AGC systems,\nconsidering the system nonlinearities. KAN models include a method for\nextracting symbolic equations, and are thus able to provide more\ninterpretability than the majority of machine learning models. The proposed KAN\nis trained offline to learn the complex nonlinear relationships between the AGC\nmeasurements under different operating scenarios. After training, symbolic\nformulas that describe the trained model's behavior can be extracted and\nleveraged, greatly enhancing interpretability. Our findings confirm that the\nproposed KAN model achieves FDIA detection rates of up to 95.97% and 95.9% for\nthe initial model and the symbolic formula, respectively, with a low false\nalarm rate, offering a reliable approach to enhancing AGC cybersecurity.", "published": "2025-09-05 17:18:17", "link": "http://arxiv.org/abs/2509.05259v1", "categories": ["cs.LG", "cs.CR", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Deep Learning-Enhanced for Amine Emission Monitoring and Performance Analysis in Industrial Carbon Capture Plants", "abstract": "We present data driven deep learning models for forecasting and monitoring\namine emissions and key performance parameters in amine-based post-combustion\ncarbon capture systems. Using operational data from the CESAR1 solvent campaign\nat Technology Center Mongstad, four DL architectures such as Basic Long\nShort-Term Memory (LSTM), Stacked LSTM, Bi-directional LSTM, and Convolutional\nLSTM were developed to capture time-dependent process behavior. For emission\nprediction, models were designed for 2-amino-2-methyl-1-propanol (AMP) and\nPiperazine emissions measured via FTIR and IMR-MS methods. System performance\nmodels target four critical parameters: CO$_2$ product flow, absorber outlet\ntemperature, depleted flue gas outlet temperature, and RFCC stripper bottom\ntemperature. These models achieved high predictive accuracy exceeding 99% and\neffectively tracked both steady trends and abrupt fluctuations. Additionally,\nwe conducted causal impact analysis to evaluate how operational variables\ninfluence emissions and system performance. Eight input variables were\nsystematically perturbed within $\\pm$20% of nominal values to simulate\ndeviations and assess their impact. This analysis revealed that adjusting\nspecific operational parameters, such as lean solvent temperature and water\nwash conditions, can significantly reduce amine emissions and enhance system\nperformance. This study highlights ML not only as a predictive tool but also as\na decision support system for optimizing carbon capture operations under steady\nstate and dynamic conditions. By enabling real time monitoring, scenario\ntesting, and operational optimization, the developed ML framework offers a\npractical pathway for mitigating environmental impacts. This work represents a\nstep toward intelligent, data-driven control strategies that enhance the\nefficiency, stability, and sustainability of carbon capture and storage\ntechnologies.", "published": "2025-09-05 16:57:54", "link": "http://arxiv.org/abs/2509.05241v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data", "abstract": "This work addresses the key challenges of applying federated learning to\nlarge-scale deep neural networks, particularly the issue of client drift due to\ndata heterogeneity across clients and the high costs of communication,\ncomputation, and memory. We propose FedSub, an efficient subspace algorithm for\nfederated learning on heterogeneous data. Specifically, FedSub utilizes\nsubspace projection to guarantee local updates of each client within\nlow-dimensional subspaces, thereby reducing communication, computation, and\nmemory costs. Additionally, it incorporates low-dimensional dual variables to\nmitigate client drift. We provide convergence analysis that reveals the impact\nof key factors such as step size and subspace projection matrices on\nconvergence. Experimental results demonstrate its efficiency.", "published": "2025-09-05 16:15:22", "link": "http://arxiv.org/abs/2509.05213v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning", "abstract": "Low-rank structure is a common implicit assumption in many modern\nreinforcement learning (RL) algorithms. For instance, reward-free and\ngoal-conditioned RL methods often presume that the successor measure admits a\nlow-rank representation. In this work, we challenge this assumption by first\nremarking that the successor measure itself is not low-rank. Instead, we\ndemonstrate that a low-rank structure naturally emerges in the shifted\nsuccessor measure, which captures the system dynamics after bypassing a few\ninitial transitions. We provide finite-sample performance guarantees for the\nentry-wise estimation of a low-rank approximation of the shifted successor\nmeasure from sampled entries. Our analysis reveals that both the approximation\nand estimation errors are primarily governed by the so-called spectral\nrecoverability of the corresponding matrix. To bound this parameter, we derive\na new class of functional inequalities for Markov chains that we call Type II\nPoincar\\'e inequalities and from which we can quantify the amount of shift\nneeded for effective low-rank approximation and estimation. This analysis shows\nin particular that the required shift depends on decay of the high-order\nsingular values of the shifted successor measure and is hence typically small\nin practice. Additionally, we establish a connection between the necessary\nshift and the local mixing properties of the underlying dynamical system, which\nprovides a natural way of selecting the shift. Finally, we validate our\ntheoretical findings with experiments, and demonstrate that shifting the\nsuccessor measure indeed leads to improved performance in goal-conditioned RL.", "published": "2025-09-05 15:48:20", "link": "http://arxiv.org/abs/2509.05193v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Probabilistic operator learning: generative modeling and uncertainty quantification for foundation models of differential equations", "abstract": "In-context operator networks (ICON) are a class of operator learning methods\nbased on the novel architectures of foundation models. Trained on a diverse set\nof datasets of initial and boundary conditions paired with corresponding\nsolutions to ordinary and partial differential equations (ODEs and PDEs), ICON\nlearns to map example condition-solution pairs of a given differential equation\nto an approximation of its solution operator. Here, we present a probabilistic\nframework that reveals ICON as implicitly performing Bayesian inference, where\nit computes the mean of the posterior predictive distribution over solution\noperators conditioned on the provided context, i.e., example condition-solution\npairs. The formalism of random differential equations provides the\nprobabilistic framework for describing the tasks ICON accomplishes while also\nproviding a basis for understanding other multi-operator learning methods. This\nprobabilistic perspective provides a basis for extending ICON to\n\\emph{generative} settings, where one can sample from the posterior predictive\ndistribution of solution operators. The generative formulation of ICON\n(GenICON) captures the underlying uncertainty in the solution operator, which\nenables principled uncertainty quantification in the solution predictions in\noperator learning.", "published": "2025-09-05 15:35:04", "link": "http://arxiv.org/abs/2509.05186v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "stat.ML"}
{"title": "Room-acoustic simulations as an alternative to measurements for audio-algorithm evaluation", "abstract": "Audio-signal-processing and audio-machine-learning (ASP/AML) algorithms are\nubiquitous in modern technology like smart devices, wearables, and\nentertainment systems. Development of such algorithms and models typically\ninvolves a formal evaluation to demonstrate their effectiveness and progress\nbeyond the state-of-the-art. Ideally, a thorough evaluation should cover many\ndiverse application scenarios and room-acoustic conditions. However, in\npractice, evaluation datasets are often limited in size and diversity because\nthey rely on costly and time-consuming measurements. This paper explores how\nroom-acoustic simulations can be used for evaluating ASP/AML algorithms. To\nthis end, we evaluate three ASP/AML algorithms with room-acoustic measurements\nand data from different simulation engines, and assess the match between the\nevaluation results obtained from measurements and simulations. The presented\ninvestigation compares a numerical wave-based solver with two geometrical\nacoustics simulators. While numerical wave-based simulations yielded similar\nevaluation results as measurements for all three evaluated ASP/AML algorithms,\ngeometrical acoustic simulations could not replicate the measured evaluation\nresults as reliably.", "published": "2025-09-05 15:22:23", "link": "http://arxiv.org/abs/2509.05175v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "KVCompose: Efficient Structured KV Cache Compression with Composite Tokens", "abstract": "Large language models (LLMs) rely on key-value (KV) caches for efficient\nautoregressive decoding; however, cache size grows linearly with context length\nand model depth, becoming a major bottleneck in long-context inference. Prior\nKV cache compression methods either enforce rigid heuristics, disrupt tensor\nlayouts with per-attention-head variability, or require specialized compute\nkernels.\n  We propose a simple, yet effective, KV cache compression framework based on\nattention-guided, layer-adaptive composite tokens. Our method aggregates\nattention scores to estimate token importance, selects head-specific tokens\nindependently, and aligns them into composite tokens that respect the uniform\ncache structure required by existing inference engines. A global allocation\nmechanism further adapts retention budgets across layers, assigning more\ncapacity to layers with informative tokens. This approach achieves significant\nmemory reduction while preserving accuracy, consistently outperforming prior\nstructured and semi-structured methods. Crucially, our approach remains fully\ncompatible with standard inference pipelines, offering a practical and scalable\nsolution for efficient long-context LLM deployment.", "published": "2025-09-05 14:58:24", "link": "http://arxiv.org/abs/2509.05165v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Foundational Models and Federated Learning: Survey, Taxonomy, Challenges and Practical Insights", "abstract": "Federated learning has the potential to unlock siloed data and distributed\nresources by enabling collaborative model training without sharing private\ndata. As more complex foundational models gain widespread use, the need to\nexpand training resources and integrate privately owned data grows as well. In\nthis article, we explore the intersection of federated learning and\nfoundational models, aiming to identify, categorize, and characterize technical\nmethods that integrate the two paradigms. As a unified survey is currently\nunavailable, we present a literature survey structured around a novel taxonomy\nthat follows the development life-cycle stages, along with a technical\ncomparison of available methods. Additionally, we provide practical insights\nand guidelines for implementing and evolving these methods, with a specific\nfocus on the healthcare domain as a case study, where the potential impact of\nfederated learning and foundational models is considered significant. Our\nsurvey covers multiple intersecting topics, including but not limited to\nfederated learning, self-supervised learning, fine-tuning, distillation, and\ntransfer learning. Initially, we retrieved and reviewed a set of over 4,200\narticles. This collection was narrowed to more than 250 thoroughly reviewed\narticles through inclusion criteria, featuring 42 unique methods. The methods\nwere used to construct the taxonomy and enabled their comparison based on\ncomplexity, efficiency, and scalability. We present these results as a\nself-contained overview that not only summarizes the state of the field but\nalso provides insights into the practical aspects of adopting, evolving, and\nintegrating foundational models with federated learning.", "published": "2025-09-05 14:34:19", "link": "http://arxiv.org/abs/2509.05142v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On the Learnability of Distribution Classes with Adaptive Adversaries", "abstract": "We consider the question of learnability of distribution classes in the\npresence of adaptive adversaries -- that is, adversaries capable of\nintercepting the samples requested by a learner and applying manipulations with\nfull knowledge of the samples before passing it on to the learner. This stands\nin contrast to oblivious adversaries, who can only modify the underlying\ndistribution the samples come from but not their i.i.d.\\ nature. We formulate a\ngeneral notion of learnability with respect to adaptive adversaries, taking\ninto account the budget of the adversary. We show that learnability with\nrespect to additive adaptive adversaries is a strictly stronger condition than\nlearnability with respect to additive oblivious adversaries.", "published": "2025-09-05 14:28:18", "link": "http://arxiv.org/abs/2509.05137v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Should We Always Train Models on Fine-Grained Classes?", "abstract": "In classification problems, models must predict a class label based on the\ninput data features. However, class labels are organized hierarchically in many\ndatasets. While a classification task is often defined at a specific level of\nthis hierarchy, training can utilize a finer granularity of labels. Empirical\nevidence suggests that such fine-grained training can enhance performance. In\nthis work, we investigate the generality of this observation and explore its\nunderlying causes using both real and synthetic datasets. We show that training\non fine-grained labels does not universally improve classification accuracy.\nInstead, the effectiveness of this strategy depends critically on the geometric\nstructure of the data and its relations with the label hierarchy. Additionally,\nfactors such as dataset size and model capacity significantly influence whether\nfine-grained labels provide a performance benefit.", "published": "2025-09-05 14:15:46", "link": "http://arxiv.org/abs/2509.05130v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions", "abstract": "We present HyPINO, a multi-physics neural operator designed for zero-shot\ngeneralization across a broad class of parametric PDEs without requiring\ntask-specific fine-tuning. Our approach combines a Swin Transformer-based\nhypernetwork with mixed supervision: (i) labeled data from analytical solutions\ngenerated via the Method of Manufactured Solutions (MMS), and (ii) unlabeled\nsamples optimized using physics-informed objectives. The model maps PDE\nparametrizations to target Physics-Informed Neural Networks (PINNs) and can\nhandle linear elliptic, hyperbolic, and parabolic equations in two dimensions\nwith varying source terms, geometries, and mixed Dirichlet/Neumann boundary\nconditions, including interior boundaries. HyPINO achieves strong zero-shot\naccuracy on seven benchmark problems from PINN literature, outperforming\nU-Nets, Poseidon, and Physics-Informed Neural Operators (PINO). Further, we\nintroduce an iterative refinement procedure that compares the physics of the\ngenerated PINN to the requested PDE and uses the discrepancy to generate a\n\"delta\" PINN. Summing their contributions and repeating this process forms an\nensemble whose combined solution progressively reduces the error on six\nbenchmarks and achieves over 100x gain in average $L_2$ loss in the best case,\nwhile retaining forward-only inference. Additionally, we evaluate the\nfine-tuning behavior of PINNs initialized by HyPINO and show that they converge\nfaster and to lower final error than both randomly initialized and\nReptile-meta-learned PINNs on five benchmarks, performing on par on the\nremaining two. Our results highlight the potential of this scalable approach as\na foundation for extending neural operators toward solving increasingly\ncomplex, nonlinear, and high-dimensional PDE problems with significantly\nimproved accuracy and reduced computational cost.", "published": "2025-09-05 13:59:25", "link": "http://arxiv.org/abs/2509.05117v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Spectral Algorithms in Misspecified Regression: Convergence under Covariate Shift", "abstract": "This paper investigates the convergence properties of spectral algorithms --\na class of regularization methods originating from inverse problems -- under\ncovariate shift. In this setting, the marginal distributions of inputs differ\nbetween source and target domains, while the conditional distribution of\noutputs given inputs remains unchanged. To address this distributional\nmismatch, we incorporate importance weights, defined as the ratio of target to\nsource densities, into the learning framework. This leads to a weighted\nspectral algorithm within a nonparametric regression setting in a reproducing\nkernel Hilbert space (RKHS). More importantly, in contrast to prior work that\nlargely focuses on the well-specified setting, we provide a comprehensive\ntheoretical analysis of the more challenging misspecified case, in which the\ntarget function does not belong to the RKHS. Under the assumption of uniformly\nbounded density ratios, we establish minimax-optimal convergence rates when the\ntarget function lies within the RKHS. For scenarios involving unbounded\nimportance weights, we introduce a novel truncation technique that attains\nnear-optimal convergence rates under mild regularity conditions, and we further\nextend these results to the misspecified regime. By addressing the intertwined\nchallenges of covariate shift and model misspecification, this work extends\nclassical kernel learning theory to more practical scenarios, providing a\nsystematic framework for understanding their interaction.", "published": "2025-09-05 13:42:27", "link": "http://arxiv.org/abs/2509.05106v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Recurrent State Encoders for Efficient Neural Combinatorial Optimization", "abstract": "The primary paradigm in Neural Combinatorial Optimization (NCO) are\nconstruction methods, where a neural network is trained to sequentially add one\nsolution component at a time until a complete solution is constructed. We\nobserve that the typical changes to the state between two steps are small,\nsince usually only the node that gets added to the solution is removed from the\nstate. An efficient model should be able to reuse computation done in prior\nsteps. To that end, we propose to train a recurrent encoder that computes the\nstate embeddings not only based on the state but also the embeddings of the\nstep before. We show that the recurrent encoder can achieve equivalent or\nbetter performance than a non-recurrent encoder even if it consists of\n$3\\times$ fewer layers, thus significantly improving on latency. We demonstrate\nour findings on three different problems: the Traveling Salesman Problem (TSP),\nthe Capacitated Vehicle Routing Problem (CVRP), and the Orienteering Problem\n(OP) and integrate the models into a large neighborhood search algorithm, to\nshowcase the practical relevance of our findings.", "published": "2025-09-05 13:22:42", "link": "http://arxiv.org/abs/2509.05084v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Lightweight DNN for Full-Band Speech Denoising on Mobile Devices: Exploiting Long and Short Temporal Patterns", "abstract": "Speech denoising (SD) is an important task of many, if not all, modern signal\nprocessing chains used in devices and for everyday-life applications. While\nthere are many published and powerful deep neural network (DNN)-based methods\nfor SD, few are optimized for resource-constrained platforms such as mobile\ndevices. Additionally, most DNN-based methods for SD are not focusing on\nfull-band (FB) signals, i.e. having 48 kHz sampling rate, and/or low latency\ncases. In this paper we present a causal, low latency, and lightweight\nDNN-based method for full-band SD, leveraging both short and long temporal\npatterns. The method is based on a modified UNet architecture employing\nlook-back frames, temporal spanning of convolutional kernels, and recurrent\nneural networks for exploiting short and long temporal patterns in the signal\nand estimated denoising mask. The DNN operates on a causal frame-by-frame basis\ntaking as an input the STFT magnitude, utilizes inverted bottlenecks inspired\nby MobileNet, employs causal instance normalization for channel-wise\nnormalization, and achieves a real-time factor below 0.02 when deployed on a\nmodern mobile phone. The proposed method is evaluated using established speech\ndenoising metrics and publicly available datasets, demonstrating its\neffectiveness in achieving an (SI-)SDR value that outperforms existing FB and\nlow latency SD methods.", "published": "2025-09-05 13:18:25", "link": "http://arxiv.org/abs/2509.05079v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "QCA-MolGAN: Quantum Circuit Associative Molecular GAN with Multi-Agent Reinforcement Learning", "abstract": "Navigating the vast chemical space of molecular structures to design novel\ndrug molecules with desired target properties remains a central challenge in\ndrug discovery. Recent advances in generative models offer promising solutions.\nThis work presents a novel quantum circuit Born machine (QCBM)-enabled\nGenerative Adversarial Network (GAN), called QCA-MolGAN, for generating\ndrug-like molecules. The QCBM serves as a learnable prior distribution, which\nis associatively trained to define a latent space aligning with high-level\nfeatures captured by the GANs discriminator. Additionally, we integrate a novel\nmulti-agent reinforcement learning network to guide molecular generation with\ndesired targeted properties, optimising key metrics such as quantitative\nestimate of drug-likeness (QED), octanol-water partition coefficient (LogP) and\nsynthetic accessibility (SA) scores in conjunction with one another.\nExperimental results demonstrate that our approach enhances the property\nalignment of generated molecules with the multi-agent reinforcement learning\nagents effectively balancing chemical properties.", "published": "2025-09-05 12:31:58", "link": "http://arxiv.org/abs/2509.05051v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Dynamical Learning in Deep Asymmetric Recurrent Neural Networks", "abstract": "We show that asymmetric deep recurrent neural networks, enhanced with\nadditional sparse excitatory couplings, give rise to an exponentially large,\ndense accessible manifold of internal representations which can be found by\ndifferent algorithms, including simple iterative dynamics. Building on the\ngeometrical properties of the stable configurations, we propose a distributed\nlearning scheme in which input-output associations emerge naturally from the\nrecurrent dynamics, without any need of gradient evaluation. A critical feature\nenabling the learning process is the stability of the configurations reached at\nconvergence, even after removal of the supervisory output signal. Extensive\nsimulations demonstrate that this approach performs competitively on standard\nAI benchmarks. The model can be generalized in multiple directions, both\ncomputational and biological, potentially contributing to narrowing the gap\nbetween AI and computational neuroscience.", "published": "2025-09-05 12:05:09", "link": "http://arxiv.org/abs/2509.05041v1", "categories": ["cond-mat.dis-nn", "cs.LG", "q-bio.NC"], "primary_category": "cond-mat.dis-nn"}
{"title": "MultiSurv: A Multimodal Deep Survival Framework for Prostrate and Bladder Cancer", "abstract": "Accurate prediction of time-to-event outcomes is a central challenge in\noncology, with significant implications for treatment planning and patient\nmanagement. In this work, we present MultiSurv, a multimodal deep survival\nmodel utilising DeepHit with a projection layer and inter-modality\ncross-attention, which integrates heterogeneous patient data, including\nclinical, MRI, RNA-seq and whole-slide pathology features. The model is\ndesigned to capture complementary prognostic signals across modalities and\nestimate individualised time-to-biochemical recurrence in prostate cancer and\ntime-to-cancer recurrence in bladder cancer. Our approach was evaluated in the\ncontext of the CHIMERA Grand Challenge, across two of the three provided tasks.\nFor Task 1 (prostate cancer bio-chemical recurrence prediction), the proposed\nframework achieved a concordance index (C-index) of 0.843 on 5-folds\ncross-validation and 0.818 on CHIMERA development set, demonstrating robust\ndiscriminatory ability. For Task 3 (bladder cancer recurrence prediction), the\nmodel obtained a C-index of 0.662 on 5-folds cross-validation and 0.457 on\ndevelopment set, highlighting its adaptability and potential for clinical\ntranslation. These results suggest that leveraging multimodal integration with\ndeep survival learning provides a promising pathway toward personalised risk\nstratification in prostate and bladder cancer. Beyond the challenge setting,\nour framework is broadly applicable to survival prediction tasks involving\nheterogeneous biomedical data.", "published": "2025-09-05 11:52:53", "link": "http://arxiv.org/abs/2509.05037v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Depth-Aware Initialization for Stable and Efficient Neural Network Training", "abstract": "In past few years, various initialization schemes have been proposed. These\nschemes are glorot initialization, He initialization, initialization using\northogonal matrix, random walk method for initialization. Some of these methods\nstress on keeping unit variance of activation and gradient propagation through\nthe network layer. Few of these methods are independent of the depth\ninformation while some methods has considered the total network depth for\nbetter initialization. In this paper, comprehensive study has been done where\ndepth information of each layer as well as total network is incorporated for\nbetter initialization scheme. It has also been studied that for deeper networks\ntheoretical assumption of unit variance throughout the network does not perform\nwell. It requires the need to increase the variance of the network from first\nlayer activation to last layer activation. We proposed a novel way to increase\nthe variance of the network in flexible manner, which incorporates the\ninformation of each layer depth. Experiments shows that proposed method\nperforms better than the existing initialization scheme.", "published": "2025-09-05 11:26:20", "link": "http://arxiv.org/abs/2509.05018v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On approximating the $f$-divergence between two Ising models", "abstract": "The $f$-divergence is a fundamental notion that measures the difference\nbetween two distributions. In this paper, we study the problem of approximating\nthe $f$-divergence between two Ising models, which is a generalization of\nrecent work on approximating the TV-distance. Given two Ising models $\\nu$ and\n$\\mu$, which are specified by their interaction matrices and external fields,\nthe problem is to approximate the $f$-divergence $D_f(\\nu\\,\\|\\,\\mu)$ within an\narbitrary relative error $\\mathrm{e}^{\\pm \\varepsilon}$. For\n$\\chi^\\alpha$-divergence with a constant integer $\\alpha$, we establish both\nalgorithmic and hardness results. The algorithm works in a parameter regime\nthat matches the hardness result. Our algorithm can be extended to other\n$f$-divergences such as $\\alpha$-divergence, Kullback-Leibler divergence,\nR\\'enyi divergence, Jensen-Shannon divergence, and squared Hellinger distance.", "published": "2025-09-05 11:25:22", "link": "http://arxiv.org/abs/2509.05016v1", "categories": ["cs.DS", "cs.LG", "math.PR"], "primary_category": "cs.DS"}
{"title": "Directed Evolution of Proteins via Bayesian Optimization in Embedding Space", "abstract": "Directed evolution is an iterative laboratory process of designing proteins\nwith improved function by iteratively synthesizing new protein variants and\nevaluating their desired property with expensive and time-consuming biochemical\nscreening. Machine learning methods can help select informative or promising\nvariants for screening to increase their quality and reduce the amount of\nnecessary screening. In this paper, we present a novel method for\nmachine-learning-assisted directed evolution of proteins which combines\nBayesian optimization with informative representation of protein variants\nextracted from a pre-trained protein language model. We demonstrate that the\nnew representation based on the sequence embeddings significantly improves the\nperformance of Bayesian optimization yielding better results with the same\nnumber of conducted screening in total. At the same time, our method\noutperforms the state-of-the-art machine-learning-assisted directed evolution\nmethods with regression objective.", "published": "2025-09-05 10:47:49", "link": "http://arxiv.org/abs/2509.04998v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "MAIA: An Inpainting-Based Approach for Music Adversarial Attacks", "abstract": "Music adversarial attacks have garnered significant interest in the field of\nMusic Information Retrieval (MIR). In this paper, we present Music Adversarial\nInpainting Attack (MAIA), a novel adversarial attack framework that supports\nboth white-box and black-box attack scenarios. MAIA begins with an importance\nanalysis to identify critical audio segments, which are then targeted for\nmodification. Utilizing generative inpainting models, these segments are\nreconstructed with guidance from the output of the attacked model, ensuring\nsubtle and effective adversarial perturbations. We evaluate MAIA on multiple\nMIR tasks, demonstrating high attack success rates in both white-box and\nblack-box settings while maintaining minimal perceptual distortion.\nAdditionally, subjective listening tests confirm the high audio fidelity of the\nadversarial samples. Our findings highlight vulnerabilities in current MIR\nsystems and emphasize the need for more robust and secure models.", "published": "2025-09-05 10:05:26", "link": "http://arxiv.org/abs/2509.04980v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adapt in the Wild: Test-Time Entropy Minimization with Sharpness and Feature Regularization", "abstract": "Test-time adaptation (TTA) may fail to improve or even harm the model\nperformance when test data have: 1) mixed distribution shifts, 2) small batch\nsizes, 3) online imbalanced label distribution shifts. This is often a key\nobstacle preventing existing TTA methods from being deployed in the real world.\nIn this paper, we investigate the unstable reasons and find that the batch norm\nlayer is a crucial factor hindering TTA stability. Conversely, TTA can perform\nmore stably with batch-agnostic norm layers, i.e., group or layer norm.\nHowever, we observe that TTA with group and layer norms does not always succeed\nand still suffers many failure cases, i.e., the model collapses into trivial\nsolutions by assigning the same class label for all samples. By digging into\nthis, we find that, during the collapse process: 1) the model gradients often\nundergo an initial explosion followed by rapid degradation, suggesting that\ncertain noisy test samples with large gradients may disrupt adaptation; and 2)\nthe model representations tend to exhibit high correlations and classification\nbias. To address this, we first propose a sharpness-aware and reliable entropy\nminimization method, called SAR, for stabilizing TTA from two aspects: 1)\nremove partial noisy samples with large gradients, 2) encourage model weights\nto go to a flat minimum so that the model is robust to the remaining noisy\nsamples. Based on SAR, we further introduce SAR^2 to prevent representation\ncollapse with two regularizers: 1) a redundancy regularizer to reduce\ninter-dimensional correlations among centroid-invariant features; and 2) an\ninequity regularizer to maximize the prediction entropy of a prototype\ncentroid, thereby penalizing biased representations toward any specific class.\nPromising results demonstrate that our methods perform more stably over prior\nmethods and are computationally efficient under the above wild test scenarios.", "published": "2025-09-05 10:03:00", "link": "http://arxiv.org/abs/2509.04977v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks", "abstract": "This paper proposes a topology-aware graph reinforcement learning approach to\naddress the routing policy optimization problem in cloud server environments.\nThe method builds a unified framework for state representation and structural\nevolution by integrating a Structure-Aware State Encoding (SASE) module and a\nPolicy-Adaptive Graph Update (PAGU) mechanism. It aims to tackle the challenges\nof decision instability and insufficient structural awareness under dynamic\ntopologies. The SASE module models node states through multi-layer graph\nconvolution and structural positional embeddings, capturing high-order\ndependencies in the communication topology and enhancing the expressiveness of\nstate representations. The PAGU module adjusts the graph structure based on\npolicy behavior shifts and reward feedback, enabling adaptive structural\nupdates in dynamic environments. Experiments are conducted on the real-world\nGEANT topology dataset, where the model is systematically evaluated against\nseveral representative baselines in terms of throughput, latency control, and\nlink balance. Additional experiments, including hyperparameter sensitivity,\ngraph sparsity perturbation, and node feature dimensionality variation, further\nexplore the impact of structure modeling and graph updates on model stability\nand decision quality. Results show that the proposed method outperforms\nexisting graph reinforcement learning models across multiple performance\nmetrics, achieving efficient and robust routing in dynamic and complex cloud\nnetworks.", "published": "2025-09-05 09:55:28", "link": "http://arxiv.org/abs/2509.04973v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Neuro-Spectral Architectures for Causal Physics-Informed Networks", "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful neural\nframework for solving partial differential equations (PDEs). However, standard\nMLP-based PINNs often fail to converge when dealing with complex initial-value\nproblems, leading to solutions that violate causality and suffer from a\nspectral bias towards low-frequency components. To address these issues, we\nintroduce NeuSA (Neuro-Spectral Architectures), a novel class of PINNs inspired\nby classical spectral methods, designed to solve linear and nonlinear PDEs with\nvariable coefficients. NeuSA learns a projection of the underlying PDE onto a\nspectral basis, leading to a finite-dimensional representation of the dynamics\nwhich is then integrated with an adapted Neural ODE (NODE). This allows us to\novercome spectral bias, by leveraging the high-frequency components enabled by\nthe spectral representation; to enforce causality, by inheriting the causal\nstructure of NODEs, and to start training near the target solution, by means of\nan initialization scheme based on classical methods. We validate NeuSA on\ncanonical benchmarks for linear and nonlinear wave equations, demonstrating\nstrong performance as compared to other architectures, with faster convergence,\nimproved temporal consistency and superior predictive accuracy. Code and\npretrained models will be released.", "published": "2025-09-05 09:43:45", "link": "http://arxiv.org/abs/2509.04966v1", "categories": ["cs.LG", "68T07", "I.2.1"], "primary_category": "cs.LG"}
{"title": "On the Normalization of Confusion Matrices: Methods and Geometric Interpretations", "abstract": "The confusion matrix is a standard tool for evaluating classifiers by\nproviding insights into class-level errors. In heterogeneous settings, its\nvalues are shaped by two main factors: class similarity -- how easily the model\nconfuses two classes -- and distribution bias, arising from skewed\ndistributions in the training and test sets. However, confusion matrix values\nreflect a mix of both factors, making it difficult to disentangle their\nindividual contributions. To address this, we introduce bistochastic\nnormalization using Iterative Proportional Fitting, a generalization of row and\ncolumn normalization. Unlike standard normalizations, this method recovers the\nunderlying structure of class similarity. By disentangling error sources, it\nenables more accurate diagnosis of model behavior and supports more targeted\nimprovements. We also show a correspondence between confusion matrix\nnormalizations and the model's internal class representations. Both standard\nand bistochastic normalizations can be interpreted geometrically in this space,\noffering a deeper understanding of what normalization reveals about a\nclassifier.", "published": "2025-09-05 09:36:51", "link": "http://arxiv.org/abs/2509.04959v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Detecting Blinks in Healthy and Parkinson's EEG: A Deep Learning Perspective", "abstract": "Blinks in electroencephalography (EEG) are often treated as unwanted\nartifacts. However, recent studies have demonstrated that blink rate and its\nvariability are important physiological markers to monitor cognitive load,\nattention, and potential neurological disorders. This paper addresses the\ncritical task of accurate blink detection by evaluating various deep learning\nmodels for segmenting EEG signals into involuntary blinks and non-blinks. We\npresent a pipeline for blink detection using 1, 3, or 5 frontal EEG electrodes.\nThe problem is formulated as a sequence-to-sequence task and tested on various\ndeep learning architectures including standard recurrent neural networks,\nconvolutional neural networks (both standard and depth-wise), temporal\nconvolutional networks (TCN), transformer-based models, and hybrid\narchitectures. The models were trained on raw EEG signals with minimal\npre-processing. Training and testing was carried out on a public dataset of 31\nsubjects collected at UCSD. This dataset consisted of 15 healthy participants\nand 16 patients with Parkinson's disease allowing us to verify the model's\nrobustness to tremor. Out of all models, CNN-RNN hybrid model consistently\noutperformed other models and achieved the best blink detection accuracy of\n93.8%, 95.4% and 95.8% with 1, 3, and 5 channels in the healthy cohort and\ncorrespondingly 73.8%, 75.4% and 75.8% in patients with PD. The paper compares\nneural networks for the task of segmenting EEG recordings to involuntary blinks\nand no blinks allowing for computing blink rate and other statistics.", "published": "2025-09-05 09:17:55", "link": "http://arxiv.org/abs/2509.04951v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Ontology-Aligned Embeddings for Data-Driven Labour Market Analytics", "abstract": "The limited ability to reason across occupational data from different sources\nis a long-standing bottleneck for data-driven labour market analytics. Previous\nresearch has relied on hand-crafted ontologies that allow such reasoning but\nare computationally expensive and require careful maintenance by human experts.\nThe rise of language processing machine learning models offers a scalable\nalternative by learning shared semantic spaces that bridge diverse occupational\nvocabularies without extensive human curation. We present an embedding-based\nalignment process that links any free-form German job title to two established\nontologies - the German Klassifikation der Berufe and the International\nStandard Classification of Education. Using publicly available data from the\nGerman Federal Employment Agency, we construct a dataset to fine-tune a\nSentence-BERT model to learn the structure imposed by the ontologies. The\nenriched pairs (job title, embedding) define a similarity graph structure that\nwe can use for efficient approximate nearest-neighbour search, allowing us to\nframe the classification process as a semantic search problem. This allows for\ngreater flexibility, e.g., adding more classes. We discuss design decisions,\nopen challenges, and outline ongoing work on extending the graph with other\nontologies and multilingual titles.", "published": "2025-09-05 09:08:19", "link": "http://arxiv.org/abs/2509.04942v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A transformer-BiGRU-based framework with data augmentation and confident learning for network intrusion detection", "abstract": "In today's fast-paced digital communication, the surge in network traffic\ndata and frequency demands robust and precise network intrusion solutions.\nConventional machine learning methods struggle to grapple with complex patterns\nwithin the vast network intrusion datasets, which suffer from data scarcity and\nclass imbalance. As a result, we have integrated machine learning and deep\nlearning techniques within the network intrusion detection system to bridge\nthis gap. This study has developed TrailGate, a novel framework that combines\nmachine learning and deep learning techniques. By integrating Transformer and\nBidirectional Gated Recurrent Unit (BiGRU) architectures with advanced feature\nselection strategies and supplemented by data augmentation techniques,\nTrailGate can identifies common attack types and excels at detecting and\nmitigating emerging threats. This algorithmic fusion excels at detecting common\nand well-understood attack types and has the unique ability to swiftly identify\nand neutralize emerging threats that stem from existing paradigms.", "published": "2025-09-05 08:42:20", "link": "http://arxiv.org/abs/2509.04925v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Scaling Law for Large-Scale Pre-Training Using Chaotic Time Series and Predictability in Financial Time Series", "abstract": "Time series forecasting plays a critical role in decision-making processes\nacross diverse fields including meteorology, traffic, electricity, economics,\nfinance, and so on. Especially, predicting returns on financial instruments is\na challenging problem. Some researchers have proposed time series foundation\nmodels applicable to various forecasting tasks. Simultaneously, based on the\nrecognition that real-world time series exhibit chaotic properties, methods\nhave been developed to artificially generate synthetic chaotic time series,\nconstruct diverse datasets and train models. In this study, we propose a\nmethodology for modeling financial time series by generating artificial chaotic\ntime series and applying resampling techniques to simulate financial time\nseries data, which we then use as training samples. Increasing the resampling\ninterval to extend predictive horizons, we conducted large-scale pre-training\nusing 10 billion training samples for each case. We subsequently created test\ndatasets for multiple timeframes using actual Bitcoin trade data and performed\nzero-shot prediction without re-training the pre-trained model. The results of\nevaluating the profitability of a simple trading strategy based on these\npredictions demonstrated significant performance improvements over\nautocorrelation models. During the large-scale pre-training process, we\nobserved a scaling law-like phenomenon that we can achieve predictive\nperformance at a certain level with extended predictive horizons for chaotic\ntime series by increasing the number of training samples exponentially. If this\nscaling law proves robust and holds true across various chaotic models, it\nsuggests the potential to predict near-future events by investing substantial\ncomputational resources. Future research should focus on further large-scale\ntraining and verifying the applicability of this scaling law to diverse chaotic\nmodels.", "published": "2025-09-05 08:40:13", "link": "http://arxiv.org/abs/2509.04921v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Optimal Variance and Covariance Estimation under Differential Privacy in the Add-Remove Model and Beyond", "abstract": "In this paper, we study the problem of estimating the variance and covariance\nof datasets under differential privacy in the add-remove model. While\nestimation in the swap model has been extensively studied in the literature,\nthe add-remove model remains less explored and more challenging, as the dataset\nsize must also be kept private. To address this issue, we develop efficient\nmechanisms for variance and covariance estimation based on the \\emph{B\\'{e}zier\nmechanism}, a novel moment-release framework that leverages Bernstein bases. We\nprove that our proposed mechanisms are minimax optimal in the high-privacy\nregime by establishing new minimax lower bounds. Moreover, beyond worst-case\nscenarios, we analyze instance-wise utility and show that the B\\'{e}zier-based\nestimator consistently achieves better utility compared to alternative\nmechanisms. Finally, we demonstrate the effectiveness of the B\\'{e}zier\nmechanism beyond variance and covariance estimation, showcasing its\napplicability to other statistical tasks.", "published": "2025-09-05 08:37:30", "link": "http://arxiv.org/abs/2509.04919v1", "categories": ["stat.ML", "cs.DS", "cs.LG"], "primary_category": "stat.ML"}
{"title": "RobQFL: Robust Quantum Federated Learning in Adversarial Environment", "abstract": "Quantum Federated Learning (QFL) merges privacy-preserving federation with\nquantum computing gains, yet its resilience to adversarial noise is unknown. We\nfirst show that QFL is as fragile as centralized quantum learning. We propose\nRobust Quantum Federated Learning (RobQFL), embedding adversarial training\ndirectly into the federated loop. RobQFL exposes tunable axes: client coverage\n$\\gamma$ (0-100\\%), perturbation scheduling (fixed-$\\varepsilon$ vs\n$\\varepsilon$-mixes), and optimization (fine-tune vs scratch), and distils the\nresulting $\\gamma \\times \\varepsilon$ surface into two metrics:\nAccuracy-Robustness Area and Robustness Volume. On 15-client simulations with\nMNIST and Fashion-MNIST, IID and Non-IID conditions, training only 20-50\\%\nclients adversarially boosts $\\varepsilon \\leq 0.1$ accuracy $\\sim$15 pp at $<\n2$ pp clean-accuracy cost; fine-tuning adds 3-5 pp. With $\\geq$75\\% coverage, a\nmoderate $\\varepsilon$-mix is optimal, while high-$\\varepsilon$ schedules help\nonly at 100\\% coverage. Label-sorted non-IID splits halve robustness,\nunderscoring data heterogeneity as a dominant risk.", "published": "2025-09-05 08:28:10", "link": "http://arxiv.org/abs/2509.04914v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Revolution or Hype? Seeking the Limits of Large Models in Hardware Design", "abstract": "Recent breakthroughs in Large Language Models (LLMs) and Large Circuit Models\n(LCMs) have sparked excitement across the electronic design automation (EDA)\ncommunity, promising a revolution in circuit design and optimization. Yet, this\nexcitement is met with significant skepticism: Are these AI models a genuine\nrevolution in circuit design, or a temporary wave of inflated expectations?\nThis paper serves as a foundational text for the corresponding ICCAD 2025\npanel, bringing together perspectives from leading experts in academia and\nindustry. It critically examines the practical capabilities, fundamental\nlimitations, and future prospects of large AI models in hardware design. The\npaper synthesizes the core arguments surrounding reliability, scalability, and\ninterpretability, framing the debate on whether these models can meaningfully\noutperform or complement traditional EDA methods. The result is an\nauthoritative overview offering fresh insights into one of today's most\ncontentious and impactful technology trends.", "published": "2025-09-05 08:23:16", "link": "http://arxiv.org/abs/2509.04905v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning and composing of classical music using restricted Boltzmann machines", "abstract": "Recently, software has been developed that uses machine learning to mimic the\nstyle of a particular composer, such as J. S. Bach. However, since such\nsoftware often adopts machine learning models with complex structures, it is\ndifficult to analyze how the software understands the characteristics of the\ncomposer's music. In this study, we adopted J. S. Bach's music for training of\na restricted Boltzmann machine (RBM). Since the structure of RBMs is simple, it\nallows us to investigate the internal states after learning. We found that the\nlearned RBM is able to compose music.", "published": "2025-09-05 08:18:14", "link": "http://arxiv.org/abs/2509.04899v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Filtering with Randomised Observations: Sequential Learning of Relevant Subspace Properties and Accuracy Analysis", "abstract": "State estimation that combines observational data with mathematical models is\ncentral to many applications and is commonly addressed through filtering\nmethods, such as ensemble Kalman filters. In this article, we examine the\nsignal-tracking performance of a continuous ensemble Kalman filtering under\nfixed, randomised, and adaptively varying partial observations. Rigorous bounds\nare established for the expected signal-tracking error relative to the\nrandomness of the observation operator. In addition, we propose a sequential\nlearning scheme that adaptively determines the dimension of a state subspace\nsufficient to ensure bounded filtering error, by balancing observation\ncomplexity with estimation accuracy. Beyond error control, the adaptive scheme\nprovides a systematic approach to identifying the appropriate size of the\nfilter-relevant subspace of the underlying dynamics.", "published": "2025-09-05 07:30:01", "link": "http://arxiv.org/abs/2509.04867v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math.ST", "stat.TH", "93E11, 60G35, 65C35, 62L05, 60H10, 86A10", "G.1.7; I.2.6; J.2; G.3"], "primary_category": "math.NA"}
{"title": "Any-Step Density Ratio Estimation via Interval-Annealed Secant Alignment", "abstract": "Estimating density ratios is a fundamental problem in machine learning, but\nexisting methods often trade off accuracy for efficiency. We propose\n\\textit{Interval-annealed Secant Alignment Density Ratio Estimation (ISA-DRE)},\na framework that enables accurate, any-step estimation without numerical\nintegration.\n  Instead of modeling infinitesimal tangents as in prior methods, ISA-DRE\nlearns a global secant function, defined as the expectation of all tangents\nover an interval, with provably lower variance, making it more suitable for\nneural approximation. This is made possible by the \\emph{Secant Alignment\nIdentity}, a self-consistency condition that formally connects the secant with\nits underlying tangent representations.\n  To mitigate instability during early training, we introduce \\emph{Contraction\nInterval Annealing}, a curriculum strategy that gradually expands the alignment\ninterval during training. This process induces a contraction mapping, which\nimproves convergence and training stability.\n  Empirically, ISA-DRE achieves competitive accuracy with significantly fewer\nfunction evaluations compared to prior methods, resulting in much faster\ninference and making it well suited for real-time and interactive applications.", "published": "2025-09-05 07:06:56", "link": "http://arxiv.org/abs/2509.04852v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "An Arbitration Control for an Ensemble of Diversified DQN variants in Continual Reinforcement Learning", "abstract": "Deep reinforcement learning (RL) models, despite their efficiency in learning\nan optimal policy in static environments, easily loses previously learned\nknowledge (i.e., catastrophic forgetting). It leads RL models to poor\nperformance in continual reinforcement learning (CRL) scenarios. To address\nthis, we present an arbitration control mechanism over an ensemble of RL\nagents. It is motivated by and closely aligned with how humans make decisions\nin a CRL context using an arbitration control of multiple RL agents in parallel\nas observed in the prefrontal cortex. We integrated two key ideas into our\nmodel: (1) an ensemble of RLs (i.e., DQN variants) explicitly trained to have\ndiverse value functions and (2) an arbitration control that prioritizes agents\nwith higher reliability (i.e., less error) in recent trials. We propose a\nframework for CRL, an Arbitration Control for an Ensemble of Diversified DQN\nvariants (ACED-DQN). We demonstrate significant performance improvements in\nboth static and continual environments, supported by empirical evidence showing\nthe effectiveness of arbitration control over diversified DQNs during training.\nIn this work, we introduced a framework that enables RL agents to continuously\nlearn, with inspiration from the human brain.", "published": "2025-09-05 05:28:52", "link": "http://arxiv.org/abs/2509.04815v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Real-Time Performance Benchmarking of TinyML Models in Embedded Systems (PICO: Performance of Inference, CPU, and Operations)", "abstract": "This paper presents PICO-TINYML-BENCHMARK, a modular and platform-agnostic\nframework for benchmarking the real-time performance of TinyML models on\nresource-constrained embedded systems. Evaluating key metrics such as inference\nlatency, CPU utilization, memory efficiency, and prediction stability, the\nframework provides insights into computational trade-offs and platform-specific\noptimizations. We benchmark three representative TinyML models -- Gesture\nClassification, Keyword Spotting, and MobileNet V2 -- on two widely adopted\nplatforms, BeagleBone AI64 and Raspberry Pi 4, using real-world datasets.\nResults reveal critical trade-offs: the BeagleBone AI64 demonstrates consistent\ninference latency for AI-specific tasks, while the Raspberry Pi 4 excels in\nresource efficiency and cost-effectiveness. These findings offer actionable\nguidance for optimizing TinyML deployments, bridging the gap between\ntheoretical advancements and practical applications in embedded systems.", "published": "2025-09-05 00:30:39", "link": "http://arxiv.org/abs/2509.04721v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Natural Spectral Fusion: p-Exponent Cyclic Scheduling and Early Decision-Boundary Alignment in First-Order Optimization", "abstract": "Spectral behaviors have been widely discussed in machine learning, yet the\noptimizer's own spectral bias remains unclear. We argue that first-order\noptimizers exhibit an intrinsic frequency preference that significantly\nreshapes the optimization path. To address this, we propose Natural Spectral\nFusion (NSF): reframing training as controllable spectral coverage and\ninformation fusion rather than merely scaling step sizes. NSF has two core\nprinciples: treating the optimizer as a spectral controller that dynamically\nbalances low- and high-frequency information; and periodically reweighting\nfrequency bands at negligible cost, without modifying the model, data, or\ntraining pipeline. We realize NSF via a p-exponent extension of the\nsecond-moment term, enabling both positive and negative exponents, and\nimplement it through cyclic scheduling. Theory and experiments show that\nadaptive methods emphasize low frequencies, SGD is near-neutral, and negative\nexponents amplify high-frequency information. Cyclic scheduling broadens\nspectral coverage, improves cross-band fusion, and induces early\ndecision-boundary alignment, where accuracy improves even while loss remains\nhigh. Across multiple benchmarks, with identical learning-rate strategies and\nfixed hyperparameters, p-exponent cyclic scheduling consistently reduces test\nerror and demonstrates distinct convergence behavior; on some tasks, it matches\nbaseline accuracy with only one-quarter of the training cost. Overall, NSF\nreveals the optimizer's role as an active spectral controller and provides a\nunified, controllable, and efficient framework for first-order optimization.", "published": "2025-09-05 00:00:00", "link": "http://arxiv.org/abs/2509.04713v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Collective decision-making dynamics in hypernetworks", "abstract": "This work describes a collective decision-making dynamical process in a\nmultiagent system under the assumption of cooperative higher-order interactions\nwithin the community, modeled as a hypernetwork. The nonlinear interconnected\nsystem is characterized by saturated nonlinearities that describe how agents\ntransmit their opinion state to their neighbors in the hypernetwork, and by a\nbifurcation parameter representing the community's social effort. We show that\nthe presence of higher-order interactions leads to the unfolding of a pitchfork\nbifurcation, introducing an interval for the social effort parameter in which\nthe system exhibits bistability. With equilibrium points representing\ncollective decisions, this implies that, depending on the initial conditions,\nthe community will either remain in a deadlock state (with the origin as the\nequilibrium point) or reach a nontrivial decision. A numerical example is given\nto illustrate the results.", "published": "2025-09-05 15:30:36", "link": "http://arxiv.org/abs/2509.05182v1", "categories": ["math.OC", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "New Constructions of Cubature Formulas on Wiener Space", "abstract": "Building on techniques developed by Lyons and Victoir, we present the first\nexplicit construction of a degree-7 cubature formula for Wiener space over\n$\\mathbb{R}^3$. We then examine and compare two approaches for computing\ncubature approximations: one based on the stochastic Taylor expansion and the\nother on the Log-ODE method. Our numerical experiments illustrate how the\ncubature degree influences the order of convergence and demonstrate the utility\nof cubature methods for weak approximations of stochastic differential\nequations (SDEs). These results were originally part of a Master's thesis and\nare provided here as context and a reference point for subsequent work. A more\ngeneral construction in arbitrary dimensions has since been obtained by\nFerrucci, Herschell, Litterer and Lyons arXiv:2411.13707 using different\ntechniques.", "published": "2025-09-05 16:50:34", "link": "http://arxiv.org/abs/2509.05236v1", "categories": ["math.NA", "cs.NA", "math.PR"], "primary_category": "math.NA"}
{"title": "Two Precision-controlled Numerical Algorithms for the CDF of Doubly Non-central Beta Distribution Based on the Segmentation of the Infinite Double Series Matrix", "abstract": "The cumulative distribution function (CDF) of the doubly non-central beta\ndistribution can be expressed as an infinite double series. By truncating the\nsum of this series, one can obtain an approximate value of the CDF. Although\nnumerous methods exist for calculating the non-central beta distribution, which\nallow for the control of the truncation range and estimation of the\ncomputational error, no such methods have been developed for the doubly\nnon-central beta distribution. In this paper, we propose two new numerical\ncomputation methods based on the segmentation of the infinite double series,\ntermed DIV1 and DIV2. Both methods enable automated calculations once the error\ncontrol parameters are set; there is no need to predetermine the truncation\nrange, and their computational times are comparable. Following detailed\nderivations, we have established the upper bounds of the errors for both\nmethods, thus ensuring the determinability of the precision.", "published": "2025-09-05 12:14:43", "link": "http://arxiv.org/abs/2509.05045v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical approximations to statistical conservation laws for scalar hyperbolic equations", "abstract": "Motivated by the statistical description of turbulence, we study statistical\nconservation laws in the form of kinetic-type PDEs for joint probability\ndensity functions (PDFs) and cumulative distribution functions (CDFs)\nassociated with solutions of scalar balance laws. Starting from viscous balance\nlaws, the resulting PDF/CDF equations involve unclosed conditional averages\narising in the viscous terms. We show that these terms exhibit a dissipative\nanomaly: they remain non-negligible in the vanishing viscosity limit and are\nessential to preserve the nonnegativity of evolving PDFs. To approximate these\nPDF/CDF equations in a unified framework, we propose a novel sampling-based\nestimator for the unclosed terms, constructed from numerical or exact\nrealizations of the underlying balance-law solutions. In certain cases, a\npriori error bounds can be derived, demonstrating that the deviation between\nthe true and approximate CDFs is controlled by the estimation error of the\nunclosed terms. Numerical experiments with analytically solvable test problems\nconfirm that the sampling-based approximation converges satisfactorily with the\nnumber of samples.", "published": "2025-09-05 12:00:33", "link": "http://arxiv.org/abs/2509.05039v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "35L65, 35R60, 35Q35"], "primary_category": "math.NA"}
{"title": "Synthetic Acceleration Preconditioners for Parametric Radiative Transfer Equations based on Trajectory-Aware Reduced Order Models", "abstract": "The parametric radiative transfer equation (RTE) arises in multi-query\napplications, such as design optimization, inverse problems, and uncertainty\nquantification, which require solving the RTE multiple times for various\nparameters. Classical synthetic acceleration (SA) preconditioners are designed\nbased on low-order approximations of a kinetic correction equation, e.g., its\ndiffusion limit in diffusion synthetic acceleration (DSA). Despite their\nwidespread success, these methods rely on empirical physical assumptions and do\nnot leverage low-rank structures across parameters of the parametric problem.\n  To address these limitations, our previous work introduced a reduced-order\nmodel (ROM) enhanced preconditioner called ROMSAD, which exploits low-rank\nstructures across parameters and the original kinetic description of the\ncorrection equation. While ROMSAD improves overall efficiency compared with\nDSA, its efficiency reduces after the first iteration, because the construction\nof the underlying ROM ignores the preconditioner-dependence of the residual\ntrajectory, leading to a mismatch between the offline and online residual\ntrajectories.\n  To overcome this issue, we introduce a trajectory-aware framework that\niteratively constructs ROMs to eliminate the mismatch between offline and\nonline residual trajectories. Numerical tests demonstrate superior efficiency\nover DSA, and substantial gains in both efficiency and robustness over ROMSAD.\nFor a parametric lattice problem, trajectory-aware ROM preconditioners achieve\nrapid convergence within only $2$-$3$ iterations online.", "published": "2025-09-05 10:50:41", "link": "http://arxiv.org/abs/2509.05001v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Spectral scheme for an energetic Fokker-Planck equation with $\u03ba$-distribution steady states", "abstract": "The concern of the present paper is the design of efficient numerical schemes\nfor a specific Fokker-Planck equation describing the dynamics of energetic\nparticles occurring in thermonuclear fusion plasmas (runaway electrons for\nexample). In the long-time limit, the velocity distribution function of these\nparticles tends towards a thermal non-equilibrium $\\kappa$-distribution\nfunction which is a steady-state of the considered Fokker-Planck equation.\nThese $\\kappa$-distribution functions have the particularity of being only\nalgebraically decaying for large velocities, thus describing very well\nsuprathermal particle populations. Our aim is to present two efficient spectral\nmethods for the simulation of such energetic particle dynamics. The first\nmethod will be based on rational Chebyshev basis functions, rather than on\nHermite basis sets, which are the basis of choice for Maxwellian steady states.\nThe second method is based on a different polynomial basis set, constructed via\nthe Gram-Schmidt orthogonalisation process. These two new spectral schemes,\nspecifically adapted to the here considered physical context, shall permit to\ncope with the long-time asymptotics without significant numerical costs.", "published": "2025-09-05 08:24:51", "link": "http://arxiv.org/abs/2509.04911v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "Solving Inverse Acoustic Obstacle Scattering Problem with Phaseless Far-Field Measurement Using Deep Neural Network Surrogates", "abstract": "In this work, we investigate the use of deep neural networks (DNNs) as\nsurrogates for solving the inverse acoustic scattering problem of recovering a\nsound-soft obstacle from phaseless far-field measurements. We approximate the\nforward maps from the obstacle to the far-field data using DNNs, and for\nstar-shaped domains in two and three dimensions, we establish the expression\nrates for fully connected feedforward neural networks with the ReLU activation\nfor approximating the forward maps. The analysis is based on the weak\nformulation of the direct problem, and can handle variable coefficients.\nNumerically we validate the accuracy of the DNN surrogates of the forward maps,\nand demonstrate the use of DNN surrogates in the Bayesian treatment of the\ninverse obstacle scattering problem. Numerical experiments indicate that the\nsurrogates are effective in both two- and three-dimensional cases, and can\nsignificantly speed up the exploration of the posterior distribution of the\nshape parameters using Markov chain Monte Carlo.", "published": "2025-09-05 01:58:43", "link": "http://arxiv.org/abs/2509.04747v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Deep Learning for Conditional Asset Pricing Models", "abstract": "We propose a new pseudo-Siamese Network for Asset Pricing (SNAP) model, based\non deep learning approaches, for conditional asset pricing. Our model allows\nfor the deep alpha, deep beta and deep factor risk premia conditional on high\ndimensional observable information of financial characteristics and\nmacroeconomic states, while storing the long-term dependency of the informative\nfeatures through long short-term memory network. We apply this method to\nmonthly U.S. stock returns from 1970-2019 and find that our pseudo-SNAP model\noutperforms the benchmark approaches in terms of out-of-sample prediction and\nout-of-sample Sharpe ratio. In addition, we also apply our method to calculate\ndeep mispricing errors which we use to construct an arbitrage portfolio K-Means\nclustering. We find that the arbitrage portfolio has significant alphas.", "published": "2025-09-05 05:22:41", "link": "http://arxiv.org/abs/2509.04812v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Painting the market: generative diffusion models for financial limit order book simulation and forecasting", "abstract": "Simulating limit order books (LOBs) has important applications across\nforecasting and backtesting for financial market data. However, deep generative\nmodels struggle in this context due to the high noise and complexity of the\ndata. Previous work uses autoregressive models, although these experience error\naccumulation over longer-time sequences. We introduce a novel approach,\nconverting LOB data into a structured image format, and applying diffusion\nmodels with inpainting to generate future LOB states. This method leverages\nspatio-temporal inductive biases in the order book and enables parallel\ngeneration of long sequences overcoming issues with error accumulation. We also\npublicly contribute to LOB-Bench, the industry benchmark for LOB generative\nmodels, to allow fair comparison between models using Level-2 and Level-3 order\nbook data (with or without message level data respectively). We show that our\nmodel achieves state-of-the-art performance on LOB-Bench, despite using lower\nfidelity data as input. We also show that our method prioritises coherent\nglobal structures over local, high-fidelity details, providing significant\nimprovements over existing methods on certain metrics. Overall, our method lays\na strong foundation for future research into generative diffusion approaches to\nLOB modelling.", "published": "2025-09-05 13:43:12", "link": "http://arxiv.org/abs/2509.05107v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "MM-DREX: Multimodal-Driven Dynamic Routing of LLM Experts for Financial Trading", "abstract": "The inherent non-stationarity of financial markets and the complexity of\nmulti-modal information pose significant challenges to existing quantitative\ntrading models. Traditional methods relying on fixed structures and unimodal\ndata struggle to adapt to market regime shifts, while large language model\n(LLM)-driven solutions - despite their multi-modal comprehension - suffer from\nstatic strategies and homogeneous expert designs, lacking dynamic adjustment\nand fine-grained decision mechanisms. To address these limitations, we propose\nMM-DREX: a Multimodal-driven, Dynamically-Routed EXpert framework based on\nlarge language models. MM-DREX explicitly decouples market state perception\nfrom strategy execution to enable adaptive sequential decision-making in\nnon-stationary environments. Specifically, it (1) introduces a vision-language\nmodel (VLM)-powered dynamic router that jointly analyzes candlestick chart\npatterns and long-term temporal features to allocate real-time expert weights;\n(2) designs four heterogeneous trading experts (trend, reversal, breakout,\npositioning) generating specialized fine-grained sub-strategies; and (3)\nproposes an SFT-RL hybrid training paradigm to synergistically optimize the\nrouter's market classification capability and experts' risk-adjusted\ndecision-making. Extensive experiments on multi-modal datasets spanning stocks,\nfutures, and cryptocurrencies demonstrate that MM-DREX significantly\noutperforms 15 baselines (including state-of-the-art financial LLMs and deep\nreinforcement learning models) across key metrics: total return, Sharpe ratio,\nand maximum drawdown, validating its robustness and generalization.\nAdditionally, an interpretability module traces routing logic and expert\nbehavior in real time, providing an audit trail for strategy transparency.", "published": "2025-09-05 13:19:51", "link": "http://arxiv.org/abs/2509.05080v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "The Subtle Interplay between Square-root Impact, Order Imbalance & Volatility II: An Artificial Market Generator", "abstract": "This work extends and complements our previous theoretical paper on the\nsubtle interplay between impact, order flow and volatility. In the present\npaper, we generate synthetic market data following the specification of that\npaper and show that the approximations made there are actually justified, which\nprovides quantitative support our conclusion that price volatility can be fully\nexplained by the superposition of correlated metaorders which all impact\nprices, on average, as a square-root of executed volume. One of the most\nstriking predictions of our model is the structure of the correlation between\ngeneralized order flow and returns, which is observed empirically and\nreproduced using our synthetic market generator. Furthermore, we were able to\nconstruct proxy metaorders from our simulated order flow that reproduce the\nsquare-root law of market impact, lending further credence to the proposal made\nin Ref. [2] to measure the impact of real metaorders from tape data (i.e.\nanonymized trades), which was long thought to be impossible.", "published": "2025-09-05 12:57:59", "link": "http://arxiv.org/abs/2509.05065v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Dynamics of Liquidity Surfaces in Uniswap v3", "abstract": "This paper presents a comprehensive study on the empirical dynamics of\nUniswap v3 liquidity, which we model as a time-tick surface, $L_t(x)$. Using a\ncombination of functional principal component analysis (FPCA) and dynamic\nfactor methods, we analyze three distinct pools over multiple sample periods.\nOur findings offer three main contributions: a statistical characterization of\nautomated market maker liquidity, an interpretable and portable basis for\ndimension reduction, and a robust analysis of liquidity dynamics using rolling\nwindow metrics. For the 5 bps pools, the leading empirical eigenfunctions\nexplain the majority of cross-tick variation and remain stable, aligning\nclosely with a low-order Legendre polynomial basis. This alignment provides a\nparsimonious and interpretable structure, similar to the dynamic Nelson-Siegel\nmethod for yield curves. The factor coefficients exhibit a time series\nstructure well-captured by AR(1) models with clear GARCH-type\nheteroskedasticity and heavy-tailed innovations.", "published": "2025-09-05 11:23:21", "link": "http://arxiv.org/abs/2509.05013v1", "categories": ["q-fin.TR", "stat.AP", "91G80, 62M10, 42C10, 60G10"], "primary_category": "q-fin.TR"}
{"title": "MEAN-RIR: Multi-Modal Environment-Aware Network for Robust Room Impulse Response Estimation", "abstract": "This paper presents a Multi-Modal Environment-Aware Network (MEAN-RIR), which\nuses an encoder-decoder framework to predict room impulse response (RIR) based\non multi-level environmental information from audio, visual, and textual\nsources. Specifically, reverberant speech capturing room acoustic properties\nserves as the primary input, which is combined with panoramic images and text\ndescriptions as supplementary inputs. Each input is processed by its respective\nencoder, and the outputs are fed into cross-attention modules to enable\neffective interaction between different modalities. The MEAN-RIR decoder\ngenerates two distinct components: the first component captures the direct\nsound and early reflections, while the second produces masks that modulate\nlearnable filtered noise to synthesize the late reverberation. These two\ncomponents are mixed to reconstruct the final RIR. The results show that\nMEAN-RIR significantly improves RIR estimation, with notable gains in acoustic\nparameters.", "published": "2025-09-05 16:07:59", "link": "http://arxiv.org/abs/2509.05205v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Training a Perceptual Model for Evaluating Auditory Similarity in Music Adversarial Attack", "abstract": "Music Information Retrieval (MIR) systems are highly vulnerable to\nadversarial attacks that are often imperceptible to humans, primarily due to a\nmisalignment between model feature spaces and human auditory perception.\nExisting defenses and perceptual metrics frequently fail to adequately capture\nthese auditory nuances, a limitation supported by our initial listening tests\nshowing low correlation between common metrics and human judgments. To bridge\nthis gap, we introduce Perceptually-Aligned MERT Transformer (PAMT), a novel\nframework for learning robust, perceptually-aligned music representations. Our\ncore innovation lies in the psychoacoustically-conditioned sequential\ncontrastive transformer, a lightweight projection head built atop a frozen MERT\nencoder. PAMT achieves a Spearman correlation coefficient of 0.65 with\nsubjective scores, outperforming existing perceptual metrics. Our approach also\nachieves an average of 9.15\\% improvement in robust accuracy on challenging MIR\ntasks, including Cover Song Identification and Music Genre Classification,\nunder diverse perceptual adversarial attacks. This work pioneers\narchitecturally-integrated psychoacoustic conditioning, yielding\nrepresentations significantly more aligned with human perception and robust\nagainst music adversarial attacks.", "published": "2025-09-05 10:23:44", "link": "http://arxiv.org/abs/2509.04985v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quantum Fourier Transform Based Denoising: Unitary Filtering for Enhanced Speech Clarity", "abstract": "This paper introduces a quantum-inspired denoising framework that integrates\nthe Quantum Fourier Transform (QFT) into classical audio enhancement pipelines.\nUnlike conventional Fast Fourier Transform (FFT) based methods, QFT provides a\nunitary transformation with global phase coherence and energy preservation,\nenabling improved discrimination between speech and noise. The proposed\napproach replaces FFT in Wiener and spectral subtraction filters with a QFT\noperator, ensuring consistent hyperparameter settings for fair comparison.\nExperiments on clean speech, synthetic tones, and noisy mixtures across diverse\nsignal to noise ratio (SNR) conditions, demonstrate statistically significant\ngains in SNR, with up to 15 dB improvement and reduced artifact generation.\nResults confirm that QFT based denoising offers robustness under low SNR and\nnonstationary noise scenarios without additional computational overhead,\nhighlighting its potential as a scalable pathway toward quantum-enhanced speech\nprocessing.", "published": "2025-09-05 07:06:14", "link": "http://arxiv.org/abs/2509.04851v1", "categories": ["cs.SD", "cs.ET", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Layer-wise Analysis for Quality of Multilingual Synthesized Speech", "abstract": "While supervised quality predictors for synthesized speech have demonstrated\nstrong correlations with human ratings, their requirement for in-domain labeled\ntraining data hinders their generalization ability to new domains. Unsupervised\napproaches based on pretrained self-supervised learning (SSL) based models and\nautomatic speech recognition (ASR) models are a promising alternative; however,\nlittle is known about how these models encode information about speech quality.\nTowards the goal of better understanding how different aspects of speech\nquality are encoded in a multilingual setting, we present a layer-wise analysis\nof multilingual pretrained speech models based on reference modeling. We find\nthat features extracted from early SSL layers show correlations with human\nratings of synthesized speech, and later layers of ASR models can predict\nquality of non-neural systems as well as intelligibility. We also demonstrate\nthe importance of using well-matched reference data.", "published": "2025-09-05 06:01:28", "link": "http://arxiv.org/abs/2509.04830v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Multiclass Acoustic Dataset and Interactive Tool for Analyzing Drone Signatures in Real-World Environments", "abstract": "The rapid proliferation of drones across various industries has introduced\nsignificant challenges related to privacy, security, and noise pollution.\nCurrent drone detection systems, primarily based on visual and radar\ntechnologies, face limitations under certain conditions, highlighting the need\nfor effective acoustic-based detection methods. This paper presents a unique\nand comprehensive dataset of drone acoustic signatures, encompassing 32\ndifferent categories differentiated by brand and model. The dataset includes\nraw audio recordings, spectrogram plots, and Mel-frequency cepstral coefficient\n(MFCC) plots for each drone. Additionally, we introduce an interactive web\napplication that allows users to explore this dataset by selecting specific\ndrone categories, listening to the associated audio, and viewing the\ncorresponding spectrogram and MFCC plots. This tool aims to facilitate research\nin drone detection, classification, and acoustic analysis, supporting both\ntechnological advancements and educational initiatives. The paper details the\ndataset creation process, the design and implementation of the web application,\nand provides experimental results and user feedback. Finally, we discuss\npotential applications and future work to expand and enhance the project.", "published": "2025-09-05 00:04:29", "link": "http://arxiv.org/abs/2509.04715v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ROPE: A Novel Method for Real-Time Phase Estimation of Complex Biological Rhythms", "abstract": "Accurate phase estimation -- the process of assigning phase values between\n$0$ and $2\\pi$ to repetitive or periodic signals -- is a cornerstone in the\nanalysis of oscillatory signals across diverse fields, from neuroscience to\nrobotics, where it is fundamental, e.g., to understanding coordination in\nneural networks, cardiorespiratory coupling, and human-robot interaction.\nHowever, existing methods are often limited to offline processing and/or\nconstrained to one-dimensional signals. In this paper, we introduce ROPE,\nwhich, to the best of our knowledge, is the first phase-estimation algorithm\ncapable of (i) handling signals of arbitrary dimension and (ii) operating in\nreal-time, with minimal error. ROPE identifies repetitions within the signal to\nsegment it into (pseudo-)periods and assigns phase values by performing\nefficient, tractable searches over previous signal segments. We extensively\nvalidate the algorithm on a variety of signal types, including trajectories\nfrom chaotic dynamical systems, human motion-capture data, and\nelectrocardiographic recordings. Our results demonstrate that ROPE is robust\nagainst noise and signal drift, and achieves significantly superior performance\ncompared to state-of-the-art phase estimation methods. This advancement enables\nreal-time analysis of complex biological rhythms, opening new pathways, for\nexample, for early diagnosis of pathological rhythm disruptions and developing\nrhythm-based therapeutic interventions in neurological and cardiovascular\ndisorders.", "published": "2025-09-05 09:39:12", "link": "http://arxiv.org/abs/2509.04962v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Coupled tensor models for probability mass function estimation: Part II, Uniqueness of the model", "abstract": "In this paper, uniqueness properties of a coupled tensor model are studied.\nThis new coupled tensor model is used in a new method called Partial Coupled\nTensor Factorization of 3D marginals or PCTF3D. This method performs estimation\nof probability mass functions by coupling 3D marginals, seen as order-3\ntensors. The core novelty of PCTF3D's approach (detailed in the part I article)\nrelies on the partial coupling which consists on the choice of 3D marginals to\nbe coupled. Tensor methods are ubiquitous in many applications of statistical\nlearning, with their biggest advantage of having strong uniqueness properties.\nIn this paper, the uniqueness properties of PCTF3D's constrained coupled\nlow-rank model is assessed. While probabilistic constraints of the coupled\nmodel are handled properly, it is shown that uniqueness highly depends on the\ncoupling used in PCTF3D. After proposing a Jacobian algorithm providing maximum\nrecoverable rank, different coupling strategies presented in the Part I article\nare examined with respect to their uniqueness properties. Finally, an\nidentifiability bound is given for a so-called Cartesian coupling which permits\nenhancing sufficient bounds of the literature.", "published": "2025-09-05 08:53:25", "link": "http://arxiv.org/abs/2509.04931v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Coupled tensor models for probability mass function estimation: Part I, Principles and algorithms", "abstract": "In this article, a Probability Mass Function (PMF) estimation method which\ntames the curse of dimensionality is proposed. This method, called Partial\nCoupled Tensor Factorization of 3D marginals or PCTF3D, has for principle to\npartially couple order-3 data projections -- seen as order-3 tensors -- to\nobtain a tensor decomposition of the probability mass tensor. The novelty of\nPCTF3D relies on partial coupling which consists in choosing a subset of 3D\nmarginals. The choice of marginals is then formulated with hypergraphs. After\npresenting possible coupling strategies, some numerical experiments and an\napplication of the method are proposed. This article is the first of a two-part\narticle. While this first article focuses on a new algorithmic framework for\nPMF estimation, the second studies uniqueness properties of the model\nintroduced in this article.", "published": "2025-09-05 08:52:31", "link": "http://arxiv.org/abs/2509.04930v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Movable IRS-Aided ISAC Systems: Joint Beamforming and Position Optimization", "abstract": "Driven by intelligent reflecting surface (IRS) and movable antenna (MA)\ntechnologies, movable IRS (MIRS) has been proposed to improve the adaptability\nand performance of conventional IRS, enabling flexible adjustment of the IRS\nreflecting element positions. This paper investigates MIRS-aided integrated\nsensing and communication (ISAC) systems. The objective is to minimize the\npower required for satisfying the quality-of-service (QoS) of sensing and\ncommunication by jointly optimizing the MIRS element positions, IRS reflection\ncoefficients, transmit beamforming, and receive filters. To balance the\nperformance-cost trade-off, we proposed two MIRS schemes: element-wise control\nand array-wise control, where the positions of individual reflecting elements\nand arrays consisting of multiple elements are controllable, respectively. To\naddress the joint beamforming and position optimization, a product Riemannian\nmanifold optimization (PRMO) method is proposed, where the variables are\nupdated over a constructed product Riemannian manifold space (PRMS) in parallel\nvia penalty-based transformation and Riemannian\nBroyden-Fletcher-Goldfarb-Shanno (RBFGS) algorithm. Simulation results\ndemonstrate that the proposed MIRS outperforms conventional IRS in power\nminimization with both element-wise control and array-wise control.\nSpecifically, with different system parameters, the minimum power is achieved\nby the MIRS with the element-wise control scheme, while suboptimal solution and\nhigher computational efficiency are achieved by the MIRS with array-wise\ncontrol scheme.", "published": "2025-09-05 07:40:07", "link": "http://arxiv.org/abs/2509.04873v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Plug-and-Play Latent Diffusion for Electromagnetic Inverse Scattering with Application to Brain Imaging", "abstract": "Electromagnetic (EM) imaging is an important tool for non-invasive sensing\nwith low-cost and portable devices. One emerging application is EM stroke\nimaging, which enables early diagnosis and continuous monitoring of brain\nstrokes. Quantitative imaging is achieved by solving an inverse scattering\nproblem (ISP) that reconstructs permittivity and conductivity maps from\nmeasurements. In general, the reconstruction accuracy is limited by its\ninherent nonlinearity and ill-posedness. Existing methods, including\nlearning-free and learning-based approaches, fail to either incorporate\ncomplicated prior distributions or provide theoretical guarantees, posing\ndifficulties in balancing interpretability, distortion error, and reliability.\nTo overcome these limitations, we propose a posterior sampling method based on\nlatent diffusion for quantitative EM brain imaging, adapted from a generative\nplug-and-play (PnP) posterior sampling framework. Our approach allows to\nflexibly integrate prior knowledge into physics-based inversion without\nrequiring paired measurement-label datasets. We first learn the prior\ndistribution of targets from an unlabeled dataset, and then incorporate the\nlearned prior into posterior sampling. In particular, we train a latent\ndiffusion model on permittivity and conductivity maps to capture their prior\ndistribution. Then, given measurements and the forward model describing EM wave\nphysics, we perform posterior sampling by alternating between two samplers that\nrespectively enforce the likelihood and prior distributions. Finally, reliable\nreconstruction is obtained through minimum mean squared error (MMSE) estimation\nbased on the samples. Experimental results on brain imaging demonstrate that\nour approach achieves state-of-the-art performance in reconstruction accuracy\nand structural similarity while maintaining high measurement fidelity.", "published": "2025-09-05 07:21:31", "link": "http://arxiv.org/abs/2509.04860v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SemSteDiff: Generative Diffusion Model-based Coverless Semantic Steganography Communication", "abstract": "Semantic communication (SemCom), as a novel paradigm for future communication\nsystems, has recently attracted much attention due to its superiority in\ncommunication efficiency. However, similar to traditional communication, it\nalso suffers from eavesdropping threats. Intelligent eavesdroppers could launch\nadvanced semantic analysis techniques to infer secret semantic information.\nTherefore, some researchers have designed Semantic Steganography Communication\n(SemSteCom) scheme to confuse semantic eavesdroppers. However, the\nstate-of-the-art SemSteCom schemes for image transmission rely on the\npre-selected cover image, which limits the universality. To address this issue,\nwe propose a Generative Diffusion Model-based Coverless Semantic Steganography\nCommunication (SemSteDiff) scheme to hide secret images into generated stego\nimages. The semantic related private and public keys enable legitimate receiver\nto decode secret images correctly while the eavesdropper without completely\ntrue key-pairs fail to obtain them. Simulation results demonstrate the\neffectiveness of the plug-and-play design in different Joint Source-Channel\nCoding (JSCC) frameworks. The comparison results under different eavesdroppers'\nthreats show that, when Signal-to-Noise Ratio (SNR) = 0 dB, the peak\nsignal-to-noise ratio (PSNR) of the legitimate receiver is 4.14 dB higher than\nthat of the eavesdropper.", "published": "2025-09-05 04:38:50", "link": "http://arxiv.org/abs/2509.04803v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "KGRAG-SC: Knowledge Graph RAG-Assisted Semantic Communication", "abstract": "The state-of-the-art semantic communication (SC) schemes typically rely on\nend-to-end deep learning frameworks that lack interpretability and struggle\nwith robust semantic selection and reconstruction under noisy conditions. To\naddress this issue, this paper presents KGRAG-SC, a knowledge graph-assisted SC\nframework that leverages retrieval-augmented generation principles. KGRAG-SC\nemploys a multi-dimensional knowledge graph, enabling efficient semantic\nextraction through community-guided entity linking and GraphRAG-assisted\nprocessing. The transmitter constructs minimal connected subgraphs that capture\nessential semantic relationships and transmits only compact entity indices\nrather than full text or semantic triples. An importance-aware adaptive\ntransmission strategy provides unequal error protection based on structural\ncentrality metrics, prioritizing critical semantic elements under adverse\nchannel conditions. At the receiver, large language models perform\nknowledge-driven text reconstruction using the shared knowledge graph as\nstructured context, ensuring robust semantic recovery even with partial\ninformation loss. Experimental results demonstrate that KGRAG-SC achieves\nsuperior semantic fidelity in low Signal-to-Noise Ratio (SNR) conditions while\nsignificantly reducing transmission overhead compared to traditional\ncommunication methods, highlighting the effectiveness of integrating structured\nknowledge representation with generative language models for SC systems.", "published": "2025-09-05 04:33:12", "link": "http://arxiv.org/abs/2509.04801v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SREC: Encrypted Semantic Super-Resolution Enhanced Communication", "abstract": "Semantic communication (SemCom), as a typical paradigm of deep integration\nbetween artificial intelligence (AI) and communication technology,\nsignificantly improves communication efficiency and resource utilization\nefficiency. However, the security issues of SemCom are becoming increasingly\nprominent. Semantic features transmitted in plaintext over physical channels\nare easily intercepted by eavesdroppers. To address this issue, this paper\nproposes Encrypted Semantic Super-Resolution Enhanced Communication (SREC) to\nsecure SemCom. SREC uses the modulo-256 encryption method to encrypt semantic\nfeatures, and employs super-resolution reconstruction method to improve the\nreconstruction quality of images. The simulation results show that in the\nadditive Gaussian white noise (AWGN) channel, when different modulation methods\nare used, SREC can not only stably guarantee security, but also achieve better\ntransmission performance under low signal-to-noise ratio (SNR) conditions.", "published": "2025-09-05 03:54:15", "link": "http://arxiv.org/abs/2509.04787v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Environment-Aware IRS Deployment via Channel Knowledge Map: Joint Sensing-Communications Coverage Optimization", "abstract": "This paper studies the intelligent reflecting surface (IRS) deployment\noptimization problem for IRS-enabled integrated sensing and communications\n(ISAC) systems, in which multiple IRSs are strategically deployed at candidate\nlocations to assist a base station (BS) to enhance the coverage of both sensing\nand communications. We present an environment-aware IRS deployment design via\nexploiting the channel knowledge map (CKM), which provides the channel state\ninformation (CSI) between each candidate IRS location and BS or targeted\nsensing/communication points. Based on the obtained CSI from CKM, we optimize\nthe deployment of IRSs, jointly with the BS's transmit beamforming and IRSs'\nreflective beamforming during operation, with the objective of minimizing the\nsystem cost, while guaranteeing the minimum illumination power requirements at\nsensing areas and the minimum signal-to-noise ratio (SNR) requirements at\ncommunication areas. In particular, we consider two cases when the IRSs'\nreflective beamforming optimization can be implemented dynamically in real time\nand quasi-stationarily over the whole operation period, respectively. For both\ncases, the joint IRS deployment and transmit/reflective beamforming designs are\nformulated as mixed-integer non-convex optimization problems, which are solved\nvia the successive convex approximation (SCA)-based relax-and-bound method.\nSpecifically, we first relax the binary IRS deployment indicators into\ncontinuous variables, then find converged solutions via SCA, and finally round\nrelaxed indicators back to binary values. Numerical results demonstrate the\neffectiveness of our proposed algorithms in reducing the system cost while\nmeeting the sensing and communication requirements.", "published": "2025-09-05 02:55:14", "link": "http://arxiv.org/abs/2509.04768v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models", "abstract": "Positional encoding mechanisms enable Transformers to model sequential\nstructure and long-range dependencies in text. While absolute positional\nencodings struggle with extrapolation to longer sequences due to fixed\npositional representations, and relative approaches like Alibi exhibit\nperformance degradation on extremely long contexts, the widely-used Rotary\nPositional Encoding (RoPE) introduces oscillatory attention patterns that\nhinder stable long-distance dependency modelling. We address these limitations\nthrough a geometric reformulation of positional encoding. Drawing inspiration\nfrom Lorentz transformations in hyperbolic geometry, we propose Hyperbolic\nRotary Positional Encoding (HoPE), which leverages hyperbolic functions to\nimplement Lorentz rotations on token representations. Theoretical analysis\ndemonstrates that RoPE is a special case of our generalized formulation. HoPE\nfundamentally resolves RoPE's slation issues by enforcing monotonic decay of\nattention weights with increasing token distances. Extensive experimental\nresults, including perplexity evaluations under several extended sequence\nbenchmarks, show that HoPE consistently exceeds existing positional encoding\nmethods. These findings underscore HoPE's enhanced capacity for representing\nand generalizing long-range dependencies. Data and code will be available.", "published": "2025-09-05 16:20:48", "link": "http://arxiv.org/abs/2509.05218v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework", "abstract": "Large reasoning models (LRMs) have exhibited strong performance on complex\nreasoning tasks, with further gains achievable through increased computational\nbudgets at inference. However, current test-time scaling methods predominantly\nrely on redundant sampling, ignoring the historical experience utilization,\nthereby limiting computational efficiency. To overcome this limitation, we\npropose Sticker-TTS, a novel test-time scaling framework that coordinates three\ncollaborative LRMs to iteratively explore and refine solutions guided by\nhistorical attempts. At the core of our framework are distilled key\nconditions-termed stickers-which drive the extraction, refinement, and reuse of\ncritical information across multiple rounds of reasoning. To further enhance\nthe efficiency and performance of our framework, we introduce a two-stage\noptimization strategy that combines imitation learning with self-improvement,\nenabling progressive refinement. Extensive evaluations on three challenging\nmathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,\ndemonstrate that Sticker-TTS consistently surpasses strong baselines, including\nself-consistency and advanced reinforcement learning approaches, under\ncomparable inference budgets. These results highlight the effectiveness of\nsticker-guided historical experience utilization. Our code and data are\navailable at https://github.com/RUCAIBox/Sticker-TTS.", "published": "2025-09-05 11:14:11", "link": "http://arxiv.org/abs/2509.05007v2", "categories": ["cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.AI"}
{"title": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models", "abstract": "Explainable Reinforcement Learning (XRL) has emerged as a promising approach\nin improving the transparency of Reinforcement Learning (RL) agents. However,\nthere remains a gap between complex RL policies and domain experts, due to the\nlimited comprehensibility of XRL results and isolated coverage of current XRL\napproaches that leave users uncertain about which tools to employ. To address\nthese challenges, we introduce TalkToAgent, a multi-agent Large Language Models\n(LLM) framework that delivers interactive, natural language explanations for RL\npolicies. The architecture with five specialized LLM agents (Coordinator,\nExplainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically\nmap user queries to relevant XRL tools and clarify an agent's actions in terms\nof either key state variables, expected outcomes, or counterfactual\nexplanations. Moreover, our approach extends previous counterfactual\nexplanations by deriving alternative scenarios from qualitative behavioral\ndescriptions, or even new rule-based policies. We validated TalkToAgent on\nquadruple-tank process control problem, a well-known nonlinear control\nbenchmark. Results demonstrated that TalkToAgent successfully mapped user\nqueries into XRL tasks with high accuracy, and coder-debugger interactions\nminimized failures in counterfactual generation. Furthermore, qualitative\nevaluation confirmed that TalkToAgent effectively interpreted agent's actions\nand contextualized their meaning within the problem domain.", "published": "2025-09-05 05:09:09", "link": "http://arxiv.org/abs/2509.04809v2", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation", "abstract": "Recent research has been increasingly focusing on developing 3D world models\nthat simulate complex real-world scenarios. World models have found broad\napplications across various domains, including embodied AI, autonomous driving,\nentertainment, etc. A more realistic simulation with accurate physics will\neffectively narrow the sim-to-real gap and allow us to gather rich information\nabout the real world conveniently. While traditional manual modeling has\nenabled the creation of virtual 3D scenes, modern approaches have leveraged\nadvanced machine learning algorithms for 3D world generation, with most recent\nadvances focusing on generative methods that can create virtual worlds based on\nuser instructions. This work explores such a research direction by proposing\nLatticeWorld, a simple yet effective 3D world generation framework that\nstreamlines the industrial production pipeline of 3D environments. LatticeWorld\nleverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering\nengine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed\nframework accepts textual descriptions and visual instructions as multimodal\ninputs and creates large-scale 3D interactive worlds with dynamic agents,\nfeaturing competitive multi-agent interaction, high-fidelity physics\nsimulation, and real-time rendering. We conduct comprehensive experiments to\nevaluate LatticeWorld, showing that it achieves superior accuracy in scene\nlayout generation and visual fidelity. Moreover, LatticeWorld achieves over a\n$90\\times$ increase in industrial production efficiency while maintaining high\ncreative quality compared with traditional manual production methods. Our demo\nvideo is available at https://youtu.be/8VWZXpERR18", "published": "2025-09-05 17:22:33", "link": "http://arxiv.org/abs/2509.05263v2", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "AURAD: Anatomy-Pathology Unified Radiology Synthesis with Progressive Representations", "abstract": "Medical image synthesis has become an essential strategy for augmenting\ndatasets and improving model generalization in data-scarce clinical settings.\nHowever, fine-grained and controllable synthesis remains difficult due to\nlimited high-quality annotations and domain shifts across datasets. Existing\nmethods, often designed for natural images or well-defined tumors, struggle to\ngeneralize to chest radiographs, where disease patterns are morphologically\ndiverse and tightly intertwined with anatomical structures. To address these\nchallenges, we propose AURAD, a controllable radiology synthesis framework that\njointly generates high-fidelity chest X-rays and pseudo semantic masks. Unlike\nprior approaches that rely on randomly sampled masks-limiting diversity,\ncontrollability, and clinical relevance-our method learns to generate masks\nthat capture multi-pathology coexistence and anatomical-pathological\nconsistency. It follows a progressive pipeline: pseudo masks are first\ngenerated from clinical prompts conditioned on anatomical structures, and then\nused to guide image synthesis. We also leverage pretrained expert medical\nmodels to filter outputs and ensure clinical plausibility. Beyond visual\nrealism, the synthesized masks also serve as labels for downstream tasks such\nas detection and segmentation, bridging the gap between generative modeling and\nreal-world clinical applications. Extensive experiments and blinded radiologist\nevaluations demonstrate the effectiveness and generalizability of our method\nacross tasks and datasets. In particular, 78% of our synthesized images are\nclassified as authentic by board-certified radiologists, and over 40% of\npredicted segmentation overlays are rated as clinically useful. All code,\npre-trained models, and the synthesized dataset will be released upon\npublication.", "published": "2025-09-05 05:40:55", "link": "http://arxiv.org/abs/2509.04819v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "An information metric for comparing and assessing informative interim decisions in sequential clinical trials", "abstract": "Group sequential designs enable interim analyses and potential early stopping\nfor efficacy or futility. While these adaptations improve trial efficiency and\nethical considerations, they also introduce bias into the adapted analyses. We\ndemonstrate how failing to account for informative interim decisions in the\nanalysis can substantially affect posterior estimates of the treatment effect,\noften resulting in overly optimistic credible intervals aligned with the\nstopping decision. Drawing on information theory, we use the Kullback-Leibler\ndivergence to quantify this distortion and highlight its use for post-hoc\nevaluation of informative interim decisions, with a focus on end-of-study\ninference. Unlike pointwise comparisons, this measure provides an integrated\nsummary of this distortion on the whole parameter space. By comparing\nalternative decision boundaries and prior specifications, we illustrate how\nthis measure can improve the understanding of trial results and inform the\nplanning of future adaptive studies. We also introduce an expected version of\nthis metric to support clinicians in choosing decision boundaries. This\nguidance complements traditional strategies based on type-I error rate control\nby offering insights into the distortion introduced to the treatment effect at\neach interim phase. The use of this pre-experimental measure is finally\nillustrated in a group sequential trial for evaluating a treatment for central\nnervous system disorders.", "published": "2025-09-05 08:23:14", "link": "http://arxiv.org/abs/2509.04904v2", "categories": ["stat.ME", "cs.IT", "math.IT", "stat.AP"], "primary_category": "stat.ME"}
{"title": "Beyond Linearity and Time-homogeneity: Relational Hyper Event Models with Time-Varying Non-Linear Effects", "abstract": "Recent technological advances have made it easier to collect large and\ncomplex networks of time-stamped relational events connecting two or more\nentities. Relational hyper-event models (RHEMs) aim to explain the dynamics of\nthese events by modeling the event rate as a function of statistics based on\npast history and external information.\n  However, despite the complexity of the data, most current RHEM approaches\nstill rely on a linearity assumption to model this relationship. In this work,\nwe address this limitation by introducing a more flexible model that allows the\neffects of statistics to vary non-linearly and over time. While time-varying\nand non-linear effects have been used in relational event modeling, we take\nthis further by modeling joint time-varying and non-linear effects using tensor\nproduct smooths.\n  We validate our methodology on both synthetic and empirical data. In\nparticular, we use RHEMs to study how patterns of scientific collaboration and\nimpact evolve over time. Our approach provides deeper insights into the dynamic\nfactors driving relational hyper-events, allowing us to evaluate potential\nnon-monotonic patterns that cannot be identified using linear models.", "published": "2025-09-05 17:55:29", "link": "http://arxiv.org/abs/2509.05289v2", "categories": ["stat.ME", "cs.LG", "stat.AP"], "primary_category": "stat.ME"}
{"title": "Probabilistic operator learning: generative modeling and uncertainty quantification for foundation models of differential equations", "abstract": "In-context operator networks (ICON) are a class of operator learning methods\nbased on the novel architectures of foundation models. Trained on a diverse set\nof datasets of initial and boundary conditions paired with corresponding\nsolutions to ordinary and partial differential equations (ODEs and PDEs), ICON\nlearns to map example condition-solution pairs of a given differential equation\nto an approximation of its solution operator. Here, we present a probabilistic\nframework that reveals ICON as implicitly performing Bayesian inference, where\nit computes the mean of the posterior predictive distribution over solution\noperators conditioned on the provided context, i.e., example condition-solution\npairs. The formalism of random differential equations provides the\nprobabilistic framework for describing the tasks ICON accomplishes while also\nproviding a basis for understanding other multi-operator learning methods. This\nprobabilistic perspective provides a basis for extending ICON to\n\\emph{generative} settings, where one can sample from the posterior predictive\ndistribution of solution operators. The generative formulation of ICON\n(GenICON) captures the underlying uncertainty in the solution operator, which\nenables principled uncertainty quantification in the solution predictions in\noperator learning.", "published": "2025-09-05 15:35:04", "link": "http://arxiv.org/abs/2509.05186v2", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "stat.ML"}
{"title": "ModalSurv: A Multimodal Deep Survival Framework for Prostrate and Bladder Cancer", "abstract": "Accurate prediction of time-to-event outcomes is a central challenge in\noncology, with significant implications for treatment planning and patient\nmanagement. In this work, we present ModaliSurv, a multimodal deep survival\nmodel utilising DeepHit with a projection layer and inter-modality\ncross-attention, which integrates heterogeneous patient data, including\nclinical, MRI, RNA-seq and whole-slide pathology features. The model is\ndesigned to capture complementary prognostic signals across modalities and\nestimate individualised time-to-biochemical recurrence in prostate cancer and\ntime-to-cancer recurrence in bladder cancer. Our approach was evaluated in the\ncontext of the CHIMERA Grand Challenge, across two of the three provided tasks.\nFor Task 1 (prostate cancer bio-chemical recurrence prediction), the proposed\nframework achieved a concordance index (C-index) of 0.843 on 5-folds\ncross-validation and 0.818 on CHIMERA development set, demonstrating robust\ndiscriminatory ability. For Task 3 (bladder cancer recurrence prediction), the\nmodel obtained a C-index of 0.662 on 5-folds cross-validation and 0.457 on\ndevelopment set, highlighting its adaptability and potential for clinical\ntranslation. These results suggest that leveraging multimodal integration with\ndeep survival learning provides a promising pathway toward personalised risk\nstratification in prostate and bladder cancer. Beyond the challenge setting,\nour framework is broadly applicable to survival prediction tasks involving\nheterogeneous biomedical data.", "published": "2025-09-05 11:52:53", "link": "http://arxiv.org/abs/2509.05037v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning and composing of classical music using restricted Boltzmann machines", "abstract": "Recently, software has been developed that uses machine learning to mimic the\nstyle of a particular composer, such as J. S. Bach. However, since such\nsoftware often adopts machine learning models with complex structures, it is\ndifficult to analyze how the software understands the characteristics of the\ncomposer's music. In this study, we adopted J. S. Bach's music for training of\na restricted Boltzmann machine (RBM). Since the structure of RBMs is simple, it\nallows us to investigate the internal states after learning. We found that the\nlearned RBM is able to compose music.", "published": "2025-09-05 08:18:14", "link": "http://arxiv.org/abs/2509.04899v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)", "abstract": "This work presents a Biomedical Literature Question Answering (Q&A) system\nbased on a Retrieval-Augmented Generation (RAG) architecture, designed to\nimprove access to accurate, evidence-based medical information. Addressing the\nshortcomings of conventional health search engines and the lag in public access\nto biomedical research, the system integrates diverse sources, including PubMed\narticles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant\ninformation and generate concise, context-aware responses. The retrieval\npipeline uses MiniLM-based semantic embeddings and FAISS vector search, while\nanswer generation is performed by a fine-tuned Mistral-7B-v0.3 language model\noptimized using QLoRA for efficient, low-resource training. The system supports\nboth general medical queries and domain-specific tasks, with a focused\nevaluation on breast cancer literature demonstrating the value of\ndomain-aligned retrieval. Empirical results, measured using BERTScore (F1),\nshow substantial improvements in factual consistency and semantic relevance\ncompared to baseline models. The findings underscore the potential of\nRAG-enhanced language models to bridge the gap between complex biomedical\nliterature and accessible public health knowledge, paving the way for future\nwork on multilingual adaptation, privacy-preserving inference, and personalized\nmedical AI systems.", "published": "2025-09-05 21:29:52", "link": "http://arxiv.org/abs/2509.05505v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Token Tax: Systematic Bias in Multilingual Tokenization", "abstract": "Tokenization inefficiency imposes structural disadvantages on morphologically\ncomplex, low-resource languages, inflating compute resources and depressing\naccuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA\nitems; 5 subjects; 16 African languages) and show that fertility (tokens/word)\nreliably predicts accuracy. Higher fertility consistently predicts lower\naccuracy across all models and subjects. We further find that reasoning models\n(DeepSeek, o1) consistently outperform non-reasoning peers across high and low\nresource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in\nprior generations. Finally, translating token inflation to economics, a\ndoubling in tokens results in quadrupled training cost and time, underscoring\nthe token tax faced by many languages. These results motivate morphologically\naware tokenization, fair pricing, and multilingual benchmarks for equitable\nnatural language processing (NLP).", "published": "2025-09-05 20:20:51", "link": "http://arxiv.org/abs/2509.05486v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics", "abstract": "Hospital call centers serve as the primary contact point for patients within\na hospital system. They also generate substantial volumes of staff messages as\nnavigators process patient requests and communicate with the hospital offices\nfollowing the established protocol restrictions and guidelines. This\ncontinuously accumulated large amount of text data can be mined and processed\nto retrieve insights; however, traditional supervised learning approaches\nrequire annotated data, extensive training, and model tuning. Large Language\nModels (LLMs) offer a paradigm shift toward more computationally efficient\nmethodologies for healthcare analytics. This paper presents a multi-stage\nLLM-based framework that identifies staff message topics and classifies\nmessages by their reasons in a multi-class fashion. In the process, multiple\nLLM types, including reasoning, general-purpose, and lightweight models, were\nevaluated. The best-performing model was o3, achieving 78.4% weighted F1-score\nand 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and\n76.2% accuracy). The proposed methodology incorporates data security measures\nand HIPAA compliance requirements essential for healthcare environments. The\nprocessed LLM outputs are integrated into a visualization decision support tool\nthat transforms the staff messages into actionable insights accessible to\nhealthcare professionals. This approach enables more efficient utilization of\nthe collected staff messaging data, identifies navigator training\nopportunities, and supports improved patient experience and care quality.", "published": "2025-09-05 20:15:52", "link": "http://arxiv.org/abs/2509.05484v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too", "abstract": "As large-language models have been increasingly used as automatic raters for\nevaluating free-form content, including document summarization, dialog, and\nstory generation, work has been dedicated to evaluating such models by\nmeasuring their correlations with human judgment. For \\textit{sample-level}\nperformance, methods which operate by using pairwise comparisons between\nmachine-generated text perform well but often lack the ability to assign\nabsolute scores to individual summaries, an ability crucial for use cases that\nrequire thresholding. In this work, we propose a direct-scoring method which\nuses synthetic summaries to act as pairwise machine rankings at test time. We\nshow that our method performs comparably to state-of-the-art pairwise\nevaluators in terms of axis-averaged sample-level correlations on the SummEval\n(\\textbf{+0.03}), TopicalChat (\\textbf{-0.03}), and HANNA (\\textbf{+0.05})\nmeta-evaluation benchmarks, and release the synthetic in-context summaries as\ndata to facilitate future work.", "published": "2025-09-05 18:48:34", "link": "http://arxiv.org/abs/2509.05440v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "No Translation Needed: Forecasting Quality from Fertility and Metadata", "abstract": "We show that translation quality can be predicted with surprising accuracy\n\\textit{without ever running the translation system itself}. Using only a\nhandful of features, token fertility ratios, token counts, and basic linguistic\nmetadata (language family, script, and region), we can forecast ChrF scores for\nGPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient\nboosting models achieve favorable performance ($R^{2}=0.66$ for\nXX$\\rightarrow$English and $R^{2}=0.72$ for English$\\rightarrow$XX). Feature\nimportance analyses reveal that typological factors dominate predictions into\nEnglish, while fertility plays a larger role for translations into diverse\ntarget languages. These findings suggest that translation quality is shaped by\nboth token-level fertility and broader linguistic typology, offering new\ninsights for multilingual evaluation and quality estimation.", "published": "2025-09-05 18:11:49", "link": "http://arxiv.org/abs/2509.05425v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate", "abstract": "While multi-agent debate has been proposed as a promising strategy for\nimproving AI reasoning ability, we find that debate can sometimes be harmful\nrather than helpful. The prior work has exclusively focused on debates within\nhomogeneous groups of agents, whereas we explore how diversity in model\ncapabilities influences the dynamics and outcomes of multi-agent interactions.\nThrough a series of experiments, we demonstrate that debate can lead to a\ndecrease in accuracy over time -- even in settings where stronger (i.e., more\ncapable) models outnumber their weaker counterparts. Our analysis reveals that\nmodels frequently shift from correct to incorrect answers in response to peer\nreasoning, favoring agreement over challenging flawed reasoning. These results\nhighlight important failure modes in the exchange of reasons during multi-agent\ndebate, suggesting that naive applications of debate may cause performance\ndegradation when agents are neither incentivized nor adequately equipped to\nresist persuasive but incorrect reasoning.", "published": "2025-09-05 13:47:38", "link": "http://arxiv.org/abs/2509.05396v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "On covering cubic graphs with 3 perfect matchings", "abstract": "For a bridgeless cubic graph $G$, $m_3(G)$ is the ratio of the maximum number\nof edges of $G$ covered by the union of $3$ perfect matchings to $|E(G)|$. We\nprove that for any $r\\in [4/5, 1)$, there exist infinitely many cubic graphs\n$G$ such that $m_3(G) = r$. For any $r\\in [9/10, 1)$, there exist infinitely\nmany cyclically $4$-connected cubic graphs $G$ with $m_3(G) = r$.", "published": "2025-09-05 21:25:01", "link": "http://arxiv.org/abs/2509.05501v1", "categories": ["math.CO", "cs.DM", "05C70"], "primary_category": "math.CO"}
{"title": "Distributed Link Sparsification for Scalable Scheduling Using Graph Neural Networks (Journal Version)", "abstract": "In wireless networks characterized by dense connectivity, the significant\nsignaling overhead generated by distributed link scheduling algorithms can\nexacerbate issues like congestion, energy consumption, and radio footprint\nexpansion. To mitigate these challenges, we propose a distributed link\nsparsification scheme employing graph neural networks (GNNs) to reduce\nscheduling overhead for delay-tolerant traffic while maintaining network\ncapacity. A GNN module is trained to adjust contention thresholds for\nindividual links based on traffic statistics and network topology, enabling\nlinks to withdraw from scheduling contention when they are unlikely to succeed.\nOur approach is facilitated by a novel offline constrained {unsupervised}\nlearning algorithm capable of balancing two competing objectives: minimizing\nscheduling overhead while ensuring that total utility meets the required level.\nIn simulated wireless multi-hop networks with up to 500 links, our link\nsparsification technique effectively alleviates network congestion and reduces\nradio footprints across four distinct distributed link scheduling protocols.", "published": "2025-09-05 18:59:14", "link": "http://arxiv.org/abs/2509.05447v1", "categories": ["cs.NI", "cs.DM", "cs.LG", "eess.SP", "05-08", "C.2.1; I.2.8; G.2.2"], "primary_category": "cs.NI"}
{"title": "Calibrated Recommendations with Contextual Bandits", "abstract": "Spotify's Home page features a variety of content types, including music,\npodcasts, and audiobooks. However, historical data is heavily skewed toward\nmusic, making it challenging to deliver a balanced and personalized content\nmix. Moreover, users' preference towards different content types may vary\ndepending on the time of day, the day of week, or even the device they use. We\npropose a calibration method that leverages contextual bandits to dynamically\nlearn each user's optimal content type distribution based on their context and\npreferences. Unlike traditional calibration methods that rely on historical\naverages, our approach boosts engagement by adapting to how users interests in\ndifferent content types varies across contexts. Both offline and online results\ndemonstrate improved precision and user engagement with the Spotify Home page,\nin particular with under-represented content types such as podcasts.", "published": "2025-09-05 19:28:08", "link": "http://arxiv.org/abs/2509.05460v1", "categories": ["cs.LG", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Strategic Concealment of Environment Representations in Competitive Games", "abstract": "This paper investigates the strategic concealment of map abstractions used by\nthe players in competitive games. We consider a defense scenario in which one\nplayer (the Defender) seeks to infer and exploit the abstraction used by the\nother player (the Attacker). The interaction between the two players is modeled\nas a Bayesian game: the Defender selects a barrier configuration, i.e., a\nplacement of obstacles that can obstruct the Attacker's movement, based on its\nbelief about the Attacker's abstraction, while the Attacker chooses a\ntrajectory that may intentionally obfuscate its own abstraction of the\nenvironment to mislead the Defender. We show that purposeful abstraction\nconcealment naturally emerges from this formulation as a means of improving the\nAttacker's performance. To solve the game, we propose a bilinear programming\napproach that integrates Bayesian inference, strategic planning, and belief\nmanipulation. Simulations demonstrate that, by shaping the Defender's belief,\nthe Attacker can induce suboptimal Defender barrier placement, thereby gaining\na strategic advantage.", "published": "2025-09-05 21:26:30", "link": "http://arxiv.org/abs/2509.05503v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Cryo-EM as a Stochastic Inverse Problem", "abstract": "Cryo-electron microscopy (Cryo-EM) enables high-resolution imaging of\nbiomolecules, but structural heterogeneity remains a major challenge in 3D\nreconstruction. Traditional methods assume a discrete set of conformations,\nlimiting their ability to recover continuous structural variability. In this\nwork, we formulate cryo-EM reconstruction as a stochastic inverse problem (SIP)\nover probability measures, where the observed images are modeled as the\npush-forward of an unknown distribution over molecular structures via a random\nforward operator. We pose the reconstruction problem as the minimization of a\nvariational discrepancy between observed and simulated image distributions,\nusing statistical distances such as the KL divergence and the Maximum Mean\nDiscrepancy. The resulting optimization is performed over the space of\nprobability measures via a Wasserstein gradient flow, which we numerically\nsolve using particles to represent and evolve conformational ensembles. We\nvalidate our approach using synthetic examples, including a realistic protein\nmodel, which demonstrates its ability to recover continuous distributions over\nstructural states. We analyze the connection between our formulation and\nMaximum A Posteriori (MAP) approaches, which can be interpreted as instances of\nthe discretize-then-optimize (DTO) framework. We further provide a consistency\nanalysis, establishing conditions under which DTO methods, such as MAP\nestimation, converge to the solution of the underlying infinite-dimensional\ncontinuous problem. Beyond cryo-EM, the framework provides a general\nmethodology for solving SIPs involving random forward operators.", "published": "2025-09-05 23:35:04", "link": "http://arxiv.org/abs/2509.05541v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "math.OC", "physics.data-an", "65M32, 49Q22, 65M75, 65K10"], "primary_category": "stat.ML"}
{"title": "Fast Multipole Method with Complex Coordinates", "abstract": "In this work we present a variant of the fast multipole method (FMM) for\nefficiently evaluating standard layer potentials on geometries with complex\ncoordinates in two and three dimensions. The complex scaled boundary integral\nmethod for the efficient solution of scattering problems on unbounded domains\nresults in complex point locations upon discretization. Classical\nreal-coordinate FMMs are no longer applicable, hindering the use of this\napproach for large-scale problems. Here we develop the complex-coordinate FMM\nbased on the analytic continuation of certain special function identities used\nin the construction of the classical FMM. To achieve the same linear time\ncomplexity as the classical FMM, we construct a hierarchical tree based solely\non the real parts of the complex point locations, and derive convergence rates\nfor truncated expansions when the imaginary parts of the locations are a\nLipschitz function of the corresponding real parts. We demonstrate the\nefficiency of our approach through several numerical examples and illustrate\nits application for solving large-scale time-harmonic water wave problems and\nHelmholtz transmission problems.", "published": "2025-09-05 19:23:33", "link": "http://arxiv.org/abs/2509.05458v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A class of regularization schemes for linear ill-posed problems in Banach spaces under low order source conditions", "abstract": "In this work we consider, in a Banach space framework, the regularization of\nlinear ill-posed problems. Our focus is on the recovery of solutions that have\na logarithmic source representation. Such cases typically occur in\nexponentially ill-posed problems like the backwards heat equation. The\nmathematical framework on logarithms of operators is provided, and convergence\nrates for a class of parametric regularization schemes are deduced. This class\nincludes the iterated version of Lavrentiev's method and the method of the\nabstract Cauchy problem. The presentation includes both a priori and a\nposteriori parameter choice strategies. Finally, we present an example for a\nlogarithmic source representable function with respect to the integration\noperator.", "published": "2025-09-05 18:01:04", "link": "http://arxiv.org/abs/2509.05418v1", "categories": ["math.NA", "cs.NA", "65J20 65J22 47D06 26A33"], "primary_category": "math.NA"}
{"title": "Graph Connectionist Temporal Classification for Phoneme Recognition", "abstract": "Automatic Phoneme Recognition (APR) systems are often trained using pseudo\nphoneme-level annotations generated from text through Grapheme-to-Phoneme (G2P)\nsystems. These G2P systems frequently output multiple possible pronunciations\nper word, but the standard Connectionist Temporal Classification (CTC) loss\ncannot account for such ambiguity during training. In this work, we adapt Graph\nTemporal Classification (GTC) to the APR setting. GTC enables training from a\ngraph of alternative phoneme sequences, allowing the model to consider multiple\npronunciations per word as valid supervision. Our experiments on English and\nDutch data sets show that incorporating multiple pronunciations per word into\nthe training loss consistently improves phoneme error rates compared to a\nbaseline trained with CTC. These results suggest that integrating pronunciation\nvariation into the loss function is a promising strategy for training APR\nsystems from noisy G2P-based supervision.", "published": "2025-09-05 15:20:59", "link": "http://arxiv.org/abs/2509.05399v1", "categories": ["eess.AS", "cs.AI", "68T10, 68T07", "I.2.7; I.5.4; H.5.1"], "primary_category": "eess.AS"}
{"title": "Developing a Framework to Simulate Quantitative Ultrasound Flow and Tissue Motion for Ultrafast Doppler Ultrasound", "abstract": "Ultrafast power Doppler imaging (uPDI) has made significant progress and\nbecome an important imaging method for both research and clinical\nimplementations. While, it lacks simulation tools that can perform\nthree-dimensional (3D) quantitative flow with tissue motion close to realistic\nconditions. In this study, we explore to construct an open-source framework,\nnamed 3D-Fully Quantitative Flow (3D-FQFlow), to provide quantitative modeling\nof 3D vascular flow with tissue motion and uPDI imaging. The framework\nintegrates a L-system-based vascular generator with SimVascular CFD for\nhemodynamics, a tissue motion simulator supporting user-defined or\nclinical-data-driven condition, an optimized PFILED ultrasound simulator, a\nprecomputed-matrix-based reconstructor, and a quantitative analyzer\n(MSE/PSNR/SSIM). Results demonstrate distinct influences of four motion\npatterns on SVD decomposition; successful 3D imaging of rabbit kidney (SSIM =\n0.951), generated vasculature (SSIM = 0.902), and clinical pulmonary arteries\n(SSIM = 0.850); and GPU acceleration permitting 1-million-scatterer simulation\nin 4,117 seconds with 18.8* speedup for 100-frame 3D-uPDI generation. 3D-FQFlow\nestablishes the first open-source framework for quantitative validation of uPDI\nunder realistic vascular and motion conditions, creating a reproducible\nstandard for microvascular imaging research\n(https://github.com/FortuneOU/3D-FQFlow).", "published": "2025-09-05 19:39:25", "link": "http://arxiv.org/abs/2509.05464v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Hunyuan-MT Technical Report", "abstract": "In this report, we introduce Hunyuan-MT-7B, our first open-source\nmultilingual translation model, which supports bidirectional translation across\n33 major languages and places a special emphasis on translation between\nMandarin and several ethnic minority languages as well as dialects.\nFurthermore, to serve and address diverse translation scenarios and enhance\nmodel performance at test time, we introduce Hunyuan-MT-Chimera-7B, a\ntranslation model inspired by the slow thinking mode. This model integrates\nmultiple outputs generated by the Hunyuan-MT-7B model under varying parameter\nsettings, thereby achieving performance superior to that of conventional\nslow-thinking models based on Chain-of-Thought (CoT). The development of our\nmodels follows a holistic training process specifically engineered for\nmultilingual translation, which begins with general and MT-oriented\npre-training to build foundational capabilities, proceeds to Supervised\nFine-Tuning (SFT) for task-specific adaptation, and culminates in advanced\nalignment through Reinforcement Learning (RL) and weak-to-strong RL. Through\ncomprehensive experimentation, we demonstrate that both Hunyuan-MT-7B and\nHunyuan-MT-Chimera-7B significantly outperform all translation-specific models\nof comparable parameter size and most of the SOTA large models, particularly on\nthe task of translation between Mandarin and minority languages as well as\ndialects. In the WMT2025 shared task (General Machine Translation), our models\ndemonstrate state-of-the-art performance, ranking first in 30 out of 31\nlanguage pairs. This result highlights the robustness of our models across a\ndiverse linguistic spectrum, encompassing high-resource languages such as\nChinese, English, and Japanese, as well as low-resource languages including\nCzech, Marathi, Estonian, and Icelandic.", "published": "2025-09-05 16:11:05", "link": "http://arxiv.org/abs/2509.05209v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Estimating Cellular Network Delays in Finnish Railways: A Machine Learning Enhanced Approach", "abstract": "There is growing interest in using public cellular networks for specialized\ncommunication applications, replacing standalone sector-specific networks. One\nsuch application is transitioning from the aging GSM-R railway network to\npublic 4G and 5G networks. Finland is modernizing its railway communication\nsystem through the Digirail project, leveraging public cellular networks. To\nevaluate network performance, a nationwide measurement campaign was conducted\nin two modes: Best Quality and Packet Replication. However, Best Quality mode\nintroduces artificial delays, making it unsuitable for real-world assessments.\nIn this paper, railway network delays are modeled using machine learning based\non measurements from the Packet Replication mode. The best-performing model is\nthen employed to generate a dataset estimating network delays across Finland's\nrailway network. This dataset provides a more accurate representation of\nnetwork performance. Machine learning based network performance prediction is\nshown to be feasible, and the results indicate that Finland's public cellular\nnetwork can meet the stringent performance requirements of railway network\ncontrol.", "published": "2025-09-05 10:53:59", "link": "http://arxiv.org/abs/2509.05003v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
