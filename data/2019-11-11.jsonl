{"title": "Word Sense Disambiguation using Knowledge-based Word Similarity", "abstract": "In natural language processing, word-sense disambiguation (WSD) is an open\nproblem concerned with identifying the correct sense of words in a particular\ncontext. To address this problem, we introduce a novel knowledge-based WSD\nsystem. We suggest the adoption of two methods in our system. First, we suggest\na novel method to encode the word vector representation by considering the\ngraphical semantic relationships from the lexical knowledge-base. Second, we\npropose a method for extracting the contextual words from the text for\nanalyzing an ambiguous word based on the similarity of word vector\nrepresentations. To validate the effectiveness of our WSD system, we conducted\nexperiments on the five benchmark English WSD corpora (Senseval-02,\nSenseval-03, SemEval-07, SemEval-13, and SemEval-15). The obtained results\ndemonstrated that the suggested methods significantly enhanced the WSD\nperformance. Furthermore, our system outperformed the existing knowledge-based\nWSD systems and showed a performance comparable to that of the state-of-the-art\nsupervised WSD systems.", "published": "2019-11-11 00:07:02", "link": "http://arxiv.org/abs/1911.04015v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decompressing Knowledge Graph Representations for Link Prediction", "abstract": "This paper studies the problem of predicting missing relationships between\nentities in knowledge graphs through learning their representations. Currently,\nthe majority of existing link prediction models employ simple but intuitive\nscoring functions and relatively small embedding size so that they could be\napplied to large-scale knowledge graphs. However, these properties also\nrestrict the ability to learn more expressive and robust features. Therefore,\ndiverging from most of the prior works which focus on designing new objective\nfunctions, we propose, DeCom, a simple but effective mechanism to boost the\nperformance of existing link predictors such as DistMult, ComplEx, etc, through\nextracting more expressive features while preventing overfitting by adding just\na few extra parameters. Specifically, embeddings of entities and relationships\nare first decompressed to a more expressive and robust space by decompressing\nfunctions, then knowledge graph embedding models are trained in this new\nfeature space. Experimental results on several benchmark knowledge graphs and\nadvanced link prediction systems demonstrate the generalization and\neffectiveness of our method. Especially, RESCAL + DeCom achieves\nstate-of-the-art performance on the FB15k-237 benchmark across all evaluation\nmetrics. In addition, we also show that compared with DeCom, explicitly\nincreasing the embedding size significantly increase the number of parameters\nbut could not achieve promising performance improvement.", "published": "2019-11-11 03:15:22", "link": "http://arxiv.org/abs/1911.04053v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DialogAct2Vec: Towards End-to-End Dialogue Agent by Multi-Task\n  Representation Learning", "abstract": "In end-to-end dialogue modeling and agent learning, it is important to (1)\neffectively learn knowledge from data, and (2) fully utilize heterogeneous\ninformation, e.g., dialogue act flow and utterances. However, the majority of\nexisting methods cannot simultaneously satisfy the two conditions. For example,\nrule definition and data labeling during system design take too much manual\nwork, and sequence-to-sequence methods only model one-side utterance\ninformation. In this paper, we propose a novel joint end-to-end model by\nmulti-task representation learning, which can capture the knowledge from\nheterogeneous information through automatically learning knowledgeable\nlow-dimensional embeddings from data, named with DialogAct2Vec. The model\nrequires little manual work for intervention in system design and we find that\nthe multi-task learning can greatly improve the effectiveness of representation\nlearning. Extensive experiments on a public dataset for restaurant reservation\nshow that the proposed method leads to significant improvements against the\nstate-of-the-art baselines on both the act prediction task and utterance\nprediction task.", "published": "2019-11-11 05:43:45", "link": "http://arxiv.org/abs/1911.04088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text classification with pixel embedding", "abstract": "We propose a novel framework to understand the text by converting sentences\nor articles into video-like 3-dimensional tensors. Each frame, corresponding to\na slice of the tensor, is a word image that is rendered by the word's shape.\nThe length of the tensor equals to the number of words in the sentence or\narticle. The proposed transformation from the text to a 3-dimensional tensor\nmakes it very convenient to implement an $n$-gram model with convolutional\nneural networks for text analysis. Concretely, we impose a 3-dimensional\nconvolutional kernel on the 3-dimensional text tensor. The first two dimensions\nof the convolutional kernel size equal the size of the word image and the last\ndimension of the kernel size is $n$. That is, every time when we slide the\n3-dimensional kernel over a word sequence, the convolution covers $n$ word\nimages and outputs a scalar. By iterating this process continuously for each\n$n$-gram along with the sentence or article with multiple kernels, we obtain a\n2-dimensional feature map. A subsequent 1-dimensional max-over-time pooling is\napplied to this feature map, and three fully-connected layers are used for\nconducting text classification finally. Experiments of several text\nclassification datasets demonstrate surprisingly superior performances using\nthe proposed model in comparison with existing methods.", "published": "2019-11-11 07:28:25", "link": "http://arxiv.org/abs/1911.04115v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer\n  Sentence Selection", "abstract": "We propose TANDA, an effective technique for fine-tuning pre-trained\nTransformer models for natural language tasks. Specifically, we first transfer\na pre-trained model into a model for a general task by fine-tuning it with a\nlarge and high-quality dataset. We then perform a second fine-tuning step to\nadapt the transferred model to the target domain. We demonstrate the benefits\nof our approach for answer sentence selection, which is a well-known inference\ntask in Question Answering. We built a large scale dataset to enable the\ntransfer step, exploiting the Natural Questions dataset. Our approach\nestablishes the state of the art on two well-known benchmarks, WikiQA and\nTREC-QA, achieving MAP scores of 92% and 94.3%, respectively, which largely\noutperform the previous highest scores of 83.4% and 87.5%, obtained in very\nrecent work. We empirically show that TANDA generates more stable and robust\nmodels reducing the effort required for selecting optimal hyper-parameters.\nAdditionally, we show that the transfer step of TANDA makes the adaptation step\nmore robust to noise. This enables a more effective use of noisy datasets for\nfine-tuning. Finally, we also confirm the positive impact of TANDA in an\nindustrial setting, using domain specific datasets subject to different types\nof noise.", "published": "2019-11-11 07:40:37", "link": "http://arxiv.org/abs/1911.04118v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Dependency Forest for Neural Medical Relation Extraction", "abstract": "Medical relation extraction discovers relations between entity mentions in\ntext, such as research articles. For this task, dependency syntax has been\nrecognized as a crucial source of features. Yet in the medical domain, 1-best\nparse trees suffer from relatively low accuracies, diminishing their\nusefulness. We investigate a method to alleviate this problem by utilizing\ndependency forests. Forests contain many possible decisions and therefore have\nhigher recall but more noise compared with 1-best outputs. A graph neural\nnetwork is used to represent the forests, automatically distinguishing the\nuseful syntactic information from parsing noise. Results on two biomedical\nbenchmarks show that our method outperforms the standard tree-based methods,\ngiving the state-of-the-art results in the literature.", "published": "2019-11-11 07:58:52", "link": "http://arxiv.org/abs/1911.04123v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A hybrid text normalization system using multi-head self-attention for\n  mandarin", "abstract": "In this paper, we propose a hybrid text normalization system using multi-head\nself-attention. The system combines the advantages of a rule-based model and a\nneural model for text preprocessing tasks. Previous studies in Mandarin text\nnormalization usually use a set of hand-written rules, which are hard to\nimprove on general cases. The idea of our proposed system is motivated by the\nneural models from recent studies and has a better performance on our internal\nnews corpus. This paper also includes different attempts to deal with\nimbalanced pattern distribution of the dataset. Overall, the performance of the\nsystem is improved by over 1.5% on sentence-level and it has a potential to\nimprove further.", "published": "2019-11-11 08:19:49", "link": "http://arxiv.org/abs/1911.04128v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NegBERT: A Transfer Learning Approach for Negation Detection and Scope\n  Resolution", "abstract": "Negation is an important characteristic of language, and a major component of\ninformation extraction from text. This subtask is of considerable importance to\nthe biomedical domain. Over the years, multiple approaches have been explored\nto address this problem: Rule-based systems, Machine Learning classifiers,\nConditional Random Field Models, CNNs and more recently BiLSTMs. In this paper,\nwe look at applying Transfer Learning to this problem. First, we extensively\nreview previous literature addressing Negation Detection and Scope Resolution\nacross the 3 datasets that have gained popularity over the years: the BioScope\nCorpus, the Sherlock dataset, and the SFU Review Corpus. We then explore the\ndecision choices involved with using BERT, a popular transfer learning model,\nfor this task, and report state-of-the-art results for scope resolution across\nall 3 datasets. Our model, referred to as NegBERT, achieves a token level F1\nscore on scope resolution of 92.36 on the Sherlock dataset, 95.68 on the\nBioScope Abstracts subcorpus, 91.24 on the BioScope Full Papers subcorpus,\n90.95 on the SFU Review Corpus, outperforming the previous state-of-the-art\nsystems by a significant margin. We also analyze the model's generalizability\nto datasets on which it is not trained.", "published": "2019-11-11 12:28:29", "link": "http://arxiv.org/abs/1911.04211v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attending to Entities for Better Text Understanding", "abstract": "Recent progress in NLP witnessed the development of large-scale pre-trained\nlanguage models (GPT, BERT, XLNet, etc.) based on Transformer (Vaswani et al.\n2017), and in a range of end tasks, such models have achieved state-of-the-art\nresults, approaching human performance. This demonstrates the power of the\nstacked self-attention architecture when paired with a sufficient number of\nlayers and a large amount of pre-training data. However, on tasks that require\ncomplex and long-distance reasoning where surface-level cues are not enough,\nthere is still a large gap between the pre-trained models and human\nperformance. Strubell et al. (2018) recently showed that it is possible to\ninject knowledge of syntactic structure into a model through supervised\nself-attention. We conjecture that a similar injection of semantic knowledge,\nin particular, coreference information, into an existing model would improve\nperformance on such complex problems. On the LAMBADA (Paperno et al. 2016)\ntask, we show that a model trained from scratch with coreference as auxiliary\nsupervision for self-attention outperforms the largest GPT-2 model, setting the\nnew state-of-the-art, while only containing a tiny fraction of parameters\ncompared to GPT-2. We also conduct a thorough analysis of different variants of\nmodel architectures and supervision configurations, suggesting future\ndirections on applying similar techniques to other problems.", "published": "2019-11-11 16:04:55", "link": "http://arxiv.org/abs/1911.04361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding BERT performance in propaganda analysis", "abstract": "In this paper, we describe our system used in the shared task for\nfine-grained propaganda analysis at sentence level. Despite the challenging\nnature of the task, our pretrained BERT model (team YMJA) fine tuned on the\ntraining dataset provided by the shared task scored 0.62 F1 on the test set and\nranked third among 25 teams who participated in the contest. We present a set\nof illustrative experiments to better understand the performance of our BERT\nmodel on this shared task. Further, we explore beyond the given dataset for\nfalse-positive cases that likely to be produced by our system. We show that\ndespite the high performance on the given testset, our system may have the\ntendency of classifying opinion pieces as propaganda and cannot distinguish\nquotations of propaganda speech from actual usage of propaganda techniques.", "published": "2019-11-11 19:16:01", "link": "http://arxiv.org/abs/1911.04525v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Biomedical Evidence Generation Engine", "abstract": "With the rapid development of precision medicine, a large amount of health\ndata (such as electronic health records, gene sequencing, medical images, etc.)\nhas been produced. It encourages more and more interest in data-driven insight\ndiscovery from these data. It is a reasonable way to verify the derived\ninsights in biomedical literature. However, manual verification is inefficient\nand not scalable. Therefore, an intelligent technique is necessary to solve\nthis problem. In this paper, we propose a task of biomedical evidence\ngeneration, which is very novel and different from existing NLP tasks.\nFurthermore, we developed a biomedical evidence generation engine for this task\nwith the pipeline of three components which are a literature retrieval module,\na skeleton information identification module, and a text summarization module.", "published": "2019-11-11 23:10:15", "link": "http://arxiv.org/abs/1911.06146v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Order Sub-questions for Complex Question Answering", "abstract": "Answering complex questions involving multiple entities and relations is a\nchallenging task. Logically, the answer to a complex question should be derived\nby decomposing the complex question into multiple simple sub-questions and then\nanswering those sub-questions. Existing work has followed this strategy but has\nnot attempted to optimize the order of how those sub-questions are answered. As\na result, the sub-questions are answered in an arbitrary order, leading to\nlarger search space and a higher risk of missing an answer. In this paper, we\npropose a novel reinforcement learning(RL) approach to answering complex\nquestions that can learn a policy to dynamically decide which sub-question\nshould be answered at each stage of reasoning. We lever-age the expected\nvalue-variance criterion to enable the learned policy to balance between the\nrisk and utility of answering a sub-question. Experiment results show that the\nRL approach can substantially improve the optimality of ordering the\nsub-questions, leading to improved accuracy of question answering. The proposed\nmethod for learning to order sub-questions is general and can thus be\npotentially combined with many existing ideas for answering complex questions\nto enhance their performance.", "published": "2019-11-11 04:06:46", "link": "http://arxiv.org/abs/1911.04065v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning", "abstract": "The Transformer model is widely successful on many natural language\nprocessing tasks. However, the quadratic complexity of self-attention limit its\napplication on long text. In this paper, adopting a fine-to-coarse attention\nmechanism on multi-scale spans via binary partitioning (BP), we propose\nBP-Transformer (BPT for short). BPT yields $O(k\\cdot n\\log (n/k))$ connections\nwhere $k$ is a hyperparameter to control the density of attention. BPT has a\ngood balance between computation complexity and model capacity. A series of\nexperiments on text classification, machine translation and language modeling\nshows BPT has a superior performance for long text than previous self-attention\nmodels. Our code, hyperparameters and CUDA kernels for sparse attention are\navailable in PyTorch.", "published": "2019-11-11 04:31:23", "link": "http://arxiv.org/abs/1911.04070v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-shot Cross-lingual Dialogue Systems with Transferable Latent\n  Variables", "abstract": "Despite the surging demands for multilingual task-oriented dialog systems\n(e.g., Alexa, Google Home), there has been less research done in multilingual\nor cross-lingual scenarios. Hence, we propose a zero-shot adaptation of\ntask-oriented dialogue system to low-resource languages. To tackle this\nchallenge, we first use a set of very few parallel word pairs to refine the\naligned cross-lingual word-level representations. We then employ a latent\nvariable model to cope with the variance of similar sentences across different\nlanguages, which is induced by imperfect cross-lingual alignments and inherent\ndifferences in languages. Finally, the experimental results show that even\nthough we utilize much less external resources, our model achieves better\nadaptation performance for natural language understanding task (i.e., the\nintent detection and slot filling) compared to the current state-of-the-art\nmodel in the zero-shot scenario.", "published": "2019-11-11 05:22:26", "link": "http://arxiv.org/abs/1911.04081v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Meta Answering for Machine Reading", "abstract": "We investigate a framework for machine reading, inspired by real world\ninformation-seeking problems, where a meta question answering system interacts\nwith a black box environment. The environment encapsulates a competitive\nmachine reader based on BERT, providing candidate answers to questions, and\npossibly some context. To validate the realism of our formulation, we ask\nhumans to play the role of a meta-answerer. With just a small snippet of text\naround an answer, humans can outperform the machine reader, improving recall.\nSimilarly, a simple machine meta-answerer outperforms the environment,\nimproving both precision and recall on the Natural Questions dataset. The\nsystem relies on joint training of answer scoring and the selection of\nconditioning information.", "published": "2019-11-11 10:07:57", "link": "http://arxiv.org/abs/1911.04156v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Contextualized Self-training for Low Resource Dependency Parsing", "abstract": "Neural dependency parsing has proven very effective, achieving\nstate-of-the-art results on numerous domains and languages. Unfortunately, it\nrequires large amounts of labeled data, that is costly and laborious to create.\nIn this paper we propose a self-training algorithm that alleviates this\nannotation bottleneck by training a parser on its own output. Our Deep\nContextualized Self-training (DCST) algorithm utilizes representation models\ntrained on sequence labeling tasks that are derived from the parser's output\nwhen applied to unlabeled data, and integrates these models with the base\nparser through a gating mechanism. We conduct experiments across multiple\nlanguages, both in low resource in-domain and in cross-domain setups, and\ndemonstrate that DCST substantially outperforms traditional self-training as\nwell as recent semi-supervised training methods.", "published": "2019-11-11 14:07:46", "link": "http://arxiv.org/abs/1911.04286v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RNN-Test: Towards Adversarial Testing for Recurrent Neural Network\n  Systems", "abstract": "While massive efforts have been investigated in adversarial testing of\nconvolutional neural networks (CNN), testing for recurrent neural networks\n(RNN) is still limited and leaves threats for vast sequential application\ndomains. In this paper, we propose an adversarial testing framework RNN-Test\nfor RNN systems, focusing on the main sequential domains, not only\nclassification tasks. First, we design a novel search methodology customized\nfor RNN models by maximizing the inconsistency of RNN states to produce\nadversarial inputs. Next, we introduce two state-based coverage metrics\naccording to the distinctive structure of RNNs to explore more inference\nlogics. Finally, RNN-Test solves the joint optimization problem to maximize\nstate inconsistency and state coverage, and crafts adversarial inputs for\nvarious tasks of different kinds of inputs.\n  For evaluations, we apply RNN-Test on three sequential models of common RNN\nstructures. On the tested models, the RNN-Test approach is demonstrated to be\ncompetitive in generating adversarial inputs, outperforming FGSM-based and\nDLFuzz-based methods to reduce the model performance more sharply with 2.78% to\n32.5% higher success (or generation) rate. RNN-Test could also achieve 52.65%\nto 66.45% higher adversary rate on MNIST-LSTM model than relevant work testRNN.\nCompared with the neuron coverage, the proposed state coverage metrics as\nguidance excel with 4.17% to 97.22% higher success (or generation) rate.", "published": "2019-11-11 05:30:53", "link": "http://arxiv.org/abs/1911.06155v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A unified sequence-to-sequence front-end model for Mandarin\n  text-to-speech synthesis", "abstract": "In Mandarin text-to-speech (TTS) system, the front-end text processing module\nsignificantly influences the intelligibility and naturalness of synthesized\nspeech. Building a typical pipeline-based front-end which consists of multiple\nindividual components requires extensive efforts. In this paper, we proposed a\nunified sequence-to-sequence front-end model for Mandarin TTS that converts raw\ntexts to linguistic features directly. Compared to the pipeline-based\nfront-end, our unified front-end can achieve comparable performance in\npolyphone disambiguation and prosody word prediction, and improve intonation\nphrase prediction by 0.0738 in F1 score. We also implemented the unified\nfront-end with Tacotron and WaveRNN to build a Mandarin TTS system. The\nsynthesized speech by that got a comparable MOS (4.38) with the pipeline-based\nfront-end (4.37) and close to human recordings (4.49).", "published": "2019-11-11 06:54:46", "link": "http://arxiv.org/abs/1911.04111v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Keep it Consistent: Topic-Aware Storytelling from an Image Stream via\n  Iterative Multi-agent Communication", "abstract": "Visual storytelling aims to generate a narrative paragraph from a sequence of\nimages automatically. Existing approaches construct text description\nindependently for each image and roughly concatenate them as a story, which\nleads to the problem of generating semantically incoherent content. In this\npaper, we propose a new way for visual storytelling by introducing a topic\ndescription task to detect the global semantic context of an image stream. A\nstory is then constructed with the guidance of the topic description. In order\nto combine the two generation tasks, we propose a multi-agent communication\nframework that regards the topic description generator and the story generator\nas two agents and learn them simultaneously via iterative updating mechanism.\nWe validate our approach on VIST dataset, where quantitative results,\nablations, and human evaluation demonstrate our method's good ability in\ngenerating stories with higher quality compared to state-of-the-art methods.", "published": "2019-11-11 11:35:21", "link": "http://arxiv.org/abs/1911.04192v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Data Efficient Direct Speech-to-Text Translation with Modality Agnostic\n  Meta-Learning", "abstract": "End-to-end Speech Translation (ST) models have several advantages such as\nlower latency, smaller model size, and less error compounding over conventional\npipelines that combine Automatic Speech Recognition (ASR) and text Machine\nTranslation (MT) models. However, collecting large amounts of parallel data for\nST task is more difficult compared to the ASR and MT tasks. Previous studies\nhave proposed the use of transfer learning approaches to overcome the above\ndifficulty. These approaches benefit from weakly supervised training data, such\nas ASR speech-to-transcript or MT text-to-text translation pairs. However, the\nparameters in these models are updated independently of each task, which may\nlead to sub-optimal solutions. In this work, we adopt a meta-learning algorithm\nto train a modality agnostic multi-task model that transfers knowledge from\nsource tasks=ASR+MT to target task=ST where ST task severely lacks data. In the\nmeta-learning phase, the parameters of the model are exposed to vast amounts of\nspeech transcripts (e.g., English ASR) and text translations (e.g.,\nEnglish-German MT). During this phase, parameters are updated in such a way to\nunderstand speech, text representations, the relation between them, as well as\nact as a good initialization point for the target ST task. We evaluate the\nproposed meta-learning approach for ST tasks on English-German (En-De) and\nEnglish-French (En-Fr) language pairs from the Multilingual Speech Translation\nCorpus (MuST-C). Our method outperforms the previous transfer learning\napproaches and sets new state-of-the-art results for En-De and En-Fr ST tasks\nby obtaining 9.18, and 11.76 BLEU point improvements, respectively.", "published": "2019-11-11 14:03:52", "link": "http://arxiv.org/abs/1911.04283v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Diversity by Phonetics and its Application in Neural Machine Translation", "abstract": "We introduce a powerful approach for Neural Machine Translation (NMT),\nwhereby, during training and testing, together with the input we provide its\nphonetic encoding and the variants of such an encoding. This way we obtain very\nsignificant improvements up to 4 BLEU points over the state-of-the-art\nlarge-scale system. The phonetic encoding is the first part of our\ncontribution, with a second being a theory that aims to understand the reason\nfor this improvement. Our hypothesis states that the phonetic encoding helps\nNMT because it encodes a procedure to emphasize the difference between\nsemantically diverse sentences. We conduct an empirical geometric validation of\nour hypothesis in support of which we obtain overwhelming evidence.\nSubsequently, as our third contribution and based on our theory, we develop\nartificial mechanisms that leverage during learning the hypothesized (and\nverified) effect phonetics. We achieve significant and consistent improvements\noverall language pairs and datasets: French-English, German-English, and\nChinese-English in medium task IWSLT'17 and French-English in large task WMT'18\nBio, with up to 4 BLEU points over the state-of-the-art. Moreover, our\napproaches are more robust than baselines when evaluated on unknown\nout-of-domain test sets with up to a 5 BLEU point increase.", "published": "2019-11-11 14:11:21", "link": "http://arxiv.org/abs/1911.04292v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Sequence-to-Set Semantic Tagging: End-to-End Multi-label Prediction\n  using Neural Attention for Complex Query Reformulation and Automated Text\n  Categorization", "abstract": "Novel contexts may often arise in complex querying scenarios such as in\nevidence-based medicine (EBM) involving biomedical literature, that may not\nexplicitly refer to entities or canonical concept forms occurring in any fact-\nor rule-based knowledge source such as an ontology like the UMLS. Moreover,\nhidden associations between candidate concepts meaningful in the current\ncontext, may not exist within a single document, but within the collection, via\nalternate lexical forms. Therefore, inspired by the recent success of\nsequence-to-sequence neural models in delivering the state-of-the-art in a wide\nrange of NLP tasks, we develop a novel sequence-to-set framework with neural\nattention for learning document representations that can effect term transfer\nwithin the corpus, for semantically tagging a large collection of documents. We\ndemonstrate that our proposed method can be effective in both a supervised\nmulti-label classification setup for text categorization, as well as in a\nunique unsupervised setting with no human-annotated document labels that uses\nno external knowledge resources and only corpus-derived term statistics to\ndrive the training. Further, we show that semi-supervised training using our\narchitecture on large amounts of unlabeled data can augment performance on the\ntext categorization task when limited labeled data is available. Our approach\nto generate document encodings employing our sequence-to-set models for\ninference of semantic tags, gives to the best of our knowledge, the\nstate-of-the-art for both, the unsupervised query expansion task for the TREC\nCDS 2016 challenge dataset when evaluated on an Okapi BM25--based document\nretrieval system; and also over the MLTM baseline (Soleimani et al, 2016), for\nboth supervised and semi-supervised multi-label prediction tasks on the\ndel.icio.us and Ohsumed datasets. We will make our code and data publicly\navailable.", "published": "2019-11-11 18:13:05", "link": "http://arxiv.org/abs/1911.04427v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Long-span language modeling for speech recognition", "abstract": "We explore neural language modeling for speech recognition where the context\nspans multiple sentences. Rather than encode history beyond the current\nsentence using a cache of words or document-level features, we focus our study\non the ability of LSTM and Transformer language models to implicitly learn to\ncarry over context across sentence boundaries. We introduce a new architecture\nthat incorporates an attention mechanism into LSTM to combine the benefits of\nrecurrent and attention architectures. We conduct language modeling and speech\nrecognition experiments on the publicly available LibriSpeech corpus. We show\nthat conventional training on a paragraph-level corpus results in significant\nreductions in perplexity compared to training on a sentence-level corpus. We\nalso describe speech recognition experiments using long-span language models in\nsecond-pass re-ranking, and provide insights into the ability of such models to\ntake advantage of context beyond the current sentence.", "published": "2019-11-11 21:18:53", "link": "http://arxiv.org/abs/1911.04571v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "t-SS3: a text classifier with dynamic n-grams for early risk detection\n  over text streams", "abstract": "A recently introduced classifier, called SS3, has shown to be well suited to\ndeal with early risk detection (ERD) problems on text streams. It obtained\nstate-of-the-art performance on early depression and anorexia detection on\nReddit in the CLEF's eRisk open tasks. SS3 was created to deal with ERD\nproblems naturally since: it supports incremental training and classification\nover text streams, and it can visually explain its rationale. However, SS3\nprocesses the input using a bag-of-word model lacking the ability to recognize\nimportant word sequences. This aspect could negatively affect the\nclassification performance and also reduces the descriptiveness of visual\nexplanations. In the standard document classification field, it is very common\nto use word n-grams to try to overcome some of these limitations.\nUnfortunately, when working with text streams, using n-grams is not trivial\nsince the system must learn and recognize which n-grams are important \"on the\nfly\". This paper introduces t-SS3, an extension of SS3 that allows it to\nrecognize useful patterns over text streams dynamically. We evaluated our model\nin the eRisk 2017 and 2018 tasks on early depression and anorexia detection.\nExperimental results suggest that t-SS3 is able to improve both current results\nand the richness of visual explanations.", "published": "2019-11-11 22:06:40", "link": "http://arxiv.org/abs/1911.06147v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Emotional Voice Conversion using Multitask Learning with Text-to-speech", "abstract": "Voice conversion (VC) is a task to transform a person's voice to different\nstyle while conserving linguistic contents. Previous state-of-the-art on VC is\nbased on sequence-to-sequence (seq2seq) model, which could mislead linguistic\ninformation. There was an attempt to overcome it by using textual supervision,\nit requires explicit alignment which loses the benefit of using seq2seq model.\nIn this paper, a voice converter using multitask learning with text-to-speech\n(TTS) is presented. The embedding space of seq2seq-based TTS has abundant\ninformation on the text. The role of the decoder of TTS is to convert embedding\nspace to speech, which is same to VC. In the proposed model, the whole network\nis trained to minimize loss of VC and TTS. VC is expected to capture more\nlinguistic information and to preserve training stability by multitask\nlearning. Experiments of VC were performed on a male Korean emotional\ntext-speech dataset, and it is shown that multitask learning is helpful to keep\nlinguistic contents in VC.", "published": "2019-11-11 19:53:58", "link": "http://arxiv.org/abs/1911.06149v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Knowledge Distillation in Document Retrieval", "abstract": "Complex deep learning models now achieve state of the art performance for\nmany document retrieval tasks. The best models process the query or claim\njointly with the document. However for fast scalable search it is desirable to\nhave document embeddings which are independent of the claim. In this paper we\nshow that knowledge distillation can be used to encourage a model that\ngenerates claim independent document encodings to mimic the behavior of a more\ncomplex model which generates claim dependent encodings. We explore this\napproach in document retrieval for a fact extraction and verification task. We\nshow that by using the soft labels from a complex cross attention teacher\nmodel, the performance of claim independent student LSTM or CNN models is\nimproved across all the ranking metrics. The student models we use are 12x\nfaster in runtime and 20x smaller in number of parameters than the teacher", "published": "2019-11-11 21:02:54", "link": "http://arxiv.org/abs/1911.11065v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Unsupervised Training for Deep Speech Source Separation with\n  Kullback-Leibler Divergence Based Probabilistic Loss Function", "abstract": "In this paper, we propose a multi-channel speech source separation with a\ndeep neural network (DNN) which is trained under the condition that no clean\nsignal is available. As an alternative to a clean signal, the proposed method\nadopts an estimated speech signal by an unsupervised speech source separation\nwith a statistical model. As a statistical model of microphone input signal, we\nadopts a time-varying spatial covariance matrix (SCM) model which includes\nreverberation and background noise submodels so as to achieve robustness\nagainst reverberation and background noise. The DNN infers intermediate\nvariables which are needed for constructing the time-varying SCM. Speech source\nseparation is performed in a probabilistic manner so as to avoid overfitting to\nseparation error. Since there are multiple intermediate variables, a loss\nfunction which evaluates a single intermediate variable is not applicable.\nInstead, the proposed method adopts a loss function which evaluates the output\nprobabilistic signal directly based on Kullback-Leibler Divergence (KLD).\nGradient of the loss function can be back-propagated into the DNN through all\nthe intermediate variables. Experimental results under reverberant conditions\nshow that the proposed method can train the DNN efficiently even when the\nnumber of training utterances is small, i.e., 1K.", "published": "2019-11-11 13:12:18", "link": "http://arxiv.org/abs/1911.04228v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Visualizing and Understanding Self-attention based Music Tagging", "abstract": "Recently, we proposed a self-attention based music tagging model. Different\nfrom most of the conventional deep architectures in music information\nretrieval, which use stacked 3x3 filters by treating music spectrograms as\nimages, the proposed self-attention based model attempted to regard music as a\ntemporal sequence of individual audio events. Not only the performance, but it\ncould also facilitate better interpretability. In this paper, we mainly focus\non visualizing and understanding the proposed self-attention based music\ntagging model.", "published": "2019-11-11 16:52:11", "link": "http://arxiv.org/abs/1911.04385v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Feedback Recurrent AutoEncoder", "abstract": "In this work, we propose a new recurrent autoencoder architecture, termed\nFeedback Recurrent AutoEncoder (FRAE), for online compression of sequential\ndata with temporal dependency. The recurrent structure of FRAE is designed to\nefficiently extract the redundancy along the time dimension and allows a\ncompact discrete representation of the data to be learned. We demonstrate its\neffectiveness in speech spectrogram compression. Specifically, we show that the\nFRAE, paired with a powerful neural vocoder, can produce high-quality speech\nwaveforms at a low, fixed bitrate. We further show that by adding a learned\nprior for the latent space and using an entropy coder, we can achieve an even\nlower variable bitrate.", "published": "2019-11-11 00:31:14", "link": "http://arxiv.org/abs/1911.04018v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Generative Autoregressive Networks for 3D Dancing Move Synthesis from\n  Music", "abstract": "This paper proposes a framework which is able to generate a sequence of\nthree-dimensional human dance poses for a given music. The proposed framework\nconsists of three components: a music feature encoder, a pose generator, and a\nmusic genre classifier. We focus on integrating these components for generating\na realistic 3D human dancing move from music, which can be applied to\nartificial agents and humanoid robots. The trained dance pose generator, which\nis a generative autoregressive model, is able to synthesize a dance sequence\nlonger than 5,000 pose frames. Experimental results of generated dance\nsequences from various songs show how the proposed method generates human-like\ndancing move to a given music. In addition, a generated 3D dance sequence is\napplied to a humanoid robot, showing that the proposed framework can make a\nrobot to dance just by listening to music.", "published": "2019-11-11 04:27:22", "link": "http://arxiv.org/abs/1911.04069v1", "categories": ["cs.LG", "cs.RO", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Supervised Initialization of LSTM Networks for Fundamental Frequency\n  Detection in Noisy Speech Signals", "abstract": "Fundamental frequency is one of the most important parameters of human\nspeech, of importance for the classification of accent, gender, speaking\nstyles, speaker identification, age, among others. The proper detection of this\nparameter remains as an important challenge for severely degraded signals. In\nprevious references for detecting fundamental frequency in noisy speech using\ndeep learning, the networks, such as Long Short-term Memory (LSTM) has been\ninitialized with random weights, and then trained following a back-propagation\nthrough time algorithm. In this work, a proposal for a more efficient\ninitialization, based on a supervised training using an Auto-associative\nnetwork, is presented. This initialization is a better starting point for the\ndetection of fundamental frequency in noisy speech. The advantages of this\ninitialization are noticeable using objective measures for the accuracy of the\ndetection and for the training of the networks, under the presence of additive\nwhite noise at different signal-to-noise levels.", "published": "2019-11-11 21:57:29", "link": "http://arxiv.org/abs/1911.04580v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
