{"title": "Building chatbots from large scale domain-specific knowledge bases:\n  challenges and opportunities", "abstract": "Popular conversational agents frameworks such as Alexa Skills Kit (ASK) and\nGoogle Actions (gActions) offer unprecedented opportunities for facilitating\nthe development and deployment of voice-enabled AI solutions in various\nverticals. Nevertheless, understanding user utterances with high accuracy\nremains a challenging task with these frameworks. Particularly, when building\nchatbots with large volume of domain-specific entities. In this paper, we\ndescribe the challenges and lessons learned from building a large scale virtual\nassistant for understanding and responding to equipment-related complaints. In\nthe process, we describe an alternative scalable framework for: 1) extracting\nthe knowledge about equipment components and their associated problem entities\nfrom short texts, and 2) learning to identify such entities in user utterances.\nWe show through evaluation on a real dataset that the proposed framework,\ncompared to off-the-shelf popular ones, scales better with large volume of\nentities being up to 30% more accurate, and is more effective in understanding\nuser utterances with domain-specific entities.", "published": "2019-12-31 22:40:30", "link": "http://arxiv.org/abs/2001.00100v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CASE: Context-Aware Semantic Expansion", "abstract": "In this paper, we define and study a new task called Context-Aware Semantic\nExpansion (CASE). Given a seed term in a sentential context, we aim to suggest\nother terms that well fit the context as the seed. CASE has many interesting\napplications such as query suggestion, computer-assisted writing, and word\nsense disambiguation, to name a few. Previous explorations, if any, only\ninvolve some similar tasks, and all require human annotations for evaluation.\nIn this study, we demonstrate that annotations for this task can be harvested\nat scale from existing corpora, in a fully automatic manner. On a dataset of\n1.8 million sentences thus derived, we propose a network architecture that\nencodes the context and seed term separately before suggesting alternative\nterms. The context encoder in this architecture can be easily extended by\nincorporating seed-aware attention. Our experiments demonstrate that\ncompetitive results are achieved with appropriate choices of context encoder\nand attention scoring function.", "published": "2019-12-31 06:38:57", "link": "http://arxiv.org/abs/1912.13194v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LayoutLM: Pre-training of Text and Layout for Document Image\n  Understanding", "abstract": "Pre-training techniques have been verified successfully in a variety of NLP\ntasks in recent years. Despite the widespread use of pre-training models for\nNLP applications, they almost exclusively focus on text-level manipulation,\nwhile neglecting layout and style information that is vital for document image\nunderstanding. In this paper, we propose the \\textbf{LayoutLM} to jointly model\ninteractions between text and layout information across scanned document\nimages, which is beneficial for a great number of real-world document image\nunderstanding tasks such as information extraction from scanned documents.\nFurthermore, we also leverage image features to incorporate words' visual\ninformation into LayoutLM. To the best of our knowledge, this is the first time\nthat text and layout are jointly learned in a single framework for\ndocument-level pre-training. It achieves new state-of-the-art results in\nseveral downstream tasks, including form understanding (from 70.72 to 79.27),\nreceipt understanding (from 94.02 to 95.24) and document image classification\n(from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly\navailable at \\url{https://aka.ms/layoutlm}.", "published": "2019-12-31 14:31:29", "link": "http://arxiv.org/abs/1912.13318v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OTEANN: Estimating the Transparency of Orthographies with an Artificial\n  Neural Network", "abstract": "To transcribe spoken language to written medium, most alphabets enable an\nunambiguous sound-to-letter rule. However, some writing systems have distanced\nthemselves from this simple concept and little work exists in Natural Language\nProcessing (NLP) on measuring such distance. In this study, we use an\nArtificial Neural Network (ANN) model to evaluate the transparency between\nwritten words and their pronunciation, hence its name Orthographic Transparency\nEstimation with an ANN (OTEANN). Based on datasets derived from Wikimedia\ndictionaries, we trained and tested this model to score the percentage of\ncorrect predictions in phoneme-to-grapheme and grapheme-to-phoneme translation\ntasks. The scores obtained on 17 orthographies were in line with the\nestimations of other studies. Interestingly, the model also provided insight\ninto typical mistakes made by learners who only consider the phonemic rule in\nreading and writing.", "published": "2019-12-31 14:36:45", "link": "http://arxiv.org/abs/1912.13321v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Does My QA Model Know? Devising Controlled Probes using Expert\n  Knowledge", "abstract": "Open-domain question answering (QA) is known to involve several underlying\nknowledge and reasoning challenges, but are models actually learning such\nknowledge when trained on benchmark tasks? To investigate this, we introduce\nseveral new challenge tasks that probe whether state-of-the-art QA models have\ngeneral knowledge about word definitions and general taxonomic reasoning, both\nof which are fundamental to more complex forms of reasoning and are widespread\nin benchmark datasets. As an alternative to expensive crowd-sourcing, we\nintroduce a methodology for automatically building datasets from various types\nof expert knowledge (e.g., knowledge graphs and lexical taxonomies), allowing\nfor systematic control over the resulting probes and for a more comprehensive\nevaluation. We find automatically constructing probes to be vulnerable to\nannotation artifacts, which we carefully control for. Our evaluation confirms\nthat transformer-based QA models are already predisposed to recognize certain\ntypes of structural lexical knowledge. However, it also reveals a more nuanced\npicture: their performance degrades substantially with even a slight increase\nin the number of hops in the underlying taxonomic hierarchy, or as more\nchallenging distractor candidate answers are introduced. Further, even when\nthese models succeed at the standard instance-level evaluation, they leave much\nroom for improvement when assessed at the level of clusters of semantically\nconnected probes (e.g., all Isa questions about a concept).", "published": "2019-12-31 15:05:54", "link": "http://arxiv.org/abs/1912.13337v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Paraphrase Question Generator using Pairwise Discriminator", "abstract": "In this paper, we propose a method for obtaining sentence-level embeddings.\nWhile the problem of securing word-level embeddings is very well studied, we\npropose a novel method for obtaining sentence-level embeddings. This is\nobtained by a simple method in the context of solving the paraphrase generation\ntask. If we use a sequential encoder-decoder model for generating paraphrase,\nwe would like the generated paraphrase to be semantically close to the original\nsentence. One way to ensure this is by adding constraints for true paraphrase\nembeddings to be close and unrelated paraphrase candidate sentence embeddings\nto be far. This is ensured by using a sequential pair-wise discriminator that\nshares weights with the encoder that is trained with a suitable loss function.\nOur loss function penalizes paraphrase sentence embedding distances from being\ntoo large. This loss is used in combination with a sequential encoder-decoder\nnetwork. We also validated our method by evaluating the obtained embeddings for\na sentiment analysis task. The proposed method results in semantic embeddings\nand outperforms the state-of-the-art on the paraphrase generation and sentiment\nanalysis task on standard datasets. These results are also shown to be\nstatistically significant.", "published": "2019-12-31 02:46:29", "link": "http://arxiv.org/abs/1912.13149v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Attentive Ranking Networks for Learning to Order Sentences", "abstract": "We present an attention-based ranking framework for learning to order\nsentences given a paragraph. Our framework is built on a bidirectional sentence\nencoder and a self-attention based transformer network to obtain an input order\ninvariant representation of paragraphs. Moreover, it allows seamless training\nusing a variety of ranking based loss functions, such as pointwise, pairwise,\nand listwise ranking. We apply our framework on two tasks: Sentence Ordering\nand Order Discrimination. Our framework outperforms various state-of-the-art\nmethods on these tasks on a variety of evaluation metrics. We also show that it\nachieves better results when using pairwise and listwise ranking losses, rather\nthan the pointwise ranking loss, which suggests that incorporating relative\npositions of two or more sentences in the loss function contributes to better\nlearning.", "published": "2019-12-31 19:54:27", "link": "http://arxiv.org/abs/2001.00056v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Emergent Behaviors from Folksonomy Driven Interactions", "abstract": "To reflect the evolving knowledge on the Web this paper considers ontologies\nbased on folksonomies according to a new concept structure called\n\"Folksodriven\" to represent folksonomies. This paper describes a research\nprogram for studying Folksodriven tags interactions leading to Folksodriven\ncluster behavior. The goal of the research is to understand the type of simple\nlocal interactions which produce complex and purposive group behaviors on\nFolksodriven tags. We describe a synthetic, bottom-up approach to studying\ngroup behavior, consisting of designing and testing a variety of social\ninteractions and cultural scenarios with Folksodriven tags. We propose a set of\nbasic interactions which can be used to structure and simplify the process of\nboth designing and analyzing emergent group behaviors. The presented behavior\nrepertories was developed and tested on a folksonomy environment.", "published": "2019-12-31 18:33:03", "link": "http://arxiv.org/abs/2001.00569v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.SI", "D.2.2; G.1.10; G.2.2; H.1.1; H.1.2; H.3.1; H.3.3; H.3.5; H.5.2;\n  H.5.3; H.5.4; I.2.1; I.2.4; I.2.7; I.3.6; K.4"], "primary_category": "cs.AI"}
{"title": "A Hybrid Framework for Topic Structure using Laughter Occurrences", "abstract": "Conversational discourse coherence depends on both linguistic and\nparalinguistic phenomena. In this work we combine both paralinguistic and\nlinguistic knowledge into a hybrid framework through a multi-level hierarchy.\nThus it outputs the discourse-level topic structures. The laughter occurrences\nare used as paralinguistic information from the multiparty meeting transcripts\nof ICSI database. A clustering-based algorithm is proposed that chose the best\ntopic-segment cluster from two independent, optimized clusters, namely,\nhierarchical agglomerative clustering and $K$-medoids. Then it is iteratively\nhybridized with an existing lexical cohesion based Bayesian topic segmentation\nframework. The hybrid approach improves the performance of both of the\nstand-alone approaches. This leads to the brief study of interactions between\ntopic structures with discourse relational structure. This training-free topic\nstructuring approach can be applicable to online understanding of spoken\ndialogs.", "published": "2019-12-31 23:31:42", "link": "http://arxiv.org/abs/2001.00573v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "oLMpics -- On what Language Model Pre-training Captures", "abstract": "Recent success of pre-trained language models (LMs) has spurred widespread\ninterest in the language capabilities that they possess. However, efforts to\nunderstand whether LM representations are useful for symbolic reasoning tasks\nhave been limited and scattered. In this work, we propose eight reasoning\ntasks, which conceptually require operations such as comparison, conjunction,\nand composition. A fundamental challenge is to understand whether the\nperformance of a LM on a task should be attributed to the pre-trained\nrepresentations or to the process of fine-tuning on the task data. To address\nthis, we propose an evaluation protocol that includes both zero-shot evaluation\n(no fine-tuning), as well as comparing the learning curve of a fine-tuned LM to\nthe learning curve of multiple controls, which paints a rich picture of the LM\ncapabilities. Our main findings are that: (a) different LMs exhibit\nqualitatively different reasoning abilities, e.g., RoBERTa succeeds in\nreasoning tasks where BERT fails completely; (b) LMs do not reason in an\nabstract manner and are context-dependent, e.g., while RoBERTa can compare\nages, it can do so only when the ages are in the typical range of human ages;\n(c) On half of our reasoning tasks all models fail completely. Our findings and\ninfrastructure can help future work on designing new datasets, models and\nobjective functions for pre-training.", "published": "2019-12-31 12:11:35", "link": "http://arxiv.org/abs/1912.13283v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Essential Sentences for Navigating Stack Overflow Answers", "abstract": "Stack Overflow (SO) has become an essential resource for software\ndevelopment. Despite its success and prevalence, navigating SO remains a\nchallenge. Ideally, SO users could benefit from highlighted navigational cues\nthat help them decide if an answer is relevant to their task and context. Such\nnavigational cues could be in the form of essential sentences that help the\nsearcher decide whether they want to read the answer or skip over it. In this\npaper, we compare four potential approaches for identifying essential\nsentences. We adopt two existing approaches and develop two new approaches\nbased on the idea that contextual information in a sentence (e.g., \"if using\nwindows\") could help identify essential sentences. We compare the four\ntechniques using a survey of 43 participants. Our participants indicate that it\nis not always easy to figure out what the best solution for their specific\nproblem is, given the options, and that they would indeed like to easily spot\ncontextual information that may narrow down the search. Our quantitative\ncomparison of the techniques shows that there is no single technique sufficient\nfor identifying essential sentences that can serve as navigational cues, while\nour qualitative analysis shows that participants valued explanations and\nspecific conditions, and did not value filler sentences or speculations. Our\nwork sheds light on the importance of navigational cues, and our findings can\nbe used to guide future research to find the best combination of techniques to\nidentify such cues.", "published": "2019-12-31 17:52:05", "link": "http://arxiv.org/abs/1912.13455v1", "categories": ["cs.SE", "cs.CL", "cs.IR"], "primary_category": "cs.SE"}
{"title": "Attention-based gated scaling adaptative acoustic model for ctc-based\n  speech recognition", "abstract": "In this paper, we propose a novel adaptive technique that uses an\nattention-based gated scaling (AGS) scheme to improve deep feature learning for\nconnectionist temporal classification (CTC) acoustic modeling. In AGS, the\noutputs of each hidden layer of the main network are scaled by an auxiliary\ngate matrix extracted from the lower layer by using attention mechanisms.\nFurthermore, the auxiliary AGS layer and the main network are jointly trained\nwithout requiring second-pass model training or additional speaker information,\nsuch as speaker code. On the Mandarin AISHELL-1 datasets, the proposed AGS\nyields a 7.94% character error rate (CER). To the best of our knowledge, this\nresult is the best recognition accuracy achieved on this dataset by using an\nend-to-end framework.", "published": "2019-12-31 13:58:58", "link": "http://arxiv.org/abs/1912.13307v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "EEG based Continuous Speech Recognition using Transformers", "abstract": "In this paper we investigate continuous speech recognition using\nelectroencephalography (EEG) features using recently introduced end-to-end\ntransformer based automatic speech recognition (ASR) model. Our results\ndemonstrate that transformer based model demonstrate faster training compared\nto recurrent neural network (RNN) based sequence-to-sequence EEG models and\nbetter performance during inference time for smaller test set vocabulary but as\nwe increase the vocabulary size, the performance of the RNN based models were\nbetter than transformer based model on a limited English vocabulary.", "published": "2019-12-31 08:36:59", "link": "http://arxiv.org/abs/2001.00501v3", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Statistical Models in Forensic Voice Comparison", "abstract": "This chapter describes a number of signal-processing and statistical-modeling\ntechniques that are commonly used to calculate likelihood ratios in\nhuman-supervised automatic approaches to forensic voice comparison. Techniques\ndescribed include mel-frequency cepstral coefficients (MFCCs) feature\nextraction, Gaussian mixture model - universal background model (GMM-UBM)\nsystems, i-vector - probabilistic linear discriminant analysis (i-vector PLDA)\nsystems, deep neural network (DNN) based systems (including senone posterior\ni-vectors, bottleneck features, and embeddings / x-vectors), mismatch\ncompensation, and score-to-likelihood-ratio conversion (aka calibration).\nEmpirical validation of forensic-voice-comparison systems is also covered. The\naim of the chapter is to bridge the gap between general introductions to\nforensic voice comparison and the highly technical\nautomatic-speaker-recognition literature from which the signal-processing and\nstatistical-modeling techniques are mostly drawn. Knowledge of the\nlikelihood-ratio framework for the evaluation of forensic evidence is assumed.\nIt is hoped that the material presented here will be of value to students of\nforensic voice comparison and to researchers interested in learning about\nstatistical modeling techniques that could potentially also be applied to data\nfrom other branches of forensic science.", "published": "2019-12-31 09:45:05", "link": "http://arxiv.org/abs/1912.13242v2", "categories": ["stat.AP", "cs.SD", "eess.AS"], "primary_category": "stat.AP"}
