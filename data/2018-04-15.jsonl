{"title": "The EcoLexicon Semantic Sketch Grammar: from Knowledge Patterns to Word\n  Sketches", "abstract": "Many projects have applied knowledge patterns (KPs) to the retrieval of\nspecialized information. Yet terminologists still rely on manual analysis of\nconcordance lines to extract semantic information, since there are no\nuser-friendly publicly available applications enabling them to find knowledge\nrich contexts (KRCs). To fill this void, we have created the KP-based\nEcoLexicon Semantic SketchGrammar (ESSG) in the well-known corpus query system\nSketch Engine. For the first time, the ESSG is now publicly available inSketch\nEngine to query the EcoLexicon English Corpus. Additionally, reusing the ESSG\nin any English corpus uploaded by the user enables Sketch Engine to extract\nKRCs codifying generic-specific, part-whole, location, cause and function\nrelations, because most of the KPs are domain-independent. The information is\ndisplayed in the form of summary lists (word sketches) containing the pairs of\nterms linked by a given semantic relation. This paper describes the process of\nbuilding a KP-based sketch grammar with special focus on the last stage,\nnamely, the evaluation with refinement purposes. We conducted an initial\nshallow precision and recall evaluation of the 64 English sketch grammar rules\ncreated so far for hyponymy, meronymy and causality. Precision was measured\nbased on a random sample of concordances extracted from each word sketch type.\nRecall was assessed based on a random sample of concordances where known term\npairs are found. The results are necessary for the improvement and refinement\nof the ESSG. The noise of false positives helped to further specify the rules,\nwhereas the silence of false negatives allows us to find useful new patterns.", "published": "2018-04-15 02:21:28", "link": "http://arxiv.org/abs/1804.05294v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Introducing two Vietnamese Datasets for Evaluating Semantic Models of\n  (Dis-)Similarity and Relatedness", "abstract": "We present two novel datasets for the low-resource language Vietnamese to\nassess models of semantic similarity: ViCon comprises pairs of synonyms and\nantonyms across word classes, thus offering data to distinguish between\nsimilarity and dissimilarity. ViSim-400 provides degrees of similarity across\nfive semantic relations, as rated by human judges. The two datasets are\nverified through standard co-occurrence and neural network models, showing\nresults comparable to the respective English datasets.", "published": "2018-04-15 17:38:16", "link": "http://arxiv.org/abs/1804.05388v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Higher-order Coreference Resolution with Coarse-to-fine Inference", "abstract": "We introduce a fully differentiable approximation to higher-order inference\nfor coreference resolution. Our approach uses the antecedent distribution from\na span-ranking architecture as an attention mechanism to iteratively refine\nspan representations. This enables the model to softly consider multiple hops\nin the predicted clusters. To alleviate the computational cost of this\niterative process, we introduce a coarse-to-fine approach that incorporates a\nless accurate but more efficient bilinear factor, enabling more aggressive\npruning without hurting accuracy. Compared to the existing state-of-the-art\nspan-ranking approach, our model significantly improves accuracy on the English\nOntoNotes benchmark, while being far more computationally efficient.", "published": "2018-04-15 17:47:26", "link": "http://arxiv.org/abs/1804.05392v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context and Humor: Understanding Amul advertisements of India", "abstract": "Contextual knowledge is the most important element in understanding language.\nBy contextual knowledge we mean both general knowledge and discourse knowledge\ni.e. knowledge of the situational context, background knowledge and the\nco-textual context [10]. In this paper, we will discuss the importance of\ncontextual knowledge in understanding the humor present in the cartoon based\nAmul advertisements in India.In the process, we will analyze these\nadvertisements and also see if humor is an effective tool for advertising and\nthereby, for marketing.These bilingual advertisements also expect the audience\nto have the appropriate linguistic knowledge which includes knowledge of\nEnglish and Hindi vocabulary, morphology and syntax. Different techniques like\npunning, portmanteaus and parodies of popular proverbs, expressions, acronyms,\nfamous dialogues, songs etc are employed to convey the message in a humorous\nway. The present study will concentrate on these linguistic cues and the\nrequired context for understanding wit and humor.", "published": "2018-04-15 18:00:53", "link": "http://arxiv.org/abs/1804.05398v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GU IRLAB at SemEval-2018 Task 7: Tree-LSTMs for Scientific Relation\n  Classification", "abstract": "SemEval 2018 Task 7 focuses on relation ex- traction and classification in\nscientific literature. In this work, we present our tree-based LSTM network for\nthis shared task. Our approach placed 9th (of 28) for subtask 1.1 (relation\nclassification), and 5th (of 20) for subtask 1.2 (relation classification with\nnoisy entities). We also provide an ablation study of features included as\ninput to the network.", "published": "2018-04-15 19:02:13", "link": "http://arxiv.org/abs/1804.05408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Automatic Methods for Cognate Detection Good Enough for Phylogenetic\n  Reconstruction in Historical Linguistics?", "abstract": "We evaluate the performance of state-of-the-art algorithms for automatic\ncognate detection by comparing how useful automatically inferred cognates are\nfor the task of phylogenetic inference compared to classical manually annotated\ncognate sets. Our findings suggest that phylogenies inferred from automated\ncognate sets come close to phylogenies inferred from expert-annotated ones,\nalthough on average, the latter are still superior. We conclude that future\nwork on phylogenetic reconstruction can profit much from automatic cognate\ndetection. Especially where scholars are merely interested in exploring the\nbigger picture of a language family's phylogeny, algorithms for automatic\ncognate detection are a useful complement for current research on language\nphylogenies.", "published": "2018-04-15 19:45:07", "link": "http://arxiv.org/abs/1804.05416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pragmatically Informative Image Captioning with Character-Level\n  Inference", "abstract": "We combine a neural image captioner with a Rational Speech Acts (RSA) model\nto make a system that is pragmatically informative: its objective is to produce\ncaptions that are not merely true but also distinguish their inputs from\nsimilar images. Previous attempts to combine RSA with neural image captioning\nrequire an inference which normalizes over the entire set of possible\nutterances. This poses a serious problem of efficiency, previously solved by\nsampling a small subset of possible utterances. We instead solve this problem\nby implementing a version of RSA which operates at the level of characters\n(\"a\",\"b\",\"c\"...) during the unrolling of the caption. We find that the\nutterance-level effect of referential captions can be obtained with only\ncharacter-level decisions. Finally, we introduce an automatic method for\ntesting the performance of pragmatic speaker models, and show that our model\noutperforms a non-pragmatic baseline as well as a word-level RSA captioner.", "published": "2018-04-15 19:55:13", "link": "http://arxiv.org/abs/1804.05417v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Happened? Leveraging VerbNet to Predict the Effects of Actions in\n  Procedural Text", "abstract": "Our goal is to answer questions about paragraphs describing processes (e.g.,\nphotosynthesis). Texts of this genre are challenging because the effects of\nactions are often implicit (unstated), requiring background knowledge and\ninference to reason about the changing world states. To supply this knowledge,\nwe leverage VerbNet to build a rulebase (called the Semantic Lexicon) of the\npreconditions and effects of actions, and use it along with commonsense\nknowledge of persistence to answer questions about change. Our evaluation shows\nthat our system, ProComp, significantly outperforms two strong reading\ncomprehension (RC) baselines. Our contributions are two-fold: the Semantic\nLexicon rulebase itself, and a demonstration of how a simulation-based approach\nto machine reading can outperform RC methods that rely on surface cues alone.\n  Since this work was performed, we have developed neural systems that\noutperform ProComp, described elsewhere (Dalvi et al., NAACL'18). However, the\nSemantic Lexicon remains a novel and potentially useful resource, and its\nintegration with neural systems remains a currently unexplored opportunity for\nfurther improvements in machine reading about processes.", "published": "2018-04-15 21:48:28", "link": "http://arxiv.org/abs/1804.05435v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transcribing Lyrics From Commercial Song Audio: The First Step Towards\n  Singing Content Processing", "abstract": "Spoken content processing (such as retrieval and browsing) is maturing, but\nthe singing content is still almost completely left out. Songs are human voice\ncarrying plenty of semantic information just as speech, and may be considered\nas a special type of speech with highly flexible prosody. The various problems\nin song audio, for example the significantly changing phone duration over\nhighly flexible pitch contours, make the recognition of lyrics from song audio\nmuch more difficult. This paper reports an initial attempt towards this goal.\nWe collected music-removed version of English songs directly from commercial\nsinging content. The best results were obtained by TDNN-LSTM with data\naugmentation with 3-fold speed perturbation plus some special approaches. The\nWER achieved (73.90%) was significantly lower than the baseline (96.21%), but\nstill relatively high.", "published": "2018-04-15 05:50:27", "link": "http://arxiv.org/abs/1804.05306v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal\n  Attentions for Video Captioning", "abstract": "A major challenge for video captioning is to combine audio and visual cues.\nExisting multi-modal fusion methods have shown encouraging results in video\nunderstanding. However, the temporal structures of multiple modalities at\ndifferent granularities are rarely explored, and how to selectively fuse the\nmulti-modal representations at different levels of details remains uncharted.\nIn this paper, we propose a novel hierarchically aligned cross-modal attention\n(HACA) framework to learn and selectively fuse both global and local temporal\ndynamics of different modalities. Furthermore, for the first time, we validate\nthe superior performance of the deep audio features on the video captioning\ntask. Finally, our HACA model significantly outperforms the previous best\nsystems and achieves new state-of-the-art results on the widely used MSR-VTT\ndataset.", "published": "2018-04-15 23:04:57", "link": "http://arxiv.org/abs/1804.05448v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Twin Regularization for online speech recognition", "abstract": "Online speech recognition is crucial for developing natural human-machine\ninterfaces. This modality, however, is significantly more challenging than\noff-line ASR, since real-time/low-latency constraints inevitably hinder the use\nof future information, that is known to be very helpful to perform robust\npredictions. A popular solution to mitigate this issue consists of feeding\nneural acoustic models with context windows that gather some future frames.\nThis introduces a latency which depends on the number of employed look-ahead\nfeatures. This paper explores a different approach, based on estimating the\nfuture rather than waiting for it. Our technique encourages the hidden\nrepresentations of a unidirectional recurrent network to embed some useful\ninformation about the future. Inspired by a recently proposed technique called\nTwin Networks, we add a regularization term that forces forward hidden states\nto be as close as possible to cotemporal backward ones, computed by a \"twin\"\nneural network running backwards in time. The experiments, conducted on a\nnumber of datasets, recurrent architectures, input features, and acoustic\nconditions, have shown the effectiveness of this approach. One important\nadvantage is that our method does not introduce any additional computation at\ntest time if compared to standard unidirectional recurrent networks.", "published": "2018-04-15 15:52:16", "link": "http://arxiv.org/abs/1804.05374v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "eess.AS"}
