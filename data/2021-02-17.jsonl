{"title": "A Context-Enhanced De-identification System", "abstract": "Many modern entity recognition systems, including the current\nstate-of-the-art de-identification systems, are based on bidirectional long\nshort-term memory (biLSTM) units augmented by a conditional random field (CRF)\nsequence optimizer. These systems process the input sentence by sentence. This\napproach prevents the systems from capturing dependencies over sentence\nboundaries and makes accurate sentence boundary detection a prerequisite. Since\nsentence boundary detection can be problematic especially in clinical reports,\nwhere dependencies and co-references across sentence boundaries are abundant,\nthese systems have clear limitations. In this study, we built a new system on\nthe framework of one of the current state-of-the-art de-identification systems,\nNeuroNER, to overcome these limitations. This new system incorporates context\nembeddings through forward and backward n-grams without using sentence\nboundaries. Our context-enhanced de-identification (CEDI) system captures\ndependencies over sentence boundaries and bypasses the sentence boundary\ndetection problem altogether. We enhanced this system with deep affix features\nand an attention mechanism to capture the pertinent parts of the input. The\nCEDI system outperforms NeuroNER on the 2006 i2b2 de-identification challenge\ndataset, the 2014 i2b2 shared task de-identification dataset, and the 2016 CEGS\nN-GRID de-identification dataset (p<0.01). All datasets comprise narrative\nclinical reports in English but contain different note types varying from\ndischarge summaries to psychiatric notes. Enhancing CEDI with deep affix\nfeatures and the attention mechanism further increased performance.", "published": "2021-02-17 00:43:37", "link": "http://arxiv.org/abs/2102.08513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "First Target and Opinion then Polarity: Enhancing Target-opinion\n  Correlation for Aspect Sentiment Triplet Extraction", "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract triplets from a\nsentence, including target entities, associated sentiment polarities, and\nopinion spans which rationalize the polarities. Existing methods are short on\nbuilding correlation between target-opinion pairs, and neglect the mutual\ninterference among different sentiment triplets. To address these issues, we\nutilize a two-stage framework to enhance the correlation between targets and\nopinions: at stage one, we extract targets and opinions through sequence\ntagging; then we append a group of artificial tags named Perceivable Pair,\nwhich indicate the span of a specific target-opinion tuple, to the input\nsentence to obtain closer correlated target-opinion pair representation.\nMeanwhile, we reduce the negative interference between triplets by restricting\ntokens' attention field. Finally, the polarity is identified according to the\nrepresentation of the Perceivable Pair. We conduct experiments on four\ndatasets, and the experimental results show the effectiveness of our model.", "published": "2021-02-17 03:28:17", "link": "http://arxiv.org/abs/2102.08549v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoding EEG Brain Activity for Multi-Modal Natural Language Processing", "abstract": "Until recently, human behavioral data from reading has mainly been of\ninterest to researchers to understand human cognition. However, these human\nlanguage processing signals can also be beneficial in machine learning-based\nnatural language processing tasks. Using EEG brain activity to this purpose is\nlargely unexplored as of yet. In this paper, we present the first large-scale\nstudy of systematically analyzing the potential of EEG brain activity data for\nimproving natural language processing tasks, with a special focus on which\nfeatures of the signal are most beneficial. We present a multi-modal machine\nlearning architecture that learns jointly from textual input as well as from\nEEG features. We find that filtering the EEG signals into frequency bands is\nmore beneficial than using the broadband signal. Moreover, for a range of word\nembedding types, EEG data improves binary and ternary sentiment classification\nand outperforms multiple baselines. For more complex tasks such as relation\ndetection, further research is needed. Finally, EEG data shows to be\nparticularly promising when limited training data is available.", "published": "2021-02-17 09:44:21", "link": "http://arxiv.org/abs/2102.08655v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting Lexical Complexity in English Texts: The Complex 2.0 Dataset", "abstract": "Identifying words which may cause difficulty for a reader is an essential\nstep in most lexical text simplification systems prior to lexical substitution\nand can also be used for assessing the readability of a text. This task is\ncommonly referred to as Complex Word Identification (CWI) and is often modelled\nas a supervised classification problem. For training such systems, annotated\ndatasets in which words and sometimes multi-word expressions are labelled\nregarding complexity are required. In this paper we analyze previous work\ncarried out in this task and investigate the properties of CWI datasets for\nEnglish. We develop a protocol for the annotation of lexical complexity and use\nthis to annotate a new dataset, CompLex 2.0. We present experiments using both\nnew and old datasets to investigate the nature of lexical complexity. We found\nthat a Likert-scale annotation protocol provides an objective setting that is\nsuperior for identifying the complexity of words compared to a binary\nannotation protocol. We release a new dataset using our new protocol to promote\nthe task of Lexical Complexity Prediction.", "published": "2021-02-17 14:05:30", "link": "http://arxiv.org/abs/2102.08773v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SciDr at SDU-2020: IDEAS -- Identifying and Disambiguating Everyday\n  Acronyms for Scientific Domain", "abstract": "We present our systems submitted for the shared tasks of Acronym\nIdentification (AI) and Acronym Disambiguation (AD) held under Workshop on SDU.\nWe mainly experiment with BERT and SciBERT. In addition, we assess the\neffectiveness of \"BIOless\" tagging and blending along with the prowess of\nensembling in AI. For AD, we formulate the problem as a span prediction task,\nexperiment with different training techniques and also leverage the use of\nexternal data. Our systems rank 11th and 3rd in AI and AD tasks respectively.", "published": "2021-02-17 15:24:50", "link": "http://arxiv.org/abs/2102.08818v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metrical Tagging in the Wild: Building and Annotating Poetry Corpora\n  with Rhythmic Features", "abstract": "A prerequisite for the computational study of literature is the availability\nof properly digitized texts, ideally with reliable meta-data and ground-truth\nannotation. Poetry corpora do exist for a number of languages, but larger\ncollections lack consistency and are encoded in various standards, while\nannotated corpora are typically constrained to a particular genre and/or were\ndesigned for the analysis of certain linguistic features (like rhyme). In this\nwork, we provide large poetry corpora for English and German, and annotate\nprosodic features in smaller corpora to train corpus driven neural models that\nenable robust large scale analysis.\n  We show that BiLSTM-CRF models with syllable embeddings outperform a CRF\nbaseline and different BERT-based approaches. In a multi-task setup, particular\nbeneficial task relations illustrate the inter-dependence of poetic features. A\nmodel learns foot boundaries better when jointly predicting syllable stress,\naesthetic emotions and verse measures benefit from each other, and we find that\ncaesuras are quite dependent on syntax and also integral to shaping the overall\nmeasure of the line.", "published": "2021-02-17 16:38:57", "link": "http://arxiv.org/abs/2102.08858v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards generalisable hate speech detection: a review on obstacles and\n  solutions", "abstract": "Hate speech is one type of harmful online content which directly attacks or\npromotes hate towards a group or an individual member based on their actual or\nperceived aspects of identity, such as ethnicity, religion, and sexual\norientation. With online hate speech on the rise, its automatic detection as a\nnatural language processing task is gaining increasing interest. However, it is\nonly recently that it has been shown that existing models generalise poorly to\nunseen data. This survey paper attempts to summarise how generalisable existing\nhate speech detection models are, reason why hate speech models struggle to\ngeneralise, sums up existing attempts at addressing the main obstacles, and\nthen proposes directions of future research to improve generalisation in hate\nspeech detection.", "published": "2021-02-17 17:27:48", "link": "http://arxiv.org/abs/2102.08886v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Performance of Automatic De-identification Across Different Note Types", "abstract": "Free-text clinical notes detail all aspects of patient care and have great\npotential to facilitate quality improvement and assurance initiatives as well\nas advance clinical research. However, concerns about patient privacy and\nconfidentiality limit the use of clinical notes for research. As a result, the\ninformation documented in these notes remains unavailable for most researchers.\nDe-identification (de-id), i.e., locating and removing personally identifying\nprotected health information (PHI), is one way of improving access to clinical\nnarratives. However, there are limited off-the-shelf de-identification systems\nable to consistently detect PHI across different data sources and medical\nspecialties. In this abstract, we present the performance of a state-of-the art\nde-id system called NeuroNER1 on a diverse set of notes from University of\nWashington (UW) when the models are trained on data from an external\ninstitution (Partners Healthcare) vs. from the same institution (UW). We\npresent results at the level of PHI and note types.", "published": "2021-02-17 00:55:40", "link": "http://arxiv.org/abs/2102.11032v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IFoodCloud: A Platform for Real-time Sentiment Analysis of Public\n  Opinion about Food Safety in China", "abstract": "The Internet contains a wealth of public opinion on food safety, including\nviews on food adulteration, food-borne diseases, agricultural pollution,\nirregular food distribution, and food production issues. In order to\nsystematically collect and analyse public opinion on food safety, we developed\nIFoodCloud, a platform for the real-time sentiment analysis of public opinion\non food safety in China. It collects data from more than 3,100 public sources\nthat can be used to explore public opinion trends, public sentiment, and\nregional attention differences of food safety incidents. At the same time, we\nconstructed a sentiment classification model using multiple lexicon-based and\ndeep learning-based algorithms integrated with IFoodCloud that provide an\nunprecedented rapid means of understanding the public sentiment toward specific\nfood safety incidents. Our best model's F1-score achieved 0.9737. Further,\nthree real-world cases are presented to demonstrate the application and\nrobustness. IFoodCloud could be considered a valuable tool for promote\nscientisation of food safety supervision and risk communication.", "published": "2021-02-17 04:42:33", "link": "http://arxiv.org/abs/2102.11033v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Pre-trained Model into Rule-based Dialogue Management", "abstract": "Rule-based dialogue management is still the most popular solution for\nindustrial task-oriented dialogue systems for their interpretablility. However,\nit is hard for developers to maintain the dialogue logic when the scenarios get\nmore and more complex. On the other hand, data-driven dialogue systems, usually\nwith end-to-end structures, are popular in academic research and easier to deal\nwith complex conversations, but such methods require plenty of training data\nand the behaviors are less interpretable. In this paper, we propose a method to\nleverages the strength of both rule-based and data-driven dialogue managers\n(DM). We firstly introduce the DM of Carina Dialog System (CDS, an advanced\nindustrial dialogue system built by Microsoft). Then we propose the\n\"model-trigger\" design to make the DM trainable thus scalable to scenario\nchanges. Furthermore, we integrate pre-trained models and empower the DM with\nfew-shot capability. The experimental results demonstrate the effectiveness and\nstrong few-shot capability of our method.", "published": "2021-02-17 03:44:22", "link": "http://arxiv.org/abs/2102.08553v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contextual Skipgram: Training Word Representation Using Context\n  Information", "abstract": "The skip-gram (SG) model learns word representation by predicting the words\nsurrounding a center word from unstructured text data. However, not all words\nin the context window contribute to the meaning of the center word. For\nexample, less relevant words could be in the context window, hindering the SG\nmodel from learning a better quality representation. In this paper, we propose\nan enhanced version of the SG that leverages context information to produce\nword representation. The proposed model, Contextual Skip-gram, is designed to\npredict contextual words with both the center words and the context\ninformation. This simple idea helps to reduce the impact of irrelevant words on\nthe training process, thus enhancing the final performance", "published": "2021-02-17 04:19:56", "link": "http://arxiv.org/abs/2102.08565v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Faithfulness in Open Domain Table-to-text Generation from an\n  Entity-centric View", "abstract": "In open domain table-to-text generation, we notice that the unfaithful\ngeneration usually contains hallucinated content which can not be aligned to\nany input table record. We thus try to evaluate the generation faithfulness\nwith two entity-centric metrics: table record coverage and the ratio of\nhallucinated entities in text, both of which are shown to have strong agreement\nwith human judgements. Then based on these metrics, we quantitatively analyze\nthe correlation between training data quality and generation fidelity which\nindicates the potential usage of entity information in faithful generation.\nMotivated by these findings, we propose two methods for faithful generation: 1)\naugmented training by incorporating the auxiliary entity information, including\nboth an augmented plan-based model and an unsupervised model and 2) training\ninstance selection based on faithfulness ranking. We show these approaches\nimprove generation fidelity in both full dataset setting and few shot learning\nsettings by both automatic and human evaluations.", "published": "2021-02-17 05:41:06", "link": "http://arxiv.org/abs/2102.08585v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Query Resolution and Reading Comprehension for Conversational\n  Passage Retrieval", "abstract": "This paper describes the participation of UvA.ILPS group at the TREC CAsT\n2020 track. Our passage retrieval pipeline consists of (i) an initial retrieval\nmodule that uses BM25, and (ii) a re-ranking module that combines the score of\na BERT ranking model with the score of a machine comprehension model adjusted\nfor passage retrieval. An important challenge in conversational passage\nretrieval is that queries are often under-specified. Thus, we perform query\nresolution, that is, add missing context from the conversation history to the\ncurrent turn query using QuReTeC, a term classification query resolution model.\nWe show that our best automatic and manual runs outperform the corresponding\nmedian runs by a large margin.", "published": "2021-02-17 14:41:57", "link": "http://arxiv.org/abs/2102.08795v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "THEaiTRE 1.0: Interactive generation of theatre play scripts", "abstract": "We present the first version of a system for interactive generation of\ntheatre play scripts. The system is based on a vanilla GPT-2 model with several\nadjustments, targeting specific issues we encountered in practice. We also list\nother issues we encountered but plan to only solve in a future version of the\nsystem. The presented system was used to generate a theatre play script planned\nfor premiere in February 2021.", "published": "2021-02-17 17:40:33", "link": "http://arxiv.org/abs/2102.08892v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection", "abstract": "As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.", "published": "2021-02-17 18:30:43", "link": "http://arxiv.org/abs/2102.08924v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sparsely Factored Neural Machine Translation", "abstract": "The standard approach to incorporate linguistic information to neural machine\ntranslation systems consists in maintaining separate vocabularies for each of\nthe annotated features to be incorporated (e.g. POS tags, dependency relation\nlabel), embed them, and then aggregate them with each subword in the word they\nbelong to. This approach, however, cannot easily accommodate annotation schemes\nthat are not dense for every word.\n  We propose a method suited for such a case, showing large improvements in\nout-of-domain data, and comparable quality for the in-domain data. Experiments\nare performed in morphologically-rich languages like Basque and German, for the\ncase of low-resource scenarios.", "published": "2021-02-17 18:42:00", "link": "http://arxiv.org/abs/2102.08934v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize\n  Long-Tail Visual Concepts", "abstract": "The availability of large-scale image captioning and visual question\nanswering datasets has contributed significantly to recent successes in\nvision-and-language pre-training. However, these datasets are often collected\nwith overrestrictive requirements inherited from their original target tasks\n(e.g., image caption generation), which limit the resulting dataset scale and\ndiversity. We take a step further in pushing the limits of vision-and-language\npre-training data by relaxing the data collection pipeline used in Conceptual\nCaptions 3M (CC3M) [Sharma et al. 2018] and introduce the Conceptual 12M\n(CC12M), a dataset with 12 million image-text pairs specifically meant to be\nused for vision-and-language pre-training. We perform an analysis of this\ndataset and benchmark its effectiveness against CC3M on multiple downstream\ntasks with an emphasis on long-tail visual recognition. Our results clearly\nillustrate the benefit of scaling up pre-training data for vision-and-language\ntasks, as indicated by the new state-of-the-art results on both the nocaps and\nConceptual Captions benchmarks.", "published": "2021-02-17 19:15:53", "link": "http://arxiv.org/abs/2102.08981v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Jointly Learning Clinical Entities and Relations with Contextual\n  Language Models and Explicit Context", "abstract": "We hypothesize that explicit integration of contextual information into an\nMulti-task Learning framework would emphasize the significance of context for\nboosting performance in jointly learning Named Entity Recognition (NER) and\nRelation Extraction (RE). Our work proves this hypothesis by segmenting\nentities from their surrounding context and by building contextual\nrepresentations using each independent segment. This relation representation\nallows for a joint NER/RE system that achieves near state-of-the-art (SOTA)\nperformance on both NER and RE tasks while beating the SOTA RE system at\nend-to-end NER & RE with a 49.07 F1.", "published": "2021-02-17 00:06:58", "link": "http://arxiv.org/abs/2102.11031v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Highly Fast Text Segmentation With Pairwise Markov Chains", "abstract": "Natural Language Processing (NLP) models' current trend consists of using\nincreasingly more extra-data to build the best models as possible. It implies\nmore expensive computational costs and training time, difficulties for\ndeployment, and worries about these models' carbon footprint reveal a critical\nproblem in the future. Against this trend, our goal is to develop NLP models\nrequiring no extra-data and minimizing training time. To do so, in this paper,\nwe explore Markov chain models, Hidden Markov Chain (HMC) and Pairwise Markov\nChain (PMC), for NLP segmentation tasks. We apply these models for three\nclassic applications: POS Tagging, Named-Entity-Recognition, and Chunking. We\ndevelop an original method to adapt these models for text segmentation's\nspecific challenges to obtain relevant performances with very short training\nand execution times. PMC achieves equivalent results to those obtained by\nConditional Random Fields (CRF), one of the most applied models for these tasks\nwhen no extra-data are used. Moreover, PMC has training times 30 times shorter\nthan the CRF ones, which validates this model given our objectives.", "published": "2021-02-17 20:08:57", "link": "http://arxiv.org/abs/2102.11037v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Introducing the Hidden Neural Markov Chain framework", "abstract": "Nowadays, neural network models achieve state-of-the-art results in many\nareas as computer vision or speech processing. For sequential data, especially\nfor Natural Language Processing (NLP) tasks, Recurrent Neural Networks (RNNs)\nand their extensions, the Long Short Term Memory (LSTM) network and the Gated\nRecurrent Unit (GRU), are among the most used models, having a \"term-to-term\"\nsequence processing. However, if many works create extensions and improvements\nof the RNN, few have focused on developing other ways for sequential data\nprocessing with neural networks in a \"term-to-term\" way. This paper proposes\nthe original Hidden Neural Markov Chain (HNMC) framework, a new family of\nsequential neural models. They are not based on the RNN but on the Hidden\nMarkov Model (HMM), a probabilistic graphical model. This neural extension is\npossible thanks to the recent Entropic Forward-Backward algorithm for HMM\nrestoration. We propose three different models: the classic HNMC, the HNMC2,\nand the HNMC-CN. After describing our models' whole construction, we compare\nthem with classic RNN and Bidirectional RNN (BiRNN) models for some sequence\nlabeling tasks: Chunking, Part-Of-Speech Tagging, and Named Entity Recognition.\nFor every experiment, whatever the architecture or the embedding method used,\none of our proposed models has the best results. It shows this new neural\nsequential framework's potential, which can open the way to new models, and\nmight eventually compete with the prevalent BiLSTM and BiGRU.", "published": "2021-02-17 20:13:45", "link": "http://arxiv.org/abs/2102.11038v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transferability of Neural Network Clinical De-identification Systems", "abstract": "Objective: Neural network de-identification studies have focused on\nindividual datasets. These studies assume the availability of a sufficient\namount of human-annotated data to train models that can generalize to\ncorresponding test data. In real-world situations, however, researchers often\nhave limited or no in-house training data. Existing systems and external data\ncan help jump-start de-identification on in-house data; however, the most\nefficient way of utilizing existing systems and external data is unclear. This\narticle investigates the transferability of a state-of-the-art neural clinical\nde-identification system, NeuroNER, across a variety of datasets, when it is\nmodified architecturally for domain generalization and when it is trained\nstrategically for domain transfer. Methods and Materials: We conducted a\ncomparative study of the transferability of NeuroNER using four clinical note\ncorpora with multiple note types from two institutions. We modified NeuroNER\narchitecturally to integrate two types of domain generalization approaches. We\nevaluated each architecture using three training strategies. We measured:\ntransferability from external sources; transferability across note types; the\ncontribution of external source data when in-domain training data are\navailable; and transferability across institutions. Results and Conclusions:\nTransferability from a single external source gave inconsistent results. Using\nadditional external sources consistently yielded an F1-score of approximately\n80%. Fine-tuning emerged as a dominant transfer strategy, with or without\ndomain generalization. We also found that external sources were useful even in\ncases where in-domain training data were available. Transferability across\ninstitutions differed by note type and annotation label but resulted in\nimproved performance.", "published": "2021-02-17 00:49:34", "link": "http://arxiv.org/abs/2102.08517v3", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ATCSpeechNet: A multilingual end-to-end speech recognition framework for\n  air traffic control systems", "abstract": "In this paper, a multilingual end-to-end framework, called as ATCSpeechNet,\nis proposed to tackle the issue of translating communication speech into\nhuman-readable text in air traffic control (ATC) systems. In the proposed\nframework, we focus on integrating the multilingual automatic speech\nrecognition (ASR) into one model, in which an end-to-end paradigm is developed\nto convert speech waveform into text directly, without any feature engineering\nor lexicon. In order to make up for the deficiency of the handcrafted feature\nengineering caused by ATC challenges, a speech representation learning (SRL)\nnetwork is proposed to capture robust and discriminative speech representations\nfrom the raw wave. The self-supervised training strategy is adopted to optimize\nthe SRL network from unlabeled data, and further to predict the speech\nfeatures, i.e., wave-to-feature. An end-to-end architecture is improved to\ncomplete the ASR task, in which a grapheme-based modeling unit is applied to\naddress the multilingual ASR issue. Facing the problem of small transcribed\nsamples in the ATC domain, an unsupervised approach with mask prediction is\napplied to pre-train the backbone network of the ASR model on unlabeled data by\na feature-to-feature process. Finally, by integrating the SRL with ASR, an\nend-to-end multilingual ASR framework is formulated in a supervised manner,\nwhich is able to translate the raw wave into text in one model, i.e.,\nwave-to-text. Experimental results on the ATCSpeech corpus demonstrate that the\nproposed approach achieves a high performance with a very small labeled corpus\nand less resource consumption, only 4.20% label error rate on the 58-hour\ntranscribed corpus. Compared to the baseline model, the proposed approach\nobtains over 100% relative performance improvement which can be further\nenhanced with the increasing of the size of the transcribed samples.", "published": "2021-02-17 02:27:09", "link": "http://arxiv.org/abs/2102.08535v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Beyond Fully-Connected Layers with Quaternions: Parameterization of\n  Hypercomplex Multiplications with $1/n$ Parameters", "abstract": "Recent works have demonstrated reasonable success of representation learning\nin hypercomplex space. Specifically, \"fully-connected layers with Quaternions\"\n(4D hypercomplex numbers), which replace real-valued matrix multiplications in\nfully-connected layers with Hamilton products of Quaternions, both enjoy\nparameter savings with only 1/4 learnable parameters and achieve comparable\nperformance in various applications. However, one key caveat is that\nhypercomplex space only exists at very few predefined dimensions (4D, 8D, and\n16D). This restricts the flexibility of models that leverage hypercomplex\nmultiplications. To this end, we propose parameterizing hypercomplex\nmultiplications, allowing models to learn multiplication rules from data\nregardless of whether such rules are predefined. As a result, our method not\nonly subsumes the Hamilton product, but also learns to operate on any arbitrary\nnD hypercomplex space, providing more architectural flexibility using\narbitrarily $1/n$ learnable parameters compared with the fully-connected layer\ncounterpart. Experiments of applications to the LSTM and Transformer models on\nnatural language inference, machine translation, text style transfer, and\nsubject verb agreement demonstrate architectural flexibility and effectiveness\nof the proposed approach.", "published": "2021-02-17 06:16:58", "link": "http://arxiv.org/abs/2102.08597v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Open-Retrieval Conversational Machine Reading", "abstract": "In conversational machine reading, systems need to interpret natural language\nrules, answer high-level questions such as \"May I qualify for VA health care\nbenefits?\", and ask follow-up clarification questions whose answer is necessary\nto answer the original question. However, existing works assume the rule text\nis provided for each user question, which neglects the essential retrieval step\nin real scenarios. In this work, we propose and investigate an open-retrieval\nsetting of conversational machine reading. In the open-retrieval setting, the\nrelevant rule texts are unknown so that a system needs to retrieve\nquestion-relevant evidence from a collection of rule texts, and answer users'\nhigh-level questions according to multiple retrieved rule texts in a\nconversational manner. We propose MUDERN, a Multi-passage Discourse-aware\nEntailment Reasoning Network which extracts conditions in the rule texts\nthrough discourse segmentation, conducts multi-passage entailment reasoning to\nanswer user questions directly, or asks clarification follow-up questions to\ninquiry more information. On our created OR-ShARC dataset, MUDERN achieves the\nstate-of-the-art performance, outperforming existing single-passage\nconversational machine reading models as well as a new multi-passage\nconversational machine reading baseline by a large margin. In addition, we\nconduct in-depth analyses to provide new insights into this new setting and our\nmodel.", "published": "2021-02-17 08:55:01", "link": "http://arxiv.org/abs/2102.08633v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Visual Models using a Knowledge Graph as a Trainer", "abstract": "Traditional computer vision approaches, based on neural networks (NN), are\ntypically trained on a large amount of image data. By minimizing the\ncross-entropy loss between a prediction and a given class label, the NN and its\nvisual embedding space are learned to fulfill a given task. However, due to the\nsole dependence on the image data distribution of the training domain, these\nmodels tend to fail when applied to a target domain that differs from their\nsource domain. To learn a more robust NN to domain shifts, we propose the\nknowledge graph neural network (KG-NN), a neuro-symbolic approach that\nsupervises the training using image-data-invariant auxiliary knowledge. The\nauxiliary knowledge is first encoded in a knowledge graph with respective\nconcepts and their relationships, which is then transformed into a dense vector\nrepresentation via an embedding method. Using a contrastive loss function,\nKG-NN learns to adapt its visual embedding space and thus its weights according\nto the image-data invariant knowledge graph embedding space. We evaluate KG-NN\non visual transfer learning tasks for classification using the mini-ImageNet\ndataset and its derivatives, as well as road sign recognition datasets from\nGermany and China. The results show that a visual model trained with a\nknowledge graph as a trainer outperforms a model trained with cross-entropy in\nall experiments, in particular when the domain gap increases. Besides better\nperformance and stronger robustness to domain shifts, these KG-NN adapts to\nmultiple datasets and classes without suffering heavily from catastrophic\nforgetting.", "published": "2021-02-17 13:24:41", "link": "http://arxiv.org/abs/2102.08747v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Few-shot Conformal Prediction with Auxiliary Tasks", "abstract": "We develop a novel approach to conformal prediction when the target task has\nlimited data available for training. Conformal prediction identifies a small\nset of promising output candidates in place of a single prediction, with\nguarantees that the set contains the correct answer with high probability. When\ntraining data is limited, however, the predicted set can easily become unusably\nlarge. In this work, we obtain substantially tighter prediction sets while\nmaintaining desirable marginal guarantees by casting conformal prediction as a\nmeta-learning paradigm over exchangeable collections of auxiliary tasks. Our\nconformalization algorithm is simple, fast, and agnostic to the choice of\nunderlying model, learning algorithm, or dataset. We demonstrate the\neffectiveness of this approach across a number of few-shot classification and\nregression tasks in natural language processing, computer vision, and\ncomputational chemistry for drug discovery.", "published": "2021-02-17 17:46:57", "link": "http://arxiv.org/abs/2102.08898v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Do End-to-End Speech Recognition Models Care About Context?", "abstract": "The two most common paradigms for end-to-end speech recognition are\nconnectionist temporal classification (CTC) and attention-based encoder-decoder\n(AED) models. It has been argued that the latter is better suited for learning\nan implicit language model. We test this hypothesis by measuring temporal\ncontext sensitivity and evaluate how the models perform when we constrain the\namount of contextual information in the audio input. We find that the AED model\nis indeed more context sensitive, but that the gap can be closed by adding\nself-attention to the CTC model. Furthermore, the two models perform similarly\nwhen contextual information is constrained. Finally, in contrast to previous\nresearch, our results show that the CTC model is highly competitive on WSJ and\nLibriSpeech without the help of an external language model.", "published": "2021-02-17 11:13:50", "link": "http://arxiv.org/abs/2102.09928v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Weighted Recursive Least Square Filter and Neural Network based Residual\n  Echo Suppression for the AEC-Challenge", "abstract": "This paper presents a real-time Acoustic Echo Cancellation (AEC) algorithm\nsubmitted to the AEC-Challenge. The algorithm consists of three modules:\nGeneralized Cross-Correlation with PHAse Transform (GCC-PHAT) based time delay\ncompensation, weighted Recursive Least Square (wRLS) based linear adaptive\nfiltering and neural network based residual echo suppression. The wRLS filter\nis derived from a novel semi-blind source separation perspective. The neural\nnetwork model predicts a Phase-Sensitive Mask (PSM) based on the aligned\nreference and the linear filter output. The algorithm achieved a mean\nsubjective score of 4.00 and ranked 2nd in the AEC-Challenge.", "published": "2021-02-17 03:35:58", "link": "http://arxiv.org/abs/2102.08551v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "End-to-end lyrics Recognition with Voice to Singing Style Transfer", "abstract": "Automatic transcription of monophonic/polyphonic music is a challenging task\ndue to the lack of availability of large amounts of transcribed data. In this\npaper, we propose a data augmentation method that converts natural speech to\nsinging voice based on vocoder based speech synthesizer. This approach, called\nvoice to singing (V2S), performs the voice style conversion by modulating the\nF0 contour of the natural speech with that of a singing voice. The V2S model\nbased style transfer can generate good quality singing voice thereby enabling\nthe conversion of large corpora of natural speech to singing voice that is\nuseful in building an E2E lyrics transcription system. In our experiments on\nmonophonic singing voice data, the V2S style transfer provides a significant\ngain (relative improvements of 21%) for the E2E lyrics transcription system. We\nalso discuss additional components like transfer learning and lyrics based\nlanguage modeling to improve the performance of the lyrics transcription\nsystem.", "published": "2021-02-17 04:52:52", "link": "http://arxiv.org/abs/2102.08575v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Variational Autoencoder for Speech Enhancement with a Noise-Aware\n  Encoder", "abstract": "Recently, a generative variational autoencoder (VAE) has been proposed for\nspeech enhancement to model speech statistics. However, this approach only uses\nclean speech in the training phase, making the estimation particularly\nsensitive to noise presence, especially in low signal-to-noise ratios (SNRs).\nTo increase the robustness of the VAE, we propose to include noise information\nin the training phase by using a noise-aware encoder trained on noisy-clean\nspeech pairs. We evaluate our approach on real recordings of different noisy\nenvironments and acoustic conditions using two different noise datasets. We\nshow that our proposed noise-aware VAE outperforms the standard VAE in terms of\noverall distortion without increasing the number of model parameters. At the\nsame time, we demonstrate that our model is capable of generalizing to unseen\nnoise conditions better than a supervised feedforward deep neural network\n(DNN). Furthermore, we demonstrate the robustness of the model performance to a\nreduction of the noisy-clean speech training data size.", "published": "2021-02-17 11:40:42", "link": "http://arxiv.org/abs/2102.08706v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DESED-FL and URBAN-FL: Federated Learning Datasets for Sound Event\n  Detection", "abstract": "Research on sound event detection (SED) in environmental settings has seen\nincreased attention in recent years. The large amounts of (private) domestic or\nurban audio data needed raise significant logistical and privacy concerns. The\ninherently distributed nature of these tasks, make federated learning (FL) a\npromising approach to take advantage of largescale data while mitigating\nprivacy issues. While FL has also seen increased attention recently, to the\nbest of our knowledge there is no research towards FL for SED. To address this\ngap and foster further research in this field, we create and publish novel FL\ndatasets for SED in domestic and urban environments. Furthermore, we provide\nbaseline results on the datasets in a FL context for three deep neural network\narchitectures. The results indicate that FL is a promising approach for SED,\nbut faces challenges with divergent data distributions inherent to distributed\nclient edge devices.", "published": "2021-02-17 15:41:38", "link": "http://arxiv.org/abs/2102.08833v3", "categories": ["cs.SD", "cs.DC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
