{"title": "Incorporating a Local Translation Mechanism into Non-autoregressive\n  Translation", "abstract": "In this work, we introduce a novel local autoregressive translation (LAT)\nmechanism into non-autoregressive translation (NAT) models so as to capture\nlocal dependencies among tar-get outputs. Specifically, for each target\ndecoding position, instead of only one token, we predict a short sequence of\ntokens in an autoregressive way. We further design an efficient merging\nalgorithm to align and merge the out-put pieces into one final output sequence.\nWe integrate LAT into the conditional masked language model (CMLM;\nGhazvininejad et al.,2019) and similarly adopt iterative decoding. Empirical\nresults on five translation tasks show that compared with CMLM, our method\nachieves comparable or better performance with fewer decoding iterations,\nbringing a 2.5xspeedup. Further analysis indicates that our method reduces\nrepeated translations and performs better at longer sentences.", "published": "2020-11-12 00:32:51", "link": "http://arxiv.org/abs/2011.06132v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Depressive Symptoms from Tweets: Figurative Language Enabled\n  Multitask Learning Framework", "abstract": "Existing studies on using social media for deriving mental health status of\nusers focus on the depression detection task. However, for case management and\nreferral to psychiatrists, healthcare workers require practical and scalable\ndepressive disorder screening and triage system. This study aims to design and\nevaluate a decision support system (DSS) to reliably determine the depressive\ntriage level by capturing fine-grained depressive symptoms expressed in user\ntweets through the emulation of Patient Health Questionnaire-9 (PHQ-9) that is\nroutinely used in clinical practice. The reliable detection of depressive\nsymptoms from tweets is challenging because the 280-character limit on tweets\nincentivizes the use of creative artifacts in the utterances and figurative\nusage contributes to effective expression. We propose a novel BERT based robust\nmulti-task learning framework to accurately identify the depressive symptoms\nusing the auxiliary task of figurative usage detection. Specifically, our\nproposed novel task sharing mechanism, co-task aware attention, enables\nautomatic selection of optimal information across the BERT layers and tasks by\nsoft-sharing of parameters. Our results show that modeling figurative usage can\ndemonstrably improve the model's robustness and reliability for distinguishing\nthe depression symptoms.", "published": "2020-11-12 01:17:49", "link": "http://arxiv.org/abs/2011.06149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Theoretical Rule-based Knowledge Graph Reasoning by Connectivity\n  Dependency Discovery", "abstract": "Discovering precise and interpretable rules from knowledge graphs is regarded\nas an essential challenge, which can improve the performances of many\ndownstream tasks and even provide new ways to approach some Natural Language\nProcessing research topics. In this paper, we present a fundamental theory for\nrule-based knowledge graph reasoning, based on which the connectivity\ndependencies in the graph are captured via multiple rule types. It is the first\ntime for some of these rule types in a knowledge graph to be considered. Based\non these rule types, our theory can provide precise interpretations to unknown\ntriples. Then, we implement our theory by what we call the RuleDict model.\nResults show that our RuleDict model not only provides precise rules to\ninterpret new triples, but also achieves state-of-the-art performances on one\nbenchmark knowledge graph completion task, and is competitive on other tasks.", "published": "2020-11-12 03:00:20", "link": "http://arxiv.org/abs/2011.06174v7", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enabling Interactive Transcription in an Indigenous Community", "abstract": "We propose a novel transcription workflow which combines spoken term\ndetection and human-in-the-loop, together with a pilot experiment. This work is\ngrounded in an almost zero-resource scenario where only a few terms have so far\nbeen identified, involving two endangered languages. We show that in the early\nstages of transcription, when the available data is insufficient to train a\nrobust ASR system, it is possible to take advantage of the transcription of a\nsmall number of isolated words in order to bootstrap the transcription of a\nspeech collection.", "published": "2020-11-12 04:41:35", "link": "http://arxiv.org/abs/2011.06198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual and Multilingual Spoken Term Detection for Low-Resource\n  Indian Languages", "abstract": "Spoken Term Detection (STD) is the task of searching for words or phrases\nwithin audio, given either text or spoken input as a query. In this work, we\nuse state-of-the-art Hindi, Tamil and Telugu ASR systems cross-lingually for\nlexical Spoken Term Detection in ten low-resource Indian languages. Since no\npublicly available dataset exists for Spoken Term Detection in these languages,\nwe create a new dataset using a publicly available TTS dataset. We report a\nstandard metric for STD, Mean Term Weighted Value (MTWV) and show that ASR\nsystems built in languages that are phonetically similar to the target\nlanguages have higher accuracy, however, it is also possible to get high MTWV\nscores for dissimilar languages by using a relaxed phone matching algorithm. We\npropose a technique to bootstrap the Grapheme-to-Phoneme (g2p) mapping between\nall the languages under consideration using publicly available resources. Gains\nare obtained when we combine the output of multiple ASR systems and when we use\nlanguage-specific Language Models. We show that it is possible to perform STD\ncross-lingually in a zero-shot manner without the need for any\nlanguage-specific speech data. We plan to make the STD dataset available for\nother researchers interested in cross-lingual STD.", "published": "2020-11-12 06:41:27", "link": "http://arxiv.org/abs/2011.06226v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "World Trade Center responders in their own words: Predicting PTSD\n  symptom trajectories with AI-based language analyses of interviews", "abstract": "Background: Oral histories from 9/11 responders to the World Trade Center\n(WTC) attacks provide rich narratives about distress and resilience. Artificial\nIntelligence (AI) models promise to detect psychopathology in natural language,\nbut they have been evaluated primarily in non-clinical settings using social\nmedia. This study sought to test the ability of AI-based language assessments\nto predict PTSD symptom trajectories among responders. Methods: Participants\nwere 124 responders whose health was monitored at the Stony Brook WTC Health\nand Wellness Program who completed oral history interviews about their initial\nWTC experiences. PTSD symptom severity was measured longitudinally using the\nPTSD Checklist (PCL) for up to 7 years post-interview. AI-based indicators were\ncomputed for depression, anxiety, neuroticism, and extraversion along with\ndictionary-based measures of linguistic and interpersonal style. Linear\nregression and multilevel models estimated associations of AI indicators with\nconcurrent and subsequent PTSD symptom severity (significance adjusted by false\ndiscovery rate). Results: Cross-sectionally, greater depressive language\n(beta=0.32; p=0.043) and first-person singular usage (beta=0.31; p=0.044) were\nassociated with increased symptom severity. Longitudinally, anxious language\npredicted future worsening in PCL scores (beta=0.31; p=0.031), whereas\nfirst-person plural usage (beta=-0.37; p=0.007) and longer words usage\n(beta=-0.36; p=0.007) predicted improvement. Conclusions: This is the first\nstudy to demonstrate the value of AI in understanding PTSD in a vulnerable\npopulation. Future studies should extend this application to other trauma\nexposures and to other demographic groups, especially under-represented\nminorities.", "published": "2020-11-12 15:57:23", "link": "http://arxiv.org/abs/2011.06457v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Cross-Dialectal Gold Syntax for Low-Resource Historical\n  Languages: Towards a Generic Parser for Pre-Modern Slavic", "abstract": "This paper explores the possibility of improving the performance of\nspecialized parsers for pre-modern Slavic by training them on data from\ndifferent related varieties. Because of their linguistic heterogeneity,\npre-modern Slavic varieties are treated as low-resource historical languages,\nwhereby cross-dialectal treebank data may be exploited to overcome data\nscarcity and attempt the training of a variety-agnostic parser. Previous\nexperiments on early Slavic dependency parsing are discussed, particularly with\nregard to their ability to tackle different orthographic, regional and\nstylistic features. A generic pre-modern Slavic parser and two specialized\nparsers -- one for East Slavic and one for South Slavic -- are trained using\njPTDP (Nguyen & Verspoor 2018), a neural network model for joint part-of-speech\n(POS) tagging and dependency parsing which had shown promising results on a\nnumber of Universal Dependency (UD) treebanks, including Old Church Slavonic\n(OCS). With these experiments, a new state of the art is obtained for both OCS\n(83.79\\% unlabelled attachment score (UAS) and 78.43\\% labelled attachement\nscore (LAS)) and Old East Slavic (OES) (85.7\\% UAS and 80.16\\% LAS).", "published": "2020-11-12 16:17:59", "link": "http://arxiv.org/abs/2011.06467v1", "categories": ["cs.CL", "68T50, 68T07 (Primary), 91F20 (Secondary)", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Overview of the Ninth Dialog System Technology Challenge: DSTC9", "abstract": "This paper introduces the Ninth Dialog System Technology Challenge (DSTC-9).\nThis edition of the DSTC focuses on applying end-to-end dialog technologies for\nfour distinct tasks in dialog systems, namely, 1. Task-oriented dialog Modeling\nwith unstructured knowledge access, 2. Multi-domain task-oriented dialog, 3.\nInteractive evaluation of dialog, and 4. Situated interactive multi-modal\ndialog. This paper describes the task definition, provided datasets, baselines\nand evaluation set-up for each track. We also summarize the results of the\nsubmitted systems to highlight the overall trends of the state-of-the-art\ntechnologies for the tasks.", "published": "2020-11-12 16:43:10", "link": "http://arxiv.org/abs/2011.06486v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Processing to Detect Cognitive Concerns in Electronic\n  Health Records Using Deep Learning", "abstract": "Dementia is under-recognized in the community, under-diagnosed by healthcare\nprofessionals, and under-coded in claims data. Information on cognitive\ndysfunction, however, is often found in unstructured clinician notes within\nmedical records but manual review by experts is time consuming and often prone\nto errors. Automated mining of these notes presents a potential opportunity to\nlabel patients with cognitive concerns who could benefit from an evaluation or\nbe referred to specialist care. In order to identify patients with cognitive\nconcerns in electronic medical records, we applied natural language processing\n(NLP) algorithms and compared model performance to a baseline model that used\nstructured diagnosis codes and medication data only. An attention-based deep\nlearning model outperformed the baseline model and other simpler models.", "published": "2020-11-12 16:59:56", "link": "http://arxiv.org/abs/2011.06489v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Inference-only sub-character decomposition improves translation of\n  unseen logographic characters", "abstract": "Neural Machine Translation (NMT) on logographic source languages struggles\nwhen translating `unseen' characters, which never appear in the training data.\nOne possible approach to this problem uses sub-character decomposition for\ntraining and test sentences. However, this approach involves complete\nretraining, and its effectiveness for unseen character translation to\nnon-logographic languages has not been fully explored.\n  We investigate existing ideograph-based sub-character decomposition\napproaches for Chinese-to-English and Japanese-to-English NMT, for both\nhigh-resource and low-resource domains. For each language pair and domain we\nconstruct a test set where all source sentences contain at least one unseen\nlogographic character. We find that complete sub-character decomposition often\nharms unseen character translation, and gives inconsistent results generally.\n  We offer a simple alternative based on decomposition before inference for\nunseen characters only. Our approach allows flexible application, achieving\ntranslation adequacy improvements and requiring no additional models or\ntraining.", "published": "2020-11-12 17:36:22", "link": "http://arxiv.org/abs/2011.06523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset", "abstract": "We introduce doc2dial, a new dataset of goal-oriented dialogues that are\ngrounded in the associated documents. Inspired by how the authors compose\ndocuments for guiding end users, we first construct dialogue flows based on the\ncontent elements that corresponds to higher-level relations across text\nsections as well as lower-level relations between discourse units within a\nsection. Then we present these dialogue flows to crowd contributors to create\nconversational utterances. The dataset includes about 4800 annotated\nconversations with an average of 14 turns that are grounded in over 480\ndocuments from four domains. Compared to the prior document-grounded dialogue\ndatasets, this dataset covers a variety of dialogue scenes in\ninformation-seeking conversations. For evaluating the versatility of the\ndataset, we introduce multiple dialogue modeling tasks and present baseline\napproaches.", "published": "2020-11-12 19:08:44", "link": "http://arxiv.org/abs/2011.06623v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-aware Stand-alone Neural Spelling Correction", "abstract": "Existing natural language processing systems are vulnerable to noisy inputs\nresulting from misspellings. On the contrary, humans can easily infer the\ncorresponding correct words from their misspellings and surrounding context.\nInspired by this, we address the stand-alone spelling correction problem, which\nonly corrects the spelling of each token without additional token insertion or\ndeletion, by utilizing both spelling information and global context\nrepresentations. We present a simple yet powerful solution that jointly detects\nand corrects misspellings as a sequence labeling task by fine-turning a\npre-trained language model. Our solution outperforms the previous\nstate-of-the-art result by 12.8% absolute F0.5 score.", "published": "2020-11-12 20:34:49", "link": "http://arxiv.org/abs/2011.06642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Author's Sentiment Prediction", "abstract": "We introduce PerSenT, a dataset of crowd-sourced annotations of the sentiment\nexpressed by the authors towards the main entities in news articles. The\ndataset also includes paragraph-level sentiment annotations to provide more\nfine-grained supervision for the task. Our benchmarks of multiple strong\nbaselines show that this is a difficult classification task. The results also\nsuggest that simply fine-tuning document-level representations from BERT isn't\nadequate for this task. Making paragraph-level decisions and aggregating them\nover the entire document is also ineffective. We present empirical and\nqualitative analyses that illustrate the specific challenges posed by this\ndataset. We release this dataset with 5.3k documents and 38k paragraphs\ncovering 3.2k unique entities as a challenge in entity sentiment analysis.", "published": "2020-11-12 00:03:26", "link": "http://arxiv.org/abs/2011.06128v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Augmenting BERT Carefully with Underrepresented Linguistic Features", "abstract": "Fine-tuned Bidirectional Encoder Representations from Transformers\n(BERT)-based sequence classification models have proven to be effective for\ndetecting Alzheimer's Disease (AD) from transcripts of human speech. However,\nprevious research shows it is possible to improve BERT's performance on various\ntasks by augmenting the model with additional information. In this work, we use\nprobing tasks as introspection techniques to identify linguistic information\nnot well-represented in various layers of BERT, but important for the AD\ndetection task. We supplement these linguistic features in which\nrepresentations from BERT are found to be insufficient with hand-crafted\nfeatures externally, and show that jointly fine-tuning BERT in combination with\nthese features improves the performance of AD classification by upto 5\\% over\nfine-tuned BERT alone.", "published": "2020-11-12 01:32:41", "link": "http://arxiv.org/abs/2011.06153v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SigmaLaw-ABSA: Dataset for Aspect-Based Sentiment Analysis in Legal\n  Opinion Texts", "abstract": "Aspect-Based Sentiment Analysis (ABSA) has been prominent and ongoing\nresearch over many different domains, but it is not widely discussed in the\nlegal domain. A number of publicly available datasets for a wide range of\ndomains usually fulfill the needs of researchers to perform their studies in\nthe field of ABSA. To the best of our knowledge, there is no publicly available\ndataset for the Aspect (Party) Based Sentiment Analysis for legal opinion\ntexts. Therefore, creating a publicly available dataset for the research of\nABSA for the legal domain can be considered as a task with significant\nimportance. In this study, we introduce a manually annotated legal opinion text\ndataset (SigmaLaw-ABSA) intended towards facilitating researchers for ABSA\ntasks in the legal domain. SigmaLaw-ABSA consists of legal opinion texts in the\nEnglish language which have been annotated by human judges. This study\ndiscusses the sub-tasks of ABSA relevant to the legal domain and how to use the\ndataset to perform them. This paper also describes the statistics of the\ndataset and as a baseline, we present some results on the performance of some\nexisting deep learning based systems on the SigmaLaw-ABSA dataset.", "published": "2020-11-12 11:45:47", "link": "http://arxiv.org/abs/2011.06326v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards A Sentiment Analyzer for Low-Resource Languages", "abstract": "Twitter is one of the top influenced social media which has a million number\nof active users. It is commonly used for microblogging that allows users to\nshare messages, ideas, thoughts and many more. Thus, millions interaction such\nas short messages or tweets are flowing around among the twitter users\ndiscussing various topics that has been happening world-wide. This research\naims to analyse a sentiment of the users towards a particular trending topic\nthat has been actively and massively discussed at that time. We chose a hashtag\n\\textit{\\#kpujangancurang} that was the trending topic during the Indonesia\npresidential election in 2019. We use the hashtag to obtain a set of data from\nTwitter to analyse and investigate further the positive or the negative\nsentiment of the users from their tweets. This research utilizes rapid miner\ntool to generate the twitter data and comparing Naive Bayes, K-Nearest\nNeighbor, Decision Tree, and Multi-Layer Perceptron classification methods to\nclassify the sentiment of the twitter data. There are overall 200 labeled data\nin this experiment. Overall, Naive Bayes and Multi-Layer Perceptron\nclassification outperformed the other two methods on 11 experiments with\ndifferent size of training-testing data split. The two classifiers are\npotential to be used in creating sentiment analyzer for low-resource languages\nwith small corpus.", "published": "2020-11-12 13:50:00", "link": "http://arxiv.org/abs/2011.06382v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Interpretable End-to-end Fine-tuning Approach for Long Clinical Text", "abstract": "Unstructured clinical text in EHRs contains crucial information for\napplications including decision support, trial matching, and retrospective\nresearch. Recent work has applied BERT-based models to clinical information\nextraction and text classification, given these models' state-of-the-art\nperformance in other NLP domains. However, BERT is difficult to apply to\nclinical notes because it doesn't scale well to long sequences of text. In this\nwork, we propose a novel fine-tuning approach called SnipBERT. Instead of using\nentire notes, SnipBERT identifies crucial snippets and then feeds them into a\ntruncated BERT-based model in a hierarchical manner. Empirically, SnipBERT not\nonly has significant predictive performance gain across three tasks but also\nprovides improved interpretability, as the model can identify key pieces of\ntext that led to its prediction.", "published": "2020-11-12 17:14:32", "link": "http://arxiv.org/abs/2011.06504v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Medical symptom recognition from patient text: An active learning\n  approach for long-tailed multilabel distributions", "abstract": "We study the problem of medical symptoms recognition from patient text, for\nthe purposes of gathering pertinent information from the patient (known as\nhistory-taking). A typical patient text is often descriptive of the symptoms\nthe patient is experiencing and a single instance of such a text can be\n\"labeled\" with multiple symptoms. This makes learning a medical symptoms\nrecognizer challenging on account of i) the lack of availability of voluminous\nannotated data as well as ii) the large unknown universe of multiple symptoms\nthat a single text can map to. Furthermore, patient text is often characterized\nby a long tail in the data (i.e., some labels/symptoms occur more frequently\nthan others for e.g \"fever\" vs \"hematochezia\"). In this paper, we introduce an\nactive learning method that leverages underlying structure of a continually\nrefined, learned latent space to select the most informative examples to label.\nThis enables the selection of the most informative examples that progressively\nincreases the coverage on the universe of symptoms via the learned model,\ndespite the long tail in data distribution.", "published": "2020-11-12 05:26:56", "link": "http://arxiv.org/abs/2011.06874v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deconstructing word embedding algorithms", "abstract": "Word embeddings are reliable feature representations of words used to obtain\nhigh quality results for various NLP applications. Uncontextualized word\nembeddings are used in many NLP tasks today, especially in resource-limited\nsettings where high memory capacity and GPUs are not available. Given the\nhistorical success of word embeddings in NLP, we propose a retrospective on\nsome of the most well-known word embedding algorithms. In this work, we\ndeconstruct Word2vec, GloVe, and others, into a common form, unveiling some of\nthe common conditions that seem to be required for making performant word\nembeddings. We believe that the theoretical findings in this paper can provide\na basis for more informed development of future models.", "published": "2020-11-12 14:23:35", "link": "http://arxiv.org/abs/2011.07013v1", "categories": ["cs.CL", "cs.AI", "68T50"], "primary_category": "cs.CL"}
{"title": "Analyzing Neural Discourse Coherence Models", "abstract": "In this work, we systematically investigate how well current models of\ncoherence can capture aspects of text implicated in discourse organisation. We\ndevise two datasets of various linguistic alterations that undermine coherence\nand test model sensitivity to changes in syntax and semantics. We furthermore\nprobe discourse embedding space and examine the knowledge that is encoded in\nrepresentations of coherence. We hope this study shall provide further insight\ninto how to frame the task and improve models of coherence assessment further.\nFinally, we make our datasets publicly available as a resource for researchers\nto use to test discourse coherence models.", "published": "2020-11-12 10:44:41", "link": "http://arxiv.org/abs/2011.06306v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Biomedical Named Entity Recognition at Scale", "abstract": "Named entity recognition (NER) is a widely applicable natural language\nprocessing task and building block of question answering, topic modeling,\ninformation retrieval, etc. In the medical domain, NER plays a crucial role by\nextracting meaningful chunks from clinical notes and reports, which are then\nfed to downstream tasks like assertion status detection, entity resolution,\nrelation extraction, and de-identification. Reimplementing a Bi-LSTM-CNN-Char\ndeep learning architecture on top of Apache Spark, we present a single\ntrainable NER model that obtains new state-of-the-art results on seven public\nbiomedical benchmarks without using heavy contextual embeddings like BERT. This\nincludes improving BC4CHEMD to 93.72% (4.1% gain), Species800 to 80.91% (4.6%\ngain), and JNLPBA to 81.29% (5.2% gain). In addition, this model is freely\navailable within a production-grade code base as part of the open-source Spark\nNLP library; can scale up for training and inference in any Spark cluster; has\nGPU support and libraries for popular programming languages such as Python, R,\nScala and Java; and can be extended to support other human languages with no\ncode changes.", "published": "2020-11-12 11:10:17", "link": "http://arxiv.org/abs/2011.06315v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic Neural Lyrics and Melody Composition", "abstract": "In this paper, we propose a technique to address the most challenging aspect\nof algorithmic songwriting process, which enables the human community to\ndiscover original lyrics, and melodies suitable for the generated lyrics. The\nproposed songwriting system, Automatic Neural Lyrics and Melody Composition\n(AutoNLMC) is an attempt to make the whole process of songwriting automatic\nusing artificial neural networks. Our lyric to vector (lyric2vec) model trained\non a large set of lyric-melody pairs dataset parsed at syllable, word and\nsentence levels are large scale embedding models enable us to train data driven\nmodel such as recurrent neural networks for popular English songs. AutoNLMC is\na encoder-decoder sequential recurrent neural network model consisting of a\nlyric generator, a lyric encoder and melody decoder trained end-to-end.\nAutoNLMC is designed to generate both lyrics and corresponding melody\nautomatically for an amateur or a person without music knowledge. It can also\ntake lyrics from professional lyric writer to generate matching melodies. The\nqualitative and quantitative evaluation measures revealed that the proposed\nmethod is indeed capable of generating original lyrics and corresponding melody\nfor composing new songs.", "published": "2020-11-12 13:44:01", "link": "http://arxiv.org/abs/2011.06380v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fairness and Robustness in Invariant Learning: A Case Study in Toxicity\n  Classification", "abstract": "Robustness is of central importance in machine learning and has given rise to\nthe fields of domain generalization and invariant learning, which are concerned\nwith improving performance on a test distribution distinct from but related to\nthe training distribution. In light of recent work suggesting an intimate\nconnection between fairness and robustness, we investigate whether algorithms\nfrom robust ML can be used to improve the fairness of classifiers that are\ntrained on biased data and tested on unbiased data. We apply Invariant Risk\nMinimization (IRM), a domain generalization algorithm that employs a causal\ndiscovery inspired method to find robust predictors, to the task of fairly\npredicting the toxicity of internet comments. We show that IRM achieves better\nout-of-distribution accuracy and fairness than Empirical Risk Minimization\n(ERM) methods, and analyze both the difficulties that arise when applying IRM\nin practice and the conditions under which IRM will likely be effective in this\nscenario. We hope that this work will inspire further studies of how robust\nmachine learning methods relate to algorithmic fairness.", "published": "2020-11-12 16:42:14", "link": "http://arxiv.org/abs/2011.06485v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The CUHK-TUDELFT System for The SLT 2021 Children Speech Recognition\n  Challenge", "abstract": "This technical report describes our submission to the 2021 SLT Children\nSpeech Recognition Challenge (CSRC) Track 1. Our approach combines the use of a\njoint CTC-attention end-to-end (E2E) speech recognition framework, transfer\nlearning, data augmentation and development of various language models.\nProcedures of data pre-processing, the background and the course of system\ndevelopment are described. The analysis of the experiment results, as well as\nthe comparison between the E2E and DNN-HMM hybrid system are discussed in\ndetail. Our system achieved a character error rate (CER) of 20.1% in our\ndesignated test set, and 23.6% in the official evaluation set, which is placed\nat 10-th overall.", "published": "2020-11-12 07:31:19", "link": "http://arxiv.org/abs/2011.06239v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Evaluating the Intelligibility Benefits of Neural Speech Enrichment for\n  Listeners with Normal Hearing and Hearing Impairment using the Greek Harvard\n  Corpus", "abstract": "In this work we evaluate a neural based speech intelligibility booster based\non spectral shaping and dynamic range compression (SSDRC), referred to as\nWaveNet-based SSDRC (wSSDRC), using a recently designed Greek Harvard-style\ncorpus. The corpus has been developed according to the format of the\nHarvard/IEEE sentences and offers the opportunity to apply neural speech\nenhancement models and examine their performance gain for Greek listeners.\nwSSDRC has been successfully tested for English material and speakers in the\npast. In this paper we revisit wSSDRC to perform a full scale evaluation of the\nmodel with Greek listeners under the condition of equal energy before and after\nmodification. Both normal hearing (NH) and hearing impaired (HI) listeners\nevaluated the model under speech shaped noise (SSN) at listener-specific SNRs\nmatching their Speech Reception Threshold (SRT) - a point at which 50 % of\nunmodified speech is intelligible. The analysis statistics show that the wSSDRC\nmodel has produced a median intelligibility boost of 39% for NH and 38% for HI,\nrelative to the plain unprocessed speech.", "published": "2020-11-12 18:07:30", "link": "http://arxiv.org/abs/2011.06548v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker\n  Adaptation and Pronunciation Enhancement", "abstract": "Recent neural Text-to-Speech (TTS) models have been shown to perform very\nwell when enough data is available. However, fine-tuning them for new speakers\nor languages is not straightforward in a low-resource setup. In this paper, we\nshow that by applying minor modifications to a Tacotron model, one can transfer\nan existing TTS model for new speakers from the same or a different language\nusing only 20 minutes of data. For this purpose, we first introduce a base\nmulti-lingual Tacotron with language-agnostic input, then demonstrate how\ntransfer learning is done for different scenarios of speaker adaptation without\nexploiting any pre-trained speaker encoder or code-switching technique. We\nevaluate the transferred model in both subjective and objective ways.", "published": "2020-11-12 14:05:34", "link": "http://arxiv.org/abs/2011.06392v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hierarchical Prosody Modeling for Non-Autoregressive Speech Synthesis", "abstract": "Prosody modeling is an essential component in modern text-to-speech (TTS)\nframeworks. By explicitly providing prosody features to the TTS model, the\nstyle of synthesized utterances can thus be controlled. However, predicting\nnatural and reasonable prosody at inference time is challenging. In this work,\nwe analyzed the behavior of non-autoregressive TTS models under different\nprosody-modeling settings and proposed a hierarchical architecture, in which\nthe prediction of phoneme-level prosody features are conditioned on the\nword-level prosody features. The proposed method outperforms other competitors\nin terms of audio quality and prosody naturalness in our objective and\nsubjective evaluation.", "published": "2020-11-12 16:16:41", "link": "http://arxiv.org/abs/2011.06465v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
