{"title": "A Unified Model for Opinion Target Extraction and Target Sentiment\n  Prediction", "abstract": "Target-based sentiment analysis involves opinion target extraction and target\nsentiment classification. However, most of the existing works usually studied\none of these two sub-tasks alone, which hinders their practical use. This paper\naims to solve the complete task of target-based sentiment analysis in an\nend-to-end fashion, and presents a novel unified model which applies a unified\ntagging scheme. Our framework involves two stacked recurrent neural networks:\nThe upper one predicts the unified tags to produce the final output results of\nthe primary target-based sentiment analysis; The lower one performs an\nauxiliary target boundary prediction aiming at guiding the upper network to\nimprove the performance of the primary task. To explore the inter-task\ndependency, we propose to explicitly model the constrained transitions from\ntarget boundaries to target sentiment polarities. We also propose to maintain\nthe sentiment consistency within an opinion target via a gate mechanism which\nmodels the relation between the features for the current word and the previous\nword. We conduct extensive experiments on three benchmark datasets and our\nframework achieves consistently superior results.", "published": "2018-11-13 03:04:41", "link": "http://arxiv.org/abs/1811.05082v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Agnostic Real-Valued Specificity Prediction", "abstract": "Sentence specificity quantifies the level of detail in a sentence,\ncharacterizing the organization of information in discourse. While this\ninformation is useful for many downstream applications, specificity prediction\nsystems predict very coarse labels (binary or ternary) and are trained on and\ntailored toward specific domains (e.g., news). The goal of this work is to\ngeneralize specificity prediction to domains where no labeled data is available\nand output more nuanced real-valued specificity ratings.\n  We present an unsupervised domain adaptation system for sentence specificity\nprediction, specifically designed to output real-valued estimates from binary\ntraining labels. To calibrate the values of these predictions appropriately, we\nregularize the posterior distribution of the labels towards a reference\ndistribution. We show that our framework generalizes well to three different\ndomains with 50%~68% mean absolute error reduction than the current\nstate-of-the-art system trained for news sentence specificity. We also\ndemonstrate the potential of our work in improving the quality and\ninformativeness of dialogue generation systems.", "published": "2018-11-13 03:16:29", "link": "http://arxiv.org/abs/1811.05085v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hate Speech Detection from Code-mixed Hindi-English Tweets Using Deep\n  Learning Models", "abstract": "This paper reports an increment to the state-of-the-art in hate speech\ndetection for English-Hindi code-mixed tweets. We compare three typical deep\nlearning models using domain-specific embeddings. On experimenting with a\nbenchmark dataset of English-Hindi code-mixed tweets, we observe that using\ndomain-specific embeddings results in an improved representation of target\ngroups, and an improved F-score.", "published": "2018-11-13 07:49:02", "link": "http://arxiv.org/abs/1811.05145v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-task learning for Joint Language Understanding and Dialogue State\n  Tracking", "abstract": "This paper presents a novel approach for multi-task learning of language\nunderstanding (LU) and dialogue state tracking (DST) in task-oriented dialogue\nsystems. Multi-task training enables the sharing of the neural network layers\nresponsible for encoding the user utterance for both LU and DST and improves\nperformance while reducing the number of network parameters. In our proposed\nframework, DST operates on a set of candidate values for each slot that has\nbeen mentioned so far. These candidate sets are generated using LU slot\nannotations for the current user utterance, dialogue acts corresponding to the\npreceding system utterance and the dialogue state estimated for the previous\nturn, enabling DST to handle slots with a large or unbounded set of possible\nvalues and deal with slot values not seen during training. Furthermore, to\nbridge the gap between training and inference, we investigate the use of\nscheduled sampling on LU output for the current user utterance as well as the\nDST output for the preceding turn.", "published": "2018-11-13 17:01:50", "link": "http://arxiv.org/abs/1811.05408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discourse in Multimedia: A Case Study in Information Extraction", "abstract": "To ensure readability, text is often written and presented with due\nformatting. These text formatting devices help the writer to effectively convey\nthe narrative. At the same time, these help the readers pick up the structure\nof the discourse and comprehend the conveyed information. There have been a\nnumber of linguistic theories on discourse structure of text. However, these\ntheories only consider unformatted text. Multimedia text contains rich\nformatting features which can be leveraged for various NLP tasks. In this\npaper, we study some of these discourse features in multimedia text and what\ncommunicative function they fulfil in the context. We examine how these\nmultimedia discourse features can be used to improve an information extraction\nsystem. We show that the discourse and text layout features provide information\nthat is complementary to lexical semantic information commonly used for\ninformation extraction. As a case study, we use these features to harvest\nstructured subject knowledge of geometry from textbooks. We show that the\nharvested structured knowledge can be used to improve an existing solver for\ngeometry problems, making it more accurate as well as more explainable.", "published": "2018-11-13 22:08:39", "link": "http://arxiv.org/abs/1811.05546v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Corpus Phonetics Tutorial", "abstract": "Corpus phonetics has become an increasingly popular method of research in\nlinguistic analysis. With advances in speech technology and computational\npower, large scale processing of speech data has become a viable technique.\nThis tutorial introduces the speech scientist and engineer to various automatic\nspeech processing tools. These include acoustic model creation and forced\nalignment using the Kaldi Automatic Speech Recognition Toolkit (Povey et al.,\n2011), forced alignment using FAVE-align (Rosenfelder et al., 2014), the\nMontreal Forced Aligner (McAuliffe et al., 2017), and the Penn Phonetics Lab\nForced Aligner (Yuan & Liberman, 2008), as well as stop consonant burst\nalignment using AutoVOT (Keshet et al., 2014). The tutorial provides a general\noverview of each program, step-by-step instructions for running the program, as\nwell as several tips and tricks.", "published": "2018-11-13 22:42:10", "link": "http://arxiv.org/abs/1811.05553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Short-text Matching with Deep Learning", "abstract": "The problem of short text matching is formulated as follows: given a pair of\nsentences or questions, a matching model determines whether the input pair mean\nthe same or not. Models that can automatically identify questions with the same\nmeaning have a wide range of applications in question answering sites and\nmodern chatbots. In this article, we describe the approach by team hahu to\nsolve this problem in the context of the \"CIKM AnalytiCup 2018 - Cross-lingual\nShort-text Matching of Question Pairs\" that is sponsored by Alibaba. Our\nsolution is an end-to-end system based on current advances in deep learning\nwhich avoids heavy feature-engineering and achieves improved performance over\ntraditional machine-learning approaches. The log-loss scores for the first and\nsecond rounds of the contest are 0.35 and 0.39 respectively. The team was\nranked 7th from 1027 teams in the overall ranking scheme by the organizers that\nconsisted of the two contest scores as well as: innovation and system\nintegrity, understanding data as well as practicality of the solution for\nbusiness.", "published": "2018-11-13 23:27:06", "link": "http://arxiv.org/abs/1811.05569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Jointly identifying opinion mining elements and fuzzy measurement of\n  opinion intensity to analyze product features", "abstract": "Opinion mining mainly involves three elements: feature and feature-of\nrelations, opinion expressions and the related opinion attributes (e.g.\nPolarity), and feature-opinion relations. Although many works have emerged to\nachieve its aim of gaining information, the previous researches typically\nhandled each of the three elements in isolation, which cannot give sufficient\ninformation extraction results; hence, the complexity and the running time of\ninformation extraction is increased. In this paper, we propose an opinion\nmining extraction algorithm to jointly discover the main opinion mining\nelements. Specifically, the algorithm automatically builds kernels to combine\nclosely related words into new terms from word level to phrase level based on\ndependency relations; and we ensure the accuracy of opinion expressions and\npolarity based on: fuzzy measurements, opinion degree intensifiers, and opinion\npatterns. The 3458 analyzed reviews show that the proposed algorithm can\neffectively identify the main elements simultaneously and outperform the\nbaseline methods. The proposed algorithm is used to analyze the features among\nheterogeneous products in the same category. The feature-by-feature comparison\ncan help to select the weaker features and recommend the correct specifications\nfrom the beginning life of a product. From this comparison, some interesting\nobservations are revealed. For example, the negative polarity of video\ndimension is higher than the product usability dimension for a product. Yet,\nenhancing the dimension of product usability can more effectively improve the\nproduct (C) 2015 Elsevier Ltd. All rights reserved.", "published": "2018-11-13 09:27:24", "link": "http://arxiv.org/abs/1811.05827v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Shall I Compare Thee to a Machine-Written Sonnet? An Approach to\n  Algorithmic Sonnet Generation", "abstract": "We provide an approach for generating beautiful poetry. Our sonnet-generation\nalgorithm includes several novel elements that improve over the state of the\nart, leading to metrical, rhyming poetry with many human-like qualities. These\nnovel elements include in-line punctuation, part of speech restrictions, and\nmore appropriate training corpora. Our work is the winner of the 2018 PoetiX\nLiterary Turing Test Award for computer-generated poetry.", "published": "2018-11-13 02:04:42", "link": "http://arxiv.org/abs/1811.05067v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Interpreting Models by Allowing to Ask", "abstract": "Questions convey information about the questioner, namely what one does not\nknow. In this paper, we propose a novel approach to allow a learning agent to\nask what it considers as tricky to predict, in the course of producing a final\noutput. By analyzing when and what it asks, we can make our model more\ntransparent and interpretable. We first develop this idea to propose a general\nframework of deep neural networks that can ask questions, which we call asking\nnetworks. A specific architecture and training process for an asking network is\nproposed for the task of colorization, which is an exemplar one-to-many task\nand thus a task where asking questions is helpful in performing the task\naccurately. Our results show that the model learns to generate meaningful\nquestions, asks difficult questions first, and utilizes the provided hint more\nefficiently than baseline models. We conclude that the proposed asking\nframework makes the learning agent reveal its weaknesses, which poses a\npromising new direction in developing interpretable and interactive models.", "published": "2018-11-13 04:57:48", "link": "http://arxiv.org/abs/1811.05106v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Modeling Local Dependence in Natural Language with Multi-channel\n  Recurrent Neural Networks", "abstract": "Recurrent Neural Networks (RNNs) have been widely used in processing natural\nlanguage tasks and achieve huge success. Traditional RNNs usually treat each\ntoken in a sentence uniformly and equally. However, this may miss the rich\nsemantic structure information of a sentence, which is useful for understanding\nnatural languages. Since semantic structures such as word dependence patterns\nare not parameterized, it is a challenge to capture and leverage structure\ninformation. In this paper, we propose an improved variant of RNN,\nMulti-Channel RNN (MC-RNN), to dynamically capture and leverage local semantic\nstructure information. Concretely, MC-RNN contains multiple channels, each of\nwhich represents a local dependence pattern at a time. An attention mechanism\nis introduced to combine these patterns at each step, according to the semantic\ninformation. Then we parameterize structure information by adaptively selecting\nthe most appropriate connection structures among channels. In this way, diverse\nlocal structures and dependence patterns in sentences can be well captured by\nMC-RNN. To verify the effectiveness of MC-RNN, we conduct extensive experiments\non typical natural language processing tasks, including neural machine\ntranslation, abstractive summarization, and language modeling. Experimental\nresults on these tasks all show significant improvements of MC-RNN over current\ntop systems.", "published": "2018-11-13 06:22:02", "link": "http://arxiv.org/abs/1811.05121v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Multi-layer LSTM-based Approach for Robot Command Interaction Modeling", "abstract": "As the first robotic platforms slowly approach our everyday life, we can\nimagine a near future where service robots will be easily accessible by\nnon-expert users through vocal interfaces. The capability of managing natural\nlanguage would indeed speed up the process of integrating such platform in the\nordinary life. Semantic parsing is a fundamental task of the Natural Language\nUnderstanding process, as it allows extracting the meaning of a user utterance\nto be used by a machine. In this paper, we present a preliminary study to\nsemantically parse user vocal commands for a House Service robot, using a\nmulti-layer Long-Short Term Memory neural network with attention mechanism. The\nsystem is trained on the Human Robot Interaction Corpus, and it is\npreliminarily compared with previous approaches.", "published": "2018-11-13 12:10:29", "link": "http://arxiv.org/abs/1811.05242v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Translating Natural Language to SQL using Pointer-Generator Networks and\n  How Decoding Order Matters", "abstract": "Translating natural language to SQL queries for table-based question\nanswering is a challenging problem and has received significant attention from\nthe research community. In this work, we extend a pointer-generator and\ninvestigate the order-matters problem in semantic parsing for SQL. Even though\nour model is a straightforward extension of a general-purpose\npointer-generator, it outperforms early works for WikiSQL and remains\ncompetitive to concurrently introduced, more complex models. Moreover, we\nprovide a deeper investigation of the potential order-matters problem that\ncould arise due to having multiple correct decoding paths, and investigate the\nuse of REINFORCE as well as a dynamic oracle in this context.", "published": "2018-11-13 14:06:58", "link": "http://arxiv.org/abs/1811.05303v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Embedding Electronic Health Records for Clinical Information Retrieval", "abstract": "Neural network representation learning frameworks have recently shown to be\nhighly effective at a wide range of tasks ranging from radiography\ninterpretation via data-driven diagnostics to clinical decision support. This\noften superior performance comes at the price of dramatically increased\ntraining data requirements that cannot be satisfied in every given institution\nor scenario. As a means of countering such data sparsity effects, distant\nsupervision alleviates the need for scarce in-domain data by relying on a\nrelated, resource-rich, task for training.\n  This study presents an end-to-end neural clinical decision support system\nthat recommends relevant literature for individual patients (few available\nresources) via distant supervision on the well-known MIMIC-III collection\n(abundant resource). Our experiments show significant improvements in retrieval\neffectiveness over traditional statistical as well as purely locally supervised\nretrieval models.", "published": "2018-11-13 16:55:52", "link": "http://arxiv.org/abs/1811.05402v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "An Analysis of the Semantic Annotation Task on the Linked Data Cloud", "abstract": "Semantic annotation, the process of identifying key-phrases in texts and\nlinking them to concepts in a knowledge base, is an important basis for\nsemantic information retrieval and the Semantic Web uptake. Despite the\nemergence of semantic annotation systems, very few comparative studies have\nbeen published on their performance. In this paper, we provide an evaluation of\nthe performance of existing systems over three tasks: full semantic annotation,\nnamed entity recognition, and keyword detection. More specifically, the\nspotting capability (recognition of relevant surface forms in text) is\nevaluated for all three tasks, whereas the disambiguation (correctly\nassociating an entity from Wikipedia or DBpedia to the spotted surface forms)\nis evaluated only for the first two tasks. Our evaluation is twofold: First, we\ncompute standard precision and recall on the output of semantic annotators on\ndiverse datasets, each best suited for one of the identified tasks. Second, we\nbuild a statistical model using logistic regression to identify significant\nperformance differences. Our results show that systems that provide full\nannotation perform better than named entities annotators and keyword\nextractors, for all three tasks. However, there is still much room for\nimprovement for the identification of the most relevant entities described in a\ntext.", "published": "2018-11-13 22:24:29", "link": "http://arxiv.org/abs/1811.05549v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Text Assisted Insight Ranking Using Context-Aware Memory Network", "abstract": "Extracting valuable facts or informative summaries from multi-dimensional\ntables, i.e. insight mining, is an important task in data analysis and business\nintelligence. However, ranking the importance of insights remains a challenging\nand unexplored task. The main challenge is that explicitly scoring an insight\nor giving it a rank requires a thorough understanding of the tables and costs a\nlot of manual efforts, which leads to the lack of available training data for\nthe insight ranking problem. In this paper, we propose an insight ranking model\nthat consists of two parts: A neural ranking model explores the data\ncharacteristics, such as the header semantics and the data statistical\nfeatures, and a memory network model introduces table structure and context\ninformation into the ranking process. We also build a dataset with text\nassistance. Experimental results show that our approach largely improves the\nranking precision as reported in multi evaluation metrics.", "published": "2018-11-13 23:11:26", "link": "http://arxiv.org/abs/1811.05563v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Exploring RNN-Transducer for Chinese Speech Recognition", "abstract": "End-to-end approaches have drawn much attention recently for significantly\nsimplifying the construction of an automatic speech recognition (ASR) system.\nRNN transducer (RNN-T) is one of the popular end-to-end methods. Previous\nstudies have shown that RNN-T is difficult to train and a very complex training\nprocess is needed for a reasonable performance. In this paper, we explore RNN-T\nfor a Chinese large vocabulary continuous speech recognition (LVCSR) task and\naim to simplify the training process while maintaining performance. First, a\nnew strategy of learning rate decay is proposed to accelerate the model\nconvergence. Second, we find that adding convolutional layers at the beginning\nof the network and using ordered data can discard the pre-training process of\nthe encoder without loss of performance. Besides, we design experiments to find\na balance among the usage of GPU memory, training circle and model performance.\nFinally, we achieve 16.9% character error rate (CER) on our test set which is\n2% absolute improvement from a strong BLSTM CE system with language model\ntrained on the same text corpus.", "published": "2018-11-13 04:37:11", "link": "http://arxiv.org/abs/1811.05097v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "An Online Attention-based Model for Speech Recognition", "abstract": "Attention-based end-to-end models such as Listen, Attend and Spell (LAS),\nsimplify the whole pipeline of traditional automatic speech recognition (ASR)\nsystems and become popular in the field of speech recognition. In previous\nwork, researchers have shown that such architectures can acquire comparable\nresults to state-of-the-art ASR systems, especially when using a bidirectional\nencoder and global soft attention (GSA) mechanism. However, bidirectional\nencoder and GSA are two obstacles for real-time speech recognition. In this\nwork, we aim to stream LAS baseline by removing the above two obstacles. On the\nencoder side, we use a latency-controlled (LC) bidirectional structure to\nreduce the delay of forward computation. Meanwhile, an adaptive monotonic\nchunk-wise attention (AMoChA) mechanism is proposed to replace GSA for the\ncalculation of attention weight distribution. Furthermore, we propose two\nmethods to alleviate the huge performance degradation when combining LC and\nAMoChA. Finally, we successfully acquire an online LAS model, LC-AMoChA, which\nhas only 3.5% relative performance reduction to LAS baseline on our internal\nMandarin corpus.", "published": "2018-11-13 12:23:37", "link": "http://arxiv.org/abs/1811.05247v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Modality Attention for End-to-End Audio-visual Speech Recognition", "abstract": "Audio-visual speech recognition (AVSR) system is thought to be one of the\nmost promising solutions for robust speech recognition, especially in noisy\nenvironment. In this paper, we propose a novel multimodal attention based\nmethod for audio-visual speech recognition which could automatically learn the\nfused representation from both modalities based on their importance. Our method\nis realized using state-of-the-art sequence-to-sequence (Seq2seq)\narchitectures. Experimental results show that relative improvements from 2% up\nto 36% over the auditory modality alone are obtained depending on the different\nsignal-to-noise-ratio (SNR). Compared to the traditional feature concatenation\nmethods, our proposed approach can achieve better recognition performance under\nboth clean and noisy conditions. We believe modality attention based end-to-end\nmethod can be easily generalized to other multimodal tasks with correlated\ninformation.", "published": "2018-11-13 12:28:03", "link": "http://arxiv.org/abs/1811.05250v2", "categories": ["cs.CL", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Predicting Distresses using Deep Learning of Text Segments in Annual\n  Reports", "abstract": "Corporate distress models typically only employ the numerical financial\nvariables in the firms' annual reports. We develop a model that employs the\nunstructured textual data in the reports as well, namely the auditors' reports\nand managements' statements. Our model consists of a convolutional recurrent\nneural network which, when concatenated with the numerical financial variables,\nlearns a descriptive representation of the text that is suited for corporate\ndistress prediction. We find that the unstructured data provides a\nstatistically significant enhancement of the distress prediction performance,\nin particular for large firms where accurate predictions are of the utmost\nimportance. Furthermore, we find that auditors' reports are more informative\nthan managements' statements and that a joint model including both managements'\nstatements and auditors' reports displays no enhancement relative to a model\nincluding only auditors' reports. Our model demonstrates a direct improvement\nover existing state-of-the-art models.", "published": "2018-11-13 13:09:58", "link": "http://arxiv.org/abs/1811.05270v1", "categories": ["cs.CL", "q-fin.CP", "q-fin.RM"], "primary_category": "cs.CL"}
{"title": "Unsupervised Transfer Learning for Spoken Language Understanding in\n  Intelligent Agents", "abstract": "User interaction with voice-powered agents generates large amounts of\nunlabeled utterances. In this paper, we explore techniques to efficiently\ntransfer the knowledge from these unlabeled utterances to improve model\nperformance on Spoken Language Understanding (SLU) tasks. We use Embeddings\nfrom Language Model (ELMo) to take advantage of unlabeled data by learning\ncontextualized word representations. Additionally, we propose ELMo-Light\n(ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our\nfindings suggest unsupervised pre-training on a large corpora of unlabeled\nutterances leads to significantly better SLU performance compared to training\nfrom scratch and it can even outperform conventional supervised transfer.\nAdditionally, we show that the gains from unsupervised transfer techniques can\nbe further improved by supervised transfer. The improvements are more\npronounced in low resource settings and when using only 1000 labeled in-domain\nsamples, our techniques match the performance of training from scratch on\n10-15x more labeled in-domain data.", "published": "2018-11-13 15:44:31", "link": "http://arxiv.org/abs/1811.05370v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Towards Neural Machine Translation for African Languages", "abstract": "Given that South African education is in crisis, strategies for improvement\nand sustainability of high-quality, up-to-date education must be explored. In\nthe migration of education online, inclusion of machine translation for\nlow-resourced local languages becomes necessary. This paper aims to spur the\nuse of current neural machine translation (NMT) techniques for low-resourced\nlocal languages. The paper demonstrates state-of-the-art performance on\nEnglish-to-Setswana translation using the Autshumato dataset. The use of the\nTransformer architecture beat previous techniques by 5.33 BLEU points. This\ndemonstrates the promise of using current NMT techniques for African languages.", "published": "2018-11-13 06:49:08", "link": "http://arxiv.org/abs/1811.05467v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Few-shot Learning for Named Entity Recognition in Medical Text", "abstract": "Deep neural network models have recently achieved state-of-the-art\nperformance gains in a variety of natural language processing (NLP) tasks\n(Young, Hazarika, Poria, & Cambria, 2017). However, these gains rely on the\navailability of large amounts of annotated examples, without which\nstate-of-the-art performance is rarely achievable. This is especially\ninconvenient for the many NLP fields where annotated examples are scarce, such\nas medical text. To improve NLP models in this situation, we evaluate five\nimprovements on named entity recognition (NER) tasks when only ten annotated\nexamples are available: (1) layer-wise initialization with pre-trained weights,\n(2) hyperparameter tuning, (3) combining pre-training data, (4) custom word\nembeddings, and (5) optimizing out-of-vocabulary (OOV) words. Experimental\nresults show that the F1 score of 69.3% achievable by state-of-the-art models\ncan be improved to 78.87%.", "published": "2018-11-13 13:12:02", "link": "http://arxiv.org/abs/1811.05468v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "ML-Net: multi-label classification of biomedical texts with deep neural\n  networks", "abstract": "In multi-label text classification, each textual document can be assigned\nwith one or more labels. Due to this nature, the multi-label text\nclassification task is often considered to be more challenging compared to the\nbinary or multi-class text classification problems. As an important task with\nbroad applications in biomedicine such as assigning diagnosis codes, a number\nof different computational methods (e.g. training and combining binary\nclassifiers for each label) have been proposed in recent years. However, many\nsuffered from modest accuracy and efficiency, with only limited success in\npractical use. We propose ML-Net, a novel deep learning framework, for\nmulti-label classification of biomedical texts. As an end-to-end system, ML-Net\ncombines a label prediction network with an automated label count prediction\nmechanism to output an optimal set of labels by leveraging both predicted\nconfidence score of each label and the contextual information in the target\ndocument. We evaluate ML-Net on three independent, publicly-available corpora\nin two kinds of text genres: biomedical literature and clinical notes. For\nevaluation, example-based measures such as precision, recall and f-measure are\nused. ML-Net is compared with several competitive machine learning baseline\nmodels. Our benchmarking results show that ML-Net compares favorably to the\nstate-of-the-art methods in multi-label classification of biomedical texts.\nML-NET is also shown to be robust when evaluated on different text genres in\nbiomedicine. Unlike traditional machine learning methods, ML-Net does not\nrequire human efforts in feature engineering and is highly efficient and\nscalable approach to tasks with a large set of labels (no need to build\nindividual classifiers for each separate label). Finally, ML-NET is able to\ndynamically estimate the label count based on the document context in a more\nsystematic and accurate manner.", "published": "2018-11-13 17:31:49", "link": "http://arxiv.org/abs/1811.05475v2", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Staging Human-computer Dialogs: An Application of the Futamura\n  Projections", "abstract": "We demonstrate an application of the Futamura Projections to human-computer\ninteraction, and particularly to staging human-computer dialogs. Specifically,\nby providing staging analogs to the classical Futamura Projections, we\ndemonstrate that the Futamura Projections can be applied to the staging of\nhuman-computer dialogs in addition to the execution of programs.", "published": "2018-11-13 21:45:20", "link": "http://arxiv.org/abs/1811.05536v1", "categories": ["cs.PL", "cs.CL", "cs.HC", "cs.SC", "cs.SE"], "primary_category": "cs.PL"}
{"title": "Neural Wavetable: a playable wavetable synthesizer using neural networks", "abstract": "We present Neural Wavetable, a proof-of-concept wavetable synthesizer that\nuses neural networks to generate playable wavetables. The system can produce\nnew, distinct waveforms through the interpolation of traditional wavetables in\nan autoencoder's latent space. It is available as a VST/AU plugin for use in a\nDigital Audio Workstation.", "published": "2018-11-13 22:27:17", "link": "http://arxiv.org/abs/1811.05550v2", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Open-source platforms for fast room acoustic simulations in complex\n  structures", "abstract": "This article presents new numerical simulation tools, respectively developed\nin Matlab and Blender softwares. Available in open-source under the GPL 3.0\nlicense, it uses a ray-tracing/image-sources hybrid method to calculate the\nroom acoustics for large meshes. Performances are optimized to solve problems\nof significant size (typically more than 100,000 surface elements and about a\nmillion of rays). For this purpose, a Divide and Conquer approach with a\nrecursive binary tree structure has been implemented to reduce the quadratic\ncomplexity of the ray/element interactions to near-linear. Thus, execution\ntimes are less sensitive to the mesh density, which allows simulations of\ncomplex geometry. After ray propagation, a hybrid method leads to\nimage-sources, which can be visually analyzed to localize sound map. Finally,\nimpulse responses are constructed from the image-sources and FIR filters are\nproposed natively over 8 octave bands, taking into account material absorption\nproperties and propagation medium. This algorithm is validated by comparisons\nwith theoretical test cases. Furthermore, an example on a quite complex case,\nnamely the ancient theater of Orange is presented.", "published": "2018-11-13 14:41:25", "link": "http://arxiv.org/abs/1811.05784v1", "categories": ["eess.AS", "cs.CE", "cs.SD"], "primary_category": "eess.AS"}
