{"title": "KANOP: A Data-Efficient Option Pricing Model using Kolmogorov-Arnold Networks", "abstract": "Inspired by the recently proposed Kolmogorov-Arnold Networks (KANs), we\nintroduce the KAN-based Option Pricing (KANOP) model to value American-style\noptions, building on the conventional Least Square Monte Carlo (LSMC)\nalgorithm. KANs, which are based on Kolmogorov-Arnold representation theorem,\noffer a data-efficient alternative to traditional Multi-Layer Perceptrons,\nrequiring fewer hidden layers to achieve a higher level of performance. By\nleveraging the flexibility of KANs, KANOP provides a learnable alternative to\nthe conventional set of basis functions used in the LSMC model, allowing the\nmodel to adapt to the pricing task and effectively estimate the expected\ncontinuation value. Using examples of standard American and Asian-American\noptions, we demonstrate that KANOP produces more reliable option value\nestimates, both for single-dimensional cases and in more complex scenarios\ninvolving multiple input variables. The delta estimated by the KANOP model is\nalso more accurate than that obtained using conventional basis functions, which\nis crucial for effective option hedging. Graphical illustrations further\nvalidate KANOP's ability to accurately model the expected continuation value\nfor American-style options.", "published": "2024-10-01 05:56:43", "link": "http://arxiv.org/abs/2410.00419v1", "categories": ["q-fin.CP", "cs.CE", "q-fin.MF", "q-fin.PR"], "primary_category": "q-fin.CP"}
{"title": "Tax systems for sustainable economic development", "abstract": "A complete description of taxation systems that ensure sustainable economic\ndevelopment is given. These tax systems depend on production technologies and\ngross output volumes. Explicit formulas for such dependencies are found. In a\nsustainable economy, the value added either exceeds or is strictly less than\nthe value of the product produced. The latter is determined by the tax system.\nThe concept of perfect taxation systems is introduced and their explicit form\nis found. For perfect taxation systems, it is proved that the vector of gross\noutput should belong to the interior of the cone formed by the vectors of the\ncolumns of the total cost matrix. It is shown that under perfect taxation\nsystems the vector of gross output must satisfy a certain system of linear\nhomogeneous equations. It is shown, that under certain conditions there are tax\nsystems under which certain industries require subsidies for their existence.\nUnder such taxation systems, the industries that require subsidies are\nidentified. The family of all non negative solutions of the system of linear\nequations and inequalities is constructed, which allowed us to formulate a\ncriterion for describing all equilibrium states in which partial clearing of\nmarkets occurs.", "published": "2024-10-01 08:39:24", "link": "http://arxiv.org/abs/2410.00505v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Impermanent loss and loss-vs-rebalancing I: some statistical properties", "abstract": "There are two predominant metrics to assess the performance of automated\nmarket makers and their profitability for liquidity providers: 'impermanent\nloss' (IL) and 'loss-versus-rebalance' (LVR). In this short paper we shed light\non the statistical aspects of both concepts and show that they are more similar\nthan conventionally appreciated. Our analysis uses the properties of a random\nwalk and some analytical properties of the statistical integral combined with\nthe mechanics of a constant function market maker (CFMM). We consider non-toxic\nor rather unspecific trading in this paper. Our main finding can be summarized\nin one sentence: For Brownian motion with a given volatility, IL and LVR have\nidentical expectation values but vastly differing distribution functions.", "published": "2024-10-01 16:43:37", "link": "http://arxiv.org/abs/2410.00854v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "Hierarchical Organization Simulacra in the Investment Sector", "abstract": "This paper explores designing artificial organizations with professional\nbehavior in investments using a multi-agent simulation. The method mimics\nhierarchical decision-making in investment firms, using news articles to inform\ndecisions. A large-scale study analyzing over 115,000 news articles of 300\ncompanies across 15 years compared this approach against professional traders'\ndecisions. Results show that hierarchical simulations align closely with\nprofessional choices, both in frequency and profitability. However, the study\nalso reveals biases in decision-making, where changes in prompt wording and\nperceived agent seniority significantly influence outcomes. This highlights\nboth the potential and limitations of large language models in replicating\nprofessional financial decision-making.", "published": "2024-10-01 02:59:41", "link": "http://arxiv.org/abs/2410.00354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PclGPT: A Large Language Model for Patronizing and Condescending\n  Language Detection", "abstract": "Disclaimer: Samples in this paper may be harmful and cause discomfort!\n  Patronizing and condescending language (PCL) is a form of speech directed at\nvulnerable groups. As an essential branch of toxic language, this type of\nlanguage exacerbates conflicts and confrontations among Internet communities\nand detrimentally impacts disadvantaged groups. Traditional pre-trained\nlanguage models (PLMs) perform poorly in detecting PCL due to its implicit\ntoxicity traits like hypocrisy and false sympathy. With the rise of large\nlanguage models (LLMs), we can harness their rich emotional semantics to\nestablish a paradigm for exploring implicit toxicity. In this paper, we\nintroduce PclGPT, a comprehensive LLM benchmark designed specifically for PCL.\nWe collect, annotate, and integrate the Pcl-PT/SFT dataset, and then develop a\nbilingual PclGPT-EN/CN model group through a comprehensive pre-training and\nsupervised fine-tuning staircase process to facilitate implicit toxic\ndetection. Group detection results and fine-grained detection from PclGPT and\nother models reveal significant variations in the degree of bias in PCL towards\ndifferent vulnerable groups, necessitating increased societal attention to\nprotect them.", "published": "2024-10-01 03:19:13", "link": "http://arxiv.org/abs/2410.00361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unleashing the Potentials of Likelihood Composition for Multi-modal\n  Language Models", "abstract": "Model fusing has always been an important topic, especially in an era where\nlarge language models (LLM) and multi-modal language models (MLM) with\ndifferent architectures, parameter sizes and training pipelines, are being\ncreated all the time. In this work, we propose a post-hoc framework, aiming at\nfusing heterogeneous models off-the-shell, which we call \\textit{likelihood\ncomposition}, and the basic idea is to compose multiple models' likelihood\ndistribution when doing a multi-choice visual-question-answering task. Here the\ncore concept, \\textit{likelihood}, is actually the log-probability of the\ncandidate answer. In \\textit{likelihood composition}, we introduce some basic\noperations: \\textit{debias}, \\textit{highlight}, \\textit{majority-vote} and\n\\textit{ensemble}. By combining (composing) these basic elements, we get the\nmixed composition methods: \\textit{mix-composition}. Through conducting\ncomprehensive experiments on 9 VQA datasets and 10 MLMs, we prove the\neffectiveness of \\textit{mix-composition} compared with simple\n\\textit{ensemble} or \\textit{majority-vote} methods. In this framework, people\ncan propose new basic composition methods and combine them to get the new mixed\ncomposition methods. We hope our proposed \\textit{likelihood composition} can\nprovide a new perspective of fusing heterogeneous models and inspire the\nexploration under this framework.", "published": "2024-10-01 03:22:52", "link": "http://arxiv.org/abs/2410.00363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Answer When Needed, Forget When Not: Language Models Pretend to Forget\n  via In-Context Knowledge Unlearning", "abstract": "As large language models (LLMs) are applied across diverse domains, the\nability to selectively unlearn specific information has become increasingly\nessential. For instance, LLMs are expected to provide confidential information\nto authorized internal users, such as employees or trusted partners, while\nwithholding it from external users, including the general public and\nunauthorized entities. In response to this challenge, we propose a novel method\ntermed ``in-context knowledge unlearning'', which enables the model to\nselectively forget information in test-time based on the context of the query.\nOur method fine-tunes pre-trained LLMs to enable prompt unlearning of target\nknowledge within the context, while preserving other knowledge. Experiments on\nthe TOFU and AGE datasets using Llama2-7B/13B and Mistral-7B models show our\nmethod achieves up to 95% forgetting accuracy while retaining 80% of unrelated\nknowledge, significantly outperforming baselines in both in-domain and\nout-of-domain scenarios. Further investigation into the model's internal\nbehavior revealed that while fine-tuned LLMs generate correct predictions in\nthe middle layers and maintain them up to the final layer, they make the\ndecision to forget at the last layer, i.e., ``LLMs pretend to forget''. Our\nfindings offer valuable insights into enhancing the robustness of unlearning\nmechanisms in LLMs, setting a foundation for future research in the field.", "published": "2024-10-01 04:13:25", "link": "http://arxiv.org/abs/2410.00382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AlignSum: Data Pyramid Hierarchical Fine-tuning for Aligning with Human\n  Summarization Preference", "abstract": "Text summarization tasks commonly employ Pre-trained Language Models (PLMs)\nto fit diverse standard datasets. While these PLMs excel in automatic\nevaluations, they frequently underperform in human evaluations, indicating a\ndeviation between their generated summaries and human summarization\npreferences. This discrepancy is likely due to the low quality of fine-tuning\ndatasets and the limited availability of high-quality human-annotated data that\nreflect true human preference. To address this challenge, we introduce a novel\nhuman summarization preference alignment framework AlignSum. This framework\nconsists of three parts: Firstly, we construct a Data Pymarid with extractive,\nabstractive, and human-annotated summary data. Secondly, we conduct the\nGaussian Resampling to remove summaries with extreme lengths. Finally, we\nimplement the two-stage hierarchical fine-tuning with Data Pymarid after\nGaussian Resampling. We apply AlignSum to PLMs on the human-annotated\nCNN/DailyMail and BBC XSum datasets. Experiments show that with AlignSum, PLMs\nlike BART-Large surpass 175B GPT-3 in both automatic and human evaluations.\nThis demonstrates that AlignSum significantly enhances the alignment of\nlanguage models with human summarization preferences.", "published": "2024-10-01 05:14:48", "link": "http://arxiv.org/abs/2410.00409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Parsing with Candidate Expressions for Knowledge Base Question\n  Answering", "abstract": "Semantic parsers convert natural language to logical forms, which can be\nevaluated on knowledge bases (KBs) to produce denotations. Recent semantic\nparsers have been developed with sequence-to-sequence (seq2seq) pre-trained\nlanguage models (PLMs) or large language models, where the models treat logical\nforms as sequences of tokens. For syntactic and semantic validity, the semantic\nparsers use grammars that enable constrained decoding. However, the grammars\nlack the ability to utilize large information of KBs, although logical forms\ncontain representations of KB elements, such as entities or relations. In this\nwork, we propose a grammar augmented with candidate expressions for semantic\nparsing on a large KB with a seq2seq PLM. The grammar defines actions as\nproduction rules, and our semantic parser predicts actions during inference\nunder the constraints by types and candidate expressions. We apply the grammar\nto knowledge base question answering, where the constraints by candidate\nexpressions assist a semantic parser to generate valid KB elements. We also\nintroduce two special rules, sub-type inference and union types, and a mask\ncaching algorithm. In particular, sub-type inference and the mask caching\nalgorithm greatly increase the decoding speed of our semantic parser. We\nexperimented on two benchmarks, KQA Pro and Overnight, where the constraints by\ncandidate expressions increased the accuracy of our semantic parser, whether it\nwas trained with strong supervision or weak supervision. In addition, our\nsemantic parser had a fast decoding speed in the experiments.", "published": "2024-10-01 05:46:22", "link": "http://arxiv.org/abs/2410.00414v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are LLMs Aware that Some Questions are not Open-ended?", "abstract": "Large Language Models (LLMs) have shown the impressive capability of\nanswering questions in a wide range of scenarios. However, when LLMs face\ndifferent types of questions, it is worth exploring whether LLMs are aware that\nsome questions have limited answers and need to respond more deterministically\nbut some do not. We refer to this as question awareness of LLMs. The lack of\nquestion awareness in LLMs leads to two phenomena that LLMs are: (1) too casual\nto answer non-open-ended questions or (2) too boring to answer open-ended\nquestions. In this paper, we first evaluate the question awareness in LLMs. The\nexperimental results show that LLMs have the issues of lacking awareness of\nquestions in certain domains, e.g. factual knowledge, resulting in\nhallucinations during the generation. To mitigate these, we propose a method\ncalled Question Awareness Temperature Sampling (QuATS). This method enhances\nthe question awareness of LLMs by adaptively adjusting the output distributions\nbased on question features. The automatic adjustment in QuATS eliminates the\nneed for manual temperature tuning in text generation and consistently improves\nmodel performance in various benchmarks.", "published": "2024-10-01 06:07:00", "link": "http://arxiv.org/abs/2410.00423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Updatable Large Language Models by Integrating Context into Model\n  Parameters", "abstract": "Despite significant advancements in large language models (LLMs), the rapid\nand frequent integration of small-scale experiences, such as interactions with\nsurrounding objects, remains a substantial challenge. Two critical factors in\nassimilating these experiences are (1) Efficacy: the ability to accurately\nremember recent events; (2) Retention: the capacity to recall long-past\nexperiences. Current methods either embed experiences within model parameters\nusing continual learning, model editing, or knowledge distillation techniques,\nwhich often struggle with rapid updates and complex interactions, or rely on\nexternal storage to achieve long-term retention, thereby increasing storage\nrequirements. In this paper, we propose SELF-PARAM (Self-Updatable Large\nLanguage Models with Parameter Integration). SELF-PARAM requires no extra\nparameters while ensuring near-optimal efficacy and long-term retention. Our\nmethod employs a training objective that minimizes the Kullback-Leibler (KL)\ndivergence between the predictions of an original model (with access to\ncontextual information) and a target model (without such access). By generating\ndiverse question-answer pairs related to the knowledge and minimizing the KL\ndivergence across this dataset, we update the target model to internalize the\nknowledge seamlessly within its parameters. Evaluations on question-answering\nand conversational recommendation tasks demonstrate that SELF-PARAM\nsignificantly outperforms existing methods, even when accounting for non-zero\nstorage requirements. This advancement paves the way for more efficient and\nscalable integration of experiences in large language models by embedding\nknowledge directly into model parameters.", "published": "2024-10-01 08:18:17", "link": "http://arxiv.org/abs/2410.00487v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Annotation Guidelines for Corpus Novelties: Part 2 -- Alias Resolution\n  Version 1.0", "abstract": "The Novelties corpus is a collection of novels (and parts of novels)\nannotated for Alias Resolution, among other tasks. This document describes the\nguidelines applied during the annotation process. It contains the instructions\nused by the annotators, as well as a number of examples retrieved from the\nannotated novels, and illustrating how canonical names should be defined, and\nwhich names should be considered as referring to the same entity.", "published": "2024-10-01 09:06:52", "link": "http://arxiv.org/abs/2410.00522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Large Language Models for Conversational Question Answering\n  in Multi-instructional Documents", "abstract": "Instructional documents are rich sources of knowledge for completing various\ntasks, yet their unique challenges in conversational question answering (CQA)\nhave not been thoroughly explored. Existing benchmarks have primarily focused\non basic factual question-answering from single narrative documents, making\nthem inadequate for assessing a model`s ability to comprehend complex\nreal-world instructional documents and provide accurate step-by-step guidance\nin daily life. To bridge this gap, we present InsCoQA, a novel benchmark\ntailored for evaluating large language models (LLMs) in the context of CQA with\ninstructional documents. Sourced from extensive, encyclopedia-style\ninstructional content, InsCoQA assesses models on their ability to retrieve,\ninterpret, and accurately summarize procedural guidance from multiple\ndocuments, reflecting the intricate and multi-faceted nature of real-world\ninstructional tasks. Additionally, to comprehensively assess state-of-the-art\nLLMs on the InsCoQA benchmark, we propose InsEval, an LLM-assisted evaluator\nthat measures the integrity and accuracy of generated responses and procedural\ninstructions.", "published": "2024-10-01 09:10:00", "link": "http://arxiv.org/abs/2410.00526v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine\n  Translation with a Human-centered Study", "abstract": "Gender bias in machine translation (MT) is recognized as an issue that can\nharm people and society. And yet, advancements in the field rarely involve\npeople, the final MT users, or inform how they might be impacted by biased\ntechnologies. Current evaluations are often restricted to automatic methods,\nwhich offer an opaque estimate of what the downstream impact of gender\ndisparities might be. We conduct an extensive human-centered study to examine\nif and to what extent bias in MT brings harms with tangible costs, such as\nquality of service gaps across women and men. To this aim, we collect\nbehavioral data from 90 participants, who post-edited MT outputs to ensure\ncorrect gender translation. Across multiple datasets, languages, and types of\nusers, our study shows that feminine post-editing demands significantly more\ntechnical and temporal effort, also corresponding to higher financial costs.\nExisting bias measurements, however, fail to reflect the found disparities. Our\nfindings advocate for human-centered approaches that can inform the societal\nimpact of bias.", "published": "2024-10-01 09:38:34", "link": "http://arxiv.org/abs/2410.00545v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style-Specific Neurons for Steering LLMs in Text Style Transfer", "abstract": "Text style transfer (TST) aims to modify the style of a text without altering\nits original meaning. Large language models (LLMs) demonstrate superior\nperformance across multiple tasks, including TST. However, in zero-shot setups,\nthey tend to directly copy a significant portion of the input text to the\noutput without effectively changing its style. To enhance the stylistic variety\nand fluency of the text, we present sNeuron-TST, a novel approach for steering\nLLMs using style-specific neurons in TST. Specifically, we identify neurons\nassociated with the source and target styles and deactivate source-style-only\nneurons to give target-style words a higher probability, aiming to enhance the\nstylistic diversity of the generated text. However, we find that this\ndeactivation negatively impacts the fluency of the generated text, which we\naddress by proposing an improved contrastive decoding method that accounts for\nrapid token probability shifts across layers caused by deactivated source-style\nneurons. Empirical experiments demonstrate the effectiveness of the proposed\nmethod on six benchmarks, encompassing formality, toxicity, politics,\npoliteness, authorship, and sentiment.", "published": "2024-10-01 11:25:36", "link": "http://arxiv.org/abs/2410.00593v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecci\u00f3n Autom\u00e1tica de Patolog\u00edas en Notas Cl\u00ednicas en\n  Espa\u00f1ol Combinando Modelos de Lenguaje y Ontolog\u00edas M\u00e9dicos", "abstract": "In this paper we present a hybrid method for the automatic detection of\ndermatological pathologies in medical reports. We use a large language model\ncombined with medical ontologies to predict, given a first appointment or\nfollow-up medical report, the pathology a person may suffer from. The results\nshow that teaching the model to learn the type, severity and location on the\nbody of a dermatological pathology as well as in which order it has to learn\nthese three features significantly increases its accuracy. The article presents\nthe demonstration of state-of-the-art results for classification of medical\ntexts with a precision of 0.84, micro and macro F1-score of 0.82 and 0.75, and\nmakes both the method and the dataset used available to the community.\n  --\n  En este art\\'iculo presentamos un m\\'etodo h\\'ibrido para la detecci\\'on\nautom\\'atica de patolog\\'ias dermatol\\'ogicas en informes m\\'edicos. Usamos un\nmodelo de lenguaje amplio en espa\\~nol combinado con ontolog\\'ias m\\'edicas\npara predecir, dado un informe m\\'edico de primera cita o de seguimiento, la\npatolog\\'ia del paciente. Los resultados muestran que el tipo, la gravedad y el\nsitio en el cuerpo de una patolog\\'ia dermatol\\'ogica, as\\'i como en qu\\'e\norden tiene un modelo que aprender esas tres caracter\\'isticas, aumentan su\nprecisi\\'on. El art\\'iculo presenta la demostraci\\'on de resultados comparables\nal estado del arte de clasificaci\\'on de textos m\\'edicos con una precisi\\'on\nde 0.84, micro y macro F1-score de 0.82 y 0.75, y deja a disposici\\'on de la\ncomunidad tanto el m\\'etodo como el conjunto de datos utilizado.", "published": "2024-10-01 12:03:04", "link": "http://arxiv.org/abs/2410.00616v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Optimizing Token Usage on Large Language Model Conversations Using the\n  Design Structure Matrix", "abstract": "As Large Language Models become ubiquitous in many sectors and tasks, there\nis a need to reduce token usage, overcoming challenges such as short context\nwindows, limited output sizes, and costs associated with token intake and\ngeneration, especially in API-served LLMs. This work brings the Design\nStructure Matrix from the engineering design discipline into LLM conversation\noptimization. Applied to a use case in which the LLM conversation is about the\ndesign of a spacecraft and its subsystems, the DSM, with its analysis tools\nsuch as clustering and sequencing, demonstrates being an effective tool to\norganize the conversation, minimizing the number of tokens sent to or retrieved\nfrom the LLM at once, as well as grouping chunks that can be allocated to\ndifferent context windows. Hence, this work broadens the current set of\nmethodologies for token usage optimization and opens new avenues for the\nintegration of engineering design practices into LLMs.", "published": "2024-10-01 14:38:36", "link": "http://arxiv.org/abs/2410.00749v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thinking Outside of the Differential Privacy Box: A Case Study in Text\n  Privatization with Language Model Prompting", "abstract": "The field of privacy-preserving Natural Language Processing has risen in\npopularity, particularly at a time when concerns about privacy grow with the\nproliferation of Large Language Models. One solution consistently appearing in\nrecent literature has been the integration of Differential Privacy (DP) into\nNLP techniques. In this paper, we take these approaches into critical view,\ndiscussing the restrictions that DP integration imposes, as well as bring to\nlight the challenges that such restrictions entail. To accomplish this, we\nfocus on $\\textbf{DP-Prompt}$, a recent method for text privatization\nleveraging language models to rewrite texts. In particular, we explore this\nrewriting task in multiple scenarios, both with DP and without DP. To drive the\ndiscussion on the merits of DP in NLP, we conduct empirical utility and privacy\nexperiments. Our results demonstrate the need for more discussion on the\nusability of DP in NLP and its benefits over non-DP approaches.", "published": "2024-10-01 14:46:15", "link": "http://arxiv.org/abs/2410.00751v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoding Hate: Exploring Language Models' Reactions to Hate Speech", "abstract": "Hate speech is a harmful form of online expression, often manifesting as\nderogatory posts. It is a significant risk in digital environments. With the\nrise of Large Language Models (LLMs), there is concern about their potential to\nreplicate hate speech patterns, given their training on vast amounts of\nunmoderated internet data. Understanding how LLMs respond to hate speech is\ncrucial for their responsible deployment. However, the behaviour of LLMs\ntowards hate speech has been limited compared. This paper investigates the\nreactions of seven state-of-the-art LLMs (LLaMA 2, Vicuna, LLaMA 3, Mistral,\nGPT-3.5, GPT-4, and Gemini Pro) to hate speech. Through qualitative analysis,\nwe aim to reveal the spectrum of responses these models produce, highlighting\ntheir capacity to handle hate speech inputs. We also discuss strategies to\nmitigate hate speech generation by LLMs, particularly through fine-tuning and\nguideline guardrailing. Finally, we explore the models' responses to hate\nspeech framed in politically correct language.", "published": "2024-10-01 15:16:20", "link": "http://arxiv.org/abs/2410.00775v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantifying reliance on external information over parametric knowledge\n  during Retrieval Augmented Generation (RAG) using mechanistic analysis", "abstract": "Retrieval Augmented Generation (RAG) is a widely used approach for leveraging\nexternal context in several natural language applications such as question\nanswering and information retrieval. Yet, the exact nature in which a Language\nModel (LM) leverages this non-parametric memory or retrieved context isn't\nclearly understood. This paper mechanistically examines the RAG pipeline to\nhighlight that LMs demonstrate a \"shortcut'' effect and have a strong bias\ntowards utilizing the retrieved context to answer questions, while relying\nminimally on model priors. We propose (a) Causal Mediation Analysis; for\nproving that parametric memory is minimally utilized when answering a question\nand (b) Attention Contributions and Knockouts for showing the last token\nresidual stream do not get enriched from the subject token in the question, but\ngets enriched from tokens of RAG-context. We find this pronounced \"shortcut''\nbehaviour to be true across both LLMs (e.g.,LlaMa) and SLMs (e.g., Phi)", "published": "2024-10-01 16:48:13", "link": "http://arxiv.org/abs/2410.00857v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Implications of Verbose LLM Outputs: A Case Study in Translation\n  Evaluation", "abstract": "This paper investigates the impact of verbose LLM translations on evaluation.\nWe first demonstrate the prevalence of this behavior across several LLM outputs\ndrawn from the WMT 2024 general shared task on machine translation. We then\nidentify the primary triggers of verbosity, including safety, copyright\nconcerns, and insufficient context in short input queries. Finally, we show\nthat ignoring this behavior unfairly penalizes more verbose LLMs according to\nboth automatic and human evaluations, highlighting the need to address this\nissue for more accurate future evaluations.", "published": "2024-10-01 16:59:01", "link": "http://arxiv.org/abs/2410.00863v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Addition is All You Need for Energy-efficient Language Models", "abstract": "Large neural networks spend most computation on floating point tensor\nmultiplications. In this work, we find that a floating point multiplier can be\napproximated by one integer adder with high precision. We propose the\nlinear-complexity multiplication L-Mul algorithm that approximates floating\npoint number multiplication with integer addition operations. The new algorithm\ncosts significantly less computation resource than 8-bit floating point\nmultiplication but achieves higher precision. Compared to 8-bit floating point\nmultiplications, the proposed method achieves higher precision but consumes\nsignificantly less bit-level computation. Since multiplying floating point\nnumbers requires substantially higher energy compared to integer addition\noperations, applying the L-Mul operation in tensor processing hardware can\npotentially reduce 95% energy cost by element-wise floating point tensor\nmultiplications and 80% energy cost of dot products. We calculated the\ntheoretical error expectation of L-Mul, and evaluated the algorithm on a wide\nrange of textual, visual, and symbolic tasks, including natural language\nunderstanding, structural reasoning, mathematics, and commonsense question\nanswering. Our numerical analysis experiments agree with the theoretical error\nestimation, which indicates that L-Mul with 4-bit mantissa achieves comparable\nprecision as float8_e4m3 multiplications, and L-Mul with 3-bit mantissa\noutperforms float8_e5m2. Evaluation results on popular benchmarks show that\ndirectly applying L-Mul to the attention mechanism is almost lossless. We\nfurther show that replacing all floating point multiplications with 3-bit\nmantissa L-Mul in a transformer model achieves equivalent precision as using\nfloat8_e4m3 as accumulation precision in both fine-tuning and inference.", "published": "2024-10-01 17:53:28", "link": "http://arxiv.org/abs/2410.00907v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Speech Recognition for the Ika Language", "abstract": "We present a cost-effective approach for developing Automatic Speech\nRecognition (ASR) models for low-resource languages like Ika. We fine-tune the\npretrained wav2vec 2.0 Massively Multilingual Speech Models on a high-quality\nspeech dataset compiled from New Testament Bible translations in Ika. Our\nresults show that fine-tuning multilingual pretrained models achieves a Word\nError Rate (WER) of 0.5377 and Character Error Rate (CER) of 0.2651 with just\nover 1 hour of training data. The larger 1 billion parameter model outperforms\nthe smaller 300 million parameter model due to its greater complexity and\nability to store richer speech representations. However, we observe overfitting\nto the small training dataset, reducing generalizability. Our findings\ndemonstrate the potential of leveraging multilingual pretrained models for\nlow-resource languages. Future work should focus on expanding the dataset and\nexploring techniques to mitigate overfitting.", "published": "2024-10-01 11:56:42", "link": "http://arxiv.org/abs/2410.00940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Creative and Context-Aware Translation of East Asian Idioms with GPT-4", "abstract": "As a type of figurative language, an East Asian idiom condenses rich cultural\nbackground into only a few characters. Translating such idioms is challenging\nfor human translators, who often resort to choosing a context-aware translation\nfrom an existing list of candidates. However, compiling a dictionary of\ncandidate translations demands much time and creativity even for expert\ntranslators. To alleviate such burden, we evaluate if GPT-4 can help generate\nhigh-quality translations. Based on automatic evaluations of faithfulness and\ncreativity, we first identify Pareto-optimal prompting strategies that can\noutperform translation engines from Google and DeepL. Then, at a low cost, our\ncontext-aware translations can achieve far more high-quality translations per\nidiom than the human baseline. We open-source all code and data to facilitate\nfurther research.", "published": "2024-10-01 18:24:43", "link": "http://arxiv.org/abs/2410.00988v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"Hiding in Plain Sight\": Designing Synthetic Dialog Generation for\n  Uncovering Socially Situated Norms", "abstract": "Naturally situated conversations capture the underlying social norms\nappropriate for the topic of conversation, the relationship between\ninterlocutors and their communicative intent. This paper proposes a framework\nfor controlled generation of dialogues, spanning a wide range of interlocutors\nattributes (such as age group, profession and personality types), relationship\ntypes, conversation topics and conversational trajectories. We use this\nframework to generate NormHint, a collection of dialogues consistent with these\nrich settings and analyzed for norm violation leading to conflicts, and\npotential steps for avoiding these conflicts by adhering to social norms and\npreferring respectful utterances maintaining the communicative intents of the\noriginal utterance. We present the results of human validation and automated\nanalysis of NormHint and show it captures a wide range of conversational topics\nand scored highly by humans for the naturalness of the conversations based on\nthe prompted context.", "published": "2024-10-01 18:38:23", "link": "http://arxiv.org/abs/2410.00998v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Draft on the Fly: Adaptive Self-Speculative Decoding using Cosine\n  Similarity", "abstract": "We present a simple on the fly method for faster inference of large language\nmodels. Unlike other (self-)speculative decoding techniques, our method does\nnot require fine-tuning or black-box optimization to generate a fixed draft\nmodel, relying instead on simple rules to generate varying draft models adapted\nto the input context. We show empirically that our light-weight algorithm is\ncompetitive with the current SOTA for self-speculative decoding, while being a\ntruly plug-and-play method.", "published": "2024-10-01 19:35:23", "link": "http://arxiv.org/abs/2410.01028v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Facts to Insights: A Study on the Generation and Evaluation of\n  Analytical Reports for Deciphering Earnings Calls", "abstract": "This paper explores the use of Large Language Models (LLMs) in the generation\nand evaluation of analytical reports derived from Earnings Calls (ECs).\nAddressing a current gap in research, we explore the generation of analytical\nreports with LLMs in a multi-agent framework, designing specialized agents that\nintroduce diverse viewpoints and desirable topics of analysis into the report\ngeneration process. Through multiple analyses, we examine the alignment between\ngenerated and human-written reports and the impact of both individual and\ncollective agents. Our findings suggest that the introduction of additional\nagents results in more insightful reports, although reports generated by human\nexperts remain preferred in the majority of cases. Finally, we address the\nchallenging issue of report evaluation, we examine the limitations and\nstrengths of LLMs in assessing the quality of generated reports in different\nsettings, revealing a significant correlation with human experts across\nmultiple dimensions.", "published": "2024-10-01 20:03:22", "link": "http://arxiv.org/abs/2410.01039v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Concept Space Alignment in Multilingual LLMs", "abstract": "Multilingual large language models (LLMs) seem to generalize somewhat across\nlanguages. We hypothesize this is a result of implicit vector space alignment.\nEvaluating such alignment, we see that larger models exhibit very high-quality\nlinear alignments between corresponding concepts in different languages. Our\nexperiments show that multilingual LLMs suffer from two familiar weaknesses:\ngeneralization works best for languages with similar typology, and for abstract\nconcepts. For some models, e.g., the Llama-2 family of models, prompt-based\nembeddings align better than word embeddings, but the projections are less\nlinear -- an observation that holds across almost all model families,\nindicating that some of the implicitly learned alignments are broken somewhat\nby prompt-based methods.", "published": "2024-10-01 21:21:00", "link": "http://arxiv.org/abs/2410.01079v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unlocking Korean Verbs: A User-Friendly Exploration into the Verb\n  Lexicon", "abstract": "The Sejong dictionary dataset offers a valuable resource, providing extensive\ncoverage of morphology, syntax, and semantic representation. This dataset can\nbe utilized to explore linguistic information in greater depth. The labeled\nlinguistic structures within this dataset form the basis for uncovering\nrelationships between words and phrases and their associations with target\nverbs. This paper introduces a user-friendly web interface designed for the\ncollection and consolidation of verb-related information, with a particular\nfocus on subcategorization frames. Additionally, it outlines our efforts in\nmapping this information by aligning subcategorization frames with\ncorresponding illustrative sentence examples. Furthermore, we provide a Python\nlibrary that would simplify syntactic parsing and semantic role labeling. These\ntools are intended to assist individuals interested in harnessing the Sejong\ndictionary dataset to develop applications for Korean language processing.", "published": "2024-10-01 22:03:34", "link": "http://arxiv.org/abs/2410.01100v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Enhanced Model for Eye (LEME): An Open-Source\n  Ophthalmology-Specific Large Language Model", "abstract": "Large Language Models (LLMs) are poised to revolutionize healthcare.\nOphthalmology-specific LLMs remain scarce and underexplored. We introduced an\nopen-source, specialized LLM for ophthalmology, termed Language Enhanced Model\nfor Eye (LEME). LEME was initially pre-trained on the Llama2 70B framework and\nfurther fine-tuned with a corpus of ~127,000 non-copyrighted training instances\ncurated from ophthalmology-specific case reports, abstracts, and open-source\nstudy materials. We benchmarked LEME against eight other LLMs, namely, GPT-3.5,\nGPT-4, three Llama2 models (7B, 13B, 70B), PMC-LLAMA 13B, Meditron 70B, and\nEYE-Llama (another ophthalmology-specific LLM). Evaluations included four\ninternal validation tasks: abstract completion, fill-in-the-blank,\nmultiple-choice questions (MCQ), and short-answer QA. External validation tasks\nencompassed long-form QA, MCQ, patient EHR summarization, and clinical QA.\nEvaluation metrics included Rouge-L scores, accuracy, and expert evaluation of\ncorrectness, completeness, and readability. In internal validations, LEME\nconsistently outperformed its counterparts, achieving Rouge-L scores of 0.20 in\nabstract completion (all p<0.05), 0.82 in fill-in-the-blank (all p<0.0001), and\n0.22 in short-answer QA (all p<0.0001, except versus GPT-4). In external\nvalidations, LEME excelled in long-form QA with a Rouge-L of 0.19 (all\np<0.0001), ranked second in MCQ accuracy (0.68; all p<0.0001), and scored\nhighest in EHR summarization and clinical QA (ranging from 4.24 to 4.83 out of\n5 for correctness, completeness, and readability).\n  LEME's emphasis on robust fine-tuning and the use of non-copyrighted data\nrepresents a breakthrough in open-source ophthalmology-specific LLMs, offering\nthe potential to revolutionize execution of clinical tasks while democratizing\nresearch collaboration.", "published": "2024-10-01 02:43:54", "link": "http://arxiv.org/abs/2410.03740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Insight: A Multi-Modal Diagnostic Pipeline using LLMs for Ocular Surface\n  Disease Diagnosis", "abstract": "Accurate diagnosis of ocular surface diseases is critical in optometry and\nophthalmology, which hinge on integrating clinical data sources (e.g.,\nmeibography imaging and clinical metadata). Traditional human assessments lack\nprecision in quantifying clinical observations, while current machine-based\nmethods often treat diagnoses as multi-class classification problems, limiting\nthe diagnoses to a predefined closed-set of curated answers without reasoning\nthe clinical relevance of each variable to the diagnosis. To tackle these\nchallenges, we introduce an innovative multi-modal diagnostic pipeline (MDPipe)\nby employing large language models (LLMs) for ocular surface disease diagnosis.\nWe first employ a visual translator to interpret meibography images by\nconverting them into quantifiable morphology data, facilitating their\nintegration with clinical metadata and enabling the communication of nuanced\nmedical insight to LLMs. To further advance this communication, we introduce a\nLLM-based summarizer to contextualize the insight from the combined morphology\nand clinical metadata, and generate clinical report summaries. Finally, we\nrefine the LLMs' reasoning ability with domain-specific insight from real-life\nclinician diagnoses. Our evaluation across diverse ocular surface disease\ndiagnosis benchmarks demonstrates that MDPipe outperforms existing standards,\nincluding GPT-4, and provides clinically sound rationales for diagnoses.", "published": "2024-10-01 00:23:05", "link": "http://arxiv.org/abs/2410.00292v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "PointAD: Comprehending 3D Anomalies from Points and Pixels for Zero-shot\n  3D Anomaly Detection", "abstract": "Zero-shot (ZS) 3D anomaly detection is a crucial yet unexplored field that\naddresses scenarios where target 3D training samples are unavailable due to\npractical concerns like privacy protection. This paper introduces PointAD, a\nnovel approach that transfers the strong generalization capabilities of CLIP\nfor recognizing 3D anomalies on unseen objects. PointAD provides a unified\nframework to comprehend 3D anomalies from both points and pixels. In this\nframework, PointAD renders 3D anomalies into multiple 2D renderings and\nprojects them back into 3D space. To capture the generic anomaly semantics into\nPointAD, we propose hybrid representation learning that optimizes the learnable\ntext prompts from 3D and 2D through auxiliary point clouds. The collaboration\noptimization between point and pixel representations jointly facilitates our\nmodel to grasp underlying 3D anomaly patterns, contributing to detecting and\nsegmenting anomalies of unseen diverse 3D objects. Through the alignment of 3D\nand 2D space, our model can directly integrate RGB information, further\nenhancing the understanding of 3D anomalies in a plug-and-play manner.\nExtensive experiments show the superiority of PointAD in ZS 3D anomaly\ndetection across diverse unseen objects.", "published": "2024-10-01 01:40:22", "link": "http://arxiv.org/abs/2410.00320v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Preserving Generalization of Language models in Few-shot Continual\n  Relation Extraction", "abstract": "Few-shot Continual Relations Extraction (FCRE) is an emerging and dynamic\narea of study where models can sequentially integrate knowledge from new\nrelations with limited labeled data while circumventing catastrophic forgetting\nand preserving prior knowledge from pre-trained backbones. In this work, we\nintroduce a novel method that leverages often-discarded language model heads.\nBy employing these components via a mutual information maximization strategy,\nour approach helps maintain prior knowledge from the pre-trained backbone and\nstrategically aligns the primary classification head, thereby enhancing model\nperformance. Furthermore, we explore the potential of Large Language Models\n(LLMs), renowned for their wealth of knowledge, in addressing FCRE challenges.\nOur comprehensive experimental results underscore the efficacy of the proposed\nmethod and offer valuable insights for future work.", "published": "2024-10-01 02:22:34", "link": "http://arxiv.org/abs/2410.00334v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-controller: Controlling LLMs with Multi-round Step-by-step\n  Self-awareness", "abstract": "The applications of large language models (LLMs) have been widely spread\nacross all domains. However, the basic abilities such as the controllability of\nLLMs are still limited. To address this, we propose \"Self-controller\", a novel\nagentic framework bringing self-awareness into LLMs' reasoning logic. The core\nidea of this work is to maintain states based on the LLM's response, letting\nthe LLM become self-aware of current status and think step by step in a\nmulti-round chain-of-thought paradigm. Our experiment on the state of textual\nlength has shown the controllability and effectiveness of the Self-controller.\nWe further implement a binary search algorithm to accelerate the generation\nprocess based on the linearity and monotonicity of the textual length state.\nAnother advantage of the Self-controller comes with DeepSeek's Context Caching\ntechnology, which significantly saves computational token consumption when a\ncluster of conversations shares the same prefix of context. Theoretically, we\nprove that in this scenario the extra time complexity is $O(c \\log n)$. Results\nof the back-of-the-envelope estimation suggest that the token consumption of\nour method is no more than twice as much as that of the trivial single-round\ngeneration. Furthermore, our ablation study on word constraints demonstrates\nthe Self-controller's consistent controllability across all foundation models.", "published": "2024-10-01 03:14:12", "link": "http://arxiv.org/abs/2410.00359v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FedPT: Federated Proxy-Tuning of Large Language Models on\n  Resource-Constrained Edge Devices", "abstract": "Despite demonstrating superior performance across a variety of linguistic\ntasks, pre-trained large language models (LMs) often require fine-tuning on\nspecific datasets to effectively address different downstream tasks. However,\nfine-tuning these LMs for downstream tasks necessitates collecting data from\nindividuals, which raises significant privacy concerns. Federated learning (FL)\nhas emerged as the de facto solution, enabling collaborative model training\nwithout sharing raw data. While promising, federated fine-tuning of large LMs\nfaces significant challenges, including restricted access to model parameters\nand high computation, communication, and memory overhead. To address these\nchallenges, this paper introduces \\textbf{Fed}erated\n\\textbf{P}roxy-\\textbf{T}uning (FedPT), a novel framework for federated\nfine-tuning of black-box large LMs, requiring access only to their predictions\nover the output vocabulary instead of their parameters. Specifically, devices\nin FedPT first collaboratively tune a smaller LM, and then the server combines\nthe knowledge learned by the tuned small LM with the knowledge learned by the\nlarger pre-trained LM to construct a large proxy-tuned LM that can reach the\nperformance of directly tuned large LMs. The experimental results demonstrate\nthat FedPT can significantly reduce computation, communication, and memory\noverhead while maintaining competitive performance compared to directly\nfederated fine-tuning of large LMs. FedPT offers a promising solution for\nefficient, privacy-preserving fine-tuning of large LMs on resource-constrained\ndevices, broadening the accessibility and applicability of state-of-the-art\nlarge LMs.", "published": "2024-10-01 03:20:39", "link": "http://arxiv.org/abs/2410.00362v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Boosting the Capabilities of Compact Models in Low-Data Contexts with\n  Large Language Models and Retrieval-Augmented Generation", "abstract": "The data and compute requirements of current language modeling technology\npose challenges for the processing and analysis of low-resource languages.\nDeclarative linguistic knowledge has the potential to partially bridge this\ndata scarcity gap by providing models with useful inductive bias in the form of\nlanguage-specific rules. In this paper, we propose a retrieval augmented\ngeneration (RAG) framework backed by a large language model (LLM) to correct\nthe output of a smaller model for the linguistic task of morphological\nglossing. We leverage linguistic information to make up for the lack of data\nand trainable parameters, while allowing for inputs from written descriptive\ngrammars interpreted and distilled through an LLM.\n  The results demonstrate that significant leaps in performance and efficiency\nare possible with the right combination of: a) linguistic inputs in the form of\ngrammars, b) the interpretive power of LLMs, and c) the trainability of smaller\ntoken classification networks. We show that a compact, RAG-supported model is\nhighly effective in data-scarce settings, achieving a new state-of-the-art for\nthis task and our target languages. Our work also offers documentary linguists\na more reliable and more usable tool for morphological glossing by providing\nwell-reasoned explanations and confidence scores for each output.", "published": "2024-10-01 04:20:14", "link": "http://arxiv.org/abs/2410.00387v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TPN: Transferable Proto-Learning Network towards Few-shot Document-Level\n  Relation Extraction", "abstract": "Few-shot document-level relation extraction suffers from poor performance due\nto the challenging cross-domain transferability of NOTA (none-of-the-above)\nrelation representation. In this paper, we introduce a Transferable\nProto-Learning Network (TPN) to address the challenging issue. It comprises\nthree core components: Hybrid Encoder hierarchically encodes semantic content\nof input text combined with attention information to enhance the relation\nrepresentations. As a plug-and-play module for Out-of-Domain (OOD) Detection,\nTransferable Proto-Learner computes NOTA prototype through an adaptive\nlearnable block, effectively mitigating NOTA bias across various domains.\nDynamic Weighting Calibrator detects relation-specific classification\nconfidence, serving as dynamic weights to calibrate the NOTA-dominant loss\nfunction. Finally, to bolster the model's cross-domain performance, we\ncomplement it with virtual adversarial training (VAT). We conduct extensive\nexperimental analyses on FREDo and ReFREDo, demonstrating the superiority of\nTPN. Compared to state-of-the-art methods, our approach achieves competitive\nperformance with approximately half the parameter size. Data and code are\navailable at https://github.com/EchoDreamer/TPN.", "published": "2024-10-01 05:37:31", "link": "http://arxiv.org/abs/2410.00412v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Conversational Exploratory Search of Scholarly Publications Using\n  Knowledge Graphs", "abstract": "Traditional search methods primarily depend on string matches, while semantic\nsearch targets concept-based matches by recognizing underlying intents and\ncontextual meanings of search terms. Semantic search is particularly beneficial\nfor discovering scholarly publications where differences in vocabulary between\nusers' search terms and document content are common, often yielding irrelevant\nsearch results. Many scholarly search engines have adopted knowledge graphs to\nrepresent semantic relations between authors, publications, and research\nconcepts. However, users may face challenges when navigating these graphical\nsearch interfaces due to the complexity and volume of data, which impedes their\nability to discover publications effectively. To address this problem, we\ndeveloped a conversational search system for exploring scholarly publications\nusing a knowledge graph. We outline the methodical approach for designing and\nimplementing the proposed system, detailing its architecture and functional\ncomponents. To assess the system's effectiveness, we employed various\nperformance metrics and conducted a human evaluation with 40 participants,\ndemonstrating how the conversational interface compares against a graphical\ninterface with traditional text search. The findings from our evaluation\nprovide practical insights for advancing the design of conversational search\nsystems.", "published": "2024-10-01 06:16:07", "link": "http://arxiv.org/abs/2410.00427v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "FlipGuard: Defending Preference Alignment against Update Regression with\n  Constrained Optimization", "abstract": "Recent breakthroughs in preference alignment have significantly improved\nLarge Language Models' ability to generate texts that align with human\npreferences and values. However, current alignment metrics typically emphasize\nthe post-hoc overall improvement, while overlooking a critical aspect:\nregression, which refers to the backsliding on previously correctly-handled\ndata after updates. This potential pitfall may arise from excessive fine-tuning\non already well-aligned data, which subsequently leads to over-alignment and\ndegeneration. To address this challenge, we propose FlipGuard, a constrained\noptimization approach to detect and mitigate update regression with focal\nattention. Specifically, FlipGuard identifies performance degradation using a\ncustomized reward characterization and strategically enforces a constraint to\nencourage conditional congruence with the pre-aligned model during training.\nComprehensive experiments demonstrate that FlipGuard effectively alleviates\nupdate regression while demonstrating excellent overall performance, with the\nadded benefit of knowledge preservation while aligning preferences.", "published": "2024-10-01 08:46:59", "link": "http://arxiv.org/abs/2410.00508v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Back-Parsing: Utterance Synthesis from Meaning\n  Representation for Zero-Resource Semantic Parsing", "abstract": "Recent efforts have aimed to utilize multilingual pretrained language models\n(mPLMs) to extend semantic parsing (SP) across multiple languages without\nrequiring extensive annotations. However, achieving zero-shot cross-lingual\ntransfer for SP remains challenging, leading to a performance gap between\nsource and target languages. In this study, we propose Cross-Lingual\nBack-Parsing (CBP), a novel data augmentation methodology designed to enhance\ncross-lingual transfer for SP. Leveraging the representation geometry of the\nmPLMs, CBP synthesizes target language utterances from source meaning\nrepresentations. Our methodology effectively performs cross-lingual data\naugmentation in challenging zero-resource settings, by utilizing only labeled\ndata in the source language and monolingual corpora. Extensive experiments on\ntwo cross-language SP benchmarks (Mschema2QA and Xspider) demonstrate that CBP\nbrings substantial gains in the target language. Further analysis of the\nsynthesized utterances shows that our method successfully generates target\nlanguage utterances with high slot value alignment rates while preserving\nsemantic integrity. Our codes and data are publicly available at\nhttps://github.com/deokhk/CBP.", "published": "2024-10-01 08:53:38", "link": "http://arxiv.org/abs/2410.00513v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Learning Capabilities of Language Models using LEVERWORLDS", "abstract": "Learning a model of a stochastic setting often involves learning both general\nstructure rules and specific properties of the instance. This paper\ninvestigates the interplay between learning the general and the specific in\nvarious learning methods, with emphasis on sample efficiency. We design a\nframework called {\\sc LeverWorlds}, which allows the generation of simple\nphysics-inspired worlds that follow a similar generative process with different\ndistributions, and their instances can be expressed in natural language. These\nworlds allow for controlled experiments to assess the sample complexity of\ndifferent learning methods. We experiment with classic learning algorithms as\nwell as Transformer language models, both with fine-tuning and In-Context\nLearning (ICL). Our general finding is that (1) Transformers generally succeed\nin the task; but (2) they are considerably less sample efficient than classic\nmethods that make stronger assumptions about the structure, such as Maximum\nLikelihood Estimation and Logistic Regression. This finding is in tension with\nthe recent tendency to use Transformers as general-purpose estimators. We\npropose an approach that leverages the ICL capabilities of contemporary\nlanguage models to apply simple algorithms for this type of data. Our\nexperiments show that models currently struggle with the task but show\npromising potential.", "published": "2024-10-01 09:02:13", "link": "http://arxiv.org/abs/2410.00519v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AutoTM 2.0: Automatic Topic Modeling Framework for Documents Analysis", "abstract": "In this work, we present an AutoTM 2.0 framework for optimizing additively\nregularized topic models. Comparing to the previous version, this version\nincludes such valuable improvements as novel optimization pipeline, LLM-based\nquality metrics and distributed mode.\n  AutoTM 2.0 is a comfort tool for specialists as well as non-specialists to\nwork with text documents to conduct exploratory data analysis or to perform\nclustering task on interpretable set of features. Quality evaluation is based\non specially developed metrics such as coherence and gpt-4-based approaches.\nResearchers and practitioners can easily integrate new optimization algorithms\nand adapt novel metrics to enhance modeling quality and extend their\nexperiments.\n  We show that AutoTM 2.0 achieves better performance compared to the previous\nAutoTM by providing results on 5 datasets with different features and in two\ndifferent languages.", "published": "2024-10-01 13:13:15", "link": "http://arxiv.org/abs/2410.00655v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Efficient Technical Term Translation: A Knowledge Distillation Approach\n  for Parenthetical Terminology Translation", "abstract": "This paper addresses the challenge of accurately translating technical terms,\nwhich are crucial for clear communication in specialized fields. We introduce\nthe Parenthetical Terminology Translation (PTT) task, designed to mitigate\npotential inaccuracies by displaying the original term in parentheses alongside\nits translation. To implement this approach, we generated a representative PTT\ndataset using a collaborative approach with large language models and applied\nknowledge distillation to fine-tune traditional Neural Machine Translation\n(NMT) models and small-sized Large Language Models (sLMs). Additionally, we\ndeveloped a novel evaluation metric to assess both overall translation accuracy\nand the correct parenthetical presentation of terms. Our findings indicate that\nsLMs did not consistently outperform NMT models, with fine-tuning proving more\neffective than few-shot prompting, particularly in models with continued\npre-training in the target language. These insights contribute to the\nadvancement of more reliable terminology translation methodologies.", "published": "2024-10-01 13:40:28", "link": "http://arxiv.org/abs/2410.00683v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empowering Large Language Model for Continual Video Question Answering\n  with Collaborative Prompting", "abstract": "In recent years, the rapid increase in online video content has underscored\nthe limitations of static Video Question Answering (VideoQA) models trained on\nfixed datasets, as they struggle to adapt to new questions or tasks posed by\nnewly available content. In this paper, we explore the novel challenge of\nVideoQA within a continual learning framework, and empirically identify a\ncritical issue: fine-tuning a large language model (LLM) for a sequence of\ntasks often results in catastrophic forgetting. To address this, we propose\nCollaborative Prompting (ColPro), which integrates specific question constraint\nprompting, knowledge acquisition prompting, and visual temporal awareness\nprompting. These prompts aim to capture textual question context, visual\ncontent, and video temporal dynamics in VideoQA, a perspective underexplored in\nprior research. Experimental results on the NExT-QA and DramaQA datasets show\nthat ColPro achieves superior performance compared to existing approaches,\nachieving 55.14\\% accuracy on NExT-QA and 71.24\\% accuracy on DramaQA,\nhighlighting its practical relevance and effectiveness.", "published": "2024-10-01 15:07:07", "link": "http://arxiv.org/abs/2410.00771v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "BabelBench: An Omni Benchmark for Code-Driven Analysis of Multimodal and\n  Multistructured Data", "abstract": "Large language models (LLMs) have become increasingly pivotal across various\ndomains, especially in handling complex data types. This includes structured\ndata processing, as exemplified by ChartQA and ChatGPT-Ada, and multimodal\nunstructured data processing as seen in Visual Question Answering (VQA). These\nareas have attracted significant attention from both industry and academia.\nDespite this, there remains a lack of unified evaluation methodologies for\nthese diverse data handling scenarios. In response, we introduce BabelBench, an\ninnovative benchmark framework that evaluates the proficiency of LLMs in\nmanaging multimodal multistructured data with code execution. BabelBench\nincorporates a dataset comprising 247 meticulously curated problems that\nchallenge the models with tasks in perception, commonsense reasoning, logical\nreasoning, and so on. Besides the basic capabilities of multimodal\nunderstanding, structured data processing as well as code generation, these\ntasks demand advanced capabilities in exploration, planning, reasoning and\ndebugging. Our experimental findings on BabelBench indicate that even\ncutting-edge models like ChatGPT 4 exhibit substantial room for improvement.\nThe insights derived from our comprehensive analysis offer valuable guidance\nfor future research within the community. The benchmark data can be found at\nhttps://github.com/FFD8FFE/babelbench.", "published": "2024-10-01 15:11:24", "link": "http://arxiv.org/abs/2410.00773v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Generative causal testing to bridge data-driven models and scientific\n  theories in language neuroscience", "abstract": "Representations from large language models are highly effective at predicting\nBOLD fMRI responses to language stimuli. However, these representations are\nlargely opaque: it is unclear what features of the language stimulus drive the\nresponse in each brain area. We present generative causal testing (GCT), a\nframework for generating concise explanations of language selectivity in the\nbrain from predictive models and then testing those explanations in follow-up\nexperiments using LLM-generated stimuli.This approach is successful at\nexplaining selectivity both in individual voxels and cortical regions of\ninterest (ROIs), including newly identified microROIs in prefrontal cortex. We\nshow that explanatory accuracy is closely related to the predictive power and\nstability of the underlying predictive models. Finally, we show that GCT can\ndissect fine-grained differences between brain areas with similar functional\nselectivity. These results demonstrate that LLMs can be used to bridge the\nwidening gap between data-driven models and formal scientific theories.", "published": "2024-10-01 15:57:48", "link": "http://arxiv.org/abs/2410.00812v2", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Investigating the Synergistic Effects of Dropout and Residual\n  Connections on Language Model Training", "abstract": "This paper examines the pivotal role of dropout techniques in mitigating\noverfitting in language model training. It conducts a comprehensive\ninvestigation into the influence of variable dropout rates on both individual\nlayers and residual connections within the context of language modeling. Our\nstudy conducts training of a decoder implementation on the classic Tiny\nShakespeare data to examine the effects of the adjustments on training\nefficiency and validation error. Results not only confirm the benefits of\ndropout for regularization and residuals for convergence, but also reveal their\ninteresting interactions. There exists an important trade-off between the depth\nof residual connections and the dropout on these connections for optimal deep\nneural network convergence and generalization.", "published": "2024-10-01 19:27:00", "link": "http://arxiv.org/abs/2410.01019v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RATIONALYST: Pre-training Process-Supervision for Improving Reasoning", "abstract": "The reasoning steps generated by LLMs might be incomplete, as they mimic\nlogical leaps common in everyday communication found in their pre-training\ndata: underlying rationales are frequently left implicit (unstated). To address\nthis challenge, we introduce RATIONALYST, a model for process-supervision of\nreasoning based on pre-training on a vast collection of rationale annotations\nextracted from unlabeled data. We extract 79k rationales from web-scale\nunlabelled dataset (the Pile) and a combination of reasoning datasets with\nminimal human intervention. This web-scale pre-training for reasoning allows\nRATIONALYST to consistently generalize across diverse reasoning tasks,\nincluding mathematical, commonsense, scientific, and logical reasoning.\nFine-tuned from LLaMa-3-8B, RATIONALYST improves the accuracy of reasoning by\nan average of 3.9% on 7 representative reasoning benchmarks. It also\ndemonstrates superior performance compared to significantly larger verifiers\nlike GPT-4 and similarly sized models fine-tuned on matching training sets.", "published": "2024-10-01 20:05:51", "link": "http://arxiv.org/abs/2410.01044v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems", "abstract": "LLMs when used with Retrieval Augmented Generation (RAG), are greatly\nimproving the SOTA of translating natural language queries to structured and\ncorrect SQL. Unlike previous reviews, this survey provides a comprehensive\nstudy of the evolution of LLM-based text-to-SQL systems, from early rule-based\nmodels to advanced LLM approaches that use (RAG) systems. We discuss\nbenchmarks, evaluation methods, and evaluation metrics. Also, we uniquely study\nthe use of Graph RAGs for better contextual accuracy and schema linking in\nthese systems. Finally, we highlight key challenges such as computational\nefficiency, model robustness, and data privacy toward improvements of LLM-based\ntext-to-SQL systems.", "published": "2024-10-01 20:46:25", "link": "http://arxiv.org/abs/2410.01066v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Approximately Aligned Decoding", "abstract": "It is common to reject undesired outputs of Large Language Models (LLMs);\nhowever, current methods to do so require an excessive amount of computation,\nor severely distort the distribution of outputs. We present a method to balance\nthe distortion of the output distribution with computational efficiency,\nallowing for the generation of long sequences of text with difficult-to-satisfy\nconstraints, with less amplification of low probability outputs compared to\nexisting methods. We show through a series of experiments that the\ntask-specific performance of our method is comparable to methods that do not\ndistort the output distribution, while being much more computationally\nefficient.", "published": "2024-10-01 22:22:13", "link": "http://arxiv.org/abs/2410.01103v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ERASMO: Leveraging Large Language Models for Enhanced Clustering\n  Segmentation", "abstract": "Cluster analysis plays a crucial role in various domains and applications,\nsuch as customer segmentation in marketing. These contexts often involve\nmultimodal data, including both tabular and textual datasets, making it\nchallenging to represent hidden patterns for obtaining meaningful clusters.\nThis study introduces ERASMO, a framework designed to fine-tune a pretrained\nlanguage model on textually encoded tabular data and generate embeddings from\nthe fine-tuned model. ERASMO employs a textual converter to transform tabular\ndata into a textual format, enabling the language model to process and\nunderstand the data more effectively. Additionally, ERASMO produces\ncontextually rich and structurally representative embeddings through techniques\nsuch as random feature sequence shuffling and number verbalization. Extensive\nexperimental evaluations were conducted using multiple datasets and baseline\napproaches. Our results demonstrate that ERASMO fully leverages the specific\ncontext of each tabular dataset, leading to more precise and nuanced embeddings\nfor accurate clustering. This approach enhances clustering performance by\ncapturing complex relationship patterns within diverse tabular data.", "published": "2024-10-01 00:37:16", "link": "http://arxiv.org/abs/2410.03738v2", "categories": ["cs.CL", "cs.AI", "68T50 (Natural language processing), 68T01 (General topics in\n  artificial intelligence)"], "primary_category": "cs.CL"}
{"title": "Grammar Induction from Visual, Speech and Text", "abstract": "Grammar Induction could benefit from rich heterogeneous signals, such as\ntext, vision, and acoustics. In the process, features from distinct modalities\nessentially serve complementary roles to each other. With such intuition, this\nwork introduces a novel \\emph{unsupervised visual-audio-text grammar induction}\ntask (named \\textbf{VAT-GI}), to induce the constituent grammar trees from\nparallel images, text, and speech inputs. Inspired by the fact that language\ngrammar natively exists beyond the texts, we argue that the text has not to be\nthe predominant modality in grammar induction. Thus we further introduce a\n\\emph{textless} setting of VAT-GI, wherein the task solely relies on visual and\nauditory inputs. To approach the task, we propose a visual-audio-text\ninside-outside recursive autoencoder (\\textbf{VaTiora}) framework, which\nleverages rich modal-specific and complementary features for effective grammar\nparsing. Besides, a more challenging benchmark data is constructed to assess\nthe generalization ability of VAT-GI system. Experiments on two benchmark\ndatasets demonstrate that our proposed VaTiora system is more effective in\nincorporating the various multimodal signals, and also presents new\nstate-of-the-art performance of VAT-GI.", "published": "2024-10-01 02:24:18", "link": "http://arxiv.org/abs/2410.03739v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Khattat: Enhancing Readability and Concept Representation of Semantic\n  Typography", "abstract": "Designing expressive typography that visually conveys a word's meaning while\nmaintaining readability is a complex task, known as semantic typography. It\ninvolves selecting an idea, choosing an appropriate font, and balancing\ncreativity with legibility. We introduce an end-to-end system that automates\nthis process. First, a Large Language Model (LLM) generates imagery ideas for\nthe word, useful for abstract concepts like freedom. Then, the FontCLIP\npre-trained model automatically selects a suitable font based on its semantic\nunderstanding of font attributes. The system identifies optimal regions of the\nword for morphing and iteratively transforms them using a pre-trained diffusion\nmodel. A key feature is our OCR-based loss function, which enhances readability\nand enables simultaneous stylization of multiple characters. We compare our\nmethod with other baselines, demonstrating great readability enhancement and\nversatility across multiple languages and writing scripts.", "published": "2024-10-01 18:42:48", "link": "http://arxiv.org/abs/2410.03748v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Machine Learning Classification of Peaceful Countries: A Comparative\n  Analysis and Dataset Optimization", "abstract": "This paper presents a machine learning approach to classify countries as\npeaceful or non-peaceful using linguistic patterns extracted from global media\narticles. We employ vector embeddings and cosine similarity to develop a\nsupervised classification model that effectively identifies peaceful countries.\nAdditionally, we explore the impact of dataset size on model performance,\ninvestigating how shrinking the dataset influences classification accuracy. Our\nresults highlight the challenges and opportunities associated with using\nlarge-scale text data for peace studies.", "published": "2024-10-01 19:28:03", "link": "http://arxiv.org/abs/2410.03749v1", "categories": ["cs.CL", "cs.LG", "62H30", "I.2.6"], "primary_category": "cs.CL"}
{"title": "Duo-LLM: A Framework for Studying Adaptive Computation in Large Language\n  Models", "abstract": "Large Language Models (LLMs) typically generate outputs token by token using\na fixed compute budget, leading to inefficient resource utilization. To address\nthis shortcoming, recent advancements in mixture of expert (MoE) models,\nspeculative decoding, and early exit strategies leverage the insight that\ncomputational demands can vary significantly based on the complexity and nature\nof the input. However, identifying optimal routing patterns for dynamic\nexecution remains an open challenge, limiting the full potential of these\nadaptive methods. To address this need, we study adaptive computation in LLMs\nmore systematically. We propose a novel framework that integrates smaller\nauxiliary modules within each Feed-Forward Network layer of the LLM. This\ndesign enables dynamic routing of tokens based on task complexity: tokens can\nbe processed by either the small or big modules at each layer, or even bypass\ncertain layers entirely. This allows us to introduce a novel notion of a\ntoken's difficulty, defined by its potential to benefit from additional\ncomputational resources. Importantly, by employing oracles to identify optimal\npatterns of adaptive computations, we gain valuable insights into the internal\nworkings of LLMs and the routing processes in a simplified heterogeneous MoE\nsetup. We show that trained routers operate differently from oracles and often\nyield suboptimal solutions. Notably, activating a large module in just one\nlayer outperforms models that use large modules across all layers, underscoring\nthe gap between practical implementations of routing in MoE models and\ntheoretical optima for adaptive computation.", "published": "2024-10-01 16:10:21", "link": "http://arxiv.org/abs/2410.10846v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Sparse Attention Decomposition Applied to Circuit Tracing", "abstract": "Many papers have shown that attention heads work in conjunction with each\nother to perform complex tasks. It's frequently assumed that communication\nbetween attention heads is via the addition of specific features to token\nresiduals. In this work we seek to isolate and identify the features used to\neffect communication and coordination among attention heads in GPT-2 small. Our\nkey leverage on the problem is to show that these features are very often\nsparsely coded in the singular vectors of attention head matrices. We\ncharacterize the dimensionality and occurrence of these signals across the\nattention heads in GPT-2 small when used for the Indirect Object Identification\n(IOI) task. The sparse encoding of signals, as provided by attention head\nsingular vectors, allows for efficient separation of signals from the residual\nbackground and straightforward identification of communication paths between\nattention heads. We explore the effectiveness of this approach by tracing\nportions of the circuits used in the IOI task. Our traces reveal considerable\ndetail not present in previous studies, shedding light on the nature of\nredundant paths present in GPT-2. And our traces go beyond previous work by\nidentifying features used to communicate between attention heads when\nperforming IOI.", "published": "2024-10-01 02:34:08", "link": "http://arxiv.org/abs/2410.00340v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Unleashing the Unseen: Harnessing Benign Datasets for Jailbreaking Large\n  Language Models", "abstract": "Despite significant ongoing efforts in safety alignment, large language\nmodels (LLMs) such as GPT-4 and LLaMA 3 remain vulnerable to jailbreak attacks\nthat can induce harmful behaviors, including through the use of adversarial\nsuffixes. Building on prior research, we hypothesize that these adversarial\nsuffixes are not mere bugs but may represent features that can dominate the\nLLM's behavior. To evaluate this hypothesis, we conduct several experiments.\nFirst, we demonstrate that benign features can be effectively made to function\nas adversarial suffixes, i.e., we develop a feature extraction method to\nextract sample-agnostic features from benign dataset in the form of suffixes\nand show that these suffixes may effectively compromise safety alignment.\nSecond, we show that adversarial suffixes generated from jailbreak attacks may\ncontain meaningful features, i.e., appending the same suffix to different\nprompts results in responses exhibiting specific characteristics. Third, we\nshow that such benign-yet-safety-compromising features can be easily introduced\nthrough fine-tuning using only benign datasets. As a result, we are able to\ncompletely eliminate GPT's safety alignment in a blackbox setting through\nfinetuning with only benign data. Our code and data is available at\n\\url{https://github.com/suffix-maybe-feature/adver-suffix-maybe-features}.", "published": "2024-10-01 07:11:55", "link": "http://arxiv.org/abs/2410.00451v3", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Multi-Target Cross-Lingual Summarization: a novel task and a\n  language-neutral approach", "abstract": "Cross-lingual summarization aims to bridge language barriers by summarizing\ndocuments in different languages. However, ensuring semantic coherence across\nlanguages is an overlooked challenge and can be critical in several contexts.\nTo fill this gap, we introduce multi-target cross-lingual summarization as the\ntask of summarizing a document into multiple target languages while ensuring\nthat the produced summaries are semantically similar. We propose a principled\nre-ranking approach to this problem and a multi-criteria evaluation protocol to\nassess semantic coherence across target languages, marking a first step that\nwill hopefully stimulate further research on this problem.", "published": "2024-10-01 08:33:57", "link": "http://arxiv.org/abs/2410.00502v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge\n  Distillation for Large Language Models in Code Generation", "abstract": "The impressive performance of proprietary LLMs like GPT4 in code generation\nhas led to a trend to replicate these capabilities in open-source models\nthrough knowledge distillation (e.g. Code Evol-Instruct). However, these\nefforts often neglect the crucial aspect of response quality, relying heavily\non teacher models for direct response distillation. This paradigm, especially\nfor complex instructions, can degrade the quality of synthesized data,\ncompromising the knowledge distillation process. To this end, our study\nintroduces the Adaptive Modular Response Evolution (AMR-Evol) framework, which\nemploys a two-stage process to refine response distillation. The first stage,\nmodular decomposition, breaks down the direct response into more manageable\nsub-modules. The second stage, adaptive response evolution, automatically\nevolves the response with the related function modules. Our experiments with\nthree popular code benchmarks (HumanEval, MBPP, and EvalPlus) attest to the\nsuperiority of the AMR-Evol framework over baseline response distillation\nmethods. By comparing with the open-source Code LLMs trained on a similar scale\nof data, we observed performance enhancements: more than +3.0 points on\nHumanEval-Plus and +1.0 points on MBPP-Plus, which underscores the\neffectiveness of our framework. Our codes are available at\nhttps://github.com/ChiYeungLaw/AMR-Evol.", "published": "2024-10-01 10:12:38", "link": "http://arxiv.org/abs/2410.00558v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "\"Show Me What's Wrong!\": Combining Charts and Text to Guide Data\n  Analysis", "abstract": "Analyzing and finding anomalies in multi-dimensional datasets is a cumbersome\nbut vital task across different domains. In the context of financial fraud\ndetection, analysts must quickly identify suspicious activity among\ntransactional data. This is an iterative process made of complex exploratory\ntasks such as recognizing patterns, grouping, and comparing. To mitigate the\ninformation overload inherent to these steps, we present a tool combining\nautomated information highlights, Large Language Model generated textual\ninsights, and visual analytics, facilitating exploration at different levels of\ndetail. We perform a segmentation of the data per analysis area and visually\nrepresent each one, making use of automated visual cues to signal which require\nmore attention. Upon user selection of an area, our system provides textual and\ngraphical summaries. The text, acting as a link between the high-level and\ndetailed views of the chosen segment, allows for a quick understanding of\nrelevant details. A thorough exploration of the data comprising the selection\ncan be done through graphical representations. The feedback gathered in a study\nperformed with seven domain experts suggests our tool effectively supports and\nguides exploratory analysis, easing the identification of suspicious\ninformation.", "published": "2024-10-01 14:16:10", "link": "http://arxiv.org/abs/2410.00727v3", "categories": ["cs.LG", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP\n  Models", "abstract": "Contrastive Language-Image Pre-training (CLIP) has been widely studied and\napplied in numerous applications. However, the emphasis on brief summary texts\nduring pre-training prevents CLIP from understanding long descriptions. This\nissue is particularly acute regarding videos given that videos often contain\nabundant detailed contents. In this paper, we propose the VideoCLIP-XL (eXtra\nLength) model, which aims to unleash the long-description understanding\ncapability of video CLIP models. Firstly, we establish an automatic data\ncollection system and gather a large-scale VILD pre-training dataset with VIdeo\nand Long-Description pairs. Then, we propose Text-similarity-guided Primary\nComponent Matching (TPCM) to better learn the distribution of feature space\nwhile expanding the long description capability. We also introduce two new\ntasks namely Detail-aware Description Ranking (DDR) and Hallucination-aware\nDescription Ranking (HDR) for further understanding improvement. Finally, we\nconstruct a Long Video Description Ranking (LVDR) benchmark for evaluating the\nlong-description capability more comprehensively. Extensive experimental\nresults on widely-used text-video retrieval benchmarks with both short and long\ndescriptions and our LVDR benchmark can fully demonstrate the effectiveness of\nour method.", "published": "2024-10-01 14:33:22", "link": "http://arxiv.org/abs/2410.00741v2", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "VHASR: A Multimodal Speech Recognition System With Vision Hotwords", "abstract": "The image-based multimodal automatic speech recognition (ASR) model enhances\nspeech recognition performance by incorporating audio-related image. However,\nsome works suggest that introducing image information to model does not help\nimproving ASR performance. In this paper, we propose a novel approach\neffectively utilizing audio-related image information and set up VHASR, a\nmultimodal speech recognition system that uses vision as hotwords to strengthen\nthe model's speech recognition capability. Our system utilizes a dual-stream\narchitecture, which firstly transcribes the text on the two streams separately,\nand then combines the outputs. We evaluate the proposed model on four datasets:\nFlickr8k, ADE20k, COCO, and OpenImages. The experimental results show that\nVHASR can effectively utilize key information in images to enhance the model's\nspeech recognition ability. Its performance not only surpasses unimodal ASR,\nbut also achieves SOTA among existing image-based multimodal ASR.", "published": "2024-10-01 16:06:02", "link": "http://arxiv.org/abs/2410.00822v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Causal Representation Learning with Generative Artificial Intelligence:\n  Application to Texts as Treatments", "abstract": "In this paper, we demonstrate how to enhance the validity of causal inference\nwith unstructured high-dimensional treatments like texts, by leveraging the\npower of generative Artificial Intelligence. Specifically, we propose to use a\ndeep generative model such as large language models (LLMs) to efficiently\ngenerate treatments and use their internal representation for subsequent causal\neffect estimation. We show that the knowledge of this true internal\nrepresentation helps disentangle the treatment features of interest, such as\nspecific sentiments and certain topics, from other possibly unknown confounding\nfeatures. Unlike the existing methods, our proposed approach eliminates the\nneed to learn causal representation from the data and hence produces more\naccurate and efficient estimates. We formally establish the conditions required\nfor the nonparametric identification of the average treatment effect, propose\nan estimation strategy that avoids the violation of the overlap assumption, and\nderive the asymptotic properties of the proposed estimator through the\napplication of double machine learning. Finally, using an instrumental\nvariables approach, we extend the proposed methodology to the settings, in\nwhich the treatment feature is based on human perception rather than is assumed\nto be fixed given the treatment object. The proposed methodology is also\napplicable to text reuse where an LLM is used to regenerate the existing texts.\nWe conduct simulation and empirical studies, using the generated text data from\nan open-source LLM, Llama 3, to illustrate the advantages of our estimator over\nthe state-of-the-art causal representation learning algorithms.", "published": "2024-10-01 17:46:21", "link": "http://arxiv.org/abs/2410.00903v2", "categories": ["stat.AP", "cs.CL", "cs.LG"], "primary_category": "stat.AP"}
{"title": "MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation\n  Model Training on EU Languages", "abstract": "The rise of foundation models (FMs), coupled with regulatory efforts\naddressing their risks and impacts, has sparked significant interest in\nopen-source models. However, existing speech FMs (SFMs) fall short of full\ncompliance with the open-source principles, even if claimed otherwise, as no\nexisting SFM has model weights, code, and training data publicly available\nunder open-source terms. In this work, we take the first step toward filling\nthis gap by focusing on the 24 official languages of the European Union (EU).\nWe collect suitable training data by surveying automatic speech recognition\ndatasets and unlabeled speech corpora under open-source compliant licenses, for\na total of 950k hours. Additionally, we release automatic transcripts for 441k\nhours of unlabeled data under the permissive CC-BY license, thereby\nfacilitating the creation of open-source SFMs for the EU languages.", "published": "2024-10-01 19:54:10", "link": "http://arxiv.org/abs/2410.01036v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Exploring Empty Spaces: Human-in-the-Loop Data Augmentation", "abstract": "Data augmentation is crucial to make machine learning models more robust and\nsafe. However, augmenting data can be challenging as it requires generating\ndiverse data points to rigorously evaluate model behavior on edge cases and\nmitigate potential harms. Creating high-quality augmentations that cover these\n\"unknown unknowns\" is a time- and creativity-intensive task. In this work, we\nintroduce Amplio, an interactive tool to help practitioners navigate \"unknown\nunknowns\" in unstructured text datasets and improve data diversity by\nsystematically identifying empty data spaces to explore. Amplio includes three\nhuman-in-the-loop data augmentation techniques: Augment With Concepts, Augment\nby Interpolation, and Augment with Large Language Model. In a user study with\n18 professional red teamers, we demonstrate the utility of our augmentation\nmethods in helping generate high-quality, diverse, and relevant model safety\nprompts. We find that Amplio enabled red teamers to augment data quickly and\ncreatively, highlighting the transformative potential of interactive\naugmentation workflows.", "published": "2024-10-01 21:33:10", "link": "http://arxiv.org/abs/2410.01088v2", "categories": ["cs.HC", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Mixing It Up: The Cocktail Effect of Multi-Task Fine-Tuning on LLM\n  Performance -- A Case Study in Finance", "abstract": "The application of large language models (LLMs) in domain-specific contexts,\nincluding finance, has expanded rapidly. Domain-specific LLMs are typically\nevaluated based on their performance in various downstream tasks relevant to\nthe domain. In this work, we present a detailed analysis of fine-tuning LLMs\nfor such tasks. Somewhat counterintuitively, we find that in domain-specific\ncases, fine-tuning exclusively on the target task is not always the most\neffective strategy. Instead, multi-task finetuning - where models are trained\non a cocktail of related tasks - can significantly enhance performance. We\ndemonstrate how this approach enables a small model, such as Phi-3-Mini, to\nachieve state-of-the-art results, even surpassing the much larger GPT-4-o model\non financial benchmarks. Our study involves a large-scale experiment,\nconducting over 200 training experiments using several widely adopted LLMs as\nbaselines, and empirically confirms the benefits of multi-task fine-tuning.\nAdditionally, we explore the use of general instruction data as a form of\nregularization, suggesting that it helps minimize performance degradation. We\nalso investigate the inclusion of mathematical data, finding improvements in\nnumerical reasoning that transfer effectively to financial tasks. Finally, we\nnote that while fine-tuning for downstream tasks leads to targeted improvements\nin task performance, it does not necessarily result in broader gains in domain\nknowledge or complex domain reasoning abilities.", "published": "2024-10-01 22:35:56", "link": "http://arxiv.org/abs/2410.01109v2", "categories": ["cs.AI", "cs.CE", "cs.CL"], "primary_category": "cs.AI"}
{"title": "PyRIT: A Framework for Security Risk Identification and Red Teaming in\n  Generative AI System", "abstract": "Generative Artificial Intelligence (GenAI) is becoming ubiquitous in our\ndaily lives. The increase in computational power and data availability has led\nto a proliferation of both single- and multi-modal models. As the GenAI\necosystem matures, the need for extensible and model-agnostic risk\nidentification frameworks is growing. To meet this need, we introduce the\nPython Risk Identification Toolkit (PyRIT), an open-source framework designed\nto enhance red teaming efforts in GenAI systems. PyRIT is a model- and\nplatform-agnostic tool that enables red teamers to probe for and identify novel\nharms, risks, and jailbreaks in multimodal generative AI models. Its composable\narchitecture facilitates the reuse of core building blocks and allows for\nextensibility to future models and modalities. This paper details the\nchallenges specific to red teaming generative AI systems, the development and\nfeatures of PyRIT, and its practical applications in real-world scenarios.", "published": "2024-10-01 17:00:59", "link": "http://arxiv.org/abs/2410.02828v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Beyond Scalar Reward Model: Learning Generative Judge from Preference\n  Data", "abstract": "Learning from preference feedback is a common practice for aligning large\nlanguage models~(LLMs) with human value. Conventionally, preference data is\nlearned and encoded into a scalar reward model that connects a value head with\nan LLM to produce a scalar score as preference or reward. However, scalar\nmodels lack interpretability and are known to be susceptible to biases in\ndatasets. This paper investigates leveraging the generation capability of LLMs\nto address both limitations in one shot. Specifically, we prompt the\npre-trained LLM to generate positive and negative judgments, both supported\nwith rationales in natural language form. The self-generated contrastive\njudgment pairs are used to train the generative judge with Direct Preference\nOptimization (DPO). This proposal of training the generative Judge using\nself-generated Contrastive judgments (Con-J) ensures natural interpretability\ndue to the generated rationales together with the judgments, as well as high\nrobustness against bias without the need for an additional reward head.\nExperimental results show that the performance of Con-J is comparable to the\nscalar reward model trained on the same collection of preference data, and\ndemonstrate its superior interpretability and robustness in encoding human\npreferences.", "published": "2024-10-01 07:38:58", "link": "http://arxiv.org/abs/2410.03742v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter\n  Merging", "abstract": "Supervised fine-tuning (SFT) is crucial for adapting Large Language Models\n(LLMs) to specific tasks. In this work, we demonstrate that the order of\ntraining data can lead to significant training imbalances, potentially\nresulting in performance degradation. Consequently, we propose to mitigate this\nimbalance by merging SFT models fine-tuned with different data orders, thereby\nenhancing the overall effectiveness of SFT. Additionally, we introduce a novel\ntechnique, \"parameter-selection merging,\" which outperforms traditional\nweighted-average methods on five datasets. Further, through analysis and\nablation studies, we validate the effectiveness of our method and identify the\nsources of performance improvements.", "published": "2024-10-01 08:44:31", "link": "http://arxiv.org/abs/2410.03743v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation\n  Models", "abstract": "Large pre-trained models (LPMs), such as large language models, have become\nubiquitous and are employed in many applications. These models are often\nadapted to a desired domain or downstream task through a fine-tuning stage.\nThis paper proposes SQFT, an end-to-end solution for low-precision sparse\nparameter-efficient fine-tuning of LPMs, allowing for effective model\nmanipulation in resource-constrained environments. Additionally, an innovative\nstrategy enables the merging of sparse weights with low-rank adapters without\nlosing sparsity and accuracy, overcoming the limitations of previous\napproaches. SQFT also addresses the challenge of having quantized weights and\nadapters with different numerical precisions, enabling merging in the desired\nnumerical format without sacrificing accuracy. Multiple adaptation scenarios,\nmodels, and comprehensive sparsity levels demonstrate the effectiveness of\nSQFT. Models and code are available at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.", "published": "2024-10-01 19:49:35", "link": "http://arxiv.org/abs/2410.03750v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Recent Advances in Speech Language Models: A Survey", "abstract": "Large Language Models (LLMs) have recently garnered significant attention,\nprimarily for their capabilities in text-based interactions. However, natural\nhuman interaction often relies on speech, necessitating a shift towards\nvoice-based models. A straightforward approach to achieve this involves a\npipeline of ``Automatic Speech Recognition (ASR) + LLM + Text-to-Speech (TTS)\",\nwhere input speech is transcribed to text, processed by an LLM, and then\nconverted back to speech. Despite being straightforward, this method suffers\nfrom inherent limitations, such as information loss during modality conversion,\nsignificant latency due to the complex pipeline, and error accumulation across\nthe three stages. To address these issues, Speech Language Models (SpeechLMs)\n-- end-to-end models that generate speech without converting from text -- have\nemerged as a promising alternative. This survey paper provides the first\ncomprehensive overview of recent methodologies for constructing SpeechLMs,\ndetailing the key components of their architecture and the various training\nrecipes integral to their development. Additionally, we systematically survey\nthe various capabilities of SpeechLMs, categorize their evaluation metrics, and\ndiscuss the challenges and future research directions in this rapidly evolving\nfield. The GitHub repository is available at\nhttps://github.com/dreamtheater123/Awesome-SpeechLM-Survey", "published": "2024-10-01 21:48:12", "link": "http://arxiv.org/abs/2410.03751v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Rethinking Misalignment in Vision-Language Model Adaptation from a\n  Causal Perspective", "abstract": "Foundational Vision-Language models such as CLIP have exhibited impressive\ngeneralization in downstream tasks. However, CLIP suffers from a two-level\nmisalignment issue, i.e., task misalignment and data misalignment, when\nadapting to specific tasks. Soft prompt tuning has mitigated the task\nmisalignment, yet the data misalignment remains a challenge. To analyze the\nimpacts of the data misalignment, we revisit the pre-training and adaptation\nprocesses of CLIP and develop a structural causal model. We discover that while\nwe expect to capture task-relevant information for downstream tasks accurately,\nthe task-irrelevant knowledge impacts the prediction results and hampers the\nmodeling of the true relationships between the images and the predicted\nclasses. As task-irrelevant knowledge is unobservable, we leverage the\nfront-door adjustment and propose Causality-Guided Semantic Decoupling and\nClassification (CDC) to mitigate the interference of task-irrelevant knowledge.\nSpecifically, we decouple semantics contained in the data of downstream tasks\nand perform classification based on each semantic. Furthermore, we employ the\nDempster-Shafer evidence theory to evaluate the uncertainty of each prediction\ngenerated by diverse semantics. Experiments conducted in multiple different\nsettings have consistently demonstrated the effectiveness of CDC.", "published": "2024-10-01 09:33:45", "link": "http://arxiv.org/abs/2410.12816v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control", "abstract": "While recent advances in Text-to-Speech (TTS) technology produce natural and\nexpressive speech, they lack the option for users to select emotion and control\nintensity. We propose EmoKnob, a framework that allows fine-grained emotion\ncontrol in speech synthesis with few-shot demonstrative samples of arbitrary\nemotion. Our framework leverages the expressive speaker representation space\nmade possible by recent advances in foundation voice cloning models. Based on\nthe few-shot capability of our emotion control framework, we propose two\nmethods to apply emotion control on emotions described by open-ended text,\nenabling an intuitive interface for controlling a diverse array of nuanced\nemotions. To facilitate a more systematic emotional speech synthesis field, we\nintroduce a set of evaluation metrics designed to rigorously assess the\nfaithfulness and recognizability of emotion control frameworks. Through\nobjective and subjective evaluations, we show that our emotion control\nframework effectively embeds emotions into speech and surpasses emotion\nexpressiveness of commercial TTS services.", "published": "2024-10-01 01:29:54", "link": "http://arxiv.org/abs/2410.00316v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Do Music Generation Models Encode Music Theory?", "abstract": "Music foundation models possess impressive music generation capabilities.\nWhen people compose music, they may infuse their understanding of music into\ntheir work, by using notes and intervals to craft melodies, chords to build\nprogressions, and tempo to create a rhythmic feel. To what extent is this true\nof music generation models? More specifically, are fundamental Western music\ntheory concepts observable within the \"inner workings\" of these models? Recent\nwork proposed leveraging latent audio representations from music generation\nmodels towards music information retrieval tasks (e.g. genre classification,\nemotion recognition), which suggests that high-level musical characteristics\nare encoded within these models. However, probing individual music theory\nconcepts (e.g. tempo, pitch class, chord quality) remains under-explored. Thus,\nwe introduce SynTheory, a synthetic MIDI and audio music theory dataset,\nconsisting of tempos, time signatures, notes, intervals, scales, chords, and\nchord progressions concepts. We then propose a framework to probe for these\nmusic theory concepts in music foundation models (Jukebox and MusicGen) and\nassess how strongly they encode these concepts within their internal\nrepresentations. Our findings suggest that music theory concepts are\ndiscernible within foundation models and that the degree to which they are\ndetectable varies by model size and layer.", "published": "2024-10-01 17:06:30", "link": "http://arxiv.org/abs/2410.00872v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Scale Temporal Transformer For Speech Emotion Recognition", "abstract": "Speech emotion recognition plays a crucial role in human-machine interaction\nsystems. Recently various optimized Transformers have been successfully applied\nto speech emotion recognition. However, the existing Transformer architectures\nfocus more on global information and require large computation. On the other\nhand, abundant speech emotional representations exist locally on different\nparts of the input speech. To tackle these problems, we propose a Multi-Scale\nTRansfomer (MSTR) for speech emotion recognition. It comprises of three main\ncomponents: (1) a multi-scale temporal feature operator, (2) a fractal\nself-attention module, and (3) a scale mixer module. These three components can\neffectively enhance the transformer's ability to learn multi-scale local\nemotion representations. Experimental results demonstrate that the proposed\nMSTR model significantly outperforms a vanilla Transformer and other\nstate-of-the-art methods across three speech emotion datasets: IEMOCAP, MELD\nand, CREMAD. In addition, it can greatly reduce the computational cost.", "published": "2024-10-01 04:22:10", "link": "http://arxiv.org/abs/2410.00390v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "An alternative Approach in Voice Extraction", "abstract": "The research on audio clue-based target speaker extraction (TSE) has mostly\nfocused on modeling the mixture and reference speech, achieving high\nperformance in English due to the availability of large datasets. However, less\nattention has been given to the consistent properties of human speech across\nlanguages. To bridge this gap, we introduce an alternative model which\naddresses the challenge of transferring TSE models from one language to another\nwithout fine-tuning. In this work, we proposed a gating mechanism that is able\nto modify specific frequencies based on the speaker's acoustic features. The\nmodel achieves an SI-SDR of 17.3544 on clean English speech and 13.2032 on\nclean speech mixed with Wham! noise, outperforming all other models in its\nability to adapt to different languages.", "published": "2024-10-01 09:11:03", "link": "http://arxiv.org/abs/2410.00527v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "End-to-End Speech Recognition with Pre-trained Masked Language Model", "abstract": "We present a novel approach to end-to-end automatic speech recognition (ASR)\nthat utilizes pre-trained masked language models (LMs) to facilitate the\nextraction of linguistic information. The proposed models, BERT-CTC and BECTRA,\nare specifically designed to effectively integrate pre-trained LMs (e.g., BERT)\ninto end-to-end ASR models. BERT-CTC adapts BERT for connectionist temporal\nclassification (CTC) by addressing the constraint of the conditional\nindependence assumption between output tokens. This enables explicit\nconditioning of BERT's contextualized embeddings in the ASR process, seamlessly\nmerging audio and linguistic information through an iterative refinement\nalgorithm. BECTRA extends BERT-CTC to the transducer framework and trains the\ndecoder network using a vocabulary suitable for ASR training. This aims to\nbridge the gap between the text processed in end-to-end ASR and BERT, as these\nmodels have distinct vocabularies with varying text formats and styles, such as\nthe presence of punctuation. Experimental results on various ASR tasks\ndemonstrate that the proposed models improve over both the CTC and\ntransducer-based baselines, owing to the incorporation of BERT knowledge.\nMoreover, our in-depth analysis and investigation verify the effectiveness of\nthe proposed formulations and architectural designs.", "published": "2024-10-01 09:14:31", "link": "http://arxiv.org/abs/2410.00528v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Zero-Shot Text-to-Speech from Continuous Text Streams", "abstract": "Existing zero-shot text-to-speech (TTS) systems are typically designed to\nprocess complete sentences and are constrained by the maximum duration for\nwhich they have been trained. However, in many streaming applications, texts\narrive continuously in short chunks, necessitating instant responses from the\nsystem. We identify the essential capabilities required for chunk-level\nstreaming and introduce LiveSpeech 2, a stream-aware model that supports\ninfinitely long speech generation, text-audio stream synchronization, and\nseamless transitions between short speech chunks. To achieve these, we propose\n(1) adopting Mamba, a class of sequence modeling distinguished by linear-time\ndecoding, which is augmented by cross-attention mechanisms for conditioning,\n(2) utilizing rotary positional embeddings in the computation of\ncross-attention, enabling the model to process an infinite text stream by\nsliding a window, and (3) decoding with semantic guidance, a technique that\naligns speech with the transcript during inference with minimal overhead.\nExperimental results demonstrate that our models are competitive with\nstate-of-the-art language model-based zero-shot TTS models, while also\nproviding flexibility to support a wide range of streaming scenarios.", "published": "2024-10-01 15:04:21", "link": "http://arxiv.org/abs/2410.00767v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving curriculum learning for target speaker extraction with\n  synthetic speakers", "abstract": "Target speaker extraction (TSE) aims to isolate individual speaker voices\nfrom complex speech environments. The effectiveness of TSE systems is often\ncompromised when the speaker characteristics are similar to each other. Recent\nresearch has introduced curriculum learning (CL), in which TSE models are\ntrained incrementally on speech samples of increasing complexity. In CL\ntraining, the model is first trained on samples with low speaker similarity\nbetween the target and interference speakers, and then on samples with high\nspeaker similarity. To further improve CL, this paper uses a $k$-nearest\nneighbor-based voice conversion method to simulate and generate speech of\ndiverse interference speakers, and then uses the generated data as part of the\nCL. Experiments demonstrate that training data based on synthetic speakers can\neffectively enhance the model's capabilities and significantly improve the\nperformance of multiple TSE systems.", "published": "2024-10-01 15:57:35", "link": "http://arxiv.org/abs/2410.00811v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Integrating Text-to-Music Models with Language Models: Composing Long\n  Structured Music Pieces", "abstract": "Recent music generation methods based on transformers have a context window\nof up to a minute. The music generated by these methods is largely unstructured\nbeyond the context window. With a longer context window, learning long-scale\nstructures from musical data is a prohibitively challenging problem. This paper\nproposes integrating a text-to-music model with a large language model to\ngenerate music with form. The papers discusses the solutions to the challenges\nof such integration. The experimental results show that the proposed method can\ngenerate 2.5-minute-long music that is highly structured, strongly organized,\nand cohesive.", "published": "2024-10-01 02:43:14", "link": "http://arxiv.org/abs/2410.00344v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Pre-training with Synthetic Patterns for Audio", "abstract": "In this paper, we propose to pre-train audio encoders using synthetic\npatterns instead of real audio data. Our proposed framework consists of two key\nelements. The first one is Masked Autoencoder (MAE), a self-supervised learning\nframework that learns from reconstructing data from randomly masked\ncounterparts. MAEs tend to focus on low-level information such as visual\npatterns and regularities within data. Therefore, it is unimportant what is\nportrayed in the input, whether it be images, audio mel-spectrograms, or even\nsynthetic patterns. This leads to the second key element, which is synthetic\ndata. Synthetic data, unlike real audio, is free from privacy and licensing\ninfringement issues. By combining MAEs and synthetic patterns, our framework\nenables the model to learn generalized feature representations without real\ndata, while addressing the issues related to real audio. To evaluate the\nefficacy of our framework, we conduct extensive experiments across a total of\n13 audio tasks and 17 synthetic datasets. The experiments provide insights into\nwhich types of synthetic patterns are effective for audio. Our results\ndemonstrate that our framework achieves performance comparable to models\npre-trained on AudioSet-2M and partially outperforms image-based pre-training\nmethods.", "published": "2024-10-01 08:52:35", "link": "http://arxiv.org/abs/2410.00511v1", "categories": ["eess.AS", "cs.AI", "cs.CV"], "primary_category": "eess.AS"}
{"title": "Contribution of soundscape appropriateness to soundscape quality\n  assessment in space: a mediating variable affecting acoustic comfort", "abstract": "Soundscape appropriateness (SA) provides supplemental information on the\nmatching degree between auditory information and the surrounding scene in\nsoundscape perception. This indicator has been integrated into the standard ISO\nprocess for collecting soundscape data, forming a component of the sound\nquality assessment questionnaire. However, its role in soundscape quality\nassessment has not been fully understood. Herein, we present the findings from\nsoundscape data collected from Beiling Park in Shenyang, China. A method was\ndeveloped that integrates mediation effect models with multiscale\ngeographically weighted regression models to explore the mediating role of SA\nin the impact of sound source types on soundscape quality, as well as the\nspatial heterogeneity of this mediation effect. The results confirm that SA\ndoes mediates the influence of sound source types on acoustics comfort (AC).\nSpecifically, natural sounds (indirect effect/total effect = .19/.19), traffic\nsounds (indirect effect/total effect = -.46/-.65), and commercial sounds\n(indirect effect/total effect = -.25/-.12) impact the perception of AC by\neither enhancing or reducing SA. Moreover, the relationships among variables\ndepicted in this model demonstrate spatial heterogeneity, demonstrating that in\nurban open spaces with complex constructures, local spatial models may be\nneeded for soundscape assessment. The research reaffirms the significance of SA\nin urban open spaces. In terms of practical implications for urban and\nlandscape planners, when sound sources cannot be controlled or altered,\ncoordinating between the sound and the surrounding environment through\nlandscape optimisation could also improve the quality of the soundscape through\nenhancing SA and help achieve the goal of creating healthy urban open spaces.", "published": "2024-10-01 13:22:51", "link": "http://arxiv.org/abs/2410.00667v2", "categories": ["cs.SD", "eess.AS", "physics.class-ph"], "primary_category": "cs.SD"}
{"title": "The Conformer Encoder May Reverse the Time Dimension", "abstract": "We sometimes observe monotonically decreasing cross-attention weights in our\nConformer-based global attention-based encoder-decoder (AED) models, Further\ninvestigation shows that the Conformer encoder reverses the sequence in the\ntime dimension. We analyze the initial behavior of the decoder cross-attention\nmechanism and find that it encourages the Conformer encoder self-attention to\nbuild a connection between the initial frames and all other informative frames.\nFurthermore, we show that, at some point in training, the self-attention module\nof the Conformer starts dominating the output over the preceding feed-forward\nmodule, which then only allows the reversed information to pass through. We\npropose methods and ideas of how this flipping can be avoided and investigate a\nnovel method to obtain label-frame-position alignments by using the gradients\nof the label log probabilities w.r.t. the encoder input frames.", "published": "2024-10-01 13:39:05", "link": "http://arxiv.org/abs/2410.00680v2", "categories": ["eess.AS", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Heterogeneous sound classification with the Broad Sound Taxonomy and\n  Dataset", "abstract": "Automatic sound classification has a wide range of applications in machine\nlistening, enabling context-aware sound processing and understanding. This\npaper explores methodologies for automatically classifying heterogeneous sounds\ncharacterized by high intra-class variability. Our study evaluates the\nclassification task using the Broad Sound Taxonomy, a two-level taxonomy\ncomprising 28 classes designed to cover a heterogeneous range of sounds with\nsemantic distinctions tailored for practical user applications. We construct a\ndataset through manual annotation to ensure accuracy, diverse representation\nwithin each class and relevance in real-world scenarios. We compare a variety\nof both traditional and modern machine learning approaches to establish a\nbaseline for the task of heterogeneous sound classification. We investigate the\nrole of input features, specifically examining how acoustically derived sound\nrepresentations compare to embeddings extracted with pre-trained deep neural\nnetworks that capture both acoustic and semantic information about sounds.\nExperimental results illustrate that audio embeddings encoding acoustic and\nsemantic information achieve higher accuracy in the classification task. After\ncareful analysis of classification errors, we identify some underlying reasons\nfor failure and propose actions to mitigate them. The paper highlights the need\nfor deeper exploration of all stages of classification, understanding the data\nand adopting methodologies capable of effectively handling data complexity and\ngeneralizing in real-world sound environments.", "published": "2024-10-01 18:09:02", "link": "http://arxiv.org/abs/2410.00980v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Critical Assessment of Visual Sound Source Localization Models\n  Including Negative Audio", "abstract": "The task of Visual Sound Source Localization (VSSL) involves identifying the\nlocation of sound sources in visual scenes, integrating audio-visual data for\nenhanced scene understanding. Despite advancements in state-of-the-art (SOTA)\nmodels, we observe three critical flaws: i) The evaluation of the models is\nmainly focused in sounds produced by objects that are visible in the image, ii)\nThe evaluation often assumes a prior knowledge of the size of the sounding\nobject, and iii) No universal threshold for localization in real-world\nscenarios is established, as previous approaches only consider positive\nexamples without accounting for both positive and negative cases. In this\npaper, we introduce a novel test set and metrics designed to complete the\ncurrent standard evaluation of VSSL models by testing them in scenarios where\nnone of the objects in the image corresponds to the audio input, i.e. a\nnegative audio. We consider three types of negative audio: silence, noise and\noffscreen. Our analysis reveals that numerous SOTA models fail to appropriately\nadjust their predictions based on audio input, suggesting that these models may\nnot be leveraging audio information as intended. Additionally, we provide a\ncomprehensive analysis of the range of maximum values in the estimated\naudio-visual similarity maps, in both positive and negative audio cases, and\nshow that most of the models are not discriminative enough, making them unfit\nto choose a universal threshold appropriate to perform sound localization\nwithout any a priori information of the sounding object, that is, object size\nand visibility.", "published": "2024-10-01 19:28:45", "link": "http://arxiv.org/abs/2410.01020v3", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Augmentation through Laundering Attacks for Audio Spoof Detection", "abstract": "Recent text-to-speech (TTS) developments have made voice cloning (VC) more\nrealistic, affordable, and easily accessible. This has given rise to many\npotential abuses of this technology, including Joe Biden's New Hampshire\ndeepfake robocall. Several methodologies have been proposed to detect such\nclones. However, these methodologies have been trained and evaluated on\nrelatively clean databases. Recently, ASVspoof 5 Challenge introduced a new\ncrowd-sourced database of diverse acoustic conditions including various\nspoofing attacks and codec conditions. This paper is our submission to the\nASVspoof 5 Challenge and aims to investigate the performance of Audio Spoof\nDetection, trained using data augmentation through laundering attacks, on the\nASVSpoof 5 database. The results demonstrate that our system performs worst on\nA18, A19, A20, A26, and A30 spoofing attacks and in the codec and compression\nconditions of C08, C09, and C10.", "published": "2024-10-01 22:34:51", "link": "http://arxiv.org/abs/2410.01108v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Decoding Emotions: Unveiling Facial Expressions through Acoustic Sensing\n  with Contrastive Attention", "abstract": "Expression recognition holds great promise for applications such as content\nrecommendation and mental healthcare by accurately detecting users' emotional\nstates. Traditional methods often rely on cameras or wearable sensors, which\nraise privacy concerns and add extra device burdens. In addition, existing\nacoustic-based methods struggle to maintain satisfactory performance when there\nis a distribution shift between the training dataset and the inference dataset.\nIn this paper, we introduce FacER+, an active acoustic facial expression\nrecognition system, which eliminates the requirement for external microphone\narrays. FacER+ extracts facial expression features by analyzing the echoes of\nnear-ultrasound signals emitted between the 3D facial contour and the earpiece\nspeaker on a smartphone. This approach not only reduces background noise but\nalso enables the identification of different expressions from various users\nwith minimal training data. We develop a contrastive external attention-based\nmodel to consistently learn expression features across different users,\nreducing the distribution differences. Extensive experiments involving 20\nvolunteers, both with and without masks, demonstrate that FacER+ can accurately\nrecognize six common facial expressions with over 90% accuracy in diverse,\nuser-independent real-life scenarios, surpassing the performance of the leading\nacoustic sensing methods by 10%. FacER+ offers a robust and practical solution\nfor facial expression recognition.", "published": "2024-10-01 03:21:33", "link": "http://arxiv.org/abs/2410.12811v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
