{"title": "A First Step in Combining Cognitive Event Features and Natural Language\n  Representations to Predict Emotions", "abstract": "We explore the representational space of emotions by combining methods from\ndifferent academic fields. Cognitive science has proposed appraisal theory as a\nview on human emotion with previous research showing how human-rated abstract\nevent features can predict fine-grained emotions and capture the similarity\nspace of neural patterns in mentalizing brain regions. At the same time,\nnatural language processing (NLP) has demonstrated how transfer and multitask\nlearning can be used to cope with scarcity of annotated data for text modeling.\n  The contribution of this work is to show that appraisal theory can be\ncombined with NLP for mutual benefit. First, fine-grained emotion prediction\ncan be improved to human-level performance by using NLP representations in\naddition to appraisal features. Second, using the appraisal features as\nauxiliary targets during training can improve predictions even when only text\nis available as input. Third, we obtain a representation with a similarity\nmatrix that better correlates with the neural activity across regions. Best\nresults are achieved when the model is trained to simultaneously predict\nappraisals, emotions and emojis using a shared representation.\n  While these results are preliminary, the integration of cognitive\nneuroscience and NLP techniques opens up an interesting direction for future\nresearch.", "published": "2017-10-23 00:26:50", "link": "http://arxiv.org/abs/1710.08048v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Testing the limits of unsupervised learning for semantic similarity", "abstract": "Semantic Similarity between two sentences can be defined as a way to\ndetermine how related or unrelated two sentences are. The task of Semantic\nSimilarity in terms of distributed representations can be thought to be\ngenerating sentence embeddings (dense vectors) which take both context and\nmeaning of sentence in account. Such embeddings can be produced by multiple\nmethods, in this paper we try to evaluate LSTM auto encoders for generating\nthese embeddings. Unsupervised algorithms (auto encoders to be specific) just\ntry to recreate their inputs, but they can be forced to learn order (and some\ninherent meaning to some extent) by creating proper bottlenecks. We try to\nevaluate how properly can algorithms trained just on plain English Sentences\nlearn to figure out Semantic Similarity, without giving them any sense of what\nmeaning of a sentence is.", "published": "2017-10-23 12:58:12", "link": "http://arxiv.org/abs/1710.08246v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attending to All Mention Pairs for Full Abstract Biological Relation\n  Extraction", "abstract": "Most work in relation extraction forms a prediction by looking at a short\nspan of text within a single sentence containing a single entity pair mention.\nHowever, many relation types, particularly in biomedical text, are expressed\nacross sentences or require a large context to disambiguate. We propose a model\nto consider all mention and entity pairs simultaneously in order to make a\nprediction. We encode full paper abstracts using an efficient self-attention\nencoder and form pairwise predictions between all mentions with a bi-affine\noperation. An entity-pair wise pooling aggregates mention pair scores to make a\nfinal prediction while alleviating training noise by performing within document\nmulti-instance learning. We improve our model's performance by jointly training\nthe model to predict named entities and adding an additional corpus of weakly\nlabeled data. We demonstrate our model's effectiveness by achieving the state\nof the art on the Biocreative V Chemical Disease Relation dataset for models\nwithout KB resources, outperforming ensembles of models which use hand-crafted\nfeatures and additional linguistic resources.", "published": "2017-10-23 14:46:58", "link": "http://arxiv.org/abs/1710.08312v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining Lexical Features and a Supervised Learning Approach for Arabic\n  Sentiment Analysis", "abstract": "The importance of building sentiment analysis tools for Arabic social media\nhas been recognized during the past couple of years, especially with the rapid\nincrease in the number of Arabic social media users. One of the main\ndifficulties in tackling this problem is that text within social media is\nmostly colloquial, with many dialects being used within social media platforms.\nIn this paper, we present a set of features that were integrated with a machine\nlearning based sentiment analysis model and applied on Egyptian, Saudi,\nLevantine, and MSA Arabic social media datasets. Many of the proposed features\nwere derived through the use of an Arabic Sentiment Lexicon. The model also\npresents emoticon based features, as well as input text related features such\nas the number of segments within the text, the length of the text, whether the\ntext ends with a question mark or not, etc. We show that the presented features\nhave resulted in an increased accuracy across six of the seven datasets we've\nexperimented with and which are all benchmarked. Since the developed model\nout-performs all existing Arabic sentiment analysis systems that have publicly\navailable datasets, we can state that this model presents state-of-the-art in\nArabic sentiment analysis.", "published": "2017-10-23 18:34:37", "link": "http://arxiv.org/abs/1710.08451v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NileTMRG at SemEval-2017 Task 4: Arabic Sentiment Analysis", "abstract": "This paper describes two systems that were used by the authors for addressing\nArabic Sentiment Analysis as part of SemEval-2017, task 4. The authors\nparticipated in three Arabic related subtasks which are: Subtask A (Message\nPolarity Classification), Sub-task B (Topic-Based Message Polarity\nclassification) and Subtask D (Tweet quantification) using the team name of\nNileTMRG. For subtask A, we made use of our previously developed sentiment\nanalyzer which we augmented with a scored lexicon. For subtasks B and D, we\nused an ensemble of three different classifiers. The first classifier was a\nconvolutional neural network for which we trained (word2vec) word embeddings.\nThe second classifier consisted of a MultiLayer Perceptron, while the third\nclassifier was a Logistic regression model that takes the same input as the\nsecond classifier. Voting between the three classifiers was used to determine\nthe final outcome. The output from task B, was quantified to produce the\nresults for task D. In all three Arabic related tasks in which NileTMRG\nparticipated, the team ranked at number one.", "published": "2017-10-23 18:55:19", "link": "http://arxiv.org/abs/1710.08458v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Content Based Document Recommender using Deep Learning", "abstract": "With the recent advancements in information technology there has been a huge\nsurge in amount of data available. But information retrieval technology has not\nbeen able to keep up with this pace of information generation resulting in over\nspending of time for retrieving relevant information. Even though systems exist\nfor assisting users to search a database along with filtering and recommending\nrelevant information, but recommendation system which uses content of documents\nfor recommendation still have a long way to mature. Here we present a Deep\nLearning based supervised approach to recommend similar documents based on the\nsimilarity of content. We combine the C-DSSM model with Word2Vec distributed\nrepresentations of words to create a novel model to classify a document pair as\nrelevant/irrelavant by assigning a score to it. Using our model retrieval of\ndocuments can be done in O(1) time and the memory complexity is O(n), where n\nis number of documents.", "published": "2017-10-23 15:08:38", "link": "http://arxiv.org/abs/1710.08321v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Deep Health Care Text Classification", "abstract": "Health related social media mining is a valuable apparatus for the early\nrecognition of the diverse antagonistic medicinal conditions. Mostly, the\nexisting methods are based on machine learning with knowledge-based learning.\nThis working note presents the Recurrent neural network (RNN) and Long\nshort-term memory (LSTM) based embedding for automatic health text\nclassification in the social media mining. For each task, two systems are built\nand that classify the tweet at the tweet level. RNN and LSTM are used for\nextracting features and non-linear activation function at the last layer\nfacilitates to distinguish the tweets of different categories. The experiments\nare conducted on 2nd Social Media Mining for Health Applications Shared Task at\nAMIA 2017. The experiment results are considerable; however the proposed method\nis appropriate for the health text classification. This is primarily due to the\nreason that, it doesn't rely on any feature engineering mechanisms.", "published": "2017-10-23 17:24:12", "link": "http://arxiv.org/abs/1710.08396v1", "categories": ["cs.CL", "cs.AI", "68T50"], "primary_category": "cs.CL"}
{"title": "A Two-Level Classification Approach for Detecting Clickbait Posts using\n  Text-Based Features", "abstract": "The emergence of social media as news sources has led to the rise of\nclickbait posts attempting to attract users to click on article links without\ninforming them on the actual article content. This paper presents our efforts\nto create a clickbait detector inspired by fake news detection algorithms, and\nour submission to the Clickbait Challenge 2017. The detector is based almost\nexclusively on text-based features taken from previous work on clickbait\ndetection, our own work on fake post detection, and features we designed\nspecifically for the challenge. We use a two-level classification approach,\ncombining the outputs of 65 first-level classifiers in a second-level feature\nvector. We present our exploratory results with individual features and their\ncombinations, taken from the post text and the target article title, as well as\nfeature selection. While our own blind tests with the dataset led to an F-score\nof 0.63, our final evaluation in the Challenge only achieved an F-score of\n0.43. We explore the possible causes of this, and lay out potential future\nsteps to achieve more successful results.", "published": "2017-10-23 22:12:51", "link": "http://arxiv.org/abs/1710.08528v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Listening to the World Improves Speech Command Recognition", "abstract": "We study transfer learning in convolutional network architectures applied to\nthe task of recognizing audio, such as environmental sound events and speech\ncommands. Our key finding is that not only is it possible to transfer\nrepresentations from an unrelated task like environmental sound classification\nto a voice-focused task like speech command recognition, but also that doing so\nimproves accuracies significantly. We also investigate the effect of increased\nmodel capacity for transfer learning audio, by first validating known results\nfrom the field of Computer Vision of achieving better accuracies with\nincreasingly deeper networks on two audio datasets: UrbanSound8k and the newly\nreleased Google Speech Commands dataset. Then we propose a simple multiscale\ninput representation using dilated convolutions and show that it is able to\naggregate larger contexts and increase classification performance. Further, the\nmodels trained using a combination of transfer learning and multiscale input\nrepresentations need only 40% of the training data to achieve similar\naccuracies as a freshly trained model with 100% of the training data. Finally,\nwe demonstrate a positive interaction effect for the multiscale input and\ntransfer learning, making a case for the joint application of the two\ntechniques.", "published": "2017-10-23 16:47:05", "link": "http://arxiv.org/abs/1710.08377v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
