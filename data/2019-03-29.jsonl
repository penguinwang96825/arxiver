{"title": "Acoustically Grounded Word Embeddings for Improved Acoustics-to-Word\n  Speech Recognition", "abstract": "Direct acoustics-to-word (A2W) systems for end-to-end automatic speech\nrecognition are simpler to train, and more efficient to decode with, than\nsub-word systems. However, A2W systems can have difficulties at training time\nwhen data is limited, and at decoding time when recognizing words outside the\ntraining vocabulary. To address these shortcomings, we investigate the use of\nrecently proposed acoustic and acoustically grounded word embedding techniques\nin A2W systems. The idea is based on treating the final pre-softmax weight\nmatrix of an AWE recognizer as a matrix of word embedding vectors, and using an\nexternally trained set of word embeddings to improve the quality of this\nmatrix. In particular we introduce two ideas: (1) Enforcing similarity at\ntraining time between the external embeddings and the recognizer weights, and\n(2) using the word embeddings at test time for predicting out-of-vocabulary\nwords. Our word embedding model is acoustically grounded, that is it is learned\njointly with acoustic embeddings so as to encode the words' acoustic-phonetic\ncontent; and it is parametric, so that it can embed any arbitrary (potentially\nout-of-vocabulary) sequence of characters. We find that both techniques improve\nthe performance of an A2W recognizer on conversational telephone speech.", "published": "2019-03-29 00:44:14", "link": "http://arxiv.org/abs/1903.12306v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Train One Get One Free: Partially Supervised Neural Network for Bug\n  Report Duplicate Detection and Clustering", "abstract": "Tracking user reported bugs requires considerable engineering effort in going\nthrough many repetitive reports and assigning them to the correct teams. This\npaper proposes a neural architecture that can jointly (1) detect if two bug\nreports are duplicates, and (2) aggregate them into latent topics. Leveraging\nthe assumption that learning the topic of a bug is a sub-task for detecting\nduplicates, we design a loss function that can jointly perform both tasks but\nneeds supervision for only duplicate classification, achieving topic clustering\nin an unsupervised fashion. We use a two-step attention module that uses\nself-attention for topic clustering and conditional attention for duplicate\ndetection. We study the characteristics of two types of real world datasets\nthat have been marked for duplicate bugs by engineers and by non-technical\nannotators. The results demonstrate that our model not only can outperform\nstate-of-the-art methods for duplicate classification on both cases, but can\nalso learn meaningful latent clusters without additional supervision.", "published": "2019-03-29 10:15:45", "link": "http://arxiv.org/abs/1903.12431v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A framework for fake review detection in online consumer electronics\n  retailers", "abstract": "The impact of online reviews on businesses has grown significantly during\nlast years, being crucial to determine business success in a wide array of\nsectors, ranging from restaurants, hotels to e-commerce. Unfortunately, some\nusers use unethical means to improve their online reputation by writing fake\nreviews of their businesses or competitors. Previous research has addressed\nfake review detection in a number of domains, such as product or business\nreviews in restaurants and hotels. However, in spite of its economical\ninterest, the domain of consumer electronics businesses has not yet been\nthoroughly studied. This article proposes a feature framework for detecting\nfake reviews that has been evaluated in the consumer electronics domain. The\ncontributions are fourfold: (i) Construction of a dataset for classifying fake\nreviews in the consumer electronics domain in four different cities based on\nscraping techniques; (ii) definition of a feature framework for fake review\ndetection; (iii) development of a fake review classification method based on\nthe proposed framework and (iv) evaluation and analysis of the results for each\nof the cities under study. We have reached an 82% F-Score on the classification\ntask and the Ada Boost classifier has been proven to be the best one by\nstatistical means according to the Friedman test.", "published": "2019-03-29 11:24:40", "link": "http://arxiv.org/abs/1903.12452v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Frowning Frodo, Wincing Leia, and a Seriously Great Friendship: Learning\n  to Classify Emotional Relationships of Fictional Characters", "abstract": "The development of a fictional plot is centered around characters who closely\ninteract with each other forming dynamic social networks. In literature\nanalysis, such networks have mostly been analyzed without particular relation\ntypes or focusing on roles which the characters take with respect to each\nother. We argue that an important aspect for the analysis of stories and their\ndevelopment is the emotion between characters. In this paper, we combine these\naspects into a unified framework to classify emotional relationships of\nfictional characters. We formalize it as a new task and describe the annotation\nof a corpus, based on fan-fiction short stories. The extraction pipeline which\nwe propose consists of character identification (which we treat as given by an\noracle here) and the relation classification. For the latter, we provide\nresults using several approaches previously proposed for relation\nidentification with neural methods. The best result of 0.45 F1 is achieved with\na GRU with character position indicators on the task of predicting undirected\nemotion relations in the associated social network graph.", "published": "2019-03-29 11:26:14", "link": "http://arxiv.org/abs/1903.12453v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Knowledge-Based Personalized Product Description Generation in\n  E-commerce", "abstract": "Quality product descriptions are critical for providing competitive customer\nexperience in an e-commerce platform. An accurate and attractive description\nnot only helps customers make an informed decision but also improves the\nlikelihood of purchase. However, crafting a successful product description is\ntedious and highly time-consuming. Due to its importance, automating the\nproduct description generation has attracted considerable interests from both\nresearch and industrial communities. Existing methods mainly use templates or\nstatistical methods, and their performance could be rather limited. In this\npaper, we explore a new way to generate the personalized product description by\ncombining the power of neural networks and knowledge base. Specifically, we\npropose a KnOwledge Based pErsonalized (or KOBE) product description generation\nmodel in the context of e-commerce. In KOBE, we extend the encoder-decoder\nframework, the Transformer, to a sequence modeling formulation using\nself-attention. In order to make the description both informative and\npersonalized, KOBE considers a variety of important factors during text\ngeneration, including product aspects, user categories, and knowledge base,\netc. Experiments on real-world datasets demonstrate that the proposed method\nout-performs the baseline on various metrics. KOBE can achieve an improvement\nof 9.7% over state-of-the-arts in terms of BLEU. We also present several case\nstudies as the anecdotal evidence to further prove the effectiveness of the\nproposed approach. The framework has been deployed in Taobao, the largest\nonline e-commerce platform in China.", "published": "2019-03-29 11:57:24", "link": "http://arxiv.org/abs/1903.12457v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification", "abstract": "Insufficient or even unavailable training data of emerging classes is a big\nchallenge of many classification tasks, including text classification.\nRecognising text documents of classes that have never been seen in the learning\nstage, so-called zero-shot text classification, is therefore difficult and only\nlimited previous works tackled this problem. In this paper, we propose a\ntwo-phase framework together with data augmentation and feature augmentation to\nsolve this problem. Four kinds of semantic knowledge (word embeddings, class\ndescriptions, class hierarchy, and a general knowledge graph) are incorporated\ninto the proposed framework to deal with instances of unseen classes\neffectively. Experimental results show that each and the combination of the two\nphases achieve the best overall accuracy compared with baselines and recent\napproaches in classifying real-world texts under the zero-shot scenario.", "published": "2019-03-29 17:22:40", "link": "http://arxiv.org/abs/1903.12626v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Minimally Supervised Learning for Neural Relation Extraction", "abstract": "We present an approach to minimally supervised relation extraction that\ncombines the benefits of learned representations and structured learning, and\naccurately predicts sentence-level relation mentions given only\nproposition-level supervision from a KB. By explicitly reasoning about missing\ndata during learning, our approach enables large-scale training of 1D\nconvolutional neural networks while mitigating the issue of label noise\ninherent in distant supervision. Our approach achieves state-of-the-art results\non minimally supervised sentential relation extraction, outperforming a number\nof baselines, including a competitive approach that uses the attention layer of\na purely neural model.", "published": "2019-03-29 23:28:01", "link": "http://arxiv.org/abs/1904.00118v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Making Neural Machine Reading Comprehension Faster", "abstract": "This study aims at solving the Machine Reading Comprehension problem where\nquestions have to be answered given a context passage. The challenge is to\ndevelop a computationally faster model which will have improved inference time.\nState of the art in many natural language understanding tasks, BERT model, has\nbeen used and knowledge distillation method has been applied to train two\nsmaller models. The developed models are compared with other models which have\nbeen developed with the same intention.", "published": "2019-03-29 05:03:15", "link": "http://arxiv.org/abs/1904.00796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training neural networks to encode symbols enables combinatorial\n  generalization", "abstract": "Combinatorial generalization - the ability to understand and produce novel\ncombinations of already familiar elements - is considered to be a core capacity\nof the human mind and a major challenge to neural network models. A significant\nbody of research suggests that conventional neural networks can't solve this\nproblem unless they are endowed with mechanisms specifically engineered for the\npurpose of representing symbols. In this paper we introduce a novel way of\nrepresenting symbolic structures in connectionist terms - the vectors approach\nto representing symbols (VARS), which allows training standard neural\narchitectures to encode symbolic knowledge explicitly at their output layers.\nIn two simulations, we show that neural networks not only can learn to produce\nVARS representations, but in doing so they achieve combinatorial generalization\nin their symbolic and non-symbolic output. This adds to other recent work that\nhas shown improved combinatorial generalization under specific training\nconditions, and raises the question of whether specific mechanisms or training\nroutines are needed to support symbolic processing.", "published": "2019-03-29 05:02:51", "link": "http://arxiv.org/abs/1903.12354v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A General FOFE-net Framework for Simple and Effective Question Answering\n  over Knowledge Bases", "abstract": "Question answering over knowledge base (KB-QA) has recently become a popular\nresearch topic in NLP. One popular way to solve the KB-QA problem is to make\nuse of a pipeline of several NLP modules, including entity discovery and\nlinking (EDL) and relation detection. Recent success on KB-QA task usually\ninvolves complex network structures with sophisticated heuristics. Inspired by\na previous work that builds a strong KB-QA baseline, we propose a simple but\ngeneral neural model composed of fixed-size ordinally forgetting encoding\n(FOFE) and deep neural networks, called FOFE-net to solve KB-QA problem at\ndifferent stages. For evaluation, we use two popular KB-QA datasets,\nSimpleQuestions and WebQSP, and a newly created dataset, FreebaseQA. The\nexperimental results show that FOFE-net performs well on KB-QA subtasks, entity\ndiscovery and linking (EDL) and relation detection, and in turn pushing overall\nKB-QA system to achieve strong results on all datasets.", "published": "2019-03-29 05:15:58", "link": "http://arxiv.org/abs/1903.12356v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Attention-Augmented End-to-End Multi-Task Learning for Emotion\n  Prediction from Speech", "abstract": "Despite the increasing research interest in end-to-end learning systems for\nspeech emotion recognition, conventional systems either suffer from the\noverfitting due in part to the limited training data, or do not explicitly\nconsider the different contributions of automatically learnt representations\nfor a specific task. In this contribution, we propose a novel end-to-end\nframework which is enhanced by learning other auxiliary tasks and an attention\nmechanism. That is, we jointly train an end-to-end network with several\ndifferent but related emotion prediction tasks, i.e., arousal, valence, and\ndominance predictions, to extract more robust representations shared among\nvarious tasks than traditional systems with the hope that it is able to relieve\nthe overfitting problem. Meanwhile, an attention layer is implemented on top of\nthe layers for each task, with the aim to capture the contribution distribution\nof different segment parts for each individual task. To evaluate the\neffectiveness of the proposed system, we conducted a set of experiments on the\nwidely used database IEMOCAP. The empirical results show that the proposed\nsystems significantly outperform corresponding baseline systems.", "published": "2019-03-29 09:57:45", "link": "http://arxiv.org/abs/1903.12424v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Re-Ranking Words to Improve Interpretability of Automatically Generated\n  Topics", "abstract": "Topics models, such as LDA, are widely used in Natural Language Processing.\nMaking their output interpretable is an important area of research with\napplications to areas such as the enhancement of exploratory search interfaces\nand the development of interpretable machine learning models. Conventionally,\ntopics are represented by their n most probable words, however, these\nrepresentations are often difficult for humans to interpret. This paper\nexplores the re-ranking of topic words to generate more interpretable topic\nrepresentations. A range of approaches are compared and evaluated in two\nexperiments. The first uses crowdworkers to associate topics represented by\ndifferent word rankings with related documents. The second experiment is an\nautomatic approach based on a document retrieval task applied on multiple\ndomains. Results in both experiments demonstrate that re-ranking words improves\ntopic interpretability and that the most effective re-ranking schemes were\nthose which combine information about the importance of words both within\ntopics and their relative frequency in the entire corpus. In addition, close\ncorrelation between the results of the two evaluation approaches suggests that\nthe automatic method proposed here could be used to evaluate re-ranking methods\nwithout the need for human judgements.", "published": "2019-03-29 14:32:02", "link": "http://arxiv.org/abs/1903.12542v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Joint training framework for text-to-speech and voice conversion using\n  multi-source Tacotron and WaveNet", "abstract": "We investigated the training of a shared model for both text-to-speech (TTS)\nand voice conversion (VC) tasks. We propose using an extended model\narchitecture of Tacotron, that is a multi-source sequence-to-sequence model\nwith a dual attention mechanism as the shared model for both the TTS and VC\ntasks. This model can accomplish these two different tasks respectively\naccording to the type of input. An end-to-end speech synthesis task is\nconducted when the model is given text as the input while a\nsequence-to-sequence voice conversion task is conducted when it is given the\nspeech of a source speaker as the input. Waveform signals are generated by\nusing WaveNet, which is conditioned by using a predicted mel-spectrogram. We\npropose jointly training a shared model as a decoder for a target speaker that\nsupports multiple sources. Listening experiments show that our proposed\nmulti-source encoder-decoder model can efficiently achieve both the TTS and VC\ntasks.", "published": "2019-03-29 08:26:13", "link": "http://arxiv.org/abs/1903.12389v2", "categories": ["eess.AS", "cs.CL", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Training a Neural Speech Waveform Model using Spectral Losses of\n  Short-Time Fourier Transform and Continuous Wavelet Transform", "abstract": "Recently, we proposed short-time Fourier transform (STFT)-based loss\nfunctions for training a neural speech waveform model. In this paper, we\ngeneralize the above framework and propose a training scheme for such models\nbased on spectral amplitude and phase losses obtained by either STFT or\ncontinuous wavelet transform (CWT), or both of them. Since CWT is capable of\nhaving time and frequency resolutions different from those of STFT and is cable\nof considering those closer to human auditory scales, the proposed loss\nfunctions could provide complementary information on speech signals.\nExperimental results showed that it is possible to train a high-quality model\nby using the proposed CWT spectral loss and is as good as one using STFT-based\nloss.", "published": "2019-03-29 08:36:06", "link": "http://arxiv.org/abs/1903.12392v2", "categories": ["eess.AS", "cs.CL", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Keyphrase Generation: A Text Summarization Struggle", "abstract": "Authors' keyphrases assigned to scientific articles are essential for\nrecognizing content and topic aspects. Most of the proposed supervised and\nunsupervised methods for keyphrase generation are unable to produce terms that\nare valuable but do not appear in the text. In this paper, we explore the\npossibility of considering the keyphrase string as an abstractive summary of\nthe title and the abstract. First, we collect, process and release a large\ndataset of scientific paper metadata that contains 2.2 million records. Then we\nexperiment with popular text summarization neural architectures. Despite using\nadvanced deep learning models, large quantities of data and many days of\ncomputation, our systematic evaluation on four test datasets reveals that the\nexplored text summarization methods could not produce better keyphrases than\nthe simpler unsupervised methods, or the existing supervised ones.", "published": "2019-03-29 22:43:26", "link": "http://arxiv.org/abs/1904.00110v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Convolutional Neural Network for Language-Agnostic Source Code\n  Summarization", "abstract": "Descriptive comments play a crucial role in the software engineering process.\nThey decrease development time, enable better bug detection, and facilitate the\nreuse of previously written code. However, comments are commonly the last of a\nsoftware developer's priorities and are thus either insufficient or missing\nentirely. Automatic source code summarization may therefore have the ability to\nsignificantly improve the software development process. We introduce a novel\nencoder-decoder model that summarizes source code, effectively writing a\ncomment to describe the code's functionality. We make two primary innovations\nbeyond current source code summarization models. First, our encoder is fully\nlanguage-agnostic and requires no complex input preprocessing. Second, our\ndecoder has an open vocabulary, enabling it to predict any word, even ones not\nseen in training. We demonstrate results comparable to state-of-the-art methods\non a single-language data set and provide the first results on a data set\nconsisting of multiple programming languages.", "published": "2019-03-29 15:53:28", "link": "http://arxiv.org/abs/1904.00805v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "USTCSpeech System for VOiCES from a Distance Challenge 2019", "abstract": "This document describes the speaker verification systems developed in the\nSpeech lab at the University of Science and Technology of China (USTC) for the\nVOiCES from a Distance Challenge 2019. We develop the system for the Fixed\nCondition on two public corpus, VoxCeleb and SITW. The frameworks of our\nsystems are based on the mainstream ivector/PLDA and x-vector/PLDA algorithms.", "published": "2019-03-29 10:05:13", "link": "http://arxiv.org/abs/1903.12428v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Does the Lombard Effect Improve Emotional Communication in Noise? -\n  Analysis of Emotional Speech Acted in Noise -", "abstract": "Speakers usually adjust their way of talking in noisy environments\ninvoluntarily for effective communication. This adaptation is known as the\nLombard effect. Although speech accompanying the Lombard effect can improve the\nintelligibility of a speaker's voice, the changes in acoustic features (e.g.\nfundamental frequency, speech intensity, and spectral tilt) caused by the\nLombard effect may also affect the listener's judgment of emotional content. To\nthe best of our knowledge, there is no published study on the influence of the\nLombard effect in emotional speech. Therefore, we recorded parallel emotional\nspeech waveforms uttered by 12 speakers under both quiet and noisy conditions\nin a professional recording studio in order to explore how the Lombard effect\ninteracts with emotional speech. By analyzing confusion matrices and acoustic\nfeatures, we aim to answer the following questions: 1) Can speakers express\ntheir emotions correctly even under adverse conditions? 2) Can listeners\nrecognize the emotion contained in speech signals even under noise? 3) How does\nemotional speech uttered in noise differ from emotional speech uttered in quiet\nconditions in terms of acoustic characteristic?", "published": "2019-03-29 01:32:22", "link": "http://arxiv.org/abs/1903.12316v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Joining Sound Event Detection and Localization Through Spatial\n  Segregation", "abstract": "Identification and localization of sounds are both integral parts of\ncomputational auditory scene analysis. Although each can be solved separately,\nthe goal of forming coherent auditory objects and achieving a comprehensive\nspatial scene understanding suggests pursuing a joint solution of the two\nproblems. This work presents an approach that robustly binds localization with\nthe detection of sound events in a binaural robotic system. Both tasks are\njoined through the use of spatial stream segregation which produces\nprobabilistic time-frequency masks for individual sources attributable to\nseparate locations, enabling segregated sound event detection operating on\nthese streams. We use simulations of a comprehensive suite of test scenes with\nmultiple co-occurring sound sources, and propose performance measures for\nsystematic investigation of the impact of scene complexity on this segregated\ndetection of sound types. Analyzing the effect of spatial scene arrangement, we\nshow how a robot could facilitate high performance through optimal head\nrotation. Furthermore, we investigate the performance of segregated detection\ngiven possible localization error as well as error in the estimation of number\nof active sources. Our analysis demonstrates that the proposed approach is an\neffective method to obtain joint sound event location and type information\nunder a wide range of conditions.", "published": "2019-03-29 19:04:59", "link": "http://arxiv.org/abs/1904.00055v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Scale Time-Frequency Attention for Acoustic Event Detection", "abstract": "Most attention-based methods only concentrate along the time axis, which is\ninsufficient for Acoustic Event Detection (AED). Meanwhile, previous methods\nfor AED rarely considered that target events possess distinct temporal and\nfrequential scales. In this work, we propose a Multi-Scale Time-Frequency\nAttention (MTFA) module for AED. MTFA gathers information at multiple\nresolutions to generate a time-frequency attention mask which tells the model\nwhere to focus along both time and frequency axis. With MTFA, the model could\ncapture the characteristics of target events with different scales. We\ndemonstrate the proposed method on Task 2 of Detection and Classification of\nAcoustic Scenes and Events (DCASE) 2017 Challenge. Our method achieves\ncompetitive results on both development dataset and evaluation dataset.", "published": "2019-03-29 19:31:02", "link": "http://arxiv.org/abs/1904.00063v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Snore-GANs: Improving Automatic Snore Sound Classification with\n  Synthesized Data", "abstract": "One of the frontier issues that severely hamper the development of automatic\nsnore sound classification (ASSC) associates to the lack of sufficient\nsupervised training data. To cope with this problem, we propose a novel data\naugmentation approach based on semi-supervised conditional Generative\nAdversarial Networks (scGANs), which aims to automatically learn a mapping\nstrategy from a random noise space to original data distribution. The proposed\napproach has the capability of well synthesizing 'realistic' high-dimensional\ndata, while requiring no additional annotation process. To handle the mode\ncollapse problem of GANs, we further introduce an ensemble strategy to enhance\nthe diversity of the generated data. The systematic experiments conducted on a\nwidely used Munich-Passau snore sound corpus demonstrate that the scGANs-based\nsystems can remarkably outperform other classic data augmentation systems, and\nare also competitive to other recently reported systems for ASSC.", "published": "2019-03-29 09:52:37", "link": "http://arxiv.org/abs/1903.12422v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
