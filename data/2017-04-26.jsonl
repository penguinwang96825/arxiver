{"title": "Other Topics You May Also Agree or Disagree: Modeling Inter-Topic\n  Preferences using Tweets and Matrix Factorization", "abstract": "We present in this paper our approach for modeling inter-topic preferences of\nTwitter users: for example, those who agree with the Trans-Pacific Partnership\n(TPP) also agree with free trade. This kind of knowledge is useful not only for\nstance detection across multiple topics but also for various real-world\napplications including public opinion surveys, electoral predictions, electoral\ncampaigns, and online debates. In order to extract users' preferences on\nTwitter, we design linguistic patterns in which people agree and disagree about\nspecific topics (e.g., \"A is completely wrong\"). By applying these linguistic\npatterns to a collection of tweets, we extract statements agreeing and\ndisagreeing with various topics. Inspired by previous work on item\nrecommendation, we formalize the task of modeling inter-topic preferences as\nmatrix factorization: representing users' preferences as a user-topic matrix\nand mapping both users and topics onto a latent feature space that abstracts\nthe preferences. Our experimental results demonstrate both that our proposed\napproach is useful in predicting missing preferences of users and that the\nlatent vector representations of topics successfully encode inter-topic\npreferences.", "published": "2017-04-26 07:04:46", "link": "http://arxiv.org/abs/1704.07986v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topically Driven Neural Language Model", "abstract": "Language models are typically applied at the sentence level, without access\nto the broader document context. We present a neural language model that\nincorporates document context in the form of a topic model-like architecture,\nthus providing a succinct representation of the broader document context\noutside of the current sentence. Experiments over a range of datasets\ndemonstrate that our model outperforms a pure sentence-based model in terms of\nlanguage model perplexity, and leads to topics that are potentially more\ncoherent than those produced by a standard LDA topic model. Our model also has\nthe ability to generate related sentences for a topic, providing another way to\ninterpret topics.", "published": "2017-04-26 08:33:14", "link": "http://arxiv.org/abs/1704.08012v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Riemannian Optimization for Skip-Gram Negative Sampling", "abstract": "Skip-Gram Negative Sampling (SGNS) word embedding model, well known by its\nimplementation in \"word2vec\" software, is usually optimized by stochastic\ngradient descent. However, the optimization of SGNS objective can be viewed as\na problem of searching for a good matrix with the low-rank constraint. The most\nstandard way to solve this type of problems is to apply Riemannian optimization\nframework to optimize the SGNS objective over the manifold of required low-rank\nmatrices. In this paper, we propose an algorithm that optimizes SGNS objective\nusing Riemannian optimization and demonstrates its superiority over popular\ncompetitors, such as the original method to train SGNS and SVD over SPPMI\nmatrix.", "published": "2017-04-26 11:17:51", "link": "http://arxiv.org/abs/1704.08059v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enriching Complex Networks with Word Embeddings for Detecting Mild\n  Cognitive Impairment from Speech Transcripts", "abstract": "Mild Cognitive Impairment (MCI) is a mental disorder difficult to diagnose.\nLinguistic features, mainly from parsers, have been used to detect MCI, but\nthis is not suitable for large-scale assessments. MCI disfluencies produce\nnon-grammatical speech that requires manual or high precision automatic\ncorrection of transcripts. In this paper, we modeled transcripts into complex\nnetworks and enriched them with word embedding (CNE) to better represent short\ntexts produced in neuropsychological assessments. The network measurements were\napplied with well-known classifiers to automatically identify MCI in\ntranscripts, in a binary classification task. A comparison was made with the\nperformance of traditional approaches using Bag of Words (BoW) and linguistic\nfeatures for three datasets: DementiaBank in English, and Cinderella and\nArizona-Battery in Portuguese. Overall, CNE provided higher accuracy than using\nonly complex networks, while Support Vector Machine was superior to other\nclassifiers. CNE provided the highest accuracies for DementiaBank and\nCinderella, but BoW was more efficient for the Arizona-Battery dataset probably\nowing to its short narratives. The approach using linguistic features yielded\nhigher accuracy if the transcriptions of the Cinderella dataset were manually\nrevised. Taken together, the results indicate that complex networks enriched\nwith embedding is promising for detecting MCI in large-scale assessments", "published": "2017-04-26 13:06:25", "link": "http://arxiv.org/abs/1704.08088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diversity driven Attention Model for Query-based Abstractive\n  Summarization", "abstract": "Abstractive summarization aims to generate a shorter version of the document\ncovering all the salient points in a compact and coherent fashion. On the other\nhand, query-based summarization highlights those points that are relevant in\nthe context of a given query. The encode-attend-decode paradigm has achieved\nnotable success in machine translation, extractive summarization, dialog\nsystems, etc. But it suffers from the drawback of generation of repeated\nphrases. In this work we propose a model for the query-based summarization task\nbased on the encode-attend-decode paradigm with two key additions (i) a query\nattention model (in addition to document attention model) which learns to focus\non different portions of the query at different time steps (instead of using a\nstatic representation for the query) and (ii) a new diversity based attention\nmodel which aims to alleviate the problem of repeating phrases in the summary.\nIn order to enable the testing of this model we introduce a new query-based\nsummarization dataset building on debatepedia. Our experiments show that with\nthese two additions the proposed model clearly outperforms vanilla\nencode-attend-decode models with a gain of 28% (absolute) in ROUGE-L scores.", "published": "2017-04-26 19:06:37", "link": "http://arxiv.org/abs/1704.08300v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Characters to Words to in Between: Do We Capture Morphology?", "abstract": "Words can be represented by composing the representations of subword units\nsuch as word segments, characters, and/or character n-grams. While such\nrepresentations are effective and may capture the morphological regularities of\nwords, they have not been systematically compared, and it is not understood how\nthey interact with different morphological typologies. On a language modeling\ntask, we present experiments that systematically vary (1) the basic unit of\nrepresentation, (2) the composition of these representations, and (3) the\nmorphological typology of the language modeled. Our results extend previous\nfindings that character representations are effective across typologies, and we\nfind that a previously unstudied combination of character trigram\nrepresentations composed with bi-LSTMs outperforms most others. But we also\nfind room for improvement: none of the character-level models match the\npredictive accuracy of a model with access to true morphological analyses, even\nwhen learned from an order of magnitude more data.", "published": "2017-04-26 21:10:53", "link": "http://arxiv.org/abs/1704.08352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural AMR: Sequence-to-Sequence Models for Parsing and Generation", "abstract": "Sequence-to-sequence models have shown strong performance across a broad\nrange of applications. However, their application to parsing and generating\ntext usingAbstract Meaning Representation (AMR)has been limited, due to the\nrelatively limited amount of labeled data and the non-sequential nature of the\nAMR graphs. We present a novel training procedure that can lift this limitation\nusing millions of unlabeled sentences and careful preprocessing of the AMR\ngraphs. For AMR parsing, our model achieves competitive results of 62.1SMATCH,\nthe current best score reported without significant use of external semantic\nresources. For AMR generation, our model establishes a new state-of-the-art\nperformance of BLEU 33.8. We present extensive ablative and qualitative\nanalysis including strong evidence that sequence-based AMR models are robust\nagainst ordering variations of graph-to-sequence conversions.", "published": "2017-04-26 23:53:34", "link": "http://arxiv.org/abs/1704.08381v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Using Active Learning and Self-Training when Mining Performance\n  Discussions on Stack Overflow", "abstract": "Abundant data is the key to successful machine learning. However, supervised\nlearning requires annotated data that are often hard to obtain. In a\nclassification task with limited resources, Active Learning (AL) promises to\nguide annotators to examples that bring the most value for a classifier. AL can\nbe successfully combined with self-training, i.e., extending a training set\nwith the unlabelled examples for which a classifier is the most certain. We\nreport our experiences on using AL in a systematic manner to train an SVM\nclassifier for Stack Overflow posts discussing performance of software\ncomponents. We show that the training examples deemed as the most valuable to\nthe classifier are also the most difficult for humans to annotate. Despite\ncarefully evolved annotation criteria, we report low inter-rater agreement, but\nwe also propose mitigation strategies. Finally, based on one annotator's work,\nwe show that self-training can improve the classification accuracy. We conclude\nthe paper by discussing implication for future text miners aspiring to use AL\nand self-training.", "published": "2017-04-26 20:47:36", "link": "http://arxiv.org/abs/1705.02395v1", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "A Recurrent Neural Model with Attention for the Recognition of Chinese\n  Implicit Discourse Relations", "abstract": "We introduce an attention-based Bi-LSTM for Chinese implicit discourse\nrelations and demonstrate that modeling argument pairs as a joint sequence can\noutperform word order-agnostic approaches. Our model benefits from a partial\nsampling scheme and is conceptually simple, yet achieves state-of-the-art\nperformance on the Chinese Discourse Treebank. We also visualize its attention\nactivity to illustrate the model's ability to selectively focus on the relevant\nparts of an input sequence.", "published": "2017-04-26 13:10:12", "link": "http://arxiv.org/abs/1704.08092v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Punny Captions: Witty Wordplay in Image Descriptions", "abstract": "Wit is a form of rich interaction that is often grounded in a specific\nsituation (e.g., a comment in response to an event). In this work, we attempt\nto build computational models that can produce witty descriptions for a given\nimage. Inspired by a cognitive account of humor appreciation, we employ\nlinguistic wordplay, specifically puns, in image descriptions. We develop two\napproaches which involve retrieving witty descriptions for a given image from a\nlarge corpus of sentences, or generating them via an encoder-decoder neural\nnetwork architecture. We compare our approach against meaningful baseline\napproaches via human studies and show substantial improvements. We find that\nwhen a human is subject to similar constraints as the model regarding word\nusage and style, people vote the image descriptions generated by our model to\nbe slightly wittier than human-written witty descriptions. Unsurprisingly,\nhumans are almost always wittier than the model when they are free to choose\nthe vocabulary, style, etc.", "published": "2017-04-26 17:22:53", "link": "http://arxiv.org/abs/1704.08224v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0\n  Dataset", "abstract": "Visual Question Answering (VQA) has received a lot of attention over the past\ncouple of years. A number of deep learning models have been proposed for this\ntask. However, it has been shown that these models are heavily driven by\nsuperficial correlations in the training data and lack compositionality -- the\nability to answer questions about unseen compositions of seen concepts. This\ncompositionality is desirable and central to intelligence. In this paper, we\npropose a new setting for Visual Question Answering where the test\nquestion-answer pairs are compositionally novel compared to training\nquestion-answer pairs. To facilitate developing models under this setting, we\npresent a new compositional split of the VQA v1.0 dataset, which we call\nCompositional VQA (C-VQA). We analyze the distribution of questions and answers\nin the C-VQA splits. Finally, we evaluate several existing VQA models under\nthis new setting and show that the performances of these models degrade by a\nsignificant amount compared to the original VQA setting.", "published": "2017-04-26 17:57:59", "link": "http://arxiv.org/abs/1704.08243v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
