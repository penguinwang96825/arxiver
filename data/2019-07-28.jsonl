{"title": "Representation Degeneration Problem in Training Natural Language\n  Generation Models", "abstract": "We study an interesting problem in training neural network-based models for\nnatural language generation tasks, which we call the \\emph{representation\ndegeneration problem}. We observe that when training a model for natural\nlanguage generation tasks through likelihood maximization with the weight tying\ntrick, especially with big training datasets, most of the learnt word\nembeddings tend to degenerate and be distributed into a narrow cone, which\nlargely limits the representation power of word embeddings. We analyze the\nconditions and causes of this problem and propose a novel regularization method\nto address it. Experiments on language modeling and machine translation show\nthat our method can largely mitigate the representation degeneration problem\nand achieve better performance than baseline algorithms.", "published": "2019-07-28 03:57:41", "link": "http://arxiv.org/abs/1907.12009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAiRE: An Empathetic Neural Chatbot", "abstract": "In this paper, we present an end-to-end empathetic conversation agent CAiRE.\nOur system adapts TransferTransfo (Wolf et al., 2019) learning approach that\nfine-tunes a large-scale pre-trained language model with multi-task objectives:\nresponse language modeling, response prediction and dialogue emotion detection.\nWe evaluate our model on the recently proposed empathetic-dialogues dataset\n(Rashkin et al., 2019), the experiment results show that CAiRE achieves\nstate-of-the-art performance on dialogue emotion detection and empathetic\nresponse generation.", "published": "2019-07-28 16:52:09", "link": "http://arxiv.org/abs/1907.12108v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hybrid Code Networks using a convolutional neural network as an input\n  layer achieves higher turn accuracy", "abstract": "The dialogue management is a task of conversational artificial intelligence.\nThe goal of the dialogue manager is to select the appropriate response to the\nconversational partner conditioned by the input message and recent dialogue\nstate. Hybrid Code Networks is one of the models of dialogue managers, which\nuses an average of word embeddings and bag-of-words as input features. We\nperform experiments on Dialogue bAbI Task 6 and Alquist Conversational Dataset.\nThe experiments show that the convolutional neural network used as an input\nlayer of the Hybrid Code Network improves the model's turn accuracy.", "published": "2019-07-28 23:41:53", "link": "http://arxiv.org/abs/1907.12162v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study on Leveraging Scene Graphs for Visual Question\n  Answering", "abstract": "Visual question answering (Visual QA) has attracted significant attention\nthese years. While a variety of algorithms have been proposed, most of them are\nbuilt upon different combinations of image and language features as well as\nmulti-modal attention and fusion. In this paper, we investigate an alternative\napproach inspired by conventional QA systems that operate on knowledge graphs.\nSpecifically, we investigate the use of scene graphs derived from images for\nVisual QA: an image is abstractly represented by a graph with nodes\ncorresponding to object entities and edges to object relationships. We adapt\nthe recently proposed graph network (GN) to encode the scene graph and perform\nstructured reasoning according to the input question. Our empirical studies\ndemonstrate that scene graphs can already capture essential information of\nimages and graph networks have the potential to outperform state-of-the-art\nVisual QA algorithms but with a much cleaner architecture. By analyzing the\nfeatures generated by GNs we can further interpret the reasoning process,\nsuggesting a promising direction towards explainable Visual QA.", "published": "2019-07-28 19:59:20", "link": "http://arxiv.org/abs/1907.12133v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Text-to-SQL Generation for Question Answering on Electronic Medical\n  Records", "abstract": "Electronic medical records (EMR) contain comprehensive patient information\nand are typically stored in a relational database with multiple tables.\nEffective and efficient patient information retrieval from EMR data is a\nchallenging task for medical experts. Question-to-SQL generation methods tackle\nthis problem by first predicting the SQL query for a given question about a\ndatabase, and then, executing the query on the database. However, most of the\nexisting approaches have not been adapted to the healthcare domain due to a\nlack of healthcare Question-to-SQL dataset for learning models specific to this\ndomain. In addition, wide use of the abbreviation of terminologies and possible\ntypos in questions introduce additional challenges for accurately generating\nthe corresponding SQL queries. In this paper, we tackle these challenges by\ndeveloping a deep learning based TRanslate-Edit Model for Question-to-SQL\n(TREQS) generation, which adapts the widely used sequence-to-sequence model to\ndirectly generate the SQL query for a given question, and further performs the\nrequired edits using an attentive-copying mechanism and task-specific look-up\ntables. Based on the widely used publicly available electronic medical\ndatabase, we create a new large-scale Question-SQL pair dataset, named\nMIMICSQL, in order to perform the Question-to-SQL generation task in healthcare\ndomain. An extensive set of experiments are conducted to evaluate the\nperformance of our proposed model on MIMICSQL. Both quantitative and\nqualitative experimental results indicate the flexibility and efficiency of our\nproposed method in predicting condition values and its robustness to random\nquestions with abbreviations and typos.", "published": "2019-07-28 21:04:05", "link": "http://arxiv.org/abs/1908.01839v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fusing location and text features for sentiment classification", "abstract": "Geo-tagged Twitter data has been used recently to infer insights on the human\naspects of social media. Insights related to demographics, spatial distribution\nof cultural activities, space-time travel trajectories for humans as well as\nhappiness has been mined from geo-tagged twitter data in recent studies. To\ndate, not much study has been done on the impact of the geolocation features of\na Tweet on its sentiment. This observation has inspired us to propose the usage\nof geo-location features as a method to perform sentiment classification. In\nthis method, the sentiment classification of geo-tagged tweets is performed by\nconcatenating geo-location features and one-hot encoded word vectors as inputs\nfor convolutional neural networks (CNN) and long short-term memory (LSTM)\nnetworks. The addition of language-independent features in the form of\ngeo-location features has helped to enrich the tweet representation in order to\ncombat the sparse nature of short tweet message. The results achieved has\ndemonstrated that concatenating geo-location features to one-hot encoded word\nvectors can achieve higher accuracy as compared to the usage of word vectors\nalone for the purpose of sentiment classification.", "published": "2019-07-28 03:57:16", "link": "http://arxiv.org/abs/1907.12008v1", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "What Should I Ask? Using Conversationally Informative Rewards for\n  Goal-Oriented Visual Dialog", "abstract": "The ability to engage in goal-oriented conversations has allowed humans to\ngain knowledge, reduce uncertainty, and perform tasks more efficiently.\nArtificial agents, however, are still far behind humans in having goal-driven\nconversations. In this work, we focus on the task of goal-oriented visual\ndialogue, aiming to automatically generate a series of questions about an image\nwith a single objective. This task is challenging since these questions must\nnot only be consistent with a strategy to achieve a goal, but also consider the\ncontextual information in the image. We propose an end-to-end goal-oriented\nvisual dialogue system, that combines reinforcement learning with regularized\ninformation gain. Unlike previous approaches that have been proposed for the\ntask, our work is motivated by the Rational Speech Act framework, which models\nthe process of human inquiry to reach a goal. We test the two versions of our\nmodel on the GuessWhat?! dataset, obtaining significant results that outperform\nthe current state-of-the-art models in the task of generating questions to find\nan undisclosed object in an image.", "published": "2019-07-28 06:15:35", "link": "http://arxiv.org/abs/1907.12021v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Probabilistic Models of Relational Implication", "abstract": "Relational data in its most basic form is a static collection of known facts.\nHowever, by learning to infer and deduct additional information and structure,\nwe can massively increase the usefulness of the underlying data. One common\nform of inferential reasoning in knowledge bases is implication discovery.\nHere, by learning when one relation implies another, we can extend our\nknowledge representation. There are several existing models for relational\nimplication, however we argue they are motivated but not principled. To this\nend, we define a formal probabilistic model of relational implication. By using\nestimators based on the empirical distribution of our dataset, we demonstrate\nthat our model outperforms existing approaches. While previous work achieves a\nbest score of 0.7812 AUC on an evaluatory dataset, our ProbE model improves\nthis to 0.7915. Furthermore, we demonstrate that our model can be improved\nsubstantially through the use of link prediction models and dense latent\nrepresentations of the underlying argument and relations. This variant, denoted\nProbL, improves the state of the art on our evaluation dataset to 0.8143. In\naddition to developing a new framework and providing novel scores of relational\nimplication, we provide two pragmatic resources to assist future research.\nFirst, we motivate and develop an improved crowd framework for constructing\nlabelled datasets of relational implication. Using this, we reannotate and make\npublic a dataset comprised of 17,848 instances of labelled relational\nimplication. We demonstrate that precision (as evaluated by expert consensus\nwith the crowd labels) on the resulting dataset improves from 53% to 95%.", "published": "2019-07-28 08:56:06", "link": "http://arxiv.org/abs/1907.12048v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
