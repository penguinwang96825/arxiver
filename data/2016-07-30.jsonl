{"title": "Supervised Attentions for Neural Machine Translation", "abstract": "In this paper, we improve the attention or alignment accuracy of neural\nmachine translation by utilizing the alignments of training sentence pairs. We\nsimply compute the distance between the machine attentions and the \"true\"\nalignments, and minimize this cost in the training procedure. Our experiments\non large-scale Chinese-to-English task show that our model improves both\ntranslation and alignment qualities significantly over the large-vocabulary\nneural machine translation system, and even beats a state-of-the-art\ntraditional syntax-based system.", "published": "2016-07-30 12:39:19", "link": "http://arxiv.org/abs/1608.00112v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "World Knowledge as Indirect Supervision for Document Clustering", "abstract": "One of the key obstacles in making learning protocols realistic in\napplications is the need to supervise them, a costly process that often\nrequires hiring domain experts. We consider the framework to use the world\nknowledge as indirect supervision. World knowledge is general-purpose\nknowledge, which is not designed for any specific domain. Then the key\nchallenges are how to adapt the world knowledge to domains and how to represent\nit for learning. In this paper, we provide an example of using world knowledge\nfor domain dependent document clustering. We provide three ways to specify the\nworld knowledge to domains by resolving the ambiguity of the entities and their\ntypes, and represent the data with world knowledge as a heterogeneous\ninformation network. Then we propose a clustering algorithm that can cluster\nmultiple types and incorporate the sub-type information as constraints. In the\nexperiments, we use two existing knowledge bases as our sources of world\nknowledge. One is Freebase, which is collaboratively collected knowledge about\nentities and their organizations. The other is YAGO2, a knowledge base\nautomatically extracted from Wikipedia and maps knowledge to the linguistic\nknowledge base, WordNet. Experimental results on two text benchmark datasets\n(20newsgroups and RCV1) show that incorporating world knowledge as indirect\nsupervision can significantly outperform the state-of-the-art clustering\nalgorithms as well as clustering algorithms enhanced with world knowledge\nfeatures.", "published": "2016-07-30 11:53:04", "link": "http://arxiv.org/abs/1608.00104v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
