{"title": "CL-IMS @ DIACR-Ita: Volente o Nolente: BERT does not outperform SGNS on\n  Semantic Change Detection", "abstract": "We present the results of our participation in the DIACR-Ita shared task on\nlexical semantic change detection for Italian. We exploit Average Pairwise\nDistance of token-based BERT embeddings between time points and rank 5 (of 8)\nin the official ranking with an accuracy of $.72$. While we tune parameters on\nthe English data set of SemEval-2020 Task 1 and reach high performance, this\ndoes not translate to the Italian DIACR-Ita data set. Our results show that we\ndo not manage to find robust ways to exploit BERT embeddings in lexical\nsemantic change detection.", "published": "2020-11-14 09:50:35", "link": "http://arxiv.org/abs/2011.07247v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DebateSum: A large-scale argument mining and summarization dataset", "abstract": "Prior work in Argument Mining frequently alludes to its potential\napplications in automatic debating systems. Despite this focus, almost no\ndatasets or models exist which apply natural language processing techniques to\nproblems found within competitive formal debate. To remedy this, we present the\nDebateSum dataset. DebateSum consists of 187,386 unique pieces of evidence with\ncorresponding argument and extractive summaries. DebateSum was made using data\ncompiled by competitors within the National Speech and Debate Association over\na 7-year period. We train several transformer summarization models to benchmark\nsummarization performance on DebateSum. We also introduce a set of fasttext\nword-vectors trained on DebateSum called debate2vec. Finally, we present a\nsearch engine for this dataset which is utilized extensively by members of the\nNational Speech and Debate Association today. The DebateSum search engine is\navailable to the public here: http://www.debate.cards", "published": "2020-11-14 10:06:57", "link": "http://arxiv.org/abs/2011.07251v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Words are the Window to the Soul: Language-based User Representations\n  for Fake News Detection", "abstract": "Cognitive and social traits of individuals are reflected in language use.\nMoreover, individuals who are prone to spread fake news online often share\ncommon traits. Building on these ideas, we introduce a model that creates\nrepresentations of individuals on social media based only on the language they\nproduce, and use them to detect fake news. We show that language-based user\nrepresentations are beneficial for this task. We also present an extended\nanalysis of the language of fake news spreaders, showing that its main features\nare mostly domain independent and consistent across two English datasets.\nFinally, we exploit the relation between language use and connections in the\nsocial graph to assess the presence of the Echo Chamber effect in our data.", "published": "2020-11-14 21:14:17", "link": "http://arxiv.org/abs/2011.07389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lessons from Computational Modelling of Reference Production in Mandarin\n  and English", "abstract": "Referring expression generation (REG) algorithms offer computational models\nof the production of referring expressions. In earlier work, a corpus of\nreferring expressions (REs) in Mandarin was introduced. In the present paper,\nwe annotate this corpus, evaluate classic REG algorithms on it, and compare the\nresults with earlier results on the evaluation of REG for English referring\nexpressions. Next, we offer an in-depth analysis of the corpus, focusing on\nissues that arise from the grammar of Mandarin. We discuss shortcomings of\nprevious REG evaluations that came to light during our investigation and we\nhighlight some surprising results. Perhaps most strikingly, we found a much\nhigher proportion of under-specified expressions than previous studies had\nsuggested, not just in Mandarin but in English as well.", "published": "2020-11-14 21:55:46", "link": "http://arxiv.org/abs/2011.07398v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Utilizing Bidirectional Encoder Representations from Transformers for\n  Answer Selection", "abstract": "Pre-training a transformer-based model for the language modeling task in a\nlarge dataset and then fine-tuning it for downstream tasks has been found very\nuseful in recent years. One major advantage of such pre-trained language models\nis that they can effectively absorb the context of each word in a sentence.\nHowever, for tasks such as the answer selection task, the pre-trained language\nmodels have not been extensively used yet. To investigate their effectiveness\nin such tasks, in this paper, we adopt the pre-trained Bidirectional Encoder\nRepresentations from Transformer (BERT) language model and fine-tune it on two\nQuestion Answering (QA) datasets and three Community Question Answering (CQA)\ndatasets for the answer selection task. We find that fine-tuning the BERT model\nfor the answer selection task is very effective and observe a maximum\nimprovement of 13.1% in the QA datasets and 18.7% in the CQA datasets compared\nto the previous state-of-the-art.", "published": "2020-11-14 03:15:26", "link": "http://arxiv.org/abs/2011.07208v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis for Sinhala Language using Deep Learning Techniques", "abstract": "Due to the high impact of the fast-evolving fields of machine learning and\ndeep learning, Natural Language Processing (NLP) tasks have further obtained\ncomprehensive performances for highly resourced languages such as English and\nChinese. However Sinhala, which is an under-resourced language with a rich\nmorphology, has not experienced these advancements. For sentiment analysis,\nthere exists only two previous research with deep learning approaches, which\nfocused only on document-level sentiment analysis for the binary case. They\nexperimented with only three types of deep learning models. In contrast, this\npaper presents a much comprehensive study on the use of standard sequence\nmodels such as RNN, LSTM, Bi-LSTM, as well as more recent state-of-the-art\nmodels such as hierarchical attention hybrid neural networks, and capsule\nnetworks. Classification is done at document-level but with more granularity by\nconsidering POSITIVE, NEGATIVE, NEUTRAL, and CONFLICT classes. A data set of\n15059 Sinhala news comments, annotated with these four classes and a corpus\nconsists of 9.48 million tokens are publicly released. This is the largest\nsentiment annotated data set for Sinhala so far.", "published": "2020-11-14 12:02:30", "link": "http://arxiv.org/abs/2011.07280v1", "categories": ["cs.CL", "cs.LG", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Conditioned Natural Language Generation using only Unconditioned\n  Language Model: An Exploration", "abstract": "Transformer-based language models have shown to be very powerful for natural\nlanguage generation (NLG). However, text generation conditioned on some user\ninputs, such as topics or attributes, is non-trivial. Past approach relies on\neither modifying the original LM architecture, re-training the LM on corpora\nwith attribute labels, or having separately trained `guidance models' to guide\ntext generation in decoding. We argued that the above approaches are not\nnecessary, and the original unconditioned LM is sufficient for conditioned NLG.\nWe evaluated our approaches by the samples' fluency and diversity with\nautomated and human evaluation.", "published": "2020-11-14 17:45:11", "link": "http://arxiv.org/abs/2011.07347v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Hybrid Approach for Improved Low Resource Neural Machine Translation\n  using Monolingual Data", "abstract": "Many language pairs are low resource, meaning the amount and/or quality of\navailable parallel data is not sufficient to train a neural machine translation\n(NMT) model which can reach an acceptable standard of accuracy. Many works have\nexplored using the readily available monolingual data in either or both of the\nlanguages to improve the standard of translation models in low, and even high,\nresource languages. One of the most successful of such works is the\nback-translation that utilizes the translations of the target language\nmonolingual data to increase the amount of the training data. The quality of\nthe backward model which is trained on the available parallel data has been\nshown to determine the performance of the back-translation approach. Despite\nthis, only the forward model is improved on the monolingual target data in\nstandard back-translation. A previous study proposed an iterative\nback-translation approach for improving both models over several iterations.\nBut unlike in the traditional back-translation, it relied on both the target\nand source monolingual data. This work, therefore, proposes a novel approach\nthat enables both the backward and forward models to benefit from the\nmonolingual target data through a hybrid of self-learning and back-translation\nrespectively. Experimental results have shown the superiority of the proposed\napproach over the traditional back-translation method on English-German low\nresource neural machine translation. We also proposed an iterative\nself-learning approach that outperforms the iterative back-translation while\nalso relying only on the monolingual target data and require the training of\nless models.", "published": "2020-11-14 22:18:45", "link": "http://arxiv.org/abs/2011.07403v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Meaningful Answer Generation of E-Commerce Question-Answering", "abstract": "In e-commerce portals, generating answers for product-related questions has\nbecome a crucial task. In this paper, we focus on the task of product-aware\nanswer generation, which learns to generate an accurate and complete answer\nfrom large-scale unlabeled e-commerce reviews and product attributes. However,\nsafe answer problems pose significant challenges to text generation tasks, and\ne-commerce question-answering task is no exception. To generate more meaningful\nanswers, in this paper, we propose a novel generative neural model, called the\nMeaningful Product Answer Generator (MPAG), which alleviates the safe answer\nproblem by taking product reviews, product attributes, and a prototype answer\ninto consideration. Product reviews and product attributes are used to provide\nmeaningful content, while the prototype answer can yield a more diverse answer\npattern. To this end, we propose a novel answer generator with a review\nreasoning module and a prototype answer reader. Our key idea is to obtain the\ncorrect question-aware information from a large scale collection of reviews and\nlearn how to write a coherent and meaningful answer from an existing prototype\nanswer. To be more specific, we propose a read-and-write memory consisting of\nselective writing units to conduct reasoning among these reviews. We then\nemploy a prototype reader consisting of comprehensive matching to extract the\nanswer skeleton from the prototype answer. Finally, we propose an answer editor\nto generate the final answer by taking the question and the above parts as\ninput. Conducted on a real-world dataset collected from an e-commerce platform,\nextensive experimental results show that our model achieves state-of-the-art\nperformance in terms of both automatic metrics and human evaluations. Human\nevaluation also demonstrates that our model can consistently generate specific\nand proper answers.", "published": "2020-11-14 14:05:30", "link": "http://arxiv.org/abs/2011.07307v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Few-shot Object Grounding and Mapping for Natural Language Robot\n  Instruction Following", "abstract": "We study the problem of learning a robot policy to follow natural language\ninstructions that can be easily extended to reason about new objects. We\nintroduce a few-shot language-conditioned object grounding method trained from\naugmented reality data that uses exemplars to identify objects and align them\nto their mentions in instructions. We present a learned map representation that\nencodes object locations and their instructed use, and construct it from our\nfew-shot grounding output. We integrate this mapping approach into an\ninstruction-following policy, thereby allowing it to reason about previously\nunseen objects at test-time by simply adding exemplars. We evaluate on the task\nof learning to map raw observations and instructions to continuous control of a\nphysical quadcopter. Our approach significantly outperforms the prior state of\nthe art in the presence of new objects, even when the prior approach observes\nall objects during training.", "published": "2020-11-14 20:35:20", "link": "http://arxiv.org/abs/2011.07384v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Distortion-controlled Training for End-to-end Reverberant Speech\n  Separation with Auxiliary Autoencoding Loss", "abstract": "The performance of speech enhancement and separation systems in anechoic\nenvironments has been significantly advanced with the recent progress in\nend-to-end neural network architectures. However, the performance of such\nsystems in reverberant environments is yet to be explored. A core problem in\nreverberant speech separation is about the training and evaluation metrics.\nStandard time-domain metrics may introduce unexpected distortions during\ntraining and fail to properly evaluate the separation performance due to the\npresence of the reverberations. In this paper, we first introduce the\n\"equal-valued contour\" problem in reverberant separation where multiple outputs\ncan lead to the same performance measured by the common metrics. We then\ninvestigate how \"better\" outputs with lower target-specific distortions can be\nselected by auxiliary autoencoding training (A2T). A2T assumes that the\nseparation is done by a linear operation on the mixture signal, and it adds an\nloss term on the autoencoding of the direct-path target signals to ensure that\nthe distortion introduced on the direct-path signals is controlled during\nseparation. Evaluations on separation signal quality and speech recognition\naccuracy show that A2T is able to control the distortion on the direct-path\nsignals and improve the recognition accuracy.", "published": "2020-11-14 17:03:22", "link": "http://arxiv.org/abs/2011.07338v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Communication-Cost Aware Microphone Selection For Neural Speech\n  Enhancement with Ad-hoc Microphone Arrays", "abstract": "In this paper, we present a method for jointly-learning a microphone\nselection mechanism and a speech enhancement network for multi-channel speech\nenhancement with an ad-hoc microphone array. The attention-based microphone\nselection mechanism is trained to reduce communication-costs through a penalty\nterm which represents a task-performance/ communication-cost trade-off. While\nworking within the trade-off, our method can intelligently stream from more\nmicrophones in lower SNR scenes and fewer microphones in higher SNR scenes. We\nevaluate the model in complex echoic acoustic scenes with moving sources and\nshow that it matches the performance of models that stream from a fixed number\nof microphones while reducing communication costs.", "published": "2020-11-14 17:46:29", "link": "http://arxiv.org/abs/2011.07348v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On Filter Generalization for Music Bandwidth Extension Using Deep Neural\n  Networks", "abstract": "In this paper, we address a sub-topic of the broad domain of audio\nenhancement, namely musical audio bandwidth extension. We formulate the\nbandwidth extension problem using deep neural networks, where a band-limited\nsignal is provided as input to the network, with the goal of reconstructing a\nfull-bandwidth output. Our main contribution centers on the impact of the\nchoice of low pass filter when training and subsequently testing the network.\nFor two different state of the art deep architectures, ResNet and U-Net, we\ndemonstrate that when the training and testing filters are matched,\nimprovements in signal-to-noise ratio (SNR) of up to 7dB can be obtained.\nHowever, when these filters differ, the improvement falls considerably and\nunder some training conditions results in a lower SNR than the band-limited\ninput. To circumvent this apparent overfitting to filter shape, we propose a\ndata augmentation strategy which utilizes multiple low pass filters during\ntraining and leads to improved generalization to unseen filtering conditions at\ntest time.", "published": "2020-11-14 11:41:28", "link": "http://arxiv.org/abs/2011.07274v2", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
