{"title": "MetricBERT: Text Representation Learning via Self-Supervised Triplet\n  Training", "abstract": "We present MetricBERT, a BERT-based model that learns to embed text under a\nwell-defined similarity metric while simultaneously adhering to the\n``traditional'' masked-language task. We focus on downstream tasks of learning\nsimilarities for recommendations where we show that MetricBERT outperforms\nstate-of-the-art alternatives, sometimes by a substantial margin. We conduct\nextensive evaluations of our method and its different variants, showing that\nour training objective is highly beneficial over a traditional contrastive\nloss, a standard cosine similarity objective, and six other baselines. As an\nadditional contribution, we publish a dataset of video games descriptions along\nwith a test set of similarity annotations crafted by a domain expert.", "published": "2022-08-13 09:52:58", "link": "http://arxiv.org/abs/2208.06610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpreting BERT-based Text Similarity via Activation and Saliency Maps", "abstract": "Recently, there has been growing interest in the ability of Transformer-based\nmodels to produce meaningful embeddings of text with several applications, such\nas text similarity. Despite significant progress in the field, the explanations\nfor similarity predictions remain challenging, especially in unsupervised\nsettings. In this work, we present an unsupervised technique for explaining\nparagraph similarities inferred by pre-trained BERT models. By looking at a\npair of paragraphs, our technique identifies important words that dictate each\nparagraph's semantics, matches between the words in both paragraphs, and\nretrieves the most important pairs that explain the similarity between the two.\nThe method, which has been assessed by extensive human evaluations and\ndemonstrated on datasets comprising long and complex paragraphs, has shown\ngreat promise, providing accurate interpretations that correlate better with\nhuman perceptions.", "published": "2022-08-13 10:06:24", "link": "http://arxiv.org/abs/2208.06612v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Answer Verbalization Dataset for Conversational Question Answerings\n  over Knowledge Graphs", "abstract": "We introduce a new dataset for conversational question answering over\nKnowledge Graphs (KGs) with verbalized answers. Question answering over KGs is\ncurrently focused on answer generation for single-turn questions (KGQA) or\nmultiple-tun conversational question answering (ConvQA). However, in a\nreal-world scenario (e.g., voice assistants such as Siri, Alexa, and Google\nAssistant), users prefer verbalized answers. This paper contributes to the\nstate-of-the-art by extending an existing ConvQA dataset with multiple\nparaphrased verbalized answers. We perform experiments with five\nsequence-to-sequence models on generating answer responses while maintaining\ngrammatical correctness. We additionally perform an error analysis that details\nthe rates of models' mispredictions in specified categories. Our proposed\ndataset extended with answer verbalization is publicly available with detailed\ndocumentation on its usage for wider utility.", "published": "2022-08-13 21:21:28", "link": "http://arxiv.org/abs/2208.06734v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tinjauan atas Efektivitas Penggunaan Key Opinion Leader (KOL) dalam\n  Penjualan Surat Utang Negara Ritel seri SBR011", "abstract": "Indonesian Ministry of Finance had endorsed 10 Key Opinion Leaders to help\npromoting government retail bonds SBR011 during selling period of 25 May-16\nJune 2022. This study analyzed effectiveness of the endorsement by using\nseveral indicators; engagement rate, enthusiasm rate and sentiment analysis of\nfeedbacks from KOL audiens. Data was gathered from social media Instagram and\nTikTok social platform used by the KOL to post their marketing contents. This\npaper found that the endorsement is quite effective to promote the SBR011 and\nyields mostly positive feedback on the marketing campaign.", "published": "2022-08-13 03:38:53", "link": "http://arxiv.org/abs/2208.12619v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
