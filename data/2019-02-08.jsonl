{"title": "Models of Visually Grounded Speech Signal Pay Attention To Nouns: a\n  Bilingual Experiment on English and Japanese", "abstract": "We investigate the behaviour of attention in neural models of visually\ngrounded speech trained on two languages: English and Japanese. Experimental\nresults show that attention focuses on nouns and this behaviour holds true for\ntwo very typologically different languages. We also draw parallels between\nartificial neural attention and human attention and show that neural attention\nfocuses on word endings as it has been theorised for human attention. Finally,\nwe investigate how two visually grounded monolingual models can be used to\nperform cross-lingual speech-to-speech retrieval. For both languages, the\nenriched bilingual (speech-image) corpora with part-of-speech tags and forced\nalignments are distributed to the community for reproducible research.", "published": "2019-02-08 12:27:26", "link": "http://arxiv.org/abs/1902.03052v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Humor in Word Embeddings: Cockamamie Gobbledegook for Nincompoops", "abstract": "While humor is often thought to be beyond the reach of Natural Language\nProcessing, we show that several aspects of single-word humor correlate with\nsimple linear directions in Word Embeddings. In particular: (a) the word\nvectors capture multiple aspects discussed in humor theories from various\ndisciplines; (b) each individual's sense of humor can be represented by a\nvector, which can predict differences in people's senses of humor on new,\nunrated, words; and (c) upon clustering humor ratings of multiple demographic\ngroups, different humor preferences emerge across the different groups. Humor\nratings are taken from the work of Engelthaler and Hills (2017) as well as from\nan original crowdsourcing study of 120,000 words. Our dataset further includes\nannotations for the theoretically-motivated humor features we identify.", "published": "2019-02-08 14:36:43", "link": "http://arxiv.org/abs/1902.02783v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Fact Prediction via Knowledge-Enriched Tensor\n  Factorization", "abstract": "We present a family of novel methods for embedding knowledge graphs into\nreal-valued tensors. These tensor-based embeddings capture the ordered\nrelations that are typical in the knowledge graphs represented by semantic web\nlanguages like RDF. Unlike many previous models, our methods can easily use\nprior background knowledge provided by users or extracted automatically from\nexisting knowledge graphs. In addition to providing more robust methods for\nknowledge graph embedding, we provide a provably-convergent, linear tensor\nfactorization algorithm. We demonstrate the efficacy of our models for the task\nof predicting new facts across eight different knowledge graphs, achieving\nbetween 5% and 50% relative improvement over existing state-of-the-art\nknowledge graph embedding techniques. Our empirical evaluation shows that all\nof the tensor decomposition models perform well when the average degree of an\nentity in a graph is high, with constraint-based models doing better on graphs\nwith a small number of highly similar relations and regularization-based models\ndominating for graphs with relations of varying degrees of similarity.", "published": "2019-02-08 13:42:51", "link": "http://arxiv.org/abs/1902.03077v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Speaker diarisation using 2D self-attentive combination of embeddings", "abstract": "Speaker diarisation systems often cluster audio segments using speaker\nembeddings such as i-vectors and d-vectors. Since different types of embeddings\nare often complementary, this paper proposes a generic framework to improve\nperformance by combining them into a single embedding, referred to as a\nc-vector. This combination uses a 2-dimensional (2D) self-attentive structure,\nwhich extends the standard self-attentive layer by averaging not only across\ntime but also across different types of embeddings. Two types of 2D\nself-attentive structure in this paper are the simultaneous combination and the\nconsecutive combination, adopting a single and multiple self-attentive layers\nrespectively. The penalty term in the original self-attentive layer which is\njointly minimised with the objective function to encourage diversity of\nannotation vectors is also modified to obtain not only different local peaks\nbut also the overall trends in the multiple annotation vectors. Experiments on\nthe AMI meeting corpus show that our modified penalty term improves the d-\nvector relative speaker error rate (SER) by 6% and 21% for d-vector systems,\nand a 10% further relative SER reduction can be obtained using the c-vector\nfrom our best 2D self-attentive structure.", "published": "2019-02-08 16:54:51", "link": "http://arxiv.org/abs/1902.03190v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Insertion Transformer: Flexible Sequence Generation via Insertion\n  Operations", "abstract": "We present the Insertion Transformer, an iterative, partially autoregressive\nmodel for sequence generation based on insertion operations. Unlike typical\nautoregressive models which rely on a fixed, often left-to-right ordering of\nthe output, our approach accommodates arbitrary orderings by allowing for\ntokens to be inserted anywhere in the sequence during decoding. This\nflexibility confers a number of advantages: for instance, not only can our\nmodel be trained to follow specific orderings such as left-to-right generation\nor a binary tree traversal, but it can also be trained to maximize entropy over\nall valid insertions for robustness. In addition, our model seamlessly\naccommodates both fully autoregressive generation (one insertion at a time) and\npartially autoregressive generation (simultaneous insertions at multiple\nlocations). We validate our approach by analyzing its performance on the WMT\n2014 English-German machine translation task under various settings for\ntraining and decoding. We find that the Insertion Transformer outperforms many\nprior non-autoregressive approaches to translation at comparable or better\nlevels of parallelism, and successfully recovers the performance of the\noriginal Transformer while requiring only logarithmically many iterations\nduring decoding.", "published": "2019-02-08 19:00:04", "link": "http://arxiv.org/abs/1902.03249v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Speech enhancement with variational autoencoders and alpha-stable\n  distributions", "abstract": "This paper focuses on single-channel semi-supervised speech enhancement. We\nlearn a speaker-independent deep generative speech model using the framework of\nvariational autoencoders. The noise model remains unsupervised because we do\nnot assume prior knowledge of the noisy recording environment. In this context,\nour contribution is to propose a noise model based on alpha-stable\ndistributions, instead of the more conventional Gaussian non-negative matrix\nfactorization approach found in previous studies. We develop a Monte Carlo\nexpectation-maximization algorithm for estimating the model parameters at test\ntime. Experimental results show the superiority of the proposed approach both\nin terms of perceptual quality and intelligibility of the enhanced speech\nsignal.", "published": "2019-02-08 14:50:47", "link": "http://arxiv.org/abs/1902.03926v1", "categories": ["cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Machine learning and chord based feature engineering for genre\n  prediction in popular Brazilian music", "abstract": "Music genre can be hard to describe: many factors are involved, such as\nstyle, music technique, and historical context. Some genres even have\noverlapping characteristics. Looking for a better understanding of how music\ngenres are related to musical harmonic structures, we gathered data about the\nmusic chords for thousands of popular Brazilian songs. Here, 'popular' does not\nonly refer to the genre named MPB (Brazilian Popular Music) but to nine\ndifferent genres that were considered particular to the Brazilian case. The\nmain goals of the present work are to extract and engineer harmonically related\nfeatures from chords data and to use it to classify popular Brazilian music\ngenres towards establishing a connection between harmonic relationships and\nBrazilian genres. We also emphasize the generalization of the method for\nobtaining the data, allowing for the replication and direct extension of this\nwork. Our final model is a combination of multiple classification trees, also\nknown as the random forest model. We found that features extracted from\nharmonic elements can satisfactorily predict music genre for the Brazilian\ncase, as well as features obtained from the Spotify API. The variables\nconsidered in this work also give an intuition about how they relate to the\ngenres.", "published": "2019-02-08 20:38:18", "link": "http://arxiv.org/abs/1902.03283v1", "categories": ["cs.IR", "cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.IR"}
