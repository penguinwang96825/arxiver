{"title": "Tuiteamos o pongamos un tuit? Investigating the Social Constraints of\n  Loanword Integration in Spanish Social Media", "abstract": "Speakers of non-English languages often adopt loanwords from English to\nexpress new or unusual concepts. While these loanwords may be borrowed\nunchanged, speakers may also integrate the words to fit the constraints of\ntheir native language, e.g. creating Spanish \"tuitear\" from English \"tweet.\"\nLinguists have often considered the process of loanword integration to be more\ndependent on language-internal constraints, but sociolinguistic constraints\nsuch as speaker background remain only qualitatively understood. We investigate\nthe role of social context and speaker background in Spanish speakers' use of\nintegrated loanwords on social media. We find first that newspaper authors use\nthe integrated forms of loanwords and native words more often than social media\nauthors, showing that integration is associated with formal domains. In social\nmedia, we find that speaker background and expectations of formality explain\nloanword and native word integration, such that authors who use more Spanish\nand who write to a wider audience tend to use integrated verb forms more often.\nThis study shows that loanword integration reflects not only language-internal\nconstraints but also social expectations that vary by conversation and speaker.", "published": "2021-01-16 04:42:44", "link": "http://arxiv.org/abs/2101.06368v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "To Understand Representation of Layer-aware Sequence Encoders as\n  Multi-order-graph", "abstract": "In this paper, we propose an explanation of representation for self-attention\nnetwork (SAN) based neural sequence encoders, which regards the information\ncaptured by the model and the encoding of the model as graph structure and the\ngeneration of these graph structures respectively. The proposed explanation\napplies to existing works on SAN-based models and can explain the relationship\namong the ability to capture the structural or linguistic information, depth of\nmodel, and length of sentence, and can also be extended to other models such as\nrecurrent neural network based models. We also propose a revisited multigraph\ncalled Multi-order-Graph (MoG) based on our explanation to model the graph\nstructures in the SAN-based model as subgraphs in MoG and convert the encoding\nof SAN-based model to the generation of MoG. Based on our explanation, we\nfurther introduce a Graph-Transformer by enhancing the ability to capture\nmultiple subgraphs of different orders and focusing on subgraphs of high\norders. Experimental results on multiple neural machine translation tasks show\nthat the Graph-Transformer can yield effective performance improvement.", "published": "2021-01-16 08:12:03", "link": "http://arxiv.org/abs/2101.06397v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ComQA:Compositional Question Answering via Hierarchical Graph Neural\n  Networks", "abstract": "With the development of deep learning techniques and large scale datasets,\nthe question answering (QA) systems have been quickly improved, providing more\naccurate and satisfying answers. However, current QA systems either focus on\nthe sentence-level answer, i.e., answer selection, or phrase-level answer,\ni.e., machine reading comprehension. How to produce compositional answers has\nnot been throughout investigated. In compositional question answering, the\nsystems should assemble several supporting evidence from the document to\ngenerate the final answer, which is more difficult than sentence-level or\nphrase-level QA. In this paper, we present a large-scale compositional question\nanswering dataset containing more than 120k human-labeled questions. The answer\nin this dataset is composed of discontiguous sentences in the corresponding\ndocument. To tackle the ComQA problem, we proposed a hierarchical graph neural\nnetworks, which represents the document from the low-level word to the\nhigh-level sentence. We also devise a question selection and node selection\ntask for pre-training. Our proposed model achieves a significant improvement\nover previous machine reading comprehension methods and pre-training methods.\nCodes and dataset can be found at \\url{https://github.com/benywon/ComQA}.", "published": "2021-01-16 08:23:27", "link": "http://arxiv.org/abs/2101.06400v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistically-Enriched and Context-Aware Zero-shot Slot Filling", "abstract": "Slot filling is identifying contiguous spans of words in an utterance that\ncorrespond to certain parameters (i.e., slots) of a user request/query. Slot\nfilling is one of the most important challenges in modern task-oriented dialog\nsystems. Supervised learning approaches have proven effective at tackling this\nchallenge, but they need a significant amount of labeled training data in a\ngiven domain. However, new domains (i.e., unseen in training) may emerge after\ndeployment. Thus, it is imperative that these models seamlessly adapt and fill\nslots from both seen and unseen domains -- unseen domains contain unseen slot\ntypes with no training data, and even seen slots in unseen domains are\ntypically presented in different contexts. This setting is commonly referred to\nas zero-shot slot filling. Little work has focused on this setting, with\nlimited experimental evaluation. Existing models that mainly rely on\ncontext-independent embedding-based similarity measures fail to detect slot\nvalues in unseen domains or do so only partially. We propose a new zero-shot\nslot filling neural model, LEONA, which works in three steps. Step one acquires\ndomain-oblivious, context-aware representations of the utterance word by\nexploiting (a) linguistic features; (b) named entity recognition cues; (c)\ncontextual embeddings from pre-trained language models. Step two fine-tunes\nthese rich representations and produces slot-independent tags for each word.\nStep three exploits generalizable context-aware utterance-slot similarity\nfeatures at the word level, uses slot-independent tags, and contextualizes them\nto produce slot-specific predictions for each word. Our thorough evaluation on\nfour diverse public datasets demonstrates that our approach consistently\noutperforms the SOTA models by 17.52%, 22.15%, 17.42%, and 17.95% on average\nfor unseen domains on SNIPS, ATIS, MultiWOZ, and SGD datasets, respectively.", "published": "2021-01-16 20:18:16", "link": "http://arxiv.org/abs/2101.06514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weakly-Supervised Hierarchical Models for Predicting Persuasive\n  Strategies in Good-faith Textual Requests", "abstract": "Modeling persuasive language has the potential to better facilitate our\ndecision-making processes. Despite its importance, computational modeling of\npersuasion is still in its infancy, largely due to the lack of benchmark\ndatasets that can provide quantitative labels of persuasive strategies to\nexpedite this line of research. To this end, we introduce a large-scale\nmulti-domain text corpus for modeling persuasive strategies in good-faith text\nrequests. Moreover, we design a hierarchical weakly-supervised latent variable\nmodel that can leverage partially labeled data to predict such associated\npersuasive strategies for each sentence, where the supervision comes from both\nthe overall document-level labels and very limited sentence-level labels.\nExperimental results showed that our proposed method outperformed existing\nsemi-supervised baselines significantly. We have publicly released our code at\nhttps://github.com/GT-SALT/Persuasion_Strategy_WVAE.", "published": "2021-01-16 02:31:04", "link": "http://arxiv.org/abs/2101.06351v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Comparison of Machine Learning for Sentiment Analysis in Detecting\n  Anxiety Based on Social Media Data", "abstract": "All groups of people felt the impact of the COVID-19 pandemic. This situation\ntriggers anxiety, which is bad for everyone. The government's role is very\ninfluential in solving these problems with its work program. It also has many\npros and cons that cause public anxiety. For that, it is necessary to detect\nanxiety to improve government programs that can increase public expectations.\nThis study applies machine learning to detecting anxiety based on social media\ncomments regarding government programs to deal with this pandemic. This concept\nwill adopt a sentiment analysis in detecting anxiety based on positive and\nnegative comments from netizens. The machine learning methods implemented\ninclude K-NN, Bernoulli, Decision Tree Classifier, Support Vector Classifier,\nRandom Forest, and XG-boost. The data sample used is the result of crawling\nYouTube comments. The data used amounted to 4862 comments consisting of\nnegative and positive data with 3211 and 1651. Negative data identify anxiety,\nwhile positive data identifies hope (not anxious). Machine learning is\nprocessed based on feature extraction of count-vectorization and TF-IDF. The\nresults showed that the sentiment data amounted to 3889 and 973 in testing, and\ntraining with the greatest accuracy was the random forest with feature\nextraction of vectorization count and TF-IDF of 84.99% and 82.63%,\nrespectively. The best precision test is K-NN, while the best recall is\nXG-Boost. Thus, Random Forest is the best accurate to detect someone's anxiety\nbased-on data from social media.", "published": "2021-01-16 02:47:14", "link": "http://arxiv.org/abs/2101.06353v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Match-Ignition: Plugging PageRank into Transformer for Long-form Text\n  Matching", "abstract": "Neural text matching models have been widely used in community question\nanswering, information retrieval, and dialogue. However, these models designed\nfor short texts cannot well address the long-form text matching problem,\nbecause there are many contexts in long-form texts can not be directly aligned\nwith each other, and it is difficult for existing models to capture the key\nmatching signals from such noisy data. Besides, these models are\ncomputationally expensive for simply use all textual data indiscriminately. To\ntackle the effectiveness and efficiency problem, we propose a novel\nhierarchical noise filtering model, namely Match-Ignition. The main idea is to\nplug the well-known PageRank algorithm into the Transformer, to identify and\nfilter both sentence and word level noisy information in the matching process.\nNoisy sentences are usually easy to detect because previous work has shown that\ntheir similarity can be explicitly evaluated by the word overlapping, so we\ndirectly use PageRank to filter such information based on a sentence similarity\ngraph. Unlike sentences, words rely on their contexts to express concrete\nmeanings, so we propose to jointly learn the filtering and matching process, to\nwell capture the critical word-level matching signals. Specifically, a word\ngraph is first built based on the attention scores in each self-attention block\nof Transformer, and key words are then selected by applying PageRank on this\ngraph. In this way, noisy words will be filtered out layer by layer in the\nmatching process. Experimental results show that Match-Ignition outperforms\nboth SOTA short text matching models and recent long-form text matching models.\nWe also conduct detailed analysis to show that Match-Ignition efficiently\ncaptures important sentences and words, to facilitate the long-form text\nmatching process.", "published": "2021-01-16 10:34:03", "link": "http://arxiv.org/abs/2101.06423v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Survey on Extraction of Causal Relations from Natural Language Text", "abstract": "As an essential component of human cognition, cause-effect relations appear\nfrequently in text, and curating cause-effect relations from text helps in\nbuilding causal networks for predictive tasks. Existing causality extraction\ntechniques include knowledge-based, statistical machine learning(ML)-based, and\ndeep learning-based approaches. Each method has its advantages and weaknesses.\nFor example, knowledge-based methods are understandable but require extensive\nmanual domain knowledge and have poor cross-domain applicability. Statistical\nmachine learning methods are more automated because of natural language\nprocessing (NLP) toolkits. However, feature engineering is labor-intensive, and\ntoolkits may lead to error propagation. In the past few years, deep learning\ntechniques attract substantial attention from NLP researchers because of its'\npowerful representation learning ability and the rapid increase in\ncomputational resources. Their limitations include high computational costs and\na lack of adequate annotated training data. In this paper, we conduct a\ncomprehensive survey of causality extraction. We initially introduce primary\nforms existing in the causality extraction: explicit intra-sentential\ncausality, implicit causality, and inter-sentential causality. Next, we list\nbenchmark datasets and modeling assessment methods for causal relation\nextraction. Then, we present a structured overview of the three techniques with\ntheir representative systems. Lastly, we highlight existing open challenges\nwith their potential directions.", "published": "2021-01-16 10:49:39", "link": "http://arxiv.org/abs/2101.06426v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Transformer-Based Models for Question Answering on COVID19", "abstract": "In response to the Kaggle's COVID-19 Open Research Dataset (CORD-19)\nchallenge, we have proposed three transformer-based question-answering systems\nusing BERT, ALBERT, and T5 models. Since the CORD-19 dataset is unlabeled, we\nhave evaluated the question-answering models' performance on two labeled\nquestions answers datasets \\textemdash CovidQA and CovidGQA. The BERT-based QA\nsystem achieved the highest F1 score (26.32), while the ALBERT-based QA system\nachieved the highest Exact Match (13.04). However, numerous challenges are\nassociated with developing high-performance question-answering systems for the\nongoing COVID-19 pandemic and future pandemics. At the end of this paper, we\ndiscuss these challenges and suggest potential solutions to address them.", "published": "2021-01-16 23:06:30", "link": "http://arxiv.org/abs/2101.11432v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Latent Variable Models for Visual Question Answering", "abstract": "Current work on Visual Question Answering (VQA) explore deterministic\napproaches conditioned on various types of image and question features. We\nposit that, in addition to image and question pairs, other modalities are\nuseful for teaching machine to carry out question answering. Hence in this\npaper, we propose latent variable models for VQA where extra information (e.g.\ncaptions and answer categories) are incorporated as latent variables, which are\nobserved during training but in turn benefit question-answering performance at\ntest time. Experiments on the VQA v2.0 benchmarking dataset demonstrate the\neffectiveness of our proposed models: they improve over strong baselines,\nespecially those that do not rely on extensive language-vision pre-training.", "published": "2021-01-16 08:21:43", "link": "http://arxiv.org/abs/2101.06399v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Minimum-volume Multichannel Nonnegative matrix factorization for blind\n  source separation", "abstract": "Multichannel blind audio source separation aims to recover the latent sources\nfrom their multichannel mixtures without supervised information. One\nstate-of-the-art blind audio source separation method, named independent\nlow-rank matrix analysis (ILRMA), unifies independent vector analysis (IVA) and\nnonnegative matrix factorization (NMF). However, the spectra matrix produced\nfrom NMF may not find a compact spectral basis. It may not guarantee the\nidentifiability of each source as well. To address this problem, here we\npropose to enhance the identifiability of the source model by a minimum-volume\nprior distribution. We further regularize a multichannel NMF (MNMF) and ILRMA\nrespectively with the minimum-volume regularizer. The proposed methods maximize\nthe posterior distribution of the separated sources, which ensures the\nstability of the convergence. Experimental results demonstrate the\neffectiveness of the proposed methods compared with auxiliary independent\nvector analysis, MNMF, ILRMA and its extensions.", "published": "2021-01-16 08:12:23", "link": "http://arxiv.org/abs/2101.06398v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Mispronunciation Detection in Non-native (L2) English with Uncertainty\n  Modeling", "abstract": "A common approach to the automatic detection of mispronunciation in language\nlearning is to recognize the phonemes produced by a student and compare it to\nthe expected pronunciation of a native speaker. This approach makes two\nsimplifying assumptions: a) phonemes can be recognized from speech with high\naccuracy, b) there is a single correct way for a sentence to be pronounced.\nThese assumptions do not always hold, which can result in a significant amount\nof false mispronunciation alarms. We propose a novel approach to overcome this\nproblem based on two principles: a) taking into account uncertainty in the\nautomatic phoneme recognition step, b) accounting for the fact that there may\nbe multiple valid pronunciations. We evaluate the model on non-native (L2)\nEnglish speech of German, Italian and Polish speakers, where it is shown to\nincrease the precision of detecting mispronunciations by up to 18% (relative)\ncompared to the common approach.", "published": "2021-01-16 08:03:51", "link": "http://arxiv.org/abs/2101.06396v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Novel Approach for Earthquake Early Warning System Design using Deep\n  Learning Techniques", "abstract": "Earthquake signals are non-stationary in nature and thus in real-time, it is\ndifficult to identify and classify events based on classical approaches like\npeak ground displacement, peak ground velocity. Even the popular algorithm of\nSTA/LTA requires extensive research to determine basic thresholding parameters\nso as to trigger an alarm. Also, many times due to human error or other\nunavoidable natural factors such as thunder strikes or landslides, the\nalgorithm may end up raising a false alarm. This work focuses on detecting\nearthquakes by converting seismograph recorded data into corresponding audio\nsignals for better perception and then uses popular Speech Recognition\ntechniques of Filter bank coefficients and Mel Frequency Cepstral Coefficients\n(MFCC) to extract the features. These features were then used to train a\nConvolutional Neural Network(CNN) and a Long Short Term Memory(LSTM) network.\nThe proposed method can overcome the above-mentioned problems and help in\ndetecting earthquakes automatically from the waveforms without much human\nintervention. For the 1000Hz audio data set the CNN model showed a testing\naccuracy of 91.1% for 0.2-second sample window length while the LSTM model\nshowed 93.99% for the same. A total of 610 sounds consisting of 310 earthquake\nsounds and 300 non-earthquake sounds were used to train the models. While\ntesting, the total time required for generating the alarm was approximately 2\nseconds which included individual times for data collection, processing, and\nprediction taking into consideration the processing and prediction delays. This\nshows the effectiveness of the proposed method for Earthquake Early Warning\n(EEW) applications. Since the input of the method is only the waveform, it is\nsuitable for real-time processing, thus the models can also be used as an\nonsite EEW system requiring a minimum amount of preparation time and workload.", "published": "2021-01-16 20:35:34", "link": "http://arxiv.org/abs/2101.06517v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
