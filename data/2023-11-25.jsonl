{"title": "Code Search Debiasing:Improve Search Results beyond Overall Ranking\n  Performance", "abstract": "Code search engine is an essential tool in software development. Many code\nsearch methods have sprung up, focusing on the overall ranking performance of\ncode search. In this paper, we study code search from another perspective by\nanalyzing the bias of code search models. Biased code search engines provide\npoor user experience, even though they show promising overall performance. Due\nto different development conventions (e.g., prefer long queries or\nabbreviations), some programmers will find the engine useful, while others may\nfind it hard to get desirable search results. To mitigate biases, we develop a\ngeneral debiasing framework that employs reranking to calibrate search results.\nIt can be easily plugged into existing engines and handle new code search\nbiases discovered in the future. Experiments show that our framework can\neffectively reduce biases. Meanwhile, the overall ranking performance of code\nsearch gets improved after debiasing.", "published": "2023-11-25 02:31:22", "link": "http://arxiv.org/abs/2311.14901v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Faster Minimum Bayes Risk Decoding with Confidence-based Pruning", "abstract": "Minimum Bayes risk (MBR) decoding outputs the hypothesis with the highest\nexpected utility over the model distribution for some utility function. It has\nbeen shown to improve accuracy over beam search in conditional language\ngeneration problems and especially neural machine translation, in both human\nand automatic evaluations. However, the standard sampling-based algorithm for\nMBR is substantially more computationally expensive than beam search, requiring\na large number of samples as well as a quadratic number of calls to the utility\nfunction, limiting its applicability. We describe an algorithm for MBR which\ngradually grows the number of samples used to estimate the utility while\npruning hypotheses that are unlikely to have the highest utility according to\nconfidence estimates obtained with bootstrap sampling. Our method requires\nfewer samples and drastically reduces the number of calls to the utility\nfunction compared to standard MBR while being statistically indistinguishable\nin terms of accuracy. We demonstrate the effectiveness of our approach in\nexperiments on three language pairs, using chrF++ and COMET as\nutility/evaluation metrics.", "published": "2023-11-25 03:38:14", "link": "http://arxiv.org/abs/2311.14919v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vector-Quantized Prompt Learning for Paraphrase Generation", "abstract": "Deep generative modeling of natural languages has achieved many successes,\nsuch as producing fluent sentences and translating from one language into\nanother. However, the development of generative modeling techniques for\nparaphrase generation still lags behind largely due to the challenges in\naddressing the complex conflicts between expression diversity and semantic\npreservation. This paper proposes to generate diverse and high-quality\nparaphrases by exploiting the pre-trained models with instance-dependent\nprompts. To learn generalizable prompts, we assume that the number of abstract\ntransforming patterns of paraphrase generation (governed by prompts) is finite\nand usually not large. Therefore, we present vector-quantized prompts as the\ncues to control the generation of pre-trained models. Extensive experiments\ndemonstrate that the proposed method achieves new state-of-art results on three\nbenchmark datasets, including Quora, Wikianswers, and MSCOCO. We will release\nall the code upon acceptance.", "published": "2023-11-25 07:13:06", "link": "http://arxiv.org/abs/2311.14949v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Walking a Tightrope -- Evaluating Large Language Models in High-Risk\n  Domains", "abstract": "High-risk domains pose unique challenges that require language models to\nprovide accurate and safe responses. Despite the great success of large\nlanguage models (LLMs), such as ChatGPT and its variants, their performance in\nhigh-risk domains remains unclear. Our study delves into an in-depth analysis\nof the performance of instruction-tuned LLMs, focusing on factual accuracy and\nsafety adherence. To comprehensively assess the capabilities of LLMs, we\nconduct experiments on six NLP datasets including question answering and\nsummarization tasks within two high-risk domains: legal and medical. Further\nqualitative analysis highlights the existing limitations inherent in current\nLLMs when evaluating in high-risk domains. This underscores the essential\nnature of not only improving LLM capabilities but also prioritizing the\nrefinement of domain-specific metrics, and embracing a more human-centric\napproach to enhance safety and factual reliability. Our findings advance the\nfield toward the concerns of properly evaluating LLMs in high-risk domains,\naiming to steer the adaptability of LLMs in fulfilling societal obligations and\naligning with forthcoming regulations, such as the EU AI Act.", "published": "2023-11-25 08:58:07", "link": "http://arxiv.org/abs/2311.14966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Offensive Language Identification in Transliterated and Code-Mixed\n  Bangla", "abstract": "Identifying offensive content in social media is vital for creating safe\nonline communities. Several recent studies have addressed this problem by\ncreating datasets for various languages. In this paper, we explore offensive\nlanguage identification in texts with transliterations and code-mixing,\nlinguistic phenomena common in multilingual societies, and a known challenge\nfor NLP systems. We introduce TB-OLID, a transliterated Bangla offensive\nlanguage dataset containing 5,000 manually annotated comments. We train and\nfine-tune machine learning models on TB-OLID, and we evaluate their results on\nthis dataset. Our results show that English pre-trained transformer-based\nmodels, such as fBERT and HateBERT achieve the best performance on this\ndataset.", "published": "2023-11-25 13:27:22", "link": "http://arxiv.org/abs/2311.15023v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "nlpBDpatriots at BLP-2023 Task 1: A Two-Step Classification for Violence\n  Inciting Text Detection in Bangla", "abstract": "In this paper, we discuss the nlpBDpatriots entry to the shared task on\nViolence Inciting Text Detection (VITD) organized as part of the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The aim of this task\nis to identify and classify the violent threats, that provoke further unlawful\nviolent acts. Our best-performing approach for the task is two-step\nclassification using back translation and multilinguality which ranked 6th out\nof 27 teams with a macro F1 score of 0.74.", "published": "2023-11-25 13:47:34", "link": "http://arxiv.org/abs/2311.15029v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach to Bangla\n  Sentiment Analysis", "abstract": "In this paper, we discuss the nlpBDpatriots entry to the shared task on\nSentiment Analysis of Bangla Social Media Posts organized at the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The main objective\nof this task is to identify the polarity of social media content using a Bangla\ndataset annotated with positive, neutral, and negative labels provided by the\nshared task organizers. Our best system for this task is a transfer learning\napproach with data augmentation which achieved a micro F1 score of 0.71. Our\nbest system ranked 12th among 30 teams that participated in the competition.", "published": "2023-11-25 13:58:58", "link": "http://arxiv.org/abs/2311.15032v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual self-supervised speech representations improve the speech\n  recognition of low-resource African languages with codeswitching", "abstract": "While many speakers of low-resource languages regularly code-switch between\ntheir languages and other regional languages or English, datasets of\ncodeswitched speech are too small to train bespoke acoustic models from scratch\nor do language model rescoring. Here we propose finetuning self-supervised\nspeech representations such as wav2vec 2.0 XLSR to recognize code-switched\ndata. We find that finetuning self-supervised multilingual representations and\naugmenting them with n-gram language models trained from transcripts reduces\nabsolute word error rates by up to 20% compared to baselines of hybrid models\ntrained from scratch on code-switched data. Our findings suggest that in\ncircumstances with limited training data finetuning self-supervised\nrepresentations is a better performing and viable solution.", "published": "2023-11-25 17:05:21", "link": "http://arxiv.org/abs/2311.15077v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Solving the Right Problem is Key for Translational NLP: A Case Study in\n  UMLS Vocabulary Insertion", "abstract": "As the immense opportunities enabled by large language models become more\napparent, NLP systems will be increasingly expected to excel in real-world\nsettings. However, in many instances, powerful models alone will not yield\ntranslational NLP solutions, especially if the formulated problem is not well\naligned with the real-world task. In this work, we study the case of UMLS\nvocabulary insertion, an important real-world task in which hundreds of\nthousands of new terms, referred to as atoms, are added to the UMLS, one of the\nmost comprehensive open-source biomedical knowledge bases. Previous work aimed\nto develop an automated NLP system to make this time-consuming, costly, and\nerror-prone task more efficient. Nevertheless, practical progress in this\ndirection has been difficult to achieve due to a problem formulation and\nevaluation gap between research output and the real-world task. In order to\naddress this gap, we introduce a new formulation for UMLS vocabulary insertion\nwhich mirrors the real-world task, datasets which faithfully represent it and\nseveral strong baselines we developed through re-purposing existing solutions.\nAdditionally, we propose an effective rule-enhanced biomedical language model\nwhich enables important new model behavior, outperforms all strong baselines\nand provides measurable qualitative improvements to editors who carry out the\nUVI task. We hope this case study provides insight into the considerable\nimportance of problem formulation for the success of translational NLP\nsolutions.", "published": "2023-11-25 19:35:53", "link": "http://arxiv.org/abs/2311.15106v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relevance feedback strategies for recall-oriented neural information\n  retrieval", "abstract": "In a number of information retrieval applications (e.g., patent search,\nliterature review, due diligence, etc.), preventing false negatives is more\nimportant than preventing false positives. However, approaches designed to\nreduce review effort (like \"technology assisted review\") can create false\nnegatives, since they are often based on active learning systems that exclude\ndocuments automatically based on user feedback. Therefore, this research\nproposes a more recall-oriented approach to reducing review effort. More\nspecifically, through iteratively re-ranking the relevance rankings based on\nuser feedback, which is also referred to as relevance feedback. In our proposed\nmethod, the relevance rankings are produced by a BERT-based dense-vector search\nand the relevance feedback is based on cumulatively summing the queried and\nselected embeddings. Our results show that this method can reduce review effort\nbetween 17.85% and 59.04%, compared to a baseline approach (of no feedback),\ngiven a fixed recall target", "published": "2023-11-25 19:50:41", "link": "http://arxiv.org/abs/2311.15110v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation", "abstract": "Achieving empathy is a crucial step toward humanized dialogue systems.\nCurrent approaches for empathetic dialogue generation mainly perceive an\nemotional label to generate an empathetic response conditioned on it, which\nsimply treat emotions independently, but ignore the intrinsic emotion\ncorrelation in dialogues, resulting in inaccurate emotion perception and\nunsuitable response generation. In this paper, we propose a novel emotion\ncorrelation enhanced empathetic dialogue generation framework, which\ncomprehensively realizes emotion correlation learning, utilization, and\nsupervising. Specifically, a multi-resolution emotion graph is devised to\ncapture context-based emotion interactions from different resolutions, further\nmodeling emotion correlation. Then we propose an emotion correlation enhanced\ndecoder, with a novel correlation-aware aggregation and soft/hard strategy,\nrespectively improving the emotion perception and response generation.\nExperimental results on the benchmark dataset demonstrate the superiority of\nour model in both empathetic perception and expression.", "published": "2023-11-25 12:47:39", "link": "http://arxiv.org/abs/2311.15016v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Detection of developmental language disorder in Cypriot Greek children\n  using a neural network algorithm", "abstract": "Children with developmental language disorder (DLD) encounter difficulties in\nacquiring various language structures. Early identification and intervention\nare crucial to prevent negative long-term outcomes impacting the academic,\nsocial, and emotional development of children. The study aims to develop an\nautomated method for the identification of DLD using artificial intelligence,\nspecifically a neural network machine learning algorithm. This protocol is\napplied for the first time in a Cypriot Greek child population with DLD. The\nneural network model was trained using perceptual and production data elicited\nfrom 15 children with DLD and 15 healthy controls in the age range of 7;10\nuntil 10;4. The k-fold technique was used to crossvalidate the algorithm. The\nperformance of the model was evaluated using metrics such as accuracy,\nprecision, recall, F1 score, and ROC/AUC curve to assess its ability to make\naccurate predictions on a set of unseen data. The results demonstrated high\nclassification values for all metrics, indicating the high accuracy of the\nneural model in classifying children with DLD. Additionally, the variable\nimportance analysis revealed that the language production skills of children\nhad a more significant impact on the performance of the model compared to\nperception skills. Machine learning paradigms provide effective discrimination\nbetween children with DLD and those with TD, with the potential to enhance\nclinical assessment and facilitate earlier and more efficient detection of the\ndisorder.", "published": "2023-11-25 15:23:46", "link": "http://arxiv.org/abs/2311.15054v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatically Finding and Categorizing Replication Studies", "abstract": "In many fields of experimental science, papers that failed to replicate\ncontinue to be cited as a result of the poor discoverability of replication\nstudies. As a first step to creating a system that automatically finds\nreplication studies for a given paper, 334 replication studies and 344\nreplicated studies were collected. Replication studies could be identified in\nthe dataset based on text content at a higher rate than chance (AUROC = 0.886).\n  Additionally, successful replication studies could be distinguished from\nfailed replication studies at a higher rate than chance (AUROC = 0.664).", "published": "2023-11-25 15:27:10", "link": "http://arxiv.org/abs/2311.15055v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Localizing Lying in Llama: Understanding Instructed Dishonesty on\n  True-False Questions Through Prompting, Probing, and Patching", "abstract": "Large language models (LLMs) demonstrate significant knowledge through their\noutputs, though it is often unclear whether false outputs are due to a lack of\nknowledge or dishonesty. In this paper, we investigate instructed dishonesty,\nwherein we explicitly prompt LLaMA-2-70b-chat to lie. We perform prompt\nengineering to find which prompts best induce lying behavior, and then use\nmechanistic interpretability approaches to localize where in the network this\nbehavior occurs. Using linear probing and activation patching, we localize five\nlayers that appear especially important for lying. We then find just 46\nattention heads within these layers that enable us to causally intervene such\nthat the lying model instead answers honestly. We show that these interventions\nwork robustly across many prompts and dataset splits. Overall, our work\ncontributes a greater understanding of dishonesty in LLMs so that we may hope\nto prevent it.", "published": "2023-11-25 22:41:23", "link": "http://arxiv.org/abs/2311.15131v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Sentiment Analysis Results through Outlier Detection\n  Optimization", "abstract": "When dealing with text data containing subjective labels like speaker\nemotions, inaccuracies or discrepancies among labelers are not uncommon. Such\ndiscrepancies can significantly affect the performance of machine learning\nalgorithms. This study investigates the potential of identifying and addressing\noutliers in text data with subjective labels, aiming to enhance classification\noutcomes. We utilized the Deep SVDD algorithm, a one-class classification\nmethod, to detect outliers in nine text-based emotion and sentiment analysis\ndatasets. By employing both a small-sized language model (DistilBERT base model\nwith 66 million parameters) and non-deep learning machine learning algorithms\n(decision tree, KNN, Logistic Regression, and LDA) as the classifier, our\nfindings suggest that the removal of outliers can lead to enhanced results in\nmost cases. Additionally, as outliers in such datasets are not necessarily\nunlearnable, we experienced utilizing a large language model -- DeBERTa v3\nlarge with 131 million parameters, which can capture very complex patterns in\ndata. We continued to observe performance enhancements across multiple\ndatasets.", "published": "2023-11-25 18:20:43", "link": "http://arxiv.org/abs/2311.16185v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Multi-Scale Sub-Band Constant-Q Transform Discriminator for\n  High-Fidelity Vocoder", "abstract": "Generative Adversarial Network (GAN) based vocoders are superior in inference\nspeed and synthesis quality when reconstructing an audible waveform from an\nacoustic representation. This study focuses on improving the discriminator to\npromote GAN-based vocoders. Most existing time-frequency-representation-based\ndiscriminators are rooted in Short-Time Fourier Transform (STFT), whose\ntime-frequency resolution in a spectrogram is fixed, making it incompatible\nwith signals like singing voices that require flexible attention for different\nfrequency bands. Motivated by that, our study utilizes the Constant-Q Transform\n(CQT), which owns dynamic resolution among frequencies, contributing to a\nbetter modeling ability in pitch accuracy and harmonic tracking. Specifically,\nwe propose a Multi-Scale Sub-Band CQT (MS-SB-CQT) Discriminator, which operates\non the CQT spectrogram at multiple scales and performs sub-band processing\naccording to different octaves. Experiments conducted on both speech and\nsinging voices confirm the effectiveness of our proposed method. Moreover, we\nalso verified that the CQT-based and the STFT-based discriminators could be\ncomplementary under joint training. Specifically, enhanced by the proposed\nMS-SB-CQT and the existing MS-STFT Discriminators, the MOS of HiFi-GAN can be\nboosted from 3.27 to 3.87 for seen singers and from 3.40 to 3.78 for unseen\nsingers.", "published": "2023-11-25 07:49:09", "link": "http://arxiv.org/abs/2311.14957v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Weakly-Supervised Audio-Visual Segmentation", "abstract": "Audio-visual segmentation is a challenging task that aims to predict\npixel-level masks for sound sources in a video. Previous work applied a\ncomprehensive manually designed architecture with countless pixel-wise accurate\nmasks as supervision. However, these pixel-level masks are expensive and not\navailable in all cases. In this work, we aim to simplify the supervision as the\ninstance-level annotation, i.e., weakly-supervised audio-visual segmentation.\nWe present a novel Weakly-Supervised Audio-Visual Segmentation framework,\nnamely WS-AVS, that can learn multi-scale audio-visual alignment with\nmulti-scale multiple-instance contrastive learning for audio-visual\nsegmentation. Extensive experiments on AVSBench demonstrate the effectiveness\nof our WS-AVS in the weakly-supervised audio-visual segmentation of\nsingle-source and multi-source scenarios.", "published": "2023-11-25 17:18:35", "link": "http://arxiv.org/abs/2311.15080v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
