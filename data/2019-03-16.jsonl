{"title": "Emotion Action Detection and Emotion Inference: the Task and Dataset", "abstract": "Many Natural Language Processing works on emotion analysis only focus on\nsimple emotion classification without exploring the potentials of putting\nemotion into \"event context\", and ignore the analysis of emotion-related\nevents. One main reason is the lack of this kind of corpus. Here we present\nCause-Emotion-Action Corpus, which manually annotates not only emotion, but\nalso cause events and action events. We propose two new tasks based on the\ndata-set: emotion causality and emotion inference. The first task is to extract\na triple (cause, emotion, action). The second task is to infer the probable\nemotion. We are currently releasing the data-set with 10,603 samples and 15,892\nevents, basic statistic analysis and baseline on both emotion causality and\nemotion inference tasks. Baseline performance demonstrates that there is much\nroom for both tasks to be improved.", "published": "2019-03-16 09:46:29", "link": "http://arxiv.org/abs/1903.06901v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Lemmatization of Non-Standard Languages with Joint Learning", "abstract": "Lemmatization of standard languages is concerned with (i) abstracting over\nmorphological differences and (ii) resolving token-lemma ambiguities of\ninflected words in order to map them to a dictionary headword. In the present\npaper we aim to improve lemmatization performance on a set of non-standard\nhistorical languages in which the difficulty is increased by an additional\naspect (iii): spelling variation due to lacking orthographic standards. We\napproach lemmatization as a string-transduction task with an encoder-decoder\narchitecture which we enrich with sentence context information using a\nhierarchical sentence encoder. We show significant improvements over the\nstate-of-the-art when training the sentence encoder jointly for lemmatization\nand language modeling. Crucially, our architecture does not require POS or\nmorphological annotations, which are not always available for historical\ncorpora. Additionally, we also test the proposed model on a set of\ntypologically diverse standard languages showing results on par or better than\na model without enhanced sentence representations and previous state-of-the-art\nsystems. Finally, to encourage future work on processing of non-standard\nvarieties, we release the dataset of non-standard languages underlying the\npresent study, based on openly accessible sources.", "published": "2019-03-16 14:59:13", "link": "http://arxiv.org/abs/1903.06939v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Imbalanced multi-label classification using multi-task learning with\n  extractive summarization", "abstract": "Extractive summarization and imbalanced multi-label classification often\nrequire vast amounts of training data to avoid overfitting. In situations where\ntraining data is expensive to generate, leveraging information between tasks is\nan attractive approach to increasing the amount of available information. This\npaper employs multi-task training of an extractive summarizer and an RNN-based\nclassifier to improve summarization and classification accuracy by 50% and 75%,\nrespectively, relative to RNN baselines. We hypothesize that concatenating\nsentence encodings based on document and class context increases\ngeneralizability for highly variable corpuses.", "published": "2019-03-16 17:31:29", "link": "http://arxiv.org/abs/1903.06963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combination of multiple Deep Learning architectures for Offensive\n  Language Detection in Tweets", "abstract": "This report contains the details regarding our submission to the OffensEval\n2019 (SemEval 2019 - Task 6). The competition was based on the Offensive\nLanguage Identification Dataset. We first discuss the details of the classifier\nimplemented and the type of input data used and pre-processing performed. We\nthen move onto critically evaluating our performance. We have achieved a\nmacro-average F1-score of 0.76, 0.68, 0.54, respectively for Task a, Task b,\nand Task c, which we believe reflects on the level of sophistication of the\nmodels implemented. Finally, we will be discussing the difficulties encountered\nand possible improvements for the future.", "published": "2019-03-16 11:19:38", "link": "http://arxiv.org/abs/1903.08734v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Non-intrusive speech quality assessment using neural networks", "abstract": "Estimating the perceived quality of an audio signal is critical for many\nmultimedia and audio processing systems. Providers strive to offer optimal and\nreliable services in order to increase the user quality of experience (QoE). In\nthis work, we present an investigation of the applicability of neural networks\nfor non-intrusive audio quality assessment. We propose three neural\nnetwork-based approaches for mean opinion score (MOS) estimation. We compare\nour results to three instrumental measures: the perceptual evaluation of speech\nquality (PESQ), the ITU-T Recommendation P.563, and the speech-to-reverberation\nenergy ratio. Our evaluation uses a speech dataset contaminated with\nconvolutive and additive noise, labeled using a crowd-based QoE evaluation,\nevaluated with Pearson correlation with MOS labels, and mean-squared-error of\nthe estimated MOS. Our proposed approaches outperform the aforementioned\ninstrumental measures, with a fully connected deep neural network using\nMel-frequency features providing the best correlation (0.87) and the lowest\nmean squared error (0.15)", "published": "2019-03-16 11:10:43", "link": "http://arxiv.org/abs/1903.06908v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
