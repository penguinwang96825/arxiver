{"title": "Unsupervised Text Style Transfer using Language Models as Discriminators", "abstract": "Binary classifiers are often employed as discriminators in GAN-based\nunsupervised style transfer systems to ensure that transferred sentences are\nsimilar to sentences in the target domain. One difficulty with this approach is\nthat the error signal provided by the discriminator can be unstable and is\nsometimes insufficient to train the generator to produce fluent language. In\nthis paper, we propose a new technique that uses a target domain language model\nas the discriminator, providing richer and more stable token-level feedback\nduring the learning process. We train the generator to minimize the negative\nlog likelihood (NLL) of generated sentences, evaluated by the language model.\nBy using a continuous approximation of discrete sampling under the generator,\nour model can be trained using back-propagation in an end- to-end fashion.\nMoreover, our empirical results show that when using a language model as a\nstructured discriminator, it is possible to forgo adversarial steps during\ntraining, making the process more stable. We compare our model with previous\nwork using convolutional neural networks (CNNs) as discriminators and show that\nour approach leads to improved performance on three tasks: word substitution\ndecipherment, sentiment modification, and related language translation.", "published": "2018-05-30 00:02:59", "link": "http://arxiv.org/abs/1805.11749v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Learning of Task-Oriented Neural Dialog Models", "abstract": "In this work, we propose an adversarial learning method for reward estimation\nin reinforcement learning (RL) based task-oriented dialog models. Most of the\ncurrent RL based task-oriented dialog systems require the access to a reward\nsignal from either user feedback or user ratings. Such user ratings, however,\nmay not always be consistent or available in practice. Furthermore, online\ndialog policy learning with RL typically requires a large number of queries to\nusers, suffering from sample efficiency problem. To address these challenges,\nwe propose an adversarial learning method to learn dialog rewards directly from\ndialog samples. Such rewards are further used to optimize the dialog policy\nwith policy gradient based RL. In the evaluation in a restaurant search domain,\nwe show that the proposed adversarial dialog learning method achieves advanced\ndialog success rate comparing to strong baseline methods. We further discuss\nthe covariate shift problem in online adversarial dialog learning and show how\nwe can address that with partial access to user feedback.", "published": "2018-05-30 00:48:44", "link": "http://arxiv.org/abs/1805.11762v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Planning, Inference and Pragmatics in Sequential Language Games", "abstract": "We study sequential language games in which two players, each with private\ninformation, communicate to achieve a common goal. In such games, a successful\nplayer must (i) infer the partner's private information from the partner's\nmessages, (ii) generate messages that are most likely to help with the goal,\nand (iii) reason pragmatically about the partner's strategy. We propose a model\nthat captures all three characteristics and demonstrate their importance in\ncapturing human behavior on a new goal-oriented dataset we collected using\ncrowdsourcing.", "published": "2018-05-30 02:04:30", "link": "http://arxiv.org/abs/1805.11774v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anaphora and Coreference Resolution: A Review", "abstract": "Entity resolution aims at resolving repeated references to an entity in a\ndocument and forms a core component of natural language processing (NLP)\nresearch. This field possesses immense potential to improve the performance of\nother NLP fields like machine translation, sentiment analysis, paraphrase\ndetection, summarization, etc. The area of entity resolution in NLP has seen\nproliferation of research in two separate sub-areas namely: anaphora resolution\nand coreference resolution. Through this review article, we aim at clarifying\nthe scope of these two tasks in entity resolution. We also carry out a detailed\nanalysis of the datasets, evaluation metrics and research methods that have\nbeen adopted to tackle this NLP problem. This survey is motivated with the aim\nof providing the reader with a clear understanding of what constitutes this NLP\nproblem and the issues that require attention.", "published": "2018-05-30 06:49:15", "link": "http://arxiv.org/abs/1805.11824v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An English-Hindi Code-Mixed Corpus: Stance Annotation and Baseline\n  System", "abstract": "Social media has become one of the main channels for peo- ple to communicate\nand share their views with the society. We can often detect from these views\nwhether the person is in favor, against or neu- tral towards a given topic.\nThese opinions from social media are very useful for various companies. We\npresent a new dataset that consists of 3545 English-Hindi code-mixed tweets\nwith opinion towards Demoneti- sation that was implemented in India in 2016\nwhich was followed by a large countrywide debate. We present a baseline\nsupervised classification system for stance detection developed using the same\ndataset that uses various machine learning techniques to achieve an accuracy of\n58.7% on 10-fold cross validation.", "published": "2018-05-30 09:03:50", "link": "http://arxiv.org/abs/1805.11868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Corpus of English-Hindi Code-Mixed Tweets for Sarcasm Detection", "abstract": "Social media platforms like twitter and facebook have be- come two of the\nlargest mediums used by people to express their views to- wards different\ntopics. Generation of such large user data has made NLP tasks like sentiment\nanalysis and opinion mining much more important. Using sarcasm in texts on\nsocial media has become a popular trend lately. Using sarcasm reverses the\nmeaning and polarity of what is implied by the text which poses challenge for\nmany NLP tasks. The task of sarcasm detection in text is gaining more and more\nimportance for both commer- cial and security services. We present the first\nEnglish-Hindi code-mixed dataset of tweets marked for presence of sarcasm and\nirony where each token is also annotated with a language tag. We present a\nbaseline su- pervised classification system developed using the same dataset\nwhich achieves an average F-score of 78.4 after using random forest classifier\nand performing 10-fold cross validation.", "published": "2018-05-30 09:08:54", "link": "http://arxiv.org/abs/1805.11869v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Character-Level Models versus Morphology in Semantic Role Labeling", "abstract": "Character-level models have become a popular approach specially for their\naccessibility and ability to handle unseen data. However, little is known on\ntheir ability to reveal the underlying morphological structure of a word, which\nis a crucial skill for high-level semantic analysis tasks, such as semantic\nrole labeling (SRL). In this work, we train various types of SRL models that\nuse word, character and morphology level information and analyze how\nperformance of characters compare to words and morphology for several\nlanguages. We conduct an in-depth error analysis for each morphological\ntypology and analyze the strengths and limitations of character-level models\nthat relate to out-of-domain data, training data size, long range dependencies\nand model complexity. Our exhaustive analyses shed light on important\ncharacteristics of character-level models and their semantic capability.", "published": "2018-05-30 13:22:02", "link": "http://arxiv.org/abs/1805.11937v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying and Understanding User Reactions to Deceptive and Trusted\n  Social News Sources", "abstract": "In the age of social news, it is important to understand the types of\nreactions that are evoked from news sources with various levels of credibility.\nIn the present work we seek to better understand how users react to trusted and\ndeceptive news sources across two popular, and very different, social media\nplatforms. To that end, (1) we develop a model to classify user reactions into\none of nine types, such as answer, elaboration, and question, etc, and (2) we\nmeasure the speed and the type of reaction for trusted and deceptive news\nsources for 10.8M Twitter posts and 6.2M Reddit comments. We show that there\nare significant differences in the speed and the type of reactions between\ntrusted and deceptive news sources on Twitter, but far smaller differences on\nReddit.", "published": "2018-05-30 15:20:14", "link": "http://arxiv.org/abs/1805.12032v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-end named entity extraction from speech", "abstract": "Named entity recognition (NER) is among SLU tasks that usually extract\nsemantic information from textual documents. Until now, NER from speech is made\nthrough a pipeline process that consists in processing first an automatic\nspeech recognition (ASR) on the audio and then processing a NER on the ASR\noutputs. Such approach has some disadvantages (error propagation, metric to\ntune ASR systems sub-optimal in regards to the final task, reduced space search\nat the ASR output level...) and it is known that more integrated approaches\noutperform sequential ones, when they can be applied. In this paper, we present\na first study of end-to-end approach that directly extracts named entities from\nspeech, though a unique neural architecture. On a such way, a joint\noptimization is able for both ASR and NER. Experiments are carried on French\ndata easily accessible, composed of data distributed in several evaluation\ncampaign. Experimental results show that this end-to-end approach provides\nbetter results (F-measure=0.69 on test data) than a classical pipeline approach\nto detect named entity categories (F-measure=0.65).", "published": "2018-05-30 15:56:22", "link": "http://arxiv.org/abs/1805.12045v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Bilingual Character Representation for Efficiently Addressing\n  Out-of-Vocabulary Words in Code-Switching Named Entity Recognition", "abstract": "We propose an LSTM-based model with hierarchical architecture on named entity\nrecognition from code-switching Twitter data. Our model uses bilingual\ncharacter representation and transfer learning to address out-of-vocabulary\nwords. In order to mitigate data noise, we propose to use token replacement and\nnormalization. In the 3rd Workshop on Computational Approaches to Linguistic\nCode-Switching Shared Task, we achieved second place with 62.76% harmonic mean\nF1-score for English-Spanish language pair without using any gazetteer and\nknowledge-based information.", "published": "2018-05-30 16:29:32", "link": "http://arxiv.org/abs/1805.12061v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code-Switching Language Modeling using Syntax-Aware Multi-Task Learning", "abstract": "Lack of text data has been the major issue on code-switching language\nmodeling. In this paper, we introduce multi-task learning based language model\nwhich shares syntax representation of languages to leverage linguistic\ninformation and tackle the low resource data issue. Our model jointly learns\nboth language modeling and Part-of-Speech tagging on code-switched utterances.\nIn this way, the model is able to identify the location of code-switching\npoints and improves the prediction of next word. Our approach outperforms\nstandard LSTM based language model, with an improvement of 9.7% and 7.4% in\nperplexity on SEAME Phase I and Phase II dataset respectively.", "published": "2018-05-30 16:37:43", "link": "http://arxiv.org/abs/1805.12070v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Marian: Cost-effective High-Quality Neural Machine Translation in C++", "abstract": "This paper describes the submissions of the \"Marian\" team to the WNMT 2018\nshared task. We investigate combinations of teacher-student training,\nlow-precision matrix products, auto-tuning and other methods to optimize the\nTransformer model on GPU and CPU. By further integrating these methods with the\nnew averaging attention networks, a recently introduced faster Transformer\nvariant, we create a number of high-quality, high-performance models on the GPU\nand CPU, dominating the Pareto frontier for this shared task.", "published": "2018-05-30 17:23:24", "link": "http://arxiv.org/abs/1805.12096v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Dialogue Act Classification for Spontaneous Arabic Speech and\n  Instant Messages at Utterance Level", "abstract": "The ability to model and automatically detect dialogue act is an important\nstep toward understanding spontaneous speech and Instant Messages. However, it\nhas been difficult to infer a dialogue act from a surface utterance because it\nhighly depends on the context of the utterance and speaker linguistic\nknowledge; especially in Arabic dialects. This paper proposes a statistical\ndialogue analysis model to recognize utterance's dialogue acts using a\nmulti-classes hierarchical structure. The model can automatically acquire\nprobabilistic discourse knowledge from a dialogue corpus were collected and\nannotated manually from multi-genre Egyptian call-centers. Extensive\nexperiments were conducted using Support Vector Machines classifier to evaluate\nthe system performance. The results attained in the term of average F-measure\nscores of 0.912; showed that the proposed approach has moderately improved\nF-measure by approximately 20%.", "published": "2018-05-30 22:27:15", "link": "http://arxiv.org/abs/1806.00522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Joking Machine : Humorous image captioning", "abstract": "What is an effective expression that draws laughter from human beings? In the\npresent paper, in order to consider this question from an academic standpoint,\nwe generate an image caption that draws a \"laugh\" by a computer. A system that\noutputs funny captions based on the image caption proposed in the computer\nvision field is constructed. Moreover, we also propose the Funny Score, which\nflexibly gives weights according to an evaluation database. The Funny Score\nmore effectively brings out \"laughter\" to optimize a model. In addition, we\nbuild a self-collected BoketeDB, which contains a theme (image) and funny\ncaption (text) posted on \"Bokete\", which is an image Ogiri website. In an\nexperiment, we use BoketeDB to verify the effectiveness of the proposed method\nby comparing the results obtained using the proposed method and those obtained\nusing MS COCO Pre-trained CNN+LSTM, which is the baseline and idiot created by\nhumans. We refer to the proposed method, which uses the BoketeDB pre-trained\nmodel, as the Neural Joking Machine (NJM).", "published": "2018-05-30 08:20:55", "link": "http://arxiv.org/abs/1805.11850v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Using Inter-Sentence Diverse Beam Search to Reduce Redundancy in Visual\n  Storytelling", "abstract": "Visual storytelling includes two important parts: coherence between the story\nand images as well as the story structure. For image to text neural network\nmodels, similar images in the sequence would provide close information for\nstory generator to obtain almost identical sentence. However, repeatedly\nnarrating same objects or events will undermine a good story structure. In this\npaper, we proposed an inter-sentence diverse beam search to generate a more\nexpressive story. Comparing to some recent models of visual storytelling task,\nwhich generate story without considering the generated sentence of the previous\npicture, our proposed method can avoid generating identical sentence even given\na sequence of similar pictures.", "published": "2018-05-30 08:59:44", "link": "http://arxiv.org/abs/1805.11867v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Amnestic Forgery: an Ontology of Conceptual Metaphors", "abstract": "This paper presents Amnestic Forgery, an ontology for metaphor semantics,\nbased on MetaNet, which is inspired by the theory of Conceptual Metaphor.\nAmnestic Forgery reuses and extends the Framester schema, as an ideal ontology\ndesign framework to deal with both semiotic and referential aspects of frames,\nroles, mappings, and eventually blending. The description of the resource is\nsupplied by a discussion of its applications, with examples taken from metaphor\ngeneration, and the referential problems of metaphoric mappings. Both schema\nand data are available from the Framester SPARQL endpoint.", "published": "2018-05-30 17:56:32", "link": "http://arxiv.org/abs/1805.12115v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Web-scale system for scientific knowledge exploration", "abstract": "To enable efficient exploration of Web-scale scientific knowledge, it is\nnecessary to organize scientific publications into a hierarchical concept\nstructure. In this work, we present a large-scale system to (1) identify\nhundreds of thousands of scientific concepts, (2) tag these identified concepts\nto hundreds of millions of scientific publications by leveraging both text and\ngraph structure, and (3) build a six-level concept hierarchy with a\nsubsumption-based model. The system builds the most comprehensive cross-domain\nscientific concept ontology published to date, with more than 200 thousand\nconcepts and over one million relationships.", "published": "2018-05-30 20:28:36", "link": "http://arxiv.org/abs/1805.12216v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Visual Referring Expression Recognition: What Do Systems Actually Learn?", "abstract": "We present an empirical analysis of the state-of-the-art systems for\nreferring expression recognition -- the task of identifying the object in an\nimage referred to by a natural language expression -- with the goal of gaining\ninsight into how these systems reason about language and vision. Surprisingly,\nwe find strong evidence that even sophisticated and linguistically-motivated\nmodels for this task may ignore the linguistic structure, instead relying on\nshallow correlations introduced by unintended biases in the data selection and\nannotation process. For example, we show that a system trained and tested on\nthe input image $\\textit{without the input referring expression}$ can achieve a\nprecision of 71.2% in top-2 predictions. Furthermore, a system that predicts\nonly the object category given the input can achieve a precision of 84.2% in\ntop-2 predictions. These surprisingly positive results for what should be\ndeficient prediction scenarios suggest that careful analysis of what our models\nare learning -- and further, how our data is constructed -- is critical as we\nseek to make substantive progress on grounded language tasks.", "published": "2018-05-30 06:03:21", "link": "http://arxiv.org/abs/1805.11818v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.NE"], "primary_category": "cs.CL"}
{"title": "What the Vec? Towards Probabilistically Grounded Embeddings", "abstract": "Word2Vec (W2V) and GloVe are popular, fast and efficient word embedding\nalgorithms. Their embeddings are widely used and perform well on a variety of\nnatural language processing tasks. Moreover, W2V has recently been adopted in\nthe field of graph embedding, where it underpins several leading algorithms.\nHowever, despite their ubiquity and relatively simple model architecture, a\ntheoretical understanding of what the embedding parameters of W2V and GloVe\nlearn and why that is useful in downstream tasks has been lacking. We show that\ndifferent interactions between PMI vectors reflect semantic word relationships,\nsuch as similarity and paraphrasing, that are encoded in low dimensional word\nembeddings under a suitable projection, theoretically explaining why embeddings\nof W2V and GloVe work. As a consequence, we also reveal an interesting\nmathematical interconnection between the considered semantic relationships\nthemselves.", "published": "2018-05-30 18:19:38", "link": "http://arxiv.org/abs/1805.12164v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multi-turn Dialogue Response Generation in an Adversarial Learning\n  Framework", "abstract": "We propose an adversarial learning approach for generating multi-turn\ndialogue responses. Our proposed framework, hredGAN, is based on conditional\ngenerative adversarial networks (GANs). The GAN's generator is a modified\nhierarchical recurrent encoder-decoder network (HRED) and the discriminator is\na word-level bidirectional RNN that shares context and word embeddings with the\ngenerator. During inference, noise samples conditioned on the dialogue history\nare used to perturb the generator's latent space to generate several possible\nresponses. The final response is the one ranked best by the discriminator. The\nhredGAN shows improved performance over existing methods: (1) it generalizes\nbetter than networks trained using only the log-likelihood criterion, and (2)\nit generates longer, more informative and more diverse responses with high\nutterance and topic relevance even with limited training data. This improvement\nis demonstrated on the Movie triples and Ubuntu dialogue datasets using both\nautomatic and human evaluations.", "published": "2018-05-30 00:05:53", "link": "http://arxiv.org/abs/1805.11752v5", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Acoustic Scene Analysis Using Partially Connected Microphones Based on\n  Graph Cepstrum", "abstract": "In this paper, we propose an effective and robust method for acoustic scene\nanalysis based on spatial information extracted from partially synchronized\nand/or closely located distributed microphones. In the proposed method, to\nextract spatial information from distributed microphones while taking into\naccount whether any pairs of microphones are synchronized and/or closely\nlocated, we derive a new cepstrum feature utilizing a graph-based basis\ntransformation. Specifically, in the proposed graph-based cepstrum, the\nlogarithm of the amplitude in a multichannel observation is converted to a\nfeature vector by an inverse graph Fourier transform, which can consider\nwhether any pair of microphones is connected. Our experimental results indicate\nthat the proposed graph-based cepstrum effectively extracts spatial information\nwith consideration of the microphone connections. Moreover, the results show\nthat the proposed method more robustly classifies acoustic scenes than\nconventional spatial features when the observed sounds have a large\nsynchronization mismatch between partially synchronized microphone groups.", "published": "2018-05-30 02:48:20", "link": "http://arxiv.org/abs/1805.11782v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ADAGIO: Interactive Experimentation with Adversarial Attack and Defense\n  for Audio", "abstract": "Adversarial machine learning research has recently demonstrated the\nfeasibility to confuse automatic speech recognition (ASR) models by introducing\nacoustically imperceptible perturbations to audio samples. To help researchers\nand practitioners gain better understanding of the impact of such attacks, and\nto provide them with tools to help them more easily evaluate and craft strong\ndefenses for their models, we present ADAGIO, the first tool designed to allow\ninteractive experimentation with adversarial attacks and defenses on an ASR\nmodel in real time, both visually and aurally. ADAGIO incorporates AMR and MP3\naudio compression techniques as defenses, which users can interactively apply\nto attacked audio samples. We show that these techniques, which are based on\npsychoacoustic principles, effectively eliminate targeted attacks, reducing the\nattack success rate from 92.5% to 0%. We will demonstrate ADAGIO and invite the\naudience to try it on the Mozilla Common Voice dataset.", "published": "2018-05-30 08:24:52", "link": "http://arxiv.org/abs/1805.11852v1", "categories": ["cs.LG", "cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
