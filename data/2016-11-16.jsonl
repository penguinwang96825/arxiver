{"title": "How to do lexical quality estimation of a large OCRed historical Finnish\n  newspaper collection with scarce resources", "abstract": "The National Library of Finland has digitized the historical newspapers\npublished in Finland between 1771 and 1910. This collection contains\napproximately 1.95 million pages in Finnish and Swedish. Finnish part of the\ncollection consists of about 2.40 billion words. The National Library's Digital\nCollections are offered via the digi.kansalliskirjasto.fi web service, also\nknown as Digi. Part of the newspaper material (from 1771 to 1874) is also\navailable freely downloadable in The Language Bank of Finland provided by the\nFINCLARIN consortium. The collection can also be accessed through the Korp\nenvironment that has been developed by Spr{\\aa}kbanken at the University of\nGothenburg and extended by FINCLARIN team at the University of Helsinki to\nprovide concordances of text resources. A Cranfield style information retrieval\ntest collection has also been produced out of a small part of the Digi\nnewspaper material at the University of Tampere.\n  Quality of OCRed collections is an important topic in digital humanities, as\nit affects general usability and searchability of collections. There is no\nsingle available method to assess quality of large collections, but different\nmethods can be used to approximate quality. This paper discusses different\ncorpus analysis style methods to approximate overall lexical quality of the\nFinnish part of the Digi collection. Methods include usage of parallel samples\nand word error rates, usage of morphological analyzers, frequency analysis of\nwords and comparisons to comparable edited lexical data. Our aim in the quality\nanalysis is twofold: firstly to analyze the present state of the lexical data\nand secondly, to establish a set of assessment methods that build up a compact\nprocedure for quality assessment after e.g. new OCRing or post correction of\nthe material. In the discussion part of the paper we shall synthesize results\nof our different analyses.", "published": "2016-11-16 12:04:19", "link": "http://arxiv.org/abs/1611.05239v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Life of Lazarillo de Tormes and of His Machine Learning Adversities", "abstract": "Summit work of the Spanish Golden Age and forefather of the so-called\npicaresque novel, The Life of Lazarillo de Tormes and of His Fortunes and\nAdversities still remains an anonymous text. Although distinguished scholars\nhave tried to attribute it to different authors based on a variety of criteria,\na consensus has yet to be reached. The list of candidates is long and not all\nof them enjoy the same support within the scholarly community. Analyzing their\nworks from a data-driven perspective and applying machine learning techniques\nfor style and text fingerprinting, we shed light on the authorship of the\nLazarillo. As in a state-of-the-art survey, we discuss the methods used and how\nthey perform in our specific case. According to our methodology, the most\nlikely author seems to be Juan Arce de Ot\\'alora, closely followed by Alfonso\nde Vald\\'es. The method states that not certain attribution can be made with\nthe given corpus.", "published": "2016-11-16 16:55:42", "link": "http://arxiv.org/abs/1611.05360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Feature-Enriched Neural Model for Joint Chinese Word Segmentation and\n  Part-of-Speech Tagging", "abstract": "Recently, neural network models for natural language processing tasks have\nbeen increasingly focused on for their ability of alleviating the burden of\nmanual feature engineering. However, the previous neural models cannot extract\nthe complicated feature compositions as the traditional methods with discrete\nfeatures. In this work, we propose a feature-enriched neural model for joint\nChinese word segmentation and part-of-speech tagging task. Specifically, to\nsimulate the feature templates of traditional discrete feature based models, we\nuse different filters to model the complex compositional features with\nconvolutional and pooling layer, and then utilize long distance dependency\ninformation with recurrent layer. Experimental results on five different\ndatasets show the effectiveness of our proposed model.", "published": "2016-11-16 17:47:57", "link": "http://arxiv.org/abs/1611.05384v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Way out of the Odyssey: Analyzing and Combining Recent Insights for\n  LSTMs", "abstract": "LSTMs have become a basic building block for many deep NLP models. In recent\nyears, many improvements and variations have been proposed for deep sequence\nmodels in general, and LSTMs in particular. We propose and analyze a series of\naugmentations and modifications to LSTM networks resulting in improved\nperformance for text classification datasets. We observe compounding\nimprovements on traditional LSTMs using Monte Carlo test-time model averaging,\naverage pooling, and residual connections, along with four other suggested\nmodifications. Our analysis provides a simple, reliable, and high quality\nbaseline model.", "published": "2016-11-16 00:53:01", "link": "http://arxiv.org/abs/1611.05104v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels\n  in Comic Book Narratives", "abstract": "Visual narrative is often a combination of explicit information and judicious\nomissions, relying on the viewer to supply missing details. In comics, most\nmovements in time and space are hidden in the \"gutters\" between panels. To\nfollow the story, readers logically connect panels together by inferring unseen\nactions through a process called \"closure\". While computers can now describe\nwhat is explicitly depicted in natural images, in this paper we examine whether\nthey can understand the closure-driven narratives conveyed by stylized artwork\nand dialogue in comic book panels. We construct a dataset, COMICS, that\nconsists of over 1.2 million panels (120 GB) paired with automatic textbox\ntranscriptions. An in-depth analysis of COMICS demonstrates that neither text\nnor image alone can tell a comic book story, so a computer must understand both\nmodalities to keep up with the plot. We introduce three cloze-style tasks that\nask models to predict narrative and character-centric aspects of a panel given\nn preceding panels as context. Various deep neural architectures underperform\nhuman baselines on these tasks, suggesting that COMICS contains fundamental\nchallenges for both vision and language.", "published": "2016-11-16 02:16:09", "link": "http://arxiv.org/abs/1611.05118v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "PCT and Beyond: Towards a Computational Framework for `Intelligent'\n  Communicative Systems", "abstract": "Recent years have witnessed increasing interest in the potential benefits of\n`intelligent' autonomous machines such as robots. Honda's Asimo humanoid robot,\niRobot's Roomba robot vacuum cleaner and Google's driverless cars have fired\nthe imagination of the general public, and social media buzz with speculation\nabout a utopian world of helpful robot assistants or the coming robot\napocalypse! However, there is a long way to go before autonomous systems reach\nthe level of capabilities required for even the simplest of tasks involving\nhuman-robot interaction - especially if it involves communicative behaviour\nsuch as speech and language. Of course the field of Artificial Intelligence\n(AI) has made great strides in these areas, and has moved on from abstract\nhigh-level rule-based paradigms to embodied architectures whose operations are\ngrounded in real physical environments. What is still missing, however, is an\noverarching theory of intelligent communicative behaviour that informs\nsystem-level design decisions in order to provide a more coherent approach to\nsystem integration. This chapter introduces the beginnings of such a framework\ninspired by the principles of Perceptual Control Theory (PCT). In particular,\nit is observed that PCT has hitherto tended to view perceptual processes as a\nrelatively straightforward series of transformations from sensation to\nperception, and has overlooked the potential of powerful generative model-based\nsolutions that have emerged in practical fields such as visual or auditory\nscene analysis. Starting from first principles, a sequence of arguments is\npresented which not only shows how these ideas might be integrated into PCT,\nbut which also extend PCT towards a remarkably symmetric architecture for a\nneeds-driven communicative agent. It is concluded that, if behaviour is the\ncontrol of perception, then perception is the simulation of behaviour.", "published": "2016-11-16 17:32:10", "link": "http://arxiv.org/abs/1611.05379v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.RO"], "primary_category": "cs.AI"}
