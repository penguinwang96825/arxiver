{"title": "Machine Translation Model based on Non-parallel Corpus and\n  Semi-supervised Transductive Learning", "abstract": "Although the parallel corpus has an irreplaceable role in machine\ntranslation, its scale and coverage is still beyond the actual needs.\nNon-parallel corpus resources on the web have an inestimable potential value in\nmachine translation and other natural language processing tasks. This article\nproposes a semi-supervised transductive learning method for expanding the\ntraining corpus in statistical machine translation system by extracting\nparallel sentences from the non-parallel corpus. This method only requires a\nsmall amount of labeled corpus and a large unlabeled corpus to build a\nhigh-performance classifier, especially for when there is short of labeled\ncorpus. The experimental results show that by combining the non-parallel corpus\nalignment and the semi-supervised transductive learning method, we can more\neffectively use their respective strengths to improve the performance of\nmachine translation system.", "published": "2014-05-22 07:58:56", "link": "http://arxiv.org/abs/1405.5654v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mot\u00e0Mot project: conversion of a French-Khmer published dictionary for\n  building a multilingual lexical system", "abstract": "Economic issues related to the information processing techniques are very\nimportant. The development of such technologies is a major asset for developing\ncountries like Cambodia and Laos, and emerging ones like Vietnam, Malaysia and\nThailand. The MotAMot project aims to computerize an under-resourced language:\nKhmer, spoken mainly in Cambodia. The main goal of the project is the\ndevelopment of a multilingual lexical system targeted for Khmer. The\nmacrostructure is a pivot one with each word sense of each language linked to a\npivot axi. The microstructure comes from a simplification of the explanatory\nand combinatory dictionary. The lexical system has been initialized with data\ncoming mainly from the conversion of the French-Khmer bilingual dictionary of\nDenis Richer from Word to XML format. The French part was completed with\npronunciation and parts-of-speech coming from the FeM French-english-Malay\ndictionary. The Khmer headwords noted in IPA in the Richer dictionary were\nconverted to Khmer writing with OpenFST, a finite state transducer tool. The\nresulting resource is available online for lookup, editing, download and remote\nprogramming via a REST API on a Jibiki platform.", "published": "2014-05-22 08:57:54", "link": "http://arxiv.org/abs/1405.5674v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Computerization of African languages-French dictionaries", "abstract": "This paper relates work done during the DiLAF project. It consists in\nconverting 5 bilingual African language-French dictionaries originally in Word\nformat into XML following the LMF model. The languages processed are Bambara,\nHausa, Kanuri, Tamajaq and Songhai-zarma, still considered as under-resourced\nlanguages concerning Natural Language Processing tools. Once converted, the\ndictionaries are available online on the Jibiki platform for lookup and\nmodification. The DiLAF project is first presented. A description of each\ndictionary follows. Then, the conversion methodology from .doc format to XML\nfiles is presented. A specific point on the usage of Unicode follows. Then,\neach step of the conversion into XML and LMF is detailed. The last part\npresents the Jibiki lexical resources management platform used for the project.", "published": "2014-05-22 20:15:57", "link": "http://arxiv.org/abs/1405.5893v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
