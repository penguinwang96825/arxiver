{"title": "How would Stance Detection Techniques Evolve after the Launch of\n  ChatGPT?", "abstract": "Stance detection refers to the task of extracting the standpoint (Favor,\nAgainst or Neither) towards a target in given texts. Such research gains\nincreasing attention with the proliferation of social media contents. The\nconventional framework of handling stance detection is converting it into text\nclassification tasks. Deep learning models have already replaced rule-based\nmodels and traditional machine learning models in solving such problems.\nCurrent deep neural networks are facing two main challenges which are\ninsufficient labeled data and information in social media posts and the\nunexplainable nature of deep learning models. A new pre-trained language model\nchatGPT was launched on Nov 30, 2022. For the stance detection tasks, our\nexperiments show that ChatGPT can achieve SOTA or similar performance for\ncommonly used datasets including SemEval-2016 and P-Stance. At the same time,\nChatGPT can provide explanation for its own prediction, which is beyond the\ncapability of any existing model. The explanations for the cases it cannot\nprovide classification results are especially useful. ChatGPT has the potential\nto be the best AI model for stance detection tasks in NLP, or at least change\nthe research paradigm of this field. ChatGPT also opens up the possibility of\nbuilding explanatory AI for stance detection.", "published": "2022-12-30 05:03:15", "link": "http://arxiv.org/abs/2212.14548v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distant Reading of the German Coalition Deal: Recognizing Policy\n  Positions with BERT-based Text Classification", "abstract": "Automated text analysis has become a widely used tool in political science.\nIn this research, we use a BERT model trained on German party manifestos to\nidentify the individual parties' contribution to the coalition agreement of\n2021.", "published": "2022-12-30 12:20:39", "link": "http://arxiv.org/abs/2212.14648v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TA-DA: Topic-Aware Domain Adaptation for Scientific Keyphrase\n  Identification and Classification (Student Abstract)", "abstract": "Keyphrase identification and classification is a Natural Language Processing\nand Information Retrieval task that involves extracting relevant groups of\nwords from a given text related to the main topic. In this work, we focus on\nextracting keyphrases from scientific documents. We introduce TA-DA, a\nTopic-Aware Domain Adaptation framework for keyphrase extraction that\nintegrates Multi-Task Learning with Adversarial Training and Domain Adaptation.\nOur approach improves performance over baseline models by up to 5% in the exact\nmatch of the F1-score.", "published": "2022-12-30 15:07:27", "link": "http://arxiv.org/abs/2301.06902v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linear programming word problems formulation using EnsembleCRF NER\n  labeler and T5 text generator with data augmentations", "abstract": "We propose an ensemble approach to predict the labels in linear programming\nword problems. The entity identification and the meaning representation are two\ntypes of tasks to be solved in the NL4Opt competition. We propose the\nensembleCRF method to identify the named entities for the first task. We found\nthat single models didn't improve for the given task in our analysis. A set of\nprediction models predict the entities. The generated results are combined to\nform a consensus result in the ensembleCRF method. We present an ensemble text\ngenerator to produce the representation sentences for the second task. We\nthought of dividing the problem into multiple small tasks due to the overflow\nin the output. A single model generates different representations based on the\nprompt. All the generated text is combined to form an ensemble and produce a\nmathematical meaning of a linear programming problem.", "published": "2022-12-30 12:39:26", "link": "http://arxiv.org/abs/2212.14657v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Black-box language model explanation by context length probing", "abstract": "The increasingly widespread adoption of large language models has highlighted\nthe need for improving their explainability. We present context length probing,\na novel explanation technique for causal language models, based on tracking the\npredictions of a model as a function of the length of available context, and\nallowing to assign differential importance scores to different contexts. The\ntechnique is model-agnostic and does not rely on access to model internals\nbeyond computing token-level probabilities. We apply context length probing to\nlarge pre-trained language models and offer some initial analyses and insights,\nincluding the potential for studying long-range dependencies. The source code\nand an interactive demo of the method are available.", "published": "2022-12-30 16:24:10", "link": "http://arxiv.org/abs/2212.14815v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study on\n  Simplified Radiology Reports", "abstract": "The release of ChatGPT, a language model capable of generating text that\nappears human-like and authentic, has gained significant attention beyond the\nresearch community. We expect that the convincing performance of ChatGPT\nincentivizes users to apply it to a variety of downstream tasks, including\nprompting the model to simplify their own medical reports. To investigate this\nphenomenon, we conducted an exploratory case study. In a questionnaire, we\nasked 15 radiologists to assess the quality of radiology reports simplified by\nChatGPT. Most radiologists agreed that the simplified reports were factually\ncorrect, complete, and not potentially harmful to the patient. Nevertheless,\ninstances of incorrect statements, missed key medical findings, and potentially\nharmful passages were reported. While further studies are needed, the initial\ninsights of this study indicate a great potential in using large language\nmodels like ChatGPT to improve patient-centered care in radiology and other\nmedical domains.", "published": "2022-12-30 18:55:16", "link": "http://arxiv.org/abs/2212.14882v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Memory Augmented Lookup Dictionary based Language Modeling for Automatic\n  Speech Recognition", "abstract": "Recent studies have shown that using an external Language Model (LM) benefits\nthe end-to-end Automatic Speech Recognition (ASR). However, predicting tokens\nthat appear less frequently in the training set is still quite challenging. The\nlong-tail prediction problems have been widely studied in many applications,\nbut only been addressed by a few studies for ASR and LMs. In this paper, we\npropose a new memory augmented lookup dictionary based Transformer architecture\nfor LM. The newly introduced lookup dictionary incorporates rich contextual\ninformation in training set, which is vital to correctly predict long-tail\ntokens. With intensive experiments on Chinese and English data sets, our\nproposed method is proved to outperform the baseline Transformer LM by a great\nmargin on both word/character error rate and tail tokens error rate. This is\nachieved without impact on the decoding efficiency. Overall, we demonstrate the\neffectiveness of our proposed method in boosting the ASR decoding performance,\nespecially for long-tail tokens.", "published": "2022-12-30 22:26:57", "link": "http://arxiv.org/abs/2301.00066v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Inconsistencies in Masked Language Models", "abstract": "Learning to predict masked tokens in a sequence has been shown to be a\nhelpful pretraining objective for powerful language models such as PaLM2. After\ntraining, such masked language models (MLMs) can provide distributions of\ntokens in the masked positions in a sequence. However, this paper shows that\ndistributions corresponding to different masking patterns can demonstrate\nconsiderable inconsistencies, i.e., they cannot be derived from a coherent\njoint distribution when considered together.\n  This fundamental flaw in MLMs can lead to self-contradictory behaviors during\ninference. On various benchmark datasets including MMLU, MLMs can give\ndifferent predictions to the same input question. From BERT-base to UL2-20B, we\nshow that such inconsistencies exist ubiquitously in MLMs of diverse sizes and\nconfigurations. In light of our observations, we further propose an\ninference-time strategy for MLMs called Ensemble of Conditionals. It jointly\nconsiders a selected range of inconsistent conditionals directly produced by\nthe MLM for the final prediction, which often leads to considerable accuracy\nimprovement.", "published": "2022-12-30 22:53:25", "link": "http://arxiv.org/abs/2301.00068v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Active Learning for Neural Machine Translation", "abstract": "The machine translation mechanism translates texts automatically between\ndifferent natural languages, and Neural Machine Translation (NMT) has gained\nattention for its rational context analysis and fluent translation accuracy.\nHowever, processing low-resource languages that lack relevant training\nattributes like supervised data is a current challenge for Natural Language\nProcessing (NLP). We incorporated a technique known Active Learning with the\nNMT toolkit Joey NMT to reach sufficient accuracy and robust predictions of\nlow-resource language translation. With active learning, a semi-supervised\nmachine learning strategy, the training algorithm determines which unlabeled\ndata would be the most beneficial for obtaining labels using selected query\ntechniques. We implemented two model-driven acquisition functions for selecting\nthe samples to be validated. This work uses transformer-based NMT systems;\nbaseline model (BM), fully trained model (FTM) , active learning least\nconfidence based model (ALLCM), and active learning margin sampling based model\n(ALMSM) when translating English to Hindi. The Bilingual Evaluation Understudy\n(BLEU) metric has been used to evaluate system results. The BLEU scores of BM,\nFTM, ALLCM and ALMSM systems are 16.26, 22.56 , 24.54, and 24.20, respectively.\nThe findings in this paper demonstrate that active learning techniques helps\nthe model to converge early and improve the overall quality of the translation\nsystem.", "published": "2022-12-30 17:04:01", "link": "http://arxiv.org/abs/2301.00688v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-modal deep learning system for depression and anxiety detection", "abstract": "Traditional screening practices for anxiety and depression pose an impediment\nto monitoring and treating these conditions effectively. However, recent\nadvances in NLP and speech modelling allow textual, acoustic, and hand-crafted\nlanguage-based features to jointly form the basis of future mental health\nscreening and condition detection. Speech is a rich and readily available\nsource of insight into an individual's cognitive state and by leveraging\ndifferent aspects of speech, we can develop new digital biomarkers for\ndepression and anxiety. To this end, we propose a multi-modal system for the\nscreening of depression and anxiety from self-administered speech tasks. The\nproposed model integrates deep-learned features from audio and text, as well as\nhand-crafted features that are informed by clinically-validated domain\nknowledge. We find that augmenting hand-crafted features with deep-learned\nfeatures improves our overall classification F1 score comparing to a baseline\nof hand-crafted features alone from 0.58 to 0.63 for depression and from 0.54\nto 0.57 for anxiety. The findings of our work suggest that speech-based\nbiomarkers for depression and anxiety hold significant promise in the future of\ndigital health.", "published": "2022-12-30 00:02:58", "link": "http://arxiv.org/abs/2212.14490v1", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "HiTeA: Hierarchical Temporal-Aware Video-Language Pre-training", "abstract": "Video-language pre-training has advanced the performance of various\ndownstream video-language tasks. However, most previous methods directly\ninherit or adapt typical image-language pre-training paradigms to\nvideo-language pre-training, thus not fully exploiting the unique\ncharacteristic of video, i.e., temporal. In this paper, we propose a\nHierarchical Temporal-Aware video-language pre-training framework, HiTeA, with\ntwo novel pre-training tasks for modeling cross-modal alignment between moments\nand texts as well as the temporal relations of video-text pairs. Specifically,\nwe propose a cross-modal moment exploration task to explore moments in videos,\nwhich results in detailed video moment representation. Besides, the inherent\ntemporal relations are captured by aligning video-text pairs as a whole in\ndifferent time resolutions with multi-modal temporal relation exploration task.\nFurthermore, we introduce the shuffling test to evaluate the temporal reliance\nof datasets and video-language pre-training models. We achieve state-of-the-art\nresults on 15 well-established video-language understanding and generation\ntasks, especially on temporal-oriented datasets (e.g., SSv2-Template and\nSSv2-Label) with 8.6% and 11.1% improvement respectively. HiTeA also\ndemonstrates strong generalization ability when directly transferred to\ndownstream tasks in a zero-shot manner. Models and demo will be available on\nModelScope.", "published": "2022-12-30 04:27:01", "link": "http://arxiv.org/abs/2212.14546v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "MAUVE Scores for Generative Models: Theory and Practice", "abstract": "Generative artificial intelligence has made significant strides, producing\ntext indistinguishable from human prose and remarkably photorealistic images.\nAutomatically measuring how close the generated data distribution is to the\ntarget distribution is central to diagnosing existing models and developing\nbetter ones. We present MAUVE, a family of comparison measures between pairs of\ndistributions such as those encountered in the generative modeling of text or\nimages. These scores are statistical summaries of divergence frontiers\ncapturing two types of errors in generative modeling. We explore three\napproaches to statistically estimate these scores: vector quantization,\nnon-parametric estimation, and classifier-based estimation. We provide\nstatistical bounds for the vector quantization approach.\n  Empirically, we find that the proposed scores paired with a range of\n$f$-divergences and statistical estimation methods can quantify the gaps\nbetween the distributions of human-written text and those of modern neural\nlanguage models by correlating with human judgments and identifying known\nproperties of the generated texts. We demonstrate in the vision domain that\nMAUVE can identify known properties of generated images on par with or better\nthan existing metrics. In conclusion, we present practical recommendations for\nusing MAUVE effectively with language and image modalities.", "published": "2022-12-30 07:37:40", "link": "http://arxiv.org/abs/2212.14578v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Targeted Phishing Campaigns using Large Scale Language Models", "abstract": "In this research, we aim to explore the potential of natural language models\n(NLMs) such as GPT-3 and GPT-2 to generate effective phishing emails. Phishing\nemails are fraudulent messages that aim to trick individuals into revealing\nsensitive information or taking actions that benefit the attackers. We propose\na framework for evaluating the performance of NLMs in generating these types of\nemails based on various criteria, including the quality of the generated text,\nthe ability to bypass spam filters, and the success rate of tricking\nindividuals. Our evaluations show that NLMs are capable of generating phishing\nemails that are difficult to detect and that have a high success rate in\ntricking individuals, but their effectiveness varies based on the specific NLM\nand training data used. Our research indicates that NLMs could have a\nsignificant impact on the prevalence of phishing attacks and emphasizes the\nneed for further study on the ethical and security implications of using NLMs\nfor malicious purposes.", "published": "2022-12-30 03:18:05", "link": "http://arxiv.org/abs/2301.00665v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to\n  Speech", "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) are emerging in\ntext-to-speech (TTS) synthesis because of their strong capability of generating\nhigh-fidelity samples. However, their iterative refinement process in\nhigh-dimensional data space results in slow inference speed, which restricts\ntheir application in real-time systems. Previous works have explored speeding\nup by minimizing the number of inference steps but at the cost of sample\nquality. In this work, to improve the inference speed for DDPM-based TTS model\nwhile achieving high sample quality, we propose ResGrad, a lightweight\ndiffusion model which learns to refine the output spectrogram of an existing\nTTS model (e.g., FastSpeech 2) by predicting the residual between the model\noutput and the corresponding ground-truth speech. ResGrad has several\nadvantages: 1) Compare with other acceleration methods for DDPM which need to\nsynthesize speech from scratch, ResGrad reduces the complexity of task by\nchanging the generation target from ground-truth mel-spectrogram to the\nresidual, resulting into a more lightweight model and thus a smaller real-time\nfactor. 2) ResGrad is employed in the inference process of the existing TTS\nmodel in a plug-and-play way, without re-training this model. We verify ResGrad\non the single-speaker dataset LJSpeech and two more challenging datasets with\nmultiple speakers (LibriTTS) and high sampling rate (VCTK). Experimental\nresults show that in comparison with other speed-up methods of DDPMs: 1)\nResGrad achieves better sample quality with the same inference speed measured\nby real-time factor; 2) with similar speech quality, ResGrad synthesizes speech\nfaster than baseline methods by more than 10 times. Audio samples are available\nat https://resgrad1.github.io/.", "published": "2022-12-30 02:31:35", "link": "http://arxiv.org/abs/2212.14518v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Defense Against Adversarial Attacks on Audio DeepFake Detection", "abstract": "Audio DeepFakes (DF) are artificially generated utterances created using deep\nlearning, with the primary aim of fooling the listeners in a highly convincing\nmanner. Their quality is sufficient to pose a severe threat in terms of\nsecurity and privacy, including the reliability of news or defamation. Multiple\nneural network-based methods to detect generated speech have been proposed to\nprevent the threats. In this work, we cover the topic of adversarial attacks,\nwhich decrease the performance of detectors by adding superficial (difficult to\nspot by a human) changes to input data. Our contribution contains evaluating\nthe robustness of 3 detection architectures against adversarial attacks in two\nscenarios (white-box and using transferability) and enhancing it later by using\nadversarial training performed by our novel adaptive training. Moreover, one of\nthe investigated architectures is RawNet3, which, to the best of our knowledge,\nwe adapted for the first time to DeepFake detection.", "published": "2022-12-30 08:41:06", "link": "http://arxiv.org/abs/2212.14597v2", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Blind Restoration of Real-World Audio by 1D Operational GANs", "abstract": "Objective: Despite numerous studies proposed for audio restoration in the\nliterature, most of them focus on an isolated restoration problem such as\ndenoising or dereverberation, ignoring other artifacts. Moreover, assuming a\nnoisy or reverberant environment with limited number of fixed\nsignal-to-distortion ratio (SDR) levels is a common practice. However,\nreal-world audio is often corrupted by a blend of artifacts such as\nreverberation, sensor noise, and background audio mixture with varying types,\nseverities, and duration. In this study, we propose a novel approach for blind\nrestoration of real-world audio signals by Operational Generative Adversarial\nNetworks (Op-GANs) with temporal and spectral objective metrics to enhance the\nquality of restored audio signal regardless of the type and severity of each\nartifact corrupting it. Methods: 1D Operational-GANs are used with generative\nneuron model optimized for blind restoration of any corrupted audio signal.\nResults: The proposed approach has been evaluated extensively over the\nbenchmark TIMIT-RAR (speech) and GTZAN-RAR (non-speech) datasets corrupted with\na random blend of artifacts each with a random severity to mimic real-world\naudio signals. Average SDR improvements of over 7.2 dB and 4.9 dB are achieved,\nrespectively, which are substantial when compared with the baseline methods.\nSignificance: This is a pioneer study in blind audio restoration with the\nunique capability of direct (time-domain) restoration of real-world audio\nwhilst achieving an unprecedented level of performance for a wide SDR range and\nartifact types. Conclusion: 1D Op-GANs can achieve robust and computationally\neffective real-world audio restoration with significantly improved performance.\nThe source codes and the generated real-world audio datasets are shared\npublicly with the research community in a dedicated GitHub repository1.", "published": "2022-12-30 10:11:57", "link": "http://arxiv.org/abs/2212.14618v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
