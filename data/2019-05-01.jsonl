{"title": "Nested Variational Autoencoder for Topic Modeling on Microtexts with\n  Word Vectors", "abstract": "Most of the information on the Internet is represented in the form of\nmicrotexts, which are short text snippets such as news headlines or tweets.\nThese sources of information are abundant, and mining these data could uncover\nmeaningful insights. Topic modeling is one of the popular methods to extract\nknowledge from a collection of documents; however, conventional topic models\nsuch as latent Dirichlet allocation (LDA) are unable to perform well on short\ndocuments, mostly due to the scarcity of word co-occurrence statistics embedded\nin the data. The objective of our research is to create a topic model that can\nachieve great performances on microtexts while requiring a small runtime for\nscalability to large datasets. To solve the lack of information of microtexts,\nwe allow our method to take advantage of word embeddings for additional\nknowledge of relationships between words. For speed and scalability, we apply\nautoencoding variational Bayes, an algorithm that can perform efficient\nblack-box inference in probabilistic models. The result of our work is a novel\ntopic model called the nested variational autoencoder, which is a distribution\nthat takes into account word vectors and is parameterized by a neural network\narchitecture. For optimization, the model is trained to approximate the\nposterior distribution of the original LDA model. Experiments show the\nimprovements of our model on microtexts as well as its runtime advantage.", "published": "2019-05-01 06:03:56", "link": "http://arxiv.org/abs/1905.00195v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A system for the 2019 Sentiment, Emotion and Cognitive State Task of\n  DARPAs LORELEI project", "abstract": "During the course of a Humanitarian Assistance-Disaster Relief (HADR) crisis,\nthat can happen anywhere in the world, real-time information is often posted\nonline by the people in need of help which, in turn, can be used by different\nstakeholders involved with management of the crisis. Automated processing of\nsuch posts can considerably improve the effectiveness of such efforts; for\nexample, understanding the aggregated emotion from affected populations in\nspecific areas may help inform decision-makers on how to best allocate\nresources for an effective disaster response. However, these efforts may be\nseverely limited by the availability of resources for the local language. The\nongoing DARPA project Low Resource Languages for Emergent Incidents (LORELEI)\naims to further language processing technologies for low resource languages in\nthe context of such a humanitarian crisis. In this work, we describe our\nsubmission for the 2019 Sentiment, Emotion and Cognitive state (SEC) pilot task\nof the LORELEI project. We describe a collection of sentiment analysis systems\nincluded in our submission along with the features extracted. Our fielded\nsystems obtained the best results in both English and Spanish language\nevaluations of the SEC pilot task.", "published": "2019-05-01 19:55:46", "link": "http://arxiv.org/abs/1905.00472v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Declarative Question Answering over Knowledge Bases containing Natural\n  Language Text with Answer Set Programming", "abstract": "While in recent years machine learning (ML) based approaches have been the\npopular approach in developing end-to-end question answering systems, such\nsystems often struggle when additional knowledge is needed to correctly answer\nthe questions. Proposed alternatives involve translating the question and the\nnatural language text to a logical representation and then use logical\nreasoning. However, this alternative falters when the size of the text gets\nbigger. To address this we propose an approach that does logical reasoning over\npremises written in natural language text. The proposed method uses recent\nfeatures of Answer Set Programming (ASP) to call external NLP modules (which\nmay be based on ML) which perform simple textual entailment. To test our\napproach we develop a corpus based on the life cycle questions and showed that\nOur system achieves up to $18\\%$ performance gain when compared to standard MCQ\nsolvers.", "published": "2019-05-01 06:29:02", "link": "http://arxiv.org/abs/1905.00198v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Context-Dependent Semantic Parsing over Temporally Structured Data", "abstract": "We describe a new semantic parsing setting that allows users to query the\nsystem using both natural language questions and actions within a graphical\nuser interface. Multiple time series belonging to an entity of interest are\nstored in a database and the user interacts with the system to obtain a better\nunderstanding of the entity's state and behavior, entailing sequences of\nactions and questions whose answers may depend on previous factual or\nnavigational interactions. We design an LSTM-based encoder-decoder architecture\nthat models context dependency through copying mechanisms and multiple levels\nof attention over inputs and previous outputs. When trained to predict tokens\nusing supervised learning, the proposed architecture substantially outperforms\nstandard sequence generation baselines. Training the architecture using policy\ngradient leads to further improvements in performance, reaching a\nsequence-level accuracy of 88.7% on artificial data and 74.8% on real data.", "published": "2019-05-01 10:16:46", "link": "http://arxiv.org/abs/1905.00245v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ASER: A Large-scale Eventuality Knowledge Graph", "abstract": "Understanding human's language requires complex world knowledge. However,\nexisting large-scale knowledge graphs mainly focus on knowledge about entities\nwhile ignoring knowledge about activities, states, or events, which are used to\ndescribe how entities or things act in the real world. To fill this gap, we\ndevelop ASER (activities, states, events, and their relations), a large-scale\neventuality knowledge graph extracted from more than 11-billion-token\nunstructured textual data. ASER contains 15 relation types belonging to five\ncategories, 194-million unique eventualities, and 64-million unique edges among\nthem. Both intrinsic and extrinsic evaluations demonstrate the quality and\neffectiveness of ASER.", "published": "2019-05-01 11:32:13", "link": "http://arxiv.org/abs/1905.00270v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Time-series Insights into the Process of Passing or Failing Online\n  University Courses using Neural-Induced Interpretable Student States", "abstract": "This paper addresses a key challenge in Educational Data Mining, namely to\nmodel student behavioral trajectories in order to provide a means for\nidentifying students most at-risk, with the goal of providing supportive\ninterventions. While many forms of data including clickstream data or data from\nsensors have been used extensively in time series models for such purposes, in\nthis paper we explore the use of textual data, which is sometimes available in\nthe records of students at large, online universities. We propose a time series\nmodel that constructs an evolving student state representation using both\nclickstream data and a signal extracted from the textual notes recorded by\nhuman mentors assigned to each student. We explore how the addition of this\ntextual data improves both the predictive power of student states for the\npurpose of identifying students at risk for course failure as well as for\nproviding interpretable insights about student course engagement processes.", "published": "2019-05-01 16:04:12", "link": "http://arxiv.org/abs/1905.00422v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Semi-automatic System for Title Construction", "abstract": "In this paper, we propose a semi-automatic system for title construction from\nscientific abstracts. The system extracts and recommends impactful words from\nthe text, which the author can creatively use to construct an appropriate title\nfor the manuscript. The work is based on the hypothesis that keywords are good\ncandidates for title construction. We extract important words from the document\nby inducing a supervised keyword extraction model. The model is trained on\nnovel features extracted from graph-of-text representation of the document. We\nempirically show that these graph-based features are capable of discriminating\nkeywords from non-keywords. We further establish empirically that the proposed\napproach can be applied to any text irrespective of the training domain and\ncorpus. We evaluate the proposed system by computing the overlap between\nextracted keywords and the list of title-words for documents, and we observe a\nmacro-averaged precision of 82%.", "published": "2019-05-01 19:49:41", "link": "http://arxiv.org/abs/1905.00470v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Disease Identification From Unstructured User Input", "abstract": "A method to identify probable diseases from the unstructured textual input\n(eg, health forum posts) by incorporating a lexicographic and semantic feature\nbased two-phase text classification module and a symptom-disease\ncorrelation-based similarity measurement module. One notable aspect of my\napproach was to develop a competent algorithm to extract all inherent features\nfrom the data source to make a better decision.", "published": "2019-05-01 05:10:48", "link": "http://arxiv.org/abs/1905.01987v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Computer Science and Metaphysics: A Cross-Fertilization", "abstract": "Computational philosophy is the use of mechanized computational techniques to\nunearth philosophical insights that are either difficult or impossible to find\nusing traditional philosophical methods. Computational metaphysics is\ncomputational philosophy with a focus on metaphysics. In this paper, we (a)\ndevelop results in modal metaphysics whose discovery was computer assisted, and\n(b) conclude that these results work not only to the obvious benefit of\nphilosophy but also, less obviously, to the benefit of computer science, since\nthe new computational techniques that led to these results may be more broadly\napplicable within computer science. The paper includes a description of our\nbackground methodology and how it evolved, and a discussion of our new results.", "published": "2019-05-01 16:51:32", "link": "http://arxiv.org/abs/1905.00787v4", "categories": ["cs.LO", "cs.AI", "cs.CL", "math.LO", "03Axx, 03B15, 03B45, 03B60, 03B80, 68T15, 68T27, 68T30", "F.4.0; F.4.1; I.2.3; I.2.4; J.5; I.1.3"], "primary_category": "cs.LO"}
{"title": "AI-Powered Text Generation for Harmonious Human-Machine Interaction:\n  Current State and Future Directions", "abstract": "In the last two decades, the landscape of text generation has undergone\ntremendous changes and is being reshaped by the success of deep learning. New\ntechnologies for text generation ranging from template-based methods to neural\nnetwork-based methods emerged. Meanwhile, the research objectives have also\nchanged from generating smooth and coherent sentences to infusing personalized\ntraits to enrich the diversification of newly generated content. With the rapid\ndevelopment of text generation solutions, one comprehensive survey is urgent to\nsummarize the achievements and track the state of the arts. In this survey\npaper, we present the general systematical framework, illustrate the widely\nutilized models and summarize the classic applications of text generation.", "published": "2019-05-01 23:26:38", "link": "http://arxiv.org/abs/1905.01984v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A Style Transfer Approach to Source Separation", "abstract": "Training neural networks for source separation involves presenting a mixture\nrecording at the input of the network and updating network parameters in order\nto produce an output that resembles the clean source. Consequently, supervised\nsource separation depends on the availability of paired mixture-clean training\nexamples. In this paper, we interpret source separation as a style transfer\nproblem. We present a variational auto-encoder network that exploits the\ncommonality across the domain of mixtures and the domain of clean sounds and\nlearns a shared latent representation across the two domains. Using these\ncycle-consistent variational auto-encoders, we learn a mapping from the mixture\ndomain to the domain of clean sounds and perform source separation without\nexplicitly supervising with paired training examples.", "published": "2019-05-01 01:09:24", "link": "http://arxiv.org/abs/1905.00151v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Polyphonic Sound Event Detection and Localization using a Two-Stage\n  Strategy", "abstract": "Sound event detection (SED) and localization refer to recognizing sound\nevents and estimating their spatial and temporal locations. Using neural\nnetworks has become the prevailing method for SED. In the area of sound\nlocalization, which is usually performed by estimating the direction of arrival\n(DOA), learning-based methods have recently been developed. In this paper, it\nis experimentally shown that the trained SED model is able to contribute to the\ndirection of arrival estimation (DOAE). However, joint training of SED and DOAE\ndegrades the performance of both. Based on these results, a two-stage\npolyphonic sound event detection and localization method is proposed. The\nmethod learns SED first, after which the learned feature layers are transferred\nfor DOAE. It then uses the SED ground truth as a mask to train DOAE. The\nproposed method is evaluated on the DCASE 2019 Task 3 dataset, which contains\ndifferent overlapping sound events in different environments. Experimental\nresults show that the proposed method is able to improve the performance of\nboth SED and DOAE, and also performs significantly better than the baseline\nmethod.", "published": "2019-05-01 11:27:28", "link": "http://arxiv.org/abs/1905.00268v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Developing a large scale population screening tool for the assessment of\n  Parkinson's disease using telephone-quality voice", "abstract": "Recent studies have demonstrated that analysis of laboratory-quality voice\nrecordings can be used to accurately differentiate people diagnosed with\nParkinson's disease (PD) from healthy controls (HC). These findings could help\nfacilitate the development of remote screening and monitoring tools for PD. In\nthis study, we analyzed 2759 telephone-quality voice recordings from 1483 PD\nand 15321 recordings from 8300 HC participants. To account for variations in\nphonetic backgrounds, we acquired data from seven countries. We developed a\nstatistical framework for analyzing voice, whereby we computed 307 dysphonia\nmeasures that quantify different properties of voice impairment, such as,\nbreathiness, roughness, monopitch, hoarse voice quality, and exaggerated vocal\ntremor. We used feature selection algorithms to identify robust parsimonious\nfeature subsets, which were used in combination with a Random Forests (RF)\nclassifier to accurately distinguish PD from HC. The best 10-fold\ncross-validation performance was obtained using Gram-Schmidt Orthogonalization\n(GSO) and RF, leading to mean sensitivity of 64.90% (standard deviation, SD\n2.90%) and mean specificity of 67.96% (SD 2.90%). This large-scale study is a\nstep forward towards assessing the development of a reliable, cost-effective\nand practical clinical decision support tool for screening the population at\nlarge for PD using telephone-quality voice.", "published": "2019-05-01 16:55:15", "link": "http://arxiv.org/abs/1905.00377v1", "categories": ["stat.AP", "cs.SD", "eess.AS"], "primary_category": "stat.AP"}
{"title": "A Feature Learning Siamese Model for Intelligent Control of the Dynamic\n  Range Compressor", "abstract": "In this paper, a siamese DNN model is proposed to learn the characteristics\nof the audio dynamic range compressor (DRC). This facilitates an intelligent\ncontrol system that uses audio examples to configure the DRC, a widely used\nnon-linear audio signal conditioning technique in the areas of music\nproduction, speech communication and broadcasting. Several alternative siamese\nDNN architectures are proposed to learn feature embeddings that can\ncharacterise subtle effects due to dynamic range compression. These models are\ncompared with each other as well as handcrafted features proposed in previous\nwork. The evaluation of the relations between the hyperparameters of DNN and\nDRC parameters are also provided. The best model is able to produce a universal\nfeature embedding that is capable of predicting multiple DRC parameters\nsimultaneously, which is a significant improvement from our previous research.\nThe feature embedding shows better performance than handcrafted audio features\nwhen predicting DRC parameters for both mono-instrument audio loops and\npolyphonic music pieces.", "published": "2019-05-01 11:28:54", "link": "http://arxiv.org/abs/1905.01022v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
