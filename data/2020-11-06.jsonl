{"title": "What's New? Summarizing Contributions in Scientific Literature", "abstract": "With thousands of academic articles shared on a daily basis, it has become\nincreasingly difficult to keep up with the latest scientific findings. To\novercome this problem, we introduce a new task of disentangled paper\nsummarization, which seeks to generate separate summaries for the paper\ncontributions and the context of the work, making it easier to identify the key\nfindings shared in articles. For this purpose, we extend the S2ORC corpus of\nacademic articles, which spans a diverse set of domains ranging from economics\nto psychology, by adding disentangled \"contribution\" and \"context\" reference\nlabels. Together with the dataset, we introduce and analyze three baseline\napproaches: 1) a unified model controlled by input code prefixes, 2) a model\nwith separate generation heads specialized in generating the disentangled\noutputs, and 3) a training strategy that guides the model using additional\nsupervision coming from inbound and outbound citations. We also propose a\ncomprehensive automatic evaluation protocol which reports the relevance,\nnovelty, and disentanglement of generated outputs. Through a human study\ninvolving expert annotators, we show that in 79%, of cases our new task is\nconsidered more helpful than traditional scientific paper summarization.", "published": "2020-11-06 02:23:01", "link": "http://arxiv.org/abs/2011.03161v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unleashing the Power of Neural Discourse Parsers -- A Context and\n  Structure Aware Approach Using Large Scale Pretraining", "abstract": "RST-based discourse parsing is an important NLP task with numerous downstream\napplications, such as summarization, machine translation and opinion mining. In\nthis paper, we demonstrate a simple, yet highly accurate discourse parser,\nincorporating recent contextual language models. Our parser establishes the new\nstate-of-the-art (SOTA) performance for predicting structure and nuclearity on\ntwo key RST datasets, RST-DT and Instr-DT. We further demonstrate that\npretraining our parser on the recently available large-scale \"silver-standard\"\ndiscourse treebank MEGA-DT provides even larger performance benefits,\nsuggesting a novel and promising research direction in the field of discourse\nanalysis.", "published": "2020-11-06 06:11:26", "link": "http://arxiv.org/abs/2011.03203v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OP-IMS @ DIACR-Ita: Back to the Roots: SGNS+OP+CD still rocks Semantic\n  Change Detection", "abstract": "We present the results of our participation in the DIACR-Ita shared task on\nlexical semantic change detection for Italian. We exploit one of the earliest\nand most influential semantic change detection models based on Skip-Gram with\nNegative Sampling, Orthogonal Procrustes alignment and Cosine Distance and\nobtain the winning submission of the shared task with near to perfect accuracy\n.94. Our results once more indicate that, within the present task setup in\nlexical semantic change detection, the traditional type-based approaches yield\nexcellent performance.", "published": "2020-11-06 10:02:12", "link": "http://arxiv.org/abs/2011.03258v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alquist 2.0: Alexa Prize Socialbot Based on Sub-Dialogue Models", "abstract": "This paper presents the second version of the dialogue system named Alquist\ncompeting in Amazon Alexa Prize 2018. We introduce a system leveraging\nontology-based topic structure called topic nodes. Each of the nodes consists\nof several sub-dialogues, and each sub-dialogue has its own LSTM-based model\nfor dialogue management. The sub-dialogues can be triggered according to the\ntopic hierarchy or a user intent which allows the bot to create a unique\nexperience during each session.", "published": "2020-11-06 10:06:10", "link": "http://arxiv.org/abs/2011.03259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alquist 3.0: Alexa Prize Bot Using Conversational Knowledge Graph", "abstract": "The third version of the open-domain dialogue system Alquist developed within\nthe Alexa Prize 2020 competition is designed to conduct coherent and engaging\nconversations on popular topics. The main novel contribution is the\nintroduction of a system leveraging an innovative approach based on a\nconversational knowledge graph and adjacency pairs. The conversational\nknowledge graph allows the system to utilize knowledge expressed during the\ndialogue in consequent turns and across conversations. Dialogue adjacency pairs\ndivide the conversation into small conversational structures, which can be\ncombined and allow the system to react to a wide range of user inputs flexibly.\n  We discuss and describe Alquist's pipeline, data acquisition and processing,\ndialogue manager, NLG, knowledge aggregation, and a hierarchy of adjacency\npairs. We present the experimental results of the individual parts of the\nsystem.", "published": "2020-11-06 10:10:02", "link": "http://arxiv.org/abs/2011.03261v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-Supervised Low-Resource Style Transfer of Indonesian Informal to\n  Formal Language with Iterative Forward-Translation", "abstract": "In its daily use, the Indonesian language is riddled with informality, that\nis, deviations from the standard in terms of vocabulary, spelling, and word\norder. On the other hand, current available Indonesian NLP models are typically\ndeveloped with the standard Indonesian in mind. In this work, we address a\nstyle-transfer from informal to formal Indonesian as a low-resource machine\ntranslation problem. We build a new dataset of parallel sentences of informal\nIndonesian and its formal counterpart. We benchmark several strategies to\nperform style transfer from informal to formal Indonesian. We also explore\naugmenting the training set with artificial forward-translated data. Since we\nare dealing with an extremely low-resource setting, we find that a phrase-based\nmachine translation approach outperforms the Transformer-based approach.\nAlternatively, a pre-trained GPT-2 fined-tuned to this task performed equally\nwell but costs more computational resource. Our findings show a promising step\ntowards leveraging machine translation models for style transfer. Our code and\ndata are available in https://github.com/haryoa/stif-indonesia", "published": "2020-11-06 11:19:47", "link": "http://arxiv.org/abs/2011.03286v2", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "The ApposCorpus: A new multilingual, multi-domain dataset for factual\n  appositive generation", "abstract": "News articles, image captions, product reviews and many other texts mention\npeople and organizations whose name recognition could vary for different\naudiences. In such cases, background information about the named entities could\nbe provided in the form of an appositive noun phrase, either written by a human\nor generated automatically. We expand on the previous work in appositive\ngeneration with a new, more realistic, end-to-end definition of the task,\ninstantiated by a dataset that spans four languages (English, Spanish, German\nand Polish), two entity types (person and organization) and two domains\n(Wikipedia and News). We carry out an extensive analysis of the data and the\ntask, pointing to the various modeling challenges it poses. The results we\nobtain with standard language generation methods show that the task is indeed\nnon-trivial, and leaves plenty of room for improvement.", "published": "2020-11-06 11:23:09", "link": "http://arxiv.org/abs/2011.03287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Machine Reading Comprehension with Single-choice Decision and\n  Transfer Learning", "abstract": "Multi-choice Machine Reading Comprehension (MMRC) aims to select the correct\nanswer from a set of options based on a given passage and question. Due to task\nspecific of MMRC, it is non-trivial to transfer knowledge from other MRC tasks\nsuch as SQuAD, Dream. In this paper, we simply reconstruct multi-choice to\nsingle-choice by training a binary classification to distinguish whether a\ncertain answer is correct. Then select the option with the highest confidence\nscore. We construct our model upon ALBERT-xxlarge model and estimate it on the\nRACE dataset. During training, We adopt AutoML strategy to tune better\nparameters. Experimental results show that the single-choice is better than\nmulti-choice. In addition, by transferring knowledge from other kinds of MRC\ntasks, our model achieves a new state-of-the-art results in both single and\nensemble settings.", "published": "2020-11-06 11:33:29", "link": "http://arxiv.org/abs/2011.03292v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Pure Character-Based Neural Machine Translation: The Case\n  of Translating Finnish into English", "abstract": "Recent work has shown that deeper character-based neural machine translation\n(NMT) models can outperform subword-based models. However, it is still unclear\nwhat makes deeper character-based models successful. In this paper, we conduct\nan investigation into pure character-based models in the case of translating\nFinnish into English, including exploring the ability to learn word senses and\nmorphological inflections and the attention mechanism. We demonstrate that\nword-level information is distributed over the entire character sequence rather\nthan over a single character, and characters at different positions play\ndifferent roles in learning linguistic knowledge. In addition, character-based\nmodels need more layers to encode word senses which explains why only deeper\nmodels outperform subword-based models. The attention distribution pattern\nshows that separators attract a lot of attention and we explore a sparse\nword-level attention to enforce character hidden states to capture the full\nword-level information. Experimental results show that the word-level attention\nwith a single head results in 1.2 BLEU points drop.", "published": "2020-11-06 16:47:43", "link": "http://arxiv.org/abs/2011.03469v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Practical and Ethical Considerations in the Effective use of Emotion and\n  Sentiment Lexicons", "abstract": "Lexicons of word-emotion associations are widely used in research and\nreal-world applications. As part of my research, I have created several such\nlexicons (e.g., the NRC Emotion Lexicon). This paper outlines some practical\nand ethical considerations involved in the effective use of these lexical\nresources.", "published": "2020-11-06 17:57:18", "link": "http://arxiv.org/abs/2011.03492v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hostility Detection Dataset in Hindi", "abstract": "In this paper, we present a novel hostility detection dataset in Hindi\nlanguage. We collect and manually annotate ~8200 online posts. The annotated\ndataset covers four hostility dimensions: fake news, hate speech, offensive,\nand defamation posts, along with a non-hostile label. The hostile posts are\nalso considered for multi-label tags due to a significant overlap among the\nhostile classes. We release this dataset as part of the CONSTRAINT-2021 shared\ntask on hostile post detection.", "published": "2020-11-06 20:33:12", "link": "http://arxiv.org/abs/2011.03588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Dataset Recycling to Multi-Property Extraction and Beyond", "abstract": "This paper investigates various Transformer architectures on the WikiReading\nInformation Extraction and Machine Reading Comprehension dataset. The proposed\ndual-source model outperforms the current state-of-the-art by a large margin.\nNext, we introduce WikiReading Recycled-a newly developed public dataset and\nthe task of multiple property extraction. It uses the same data as WikiReading\nbut does not inherit its predecessor's identified disadvantages. In addition,\nwe provide a human-annotated test set with diagnostic subsets for a detailed\nanalysis of model performance.", "published": "2020-11-06 08:22:12", "link": "http://arxiv.org/abs/2011.03228v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Corpora Compared: The Case of the Swedish Gigaword & Wikipedia Corpora", "abstract": "In this work, we show that the difference in performance of embeddings from\ndifferently sourced data for a given language can be due to other factors\nbesides data size. Natural language processing (NLP) tasks usually perform\nbetter with embeddings from bigger corpora. However, broadness of covered\ndomain and noise can play important roles. We evaluate embeddings based on two\nSwedish corpora: The Gigaword and Wikipedia, in analogy (intrinsic) tests and\ndiscover that the embeddings from the Wikipedia corpus generally outperform\nthose from the Gigaword corpus, which is a bigger corpus. Downstream tests will\nbe required to have a definite evaluation.", "published": "2020-11-06 11:00:47", "link": "http://arxiv.org/abs/2011.03281v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Unsupervised method for OCR Post-Correction and Spelling\n  Normalisation for Finnish", "abstract": "Historical corpora are known to contain errors introduced by OCR (optical\ncharacter recognition) methods used in the digitization process, often said to\nbe degrading the performance of NLP systems. Correcting these errors manually\nis a time-consuming process and a great part of the automatic approaches have\nbeen relying on rules or supervised machine learning. We build on previous work\non fully automatic unsupervised extraction of parallel data to train a\ncharacter-based sequence-to-sequence NMT (neural machine translation) model to\nconduct OCR error correction designed for English, and adapt it to Finnish by\nproposing solutions that take the rich morphology of the language into account.\nOur new method shows increased performance while remaining fully unsupervised,\nwith the added benefit of spelling normalisation. The source code and models\nare available on GitHub and Zenodo.", "published": "2020-11-06 18:19:48", "link": "http://arxiv.org/abs/2011.03502v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fighting an Infodemic: COVID-19 Fake News Dataset", "abstract": "Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news\nand rumors are rampant on social media. Believing in rumors can cause\nsignificant harm. This is further exacerbated at the time of a pandemic. To\ntackle this, we curate and release a manually annotated dataset of 10,700\nsocial media posts and articles of real and fake news on COVID-19. We benchmark\nthe annotated dataset with four machine learning baselines - Decision Tree,\nLogistic Regression, Gradient Boost, and Support Vector Machine (SVM). We\nobtain the best performance of 93.46% F1-score with SVM. The data and code is\navailable at: https://github.com/parthpatwa/covid19-fake-news-dectection", "published": "2020-11-06 13:09:37", "link": "http://arxiv.org/abs/2011.03327v4", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Answer Span Correction in Machine Reading Comprehension", "abstract": "Answer validation in machine reading comprehension (MRC) consists of\nverifying an extracted answer against an input context and question pair.\nPrevious work has looked at re-assessing the \"answerability\" of the question\ngiven the extracted answer. Here we address a different problem: the tendency\nof existing MRC systems to produce partially correct answers when presented\nwith answerable questions. We explore the nature of such errors and propose a\npost-processing correction method that yields statistically significant\nperformance improvements over state-of-the-art MRC systems in both monolingual\nand multilingual evaluation.", "published": "2020-11-06 15:31:07", "link": "http://arxiv.org/abs/2011.03435v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Wave-Tacotron: Spectrogram-free end-to-end text-to-speech synthesis", "abstract": "We describe a sequence-to-sequence neural network which directly generates\nspeech waveforms from text inputs. The architecture extends the Tacotron model\nby incorporating a normalizing flow into the autoregressive decoder loop.\nOutput waveforms are modeled as a sequence of non-overlapping fixed-length\nblocks, each one containing hundreds of samples. The interdependencies of\nwaveform samples within each block are modeled using the normalizing flow,\nenabling parallel training and synthesis. Longer-term dependencies are handled\nautoregressively by conditioning each flow on preceding blocks.This model can\nbe optimized directly with maximum likelihood, with-out using intermediate,\nhand-designed features nor additional loss terms. Contemporary state-of-the-art\ntext-to-speech (TTS) systems use a cascade of separately learned models: one\n(such as Tacotron) which generates intermediate features (such as spectrograms)\nfrom text, followed by a vocoder (such as WaveRNN) which generates waveform\nsamples from the intermediate features. The proposed system, in contrast, does\nnot use a fixed intermediate representation, and learns all parameters\nend-to-end. Experiments show that the proposed model generates speech with\nquality approaching a state-of-the-art neural TTS system, with significantly\nimproved generation speed.", "published": "2020-11-06 19:30:07", "link": "http://arxiv.org/abs/2011.03568v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Misalignment Recognition in Acoustic Sensor Networks using a\n  Semi-supervised Source Estimation Method and Markov Random Fields", "abstract": "In this paper, we consider the problem of acoustic source localization by\nacoustic sensor networks (ASNs) using a promising, learning-based technique\nthat adapts to the acoustic environment. In particular, we look at the scenario\nwhen a node in the ASN is displaced from its position during training. As the\nmismatch between the ASN used for learning the localization model and the one\nafter a node displacement leads to erroneous position estimates, a displacement\nhas to be detected and the displaced nodes need to be identified. We propose a\nmethod that considers the disparity in position estimates made by\nleave-one-node-out (LONO) sub-networks and uses a Markov random field (MRF)\nframework to infer the probability of each LONO position estimate being\naligned, misaligned or unreliable while accounting for the noise inherent to\nthe estimator. This probabilistic approach is advantageous over naive detection\nmethods, as it outputs a normalized value that encapsulates conditional\ninformation provided by each LONO sub-network on whether the reading is in\nmisalignment with the overall network. Experimental results confirm that the\nperformance of the proposed method is consistent in identifying compromised\nnodes in various acoustic conditions.", "published": "2020-11-06 15:29:01", "link": "http://arxiv.org/abs/2011.03432v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust ENF Estimation Based on Harmonic Enhancement and Maximum Weight\n  Clique", "abstract": "We present a framework for robust electric network frequency (ENF) extraction\nfrom real-world audio recordings, featuring multi-tone ENF harmonic enhancement\nand graph-based optimal harmonic selection. Specifically, We first extend the\nrecently developed single-tone ENF signal enhancement method to the multi-tone\nscenario and propose a harmonic robust filtering algorithm (HRFA). It can\nrespectively enhance each harmonic component without cross-component\ninterference, thus further alleviating the effects of unwanted noise and audio\ncontent on the much weaker ENF signal. In addition, considering the fact that\nsome harmonic components could be severely corrupted even after enhancement,\ndisturbing rather than facilitating ENF estimation, we propose a graph-based\nharmonic selection algorithm (GHSA), which finds the optimal combination of\nharmonic components for more accurate ENF estimation. Noticeably, the harmonic\nselection problem is equivalently formulated as a maximum weight clique (MWC)\nproblem in graph theory, and the Bron-Kerbosch algorithm (BKA) is adopted in\nthe GHSA. With the enhanced and optimally selected harmonic components, both\nthe existing maximum likelihood estimator (MLE) and weighted MLE (WMLE) are\nincorporated to yield the final ENF estimation results. The proposed framework\nis extensively evaluated using both synthetic signals and our ENF-WHU dataset\nconsisting of $130$ real-world audio recordings, demonstrating substantially\nimproved capability of extracting the ENF from realistically noisy observations\nover the existing single- and multi-tone competitors. This work further\nimproves the applicability of the ENF as a forensic criterion in real-world\nsituations.", "published": "2020-11-06 15:10:08", "link": "http://arxiv.org/abs/2011.03414v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Self-Supervised Learning from Contrastive Mixtures for Personalized\n  Speech Enhancement", "abstract": "This work explores how self-supervised learning can be universally used to\ndiscover speaker-specific features towards enabling personalized speech\nenhancement models. We specifically address the few-shot learning scenario\nwhere access to cleaning recordings of a test-time speaker is limited to a few\nseconds, but noisy recordings of the speaker are abundant. We develop a simple\ncontrastive learning procedure which treats the abundant noisy data as\nmakeshift training targets through pairwise noise injection: the model is\npretrained to maximize agreement between pairs of differently deformed\nidentical utterances and to minimize agreement between pairs of similarly\ndeformed nonidentical utterances. Our experiments compare the proposed\npretraining approach with two baseline alternatives: speaker-agnostic\nfully-supervised pretraining, and speaker-specific self-supervised pretraining\nwithout contrastive loss terms. Of all three approaches, the proposed method\nusing contrastive mixtures is found to be most robust to model compression\n(using 85% fewer parameters) and reduced clean speech (requiring only 3\nseconds).", "published": "2020-11-06 15:21:00", "link": "http://arxiv.org/abs/2011.03426v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Large-scale multilingual audio visual dubbing", "abstract": "We describe a system for large-scale audiovisual translation and dubbing,\nwhich translates videos from one language to another. The source language's\nspeech content is transcribed to text, translated, and automatically\nsynthesized into target language speech using the original speaker's voice. The\nvisual content is translated by synthesizing lip movements for the speaker to\nmatch the translated audio, creating a seamless audiovisual experience in the\ntarget language. The audio and visual translation subsystems each contain a\nlarge-scale generic synthesis model trained on thousands of hours of data in\nthe corresponding domain. These generic models are fine-tuned to a specific\nspeaker before translation, either using an auxiliary corpus of data from the\ntarget speaker, or using the video to be translated itself as the input to the\nfine-tuning process. This report gives an architectural overview of the full\nsystem, as well as an in-depth discussion of the video dubbing component. The\nrole of the audio and text components in relation to the full system is\noutlined, but their design is not discussed in detail. Translated and dubbed\ndemo videos generated using our system can be viewed at\nhttps://www.youtube.com/playlist?list=PLSi232j2ZA6_1Exhof5vndzyfbxAhhEs5", "published": "2020-11-06 18:58:15", "link": "http://arxiv.org/abs/2011.03530v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "GANterpretations", "abstract": "Since the introduction of Generative Adversarial Networks (GANs) [Goodfellow\net al., 2014] there has been a regular stream of both technical advances (e.g.,\nArjovsky et al. [2017]) and creative uses of these generative models (e.g.,\n[Karras et al., 2019, Zhu et al., 2017, Jin et al., 2017]). In this work we\npropose an approach for using the power of GANs to automatically generate\nvideos to accompany audio recordings by aligning to spectral properties of the\nrecording. This allows musicians to explore new forms of multi-modal creative\nexpression, where musical performance can induce an AI-generated musical video\nthat is guided by said performance, as well as a medium for creating a visual\nnarrative to follow a storyline (similar to what was proposed by Frosst and\nKereliuk [2019]).", "published": "2020-11-06 19:08:40", "link": "http://arxiv.org/abs/2011.05158v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Prosody Modelling with Cross-Utterance BERT Embeddings for\n  End-to-end Speech Synthesis", "abstract": "Despite prosody is related to the linguistic information up to the discourse\nstructure, most text-to-speech (TTS) systems only take into account that within\neach sentence, which makes it challenging when converting a paragraph of texts\ninto natural and expressive speech. In this paper, we propose to use the text\nembeddings of the neighboring sentences to improve the prosody generation for\neach utterance of a paragraph in an end-to-end fashion without using any\nexplicit prosody features. More specifically, cross-utterance (CU) context\nvectors, which are produced by an additional CU encoder based on the sentence\nembeddings extracted by a pre-trained BERT model, are used to augment the input\nof the Tacotron2 decoder. Two types of BERT embeddings are investigated, which\nleads to the use of different CU encoder structures. Experimental results on a\nMandarin audiobook dataset and the LJ-Speech English audiobook dataset\ndemonstrate the use of CU information can improve the naturalness and\nexpressiveness of the synthesized speech. Subjective listening testing shows\nmost of the participants prefer the voice generated using the CU encoder over\nthat generated using standard Tacotron2. It is also found that the prosody can\nbe controlled indirectly by changing the neighbouring sentences.", "published": "2020-11-06 10:03:11", "link": "http://arxiv.org/abs/2011.05161v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
