{"title": "Bipol: A Novel Multi-Axes Bias Evaluation Metric with Explainability for\n  NLP", "abstract": "We introduce bipol, a new metric with explainability, for estimating social\nbias in text data. Harmful bias is prevalent in many online sources of data\nthat are used for training machine learning (ML) models. In a step to address\nthis challenge we create a novel metric that involves a two-step process:\ncorpus-level evaluation based on model classification and sentence-level\nevaluation based on (sensitive) term frequency (TF). After creating new models\nto detect bias along multiple axes using SotA architectures, we evaluate two\npopular NLP datasets (COPA and SQUAD). As additional contribution, we created a\nlarge dataset (with almost 2 million labelled samples) for training models in\nbias detection and make it publicly available. We also make public our codes.", "published": "2023-04-08 14:45:15", "link": "http://arxiv.org/abs/2304.04029v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Factify 2: A Multimodal Fake News and Satire News Dataset", "abstract": "The internet gives the world an open platform to express their views and\nshare their stories. While this is very valuable, it makes fake news one of our\nsociety's most pressing problems. Manual fact checking process is time\nconsuming, which makes it challenging to disprove misleading assertions before\nthey cause significant harm. This is he driving interest in automatic fact or\nclaim verification. Some of the existing datasets aim to support development of\nautomating fact-checking techniques, however, most of them are text based.\nMulti-modal fact verification has received relatively scant attention. In this\npaper, we provide a multi-modal fact-checking dataset called FACTIFY 2,\nimproving Factify 1 by using new data sources and adding satire articles.\nFactify 2 has 50,000 new data instances. Similar to FACTIFY 1.0, we have three\nbroad categories - support, no-evidence, and refute, with sub-categories based\non the entailment of visual and textual data. We also provide a BERT and Vison\nTransformer based baseline, which achieves 65% F1 score in the test set. The\nbaseline codes and the dataset will be made available at\nhttps://github.com/surya1701/Factify-2.0.", "published": "2023-04-08 03:14:19", "link": "http://arxiv.org/abs/2304.03897v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "The Short Text Matching Model Enhanced with Knowledge via Contrastive\n  Learning", "abstract": "In recent years, short Text Matching tasks have been widely applied in the\nfields ofadvertising search and recommendation. The difficulty lies in the lack\nof semantic information and word ambiguity caused by the short length of the\ntext. Previous works have introduced complement sentences or knowledge bases to\nprovide additional feature information. However, these methods have not fully\ninteracted between the original sentence and the complement sentence, and have\nnot considered the noise issue that may arise from the introduction of external\nknowledge bases. Therefore, this paper proposes a short Text Matching model\nthat combines contrastive learning and external knowledge. The model uses a\ngenerative model to generate corresponding complement sentences and uses the\ncontrastive learning method to guide the model to obtain more semantically\nmeaningful encoding of the original sentence. In addition, to avoid noise, we\nuse keywords as the main semantics of the original sentence to retrieve\ncorresponding knowledge words in the knowledge base, and construct a knowledge\ngraph. The graph encoding model is used to integrate the knowledge base\ninformation into the model. Our designed model achieves state-of-the-art\nperformance on two publicly available Chinese Text Matching datasets,\ndemonstrating the effectiveness of our model.", "published": "2023-04-08 03:24:05", "link": "http://arxiv.org/abs/2304.03898v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MphayaNER: Named Entity Recognition for Tshivenda", "abstract": "Named Entity Recognition (NER) plays a vital role in various Natural Language\nProcessing tasks such as information retrieval, text classification, and\nquestion answering. However, NER can be challenging, especially in low-resource\nlanguages with limited annotated datasets and tools. This paper adds to the\neffort of addressing these challenges by introducing MphayaNER, the first\nTshivenda NER corpus in the news domain. We establish NER baselines by\n\\textit{fine-tuning} state-of-the-art models on MphayaNER. The study also\nexplores zero-shot transfer between Tshivenda and other related Bantu\nlanguages, with chiShona and Kiswahili showing the best results. Augmenting\nMphayaNER with chiShona data was also found to improve model performance\nsignificantly. Both MphayaNER and the baseline models are made publicly\navailable.", "published": "2023-04-08 08:03:58", "link": "http://arxiv.org/abs/2304.03952v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WikiGoldSK: Annotated Dataset, Baselines and Few-Shot Learning\n  Experiments for Slovak Named Entity Recognition", "abstract": "Named Entity Recognition (NER) is a fundamental NLP tasks with a wide range\nof practical applications. The performance of state-of-the-art NER methods\ndepends on high quality manually anotated datasets which still do not exist for\nsome languages. In this work we aim to remedy this situation in Slovak by\nintroducing WikiGoldSK, the first sizable human labelled Slovak NER dataset. We\nbenchmark it by evaluating state-of-the-art multilingual Pretrained Language\nModels and comparing it to the existing silver-standard Slovak NER dataset. We\nalso conduct few-shot experiments and show that training on a sliver-standard\ndataset yields better results. To enable future work that can be based on\nSlovak NER, we release the dataset, code, as well as the trained models\npublicly under permissible licensing terms at\nhttps://github.com/NaiveNeuron/WikiGoldSK.", "published": "2023-04-08 14:37:52", "link": "http://arxiv.org/abs/2304.04026v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-class Categorization of Reasons behind Mental Disturbance in Long\n  Texts", "abstract": "Motivated with recent advances in inferring users' mental state in social\nmedia posts, we identify and formulate the problem of finding causal indicators\nbehind mental illness in self-reported text. In the past, we witness the\npresence of rule-based studies for causal explanation analysis on curated\nFacebook data. The investigation on transformer-based model for multi-class\ncausal categorization in Reddit posts point to a problem of using long-text\nwhich contains as many as 4000 words. Developing end-to-end transformer-based\nmodels subject to the limitation of maximum-length in a given instance. To\nhandle this problem, we use Longformer and deploy its encoding on\ntransformer-based classifier. The experimental results show that Longformer\nachieves new state-of-the-art results on M-CAMS, a publicly available dataset\nwith 62\\% F1-score. Cause-specific analysis and ablation study prove the\neffectiveness of Longformer. We believe our work facilitates causal analysis of\ndepression and suicide risk on social media data, and shows potential for\napplication on other mental health conditions.", "published": "2023-04-08 22:44:32", "link": "http://arxiv.org/abs/2304.04118v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "An Empirical Study and Improvement for Speech Emotion Recognition", "abstract": "Multimodal speech emotion recognition aims to detect speakers' emotions from\naudio and text. Prior works mainly focus on exploiting advanced networks to\nmodel and fuse different modality information to facilitate performance, while\nneglecting the effect of different fusion strategies on emotion recognition. In\nthis work, we consider a simple yet important problem: how to fuse audio and\ntext modality information is more helpful for this multimodal task. Further, we\npropose a multimodal emotion recognition model improved by perspective loss.\nEmpirical results show our method obtained new state-of-the-art results on the\nIEMOCAP dataset. The in-depth analysis explains why the improved model can\nachieve improvements and outperforms baselines.", "published": "2023-04-08 03:24:06", "link": "http://arxiv.org/abs/2304.03899v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Decoder-Only or Encoder-Decoder? Interpreting Language Model as a\n  Regularized Encoder-Decoder", "abstract": "The sequence-to-sequence (seq2seq) task aims at generating the target\nsequence based on the given input source sequence. Traditionally, most of the\nseq2seq task is resolved by the Encoder-Decoder framework which requires an\nencoder to encode the source sequence and a decoder to generate the target\ntext. Recently, a bunch of new approaches have emerged that apply decoder-only\nlanguage models directly to the seq2seq task. Despite the significant\nadvancements in applying language models to the seq2seq task, there is still a\nlack of thorough analysis on the effectiveness of the decoder-only language\nmodel architecture. This paper aims to address this gap by conducting a\ndetailed comparison between the encoder-decoder architecture and the\ndecoder-only language model framework through the analysis of a regularized\nencoder-decoder structure. This structure is designed to replicate all\nbehaviors in the classical decoder-only language model but has an encoder and a\ndecoder making it easier to be compared with the classical encoder-decoder\nstructure. Based on the analysis, we unveil the attention degeneration problem\nin the language model, namely, as the generation step number grows, less and\nless attention is focused on the source sequence. To give a quantitative\nunderstanding of this problem, we conduct a theoretical sensitivity analysis of\nthe attention output with respect to the source input. Grounded on our\nanalysis, we propose a novel partial attention language model to solve the\nattention degeneration problem. Experimental results on machine translation,\nsummarization, and data-to-text generation tasks support our analysis and\ndemonstrate the effectiveness of our proposed model.", "published": "2023-04-08 15:44:29", "link": "http://arxiv.org/abs/2304.04052v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "tmn at SemEval-2023 Task 9: Multilingual Tweet Intimacy Detection using\n  XLM-T, Google Translate, and Ensemble Learning", "abstract": "The paper describes a transformer-based system designed for SemEval-2023 Task\n9: Multilingual Tweet Intimacy Analysis. The purpose of the task was to predict\nthe intimacy of tweets in a range from 1 (not intimate at all) to 5 (very\nintimate). The official training set for the competition consisted of tweets in\nsix languages (English, Spanish, Italian, Portuguese, French, and Chinese). The\ntest set included the given six languages as well as external data with four\nlanguages not presented in the training set (Hindi, Arabic, Dutch, and Korean).\nWe presented a solution based on an ensemble of XLM-T, a multilingual RoBERTa\nmodel adapted to the Twitter domain. To improve the performance of unseen\nlanguages, each tweet was supplemented by its English translation. We explored\nthe effectiveness of translated data for the languages seen in fine-tuning\ncompared to unseen languages and estimated strategies for using translated data\nin transformer-based models. Our solution ranked 4th on the leaderboard while\nachieving an overall Pearson's r of 0.599 over the test set. The proposed\nsystem improves up to 0.088 Pearson's r over a score averaged across all 45\nsubmissions.", "published": "2023-04-08 15:50:16", "link": "http://arxiv.org/abs/2304.04054v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "68T50", "I.2.7; I.7.m; H.3.3"], "primary_category": "cs.CL"}
{"title": "Interpretable Multi Labeled Bengali Toxic Comments Classification using\n  Deep Learning", "abstract": "This paper presents a deep learning-based pipeline for categorizing Bengali\ntoxic comments, in which at first a binary classification model is used to\ndetermine whether a comment is toxic or not, and then a multi-label classifier\nis employed to determine which toxicity type the comment belongs to. For this\npurpose, we have prepared a manually labeled dataset consisting of 16,073\ninstances among which 8,488 are Toxic and any toxic comment may correspond to\none or more of the six toxic categories - vulgar, hate, religious, threat,\ntroll, and insult simultaneously. Long Short Term Memory (LSTM) with BERT\nEmbedding achieved 89.42% accuracy for the binary classification task while as\na multi-label classifier, a combination of Convolutional Neural Network and\nBi-directional Long Short Term Memory (CNN-BiLSTM) with attention mechanism\nachieved 78.92% accuracy and 0.86 as weighted F1-score. To explain the\npredictions and interpret the word feature importance during classification by\nthe proposed models, we utilized Local Interpretable Model-Agnostic\nExplanations (LIME) framework. We have made our dataset public and can be\naccessed at -\nhttps://github.com/deepu099cse/Multi-Labeled-Bengali-Toxic-Comments-Classification", "published": "2023-04-08 19:28:26", "link": "http://arxiv.org/abs/2304.04087v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Story Discovery from Continuous News Streams via Scalable\n  Thematic Embedding", "abstract": "Unsupervised discovery of stories with correlated news articles in real-time\nhelps people digest massive news streams without expensive human annotations. A\ncommon approach of the existing studies for unsupervised online story discovery\nis to represent news articles with symbolic- or graph-based embedding and\nincrementally cluster them into stories. Recent large language models are\nexpected to improve the embedding further, but a straightforward adoption of\nthe models by indiscriminately encoding all information in articles is\nineffective to deal with text-rich and evolving news streams. In this work, we\npropose a novel thematic embedding with an off-the-shelf pretrained sentence\nencoder to dynamically represent articles and stories by considering their\nshared temporal themes. To realize the idea for unsupervised online story\ndiscovery, a scalable framework USTORY is introduced with two main techniques,\ntheme- and time-aware dynamic embedding and novelty-aware adaptive clustering,\nfueled by lightweight story summaries. A thorough evaluation with real news\ndata sets demonstrates that USTORY achieves higher story discovery performances\nthan baselines while being robust and scalable to various streaming settings.", "published": "2023-04-08 20:41:15", "link": "http://arxiv.org/abs/2304.04099v3", "categories": ["cs.IR", "cs.CL", "cs.DB", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Comparing Code Explanations Created by Students and Large Language\n  Models", "abstract": "Reasoning about code and explaining its purpose are fundamental skills for\ncomputer scientists. There has been extensive research in the field of\ncomputing education on the relationship between a student's ability to explain\ncode and other skills such as writing and tracing code. In particular, the\nability to describe at a high-level of abstraction how code will behave over\nall possible inputs correlates strongly with code writing skills. However,\ndeveloping the expertise to comprehend and explain code accurately and\nsuccinctly is a challenge for many students. Existing pedagogical approaches\nthat scaffold the ability to explain code, such as producing exemplar code\nexplanations on demand, do not currently scale well to large classrooms. The\nrecent emergence of powerful large language models (LLMs) may offer a solution.\nIn this paper, we explore the potential of LLMs in generating explanations that\ncan serve as examples to scaffold students' ability to understand and explain\ncode. To evaluate LLM-created explanations, we compare them with explanations\ncreated by students in a large course ($n \\approx 1000$) with respect to\naccuracy, understandability and length. We find that LLM-created explanations,\nwhich can be produced automatically on demand, are rated as being significantly\neasier to understand and more accurate summaries of code than student-created\nexplanations. We discuss the significance of this finding, and suggest how such\nmodels can be incorporated into introductory programming education.", "published": "2023-04-08 06:52:54", "link": "http://arxiv.org/abs/2304.03938v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.SE"], "primary_category": "cs.CY"}
{"title": "Unsupervised Speech Representation Pooling Using Vector Quantization", "abstract": "With the advent of general-purpose speech representations from large-scale\nself-supervised models, applying a single model to multiple downstream tasks is\nbecoming a de-facto approach. However, the pooling problem remains; the length\nof speech representations is inherently variable. The naive average pooling is\noften used, even though it ignores the characteristics of speech, such as\ndifferently lengthed phonemes. Hence, we design a novel pooling method to\nsquash acoustically similar representations via vector quantization, which does\nnot require additional training, unlike attention-based pooling. Further, we\nevaluate various unsupervised pooling methods on various self-supervised\nmodels. We gather diverse methods scattered around speech and text to evaluate\non various tasks: keyword spotting, speaker identification, intent\nclassification, and emotion recognition. Finally, we quantitatively and\nqualitatively analyze our method, comparing it with supervised pooling methods.", "published": "2023-04-08 07:03:01", "link": "http://arxiv.org/abs/2304.03940v1", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
