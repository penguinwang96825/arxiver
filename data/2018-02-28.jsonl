{"title": "Collective Entity Disambiguation with Structured Gradient Tree Boosting", "abstract": "We present a gradient-tree-boosting-based structured learning model for\njointly disambiguating named entities in a document. Gradient tree boosting is\na widely used machine learning algorithm that underlies many top-performing\nnatural language processing systems. Surprisingly, most works limit the use of\ngradient tree boosting as a tool for regular classification or regression\nproblems, despite the structured nature of language. To the best of our\nknowledge, our work is the first one that employs the structured gradient tree\nboosting (SGTB) algorithm for collective entity disambiguation. By defining\nglobal features over previous disambiguation decisions and jointly modeling\nthem with local features, our system is able to produce globally optimized\nentity assignments for mentions in a document. Exact inference is prohibitively\nexpensive for our globally normalized model. To solve this problem, we propose\nBidirectional Beam Search with Gold path (BiBSG), an approximate inference\nalgorithm that is a variant of the standard beam search algorithm. BiBSG makes\nuse of global information from both past and future to perform better local\nsearch. Experiments on standard benchmark datasets show that SGTB significantly\nimproves upon published results. Specifically, SGTB outperforms the previous\nstate-of-the-art neural system by near 1\\% absolute accuracy on the popular\nAIDA-CoNLL dataset.", "published": "2018-02-28 02:01:30", "link": "http://arxiv.org/abs/1802.10229v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Medical Exam Question Answering with Large-scale Reading Comprehension", "abstract": "Reading and understanding text is one important component in computer aided\ndiagnosis in clinical medicine, also being a major research problem in the\nfield of NLP. In this work, we introduce a question-answering task called MedQA\nto study answering questions in clinical medicine using knowledge in a\nlarge-scale document collection. The aim of MedQA is to answer real-world\nquestions with large-scale reading comprehension. We propose our solution\nSeaReader--a modular end-to-end reading comprehension model based on LSTM\nnetworks and dual-path attention architecture. The novel dual-path attention\nmodels information flow from two perspectives and has the ability to\nsimultaneously read individual documents and integrate information across\nmultiple documents. In experiments our SeaReader achieved a large increase in\naccuracy on MedQA over competing models. Additionally, we develop a series of\nnovel techniques to demonstrate the interpretation of the question answering\nprocess in SeaReader.", "published": "2018-02-28 06:27:37", "link": "http://arxiv.org/abs/1802.10279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simultaneously Self-Attending to All Mentions for Full-Abstract\n  Biological Relation Extraction", "abstract": "Most work in relation extraction forms a prediction by looking at a short\nspan of text within a single sentence containing a single entity pair mention.\nThis approach often does not consider interactions across mentions, requires\nredundant computation for each mention pair, and ignores relationships\nexpressed across sentence boundaries. These problems are exacerbated by the\ndocument- (rather than sentence-) level annotation common in biological text.\nIn response, we propose a model which simultaneously predicts relationships\nbetween all mention pairs in a document. We form pairwise predictions over\nentire paper abstracts using an efficient self-attention encoder. All-pairs\nmention scores allow us to perform multi-instance learning by aggregating over\nmentions to form entity pair representations. We further adapt to settings\nwithout mention-level annotation by jointly training to predict named entities\nand adding a corpus of weakly labeled data. In experiments on two Biocreative\nbenchmark datasets, we achieve state of the art performance on the Biocreative\nV Chemical Disease Relation dataset for models without external KB resources.\nWe also introduce a new dataset an order of magnitude larger than existing\nhuman-annotated biological information extraction datasets and more accurate\nthan distantly supervised alternatives.", "published": "2018-02-28 18:17:40", "link": "http://arxiv.org/abs/1802.10569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Uncertainty in Neural Machine Translation", "abstract": "Machine translation is a popular test bed for research in neural\nsequence-to-sequence models but despite much recent research, there is still a\nlack of understanding of these models. Practitioners report performance\ndegradation with large beams, the under-estimation of rare words and a lack of\ndiversity in the final translations. Our study relates some of these issues to\nthe inherent uncertainty of the task, due to the existence of multiple valid\ntranslations for a single source sentence, and to the extrinsic uncertainty\ncaused by noisy training data. We propose tools and metrics to assess how\nuncertainty in the data is captured by the model distribution and how it\naffects search strategies that generate translations. Our results show that\nsearch works remarkably well but that models tend to spread too much\nprobability mass over the hypothesis space. Next, we propose tools to assess\nmodel calibration and show how to easily fix some shortcomings of current\nmodels. As part of this study, we release multiple human reference translations\nfor two popular benchmarks.", "published": "2018-02-28 19:33:24", "link": "http://arxiv.org/abs/1803.00047v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Sentiment Analysis in Arabic Using Word Representation", "abstract": "The complexities of Arabic language in morphology, orthography and dialects\nmakes sentiment analysis for Arabic more challenging. Also, text feature\nextraction from short messages like tweets, in order to gauge the sentiment,\nmakes this task even more difficult. In recent years, deep neural networks were\noften employed and showed very good results in sentiment classification and\nnatural language processing applications. Word embedding, or word distributing\napproach, is a current and powerful tool to capture together the closest words\nfrom a contextual text. In this paper, we describe how we construct Word2Vec\nmodels from a large Arabic corpus obtained from ten newspapers in different\nArab countries. By applying different machine learning algorithms and\nconvolutional neural networks with different text feature selections, we report\nimproved accuracy of sentiment classification (91%-95%) on our publicly\navailable Arabic language health sentiment dataset [1]", "published": "2018-02-28 22:46:19", "link": "http://arxiv.org/abs/1803.00124v2", "categories": ["cs.CL", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Distance entropy cartography characterises centrality in complex\n  networks", "abstract": "We introduce distance entropy as a measure of homogeneity in the distribution\nof path lengths between a given node and its neighbours in a complex network.\nDistance entropy defines a new centrality measure whose properties are\ninvestigated for a variety of synthetic network models. By coupling distance\nentropy information with closeness centrality, we introduce a network\ncartography which allows one to reduce the degeneracy of ranking based on\ncloseness alone. We apply this methodology to the empirical multiplex lexical\nnetwork encoding the linguistic relationships known to English speaking\ntoddlers. We show that the distance entropy cartography better predicts how\nchildren learn words compared to closeness centrality. Our results highlight\nthe importance of distance entropy for gaining insights from distance patterns\nin complex networks.", "published": "2018-02-28 13:53:34", "link": "http://arxiv.org/abs/1802.10411v1", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "cs.CL", "cs.SI", "physics.data-an"], "primary_category": "physics.soc-ph"}
{"title": "Pop Music Highlighter: Marking the Emotion Keypoints", "abstract": "The goal of music highlight extraction is to get a short consecutive segment\nof a piece of music that provides an effective representation of the whole\npiece. In a previous work, we introduced an attention-based convolutional\nrecurrent neural network that uses music emotion classification as a surrogate\ntask for music highlight extraction, for Pop songs. The rationale behind that\napproach is that the highlight of a song is usually the most emotional part.\nThis paper extends our previous work in the following two aspects. First,\nmethodology-wise we experiment with a new architecture that does not need any\nrecurrent layers, making the training process faster. Moreover, we compare a\nlate-fusion variant and an early-fusion variant to study which one better\nexploits the attention mechanism. Second, we conduct and report an extensive\nset of experiments comparing the proposed attention-based methods against a\nheuristic energy-based method, a structural repetition-based method, and a few\nother simple feature-based methods for this task. Due to the lack of\npublic-domain labeled data for highlight extraction, following our previous\nwork we use the RWC POP 100-song data set to evaluate how the detected\nhighlights overlap with any chorus sections of the songs. The experiments\ndemonstrate the effectiveness of our methods over competing methods. For\nreproducibility, we open source the code and pre-trained model at\nhttps://github.com/remyhuang/pop-music-highlighter/.", "published": "2018-02-28 16:02:47", "link": "http://arxiv.org/abs/1802.10495v2", "categories": ["eess.AS", "cs.AI", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
