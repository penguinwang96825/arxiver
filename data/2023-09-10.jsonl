{"title": "Unsupervised Chunking with Hierarchical RNN", "abstract": "In Natural Language Processing (NLP), predicting linguistic structures, such\nas parsing and chunking, has mostly relied on manual annotations of syntactic\nstructures. This paper introduces an unsupervised approach to chunking, a\nsyntactic task that involves grouping words in a non-hierarchical manner. We\npresent a two-layer Hierarchical Recurrent Neural Network (HRNN) designed to\nmodel word-to-chunk and chunk-to-sentence compositions. Our approach involves a\ntwo-stage training process: pretraining with an unsupervised parser and\nfinetuning on downstream NLP tasks. Experiments on the CoNLL-2000 dataset\nreveal a notable improvement over existing unsupervised methods, enhancing\nphrase F1 score by up to 6 percentage points. Further, finetuning with\ndownstream tasks results in an additional performance improvement.\nInterestingly, we observe that the emergence of the chunking structure is\ntransient during the neural model's downstream-task training. This study\ncontributes to the advancement of unsupervised syntactic structure discovery\nand opens avenues for further research in linguistic theory.", "published": "2023-09-10 02:55:12", "link": "http://arxiv.org/abs/2309.04919v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's Hard in English RST Parsing? Predictive Models for Error Analysis", "abstract": "Despite recent advances in Natural Language Processing (NLP), hierarchical\ndiscourse parsing in the framework of Rhetorical Structure Theory remains\nchallenging, and our understanding of the reasons for this are as yet limited.\nIn this paper, we examine and model some of the factors associated with parsing\ndifficulties in previous work: the existence of implicit discourse relations,\nchallenges in identifying long-distance relations, out-of-vocabulary items, and\nmore. In order to assess the relative importance of these variables, we also\nrelease two annotated English test-sets with explicit correct and distracting\ndiscourse markers associated with gold standard RST relations. Our results show\nthat as in shallow discourse parsing, the explicit/implicit distinction plays a\nrole, but that long-distance dependencies are the main challenge, while lack of\nlexical overlap is less of a problem, at least for in-domain parsing. Our final\nmodel is able to predict where errors will occur with an accuracy of 76.3% for\nthe bottom-up parser and 76.6% for the top-down parser.", "published": "2023-09-10 06:10:03", "link": "http://arxiv.org/abs/2309.04940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt Learning With Knowledge Memorizing Prototypes For Generalized\n  Few-Shot Intent Detection", "abstract": "Generalized Few-Shot Intent Detection (GFSID) is challenging and realistic\nbecause it needs to categorize both seen and novel intents simultaneously.\nPrevious GFSID methods rely on the episodic learning paradigm, which makes it\nhard to extend to a generalized setup as they do not explicitly learn the\nclassification of seen categories and the knowledge of seen intents. To address\nthe dilemma, we propose to convert the GFSID task into the class incremental\nlearning paradigm. Specifically, we propose a two-stage learning framework,\nwhich sequentially learns the knowledge of different intents in various periods\nvia prompt learning. And then we exploit prototypes for categorizing both seen\nand novel intents. Furthermore, to achieve the transfer knowledge of intents in\ndifferent stages, for different scenarios we design two knowledge preservation\nmethods which close to realistic applications. Extensive experiments and\ndetailed analyses on two widely used datasets show that our framework based on\nthe class incremental learning paradigm achieves promising performance.", "published": "2023-09-10 09:16:38", "link": "http://arxiv.org/abs/2309.04971v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Meta Learning for Low-Resource Text Classification", "abstract": "Meta learning have achieved promising performance in low-resource text\nclassification which aims to identify target classes with knowledge transferred\nfrom source classes with sets of small tasks named episodes. However, due to\nthe limited training data in the meta-learning scenario and the inherent\nproperties of parameterized neural networks, poor generalization performance\nhas become a pressing problem that needs to be addressed. To deal with this\nissue, we propose a meta-learning based method called Retrieval-Augmented Meta\nLearning(RAML). It not only uses parameterization for inference but also\nretrieves non-parametric knowledge from an external corpus to make inferences,\nwhich greatly alleviates the problem of poor generalization performance caused\nby the lack of diverse training data in meta-learning. This method differs from\nprevious models that solely rely on parameters, as it explicitly emphasizes the\nimportance of non-parametric knowledge, aiming to strike a balance between\nparameterized neural networks and non-parametric knowledge. The model is\nrequired to determine which knowledge to access and utilize during inference.\nAdditionally, our multi-view passages fusion network module can effectively and\nefficiently integrate the retrieved information into low-resource\nclassification task. The extensive experiments demonstrate that RAML\nsignificantly outperforms current SOTA low-resource text classification models.", "published": "2023-09-10 10:05:03", "link": "http://arxiv.org/abs/2309.04979v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Word Bias in Zero-shot Prompt-based Classifiers", "abstract": "Prompt-based classifiers are an attractive approach for zero-shot\nclassification. However, the precise choice of the prompt template and label\nwords can largely influence performance, with semantically equivalent settings\noften showing notable performance difference. This discrepancy can be partly\nattributed to word biases, where the classifier may be biased towards classes.\nTo address this problem, it is possible to optimise classification thresholds\non a labelled data set, however, this mitigates some of the advantages of\nprompt-based classifiers. This paper instead approaches this problem by\nexamining the expected marginal probabilities of the classes. Here,\nprobabilities are reweighted to have a uniform prior over classes, in an\nunsupervised fashion. Further, we draw a theoretical connection between the\nclass priors and the language models' word prior, and offer the ability to set\na threshold in a zero-resource fashion. We show that matching class priors\ncorrelates strongly with the oracle upper bound performance and demonstrate\nlarge consistent performance gains for prompt settings over a range of NLP\ntasks.", "published": "2023-09-10 10:57:41", "link": "http://arxiv.org/abs/2309.04992v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chat2Brain: A Method for Mapping Open-Ended Semantic Queries to Brain\n  Activation Maps", "abstract": "Over decades, neuroscience has accumulated a wealth of research results in\nthe text modality that can be used to explore cognitive processes.\nMeta-analysis is a typical method that successfully establishes a link from\ntext queries to brain activation maps using these research results, but it\nstill relies on an ideal query environment. In practical applications, text\nqueries used for meta-analyses may encounter issues such as semantic redundancy\nand ambiguity, resulting in an inaccurate mapping to brain images. On the other\nhand, large language models (LLMs) like ChatGPT have shown great potential in\ntasks such as context understanding and reasoning, displaying a high degree of\nconsistency with human natural language. Hence, LLMs could improve the\nconnection between text modality and neuroscience, resolving existing\nchallenges of meta-analyses. In this study, we propose a method called\nChat2Brain that combines LLMs to basic text-2-image model, known as Text2Brain,\nto map open-ended semantic queries to brain activation maps in data-scarce and\ncomplex query environments. By utilizing the understanding and reasoning\ncapabilities of LLMs, the performance of the mapping model is optimized by\ntransferring text queries to semantic queries. We demonstrate that Chat2Brain\ncan synthesize anatomically plausible neural activation patterns for more\ncomplex tasks of text queries.", "published": "2023-09-10 13:06:45", "link": "http://arxiv.org/abs/2309.05021v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Effect of Alignment Objectives on Code-Switching Translation", "abstract": "One of the things that need to change when it comes to machine translation is\nthe models' ability to translate code-switching content, especially with the\nrise of social media and user-generated content. In this paper, we are\nproposing a way of training a single machine translation model that is able to\ntranslate monolingual sentences from one language to another, along with\ntranslating code-switched sentences to either language. This model can be\nconsidered a bilingual model in the human sense. For better use of parallel\ndata, we generated synthetic code-switched (CSW) data along with an alignment\nloss on the encoder to align representations across languages. Using the WMT14\nEnglish-French (En-Fr) dataset, the trained model strongly outperforms\nbidirectional baselines on code-switched translation while maintaining quality\nfor non-code-switched (monolingual) data.", "published": "2023-09-10 14:46:31", "link": "http://arxiv.org/abs/2309.05044v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-document Summarization: A Comparative Evaluation", "abstract": "This paper is aimed at evaluating state-of-the-art models for Multi-document\nSummarization (MDS) on different types of datasets in various domains and\ninvestigating the limitations of existing models to determine future research\ndirections. To address this gap, we conducted an extensive literature review to\nidentify state-of-the-art models and datasets. We analyzed the performance of\nPRIMERA and PEGASUS models on BigSurvey-MDS and MS$^2$ datasets, which posed\nunique challenges due to their varied domains. Our findings show that the\nGeneral-Purpose Pre-trained Model LED outperforms PRIMERA and PEGASUS on the\nMS$^2$ dataset. We used the ROUGE score as a performance metric to evaluate the\nidentified models on different datasets. Our study provides valuable insights\ninto the models' strengths and weaknesses, as well as their applicability in\ndifferent domains. This work serves as a reference for future MDS research and\ncontributes to the development of accurate and robust models which can be\nutilized on demanding datasets with academically and/or scientifically complex\ndata as well as generalized, relatively simple datasets.", "published": "2023-09-10 07:43:42", "link": "http://arxiv.org/abs/2309.04951v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RGAT: A Deeper Look into Syntactic Dependency Information for\n  Coreference Resolution", "abstract": "Although syntactic information is beneficial for many NLP tasks, combining it\nwith contextual information between words to solve the coreference resolution\nproblem needs to be further explored. In this paper, we propose an end-to-end\nparser that combines pre-trained BERT with a Syntactic Relation Graph Attention\nNetwork (RGAT) to take a deeper look into the role of syntactic dependency\ninformation for the coreference resolution task. In particular, the RGAT model\nis first proposed, then used to understand the syntactic dependency graph and\nlearn better task-specific syntactic embeddings. An integrated architecture\nincorporating BERT embeddings and syntactic embeddings is constructed to\ngenerate blending representations for the downstream task. Our experiments on a\npublic Gendered Ambiguous Pronouns (GAP) dataset show that with the supervision\nlearning of the syntactic dependency graph and without fine-tuning the entire\nBERT, we increased the F1-score of the previous best model (RGCN-with-BERT)\nfrom 80.3% to 82.5%, compared to the F1-score by single BERT embeddings from\n78.5% to 82.5%. Experimental results on another public dataset - OntoNotes 5.0\ndemonstrate that the performance of the model is also improved by incorporating\nsyntactic dependency information learned from RGAT.", "published": "2023-09-10 09:46:38", "link": "http://arxiv.org/abs/2309.04977v1", "categories": ["cs.CL", "cs.AI", "14J60 (Primary) 14F05, 14J26 (Secondary)"], "primary_category": "cs.CL"}
{"title": "FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation", "abstract": "Humans ask follow-up questions driven by curiosity, which reflects a creative\nhuman cognitive process. We introduce the task of real-world\ninformation-seeking follow-up question generation (FQG), which aims to generate\nfollow-up questions seeking a more in-depth understanding of an initial\nquestion and answer. We construct FOLLOWUPQG, a dataset of over 3K real-world\n(initial question, answer, follow-up question) tuples collected from a Reddit\nforum providing layman-friendly explanations for open-ended questions. In\ncontrast to existing datasets, questions in FOLLOWUPQG use more diverse\npragmatic strategies to seek information, and they also show higher-order\ncognitive skills (such as applying and relating). We evaluate current question\ngeneration models on their efficacy for generating follow-up questions,\nexploring how to generate specific types of follow-up questions based on\nstep-by-step demonstrations. Our results validate FOLLOWUPQG as a challenging\nbenchmark, as model-generated questions are adequate but far from human-raised\nquestions in terms of informativeness and complexity.", "published": "2023-09-10 11:58:29", "link": "http://arxiv.org/abs/2309.05007v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler", "abstract": "We propose a neuralized undirected graphical model called Neural-Hidden-CRF\nto solve the weakly-supervised sequence labeling problem. Under the umbrella of\nprobabilistic undirected graph theory, the proposed Neural-Hidden-CRF embedded\nwith a hidden CRF layer models the variables of word sequence, latent ground\ntruth sequence, and weak label sequence with the global perspective that\nundirected graphical models particularly enjoy. In Neural-Hidden-CRF, we can\ncapitalize on the powerful language model BERT or other deep models to provide\nrich contextual semantic knowledge to the latent ground truth sequence, and use\nthe hidden CRF layer to capture the internal label dependencies.\nNeural-Hidden-CRF is conceptually simple and empirically powerful. It obtains\nnew state-of-the-art results on one crowdsourcing benchmark and three\nweak-supervision benchmarks, including outperforming the recent advanced model\nCHMM by 2.80 F1 points and 2.23 F1 points in average generalization and\ninference performance, respectively.", "published": "2023-09-10 17:13:25", "link": "http://arxiv.org/abs/2309.05086v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AGent: A Novel Pipeline for Automatically Creating Unanswerable\n  Questions", "abstract": "The development of large high-quality datasets and high-performing models\nhave led to significant advancements in the domain of Extractive Question\nAnswering (EQA). This progress has sparked considerable interest in exploring\nunanswerable questions within the EQA domain. Training EQA models with\nunanswerable questions helps them avoid extracting misleading or incorrect\nanswers for queries that lack valid responses. However, manually annotating\nunanswerable questions is labor-intensive. To address this, we propose AGent, a\nnovel pipeline that automatically creates new unanswerable questions by\nre-matching a question with a context that lacks the necessary information for\na correct answer. In this paper, we demonstrate the usefulness of this AGent\npipeline by creating two sets of unanswerable questions from answerable\nquestions in SQuAD and HotpotQA. These created question sets exhibit low error\nrates. Additionally, models fine-tuned on these questions show comparable\nperformance with those fine-tuned on the SQuAD 2.0 dataset on multiple EQA\nbenchmarks.", "published": "2023-09-10 18:13:11", "link": "http://arxiv.org/abs/2309.05103v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Difficulty Estimation of Foreign Language\n  Content with Application to Language Learning", "abstract": "We use large language models to aid learners enhance proficiency in a foreign\nlanguage. This is accomplished by identifying content on topics that the user\nis interested in, and that closely align with the learner's proficiency level\nin that foreign language. Our work centers on French content, but our approach\nis readily transferable to other languages. Our solution offers several\ndistinctive characteristics that differentiate it from existing\nlanguage-learning solutions, such as, a) the discovery of content across topics\nthat the learner cares about, thus increasing motivation, b) a more precise\nestimation of the linguistic difficulty of the content than traditional\nreadability measures, and c) the availability of both textual and video-based\ncontent. The linguistic complexity of video content is derived from the video\ncaptions. It is our aspiration that such technology will enable learners to\nremain engaged in the language-learning process by continuously adapting the\ntopics and the difficulty of the content to align with the learners' evolving\ninterests and learning objectives.", "published": "2023-09-10 21:23:09", "link": "http://arxiv.org/abs/2309.05142v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image\n  Captioning", "abstract": "While impressive performance has been achieved in image captioning, the\nlimited diversity of the generated captions and the large parameter scale\nremain major barriers to the real-word application of these systems. In this\nwork, we propose a lightweight image captioning network in combination with\ncontinuous diffusion, called Prefix-diffusion. To achieve diversity, we design\nan efficient method that injects prefix image embeddings into the denoising\nprocess of the diffusion model. In order to reduce trainable parameters, we\nemploy a pre-trained model to extract image features and further design an\nextra mapping network. Prefix-diffusion is able to generate diverse captions\nwith relatively less parameters, while maintaining the fluency and relevance of\nthe captions benefiting from the generative capabilities of the diffusion\nmodel. Our work paves the way for scaling up diffusion models for image\ncaptioning, and achieves promising performance compared with recent approaches.", "published": "2023-09-10 08:55:24", "link": "http://arxiv.org/abs/2309.04965v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language\n  Model Game Agents", "abstract": "The development of believable, natural, and interactive digital artificial\nagents is a field of growing interest. Theoretical uncertainties and technical\nbarriers present considerable challenges to the field, particularly with\nregards to developing agents that effectively simulate human emotions. Large\nlanguage models (LLMs) might address these issues by tapping common patterns in\nsituational appraisal. In three empirical experiments, this study tests the\ncapabilities of LLMs to solve emotional intelligence tasks and to simulate\nemotions. It presents and evaluates a new chain-of-emotion architecture for\nemotion simulation within video games, based on psychological appraisal\nresearch. Results show that it outperforms standard LLM architectures on a\nrange of user experience and content analysis metrics. This study therefore\nprovides early evidence of how to construct and test affective agents based on\ncognitive processes represented in language models.", "published": "2023-09-10 16:55:49", "link": "http://arxiv.org/abs/2309.05076v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Collecting Visually-Grounded Dialogue with A Game Of Sorts", "abstract": "An idealized, though simplistic, view of the referring expression production\nand grounding process in (situated) dialogue assumes that a speaker must merely\nappropriately specify their expression so that the target referent may be\nsuccessfully identified by the addressee. However, referring in conversation is\na collaborative process that cannot be aptly characterized as an exchange of\nminimally-specified referring expressions. Concerns have been raised regarding\nassumptions made by prior work on visually-grounded dialogue that reveal an\noversimplified view of conversation and the referential process. We address\nthese concerns by introducing a collaborative image ranking task, a grounded\nagreement game we call \"A Game Of Sorts\". In our game, players are tasked with\nreaching agreement on how to rank a set of images given some sorting criterion\nthrough a largely unrestricted, role-symmetric dialogue. By putting emphasis on\nthe argumentation in this mixed-initiative interaction, we collect discussions\nthat involve the collaborative referential process. We describe results of a\nsmall-scale data collection experiment with the proposed task. All discussed\nmaterials, which includes the collected data, the codebase, and a containerized\nversion of the application, are publicly available.", "published": "2023-09-10 23:00:35", "link": "http://arxiv.org/abs/2309.05162v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Machine Translation Models Stand Strong in the Face of Adversarial\n  Attacks", "abstract": "Adversarial attacks expose vulnerabilities of deep learning models by\nintroducing minor perturbations to the input, which lead to substantial\nalterations in the output. Our research focuses on the impact of such\nadversarial attacks on sequence-to-sequence (seq2seq) models, specifically\nmachine translation models. We introduce algorithms that incorporate basic text\nperturbation heuristics and more advanced strategies, such as the\ngradient-based attack, which utilizes a differentiable approximation of the\ninherently non-differentiable translation metric. Through our investigation, we\nprovide evidence that machine translation models display robustness displayed\nrobustness against best performed known adversarial attacks, as the degree of\nperturbation in the output is directly proportional to the perturbation in the\ninput. However, among underdogs, our attacks outperform alternatives, providing\nthe best relative performance. Another strong candidate is an attack based on\nmixing of individual characters.", "published": "2023-09-10 11:22:59", "link": "http://arxiv.org/abs/2309.06527v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PlumberNet: Fixing interference leakage after GEV beamforming", "abstract": "Spatial filters can exploit deep-learning-based speech enhancement models to\nincrease their reliability in scenarios with multiple speech sources scenarios.\nTo further improve speech quality, it is common to perform postfiltering on the\nestimated target speech obtained with spatial filtering. In this work,\nGeneralized Eigenvalue (GEV) beamforming is employed to provide the leakage\nestimation, along with the estimation of the target speech, to be later used\nfor postfiltering. This improves the enhancement performance over a postfilter\nthat uses the target speech and a reference microphone signal. This work also\ndemonstrates that the spatial covariance matrices (SCMs) can be accurately\nestimated from the direction of arrival (DoA) of the target and a\ndiscriminative selection amongst the pairwise estimated time-frequency masks.", "published": "2023-09-10 15:45:31", "link": "http://arxiv.org/abs/2309.05057v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation", "abstract": "Audio-driven talking-head synthesis is a popular research topic for virtual\nhuman-related applications. However, the inflexibility and inefficiency of\nexisting methods, which necessitate expensive end-to-end training to transfer\nemotions from guidance videos to talking-head predictions, are significant\nlimitations. In this work, we propose the Emotional Adaptation for Audio-driven\nTalking-head (EAT) method, which transforms emotion-agnostic talking-head\nmodels into emotion-controllable ones in a cost-effective and efficient manner\nthrough parameter-efficient adaptations. Our approach utilizes a pretrained\nemotion-agnostic talking-head transformer and introduces three lightweight\nadaptations (the Deep Emotional Prompts, Emotional Deformation Network, and\nEmotional Adaptation Module) from different perspectives to enable precise and\nrealistic emotion controls. Our experiments demonstrate that our approach\nachieves state-of-the-art performance on widely-used benchmarks, including LRW\nand MEAD. Additionally, our parameter-efficient adaptations exhibit remarkable\ngeneralization ability, even in scenarios where emotional training videos are\nscarce or nonexistent. Project website: https://yuangan.github.io/eat/", "published": "2023-09-10 06:33:17", "link": "http://arxiv.org/abs/2309.04946v2", "categories": ["cs.SD", "cs.CV", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching", "abstract": "Although diffusion models in text-to-speech have become a popular choice due\nto their strong generative ability, the intrinsic complexity of sampling from\ndiffusion models harms their efficiency. Alternatively, we propose VoiceFlow,\nan acoustic model that utilizes a rectified flow matching algorithm to achieve\nhigh synthesis quality with a limited number of sampling steps. VoiceFlow\nformulates the process of generating mel-spectrograms into an ordinary\ndifferential equation conditional on text inputs, whose vector field is then\nestimated. The rectified flow technique then effectively straightens its\nsampling trajectory for efficient synthesis. Subjective and objective\nevaluations on both single and multi-speaker corpora showed the superior\nsynthesis quality of VoiceFlow compared to the diffusion counterpart. Ablation\nstudies further verified the validity of the rectified flow technique in\nVoiceFlow.", "published": "2023-09-10 13:47:39", "link": "http://arxiv.org/abs/2309.05027v3", "categories": ["eess.AS", "cs.AI", "cs.HC", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multimodal Fish Feeding Intensity Assessment in Aquaculture", "abstract": "Fish feeding intensity assessment (FFIA) aims to evaluate fish appetite\nchanges during feeding, which is crucial in industrial aquaculture\napplications. Existing FFIA methods are limited by their robustness to noise,\ncomputational complexity, and the lack of public datasets for developing the\nmodels. To address these issues, we first introduce AV-FFIA, a new dataset\ncontaining 27,000 labeled audio and video clips that capture different levels\nof fish feeding intensity. Then, we introduce multi-modal approaches for FFIA\nby leveraging the models pre-trained on individual modalities and fused with\ndata fusion methods. We perform benchmark studies of these methods on AV-FFIA,\nand demonstrate the advantages of the multi-modal approach over the\nsingle-modality based approach, especially in noisy environments. However,\ncompared to the methods developed for individual modalities, the multimodal\napproaches may involve higher computational costs due to the need for\nindependent encoders for each modality. To overcome this issue, we further\npresent a novel unified mixed-modality based method for FFIA, termed as U-FFIA.\nU-FFIA is a single model capable of processing audio, visual, or audio-visual\nmodalities, by leveraging modality dropout during training and knowledge\ndistillation using the models pre-trained with data from single modality. We\ndemonstrate that U-FFIA can achieve performance better than or on par with the\nstate-of-the-art modality-specific FFIA models, with significantly lower\ncomputational overhead, enabling robust and efficient FFIA for improved\naquaculture management.", "published": "2023-09-10 15:52:56", "link": "http://arxiv.org/abs/2309.05058v3", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
