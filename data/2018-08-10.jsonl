{"title": "Lingke: A Fine-grained Multi-turn Chatbot for Customer Service", "abstract": "Traditional chatbots usually need a mass of human dialogue data, especially\nwhen using supervised machine learning method. Though they can easily deal with\nsingle-turn question answering, for multi-turn the performance is usually\nunsatisfactory. In this paper, we present Lingke, an information retrieval\naugmented chatbot which is able to answer questions based on given product\nintroduction document and deal with multi-turn conversations. We will introduce\na fine-grained pipeline processing to distill responses based on unstructured\ndocuments, and attentive sequential context-response matching for multi-turn\nconversations.", "published": "2018-08-10 06:58:33", "link": "http://arxiv.org/abs/1808.03430v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hybrid approach for transliteration of Algerian arabizi: a primary study", "abstract": "A hybrid approach for the transliteration of Algerian Arabizi: A primary\nstudy In this paper, we present a hybrid approach for the transliteration of\nthe Algerian Arabizi. We define a set of rules enable us the passage from\nArabizi to Arabic. Through these rules, we generate a set of candidates for the\ntransliteration of each Arabizi word into arabic. Then, we extract the best\ncandidate. This approach was evaluated by using three test corpora, and the\nobtained results show an improvement of the precision score which is equal to\n75.11% for the best result. These results allow us to verify that our approach\nis very competitive comparing to others works that treat Arabizi\ntransliteration in general.\n  Keywords: Arabizi, Dialecte Alg\\'erien, Arabizi Alg\\'erien,\nTranslit\\'eration.", "published": "2018-08-10 07:46:48", "link": "http://arxiv.org/abs/1808.03437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TwoWingOS: A Two-Wing Optimization Strategy for Evidential Claim\n  Verification", "abstract": "Determining whether a given claim is supported by evidence is a fundamental\nNLP problem that is best modeled as Textual Entailment. However, given a large\ncollection of text, finding evidence that could support or refute a given claim\nis a challenge in itself, amplified by the fact that different evidence might\nbe needed to support or refute a claim. Nevertheless, most prior work decouples\nevidence identification from determining the truth value of the claim given the\nevidence.\n  We propose to consider these two aspects jointly. We develop TwoWingOS\n(two-wing optimization strategy), a system that, while identifying appropriate\nevidence for a claim, also determines whether or not the claim is supported by\nthe evidence. Given the claim, TwoWingOS attempts to identify a subset of the\nevidence candidates; given the predicted evidence, it then attempts to\ndetermine the truth value of the corresponding claim. We treat this challenge\nas coupled optimization problems, training a joint model for it. TwoWingOS\noffers two advantages: (i) Unlike pipeline systems, it facilitates\nflexible-size evidence set, and (ii) Joint training improves both the claim\nentailment and the evidence identification. Experiments on a benchmark dataset\nshow state-of-the-art performance. Code: https://github.com/yinwenpeng/FEVER", "published": "2018-08-10 09:27:44", "link": "http://arxiv.org/abs/1808.03465v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Densely Connected Convolutional Networks for Speech Recognition", "abstract": "This paper presents our latest investigation on Densely Connected\nConvolutional Networks (DenseNets) for acoustic modelling (AM) in automatic\nspeech recognition. DenseN-ets are very deep, compact convolutional neural\nnetworks, which have demonstrated incredible improvements over the\nstate-of-the-art results on several data sets in computer vision. Our\nexperimental results show that DenseNet can be used for AM significantly\noutperforming other neural-based models such as DNNs, CNNs, VGGs. Furthermore,\nresults on Wall Street Journal revealed that with only a half of the training\ndata DenseNet was able to outperform other models trained with the full data\nset by a large margin.", "published": "2018-08-10 14:54:10", "link": "http://arxiv.org/abs/1808.03570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Keyphrase Extraction from Scientific Publications", "abstract": "We propose a novel unsupervised keyphrase extraction approach that filters\ncandidate keywords using outlier detection. It starts by training word\nembeddings on the target document to capture semantic regularities among the\nwords. It then uses the minimum covariance determinant estimator to model the\ndistribution of non-keyphrase word vectors, under the assumption that these\nvectors come from the same distribution, indicative of their irrelevance to the\nsemantics expressed by the dimensions of the learned vector representation.\nCandidate keyphrases only consist of words that are detected as outliers of\nthis dominant distribution. Empirical results show that our approach\noutperforms state-of-the-art and recent unsupervised keyphrase extraction\nmethods.", "published": "2018-08-10 21:50:59", "link": "http://arxiv.org/abs/1808.03712v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Attention: What Really Counts in Various NLP Tasks", "abstract": "Attention mechanisms in sequence to sequence models have shown great ability\nand wonderful performance in various natural language processing (NLP) tasks,\nsuch as sentence embedding, text generation, machine translation, machine\nreading comprehension, etc. Unfortunately, existing attention mechanisms only\nlearn either high-level or low-level features. In this paper, we think that the\nlack of hierarchical mechanisms is a bottleneck in improving the performance of\nthe attention mechanisms, and propose a novel Hierarchical Attention Mechanism\n(Ham) based on the weighted sum of different layers of a multi-level attention.\nHam achieves a state-of-the-art BLEU score of 0.26 on Chinese poem generation\ntask and a nearly 6.5% averaged improvement compared with the existing machine\nreading comprehension models such as BIDAF and Match-LSTM. Furthermore, our\nexperiments and theorems reveal that Ham has greater generalization and\nrepresentation ability than existing attention mechanisms.", "published": "2018-08-10 23:28:33", "link": "http://arxiv.org/abs/1808.03728v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Making effective use of healthcare data using data-to-text technology", "abstract": "Healthcare organizations are in a continuous effort to improve health\noutcomes, reduce costs and enhance patient experience of care. Data is\nessential to measure and help achieving these improvements in healthcare\ndelivery. Consequently, a data influx from various clinical, financial and\noperational sources is now overtaking healthcare organizations and their\npatients. The effective use of this data, however, is a major challenge.\nClearly, text is an important medium to make data accessible. Financial reports\nare produced to assess healthcare organizations on some key performance\nindicators to steer their healthcare delivery. Similarly, at a clinical level,\ndata on patient status is conveyed by means of textual descriptions to\nfacilitate patient review, shift handover and care transitions. Likewise,\npatients are informed about data on their health status and treatments via\ntext, in the form of reports or via ehealth platforms by their doctors.\nUnfortunately, such text is the outcome of a highly labour-intensive process if\nit is done by healthcare professionals. It is also prone to incompleteness,\nsubjectivity and hard to scale up to different domains, wider audiences and\nvarying communication purposes. Data-to-text is a recent breakthrough\ntechnology in artificial intelligence which automatically generates natural\nlanguage in the form of text or speech from data. This chapter provides a\nsurvey of data-to-text technology, with a focus on how it can be deployed in a\nhealthcare setting. It will (1) give an up-to-date synthesis of data-to-text\napproaches, (2) give a categorized overview of use cases in healthcare, (3)\nseek to make a strong case for evaluating and implementing data-to-text in a\nhealthcare setting, and (4) highlight recent research challenges.", "published": "2018-08-10 12:33:45", "link": "http://arxiv.org/abs/1808.03507v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Unsupervised Learning of Sentence Representations Using Sequence\n  Consistency", "abstract": "Computing universal distributed representations of sentences is a fundamental\ntask in natural language processing. We propose ConsSent, a simple yet\nsurprisingly powerful unsupervised method to learn such representations by\nenforcing consistency constraints on sequences of tokens. We consider two\nclasses of such constraints -- sequences that form a sentence and between two\nsequences that form a sentence when merged. We learn sentence encoders by\ntraining them to distinguish between consistent and inconsistent examples, the\nlatter being generated by randomly perturbing consistent examples in six\ndifferent ways. Extensive evaluation on several transfer learning and\nlinguistic probing tasks shows improved performance over strong unsupervised\nand supervised baselines, substantially surpassing them in several cases. Our\nbest results are achieved by training sentence encoders in a multitask setting\nand by an ensemble of encoders trained on the individual tasks.", "published": "2018-08-10 08:15:01", "link": "http://arxiv.org/abs/1808.04217v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Homophonic Quotients of Linguistic Free Groups: German, Korean, and\n  Turkish", "abstract": "In 1993, the homophonic quotient groups for French and English (the quotient\nof the free group generated by the French (respectively English) alphabet\ndetermined by relations representing standard pronunciation rules) were\nexplicitly characterized [5]. In this paper we apply the same methodology to\nthree different language systems: German, Korean, and Turkish. We argue that\nour results point to some interesting differences between these three languages\n(or at least their current script systems).", "published": "2018-08-10 12:40:58", "link": "http://arxiv.org/abs/1808.04254v1", "categories": ["math.GR", "cs.CL"], "primary_category": "math.GR"}
{"title": "A Hassle-Free Machine Learning Method for Cohort Selection of Clinical\n  Trials", "abstract": "Traditional text classification techniques in clinical domain have heavily\nrelied on the manually extracted textual cues. This paper proposes a generally\nsupervised machine learning method that is equally hassle-free and does not use\nclinical knowledge. The employed methods were simple to implement, fast to run\nand yet effective. This paper proposes a novel named entity recognition (NER)\nbased an ensemble system capable of learning the keyword features in the\ndocument. Instead of merely considering the whole sentence/paragraph for\nanalysis, the NER based keyword features can stress the important clinic\nrelevant phases more. In addition, to capture the semantic information in the\ndocuments, the FastText features originating from the document level FastText\nclassification results are exploited.", "published": "2018-08-10 04:24:34", "link": "http://arxiv.org/abs/1808.04694v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "LemmaTag: Jointly Tagging and Lemmatizing for Morphologically-Rich\n  Languages with BRNNs", "abstract": "We present LemmaTag, a featureless neural network architecture that jointly\ngenerates part-of-speech tags and lemmas for sentences by using bidirectional\nRNNs with character-level and word-level embeddings. We demonstrate that both\ntasks benefit from sharing the encoding part of the network, predicting tag\nsubcategories, and using the tagger output as an input to the lemmatizer. We\nevaluate our model across several languages with complex morphology, which\nsurpasses state-of-the-art accuracy in both part-of-speech tagging and\nlemmatization in Czech, German, and Arabic.", "published": "2018-08-10 20:46:32", "link": "http://arxiv.org/abs/1808.03703v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Learning to Represent Bilingual Dictionaries", "abstract": "Bilingual word embeddings have been widely used to capture the similarity of\nlexical semantics in different human languages. However, many applications,\nsuch as cross-lingual semantic search and question answering, can be largely\nbenefited from the cross-lingual correspondence between sentences and lexicons.\nTo bridge this gap, we propose a neural embedding model that leverages\nbilingual dictionaries. The proposed model is trained to map the literal word\ndefinitions to the cross-lingual target words, for which we explore with\ndifferent sentence encoding techniques. To enhance the learning process on\nlimited resources, our model adopts several critical learning strategies,\nincluding multi-task learning on different bridges of languages, and joint\nlearning of the dictionary model with a bilingual word embedding model.\nExperimental evaluation focuses on two applications. The results of the\ncross-lingual reverse dictionary retrieval task show our model's promising\nability of comprehending bilingual concepts based on descriptions, and\nhighlight the effectiveness of proposed learning strategies in improving\nperformance. Meanwhile, our model effectively addresses the bilingual\nparaphrase identification problem and significantly outperforms previous\napproaches.", "published": "2018-08-10 23:21:07", "link": "http://arxiv.org/abs/1808.03726v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Effective Unsupervised Author Disambiguation with Relative Frequencies", "abstract": "This work addresses the problem of author name homonymy in the Web of\nScience. Aiming for an efficient, simple and straightforward solution, we\nintroduce a novel probabilistic similarity measure for author name\ndisambiguation based on feature overlap. Using the researcher-ID available for\na subset of the Web of Science, we evaluate the application of this measure in\nthe context of agglomeratively clustering author mentions. We focus on a\nconcise evaluation that shows clearly for which problem setups and at which\ntime during the clustering process our approach works best. In contrast to most\nother works in this field, we are sceptical towards the performance of author\nname disambiguation methods in general and compare our approach to the trivial\nsingle-cluster baseline. Our results are presented separately for each correct\nclustering size as we can explain that, when treating all cases together, the\ntrivial baseline and more sophisticated approaches are hardly distinguishable\nin terms of evaluation results. Our model shows state-of-the-art performance\nfor all correct clustering sizes without any discriminative training and with\ntuning only one convergence parameter.", "published": "2018-08-10 10:09:54", "link": "http://arxiv.org/abs/1808.04216v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Community Regularization of Visually-Grounded Dialog", "abstract": "The task of conducting visually grounded dialog involves learning\ngoal-oriented cooperative dialog between autonomous agents who exchange\ninformation about a scene through several rounds of questions and answers in\nnatural language. We posit that requiring artificial agents to adhere to the\nrules of human language, while also requiring them to maximize information\nexchange through dialog is an ill-posed problem. We observe that humans do not\nstray from a common language because they are social creatures who live in\ncommunities, and have to communicate with many people everyday, so it is far\neasier to stick to a common language even at the cost of some efficiency loss.\nUsing this as inspiration, we propose and evaluate a multi-agent\ncommunity-based dialog framework where each agent interacts with, and learns\nfrom, multiple agents, and show that this community-enforced regularization\nresults in more relevant and coherent dialog (as judged by human evaluators)\nwithout sacrificing task performance (as judged by quantitative metrics).", "published": "2018-08-10 22:09:43", "link": "http://arxiv.org/abs/1808.04359v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.CV"}
{"title": "This Time with Feeling: Learning Expressive Musical Performance", "abstract": "Music generation has generally been focused on either creating scores or\ninterpreting them. We discuss differences between these two problems and\npropose that, in fact, it may be valuable to work in the space of direct $\\it\nperformance$ generation: jointly predicting the notes $\\it and$ $\\it also$\ntheir expressive timing and dynamics. We consider the significance and\nqualities of the data set needed for this. Having identified both a problem\ndomain and characteristics of an appropriate data set, we show an LSTM-based\nrecurrent network model that subjectively performs quite well on this task.\nCritically, we provide generated examples. We also include feedback from\nprofessional composers and musicians about some of these examples.", "published": "2018-08-10 21:53:51", "link": "http://arxiv.org/abs/1808.03715v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
