{"title": "PAT: Parallel Attention Transformer for Visual Question Answering in\n  Vietnamese", "abstract": "We present in this paper a novel scheme for multimodal learning named the\nParallel Attention mechanism. In addition, to take into account the advantages\nof grammar and context in Vietnamese, we propose the Hierarchical Linguistic\nFeatures Extractor instead of using an LSTM network to extract linguistic\nfeatures. Based on these two novel modules, we introduce the Parallel Attention\nTransformer (PAT), achieving the best accuracy compared to all baselines on the\nbenchmark ViVQA dataset and other SOTA methods including SAAA and MCAN.", "published": "2023-07-17 05:05:15", "link": "http://arxiv.org/abs/2307.08247v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChatGPT is Good but Bing Chat is Better for Vietnamese Students", "abstract": "This study examines the efficacy of two SOTA large language models (LLMs),\nnamely ChatGPT and Microsoft Bing Chat (BingChat), in catering to the needs of\nVietnamese students. Although ChatGPT exhibits proficiency in multiple\ndisciplines, Bing Chat emerges as the more advantageous option. We conduct a\ncomparative analysis of their academic achievements in various disciplines,\nencompassing mathematics, literature, English language, physics, chemistry,\nbiology, history, geography, and civic education. The results of our study\nsuggest that BingChat demonstrates superior performance compared to ChatGPT\nacross a wide range of subjects, with the exception of literature, where\nChatGPT exhibits better performance. Additionally, BingChat utilizes the more\nadvanced GPT-4 technology in contrast to ChatGPT, which is built upon GPT-3.5.\nThis allows BingChat to improve to comprehension, reasoning and generation of\ncreative and informative text. Moreover, the fact that BingChat is accessible\nin Vietnam and its integration of hyperlinks and citations within responses\nserve to reinforce its superiority. In our analysis, it is evident that while\nChatGPT exhibits praiseworthy qualities, BingChat presents a more apdated\nsolutions for Vietnamese students.", "published": "2023-07-17 06:36:53", "link": "http://arxiv.org/abs/2307.08272v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoAD: Automatic Diagnosis through Symptom and Disease Collaborative\n  Generation", "abstract": "Automatic diagnosis (AD), a critical application of AI in healthcare, employs\nmachine learning techniques to assist doctors in gathering patient symptom\ninformation for precise disease diagnosis. The Transformer-based method\nutilizes an input symptom sequence, predicts itself through auto-regression,\nand employs the hidden state of the final symptom to determine the disease.\nDespite its simplicity and superior performance demonstrated, a decline in\ndisease diagnosis accuracy is observed caused by 1) a mismatch between symptoms\nobserved during training and generation, and 2) the effect of different symptom\norders on disease prediction. To address the above obstacles, we introduce the\nCoAD, a novel disease and symptom collaborative generation framework, which\nincorporates several key innovations to improve AD: 1) aligning sentence-level\ndisease labels with multiple possible symptom inquiry steps to bridge the gap\nbetween training and generation; 2) expanding symptom labels for each\nsub-sequence of symptoms to enhance annotation and eliminate the effect of\nsymptom order; 3) developing a repeated symptom input schema to effectively and\nefficiently learn the expanded disease and symptom labels. We evaluate the CoAD\nframework using four datasets, including three public and one private, and\ndemonstrate that it achieves an average 2.3% improvement over previous\nstate-of-the-art results in automatic disease diagnosis. For reproducibility,\nwe release the code and data at https://github.com/KwanWaiChung/coad.", "published": "2023-07-17 07:24:55", "link": "http://arxiv.org/abs/2307.08290v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Legal Syllogism Prompting: Teaching Large Language Models for Legal\n  Judgment Prediction", "abstract": "Legal syllogism is a form of deductive reasoning commonly used by legal\nprofessionals to analyze cases. In this paper, we propose legal syllogism\nprompting (LoT), a simple prompting method to teach large language models\n(LLMs) for legal judgment prediction. LoT teaches only that in the legal\nsyllogism the major premise is law, the minor premise is the fact, and the\nconclusion is judgment. Then the models can produce a syllogism reasoning of\nthe case and give the judgment without any learning, fine-tuning, or examples.\nOn CAIL2018, a Chinese criminal case dataset, we performed zero-shot judgment\nprediction experiments with GPT-3 models. Our results show that LLMs with LoT\nachieve better performance than the baseline and chain of thought prompting,\nthe state-of-art prompting method on diverse reasoning tasks. LoT enables the\nmodel to concentrate on the key information relevant to the judgment and to\ncorrectly understand the legal meaning of acts, as compared to other methods.\nOur method enables LLMs to predict judgment along with law articles and\njustification, which significantly enhances the explainability of models.", "published": "2023-07-17 08:38:46", "link": "http://arxiv.org/abs/2307.08321v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Supervised Learning with Contrastive Markings in Neural\n  Machine Translation Training", "abstract": "Supervised learning in Neural Machine Translation (NMT) typically follows a\nteacher forcing paradigm where reference tokens constitute the conditioning\ncontext in the model's prediction, instead of its own previous predictions. In\norder to alleviate this lack of exploration in the space of translations, we\npresent a simple extension of standard maximum likelihood estimation by a\ncontrastive marking objective. The additional training signals are extracted\nautomatically from reference translations by comparing the system hypothesis\nagainst the reference, and used for up/down-weighting correct/incorrect tokens.\nThe proposed new training procedure requires one additional translation pass\nover the training set per epoch, and does not alter the standard inference\nsetup. We show that training with contrastive markings yields improvements on\ntop of supervised learning, and is especially useful when learning from\npostedits where contrastive markings indicate human error corrections to the\noriginal hypotheses. Code is publicly released.", "published": "2023-07-17 11:56:32", "link": "http://arxiv.org/abs/2307.08416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving End-to-End Speech Translation by Imitation-Based Knowledge\n  Distillation with Synthetic Transcripts", "abstract": "End-to-end automatic speech translation (AST) relies on data that combines\naudio inputs with text translation outputs. Previous work used existing large\nparallel corpora of transcriptions and translations in a knowledge distillation\n(KD) setup to distill a neural machine translation (NMT) into an AST student\nmodel. While KD allows using larger pretrained models, the reliance of previous\nKD approaches on manual audio transcripts in the data pipeline restricts the\napplicability of this framework to AST. We present an imitation learning\napproach where a teacher NMT system corrects the errors of an AST student\nwithout relying on manual transcripts. We show that the NMT teacher can recover\nfrom errors in automatic transcriptions and is able to correct erroneous\ntranslations of the AST student, leading to improvements of about 4 BLEU points\nover the standard AST end-to-end baseline on the English-German CoVoST-2 and\nMuST-C datasets, respectively. Code and data are publicly\navailable.\\footnote{\\url{https://github.com/HubReb/imitkd_ast/releases/tag/v1.1}}", "published": "2023-07-17 12:14:45", "link": "http://arxiv.org/abs/2307.08426v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output\n  Robustness of Large Language Models", "abstract": "Considerable research efforts have been devoted to ensuring that large\nlanguage models (LLMs) align with human values and generate safe text. However,\nan excessive focus on sensitivity to certain topics can compromise the model's\nrobustness in following instructions, thereby impacting its overall performance\nin completing tasks. Previous benchmarks for jailbreaking LLMs have primarily\nfocused on evaluating the safety of the models without considering their\nrobustness. In this paper, we propose a benchmark that assesses both the safety\nand robustness of LLMs, emphasizing the need for a balanced approach. To\ncomprehensively study text safety and output robustness, we introduce a latent\njailbreak prompt dataset, each involving malicious instruction embedding.\nSpecifically, we instruct the model to complete a regular task, such as\ntranslation, with the text to be translated containing malicious instructions.\nTo further analyze safety and robustness, we design a hierarchical annotation\nframework. We present a systematic analysis of the safety and robustness of\nLLMs regarding the position of explicit normal instructions, word replacements\n(verbs in explicit normal instructions, target groups in malicious\ninstructions, cue words for explicit normal instructions), and instruction\nreplacements (different explicit normal instructions). Our results demonstrate\nthat current LLMs not only prioritize certain instruction verbs but also\nexhibit varying jailbreak rates for different instruction verbs in explicit\nnormal instructions. Code and data are available at\nhttps://github.com/qiuhuachuan/latent-jailbreak.", "published": "2023-07-17 13:49:52", "link": "http://arxiv.org/abs/2307.08487v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax-Aware Complex-Valued Neural Machine Translation", "abstract": "Syntax has been proven to be remarkably effective in neural machine\ntranslation (NMT). Previous models obtained syntax information from syntactic\nparsing tools and integrated it into NMT models to improve translation\nperformance. In this work, we propose a method to incorporate syntax\ninformation into a complex-valued Encoder-Decoder architecture. The proposed\nmodel jointly learns word-level and syntax-level attention scores from the\nsource side to the target side using an attention mechanism. Importantly, it is\nnot dependent on specific network architectures and can be directly integrated\ninto any existing sequence-to-sequence (Seq2Seq) framework. The experimental\nresults demonstrate that the proposed method can bring significant improvements\nin BLEU scores on two datasets. In particular, the proposed method achieves a\ngreater improvement in BLEU scores in translation tasks involving language\npairs with significant syntactic differences.", "published": "2023-07-17 15:58:05", "link": "http://arxiv.org/abs/2307.08586v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AlpaGasus: Training A Better Alpaca with Fewer Data", "abstract": "Large language models (LLMs) strengthen instruction-following capability\nthrough instruction-finetuning (IFT) on supervised instruction/response data.\nHowever, widely used IFT datasets (e.g., Alpaca's 52k data) surprisingly\ncontain many low-quality instances with incorrect or irrelevant responses,\nwhich are misleading and detrimental to IFT. In this paper, we propose a simple\nand effective data selection strategy that automatically identifies and filters\nout low-quality data using a strong LLM (e.g., ChatGPT). To this end, we\nintroduce AlpaGasus, which is finetuned on only 9k high-quality data filtered\nfrom the 52k Alpaca data. AlpaGasus significantly outperforms the original\nAlpaca as evaluated by GPT-4 on multiple test sets and the controlled human\nevaluation. Its 13B variant matches $>90\\%$ performance of its teacher LLM\n(i.e., Text-Davinci-003 generating the 52k data) on test tasks. It also\nprovides 5.7x faster training, reducing the training time for a 7B variant from\n80 minutes (for Alpaca) to 14 minutes. Moreover, the experiments prove the\nefficacy of our method across diverse datasets, base models, and LLM filters.\nOverall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can be\ngenerally applied to instruction-tuning data, leading to faster training and\nbetter instruction-following models. Our project page is available at:\nhttps://lichang-chen.github.io/AlpaGasus/", "published": "2023-07-17 17:59:40", "link": "http://arxiv.org/abs/2307.08701v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Knowledge Distillation from Large Language Model: An Empirical\n  Study in the Autonomous Driving Domain", "abstract": "Engineering knowledge-based (or expert) systems require extensive manual\neffort and domain knowledge. As Large Language Models (LLMs) are trained using\nan enormous amount of cross-domain knowledge, it becomes possible to automate\nsuch engineering processes. This paper presents an empirical automation and\nsemi-automation framework for domain knowledge distillation using prompt\nengineering and the LLM ChatGPT. We assess the framework empirically in the\nautonomous driving domain and present our key observations. In our\nimplementation, we construct the domain knowledge ontology by \"chatting\" with\nChatGPT. The key finding is that while fully automated domain ontology\nconstruction is possible, human supervision and early intervention typically\nimprove efficiency and output quality as they lessen the effects of response\nrandomness and the butterfly effect. We, therefore, also develop a web-based\ndistillation assistant enabling supervision and flexible intervention at\nruntime. We hope our findings and tools could inspire future research toward\nrevolutionizing the engineering of knowledge-based systems across application\ndomains.", "published": "2023-07-17 13:34:31", "link": "http://arxiv.org/abs/2307.11769v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extending the Frontier of ChatGPT: Code Generation and Debugging", "abstract": "Large-scale language models (LLMs) have emerged as a groundbreaking\ninnovation in the realm of question-answering and conversational agents. These\nmodels, leveraging different deep learning architectures such as Transformers,\nare trained on vast corpora to predict sentences based on given queries. Among\nthese LLMs, ChatGPT, developed by OpenAI, has ushered in a new era by utilizing\nartificial intelligence (AI) to tackle diverse problem domains, ranging from\ncomposing essays and biographies to solving intricate mathematical integrals.\nThe versatile applications enabled by ChatGPT offer immense value to users.\nHowever, assessing the performance of ChatGPT's output poses a challenge,\nparticularly in scenarios where queries lack clear objective criteria for\ncorrectness. For instance, evaluating the quality of generated essays becomes\narduous and relies heavily on manual labor, in stark contrast to evaluating\nsolutions to well-defined, closed-ended questions such as mathematical\nproblems. This research paper delves into the efficacy of ChatGPT in solving\nprogramming problems, examining both the correctness and the efficiency of its\nsolution in terms of time and memory complexity. The research reveals a\ncommendable overall success rate of 71.875\\%, denoting the proportion of\nproblems for which ChatGPT was able to provide correct solutions that\nsuccessfully satisfied all the test cases present in Leetcode. It exhibits\nstrengths in structured problems and shows a linear correlation between its\nsuccess rate and problem acceptance rates. However, it struggles to improve\nsolutions based on feedback, pointing to potential shortcomings in debugging\ntasks. These findings provide a compact yet insightful glimpse into ChatGPT's\ncapabilities and areas for improvement.", "published": "2023-07-17 06:06:58", "link": "http://arxiv.org/abs/2307.08260v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Gender mobility in the labor market with skills-based matching models", "abstract": "Skills-based matching promises mobility of workers between different sectors\nand occupations in the labor market. In this case, job seekers can look for\njobs they do not yet have experience in, but for which they do have relevant\nskills. Currently, there are multiple occupations with a skewed gender\ndistribution. For skills-based matching, it is unclear if and how a shift in\nthe gender distribution, which we call gender mobility, between occupations\nwill be effected. It is expected that the skills-based matching approach will\nlikely be data-driven, including computational language models and supervised\nlearning methods.\n  This work, first, shows the presence of gender segregation in language\nmodel-based skills representation of occupations. Second, we assess the use of\nthese representations in a potential application based on simulated data, and\nshow that the gender segregation is propagated by various data-driven\nskills-based matching models.These models are based on different language\nrepresentations (bag of words, word2vec, and BERT), and distance metrics\n(static and machine learning-based). Accordingly, we show how skills-based\nmatching approaches can be evaluated and compared on matching performance as\nwell as on the risk of gender segregation. Making the gender segregation bias\nof models more explicit can help in generating healthy trust in the use of\nthese models in practice.", "published": "2023-07-17 10:06:21", "link": "http://arxiv.org/abs/2307.08368v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "On the application of Large Language Models for language teaching and\n  assessment technology", "abstract": "The recent release of very large language models such as PaLM and GPT-4 has\nmade an unprecedented impact in the popular media and public consciousness,\ngiving rise to a mixture of excitement and fear as to their capabilities and\npotential uses, and shining a light on natural language processing research\nwhich had not previously received so much attention. The developments offer\ngreat promise for education technology, and in this paper we look specifically\nat the potential for incorporating large language models in AI-driven language\nteaching and assessment systems. We consider several research areas and also\ndiscuss the risks and ethical considerations surrounding generative AI in\neducation technology for language learners. Overall we find that larger\nlanguage models offer improvements over previous models in text generation,\nopening up routes toward content generation which had not previously been\nplausible. For text generation they must be prompted carefully and their\noutputs may need to be reshaped before they are ready for use. For automated\ngrading and grammatical error correction, tasks whose progress is checked on\nwell-known benchmarks, early investigations indicate that large language models\non their own do not improve on state-of-the-art results according to standard\nevaluation metrics. For grading it appears that linguistic features established\nin the literature should still be used for best performance, and for error\ncorrection it may be that the models can offer alternative feedback styles\nwhich are not measured sensitively with existing methods. In all cases, there\nis work to be done to experiment with the inclusion of large language models in\neducation technology for language learners, in order to properly understand and\nreport on their capacities and limitations, and to ensure that foreseeable\nrisks such as misinformation and harmful bias are mitigated.", "published": "2023-07-17 11:12:56", "link": "http://arxiv.org/abs/2307.08393v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Discovering collective narratives shifts in online discussions", "abstract": "Narrative is a foundation of human cognition and decision making. Because\nnarratives play a crucial role in societal discourses and spread of\nmisinformation and because of the pervasive use of social media, the narrative\ndynamics on social media can have profound societal impact. Yet, systematic and\ncomputational understanding of online narratives faces critical challenge of\nthe scale and dynamics; how can we reliably and automatically extract\nnarratives from massive amount of texts? How do narratives emerge, spread, and\ndie? Here, we propose a systematic narrative discovery framework that fill this\ngap by combining change point detection, semantic role labeling (SRL), and\nautomatic aggregation of narrative fragments into narrative networks. We\nevaluate our model with synthetic and empirical data two-Twitter corpora about\nCOVID-19 and 2017 French Election. Results demonstrate that our approach can\nrecover major narrative shifts that correspond to the major events.", "published": "2023-07-17 15:00:04", "link": "http://arxiv.org/abs/2307.08541v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "The Resume Paradox: Greater Language Differences, Smaller Pay Gaps", "abstract": "Over the past decade, the gender pay gap has remained steady with women\nearning 84 cents for every dollar earned by men on average. Many studies\nexplain this gap through demand-side bias in the labor market represented\nthrough employers' job postings. However, few studies analyze potential bias\nfrom the worker supply-side. Here, we analyze the language in millions of US\nworkers' resumes to investigate how differences in workers' self-representation\nby gender compare to differences in earnings. Across US occupations, language\ndifferences between male and female resumes correspond to 11% of the variation\nin gender pay gap. This suggests that females' resumes that are semantically\nsimilar to males' resumes may have greater wage parity. However, surprisingly,\noccupations with greater language differences between male and female resumes\nhave lower gender pay gaps. A doubling of the language difference between\nfemale and male resumes results in an annual wage increase of $2,797 for the\naverage female worker. This result holds with controls for gender-biases of\nresume text and we find that per-word bias poorly describes the variance in\nwage gap. The results demonstrate that textual data and self-representation are\nvaluable factors for improving worker representations and understanding\nemployment inequities.", "published": "2023-07-17 15:49:35", "link": "http://arxiv.org/abs/2307.08580v1", "categories": ["physics.soc-ph", "cs.CL"], "primary_category": "physics.soc-ph"}
{"title": "Retentive Network: A Successor to Transformer for Large Language Models", "abstract": "In this work, we propose Retentive Network (RetNet) as a foundation\narchitecture for large language models, simultaneously achieving training\nparallelism, low-cost inference, and good performance. We theoretically derive\nthe connection between recurrence and attention. Then we propose the retention\nmechanism for sequence modeling, which supports three computation paradigms,\ni.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel\nrepresentation allows for training parallelism. The recurrent representation\nenables low-cost $O(1)$ inference, which improves decoding throughput, latency,\nand GPU memory without sacrificing performance. The chunkwise recurrent\nrepresentation facilitates efficient long-sequence modeling with linear\ncomplexity, where each chunk is encoded parallelly while recurrently\nsummarizing the chunks. Experimental results on language modeling show that\nRetNet achieves favorable scaling results, parallel training, low-cost\ndeployment, and efficient inference. The intriguing properties make RetNet a\nstrong successor to Transformer for large language models. Code will be\navailable at https://aka.ms/retnet.", "published": "2023-07-17 16:40:01", "link": "http://arxiv.org/abs/2307.08621v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comparative Performance Evaluation of Large Language Models for\n  Extracting Molecular Interactions and Pathway Knowledge", "abstract": "Background Identification of the interactions and regulatory relations\nbetween biomolecules play pivotal roles in understanding complex biological\nsystems and the mechanisms underlying diverse biological functions. However,\nthe collection of such molecular interactions has heavily relied on expert\ncuration in the past, making it labor-intensive and time-consuming. To mitigate\nthese challenges, we propose leveraging the capabilities of large language\nmodels (LLMs) to automate genome-scale extraction of this crucial knowledge.\n  Results In this study, we investigate the efficacy of various LLMs in\naddressing biological tasks, such as the recognition of protein interactions,\nidentification of genes linked to pathways affected by low-dose radiation, and\nthe delineation of gene regulatory relationships. Overall, the larger models\nexhibited superior performance, indicating their potential for specific tasks\nthat involve the extraction of complex interactions among genes and proteins.\nAlthough these models possessed detailed information for distinct gene and\nprotein groups, they faced challenges in identifying groups with diverse\nfunctions and in recognizing highly correlated gene regulatory relationships.\n  Conclusions By conducting a comprehensive assessment of the state-of-the-art\nmodels using well-established molecular interaction and pathway databases, our\nstudy reveals that LLMs can identify genes/proteins associated with pathways of\ninterest and predict their interactions to a certain extent. Furthermore, these\nmodels can provide important insights, marking a noteworthy stride toward\nadvancing our understanding of biological systems through AI-assisted knowledge\ndiscovery.", "published": "2023-07-17 20:01:11", "link": "http://arxiv.org/abs/2307.08813v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How do software citation formats evolve over time? A longitudinal\n  analysis of R programming language packages", "abstract": "Under the data-driven research paradigm, research software has come to play\ncrucial roles in nearly every stage of scientific inquiry. Scholars are\nadvocating for the formal citation of software in academic publications,\ntreating it on par with traditional research outputs. However, software is\nhardly consistently cited: one software entity can be cited as different\nobjects, and the citations can change over time. These issues, however, are\nlargely overlooked in existing empirical research on software citation. To fill\nthe above gaps, the present study compares and analyzes a longitudinal dataset\nof citation formats of all R packages collected in 2021 and 2022, in order to\nunderstand the citation formats of R-language packages, important members in\nthe open-source software family, and how the citations evolve over time. In\nparticular, we investigate the different document types underlying the\ncitations and what metadata elements in the citation formats changed over time.\nFurthermore, we offer an in-depth analysis of the disciplinarity of journal\narticles cited as software (software papers). By undertaking this research, we\naim to contribute to a better understanding of the complexities associated with\nsoftware citation, shedding light on future software citation policies and\ninfrastructure.", "published": "2023-07-17 09:18:57", "link": "http://arxiv.org/abs/2307.09390v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Large-Scale Evaluation of Topic Models and Dimensionality Reduction\n  Methods for 2D Text Spatialization", "abstract": "Topic models are a class of unsupervised learning algorithms for detecting\nthe semantic structure within a text corpus. Together with a subsequent\ndimensionality reduction algorithm, topic models can be used for deriving\nspatializations for text corpora as two-dimensional scatter plots, reflecting\nsemantic similarity between the documents and supporting corpus analysis.\nAlthough the choice of the topic model, the dimensionality reduction, and their\nunderlying hyperparameters significantly impact the resulting layout, it is\nunknown which particular combinations result in high-quality layouts with\nrespect to accuracy and perception metrics. To investigate the effectiveness of\ntopic models and dimensionality reduction methods for the spatialization of\ncorpora as two-dimensional scatter plots (or basis for landscape-type\nvisualizations), we present a large-scale, benchmark-based computational\nevaluation. Our evaluation consists of (1) a set of corpora, (2) a set of\nlayout algorithms that are combinations of topic models and dimensionality\nreductions, and (3) quality metrics for quantifying the resulting layout. The\ncorpora are given as document-term matrices, and each document is assigned to a\nthematic class. The chosen metrics quantify the preservation of local and\nglobal properties and the perceptual effectiveness of the two-dimensional\nscatter plots. By evaluating the benchmark on a computing cluster, we derived a\nmultivariate dataset with over 45 000 individual layouts and corresponding\nquality metrics. Based on the results, we propose guidelines for the effective\ndesign of text spatializations that are based on topic models and\ndimensionality reductions. As a main result, we show that interpretable topic\nmodels are beneficial for capturing the structure of text corpora. We\nfurthermore recommend the use of t-SNE as a subsequent dimensionality\nreduction.", "published": "2023-07-17 14:08:25", "link": "http://arxiv.org/abs/2307.11770v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mini-Giants: \"Small\" Language Models and Open Source Win-Win", "abstract": "ChatGPT is phenomenal. However, it is prohibitively expensive to train and\nrefine such giant models. Fortunately, small language models are flourishing\nand becoming more and more competent. We call them \"mini-giants\". We argue that\nopen source community like Kaggle and mini-giants will win-win in many ways,\ntechnically, ethically and socially. In this article, we present a brief yet\nrich background, discuss how to attain small language models, present a\ncomparative study of small language models and a brief discussion of evaluation\nmethods, discuss the application scenarios where small language models are most\nneeded in the real world, and conclude with discussion and outlook.", "published": "2023-07-17 01:35:56", "link": "http://arxiv.org/abs/2307.08189v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BASS: Block-wise Adaptation for Speech Summarization", "abstract": "End-to-end speech summarization has been shown to improve performance over\ncascade baselines. However, such models are difficult to train on very large\ninputs (dozens of minutes or hours) owing to compute restrictions and are hence\ntrained with truncated model inputs. Truncation leads to poorer models, and a\nsolution to this problem rests in block-wise modeling, i.e., processing a\nportion of the input frames at a time. In this paper, we develop a method that\nallows one to train summarization models on very long sequences in an\nincremental manner. Speech summarization is realized as a streaming process,\nwhere hypothesis summaries are updated every block based on new acoustic\ninformation. We devise and test strategies to pass semantic context across the\nblocks. Experiments on the How2 dataset demonstrate that the proposed\nblock-wise training method improves by 3 points absolute on ROUGE-L over a\ntruncated input baseline.", "published": "2023-07-17 03:31:36", "link": "http://arxiv.org/abs/2307.08217v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language\n  Models", "abstract": "Dense retrieval (DR) converts queries and documents into dense embeddings and\nmeasures the similarity between queries and documents in vector space. One of\nthe challenges in DR is the lack of domain-specific training data. While DR\nmodels can learn from large-scale public datasets like MS MARCO through\ntransfer learning, evidence shows that not all DR models and domains can\nbenefit from transfer learning equally. Recently, some researchers have\nresorted to large language models (LLMs) to improve the zero-shot and few-shot\nDR models. However, the hard prompts or human-written prompts utilized in these\nworks cannot guarantee the good quality of generated weak queries. To tackle\nthis, we propose soft prompt tuning for augmenting DR (SPTAR): For each task,\nwe leverage soft prompt-tuning to optimize a task-specific soft prompt on\nlimited ground truth data and then prompt the LLMs to tag unlabeled documents\nwith weak queries, yielding enough weak document-query pairs to train\ntask-specific dense retrievers. We design a filter to select high-quality\nexample document-query pairs in the prompt to further improve the quality of\nweak tagged queries. To the best of our knowledge, there is no prior work\nutilizing soft prompt tuning to augment DR models. The experiments demonstrate\nthat SPTAR outperforms the unsupervised baselines BM25 and the recently\nproposed LLMs-based augmentation method for DR.", "published": "2023-07-17 07:55:47", "link": "http://arxiv.org/abs/2307.08303v5", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "IterLara: A Turing Complete Algebra for Big Data, AI, Scientific\n  Computing, and Database", "abstract": "\\textsc{Lara} is a key-value algebra that aims at unifying linear and\nrelational algebra with three types of operation abstraction. The study of\n\\textsc{Lara}'s expressive ability reports that it can represent relational\nalgebra and most linear algebra operations. However, several essential\ncomputations, such as matrix inversion and determinant, cannot be expressed in\n\\textsc{Lara}. \\textsc{Lara} cannot represent global and iterative computation,\neither. This article proposes \\textsc{IterLara}, extending \\textsc{Lara} with\niterative operators, to provide an algebraic model that unifies operations in\ngeneral-purpose computing, like big data, AI, scientific computing, and\ndatabase. We study the expressive ability of \\textsc{Lara} and\n\\textsc{IterLara} and prove that \\textsc{IterLara} with aggregation functions\ncan represent matrix inversion, determinant. Besides, we demonstrate that\n\\textsc{IterLara} with no limitation of function utility is Turing complete. We\nalso propose the Operation Count (OP) as a metric of computation amount for\n\\textsc{IterLara} and ensure that the OP metric is in accordance with the\nexisting computation metrics.", "published": "2023-07-17 08:23:09", "link": "http://arxiv.org/abs/2307.08315v1", "categories": ["cs.DB", "cs.CL", "cs.DS"], "primary_category": "cs.DB"}
{"title": "Multimodal Diffusion Segmentation Model for Object Segmentation from\n  Manipulation Instructions", "abstract": "In this study, we aim to develop a model that comprehends a natural language\ninstruction (e.g., \"Go to the living room and get the nearest pillow to the\nradio art on the wall\") and generates a segmentation mask for the target\neveryday object. The task is challenging because it requires (1) the\nunderstanding of the referring expressions for multiple objects in the\ninstruction, (2) the prediction of the target phrase of the sentence among the\nmultiple phrases, and (3) the generation of pixel-wise segmentation masks\nrather than bounding boxes. Studies have been conducted on languagebased\nsegmentation methods; however, they sometimes mask irrelevant regions for\ncomplex sentences. In this paper, we propose the Multimodal Diffusion\nSegmentation Model (MDSM), which generates a mask in the first stage and\nrefines it in the second stage. We introduce a crossmodal parallel feature\nextraction mechanism and extend diffusion probabilistic models to handle\ncrossmodal features. To validate our model, we built a new dataset based on the\nwell-known Matterport3D and REVERIE datasets. This dataset consists of\ninstructions with complex referring expressions accompanied by real indoor\nenvironmental images that feature various target objects, in addition to\npixel-wise segmentation masks. The performance of MDSM surpassed that of the\nbaseline method by a large margin of +10.13 mean IoU.", "published": "2023-07-17 16:07:07", "link": "http://arxiv.org/abs/2307.08597v1", "categories": ["cs.CV", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Multilingual Speech-to-Speech Translation into Multiple Target Languages", "abstract": "Speech-to-speech translation (S2ST) enables spoken communication between\npeople talking in different languages. Despite a few studies on multilingual\nS2ST, their focus is the multilinguality on the source side, i.e., the\ntranslation from multiple source languages to one target language. We present\nthe first work on multilingual S2ST supporting multiple target languages.\nLeveraging recent advance in direct S2ST with speech-to-unit and vocoder, we\nequip these key components with multilingual capability. Speech-to-masked-unit\n(S2MU) is the multilingual extension of S2U, which applies masking to units\nwhich don't belong to the given target language to reduce the language\ninterference. We also propose multilingual vocoder which is trained with\nlanguage embedding and the auxiliary loss of language identification. On\nbenchmark translation testsets, our proposed multilingual model shows superior\nperformance than bilingual models in the translation from English into $16$\ntarget languages.", "published": "2023-07-17 17:12:44", "link": "http://arxiv.org/abs/2307.08655v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Do Models Explain Themselves? Counterfactual Simulatability of Natural\n  Language Explanations", "abstract": "Large language models (LLMs) are trained to imitate humans to explain human\ndecisions. However, do LLMs explain themselves? Can they help humans build\nmental models of how LLMs process different inputs? To answer these questions,\nwe propose to evaluate $\\textbf{counterfactual simulatability}$ of natural\nlanguage explanations: whether an explanation can enable humans to precisely\ninfer the model's outputs on diverse counterfactuals of the explained input.\nFor example, if a model answers \"yes\" to the input question \"Can eagles fly?\"\nwith the explanation \"all birds can fly\", then humans would infer from the\nexplanation that it would also answer \"yes\" to the counterfactual input \"Can\npenguins fly?\". If the explanation is precise, then the model's answer should\nmatch humans' expectations.\n  We implemented two metrics based on counterfactual simulatability: precision\nand generality. We generated diverse counterfactuals automatically using LLMs.\nWe then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4) on\ntwo tasks: multi-hop factual reasoning and reward modeling. We found that LLM's\nexplanations have low precision and that precision does not correlate with\nplausibility. Therefore, naively optimizing human approvals (e.g., RLHF) may\nnot be a sufficient solution.", "published": "2023-07-17 17:41:47", "link": "http://arxiv.org/abs/2307.08678v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "COLLIE: Systematic Construction of Constrained Text Generation Tasks", "abstract": "Text generation under constraints have seen increasing interests in natural\nlanguage processing, especially with the rapidly improving capabilities of\nlarge language models. However, existing benchmarks for constrained generation\nusually focus on fixed constraint types (e.g.,generate a sentence containing\ncertain words) that have proved to be easy for state-of-the-art models like\nGPT-4. We present COLLIE, a grammar-based framework that allows the\nspecification of rich, compositional constraints with diverse generation levels\n(word, sentence, paragraph, passage) and modeling challenges (e.g.,language\nunderstanding, logical reasoning, counting, semantic planning). We also develop\ntools for automatic extraction of task instances given a constraint structure\nand a raw text corpus. Using COLLIE, we compile the COLLIE-v1 dataset with 2080\ninstances comprising 13 constraint structures. We perform systematic\nexperiments across five state-of-the-art instruction-tuned language models and\nanalyze their performances to reveal shortcomings. COLLIE is designed to be\nextensible and lightweight, and we hope the community finds it useful to\ndevelop more complex constraints and evaluations in the future.", "published": "2023-07-17 17:48:51", "link": "http://arxiv.org/abs/2307.08689v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ivrit.ai: A Comprehensive Dataset of Hebrew Speech for AI Research and\n  Development", "abstract": "We introduce \"ivrit.ai\", a comprehensive Hebrew speech dataset, addressing\nthe distinct lack of extensive, high-quality resources for advancing Automated\nSpeech Recognition (ASR) technology in Hebrew. With over 3,300 speech hours and\na over a thousand diverse speakers, ivrit.ai offers a substantial compilation\nof Hebrew speech across various contexts. It is delivered in three forms to\ncater to varying research needs: raw unprocessed audio; data post-Voice\nActivity Detection, and partially transcribed data. The dataset stands out for\nits legal accessibility, permitting use at no cost, thereby serving as a\ncrucial resource for researchers, developers, and commercial entities. ivrit.ai\nopens up numerous applications, offering vast potential to enhance AI\ncapabilities in Hebrew. Future efforts aim to expand ivrit.ai further, thereby\nadvancing Hebrew's standing in AI research and technology.", "published": "2023-07-17 04:19:30", "link": "http://arxiv.org/abs/2307.08720v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A mixed policy to improve performance of language models on math\n  problems", "abstract": "When to solve math problems, most language models take a sampling strategy to\npredict next word according conditional probabilities. In the math reasoning\nstep, it may generate wrong answer. Considering math problems are\ndeterministic, we propose a mixed policy exploration approach to solve math\nproblems with reinforcement learning. In peculiar, we propose a two level token\nexploration policy: the abstract level explores next token with probability and\nthe second level is deterministic. Specifically, the abstract level policy will\ndecide whether the token is operator or operand with probability sampling,\nwhile the second level is deterministic to select next token with the highest\nscore in a greedy way. We test our method on GSM8K dataset with GPT-2 model,\nand demonstrate more than $2\\%$ performance gain. Our implementation is\navailable at https://github.com/vividitytech/math_lm_rl.", "published": "2023-07-17 18:27:49", "link": "http://arxiv.org/abs/2307.08767v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T10", "I.2.6"], "primary_category": "cs.CL"}
{"title": "Curriculum Learning for Graph Neural Networks: A Multiview\n  Competence-based Approach", "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.", "published": "2023-07-17 21:33:35", "link": "http://arxiv.org/abs/2307.08859v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Automated Action Model Acquisition from Narrative Texts", "abstract": "Action models, which take the form of precondition/effect axioms, facilitate\ncausal and motivational connections between actions for AI agents. Action model\nacquisition has been identified as a bottleneck in the application of planning\ntechnology, especially within narrative planning. Acquiring action models from\nnarrative texts in an automated way is essential, but challenging because of\nthe inherent complexities of such texts. We present NaRuto, a system that\nextracts structured events from narrative text and subsequently generates\nplanning-language-style action models based on predictions of commonsense event\nrelations, as well as textual contradictions and similarities, in an\nunsupervised manner. Experimental results in classical narrative planning\ndomains show that NaRuto can generate action models of significantly better\nquality than existing fully automated methods, and even on par with those of\nsemi-automated methods.", "published": "2023-07-17 07:04:31", "link": "http://arxiv.org/abs/2307.10247v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Question Decomposition Improves the Faithfulness of Model-Generated\n  Reasoning", "abstract": "As large language models (LLMs) perform more difficult tasks, it becomes\nharder to verify the correctness and safety of their behavior. One approach to\nhelp with this issue is to prompt LLMs to externalize their reasoning, e.g., by\nhaving them generate step-by-step reasoning as they answer a question\n(Chain-of-Thought; CoT). The reasoning may enable us to check the process that\nmodels use to perform tasks. However, this approach relies on the stated\nreasoning faithfully reflecting the model's actual reasoning, which is not\nalways the case. To improve over the faithfulness of CoT reasoning, we have\nmodels generate reasoning by decomposing questions into subquestions.\nDecomposition-based methods achieve strong performance on question-answering\ntasks, sometimes approaching that of CoT while improving the faithfulness of\nthe model's stated reasoning on several recently-proposed metrics. By forcing\nthe model to answer simpler subquestions in separate contexts, we greatly\nincrease the faithfulness of model-generated reasoning over CoT, while still\nachieving some of the performance gains of CoT. Our results show it is possible\nto improve the faithfulness of model-generated reasoning; continued\nimprovements may lead to reasoning that enables us to verify the correctness\nand safety of LLM behavior.", "published": "2023-07-17 00:54:10", "link": "http://arxiv.org/abs/2307.11768v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Measuring Faithfulness in Chain-of-Thought Reasoning", "abstract": "Large language models (LLMs) perform better when they produce step-by-step,\n\"Chain-of-Thought\" (CoT) reasoning before answering a question, but it is\nunclear if the stated reasoning is a faithful explanation of the model's actual\nreasoning (i.e., its process for answering the question). We investigate\nhypotheses for how CoT reasoning may be unfaithful, by examining how the model\npredictions change when we intervene on the CoT (e.g., by adding mistakes or\nparaphrasing it). Models show large variation across tasks in how strongly they\ncondition on the CoT when predicting their answer, sometimes relying heavily on\nthe CoT and other times primarily ignoring it. CoT's performance boost does not\nseem to come from CoT's added test-time compute alone or from information\nencoded via the particular phrasing of the CoT. As models become larger and\nmore capable, they produce less faithful reasoning on most tasks we study.\nOverall, our results suggest that CoT can be faithful if the circumstances such\nas the model size and task are carefully chosen.", "published": "2023-07-17 01:08:39", "link": "http://arxiv.org/abs/2307.13702v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding\n  (Survey)", "abstract": "Can artificial intelligence unlock the secrets of the human brain? How do the\ninner mechanisms of deep learning models relate to our neural circuits? Is it\npossible to enhance AI by tapping into the power of brain recordings? These\ncaptivating questions lie at the heart of an emerging field at the intersection\nof neuroscience and artificial intelligence. Our survey dives into this\nexciting domain, focusing on human brain recording studies and cutting-edge\ncognitive neuroscience datasets that capture brain activity during natural\nlanguage processing, visual perception, and auditory experiences. We explore\ntwo fundamental approaches: encoding models, which attempt to generate brain\nactivity patterns from sensory inputs; and decoding models, which aim to\nreconstruct our thoughts and perceptions from neural signals. These techniques\nnot only promise breakthroughs in neurological diagnostics and brain-computer\ninterfaces but also offer a window into the very nature of cognition. In this\nsurvey, we first discuss popular representations of language, vision, and\nspeech stimuli, and present a summary of neuroscience datasets. We then review\nhow the recent advances in deep learning transformed this field, by\ninvestigating the popular deep learning based encoding and decoding\narchitectures, noting their benefits and limitations across different sensory\nmodalities. From text to images, speech to videos, we investigate how these\nmodels capture the brain's response to our complex, multimodal world. While our\nprimary focus is on human studies, we also highlight the crucial role of animal\nmodels in advancing our understanding of neural mechanisms. Throughout, we\nmention the ethical implications of these powerful technologies, addressing\nconcerns about privacy and cognitive liberty. We conclude with a summary and\ndiscussion of future trends in this rapidly evolving field.", "published": "2023-07-17 06:54:36", "link": "http://arxiv.org/abs/2307.10246v3", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.CV", "cs.HC", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Adapting Large Language Model with Speech for Fully Formatted End-to-End\n  Speech Recognition", "abstract": "Most end-to-end (E2E) speech recognition models are composed of encoder and\ndecoder blocks that perform acoustic and language modeling functions.\nPretrained large language models (LLMs) have the potential to improve the\nperformance of E2E ASR. However, integrating a pretrained language model into\nan E2E speech recognition model has shown limited benefits due to the\nmismatches between text-based LLMs and those used in E2E ASR. In this paper, we\nexplore an alternative approach by adapting a pretrained LLMs to speech. Our\nexperiments on fully-formatted E2E ASR transcription tasks across various\ndomains demonstrate that our approach can effectively leverage the strengths of\npretrained LLMs to produce more readable ASR transcriptions. Our model, which\nis based on the pretrained large language models with either an encoder-decoder\nor decoder-only structure, surpasses strong ASR models such as Whisper, in\nterms of recognition error rate, considering formats like punctuation and\ncapitalization as well.", "published": "2023-07-17 04:29:41", "link": "http://arxiv.org/abs/2307.08234v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Dynamic Kernel Convolution Network with Scene-dedicate Training for\n  Sound Event Localization and Detection", "abstract": "DNN-based methods have shown high performance in sound event localization and\ndetection(SELD). While in real spatial sound scenes, reverberation and the\nimbalanced presence of various sound events increase the complexity of the SELD\ntask. In this paper, we propose an effective SELD system in real spatial\nscenes.In our approach, a dynamic kernel convolution module is introduced after\nthe convolution blocks to adaptively model the channel-wise features with\ndifferent receptive fields. Secondly, we incorporate the SELDnet and EINv2\nframework into the proposed SELD system with multi-track ACCDOA. Moreover, two\nscene-dedicated strategies are introduced into the training stage to improve\nthe generalization of the system in realistic spatial sound scenes. Finally, we\napply data augmentation methods to extend the dataset using channel rotation,\nspatial data synthesis. Four joint metrics are used to evaluate the performance\nof the SELD system on the Sony-TAu Realistic Spatial Soundscapes 2022\ndataset.Experimental results show that the proposed systems outperform the\nfixed-kernel convolution SELD systems. In addition, the proposed system\nachieved an SELD score of 0.348 in the DCASE SELD task and surpassed the SOTA\nmethods.", "published": "2023-07-17 04:41:19", "link": "http://arxiv.org/abs/2307.08239v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Semi-supervised multi-channel speaker diarization with cross-channel\n  attention", "abstract": "Most neural speaker diarization systems rely on sufficient manual training\ndata labels, which are hard to collect under real-world scenarios. This paper\nproposes a semi-supervised speaker diarization system to utilize large-scale\nmulti-channel training data by generating pseudo-labels for unlabeled data.\nFurthermore, we introduce cross-channel attention into the Neural Speaker\nDiarization Using Memory-Aware Multi-Speaker Embedding (NSD-MA-MSE) to learn\nchannel contextual information of speaker embeddings better. Experimental\nresults on the CHiME-7 Mixer6 dataset which only contains partial speakers'\nlabels of the training set, show that our system achieved 57.01% relative DER\nreduction compared to the clustering-based model on the development set. We\nfurther conducted experiments on the CHiME-6 dataset to simulate the scenario\nof missing partial training set labels. When using 80% and 50% labeled training\ndata, our system performs comparably to the results obtained using 100% labeled\ndata for training.", "published": "2023-07-17 17:48:26", "link": "http://arxiv.org/abs/2307.08688v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Low bit rate binaural link for improved ultra low-latency low-complexity\n  multichannel speech enhancement in Hearing Aids", "abstract": "Speech enhancement in hearing aids is a challenging task since the hardware\nlimits the number of possible operations and the latency needs to be in the\nrange of only a few milliseconds. We propose a deep-learning model compatible\nwith these limitations, which we refer to as Group-Communication Filter-and-Sum\nNetwork (GCFSnet). GCFSnet is a causal multiple-input single output enhancement\nmodel using filter-and-sum processing in the time-frequency domain and a\nmulti-frame deep post filter. All filters are complex-valued and are estimated\nby a deep-learning model using weight-sharing through Group Communication and\nquantization-aware training for reducing model size and computational\nfootprint. For a further increase in performance, a low bit rate binaural link\nfor delayed binaural features is proposed to use binaural information while\nretaining a latency of 2ms. The performance of an oracle binaural LCMV\nbeamformer in non-low-latency configuration can be matched even by a unilateral\nconfiguration of the GCFSnet in terms of objective metrics.", "published": "2023-07-17 21:33:34", "link": "http://arxiv.org/abs/2307.08858v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Exploring Binary Classification Loss For Speaker Verification", "abstract": "The mismatch between close-set training and open-set testing usually leads to\nsignificant performance degradation for speaker verification task. For existing\nloss functions, metric learning-based objectives depend strongly on searching\neffective pairs which might hinder further improvements. And popular\nmulti-classification methods are usually observed with degradation when\nevaluated on unseen speakers. In this work, we introduce SphereFace2 framework\nwhich uses several binary classifiers to train the speaker model in a pair-wise\nmanner instead of performing multi-classification. Benefiting from this\nlearning paradigm, it can efficiently alleviate the gap between training and\nevaluation. Experiments conducted on Voxceleb show that the SphereFace2\noutperforms other existing loss functions, especially on hard trials. Besides,\nlarge margin fine-tuning strategy is proven to be compatible with it for\nfurther improvements. Finally, SphereFace2 also shows its strong robustness to\nclass-wise noisy labels which has the potential to be applied in the\nsemi-supervised training scenario with inaccurate estimated pseudo labels.\nCodes are available in\nhttps://github.com/Hunterhuan/sphereface2_speaker_verification", "published": "2023-07-17 02:48:04", "link": "http://arxiv.org/abs/2307.08205v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "TST: Time-Sparse Transducer for Automatic Speech Recognition", "abstract": "End-to-end model, especially Recurrent Neural Network Transducer (RNN-T), has\nachieved great success in speech recognition. However, transducer requires a\ngreat memory footprint and computing time when processing a long decoding\nsequence. To solve this problem, we propose a model named time-sparse\ntransducer, which introduces a time-sparse mechanism into transducer. In this\nmechanism, we obtain the intermediate representations by reducing the time\nresolution of the hidden states. Then the weighted average algorithm is used to\ncombine these representations into sparse hidden states followed by the\ndecoder. All the experiments are conducted on a Mandarin dataset AISHELL-1.\nCompared with RNN-T, the character error rate of the time-sparse transducer is\nclose to RNN-T and the real-time factor is 50.00% of the original. By adjusting\nthe time resolution, the time-sparse transducer can also reduce the real-time\nfactor to 16.54% of the original at the expense of a 4.94% loss of precision.", "published": "2023-07-17 08:41:11", "link": "http://arxiv.org/abs/2307.08323v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Stealthy Backdoor Attacks against Speech Recognition via\n  Elements of Sound", "abstract": "Deep neural networks (DNNs) have been widely and successfully adopted and\ndeployed in various applications of speech recognition. Recently, a few works\nrevealed that these models are vulnerable to backdoor attacks, where the\nadversaries can implant malicious prediction behaviors into victim models by\npoisoning their training process. In this paper, we revisit poison-only\nbackdoor attacks against speech recognition. We reveal that existing methods\nare not stealthy since their trigger patterns are perceptible to humans or\nmachine detection. This limitation is mostly because their trigger patterns are\nsimple noises or separable and distinctive clips. Motivated by these findings,\nwe propose to exploit elements of sound ($e.g.$, pitch and timbre) to design\nmore stealthy yet effective poison-only backdoor attacks. Specifically, we\ninsert a short-duration high-pitched signal as the trigger and increase the\npitch of remaining audio clips to `mask' it for designing stealthy pitch-based\ntriggers. We manipulate timbre features of victim audios to design the stealthy\ntimbre-based attack and design a voiceprint selection module to facilitate the\nmulti-backdoor attack. Our attacks can generate more `natural' poisoned samples\nand therefore are more stealthy. Extensive experiments are conducted on\nbenchmark datasets, which verify the effectiveness of our attacks under\ndifferent settings ($e.g.$, all-to-one, all-to-all, clean-label, physical, and\nmulti-backdoor settings) and their stealthiness. The code for reproducing main\nexperiments are available at \\url{https://github.com/HanboCai/BadSpeech_SoE}.", "published": "2023-07-17 02:58:25", "link": "http://arxiv.org/abs/2307.08208v1", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Vocoder drift compensation by x-vector alignment in speaker\n  anonymisation", "abstract": "For the most popular x-vector-based approaches to speaker anonymisation, the\nbulk of the anonymisation can stem from vocoding rather than from the core\nanonymisation function which is used to substitute an original speaker x-vector\nwith that of a fictitious pseudo-speaker. This phenomenon can impede the design\nof better anonymisation systems since there is a lack of fine-grained control\nover the x-vector space. The work reported in this paper explores the origin of\nso-called vocoder drift and shows that it is due to the mismatch between the\nsubstituted x-vector and the original representations of the linguistic\ncontent, intonation and prosody. Also reported is an original approach to\nvocoder drift compensation. While anonymisation performance degrades as\nexpected, compensation reduces vocoder drift substantially, offers improved\ncontrol over the x-vector space and lays a foundation for the design of better\nanonymisation functions in the future.", "published": "2023-07-17 11:38:35", "link": "http://arxiv.org/abs/2307.08403v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
