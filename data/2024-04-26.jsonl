{"title": "Small Language Models Need Strong Verifiers to Self-Correct Reasoning", "abstract": "Self-correction has emerged as a promising solution to boost the reasoning\nperformance of large language models (LLMs), where LLMs refine their solutions\nusing self-generated critiques that pinpoint the errors. This work explores\nwhether small (<= 13B) language models (LMs) have the ability of\nself-correction on reasoning tasks with minimal inputs from stronger LMs. We\npropose a novel pipeline that prompts smaller LMs to collect self-correction\ndata that supports the training of self-refinement abilities. First, we\nleverage correct solutions to guide the model in critiquing their incorrect\nresponses. Second, the generated critiques, after filtering, are used for\nsupervised fine-tuning of the self-correcting reasoner through solution\nrefinement. Our experimental results show improved self-correction abilities of\ntwo models on five datasets spanning math and commonsense reasoning, with\nnotable performance gains when paired with a strong GPT-4-based verifier,\nthough limitations are identified when using a weak self-verifier for\ndetermining when to correct.", "published": "2024-04-26 03:41:28", "link": "http://arxiv.org/abs/2404.17140v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantifying Memorization and Detecting Training Data of Pre-trained\n  Language Models using Japanese Newspaper", "abstract": "Dominant pre-trained language models (PLMs) have demonstrated the potential\nrisk of memorizing and outputting the training data. While this concern has\nbeen discussed mainly in English, it is also practically important to focus on\ndomain-specific PLMs. In this study, we pre-trained domain-specific GPT-2\nmodels using a limited corpus of Japanese newspaper articles and evaluated\ntheir behavior. Experiments replicated the empirical finding that memorization\nof PLMs is related to the duplication in the training data, model size, and\nprompt length, in Japanese the same as in previous English studies.\nFurthermore, we attempted membership inference attacks, demonstrating that the\ntraining data can be detected even in Japanese, which is the same trend as in\nEnglish. The study warns that domain-specific PLMs, sometimes trained with\nvaluable private data, can ''copy and paste'' on a large scale.", "published": "2024-04-26 04:12:08", "link": "http://arxiv.org/abs/2404.17143v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Unified Label-Aware Contrastive Learning Framework for Few-Shot Named\n  Entity Recognition", "abstract": "Few-shot Named Entity Recognition (NER) aims to extract named entities using\nonly a limited number of labeled examples. Existing contrastive learning\nmethods often suffer from insufficient distinguishability in context vector\nrepresentation because they either solely rely on label semantics or completely\ndisregard them. To tackle this issue, we propose a unified label-aware\ntoken-level contrastive learning framework. Our approach enriches the context\nby utilizing label semantics as suffix prompts. Additionally, it simultaneously\noptimizes context-context and context-label contrastive learning objectives to\nenhance generalized discriminative contextual representations.Extensive\nexperiments on various traditional test domains (OntoNotes, CoNLL'03, WNUT'17,\nGUM, I2B2) and the large-scale few-shot NER dataset (FEWNERD) demonstrate the\neffectiveness of our approach. It outperforms prior state-of-the-art models by\na significant margin, achieving an average absolute gain of 7% in micro F1\nscores across most scenarios. Further analysis reveals that our model benefits\nfrom its powerful transfer capability and improved contextual representations.", "published": "2024-04-26 06:19:21", "link": "http://arxiv.org/abs/2404.17178v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TIGQA:An Expert Annotated Question Answering Dataset in Tigrinya", "abstract": "The absence of explicitly tailored, accessible annotated datasets for\neducational purposes presents a notable obstacle for NLP tasks in languages\nwith limited resources.This study initially explores the feasibility of using\nmachine translation (MT) to convert an existing dataset into a Tigrinya dataset\nin SQuAD format. As a result, we present TIGQA, an expert annotated educational\ndataset consisting of 2.68K question-answer pairs covering 122 diverse topics\nsuch as climate, water, and traffic. These pairs are from 537 context\nparagraphs in publicly accessible Tigrinya and Biology books. Through\ncomprehensive analyses, we demonstrate that the TIGQA dataset requires skills\nbeyond simple word matching, requiring both single-sentence and\nmultiple-sentence inference abilities. We conduct experiments using\nstate-of-the art MRC methods, marking the first exploration of such models on\nTIGQA. Additionally, we estimate human performance on the dataset and juxtapose\nit with the results obtained from pretrained models.The notable disparities\nbetween human performance and best model performance underscore the potential\nfor further enhancements to TIGQA through continued research. Our dataset is\nfreely accessible via the provided link to encourage the research community to\naddress the challenges in the Tigrinya MRC.", "published": "2024-04-26 07:07:43", "link": "http://arxiv.org/abs/2404.17194v1", "categories": ["cs.CL", "cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompting Towards Alleviating Code-Switched Data Scarcity in\n  Under-Resourced Languages with GPT as a Pivot", "abstract": "Many multilingual communities, including numerous in Africa, frequently\nengage in code-switching during conversations. This behaviour stresses the need\nfor natural language processing technologies adept at processing code-switched\ntext. However, data scarcity, particularly in African languages, poses a\nsignificant challenge, as many are low-resourced and under-represented. In this\nstudy, we prompted GPT 3.5 to generate Afrikaans--English and Yoruba--English\ncode-switched sentences, enhancing diversity using topic-keyword pairs,\nlinguistic guidelines, and few-shot examples. Our findings indicate that the\nquality of generated sentences for languages using non-Latin scripts, like\nYoruba, is considerably lower when compared with the high Afrikaans-English\nsuccess rate. There is therefore a notable opportunity to refine prompting\nguidelines to yield sentences suitable for the fine-tuning of language models.\nWe propose a framework for augmenting the diversity of synthetically generated\ncode-switched data using GPT and propose leveraging this technology to mitigate\ndata scarcity in low-resourced languages, underscoring the essential role of\nnative speakers in this process.", "published": "2024-04-26 07:44:44", "link": "http://arxiv.org/abs/2404.17216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompting Techniques for Reducing Social Bias in LLMs through System 1\n  and System 2 Cognitive Processes", "abstract": "Dual process theory posits that human cognition arises via two systems.\nSystem 1, which is a quick, emotional, and intuitive process, which is subject\nto cognitive biases, and System 2, is a slow, onerous, and deliberate process.\nNLP researchers often compare zero-shot prompting in LLMs to System 1 reasoning\nand chain-of-thought (CoT) prompting to System 2. In line with this\ninterpretation, prior research has found that using CoT prompting in LLMs leads\nto reduced gender bias. We investigate the relationship between bias, CoT\nprompting, a debiasing prompt, and dual process theory in LLMs directly. We\ncompare zero-shot CoT, debiasing, and a variety of dual process theory-based\nprompting strategies on two bias datasets spanning nine different social bias\ncategories. We incorporate human and machine personas to determine whether the\neffects of dual process theory in LLMs exist independent of explicit persona\nmodels or are based on modeling human cognition. We find that a human persona,\ndebiasing, System 2, and CoT prompting all tend to reduce social biases in\nLLMs, though the best combination of features depends on the exact model and\nbias category -- resulting in up to a 19 percent drop in stereotypical\njudgments by an LLM.", "published": "2024-04-26 07:46:29", "link": "http://arxiv.org/abs/2404.17218v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact\n  Checking News Claims with Black-Box LLM", "abstract": "Retrieval-augmented language models have exhibited promising performance\nacross various areas of natural language processing (NLP), including\nfact-critical tasks. However, due to the black-box nature of advanced large\nlanguage models (LLMs) and the non-retrieval-oriented supervision signal of\nspecific tasks, the training of retrieval model faces significant challenges\nunder the setting of black-box LLM. We propose an approach leveraging\nFine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance\nfact-checking on news claims by using black-box LLM. FFRR adopts a two-level\nstrategy to gather fine-grained feedback from the LLM, which serves as a reward\nfor optimizing the retrieval policy, by rating the retrieved documents based on\nthe non-retrieval ground truth of the task. We evaluate our model on two public\ndatasets for real-world news claim verification, and the results demonstrate\nthat FFRR achieves significant improvements over strong LLM-enabled and non-LLM\nbaselines.", "published": "2024-04-26 09:38:27", "link": "http://arxiv.org/abs/2404.17283v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When to Trust LLMs: Aligning Confidence with Response Quality", "abstract": "Despite the success of large language models (LLMs) in natural language\ngeneration, much evidence shows that LLMs may produce incorrect or nonsensical\ntext. This limitation highlights the importance of discerning when to trust\nLLMs, especially in safety-critical domains. Existing methods often express\nreliability by confidence level, however, their effectiveness is limited by the\nlack of objective guidance. To address this, we propose\nCONfidence-Quality-ORDer-preserving alignment approach (CONQORD), which\nleverages reinforcement learning guided by a tailored dual-component reward\nfunction. This function integrates quality reward and order-preserving\nalignment reward functions. Specifically, the order-preserving reward\nincentivizes the model to verbalize greater confidence for responses of higher\nquality to align the order of confidence and quality. Experiments demonstrate\nthat CONQORD significantly improves the alignment performance between\nconfidence and response accuracy, without causing over-cautious. Furthermore,\nthe aligned confidence provided by CONQORD informs when to trust LLMs, and acts\nas a determinant for initiating the retrieval process of external knowledge.\nAligning confidence with response quality ensures more transparent and reliable\nresponses, providing better trustworthiness.", "published": "2024-04-26 09:42:46", "link": "http://arxiv.org/abs/2404.17287v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metronome: tracing variation in poetic meters via local sequence\n  alignment", "abstract": "All poetic forms come from somewhere. Prosodic templates can be copied for\ngenerations, altered by individuals, imported from foreign traditions, or\nfundamentally changed under the pressures of language evolution. Yet these\nrelationships are notoriously difficult to trace across languages and times.\nThis paper introduces an unsupervised method for detecting structural\nsimilarities in poems using local sequence alignment. The method relies on\nencoding poetic texts as strings of prosodic features using a four-letter\nalphabet; these sequences are then aligned to derive a distance measure based\non weighted symbol (mis)matches. Local alignment allows poems to be clustered\naccording to emergent properties of their underlying prosodic patterns. We\nevaluate method performance on a meter recognition tasks against strong\nbaselines and show its potential for cross-lingual and historical research\nusing three short case studies: 1) mutations in quantitative meter in classical\nLatin, 2) European diffusion of the Renaissance hendecasyllable, and 3)\ncomparative alignment of modern meters in 18--19th century Czech, German and\nRussian. We release an implementation of the algorithm as a Python package with\nan open license.", "published": "2024-04-26 11:37:45", "link": "http://arxiv.org/abs/2404.17337v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation of Geographical Distortions in Language Models: A Crucial\n  Step Towards Equitable Representations", "abstract": "Language models now constitute essential tools for improving efficiency for\nmany professional tasks such as writing, coding, or learning. For this reason,\nit is imperative to identify inherent biases. In the field of Natural Language\nProcessing, five sources of bias are well-identified: data, annotation,\nrepresentation, models, and research design. This study focuses on biases\nrelated to geographical knowledge. We explore the connection between geography\nand language models by highlighting their tendency to misrepresent spatial\ninformation, thus leading to distortions in the representation of geographical\ndistances. This study introduces four indicators to assess these distortions,\nby comparing geographical and semantic distances. Experiments are conducted\nfrom these four indicators with ten widely used language models. Results\nunderscore the critical necessity of inspecting and rectifying spatial biases\nin language models to ensure accurate and equitable representations.", "published": "2024-04-26 13:22:28", "link": "http://arxiv.org/abs/2404.17401v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ruffle&Riley: Insights from Designing and Evaluating a Large Language\n  Model-Based Conversational Tutoring System", "abstract": "Conversational tutoring systems (CTSs) offer learning experiences through\ninteractions based on natural language. They are recognized for promoting\ncognitive engagement and improving learning outcomes, especially in reasoning\ntasks. Nonetheless, the cost associated with authoring CTS content is a major\nobstacle to widespread adoption and to research on effective instructional\ndesign. In this paper, we discuss and evaluate a novel type of CTS that\nleverages recent advances in large language models (LLMs) in two ways: First,\nthe system enables AI-assisted content authoring by inducing an easily editable\ntutoring script automatically from a lesson text. Second, the system automates\nthe script orchestration in a learning-by-teaching format via two LLM-based\nagents (Ruffle&Riley) acting as a student and a professor. The system allows\nfor free-form conversations that follow the ITS-typical inner and outer loop\nstructure. We evaluate Ruffle&Riley's ability to support biology lessons in two\nbetween-subject online user studies (N = 200) comparing the system to simpler\nQA chatbots and reading activity. Analyzing system usage patterns,\npre/post-test scores and user experience surveys, we find that Ruffle&Riley\nusers report high levels of engagement, understanding and perceive the offered\nsupport as helpful. Even though Ruffle&Riley users require more time to\ncomplete the activity, we did not find significant differences in short-term\nlearning gains over the reading activity. Our system architecture and user\nstudy provide various insights for designers of future CTSs. We further\nopen-source our system to support ongoing research on effective instructional\ndesign of LLM-based learning technologies.", "published": "2024-04-26 14:57:55", "link": "http://arxiv.org/abs/2404.17460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReproHum #0087-01: Human Evaluation Reproduction Report for Generating\n  Fact Checking Explanations", "abstract": "This paper presents a partial reproduction of Generating Fact Checking\nExplanations by Anatanasova et al (2020) as part of the ReproHum element of the\nReproNLP shared task to reproduce the findings of NLP research regarding human\nevaluation. This shared task aims to investigate the extent to which NLP as a\nfield is becoming more or less reproducible over time. Following the\ninstructions provided by the task organisers and the original authors, we\ncollect relative rankings of 3 fact-checking explanations (comprising a gold\nstandard and the outputs of 2 models) for 40 inputs on the criteria of\nCoverage. The results of our reproduction and reanalysis of the original work's\nraw results lend support to the original findings, with similar patterns seen\nbetween the original work and our reproduction. Whilst we observe slight\nvariation from the original results, our findings support the main conclusions\ndrawn by the original authors pertaining to the efficacy of their proposed\nmodels.", "published": "2024-04-26 15:31:25", "link": "http://arxiv.org/abs/2404.17481v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Questioning the Unknown: Optimising Multi-Agent Collaboration in\n  Narrative-Driven Games", "abstract": "We present Questum, a novel framework for Large Language Model (LLM)-based\nagents in Murder Mystery Games (MMGs). MMGs pose unique challenges, including\nundefined state spaces, absent intermediate rewards, and the need for strategic\ninteraction in a continuous language domain. Questum addresses these\ncomplexities through a sensor-based representation of agent states, a\nquestion-targeting mechanism guided by information gain, and a pruning strategy\nto refine suspect lists and enhance decision-making efficiency. To enable\nsystematic evaluation, we propose WellPlay, a dataset comprising 1,482\ninferential questions across 12 games, categorised into objectives, reasoning,\nand relationships. Experiments demonstrate Questum's capacity to achieve\nsuperior performance in reasoning accuracy and efficiency compared to existing\napproaches, while also significantly improving the quality of agent-human\ninteractions in MMGs. This study advances the development of reasoning agents\nfor complex social and interactive scenarios.", "published": "2024-04-26 19:07:30", "link": "http://arxiv.org/abs/2404.17662v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for\n  Complex Problem Solving", "abstract": "Large Language Models (LLMs) have shown great ability in solving traditional\nnatural language tasks and elementary reasoning tasks with appropriate\nprompting techniques. However, their ability is still limited in solving\ncomplicated science problems. In this work, we aim to push the upper bound of\nthe reasoning capability of LLMs by proposing a collaborative multi-agent,\nmulti-reasoning-path (CoMM) prompting framework. Specifically, we prompt LLMs\nto play different roles in a problem-solving team, and encourage different\nrole-play agents to collaboratively solve the target task. In particular, we\ndiscover that applying different reasoning paths for different roles is an\neffective strategy to implement few-shot prompting approaches in the\nmulti-agent scenarios. Empirical results demonstrate the effectiveness of the\nproposed methods on two college-level science problems over competitive\nbaselines. Our further analysis shows the necessity of prompting LLMs to play\ndifferent roles or experts independently. We release the code at:\nhttps://github.com/amazon-science/comm-prompt", "published": "2024-04-26 23:29:12", "link": "http://arxiv.org/abs/2404.17729v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "2M-NER: Contrastive Learning for Multilingual and Multimodal NER with\n  Language and Modal Fusion", "abstract": "Named entity recognition (NER) is a fundamental task in natural language\nprocessing that involves identifying and classifying entities in sentences into\npre-defined types. It plays a crucial role in various research fields,\nincluding entity linking, question answering, and online product\nrecommendation. Recent studies have shown that incorporating multilingual and\nmultimodal datasets can enhance the effectiveness of NER. This is due to\nlanguage transfer learning and the presence of shared implicit features across\ndifferent modalities. However, the lack of a dataset that combines\nmultilingualism and multimodality has hindered research exploring the\ncombination of these two aspects, as multimodality can help NER in multiple\nlanguages simultaneously. In this paper, we aim to address a more challenging\ntask: multilingual and multimodal named entity recognition (MMNER), considering\nits potential value and influence. Specifically, we construct a large-scale\nMMNER dataset with four languages (English, French, German and Spanish) and two\nmodalities (text and image). To tackle this challenging MMNER task on the\ndataset, we introduce a new model called 2M-NER, which aligns the text and\nimage representations using contrastive learning and integrates a multimodal\ncollaboration module to effectively depict the interactions between the two\nmodalities. Extensive experimental results demonstrate that our model achieves\nthe highest F1 score in multilingual and multimodal NER tasks compared to some\ncomparative and representative baselines. Additionally, in a challenging\nanalysis, we discovered that sentence-level alignment interferes a lot with NER\nmodels, indicating the higher level of difficulty in our dataset.", "published": "2024-04-26 02:34:31", "link": "http://arxiv.org/abs/2404.17122v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Text Sentiment Analysis and Classification Based on Bidirectional Gated\n  Recurrent Units (GRUs) Model", "abstract": "This paper explores the importance of text sentiment analysis and\nclassification in the field of natural language processing, and proposes a new\napproach to sentiment analysis and classification based on the bidirectional\ngated recurrent units (GRUs) model. The study firstly analyses the word cloud\nmodel of the text with six sentiment labels, and then carries out data\npreprocessing, including the steps of removing special symbols, punctuation\nmarks, numbers, stop words and non-alphabetic parts. Subsequently, the data set\nis divided into training set and test set, and through model training and\ntesting, it is found that the accuracy of the validation set is increased from\n85% to 93% with training, which is an increase of 8%; at the same time, the\nloss value of the validation set decreases from 0.7 to 0.1 and tends to be\nstable, and the model is gradually close to the actual value, which can\neffectively classify the text emotions. The confusion matrix shows that the\naccuracy of the model on the test set reaches 94.8%, the precision is 95.9%,\nthe recall is 99.1%, and the F1 score is 97.4%, which proves that the model has\ngood generalisation ability and classification effect. Overall, the study\ndemonstrated an effective method for text sentiment analysis and classification\nwith satisfactory results.", "published": "2024-04-26 02:40:03", "link": "http://arxiv.org/abs/2404.17123v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety\n  using Zero Shot Classification: An Observational Study", "abstract": "Social anxiety represents a prevalent challenge in modern society, affecting\nindividuals across personal and professional spheres. Left unaddressed, this\ncondition can yield substantial negative consequences, impacting social\ninteractions and performance. Further understanding its diverse physical and\nemotional symptoms becomes pivotal for comprehensive diagnosis and tailored\ntherapeutic interventions. This study analyze prevalence and frequency of\nsocial anxiety symptoms taken from Mayo Clinic, exploring diverse human\nexperiences from utilizing a large Reddit dataset dedicated to this issue.\nLeveraging these platforms, the research aims to extract insights and examine a\nspectrum of physical and emotional symptoms linked to social anxiety disorder.\nUpholding ethical considerations, the study maintains strict user anonymity\nwithin the dataset. By employing a novel approach, the research utilizes\nBART-based multi-label zero-shot classification to identify and measure symptom\nprevalence and significance in the form of probability score for each symptom\nunder consideration. Results uncover distinctive patterns: \"Trembling\" emerges\nas a prevalent physical symptom, while emotional symptoms like \"Fear of being\njudged negatively\" exhibit high frequencies. These findings offer insights into\nthe multifaceted nature of social anxiety, aiding clinical practices and\ninterventions tailored to its diverse expressions.", "published": "2024-04-26 06:28:51", "link": "http://arxiv.org/abs/2404.17183v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Introducing cosmosGPT: Monolingual Training for Turkish Language Models", "abstract": "The number of open source language models that can produce Turkish is\nincreasing day by day, as in other languages. In order to create the basic\nversions of such models, the training of multilingual models is usually\ncontinued with Turkish corpora. The alternative is to train the model with only\nTurkish corpora. In this study, we first introduce the cosmosGPT models that we\ncreated with this alternative method. Then, we introduce new finetune datasets\nfor basic language models to fulfill user requests and new evaluation datasets\nfor measuring the capabilities of Turkish language models. Finally, a\ncomprehensive comparison of the adapted Turkish language models on different\ncapabilities is presented. The results show that the language models we built\nwith the monolingual corpus have promising performance despite being about 10\ntimes smaller than the others.", "published": "2024-04-26 11:34:11", "link": "http://arxiv.org/abs/2404.17336v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Multiple-Choice to Extractive QA: A Case Study for English and\n  Arabic", "abstract": "The rapid evolution of Natural Language Processing (NLP) has favoured major\nlanguages such as English, leaving a significant gap for many others due to\nlimited resources. This is especially evident in the context of data\nannotation, a task whose importance cannot be underestimated, but which is\ntime-consuming and costly. Thus, any dataset for resource-poor languages is\nprecious, in particular when it is task-specific. Here, we explore the\nfeasibility of repurposing an existing multilingual dataset for a new NLP task:\nwe repurpose a subset of the BELEBELE dataset (Bandarkar et al., 2023), which\nwas designed for multiple-choice question answering (MCQA), to enable the more\npractical task of extractive QA (EQA) in the style of machine reading\ncomprehension. We present annotation guidelines and a parallel EQA dataset for\nEnglish and Modern Standard Arabic (MSA). We also present QA evaluation results\nfor several monolingual and cross-lingual QA pairs including English, MSA, and\nfive Arabic dialects. We aim to help others adapt our approach for the\nremaining 120 BELEBELE language variants, many of which are deemed\nunder-resourced. We also provide a thorough analysis and share insights to\ndeepen understanding of the challenges and opportunities in NLP task\nreformulation.", "published": "2024-04-26 11:46:05", "link": "http://arxiv.org/abs/2404.17342v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Bionic Natural Language Parser Equivalent to a Pushdown Automaton", "abstract": "Assembly Calculus (AC), proposed by Papadimitriou et al., aims to reproduce\nadvanced cognitive functions through simulating neural activities, with several\napplications based on AC having been developed, including a natural language\nparser proposed by Mitropolsky et al. However, this parser lacks the ability to\nhandle Kleene closures, preventing it from parsing all regular languages and\nrendering it weaker than Finite Automata (FA). In this paper, we propose a new\nbionic natural language parser (BNLP) based on AC and integrates two new\nbiologically rational structures, Recurrent Circuit and Stack Circuit which are\ninspired by RNN and short-term memory mechanism. In contrast to the original\nparser, the BNLP can fully handle all regular languages and Dyck languages.\nTherefore, leveraging the Chomsky-Sch \\H{u}tzenberger theorem, the BNLP which\ncan parse all Context-Free Languages can be constructed. We also formally prove\nthat for any PDA, a Parser Automaton corresponding to BNLP can always be\nformed, ensuring that BNLP has a description ability equal to that of PDA and\naddressing the deficiencies of the original parser.", "published": "2024-04-26 11:50:15", "link": "http://arxiv.org/abs/2404.17343v1", "categories": ["cs.CL", "cs.FL"], "primary_category": "cs.CL"}
{"title": "CEval: A Benchmark for Evaluating Counterfactual Text Generation", "abstract": "Counterfactual text generation aims to minimally change a text, such that it\nis classified differently. Judging advancements in method development for\ncounterfactual text generation is hindered by a non-uniform usage of data sets\nand metrics in related work. We propose CEval, a benchmark for comparing\ncounterfactual text generation methods. CEval unifies counterfactual and text\nquality metrics, includes common counterfactual datasets with human\nannotations, standard baselines (MICE, GDBA, CREST) and the open-source\nlanguage model LLAMA-2. Our experiments found no perfect method for generating\ncounterfactual text. Methods that excel at counterfactual metrics often produce\nlower-quality text while LLMs with simple prompts generate high-quality text\nbut struggle with counterfactual criteria. By making CEval available as an\nopen-source Python library, we encourage the community to contribute more\nmethods and maintain consistent evaluation in future work.", "published": "2024-04-26 15:23:47", "link": "http://arxiv.org/abs/2404.17475v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Evaluation on Event Reasoning of Large Language Models", "abstract": "Event reasoning is a fundamental ability that underlies many applications. It\nrequires event schema knowledge to perform global reasoning and needs to deal\nwith the diversity of the inter-event relations and the reasoning paradigms.\nHow well LLMs accomplish event reasoning on various relations and reasoning\nparadigms remains unknown. To mitigate this disparity, we comprehensively\nevaluate the abilities of event reasoning of LLMs. We introduce a novel\nbenchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of\nevaluation of schema and instance and is comprehensive in relations and\nreasoning paradigms. We conduct extensive experiments on EV2. We find that LLMs\nhave abilities to accomplish event reasoning but their performances are far\nfrom satisfactory. We also notice the imbalance of event reasoning abilities in\nLLMs. Besides, LLMs have event schema knowledge, however, they're not aligned\nwith humans on how to utilize the knowledge. Based on these findings, we guide\nthe LLMs in utilizing the event schema knowledge as memory leading to\nimprovements on event reasoning.", "published": "2024-04-26 16:28:34", "link": "http://arxiv.org/abs/2404.17513v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Use of Large Language Models to Generate Capability Ontologies", "abstract": "Capability ontologies are increasingly used to model functionalities of\nsystems or machines. The creation of such ontological models with all\nproperties and constraints of capabilities is very complex and can only be done\nby ontology experts. However, Large Language Models (LLMs) have shown that they\ncan generate machine-interpretable models from natural language text input and\nthus support engineers / ontology experts. Therefore, this paper investigates\nhow LLMs can be used to create capability ontologies. We present a study with a\nseries of experiments in which capabilities with varying complexities are\ngenerated using different prompting techniques and with different LLMs. Errors\nin the generated ontologies are recorded and compared. To analyze the quality\nof the generated ontologies, a semi-automated approach based on RDF syntax\nchecking, OWL reasoning, and SHACL constraints is used. The results of this\nstudy are very promising because even for complex capabilities, the generated\nontologies are almost free of errors.", "published": "2024-04-26 16:41:00", "link": "http://arxiv.org/abs/2404.17524v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Empowering Large Language Models for Textual Data Augmentation", "abstract": "With the capabilities of understanding and executing natural language\ninstructions, Large language models (LLMs) can potentially act as a powerful\ntool for textual data augmentation. However, the quality of augmented data\ndepends heavily on the augmentation instructions provided, and the\neffectiveness can fluctuate across different downstream tasks. While manually\ncrafting and selecting instructions can offer some improvement, this approach\nfaces scalability and consistency issues in practice due to the diversity of\ndownstream tasks. In this work, we address these limitations by proposing a new\nsolution, which can automatically generate a large pool of augmentation\ninstructions and select the most suitable task-informed instructions, thereby\nempowering LLMs to create high-quality augmented data for different downstream\ntasks. Empirically, the proposed approach consistently generates augmented data\nwith better quality compared to non-LLM and LLM-based data augmentation\nmethods, leading to the best performance on 26 few-shot learning tasks sourced\nfrom a wide range of application domains.", "published": "2024-04-26 18:04:25", "link": "http://arxiv.org/abs/2404.17642v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bridging the Social & Technical Divide in Augmentative and Alternative\n  Communication (AAC) Applications for Autistic Adults", "abstract": "Natural Language Processing (NLP) techniques are being used more frequently\nto improve high-tech Augmentative and Alternative Communication (AAC), but many\nof these techniques are integrated without the inclusion of the users'\nperspectives. Autistic adults are particularly neglected in the design of AAC\ntools. We conducted in-depth interviews with 12 autistic adults to find the\npain points of current AAC and determine what technological advances they might\nfind helpful. We found that in addition to technological issues, there are many\nsocietal issues as well. We found 9 different categories of themes from our\ninterviews: input flexibility, output flexibility, selecting or adapting AAC\nfor a good fit, when to start or swap AAC, benefits, access as an adult,\nstumbling blocks for continued use, social concerns, and control of\ncommunication. In this paper, we go through these categories in depth and then\nsuggest possible guidelines for developers, NLP researchers, and policy makers.", "published": "2024-04-26 23:30:07", "link": "http://arxiv.org/abs/2404.17730v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive\n  Study", "abstract": "As NLP models become more complex, understanding their decisions becomes more\ncrucial. Counterfactuals (CFs), where minimal changes to inputs flip a model's\nprediction, offer a way to explain these models. While Large Language Models\n(LLMs) have shown remarkable performance in NLP tasks, their efficacy in\ngenerating high-quality CFs remains uncertain. This work fills this gap by\ninvestigating how well LLMs generate CFs for two NLU tasks. We conduct a\ncomprehensive comparison of several common LLMs, and evaluate their CFs,\nassessing both intrinsic metrics, and the impact of these CFs on data\naugmentation. Moreover, we analyze differences between human and LLM-generated\nCFs, providing insights for future research directions. Our results show that\nLLMs generate fluent CFs, but struggle to keep the induced changes minimal.\nGenerating CFs for Sentiment Analysis (SA) is less challenging than NLI where\nLLMs show weaknesses in generating CFs that flip the original label. This also\nreflects on the data augmentation performance, where we observe a large gap\nbetween augmenting with human and LLMs CFs. Furthermore, we evaluate LLMs'\nability to assess CFs in a mislabelled data setting, and show that they have a\nstrong bias towards agreeing with the provided labels. GPT4 is more robust\nagainst this bias and its scores correlate well with automatic metrics. Our\nfindings reveal several limitations and point to potential future work\ndirections.", "published": "2024-04-26 11:57:21", "link": "http://arxiv.org/abs/2405.00722v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HateTinyLLM : Hate Speech Detection Using Tiny Large Language Models", "abstract": "Hate speech encompasses verbal, written, or behavioral communication that\ntargets derogatory or discriminatory language against individuals or groups\nbased on sensitive characteristics. Automated hate speech detection plays a\ncrucial role in curbing its propagation, especially across social media\nplatforms. Various methods, including recent advancements in deep learning,\nhave been devised to address this challenge. In this study, we introduce\nHateTinyLLM, a novel framework based on fine-tuned decoder-only tiny large\nlanguage models (tinyLLMs) for efficient hate speech detection. Our\nexperimental findings demonstrate that the fine-tuned HateTinyLLM outperforms\nthe pretrained mixtral-7b model by a significant margin. We explored various\ntiny LLMs, including PY007/TinyLlama-1.1B-step-50K-105b, Microsoft/phi-2, and\nfacebook/opt-1.3b, and fine-tuned them using LoRA and adapter methods. Our\nobservations indicate that all LoRA-based fine-tuned models achieved over 80\\%\naccuracy.", "published": "2024-04-26 05:29:35", "link": "http://arxiv.org/abs/2405.01577v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Mercurial Top-Level Ontology of Large Language Models", "abstract": "In our work, we systematize and analyze implicit ontological commitments in\nthe responses generated by large language models (LLMs), focusing on ChatGPT\n3.5 as a case study. We investigate how LLMs, despite having no explicit\nontology, exhibit implicit ontological categorizations that are reflected in\nthe texts they generate. The paper proposes an approach to understanding the\nontological commitments of LLMs by defining ontology as a theory that provides\na systematic account of the ontological commitments of some text. We\ninvestigate the ontological assumptions of ChatGPT and present a systematized\naccount, i.e., GPT's top-level ontology. This includes a taxonomy, which is\navailable as an OWL file, as well as a discussion about ontological assumptions\n(e.g., about its mereology or presentism). We show that in some aspects GPT's\ntop-level ontology is quite similar to existing top-level ontologies. However,\nthere are significant challenges arising from the flexible nature of\nLLM-generated texts, including ontological overload, ambiguity, and\ninconsistency.", "published": "2024-04-26 16:52:32", "link": "http://arxiv.org/abs/2405.01581v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Talking Nonsense: Probing Large Language Models' Understanding of\n  Adversarial Gibberish Inputs", "abstract": "Large language models (LLMs) exhibit excellent ability to understand human\nlanguages, but do they also understand their own language that appears\ngibberish to us? In this work we delve into this question, aiming to uncover\nthe mechanisms underlying such behavior in LLMs. We employ the Greedy\nCoordinate Gradient optimizer to craft prompts that compel LLMs to generate\ncoherent responses from seemingly nonsensical inputs. We call these inputs LM\nBabel and this work systematically studies the behavior of LLMs manipulated by\nthese prompts. We find that the manipulation efficiency depends on the target\ntext's length and perplexity, with the Babel prompts often located in lower\nloss minima compared to natural prompts. We further examine the structure of\nthe Babel prompts and evaluate their robustness. Notably, we find that guiding\nthe model to generate harmful texts is not more difficult than into generating\nbenign texts, suggesting lack of alignment for out-of-distribution prompts.", "published": "2024-04-26 02:29:26", "link": "http://arxiv.org/abs/2404.17120v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automated Data Visualization from Natural Language via Large Language\n  Models: An Exploratory Study", "abstract": "The Natural Language to Visualization (NL2Vis) task aims to transform\nnatural-language descriptions into visual representations for a grounded table,\nenabling users to gain insights from vast amounts of data. Recently, many deep\nlearning-based approaches have been developed for NL2Vis. Despite the\nconsiderable efforts made by these approaches, challenges persist in\nvisualizing data sourced from unseen databases or spanning multiple tables.\nTaking inspiration from the remarkable generation capabilities of Large\nLanguage Models (LLMs), this paper conducts an empirical study to evaluate\ntheir potential in generating visualizations, and explore the effectiveness of\nin-context learning prompts for enhancing this task. In particular, we first\nexplore the ways of transforming structured tabular data into sequential text\nprompts, as to feed them into LLMs and analyze which table content contributes\nmost to the NL2Vis. Our findings suggest that transforming structured tabular\ndata into programs is effective, and it is essential to consider the table\nschema when formulating prompts. Furthermore, we evaluate two types of LLMs:\nfinetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5),\nagainst state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench).\nThe experimental results reveal that LLMs outperform baselines, with\ninference-only models consistently exhibiting performance improvements, at\ntimes even surpassing fine-tuned models when provided with certain few-shot\ndemonstrations through in-context learning. Finally, we analyze when the LLMs\nfail in NL2Vis, and propose to iteratively update the results using strategies\nsuch as chain-of-thought, role-playing, and code-interpreter. The experimental\nresults confirm the efficacy of iterative updates and hold great potential for\nfuture study.", "published": "2024-04-26 03:25:35", "link": "http://arxiv.org/abs/2404.17136v1", "categories": ["cs.DB", "cs.AI", "cs.CL"], "primary_category": "cs.DB"}
{"title": "Child Speech Recognition in Human-Robot Interaction: Problem Solved?", "abstract": "Automated Speech Recognition shows superhuman performance for adult English\nspeech on a range of benchmarks, but disappoints when fed children's speech.\nThis has long sat in the way of child-robot interaction. Recent evolutions in\ndata-driven speech recognition, including the availability of Transformer\narchitectures and unprecedented volumes of training data, might mean a\nbreakthrough for child speech recognition and social robot applications aimed\nat children. We revisit a study on child speech recognition from 2017 and show\nthat indeed performance has increased, with newcomer OpenAI Whisper doing\nmarkedly better than leading commercial cloud services. Performance improves\neven more in highly structured interactions when priming models with specific\nphrases. While transcription is not perfect yet, the best model recognises\n60.3% of sentences correctly barring small grammatical differences, with\nsub-second transcription time running on a local GPU, showing potential for\nusable autonomous child-robot speech interactions.", "published": "2024-04-26 13:14:28", "link": "http://arxiv.org/abs/2404.17394v2", "categories": ["cs.CL", "cs.HC", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Large Language Model Agent as a Mechanical Designer", "abstract": "Conventional mechanical design paradigms rely on experts systematically\nrefining concepts through experience-guided modification and FEA to meet\nspecific requirements. However, this approach can be time-consuming and heavily\ndependent on prior knowledge and experience. While numerous machine learning\nmodels have been developed to streamline this intensive and expert-driven\niterative process, these methods typically demand extensive training data and\nconsiderable computational resources. Furthermore, methods based on deep\nlearning are usually restricted to the specific domains and tasks for which\nthey were trained, limiting their applicability across different tasks. This\ncreates a trade-off between the efficiency of automation and the demand for\nresources. In this study, we present a novel approach that integrates\npre-trained LLMs with a FEM module. The FEM module evaluates each design and\nprovides essential feedback, guiding the LLMs to continuously learn, plan,\ngenerate, and optimize designs without the need for domain-specific training.\nWe demonstrate the effectiveness of our proposed framework in managing the\niterative optimization of truss structures, showcasing its capability to reason\nabout and refine designs according to structured feedback and criteria. Our\nresults reveal that these LLM-based agents can successfully generate truss\ndesigns that comply with natural language specifications with a success rate of\nup to 90%, which varies according to the applied constraints. By employing\nprompt-based optimization techniques we show that LLM based agents exhibit\noptimization behavior when provided with solution-score pairs to iteratively\nrefine designs to meet specifications. This ability of LLM agents to produce\nviable designs and optimize them based on their inherent reasoning capabilities\nhighlights their potential to develop and implement effective design strategies\nautonomously.", "published": "2024-04-26 16:41:24", "link": "http://arxiv.org/abs/2404.17525v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Probabilistic Inference in Language Models via Twisted Sequential Monte\n  Carlo", "abstract": "Numerous capability and safety techniques of Large Language Models (LLMs),\nincluding RLHF, automated red-teaming, prompt engineering, and infilling, can\nbe cast as sampling from an unnormalized target distribution defined by a given\nreward or potential function over the full sequence. In this work, we leverage\nthe rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic\ninference problems. In particular, we use learned twist functions to estimate\nthe expected future value of the potential at each timestep, which enables us\nto focus inference-time computation on promising partial sequences. We propose\na novel contrastive method for learning the twist functions, and establish\nconnections with the rich literature of soft reinforcement learning. As a\ncomplementary application of our twisted SMC framework, we present methods for\nevaluating the accuracy of language model inference techniques using novel\nbidirectional SMC bounds on the log partition function. These bounds can be\nused to estimate the KL divergence between the inference and target\ndistributions in both directions. We apply our inference evaluation techniques\nto show that twisted SMC is effective for sampling undesirable outputs from a\npretrained model (a useful component of harmlessness training and automated\nred-teaming), generating reviews with varied sentiment, and performing\ninfilling tasks.", "published": "2024-04-26 17:18:32", "link": "http://arxiv.org/abs/2404.17546v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CoSD: Collaborative Stance Detection with Contrastive Heterogeneous\n  Topic Graph Learning", "abstract": "Stance detection seeks to identify the viewpoints of individuals either in\nfavor or against a given target or a controversial topic. Current advanced\nneural models for stance detection typically employ fully parametric softmax\nclassifiers. However, these methods suffer from several limitations, including\nlack of explainability, insensitivity to the latent data structure, and\nunimodality, which greatly restrict their performance and applications. To\naddress these challenges, we present a novel collaborative stance detection\nframework called (CoSD) which leverages contrastive heterogeneous topic graph\nlearning to learn topic-aware semantics and collaborative signals among texts,\ntopics, and stance labels for enhancing stance detection. During training, we\nconstruct a heterogeneous graph to structurally organize texts and stances\nthrough implicit topics via employing latent Dirichlet allocation. We then\nperform contrastive graph learning to learn heterogeneous node representations,\naggregating informative multi-hop collaborative signals via an elaborate\nCollaboration Propagation Aggregation (CPA) module. During inference, we\nintroduce a hybrid similarity scoring module to enable the comprehensive\nincorporation of topic-aware semantics and collaborative signals for stance\ndetection. Extensive experiments on two benchmark datasets demonstrate the\nstate-of-the-art detection performance of CoSD, verifying the effectiveness and\nexplainability of our collaborative framework.", "published": "2024-04-26 02:04:05", "link": "http://arxiv.org/abs/2404.17609v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Retrieval-Augmented Generation with Knowledge Graphs for Customer\n  Service Question Answering", "abstract": "In customer service technical support, swiftly and accurately retrieving\nrelevant past issues is critical for efficiently resolving customer inquiries.\nThe conventional retrieval methods in retrieval-augmented generation (RAG) for\nlarge language models (LLMs) treat a large corpus of past issue tracking\ntickets as plain text, ignoring the crucial intra-issue structure and\ninter-issue relations, which limits performance. We introduce a novel customer\nservice question-answering method that amalgamates RAG with a knowledge graph\n(KG). Our method constructs a KG from historical issues for use in retrieval,\nretaining the intra-issue structure and inter-issue relations. During the\nquestion-answering phase, our method parses consumer queries and retrieves\nrelated sub-graphs from the KG to generate answers. This integration of a KG\nnot only improves retrieval accuracy by preserving customer service structure\ninformation but also enhances answering quality by mitigating the effects of\ntext segmentation. Empirical assessments on our benchmark datasets, utilizing\nkey retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR)\nmetrics, reveal that our method outperforms the baseline by 77.6% in MRR and by\n0.32 in BLEU. Our method has been deployed within LinkedIn's customer service\nteam for approximately six months and has reduced the median per-issue\nresolution time by 28.6%.", "published": "2024-04-26 23:05:20", "link": "http://arxiv.org/abs/2404.17723v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "I.2"], "primary_category": "cs.IR"}
{"title": "Text Quality-Based Pruning for Efficient Training of Language Models", "abstract": "In recent times training Language Models (LMs) have relied on computationally\nheavy training over massive datasets which makes this training process\nextremely laborious. In this paper we propose a novel method for numerically\nevaluating text quality in large unlabelled NLP datasets in a model agnostic\nmanner to assign the text instances a \"quality score\".\n  By proposing the text quality metric, the paper establishes a framework to\nidentify and eliminate low-quality text instances, leading to improved training\nefficiency for LM models. Experimental results over multiple models and\ndatasets demonstrate the efficacy of this approach, showcasing substantial\ngains in training effectiveness and highlighting the potential for\nresource-efficient LM training.\n  For example, we observe an absolute accuracy improvement of 0.9% averaged\nover 14 downstream evaluation tasks for multiple LM models while using 40%\nlesser data and training 42% faster when training on the OpenWebText dataset\nand 0.8% average absolute accuracy improvement while using 20% lesser data and\ntraining 21% faster on the Wikipedia dataset.", "published": "2024-04-26 18:01:25", "link": "http://arxiv.org/abs/2405.01582v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speech Technology Services for Oral History Research", "abstract": "Oral history is about oral sources of witnesses and commentors on historical\nevents. Speech technology is an important instrument to process such recordings\nin order to obtain transcription and further enhancements to structure the oral\naccount In this contribution we address the transcription portal and the\nwebservices associated with speech processing at BAS, speech solutions\ndeveloped at LINDAT, how to do it yourself with Whisper, remaining challenges,\nand future developments.", "published": "2024-04-26 09:44:26", "link": "http://arxiv.org/abs/2405.02333v1", "categories": ["cs.SD", "cs.CL", "eess.AS", "J.5"], "primary_category": "cs.SD"}
{"title": "Language Interaction Network for Clinical Trial Approval Estimation", "abstract": "Clinical trial outcome prediction seeks to estimate the likelihood that a\nclinical trial will successfully reach its intended endpoint. This process\npredominantly involves the development of machine learning models that utilize\na variety of data sources such as descriptions of the clinical trials,\ncharacteristics of the drug molecules, and specific disease conditions being\ntargeted. Accurate predictions of trial outcomes are crucial for optimizing\ntrial planning and prioritizing investments in a drug portfolio. While previous\nresearch has largely concentrated on small-molecule drugs, there is a growing\nneed to focus on biologics-a rapidly expanding category of therapeutic agents\nthat often lack the well-defined molecular properties associated with\ntraditional drugs. Additionally, applying conventional methods like graph\nneural networks to biologics data proves challenging due to their complex\nnature. To address these challenges, we introduce the Language Interaction\nNetwork (LINT), a novel approach that predicts trial outcomes using only the\nfree-text descriptions of the trials. We have rigorously tested the\neffectiveness of LINT across three phases of clinical trials, where it achieved\nROC-AUC scores of 0.770, 0.740, and 0.748 for phases I, II, and III,\nrespectively, specifically concerning trials involving biologic interventions.", "published": "2024-04-26 14:50:59", "link": "http://arxiv.org/abs/2405.06662v1", "categories": ["q-bio.BM", "cs.CL", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "A Semi-Automatic Approach to Create Large Gender- and Age-Balanced\n  Speaker Corpora: Usefulness of Speaker Diarization & Identification", "abstract": "This paper presents a semi-automatic approach to create a diachronic corpus\nof voices balanced for speaker's age, gender, and recording period, according\nto 32 categories (2 genders, 4 age ranges and 4 recording periods). Corpora\nwere selected at French National Institute of Audiovisual (INA) to obtain at\nleast 30 speakers per category (a total of 960 speakers; only 874 have be found\nyet). For each speaker, speech excerpts were extracted from audiovisual\ndocuments using an automatic pipeline consisting of speech detection,\nbackground music and overlapped speech removal and speaker diarization, used to\npresent clean speaker segments to human annotators identifying target speakers.\nThis pipeline proved highly effective, cutting down manual processing by a\nfactor of ten. Evaluation of the quality of the automatic processing and of the\nfinal output is provided. It shows the automatic processing compare to\nup-to-date process, and that the output provides high quality speech for most\nof the selected excerpts. This method shows promise for creating large corpora\nof known target speakers.", "published": "2024-04-26 17:30:36", "link": "http://arxiv.org/abs/2404.17552v1", "categories": ["eess.AS", "cs.CL", "cs.DL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Exploring Pre-trained General-purpose Audio Representations for Heart\n  Murmur Detection", "abstract": "To reduce the need for skilled clinicians in heart sound interpretation,\nrecent studies on automating cardiac auscultation have explored deep learning\napproaches. However, despite the demands for large data for deep learning, the\nsize of the heart sound datasets is limited, and no pre-trained model is\navailable. On the contrary, many pre-trained models for general audio tasks are\navailable as general-purpose audio representations. This study explores the\npotential of general-purpose audio representations pre-trained on large-scale\ndatasets for transfer learning in heart murmur detection. Experiments on the\nCirCor DigiScope heart sound dataset show that the recent self-supervised\nlearning Masked Modeling Duo (M2D) outperforms previous methods with the\nresults of a weighted accuracy of 0.832 and an unweighted average recall of\n0.713. Experiments further confirm improved performance by ensembling M2D with\nother models. These results demonstrate the effectiveness of general-purpose\naudio representation in processing heart sounds and open the way for further\napplications. Our code is available online which runs on a 24 GB consumer GPU\nat https://github.com/nttcslab/m2d/tree/master/app/circor", "published": "2024-04-26 01:52:50", "link": "http://arxiv.org/abs/2404.17107v1", "categories": ["eess.AS", "cs.SD", "68T07"], "primary_category": "eess.AS"}
{"title": "Device Feature based on Graph Fourier Transformation with Logarithmic\n  Processing For Detection of Replay Speech Attacks", "abstract": "The most common spoofing attacks on automatic speaker verification systems\nare replay speech attacks. Detection of replay speech heavily relies on replay\nconfiguration information. Previous studies have shown that graph Fourier\ntransform-derived features can effectively detect replay speech but ignore\ndevice and environmental noise effects. In this work, we propose a new feature,\nthe graph frequency device cepstral coefficient, derived from the graph\nfrequency domain using a device-related linear transformation. We also\nintroduce two novel representations: graph frequency logarithmic coefficient\nand graph frequency logarithmic device coefficient. We evaluate our methods\nusing traditional Gaussian mixture model and light convolutional neural network\nsystems as classifiers. On the ASVspoof 2017 V2, ASVspoof 2019 physical access,\nand ASVspoof 2021 physical access datasets, our proposed features outperform\nknown front-ends, demonstrating their effectiveness for replay speech\ndetection.", "published": "2024-04-26 09:36:49", "link": "http://arxiv.org/abs/2404.17280v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Investigation of Time-Frequency Representation Discriminators for\n  High-Fidelity Vocoder", "abstract": "Generative Adversarial Network (GAN) based vocoders are superior in both\ninference speed and synthesis quality when reconstructing an audible waveform\nfrom an acoustic representation. This study focuses on improving the\ndiscriminator for GAN-based vocoders. Most existing Time-Frequency\nRepresentation (TFR)-based discriminators are rooted in Short-Time Fourier\nTransform (STFT), which owns a constant Time-Frequency (TF) resolution,\nlinearly scaled center frequencies, and a fixed decomposition basis, making it\nincompatible with signals like singing voices that require dynamic attention\nfor different frequency bands and different time intervals. Motivated by that,\nwe propose a Multi-Scale Sub-Band Constant-Q Transform CQT (MS-SB-CQT)\ndiscriminator and a Multi-Scale Temporal-Compressed Continuous Wavelet\nTransform CWT (MS-TC-CWT) discriminator. Both CQT and CWT have a dynamic TF\nresolution for different frequency bands. In contrast, CQT has a better\nmodeling ability in pitch information, and CWT has a better modeling ability in\nshort-time transients. Experiments conducted on both speech and singing voices\nconfirm the effectiveness of our proposed discriminators. Moreover, the STFT,\nCQT, and CWT-based discriminators can be used jointly for better performance.\nThe proposed discriminators can boost the synthesis quality of various\nstate-of-the-art GAN-based vocoders, including HiFi-GAN, BigVGAN, and APNet.", "published": "2024-04-26 05:11:03", "link": "http://arxiv.org/abs/2404.17161v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "The CARFAC v2 Cochlear Model in Matlab, NumPy, and JAX", "abstract": "The open-source CARFAC (Cascade of Asymmetric Resonators with Fast-Acting\nCompression) cochlear model is upgraded to version 2, with improvements to the\nMatlab implementation, and with new Python/NumPy and JAX implementations -- but\nC++ version changes are still pending. One change addresses the DC (direct\ncurrent, or zero frequency) quadratic distortion anomaly previously reported;\nanother reduces the neural synchrony at high frequencies; the others have\nlittle or no noticeable effect in the default configuration. A new feature\nallows modeling a reduction of cochlear amplifier function, as a step toward a\ndifferentiable parameterized model of hearing impairment. In addition, the\nintegration into the Auditory Model Toolbox (AMT) has been extensively\nimproved, as the prior integration had bugs that made it unsuitable for\nincluding CARFAC in multi-model comparisons.", "published": "2024-04-26 15:45:31", "link": "http://arxiv.org/abs/2404.17490v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "An RFP dataset for Real, Fake, and Partially fake audio detection", "abstract": "Recent advances in deep learning have enabled the creation of\nnatural-sounding synthesised speech. However, attackers have also utilised\nthese tech-nologies to conduct attacks such as phishing. Numerous public\ndatasets have been created to facilitate the development of effective detection\nmodels. How-ever, available datasets contain only entirely fake audio;\ntherefore, detection models may miss attacks that replace a short section of\nthe real audio with fake audio. In recognition of this problem, the current\npaper presents the RFP da-taset, which comprises five distinct audio types:\npartial fake (PF), audio with noise, voice conversion (VC), text-to-speech\n(TTS), and real. The data are then used to evaluate several detection models,\nrevealing that the available detec-tion models incur a markedly higher equal\nerror rate (EER) when detecting PF audio instead of entirely fake audio. The\nlowest EER recorded was 25.42%. Therefore, we believe that creators of\ndetection models must seriously consid-er using datasets like RFP that include\nPF and other types of fake audio.", "published": "2024-04-26 23:00:56", "link": "http://arxiv.org/abs/2404.17721v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
