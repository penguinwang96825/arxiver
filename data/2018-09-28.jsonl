{"title": "Adaptive Input Representations for Neural Language Modeling", "abstract": "We introduce adaptive input representations for neural language modeling\nwhich extend the adaptive softmax of Grave et al. (2017) to input\nrepresentations of variable capacity. There are several choices on how to\nfactorize the input and output layers, and whether to model words, characters\nor sub-word units. We perform a systematic comparison of popular choices for a\nself-attentional architecture. Our experiments show that models equipped with\nadaptive embeddings are more than twice as fast to train than the popular\ncharacter input CNN while having a lower number of parameters. On the\nWikiText-103 benchmark we achieve 18.7 perplexity, an improvement of 10.5\nperplexity compared to the previously best published result and on the Billion\nWord benchmark, we achieve 23.02 perplexity.", "published": "2018-09-28 04:30:11", "link": "http://arxiv.org/abs/1809.10853v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Rule of Three: Abstractive Text Summarization in Three Bullet Points", "abstract": "Neural network-based approaches have become widespread for abstractive text\nsummarization. Though previously proposed models for abstractive text\nsummarization addressed the problem of repetition of the same contents in the\nsummary, they did not explicitly consider its information structure. One of the\nreasons these previous models failed to account for information structure in\nthe generated summary is that standard datasets include summaries of variable\nlengths, resulting in problems in analyzing information flow, specifically, the\nmanner in which the first sentence is related to the following sentences.\nTherefore, we use a dataset containing summaries with only three bullet points,\nand propose a neural network-based abstractive summarization model that\nconsiders the information structures of the generated summaries. Our\nexperimental results show that the information structure of a summary can be\ncontrolled, thus improving the performance of the overall summarization.", "published": "2018-09-28 06:04:32", "link": "http://arxiv.org/abs/1809.10867v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Robust, Transferable Sentence Representations for Text\n  Classification", "abstract": "Despite deep recurrent neural networks (RNNs) demonstrate strong performance\nin text classification, training RNN models are often expensive and requires an\nextensive collection of annotated data which may not be available. To overcome\nthe data limitation issue, existing approaches leverage either pre-trained word\nembedding or sentence representation to lift the burden of training RNNs from\nscratch. In this paper, we show that jointly learning sentence representations\nfrom multiple text classification tasks and combining them with pre-trained\nword-level and sentence level encoders result in robust sentence\nrepresentations that are useful for transfer learning. Extensive experiments\nand analyses using a wide range of transfer and linguistic tasks endorse the\neffectiveness of our approach.", "published": "2018-09-28 05:40:20", "link": "http://arxiv.org/abs/1810.00681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-situational learning of large lexicons with finite memory", "abstract": "Cross-situational word learning, wherein a learner combines information about\npossible meanings of a word across multiple exposures, has previously been\nshown to be a very powerful strategy to acquire a large lexicon in a short\ntime. However, this success may derive from idealizations that are made when\nmodeling the word-learning process. In particular, an earlier model assumed\nthat a learner could perfectly recall all previous instances of a word's use\nand the inferences that were drawn about its meaning. In this work, we relax\nthis assumption and determine the performance of a model cross-situational\nlearner who forgets word-meaning associations over time. Our main finding is\nthat it is possible for this learner to acquire a human-scale lexicon by\nadulthood with word-exposure and memory-decay rates that are consistent with\nempirical research on childhood word learning, as long as the degree of\nreferential uncertainty is not too high or the learner employs a mutual\nexclusivity constraint. Our findings therefore suggest that successful word\nlearning does not necessarily demand either highly accurate long-term tracking\nof word and meaning statistics or hypothesis-testing strategies.", "published": "2018-09-28 14:11:26", "link": "http://arxiv.org/abs/1809.11047v1", "categories": ["physics.soc-ph", "cs.CL"], "primary_category": "physics.soc-ph"}
{"title": "SALSA-TEXT : self attentive latent space based adversarial text\n  generation", "abstract": "Inspired by the success of self attention mechanism and Transformer\narchitecture in sequence transduction and image generation applications, we\npropose novel self attention-based architectures to improve the performance of\nadversarial latent code- based schemes in text generation. Adversarial latent\ncode-based text generation has recently gained a lot of attention due to their\npromising results. In this paper, we take a step to fortify the architectures\nused in these setups, specifically AAE and ARAE. We benchmark two latent\ncode-based methods (AAE and ARAE) designed based on adversarial setups. In our\nexperiments, the Google sentence compression dataset is utilized to compare our\nmethod with these methods using various objective and subjective measures. The\nexperiments demonstrate the proposed (self) attention-based models outperform\nthe state-of-the-art in adversarial code-based text generation.", "published": "2018-09-28 17:38:36", "link": "http://arxiv.org/abs/1809.11155v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Real Time Monitoring of Social Media and Digital Press", "abstract": "Talaia is a platform for monitoring social media and digital press. A\nconfigurable crawler gathers content with respect to user defined domains or\ntopics. Crawled data is processed by means of the EliXa Sentiment Analysis\nsystem. A Django powered interface provides data visualization for a user-based\nanalysis of the data. This paper presents the architecture of the system and\ndescribes in detail its different components. To prove the validity of the\napproach, two real use cases are accounted for: one in the cultural domain and\none in the political domain. Evaluation for the sentiment analysis task in both\nscenarios is also provided, showing the capacity for domain adaptation.", "published": "2018-09-28 16:00:20", "link": "http://arxiv.org/abs/1810.00647v2", "categories": ["cs.CL", "cs.IR", "68T35"], "primary_category": "cs.CL"}
{"title": "Patient Risk Assessment and Warning Symptom Detection Using Deep\n  Attention-Based Neural Networks", "abstract": "We present an operational component of a real-world patient triage system.\nGiven a specific patient presentation, the system is able to assess the level\nof medical urgency and issue the most appropriate recommendation in terms of\nbest point of care and time to treat. We use an attention-based convolutional\nneural network architecture trained on 600,000 doctor notes in German. We\ncompare two approaches, one that uses the full text of the medical notes and\none that uses only a selected list of medical entities extracted from the text.\nThese approaches achieve 79% and 66% precision, respectively, but on a\nconfidence threshold of 0.6, precision increases to 85% and 75%, respectively.\nIn addition, a method to detect warning symptoms is implemented to render the\nclassification task transparent from a medical perspective. The method is based\non the learning of attention scores and a method of automatic validation using\nthe same data.", "published": "2018-09-28 00:14:10", "link": "http://arxiv.org/abs/1809.10804v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Embedded-State Latent Conditional Random Fields for Sequence Labeling", "abstract": "Complex textual information extraction tasks are often posed as sequence\nlabeling or \\emph{shallow parsing}, where fields are extracted using local\nlabels made consistent through probabilistic inference in a graphical model\nwith constrained transitions. Recently, it has become common to locally\nparametrize these models using rich features extracted by recurrent neural\nnetworks (such as LSTM), while enforcing consistent outputs through a simple\nlinear-chain model, representing Markovian dependencies between successive\nlabels. However, the simple graphical model structure belies the often complex\nnon-local constraints between output labels. For example, many fields, such as\na first name, can only occur a fixed number of times, or in the presence of\nother fields. While RNNs have provided increasingly powerful context-aware\nlocal features for sequence tagging, they have yet to be integrated with a\nglobal graphical model of similar expressivity in the output distribution. Our\nmodel goes beyond the linear chain CRF to incorporate multiple hidden states\nper output label, but parametrizes their transitions parsimoniously with\nlow-rank log-potential scoring matrices, effectively learning an embedding\nspace for hidden states. This augmented latent space of inference variables\ncomplements the rich feature representation of the RNN, and allows exact global\ninference obeying complex, learned non-local output constraints. We experiment\nwith several datasets and show that the model outperforms baseline CRF+RNN\nmodels when global output constraints are necessary at inference-time, and\nexplore the interpretable latent structure.", "published": "2018-09-28 03:06:31", "link": "http://arxiv.org/abs/1809.10835v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Spoken Pass-Phrase Verification in the i-vector Space", "abstract": "The task of spoken pass-phrase verification is to decide whether a test\nutterance contains the same phrase as given enrollment utterances. Beside other\napplications, pass-phrase verification can complement an independent speaker\nverification subsystem in text-dependent speaker verification. It can also be\nused for liveness detection by verifying that the user is able to correctly\nrespond to a randomly prompted phrase. In this paper, we build on our previous\nwork on i-vector based text-dependent speaker verification, where we have shown\nthat i-vectors extracted using phrase specific Hidden Markov Models (HMMs) or\nusing Deep Neural Network (DNN) based bottle-neck (BN) features help to reject\nutterances with wrong pass-phrases. We apply the same i-vector extraction\ntechniques to the stand-alone task of speaker-independent spoken pass-phrase\nclassification and verification. The experiments on RSR2015 and RedDots\ndatabases show that very simple scoring techniques (e.g. cosine distance\nscoring) applied to such i-vectors can provide results superior to those\npreviously published on the same data.", "published": "2018-09-28 14:49:27", "link": "http://arxiv.org/abs/1809.11068v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Direct optimization of F-measure for retrieval-based personal question\n  answering", "abstract": "Recent advances in spoken language technologies and the introduction of many\ncustomer facing products, have given rise to a wide customer reliance on smart\npersonal assistants for many of their daily tasks. In this paper, we present a\nsystem to reduce users' cognitive load by extending personal assistants with\nlong-term personal memory where users can store and retrieve by voice,\narbitrary pieces of information. The problem is framed as a neural retrieval\nbased question answering system where answers are selected from previously\nstored user memories. We propose to directly optimize the end-to-end retrieval\nperformance, measured by the F1-score, using reinforcement learning, leading to\nbetter performance on our experimental test set(s).", "published": "2018-09-28 00:51:24", "link": "http://arxiv.org/abs/1810.00679v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Online Localization and Tracking of Multiple Moving Speakers in\n  Reverberant Environments", "abstract": "We address the problem of online localization and tracking of multiple moving\nspeakers in reverberant environments. The paper has the following\ncontributions. We use the direct-path relative transfer function (DP-RTF), an\ninter-channel feature that encodes acoustic information robust against\nreverberation, and we propose an online algorithm well suited for estimating\nDP-RTFs associated with moving audio sources. Another crucial ingredient of the\nproposed method is its ability to properly assign DP-RTFs to audio-source\ndirections. Towards this goal, we adopt a maximum-likelihood formulation and we\npropose to use an exponentiated gradient (EG) to efficiently update\nsource-direction estimates starting from their currently available values. The\nproblem of multiple speaker tracking is computationally intractable because the\nnumber of possible associations between observed source directions and physical\nspeakers grows exponentially with time. We adopt a Bayesian framework and we\npropose a variational approximation of the posterior filtering distribution\nassociated with multiple speaker tracking, as well as an efficient variational\nexpectation-maximization (VEM) solver. The proposed online localization and\ntracking method is thoroughly evaluated using two datasets that contain\nrecordings performed in real environments.", "published": "2018-09-28 09:54:26", "link": "http://arxiv.org/abs/1809.10936v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat\nto different neural network models and many downstream applications.\nNonetheless, as unique data properties have inspired distinct and powerful\nlearning principles, this paper aims to explore their potentials towards\nmitigating adversarial inputs. In particular, our results reveal the importance\nof using the temporal dependency in audio data to gain discriminate power\nagainst adversarial examples. Tested on the automatic speech recognition (ASR)\ntasks and three recent audio adversarial attacks, we find that (i) input\ntransformation developed from image adversarial defense provides limited\nrobustness improvement and is subtle to advanced attacks; (ii) temporal\ndependency can be exploited to gain discriminative power against audio\nadversarial examples and is resistant to adaptive attacks considered in our\nexperiments. Our results not only show promising means of improving the\nrobustness of ASR systems, but also offer novel insights in exploiting\ndomain-specific data properties to mitigate negative effects of adversarial\nexamples.", "published": "2018-09-28 06:39:42", "link": "http://arxiv.org/abs/1809.10875v2", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
