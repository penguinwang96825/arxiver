{"title": "Automatic Disambiguation of French Discourse Connectives", "abstract": "Discourse connectives (e.g. however, because) are terms that can explicitly\nconvey a discourse relation within a text. While discourse connectives have\nbeen shown to be an effective clue to automatically identify discourse\nrelations, they are not always used to convey such relations, thus they should\nfirst be disambiguated between discourse-usage non-discourse-usage. In this\npaper, we investigate the applicability of features proposed for the\ndisambiguation of English discourse connectives for French. Our results with\nthe French Discourse Treebank (FDTB) show that syntactic and lexical features\ndeveloped for English texts are as effective for French and allow the\ndisambiguation of French discourse connectives with an accuracy of 94.2%.", "published": "2017-04-18 01:04:49", "link": "http://arxiv.org/abs/1704.05162v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine", "abstract": "We publicly release a new large-scale dataset, called SearchQA, for machine\ncomprehension, or question-answering. Unlike recently released datasets, such\nas DeepMind CNN/DailyMail and SQuAD, the proposed SearchQA was constructed to\nreflect a full pipeline of general question-answering. That is, we start not\nfrom an existing article and generate a question-answer pair, but start from an\nexisting question-answer pair, crawled from J! Archive, and augment it with\ntext snippets retrieved by Google. Following this approach, we built SearchQA,\nwhich consists of more than 140k question-answer pairs with each pair having\n49.6 snippets on average. Each question-answer-context tuple of the SearchQA\ncomes with additional meta-data such as the snippet's URL, which we believe\nwill be valuable resources for future research. We conduct human evaluation as\nwell as test two baseline methods, one simple word selection and the other deep\nlearning based, on the SearchQA. We show that there is a meaningful gap between\nthe human and machine performances. This suggests that the proposed dataset\ncould well serve as a benchmark for question-answering.", "published": "2017-04-18 02:42:17", "link": "http://arxiv.org/abs/1704.05179v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment analysis based on rhetorical structure theory: Learning deep\n  neural networks from discourse trees", "abstract": "Prominent applications of sentiment analysis are countless, covering areas\nsuch as marketing, customer service and communication. The conventional\nbag-of-words approach for measuring sentiment merely counts term frequencies;\nhowever, it neglects the position of the terms within the discourse. As a\nremedy, we develop a discourse-aware method that builds upon the discourse\nstructure of documents. For this purpose, we utilize rhetorical structure\ntheory to label (sub-)clauses according to their hierarchical relationships and\nthen assign polarity scores to individual leaves. To learn from the resulting\nrhetorical structure, we propose a tensor-based, tree-structured deep neural\nnetwork (named Discourse-LSTM) in order to process the complete discourse tree.\nThe underlying tensors infer the salient passages of narrative materials. In\naddition, we suggest two algorithms for data augmentation (node reordering and\nartificial leaf insertion) that increase our training set and reduce\noverfitting. Our benchmarks demonstrate the superior performance of our\napproach. Moreover, our tensor structure reveals the salient text passages and\nthereby provides explanatory insights.", "published": "2017-04-18 08:24:20", "link": "http://arxiv.org/abs/1704.05228v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Baselines and test data for cross-lingual inference", "abstract": "The recent years have seen a revival of interest in textual entailment,\nsparked by i) the emergence of powerful deep neural network learners for\nnatural language processing and ii) the timely development of large-scale\nevaluation datasets such as SNLI. Recast as natural language inference, the\nproblem now amounts to detecting the relation between pairs of statements: they\neither contradict or entail one another, or they are mutually neutral. Current\nresearch in natural language inference is effectively exclusive to English. In\nthis paper, we propose to advance the research in SNLI-style natural language\ninference toward multilingual evaluation. To that end, we provide test data for\nfour major languages: Arabic, French, Spanish, and Russian. We experiment with\na set of baselines. Our systems are based on cross-lingual word embeddings and\nmachine translation. While our best system scores an average accuracy of just\nover 75%, we focus largely on enabling further research in multilingual\ninference.", "published": "2017-04-18 14:12:37", "link": "http://arxiv.org/abs/1704.05347v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representing Sentences as Low-Rank Subspaces", "abstract": "Sentences are important semantic units of natural language. A generic,\ndistributional representation of sentences that can capture the latent\nsemantics is beneficial to multiple downstream applications. We observe a\nsimple geometry of sentences -- the word representations of a given sentence\n(on average 10.23 words in all SemEval datasets with a standard deviation 4.84)\nroughly lie in a low-rank subspace (roughly, rank 4). Motivated by this\nobservation, we represent a sentence by the low-rank subspace spanned by its\nword vectors. Such an unsupervised representation is empirically validated via\nsemantic textual similarity tasks on 19 different datasets, where it\noutperforms the sophisticated neural network models, including skip-thought\nvectors, by 15% on average.", "published": "2017-04-18 14:30:32", "link": "http://arxiv.org/abs/1704.05358v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Analysis of NMT-Derived Interlingual Embeddings and their\n  Use in Parallel Sentence Identification", "abstract": "End-to-end neural machine translation has overtaken statistical machine\ntranslation in terms of translation quality for some language pairs, specially\nthose with large amounts of parallel data. Besides this palpable improvement,\nneural networks provide several new properties. A single system can be trained\nto translate between many languages at almost no additional cost other than\ntraining time. Furthermore, internal representations learned by the network\nserve as a new semantic representation of words -or sentences- which, unlike\nstandard word embeddings, are learned in an essentially bilingual or even\nmultilingual context. In view of these properties, the contribution of the\npresent work is two-fold. First, we systematically study the NMT context\nvectors, i.e. output of the encoder, and their power as an interlingua\nrepresentation of a sentence. We assess their quality and effectiveness by\nmeasuring similarities across translations, as well as semantically related and\nsemantically unrelated sentence pairs. Second, as extrinsic evaluation of the\nfirst point, we identify parallel sentences in comparable corpora, obtaining an\nF1=98.2% on data from a shared task when using only NMT context vectors. Using\ncontext vectors jointly with similarity measures F1 reaches 98.9%.", "published": "2017-04-18 16:38:01", "link": "http://arxiv.org/abs/1704.05415v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through\n  Inference", "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI)\ncorpus, a dataset designed for use in the development and evaluation of machine\nlearning models for sentence understanding. In addition to being one of the\nlargest corpora available for the task of NLI, at 433k examples, this corpus\nimproves upon available resources in its coverage: it offers data from ten\ndistinct genres of written and spoken English--making it possible to evaluate\nsystems on nearly the full complexity of the language--and it offers an\nexplicit setting for the evaluation of cross-genre domain adaptation.", "published": "2017-04-18 17:10:13", "link": "http://arxiv.org/abs/1704.05426v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Similarity from Natural Language and Ontology Analysis", "abstract": "Artificial Intelligence federates numerous scientific fields in the aim of\ndeveloping machines able to assist human operators performing complex\ntreatments -- most of which demand high cognitive skills (e.g. learning or\ndecision processes). Central to this quest is to give machines the ability to\nestimate the likeness or similarity between things in the way human beings\nestimate the similarity between stimuli.\n  In this context, this book focuses on semantic measures: approaches designed\nfor comparing semantic entities such as units of language, e.g. words,\nsentences, or concepts and instances defined into knowledge bases. The aim of\nthese measures is to assess the similarity or relatedness of such semantic\nentities by taking into account their semantics, i.e. their meaning --\nintuitively, the words tea and coffee, which both refer to stimulating\nbeverage, will be estimated to be more semantically similar than the words\ntoffee (confection) and coffee, despite that the last pair has a higher\nsyntactic similarity. The two state-of-the-art approaches for estimating and\nquantifying semantic similarities/relatedness of semantic entities are\npresented in detail: the first one relies on corpora analysis and is based on\nNatural Language Processing techniques and semantic models while the second is\nbased on more or less formal, computer-readable and workable forms of knowledge\nsuch as semantic networks, thesaurus or ontologies. (...) Beyond a simple\ninventory and categorization of existing measures, the aim of this monograph is\nto convey novices as well as researchers of these domains towards a better\nunderstanding of semantic similarity estimation and more generally semantic\nmeasures.", "published": "2017-04-18 12:24:26", "link": "http://arxiv.org/abs/1704.05295v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Extractive Summarization: Limits, Compression, Generalized Model and\n  Heuristics", "abstract": "Due to its promise to alleviate information overload, text summarization has\nattracted the attention of many researchers. However, it has remained a serious\nchallenge. Here, we first prove empirical limits on the recall (and F1-scores)\nof extractive summarizers on the DUC datasets under ROUGE evaluation for both\nthe single-document and multi-document summarization tasks. Next we define the\nconcept of compressibility of a document and present a new model of\nsummarization, which generalizes existing models in the literature and\nintegrates several dimensions of the summarization, viz., abstractive versus\nextractive, single versus multi-document, and syntactic versus semantic.\nFinally, we examine some new and existing single-document summarization\nalgorithms in a single framework and compare with state of the art summarizers\non DUC data.", "published": "2017-04-18 22:21:22", "link": "http://arxiv.org/abs/1704.05550v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Analysis of Computational Science Papers from ICCS 2001-2016 using Topic\n  Modeling and Graph Theory", "abstract": "This paper presents results of topic modeling and network models of topics\nusing the International Conference on Computational Science corpus, which\ncontains domain-specific (computational science) papers over sixteen years (a\ntotal of 5695 papers). We discuss topical structures of International\nConference on Computational Science, how these topics evolve over time in\nresponse to the topicality of various problems, technologies and methods, and\nhow all these topics relate to one another. This analysis illustrates\nmultidisciplinary research and collaborations among scientific communities, by\nconstructing static and dynamic networks from the topic modeling results and\nthe keywords of authors. The results of this study give insights about the past\nand future trends of core discussion topics in computational science. We used\nthe Non-negative Matrix Factorization topic modeling algorithm to discover\ntopics and labeled and grouped results hierarchically.", "published": "2017-04-18 13:24:41", "link": "http://arxiv.org/abs/1705.02203v1", "categories": ["cs.DL", "cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.DL"}
{"title": "Mining Worse and Better Opinions. Unsupervised and Agnostic Aggregation\n  of Online Reviews", "abstract": "In this paper, we propose a novel approach for aggregating online reviews,\naccording to the opinions they express. Our methodology is unsupervised - due\nto the fact that it does not rely on pre-labeled reviews - and it is agnostic -\nsince it does not make any assumption about the domain or the language of the\nreview content. We measure the adherence of a review content to the domain\nterminology extracted from a review set. First, we demonstrate the\ninformativeness of the adherence metric with respect to the score associated\nwith a review. Then, we exploit the metric values to group reviews, according\nto the opinions they express. Our experimental campaign has been carried out on\ntwo large datasets collected from Booking and Amazon, respectively.", "published": "2017-04-18 15:20:25", "link": "http://arxiv.org/abs/1704.05393v1", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "25 Tweets to Know You: A New Model to Predict Personality with Social\n  Media", "abstract": "Predicting personality is essential for social applications supporting\nhuman-centered activities, yet prior modeling methods with users written text\nrequire too much input data to be realistically used in the context of social\nmedia. In this work, we aim to drastically reduce the data requirement for\npersonality modeling and develop a model that is applicable to most users on\nTwitter. Our model integrates Word Embedding features with Gaussian Processes\nregression. Based on the evaluation of over 1.3K users on Twitter, we find that\nour model achieves comparable or better accuracy than state of the art\ntechniques with 8 times fewer data.", "published": "2017-04-18 20:16:31", "link": "http://arxiv.org/abs/1704.05513v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.SI"}
{"title": "Coordinating Collaborative Chat in Massive Open Online Courses", "abstract": "An earlier study of a collaborative chat intervention in a Massive Open\nOnline Course (MOOC) identified negative effects on attrition stemming from a\nrequirement for students to be matched with exactly one partner prior to\nbeginning the activity. That study raised questions about how to orchestrate a\ncollaborative chat intervention in a MOOC context in order to provide the\nbenefit of synchronous social engagement without the coordination difficulties.\nIn this paper we present a careful analysis of an intervention designed to\novercome coordination difficulties by welcoming students into the chat on a\nrolling basis as they arrive rather than requiring them to be matched with a\npartner before beginning. The results suggest the most positive impact when\nexperiencing a chat with exactly one partner rather than more or less. A\nqualitative analysis of the chat data reveals differential experiences between\nthese configurations that suggests a potential explanation for the effect and\nraises questions for future research.", "published": "2017-04-18 21:57:10", "link": "http://arxiv.org/abs/1704.05543v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
