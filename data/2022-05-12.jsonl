{"title": "AppTek's Submission to the IWSLT 2022 Isometric Spoken Language\n  Translation Task", "abstract": "To participate in the Isometric Spoken Language Translation Task of the IWSLT\n2022 evaluation, constrained condition, AppTek developed neural\nTransformer-based systems for English-to-German with various mechanisms of\nlength control, ranging from source-side and target-side pseudo-tokens to\nencoding of remaining length in characters that replaces positional encoding.\nWe further increased translation length compliance by sentence-level selection\nof length-compliant hypotheses from different system variants, as well as\nrescoring of N-best candidates from a single system. Length-compliant\nback-translated and forward-translated synthetic data, as well as other\nparallel data variants derived from the original MuST-C training corpus were\nimportant for a good quality/desired length trade-off. Our experimental results\nshow that length compliance levels above 90% can be reached while minimizing\nlosses in MT quality as measured in BERT and BLEU scores.", "published": "2022-05-12 00:02:24", "link": "http://arxiv.org/abs/2205.05807v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Supplementary Material: Implementation and Experiments for GAU-based\n  Model", "abstract": "In February this year Google proposed a new Transformer variant called FLASH,\nwhich has a faster speed, lower VRAM footprint and better performance. This is\nachieved by designing a performant layer named GAU (Gated Attention Unit),\nwhich combines the Attention layer and FFN. In this paper, some implementation\ndetails are re-analyzed both theoretically and practically. We then propose a\nnovel GAU-based model and pre-train it on a Chinese corpus. Results of the CLUE\nbenchmark show that our model achieves a dev average score of 75.02, 1% higher\nthan RoFormerV1 and being 45% faster, which is also competitive with\nRoFormerV2.", "published": "2022-05-12 02:18:29", "link": "http://arxiv.org/abs/2205.05842v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Open Arabic Named Entity Recognition Tools", "abstract": "The main objective of this paper is to compare and evaluate the performances\nof three open Arabic NER tools: CAMeL, Hatmi, and Stanza. We collected a corpus\nconsisting of 30 articles written in MSA and manually annotated all the\nentities of the person, organization, and location types at the article\n(document) level. Our results suggest a similarity between Stanza and Hatmi\nwith the latter receiving the highest F1 score for the three entity types.\nHowever, CAMeL achieved the highest precision values for names of people and\norganizations. Following this, we implemented a \"merge\" method that combined\nthe results from the three tools and a \"vote\" method that tagged named entities\nonly when two of the three identified them as entities. Our results showed that\nmerging achieved the highest overall F1 scores. Moreover, merging had the\nhighest recall values while voting had the highest precision values for the\nthree entity types. This indicates that merging is more suitable when recall is\ndesired, while voting is optimal when precision is required. Finally, we\ncollected a corpus of 21,635 articles related to COVID-19 and applied the merge\nand vote methods. Our analysis demonstrates the tradeoff between precision and\nrecall for the two methods.", "published": "2022-05-12 03:16:06", "link": "http://arxiv.org/abs/2205.05857v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AdaVAE: Exploring Adaptive GPT-2s in Variational Auto-Encoders for\n  Language Modeling", "abstract": "Variational Auto-Encoder (VAE) has become the de-facto learning paradigm in\nachieving representation learning and generation for natural language at the\nsame time. Nevertheless, existing VAE-based language models either employ\nelementary RNNs, which is not powerful to handle complex works in the\nmulti-task situation, or fine-tunes two pre-trained language models (PLMs) for\nany downstream task, which is a huge drain on resources. In this paper, we\npropose the first VAE framework empowered with adaptive GPT-2s (AdaVAE).\nDifferent from existing systems, we unify both the encoder\\&decoder of the VAE\nmodel using GPT-2s with adaptive parameter-efficient components, and further\nintroduce Latent Attention operation to better construct latent space from\ntransformer models. Experiments from multiple dimensions validate that AdaVAE\nis competent to effectively organize language in three related tasks (language\nmodeling, representation modeling and guided text generation) even with less\nthan $15\\%$ activated parameters in training. Our code is available at\n\\url{https://github.com/ImKeTT/AdaVAE}.", "published": "2022-05-12 03:22:07", "link": "http://arxiv.org/abs/2205.05862v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Gender Stereotypes in Hindi and Marathi", "abstract": "As the use of natural language processing increases in our day-to-day life,\nthe need to address gender bias inherent in these systems also amplifies. This\nis because the inherent bias interferes with the semantic structure of the\noutput of these systems while performing tasks like machine translation. While\nresearch is being done in English to quantify and mitigate bias, debiasing\nmethods in Indic Languages are either relatively nascent or absent for some\nIndic languages altogether. Most Indic languages are gendered, i.e., each noun\nis assigned a gender according to each language's grammar rules. As a\nconsequence, evaluation differs from what is done in English. This paper\nevaluates the gender stereotypes in Hindi and Marathi languages. The\nmethodologies will differ from the ones in the English language because there\nare masculine and feminine counterparts in the case of some words. We create a\ndataset of neutral and gendered occupation words, emotion words and measure\nbias with the help of Embedding Coherence Test (ECT) and Relative Norm Distance\n(RND). We also attempt to mitigate this bias from the embeddings. Experiments\nshow that our proposed debiasing techniques reduce gender bias in these\nlanguages.", "published": "2022-05-12 06:46:53", "link": "http://arxiv.org/abs/2205.05901v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Computational Acquisition Model for Multimodal Word Categorization", "abstract": "Recent advances in self-supervised modeling of text and images open new\nopportunities for computational models of child language acquisition, which is\nbelieved to rely heavily on cross-modal signals. However, prior studies have\nbeen limited by their reliance on vision models trained on large image datasets\nannotated with a pre-defined set of depicted object categories. This is (a) not\nfaithful to the information children receive and (b) prohibits the evaluation\nof such models with respect to category learning tasks, due to the pre-imposed\ncategory structure. We address this gap, and present a cognitively-inspired,\nmultimodal acquisition model, trained from image-caption pairs on naturalistic\ndata using cross-modal self-supervision. We show that the model learns word\ncategories and object recognition abilities, and presents trends reminiscent of\nthose reported in the developmental literature. We make our code and trained\nmodels public for future reference and use.", "published": "2022-05-12 09:28:55", "link": "http://arxiv.org/abs/2205.05974v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controlling Formality in Low-Resource NMT with Domain Adaptation and\n  Re-Ranking: SLT-CDT-UoS at IWSLT2022", "abstract": "This paper describes the SLT-CDT-UoS group's submission to the first Special\nTask on Formality Control for Spoken Language Translation, part of the IWSLT\n2022 Evaluation Campaign. Our efforts were split between two fronts: data\nengineering and altering the objective function for best hypothesis selection.\nWe used language-independent methods to extract formal and informal sentence\npairs from the provided corpora; using English as a pivot language, we\npropagated formality annotations to languages treated as zero-shot in the task;\nwe also further improved formality controlling with a hypothesis re-ranking\napproach. On the test sets for English-to-German and English-to-Spanish, we\nachieved an average accuracy of .935 within the constrained setting and .995\nwithin unconstrained setting. In a zero-shot setting for English-to-Russian and\nEnglish-to-Italian, we scored average accuracy of .590 for constrained setting\nand .659 for unconstrained.", "published": "2022-05-12 09:54:17", "link": "http://arxiv.org/abs/2205.05990v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Falsesum: Generating Document-level NLI Examples for Recognizing Factual\n  Inconsistency in Summarization", "abstract": "Neural abstractive summarization models are prone to generate summaries which\nare factually inconsistent with their source documents. Previous work has\nintroduced the task of recognizing such factual inconsistency as a downstream\napplication of natural language inference (NLI). However, state-of-the-art NLI\nmodels perform poorly in this context due to their inability to generalize to\nthe target task. In this work, we show that NLI models can be effective for\nthis task when the training data is augmented with high-quality task-oriented\nexamples. We introduce Falsesum, a data generation pipeline leveraging a\ncontrollable text generation model to perturb human-annotated summaries,\nintroducing varying types of factual inconsistencies. Unlike previously\nintroduced document-level NLI datasets, our generated dataset contains examples\nthat are diverse and inconsistent yet plausible. We show that models trained on\na Falsesum-augmented NLI dataset improve the state-of-the-art performance\nacross four benchmarks for detecting factual inconsistency in summarization.\n  The code to obtain the dataset is available online at\nhttps://github.com/joshbambrick/Falsesum", "published": "2022-05-12 10:43:42", "link": "http://arxiv.org/abs/2205.06009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DTW at Qur'an QA 2022: Utilising Transfer Learning with Transformers for\n  Question Answering in a Low-resource Domain", "abstract": "The task of machine reading comprehension (MRC) is a useful benchmark to\nevaluate the natural language understanding of machines. It has gained\npopularity in the natural language processing (NLP) field mainly due to the\nlarge number of datasets released for many languages. However, the research in\nMRC has been understudied in several domains, including religious texts. The\ngoal of the Qur'an QA 2022 shared task is to fill this gap by producing\nstate-of-the-art question answering and reading comprehension research on\nQur'an. This paper describes the DTW entry to the Quran QA 2022 shared task.\nOur methodology uses transfer learning to take advantage of available Arabic\nMRC data. We further improve the results using various ensemble learning\nstrategies. Our approach provided a partial Reciprocal Rank (pRR) score of 0.49\non the test set, proving its strong performance on the task.", "published": "2022-05-12 11:17:23", "link": "http://arxiv.org/abs/2205.06025v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient and Training-Free Control of Language Generation", "abstract": "In recent years, there has been a growing interest in the development of\nlanguage models capable of generating text with controllable attributes. While\nseveral approaches have been proposed, many of these methods require\ncondition-specific data or significant computational resources. In this study,\nwe propose a novel method called Gamma Sampling, which enables controllable\nlanguage generation without the need for any training data and maintains a fast\ngeneration speed. Gamma Sampling incorporates attribute-related information\ninto the sampling process, effectively guiding the language model to produce\ntext with desired attributes. Our experimental results demonstrate that Gamma\nSampling, when applied to GPT2, outperforms representative baselines in terms\nof diversity, attribute relevance, and overall quality of the generated\nsamples.", "published": "2022-05-12 11:48:11", "link": "http://arxiv.org/abs/2205.06036v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SimRelUz: Similarity and Relatedness scores as a Semantic Evaluation\n  dataset for Uzbek language", "abstract": "Semantic relatedness between words is one of the core concepts in natural\nlanguage processing, thus making semantic evaluation an important task. In this\npaper, we present a semantic model evaluation dataset: SimRelUz - a collection\nof similarity and relatedness scores of word pairs for the low-resource Uzbek\nlanguage. The dataset consists of more than a thousand pairs of words carefully\nselected based on their morphological features, occurrence frequency, semantic\nrelation, as well as annotated by eleven native Uzbek speakers from different\nage groups and gender. We also paid attention to the problem of dealing with\nrare words and out-of-vocabulary words to thoroughly evaluate the robustness of\nsemantic models.", "published": "2022-05-12 13:11:28", "link": "http://arxiv.org/abs/2205.06072v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Findings of the Shared Task on Offensive Span Identification from\n  Code-Mixed Tamil-English Comments", "abstract": "Offensive content moderation is vital in social media platforms to support\nhealthy online discussions. However, their prevalence in codemixed Dravidian\nlanguages is limited to classifying whole comments without identifying part of\nit contributing to offensiveness. Such limitation is primarily due to the lack\nof annotated data for offensive spans. Accordingly, in this shared task, we\nprovide Tamil-English code-mixed social comments with offensive spans. This\npaper outlines the dataset so released, methods, and results of the submitted\nsystems", "published": "2022-05-12 14:31:57", "link": "http://arxiv.org/abs/2205.06118v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi Task Learning For Zero Shot Performance Prediction of Multilingual\n  Models", "abstract": "Massively Multilingual Transformer based Language Models have been observed\nto be surprisingly effective on zero-shot transfer across languages, though the\nperformance varies from language to language depending on the pivot language(s)\nused for fine-tuning. In this work, we build upon some of the existing\ntechniques for predicting the zero-shot performance on a task, by modeling it\nas a multi-task learning problem. We jointly train predictive models for\ndifferent tasks which helps us build more accurate predictors for tasks where\nwe have test data in very few languages to measure the actual performance of\nthe model. Our approach also lends us the ability to perform a much more robust\nfeature selection and identify a common set of features that influence\nzero-shot performance across a variety of tasks.", "published": "2022-05-12 14:47:03", "link": "http://arxiv.org/abs/2205.06130v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is the Computation of Abstract Sameness Relations Human-Like in Neural\n  Language Models?", "abstract": "In recent years, deep neural language models have made strong progress in\nvarious NLP tasks. This work explores one facet of the question whether\nstate-of-the-art NLP models exhibit elementary mechanisms known from human\ncognition. The exploration is focused on a relatively primitive mechanism for\nwhich there is a lot of evidence from various psycholinguistic experiments with\ninfants. The computation of \"abstract sameness relations\" is assumed to play an\nimportant role in human language acquisition and processing, especially in\nlearning more complex grammar rules. In order to investigate this mechanism in\nBERT and other pre-trained language models (PLMs), the experiment designs from\nstudies with infants were taken as the starting point. On this basis, we\ndesigned experimental settings in which each element from the original studies\nwas mapped to a component of language models. Even though the task in our\nexperiments was relatively simple, the results suggest that the cognitive\nfaculty of computing abstract sameness relations is stronger in infants than in\nall investigated PLMs.", "published": "2022-05-12 15:19:54", "link": "http://arxiv.org/abs/2205.06149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TreeMix: Compositional Constituency-based Data Augmentation for Natural\n  Language Understanding", "abstract": "Data augmentation is an effective approach to tackle over-fitting. Many\nprevious works have proposed different data augmentations strategies for NLP,\nsuch as noise injection, word replacement, back-translation etc. Though\neffective, they missed one important characteristic of\nlanguage--compositionality, meaning of a complex expression is built from its\nsub-parts. Motivated by this, we propose a compositional data augmentation\napproach for natural language understanding called TreeMix. Specifically,\nTreeMix leverages constituency parsing tree to decompose sentences into\nconstituent sub-structures and the Mixup data augmentation technique to\nrecombine them to generate new sentences. Compared with previous approaches,\nTreeMix introduces greater diversity to the samples generated and encourages\nmodels to learn compositionality of NLP data. Extensive experiments on text\nclassification and SCAN demonstrate that TreeMix outperforms current\nstate-of-the-art data augmentation methods.", "published": "2022-05-12 15:25:12", "link": "http://arxiv.org/abs/2205.06153v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using dependency parsing for few-shot learning in distributional\n  semantics", "abstract": "In this work, we explore the novel idea of employing dependency parsing\ninformation in the context of few-shot learning, the task of learning the\nmeaning of a rare word based on a limited amount of context sentences. Firstly,\nwe use dependency-based word embedding models as background spaces for few-shot\nlearning. Secondly, we introduce two few-shot learning methods which enhance\nthe additive baseline model by using dependencies.", "published": "2022-05-12 15:45:10", "link": "http://arxiv.org/abs/2205.06168v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting Human Psychometric Properties Using Computational Language\n  Models", "abstract": "Transformer-based language models (LMs) continue to achieve state-of-the-art\nperformance on natural language processing (NLP) benchmarks, including tasks\ndesigned to mimic human-inspired \"commonsense\" competencies. To better\nunderstand the degree to which LMs can be said to have certain linguistic\nreasoning skills, researchers are beginning to adapt the tools and concepts\nfrom psychometrics. But to what extent can benefits flow in the other\ndirection? In other words, can LMs be of use in predicting the psychometric\nproperties of test items, when those items are given to human participants? If\nso, the benefit for psychometric practitioners is enormous, as it can reduce\nthe need for multiple rounds of empirical testing. We gather responses from\nnumerous human participants and LMs (transformer- and non-transformer-based) on\na broad diagnostic test of linguistic competencies. We then use the human\nresponses to calculate standard psychometric properties of the items in the\ndiagnostic test, using the human responses and the LM responses separately. We\nthen determine how well these two sets of predictions correlate. We find that\ntransformer-based LMs predict the human psychometric data consistently well\nacross most categories, suggesting that they can be used to gather human-like\npsychometric data without the need for extensive human trials.", "published": "2022-05-12 16:40:12", "link": "http://arxiv.org/abs/2205.06203v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CiteSum: Citation Text-guided Scientific Extreme Summarization and\n  Domain Adaptation with Limited Supervision", "abstract": "Scientific extreme summarization (TLDR) aims to form ultra-short summaries of\nscientific papers. Previous efforts on curating scientific TLDR datasets failed\nto scale up due to the heavy human annotation and domain expertise required. In\nthis paper, we propose a simple yet effective approach to automatically\nextracting TLDR summaries for scientific papers from their citation texts.\nBased on the proposed approach, we create a new benchmark CiteSum without human\nannotation, which is around 30 times larger than the previous human-curated\ndataset SciTLDR. We conduct a comprehensive analysis of CiteSum, examining its\ndata characteristics and establishing strong baselines. We further demonstrate\nthe usefulness of CiteSum by adapting models pre-trained on CiteSum (named\nCITES) to new tasks and domains with limited supervision. For scientific\nextreme summarization, CITES outperforms most fully-supervised methods on\nSciTLDR without any fine-tuning and obtains state-of-the-art results with only\n128 examples. For news extreme summarization, CITES achieves significant gains\non XSum over its base model (not pre-trained on CiteSum), e.g., +7.2 ROUGE-1\nzero-shot performance and state-of-the-art few-shot performance. For news\nheadline generation, CITES performs the best among unsupervised and zero-shot\nmethods on Gigaword. Our dataset and code can be found at\nhttps://github.com/morningmoni/CiteSum.", "published": "2022-05-12 16:44:19", "link": "http://arxiv.org/abs/2205.06207v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue", "abstract": "Task transfer, transferring knowledge contained in related tasks, holds the\npromise of reducing the quantity of labeled data required to fine-tune language\nmodels. Dialogue understanding encompasses many diverse tasks, yet task\ntransfer has not been thoroughly studied in conversational AI. This work\nexplores conversational task transfer by introducing FETA: a benchmark for\nfew-sample task transfer in open-domain dialogue. FETA contains two underlying\nsets of conversations upon which there are 10 and 7 tasks annotated, enabling\nthe study of intra-dataset task transfer; task transfer without domain\nadaptation. We utilize three popular language models and three learning\nalgorithms to analyze the transferability between 132 source-target task pairs\nand create a baseline for future work. We run experiments in the single- and\nmulti-source settings and report valuable findings, e.g., most performance\ntrends are model-specific, and span extraction and multiple-choice tasks\nbenefit the most from task transfer. In addition to task transfer, FETA can be\na valuable resource for future research into the efficiency and\ngeneralizability of pre-training datasets and model architectures, as well as\nfor learning settings such as continual and multitask learning.", "published": "2022-05-12 17:59:00", "link": "http://arxiv.org/abs/2205.06262v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lifting the Curse of Multilinguality by Pre-training Modular\n  Transformers", "abstract": "Multilingual pre-trained models are known to suffer from the curse of\nmultilinguality, which causes per-language performance to drop as they cover\nmore languages. We address this issue by introducing language-specific modules,\nwhich allows us to grow the total capacity of the model, while keeping the\ntotal number of trainable parameters per language constant. In contrast with\nprior work that learns language-specific components post-hoc, we pre-train the\nmodules of our Cross-lingual Modular (X-Mod) models from the start. Our\nexperiments on natural language inference, named entity recognition and\nquestion answering show that our approach not only mitigates the negative\ninterference between languages, but also enables positive transfer, resulting\nin improved monolingual and cross-lingual performance. Furthermore, our\napproach enables adding languages post-hoc with no measurable drop in\nperformance, no longer limiting the model usage to the set of pre-trained\nlanguages.", "published": "2022-05-12 17:59:56", "link": "http://arxiv.org/abs/2205.06266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Noun2Verb: Probabilistic frame semantics for word class conversion", "abstract": "Humans can flexibly extend word usages across different grammatical classes,\na phenomenon known as word class conversion. Noun-to-verb conversion, or\ndenominal verb (e.g., to Google a cheap flight), is one of the most prevalent\nforms of word class conversion. However, existing natural language processing\nsystems are impoverished in interpreting and generating novel denominal verb\nusages. Previous work has suggested that novel denominal verb usages are\ncomprehensible if the listener can compute the intended meaning based on shared\nknowledge with the speaker. Here we explore a computational formalism for this\nproposal couched in frame semantics. We present a formal framework, Noun2Verb,\nthat simulates the production and comprehension of novel denominal verb usages\nby modeling shared knowledge of speaker and listener in semantic frames. We\nevaluate an incremental set of probabilistic models that learn to interpret and\ngenerate novel denominal verb usages via paraphrasing. We show that a model\nwhere the speaker and listener cooperatively learn the joint distribution over\nsemantic frame elements better explains the empirical denominal verb usages\nthan state-of-the-art language models, evaluated against data from 1)\ncontemporary English in both adult and child speech, 2) contemporary Mandarin\nChinese, and 3) the historical development of English. Our work grounds word\nclass conversion in probabilistic frame semantics and bridges the gap between\nnatural language processing systems and humans in lexical creativity.", "published": "2022-05-12 19:16:12", "link": "http://arxiv.org/abs/2205.06321v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Economics of Multilingual Few-shot Learning: Modeling the\n  Cost-Performance Trade-offs of Machine Translated and Manual Data", "abstract": "Borrowing ideas from {\\em Production functions} in micro-economics, in this\npaper we introduce a framework to systematically evaluate the performance and\ncost trade-offs between machine-translated and manually-created labelled data\nfor task-specific fine-tuning of massively multilingual language models. We\nillustrate the effectiveness of our framework through a case-study on the\nTyDIQA-GoldP dataset. One of the interesting conclusions of the study is that\nif the cost of machine translation is greater than zero, the optimal\nperformance at least cost is always achieved with at least some or only\nmanually-created data. To our knowledge, this is the first attempt towards\nextending the concept of production functions to study data collection\nstrategies for training multilingual models, and can serve as a valuable tool\nfor other similar cost vs data trade-offs in NLP.", "published": "2022-05-12 20:27:01", "link": "http://arxiv.org/abs/2205.06350v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Static Models and Test Sets: Benchmarking the Potential of\n  Pre-trained Models Across Tasks and Languages", "abstract": "Although recent Massively Multilingual Language Models (MMLMs) like mBERT and\nXLMR support around 100 languages, most existing multilingual NLP benchmarks\nprovide evaluation data in only a handful of these languages with little\nlinguistic diversity. We argue that this makes the existing practices in\nmultilingual evaluation unreliable and does not provide a full picture of the\nperformance of MMLMs across the linguistic landscape. We propose that the\nrecent work done in Performance Prediction for NLP tasks can serve as a\npotential solution in fixing benchmarking in Multilingual NLP by utilizing\nfeatures related to data and language typology to estimate the performance of\nan MMLM on different languages. We compare performance prediction with\ntranslating test data with a case study on four different multilingual\ndatasets, and observe that these methods can provide reliable estimates of the\nperformance that are often on-par with the translation based approaches,\nwithout the need for any additional translation as well as evaluation costs.", "published": "2022-05-12 20:42:48", "link": "http://arxiv.org/abs/2205.06356v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Vocabulary Extreme Classification Using Generative Models", "abstract": "The extreme multi-label classification (XMC) task aims at tagging content\nwith a subset of labels from an extremely large label set. The label vocabulary\nis typically defined in advance by domain experts and assumed to capture all\nnecessary tags. However in real world scenarios this label set, although large,\nis often incomplete and experts frequently need to refine it. To develop\nsystems that simplify this process, we introduce the task of open vocabulary\nXMC (OXMC): given a piece of content, predict a set of labels, some of which\nmay be outside of the known tag set. Hence, in addition to not having training\ndata for some labels - as is the case in zero-shot classification - models need\nto invent some labels on-the-fly. We propose GROOV, a fine-tuned seq2seq model\nfor OXMC that generates the set of labels as a flat sequence and is trained\nusing a novel loss independent of predicted label order. We show the efficacy\nof the approach, experimenting with popular XMC datasets for which GROOV is\nable to predict meaningful labels outside the given vocabulary while performing\non par with state-of-the-art solutions for known labels.", "published": "2022-05-12 00:33:49", "link": "http://arxiv.org/abs/2205.05812v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition", "abstract": "Recently, Flat-LAttice Transformer (FLAT) has achieved great success in\nChinese Named Entity Recognition (NER). FLAT performs lexical enhancement by\nconstructing flat lattices, which mitigates the difficulties posed by blurred\nword boundaries and the lack of word semantics. In FLAT, the positions of\nstarting and ending characters are used to connect a matching word. However,\nthis method is likely to match more words when dealing with long texts,\nresulting in long input sequences. Therefore, it significantly increases the\nmemory and computational costs of the self-attention module. To deal with this\nissue, we advocate a novel lexical enhancement method, InterFormer, that\neffectively reduces the amount of computational and memory costs by\nconstructing non-flat lattices. Furthermore, with InterFormer as the backbone,\nwe implement NFLAT for Chinese NER. NFLAT decouples lexicon fusion and context\nfeature encoding. Compared with FLAT, it reduces unnecessary attention\ncalculations in \"word-character\" and \"word-word\". This reduces the memory usage\nby about 50% and can use more extensive lexicons or higher batches for network\ntraining. The experimental results obtained on several well-known benchmarks\ndemonstrate the superiority of the proposed method over the state-of-the-art\nhybrid (character-word) models.", "published": "2022-05-12 01:55:37", "link": "http://arxiv.org/abs/2205.05832v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "e-CARE: a New Dataset for Exploring Explainable Causal Reasoning", "abstract": "Understanding causality has vital importance for various Natural Language\nProcessing (NLP) applications. Beyond the labeled instances, conceptual\nexplanations of the causality can provide deep understanding of the causal\nfacts to facilitate the causal reasoning process. However, such explanation\ninformation still remains absent in existing causal reasoning resources. In\nthis paper, we fill this gap by presenting a human-annotated explainable CAusal\nREasoning dataset (e-CARE), which contains over 21K causal reasoning questions,\ntogether with natural language formed explanations of the causal questions.\nExperimental results show that generating valid explanations for causal facts\nstill remains especially challenging for the state-of-the-art models, and the\nexplanation information can be helpful for promoting the accuracy and stability\nof causal reasoning models.", "published": "2022-05-12 02:41:48", "link": "http://arxiv.org/abs/2205.05849v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Chit-Chats Enhanced Task-Oriented Dialogue Corpora for Fuse-Motive\n  Conversation Systems", "abstract": "The goal of building intelligent dialogue systems has largely been separately\npursued under two motives: task-oriented dialogue (TOD) systems, and\nopen-domain systems for chit-chat (CC). Although previous TOD dialogue systems\nwork well in the testing sets of benchmarks, they would lead to undesirable\nfailure when being exposed to natural scenarios in practice, where user\nutterances can be of high motive-diversity that fusing both TOD and CC in\nmulti-turn interaction. Since an industrial TOD system should be able to\nconverse with the user between TOD and CC motives, constructing a fuse-motive\ndialogue dataset that contains both TOD or CC is important. Most prior work\nrelies on crowd workers to collect and annotate large scale dataset and is\nrestricted to English language setting. Our work, on the contrary, addresses\nthis problem in a more effective way and releases a multi-turn dialogues\ndataset called CCET (Chinese Chat-Enhanced-Task). Meanwhile, we also propose a\nline of fuse-motive dialogues formalization approach, along with several\nevaluation metrics for TOD sessions that are integrated by CC utterances.", "published": "2022-05-12 05:43:18", "link": "http://arxiv.org/abs/2205.05886v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploiting Inductive Bias in Transformers for Unsupervised\n  Disentanglement of Syntax and Semantics with VAEs", "abstract": "We propose a generative model for text generation, which exhibits\ndisentangled latent representations of syntax and semantics. Contrary to\nprevious work, this model does not need syntactic information such as\nconstituency parses, or semantic information such as paraphrase pairs. Our\nmodel relies solely on the inductive bias found in attention-based\narchitectures such as Transformers.\n  In the attention of Transformers, keys handle information selection while\nvalues specify what information is conveyed. Our model, dubbed QKVAE, uses\nAttention in its decoder to read latent variables where one latent variable\ninfers keys while another infers values. We run experiments on latent\nrepresentations and experiments on syntax/semantics transfer which show that\nQKVAE displays clear signs of disentangled syntax and semantics. We also show\nthat our model displays competitive syntax transfer capabilities when compared\nto supervised models and that comparable supervised models need a fairly large\namount of data (more than 50K samples) to outperform it on both syntactic and\nsemantic transfer. The code for our experiments is publicly available.", "published": "2022-05-12 08:21:38", "link": "http://arxiv.org/abs/2205.05943v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Asking for Knowledge: Training RL Agents to Query External Knowledge\n  Using Language", "abstract": "To solve difficult tasks, humans ask questions to acquire knowledge from\nexternal sources. In contrast, classical reinforcement learning agents lack\nsuch an ability and often resort to exploratory behavior. This is exacerbated\nas few present-day environments support querying for knowledge. In order to\nstudy how agents can be taught to query external knowledge via language, we\nfirst introduce two new environments: the grid-world-based Q-BabyAI and the\ntext-based Q-TextWorld. In addition to physical interactions, an agent can\nquery an external knowledge source specialized for these environments to gather\ninformation. Second, we propose the \"Asking for Knowledge\" (AFK) agent, which\nlearns to generate language commands to query for meaningful knowledge that\nhelps solve the tasks. AFK leverages a non-parametric memory, a pointer\nmechanism and an episodic exploration bonus to tackle (1) irrelevant\ninformation, (2) a large query language space, (3) delayed reward for making\nmeaningful queries. Extensive experiments demonstrate that the AFK agent\noutperforms recent baselines on the challenging Q-BabyAI and Q-TextWorld\nenvironments.", "published": "2022-05-12 14:20:31", "link": "http://arxiv.org/abs/2205.06111v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Zero-shot Code-Mixed Offensive Span Identification through Rationale\n  Extraction", "abstract": "This paper investigates the effectiveness of sentence-level transformers for\nzero-shot offensive span identification on a code-mixed Tamil dataset. More\nspecifically, we evaluate rationale extraction methods of Local Interpretable\nModel Agnostic Explanations (LIME) \\cite{DBLP:conf/kdd/Ribeiro0G16} and\nIntegrated Gradients (IG) \\cite{DBLP:conf/icml/SundararajanTY17} for adapting\ntransformer based offensive language classification models for zero-shot\noffensive span identification. To this end, we find that LIME and IG show\nbaseline $F_{1}$ of 26.35\\% and 44.83\\%, respectively. Besides, we study the\neffect of data set size and training process on the overall accuracy of span\nidentification. As a result, we find both LIME and IG to show significant\nimprovement with Masked Data Augmentation and Multilabel Training, with $F_{1}$\nof 50.23\\% and 47.38\\% respectively. \\textit{Disclaimer : This paper contains\nexamples that may be considered profane, vulgar, or offensive. The examples do\nnot represent the views of the authors or their employers/graduate schools\ntowards any person(s), group(s), practice(s), or entity/entities. Instead they\nare used to emphasize only the linguistic research challenges.}", "published": "2022-05-12 14:32:12", "link": "http://arxiv.org/abs/2205.06119v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fair NLP Models with Differentially Private Text Encoders", "abstract": "Encoded text representations often capture sensitive attributes about\nindividuals (e.g., race or gender), which raise privacy concerns and can make\ndownstream models unfair to certain groups. In this work, we propose FEDERATE,\nan approach that combines ideas from differential privacy and adversarial\ntraining to learn private text representations which also induces fairer\nmodels. We empirically evaluate the trade-off between the privacy of the\nrepresentations and the fairness and accuracy of the downstream model on four\nNLP datasets. Our results show that FEDERATE consistently improves upon\nprevious methods, and thus suggest that privacy and fairness can positively\nreinforce each other.", "published": "2022-05-12 14:58:38", "link": "http://arxiv.org/abs/2205.06135v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Prefix-Tuning for Generative Template-based Event Extraction", "abstract": "We consider event extraction in a generative manner with template-based\nconditional generation. Although there is a rising trend of casting the task of\nevent extraction as a sequence generation problem with prompts, these\ngeneration-based methods have two significant challenges, including using\nsuboptimal prompts and static event type information. In this paper, we propose\na generative template-based event extraction method with dynamic prefix\n(GTEE-DynPref) by integrating context information with type-specific prefixes\nto learn a context-specific prefix for each context. Experimental results show\nthat our model achieves competitive results with the state-of-the-art\nclassification-based model OneIE on ACE 2005 and achieves the best performances\non ERE. Additionally, our model is proven to be portable to new types of events\neffectively.", "published": "2022-05-12 15:38:34", "link": "http://arxiv.org/abs/2205.06166v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What's in a Caption? Dataset-Specific Linguistic Diversity and Its\n  Effect on Visual Description Models and Metrics", "abstract": "While there have been significant gains in the field of automated video\ndescription, the generalization performance of automated description models to\nnovel domains remains a major barrier to using these systems in the real world.\nMost visual description methods are known to capture and exploit patterns in\nthe training data leading to evaluation metric increases, but what are those\npatterns? In this work, we examine several popular visual description datasets,\nand capture, analyze, and understand the dataset-specific linguistic patterns\nthat models exploit but do not generalize to new domains. At the token level,\nsample level, and dataset level, we find that caption diversity is a major\ndriving factor behind the generation of generic and uninformative captions. We\nfurther show that state-of-the-art models even outperform held-out ground truth\ncaptions on modern metrics, and that this effect is an artifact of linguistic\ndiversity in datasets. Understanding this linguistic diversity is key to\nbuilding strong captioning models, we recommend several methods and approaches\nfor maintaining diversity in the collection of new data, and dealing with the\nconsequences of limited diversity when using current models and metrics.", "published": "2022-05-12 17:55:08", "link": "http://arxiv.org/abs/2205.06253v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Using Natural Sentences for Understanding Biases in Language Models", "abstract": "Evaluation of biases in language models is often limited to synthetically\ngenerated datasets. This dependence traces back to the need for a prompt-style\ndataset to trigger specific behaviors of language models. In this paper, we\naddress this gap by creating a prompt dataset with respect to occupations\ncollected from real-world natural sentences present in Wikipedia. We aim to\nunderstand the differences between using template-based prompts and natural\nsentence prompts when studying gender-occupation biases in language models. We\nfind bias evaluations are very sensitive to the design choices of template\nprompts, and we propose using natural sentence prompts for systematic\nevaluations to step away from design choices that could introduce bias in the\nobservations.", "published": "2022-05-12 18:36:33", "link": "http://arxiv.org/abs/2205.06303v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bridging the Gap between Reality and Ideality of Entity Matching: A\n  Revisiting and Benchmark Re-Construction", "abstract": "Entity matching (EM) is the most critical step for entity resolution (ER).\nWhile current deep learningbased methods achieve very impressive performance on\nstandard EM benchmarks, their realworld application performance is much\nfrustrating. In this paper, we highlight that such the gap between reality and\nideality stems from the unreasonable benchmark construction process, which is\ninconsistent with the nature of entity matching and therefore leads to biased\nevaluations of current EM approaches. To this end, we build a new EM corpus and\nre-construct EM benchmarks to challenge critical assumptions implicit in the\nprevious benchmark construction process by step-wisely changing the restricted\nentities, balanced labels, and single-modal records in previous benchmarks into\nopen entities, imbalanced labels, and multimodal records in an open\nenvironment. Experimental results demonstrate that the assumptions made in the\nprevious benchmark construction process are not coincidental with the open\nenvironment, which conceal the main challenges of the task and therefore\nsignificantly overestimate the current progress of entity matching. The\nconstructed benchmarks and code are publicly released", "published": "2022-05-12 05:50:30", "link": "http://arxiv.org/abs/2205.05889v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Towards Answering Open-ended Ethical Quandary Questions", "abstract": "Considerable advancements have been made in various NLP tasks based on the\nimpressive power of large language models (LLMs) and many NLP applications are\ndeployed in our daily lives. In this work, we challenge the capability of LLMs\nwith the new task of Ethical Quandary Generative Question Answering. Ethical\nquandary questions are more challenging to address because multiple conflicting\nanswers may exist to a single quandary. We explore the current capability of\nLLMs in providing an answer with a deliberative exchange of different\nperspectives to an ethical quandary, in the approach of Socratic philosophy,\ninstead of providing a closed answer like an oracle. We propose a model that\nsearches for different ethical principles applicable to the ethical quandary\nand generates an answer conditioned on the chosen principles through\nprompt-based few-shot learning. We also discuss the remaining challenges and\nethical issues involved in this task and suggest the direction toward\ndeveloping responsible NLP systems by incorporating human values explicitly.", "published": "2022-05-12 09:52:59", "link": "http://arxiv.org/abs/2205.05989v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "One Model, Multiple Modalities: A Sparsely Activated Approach for Text,\n  Sound, Image, Video and Code", "abstract": "People perceive the world with multiple senses (e.g., through hearing sounds,\nreading words and seeing objects). However, most existing AI systems only\nprocess an individual modality. This paper presents an approach that excels at\nhandling multiple modalities of information with a single model. In our\n\"{SkillNet}\" model, different parts of the parameters are specialized for\nprocessing different modalities. Unlike traditional dense models that always\nactivate all the model parameters, our model sparsely activates parts of the\nparameters whose skills are relevant to the task. Such model design enables\nSkillNet to learn skills in a more interpretable way. We develop our model for\nfive modalities including text, image, sound, video and code. Results show\nthat, SkillNet performs comparably to five modality-specific fine-tuned models.\nMoreover, our model supports self-supervised pretraining with the same sparsely\nactivated way, resulting in better initialized parameters for different\nmodalities. We find that pretraining significantly improves the performance of\nSkillNet on five modalities, on par with or even better than baselines with\nmodality-specific pretraining. On the task of Chinese text-to-image retrieval,\nour final system achieves higher accuracy than existing leading systems\nincluding Wukong{ViT-B} and Wenlan 2.0 while using less number of activated\nparameters.", "published": "2022-05-12 14:39:21", "link": "http://arxiv.org/abs/2205.06126v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Generalist Agent", "abstract": "Inspired by progress in large-scale language modeling, we apply a similar\napproach towards building a single generalist agent beyond the realm of text\noutputs. The agent, which we refer to as Gato, works as a multi-modal,\nmulti-task, multi-embodiment generalist policy. The same network with the same\nweights can play Atari, caption images, chat, stack blocks with a real robot\narm and much more, deciding based on its context whether to output text, joint\ntorques, button presses, or other tokens. In this report we describe the model\nand the data, and document the current capabilities of Gato.", "published": "2022-05-12 16:03:26", "link": "http://arxiv.org/abs/2205.06175v3", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "ScAN: Suicide Attempt and Ideation Events Dataset", "abstract": "Suicide is an important public health concern and one of the leading causes\nof death worldwide. Suicidal behaviors, including suicide attempts (SA) and\nsuicide ideations (SI), are leading risk factors for death by suicide.\nInformation related to patients' previous and current SA and SI are frequently\ndocumented in the electronic health record (EHR) notes. Accurate detection of\nsuch documentation may help improve surveillance and predictions of patients'\nsuicidal behaviors and alert medical professionals for suicide prevention\nefforts. In this study, we first built Suicide Attempt and Ideation Events\n(ScAN) dataset, a subset of the publicly available MIMIC III dataset spanning\nover 12k+ EHR notes with 19k+ annotated SA and SI events information. The\nannotations also contain attributes such as method of suicide attempt. We also\nprovide a strong baseline model ScANER (Suicide Attempt and Ideation Events\nRetriever), a multi-task RoBERTa-based model with a retrieval module to extract\nall the relevant suicidal behavioral evidences from EHR notes of an\nhospital-stay and, and a prediction module to identify the type of suicidal\nbehavior (SA and SI) concluded during the patient's stay at the hospital.\nScANER achieved a macro-weighted F1-score of 0.83 for identifying suicidal\nbehavioral evidences and a macro F1-score of 0.78 and 0.60 for classification\nof SA and SI for the patient's hospital-stay, respectively. ScAN and ScANER are\npublicly available.", "published": "2022-05-12 17:11:07", "link": "http://arxiv.org/abs/2205.07872v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Data-aided Underwater Acoustic Ray Propagation Modeling", "abstract": "Acoustic propagation models are widely used in numerous oceanic and other\nunderwater applications. Most conventional models are approximate solutions of\nthe acoustic wave equation, and require accurate environmental knowledge to be\navailable beforehand. Environmental parameters may not always be easily or\naccurately measurable. While data-driven techniques might allow us to model\nacoustic propagation without the need for extensive prior environmental\nknowledge, such techniques tend to be data-hungry and often infeasible in\noceanic applications where data collection is difficult and expensive. We\npropose a data-aided ray physics based high frequency acoustic propagation\nmodeling approach that enables us to train models with only a small amount of\ndata. The proposed framework is not only data-efficient, but also offers\nflexibility to incorporate varying degrees of environmental knowledge, and\ngeneralizes well to permit extrapolation beyond the area where data was\ncollected. We demonstrate the feasibility and applicability of our method\nthrough four numerical case studies, and one controlled experiment. We also\nbenchmark our method's performance against classical data-driven techniques.", "published": "2022-05-12 13:00:11", "link": "http://arxiv.org/abs/2205.06066v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Training Strategies for Own Voice Reconstruction in Hearing Protection\n  Devices using an In-ear Microphone", "abstract": "In-ear microphones in hearing protection devices can be utilized to capture\nthe own voice speech of the person wearing the devices in noisy environments.\nSince in-ear recordings of the own voice are typically band-limited, an own\nvoice reconstruction system is required to recover clean broadband speech from\nthe in-ear signals. However, the availability of speech data for this scenario\nis typically limited due to device-specific transfer characteristics and the\nneed to collect data from in-situ measurements. In this paper, we apply a deep\nlearning-based bandwidth-extension system to the own voice reconstruction task\nand investigate different training strategies in order to overcome the limited\navailability of training data. Experimental results indicate that the use of\nsimulated training data based on recordings of several talkers in combination\nwith a fine-tuning approach using real data is advantageous compared to\ndirectly training on a small real dataset.", "published": "2022-05-12 15:27:20", "link": "http://arxiv.org/abs/2205.06157v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Robust Unsupervised Disentanglement of Sequential Data -- A Case\n  Study Using Music Audio", "abstract": "Disentangled sequential autoencoders (DSAEs) represent a class of\nprobabilistic graphical models that describes an observed sequence with dynamic\nlatent variables and a static latent variable. The former encode information at\na frame rate identical to the observation, while the latter globally governs\nthe entire sequence. This introduces an inductive bias and facilitates\nunsupervised disentanglement of the underlying local and global factors. In\nthis paper, we show that the vanilla DSAE suffers from being sensitive to the\nchoice of model architecture and capacity of the dynamic latent variables, and\nis prone to collapse the static latent variable. As a countermeasure, we\npropose TS-DSAE, a two-stage training framework that first learns\nsequence-level prior distributions, which are subsequently employed to\nregularise the model and facilitate auxiliary objectives to promote\ndisentanglement. The proposed framework is fully unsupervised and robust\nagainst the global factor collapse problem across a wide range of model\nconfigurations. It also avoids typical solutions such as adversarial training\nwhich usually involves laborious parameter tuning, and domain-specific data\naugmentation. We conduct quantitative and qualitative evaluations to\ndemonstrate its robustness in terms of disentanglement on both artificial and\nreal-world music audio datasets.", "published": "2022-05-12 04:11:25", "link": "http://arxiv.org/abs/2205.05871v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automated Audio Captioning: An Overview of Recent Progress and New\n  Challenges", "abstract": "Automated audio captioning is a cross-modal translation task that aims to\ngenerate natural language descriptions for given audio clips. This task has\nreceived increasing attention with the release of freely available datasets in\nrecent years. The problem has been addressed predominantly with deep learning\ntechniques. Numerous approaches have been proposed, such as investigating\ndifferent neural network architectures, exploiting auxiliary information such\nas keywords or sentence information to guide caption generation, and employing\ndifferent training strategies, which have greatly facilitated the development\nof this field. In this paper, we present a comprehensive review of the\npublished contributions in automated audio captioning, from a variety of\nexisting approaches to evaluation metrics and datasets. We also discuss open\nchallenges and envisage possible future research directions.", "published": "2022-05-12 08:36:35", "link": "http://arxiv.org/abs/2205.05949v2", "categories": ["eess.AS", "cs.AI", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Unified Source-Filter GAN with Harmonic-plus-Noise Source Excitation\n  Generation", "abstract": "This paper introduces a unified source-filter network with a\nharmonic-plus-noise source excitation generation mechanism. In our previous\nwork, we proposed unified Source-Filter GAN (uSFGAN) for developing a\nhigh-fidelity neural vocoder with flexible voice controllability using a\nunified source-filter neural network architecture. However, the capability of\nuSFGAN to model the aperiodic source excitation signal is insufficient, and\nthere is still a gap in sound quality between the natural and generated speech.\nTo improve the source excitation modeling and generated sound quality, a new\nsource excitation generation network separately generating periodic and\naperiodic components is proposed. The advanced adversarial training procedure\nof HiFiGAN is also adopted to replace that of Parallel WaveGAN used in the\noriginal uSFGAN. Both objective and subjective evaluation results show that the\nmodified uSFGAN significantly improves the sound quality of the basic uSFGAN\nwhile maintaining the voice controllability.", "published": "2022-05-12 12:41:15", "link": "http://arxiv.org/abs/2205.06053v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
