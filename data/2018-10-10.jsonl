{"title": "Improving Neural Text Simplification Model with Simplified Corpora", "abstract": "Text simplification (TS) can be viewed as monolingual translation task,\ntranslating between text variations within a single language. Recent neural TS\nmodels draw on insights from neural machine translation to learn lexical\nsimplification and content reduction using encoder-decoder model. But different\nfrom neural machine translation, we cannot obtain enough ordinary and\nsimplified sentence pairs for TS, which are expensive and time-consuming to\nbuild. Target-side simplified sentences plays an important role in boosting\nfluency for statistical TS, and we investigate the use of simplified sentences\nto train, with no changes to the network architecture. We propose to pair\nsimple training sentence with a synthetic ordinary sentence via\nback-translation, and treating this synthetic data as additional training data.\nWe train encoder-decoder model using synthetic sentence pairs and original\nsentence pairs, which can obtain substantial improvements on the available\nWikiLarge data and WikiSmall data compared with the state-of-the-art methods.", "published": "2018-10-10 09:14:06", "link": "http://arxiv.org/abs/1810.04428v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "New Vistas to study Bhartrhari: Cognitive NLP", "abstract": "The Sanskrit grammatical tradition which has commenced with Panini's\nAstadhyayi mostly as a Padasastra has culminated as a Vakyasastra, at the hands\nof Bhartrhari. The grammarian-philosopher Bhartrhari and his authoritative work\n'Vakyapadiya' have been a matter of study for modern scholars, at least for\nmore than 50 years, since Ashok Aklujkar submitted his Ph.D. dissertation at\nHarvard University. The notions of a sentence and a word as a meaningful\nlinguistic unit in the language have been a subject matter for the discussion\nin many works that followed later on. While some scholars have applied\nphilological techniques to critically establish the text of the works of\nBhartrhari, some others have devoted themselves to exploring philosophical\ninsights from them. Some others have studied his works from the point of view\nof modern linguistics, and psychology. Few others have tried to justify the\nviews by logical discussions.\n  In this paper, we present a fresh view to study Bhartrhari, and his works,\nespecially the 'Vakyapadiya'. This view is from the field of Natural Language\nProcessing (NLP), more specifically, what is called as Cognitive NLP. We have\nstudied the definitions of a sentence given by Bhartrhari at the beginning of\nthe second chapter of 'Vakyapadiya'. We have researched one of these\ndefinitions by conducting an experiment and following the methodology of\nsilent-reading of Sanskrit paragraphs. We collect the Gaze-behavior data of\nparticipants and analyze it to understand the underlying comprehension\nprocedure in the human mind and present our results. We evaluate the\nstatistical significance of our results using T-test, and discuss the caveats\nof our work. We also present some general remarks on this experiment and\nusefulness of this method for gaining more insights in the work of Bhartrhari.", "published": "2018-10-10 10:00:17", "link": "http://arxiv.org/abs/1810.04440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Arguments from Korean Question and Command: An Annotated\n  Corpus for Structured Paraphrasing", "abstract": "Intention identification is a core issue in dialog management. However, due\nto the non-canonicality of the spoken language, it is difficult to extract the\ncontent automatically from the conversation-style utterances. This is much more\nchallenging for languages like Korean and Japanese since the agglutination\nbetween morphemes make it difficult for the machines to parse the sentence and\nunderstand the intention. To suggest a guideline for this problem, and to merge\nthe issue flexibly with the neural paraphrasing systems introduced recently, we\npropose a structured annotation scheme for Korean question/commands and the\nresulting corpus which are widely applicable to the field of argument mining.\nThe scheme and dataset are expected to help machines understand the intention\nof natural language and grasp the core meaning of conversation-style\ninstructions.", "published": "2018-10-10 16:46:41", "link": "http://arxiv.org/abs/1810.04631v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Speech Emotion Recognition Using Audio and Text", "abstract": "Speech emotion recognition is a challenging task, and extensive reliance has\nbeen placed on models that use audio features in building well-performing\nclassifiers. In this paper, we propose a novel deep dual recurrent encoder\nmodel that utilizes text data and audio signals simultaneously to obtain a\nbetter understanding of speech data. As emotional dialogue is composed of sound\nand spoken content, our model encodes the information from audio and text\nsequences using dual recurrent neural networks (RNNs) and then combines the\ninformation from these sources to predict the emotion class. This architecture\nanalyzes speech data from the signal level to the language level, and it thus\nutilizes the information within the data more comprehensively than models that\nfocus on audio features. Extensive experiments are conducted to investigate the\nefficacy and properties of the proposed model. Our proposed model outperforms\nprevious state-of-the-art methods in assigning data to one of four emotion\ncategories (i.e., angry, happy, sad and neutral) when the model is applied to\nthe IEMOCAP dataset, as reflected by accuracies ranging from 68.8% to 71.8%.", "published": "2018-10-10 16:51:58", "link": "http://arxiv.org/abs/1810.04635v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is there Gender bias and stereotype in Portuguese Word Embeddings?", "abstract": "In this work, we propose an analysis of the presence of gender bias\nassociated with professions in Portuguese word embeddings. The objective of\nthis work is to study gender implications related to stereotyped professions\nfor women and men in the context of the Portuguese language.", "published": "2018-10-10 13:42:16", "link": "http://arxiv.org/abs/1810.04528v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "End-to-End Content and Plan Selection for Data-to-Text Generation", "abstract": "Learning to generate fluent natural language from structured data with neural\nnetworks has become an common approach for NLG. This problem can be challenging\nwhen the form of the structured data varies between examples. This paper\npresents a survey of several extensions to sequence-to-sequence models to\naccount for the latent content selection process, particularly variants of copy\nattention and coverage decoding. We further propose a training method based on\ndiverse ensembling to encourage models to learn distinct sentence templates\nduring training. An empirical evaluation of these techniques shows an increase\nin the quality of generated text across five automated metrics, as well as\nhuman evaluation.", "published": "2018-10-10 18:36:04", "link": "http://arxiv.org/abs/1810.04700v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Textual Specifications for Grammar-based Fuzzing of Network\n  Protocols", "abstract": "Grammar-based fuzzing is a technique used to find software vulnerabilities by\ninjecting well-formed inputs generated following rules that encode application\nsemantics. Most grammar-based fuzzers for network protocols rely on human\nexperts to manually specify these rules. In this work we study automated\nlearning of protocol rules from textual specifications (i.e. RFCs). We evaluate\nthe automatically extracted protocol rules by applying them to a\nstate-of-the-art fuzzer for transport protocols and show that it leads to a\nsmaller number of test cases while finding the same attacks as the system that\nuses manually specified rules.", "published": "2018-10-10 21:42:29", "link": "http://arxiv.org/abs/1810.04755v1", "categories": ["cs.CR", "cs.CL", "cs.NI"], "primary_category": "cs.CR"}
{"title": "Exploring the Use of Attention within an Neural Machine Translation\n  Decoder States to Translate Idioms", "abstract": "Idioms pose problems to almost all Machine Translation systems. This type of\nlanguage is very frequent in day-to-day language use and cannot be simply\nignored. The recent interest in memory augmented models in the field of\nLanguage Modelling has aided the systems to achieve good results by bridging\nlong-distance dependencies. In this paper we explore the use of such techniques\ninto a Neural Machine Translation system to help in translation of idiomatic\nlanguage.", "published": "2018-10-10 09:57:32", "link": "http://arxiv.org/abs/1810.06695v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Multimodal Approach towards Emotion Recognition of Music using Audio\n  and Lyrical Content", "abstract": "We propose MoodNet - A Deep Convolutional Neural Network based architecture\nto effectively predict the emotion associated with a piece of music given its\naudio and lyrical content.We evaluate different architectures consisting of\nvarying number of two-dimensional convolutional and subsampling layers,followed\nby dense layers.We use Mel-Spectrograms to represent the audio content and word\nembeddings-specifically 100 dimensional word vectors, to represent the textual\ncontent represented by the lyrics.We feed input data from both modalities to\nour MoodNet architecture.The output from both the modalities are then fused as\na fully connected layer and softmax classfier is used to predict the category\nof emotion.Using F1-score as our metric,our results show excellent performance\nof MoodNet over the two datasets we experimented on-The MIREX Multimodal\ndataset and the Million Song Dataset.Our experiments reflect the hypothesis\nthat more complex models perform better with more training data.We also observe\nthat lyrics outperform audio as a better expressed modality and conclude that\ncombining and using features from multiple modalities for prediction tasks\nresult in superior performance in comparison to using a single modality as\ninput.", "published": "2018-10-10 20:51:03", "link": "http://arxiv.org/abs/1811.05760v1", "categories": ["eess.AS", "cs.CL", "cs.CV", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "On Time-frequency Scattering and Computer Music", "abstract": "Time-frequency scattering is a mathematical transformation of sound waves.\nIts core purpose is to mimick the way the human auditory system extracts\ninformation from its environment. In the context of improving the artificial\nintelligence of sounds, it has found succesful applications in automatic speech\ntranscription as well as the recognition of urban sounds and musical sounds. In\nthis article, we show that time-frequency scattering can also be useful for\napplications in contemporary music creations.", "published": "2018-10-10 13:19:27", "link": "http://arxiv.org/abs/1810.04506v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fully Supervised Speaker Diarization", "abstract": "In this paper, we propose a fully supervised speaker diarization approach,\nnamed unbounded interleaved-state recurrent neural networks (UIS-RNN). Given\nextracted speaker-discriminative embeddings (a.k.a. d-vectors) from input\nutterances, each individual speaker is modeled by a parameter-sharing RNN,\nwhile the RNN states for different speakers interleave in the time domain. This\nRNN is naturally integrated with a distance-dependent Chinese restaurant\nprocess (ddCRP) to accommodate an unknown number of speakers. Our system is\nfully supervised and is able to learn from examples where time-stamped speaker\nlabels are annotated. We achieved a 7.6% diarization error rate on NIST SRE\n2000 CALLHOME, which is better than the state-of-the-art method using spectral\nclustering. Moreover, our method decodes in an online fashion while most\nstate-of-the-art systems rely on offline clustering.", "published": "2018-10-10 19:21:44", "link": "http://arxiv.org/abs/1810.04719v7", "categories": ["eess.AS", "cs.LG", "stat.ML"], "primary_category": "eess.AS"}
