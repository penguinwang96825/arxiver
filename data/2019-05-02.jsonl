{"title": "KnowBias: A Novel AI Method to Detect Polarity in Online Content", "abstract": "We propose a novel training and inference method for detecting political bias\nin long text content such as newspaper opinion articles. Obtaining long text\ndata and annotations at sufficient scale for training is difficult, but it is\nrelatively easy to extract political polarity from tweets through their\nauthorship; as such, we train on tweets and perform inference on articles.\nUniversal sentence encoders and other existing methods that aim to address this\ndomain-adaptation scenario deliver inaccurate and inconsistent predictions on\narticles, which we show is due to a difference in opinion concentration between\ntweets and articles. We propose a two-step classification scheme that utilizes\na neutral detector trained on tweets to remove neutral sentences from articles\nin order to align opinion concentration and therefore improve accuracy on that\ndomain.\n  We evaluate our two-step approach using a variety of test suites, including a\nset of tweets and long-form articles where annotations were crowd-sourced to\ndecrease label noise, measuring accuracy and Spearman-rho rank correlation. In\npractice, KnowBias achieves a high accuracy of 86 (rho = 0.65) on these tweets\nand 75 (rho = 0.69) on long-form articles. While we validate our method on\npolitical bias, our scheme is general and can be readily applied to other\nsettings, where there exist such domain mismatches between source and target\ndomains. Our implementation is available for public use at https://knowbias.ml.", "published": "2019-05-02 13:24:55", "link": "http://arxiv.org/abs/1905.00724v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context awareness and embedding for biomedical event extraction", "abstract": "Motivation: Biomedical event detection is fundamental for information\nextraction in molecular biology and biomedical research. The detected events\nform the central basis for comprehensive biomedical knowledge fusion,\nfacilitating the digestion of massive information influx from literature.\nLimited by the feature context, the existing event detection models are mostly\napplicable for a single task. A general and scalable computational model is\ndesiderated for biomedical knowledge management. Results: We consider and\npropose a bottom-up detection framework to identify the events from recognized\narguments. To capture the relations between the arguments, we trained a\nbi-directional Long Short-Term Memory (LSTM) network to model their context\nembedding. Leveraging the compositional attributes, we further derived the\ncandidate samples for training event classifiers. We built our models on the\ndatasets from BioNLP Shared Task for evaluations. Our method achieved the\naverage F-scores of 0.81 and 0.92 on BioNLPST-BGI and BioNLPST-BB datasets\nrespectively. Comparing with 7 state-of-the-art methods, our method nearly\ndoubled the existing F-score performance (0.92 vs 0.56) on the BioNLPST-BB\ndataset. Case studies were conducted to reveal the underlying reasons.\nAvailability: https://github.com/cskyan/evntextrc", "published": "2019-05-02 22:01:57", "link": "http://arxiv.org/abs/1905.00982v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language\n  Understanding Systems", "abstract": "In the last year, new models and methods for pretraining and transfer\nlearning have driven striking performance improvements across a range of\nlanguage understanding tasks. The GLUE benchmark, introduced a little over one\nyear ago, offers a single-number metric that summarizes progress on a diverse\nset of such tasks, but performance on the benchmark has recently surpassed the\nlevel of non-expert humans, suggesting limited headroom for further research.\nIn this paper we present SuperGLUE, a new benchmark styled after GLUE with a\nnew set of more difficult language understanding tasks, a software toolkit, and\na public leaderboard. SuperGLUE is available at super.gluebenchmark.com.", "published": "2019-05-02 00:41:50", "link": "http://arxiv.org/abs/1905.00537v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Argument Identification in Public Comments from eRulemaking", "abstract": "Administrative agencies in the United States receive millions of comments\neach year concerning proposed agency actions during the eRulemaking process.\nThese comments represent a diversity of arguments in support and opposition of\nthe proposals. While agencies are required to identify and respond to\nsubstantive comments, they have struggled to keep pace with the volume of\ninformation. In this work we address the tasks of identifying argumentative\ntext, classifying the type of argument claims employed, and determining the\nstance of the comment. First, we propose a taxonomy of argument claims based on\nan analysis of thousands of rules and millions of comments. Second, we collect\nand semi-automatically bootstrap annotations to create a dataset of millions of\nsentences with argument claim type annotation at the sentence level. Third, we\nbuild a system for automatically determining argumentative spans and claim type\nusing our proposed taxonomy in a hierarchical classification model.", "published": "2019-05-02 05:04:03", "link": "http://arxiv.org/abs/1905.00572v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Authoring and Question Answering with KALM", "abstract": "Knowledge representation and reasoning (KRR) is one of the key areas in\nartificial intelligence (AI) field. It is intended to represent the world\nknowledge in formal languages (e.g., Prolog, SPARQL) and then enhance the\nexpert systems to perform querying and inference tasks. Currently, constructing\nlarge scale knowledge bases (KBs) with high quality is prohibited by the fact\nthat the construction process requires many qualified knowledge engineers who\nnot only understand the domain-specific knowledge but also have sufficient\nskills in knowledge representation. Unfortunately, qualified knowledge\nengineers are in short supply. Therefore, it would be very useful to build a\ntool that allows the user to construct and query the KB simply via text.\nAlthough there is a number of systems developed for knowledge extraction and\nquestion answering, they mainly fail in that these system don't achieve high\nenough accuracy whereas KRR is highly sensitive to erroneous data. In this\nthesis proposal, I will present Knowledge Authoring Logic Machine (KALM), a\nrule-based system which allows the user to author knowledge and query the KB in\ntext. The experimental results show that KALM achieved superior accuracy in\nknowledge authoring and question answering as compared to the state-of-the-art\nsystems.", "published": "2019-05-02 16:39:55", "link": "http://arxiv.org/abs/1905.00840v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Investigating Robustness and Interpretability of Link Prediction via\n  Adversarial Modifications", "abstract": "Representing entities and relations in an embedding space is a well-studied\napproach for machine learning on relational data. Existing approaches, however,\nprimarily focus on improving accuracy and overlook other aspects such as\nrobustness and interpretability. In this paper, we propose adversarial\nmodifications for link prediction models: identifying the fact to add into or\nremove from the knowledge graph that changes the prediction for a target fact\nafter the model is retrained. Using these single modifications of the graph, we\nidentify the most influential fact for a predicted link and evaluate the\nsensitivity of the model to the addition of fake facts. We introduce an\nefficient approach to estimate the effect of such modifications by\napproximating the change in the embeddings when the knowledge graph changes. To\navoid the combinatorial search over all possible facts, we train a network to\ndecode embeddings to their corresponding graph components, allowing the use of\ngradient-based optimization to identify the adversarial modification. We use\nthese techniques to evaluate the robustness of link prediction models (by\nmeasuring sensitivity to additional facts), study interpretability through the\nfacts most responsible for predictions (by identifying the most influential\nneighbors), and detect incorrect facts in the knowledge base.", "published": "2019-05-02 03:30:17", "link": "http://arxiv.org/abs/1905.00563v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Compression of Acoustic Event Detection Models with Low-rank Matrix\n  Factorization and Quantization Training", "abstract": "In this paper, we present a compression approach based on the combination of\nlow-rank matrix factorization and quantization training, to reduce complexity\nfor neural network based acoustic event detection (AED) models. Our\nexperimental results show this combined compression approach is very effective.\nFor a three-layer long short-term memory (LSTM) based AED model, the original\nmodel size can be reduced to 1% with negligible loss of accuracy. Our approach\nenables the feasibility of deploying AED for resource-constraint applications.", "published": "2019-05-02 17:07:38", "link": "http://arxiv.org/abs/1905.00855v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Locale-agnostic Universal Domain Classification Model in Spoken Language\n  Understanding", "abstract": "In this paper, we introduce an approach for leveraging available data across\nmultiple locales sharing the same language to 1) improve domain classification\nmodel accuracy in Spoken Language Understanding and user experience even if new\nlocales do not have sufficient data and 2) reduce the cost of scaling the\ndomain classifier to a large number of locales. We propose a locale-agnostic\nuniversal domain classification model based on selective multi-task learning\nthat learns a joint representation of an utterance over locales with different\nsets of domains and allows locales to share knowledge selectively depending on\nthe domains. The experimental results demonstrate the effectiveness of our\napproach on domain classification task in the scenario of multiple locales with\nimbalanced data and disparate domain sets. The proposed approach outperforms\nother baselines models especially when classifying locale-specific domains and\nalso low-resourced domains.", "published": "2019-05-02 18:23:47", "link": "http://arxiv.org/abs/1905.00924v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Topic-Agnostic Approach for Identifying Fake News Pages", "abstract": "Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.", "published": "2019-05-02 20:50:22", "link": "http://arxiv.org/abs/1905.00957v1", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Conditioning LSTM Decoder and Bi-directional Attention Based Question\n  Answering System", "abstract": "Applying neural-networks on Question Answering has gained increasing\npopularity in recent years. In this paper, I implemented a model with\nBi-directional attention flow layer, connected with a Multi-layer LSTM encoder,\nconnected with one start-index decoder and one conditioning end-index decoder.\nI introduce a new end-index decoder layer, conditioning on start-index output.\nThe Experiment shows this has increased model performance by 15.16%. For\nprediction, I proposed a new smart-span equation, rewarding both short answer\nlength and high probability in start-index and end-index, which further\nimproved the prediction accuracy. The best single model achieves an F1 score of\n73.97% and EM score of 64.95% on test set.", "published": "2019-05-02 01:07:20", "link": "http://arxiv.org/abs/1905.02019v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "High quality, lightweight and adaptable TTS using LPCNet", "abstract": "We present a lightweight adaptable neural TTS system with high quality\noutput. The system is composed of three separate neural network blocks: prosody\nprediction, acoustic feature prediction and Linear Prediction Coding Net as a\nneural vocoder. This system can synthesize speech with close to natural quality\nwhile running 3 times faster than real-time on a standard CPU. The modular\nsetup of the system allows for simple adaptation to new voices with a small\namount of data. We first demonstrate the ability of the system to produce high\nquality speech when trained on large, high quality datasets. Following that, we\ndemonstrate its adaptability by mimicking unseen voices using 5 to 20 minutes\nlong datasets with lower recording quality. Large scale Mean Opinion Score\nquality and similarity tests are presented, showing that the system can adapt\nto unseen voices with quality gap of 0.12 and similarity gap of 3% compared to\nnatural speech for male voices and quality gap of 0.35 and similarity of gap of\n9 % for female voices.", "published": "2019-05-02 06:57:52", "link": "http://arxiv.org/abs/1905.00590v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Investigation of F0 conditioning and Fully Convolutional Networks in\n  Variational Autoencoder based Voice Conversion", "abstract": "In this work, we investigate the effectiveness of two techniques for\nimproving variational autoencoder (VAE) based voice conversion (VC). First, we\nreconsider the relationship between vocoder features extracted using the high\nquality vocoders adopted in conventional VC systems, and hypothesize that the\nspectral features are in fact F0 dependent. Such hypothesis implies that during\nthe conversion phase, the latent codes and the converted features in VAE based\nVC are in fact source F0 dependent. To this end, we propose to utilize the F0\nas an additional input of the decoder. The model can learn to disentangle the\nlatent code from the F0 and thus generates converted F0 dependent converted\nfeatures. Second, to better capture temporal dependencies of the spectral\nfeatures and the F0 pattern, we replace the frame wise conversion structure in\nthe original VAE based VC framework with a fully convolutional network\nstructure. Our experiments demonstrate that the degree of disentanglement as\nwell as the naturalness of the converted speech are indeed improved.", "published": "2019-05-02 08:26:57", "link": "http://arxiv.org/abs/1905.00615v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Psychoacoustically Motivated Audio Declipping Based on Weighted l1\n  Minimization", "abstract": "A novel method for audio declipping based on sparsity is presented. The\nmethod incorporates psychoacoustic information by weighting the transform\ncoefficients in the $\\ell_1$ minimization. Weighting leads to an improved\nquality of restoration while retaining a low complexity of the algorithm. Three\npossible constructions of the weights are proposed, based on the absolute\nthreshold of hearing, the global masking threshold and on a quadratic curve.\nExperiments compare the restoration quality according to the\nsignal-to-distortion ratio (SDR) and PEMO-Q objective difference grade (ODG)\nand indicate that with correctly chosen weights, the presented method is able\nto compete, or even outperform, the current state of the art.", "published": "2019-05-02 09:12:15", "link": "http://arxiv.org/abs/1905.00628v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "City classification from multiple real-world sound scenes", "abstract": "The majority of sound scene analysis work focuses on one of two clearly\ndefined tasks: acoustic scene classification or sound event detection. Whilst\nthis separation of tasks is useful for problem definition, they inherently\nignore some subtleties of the real-world, in particular how humans vary in how\nthey describe a scene. Some will describe the weather and features within it,\nothers will use a holistic descriptor like `park', and others still will use\nunique identifiers such as cities or names. In this paper, we undertake the\ntask of automatic city classification to ask whether we can recognize a city\nfrom a set of sound scenes? In this problem each city has recordings from\nmultiple scenes. We test a series of methods for this novel task and show that\na simple convolutional neural network (CNN) can achieve accuracy of 50%. This\nis less than the acoustic scene classification task baseline in the DCASE 2018\nASC challenge on the same data. A simple adaptation to the class labels of\npairing city labels with grouped scenes, accuracy increases to 52%, closer to\nthe simpler scene classification task. Finally we also formulate the problem in\na multi-task learning framework and achieve an accuracy of 56%, outperforming\nthe aforementioned approaches.", "published": "2019-05-02 22:01:10", "link": "http://arxiv.org/abs/1905.00979v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
