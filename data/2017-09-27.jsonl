{"title": "Learning of Colors from Color Names: Distribution and Point Estimation", "abstract": "Color names are often made up of multiple words. As a task in natural\nlanguage understanding we investigate in depth the capacity of neural networks\nbased on sums of word embeddings (SOWE), recurrence (LSTM and GRU based RNNs)\nand convolution (CNN), to estimate colors from sequences of terms. We consider\nboth point and distribution estimates of color. We argue that the latter has a\nparticular value as there is no clear agreement between people as to what a\nparticular color describes -- different people have a different idea of what it\nmeans to be ``very dark orange'', for example. Surprisingly, despite it's\nsimplicity, the sum of word embeddings generally performs the best on almost\nall evaluations.", "published": "2017-09-27 07:06:05", "link": "http://arxiv.org/abs/1709.09360v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prosodic Features from Large Corpora of Child-Directed Speech as\n  Predictors of the Age of Acquisition of Words", "abstract": "The impressive ability of children to acquire language is a widely studied\nphenomenon, and the factors influencing the pace and patterns of word learning\nremains a subject of active research. Although many models predicting the age\nof acquisition of words have been proposed, little emphasis has been directed\nto the raw input children achieve. In this work we present a comparatively\nlarge-scale multi-modal corpus of prosody-text aligned child directed speech.\nOur corpus contains automatically extracted word-level prosodic features, and\nwe investigate the utility of this information as predictors of age of\nacquisition. We show that prosody features boost predictive power in a\nregularized regression, and demonstrate their utility in the context of a\nmulti-modal factorized language models trained and tested on child-directed\nspeech.", "published": "2017-09-27 10:50:12", "link": "http://arxiv.org/abs/1709.09443v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Replicability Analysis for Natural Language Processing: Testing\n  Significance with Multiple Datasets", "abstract": "With the ever-growing amounts of textual data from a large variety of\nlanguages, domains, and genres, it has become standard to evaluate NLP\nalgorithms on multiple datasets in order to ensure consistent performance\nacross heterogeneous setups. However, such multiple comparisons pose\nsignificant challenges to traditional statistical analysis methods in NLP and\ncan lead to erroneous conclusions. In this paper, we propose a Replicability\nAnalysis framework for a statistically sound analysis of multiple comparisons\nbetween algorithms for NLP tasks. We discuss the theoretical advantages of this\nframework over the current, statistically unjustified, practice in the NLP\nliterature, and demonstrate its empirical value across four applications:\nmulti-domain dependency parsing, multilingual POS tagging, cross-domain\nsentiment classification and word similarity prediction.", "published": "2017-09-27 13:31:41", "link": "http://arxiv.org/abs/1709.09500v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An attentive neural architecture for joint segmentation and parsing and\n  its application to real estate ads", "abstract": "In processing human produced text using natural language processing (NLP)\ntechniques, two fundamental subtasks that arise are (i) segmentation of the\nplain text into meaningful subunits (e.g., entities), and (ii) dependency\nparsing, to establish relations between subunits. In this paper, we develop a\nrelatively simple and effective neural joint model that performs both\nsegmentation and dependency parsing together, instead of one after the other as\nin most state-of-the-art works. We will focus in particular on the real estate\nad setting, aiming to convert an ad to a structured description, which we name\nproperty tree, comprising the tasks of (1) identifying important entities of a\nproperty (e.g., rooms) from classifieds and (2) structuring them into a tree\nformat. In this work, we propose a new joint model that is able to tackle the\ntwo tasks simultaneously and construct the property tree by (i) avoiding the\nerror propagation that would arise from the subtasks one after the other in a\npipelined fashion, and (ii) exploiting the interactions between the subtasks.\nFor this purpose, we perform an extensive comparative study of the pipeline\nmethods and the new proposed joint model, reporting an improvement of over\nthree percentage points in the overall edge F1 score of the property tree.\nAlso, we propose attention methods, to encourage our model to focus on salient\ntokens during the construction of the property tree. Thus we experimentally\ndemonstrate the usefulness of attentive neural architectures for the proposed\njoint model, showcasing a further improvement of two percentage points in edge\nF1 score for our application.", "published": "2017-09-27 15:50:53", "link": "http://arxiv.org/abs/1709.09590v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Application of a Hybrid Bi-LSTM-CRF model to the task of Russian Named\n  Entity Recognition", "abstract": "Named Entity Recognition (NER) is one of the most common tasks of the natural\nlanguage processing. The purpose of NER is to find and classify tokens in text\ndocuments into predefined categories called tags, such as person names,\nquantity expressions, percentage expressions, names of locations,\norganizations, as well as expression of time, currency and others. Although\nthere is a number of approaches have been proposed for this task in Russian\nlanguage, it still has a substantial potential for the better solutions. In\nthis work, we studied several deep neural network models starting from vanilla\nBi-directional Long Short-Term Memory (Bi-LSTM) then supplementing it with\nConditional Random Fields (CRF) as well as highway networks and finally adding\nexternal word embeddings. All models were evaluated across three datasets:\nGareev's dataset, Person-1000, FactRuEval-2016. We found that extension of\nBi-LSTM model with CRF significantly increased the quality of predictions.\nEncoding input tokens with external word embeddings reduced training time and\nallowed to achieve state of the art for the Russian NER task.", "published": "2017-09-27 18:18:32", "link": "http://arxiv.org/abs/1709.09686v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Read-Write Memory Network for Movie Story Understanding", "abstract": "We propose a novel memory network model named Read-Write Memory Network\n(RWMN) to perform question and answering tasks for large-scale, multimodal\nmovie story understanding. The key focus of our RWMN model is to design the\nread network and the write network that consist of multiple convolutional\nlayers, which enable memory read and write operations to have high capacity and\nflexibility. While existing memory-augmented network models treat each memory\nslot as an independent block, our use of multi-layered CNNs allows the model to\nread and write sequential memory cells as chunks, which is more reasonable to\nrepresent a sequential story because adjacent memory blocks often have strong\ncorrelations. For evaluation, we apply our model to all the six tasks of the\nMovieQA benchmark, and achieve the best accuracies on several tasks, especially\non the visual QA task. Our model shows a potential to better understand not\nonly the content in the story, but also more abstract information, such as\nrelationships between characters and the reasons for their actions.", "published": "2017-09-27 06:02:57", "link": "http://arxiv.org/abs/1709.09345v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Preliminary Study for Building an Arabic Corpus of Pair\n  Questions-Texts from the Web: AQA-Webcorp", "abstract": "With the development of electronic media and the heterogeneity of Arabic data\non the Web, the idea of building a clean corpus for certain applications of\nnatural language processing, including machine translation, information\nretrieval, question answer, become more and more pressing. In this manuscript,\nwe seek to create and develop our own corpus of pair's questions-texts. This\nconstitution then will provide a better base for our experimentation step.\nThus, we try to model this constitution by a method for Arabic insofar as it\nrecovers texts from the web that could prove to be answers to our factual\nquestions. To do this, we had to develop a java script that can extract from a\ngiven query a list of html pages. Then clean these pages to the extent of\nhaving a data base of texts and a corpus of pair's question-texts. In addition,\nwe give preliminary results of our proposal method. Some investigations for the\nconstruction of Arabic corpus are also presented in this document.", "published": "2017-09-27 09:20:06", "link": "http://arxiv.org/abs/1709.09404v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Multi-Label Classification of Patient Notes a Case Study on ICD Code\n  Assignment", "abstract": "In the context of the Electronic Health Record, automated diagnosis coding of\npatient notes is a useful task, but a challenging one due to the large number\nof codes and the length of patient notes. We investigate four models for\nassigning multiple ICD codes to discharge summaries taken from both MIMIC II\nand III. We present Hierarchical Attention-GRU (HA-GRU), a hierarchical\napproach to tag a document by identifying the sentences relevant for each\nlabel. HA-GRU achieves state-of-the art results. Furthermore, the learned\nsentence-level attention layer highlights the model decision process, allows\neasier error analysis, and suggests future directions for improvement.", "published": "2017-09-27 15:46:07", "link": "http://arxiv.org/abs/1709.09587v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Bimodal Network Approach to Model Topic Dynamics", "abstract": "This paper presents an intertemporal bimodal network to analyze the evolution\nof the semantic content of a scientific field within the framework of topic\nmodeling, namely using the Latent Dirichlet Allocation (LDA). The main\ncontribution is the conceptualization of the topic dynamics and its\nformalization and codification into an algorithm. To benchmark the\neffectiveness of this approach, we propose three indexes which track the\ntransformation of topics over time, their rate of birth and death, and the\nnovelty of their content. Applying the LDA, we test the algorithm both on a\ncontrolled experiment and on a corpus of several thousands of scientific papers\nover a period of more than 100 years which account for the history of the\neconomic thought.", "published": "2017-09-27 07:49:03", "link": "http://arxiv.org/abs/1709.09373v1", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "WHY: Natural Explanations from a Robot Navigator", "abstract": "Effective collaboration between a robot and a person requires natural\ncommunication. When a robot travels with a human companion, the robot should be\nable to explain its navigation behavior in natural language. This paper\nexplains how a cognitively-based, autonomous robot navigation system produces\ninformative, intuitive explanations for its decisions. Language generation here\nis based upon the robot's commonsense, its qualitative reasoning, and its\nlearned spatial model. This approach produces natural explanations in real time\nfor a robot as it navigates in a large, complex indoor environment.", "published": "2017-09-27 21:30:53", "link": "http://arxiv.org/abs/1709.09741v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.RO"], "primary_category": "cs.AI"}
{"title": "KeyVec: Key-semantics Preserving Document Representations", "abstract": "Previous studies have demonstrated the empirical success of word embeddings\nin various applications. In this paper, we investigate the problem of learning\ndistributed representations for text documents which many machine learning\nalgorithms take as input for a number of NLP tasks.\n  We propose a neural network model, KeyVec, which learns document\nrepresentations with the goal of preserving key semantics of the input text. It\nenables the learned low-dimensional vectors to retain the topics and important\ninformation from the documents that will flow to downstream tasks. Our\nempirical evaluations show the superior quality of KeyVec representations in\ntwo different document understanding tasks.", "published": "2017-09-27 22:05:59", "link": "http://arxiv.org/abs/1709.09749v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Research on several key technologies in practical speech emotion\n  recognition", "abstract": "In this dissertation the practical speech emotion recognition technology is\nstudied, including several cognitive related emotion types, namely fidgetiness,\nconfidence and tiredness. The high quality of naturalistic emotional speech\ndata is the basis of this research. The following techniques are used for\ninducing practical emotional speech: cognitive task, computer game, noise\nstimulation, sleep deprivation and movie clips.\n  A practical speech emotion recognition system is studied based on Gaussian\nmixture model. A two-class classifier set is adopted for performance\nimprovement under the small sample case. Considering the context information in\ncontinuous emotional speech, a Gaussian mixture model embedded with Markov\nnetworks is proposed.\n  A further study is carried out for system robustness analysis. First, noise\nreduction algorithm based on auditory masking properties is fist introduced to\nthe practical speech emotion recognition. Second, to deal with the complicated\nunknown emotion types under real situation, an emotion recognition method with\nrejection ability is proposed, which enhanced the system compatibility against\nunknown emotion samples. Third, coping with the difficulties brought by a large\nnumber of unknown speakers, an emotional feature normalization method based on\nspeaker-sensitive feature clustering is proposed. Fourth, by adding the\nelectrocardiogram channel, a bi-modal emotion recognition system based on\nspeech signals and electrocardiogram signals is first introduced.\n  The speech emotion recognition methods studied in this dissertation may be\nextended into the cross-language speech emotion recognition and the whispered\nspeech emotion recognition.", "published": "2017-09-27 07:21:26", "link": "http://arxiv.org/abs/1709.09364v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
