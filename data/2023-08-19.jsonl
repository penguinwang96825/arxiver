{"title": "Breaking Language Barriers: A Question Answering Dataset for Hindi and\n  Marathi", "abstract": "The recent advances in deep-learning have led to the development of highly\nsophisticated systems with an unquenchable appetite for data. On the other\nhand, building good deep-learning models for low-resource languages remains a\nchallenging task. This paper focuses on developing a Question Answering dataset\nfor two such languages- Hindi and Marathi. Despite Hindi being the 3rd most\nspoken language worldwide, with 345 million speakers, and Marathi being the\n11th most spoken language globally, with 83.2 million speakers, both languages\nface limited resources for building efficient Question Answering systems. To\ntackle the challenge of data scarcity, we have developed a novel approach for\ntranslating the SQuAD 2.0 dataset into Hindi and Marathi. We release the\nlargest Question-Answering dataset available for these languages, with each\ndataset containing 28,000 samples. We evaluate the dataset on various\narchitectures and release the best-performing models for both Hindi and\nMarathi, which will facilitate further research in these languages. Leveraging\nsimilarity tools, our method holds the potential to create datasets in diverse\nlanguages, thereby enhancing the understanding of natural language across\nvaried linguistic contexts. Our fine-tuned models, code, and dataset will be\nmade publicly available.", "published": "2023-08-19 00:39:21", "link": "http://arxiv.org/abs/2308.09862v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for\n  Large Language Models", "abstract": "Large language models have demonstrated outstanding performance in various\nnatural language processing tasks, but their security capabilities in the\nfinancial domain have not been explored, and their performance on complex tasks\nlike financial agent remains unknown. This paper presents FinEval, a benchmark\ndesigned to evaluate LLMs' financial domain knowledge and practical abilities.\nThe dataset contains 8,351 questions categorized into four different key areas:\nFinancial Academic Knowledge, Financial Industry Knowledge, Financial Security\nKnowledge, and Financial Agent. Financial Academic Knowledge comprises 4,661\nmultiple-choice questions spanning 34 subjects such as finance and economics.\nFinancial Industry Knowledge contains 1,434 questions covering practical\nscenarios like investment research. Financial Security Knowledge assesses\nmodels through 1,640 questions on topics like application security and\ncryptography. Financial Agent evaluates tool usage and complex reasoning with\n616 questions. FinEval has multiple evaluation settings, including zero-shot,\nfive-shot with chain-of-thought, and assesses model performance using objective\nand subjective criteria. Our results show that Claude 3.5-Sonnet achieves the\nhighest weighted average score of 72.9 across all financial domain categories\nunder zero-shot setting. Our work provides a comprehensive benchmark closely\naligned with Chinese financial domain.", "published": "2023-08-19 10:38:00", "link": "http://arxiv.org/abs/2308.09975v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HICL: Hashtag-Driven In-Context Learning for Social Media Natural\n  Language Understanding", "abstract": "Natural language understanding (NLU) is integral to various social media\napplications. However, existing NLU models rely heavily on context for semantic\nlearning, resulting in compromised performance when faced with short and noisy\nsocial media content. To address this issue, we leverage in-context learning\n(ICL), wherein language models learn to make inferences by conditioning on a\nhandful of demonstrations to enrich the context and propose a novel\nhashtag-driven in-context learning (HICL) framework. Concretely, we pre-train a\nmodel #Encoder, which employs #hashtags (user-annotated topic labels) to drive\nBERT-based pre-training through contrastive learning. Our objective here is to\nenable #Encoder to gain the ability to incorporate topic-related semantic\ninformation, which allows it to retrieve topic-related posts to enrich contexts\nand enhance social media NLU with noisy contexts. To further integrate the\nretrieved context with the source text, we employ a gradient-based method to\nidentify trigger terms useful in fusing information from both sources. For\nempirical studies, we collected 45M tweets to set up an in-context NLU\nbenchmark, and the experimental results on seven downstream tasks show that\nHICL substantially advances the previous state-of-the-art results. Furthermore,\nwe conducted extensive analyzes and found that: (1) combining source input with\na top-retrieved post from #Encoder is more effective than using semantically\nsimilar posts; (2) trigger words can largely benefit in merging context from\nthe source and retrieved posts.", "published": "2023-08-19 11:31:45", "link": "http://arxiv.org/abs/2308.09985v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "I3: Intent-Introspective Retrieval Conditioned on Instructions", "abstract": "Recent studies indicate that dense retrieval models struggle to perform well\non a wide variety of retrieval tasks that lack dedicated training data, as\ndifferent retrieval tasks often entail distinct search intents. To address this\nchallenge, in this work we leverage instructions to flexibly describe retrieval\nintents and introduce I3, a unified retrieval system that performs\nIntent-Introspective retrieval across various tasks, conditioned on\nInstructions without any task-specific training. I3 innovatively incorporates a\npluggable introspector in a parameter-isolated manner to comprehend specific\nretrieval intents by jointly reasoning over the input query and instruction,\nand seamlessly integrates the introspected intent into the original retrieval\nmodel for intent-aware retrieval. Furthermore, we propose progressively-pruned\nintent learning. It utilizes extensive LLM-generated data to train I3\nphase-by-phase, embodying two key designs: progressive structure pruning and\ndrawback extrapolation-based data refinement. Extensive experiments show that\nin the BEIR benchmark, I3 significantly outperforms baseline methods designed\nwith task-specific retrievers, achieving state-of-the-art zero-shot performance\nwithout any task-specific tuning.", "published": "2023-08-19 14:17:57", "link": "http://arxiv.org/abs/2308.10025v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GameEval: Evaluating LLMs on Conversational Games", "abstract": "The rapid advancements in large language models (LLMs) have presented\nchallenges in evaluating those models. Existing evaluation methods are either\nreference-based or preference based, which inevitably need human intervention\nor introduce test bias caused by evaluator models. In this paper, we propose\nGameEval, a novel approach to evaluating LLMs through goal-driven\nconversational games, overcoming the limitations of previous methods. GameEval\ntreats LLMs as game players and assigns them distinct roles with specific goals\nachieved by launching conversations of various forms, including discussion,\nquestion answering, and voting. We design three unique games with cooperative\nor adversarial objectives, accompanied by corresponding evaluation metrics, to\nshow how this new paradigm comprehensively evaluates model performance.Through\nextensive experiments, we show that GameEval can effectively differentiate the\ncapabilities of various LLMs, providing a comprehensive assessment of their\nintegrated abilities to solve complex problems. Our public anonymous code is\navailable at https://github.com/GameEval/GameEval.", "published": "2023-08-19 14:33:40", "link": "http://arxiv.org/abs/2308.10032v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bayes Risk Transducer: Transducer with Controllable Alignment Prediction", "abstract": "Automatic speech recognition (ASR) based on transducers is widely used. In\ntraining, a transducer maximizes the summed posteriors of all paths. The path\nwith the highest posterior is commonly defined as the predicted alignment\nbetween the speech and the transcription. While the vanilla transducer does not\nhave a prior preference for any of the valid paths, this work intends to\nenforce the preferred paths and achieve controllable alignment prediction.\nSpecifically, this work proposes Bayes Risk Transducer (BRT), which uses a\nBayes risk function to set lower risk values to the preferred paths so that the\npredicted alignment is more likely to satisfy specific desired properties. We\nfurther demonstrate that these predicted alignments with intentionally designed\nproperties can provide practical advantages over the vanilla transducer.\nExperimentally, the proposed BRT saves inference cost by up to 46% for\nnon-streaming ASR and reduces overall system latency by 41% for streaming ASR.", "published": "2023-08-19 20:48:16", "link": "http://arxiv.org/abs/2308.10107v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Black-box Adversarial Attacks against Dense Retrieval Models: A\n  Multi-view Contrastive Learning Method", "abstract": "Neural ranking models (NRMs) and dense retrieval (DR) models have given rise\nto substantial improvements in overall retrieval performance. In addition to\ntheir effectiveness, and motivated by the proven lack of robustness of deep\nlearning-based approaches in other areas, there is growing interest in the\nrobustness of deep learning-based approaches to the core retrieval problem.\nAdversarial attack methods that have so far been developed mainly focus on\nattacking NRMs, with very little attention being paid to the robustness of DR\nmodels. In this paper, we introduce the adversarial retrieval attack (AREA)\ntask. The AREA task is meant to trick DR models into retrieving a target\ndocument that is outside the initial set of candidate documents retrieved by\nthe DR model in response to a query. We consider the decision-based black-box\nadversarial setting, which is realistic in real-world search engines. To\naddress the AREA task, we first employ existing adversarial attack methods\ndesigned for NRMs. We find that the promising results that have previously been\nreported on attacking NRMs, do not generalize to DR models: these methods\nunderperform a simple term spamming method. We attribute the observed lack of\ngeneralizability to the interaction-focused architecture of NRMs, which\nemphasizes fine-grained relevance matching. DR models follow a different\nrepresentation-focused architecture that prioritizes coarse-grained\nrepresentations. We propose to formalize attacks on DR models as a contrastive\nlearning problem in a multi-view representation space. The core idea is to\nencourage the consistency between each view representation of the target\ndocument and its corresponding viewer via view-wise supervision signals.\nExperimental results demonstrate that the proposed method can significantly\noutperform existing attack strategies in misleading the DR model with small\nindiscernible text perturbations.", "published": "2023-08-19 00:24:59", "link": "http://arxiv.org/abs/2308.09861v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Utilizing Semantic Textual Similarity for Clinical Survey Data Feature\n  Selection", "abstract": "Survey data can contain a high number of features while having a\ncomparatively low quantity of examples. Machine learning models that attempt to\npredict outcomes from survey data under these conditions can overfit and result\nin poor generalizability. One remedy to this issue is feature selection, which\nattempts to select an optimal subset of features to learn upon. A relatively\nunexplored source of information in the feature selection process is the usage\nof textual names of features, which may be semantically indicative of which\nfeatures are relevant to a target outcome. The relationships between feature\nnames and target names can be evaluated using language models (LMs) to produce\nsemantic textual similarity (STS) scores, which can then be used to select\nfeatures. We examine the performance using STS to select features directly and\nin the minimal-redundancy-maximal-relevance (mRMR) algorithm. The performance\nof STS as a feature selection metric is evaluated against preliminary survey\ndata collected as a part of a clinical study on persistent post-surgical pain\n(PPSP). The results suggest that features selected with STS can result in\nhigher performance models compared to traditional feature selection algorithms.", "published": "2023-08-19 03:10:51", "link": "http://arxiv.org/abs/2308.09892v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Eva-KELLM: A New Benchmark for Evaluating Knowledge Editing of LLMs", "abstract": "Large language models (LLMs) possess a wealth of knowledge encoded in their\nparameters. However, this knowledge may become outdated or unsuitable over\ntime. As a result, there has been a growing interest in knowledge editing for\nLLMs and evaluating its effectiveness. Existing studies primarily focus on\nknowledge editing using factual triplets, which not only incur high costs for\ncollection but also struggle to express complex facts. Furthermore, these\nstudies are often limited in their evaluation perspectives. In this paper, we\npropose Eva-KELLM, a new benchmark for evaluating knowledge editing of LLMs.\nThis benchmark includes an evaluation framework and a corresponding dataset.\nUnder our framework, we first ask the LLM to perform knowledge editing using\nraw documents, which provides a more convenient and universal approach compared\nto using factual triplets. We then evaluate the updated LLM from multiple\nperspectives. In addition to assessing the effectiveness of knowledge editing\nand the retention of unrelated knowledge from conventional studies, we further\ntest the LLM's ability in two aspects: 1) Reasoning with the altered knowledge,\naiming for the LLM to genuinely learn the altered knowledge instead of simply\nmemorizing it. 2) Cross-lingual knowledge transfer, where the LLM updated with\nraw documents in one language should be capable of handling queries from\nanother language. To facilitate further research, we construct and release the\ncorresponding dataset. Using this benchmark, we investigate the effectiveness\nof several commonly-used knowledge editing methods. Experimental results\nindicate that the current methods for knowledge editing using raw documents are\nnot effective in yielding satisfactory results, particularly when it comes to\nreasoning with altered knowledge and cross-lingual knowledge transfer.", "published": "2023-08-19 09:17:19", "link": "http://arxiv.org/abs/2308.09954v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Data-to-text Generation for Severely Under-Resourced Languages with\n  GPT-3.5: A Bit of Help Needed from Google Translate", "abstract": "LLMs like GPT are great at tasks involving English which dominates in their\ntraining data. In this paper, we look at how they cope with tasks involving\nlanguages that are severely under-represented in their training data, in the\ncontext of data-to-text generation for Irish, Maltese, Welsh and Breton. During\nthe prompt-engineering phase we tested a range of prompt types and formats on\nGPT-3.5 and~4 with a small sample of example input/output pairs. We then fully\nevaluated the two most promising prompts in two scenarios: (i) direct\ngeneration into the under-resourced language, and (ii) generation into English\nfollowed by translation into the under-resourced language. We find that\nfew-shot prompting works better for direct generation into under-resourced\nlanguages, but that the difference disappears when pivoting via English. The\nfew-shot + translation system variants were submitted to the WebNLG 2023 shared\ntask where they outperformed competitor systems by substantial margins in all\nlanguages on all metrics. We conclude that good performance on under-resourced\nlanguages can be achieved out-of-the box with state-of-the-art LLMs. However,\nour best results (for Welsh) remain well below the lowest ranked English system\nat WebNLG'20.", "published": "2023-08-19 09:19:34", "link": "http://arxiv.org/abs/2308.09957v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of CLIP for Text-based Person Search", "abstract": "Text-based Person Search (TBPS) aims to retrieve the person images using\nnatural language descriptions. Recently, Contrastive Language Image Pretraining\n(CLIP), a universal large cross-modal vision-language pre-training model, has\nremarkably performed over various cross-modal downstream tasks due to its\npowerful cross-modal semantic learning capacity. TPBS, as a fine-grained\ncross-modal retrieval task, is also facing the rise of research on the\nCLIP-based TBPS. In order to explore the potential of the visual-language\npre-training model for downstream TBPS tasks, this paper makes the first\nattempt to conduct a comprehensive empirical study of CLIP for TBPS and thus\ncontribute a straightforward, incremental, yet strong TBPS-CLIP baseline to the\nTBPS community. We revisit critical design considerations under CLIP, including\ndata augmentation and loss function. The model, with the aforementioned designs\nand practical training tricks, can attain satisfactory performance without any\nsophisticated modules. Also, we conduct the probing experiments of TBPS-CLIP in\nmodel generalization and model compression, demonstrating the effectiveness of\nTBPS-CLIP from various aspects. This work is expected to provide empirical\ninsights and highlight future CLIP-based TBPS research.", "published": "2023-08-19 15:08:10", "link": "http://arxiv.org/abs/2308.10045v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "PACE: Improving Prompt with Actor-Critic Editing for Large Language\n  Model", "abstract": "Large language models (LLMs) have showcased remarkable potential across\nvarious tasks by conditioning on prompts. However, the quality of different\nhuman-written prompts leads to substantial discrepancies in LLMs' performance,\nand improving prompts usually necessitates considerable human effort and\nexpertise. To this end, this paper proposes Prompt with Actor-Critic Editing\n(PACE) for LLMs to enable automatic prompt editing. Drawing inspiration from\nthe actor-critic algorithm in reinforcement learning, PACE leverages LLMs as\nthe dual roles of actors and critics, conceptualizing prompt as a type of\npolicy. PACE refines prompt, taking into account the feedback from both actors\nperforming prompt and critics criticizing response. This process helps LLMs\nbetter align prompt to a specific task, thanks to real responses and thinking\nfrom LLMs. We conduct extensive experiments on 24 instruction induction tasks\nand 21 big-bench tasks. Experimental results indicate that PACE elevates the\nrelative performance of medium/low-quality human-written prompts by up to 98\\%,\nwhich has comparable performance to high-quality human-written prompts.\nMoreover, PACE also exhibits notable efficacy for prompt generation.", "published": "2023-08-19 18:47:44", "link": "http://arxiv.org/abs/2308.10088v2", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Open, Closed, or Small Language Models for Text Classification?", "abstract": "Recent advancements in large language models have demonstrated remarkable\ncapabilities across various NLP tasks. But many questions remain, including\nwhether open-source models match closed ones, why these models excel or\nstruggle with certain tasks, and what types of practical procedures can improve\nperformance. We address these questions in the context of classification by\nevaluating three classes of models using eight datasets across three distinct\ntasks: named entity recognition, political party prediction, and misinformation\ndetection. While larger LLMs often lead to improved performance, open-source\nmodels can rival their closed-source counterparts by fine-tuning. Moreover,\nsupervised smaller models, like RoBERTa, can achieve similar or even greater\nperformance in many datasets compared to generative LLMs. On the other hand,\nclosed models maintain an advantage in hard tasks that demand the most\ngeneralizability. This study underscores the importance of model selection\nbased on task requirements", "published": "2023-08-19 18:58:32", "link": "http://arxiv.org/abs/2308.10092v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Optimizing Multi-Class Text Classification: A Diverse Stacking Ensemble\n  Framework Utilizing Transformers", "abstract": "Customer reviews play a crucial role in assessing customer satisfaction,\ngathering feedback, and driving improvements for businesses. Analyzing these\nreviews provides valuable insights into customer sentiments, including\ncompliments, comments, and suggestions. Text classification techniques enable\nbusinesses to categorize customer reviews into distinct categories,\nfacilitating a better understanding of customer feedback. However, challenges\nsuch as overfitting and bias limit the effectiveness of a single classifier in\nensuring optimal prediction. This study proposes a novel approach to address\nthese challenges by introducing a stacking ensemble-based multi-text\nclassification method that leverages transformer models. By combining multiple\nsingle transformers, including BERT, ELECTRA, and DistilBERT, as base-level\nclassifiers, and a meta-level classifier based on RoBERTa, an optimal\npredictive model is generated. The proposed stacking ensemble-based multi-text\nclassification method aims to enhance the accuracy and robustness of customer\nreview analysis. Experimental evaluations conducted on a real-world customer\nreview dataset demonstrate the effectiveness and superiority of the proposed\napproach over traditional single classifier models. The stacking ensemble-based\nmulti-text classification method using transformers proves to be a promising\nsolution for businesses seeking to extract valuable insights from customer\nreviews and make data-driven decisions to enhance customer satisfaction and\ndrive continuous improvement.", "published": "2023-08-19 13:29:15", "link": "http://arxiv.org/abs/2308.11519v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Power of Topic Modeling Techniques in Analyzing Customer\n  Reviews: A Comparative Analysis", "abstract": "The exponential growth of online social network platforms and applications\nhas led to a staggering volume of user-generated textual content, including\ncomments and reviews. Consequently, users often face difficulties in extracting\nvaluable insights or relevant information from such content. To address this\nchallenge, machine learning and natural language processing algorithms have\nbeen deployed to analyze the vast amount of textual data available online. In\nrecent years, topic modeling techniques have gained significant popularity in\nthis domain. In this study, we comprehensively examine and compare five\nfrequently used topic modeling methods specifically applied to customer\nreviews. The methods under investigation are latent semantic analysis (LSA),\nlatent Dirichlet allocation (LDA), non-negative matrix factorization (NMF),\npachinko allocation model (PAM), Top2Vec, and BERTopic. By practically\ndemonstrating their benefits in detecting important topics, we aim to highlight\ntheir efficacy in real-world scenarios. To evaluate the performance of these\ntopic modeling methods, we carefully select two textual datasets. The\nevaluation is based on standard statistical evaluation metrics such as topic\ncoherence score. Our findings reveal that BERTopic consistently yield more\nmeaningful extracted topics and achieve favorable results.", "published": "2023-08-19 08:18:04", "link": "http://arxiv.org/abs/2308.11520v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Causal Intersectionality and Dual Form of Gradient Descent for\n  Multimodal Analysis: a Case Study on Hateful Memes", "abstract": "Amidst the rapid expansion of Machine Learning (ML) and Large Language Models\n(LLMs), understanding the semantics within their mechanisms is vital. Causal\nanalyses define semantics, while gradient-based methods are essential to\neXplainable AI (XAI), interpreting the model's 'black box'. Integrating these,\nwe investigate how a model's mechanisms reveal its causal effect on\nevidence-based decision-making. Research indicates intersectionality - the\ncombined impact of an individual's demographics - can be framed as an Average\nTreatment Effect (ATE). This paper demonstrates that hateful meme detection can\nbe viewed as an ATE estimation using intersectionality principles, and\nsummarized gradient-based attention scores highlight distinct behaviors of\nthree Transformer models. We further reveal that LLM Llama-2 can discern the\nintersectional aspects of the detection through in-context learning and that\nthe learning process could be explained via meta-gradient, a secondary form of\ngradient. In conclusion, this work furthers the dialogue on Causality and XAI.\nOur code is available online (see External Resources section).", "published": "2023-08-19 13:14:15", "link": "http://arxiv.org/abs/2308.11585v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "UniDoc: A Universal Large Multimodal Model for Simultaneous Text\n  Detection, Recognition, Spotting and Understanding", "abstract": "In the era of Large Language Models (LLMs), tremendous strides have been made\nin the field of multimodal understanding. However, existing advanced algorithms\nare limited to effectively utilizing the immense representation capabilities\nand rich world knowledge inherent to these large pre-trained models, and the\nbeneficial connections among tasks within the context of text-rich scenarios\nhave not been sufficiently explored. In this work, we introduce UniDoc, a novel\nmultimodal model equipped with text detection and recognition capabilities,\nwhich are deficient in existing approaches. Moreover, UniDoc capitalizes on the\nbeneficial interactions among tasks to enhance the performance of each\nindividual task. To implement UniDoc, we perform unified multimodal instruct\ntuning on the contributed large-scale instruction following datasets.\nQuantitative and qualitative experimental results show that UniDoc sets\nstate-of-the-art scores across multiple challenging benchmarks. To the best of\nour knowledge, this is the first large multimodal model capable of simultaneous\ntext detection, recognition, spotting, and understanding.", "published": "2023-08-19 17:32:34", "link": "http://arxiv.org/abs/2308.11592v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Inductive-bias Learning: Generating Code Models with Large Language\n  Model", "abstract": "Large Language Models(LLMs) have been attracting attention due to a ability\ncalled in-context learning(ICL). ICL, without updating the parameters of a LLM,\nit is possible to achieve highly accurate inference based on rules ``in the\ncontext'' by merely inputting a training data into the prompt. Although ICL is\na developing field with many unanswered questions, LLMs themselves serves as a\ninference model, seemingly realizing inference without explicitly indicate\n``inductive bias''. On the other hand, a code generation is also a highlighted\napplication of LLMs. The accuracy of code generation has dramatically improved,\nenabling even non-engineers to generate code to perform the desired tasks by\ncrafting appropriate prompts. In this paper, we propose a novel ``learning''\nmethod called an ``Inductive-Bias Learning (IBL)'', which combines the\ntechniques of ICL and code generation. An idea of IBL is straightforward. Like\nICL, IBL inputs a training data into the prompt and outputs a code with a\nnecessary structure for inference (we referred to as ``Code Model'') from a\n``contextual understanding''. Despite being a seemingly simple approach, IBL\nencompasses both a ``property of inference without explicit inductive bias''\ninherent in ICL and a ``readability and explainability'' of the code\ngeneration. Surprisingly, generated Code Models have been found to achieve\npredictive accuracy comparable to, and in some cases surpassing, ICL and\nrepresentative machine learning models. Our IBL code is open source:\nhttps://github.com/fuyu-quant/IBLM", "published": "2023-08-19 03:01:45", "link": "http://arxiv.org/abs/2308.09890v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.LG"}
{"title": "BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual\n  Questions", "abstract": "Vision Language Models (VLMs), which extend Large Language Models (LLM) by\nincorporating visual understanding capability, have demonstrated significant\nadvancements in addressing open-ended visual question-answering (VQA) tasks.\nHowever, these models cannot accurately interpret images infused with text, a\ncommon occurrence in real-world scenarios. Standard procedures for extracting\ninformation from images often involve learning a fixed set of query embeddings.\nThese embeddings are designed to encapsulate image contexts and are later used\nas soft prompt inputs in LLMs. Yet, this process is limited to the token count,\npotentially curtailing the recognition of scenes with text-rich context. To\nimprove upon them, the present study introduces BLIVA: an augmented version of\nInstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings\nfrom InstructBLIP and also directly projects encoded patch embeddings into the\nLLM, a technique inspired by LLaVA. This approach assists the model to capture\nintricate details potentially missed during the query decoding process.\nEmpirical evidence demonstrates that our model, BLIVA, significantly enhances\nperformance in processing text-rich VQA benchmarks (up to 17.76% in OCR-VQA\nbenchmark) and in undertaking general (not particularly text-rich) VQA\nbenchmarks (up to 7.9% in Visual Spatial Reasoning benchmark), and achieved\n17.72% overall improvement in a comprehensive multimodal LLM benchmark (MME),\ncomparing to our baseline InstructBLIP. BLIVA demonstrates significant\ncapability in decoding real-world images, irrespective of text presence. To\ndemonstrate the broad industry applications enabled by BLIVA, we evaluate the\nmodel using a new dataset comprising YouTube thumbnails paired with\nquestion-answer sets across 11 diverse categories. Our code and models are\nfreely accessible at https://github.com/mlpc-ucsd/BLIVA.", "published": "2023-08-19 07:53:43", "link": "http://arxiv.org/abs/2308.09936v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Tackling Vision Language Tasks Through Learning Inner Monologues", "abstract": "Visual language tasks require AI models to comprehend and reason with both\nvisual and textual content. Driven by the power of Large Language Models\n(LLMs), two prominent methods have emerged: (1) the hybrid integration between\nLLMs and Vision-Language Models (VLMs), where visual inputs are firstly\nconverted into language descriptions by VLMs, serving as inputs for LLMs to\ngenerate final answer(s); (2) visual feature alignment in language space, where\nvisual inputs are encoded as embeddings and projected to LLMs' language space\nvia further supervised fine-tuning. The first approach provides light training\ncosts and interpretability but is hard to be optimized in an end-to-end\nfashion. The second approach presents decent performance, but feature alignment\nusually requires large amounts of training data and lacks interpretability. To\ntackle this dilemma, we propose a novel approach, Inner Monologue Multi-Modal\nOptimization (IMMO), to solve complex vision language problems by simulating\ninner monologue processes, a cognitive process in which an individual engages\nin silent verbal communication with themselves. We enable LLMs and VLMs to\ninteract through natural language conversation and propose to use a two-stage\ntraining process to learn how to do the inner monologue (self-asking questions\nand answering questions). IMMO is evaluated on two popular tasks and the\nresults suggest by emulating the cognitive phenomenon of internal dialogue, our\napproach can enhance reasoning and explanation abilities, contributing to the\nmore effective fusion of vision and language models. More importantly, instead\nof using predefined human-crafted monologues, IMMO learns this process within\nthe deep learning models, promising wider applicability to many different AI\nproblems beyond vision language tasks.", "published": "2023-08-19 10:10:49", "link": "http://arxiv.org/abs/2308.09970v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ASPIRE: Language-Guided Data Augmentation for Improving Robustness\n  Against Spurious Correlations", "abstract": "Neural image classifiers can often learn to make predictions by overly\nrelying on non-predictive features that are spuriously correlated with the\nclass labels in the training data. This leads to poor performance in real-world\natypical scenarios where such features are absent. This paper presents ASPIRE\n(Language-guided Data Augmentation for SPurIous correlation REmoval), a simple\nyet effective solution for supplementing the training dataset with images\nwithout spurious features, for robust learning against spurious correlations\nvia better generalization. ASPIRE, guided by language at various steps, can\ngenerate non-spurious images without requiring any group labeling or existing\nnon-spurious images in the training set. Precisely, we employ LLMs to first\nextract foreground and background features from textual descriptions of an\nimage, followed by advanced language-guided image editing to discover the\nfeatures that are spuriously correlated with the class label. Finally, we\npersonalize a text-to-image generation model using the edited images to\ngenerate diverse in-domain images without spurious features. ASPIRE is\ncomplementary to all prior robust training methods in literature, and we\ndemonstrate its effectiveness across 4 datasets and 9 baselines and show that\nASPIRE improves the worst-group classification accuracy of prior methods by 1%\n- 38%. We also contribute a novel test set for the challenging Hard ImageNet\ndataset.", "published": "2023-08-19 20:18:15", "link": "http://arxiv.org/abs/2308.10103v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Spatial Reconstructed Local Attention Res2Net with F0 Subband for Fake\n  Speech Detection", "abstract": "The rhythm of bonafide speech is often difficult to replicate, which causes\nthat the fundamental frequency (F0) of synthetic speech is significantly\ndifferent from that of real speech. It is expected that the F0 feature contains\nthe discriminative information for the fake speech detection (FSD) task. In\nthis paper, we propose a novel F0 subband for FSD. In addition, to effectively\nmodel the F0 subband so as to improve the performance of FSD, the spatial\nreconstructed local attention Res2Net (SR-LA Res2Net) is proposed.\nSpecifically, Res2Net is used as a backbone network to obtain multiscale\ninformation, and enhanced with a spatial reconstruction mechanism to avoid\nlosing important information when the channel group is constantly superimposed.\nIn addition, local attention is designed to make the model focus on the local\ninformation of the F0 subband. Experimental results on the ASVspoof 2019 LA\ndataset show that our proposed method obtains an equal error rate (EER) of\n0.47% and a minimum tandem detection cost function (min t-DCF) of 0.0159,\nachieving the state-of-the-art performance among all of the single systems.", "published": "2023-08-19 08:31:04", "link": "http://arxiv.org/abs/2308.09944v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Effects of Convolutional Autoencoder Bottleneck Width on StarGAN-based\n  Singing Technique Conversion", "abstract": "Singing technique conversion (STC) refers to the task of converting from one\nvoice technique to another while leaving the original singer identity, melody,\nand linguistic components intact. Previous STC studies, as well as singing\nvoice conversion research in general, have utilized convolutional autoencoders\n(CAEs) for conversion, but how the bottleneck width of the CAE affects the\nsynthesis quality has not been thoroughly evaluated. To this end, we\nconstructed a GAN-based multi-domain STC system which took advantage of the\nWORLD vocoder representation and the CAE architecture. We varied the bottleneck\nwidth of the CAE, and evaluated the conversion results subjectively. The model\nwas trained on a Mandarin dataset which features four singers and four singing\ntechniques: the chest voice, the falsetto, the raspy voice, and the whistle\nvoice. The results show that a wider bottleneck corresponds to better\narticulation clarity but does not necessarily lead to higher likeness to the\ntarget technique. Among the four techniques, we also found that the whistle\nvoice is the easiest target for conversion, while the other three techniques as\na source produce more convincing conversion results than the whistle.", "published": "2023-08-19 14:13:28", "link": "http://arxiv.org/abs/2308.10021v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
