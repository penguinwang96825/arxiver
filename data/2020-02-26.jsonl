{"title": "Fast Lower and Upper Estimates for the Price of Constrained Multiple Exercise American Options by Single Pass Lookahead Search and Nearest-Neighbor Martingale", "abstract": "This article presents fast lower and upper estimates for a large class of options: the class of constrained multiple exercise American options. Typical options in this class are swing options with volume and timing constraints, and passport options with multiple lookback rights. The lower estimate algorithm uses the artificial intelligence method of lookahead search. The upper estimate algorithm uses the dual approach to option pricing on a nearest-neighbor basis for the martingale space. Probabilistic convergence guarantees are provided. Several numerical examples illustrate the approaches including a swing option with four constraints, and a passport option with 16 constraints.", "published": "2020-02-26 02:06:06", "link": "http://arxiv.org/abs/2002.11258v1", "categories": ["q-fin.CP", "cs.LG", "math.OC", "q-fin.PR"], "primary_category": "q-fin.CP"}
{"title": "A Density Ratio Approach to Language Model Fusion in End-To-End Automatic Speech Recognition", "abstract": "This article describes a density ratio approach to integrating external Language Models (LMs) into end-to-end models for Automatic Speech Recognition (ASR). Applied to a Recurrent Neural Network Transducer (RNN-T) ASR model trained on a given domain, a matched in-domain RNN-LM, and a target domain RNN-LM, the proposed method uses Bayes' Rule to define RNN-T posteriors for the target domain, in a manner directly analogous to the classic hybrid model for ASR based on Deep Neural Networks (DNNs) or LSTMs in the Hidden Markov Model (HMM) framework (Bourlard & Morgan, 1994). The proposed approach is evaluated in cross-domain and limited-data scenarios, for which a significant amount of target domain text data is used for LM training, but only limited (or no) {audio, transcript} training data pairs are used to train the RNN-T. Specifically, an RNN-T model trained on paired audio & transcript data from YouTube is evaluated for its ability to generalize to Voice Search data. The Density Ratio method was found to consistently outperform the dominant approach to LM and end-to-end ASR integration, Shallow Fusion.", "published": "2020-02-26 02:53:42", "link": "http://arxiv.org/abs/2002.11268v3", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "BUT System for the Second DIHARD Speech Diarization Challenge", "abstract": "This paper describes the winning systems developed by the BUT team for the four tracks of the Second DIHARD Speech Diarization Challenge. For tracks 1 and 2 the systems were mainly based on performing agglomerative hierarchical clustering (AHC) of x-vectors, followed by another x-vector clustering based on Bayes hidden Markov model and variational Bayes inference. We provide a comparison of the improvement given by each step and share the implementation of the core of the system. For tracks 3 and 4 with recordings from the Fifth CHiME Challenge, we explored different approaches for doing multi-channel diarization and our best performance was obtained when applying AHC on the fusion of per channel probabilistic linear discriminant analysis scores.", "published": "2020-02-26 08:41:15", "link": "http://arxiv.org/abs/2002.11356v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
