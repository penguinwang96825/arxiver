{"title": "Co-PACRR: A Context-Aware Neural IR Model for Ad-hoc Retrieval", "abstract": "Neural IR models, such as DRMM and PACRR, have achieved strong results by\nsuccessfully capturing relevance matching signals. We argue that the context of\nthese matching signals is also important. Intuitively, when extracting,\nmodeling, and combining matching signals, one would like to consider the\nsurrounding text (local context) as well as other signals from the same\ndocument that can contribute to the overall relevance score. In this work, we\nhighlight three potential shortcomings caused by not considering context\ninformation and propose three neural ingredients to address them: a\ndisambiguation component, cascade k-max pooling, and a shuffling combination\nlayer. Incorporating these components into the PACRR model yields Co-PACRR, a\nnovel context-aware neural IR model. Extensive comparisons with established\nmodels on Trec Web Track data confirm that the proposed model can achieve\nsuperior search results. In addition, an ablation analysis is conducted to gain\ninsights into the impact of and interactions between different components. We\nrelease our code to enable future comparisons.", "published": "2017-06-30 13:39:03", "link": "http://arxiv.org/abs/1706.10192v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Racial Disparity in Natural Language Processing: A Case Study of Social\n  Media African-American English", "abstract": "We highlight an important frontier in algorithmic fairness: disparity in the\nquality of natural language processing algorithms when applied to language from\nauthors of different social groups. For example, current systems sometimes\nanalyze the language of females and minorities more poorly than they do of\nwhites and males. We conduct an empirical analysis of racial disparity in\nlanguage identification for tweets written in African-American English, and\ndiscuss implications of disparity in NLP.", "published": "2017-06-30 22:57:50", "link": "http://arxiv.org/abs/1707.00061v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Automated Audio Captioning with Recurrent Neural Networks", "abstract": "We present the first approach to automated audio captioning. We employ an\nencoder-decoder scheme with an alignment model in between. The input to the\nencoder is a sequence of log mel-band energies calculated from an audio file,\nwhile the output is a sequence of words, i.e. a caption. The encoder is a\nmulti-layered, bi-directional gated recurrent unit (GRU) and the decoder a\nmulti-layered GRU with a classification layer connected to the last GRU of the\ndecoder. The classification layer and the alignment model are fully connected\nlayers with shared weights between timesteps. The proposed method is evaluated\nusing data drawn from a commercial sound effects library, ProSound Effects. The\nresulting captions were rated through metrics utilized in machine translation\nand image captioning fields. Results from metrics show that the proposed method\ncan predict words appearing in the original caption, but not always correctly\nordered.", "published": "2017-06-30 02:55:55", "link": "http://arxiv.org/abs/1706.10006v2", "categories": ["cs.SD", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
