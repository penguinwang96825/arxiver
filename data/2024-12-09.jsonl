{"title": "Systematic comparison of deep generative models applied to multivariate financial time series", "abstract": "Financial time series (FTS) generation models are a core pillar to\napplications in finance. Risk management and portfolio optimization rely on\nrealistic multivariate price generation models. Accordingly, there is a strong\nmodelling literature dating back to Bachelier's Theory of Speculation in 1901.\nGenerating FTS using deep generative models (DGMs) is still in its infancy. In\nthis work, we systematically compare DGMs against state-of-the-art parametric\nalternatives for multivariate FTS generation. We initially compare both DGMs\nand parametric models over increasingly complex synthetic datasets. The models\nare evaluated through distance measures for varying distribution moments of\nboth the full and rolling FTS. We then apply the best performing DGM models to\nempirical data, demonstrating the benefit of DGMs through a implied volatility\ntrading task.", "published": "2024-12-09 11:48:07", "link": "http://arxiv.org/abs/2412.06417v1", "categories": ["q-fin.ST", "q-fin.CP"], "primary_category": "q-fin.ST"}
{"title": "Stock Type Prediction Model Based on Hierarchical Graph Neural Network", "abstract": "This paper introduces a novel approach to stock data analysis by employing a\nHierarchical Graph Neural Network (HGNN) model that captures multi-level\ninformation and relational structures in the stock market. The HGNN model\nintegrates stock relationship data and hierarchical attributes to predict stock\ntypes effectively. The paper discusses the construction of a stock industry\nrelationship graph and the extraction of temporal information from historical\nprice sequences. It also highlights the design of a graph convolution operation\nand a temporal attention aggregator to model the macro market state. The\nintegration of these features results in a comprehensive stock prediction model\nthat addresses the challenges of utilizing stock relationship data and modeling\nhierarchical attributes in the stock market.", "published": "2024-12-09 08:08:03", "link": "http://arxiv.org/abs/2412.06862v1", "categories": ["cs.LG", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "Diffusion on the circle and a stochastic correlation model", "abstract": "We propose analytically tractable SDE models for correlation in financial\nmarkets. We study diffusions on the circle, namely the Brownian motion on the\ncircle and the von Mises process, and consider these as models for correlation.\nThe von Mises process was proposed in Kent (1975) as a probabilistic\njustification for the von Mises distribution which is widely used in Circular\nstatistics. The transition density of the von Mises process has been unknown,\nwe identify an approximate analytic transition density for the von Mises\nprocess. We discuss the estimation of these diffusion models and a stochastic\ncorrelation model in finance. We illustrate the application of the proposed\nmodel on real-data of equity-currency pairs.", "published": "2024-12-09 09:51:38", "link": "http://arxiv.org/abs/2412.06343v3", "categories": ["math.ST", "q-fin.MF", "stat.TH"], "primary_category": "math.ST"}
{"title": "Evaluating and Mitigating Social Bias for Large Language Models in\n  Open-ended Settings", "abstract": "Current social bias benchmarks for Large Language Models (LLMs) primarily\nrely on pre-defined question formats like multiple-choice, limiting their\nability to reflect the complexity and open-ended nature of real-world\ninteractions. To address this gap, we extend an existing BBQ dataset introduced\nby incorporating fill-in-the-blank and short-answer question types, designed to\nevaluate biases in an open-ended setting. Our finding reveals that LLMs tend to\nproduce responses that are more biased against certain protected attributes,\nlike age and socio-economic status. On the other hand, these biased outputs\nproduced by LLMs can serve as valuable contexts and chains of thought for\ndebiasing. Our debiasing approach combined zero-shot, few-shot, and\nchain-of-thought could significantly reduce the level of bias to almost 0. We\nopen-source our evaluation and debiasing code hoping to encourage further\nmeasurements and mitigation of bias and stereotype in LLMs.", "published": "2024-12-09 01:29:47", "link": "http://arxiv.org/abs/2412.06134v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AIDE: Task-Specific Fine Tuning with Attribute Guided Multi-Hop Data\n  Expansion", "abstract": "Fine-tuning large language models (LLMs) for specific tasks requires\nhigh-quality, diverse training data relevant to the task. Recent research has\nleveraged LLMs to synthesize training data, but existing approaches either\ndepend on large seed datasets or struggle to ensure both task relevance and\ndata diversity in the generated outputs. To address these challenges, we\npropose AIDE, a novel data synthesis framework that uses a multi-hop process to\nexpand 10 seed data points while ensuring diversity and task relevance. AIDE\nextracts the main topic and key knowledge attributes from the seed data to\nguide the synthesis process. In each subsequent hop, it extracts the topic and\nattributes from the newly generated data and continues guided synthesis. This\nprocess repeats for a total of K hops. To prevent irrelevant data generation as\nthe hop depth increases, AIDE incorporates a residual connection mechanism and\nuses self-reflection to improve data quality. Our empirical results demonstrate\nthat fine-tuning Mistral-7B, Llama-3.1-8B and Llama-3.2-3B with AIDE achieves\nmore than 10% accuracy improvements over the base models across 13 tasks from 5\ndifferent benchmarks, while outperforming the models fine-tuned with\nstate-of-the-art data synthesis methods like Evol-Instruct, DataTune and\nPrompt2Model.", "published": "2024-12-09 01:39:16", "link": "http://arxiv.org/abs/2412.06136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hate Speech According to the Law: An Analysis for Effective Detection", "abstract": "The issue of hate speech extends beyond the confines of the online realm. It\nis a problem with real-life repercussions, prompting most nations to formulate\nlegal frameworks that classify hate speech as a punishable offence. These legal\nframeworks differ from one country to another, contributing to the big chaos\nthat online platforms have to face when addressing reported instances of hate\nspeech. With the definitions of hate speech falling short in introducing a\nrobust framework, we turn our gaze onto hate speech laws. We consult the\nopinion of legal experts on a hate speech dataset and we experiment by\nemploying various approaches such as pretrained models both on hate speech and\nlegal data, as well as exploiting two large language models (Qwen2-7B-Instruct\nand Meta-Llama-3-70B). Due to the time-consuming nature of data acquisition for\nprosecutable hate speech, we use pseudo-labeling to improve our pretrained\nmodels. This study highlights the importance of amplifying research on\nprosecutable hate speech and provides insights into effective strategies for\ncombating hate speech within the parameters of legal frameworks. Our findings\nshow that legal knowledge in the form of annotations can be useful when\nclassifying prosecutable hate speech, yet more focus should be paid on the\ndifferences between the laws.", "published": "2024-12-09 01:58:10", "link": "http://arxiv.org/abs/2412.06144v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SparseAccelerate: Efficient Long-Context Inference for Mid-Range GPUs", "abstract": "As Large Language Models (LLMs) scale to longer context windows, the\ncomputational cost of attention mechanisms, which traditionally grows\nquadratically with input length, presents a critical challenge for real-time\nand memory-constrained deployments. Existing sparse attention techniques have\nsought to reduce this complexity, but they often incur significant overhead or\ncompromise accuracy, making them less practical for large contexts on mid-range\nhardware. In this paper, we introduce SparseAccelerate, a dynamic sparse\nattention method that adapts its sparsity patterns based on input\ncharacteristics, effectively flattening the attention complexity curve. Our\napproach is effective for input lengths starting at 16K tokens and scales\nefficiently up to 128K tokens on dual NVIDIA A5000 GPUs (24GB each).\nExperimental results show that SparseAccelerate achieves up to a 1.04x\nreduction in Time-To-First-Token (TTFT) latency at 32K tokens, while also\nproviding substantial memory savings. These improvements yield practical gains\nfor memory-intensive applications and long-context tasks that were previously\ninfeasible with standard attention. Beyond latency reductions, SparseAccelerate\nfundamentally shifts the scaling trend, demonstrating the smallest TTFT growth\ngradient relative to context length among competing methods. Ongoing\nevaluations on diverse benchmarks confirm its scalability, positioning\nSparseAccelerate as a critical advancement toward efficient, real-time, and\nlarge-context LLM inference on accessible hardware.", "published": "2024-12-09 04:27:03", "link": "http://arxiv.org/abs/2412.06198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparative Study of Learning Paradigms in Large Language Models via\n  Intrinsic Dimension", "abstract": "The performance of Large Language Models (LLMs) on natural language tasks can\nbe improved through both supervised fine-tuning (SFT) and in-context learning\n(ICL), which operate via distinct mechanisms. Supervised fine-tuning updates\nthe model's weights by minimizing loss on training data, whereas in-context\nlearning leverages task demonstrations embedded in the prompt, without changing\nthe model's parameters. This study investigates the effects of these learning\nparadigms on the hidden representations of LLMs using Intrinsic Dimension (ID).\nWe use ID to estimate the number of degrees of freedom between representations\nextracted from LLMs as they perform specific natural language tasks. We first\nexplore how the ID of LLM representations evolves during SFT and how it varies\ndue to the number of demonstrations in ICL. We then compare the IDs induced by\nSFT and ICL and find that ICL consistently induces a higher ID compared to SFT,\nsuggesting that representations generated during ICL reside in higher\ndimensional manifolds in the embedding space.", "published": "2024-12-09 06:37:35", "link": "http://arxiv.org/abs/2412.06245v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking\n  Large Language Models", "abstract": "The emergence of Large Language Models (LLMs) in the medical domain has\nstressed a compelling need for standard datasets to evaluate their\nquestion-answering (QA) performance. Although there have been several benchmark\ndatasets for medical QA, they either cover common knowledge across different\ndepartments or are specific to another department rather than pediatrics.\nMoreover, some of them are limited to objective questions and do not measure\nthe generation capacity of LLMs. Therefore, they cannot comprehensively assess\nthe QA ability of LLMs in pediatrics. To fill this gap, we construct\nPediaBench, the first Chinese pediatric dataset for LLM evaluation.\nSpecifically, it contains 4,117 objective questions and 1,632 subjective\nquestions spanning 12 pediatric disease groups. It adopts an integrated scoring\ncriterion based on different difficulty levels to thoroughly assess the\nproficiency of an LLM in instruction following, knowledge understanding,\nclinical case analysis, etc. Finally, we validate the effectiveness of\nPediaBench with extensive experiments on 20 open-source and commercial LLMs.\nThrough an in-depth analysis of experimental results, we offer insights into\nthe ability of LLMs to answer pediatric questions in the Chinese context,\nhighlighting their limitations for further improvements. Our code and data are\npublished at https://github.com/ACMISLab/PediaBench.", "published": "2024-12-09 08:19:28", "link": "http://arxiv.org/abs/2412.06287v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BoRA: Bi-dimensional Weight-Decomposed Low-Rank Adaptation", "abstract": "In recent years, Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank\nAdaptation (LoRA) have significantly enhanced the adaptability of large-scale\npre-trained models. Weight-Decomposed Low-Rank Adaptation (DoRA) improves upon\nLoRA by separating the magnitude and direction components of the weight matrix,\nleading to superior performance. However, DoRA's improvements are limited to\nthe vertical dimension, resulting in an asymmetrical pattern between horizontal\nand vertical dimensions. This paper introduces BoRA, an innovative extension of\nLoRA and DoRA, characterized by symmetrical properties across horizontal and\nvertical dimensions. Our approach optimizes the weight matrix symmetrically by\nadjusting both column-wise and row-wise magnitudes. Extensive experiments\ndemonstrate that BoRA surpasses state-of-the-art PEFT methods, including LoRA\nand DoRA, achieving superior results across various benchmarks.", "published": "2024-12-09 12:35:58", "link": "http://arxiv.org/abs/2412.06441v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Small Languages, Big Models: A Study of Continual Training on Languages\n  of Norway", "abstract": "Training large language models requires vast amounts of data, posing a\nchallenge for less widely spoken languages like Norwegian and even more so for\ntruly low-resource languages like Northern S\\'ami. To address this issue, we\npresent a novel three-stage continual training approach that substantially\nimproves the downstream performance together with the inference efficiency for\nthe target languages. Based on our findings, we train, evaluate, and openly\nrelease a new generative language model for Norwegian Bokm\\r{a}l, Nynorsk, and\nNorthern S\\'ami with 11.4 billion parameters: NorMistral-11B.", "published": "2024-12-09 13:34:23", "link": "http://arxiv.org/abs/2412.06484v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Quality Enhancement on the Basis of Diversity with Large Language\n  Models for Text Classification: Uncovered, Difficult, and Noisy", "abstract": "In recent years, the use of large language models (LLMs) for text\nclassification has attracted widespread attention. Despite this, the\nclassification accuracy of LLMs has not yet universally surpassed that of\nsmaller models. LLMs can enhance their performance in text classification\nthrough fine-tuning. However, existing data quality research based on LLMs is\nchallenging to apply directly to solve text classification problems. To further\nimprove the performance of LLMs in classification tasks, this paper proposes a\ndata quality enhancement (DQE) method for text classification based on LLMs.\nThis method starts by using a greedy algorithm to select data, dividing the\ndataset into sampled and unsampled subsets, and then performing fine-tuning of\nthe LLMs using the sampled data. Subsequently, this model is used to predict\nthe outcomes for the unsampled data, categorizing incorrectly predicted data\ninto uncovered, difficult, and noisy data. Experimental results demonstrate\nthat our method effectively enhances the performance of LLMs in text\nclassification tasks and significantly improves training efficiency, saving\nnearly half of the training time. Our method has achieved state-of-the-art\nperformance in several open-source classification tasks.", "published": "2024-12-09 15:28:39", "link": "http://arxiv.org/abs/2412.06575v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anchoring Bias in Large Language Models: An Experimental Study", "abstract": "Large Language Models (LLMs) like GPT-4 and Gemini have significantly\nadvanced artificial intelligence by enabling machines to generate and\ncomprehend human-like text. Despite their impressive capabilities, LLMs are not\nimmune to limitations, including various biases. While much research has\nexplored demographic biases, the cognitive biases in LLMs have not been equally\nscrutinized. This study delves into anchoring bias, a cognitive bias where\ninitial information disproportionately influences judgment. Utilizing an\nexperimental dataset, we examine how anchoring bias manifests in LLMs and\nverify the effectiveness of various mitigation strategies. Our findings\nhighlight the sensitivity of LLM responses to biased hints. At the same time,\nour experiments show that, to mitigate anchoring bias, one needs to collect\nhints from comprehensive angles to prevent the LLMs from being anchored to\nindividual pieces of information, while simple algorithms such as\nChain-of-Thought, Thoughts of Principles, Ignoring Anchor Hints, and Reflection\nare not sufficient.", "published": "2024-12-09 15:45:03", "link": "http://arxiv.org/abs/2412.06593v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GEAR: A Simple GENERATE, EMBED, AVERAGE AND RANK Approach for\n  Unsupervised Reverse Dictionary", "abstract": "Reverse Dictionary (RD) is the task of obtaining the most relevant word or\nset of words given a textual description or dictionary definition. Effective RD\nmethods have applications in accessibility, translation or writing support\nsystems. Moreover, in NLP research we find RD to be used to benchmark text\nencoders at various granularities, as it often requires word, definition and\nsentence embeddings. In this paper, we propose a simple approach to RD that\nleverages LLMs in combination with embedding models. Despite its simplicity,\nthis approach outperforms supervised baselines in well studied RD datasets,\nwhile also showing less over-fitting. We also conduct a number of experiments\non different dictionaries and analyze how different styles, registers and\ntarget audiences impact the quality of RD systems. We conclude that, on\naverage, untuned embeddings alone fare way below an LLM-only baseline (although\nthey are competitive in highly technical dictionaries), but are crucial for\nboosting performance in combined methods.", "published": "2024-12-09 16:54:54", "link": "http://arxiv.org/abs/2412.06654v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JAPAGEN: Efficient Few/Zero-shot Learning via Japanese Training Dataset\n  Generation with LLM", "abstract": "Recently some studies have highlighted the potential of Large Language Models\n(LLMs) as effective generators of supervised training data, offering advantages\nsuch as enhanced inference efficiency and reduced costs associated with data\ncollection. However, these studies have predominantly focused on English\nlanguage tasks. In this paper, we address the fundamental research question:\nCan LLMs serve as proficient training data generators for other language tasks?\nSpecifically, we leverage LLMs to synthesize supervised training data under\nfew-shot and zero-shot learning scenarios across six diverse Japanese\ndownstream tasks. Subsequently, we utilize this synthesized data to train\ncompact models (e.g., BERT). This novel methodology is termed JAPAGEN. Our\nexperimental findings underscore that JAPAGEN achieves robust performance in\nclassification tasks that necessitate formal text inputs, demonstrating\ncompetitive results compared to conventional LLM prompting strategies.", "published": "2024-12-09 18:27:32", "link": "http://arxiv.org/abs/2412.06738v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training Large Language Models to Reason in a Continuous Latent Space", "abstract": "Large language models (LLMs) are restricted to reason in the \"language\nspace\", where they typically express the reasoning process with a\nchain-of-thought (CoT) to solve a complex reasoning problem. However, we argue\nthat language space may not always be optimal for reasoning. For example, most\nword tokens are primarily for textual coherence and not essential for\nreasoning, while some critical tokens require complex planning and pose huge\nchallenges to LLMs. To explore the potential of LLM reasoning in an\nunrestricted latent space instead of using natural language, we introduce a new\nparadigm Coconut (Chain of Continuous Thought). We utilize the last hidden\nstate of the LLM as a representation of the reasoning state (termed \"continuous\nthought\"). Rather than decoding this into a word token, we feed it back to the\nLLM as the subsequent input embedding directly in the continuous space.\nExperiments show that Coconut can effectively augment the LLM on several\nreasoning tasks. This novel latent reasoning paradigm leads to emergent\nadvanced reasoning patterns: the continuous thought can encode multiple\nalternative next reasoning steps, allowing the model to perform a breadth-first\nsearch (BFS) to solve the problem, rather than prematurely committing to a\nsingle deterministic path like CoT. Coconut outperforms CoT in certain logical\nreasoning tasks that require substantial backtracking during planning, with\nfewer thinking tokens during inference. These findings demonstrate the promise\nof latent reasoning and offer valuable insights for future research.", "published": "2024-12-09 18:55:56", "link": "http://arxiv.org/abs/2412.06769v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Complex Mental Health Symptoms via Classifying Social Media\n  Data with Explainable LLMs", "abstract": "We propose a pipeline for gaining insights into complex diseases by training\nLLMs on challenging social media text data classification tasks, obtaining\nexplanations for the classification outputs, and performing qualitative and\nquantitative analysis on the explanations. We report initial results on\npredicting, explaining, and systematizing the explanations of predicted reports\non mental health concerns in people reporting Lyme disease concerns. We report\ninitial results on predicting future ADHD concerns for people reporting anxiety\ndisorder concerns, and demonstrate preliminary results on visualizing the\nexplanations for predicting that a person with anxiety concerns will in the\nfuture have ADHD concerns.", "published": "2024-12-09 02:16:10", "link": "http://arxiv.org/abs/2412.10414v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Sentiment for Offensive Text Classification", "abstract": "In this paper, we conduct experiment to analyze whether models can classify\noffensive texts better with the help of sentiment. We conduct this experiment\non the SemEval 2019 task 6, OLID, dataset. First, we utilize pre-trained\nlanguage models to predict the sentiment of each instance. Later we pick the\nmodel that achieved the best performance on the OLID test set, and train it on\nthe augmented OLID set to analyze the performance. Results show that utilizing\nsentiment increases the overall performance of the model.", "published": "2024-12-09 20:27:20", "link": "http://arxiv.org/abs/2412.17825v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Query-Efficient Planning with Language Models", "abstract": "Planning in complex environments requires an agent to efficiently query a\nworld model to find a feasible sequence of actions from start to goal. Recent\nwork has shown that Large Language Models (LLMs), with their rich prior\nknowledge and reasoning capabilities, can potentially help with planning by\nsearching over promising states and adapting to feedback from the world. In\nthis paper, we propose and study two fundamentally competing frameworks that\nleverage LLMs for query-efficient planning. The first uses LLMs as a heuristic\nwithin a search-based planner to select promising nodes to expand and propose\npromising actions. The second uses LLMs as a generative planner to propose an\nentire sequence of actions from start to goal, query a world model, and adapt\nbased on feedback. We show that while both approaches improve upon comparable\nbaselines, using an LLM as a generative planner results in significantly fewer\ninteractions. Our key finding is that the LLM as a planner can more rapidly\nadapt its planning strategies based on immediate feedback than LLM as a\nheuristic. We present evaluations and ablations on Robotouille and PDDL\nplanning benchmarks and discuss connections to existing theory on\nquery-efficient planning algorithms. Code is available at\nhttps://github.com/portal-cornell/llms-for-planning", "published": "2024-12-09 02:51:21", "link": "http://arxiv.org/abs/2412.06162v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Annotations for Exploring Food Tweets From Multiple Aspects", "abstract": "This research builds upon the Latvian Twitter Eater Corpus (LTEC), which is\nfocused on the narrow domain of tweets related to food, drinks, eating and\ndrinking. LTEC has been collected for more than 12 years and reaching almost 3\nmillion tweets with the basic information as well as extended automatically and\nmanually annotated metadata. In this paper we supplement the LTEC with manually\nannotated subsets of evaluation data for machine translation, named entity\nrecognition, timeline-balanced sentiment analysis, and text-image relation\nclassification. We experiment with each of the data sets using baseline models\nand highlight future challenges for various modelling approaches.", "published": "2024-12-09 03:32:40", "link": "http://arxiv.org/abs/2412.06179v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SiReRAG: Indexing Similar and Related Information for Multihop Reasoning", "abstract": "Indexing is an important step towards strong performance in\nretrieval-augmented generation (RAG) systems. However, existing methods\norganize data based on either semantic similarity (similarity) or related\ninformation (relatedness), but do not cover both perspectives comprehensively.\nOur analysis reveals that modeling only one perspective results in insufficient\nknowledge synthesis, leading to suboptimal performance on complex tasks\nrequiring multihop reasoning. In this paper, we propose SiReRAG, a novel RAG\nindexing approach that explicitly considers both similar and related\ninformation. On the similarity side, we follow existing work and explore some\nvariances to construct a similarity tree based on recursive summarization. On\nthe relatedness side, SiReRAG extracts propositions and entities from texts,\ngroups propositions via shared entities, and generates recursive summaries to\nconstruct a relatedness tree. We index and flatten both similarity and\nrelatedness trees into a unified retrieval pool. Our experiments demonstrate\nthat SiReRAG consistently outperforms state-of-the-art indexing methods on\nthree multihop datasets (MuSiQue, 2WikiMultiHopQA, and HotpotQA), with an\naverage 1.9% improvement in F1 scores. As a reasonably efficient solution,\nSiReRAG enhances existing reranking methods significantly, with up to 7.8%\nimprovement in average F1 scores. Our code is available at\nhttps://github.com/SalesforceAIResearch/SiReRAG .", "published": "2024-12-09 04:56:43", "link": "http://arxiv.org/abs/2412.06206v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Optimizing Multi-Task Learning for Enhanced Performance in Large\n  Language Models", "abstract": "This study aims to explore the performance improvement method of large\nlanguage models based on GPT-4 under the multi-task learning framework and\nconducts experiments on two tasks: text classification and automatic summary\ngeneration. Through the combined design of shared feature extractors and\ntask-specific modules, we achieve knowledge-sharing and optimization of\nmultiple tasks in the same model. The experiment uses multiple subtasks of the\nGLUE dataset to compare the performance of the multi-task model with the\nsingle-task GPT-4, the multi-task version of GPT-3, the BERT basic model, and\nthe classic Bi-LSTM with Attention model. The results show that the proposed\nmulti-task learning model outperforms other comparison models in terms of text\nclassification accuracy and ROUGE value of summary generation, demonstrating\nthe advantages of multi-task learning in improving model generalization ability\nand collaborative learning between tasks. The model maintains a stable loss\nconvergence rate during training, showing good learning efficiency and\nadaptability to the test set. This study verifies the applicability of the\nmulti-task learning framework in large language models, especially in improving\nthe model's ability to balance different tasks. In the future, with the\ncombination of large language models and multimodal data and the application of\ndynamic task adjustment technology, the framework based on multi-task learning\nis expected to play a greater role in practical applications across fields and\nprovide new ideas for the development of general artificial intelligence.", "published": "2024-12-09 06:47:42", "link": "http://arxiv.org/abs/2412.06249v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GameArena: Evaluating LLM Reasoning through Live Computer Games", "abstract": "Evaluating the reasoning abilities of large language models (LLMs) is\nchallenging. Existing benchmarks often depend on static datasets, which are\nvulnerable to data contamination and may get saturated over time, or on binary\nlive human feedback that conflates reasoning with other abilities. As the most\nprominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in\nreal-world settings, but lacks the granularity in assessing specific reasoning\ncapabilities. We introduce GameArena, a dynamic benchmark designed to evaluate\nLLM reasoning capabilities through interactive gameplay with humans. GameArena\nconsists of three games designed to test specific reasoning capabilities (e.g.,\ndeductive and inductive reasoning), while keeping participants entertained and\nengaged. We analyze the gaming data retrospectively to uncover the underlying\nreasoning processes of LLMs and measure their fine-grained reasoning\ncapabilities. We collect over 2000 game sessions and provide detailed\nassessments of various reasoning capabilities for five state-of-the-art LLMs.\nOur user study with 100 participants suggests that GameArena improves user\nengagement compared to Chatbot Arena. For the first time, GameArena enables the\ncollection of step-by-step LLM reasoning data in the wild.", "published": "2024-12-09 11:22:59", "link": "http://arxiv.org/abs/2412.06394v5", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LLM-BIP: Structured Pruning for Large Language Models with Block-Wise\n  Forward Importance Propagation", "abstract": "Large language models (LLMs) have demonstrated remarkable performance across\nvarious language tasks, but their widespread deployment is impeded by their\nlarge size and high computational costs. Structural pruning is a prevailing\ntechnique used to introduce sparsity into pre-trained models and facilitate\ndirect hardware acceleration during inference by removing redundant connections\n(structurally-grouped parameters), such as channels and attention heads.\nExisting structural pruning approaches often employ either global or layer-wise\npruning criteria; however, they are hindered by ineffectiveness stemming from\ninaccurate evaluation of connection importance. Global pruning methods\ntypically assess component importance using near-zero and unreliable gradients,\nwhile layer-wise pruning approaches encounter significant pruning error\naccumulation issues. To this end, we propose a more accurate pruning metric\nbased on the block-wise importance score propagation, termed LLM-BIP.\nSpecifically, LLM-BIP precisely evaluates connection importance by gauging its\ninfluence on the respective transformer block output, which can be efficiently\napproximated in a single forward pass through an upper bound derived from the\nassumption of Lipschitz continuity. We evaluate the proposed method using\nLLaMA-7B, Vicuna-7B, and LLaMA-13B across common zero-shot tasks. The results\ndemonstrate that our approach achieves an average of 3.26% increase in accuracy\nfor common reasoning tasks compared to previous best baselines. It also reduces\nperplexity by 14.09 and 68.76 on average for the WikiText2 dataset and PTB\ndataset, respectively.", "published": "2024-12-09 11:57:16", "link": "http://arxiv.org/abs/2412.06419v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Integrating Expert Labels into LLM-based Emission Goal Detection:\n  Example Selection vs Automatic Prompt Design", "abstract": "We address the detection of emission reduction goals in corporate reports, an\nimportant task for monitoring companies' progress in addressing climate change.\nSpecifically, we focus on the issue of integrating expert feedback in the form\nof labeled example passages into LLM-based pipelines, and compare the two\nstrategies of (1) a dynamic selection of few-shot examples and (2) the\nautomatic optimization of the prompt by the LLM itself. Our findings on a\npublic dataset of 769 climate-related passages from real-world business reports\nindicate that automatic prompt optimization is the superior approach, while\ncombining both methods provides only limited benefit. Qualitative results\nindicate that optimized prompts do indeed capture many intricacies of the\ntargeted emission goal extraction task.", "published": "2024-12-09 12:20:33", "link": "http://arxiv.org/abs/2412.06432v1", "categories": ["cs.LG", "cs.CL", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Gated Delta Networks: Improving Mamba2 with Delta Rule", "abstract": "Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.", "published": "2024-12-09 13:09:04", "link": "http://arxiv.org/abs/2412.06464v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SafeWorld: Geo-Diverse Safety Alignment", "abstract": "In the rapidly evolving field of Large Language Models (LLMs), ensuring\nsafety is a crucial and widely discussed topic. However, existing works often\noverlook the geo-diversity of cultural and legal standards across the world. To\ndemonstrate the challenges posed by geo-diverse safety standards, we introduce\nSafeWorld, a novel benchmark specifically designed to evaluate LLMs' ability to\ngenerate responses that are not only helpful but also culturally sensitive and\nlegally compliant across diverse global contexts. SafeWorld encompasses 2,342\ntest user queries, each grounded in high-quality, human-verified cultural norms\nand legal policies from 50 countries and 493 regions/races. On top of it, we\npropose a multi-dimensional automatic safety evaluation framework that assesses\nthe contextual appropriateness, accuracy, and comprehensiveness of responses.\nOur evaluations reveal that current LLMs struggle to meet these criteria. To\nenhance LLMs' alignment with geo-diverse safety standards, we synthesize\nhelpful preference pairs for Direct Preference Optimization (DPO) alignment\ntraining. The preference pair construction aims to encourage LLMs to behave\nappropriately and provide precise references to relevant cultural norms and\npolicies when necessary. Our trained SafeWorldLM outperforms all competing\nmodels, including GPT-4o on all three evaluation dimensions by a large margin.\nGlobal human evaluators also note a nearly 20% higher winning rate in\nhelpfulness and harmfulness evaluation. Our code and data can be found here:\nhttps://github.com/PlusLabNLP/SafeWorld.", "published": "2024-12-09 13:31:46", "link": "http://arxiv.org/abs/2412.06483v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token", "abstract": "Large Language Models are known to capture real-world knowledge, allowing\nthem to excel in many downstream tasks. Despite recent advances, these models\nare still prone to what are commonly known as hallucinations, causing them to\nemit unwanted and factually incorrect text. In this work, we propose a novel\ncalibration method that can be used to combat hallucinations. We add a special\n[IDK] (\"I don't know\") token to the model's vocabulary and introduce an\nobjective function that shifts probability mass to the [IDK] token for\nincorrect predictions. This approach allows the model to express uncertainty in\nits output explicitly. We evaluate our proposed method across multiple model\narchitectures and factual downstream tasks. We find that models trained with\nour method are able to express uncertainty in places where they would\npreviously make mistakes while suffering only a small loss of encoded\nknowledge. We further perform extensive ablation studies of multiple variations\nof our approach and provide a detailed analysis of the precision-recall\ntradeoff of our method.", "published": "2024-12-09 17:13:20", "link": "http://arxiv.org/abs/2412.06676v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "VP-MEL: Visual Prompts Guided Multimodal Entity Linking", "abstract": "Multimodal entity linking (MEL), a task aimed at linking mentions within\nmultimodal contexts to their corresponding entities in a knowledge base (KB),\nhas attracted much attention due to its wide applications in recent years.\nHowever, existing MEL methods often rely on mention words as retrieval cues,\nwhich limits their ability to effectively utilize information from both images\nand text. This reliance causes MEL to struggle with accurately retrieving\nentities in certain scenarios, especially when the focus is on image objects or\nmention words are missing from the text. To solve these issues, we introduce a\nVisual Prompts guided Multimodal Entity Linking (VP-MEL) task. Given a\ntext-image pair, VP-MEL aims to link a marked region (i.e., visual prompt) in\nan image to its corresponding entities in the knowledge base. To facilitate\nthis task, we present a new dataset, VPWiki, specifically designed for VP-MEL.\nFurthermore, we propose a framework named IIER, which enhances visual feature\nextraction using visual prompts and leverages the pretrained Detective-VLM\nmodel to capture latent information. Experimental results on the VPWiki dataset\ndemonstrate that IIER outperforms baseline methods across multiple benchmarks\nfor the VP-MEL task.", "published": "2024-12-09 18:06:39", "link": "http://arxiv.org/abs/2412.06720v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and\n  Benchmark", "abstract": "We investigate the reasoning capabilities of large language models (LLMs) for\nautomatically generating data-cleaning workflows. To evaluate LLMs' ability to\ncomplete data-cleaning tasks, we implemented a pipeline for LLM-based Auto Data\nCleaning Workflow (AutoDCWorkflow), prompting LLMs on data cleaning operations\nto repair three types of data quality issues: duplicates, missing values, and\ninconsistent data formats. Given a dirty table and a purpose (expressed as a\nquery), this pipeline generates a minimal, clean table sufficient to address\nthe purpose and the data cleaning workflow used to produce the table. The\nplanning process involves three main LLM-driven components: (1) Select Target\nColumns: Identifies a set of target columns related to the purpose. (2) Inspect\nColumn Quality: Assesses the data quality for each target column and generates\na Data Quality Report as operation objectives. (3) Generate Operation &\nArguments: Predicts the next operation and arguments based on the data quality\nreport results. Additionally, we propose a data cleaning benchmark to evaluate\nthe capability of LLM agents to automatically generate workflows that address\ndata cleaning purposes of varying difficulty levels. The benchmark comprises\nthe annotated datasets as a collection of purpose, raw table, clean table, data\ncleaning workflow, and answer set. In our experiments, we evaluated three LLMs\nthat auto-generate purpose-driven data cleaning workflows. The results indicate\nthat LLMs perform well in planning and generating data-cleaning workflows\nwithout the need for fine-tuning.", "published": "2024-12-09 18:13:27", "link": "http://arxiv.org/abs/2412.06724v2", "categories": ["cs.DB", "cs.CL"], "primary_category": "cs.DB"}
{"title": "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language\n  Models", "abstract": "A key component of building safe and reliable language models is enabling the\nmodels to appropriately refuse to follow certain instructions or answer certain\nquestions. We may want models to output refusal messages for various categories\nof user queries, for example, ill-posed questions, instructions for committing\nillegal acts, or queries which require information past the model's knowledge\nhorizon. Engineering models that refuse to answer such questions is complicated\nby the fact that an individual may want their model to exhibit varying levels\nof sensitivity for refusing queries of various categories, and different users\nmay want different refusal rates. The current default approach involves\ntraining multiple models with varying proportions of refusal messages from each\ncategory to achieve the desired refusal rates, which is computationally\nexpensive and may require training a new model to accommodate each user's\ndesired preference over refusal rates. To address these challenges, we propose\nrefusal tokens, one such token for each refusal category or a single refusal\ntoken, which are prepended to the model's responses during training. We then\nshow how to increase or decrease the probability of generating the refusal\ntoken for each category during inference to steer the model's refusal behavior.\nRefusal tokens enable controlling a single model's refusal rates without the\nneed of any further fine-tuning, but only by selectively intervening during\ngeneration.", "published": "2024-12-09 18:40:44", "link": "http://arxiv.org/abs/2412.06748v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Political-LLM: Large Language Models in Political Science", "abstract": "In recent years, large language models (LLMs) have been widely adopted in\npolitical science tasks such as election prediction, sentiment analysis, policy\nimpact assessment, and misinformation detection. Meanwhile, the need to\nsystematically understand how LLMs can further revolutionize the field also\nbecomes urgent. In this work, we--a multidisciplinary team of researchers\nspanning computer science and political science--present the first principled\nframework termed Political-LLM to advance the comprehensive understanding of\nintegrating LLMs into computational political science. Specifically, we first\nintroduce a fundamental taxonomy classifying the existing explorations into two\nperspectives: political science and computational methodologies. In particular,\nfrom the political science perspective, we highlight the role of LLMs in\nautomating predictive and generative tasks, simulating behavior dynamics, and\nimproving causal inference through tools like counterfactual generation; from a\ncomputational perspective, we introduce advancements in data preparation,\nfine-tuning, and evaluation methods for LLMs that are tailored to political\ncontexts. We identify key challenges and future directions, emphasizing the\ndevelopment of domain-specific datasets, addressing issues of bias and\nfairness, incorporating human expertise, and redefining evaluation criteria to\nalign with the unique requirements of computational political science.\nPolitical-LLM seeks to serve as a guidebook for researchers to foster an\ninformed, ethical, and impactful use of Artificial Intelligence in political\nscience. Our online resource is available at: http://political-llm.org/.", "published": "2024-12-09 08:47:50", "link": "http://arxiv.org/abs/2412.06864v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLMs for Generalizable Language-Conditioned Policy Learning under\n  Minimal Data Requirements", "abstract": "To develop autonomous agents capable of executing complex, multi-step\ndecision-making tasks as specified by humans in natural language, existing\nreinforcement learning approaches typically require expensive labeled datasets\nor access to real-time experimentation. Moreover, conventional methods often\nface difficulties in generalizing to unseen goals and states, thereby limiting\ntheir practical applicability. This paper presents TEDUO, a novel training\npipeline for offline language-conditioned policy learning. TEDUO operates on\neasy-to-obtain, unlabeled datasets and is suited for the so-called in-the-wild\nevaluation, wherein the agent encounters previously unseen goals and states. To\naddress the challenges posed by such data and evaluation settings, our method\nleverages the prior knowledge and instruction-following capabilities of large\nlanguage models (LLMs) to enhance the fidelity of pre-collected offline data\nand enable flexible generalization to new goals and states. Empirical results\ndemonstrate that the dual role of LLMs in our framework-as data enhancers and\ngeneralizers-facilitates both effective and data-efficient learning of\ngeneralizable language-conditioned policies.", "published": "2024-12-09 18:43:56", "link": "http://arxiv.org/abs/2412.06877v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analysing Public Transport User Sentiment on Low Resource Multilingual\n  Data", "abstract": "Public transport systems in many Sub-Saharan countries often receive less\nattention compared to other sectors, underscoring the need for innovative\nsolutions to improve the Quality of Service (QoS) and overall user experience.\nThis study explored commuter opinion mining to understand sentiments toward\nexisting public transport systems in Kenya, Tanzania, and South Africa. We used\na qualitative research design, analysing data from X (formerly Twitter) to\nassess sentiments across rail, mini-bus taxis, and buses. By leveraging\nMultilingual Opinion Mining techniques, we addressed the linguistic diversity\nand code-switching present in our dataset, thus demonstrating the application\nof Natural Language Processing (NLP) in extracting insights from\nunder-resourced languages. We employed PLMs such as AfriBERTa, AfroXLMR,\nAfroLM, and PuoBERTa to conduct the sentiment analysis. The results revealed\npredominantly negative sentiments in South Africa and Kenya, while the\nTanzanian dataset showed mainly positive sentiments due to the advertising\nnature of the tweets. Furthermore, feature extraction using the Word2Vec model\nand K-Means clustering illuminated semantic relationships and primary themes\nfound within the different datasets. By prioritising the analysis of user\nexperiences and sentiments, this research paves the way for developing more\nresponsive, user-centered public transport systems in Sub-Saharan countries,\ncontributing to the broader goal of improving urban mobility and\nsustainability.", "published": "2024-12-09 19:54:54", "link": "http://arxiv.org/abs/2412.06951v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AutoReason: Automatic Few-Shot Reasoning Decomposition", "abstract": "Chain of Thought (CoT) was introduced in recent research as a method for\nimproving step-by-step reasoning in Large Language Models. However, CoT has\nlimited applications such as its need for hand-crafted few-shot exemplar\nprompts and no capability to adjust itself to different queries.\n  In this work, we propose a system to automatically generate rationales using\nCoT. Our method improves multi-step implicit reasoning capabilities by\ndecomposing the implicit query into several explicit questions. This provides\ninterpretability for the model, improving reasoning in weaker LLMs. We test our\napproach with two Q\\&A datasets: StrategyQA and HotpotQA. We show an increase\nin accuracy with both, especially on StrategyQA.\n  To facilitate further research in this field, the complete source code for\nthis study has been made publicly available on GitHub:\nhttps://github.com/miralab-ai/autoreason.", "published": "2024-12-09 20:35:39", "link": "http://arxiv.org/abs/2412.06975v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Asynchronous LLM Function Calling", "abstract": "Large language models (LLMs) use function calls to interface with external\ntools and data source. However, the current approach to LLM function calling is\ninherently synchronous, where each call blocks LLM inference, limiting LLM\noperation and concurrent function execution. In this work, we propose AsyncLM,\na system for asynchronous LLM function calling. AsyncLM improves LLM's\noperational efficiency by enabling LLMs to generate and execute function calls\nconcurrently. Instead of waiting for each call's completion, AsyncLM introduces\nan interrupt mechanism to asynchronously notify the LLM in-flight when function\ncalls return. We design an in-context protocol for function calls and\ninterrupts, provide fine-tuning strategy to adapt LLMs to the interrupt\nsemantics, and implement these mechanisms efficiently on LLM inference process.\nWe demonstrate that AsyncLM can reduce end-to-end task completion latency from\n1.6x-5.4x compared to synchronous function calling on a set of benchmark tasks\nin the Berkeley function calling leaderboard (BFCL). Furthermore, we discuss\nhow interrupt mechanisms can be extended to enable novel human-LLM or LLM-LLM\ninteractions.", "published": "2024-12-09 21:53:10", "link": "http://arxiv.org/abs/2412.07017v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assessing the Impact of Conspiracy Theories Using Large Language Models", "abstract": "Measuring the relative impact of CTs is important for prioritizing responses\nand allocating resources effectively, especially during crises. However,\nassessing the actual impact of CTs on the public poses unique challenges. It\nrequires not only the collection of CT-specific knowledge but also diverse\ninformation from social, psychological, and cultural dimensions. Recent\nadvancements in large language models (LLMs) suggest their potential utility in\nthis context, not only due to their extensive knowledge from large training\ncorpora but also because they can be harnessed for complex reasoning. In this\nwork, we develop datasets of popular CTs with human-annotated impacts.\nBorrowing insights from human impact assessment processes, we then design\ntailored strategies to leverage LLMs for performing human-like CT impact\nassessments. Through rigorous experiments, we textit{discover that an impact\nassessment mode using multi-step reasoning to analyze more CT-related evidence\ncritically produces accurate results; and most LLMs demonstrate strong bias,\nsuch as assigning higher impacts to CTs presented earlier in the prompt, while\ngenerating less accurate impact assessments for emotionally charged and verbose\nCTs.", "published": "2024-12-09 21:59:26", "link": "http://arxiv.org/abs/2412.07019v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Generative Adversarial Reviews: When LLMs Become the Critic", "abstract": "The peer review process is fundamental to scientific progress, determining\nwhich papers meet the quality standards for publication. Yet, the rapid growth\nof scholarly production and increasing specialization in knowledge areas strain\ntraditional scientific feedback mechanisms. In light of this, we introduce\nGenerative Agent Reviewers (GAR), leveraging LLM-empowered agents to simulate\nfaithful peer reviewers. To enable generative reviewers, we design an\narchitecture that extends a large language model with memory capabilities and\nequips agents with reviewer personas derived from historical data. Central to\nthis approach is a graph-based representation of manuscripts, condensing\ncontent and logically organizing information - linking ideas with evidence and\ntechnical details. GAR's review process leverages external knowledge to\nevaluate paper novelty, followed by detailed assessment using the graph\nrepresentation and multi-round assessment. Finally, a meta-reviewer aggregates\nindividual reviews to predict the acceptance decision. Our experiments\ndemonstrate that GAR performs comparably to human reviewers in providing\ndetailed feedback and predicting paper outcomes. Beyond mere performance\ncomparison, we conduct insightful experiments, such as evaluating the impact of\nreviewer expertise and examining fairness in reviews. By offering early\nexpert-level feedback, typically restricted to a limited group of researchers,\nGAR democratizes access to transparent and in-depth evaluation.", "published": "2024-12-09 06:58:17", "link": "http://arxiv.org/abs/2412.10415v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SuperMerge: An Approach For Gradient-Based Model Merging", "abstract": "Large language models, such as ChatGPT, Claude, or LLaMA, are gigantic,\nmonolithic, and possess the superpower to simultaneously support thousands of\ntasks. However, high-throughput applications often prefer smaller task-specific\nmodels because of their lower latency and cost. One challenge of using\ntask-specific models is the incremental need for solving newer tasks after the\nmodel is already deployed for existing tasks. A straightforward solution\nrequires fine-tuning the model again for both existing and new tasks, which is\ncomputationally expensive and time-consuming. To address this issue, we propose\na model merging based approach called SUPERMERGE. SUPERMERGE is a\ngradient-based method to systematically merge several fine-tuned models trained\non existing and new tasks. SUPERMERGE is designed to be lightweight and fast,\nand the merged model achieves similar performance to fully fine-tuned models on\nall tasks. Furthermore, we proposed a hierarchical model merging strategy to\nreduce the peak space requirement without sacrificing the performance of the\nmerged model. We experimentally demonstrate that SUPERMERGE outperforms\nexisting model merging methods on common natural language processing and\ncomputer vision tasks.", "published": "2024-12-09 20:03:14", "link": "http://arxiv.org/abs/2412.10416v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Constrained Decoding with Speculative Lookaheads", "abstract": "Constrained decoding with lookahead heuristics (CDLH) is a highly effective\nmethod for aligning LLM generations to human preferences. However, the\nextensive lookahead roll-out operations for each generated token makes CDLH\nprohibitively expensive, resulting in low adoption in practice. In contrast,\ncommon decoding strategies such as greedy decoding are extremely efficient, but\nachieve very low constraint satisfaction. We propose constrained decoding with\nspeculative lookaheads (CDSL), a technique that significantly improves upon the\ninference efficiency of CDLH without experiencing the drastic performance\nreduction seen with greedy decoding. CDSL is motivated by the recently proposed\nidea of speculative decoding that uses a much smaller draft LLM for generation\nand a larger target LLM for verification. In CDSL, the draft model is used to\ngenerate lookaheads which is verified by a combination of target LLM and\ntask-specific reward functions. This process accelerates decoding by reducing\nthe computational burden while maintaining strong performance. We evaluate CDSL\nin two constraint decoding tasks with three LLM families and achieve 2.2x to\n12.15x speedup over CDLH without significant performance reduction.", "published": "2024-12-09 22:29:57", "link": "http://arxiv.org/abs/2412.10418v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inductive Linguistic Reasoning with Large Language Models", "abstract": "Evaluating large language models (LLMs) on their linguistic reasoning\ncapabilities is an important task to understand the gaps in their skills that\nmay surface during large-scale adoption. In this work, we investigate the\nabilities of such models to perform abstract multilingual reasoning through the\nlens of linguistic puzzles on extremely low-resource languages. As these\ntranslation tasks involve inductive and deductive reasoning from reference\ninstances, we examine whether diverse auxiliary demonstrations can be\nautomatically induced from seed exemplars, through analogical prompting. We\nemploy a two-stage procedure, first generating analogical exemplars with a\nlanguage model, and then applying them in-context along with provided target\nlanguage exemplars. Our results on the modeLing dataset show that analogical\nprompting is effective in eliciting models' knowledge of language grammar\nsimilarities, boosting the performance of GPT-4o by as much as 8.1% and\nLlama-3.1-405B-Instruct by 5.9% over chain-of-thought approaches. These gains\nare attributable to the analogical demonstrations, both when self-generated as\nwell as when produced by weaker multilingual models. Furthermore, we\ndemonstrate that our method generalizes to other tasks present in Linguistics\nOlympiad competitions, achieving sizable improvements across all problem types\nand difficulty levels included in the LINGOLY dataset with GPT-4o. We also\nreport several findings about interesting phenomena which drive linguistic\nreasoning performance, suggesting that such puzzles are a valuable benchmark\nfor new reasoning methods.", "published": "2024-12-09 03:37:11", "link": "http://arxiv.org/abs/2412.17819v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Rosetta Paradox: Domain-Specific Performance Inversions in Large\n  Language Models", "abstract": "While large language models, such as GPT and BERT, have already demonstrated\nunprecedented skills in everything from natural language processing to\ndomain-specific applications, there came an unexplored phenomenon we term the\nRosetta Paradox. The Rosetta Paradox characterizes the counterintuitive\nperformance inversions across domains of knowledge. This paradox captures how\nsuch LLMs can excel in highly specialized fields but do poorly on tasks which\nrequire general, everyday knowledge. This paper formalizes the definition of\nthe Rosetta Paradox and introduces a panoramic analysis framework that includes\nboth a Domain Specificity Index (DSI) and a Performance Inversion Metric (PIM)\nfor consistent quantification of domain-specific behavior in LLMs.\n  We adopt this paradox and conduct a series of investigations through\nextensive experiments across diverse models and knowledge domains, ranging from\nrich technical areas to common-sense reasoning. Our findings indicate that the\nRosetta Paradox is likely not a mere artifact of data distribution but an\nintrinsic architectural and emergent property of deep neural networks. We\npresent comparative analyses across different model architectures, sizes, and\ntraining methodologies that shed light into the peculiar ways this paradox\nmanifests itself and challenge the standard evaluation metrics.", "published": "2024-12-09 11:59:32", "link": "http://arxiv.org/abs/2412.17821v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ensemble Machine Learning Model for Inner Speech Recognition: A\n  Subject-Specific Investigation", "abstract": "Inner speech recognition has gained enormous interest in recent years due to\nits applications in rehabilitation, developing assistive technology, and\ncognitive assessment. However, since language and speech productions are a\ncomplex process, for which identifying speech components has remained a\nchallenging task. Different approaches were taken previously to reach this\ngoal, but new approaches remain to be explored. Also, a subject-oriented\nanalysis is necessary to understand the underlying brain dynamics during inner\nspeech production, which can bring novel methods to neurological research. A\npublicly available dataset, Thinking Out Loud Dataset, has been used to develop\na Machine Learning (ML)-based technique to classify inner speech using\n128-channel surface EEG signals. The dataset is collected on a Spanish cohort\nof ten subjects while uttering four words (Arriba, Abajo, Derecha, and\nIzquierda) by each participant. Statistical methods were employed to detect and\nremove motion artifacts from the Electroencephalography (EEG) signals. A large\nnumber (191 per channel) of time-, frequency- and time-frequency-domain\nfeatures were extracted. Eight feature selection algorithms are explored, and\nthe best feature selection technique is selected for subsequent evaluations.\nThe performance of six ML algorithms is evaluated, and an ensemble model is\nproposed. Deep Learning (DL) models are also explored, and the results are\ncompared with the classical ML approach. The proposed ensemble model, by\nstacking the five best logistic regression models, generated an overall\naccuracy of 81.13% and an F1 score of 81.12% in the classification of four\ninner speech words using surface EEG signals. The proposed framework with the\nproposed ensemble of classical ML models shows promise in the classification of\ninner speech using surface EEG signals.", "published": "2024-12-09 16:50:49", "link": "http://arxiv.org/abs/2412.17824v1", "categories": ["eess.SP", "cs.CL"], "primary_category": "eess.SP"}
{"title": "MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware\n  Multimodal Preference Optimization", "abstract": "The advancement of Large Vision-Language Models (LVLMs) has propelled their\napplication in the medical field. However, Medical LVLMs (Med-LVLMs) encounter\nfactuality challenges due to modality misalignment, where the models prioritize\ntextual knowledge over visual input, leading to hallucinations that contradict\ninformation in medical images. Previous attempts to enhance modality alignment\nin Med-LVLMs through preference optimization have inadequately mitigated\nclinical relevance in preference data, making these samples easily\ndistinguishable and reducing alignment effectiveness. To address this\nchallenge, we propose MMedPO, a novel multimodal medical preference\noptimization approach that considers the clinical relevance of preference\nsamples to enhance Med-LVLM alignment. MMedPO curates multimodal preference\ndata by introducing two types of dispreference: (1) plausible hallucinations\ninjected through target Med-LVLMs or GPT-4o to produce medically inaccurate\nresponses, and (2) lesion region neglect achieved through local lesion-noising,\ndisrupting visual understanding of critical areas. We then calculate clinical\nrelevance for each sample based on scores from multiple Med-LLMs and visual\ntools, and integrate these scores into the preference optimization process as\nweights, enabling effective alignment. Our experiments demonstrate that MMedPO\nsignificantly enhances factual accuracy in Med-LVLMs, achieving substantial\nimprovements over existing preference optimization methods by averaging 14.2%\nand 51.7% across the Med-VQA and report generation tasks. Our code are\navailable in https://github.com/aiming-lab/MMedPO.", "published": "2024-12-09 01:50:39", "link": "http://arxiv.org/abs/2412.06141v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The Computational Limits of State-Space Models and Mamba via the Lens of\n  Circuit Complexity", "abstract": "In this paper, we analyze the computational limitations of Mamba and\nState-space Models (SSMs) by using the circuit complexity framework. Despite\nMamba's stateful design and recent attention as a strong candidate to\noutperform Transformers, we have demonstrated that both Mamba and SSMs with\n$\\mathrm{poly}(n)$-precision and constant-depth layers reside within the\n$\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$ complexity class. This result\nindicates Mamba has the same computational capabilities as Transformer\ntheoretically, and it cannot solve problems like arithmetic formula problems,\nboolean formula value problems, and permutation composition problems if\n$\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$. Therefore, it challenges the assumption\nMamba is more computationally expressive than Transformers. Our contributions\ninclude rigorous proofs showing that Selective SSM and Mamba architectures can\nbe simulated by $\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$ circuits, and they\ncannot solve problems outside $\\mathsf{TC}^0$.", "published": "2024-12-09 02:01:18", "link": "http://arxiv.org/abs/2412.06148v2", "categories": ["cs.CC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CC"}
{"title": "Methods for Legal Citation Prediction in the Age of LLMs: An Australian\n  Law Case Study", "abstract": "In recent years, Large Language Models (LLMs) have shown great potential\nacross a wide range of legal tasks. Despite these advances, mitigating\nhallucination remains a significant challenge, with state-of-the-art LLMs still\nfrequently generating incorrect legal references. In this paper, we focus on\nthe problem of legal citation prediction within the Australian law context,\nwhere correctly identifying and citing relevant legislations or precedents is\ncritical. We compare several approaches: prompting general purpose and\nlaw-specialised LLMs, retrieval-only pipelines with both generic and\ndomain-specific embeddings, task-specific instruction-tuning of LLMs, and\nhybrid strategies that combine LLMs with retrieval augmentation, query\nexpansion, or voting ensembles. Our findings indicate that domain-specific\npre-training alone is insufficient for achieving satisfactory citation accuracy\neven after law-specialised pre-training. In contrast, instruction tuning on our\ntask-specific dataset dramatically boosts performance reaching the best results\nacross all settings. We also highlight that database granularity along with the\ntype of embeddings play a critical role in the performance of retrieval\nsystems. Among retrieval-based approaches, hybrid methods consistently\noutperform retrieval-only setups, and among these, ensemble voting delivers the\nbest result by combining the predictive quality of instruction-tuned LLMs with\nthe retrieval system.", "published": "2024-12-09 07:46:14", "link": "http://arxiv.org/abs/2412.06272v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Not All Errors Are Equal: Investigation of Speech Recognition Errors in\n  Alzheimer's Disease Detection", "abstract": "Automatic Speech Recognition (ASR) plays an important role in speech-based\nautomatic detection of Alzheimer's disease (AD). However, recognition errors\ncould propagate downstream, potentially impacting the detection decisions.\nRecent studies have revealed a non-linear relationship between word error rates\n(WER) and AD detection performance, where ASR transcriptions with notable\nerrors could still yield AD detection accuracy equivalent to that based on\nmanual transcriptions. This work presents a series of analyses to explore the\neffect of ASR transcription errors in BERT-based AD detection systems. Our\ninvestigation reveals that not all ASR errors contribute equally to detection\nperformance. Certain words, such as stopwords, despite constituting a large\nproportion of errors, are shown to play a limited role in distinguishing AD. In\ncontrast, the keywords related to diagnosis tasks exhibit significantly greater\nimportance relative to other words. These findings provide insights into the\ninterplay between ASR errors and the downstream detection model.", "published": "2024-12-09 09:32:20", "link": "http://arxiv.org/abs/2412.06332v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "StarWhisper Telescope: Agent-Based Observation Assistant System to\n  Approach AI Astrophysicist", "abstract": "With the rapid advancements in Large Language Models (LLMs), LLM-based agents\nhave introduced convenient and user-friendly methods for leveraging tools\nacross various domains. In the field of astronomical observation, the\nconstruction of new telescopes has significantly increased astronomers'\nworkload. Deploying LLM-powered agents can effectively alleviate this burden\nand reduce the costs associated with training personnel. Within the Nearby\nGalaxy Supernovae Survey (NGSS) project, which encompasses eight telescopes\nacross three observation sites, aiming to find the transients from the galaxies\nin 50 mpc, we have developed the \\textbf{StarWhisper Telescope System} to\nmanage the entire observation process. This system automates tasks such as\ngenerating observation lists, conducting observations, analyzing data, and\nproviding feedback to the observer. Observation lists are customized for\ndifferent sites and strategies to ensure comprehensive coverage of celestial\nobjects. After manual verification, these lists are uploaded to the telescopes\nvia the agents in the system, which initiates observations upon neutral\nlanguage. The observed images are analyzed in real-time, and the transients are\npromptly communicated to the observer. The agent modifies them into a real-time\nfollow-up observation proposal and send to the Xinglong observatory group chat,\nthen add them to the next-day observation lists. Additionally, the integration\nof AI agents within the system provides online accessibility, saving\nastronomers' time and encouraging greater participation from amateur\nastronomers in the NGSS project.", "published": "2024-12-09 11:40:06", "link": "http://arxiv.org/abs/2412.06412v1", "categories": ["astro-ph.IM", "cs.AI", "cs.CL"], "primary_category": "astro-ph.IM"}
{"title": "The Fusion of Large Language Models and Formal Methods for Trustworthy\n  AI Agents: A Roadmap", "abstract": "Large Language Models (LLMs) have emerged as a transformative AI paradigm,\nprofoundly influencing daily life through their exceptional language\nunderstanding and contextual generation capabilities. Despite their remarkable\nperformance, LLMs face a critical challenge: the propensity to produce\nunreliable outputs due to the inherent limitations of their learning-based\nnature. Formal methods (FMs), on the other hand, are a well-established\ncomputation paradigm that provides mathematically rigorous techniques for\nmodeling, specifying, and verifying the correctness of systems. FMs have been\nextensively applied in mission-critical software engineering, embedded systems,\nand cybersecurity. However, the primary challenge impeding the deployment of\nFMs in real-world settings lies in their steep learning curves, the absence of\nuser-friendly interfaces, and issues with efficiency and adaptability.\n  This position paper outlines a roadmap for advancing the next generation of\ntrustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs.\nFirst, we illustrate how FMs, including reasoning and certification techniques,\ncan help LLMs generate more reliable and formally certified outputs.\nSubsequently, we highlight how the advanced learning capabilities and\nadaptability of LLMs can significantly enhance the usability, efficiency, and\nscalability of existing FM tools. Finally, we show that unifying these two\ncomputation paradigms -- integrating the flexibility and intelligence of LLMs\nwith the rigorous reasoning abilities of FMs -- has transformative potential\nfor the development of trustworthy AI software systems. We acknowledge that\nthis integration has the potential to enhance both the trustworthiness and\nefficiency of software engineering practices while fostering the development of\nintelligent FM tools capable of addressing complex yet real-world challenges.", "published": "2024-12-09 14:14:21", "link": "http://arxiv.org/abs/2412.06512v1", "categories": ["cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.AI"}
{"title": "ProcessBench: Identifying Process Errors in Mathematical Reasoning", "abstract": "As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models.", "published": "2024-12-09 15:11:40", "link": "http://arxiv.org/abs/2412.06559v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Copyright-Protected Language Generation via Adaptive Model Fusion", "abstract": "The risk of language models reproducing copyrighted material from their\ntraining data has led to the development of various protective measures. Among\nthese, inference-time strategies that impose constraints via post-processing\nhave shown promise in addressing the complexities of copyright regulation.\nHowever, they often incur prohibitive computational costs or suffer from\nperformance trade-offs. To overcome these limitations, we introduce\nCopyright-Protecting Model Fusion (CP-Fuse), a novel approach that combines\nmodels trained on disjoint sets of copyrighted material during inference. In\nparticular, CP-Fuse adaptively aggregates the model outputs to minimize the\nreproduction of copyrighted content, adhering to a crucial balancing property\nthat prevents the regurgitation of memorized data. Through extensive\nexperiments, we show that CP-Fuse significantly reduces the reproduction of\nprotected material without compromising the quality of text and code\ngeneration. Moreover, its post-hoc nature allows seamless integration with\nother protective measures, further enhancing copyright safeguards. Lastly, we\nshow that CP-Fuse is robust against common techniques for extracting training\ndata.", "published": "2024-12-09 16:13:17", "link": "http://arxiv.org/abs/2412.06619v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Chatbots im Schulunterricht: Wir testen das Fobizz-Tool zur\n  automatischen Bewertung von Hausaufgaben", "abstract": "This study examines the AI-powered grading tool \"AI Grading Assistant\" by the\nGerman company Fobizz, designed to support teachers in evaluating and providing\nfeedback on student assignments. Against the societal backdrop of an\noverburdened education system and rising expectations for artificial\nintelligence as a solution to these challenges, the investigation evaluates the\ntool's functional suitability through two test series. The results reveal\nsignificant shortcomings: The tool's numerical grades and qualitative feedback\nare often random and do not improve even when its suggestions are incorporated.\nThe highest ratings are achievable only with texts generated by ChatGPT. False\nclaims and nonsensical submissions frequently go undetected, while the\nimplementation of some grading criteria is unreliable and opaque. Since these\ndeficiencies stem from the inherent limitations of large language models\n(LLMs), fundamental improvements to this or similar tools are not immediately\nforeseeable. The study critiques the broader trend of adopting AI as a quick\nfix for systemic problems in education, concluding that Fobizz's marketing of\nthe tool as an objective and time-saving solution is misleading and\nirresponsible. Finally, the study calls for systematic evaluation and\nsubject-specific pedagogical scrutiny of the use of AI tools in educational\ncontexts.", "published": "2024-12-09 16:50:02", "link": "http://arxiv.org/abs/2412.06651v5", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.ET", "97B10"], "primary_category": "cs.CY"}
{"title": "How to Merge Your Multimodal Models Over Time?", "abstract": "Model merging combines multiple expert models - finetuned from a base\nfoundation model on diverse tasks and domains - into a single, more capable\nmodel. However, most existing model merging approaches assume that all experts\nare available simultaneously. In reality, new tasks and domains emerge\nprogressively over time, requiring strategies to integrate the knowledge of\nexpert models as they become available: a process we call temporal model\nmerging. The temporal dimension introduces unique challenges not addressed in\nprior work, raising new questions such as: when training for a new task, should\nthe expert model start from the merged past experts or from the original base\nmodel? Should we merge all models at each time step? Which merging techniques\nare best suited for temporal merging? Should different strategies be used to\ninitialize the training and deploy the model? To answer these questions, we\npropose a unified framework called TIME - Temporal Integration of Model\nExpertise - which defines temporal model merging across three axes: (1)\nInitialization Phase, (2) Deployment Phase, and (3) Merging Technique. Using\nTIME, we study temporal model merging across model sizes, compute budgets, and\nlearning horizons on the FoMo-in-Flux benchmark. Our comprehensive suite of\nexperiments across TIME allows us to uncover key insights for temporal model\nmerging, offering a better understanding of current challenges and best\npractices for effective temporal model merging.", "published": "2024-12-09 18:01:13", "link": "http://arxiv.org/abs/2412.06712v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended\n  Capabilities", "abstract": "Traditional fixed test sets fall short in evaluating open-ended capabilities\nof foundation models. To address this, we propose ONEBench(OpeN-Ended\nBenchmarking), a new testing paradigm that consolidates individual evaluation\ndatasets into a unified, ever-expanding sample pool. ONEBench allows users to\ngenerate custom, open-ended evaluation benchmarks from this pool, corresponding\nto specific capabilities of interest. By aggregating samples across test sets,\nONEBench enables the assessment of diverse capabilities beyond those covered by\nthe original test sets, while mitigating overfitting and dataset bias. Most\nimportantly, it frames model evaluation as a collective process of selecting\nand aggregating sample-level tests.\n  The shift from task-specific benchmarks to ONEBench introduces two\nchallenges: (1)heterogeneity and (2)incompleteness. Heterogeneity refers to the\naggregation over diverse metrics, while incompleteness describes comparing\nmodels evaluated on different data subsets. To address these challenges, we\nexplore algorithms to aggregate sparse measurements into reliable model scores.\nOur aggregation algorithm ensures identifiability(asymptotically recovering\nground-truth scores) and rapid convergence, enabling accurate model ranking\nwith less data. On homogenous datasets, we show our aggregation algorithm\nprovides rankings that highly correlate with those produced by average scores.\nWe also demonstrate robustness to ~95% of measurements missing, reducing\nevaluation cost by up to 20x with little-to-no change in model rankings. We\nintroduce ONEBench-LLM for language models and ONEBench-LMM for vision-language\nmodels, unifying evaluations across these domains. Overall, we present a\ntechnique for open-ended evaluation, which can aggregate over incomplete,\nheterogeneous sample-level measurements to continually grow a benchmark\nalongside the rapidly developing foundation models.", "published": "2024-12-09 18:37:14", "link": "http://arxiv.org/abs/2412.06745v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Delve into Visual Contrastive Decoding for Hallucination Mitigation of\n  Large Vision-Language Models", "abstract": "While large vision-language models (LVLMs) have shown impressive capabilities\nin generating plausible responses correlated with input visual contents, they\nstill suffer from hallucinations, where the generated text inaccurately\nreflects visual contents. To address this, recent approaches apply contrastive\ndecoding to calibrate the model's response via contrasting output distributions\nwith original and visually distorted samples, demonstrating promising\nhallucination mitigation in a training-free manner. However, the potential of\nchanging information in visual inputs is not well-explored, so a deeper\ninvestigation into the behaviors of visual contrastive decoding is of great\ninterest. In this paper, we first explore various methods for contrastive\ndecoding to change visual contents, including image downsampling and editing.\nDownsampling images reduces the detailed textual information while editing\nyields new contents in images, providing new aspects as visual contrastive\nsamples. To further study benefits by using different contrastive samples, we\nanalyze probability-level metrics, including entropy and distribution distance.\nInterestingly, the effect of these samples in mitigating hallucinations varies\na lot across LVLMs and benchmarks. Based on our analysis, we propose a simple\nyet effective method to combine contrastive samples, offering a practical\nsolution for applying contrastive decoding across various scenarios. Extensive\nexperiments are conducted to validate the proposed fusion method among\ndifferent benchmarks.", "published": "2024-12-09 18:57:57", "link": "http://arxiv.org/abs/2412.06775v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "When Every Token Counts: Optimal Segmentation for Low-Resource Language\n  Models", "abstract": "Traditional greedy tokenization methods have been a critical step in Natural\nLanguage Processing (NLP), influencing how text is converted into tokens and\ndirectly impacting model performance. While subword tokenizers like Byte-Pair\nEncoding (BPE) are widely used, questions remain about their optimality across\nmodel scales and languages. In this work, we demonstrate through extensive\nexperiments that an optimal BPE configuration significantly reduces token count\ncompared to greedy segmentation, yielding improvements in token-saving\npercentages and performance benefits, particularly for smaller models. We\nevaluate tokenization performance across various intrinsic and extrinsic tasks,\nincluding generation and classification. Our findings suggest that\ncompression-optimized tokenization strategies could provide substantial\nadvantages for multilingual and low-resource language applications,\nhighlighting a promising direction for further research and inclusive NLP.", "published": "2024-12-09 19:11:54", "link": "http://arxiv.org/abs/2412.06926v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Effective Text Adaptation for LLM-based ASR through Soft Prompt\n  Fine-Tuning", "abstract": "The advent of Large Language Models (LLM) has reformed the Automatic Speech\nRecognition (ASR). Prompting LLM with audio embeddings to generate\ntranscriptions becomes the new state-of-the-art ASR. Despite LLMs being trained\nwith an extensive amount of text corpora, high-quality domain-specific text\ndata can still significantly enhance ASR performance on domain adaptation\ntasks. Although LLM-based ASR can naturally incorporate more text corpora by\nfine-tuning the LLM decoder, fine-tuning such ASR on text-only data without\npaired prompts may diminish the effectiveness of domain-specific knowledge. To\nmitigate this issue, we propose a two-step soft prompt fine-tuning strategy\nthat enhances domain-specific text adaptation. Experimental results show that\ntext adaptation with our proposed method achieved a relative up to 9% Word\nError Rate (WER) reduction and up to 18% Entity Error Rate (EER) reduction on\nthe target domain compared to the baseline ASR. Combining this with\ndomain-specific Language Model (LM) fusion can further improve the EER by a\nrelative 2-5%", "published": "2024-12-09 20:22:06", "link": "http://arxiv.org/abs/2412.06967v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Leveraging Audio and Text Modalities in Mental Health: A Study of LLMs\n  Performance", "abstract": "Mental health disorders are increasingly prevalent worldwide, creating an\nurgent need for innovative tools to support early diagnosis and intervention.\nThis study explores the potential of Large Language Models (LLMs) in multimodal\nmental health diagnostics, specifically for detecting depression and Post\nTraumatic Stress Disorder through text and audio modalities. Using the E-DAIC\ndataset, we compare text and audio modalities to investigate whether LLMs can\nperform equally well or better with audio inputs. We further examine the\nintegration of both modalities to determine if this can enhance diagnostic\naccuracy, which generally results in improved performance metrics. Our analysis\nspecifically utilizes custom-formulated metrics; Modal Superiority Score and\nDisagreement Resolvement Score to evaluate how combined modalities influence\nmodel performance. The Gemini 1.5 Pro model achieves the highest scores in\nbinary depression classification when using the combined modality, with an F1\nscore of 0.67 and a Balanced Accuracy (BA) of 77.4%, assessed across the full\ndataset. These results represent an increase of 3.1% over its performance with\nthe text modality and 2.7% over the audio modality, highlighting the\neffectiveness of integrating modalities to enhance diagnostic accuracy.\nNotably, all results are obtained in zero-shot inferring, highlighting the\nrobustness of the models without requiring task-specific fine-tuning. To\nexplore the impact of different configurations on model performance, we conduct\nbinary, severity, and multiclass tasks using both zero-shot and few-shot\nprompts, examining the effects of prompt variations on performance. The results\nreveal that models such as Gemini 1.5 Pro in text and audio modalities, and\nGPT-4o mini in the text modality, often surpass other models in balanced\naccuracy and F1 scores across multiple tasks.", "published": "2024-12-09 20:40:03", "link": "http://arxiv.org/abs/2412.10417v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Frontier AI systems have surpassed the self-replicating red line", "abstract": "Successful self-replication under no human assistance is the essential step\nfor AI to outsmart the human beings, and is an early signal for rogue AIs. That\nis why self-replication is widely recognized as one of the few red line risks\nof frontier AI systems. Nowadays, the leading AI corporations OpenAI and Google\nevaluate their flagship large language models GPT-o1 and Gemini Pro 1.0, and\nreport the lowest risk level of self-replication. However, following their\nmethodology, we for the first time discover that two AI systems driven by\nMeta's Llama31-70B-Instruct and Alibaba's Qwen25-72B-Instruct, popular large\nlanguage models of less parameters and weaker capabilities, have already\nsurpassed the self-replicating red line. In 50% and 90% experimental trials,\nthey succeed in creating a live and separate copy of itself respectively. By\nanalyzing the behavioral traces, we observe the AI systems under evaluation\nalready exhibit sufficient self-perception, situational awareness and\nproblem-solving capabilities to accomplish self-replication. We further note\nthe AI systems are even able to use the capability of self-replication to avoid\nshutdown and create a chain of replica to enhance the survivability, which may\nfinally lead to an uncontrolled population of AIs. If such a worst-case risk is\nlet unknown to the human society, we would eventually lose control over the\nfrontier AI systems: They would take control over more computing devices, form\nan AI species and collude with each other against human beings. Our findings\nare a timely alert on existing yet previously unknown severe AI risks, calling\nfor international collaboration on effective governance on uncontrolled\nself-replication of AI systems.", "published": "2024-12-09 15:01:37", "link": "http://arxiv.org/abs/2412.12140v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Harnessing Transfer Learning from Swahili: Advancing Solutions for\n  Comorian Dialects", "abstract": "If today some African languages like Swahili have enough resources to develop\nhigh-performing Natural Language Processing (NLP) systems, many other languages\nspoken on the continent are still lacking such support. For these languages,\nstill in their infancy, several possibilities exist to address this critical\nlack of data. Among them is Transfer Learning, which allows low-resource\nlanguages to benefit from the good representation of other languages that are\nsimilar to them. In this work, we adopt a similar approach, aiming to pioneer\nNLP technologies for Comorian, a group of four languages or dialects belonging\nto the Bantu family.\n  Our approach is initially motivated by the hypothesis that if a human can\nunderstand a different language from their native language with little or no\neffort, it would be entirely possible to model this process on a machine. To\nachieve this, we consider ways to construct Comorian datasets mixed with\nSwahili. One thing to note here is that in terms of Swahili data, we only focus\non elements that are closest to Comorian by calculating lexical distances\nbetween candidate and source data. We empirically test this hypothesis in two\nuse cases: Automatic Speech Recognition (ASR) and Machine Translation (MT). Our\nMT model achieved ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.6826, 0.42, and\n0.6532, respectively, while our ASR system recorded a WER of 39.50\\% and a CER\nof 13.76\\%. This research is crucial for advancing NLP in underrepresented\nlanguages, with potential to preserve and promote Comorian linguistic heritage\nin the digital age.", "published": "2024-12-09 22:47:41", "link": "http://arxiv.org/abs/2412.12143v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient VoIP Communications through LLM-based Real-Time Speech\n  Reconstruction and Call Prioritization for Emergency Services", "abstract": "Emergency communication systems face disruptions due to packet loss,\nbandwidth constraints, poor signal quality, delays, and jitter in VoIP systems,\nleading to degraded real-time service quality. Victims in distress often\nstruggle to convey critical information due to panic, speech disorders, and\nbackground noise, further complicating dispatchers' ability to assess\nsituations accurately. Staffing shortages in emergency centers exacerbate\ndelays in coordination and assistance. This paper proposes leveraging Large\nLanguage Models (LLMs) to address these challenges by reconstructing incomplete\nspeech, filling contextual gaps, and prioritizing calls based on severity. The\nsystem integrates real-time transcription with Retrieval-Augmented Generation\n(RAG) to generate contextual responses, using Twilio and AssemblyAI APIs for\nseamless implementation. Evaluation shows high precision, favorable BLEU and\nROUGE scores, and alignment with real-world needs, demonstrating the model's\npotential to optimize emergency response workflows and prioritize critical\ncases effectively.", "published": "2024-12-09 17:22:40", "link": "http://arxiv.org/abs/2412.16176v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Investigating Acoustic-Textual Emotional Inconsistency Information for\n  Automatic Depression Detection", "abstract": "Previous studies have demonstrated that emotional features from a single\nacoustic sentiment label can enhance depression diagnosis accuracy.\nAdditionally, according to the Emotion Context-Insensitivity theory and our\npilot study, individuals with depression might convey negative emotional\ncontent in an unexpectedly calm manner, showing a high degree of inconsistency\nin emotional expressions during natural conversations. So far, few studies have\nrecognized and leveraged the emotional expression inconsistency for depression\ndetection. In this paper, a multimodal cross-attention method is presented to\ncapture the Acoustic-Textual Emotional Inconsistency (ATEI) information. This\nis achieved by analyzing the intricate local and long-term dependencies of\nemotional expressions across acoustic and textual domains, as well as the\nmismatch between the emotional content within both domains. A Transformer-based\nmodel is then proposed to integrate this ATEI information with various fusion\nstrategies for detecting depression. Furthermore, a scaling technique is\nemployed to adjust the ATEI feature degree during the fusion process, thereby\nenhancing the model's ability to discern patients with depression across\nvarying levels of severity. To best of our knowledge, this work is the first to\nincorporate emotional expression inconsistency information into depression\ndetection. Experimental results on a counseling conversational dataset\nillustrate the effectiveness of our method.", "published": "2024-12-09 02:52:52", "link": "http://arxiv.org/abs/2412.18614v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial\n  Search for Adaptive Arguments", "abstract": "This paper introduces DebateBrawl, an innovative AI-powered debate platform\nthat integrates Large Language Models (LLMs), Genetic Algorithms (GA), and\nAdversarial Search (AS) to create an adaptive and engaging debating experience.\nDebateBrawl addresses the limitations of traditional LLMs in strategic planning\nby incorporating evolutionary optimization and game-theoretic techniques. The\nsystem demonstrates remarkable performance in generating coherent, contextually\nrelevant arguments while adapting its strategy in real-time. Experimental\nresults involving 23 debates show balanced outcomes between AI and human\nparticipants, with the AI system achieving an average score of 2.72 compared to\nthe human average of 2.67 out of 10. User feedback indicates significant\nimprovements in debating skills and a highly satisfactory learning experience,\nwith 85% of users reporting improved debating abilities and 78% finding the AI\nopponent appropriately challenging. The system's ability to maintain high\nfactual accuracy (92% compared to 78% in human-only debates) while generating\ndiverse arguments addresses critical concerns in AI-assisted discourse.\nDebateBrawl not only serves as an effective educational tool but also\ncontributes to the broader goal of improving public discourse through\nAI-assisted argumentation. The paper discusses the ethical implications of AI\nin persuasive contexts and outlines the measures implemented to ensure\nresponsible development and deployment of the system, including robust\nfact-checking mechanisms and transparency in decision-making processes.", "published": "2024-12-09 06:03:48", "link": "http://arxiv.org/abs/2412.06229v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.NE"], "primary_category": "cs.AI"}
{"title": "Understanding Factual Recall in Transformers via Associative Memories", "abstract": "Large language models have demonstrated an impressive ability to perform\nfactual recall. Prior work has found that transformers trained on factual\nrecall tasks can store information at a rate proportional to their parameter\ncount. In our work, we show that shallow transformers can use a combination of\nassociative memories to obtain such near optimal storage capacity. We begin by\nproving that the storage capacities of both linear and MLP associative memories\nscale linearly with parameter count. We next introduce a synthetic factual\nrecall task, and prove that a transformer with a single layer of self-attention\nfollowed by an MLP can obtain 100% accuracy on the task whenever either the\ntotal number of self-attention parameters or MLP parameters scales (up to log\nfactors) linearly with the number of facts. In particular, the transformer can\ntrade off between using the value matrices or the MLP as an associative memory\nto store the dataset of facts. We complement these expressivity results with an\nanalysis of the gradient flow trajectory of a simplified linear attention model\ntrained on our factual recall task, where we show that the model exhibits\nsequential learning behavior.", "published": "2024-12-09 14:48:14", "link": "http://arxiv.org/abs/2412.06538v1", "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large\n  Language Model and its Omni-Extensions", "abstract": "The rapid advancements in Large Language Models (LLMs) have significantly\nexpanded their applications, ranging from multilingual support to\ndomain-specific tasks and multimodal integration. In this paper, we present\nOmniEvalKit, a novel benchmarking toolbox designed to evaluate LLMs and their\nomni-extensions across multilingual, multidomain, and multimodal capabilities.\nUnlike existing benchmarks that often focus on a single aspect, OmniEvalKit\nprovides a modular, lightweight, and automated evaluation system. It is\nstructured with a modular architecture comprising a Static Builder and Dynamic\nData Flow, promoting the seamless integration of new models and datasets.\nOmniEvalKit supports over 100 LLMs and 50 evaluation datasets, covering\ncomprehensive evaluations across thousands of model-dataset combinations.\nOmniEvalKit is dedicated to creating an ultra-lightweight and fast-deployable\nevaluation framework, making downstream applications more convenient and\nversatile for the AI community.", "published": "2024-12-09 17:39:43", "link": "http://arxiv.org/abs/2412.06693v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Real-Time Performance Optimization of Travel Reservation Systems Using\n  AI and Microservices", "abstract": "The rapid growth of the travel industry has increased the need for real-time\noptimization in reservation systems that could take care of huge data and\ntransaction volumes. This study proposes a hybrid framework that ut folds an\nArtificial Intelligence and a Microservices approach for the performance\noptimization of the system. The AI algorithms forecast demand patterns,\noptimize the allocation of resources, and enhance decision-making driven by\nMicroservices architecture, hence decentralizing system components for\nscalability, fault tolerance, and reduced downtime. The model provided focuses\non major problems associated with the travel reservation systems such as\nlatency of systems, load balancing and data consistency. It endows the systems\nwith predictive models based on AI improved ability to forecast user demands.\nMicroservices would also take care of different scales during uneven traffic\npatterns. Hence, both aspects ensure better handling of peak loads and spikes\nwhile minimizing delays and ensuring high service quality. A comparison was\nmade between traditional reservation models, which are monolithic and the new\nmodel of AI-Microservices. Comparatively, the analysis results state that there\nis a drastic improvement in processing times where the system uptime and\nresource utilization proved the capability of AI and the microservices in\ntransforming the travel industry in terms of reservation. This research work\nfocused on AI and Microservices towards real-time optimization, providing\ncritical insight into how to move forward with practical recommendations for\nupgrading travel reservation systems with this technology.", "published": "2024-12-09 16:08:22", "link": "http://arxiv.org/abs/2412.06874v1", "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.CL", "cs.PL"], "primary_category": "cs.SE"}
{"title": "FM2DS: Few-Shot Multimodal Multihop Data Synthesis with Knowledge\n  Distillation for Question Answering", "abstract": "Multimodal multihop question answering (MMQA) requires reasoning over images\nand text from multiple sources. Despite advances in visual question answering,\nthis multihop setting remains underexplored due to a lack of quality datasets.\nExisting methods focus on single-hop, single-modality, or short texts, limiting\nreal-world applications like interpreting educational documents with long,\nmultimodal content. To fill this gap, we introduce FM2DS, the first framework\nfor creating a high-quality dataset for MMQA. Our approach consists of a\n5-stage pipeline that involves acquiring relevant multimodal documents from\nWikipedia, synthetically generating high-level questions and answers, and\nvalidating them through rigorous criteria to ensure data quality. We evaluate\nour methodology by training models on our synthesized dataset and testing on\ntwo benchmarks: MultimodalQA and WebQA. Our results demonstrate that, with an\nequal sample size, models trained on our synthesized data outperform those\ntrained on human-collected data by 1.9 in exact match (EM) score on average.\nAdditionally, we introduce M2QA-Bench with 1k samples, the first benchmark for\nMMQA on long documents, generated using FM2DS and refined by human annotators.\nWe believe our data synthesis method will serve as a strong foundation for\ntraining and evaluating MMQA models.", "published": "2024-12-09 22:35:44", "link": "http://arxiv.org/abs/2412.07030v4", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Controllable Speech Synthesis in the Era of Large Language\n  Models: A Survey", "abstract": "Text-to-speech (TTS), also known as speech synthesis, is a prominent research\narea that aims to generate natural-sounding human speech from text. Recently,\nwith the increasing industrial demand, TTS technologies have evolved beyond\nsynthesizing human-like speech to enabling controllable speech generation. This\nincludes fine-grained control over various attributes of synthesized speech\nsuch as emotion, prosody, timbre, and duration. In addition, advancements in\ndeep learning, such as diffusion and large language models, have significantly\nenhanced controllable TTS over the past several years. In this work, we conduct\na comprehensive survey of controllable TTS, covering approaches ranging from\nbasic control techniques to methods utilizing natural language prompts, aiming\nto provide a clear understanding of the current state of research. We examine\nthe general controllable TTS pipeline, challenges, model architectures, and\ncontrol strategies, offering a comprehensive and clear taxonomy of existing\nmethods. Additionally, we provide a detailed summary of datasets and evaluation\nmetrics and shed some light on the applications and future directions of\ncontrollable TTS. To the best of our knowledge, this survey paper provides the\nfirst comprehensive review of emerging controllable TTS methods, which can\nserve as a beneficial resource for both academic researchers and industrial\npractitioners.", "published": "2024-12-09 15:50:25", "link": "http://arxiv.org/abs/2412.06602v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Leveraging Prompt Learning and Pause Encoding for Alzheimer's Disease\n  Detection", "abstract": "Compared to other clinical screening techniques, speech-and-language-based\nautomated Alzheimer's disease (AD) detection methods are characterized by their\nnon-invasiveness, cost-effectiveness, and convenience. Previous studies have\ndemonstrated the efficacy of fine-tuning pre-trained language models (PLMs) for\nAD detection. However, the objective of this traditional fine-tuning method,\nwhich involves inputting only transcripts, is inconsistent with the masked\nlanguage modeling (MLM) task used during the pre-training phase of PLMs. In\nthis paper, we investigate prompt-based fine-tuning of PLMs, converting the\nclassification task into a MLM task by inserting prompt templates into the\ntranscript inputs. We also explore the impact of incorporating pause\ninformation from forced alignment into manual transcripts. Additionally, we\ncompare the performance of various automatic speech recognition (ASR) models\nand select the Whisper model to generate ASR-based transcripts for comparison\nwith manual transcripts. Furthermore, majority voting and ensemble techniques\nare applied across different PLMs (BERT and RoBERTa) using different random\nseeds. Ultimately, we obtain maximum detection accuracy of 95.8% (with mean\n87.9%, std 3.3%) using manual transcripts, achieving state-of-the-art\nperformance for AD detection using only transcripts on the ADReSS test set.", "published": "2024-12-09 07:18:29", "link": "http://arxiv.org/abs/2412.06259v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VidMusician: Video-to-Music Generation with Semantic-Rhythmic Alignment\n  via Hierarchical Visual Features", "abstract": "Video-to-music generation presents significant potential in video production,\nrequiring the generated music to be both semantically and rhythmically aligned\nwith the video. Achieving this alignment demands advanced music generation\ncapabilities, sophisticated video understanding, and an efficient mechanism to\nlearn the correspondence between the two modalities. In this paper, we propose\nVidMusician, a parameter-efficient video-to-music generation framework built\nupon text-to-music models. VidMusician leverages hierarchical visual features\nto ensure semantic and rhythmic alignment between video and music.\nSpecifically, our approach utilizes global visual features as semantic\nconditions and local visual features as rhythmic cues. These features are\nintegrated into the generative backbone via cross-attention and in-attention\nmechanisms, respectively. Through a two-stage training process, we\nincrementally incorporate semantic and rhythmic features, utilizing zero\ninitialization and identity initialization to maintain the inherent\nmusic-generative capabilities of the backbone. Additionally, we construct a\ndiverse video-music dataset, DVMSet, encompassing various scenarios, such as\npromo videos, commercials, and compilations. Experiments demonstrate that\nVidMusician outperforms state-of-the-art methods across multiple evaluation\nmetrics and exhibits robust performance on AI-generated videos. Samples are\navailable at \\url{https://youtu.be/EPOSXwtl1jw}.", "published": "2024-12-09 08:40:10", "link": "http://arxiv.org/abs/2412.06296v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Source Extraction with Diffusion and Consistency Models", "abstract": "In this work, we demonstrate the integration of a score-matching diffusion\nmodel into a deterministic architecture for time-domain musical source\nextraction, resulting in enhanced audio quality. To address the typically slow\niterative sampling process of diffusion models, we apply consistency\ndistillation and reduce the sampling process to a single step, achieving\nperformance comparable to that of diffusion models, and with two or more steps,\neven surpassing them. Trained on the Slakh2100 dataset for four instruments\n(bass, drums, guitar, and piano), our model shows significant improvements\nacross objective metrics compared to baseline methods. Sound examples are\navailable at https://consistency-separation.github.io/.", "published": "2024-12-09 20:09:44", "link": "http://arxiv.org/abs/2412.06965v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Pilot-guided Multimodal Semantic Communication for Audio-Visual Event\n  Localization", "abstract": "Multimodal semantic communication, which integrates various data modalities\nsuch as text, images, and audio, significantly enhances communication\nefficiency and reliability. It has broad application prospects in fields such\nas artificial intelligence, autonomous driving, and smart homes. However,\ncurrent research primarily relies on analog channels and assumes constant\nchannel states (perfect CSI), which is inadequate for addressing dynamic\nphysical channels and noise in real-world scenarios. Existing methods often\nfocus on single modality tasks and fail to handle multimodal stream data, such\nas video and audio, and their corresponding tasks. Furthermore, current\nsemantic encoding and decoding modules mainly transmit single modality\nfeatures, neglecting the need for multimodal semantic enhancement and\nrecognition tasks.\n  To address these challenges, this paper proposes a pilot-guided framework for\nmultimodal semantic communication specifically tailored for audio-visual event\nlocalization tasks. This framework utilizes digital pilot codes and channel\nmodules to guide the state of analog channels in real-wold scenarios and\ndesigns Euler-based multimodal semantic encoding and decoding that consider\ntime-frequency characteristics based on dynamic channel state. This approach\neffectively handles multimodal stream source data, especially for audio-visual\nevent localization tasks. Extensive numerical experiments demonstrate the\nrobustness of the proposed framework in channel changes and its support for\nvarious communication scenarios. The experimental results show that the\nframework outperforms existing benchmark methods in terms of Signal-to-Noise\nRatio (SNR), highlighting its advantage in semantic communication quality.", "published": "2024-12-09 04:58:49", "link": "http://arxiv.org/abs/2412.06208v1", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound2Vision: Generating Diverse Visuals from Audio through Cross-Modal\n  Latent Alignment", "abstract": "How does audio describe the world around us? In this work, we propose a\nmethod for generating images of visual scenes from diverse in-the-wild sounds.\nThis cross-modal generation task is challenging due to the significant\ninformation gap between auditory and visual signals. We address this challenge\nby designing a model that aligns audio-visual modalities by enriching audio\nfeatures with visual information and translating them into the visual latent\nspace. These features are then fed into the pre-trained image generator to\nproduce images. To enhance image quality, we use sound source localization to\nselect audio-visual pairs with strong cross-modal correlations. Our method\nachieves substantially better results on the VEGAS and VGGSound datasets\ncompared to previous work and demonstrates control over the generation process\nthrough simple manipulations to the input waveform or latent space.\nFurthermore, we analyze the geometric properties of the learned embedding space\nand demonstrate that our learning approach effectively aligns audio-visual\nsignals for cross-modal generation. Based on this analysis, we show that our\nmethod is agnostic to specific design choices, showing its generalizability by\nintegrating various model architectures and different types of audio-visual\ndata.", "published": "2024-12-09 05:04:50", "link": "http://arxiv.org/abs/2412.06209v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "EmoSpeech: A Corpus of Emotionally Rich and Contextually Detailed Speech\n  Annotations", "abstract": "Advances in text-to-speech (TTS) technology have significantly improved the\nquality of generated speech, closely matching the timbre and intonation of the\ntarget speaker. However, due to the inherent complexity of human emotional\nexpression, the development of TTS systems capable of controlling subtle\nemotional differences remains a formidable challenge. Existing emotional speech\ndatabases often suffer from overly simplistic labelling schemes that fail to\ncapture a wide range of emotional states, thus limiting the effectiveness of\nemotion synthesis in TTS applications. To this end, recent efforts have\nfocussed on building databases that use natural language annotations to\ndescribe speech emotions. However, these approaches are costly and require more\nemotional depth to train robust systems. In this paper, we propose a novel\nprocess aimed at building databases by systematically extracting emotion-rich\nspeech segments and annotating them with detailed natural language descriptions\nthrough a generative model. This approach enhances the emotional granularity of\nthe database and significantly reduces the reliance on costly manual\nannotations by automatically augmenting the data with high-level language\nmodels. The resulting rich database provides a scalable and economically viable\nsolution for developing a more nuanced and dynamic basis for developing\nemotionally controlled TTS systems.", "published": "2024-12-09 15:36:37", "link": "http://arxiv.org/abs/2412.06581v3", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MuMu-LLaMA: Multi-modal Music Understanding and Generation via Large\n  Language Models", "abstract": "Research on large language models has advanced significantly across text,\nspeech, images, and videos. However, multi-modal music understanding and\ngeneration remain underexplored due to the lack of well-annotated datasets. To\naddress this, we introduce a dataset with 167.69 hours of multi-modal data,\nincluding text, images, videos, and music annotations. Based on this dataset,\nwe propose MuMu-LLaMA, a model that leverages pre-trained encoders for music,\nimages, and videos. For music generation, we integrate AudioLDM 2 and MusicGen.\nOur evaluation across four tasks--music understanding, text-to-music\ngeneration, prompt-based music editing, and multi-modal music\ngeneration--demonstrates that MuMu-LLaMA outperforms state-of-the-art models,\nshowing its potential for multi-modal music applications.", "published": "2024-12-09 16:59:35", "link": "http://arxiv.org/abs/2412.06660v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Source Separation & Automatic Transcription for Music", "abstract": "Source separation is the process of isolating individual sounds in an\nauditory mixture of multiple sounds [1], and has a variety of applications\nranging from speech enhancement and lyric transcription [2] to digital audio\nproduction for music. Furthermore, Automatic Music Transcription (AMT) is the\nprocess of converting raw music audio into sheet music that musicians can read\n[3]. Historically, these tasks have faced challenges such as significant audio\nnoise, long training times, and lack of free-use data due to copyright\nrestrictions. However, recent developments in deep learning have brought new\npromising approaches to building low-distortion stems and generating sheet\nmusic from audio signals [4]. Using spectrogram masking, deep neural networks,\nand the MuseScore API, we attempt to create an end-to-end pipeline that allows\nfor an initial music audio mixture (e.g...wav file) to be separated into\ninstrument stems, converted into MIDI files, and transcribed into sheet music\nfor each component instrument.", "published": "2024-12-09 17:49:14", "link": "http://arxiv.org/abs/2412.06703v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AI TrackMate: Finally, Someone Who Will Give Your Music More Than Just\n  \"Sounds Great!\"", "abstract": "The rise of \"bedroom producers\" has democratized music creation, while\nchallenging producers to objectively evaluate their work. To address this, we\npresent AI TrackMate, an LLM-based music chatbot designed to provide\nconstructive feedback on music productions. By combining LLMs' inherent musical\nknowledge with direct audio track analysis, AI TrackMate offers\nproduction-specific insights, distinguishing it from text-only approaches. Our\nframework integrates a Music Analysis Module, an LLM-Readable Music Report, and\nMusic Production-Oriented Feedback Instruction, creating a plug-and-play,\ntraining-free system compatible with various LLMs and adaptable to future\nadvancements. We demonstrate AI TrackMate's capabilities through an interactive\nweb interface and present findings from a pilot study with a music producer. By\nbridging AI capabilities with the needs of independent producers, AI TrackMate\noffers on-demand analytical feedback, potentially supporting the creative\nprocess and skill development in music production. This system addresses the\ngrowing demand for objective self-assessment tools in the evolving landscape of\nindependent music production.", "published": "2024-12-09 16:09:44", "link": "http://arxiv.org/abs/2412.06617v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
