{"title": "Analysing Temporal Evolution of Interlingual Wikipedia Article Pairs", "abstract": "Wikipedia articles representing an entity or a topic in different language\neditions evolve independently within the scope of the language-specific user\ncommunities. This can lead to different points of views reflected in the\narticles, as well as complementary and inconsistent information. An analysis of\nhow the information is propagated across the Wikipedia language editions can\nprovide important insights in the article evolution along the temporal and\ncultural dimensions and support quality control. To facilitate such analysis,\nwe present MultiWiki - a novel web-based user interface that provides an\noverview of the similarities and differences across the article pairs\noriginating from different language editions on a timeline. MultiWiki enables\nusers to observe the changes in the interlingual article similarity over time\nand to perform a detailed visual comparison of the article snapshots at a\nparticular time point.", "published": "2017-02-02 15:41:46", "link": "http://arxiv.org/abs/1702.00716v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Symbolic, Distributed and Distributional Representations for Natural\n  Language Processing in the Era of Deep Learning: a Survey", "abstract": "Natural language is inherently a discrete symbolic representation of human\nknowledge. Recent advances in machine learning (ML) and in natural language\nprocessing (NLP) seem to contradict the above intuition: discrete symbols are\nfading away, erased by vectors or tensors called distributed and distributional\nrepresentations. However, there is a strict link between\ndistributed/distributional representations and discrete symbols, being the\nfirst an approximation of the second. A clearer understanding of the strict\nlink between distributed/distributional representations and symbols may\ncertainly lead to radically new deep learning networks. In this paper we make a\nsurvey that aims to renew the link between symbolic representations and\ndistributed/distributional representations. This is the right time to\nrevitalize the area of interpreting how discrete symbols are represented inside\nneural networks.", "published": "2017-02-02 17:53:29", "link": "http://arxiv.org/abs/1702.00764v2", "categories": ["cs.CL", "68T05, 68T50", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Multilingual and Cross-lingual Timeline Extraction", "abstract": "In this paper we present an approach to extract ordered timelines of events,\ntheir participants, locations and times from a set of multilingual and\ncross-lingual data sources. Based on the assumption that event-related\ninformation can be recovered from different documents written in different\nlanguages, we extend the Cross-document Event Ordering task presented at\nSemEval 2015 by specifying two new tasks for, respectively, Multilingual and\nCross-lingual Timeline Extraction. We then develop three deterministic\nalgorithms for timeline extraction based on two main ideas. First, we address\nimplicit temporal relations at document level since explicit time-anchors are\ntoo scarce to build a wide coverage timeline extraction system. Second, we\nleverage several multilingual resources to obtain a single, inter-operable,\nsemantic representation of events across documents and across languages. The\nresult is a highly competitive system that strongly outperforms the current\nstate-of-the-art. Nonetheless, further analysis of the results reveals that\nlinking the event mentions with their target entities and time-anchors remains\na difficult challenge. The systems, resources and scorers are freely available\nto facilitate its use and guarantee the reproducibility of results.", "published": "2017-02-02 14:44:17", "link": "http://arxiv.org/abs/1702.00700v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Learning the Indus Script", "abstract": "Standardized corpora of undeciphered scripts, a necessary starting point for\ncomputational epigraphy, requires laborious human effort for their preparation\nfrom raw archaeological records. Automating this process through machine\nlearning algorithms can be of significant aid to epigraphical research. Here,\nwe take the first steps in this direction and present a deep learning pipeline\nthat takes as input images of the undeciphered Indus script, as found in\narchaeological artifacts, and returns as output a string of graphemes, suitable\nfor inclusion in a standard corpus. The image is first decomposed into regions\nusing Selective Search and these regions are classified as containing textual\nand/or graphical information using a convolutional neural network. Regions\nclassified as potentially containing text are hierarchically merged and trimmed\nto remove non-textual information. The remaining textual part of the image is\nsegmented using standard image processing techniques to isolate individual\ngraphemes. This set is finally passed to a second convolutional neural network\nto classify the graphemes, based on a standard corpus. The classifier can\nidentify the presence or absence of the most frequent Indus grapheme, the \"jar\"\nsign, with an accuracy of 92%. Our results demonstrate the great potential of\ndeep learning approaches in computational epigraphy and, more generally, in the\ndigital humanities.", "published": "2017-02-02 01:56:22", "link": "http://arxiv.org/abs/1702.00523v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "I.5.4; I.2.10; I.2.6"], "primary_category": "cs.CV"}
{"title": "Modelling dependency completion in sentence comprehension as a Bayesian\n  hierarchical mixture process: A case study involving Chinese relative clauses", "abstract": "We present a case-study demonstrating the usefulness of Bayesian hierarchical\nmixture modelling for investigating cognitive processes. In sentence\ncomprehension, it is widely assumed that the distance between linguistic\nco-dependents affects the latency of dependency resolution: the longer the\ndistance, the longer the retrieval time (the distance-based account). An\nalternative theory, direct-access, assumes that retrieval times are a mixture\nof two distributions: one distribution represents successful retrievals (these\nare independent of dependency distance) and the other represents an initial\nfailure to retrieve the correct dependent, followed by a reanalysis that leads\nto successful retrieval. We implement both models as Bayesian hierarchical\nmodels and show that the direct-access model explains Chinese relative clause\nreading time data better than the distance account.", "published": "2017-02-02 07:48:58", "link": "http://arxiv.org/abs/1702.00564v2", "categories": ["stat.AP", "cs.CL", "stat.ME", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Topic Modeling the H\u00e0n di\u0103n Ancient Classics", "abstract": "Ancient Chinese texts present an area of enormous challenge and opportunity\nfor humanities scholars interested in exploiting computational methods to\nassist in the development of new insights and interpretations of culturally\nsignificant materials. In this paper we describe a collaborative effort between\nIndiana University and Xi'an Jiaotong University to support exploration and\ninterpretation of a digital corpus of over 18,000 ancient Chinese documents,\nwhich we refer to as the \"Handian\" ancient classics corpus (H\\`an di\\u{a}n\ng\\u{u} j\\'i, i.e, the \"Han canon\" or \"Chinese classics\"). It contains classics\nof ancient Chinese philosophy, documents of historical and biographical\nsignificance, and literary works. We begin by describing the Digital Humanities\ncontext of this joint project, and the advances in humanities computing that\nmade this project feasible. We describe the corpus and introduce our\napplication of probabilistic topic modeling to this corpus, with attention to\nthe particular challenges posed by modeling ancient Chinese documents. We give\na specific example of how the software we have developed can be used to aid\ndiscovery and interpretation of themes in the corpus. We outline more advanced\nforms of computer-aided interpretation that are also made possible by the\nprogramming interface provided by our system, and the general implications of\nthese methods for understanding the nature of meaning in these texts.", "published": "2017-02-02 22:51:04", "link": "http://arxiv.org/abs/1702.00860v1", "categories": ["cs.CL", "cs.CY", "cs.DL", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
