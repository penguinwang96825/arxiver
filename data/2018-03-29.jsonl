{"title": "A Systematic Review of Automated Grammar Checking in English Language", "abstract": "Grammar checking is the task of detection and correction of grammatical\nerrors in the text. English is the dominating language in the field of science\nand technology. Therefore, the non-native English speakers must be able to use\ncorrect English grammar while reading, writing or speaking. This generates the\nneed of automatic grammar checking tools. So far many approaches have been\nproposed and implemented. But less efforts have been made in surveying the\nliterature in the past decade. The objective of this systematic review is to\nexamine the existing literature, highlighting the current issues and suggesting\nthe potential directions of future research. This systematic review is a result\nof analysis of 12 primary studies obtained after designing a search strategy\nfor selecting papers found on the web. We also present a possible scheme for\nthe classification of grammar errors. Among the main observations, we found\nthat there is a lack of efficient and robust grammar checking tools for real\ntime applications. We present several useful illustrations- most prominent are\nthe schematic diagrams that we provide for each approach and a table that\nsummarizes these approaches along different dimensions such as target error\ntypes, linguistic dataset used, strengths and limitations of the approach. This\nfacilitates better understandability, comparison and evaluation of previous\nresearch.", "published": "2018-03-29 10:42:03", "link": "http://arxiv.org/abs/1804.00540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Unsupervised Automatic Speech Recognition Trained by Unaligned\n  Speech and Text only", "abstract": "Automatic speech recognition (ASR) has been widely researched with supervised\napproaches, while many low-resourced languages lack audio-text aligned data,\nand supervised methods cannot be applied on them.\n  In this work, we propose a framework to achieve unsupervised ASR on a read\nEnglish speech dataset, where audio and text are unaligned. In the first stage,\neach word-level audio segment in the utterances is represented by a vector\nrepresentation extracted by a sequence-of-sequence autoencoder, in which\nphonetic information and speaker information are disentangled.\n  Secondly, semantic embeddings of audio segments are trained from the vector\nrepresentations using a skip-gram model. Last but not the least, an\nunsupervised method is utilized to transform semantic embeddings of audio\nsegments to text embedding space, and finally the transformed embeddings are\nmapped to words.\n  With the above framework, we are towards unsupervised ASR trained by\nunaligned text and speech only.", "published": "2018-03-29 08:03:45", "link": "http://arxiv.org/abs/1803.10952v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Computer-Assisted Text Analysis for Social Science: Topic Models and\n  Beyond", "abstract": "Topic models are a family of statistical-based algorithms to summarize,\nexplore and index large collections of text documents. After a decade of\nresearch led by computer scientists, topic models have spread to social science\nas a new generation of data-driven social scientists have searched for tools to\nexplore large collections of unstructured text. Recently, social scientists\nhave contributed to topic model literature with developments in causal\ninference and tools for handling the problem of multi-modality. In this paper,\nI provide a literature review on the evolution of topic modeling including\nextensions for document covariates, methods for evaluation and interpretation,\nand advances in interactive visualizations along with each aspect's relevance\nand application for social science research.", "published": "2018-03-29 13:11:32", "link": "http://arxiv.org/abs/1803.11045v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Semantic Divergences in Parallel Text without Annotations", "abstract": "Recognizing that even correct translations are not always semantically\nequivalent, we automatically detect meaning divergences in parallel sentence\npairs with a deep neural model of bilingual semantic similarity which can be\ntrained for any parallel corpus without any manual annotation. We show that our\nsemantic model detects divergences more accurately than models based on surface\nfeatures derived from word alignments, and that these divergences matter for\nneural machine translation.", "published": "2018-03-29 15:18:09", "link": "http://arxiv.org/abs/1803.11112v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Colorless green recurrent networks dream hierarchically", "abstract": "Recurrent neural networks (RNNs) have achieved impressive results in a\nvariety of linguistic processing tasks, suggesting that they can induce\nnon-trivial properties of language. We investigate here to what extent RNNs\nlearn to track abstract hierarchical syntactic structure. We test whether RNNs\ntrained with a generic language modeling objective in four languages (Italian,\nEnglish, Hebrew, Russian) can predict long-distance number agreement in various\nconstructions. We include in our evaluation nonsensical sentences where RNNs\ncannot rely on semantic or lexical cues (\"The colorless green ideas I ate with\nthe chair sleep furiously\"), and, for Italian, we compare model performance to\nhuman intuitions. Our language-model-trained RNNs make reliable predictions\nabout long-distance agreement, and do not lag much behind human performance. We\nthus bring support to the hypothesis that RNNs are not just shallow-pattern\nextractors, but they also acquire deeper grammatical competence.", "published": "2018-03-29 16:27:36", "link": "http://arxiv.org/abs/1803.11138v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Universal Sentence Encoder", "abstract": "We present models for encoding sentences into embedding vectors that\nspecifically target transfer learning to other NLP tasks. The models are\nefficient and result in accurate performance on diverse transfer tasks. Two\nvariants of the encoding models allow for trade-offs between accuracy and\ncompute resources. For both variants, we investigate and report the\nrelationship between model complexity, resource consumption, the availability\nof transfer task training data, and task performance. Comparisons are made with\nbaselines that use word level transfer learning via pretrained word embeddings\nas well as baselines do not use any transfer learning. We find that transfer\nlearning using sentence embeddings tends to outperform word level transfer.\nWith transfer learning via sentence embeddings, we observe surprisingly good\nperformance with minimal amounts of supervised training data for a transfer\ntask. We obtain encouraging results on Word Embedding Association Tests (WEAT)\ntargeted at detecting model bias. Our pre-trained sentence encoding models are\nmade freely available for download and on TF Hub.", "published": "2018-03-29 17:43:03", "link": "http://arxiv.org/abs/1803.11175v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Capsule Networks with Dynamic Routing for Text\n  Classification", "abstract": "In this study, we explore capsule networks with dynamic routing for text\nclassification. We propose three strategies to stabilize the dynamic routing\nprocess to alleviate the disturbance of some noise capsules which may contain\n\"background\" information or have not been successfully trained. A series of\nexperiments are conducted with capsule networks on six text classification\nbenchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets,\nwhich shows the effectiveness of capsule networks for text classification. We\nadditionally show that capsule networks exhibit significant improvement when\ntransfer single-label to multi-label text classification over strong baseline\nmethods. To the best of our knowledge, this is the first work that capsule\nnetworks have been empirically investigated for text modeling.", "published": "2018-03-29 02:27:42", "link": "http://arxiv.org/abs/1804.00538v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Two can play this Game: Visual Dialog with Discriminative Question\n  Generation and Answering", "abstract": "Human conversation is a complex mechanism with subtle nuances. It is hence an\nambitious goal to develop artificial intelligence agents that can participate\nfluently in a conversation. While we are still far from achieving this goal,\nrecent progress in visual question answering, image captioning, and visual\nquestion generation shows that dialog systems may be realizable in the not too\ndistant future. To this end, a novel dataset was introduced recently and\nencouraging results were demonstrated, particularly for question answering. In\nthis paper, we demonstrate a simple symmetric discriminative baseline, that can\nbe applied to both predicting an answer as well as predicting a question. We\nshow that this method performs on par with the state of the art, even memory\nnet based methods. In addition, for the first time on the visual dialog\ndataset, we assess the performance of a system asking questions, and\ndemonstrate how visual dialog can be generated from discriminative question\ngeneration and question answering.", "published": "2018-03-29 17:58:43", "link": "http://arxiv.org/abs/1803.11186v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Deep Recurrent Neural Networks for Product Attribute Extraction in\n  eCommerce", "abstract": "Extracting accurate attribute qualities from product titles is a vital\ncomponent in delivering eCommerce customers with a rewarding online shopping\nexperience via an enriched faceted search. We demonstrate the potential of Deep\nRecurrent Networks in this domain, primarily models such as Bidirectional LSTMs\nand Bidirectional LSTM-CRF with or without an attention mechanism. These have\nimproved overall F1 scores, as compared to the previous benchmarks (More et\nal.) by at least 0.0391, showcasing an overall precision of 97.94%, recall of\n94.12% and the F1 score of 0.9599. This has made us achieve a significant\ncoverage of important facets or attributes of products which not only shows the\nefficacy of deep recurrent models over previous machine learning benchmarks but\nalso greatly enhances the overall customer experience while shopping online.", "published": "2018-03-29 23:21:11", "link": "http://arxiv.org/abs/1803.11284v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Attention-based End-to-End Models for Small-Footprint Keyword Spotting", "abstract": "In this paper, we propose an attention-based end-to-end neural approach for\nsmall-footprint keyword spotting (KWS), which aims to simplify the pipelines of\nbuilding a production-quality KWS system. Our model consists of an encoder and\nan attention mechanism. The encoder transforms the input signal into a high\nlevel representation using RNNs. Then the attention mechanism weights the\nencoder features and generates a fixed-length vector. Finally, by linear\ntransformation and softmax function, the vector becomes a score used for\nkeyword detection. We also evaluate the performance of different encoder\narchitectures, including LSTM, GRU and CRNN. Experiments on real-world wake-up\ndata show that our approach outperforms the recent Deep KWS approach by a large\nmargin and the best performance is achieved by CRNN. To be more specific, with\n~84K parameters, our attention-based model achieves 1.02% false rejection rate\n(FRR) at 1.0 false alarm (FA) per hour.", "published": "2018-03-29 03:32:59", "link": "http://arxiv.org/abs/1803.10916v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Cracking the cocktail party problem by multi-beam deep attractor network", "abstract": "While recent progresses in neural network approaches to single-channel speech\nseparation, or more generally the cocktail party problem, achieved significant\nimprovement, their performance for complex mixtures is still not satisfactory.\nIn this work, we propose a novel multi-channel framework for multi-talker\nseparation. In the proposed model, an input multi-channel mixture signal is\nfirstly converted to a set of beamformed signals using fixed beam patterns. For\nthis beamforming, we propose to use differential beamformers as they are more\nsuitable for speech separation. Then each beamformed signal is fed into a\nsingle-channel anchored deep attractor network to generate separated signals.\nAnd the final separation is acquired by post selecting the separating output\nfor each beams. To evaluate the proposed system, we create a challenging\ndataset comprising mixtures of 2, 3 or 4 speakers. Our results show that the\nproposed system largely improves the state of the art in speech separation,\nachieving 11.5 dB, 11.76 dB and 11.02 dB average signal-to-distortion ratio\nimprovement for 4, 3 and 2 overlapped speaker mixtures, which is comparable to\nthe performance of a minimum variance distortionless response beamformer that\nuses oracle location, source, and noise information. We also run speech\nrecognition with a clean trained acoustic model on the separated speech,\nachieving relative word error rate (WER) reduction of 45.76\\%, 59.40\\% and\n62.80\\% on fully overlapped speech of 4, 3 and 2 speakers, respectively. With a\nfar talk acoustic model, the WER is further reduced.", "published": "2018-03-29 04:42:26", "link": "http://arxiv.org/abs/1803.10924v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Attentive Statistics Pooling for Deep Speaker Embedding", "abstract": "This paper proposes attentive statistics pooling for deep speaker embedding\nin text-independent speaker verification. In conventional speaker embedding,\nframe-level features are averaged over all the frames of a single utterance to\nform an utterance-level feature. Our method utilizes an attention mechanism to\ngive different weights to different frames and generates not only weighted\nmeans but also weighted standard deviations. In this way, it can capture\nlong-term variations in speaker characteristics more effectively. An evaluation\non the NIST SRE 2012 and the VoxCeleb data sets shows that it reduces equal\nerror rates (EERs) from the conventional method by 7.5% and 8.1%, respectively.", "published": "2018-03-29 08:45:55", "link": "http://arxiv.org/abs/1803.10963v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An empirical approach to the relationship between emotion and music\n  production quality", "abstract": "In music production, the role of the mix engineer is to take recorded music\nand convey the expressed emotions as professionally sounding as possible. We\ninvestigated the relationship between music production quality and musically\ninduced and perceived emotions. A listening test was performed where 10\ncritical listeners and 10 non-critical listeners evaluated 10 songs. There were\ntwo mixes of each song, the low quality mix and the high quality mix. Each\nparticipant's subjective experience was measured directly through questionnaire\nand indirectly by examining peripheral physiological changes, change in facial\nexpressions and the number of head nods and shakes they made as they listened\nto each mix. We showed that music production quality had more of an emotional\nimpact on critical listeners. Also, critical listeners had significantly\ndifferent emotional responses to non-critical listeners for the high quality\nmixes and to a lesser extent the low quality mixes. The findings suggest that\nhaving a high level of skill in mix engineering only seems to matter in an\nemotional context to a subset of music listeners.", "published": "2018-03-29 16:57:26", "link": "http://arxiv.org/abs/1803.11154v1", "categories": ["eess.IV", "cs.SD", "eess.AS"], "primary_category": "eess.IV"}
