{"title": "EmotionLines: An Emotion Corpus of Multi-Party Conversations", "abstract": "Feeling emotion is a critical characteristic to distinguish people from\nmachines. Among all the multi-modal resources for emotion detection, textual\ndatasets are those containing the least additional information in addition to\nsemantics, and hence are adopted widely for testing the developed systems.\nHowever, most of the textual emotional datasets consist of emotion labels of\nonly individual words, sentences or documents, which makes it challenging to\ndiscuss the contextual flow of emotions. In this paper, we introduce\nEmotionLines, the first dataset with emotions labeling on all utterances in\neach dialogue only based on their textual content. Dialogues in EmotionLines\nare collected from Friends TV scripts and private Facebook messenger dialogues.\nThen one of seven emotions, six Ekman's basic emotions plus the neutral\nemotion, is labeled on each utterance by 5 Amazon MTurkers. A total of 29,245\nutterances from 2,000 dialogues are labeled in EmotionLines. We also provide\nseveral strong baselines for emotion detection models on EmotionLines in this\npaper.", "published": "2018-02-23 04:06:38", "link": "http://arxiv.org/abs/1802.08379v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards end-to-end spoken language understanding", "abstract": "Spoken language understanding system is traditionally designed as a pipeline\nof a number of components. First, the audio signal is processed by an automatic\nspeech recognizer for transcription or n-best hypotheses. With the recognition\nresults, a natural language understanding system classifies the text to\nstructured data as domain, intent and slots for down-streaming consumers, such\nas dialog system, hands-free applications. These components are usually\ndeveloped and optimized independently. In this paper, we present our study on\nan end-to-end learning system for spoken language understanding. With this\nunified approach, we can infer the semantic meaning directly from audio\nfeatures without the intermediate text representation. This study showed that\nthe trained model can achieve reasonable good result and demonstrated that the\nmodel can capture the semantic attention directly from the audio features.", "published": "2018-02-23 05:39:46", "link": "http://arxiv.org/abs/1802.08395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable Charge Predictions for Criminal Cases: Learning to\n  Generate Court Views from Fact Descriptions", "abstract": "In this paper, we propose to study the problem of COURT VIEW GENeration from\nthe fact description in a criminal case. The task aims to improve the\ninterpretability of charge prediction systems and help automatic legal document\ngeneration. We formulate this task as a text-to-text natural language\ngeneration (NLG) problem. Sequenceto-sequence model has achieved cutting-edge\nperformances in many NLG tasks. However, due to the non-distinctions of fact\ndescriptions, it is hard for Seq2Seq model to generate charge-discriminative\ncourt views. In this work, we explore charge labels to tackle this issue. We\npropose a label-conditioned Seq2Seq model with attention for this problem, to\ndecode court views conditioned on encoded charge labels. Experimental results\nshow the effectiveness of our method.", "published": "2018-02-23 12:33:29", "link": "http://arxiv.org/abs/1802.08504v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Scoped Meaning Representations", "abstract": "Semantic parsing offers many opportunities to improve natural language\nunderstanding. We present a semantically annotated parallel corpus for English,\nGerman, Italian, and Dutch where sentences are aligned with scoped meaning\nrepresentations in order to capture the semantics of negation, modals,\nquantification, and presupposition triggers. The semantic formalism is based on\nDiscourse Representation Theory, but concepts are represented by WordNet\nsynsets and thematic roles by VerbNet relations. Translating scoped meaning\nrepresentations to sets of clauses enables us to compare them for the purpose\nof semantic parser evaluation and checking translations. This is done by\ncomputing precision and recall on matching clauses, in a similar way as is done\nfor Abstract Meaning Representations. We show that our matching tool for\nevaluating scoped meaning representations is both accurate and efficient.\nApplying this matching tool to three baseline semantic parsers yields F-scores\nbetween 43% and 54%. A pilot study is performed to automatically find changes\nin meaning by comparing meaning representations of translations. This\ncomparison turns out to be an additional way of (i) finding annotation mistakes\nand (ii) finding instances where our semantic analysis needs to be improved.", "published": "2018-02-23 15:31:19", "link": "http://arxiv.org/abs/1802.08599v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ranking Sentences for Extractive Summarization with Reinforcement\n  Learning", "abstract": "Single document summarization is the task of producing a shorter version of a\ndocument while preserving its principal information content. In this paper we\nconceptualize extractive summarization as a sentence ranking task and propose a\nnovel training algorithm which globally optimizes the ROUGE evaluation metric\nthrough a reinforcement learning objective. We use our algorithm to train a\nneural summarization model on the CNN and DailyMail datasets and demonstrate\nexperimentally that it outperforms state-of-the-art extractive and abstractive\nsystems when evaluated automatically and by humans.", "published": "2018-02-23 16:55:31", "link": "http://arxiv.org/abs/1802.08636v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Speech Recognition and Topic Identification for\n  Almost-Zero-Resource Languages", "abstract": "Automatic speech recognition (ASR) systems often need to be developed for\nextremely low-resource languages to serve end-uses such as audio content\ncategorization and search. While universal phone recognition is natural to\nconsider when no transcribed speech is available to train an ASR system in a\nlanguage, adapting universal phone models using very small amounts (minutes\nrather than hours) of transcribed speech also needs to be studied, particularly\nwith state-of-the-art DNN-based acoustic models. The DARPA LORELEI program\nprovides a framework for such very-low-resource ASR studies, and provides an\nextrinsic metric for evaluating ASR performance in a humanitarian assistance,\ndisaster relief setting. This paper presents our Kaldi-based systems for the\nprogram, which employ a universal phone modeling approach to ASR, and describes\nrecipes for very rapid adaptation of this universal ASR system. The results we\nobtain significantly outperform results obtained by many competing approaches\non the NIST LoReHLT 2017 Evaluation datasets.", "published": "2018-02-23 20:47:51", "link": "http://arxiv.org/abs/1802.08731v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Phonology to Syntax: Unsupervised Linguistic Typology at Different\n  Levels with Language Embeddings", "abstract": "A core part of linguistic typology is the classification of languages\naccording to linguistic properties, such as those detailed in the World Atlas\nof Language Structure (WALS). Doing this manually is prohibitively\ntime-consuming, which is in part evidenced by the fact that only 100 out of\nover 7,000 languages spoken in the world are fully covered in WALS.\n  We learn distributed language representations, which can be used to predict\ntypological properties on a massively multilingual scale. Additionally,\nquantitative and qualitative analyses of these language embeddings can tell us\nhow language similarities are encoded in NLP models for tasks at different\ntypological levels. The representations are learned in an unsupervised manner\nalongside tasks at three typological levels: phonology (grapheme-to-phoneme\nprediction, and phoneme reconstruction), morphology (morphological inflection),\nand syntax (part-of-speech tagging).\n  We consider more than 800 languages and find significant differences in the\nlanguage representations encoded, depending on the target task. For instance,\nalthough Norwegian Bokm{\\aa}l and Danish are typologically close to one\nanother, they are phonologically distant, which is reflected in their language\nembeddings growing relatively distant in a phonological task. We are also able\nto predict typological features in WALS with high accuracies, even for unseen\nlanguage families.", "published": "2018-02-23 11:55:44", "link": "http://arxiv.org/abs/1802.09375v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Grammar Induction with Depth-bounded PCFG", "abstract": "There has been recent interest in applying cognitively or empirically\nmotivated bounds on recursion depth to limit the search space of grammar\ninduction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al.,\n2016). This work extends this depth-bounding approach to probabilistic\ncontext-free grammar induction (DB-PCFG), which has a smaller parameter space\nthan hierarchical sequence models, and therefore more fully exploits the space\nreductions of depth-bounding. Results for this model on grammar acquisition\nfrom transcribed child-directed speech and newswire text exceed or are\ncompetitive with those of other models when evaluated on parse accuracy.\nMoreover, gram- mars acquired from this model demonstrate a consistent use of\ncategory labels, something which has not been demonstrated by other acquisition\nmodels.", "published": "2018-02-23 14:30:00", "link": "http://arxiv.org/abs/1802.08545v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reusing Weights in Subword-aware Neural Language Models", "abstract": "We propose several ways of reusing subword embeddings and other weights in\nsubword-aware neural language models. The proposed techniques do not benefit a\ncompetitive character-aware model, but some of them improve the performance of\nsyllable- and morpheme-aware models while showing significant reductions in\nmodel sizes. We discover a simple hands-on principle: in a multi-layer input\nembedding model, layers should be tied consecutively bottom-up if reused at\noutput. Our best morpheme-aware model with properly reused weights beats the\ncompetitive word-level model by a large margin across multiple languages and\nhas 20%-87% fewer parameters.", "published": "2018-02-23 03:44:15", "link": "http://arxiv.org/abs/1802.08375v2", "categories": ["cs.CL", "cs.NE", "stat.ML", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Visualizing the Flow of Discourse with a Concept Ontology", "abstract": "Understanding and visualizing human discourse has long being a challenging\ntask. Although recent work on argument mining have shown success in classifying\nthe role of various sentences, the task of recognizing concepts and\nunderstanding the ways in which they are discussed remains challenging. Given\nan email thread or a transcript of a group discussion, our task is to extract\nthe relevant concepts and understand how they are referenced and re-referenced\nthroughout the discussion. In the present work, we present a preliminary\napproach for extracting and visualizing group discourse by adapting Wikipedia's\ncategory hierarchy to be an external concept ontology. From a user study, we\nfound that our method achieved better results than 4 strong alternative\napproaches, and we illustrate our visualization method based on the extracted\ndiscourse flows.", "published": "2018-02-23 15:56:07", "link": "http://arxiv.org/abs/1802.08614v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "\"You are no Jack Kennedy\": On Media Selection of Highlights from\n  Presidential Debates", "abstract": "Political speeches and debates play an important role in shaping the images\nof politicians, and the public often relies on media outlets to select bits of\npolitical communication from a large pool of utterances. It is an important\nresearch question to understand what factors impact this selection process.\n  To quantitatively explore the selection process, we build a three- decade\ndataset of presidential debate transcripts and post-debate coverage. We first\nexamine the effect of wording and propose a binary classification framework\nthat controls for both the speaker and the debate situation. We find that\ncrowdworkers can only achieve an accuracy of 60% in this task, indicating that\nmedia choices are not entirely obvious. Our classifiers outperform crowdworkers\non average, mainly in primary debates. We also compare important factors from\ncrowdworkers' free-form explanations with those from data-driven methods and\nfind interesting differences. Few crowdworkers mentioned that \"context\nmatters\", whereas our data show that well-quoted sentences are more distinct\nfrom the previous utterance by the same speaker than less-quoted sentences.\nFinally, we examine the aggregate effect of media preferences towards different\nwordings to understand the extent of fragmentation among media outlets. By\nanalyzing a bipartite graph built from quoting behavior in our data, we observe\na decreasing trend in bipartisan coverage.", "published": "2018-02-23 19:00:01", "link": "http://arxiv.org/abs/1802.08690v1", "categories": ["cs.SI", "cs.CL", "physics.soc-ph"], "primary_category": "cs.SI"}
{"title": "High-Dimensional Vector Semantics", "abstract": "In this paper we explore the \"vector semantics\" problem from the perspective\nof \"almost orthogonal\" property of high-dimensional random vectors. We show\nthat this intriguing property can be used to \"memorize\" random vectors by\nsimply adding them, and we provide an efficient probabilistic solution to the\nset membership problem. Also, we discuss several applications to word context\nvector embeddings, document sentences similarity, and spam filtering.", "published": "2018-02-23 16:50:16", "link": "http://arxiv.org/abs/1802.09914v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Efficient Neural Audio Synthesis", "abstract": "Sequential models achieve state-of-the-art results in audio, visual and\ntextual domains with respect to both estimating the data distribution and\ngenerating high-quality samples. Efficient sampling for this class of models\nhas however remained an elusive problem. With a focus on text-to-speech\nsynthesis, we describe a set of general techniques for reducing sampling time\nwhile maintaining high output quality. We first describe a single-layer\nrecurrent neural network, the WaveRNN, with a dual softmax layer that matches\nthe quality of the state-of-the-art WaveNet model. The compact form of the\nnetwork makes it possible to generate 24kHz 16-bit audio 4x faster than real\ntime on a GPU. Second, we apply a weight pruning technique to reduce the number\nof weights in the WaveRNN. We find that, for a constant number of parameters,\nlarge sparse networks perform better than small dense networks and this\nrelationship holds for sparsity levels beyond 96%. The small number of weights\nin a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobile\nCPU in real time. Finally, we propose a new generation scheme based on\nsubscaling that folds a long sequence into a batch of shorter sequences and\nallows one to generate multiple samples at once. The Subscale WaveRNN produces\n16 samples per step without loss of quality and offers an orthogonal method for\nincreasing sampling efficiency.", "published": "2018-02-23 08:20:23", "link": "http://arxiv.org/abs/1802.08435v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
