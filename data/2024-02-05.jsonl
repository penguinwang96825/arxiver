{"title": "VlogQA: Task, Dataset, and Baseline Models for Vietnamese Spoken-Based\n  Machine Reading Comprehension", "abstract": "This paper presents the development process of a Vietnamese spoken language\ncorpus for machine reading comprehension (MRC) tasks and provides insights into\nthe challenges and opportunities associated with using real-world data for\nmachine reading comprehension tasks. The existing MRC corpora in Vietnamese\nmainly focus on formal written documents such as Wikipedia articles, online\nnewspapers, or textbooks. In contrast, the VlogQA consists of 10,076\nquestion-answer pairs based on 1,230 transcript documents sourced from YouTube\n-- an extensive source of user-uploaded content, covering the topics of food\nand travel. By capturing the spoken language of native Vietnamese speakers in\nnatural settings, an obscure corner overlooked in Vietnamese research, the\ncorpus provides a valuable resource for future research in reading\ncomprehension tasks for the Vietnamese language. Regarding performance\nevaluation, our deep-learning models achieved the highest F1 score of 75.34% on\nthe test set, indicating significant progress in machine reading comprehension\nfor Vietnamese spoken language data. In terms of EM, the highest score we\naccomplished is 53.97%, which reflects the challenge in processing spoken-based\ncontent and highlights the need for further improvement.", "published": "2024-02-05 00:54:40", "link": "http://arxiv.org/abs/2402.02655v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Partial to Strictly Incremental Constituent Parsing", "abstract": "We study incremental constituent parsers to assess their capacity to output\ntrees based on prefix representations alone. Guided by strictly left-to-right\ngenerative language models and tree-decoding modules, we build parsers that\nadhere to a strong definition of incrementality across languages. This builds\nupon work that asserted incrementality, but that mostly only enforced it on\neither the encoder or the decoder. Finally, we conduct an analysis against\nnon-incremental and partially incremental models.", "published": "2024-02-05 07:33:25", "link": "http://arxiv.org/abs/2402.02782v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "With a Little Help from my (Linguistic) Friends: Topic Segmentation of\n  Multi-party Casual Conversations", "abstract": "Topics play an important role in the global organisation of a conversation as\nwhat is currently discussed constrains the possible contributions of the\nparticipant. Understanding the way topics are organised in interaction would\nprovide insight on the structure of dialogue beyond the sequence of utterances.\nHowever, studying this high-level structure is a complex task that we try to\napproach by first segmenting dialogues into smaller topically coherent sets of\nutterances. Understanding the interactions between these segments would then\nenable us to propose a model of topic organisation at a dialogue level. In this\npaper we work with open-domain conversations and try to reach a comparable\nlevel of accuracy as recent machine learning based topic segmentation models\nbut with a formal approach. The features we identify as meaningful for this\ntask help us understand better the topical structure of a conversation.", "published": "2024-02-05 09:48:07", "link": "http://arxiv.org/abs/2402.02837v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Computational Model for the Assessment of Mutual Intelligibility Among\n  Closely Related Languages", "abstract": "Closely related languages show linguistic similarities that allow speakers of\none language to understand speakers of another language without having actively\nlearned it. Mutual intelligibility varies in degree and is typically tested in\npsycholinguistic experiments. To study mutual intelligibility computationally,\nwe propose a computer-assisted method using the Linear Discriminative Learner,\na computational model developed to approximate the cognitive processes by which\nhumans learn languages, which we expand with multilingual semantic vectors and\nmultilingual sound classes. We test the model on cognate data from German,\nDutch, and English, three closely related Germanic languages. We find that our\nmodel's comprehension accuracy depends on 1) the automatic trimming of\ninflections and 2) the language pair for which comprehension is tested. Our\nmultilingual modelling approach does not only offer new methodological findings\nfor automatic testing of mutual intelligibility across languages but also\nextends the use of Linear Discriminative Learning to multilingual settings.", "published": "2024-02-05 11:32:13", "link": "http://arxiv.org/abs/2402.02915v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Putting Context in Context: the Impact of Discussion Structure on Text\n  Classification", "abstract": "Current text classification approaches usually focus on the content to be\nclassified. Contextual aspects (both linguistic and extra-linguistic) are\nusually neglected, even in tasks based on online discussions. Still in many\ncases the multi-party and multi-turn nature of the context from which these\nelements are selected can be fruitfully exploited. In this work, we propose a\nseries of experiments on a large dataset for stance detection in English, in\nwhich we evaluate the contribution of different types of contextual\ninformation, i.e. linguistic, structural and temporal, by feeding them as\nnatural language input into a transformer-based model. We also experiment with\ndifferent amounts of training data and analyse the topology of local discussion\nnetworks in a privacy-compliant way. Results show that structural information\ncan be highly beneficial to text classification but only under certain\ncircumstances (e.g. depending on the amount of training data and on discussion\nchain complexity). Indeed, we show that contextual information on smaller\ndatasets from other classification tasks does not yield significant\nimprovements. Our framework, based on local discussion networks, allows the\nintegration of structural information, while minimising user profiling, thus\npreserving their privacy.", "published": "2024-02-05 12:56:22", "link": "http://arxiv.org/abs/2402.02975v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"Define Your Terms\" : Enhancing Efficient Offensive Speech\n  Classification with Definition", "abstract": "The propagation of offensive content through social media channels has\ngarnered attention of the research community. Multiple works have proposed\nvarious semantically related yet subtle distinct categories of offensive\nspeech. In this work, we explore meta-earning approaches to leverage the\ndiversity of offensive speech corpora to enhance their reliable and efficient\ndetection. We propose a joint embedding architecture that incorporates the\ninput's label and definition for classification via Prototypical Network. Our\nmodel achieves at least 75% of the maximal F1-score while using less than 10%\nof the available training data across 4 datasets. Our experimental findings\nalso provide a case study of training strategies valuable to combat resource\nscarcity.", "published": "2024-02-05 17:33:22", "link": "http://arxiv.org/abs/2402.03221v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "English Prompts are Better for NLI-based Zero-Shot Emotion\n  Classification than Target-Language Prompts", "abstract": "Emotion classification in text is a challenging task due to the processes\ninvolved when interpreting a textual description of a potential emotion\nstimulus. In addition, the set of emotion categories is highly domain-specific.\nFor instance, literature analysis might require the use of aesthetic emotions\n(e.g., finding something beautiful), and social media analysis could benefit\nfrom fine-grained sets (e.g., separating anger from annoyance) than only those\nthat represent basic categories as they have been proposed by Paul Ekman\n(anger, disgust, fear, joy, surprise, sadness). This renders the task an\ninteresting field for zero-shot classifications, in which the label set is not\nknown at model development time. Unfortunately, most resources for emotion\nanalysis are English, and therefore, most studies on emotion analysis have been\nperformed in English, including those that involve prompting language models\nfor text labels. This leaves us with a research gap that we address in this\npaper: In which language should we prompt for emotion labels on non-English\ntexts? This is particularly of interest when we have access to a multilingual\nlarge language model, because we could request labels with English prompts even\nfor non-English data. Our experiments with natural language inference-based\nlanguage models show that it is consistently better to use English prompts even\nif the data is in a different language.", "published": "2024-02-05 17:36:19", "link": "http://arxiv.org/abs/2402.03223v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JOBSKAPE: A Framework for Generating Synthetic Job Postings to Enhance\n  Skill Matching", "abstract": "Recent approaches in skill matching, employing synthetic training data for\nclassification or similarity model training, have shown promising results,\nreducing the need for time-consuming and expensive annotations. However,\nprevious synthetic datasets have limitations, such as featuring only one skill\nper sentence and generally comprising short sentences. In this paper, we\nintroduce JobSkape, a framework to generate synthetic data that tackles these\nlimitations, specifically designed to enhance skill-to-taxonomy matching.\nWithin this framework, we create SkillSkape, a comprehensive open-source\nsynthetic dataset of job postings tailored for skill-matching tasks. We\nintroduce several offline metrics that show that our dataset resembles\nreal-world data. Additionally, we present a multi-step pipeline for skill\nextraction and matching tasks using large language models (LLMs), benchmarking\nagainst known supervised methodologies. We outline that the downstream\nevaluation results on real-world data can beat baselines, underscoring its\nefficacy and adaptability.", "published": "2024-02-05 17:57:26", "link": "http://arxiv.org/abs/2402.03242v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Arabic Synonym BERT-based Adversarial Examples for Text Classification", "abstract": "Text classification systems have been proven vulnerable to adversarial text\nexamples, modified versions of the original text examples that are often\nunnoticed by human eyes, yet can force text classification models to alter\ntheir classification. Often, research works quantifying the impact of\nadversarial text attacks have been applied only to models trained in English.\nIn this paper, we introduce the first word-level study of adversarial attacks\nin Arabic. Specifically, we use a synonym (word-level) attack using a Masked\nLanguage Modeling (MLM) task with a BERT model in a black-box setting to assess\nthe robustness of the state-of-the-art text classification models to\nadversarial attacks in Arabic. To evaluate the grammatical and semantic\nsimilarities of the newly produced adversarial examples using our synonym\nBERT-based attack, we invite four human evaluators to assess and compare the\nproduced adversarial examples with their original examples. We also study the\ntransferability of these newly produced Arabic adversarial examples to various\nmodels and investigate the effectiveness of defense mechanisms against these\nadversarial examples on the BERT models. We find that fine-tuned BERT models\nwere more susceptible to our synonym attacks than the other Deep Neural\nNetworks (DNN) models like WordCNN and WordLSTM we trained. We also find that\nfine-tuned BERT models were more susceptible to transferred attacks. We,\nlastly, find that fine-tuned BERT models successfully regain at least 2% in\naccuracy after applying adversarial training as an initial defense mechanism.", "published": "2024-02-05 19:39:07", "link": "http://arxiv.org/abs/2402.03477v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Best Practices for Text Annotation with Large Language Models", "abstract": "Large Language Models (LLMs) have ushered in a new era of text annotation, as\ntheir ease-of-use, high accuracy, and relatively low costs have meant that\ntheir use has exploded in recent months. However, the rapid growth of the field\nhas meant that LLM-based annotation has become something of an academic Wild\nWest: the lack of established practices and standards has led to concerns about\nthe quality and validity of research. Researchers have warned that the\nostensible simplicity of LLMs can be misleading, as they are prone to bias,\nmisunderstandings, and unreliable results. Recognizing the transformative\npotential of LLMs, this paper proposes a comprehensive set of standards and\nbest practices for their reliable, reproducible, and ethical use. These\nguidelines span critical areas such as model selection, prompt engineering,\nstructured prompting, prompt stability analysis, rigorous model validation, and\nthe consideration of ethical and legal implications. The paper emphasizes the\nneed for a structured, directed, and formalized approach to using LLMs, aiming\nto ensure the integrity and robustness of text annotation practices, and\nadvocates for a nuanced and critical engagement with LLMs in social scientific\nresearch.", "published": "2024-02-05 15:43:50", "link": "http://arxiv.org/abs/2402.05129v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Financial Report Chunking for Effective Retrieval Augmented Generation", "abstract": "Chunking information is a key step in Retrieval Augmented Generation (RAG).\nCurrent research primarily centers on paragraph-level chunking. This approach\ntreats all texts as equal and neglects the information contained in the\nstructure of documents. We propose an expanded approach to chunk documents by\nmoving beyond mere paragraph-level chunking to chunk primary by structural\nelement components of documents. Dissecting documents into these constituent\nelements creates a new way to chunk documents that yields the best chunk size\nwithout tuning. We introduce a novel framework that evaluates how chunking\nbased on element types annotated by document understanding models contributes\nto the overall context and accuracy of the information retrieved. We also\ndemonstrate how this approach impacts RAG assisted Question & Answer task\nperformance. Our research includes a comprehensive analysis of various element\ntypes, their role in effective information retrieval, and the impact they have\non the quality of RAG outputs. Findings support that element type based\nchunking largely improve RAG results on financial reporting. Through this\nresearch, we are also able to answer how to uncover highly accurate RAG.", "published": "2024-02-05 22:35:42", "link": "http://arxiv.org/abs/2402.05131v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recursive Chain-of-Feedback Prevents Performance Degradation from\n  Redundant Prompting", "abstract": "Large Language Models (LLMs) frequently struggle with complex reasoning\ntasks, failing to construct logically sound steps towards the solution. In\nresponse to this behavior, users often try prompting the LLMs repeatedly in\nhopes of reaching a better response. This paper studies such repetitive\nbehavior and its effect by defining a novel setting, Chain-of-Feedback (CoF).\nThe setting takes questions that require multi-step reasoning as an input. Upon\nresponse, we repetitively prompt meaningless feedback (e.g. 'make another\nattempt') requesting additional trials. Surprisingly, our preliminary results\nshow that repeated meaningless feedback gradually decreases the quality of the\nresponses, eventually leading to a larger deviation from the intended outcome.\nTo alleviate these troubles, we propose a novel method, Recursive\nChain-of-Feedback (R-CoF). Following the logic of recursion in computer\nscience, R-CoF recursively revises the initially incorrect response by breaking\ndown each incorrect reasoning step into smaller individual problems. Our\npreliminary results show that majority of questions that LLMs fail to respond\ncorrectly can be answered using R-CoF without any sample data outlining the\nlogical process.", "published": "2024-02-05 00:44:28", "link": "http://arxiv.org/abs/2402.02648v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RACER: An LLM-powered Methodology for Scalable Analysis of\n  Semi-structured Mental Health Interviews", "abstract": "Semi-structured interviews (SSIs) are a commonly employed data-collection\nmethod in healthcare research, offering in-depth qualitative insights into\nsubject experiences. Despite their value, the manual analysis of SSIs is\nnotoriously time-consuming and labor-intensive, in part due to the difficulty\nof extracting and categorizing emotional responses, and challenges in scaling\nhuman evaluation for large populations. In this study, we develop RACER, a\nLarge Language Model (LLM) based expert-guided automated pipeline that\nefficiently converts raw interview transcripts into insightful domain-relevant\nthemes and sub-themes. We used RACER to analyze SSIs conducted with 93\nhealthcare professionals and trainees to assess the broad personal and\nprofessional mental health impacts of the COVID-19 crisis. RACER achieves\nmoderately high agreement with two human evaluators (72%), which approaches the\nhuman inter-rater agreement (77%). Interestingly, LLMs and humans struggle with\nsimilar content involving nuanced emotional, ambivalent/dialectical, and\npsychological statements. Our study highlights the opportunities and challenges\nin using LLMs to improve research efficiency and opens new avenues for scalable\nanalysis of SSIs in healthcare research.", "published": "2024-02-05 00:56:30", "link": "http://arxiv.org/abs/2402.02656v1", "categories": ["cs.CL", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Shortened LLaMA: Depth Pruning for Large Language Models with Comparison\n  of Retraining Methods", "abstract": "Structured pruning of modern large language models (LLMs) has emerged as a\nway of decreasing their high computational needs. Width pruning reduces the\nsize of projection weight matrices (e.g., by removing attention heads) while\nmaintaining the number of layers. Depth pruning, in contrast, removes entire\nlayers or blocks, while keeping the size of the remaining weights unchanged.\nMost current research focuses on either width-only or a blend of width and\ndepth pruning, with little comparative analysis between the two units (width\nvs. depth) concerning their impact on LLM inference efficiency. In this work,\nwe show that simple depth pruning can effectively compress LLMs while achieving\ncomparable or superior performance to recent width pruning studies. Our pruning\nmethod boosts inference speeds, especially under memory-constrained conditions\nthat require limited batch sizes for running LLMs, where width pruning is\nineffective. In retraining pruned models for quality recovery, continued\npretraining on a large corpus markedly outperforms LoRA-based tuning,\nparticularly at severe pruning ratios. We hope this work can help build compact\nyet capable LLMs. Code and models can be found at:\nhttps://github.com/Nota-NetsPresso/shortened-llm", "published": "2024-02-05 09:44:49", "link": "http://arxiv.org/abs/2402.02834v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EEVEE: An Easy Annotation Tool for Natural Language Processing", "abstract": "Annotation tools are the starting point for creating Natural Language\nProcessing (NLP) datasets. There is a wide variety of tools available; setting\nup these tools is however a hindrance. We propose EEVEE, an annotation tool\nfocused on simplicity, efficiency, and ease of use. It can run directly in the\nbrowser (no setup required) and uses tab-separated files (as opposed to\ncharacter offsets or task-specific formats) for annotation. It allows for\nannotation of multiple tasks on a single dataset and supports four task-types:\nsequence labeling, span labeling, text classification and seq2seq.", "published": "2024-02-05 10:24:40", "link": "http://arxiv.org/abs/2402.02864v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "How do Large Language Models Learn In-Context? Query and Key Matrices of\n  In-Context Heads are Two Towers for Metric Learning", "abstract": "We investigate the mechanism of in-context learning (ICL) on sentence\nclassification tasks with semantically-unrelated labels (\"foo\"/\"bar\"). We find\nintervening in only 1\\% heads (named \"in-context heads\") significantly affects\nICL accuracy from 87.6\\% to 24.4\\%. To understand this phenomenon, we analyze\nthe value-output vectors in these heads and discover that the vectors at each\nlabel position contain substantial information about the corresponding labels.\nFurthermore, we observe that the prediction shift from \"foo\" to \"bar\" is due to\nthe respective reduction and increase in these heads' attention scores at \"foo\"\nand \"bar\" positions. Therefore, we propose a hypothesis for ICL: in in-context\nheads, the value-output matrices extract label features, while the query-key\nmatrices compute the similarity between the features at the last position and\nthose at each label position. The query and key matrices can be considered as\ntwo towers that learn the similarity metric between the last position's\nfeatures and each demonstration at label positions. Using this hypothesis, we\nexplain the majority label bias and recency bias in ICL and propose two methods\nto reduce these biases by 22\\% and 17\\%, respectively.", "published": "2024-02-05 10:39:32", "link": "http://arxiv.org/abs/2402.02872v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Approximate Attributions for Off-the-Shelf Siamese Transformers", "abstract": "Siamese encoders such as sentence transformers are among the least understood\ndeep models. Established attribution methods cannot tackle this model class\nsince it compares two inputs rather than processing a single one. To address\nthis gap, we have recently proposed an attribution method specifically for\nSiamese encoders (M\\\"oller et al., 2023). However, it requires models to be\nadjusted and fine-tuned and therefore cannot be directly applied to\noff-the-shelf models. In this work, we reassess these restrictions and propose\n(i) a model with exact attribution ability that retains the original model's\npredictive performance and (ii) a way to compute approximate attributions for\noff-the-shelf models. We extensively compare approximate and exact attributions\nand use them to analyze the models' attendance to different linguistic aspects.\nWe gain insights into which syntactic roles Siamese transformers attend to,\nconfirm that they mostly ignore negation, explore how they judge semantically\nopposite adjectives, and find that they exhibit lexical bias.", "published": "2024-02-05 10:49:05", "link": "http://arxiv.org/abs/2402.02883v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UniMem: Towards a Unified View of Long-Context Large Language Models", "abstract": "Long-context processing is a critical ability that constrains the\napplicability of large language models (LLMs). Although there exist various\nmethods devoted to enhancing the long-context processing ability of LLMs, they\nare developed in an isolated manner and lack systematic analysis and\nintegration of their strengths, hindering further developments. In this paper,\nwe introduce UniMem, a Unified framework that reformulates existing\nlong-context methods from the view of Memory augmentation of LLMs.\nDistinguished by its four core dimensions-Memory Management, Memory Writing,\nMemory Reading, and Memory Injection, UniMem empowers researchers to conduct\nsystematic exploration of long-context methods. We re-formulate 16 existing\nmethods based on UniMem and analyze four representative methods:\nTransformer-XL, Memorizing Transformer, RMT, and Longformer into equivalent\nUniMem forms to reveal their design principles and strengths. Based on these\nanalyses, we propose UniMix, an innovative approach that integrates the\nstrengths of these algorithms. Experimental results show that UniMix achieves\nsuperior performance in handling long contexts with significantly lower\nperplexity than baselines.", "published": "2024-02-05 13:47:53", "link": "http://arxiv.org/abs/2402.03009v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SIDU-TXT: An XAI Algorithm for NLP with a Holistic Assessment Approach", "abstract": "Explainable AI (XAI) aids in deciphering 'black-box' models. While several\nmethods have been proposed and evaluated primarily in the image domain, the\nexploration of explainability in the text domain remains a growing research\narea. In this paper, we delve into the applicability of XAI methods for the\ntext domain. In this context, the 'Similarity Difference and Uniqueness' (SIDU)\nXAI method, recognized for its superior capability in localizing entire salient\nregions in image-based classification is extended to textual data. The extended\nmethod, SIDU-TXT, utilizes feature activation maps from 'black-box' models to\ngenerate heatmaps at a granular, word-based level, thereby providing\nexplanations that highlight contextually significant textual elements crucial\nfor model predictions. Given the absence of a unified standard for assessing\nXAI methods, this study applies a holistic three-tiered comprehensive\nevaluation framework: Functionally-Grounded, Human-Grounded and\nApplication-Grounded, to assess the effectiveness of the proposed SIDU-TXT\nacross various experiments. We find that, in sentiment analysis task of a movie\nreview dataset, SIDU-TXT excels in both functionally and human-grounded\nevaluations, demonstrating superior performance through quantitative and\nqualitative analyses compared to benchmarks like Grad-CAM and LIME. In the\napplication-grounded evaluation within the sensitive and complex legal domain\nof asylum decision-making, SIDU-TXT and Grad-CAM demonstrate comparable\nperformances, each with its own set of strengths and weaknesses. However, both\nmethods fall short of entirely fulfilling the sophisticated criteria of expert\nexpectations, highlighting the imperative need for additional research in XAI\nmethods suitable for such domains.", "published": "2024-02-05 14:29:54", "link": "http://arxiv.org/abs/2402.03043v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Lingual Malaysian Embedding: Leveraging Large Language Models for\n  Semantic Representations", "abstract": "In this work, we present a comprehensive exploration of finetuning Malaysian\nlanguage models, specifically Llama2 and Mistral, on embedding tasks involving\nnegative and positive pairs. We release two distinct models tailored for\nSemantic Similarity and Retrieval-Augmented Generation (RAG).\n  For Semantic Similarity, our 600 million parameter Llama2 model outperforms\nOpenAI text-embedding-ada-002 across all recall@k metrics for b.cari.com.my,\nc.cari.com.my, Malay news, and Malaysian Twitter test sets.\n  In the realm of RAG models, our approach proves competitive with OpenAI\ntext-embedding-ada-002 in the Malaysian context. Notably, our 2 billion\nparameter Llama2 model achieves superior Recall@5, Recall@10 for the \"Melayu\"\nkeyword research papers dataset and excels in Recall@3, Recall@5, and Recall@10\nfor the lom.agc.gov.my dataset.\n  These findings underscore the effectiveness of our finetuning strategy and\nhighlight the performance gains in both Semantic Similarity and RAG tasks.\n  All models released at\nhttps://huggingface.co/collections/mesolitica/malaysian-embedding-6523612bfe5881ad35f81b99", "published": "2024-02-05 14:36:51", "link": "http://arxiv.org/abs/2402.03053v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual transformer and BERTopic for short text topic modeling: The\n  case of Serbian", "abstract": "This paper presents the results of the first application of BERTopic, a\nstate-of-the-art topic modeling technique, to short text written in a\nmorphologi-cally rich language. We applied BERTopic with three multilingual\nembed-ding models on two levels of text preprocessing (partial and full) to\nevalu-ate its performance on partially preprocessed short text in Serbian. We\nalso compared it to LDA and NMF on fully preprocessed text. The experiments\nwere conducted on a dataset of tweets expressing hesitancy toward COVID-19\nvaccination. Our results show that with adequate parameter setting, BERTopic\ncan yield informative topics even when applied to partially pre-processed short\ntext. When the same parameters are applied in both prepro-cessing scenarios,\nthe performance drop on partially preprocessed text is minimal. Compared to LDA\nand NMF, judging by the keywords, BERTopic offers more informative topics and\ngives novel insights when the number of topics is not limited. The findings of\nthis paper can be significant for re-searchers working with other\nmorphologically rich low-resource languages and short text.", "published": "2024-02-05 14:59:29", "link": "http://arxiv.org/abs/2402.03067v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Constrained Decoding for Cross-lingual Label Projection", "abstract": "Zero-shot cross-lingual transfer utilizing multilingual LLMs has become a\npopular learning paradigm for low-resource languages with no labeled training\ndata. However, for NLP tasks that involve fine-grained predictions on words and\nphrases, the performance of zero-shot cross-lingual transfer learning lags far\nbehind supervised fine-tuning methods. Therefore, it is common to exploit\ntranslation and label projection to further improve the performance by (1)\ntranslating training data that is available in a high-resource language (e.g.,\nEnglish) together with the gold labels into low-resource languages, and/or (2)\ntranslating test data in low-resource languages to a high-source language to\nrun inference on, then projecting the predicted span-level labels back onto the\noriginal test data. However, state-of-the-art marker-based label projection\nmethods suffer from translation quality degradation due to the extra label\nmarkers injected in the input to the translation model. In this work, we\nexplore a new direction that leverages constrained decoding for label\nprojection to overcome the aforementioned issues. Our new method not only can\npreserve the quality of translated texts but also has the versatility of being\napplicable to both translating training and translating test data strategies.\nThis versatility is crucial as our experiments reveal that translating test\ndata can lead to a considerable boost in performance compared to translating\nonly training data. We evaluate on two cross-lingual transfer tasks, namely\nNamed Entity Recognition and Event Argument Extraction, spanning 20 languages.\nThe results demonstrate that our approach outperforms the state-of-the-art\nmarker-based method by a large margin and also shows better performance than\nother label projection methods that rely on external word alignment.", "published": "2024-02-05 15:57:32", "link": "http://arxiv.org/abs/2402.03131v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sociolinguistically Informed Interpretability: A Case Study on Hinglish\n  Emotion Classification", "abstract": "Emotion classification is a challenging task in NLP due to the inherent\nidiosyncratic and subjective nature of linguistic expression, especially with\ncode-mixed data. Pre-trained language models (PLMs) have achieved high\nperformance for many tasks and languages, but it remains to be seen whether\nthese models learn and are robust to the differences in emotional expression\nacross languages. Sociolinguistic studies have shown that Hinglish speakers\nswitch to Hindi when expressing negative emotions and to English when\nexpressing positive emotions. To understand if language models can learn these\nassociations, we study the effect of language on emotion prediction across 3\nPLMs on a Hinglish emotion classification dataset. Using LIME and token level\nlanguage ID, we find that models do learn these associations between language\nchoice and emotional expression. Moreover, having code-mixed data present in\nthe pre-training can augment that learning when task-specific data is scarce.\nWe also conclude from the misclassifications that the models may overgeneralise\nthis heuristic to other infrequent examples where this sociolinguistic\nphenomenon does not apply.", "published": "2024-02-05 16:05:32", "link": "http://arxiv.org/abs/2402.03137v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for\n  Large Language Models", "abstract": "Neural network pruning has become increasingly crucial due to the complexity\nof these models and their widespread use in various fields. Existing pruning\nalgorithms often suffer from limitations such as architecture specificity,\nexcessive complexity and reliance on demanding calculations, rendering them\nimpractical for real-world applications. This paper introduces KEN: a\nstraightforward, universal and unstructured pruning algorithm based on Kernel\nDensity Estimation (KDE). KEN aims to construct optimized transformers by\nselectively preserving the most significant parameters while restoring others\nto their pre-training state. This strategy preserves model performance while\nenabling storage of only the optimized subnetwork, leading to substantial\nmemory savings. Extensive evaluations across seven different LLMs demonstrate\nthat KEN achieves equal or better performance than their original unpruned\nversions, with a minimum parameter reduction of 25%. Furthermore, in-depth\ncomparisons with established pruning and PEFT algorithms confirm KEN\neffectiveness. We further introduce KEN$_{viz}$, an explainable tool that\nvisualizes the optimized model composition achieved by KEN from different\npoints of view.", "published": "2024-02-05 16:11:43", "link": "http://arxiv.org/abs/2402.03142v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Video-LaVIT: Unified Video-Language Pre-training with Decoupled\n  Visual-Motional Tokenization", "abstract": "In light of recent advances in multimodal Large Language Models (LLMs), there\nis increasing attention to scaling them from image-text data to more\ninformative real-world videos. Compared to static images, video poses unique\nchallenges for effective large-scale pre-training due to the modeling of its\nspatiotemporal dynamics. In this paper, we address such limitations in\nvideo-language pre-training with an efficient video decomposition that\nrepresents each video as keyframes and temporal motions. These are then adapted\nto an LLM using well-designed tokenizers that discretize visual and temporal\ninformation as a few tokens, thus enabling unified generative pre-training of\nvideos, images, and text. At inference, the generated tokens from the LLM are\ncarefully recovered to the original continuous pixel space to create various\nvideo content. Our proposed framework is both capable of comprehending and\ngenerating image and video content, as demonstrated by its competitive\nperformance across 13 multimodal benchmarks in image and video understanding\nand generation. Our code and models are available at\nhttps://video-lavit.github.io.", "published": "2024-02-05 16:30:49", "link": "http://arxiv.org/abs/2402.03161v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Linguistic features for sentence difficulty prediction in ABSA", "abstract": "One of the challenges of natural language understanding is to deal with the\nsubjectivity of sentences, which may express opinions and emotions that add\nlayers of complexity and nuance. Sentiment analysis is a field that aims to\nextract and analyze these subjective elements from text, and it can be applied\nat different levels of granularity, such as document, paragraph, sentence, or\naspect. Aspect-based sentiment analysis is a well-studied topic with many\navailable data sets and models. However, there is no clear definition of what\nmakes a sentence difficult for aspect-based sentiment analysis. In this paper,\nwe explore this question by conducting an experiment with three data sets:\n\"Laptops\", \"Restaurants\", and \"MTSC\" (Multi-Target-dependent Sentiment\nClassification), and a merged version of these three datasets. We study the\nimpact of domain diversity and syntactic diversity on difficulty. We use a\ncombination of classifiers to identify the most difficult sentences and analyze\ntheir characteristics. We employ two ways of defining sentence difficulty. The\nfirst one is binary and labels a sentence as difficult if the classifiers fail\nto correctly predict the sentiment polarity. The second one is a six-level\nscale based on how many of the top five best-performing classifiers can\ncorrectly predict the sentiment polarity. We also define 9 linguistic features\nthat, combined, aim at estimating the difficulty at sentence level.", "published": "2024-02-05 16:31:03", "link": "http://arxiv.org/abs/2402.03163v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Accurate and Well-Calibrated ICD Code Assignment Through Attention Over\n  Diverse Label Embeddings", "abstract": "Although the International Classification of Diseases (ICD) has been adopted\nworldwide, manually assigning ICD codes to clinical text is time-consuming,\nerror-prone, and expensive, motivating the development of automated approaches.\nThis paper describes a novel approach for automated ICD coding, combining\nseveral ideas from previous related work. We specifically employ a strong\nTransformer-based model as a text encoder and, to handle lengthy clinical\nnarratives, we explored either (a) adapting the base encoder model into a\nLongformer, or (b) dividing the text into chunks and processing each chunk\nindependently. The representations produced by the encoder are combined with a\nlabel embedding mechanism that explores diverse ICD code synonyms. Experiments\nwith different splits of the MIMIC-III dataset show that the proposed approach\noutperforms the current state-of-the-art models in ICD coding, with the label\nembeddings significantly contributing to the good performance. Our approach\nalso leads to properly calibrated classification results, which can effectively\ninform downstream tasks such as quantification.", "published": "2024-02-05 16:40:23", "link": "http://arxiv.org/abs/2402.03172v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CIDAR: Culturally Relevant Instruction Dataset For Arabic", "abstract": "Instruction tuning has emerged as a prominent methodology for teaching Large\nLanguage Models (LLMs) to follow instructions. However, current instruction\ndatasets predominantly cater to English or are derived from English-dominated\nLLMs, resulting in inherent biases toward Western culture. This bias\nsignificantly impacts the linguistic structures of non-English languages such\nas Arabic, which has a distinct grammar reflective of the diverse cultures\nacross the Arab region. This paper addresses this limitation by introducing\nCIDAR: https://hf.co/datasets/arbml/CIDAR, the first open Arabic\ninstruction-tuning dataset culturally-aligned by human reviewers. CIDAR\ncontains 10,000 instruction and output pairs that represent the Arab region. We\ndiscuss the cultural relevance of CIDAR via the analysis and comparison to\nother models fine-tuned on other datasets. Our experiments show that CIDAR can\nhelp enrich research efforts in aligning LLMs with the Arabic culture. All the\ncode is available at https://github.com/ARBML/CIDAR.", "published": "2024-02-05 16:44:17", "link": "http://arxiv.org/abs/2402.03177v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Isotropy, Clusters, and Classifiers", "abstract": "Whether embedding spaces use all their dimensions equally, i.e., whether they\nare isotropic, has been a recent subject of discussion. Evidence has been\naccrued both for and against enforcing isotropy in embedding spaces. In the\npresent paper, we stress that isotropy imposes requirements on the embedding\nspace that are not compatible with the presence of clusters -- which also\nnegatively impacts linear classification objectives. We demonstrate this fact\nboth mathematically and empirically and use it to shed light on previous\nresults from the literature.", "published": "2024-02-05 16:57:24", "link": "http://arxiv.org/abs/2402.03191v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Skill Set Optimization: Reinforcing Language Model Behavior via\n  Transferable Skills", "abstract": "Large language models (LLMs) have recently been used for sequential decision\nmaking in interactive environments. However, leveraging environment reward\nsignals for continual LLM actor improvement is not straightforward. We propose\nSkill Set Optimization (SSO) for improving LLM actor performance through\nconstructing and refining sets of transferable skills. SSO constructs skills by\nextracting common subtrajectories with high rewards and generating subgoals and\ninstructions to represent each skill. These skills are provided to the LLM\nactor in-context to reinforce behaviors with high rewards. Then, SSO further\nrefines the skill set by pruning skills that do not continue to result in high\nrewards. We evaluate our method in the classic videogame NetHack and the text\nenvironment ScienceWorld to demonstrate SSO's ability to optimize a set of\nskills and perform in-context policy improvement. SSO outperforms baselines by\n40% in our custom NetHack task and outperforms the previous state-of-the-art in\nScienceWorld by 35%.", "published": "2024-02-05 17:59:00", "link": "http://arxiv.org/abs/2402.03244v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SWAG: Storytelling With Action Guidance", "abstract": "Automated long-form story generation typically employs long-context large\nlanguage models (LLMs) for one-shot creation, which can produce cohesive but\nnot necessarily engaging content. We introduce Storytelling With Action\nGuidance (SWAG), a novel approach to storytelling with LLMs. Our approach\nframes story writing as a search problem through a two-model feedback loop: one\nLLM generates story content, and another auxiliary LLM is used to choose the\nnext best \"action\" to steer the story's future direction. Our results show that\nSWAG can substantially outperform previous end-to-end story generation\ntechniques when evaluated by GPT-4 and through human evaluation. Our SWAG\npipeline using only small open-source models surpasses GPT-3.5-Turbo.", "published": "2024-02-05 19:55:06", "link": "http://arxiv.org/abs/2402.03483v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Harnessing PubMed User Query Logs for Post Hoc Explanations of\n  Recommended Similar Articles", "abstract": "Searching for a related article based on a reference article is an integral\npart of scientific research. PubMed, like many academic search engines, has a\n\"similar articles\" feature that recommends articles relevant to the current\narticle viewed by a user. Explaining recommended items can be of great utility\nto users, particularly in the literature search process. With more than a\nmillion biomedical papers being published each year, explaining the recommended\nsimilar articles would facilitate researchers and clinicians in searching for\nrelated articles. Nonetheless, the majority of current literature\nrecommendation systems lack explanations for their suggestions. We employ a\npost hoc approach to explaining recommendations by identifying relevant tokens\nin the titles of similar articles. Our major contribution is building PubCLogs\nby repurposing 5.6 million pairs of coclicked articles from PubMed's user query\nlogs. Using our PubCLogs dataset, we train the Highlight Similar Article Title\n(HSAT), a transformer-based model designed to select the most relevant parts of\nthe title of a similar article, based on the title and abstract of a seed\narticle. HSAT demonstrates strong performance in our empirical evaluations,\nachieving an F1 score of 91.72 percent on the PubCLogs test set, considerably\noutperforming several baselines including BM25 (70.62), MPNet (67.11), MedCPT\n(62.22), GPT-3.5 (46.00), and GPT-4 (64.89). Additional evaluations on a\nseparate, manually annotated test set further verifies HSAT's performance.\nMoreover, participants of our user study indicate a preference for HSAT, due to\nits superior balance between conciseness and comprehensiveness. Our study\nsuggests that repurposing user query logs of academic search engines can be a\npromising way to train state-of-the-art models for explaining literature\nrecommendation.", "published": "2024-02-05 19:56:27", "link": "http://arxiv.org/abs/2402.03484v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical\n  System for Punctuation Restoration", "abstract": "Punctuation restoration is a crucial step after Automatic Speech Recognition\n(ASR) systems to enhance transcript readability and facilitate subsequent NLP\ntasks. Nevertheless, conventional lexical-based approaches are inadequate for\nsolving the punctuation restoration task in Spanish, where ambiguity can be\noften found between unpunctuated declaratives and questions. In this study, we\npropose a novel hybrid acoustic-lexical punctuation restoration system for\nSpanish transcription, which consolidates acoustic and lexical signals through\na modular process. Our experiment results show that the proposed system can\neffectively improve F1 score of question marks and overall punctuation\nrestoration on both public and internal Spanish conversational datasets.\nAdditionally, benchmark comparison against LLMs (Large Language Model)\nindicates the superiority of our approach in accuracy, reliability and latency.\nFurthermore, we demonstrate that the Word Error Rate (WER) of the ASR module\nalso benefits from our proposed system.", "published": "2024-02-05 21:05:35", "link": "http://arxiv.org/abs/2402.03519v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Clinical Trial Patient Matching with LLMs", "abstract": "Matching patients to clinical trials is a key unsolved challenge in bringing\nnew drugs to market. Today, identifying patients who meet a trial's eligibility\ncriteria is highly manual, taking up to 1 hour per patient. Automated screening\nis challenging, however, as it requires understanding unstructured clinical\ntext. Large language models (LLMs) offer a promising solution. In this work, we\nexplore their application to trial matching. First, we design an LLM-based\nsystem which, given a patient's medical history as unstructured clinical text,\nevaluates whether that patient meets a set of inclusion criteria (also\nspecified as free text). Our zero-shot system achieves state-of-the-art scores\non the n2c2 2018 cohort selection benchmark. Second, we improve the data and\ncost efficiency of our method by identifying a prompting strategy which matches\npatients an order of magnitude faster and more cheaply than the status quo, and\ndevelop a two-stage retrieval pipeline that reduces the number of tokens\nprocessed by up to a third while retaining high performance. Third, we evaluate\nthe interpretability of our system by having clinicians evaluate the natural\nlanguage justifications generated by the LLM for each eligibility decision, and\nshow that it can output coherent explanations for 97% of its correct decisions\nand 75% of its incorrect ones. Our results establish the feasibility of using\nLLMs to accelerate clinical trial operations.", "published": "2024-02-05 00:06:08", "link": "http://arxiv.org/abs/2402.05125v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph Neural Network and NER-Based Text Summarization", "abstract": "With the abundance of data and information in todays time, it is nearly\nimpossible for man, or, even machine, to go through all of the data line by\nline. What one usually does is to try to skim through the lines and retain the\nabsolutely important information, that in a more formal term is called\nsummarization. Text summarization is an important task that aims to compress\nlengthy documents or articles into shorter, coherent representations while\npreserving the core information and meaning. This project introduces an\ninnovative approach to text summarization, leveraging the capabilities of Graph\nNeural Networks (GNNs) and Named Entity Recognition (NER) systems. GNNs, with\ntheir exceptional ability to capture and process the relational data inherent\nin textual information, are adept at understanding the complex structures\nwithin large documents. Meanwhile, NER systems contribute by identifying and\nemphasizing key entities, ensuring that the summarization process maintains a\nfocus on the most critical aspects of the text. By integrating these two\ntechnologies, our method aims to enhances the efficiency of summarization and\nalso tries to ensures a high degree relevance in the condensed content. This\nproject, therefore, offers a promising direction for handling the ever\nincreasing volume of textual data in an information-saturated world.", "published": "2024-02-05 03:00:44", "link": "http://arxiv.org/abs/2402.05126v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing textual textbook question answering with large language models\n  and retrieval augmented generation", "abstract": "Textbook question answering (TQA) is a challenging task in artificial\nintelligence due to the complex nature of context needed to answer complex\nquestions. Although previous research has improved the task, there are still\nsome limitations in textual TQA, including weak reasoning and inability to\ncapture contextual information in the lengthy context. We propose a framework\n(PLRTQA) that incorporates the retrieval augmented generation (RAG) technique\nto handle the out-of-domain scenario where concepts are spread across different\nlessons, and utilize transfer learning to handle the long context and enhance\nreasoning abilities. Our architecture outperforms the baseline, achieving an\naccuracy improvement of 4. 12% in the validation set and 9. 84% in the test set\nfor textual multiple-choice questions. While this paper focuses on solving\nchallenges in the textual TQA, It provides a foundation for future work in\nmultimodal TQA where the visual components are integrated to address more\ncomplex educational scenarios. Code: https://github.com/hessaAlawwad/PLR-TQA", "published": "2024-02-05 11:58:56", "link": "http://arxiv.org/abs/2402.05128v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LB-KBQA: Large-language-model and BERT based Knowledge-Based Question\n  and Answering System", "abstract": "Generative Artificial Intelligence (AI), because of its emergent abilities,\nhas empowered various fields, one typical of which is large language models\n(LLMs). One of the typical application fields of Generative AI is large\nlanguage models (LLMs), and the natural language understanding capability of\nLLM is dramatically improved when compared with conventional AI-based methods.\nThe natural language understanding capability has always been a barrier to the\nintent recognition performance of the Knowledge-Based-Question-and-Answer\n(KBQA) system, which arises from linguistic diversity and the newly appeared\nintent. Conventional AI-based methods for intent recognition can be divided\ninto semantic parsing-based and model-based approaches. However, both of the\nmethods suffer from limited resources in intent recognition. To address this\nissue, we propose a novel KBQA system based on a Large Language Model(LLM) and\nBERT (LB-KBQA). With the help of generative AI, our proposed method could\ndetect newly appeared intent and acquire new knowledge. In experiments on\nfinancial domain question answering, our model has demonstrated superior\neffectiveness.", "published": "2024-02-05 16:47:17", "link": "http://arxiv.org/abs/2402.05130v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DeAL: Decoding-time Alignment for Large Language Models", "abstract": "Large Language Models (LLMs) are nowadays expected to generate content\naligned with human preferences. Current work focuses on alignment at model\ntraining time, through techniques such as Reinforcement Learning with Human\nFeedback (RLHF). However, it is unclear if such methods are an effective choice\nto teach alignment objectives to the model. First, the inability to incorporate\nmultiple, custom rewards and reliance on a model developer's view of universal\nand static principles are key limitations. Second, the residual gaps in model\ntraining and the reliability of such approaches are also questionable (e.g.\nsusceptibility to jail-breaking even after safety training). To address these,\nwe propose DeAL, a framework that allows the user to customize reward functions\nand enables Decoding-time Alignment of LLMs (DeAL). At its core, we view\ndecoding as a heuristic-guided search process and facilitate the use of a wide\nvariety of alignment objectives. Our experiments with programmatic constraints\nsuch as keyword and length constraints (studied widely in the pre-LLM era) and\nabstract objectives such as harmlessness and helpfulness (proposed in the\npost-LLM era) show that we can DeAL with fine-grained trade-offs, improve\nadherence to alignment objectives, and address residual gaps in LLMs. Lastly,\nwhile DeAL can be effectively paired with RLHF and prompting techniques, its\ngenerality makes decoding slower, an optimization we leave for future work.", "published": "2024-02-05 06:12:29", "link": "http://arxiv.org/abs/2402.06147v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on\n  Model-induced Process Supervision", "abstract": "Process supervision, using a trained verifier to evaluate the intermediate\nsteps generated by a reasoner, has demonstrated significant improvements in\nmulti-step problem solving. In this paper, to avoid the expensive effort of\nhuman annotation on the verifier training data, we introduce Model-induced\nProcess Supervision (MiPS), a novel method for automating data curation. MiPS\nannotates an intermediate step by sampling completions of this solution through\nthe reasoning model, and obtaining an accuracy defined as the proportion of\ncorrect completions. Inaccuracies of the reasoner would cause MiPS\nunderestimating the accuracy of intermediate steps, therefore, we suggest and\nempirically show that verification focusing on high predicted scores of the\nverifier shall be preferred over that of low predicted scores, contrary to\nprior observations on human curated data. Our approach significantly improves\nthe performance of PaLM 2 on math and coding tasks (accuracy +0.67% on GSM8K,\n+4.16% on MATH, +0.92% on MBPP compared with an output supervision trained\nverifier). Additionally, our study demonstrates that the verifier exhibits\nstrong generalization ability across different reasoning models.", "published": "2024-02-05 00:57:51", "link": "http://arxiv.org/abs/2402.02658v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Image-Caption Encoding for Improving Zero-Shot Generalization", "abstract": "Recent advances in vision-language models have combined contrastive\napproaches with generative methods to achieve state-of-the-art (SOTA) on\ndownstream inference tasks like zero-shot image classification. However, a\npersistent issue of these models for image classification is their\nout-of-distribution (OOD) generalization capabilities. We first show that when\nan OOD data point is misclassified, the correct class can be typically found in\nthe Top-K predicted classes. In order to steer the model prediction toward the\ncorrect class within the top predicted classes, we propose the Image-Caption\nEncoding (ICE) method, a straightforward approach that directly enforces\nconsistency between the image-conditioned and caption-conditioned predictions\nat evaluation time only. Intuitively, we take advantage of unique properties of\nthe generated captions to guide our local search for the correct class label\nwithin the Top-K predicted classes. We show that our method can be easily\ncombined with other SOTA methods to enhance Top-1 OOD accuracies by 0.5% on\naverage and up to 3% on challenging datasets. Our code:\nhttps://github.com/Chris210634/ice", "published": "2024-02-05 01:14:07", "link": "http://arxiv.org/abs/2402.02662v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Large Language Models are Geographically Biased", "abstract": "Large Language Models (LLMs) inherently carry the biases contained in their\ntraining corpora, which can lead to the perpetuation of societal harm. As the\nimpact of these foundation models grows, understanding and evaluating their\nbiases becomes crucial to achieving fairness and accuracy. We propose to study\nwhat LLMs know about the world we live in through the lens of geography. This\napproach is particularly powerful as there is ground truth for the numerous\naspects of human life that are meaningfully projected onto geographic space\nsuch as culture, race, language, politics, and religion. We show various\nproblematic geographic biases, which we define as systemic errors in geospatial\npredictions. Initially, we demonstrate that LLMs are capable of making accurate\nzero-shot geospatial predictions in the form of ratings that show strong\nmonotonic correlation with ground truth (Spearman's $\\rho$ of up to 0.89). We\nthen show that LLMs exhibit common biases across a range of objective and\nsubjective topics. In particular, LLMs are clearly biased against locations\nwith lower socioeconomic conditions (e.g. most of Africa) on a variety of\nsensitive subjective topics such as attractiveness, morality, and intelligence\n(Spearman's $\\rho$ of up to 0.70). Finally, we introduce a bias score to\nquantify this and find that there is significant variation in the magnitude of\nbias across existing LLMs. Code is available on the project website:\nhttps://rohinmanvi.github.io/GeoLLM", "published": "2024-02-05 02:32:09", "link": "http://arxiv.org/abs/2402.02680v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploiting Class Probabilities for Black-box Sentence-level Attacks", "abstract": "Sentence-level attacks craft adversarial sentences that are synonymous with\ncorrectly-classified sentences but are misclassified by the text classifiers.\nUnder the black-box setting, classifiers are only accessible through their\nfeedback to queried inputs, which is predominately available in the form of\nclass probabilities. Even though utilizing class probabilities results in\nstronger attacks, due to the challenges of using them for sentence-level\nattacks, existing attacks use either no feedback or only the class labels.\nOvercoming the challenges, we develop a novel algorithm that uses class\nprobabilities for black-box sentence-level attacks, investigate the\neffectiveness of using class probabilities on the attack's success, and examine\nthe question if it is worthy or practical to use class probabilities by\nblack-box sentence-level attacks. We conduct extensive evaluations of our\nattack comparing with the baselines across various classifiers and benchmark\ndatasets.", "published": "2024-02-05 03:15:26", "link": "http://arxiv.org/abs/2402.02695v2", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding the planning of LLM agents: A survey", "abstract": "As Large Language Models (LLMs) have shown significant intelligence, the\nprogress to leverage LLMs as planning modules of autonomous agents has\nattracted more attention. This survey provides the first systematic view of\nLLM-based agents planning, covering recent works aiming to improve planning\nability. We provide a taxonomy of existing works on LLM-Agent planning, which\ncan be categorized into Task Decomposition, Plan Selection, External Module,\nReflection and Memory. Comprehensive analyses are conducted for each direction,\nand further challenges for the field of research are discussed.", "published": "2024-02-05 04:25:24", "link": "http://arxiv.org/abs/2402.02716v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache", "abstract": "Efficiently serving large language models (LLMs) requires batching of many\nrequests to reduce the cost per request. Yet, with larger batch sizes and\nlonger context lengths, the key-value (KV) cache, which stores attention keys\nand values to avoid re-computations, significantly increases memory demands and\nbecomes the new bottleneck in speed and memory usage. Additionally, the loading\nof the KV cache causes the computational core to be idle, which limits the\ninference speed. A straightforward and effective solution to reduce KV cache\nsize is quantization, which decreases the total bytes taken by KV cache.\nHowever, there is a lack of in-depth studies that explore the element\ndistribution of KV cache to understand the hardness and limitation of KV cache\nquantization. To fill the gap, we conducted a comprehensive study on the\nelement distribution in KV cache of popular LLMs. Our findings indicate that\nthe key cache should be quantized per-channel, i.e., group elements along the\nchannel dimension and quantize them together. In contrast, the value cache\nshould be quantized per-token. From this analysis, we developed a tuning-free\n2bit KV cache quantization algorithm named KIVI. With hardware-friendly\nimplementation, KIVI can enable Llama, Falcon, and Mistral models to maintain\nalmost the same quality while using $\\mathbf{2.6\\times}$ less peak memory\n(including model weight). This reduction in memory usage enables up to\n$\\mathbf{4\\times}$ larger batch size, bringing $\\mathbf{2.35\\times \\sim\n3.47\\times}$ throughput on real LLM inference workload. The source code is\navailable at https://github.com/jy-yuan/KIVI.", "published": "2024-02-05 06:06:47", "link": "http://arxiv.org/abs/2402.02750v2", "categories": ["cs.CL", "cs.LG", "cs.PF"], "primary_category": "cs.CL"}
{"title": "List-aware Reranking-Truncation Joint Model for Search and\n  Retrieval-augmented Generation", "abstract": "The results of information retrieval (IR) are usually presented in the form\nof a ranked list of candidate documents, such as web search for humans and\nretrieval-augmented generation for large language models (LLMs). List-aware\nretrieval aims to capture the list-level contextual features to return a better\nlist, mainly including reranking and truncation. Reranking finely re-scores the\ndocuments in the list. Truncation dynamically determines the cut-off point of\nthe ranked list to achieve the trade-off between overall relevance and avoiding\nmisinformation from irrelevant documents. Previous studies treat them as two\nseparate tasks and model them separately. However, the separation is not\noptimal. First, it is hard to share the contextual information of the ranking\nlist between the two tasks. Second, the separate pipeline usually meets the\nerror accumulation problem, where the small error from the reranking stage can\nlargely affect the truncation stage. To solve these problems, we propose a\nReranking-Truncation joint model (GenRT) that can perform the two tasks\nconcurrently. GenRT integrates reranking and truncation via generative paradigm\nbased on encoder-decoder architecture. We also design the novel loss functions\nfor joint optimization to make the model learn both tasks. Sharing parameters\nby the joint model is conducive to making full use of the common modeling\ninformation of the two tasks. Besides, the two tasks are performed concurrently\nand co-optimized to solve the error accumulation problem between separate\nstages. Experiments on public learning-to-rank benchmarks and open-domain Q\\&A\ntasks show that our method achieves SOTA performance on both reranking and\ntruncation tasks for web search and retrieval-augmented LLMs.", "published": "2024-02-05 06:52:53", "link": "http://arxiv.org/abs/2402.02764v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "PanGu-$\u03c0$ Pro:Rethinking Optimization and Architecture for Tiny\n  Language Models", "abstract": "The power of large language models (LLMs) has been demonstrated through\nnumerous data and computing resources. However, the application of language\nmodels on mobile devices is facing huge challenge on the computation and memory\ncosts, that is, tiny language models with high performance are urgently\nrequired. Limited by the highly complex training process, there are many\ndetails for optimizing language models that are seldom studied carefully. In\nthis study, based on a tiny language model with 1B parameters, we carefully\ndesign a series of empirical study to analyze the effect of each component.\nThree perspectives are mainly discussed, \\ie, neural architecture, parameter\ninitialization, and optimization strategy. Several design formulas are\nempirically proved especially effective for tiny language models, including\ntokenizer compression, architecture tweaking, parameter inheritance and\nmultiple-round training. Then we train PanGu-$\\pi$-1B Pro and PanGu-$\\pi$-1.5B\nPro on 1.6T multilingual corpora, following the established formulas.\nExperimental results demonstrate the improved optimization and architecture\nyield a notable average improvement of 8.87 on benchmark evaluation sets for\nPanGu-$\\pi$-1B Pro. Besides, PanGu-$\\pi$-1.5B Pro surpasses a range of SOTA\nmodels with larger model sizes, validating its superior performance. The code\nis available at https://github.com/YuchuanTian/RethinkTinyLM.", "published": "2024-02-05 07:59:38", "link": "http://arxiv.org/abs/2402.02791v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "KS-Lottery: Finding Certified Lottery Tickets for Multilingual Language\n  Models", "abstract": "The lottery ticket hypothesis posits the existence of ``winning tickets''\nwithin a randomly initialized neural network. Do winning tickets exist for LLMs\nin fine-tuning scenarios? How can we find such winning tickets? In this paper,\nwe propose KS-Lottery, a method to identify a small subset of LLM parameters\nhighly effective in multilingual fine-tuning. Our key idea is to use\nKolmogorov-Smirnov Test to analyze the distribution shift of parameters before\nand after fine-tuning. We further theoretically prove that KS-Lottery can find\nthe certified winning tickets in the embedding layer, fine-tuning on the found\nparameters is guaranteed to perform as well as full fine-tuning. Comparing\nKS-Lottery with other parameter-efficient tuning algorithms on translation\ntasks, the experimental results show that KS-Lottery finds a much smaller set\nof parameters for fine-tuning while achieving the comparable performance as\nfull fine-tuning LLM. Surprisingly, we find that fine-tuning 18 tokens'\nembedding of LLaMA suffices to reach the fine-tuning translation\nperformance~\\footnote{https://github.com/CONE-MT/KS-Lottery.}.", "published": "2024-02-05 08:19:56", "link": "http://arxiv.org/abs/2402.02801v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Graph-enhanced Large Language Models in Asynchronous Plan Reasoning", "abstract": "Planning is a fundamental property of human intelligence. Reasoning about\nasynchronous plans is challenging since it requires sequential and parallel\nplanning to optimize time costs. Can large language models (LLMs) succeed at\nthis task? Here, we present the first large-scale study investigating this\nquestion. We find that a representative set of closed and open-source LLMs,\nincluding GPT-4 and LLaMA-2, behave poorly when not supplied with illustrations\nabout the task-solving process in our benchmark AsyncHow. We propose a novel\ntechnique called Plan Like a Graph (PLaG) that combines graphs with natural\nlanguage prompts and achieves state-of-the-art results. We show that although\nPLaG can boost model performance, LLMs still suffer from drastic degradation\nwhen task complexity increases, highlighting the limits of utilizing LLMs for\nsimulating digital devices. We see our study as an exciting step towards using\nLLMs as efficient autonomous agents. Our code and data are available at\nhttps://github.com/fangru-lin/graph-llm-asynchow-plan.", "published": "2024-02-05 08:26:33", "link": "http://arxiv.org/abs/2402.02805v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Are Sounds Sound for Phylogenetic Reconstruction?", "abstract": "In traditional studies on language evolution, scholars often emphasize the\nimportance of sound laws and sound correspondences for phylogenetic inference\nof language family trees. However, to date, computational approaches have\ntypically not taken this potential into account. Most computational studies\nstill rely on lexical cognates as major data source for phylogenetic\nreconstruction in linguistics, although there do exist a few studies in which\nauthors praise the benefits of comparing words at the level of sound sequences.\nBuilding on (a) ten diverse datasets from different language families, and (b)\nstate-of-the-art methods for automated cognate and sound correspondence\ndetection, we test, for the first time, the performance of sound-based versus\ncognate-based approaches to phylogenetic reconstruction. Our results show that\nphylogenies reconstructed from lexical cognates are topologically closer, by\napproximately one third with respect to the generalized quartet distance on\naverage, to the gold standard phylogenies than phylogenies reconstructed from\nsound correspondences.", "published": "2024-02-05 08:35:33", "link": "http://arxiv.org/abs/2402.02807v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Evading Data Contamination Detection for Language Models is (too) Easy", "abstract": "Large language models are widespread, with their performance on benchmarks\nfrequently guiding user preferences for one model over another. However, the\nvast amount of data these models are trained on can inadvertently lead to\ncontamination with public benchmarks, thus compromising performance\nmeasurements. While recently developed contamination detection methods try to\naddress this issue, they overlook the possibility of deliberate contamination\nby malicious model providers aiming to evade detection. We argue that this\nsetting is of crucial importance as it casts doubt on the reliability of public\nbenchmarks. To more rigorously study this issue, we propose a categorization of\nboth model providers and contamination detection methods. This reveals\nvulnerabilities in existing methods that we exploit with EAL, a simple yet\neffective contamination technique that significantly inflates benchmark\nperformance while completely evading current detection methods.", "published": "2024-02-05 09:10:32", "link": "http://arxiv.org/abs/2402.02823v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Comparing Knowledge Sources for Open-Domain Scientific Claim\n  Verification", "abstract": "The increasing rate at which scientific knowledge is discovered and health\nclaims shared online has highlighted the importance of developing efficient\nfact-checking systems for scientific claims. The usual setting for this task in\nthe literature assumes that the documents containing the evidence for claims\nare already provided and annotated or contained in a limited corpus. This\nrenders the systems unrealistic for real-world settings where knowledge sources\nwith potentially millions of documents need to be queried to find relevant\nevidence. In this paper, we perform an array of experiments to test the\nperformance of open-domain claim verification systems. We test the final\nverdict prediction of systems on four datasets of biomedical and health claims\nin different settings. While keeping the pipeline's evidence selection and\nverdict prediction parts constant, document retrieval is performed over three\ncommon knowledge sources (PubMed, Wikipedia, Google) and using two different\ninformation retrieval techniques. We show that PubMed works better with\nspecialized biomedical claims, while Wikipedia is more suited for everyday\nhealth concerns. Likewise, BM25 excels in retrieval precision, while semantic\nsearch in recall of relevant evidence. We discuss the results, outline frequent\nretrieval patterns and challenges, and provide promising future directions.", "published": "2024-02-05 09:57:15", "link": "http://arxiv.org/abs/2402.02844v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "LLM Agents in Interaction: Measuring Personality Consistency and\n  Linguistic Alignment in Interacting Populations of Large Language Models", "abstract": "While both agent interaction and personalisation are vibrant topics in\nresearch on large language models (LLMs), there has been limited focus on the\neffect of language interaction on the behaviour of persona-conditioned LLM\nagents. Such an endeavour is important to ensure that agents remain consistent\nto their assigned traits yet are able to engage in open, naturalistic\ndialogues. In our experiments, we condition GPT-3.5 on personality profiles\nthrough prompting and create a two-group population of LLM agents using a\nsimple variability-inducing sampling algorithm. We then administer personality\ntests and submit the agents to a collaborative writing task, finding that\ndifferent profiles exhibit different degrees of personality consistency and\nlinguistic alignment to their conversational partners. Our study seeks to lay\nthe groundwork for better understanding of dialogue-based interaction between\nLLMs and highlights the need for new approaches to crafting robust, more\nhuman-like LLM personas for interactive environments.", "published": "2024-02-05 11:05:20", "link": "http://arxiv.org/abs/2402.02896v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Automated Cognate Detection as a Supervised Link Prediction Task with\n  Cognate Transformer", "abstract": "Identification of cognates across related languages is one of the primary\nproblems in historical linguistics. Automated cognate identification is helpful\nfor several downstream tasks including identifying sound correspondences,\nproto-language reconstruction, phylogenetic classification, etc. Previous\nstate-of-the-art methods for cognate identification are mostly based on\ndistributions of phonemes computed across multilingual wordlists and make\nlittle use of the cognacy labels that define links among cognate clusters. In\nthis paper, we present a transformer-based architecture inspired by\ncomputational biology for the task of automated cognate detection. Beyond a\ncertain amount of supervision, this method performs better than the existing\nmethods, and shows steady improvement with further increase in supervision,\nthereby proving the efficacy of utilizing the labeled information. We also\ndemonstrate that accepting multiple sequence alignments as input and having an\nend-to-end architecture with link prediction head saves much computation time\nwhile simultaneously yielding superior performance.", "published": "2024-02-05 11:47:36", "link": "http://arxiv.org/abs/2402.02926v1", "categories": ["cs.CL", "cs.LG", "cs.SI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards Understanding the Word Sensitivity of Attention Layers: A Study\n  via Random Features", "abstract": "Understanding the reasons behind the exceptional success of transformers\nrequires a better analysis of why attention layers are suitable for NLP tasks.\nIn particular, such tasks require predictive models to capture contextual\nmeaning which often depends on one or few words, even if the sentence is long.\nOur work studies this key property, dubbed word sensitivity (WS), in the\nprototypical setting of random features. We show that attention layers enjoy\nhigh WS, namely, there exists a vector in the space of embeddings that largely\nperturbs the random attention features map. The argument critically exploits\nthe role of the softmax in the attention layer, highlighting its benefit\ncompared to other activations (e.g., ReLU). In contrast, the WS of standard\nrandom features is of order $1/\\sqrt{n}$, $n$ being the number of words in the\ntextual sample, and thus it decays with the length of the context. We then\ntranslate these results on the word sensitivity into generalization bounds: due\nto their low WS, random features provably cannot learn to distinguish between\ntwo sentences that differ only in a single word; in contrast, due to their high\nWS, random attention features have higher generalization capabilities. We\nvalidate our theoretical results with experimental evidence over the BERT-Base\nword embeddings of the imdb review dataset.", "published": "2024-02-05 12:47:19", "link": "http://arxiv.org/abs/2402.02969v2", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Reconstruct Your Previous Conversations! Comprehensively Investigating\n  Privacy Leakage Risks in Conversations with GPT Models", "abstract": "Significant advancements have recently been made in large language models\nrepresented by GPT models. Users frequently have multi-round private\nconversations with cloud-hosted GPT models for task optimization. Yet, this\noperational paradigm introduces additional attack surfaces, particularly in\ncustom GPTs and hijacked chat sessions. In this paper, we introduce a\nstraightforward yet potent Conversation Reconstruction Attack. This attack\ntargets the contents of previous conversations between GPT models and benign\nusers, i.e., the benign users' input contents during their interaction with GPT\nmodels. The adversary could induce GPT models to leak such contents by querying\nthem with designed malicious prompts. Our comprehensive examination of privacy\nrisks during the interactions with GPT models under this attack reveals GPT-4's\nconsiderable resilience. We present two advanced attacks targeting improved\nreconstruction of past conversations, demonstrating significant privacy leakage\nacross all models under these advanced techniques. Evaluating various defense\nmechanisms, we find them ineffective against these attacks. Our findings\nhighlight the ease with which privacy can be compromised in interactions with\nGPT models, urging the community to safeguard against potential abuses of these\nmodels' capabilities.", "published": "2024-02-05 13:18:42", "link": "http://arxiv.org/abs/2402.02987v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Decoding-time Realignment of Language Models", "abstract": "Aligning language models with human preferences is crucial for reducing\nerrors and biases in these models. Alignment techniques, such as reinforcement\nlearning from human feedback (RLHF), are typically cast as optimizing a\ntradeoff between human preference rewards and a proximity regularization term\nthat encourages staying close to the unaligned model. Selecting an appropriate\nlevel of regularization is critical: insufficient regularization can lead to\nreduced model capabilities due to reward hacking, whereas excessive\nregularization hinders alignment. Traditional methods for finding the optimal\nregularization level require retraining multiple models with varying\nregularization strengths. This process, however, is resource-intensive,\nespecially for large models. To address this challenge, we propose\ndecoding-time realignment (DeRa), a simple method to explore and evaluate\ndifferent regularization strengths in aligned models without retraining. DeRa\nenables control over the degree of alignment, allowing users to smoothly\ntransition between unaligned and aligned models. It also enhances the\nefficiency of hyperparameter tuning by enabling the identification of effective\nregularization strengths using a validation dataset.", "published": "2024-02-05 13:31:28", "link": "http://arxiv.org/abs/2402.02992v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Automatic Combination of Sample Selection Strategies for Few-Shot\n  Learning", "abstract": "In few-shot learning, such as meta-learning, few-shot fine-tuning or\nin-context learning, the limited number of samples used to train a model have a\nsignificant impact on the overall success. Although a large number of sample\nselection strategies exist, their impact on the performance of few-shot\nlearning is not extensively known, as most of them have been so far evaluated\nin typical supervised settings only. In this paper, we thoroughly investigate\nthe impact of 20 sample selection strategies on the performance of 5 few-shot\nlearning approaches over 8 image and 6 text datasets. In addition, we propose a\nnew method for automatic combination of sample selection strategies (ACSESS)\nthat leverages the strengths and complementary information of the individual\nstrategies. The experimental results show that our method consistently\noutperforms the individual selection strategies, as well as the recently\nproposed method for selecting support examples for in-context learning. We also\nshow a strong modality, dataset and approach dependence for the majority of\nstrategies as well as their dependence on the number of shots - demonstrating\nthat the sample selection strategies play a significant role for lower number\nof shots, but regresses to random selection at higher number of shots.", "published": "2024-02-05 14:23:43", "link": "http://arxiv.org/abs/2402.03038v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Comprehensive Study of the Current State-of-the-Art in Nepali\n  Automatic Speech Recognition Systems", "abstract": "In this paper, we examine the research conducted in the field of Nepali\nAutomatic Speech Recognition (ASR). The primary objective of this survey is to\nconduct a comprehensive review of the works on Nepali Automatic Speech\nRecognition Systems completed to date, explore the different datasets used,\nexamine the technology utilized, and take account of the obstacles encountered\nin implementing the Nepali ASR system. In tandem with the global trends of\never-increasing research on speech recognition based research, the number of\nNepalese ASR-related projects are also growing. Nevertheless, the investigation\nof language and acoustic models of the Nepali language has not received\nadequate attention compared to languages that possess ample resources. In this\ncontext, we provide a framework as well as directions for future\ninvestigations.", "published": "2024-02-05 14:34:14", "link": "http://arxiv.org/abs/2402.03050v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Intent-based Prompt Calibration: Enhancing prompt optimization with\n  synthetic boundary cases", "abstract": "Prompt engineering is a challenging and important task due to the high\nsensitivity of Large Language Models (LLMs) to the given prompt and the\ninherent ambiguity of a textual task instruction. Automatic prompt engineering\nis essential to achieve optimized performance from LLMs. Recent studies have\ndemonstrated the capabilities of LLMs to automatically conduct prompt\nengineering by employing a meta-prompt that incorporates the outcomes of the\nlast trials and proposes an improved prompt. However, this requires a\nhigh-quality benchmark to compare different prompts, which is difficult and\nexpensive to acquire in many real-world use cases. In this work, we introduce a\nnew method for automatic prompt engineering, using a calibration process that\niteratively refines the prompt to the user intent. During the optimization\nprocess, the system jointly generates synthetic data of boundary use cases and\noptimizes the prompt according to the generated dataset. We demonstrate the\neffectiveness of our method with respect to strong proprietary models on\nreal-world tasks such as moderation and generation. Our method outperforms\nstate-of-the-art methods with a limited number of annotated samples.\nFurthermore, we validate the advantages of each one of the system's key\ncomponents. Our system is built in a modular way, facilitating easy adaptation\nto other tasks. The code is available\n$\\href{https://github.com/Eladlev/AutoPrompt}{here}$.", "published": "2024-02-05 15:28:43", "link": "http://arxiv.org/abs/2402.03099v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Homograph Attacks on Maghreb Sentiment Analyzers", "abstract": "We examine the impact of homograph attacks on the Sentiment Analysis (SA)\ntask of different Arabic dialects from the Maghreb North-African countries.\nHomograph attacks result in a 65.3% decrease in transformer classification from\nan F1-score of 0.95 to 0.33 when data is written in \"Arabizi\". The goal of this\nstudy is to highlight LLMs weaknesses' and to prioritize ethical and\nresponsible Machine Learning.", "published": "2024-02-05 16:39:15", "link": "http://arxiv.org/abs/2402.03171v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MULTI: Multimodal Understanding Leaderboard with Text and Images", "abstract": "The rapid development of multimodal large language models (MLLMs) raises the\nquestion of how they compare to human performance. While existing datasets\noften feature synthetic or overly simplistic tasks, some models have already\nsurpassed human expert baselines. In this paper, we present MULTI, a Chinese\nmultimodal dataset derived from authentic examination questions. Comprising\nover 18,000 carefully selected and refined questions, MULTI evaluates models\nusing real-world examination standards, encompassing image-text comprehension,\ncomplex reasoning, and knowledge recall. Additionally, We also introduce\nMULTI-Elite, a 500-question selected hard subset, and MULTI-Extend with more\nthan 4,500 external knowledge context pieces for testing in-context learning\ncapabilities. Our evaluation highlights substantial room for MLLM advancement,\nwith Qwen2-VL-72B achieving a 76.9% accuracy on MULTI and 53.1% on MULTI-Elite\nleading 25 evaluated models, compared to human expert baselines of 86.1% and\n73.1%. MULTI serves not only as a robust evaluation platform but also paves the\nway for the development of expert-level AI.", "published": "2024-02-05 16:41:02", "link": "http://arxiv.org/abs/2402.03173v3", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "C-RAG: Certified Generation Risks for Retrieval-Augmented Language\n  Models", "abstract": "Despite the impressive capabilities of large language models (LLMs) across\ndiverse applications, they still suffer from trustworthiness issues, such as\nhallucinations and misalignments. Retrieval-augmented language models (RAG)\nhave been proposed to enhance the credibility of generations by grounding\nexternal knowledge, but the theoretical understandings of their generation\nrisks remains unexplored. In this paper, we answer: 1) whether RAG can indeed\nlead to low generation risks, 2) how to provide provable guarantees on the\ngeneration risks of RAG and vanilla LLMs, and 3) what sufficient conditions\nenable RAG models to reduce generation risks. We propose C-RAG, the first\nframework to certify generation risks for RAG models. Specifically, we provide\nconformal risk analysis for RAG models and certify an upper confidence bound of\ngeneration risks, which we refer to as conformal generation risk. We also\nprovide theoretical guarantees on conformal generation risks for general\nbounded risk functions under test distribution shifts. We prove that RAG\nachieves a lower conformal generation risk than that of a single LLM when the\nquality of the retrieval model and transformer is non-trivial. Our intensive\nempirical results demonstrate the soundness and tightness of our conformal\ngeneration risk guarantees across four widely-used NLP datasets on four\nstate-of-the-art retrieval models.", "published": "2024-02-05 16:46:16", "link": "http://arxiv.org/abs/2402.03181v5", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity\n  Text Embeddings Through Self-Knowledge Distillation", "abstract": "In this paper, we present a new embedding model, called M3-Embedding, which\nis distinguished for its versatility in Multi-Linguality, Multi-Functionality,\nand Multi-Granularity. It can support more than 100 working languages, leading\nto new state-of-the-art performances on multi-lingual and cross-lingual\nretrieval tasks. It can simultaneously perform the three common retrieval\nfunctionalities of embedding model: dense retrieval, multi-vector retrieval,\nand sparse retrieval, which provides a unified model foundation for real-world\nIR applications. It is able to process inputs of different granularities,\nspanning from short sentences to long documents of up to 8192 tokens. The\neffective training of M3-Embedding involves the following technical\ncontributions. We propose a novel self-knowledge distillation approach, where\nthe relevance scores from different retrieval functionalities can be integrated\nas the teacher signal to enhance the training quality. We also optimize the\nbatching strategy, enabling a large batch size and high training throughput to\nensure the discriminativeness of embeddings. To the best of our knowledge,\nM3-Embedding is the first embedding model which realizes such a strong\nversatility. The model and code will be publicly available at\nhttps://github.com/FlagOpen/FlagEmbedding.", "published": "2024-02-05 17:26:49", "link": "http://arxiv.org/abs/2402.03216v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding Reasoning Ability of Language Models From the Perspective\n  of Reasoning Paths Aggregation", "abstract": "Pre-trained language models (LMs) are able to perform complex reasoning\nwithout explicit fine-tuning. To understand how pre-training with a next-token\nprediction objective contributes to the emergence of such reasoning capability,\nwe propose that we can view an LM as deriving new conclusions by aggregating\nindirect reasoning paths seen at pre-training time. We found this perspective\neffective in two important cases of reasoning: logic reasoning with knowledge\ngraphs (KGs) and chain-of-thought (CoT) reasoning. More specifically, we\nformalize the reasoning paths as random walk paths on the knowledge/reasoning\ngraphs. Analyses of learned LM distributions suggest that a weighted sum of\nrelevant random walk path probabilities is a reasonable way to explain how LMs\nreason. Experiments and analysis on multiple KG and CoT datasets reveal the\neffect of training on random walk paths and suggest that augmenting unlabeled\nrandom walk reasoning paths can improve real-world multi-step reasoning\nperformance. code: https://github.com/WANGXinyiLinda/LM_random_walk", "published": "2024-02-05 18:25:51", "link": "http://arxiv.org/abs/2402.03268v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ISPA: Inter-Species Phonetic Alphabet for Transcribing Animal Sounds", "abstract": "Traditionally, bioacoustics has relied on spectrograms and continuous,\nper-frame audio representations for the analysis of animal sounds, also serving\nas input to machine learning models. Meanwhile, the International Phonetic\nAlphabet (IPA) system has provided an interpretable, language-independent\nmethod for transcribing human speech sounds. In this paper, we introduce ISPA\n(Inter-Species Phonetic Alphabet), a precise, concise, and interpretable system\ndesigned for transcribing animal sounds into text. We compare acoustics-based\nand feature-based methods for transcribing and classifying animal sounds,\ndemonstrating their comparable performance with baseline methods utilizing\ncontinuous, dense audio representations. By representing animal sounds with\ntext, we effectively treat them as a \"foreign language,\" and we show that\nestablished human language ML paradigms and models, such as language models,\ncan be successfully applied to improve performance.", "published": "2024-02-05 18:27:27", "link": "http://arxiv.org/abs/2402.03269v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information\n  Seeking in Large Language Models", "abstract": "In the face of uncertainty, the ability to *seek information* is of\nfundamental importance. In many practical applications, such as medical\ndiagnosis and troubleshooting, the information needed to solve the task is not\ninitially given and has to be actively sought by asking follow-up questions\n(for example, a doctor asking a patient for more details about their symptoms).\nIn this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to\naugment large language models with the ability to actively seek information by\nasking effective questions. UoT combines 1) an *uncertainty-aware simulation\napproach* which enables the model to simulate possible future scenarios and how\nlikely they are to occur, 2) *uncertainty-based rewards* motivated by\ninformation gain which incentivizes the model to seek information, and 3) a\n*reward propagation scheme* to select the optimal question to ask in a way that\nmaximizes the expected reward. In experiments on medical diagnosis,\ntroubleshooting, and the `20 Questions` game, UoT achieves an average\nperformance improvement of 38.1% in the rate of successful task completion\nacross multiple LLMs compared with direct prompting and also improves\nefficiency (i.e., the number of questions needed to complete the task). Our\ncode has been released [here](https://github.com/zhiyuanhubj/UoT)", "published": "2024-02-05 18:28:44", "link": "http://arxiv.org/abs/2402.03271v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deal, or no deal (or who knows)? Forecasting Uncertainty in\n  Conversations using Large Language Models", "abstract": "Effective interlocutors account for the uncertain goals, beliefs, and\nemotions of others. But even the best human conversationalist cannot perfectly\nanticipate the trajectory of a dialogue. How well can language models represent\ninherent uncertainty in conversations? We propose FortUne Dial, an expansion of\nthe long-standing \"conversation forecasting\" task: instead of just accuracy,\nevaluation is conducted with uncertainty-aware metrics, effectively enabling\nabstention on individual instances. We study two ways in which language models\npotentially represent outcome uncertainty (internally, using scores and\ndirectly, using tokens) and propose fine-tuning strategies to improve\ncalibration of both representations. Experiments on eight difficult negotiation\ncorpora demonstrate that our proposed fine-tuning strategies (a traditional\nsupervision strategy and an off-policy reinforcement learning strategy) can\ncalibrate smaller open-source models to compete with pre-trained models 10x\ntheir size.", "published": "2024-02-05 18:39:47", "link": "http://arxiv.org/abs/2402.03284v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GUARD: Role-playing to Generate Natural-language Jailbreakings to Test\n  Guideline Adherence of Large Language Models", "abstract": "The discovery of \"jailbreaks\" to bypass safety filters of Large Language\nModels (LLMs) and harmful responses have encouraged the community to implement\nsafety measures. One major safety measure is to proactively test the LLMs with\njailbreaks prior to the release. Therefore, such testing will require a method\nthat can generate jailbreaks massively and efficiently. In this paper, we\nfollow a novel yet intuitive strategy to generate jailbreaks in the style of\nthe human generation. We propose a role-playing system that assigns four\ndifferent roles to the user LLMs to collaborate on new jailbreaks. Furthermore,\nwe collect existing jailbreaks and split them into different independent\ncharacteristics using clustering frequency and semantic patterns sentence by\nsentence. We organize these characteristics into a knowledge graph, making them\nmore accessible and easier to retrieve. Our system of different roles will\nleverage this knowledge graph to generate new jailbreaks, which have proved\neffective in inducing LLMs to generate unethical or guideline-violating\nresponses. In addition, we also pioneer a setting in our system that will\nautomatically follow the government-issued guidelines to generate jailbreaks to\ntest whether LLMs follow the guidelines accordingly. We refer to our system as\nGUARD (Guideline Upholding through Adaptive Role-play Diagnostics). We have\nempirically validated the effectiveness of GUARD on three cutting-edge\nopen-sourced LLMs (Vicuna-13B, LongChat-7B, and Llama-2-7B), as well as a\nwidely-utilized commercial LLM (ChatGPT). Moreover, our work extends to the\nrealm of vision language models (MiniGPT-v2 and Gemini Vision Pro), showcasing\nGUARD's versatility and contributing valuable insights for the development of\nsafer, more reliable LLM-based applications across diverse modalities.", "published": "2024-02-05 18:54:43", "link": "http://arxiv.org/abs/2402.03299v4", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open\n  Language Models", "abstract": "Mathematical reasoning poses a significant challenge for language models due\nto its complex and structured nature. In this paper, we introduce DeepSeekMath\n7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B\nmath-related tokens sourced from Common Crawl, together with natural language\nand code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the\ncompetition-level MATH benchmark without relying on external toolkits and\nvoting techniques, approaching the performance level of Gemini-Ultra and GPT-4.\nSelf-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH.\nThe mathematical reasoning capability of DeepSeekMath is attributed to two key\nfactors: First, we harness the significant potential of publicly available web\ndata through a meticulously engineered data selection pipeline. Second, we\nintroduce Group Relative Policy Optimization (GRPO), a variant of Proximal\nPolicy Optimization (PPO), that enhances mathematical reasoning abilities while\nconcurrently optimizing the memory usage of PPO.", "published": "2024-02-05 18:55:32", "link": "http://arxiv.org/abs/2402.03300v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Nevermind: Instruction Override and Moderation in Large Language Models", "abstract": "Given the impressive capabilities of recent Large Language Models (LLMs), we\ninvestigate and benchmark the most popular proprietary and different sized open\nsource models on the task of explicit instruction following in conflicting\nsituations, e.g. overrides. These include the ability of the model to override\nthe knowledge within the weights of the model, the ability to override (or\nmoderate) extracted knowledge in the prompt, and lastly the ability to perform\na full jailbreak. Experimentation performed suggest several key findings to\nimprove instruction following - larger models perform the best in following\ninstructions that override internal and contextual instructions, and are\nobedient, even to a fault. When scaling to longer contexts via rope scaling, a\nsignificant buffer needs to be maintained from the edge of the perplexity cliff\nin order to maintain instruction following capabilities. Finally, we observe\nimproving instruction following, and subsequently instruction\noverrides/jailbreaks, is fundamentally at odds with the ability of a language\nmodel to follow given safety filters or guidelines. Thus, we postulate the most\neffective approach for safe, trustworthy AI should be dealt external to the LLM\nitself.", "published": "2024-02-05 18:58:19", "link": "http://arxiv.org/abs/2402.03303v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing the Stability of LLM-based Speech Generation Systems through\n  Self-Supervised Representations", "abstract": "Large Language Models (LLMs) are one of the most promising technologies for\nthe next era of speech generation systems, due to their scalability and\nin-context learning capabilities. Nevertheless, they suffer from multiple\nstability issues at inference time, such as hallucinations, content skipping or\nspeech repetitions. In this work, we introduce a new self-supervised Voice\nConversion (VC) architecture which can be used to learn to encode transitory\nfeatures, such as content, separately from stationary ones, such as speaker ID\nor recording conditions, creating speaker-disentangled representations. Using\nspeaker-disentangled codes to train LLMs for text-to-speech (TTS) allows the\nLLM to generate the content and the style of the speech only from the text,\nsimilarly to humans, while the speaker identity is provided by the decoder of\nthe VC model. Results show that LLMs trained over speaker-disentangled\nself-supervised representations provide an improvement of 4.7pp in speaker\nsimilarity over SOTA entangled representations, and a word error rate (WER)\n5.4pp lower. Furthermore, they achieve higher naturalness than human recordings\nof the LibriTTS test-other dataset. Finally, we show that using explicit\nreference embedding negatively impacts intelligibility (stability), with WER\nincreasing by 14pp compared to the model that only uses text to infer the\nstyle.", "published": "2024-02-05 15:08:19", "link": "http://arxiv.org/abs/2402.03407v1", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Psychological Assessments with Large Language Models: A Privacy-Focused\n  and Cost-Effective Approach", "abstract": "This study explores the use of Large Language Models (LLMs) to analyze text\ncomments from Reddit users, aiming to achieve two primary objectives: firstly,\nto pinpoint critical excerpts that support a predefined psychological\nassessment of suicidal risk; and secondly, to summarize the material to\nsubstantiate the preassigned suicidal risk level. The work is circumscribed to\nthe use of \"open-source\" LLMs that can be run locally, thereby enhancing data\nprivacy. Furthermore, it prioritizes models with low computational\nrequirements, making it accessible to both individuals and institutions\noperating on limited computing budgets. The implemented strategy only relies on\na carefully crafted prompt and a grammar to guide the LLM's text completion.\nDespite its simplicity, the evaluation metrics show outstanding results, making\nit a valuable privacy-focused and cost-effective approach. This work is part of\nthe Computational Linguistics and Clinical Psychology (CLPsych) 2024 shared\ntask.", "published": "2024-02-05 19:00:02", "link": "http://arxiv.org/abs/2402.03435v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Attention Meets Post-hoc Interpretability: A Mathematical Perspective", "abstract": "Attention-based architectures, in particular transformers, are at the heart\nof a technological revolution. Interestingly, in addition to helping obtain\nstate-of-the-art results on a wide range of applications, the attention\nmechanism intrinsically provides meaningful insights on the internal behavior\nof the model. Can these insights be used as explanations? Debate rages on. In\nthis paper, we mathematically study a simple attention-based architecture and\npinpoint the differences between post-hoc and attention-based explanations. We\nshow that they provide quite different results, and that, despite their\nlimitations, post-hoc methods are capable of capturing more useful insights\nthan merely examining the attention weights.", "published": "2024-02-05 19:56:56", "link": "http://arxiv.org/abs/2402.03485v2", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "An Inpainting-Infused Pipeline for Attire and Background Replacement", "abstract": "In recent years, groundbreaking advancements in Generative Artificial\nIntelligence (GenAI) have triggered a transformative paradigm shift,\nsignificantly influencing various domains. In this work, we specifically\nexplore an integrated approach, leveraging advanced techniques in GenAI and\ncomputer vision emphasizing image manipulation. The methodology unfolds through\nseveral stages, including depth estimation, the creation of inpaint masks based\non depth information, the generation and replacement of backgrounds utilizing\nStable Diffusion in conjunction with Latent Consistency Models (LCMs), and the\nsubsequent replacement of clothes and application of aesthetic changes through\nan inpainting pipeline. Experiments conducted in this study underscore the\nmethodology's efficacy, highlighting its potential to produce visually\ncaptivating content. The convergence of these advanced techniques allows users\nto input photographs of individuals and manipulate them to modify clothing and\nbackground based on specific prompts without manually input inpainting masks,\neffectively placing the subjects within the vast landscape of creative\nimagination.", "published": "2024-02-05 20:34:32", "link": "http://arxiv.org/abs/2402.03501v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Neural networks for abstraction and reasoning: Towards broad\n  generalization in machines", "abstract": "For half a century, artificial intelligence research has attempted to\nreproduce the human qualities of abstraction and reasoning - creating computer\nsystems that can learn new concepts from a minimal set of examples, in settings\nwhere humans find this easy. While specific neural networks are able to solve\nan impressive range of problems, broad generalisation to situations outside\ntheir training data has proved elusive.In this work, we look at several novel\napproaches for solving the Abstraction & Reasoning Corpus (ARC), a dataset of\nabstract visual reasoning tasks introduced to test algorithms on broad\ngeneralization. Despite three international competitions with $100,000 in\nprizes, the best algorithms still fail to solve a majority of ARC tasks and\nrely on complex hand-crafted rules, without using machine learning at all. We\nrevisit whether recent advances in neural networks allow progress on this task.\n  First, we adapt the DreamCoder neurosymbolic reasoning solver to ARC.\nDreamCoder automatically writes programs in a bespoke domain-specific language\nto perform reasoning, using a neural network to mimic human intuition. We\npresent the Perceptual Abstraction and Reasoning Language (PeARL) language,\nwhich allows DreamCoder to solve ARC tasks, and propose a new recognition model\nthat allows us to significantly improve on the previous best implementation.We\nalso propose a new encoding and augmentation scheme that allows large language\nmodels (LLMs) to solve ARC tasks, and find that the largest models can solve\nsome ARC tasks. LLMs are able to solve a different group of problems to\nstate-of-the-art solvers, and provide an interesting way to complement other\napproaches. We perform an ensemble analysis, combining models to achieve better\nresults than any system alone. Finally, we publish the arckit Python library to\nmake future research on ARC easier.", "published": "2024-02-05 20:48:57", "link": "http://arxiv.org/abs/2402.03507v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains", "abstract": "Recent work has shown that large language models (LLMs) are capable of\ngenerating summaries zero-shot (i.e., without explicit supervision) that, under\nhuman assessment, are often comparable or even preferred to manually composed\nreference summaries. However, this prior work has focussed almost exclusively\non evaluating news article summarization. How do zero-shot summarizers perform\nin other (potentially more specialized) domains? In this work we evaluate\nzero-shot generated summaries across specialized domains including biomedical\narticles, and legal bills (in addition to standard news benchmarks for\nreference). We focus especially on the factuality of outputs. We acquire\nannotations from domain experts to identify inconsistencies in summaries and\nsystematically categorize these errors. We analyze whether the prevalence of a\ngiven domain in the pretraining corpus affects extractiveness and faithfulness\nof generated summaries of articles in this domain. We release all collected\nannotations to facilitate additional research toward measuring and realizing\nfactually accurate summarization, beyond news articles. The dataset can be\ndownloaded from https://github.com/sanjanaramprasad/zero_shot_faceval_domains", "published": "2024-02-05 20:51:11", "link": "http://arxiv.org/abs/2402.03509v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language\n  Navigation", "abstract": "Outdoor Vision-and-Language Navigation (VLN) requires an agent to navigate\nthrough realistic 3D outdoor environments based on natural language\ninstructions. The performance of existing VLN methods is limited by\ninsufficient diversity in navigation environments and limited training data. To\naddress these issues, we propose VLN-Video, which utilizes the diverse outdoor\nenvironments present in driving videos in multiple cities in the U.S. augmented\nwith automatically generated navigation instructions and actions to improve\noutdoor VLN performance. VLN-Video combines the best of intuitive classical\napproaches and modern deep learning techniques, using template infilling to\ngenerate grounded navigation instructions, combined with an image rotation\nsimilarity-based navigation action predictor to obtain VLN style data from\ndriving videos for pretraining deep learning VLN models. We pre-train the model\non the Touchdown dataset and our video-augmented dataset created from driving\nvideos with three proxy tasks: Masked Language Modeling, Instruction and\nTrajectory Matching, and Next Action Prediction, so as to learn\ntemporally-aware and visually-aligned instruction representations. The learned\ninstruction representation is adapted to the state-of-the-art navigator when\nfine-tuning on the Touchdown dataset. Empirical results demonstrate that\nVLN-Video significantly outperforms previous state-of-the-art models by 2.1% in\ntask completion rate, achieving a new state-of-the-art on the Touchdown\ndataset.", "published": "2024-02-05 22:20:19", "link": "http://arxiv.org/abs/2402.03561v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Distinguishing the Knowable from the Unknowable with Language Models", "abstract": "We study the feasibility of identifying epistemic uncertainty (reflecting a\nlack of knowledge), as opposed to aleatoric uncertainty (reflecting entropy in\nthe underlying distribution), in the outputs of large language models (LLMs)\nover free-form text. In the absence of ground-truth probabilities, we explore a\nsetting where, in order to (approximately) disentangle a given LLM's\nuncertainty, a significantly larger model stands in as a proxy for the ground\ntruth. We show that small linear probes trained on the embeddings of frozen,\npretrained models accurately predict when larger models will be more confident\nat the token level and that probes trained on one text domain generalize to\nothers. Going further, we propose a fully unsupervised method that achieves\nnon-trivial accuracy on the same task. Taken together, we interpret these\nresults as evidence that LLMs naturally contain internal representations of\ndifferent types of uncertainty that could potentially be leveraged to devise\nmore informative indicators of model confidence in diverse practical settings.", "published": "2024-02-05 22:22:49", "link": "http://arxiv.org/abs/2402.03563v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Illuminate: A novel approach for depression detection with explainable\n  analysis and proactive therapy using prompt engineering", "abstract": "This paper introduces a novel paradigm for depression detection and treatment\nusing advanced Large Language Models (LLMs): Generative Pre-trained Transformer\n4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized\nprompts to diagnose, explain, and suggest therapeutic interventions for\ndepression. A unique few-shot prompting method enhances the models' ability to\nanalyze and explain depressive symptoms based on the DSM-5 criteria. In the\ninteraction phase, the models engage in empathetic dialogue management, drawing\nfrom resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,\nfostering supportive interactions with individuals experiencing major\ndepressive disorders. Additionally, the research introduces the Illuminate\nDatabase, enriched with various CBT modules, aiding in personalized therapy\nrecommendations. The study evaluates LLM performance using metrics such as F1\nscores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy\nfor Gisting Evaluation (ROUGE) across different test sets, demonstrating their\neffectiveness. This comprehensive approach blends cutting-edge AI with\nestablished psychological methods, offering new possibilities in mental health\ncare and showcasing the potential of LLMs in revolutionizing depression\ndiagnosis and treatment strategies.", "published": "2024-02-05 06:08:06", "link": "http://arxiv.org/abs/2402.05127v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TexShape: Information Theoretic Sentence Embedding for Language Models", "abstract": "With the exponential growth in data volume and the emergence of\ndata-intensive applications, particularly in the field of machine learning,\nconcerns related to resource utilization, privacy, and fairness have become\nparamount. This paper focuses on the textual domain of data and addresses\nchallenges regarding encoding sentences to their optimized representations\nthrough the lens of information-theory. In particular, we use empirical\nestimates of mutual information, using the Donsker-Varadhan definition of\nKullback-Leibler divergence. Our approach leverages this estimation to train an\ninformation-theoretic sentence embedding, called TexShape, for (task-based)\ndata compression or for filtering out sensitive information, enhancing privacy\nand fairness. In this study, we employ a benchmark language model for initial\ntext representation, complemented by neural networks for information-theoretic\ncompression and mutual information estimations. Our experiments demonstrate\nsignificant advancements in preserving maximal targeted information and minimal\nsensitive information over adverse compression ratios, in terms of predictive\naccuracy of downstream models that are trained using the compressed data.", "published": "2024-02-05 22:48:28", "link": "http://arxiv.org/abs/2402.05132v2", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "A Survey on Transformer Compression", "abstract": "Transformer plays a vital role in the realms of natural language processing\n(NLP) and computer vision (CV), specially for constructing large language\nmodels (LLM) and large vision models (LVM). Model compression methods reduce\nthe memory and computational cost of Transformer, which is a necessary step to\nimplement large language/vision models on practical devices. Given the unique\narchitecture of Transformer, featuring alternative attention and feedforward\nneural network (FFN) modules, specific compression techniques are usually\nrequired. The efficiency of these compression methods is also paramount, as\nretraining large models on the entire training dataset is usually impractical.\nThis survey provides a comprehensive review of recent compression methods, with\na specific focus on their application to Transformer-based models. The\ncompression methods are primarily categorized into pruning, quantization,\nknowledge distillation, and efficient architecture design (Mamba, RetNet, RWKV,\netc.). In each category, we discuss compression methods for both language and\nvision tasks, highlighting common underlying principles. Finally, we delve into\nthe relation between various compression methods, and discuss further\ndirections in this domain.", "published": "2024-02-05 12:16:28", "link": "http://arxiv.org/abs/2402.05964v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Adversarial Text Purification: A Large Language Model Approach for\n  Defense", "abstract": "Adversarial purification is a defense mechanism for safeguarding classifiers\nagainst adversarial attacks without knowing the type of attacks or training of\nthe classifier. These techniques characterize and eliminate adversarial\nperturbations from the attacked inputs, aiming to restore purified samples that\nretain similarity to the initially attacked ones and are correctly classified\nby the classifier. Due to the inherent challenges associated with\ncharacterizing noise perturbations for discrete inputs, adversarial text\npurification has been relatively unexplored. In this paper, we investigate the\neffectiveness of adversarial purification methods in defending text\nclassifiers. We propose a novel adversarial text purification that harnesses\nthe generative capabilities of Large Language Models (LLMs) to purify\nadversarial text without the need to explicitly characterize the discrete noise\nperturbations. We utilize prompt engineering to exploit LLMs for recovering the\npurified examples for given adversarial examples such that they are\nsemantically similar and correctly classified. Our proposed method demonstrates\nremarkable performance over various classifiers, improving their accuracy under\nthe attack by over 65% on average.", "published": "2024-02-05 02:36:41", "link": "http://arxiv.org/abs/2402.06655v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A Systematic Survey of Prompt Engineering in Large Language Models:\n  Techniques and Applications", "abstract": "Prompt engineering has emerged as an indispensable technique for extending\nthe capabilities of large language models (LLMs) and vision-language models\n(VLMs). This approach leverages task-specific instructions, known as prompts,\nto enhance model efficacy without modifying the core model parameters. Rather\nthan updating the model parameters, prompts allow seamless integration of\npre-trained models into downstream tasks by eliciting desired model behaviors\nsolely based on the given prompt. Prompts can be natural language instructions\nthat provide context to guide the model or learned vector representations that\nactivate relevant knowledge. This burgeoning field has enabled success across\nvarious applications, from question-answering to commonsense reasoning.\nHowever, there remains a lack of systematic organization and understanding of\nthe diverse prompt engineering methods and techniques. This survey paper\naddresses the gap by providing a structured overview of recent advancements in\nprompt engineering, categorized by application area. For each prompting\napproach, we provide a summary detailing the prompting methodology, its\napplications, the models involved, and the datasets utilized. We also delve\ninto the strengths and limitations of each approach and include a taxonomy\ndiagram and table summarizing datasets, models, and critical points of each\nprompting technique. This systematic analysis enables a better understanding of\nthis rapidly developing field and facilitates future research by illuminating\nopen challenges and opportunities for prompt engineering.", "published": "2024-02-05 19:49:13", "link": "http://arxiv.org/abs/2402.07927v2", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Dual Knowledge Distillation for Efficient Sound Event Detection", "abstract": "Sound event detection (SED) is essential for recognizing specific sounds and\ntheir temporal locations within acoustic signals. This becomes challenging\nparticularly for on-device applications, where computational resources are\nlimited. To address this issue, we introduce a novel framework referred to as\ndual knowledge distillation for developing efficient SED systems in this work.\nOur proposed dual knowledge distillation commences with temporal-averaging\nknowledge distillation (TAKD), utilizing a mean student model derived from the\ntemporal averaging of the student model's parameters. This allows the student\nmodel to indirectly learn from a pre-trained teacher model, ensuring a stable\nknowledge distillation. Subsequently, we introduce embedding-enhanced feature\ndistillation (EEFD), which involves incorporating an embedding distillation\nlayer within the student model to bolster contextual learning. On DCASE 2023\nTask 4A public evaluation dataset, our proposed SED system with dual knowledge\ndistillation having merely one-third of the baseline model's parameters,\ndemonstrates superior performance in terms of PSDS1 and PSDS2. This highlights\nthe importance of proposed dual knowledge distillation for compact SED systems,\nwhich can be ideal for edge devices.", "published": "2024-02-05 07:30:32", "link": "http://arxiv.org/abs/2402.02781v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EasyInstruct: An Easy-to-use Instruction Processing Framework for Large\n  Language Models", "abstract": "In recent years, instruction tuning has gained increasing attention and\nemerged as a crucial technique to enhance the capabilities of Large Language\nModels (LLMs). To construct high-quality instruction datasets, many instruction\nprocessing approaches have been proposed, aiming to achieve a delicate balance\nbetween data quantity and data quality. Nevertheless, due to inconsistencies\nthat persist among various instruction processing methods, there is no standard\nopen-source instruction processing implementation framework available for the\ncommunity, which hinders practitioners from further developing and advancing.\nTo facilitate instruction processing research and development, we present\nEasyInstruct, an easy-to-use instruction processing framework for LLMs, which\nmodularizes instruction generation, selection, and prompting, while also\nconsidering their combination and interaction. EasyInstruct is publicly\nreleased and actively maintained at https://github.com/zjunlp/EasyInstruct,\nalong with an online demo app and a demo video for quick-start, calling for\nbroader research centered on instruction data and synthetic data.", "published": "2024-02-05 14:33:56", "link": "http://arxiv.org/abs/2402.03049v4", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unified Hallucination Detection for Multimodal Large Language Models", "abstract": "Despite significant strides in multimodal tasks, Multimodal Large Language\nModels (MLLMs) are plagued by the critical issue of hallucination. The reliable\ndetection of such hallucinations in MLLMs has, therefore, become a vital aspect\nof model evaluation and the safeguarding of practical application deployment.\nPrior research in this domain has been constrained by a narrow focus on\nsingular tasks, an inadequate range of hallucination categories addressed, and\na lack of detailed granularity. In response to these challenges, our work\nexpands the investigative horizons of hallucination detection. We present a\nnovel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate\nthe evaluation of advancements in hallucination detection methods.\nAdditionally, we unveil a novel unified multimodal hallucination detection\nframework, UNIHD, which leverages a suite of auxiliary tools to validate the\noccurrence of hallucinations robustly. We demonstrate the effectiveness of\nUNIHD through meticulous evaluation and comprehensive analysis. We also provide\nstrategic insights on the application of specific tools for addressing various\ncategories of hallucinations.", "published": "2024-02-05 16:56:11", "link": "http://arxiv.org/abs/2402.03190v4", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Automatic Detection of Depression in Speech Using Ensemble Convolutional\n  Neural Networks", "abstract": "This paper proposes a speech-based method for automatic depression\nclassification. The system is based on ensemble learning for Convolutional\nNeural Networks (CNNs) and is evaluated using the data and the experimental\nprotocol provided in the Depression Classification Sub-Challenge (DCC) at the\n2016 Audio-Visual Emotion Challenge (AVEC-2016). In the pre-processing phase,\nspeech files are represented as a sequence of log-spectrograms and randomly\nsampled to balance positive and negative samples. For the classification task\nitself, first, a more suitable architecture for this task, based on\nOne-Dimensional Convolutional Neural Networks, is built. Secondly, several of\nthese CNN-based models are trained with different initializations and then the\ncorresponding individual predictions are fused by using an Ensemble Averaging\nalgorithm and combined per speaker to get an appropriate final decision. The\nproposed ensemble system achieves satisfactory results on the DCC at the\nAVEC-2016 in comparison with a reference system based on Support Vector\nMachines and hand-crafted features, with a CNN+LSTM-based system called\nDepAudionet, and with the case of a single CNN-based classifier.", "published": "2024-02-05 09:36:21", "link": "http://arxiv.org/abs/2402.02830v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Positive and negative sampling strategies for self-supervised learning\n  on audio-video data", "abstract": "In Self-Supervised Learning (SSL), Audio-Visual Correspondence (AVC) is a\npopular task to learn deep audio and video features from large unlabeled\ndatasets. The key step in AVC is to randomly sample audio and video clips from\nthe dataset and learn to minimize the feature distance between the positive\npairs (corresponding audio-video pair) while maximizing the distance between\nthe negative pairs (non-corresponding audio-video pairs). The learnt features\nare shown to be effective on various downstream tasks. However, these methods\nachieve subpar performance when the size of the dataset is rather small. In\nthis paper, we investigate the effect of utilizing class label information in\nthe AVC feature learning task. We modified various positive and negative data\nsampling techniques of SSL based on class label information to investigate the\neffect on the feature quality. We propose a new sampling approach which we call\nsoft-positive sampling, where the positive pair for one audio sample is not\nfrom the exact corresponding video, but from a video of the same class.\nExperimental results suggest that when the dataset size is small in SSL setup,\nfeatures learnt through the soft-positive sampling method significantly\noutperform those from the traditional SSL sampling approaches. This trend holds\nin both in-domain and out-of-domain downstream tasks, and even outperforms\nsupervised classification. Finally, experiments show that class label\ninformation can easily be obtained using a publicly available classifier\nnetwork and then can be used to boost the SSL performance without adding extra\ndata annotation burden.", "published": "2024-02-05 11:11:38", "link": "http://arxiv.org/abs/2402.02899v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "How phonemes contribute to deep speaker models?", "abstract": "Which phonemes convey more speaker traits is a long-standing question, and\nvarious perception experiments were conducted with human subjects. For speaker\nrecognition, studies were conducted with the conventional statistical models\nand the drawn conclusions are more or less consistent with the perception\nresults. However, which phonemes are more important with modern deep neural\nmodels is still unexplored, due to the opaqueness of the decision process. This\npaper conducts a novel study for the attribution of phonemes with two types of\ndeep speaker models that are based on TDNN and CNN respectively, from the\nperspective of model explanation. Specifically, we conducted the study by two\npost-explanation methods: LayerCAM and Time Align Occlusion (TAO). Experimental\nresults showed that: (1) At the population level, vowels are more important\nthan consonants, confirming the human perception studies. However, fricatives\nare among the most unimportant phonemes, which contrasts with previous studies.\n(2) At the speaker level, a large between-speaker variation is observed\nregarding phoneme importance, indicating that whether a phoneme is important or\nnot is largely speaker-dependent.", "published": "2024-02-05 05:06:26", "link": "http://arxiv.org/abs/2402.02730v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On combining acoustic and modulation spectrograms in an attention\n  LSTM-based system for speech intelligibility level classification", "abstract": "Speech intelligibility can be affected by multiple factors, such as noisy\nenvironments, channel distortions or physiological issues. In this work, we\ndeal with the problem of automatic prediction of the speech intelligibility\nlevel in this latter case. Starting from our previous work, a non-intrusive\nsystem based on LSTM networks with attention mechanism designed for this task,\nwe present two main contributions. In the first one, it is proposed the use of\nper-frame modulation spectrograms as input features, instead of compact\nrepresentations derived from them that discard important temporal information.\nIn the second one, two different strategies for the combination of per-frame\nacoustic log-mel and modulation spectrograms into the LSTM framework are\nexplored: at decision level or late fusion and at utterance level or\nWeighted-Pooling (WP) fusion. The proposed models are evaluated with the\nUA-Speech database that contains dysarthric speech with different degrees of\nseverity. On the one hand, results show that attentional LSTM networks are able\nto adequately modeling the modulation spectrograms sequences producing similar\nclassification rates as in the case of log-mel spectrograms. On the other hand,\nboth combination strategies, late and WP fusion, outperform the single-feature\nsystems, suggesting that per-frame log-mel and modulation spectrograms carry\ncomplementary information for the task of speech intelligibility prediction,\nthan can be effectively exploited by the LSTM-based architectures, being the\nsystem with the WP fusion strategy and Attention-Pooling the one that achieves\nbest results.", "published": "2024-02-05 10:26:28", "link": "http://arxiv.org/abs/2402.02865v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Array Geometry-Robust Attention-Based Neural Beamformer for Moving\n  Speakers", "abstract": "Although mask-based beamforming is a powerful speech enhancement approach, it\noften requires manual parameter tuning to handle moving speakers. Recently,\nthis approach was augmented with an attention-based spatial covariance matrix\naggregator (ASA) module, enabling accurate tracking of moving speakers without\nmanual tuning. However, the deep neural network model used in this module is\nlimited to specific microphone arrays, necessitating a different model for\nvarying channel permutations, numbers, or geometries. To improve the robustness\nof the ASA module against such variations, in this paper we investigate three\napproaches: training with random channel configurations, employing the\ntransform-average-concatenate method to process multi-channel input features,\nand utilizing robust input features. Our experiments on the CHiME-3 and DEMAND\ndatasets show that these approaches enable the ASA-augmented beamformer to\ntrack moving speakers across different microphone arrays unseen in training.", "published": "2024-02-05 14:48:07", "link": "http://arxiv.org/abs/2402.03058v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Description on IEEE ICME 2024 Grand Challenge: Semi-supervised Acoustic\n  Scene Classification under Domain Shift", "abstract": "Acoustic scene classification (ASC) is a crucial research problem in\ncomputational auditory scene analysis, and it aims to recognize the unique\nacoustic characteristics of an environment. One of the challenges of the ASC\ntask is the domain shift between training and testing data. Since 2018, ASC\nchallenges have focused on the generalization of ASC models across different\nrecording devices. Although this task, in recent years, has achieved\nsubstantial progress in device generalization, the challenge of domain shift\nbetween different geographical regions, involving discrepancies such as time,\nspace, culture, and language, remains insufficiently explored at present. In\naddition, considering the abundance of unlabeled acoustic scene data in the\nreal world, it is important to study the possible ways to utilize these\nunlabelled data. Therefore, we introduce the task Semi-supervised Acoustic\nScene Classification under Domain Shift in the ICME 2024 Grand Challenge. We\nencourage participants to innovate with semi-supervised learning techniques,\naiming to develop more robust ASC models under domain shift.", "published": "2024-02-05 03:12:51", "link": "http://arxiv.org/abs/2402.02694v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adversarial Data Augmentation for Robust Speaker Verification", "abstract": "Data augmentation (DA) has gained widespread popularity in deep speaker\nmodels due to its ease of implementation and significant effectiveness. It\nenriches training data by simulating real-life acoustic variations, enabling\ndeep neural networks to learn speaker-related representations while\ndisregarding irrelevant acoustic variations, thereby improving robustness and\ngeneralization. However, a potential issue with the vanilla DA is augmentation\nresidual, i.e., unwanted distortion caused by different types of augmentation.\nTo address this problem, this paper proposes a novel approach called\nadversarial data augmentation (A-DA) which combines DA with adversarial\nlearning. Specifically, it involves an additional augmentation classifier to\ncategorize various augmentation types used in data augmentation. This\nadversarial learning empowers the network to generate speaker embeddings that\ncan deceive the augmentation classifier, making the learned speaker embeddings\nmore robust in the face of augmentation variations. Experiments conducted on\nVoxCeleb and CN-Celeb datasets demonstrate that our proposed A-DA outperforms\nstandard DA in both augmentation matched and mismatched test conditions,\nshowcasing its superior robustness and generalization against acoustic\nvariations.", "published": "2024-02-05 03:23:34", "link": "http://arxiv.org/abs/2402.02699v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Focal Modulation Networks for Interpretable Sound Classification", "abstract": "The increasing success of deep neural networks has raised concerns about\ntheir inherent black-box nature, posing challenges related to interpretability\nand trust. While there has been extensive exploration of interpretation\ntechniques in vision and language, interpretability in the audio domain has\nreceived limited attention, primarily focusing on post-hoc explanations. This\npaper addresses the problem of interpretability by-design in the audio domain\nby utilizing the recently proposed attention-free focal modulation networks\n(FocalNets). We apply FocalNets to the task of environmental sound\nclassification for the first time and evaluate their interpretability\nproperties on the popular ESC-50 dataset. Our method outperforms a similarly\nsized vision transformer both in terms of accuracy and interpretability.\nFurthermore, it is competitive against PIQ, a method specifically designed for\npost-hoc interpretation in the audio domain.", "published": "2024-02-05 06:20:52", "link": "http://arxiv.org/abs/2402.02754v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Attention Long Short-Term Memory based system for automatic\n  classification of speech intelligibility", "abstract": "Speech intelligibility can be degraded due to multiple factors, such as noisy\nenvironments, technical difficulties or biological conditions. This work is\nfocused on the development of an automatic non-intrusive system for predicting\nthe speech intelligibility level in this latter case. The main contribution of\nour research on this topic is the use of Long Short-Term Memory (LSTM) networks\nwith log-mel spectrograms as input features for this purpose. In addition, this\nLSTM-based system is further enhanced by the incorporation of a simple\nattention mechanism that is able to determine the more relevant frames to this\ntask. The proposed models are evaluated with the UA-Speech database that\ncontains dysarthric speech with different degrees of severity. Results show\nthat the attention LSTM architecture outperforms both, a reference Support\nVector Machine (SVM)-based system with hand-crafted features and a LSTM-based\nsystem with Mean-Pooling.", "published": "2024-02-05 10:03:28", "link": "http://arxiv.org/abs/2402.02850v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Exploring Federated Self-Supervised Learning for General Purpose Audio\n  Understanding", "abstract": "The integration of Federated Learning (FL) and Self-supervised Learning (SSL)\noffers a unique and synergetic combination to exploit the audio data for\ngeneral-purpose audio understanding, without compromising user data privacy.\nHowever, rare efforts have been made to investigate the SSL models in the FL\nregime for general-purpose audio understanding, especially when the training\ndata is generated by large-scale heterogeneous audio sources. In this paper, we\nevaluate the performance of feature-matching and predictive audio-SSL\ntechniques when integrated into large-scale FL settings simulated with\nnon-independently identically distributed (non-iid) data. We propose a novel\nFederated SSL (F-SSL) framework, dubbed FASSL, that enables learning\nintermediate feature representations from large-scale decentralized\nheterogeneous clients, holding unlabelled audio data. Our study has found that\naudio F-SSL approaches perform on par with the centralized audio-SSL approaches\non the audio-retrieval task. Extensive experiments demonstrate the\neffectiveness and significance of FASSL as it assists in obtaining the optimal\nglobal model for state-of-the-art FL aggregation methods.", "published": "2024-02-05 10:57:48", "link": "http://arxiv.org/abs/2402.02889v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Teach Me How to ImproVISe: Co-Designing an Augmented Piano Training\n  System for Improvisation", "abstract": "Improvisation is a vital but often neglected aspect of traditional piano\nteaching. Challenges such as difficulty in assessment and subjectivity have\nhindered its effective instruction. Technological approaches, including\naugmentation, aim to enhance piano instruction, but the specific application of\ndigital augmentation for piano improvisation is under-explored. This paper\noutlines a co-design process developing an Augmented Reality (AR) Piano\nImprovisation Training System, ImproVISe, involving improvisation teachers. The\nprototype, featuring basic improvisation concepts, was created and refined\nthrough expert interaction. Their insights guided the identification of\nobjectives, tools, interaction metaphors, and software features. The findings\noffer design guidelines and recommendations to address challenges in assessing\npiano improvisation in a learning context.", "published": "2024-02-05 13:37:55", "link": "http://arxiv.org/abs/2402.02999v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Avoiding an AI-imposed Taylor's Version of all music history", "abstract": "As future musical AIs adhere closely to human music, they may form their own\nattachments to particular human artists in their databases, and these biases\nmay in the worst case lead to potential existential threats to all musical\nhistory. AI super fans may act to corrupt the historical record and extant\nrecordings in favour of their own preferences, and preservation of the\ndiversity of world music culture may become even more of a pressing issue than\nthe imposition of 12 tone equal temperament or other Western homogenisations.\nWe discuss the technical capability of AI cover software and produce Taylor's\nVersions of famous tracks from Western pop history as provocative examples; the\nquality of these productions does not affect the overall argument (which might\neven see a future AI try to impose the sound of paperclips onto all existing\naudio files, let alone Taylor Swift). We discuss some potential defenses\nagainst the danger of future musical monopolies, whilst analysing the\nfeasibility of a maximal 'Taylor Swiftication' of the complete musical record.", "published": "2024-02-05 11:36:19", "link": "http://arxiv.org/abs/2402.14589v1", "categories": ["cs.CY", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CY"}
