{"title": "Research on Optimizing Real-Time Data Processing in High-Frequency Trading Algorithms using Machine Learning", "abstract": "High-frequency trading (HFT) represents a pivotal and intensely competitive\ndomain within the financial markets. The velocity and accuracy of data\nprocessing exert a direct influence on profitability, underscoring the\nsignificance of this field. The objective of this work is to optimise the\nreal-time processing of data in high-frequency trading algorithms. The dynamic\nfeature selection mechanism is responsible for monitoring and analysing market\ndata in real time through clustering and feature weight analysis, with the\nobjective of automatically selecting the most relevant features. This process\nemploys an adaptive feature extraction method, which enables the system to\nrespond and adjust its feature set in a timely manner when the data input\nchanges, thus ensuring the efficient utilisation of data. The lightweight\nneural networks are designed in a modular fashion, comprising fast\nconvolutional layers and pruning techniques that facilitate the expeditious\ncompletion of data processing and output prediction. In contrast to\nconventional deep learning models, the neural network architecture has been\nspecifically designed to minimise the number of parameters and computational\ncomplexity, thereby markedly reducing the inference time. The experimental\nresults demonstrate that the model is capable of maintaining consistent\nperformance in the context of varying market conditions, thereby illustrating\nits advantages in terms of processing speed and revenue enhancement.", "published": "2024-12-02 02:46:10", "link": "http://arxiv.org/abs/2412.01062v1", "categories": ["cs.LG", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "Revisiting Absence withSymptoms that *T* Show up Decades Later to\n  Recover Empty Categories", "abstract": "This paper explores null elements in English, Chinese, and Korean Penn\ntreebanks. Null elements contain important syntactic and semantic information,\nyet they have typically been treated as entities to be removed during language\nprocessing tasks, particularly in constituency parsing. Thus, we work towards\nthe removal and, in particular, the restoration of null elements in parse\ntrees. We focus on expanding a rule-based approach utilizing linguistic context\ninformation to Chinese, as rule based approaches have historically only been\napplied to English. We also worked to conduct neural experiments with a\nlanguage agnostic sequence-to-sequence model to recover null elements for\nEnglish (PTB), Chinese (CTB) and Korean (KTB). To the best of the authors'\nknowledge, null elements in three different languages have been explored and\ncompared for the first time. In expanding a rule based approach to Chinese, we\nachieved an overall F1 score of 80.00, which is comparable to past results in\nthe CTB. In our neural experiments we achieved F1 scores up to 90.94, 85.38 and\n88.79 for English, Chinese, and Korean respectively with functional labels.", "published": "2024-12-02 04:30:09", "link": "http://arxiv.org/abs/2412.01109v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Think-to-Talk or Talk-to-Think? When LLMs Come Up with an Answer in\n  Multi-Step Reasoning", "abstract": "This study investigates the internal reasoning mechanism of language models\nduring symbolic multi-step reasoning, motivated by the question of whether\nchain-of-thought (CoT) outputs are faithful to the model's internals.\nSpecifically, we inspect when they internally determine their answers,\nparticularly before or after CoT begins, to determine whether models follow a\npost-hoc \"think-to-talk\" mode or a step-by-step \"talk-to-think\" mode of\nexplanation. Through causal probing experiments in controlled arithmetic\nreasoning tasks, we found systematic internal reasoning patterns across models;\nfor example, simple subproblems are solved before CoT begins, and more\ncomplicated multi-hop calculations are performed during CoT.", "published": "2024-12-02 04:35:54", "link": "http://arxiv.org/abs/2412.01113v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Function-Calling Capabilities in LLMs: Strategies for Prompt\n  Formats, Data Integration, and Multilingual Translation", "abstract": "Large language models (LLMs) have significantly advanced autonomous agents,\nparticularly in zero-shot tool usage, also known as function calling. This\nresearch delves into enhancing the function-calling capabilities of LLMs by\nexploring different approaches, including prompt formats for integrating\nfunction descriptions, blending function-calling and instruction-following\ndata, introducing a novel Decision Token for conditional prompts, leveraging\nchain-of-thought reasoning, and overcoming multilingual challenges with a\ntranslation pipeline. Our key findings and contributions are as follows: (1)\nInstruction-following data improves both function-calling accuracy and\nrelevance detection. (2) The use of the newly proposed Decision Token, combined\nwith synthetic non-function-call data, enhances relevance detection. (3) A\ntailored translation pipeline effectively overcomes multilingual limitations,\ndemonstrating significant improvements in Traditional Chinese. These insights\nhighlight the potential for improved function-calling capabilities and\nmultilingual applications in LLMs.", "published": "2024-12-02 05:10:41", "link": "http://arxiv.org/abs/2412.01130v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Evaluation of Semantic Relation Knowledge of Pretrained\n  Language Models and Humans", "abstract": "Recently, much work has concerned itself with the enigma of what exactly PLMs\n(pretrained language models) learn about different aspects of language, and how\nthey learn it. One stream of this type of research investigates the knowledge\nthat PLMs have about semantic relations. However, many aspects of semantic\nrelations were left unexplored. Only one relation was considered, namely\nhypernymy. Furthermore, previous work did not measure humans' performance on\nthe same task as that solved by the PLMs. This means that at this point in\ntime, there is only an incomplete view of models' semantic relation knowledge.\nTo address this gap, we introduce a comprehensive evaluation framework covering\nfive relations beyond hypernymy, namely hyponymy, holonymy, meronymy, antonymy,\nand synonymy. We use six metrics (two newly introduced here) for recently\nuntreated aspects of semantic relation knowledge, namely soundness,\ncompleteness, symmetry, asymmetry, prototypicality, and distinguishability and\nfairly compare humans and models on the same task. Our extensive experiments\ninvolve 16 PLMs, eight masked and eight causal language models. Up to now only\nmasked language models had been tested although causal and masked language\nmodels treat context differently. Our results reveal a significant knowledge\ngap between humans and models for almost all semantic relations. Antonymy is\nthe outlier relation where all models perform reasonably well. In general,\nmasked language models perform significantly better than causal language\nmodels. Nonetheless, both masked and causal language models are likely to\nconfuse non-antonymy relations with antonymy.", "published": "2024-12-02 05:11:34", "link": "http://arxiv.org/abs/2412.01131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SailCompass: Towards Reproducible and Robust Evaluation for Southeast\n  Asian Languages", "abstract": "In this paper, we introduce SailCompass, a reproducible and robust evaluation\nbenchmark for assessing Large Language Models (LLMs) on Southeast Asian\nLanguages (SEA). SailCompass encompasses three main SEA languages, eight\nprimary tasks including 14 datasets covering three task types (generation,\nmultiple-choice questions, and classification). To improve the robustness of\nthe evaluation approach, we explore different prompt configurations for\nmultiple-choice questions and leverage calibrations to improve the faithfulness\nof classification tasks. With SailCompass, we derive the following findings:\n(1) SEA-specialized LLMs still outperform general LLMs, although the gap has\nnarrowed; (2) A balanced language distribution is important for developing\nbetter SEA-specialized LLMs; (3) Advanced prompting techniques (e.g.,\ncalibration, perplexity-based ranking) are necessary to better utilize LLMs.\nAll datasets and evaluation scripts are public.", "published": "2024-12-02 06:42:51", "link": "http://arxiv.org/abs/2412.01186v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MiningGPT -- A Domain-Specific Large Language Model for the Mining\n  Industry", "abstract": "Recent advancements of generative LLMs (Large Language Models) have exhibited\nhuman-like language capabilities but have shown a lack of domain-specific\nunderstanding. Therefore, the research community has started the development of\ndomain-specific LLMs for many domains. In this work we focus on discussing how\nto build mining domain-specific LLMs, as the global mining industry contributes\nsignificantly to the worldwide economy. We report on MiningGPT, a mining\ndomain-specific instruction-following 7B parameter LLM model which showed a\n14\\% higher mining domain knowledge test score as compared to its parent model\nMistral 7B instruct.", "published": "2024-12-02 06:47:59", "link": "http://arxiv.org/abs/2412.01189v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GraphOTTER: Evolving LLM-based Graph Reasoning for Complex Table\n  Question Answering", "abstract": "Complex Table Question Answering involves providing accurate answers to\nspecific questions based on intricate tables that exhibit complex layouts and\nflexible header locations. Despite considerable progress having been made in\nthe LLM era, the reasoning processes of existing methods are often implicit,\nfeeding the entire table into prompts, making it difficult to effectively\nfilter out irrelevant information in the table. To this end, we propose\nGraphOTTER that explicitly establishes the reasoning process to pinpoint the\ncorrect answers. In particular, GraphOTTER leverages a graph-based\nrepresentation, transforming the complex table into an undirected graph. It\nthen conducts step-by-step reasoning on the graph, with each step guided by a\nset of pre-defined intermediate reasoning actions. As such, it constructs a\nclear reasoning path and effectively identifies the answer to a given question.\nComprehensive experiments on two benchmark datasets and two LLM backbones\ndemonstrate the effectiveness of GraphOTTER. Further analysis indicates that\nits success may be attributed to the ability to efficiently filter out\nirrelevant information, thereby focusing the reasoning process on the most\npertinent data. Our code and experimental datasets are available at\n\\url{https://github.com/JDing0521/GraphOTTER}.", "published": "2024-12-02 07:49:23", "link": "http://arxiv.org/abs/2412.01230v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Uncertainty-Aware Learning for Multimodal Aspect-based Sentiment\n  Analysis", "abstract": "As a fine-grained task, multimodal aspect-based sentiment analysis (MABSA)\nmainly focuses on identifying aspect-level sentiment information in the\ntext-image pair. However, we observe that it is difficult to recognize the\nsentiment of aspects in low-quality samples, such as those with low-resolution\nimages that tend to contain noise. And in the real world, the quality of data\nusually varies for different samples, such noise is called data uncertainty.\nBut previous works for the MABSA task treat different quality samples with the\nsame importance and ignored the influence of data uncertainty. In this paper,\nwe propose a novel data uncertainty-aware multimodal aspect-based sentiment\nanalysis approach, UA-MABSA, which weighted the loss of different samples by\nthe data quality and difficulty. UA-MABSA adopts a novel quality assessment\nstrategy that takes into account both the image quality and the aspect-based\ncross-modal relevance, thus enabling the model to pay more attention to\nhigh-quality and challenging samples. Extensive experiments show that our\nmethod achieves state-of-the-art (SOTA) performance on the Twitter-2015\ndataset. Further analysis demonstrates the effectiveness of the quality\nassessment strategy.", "published": "2024-12-02 08:13:40", "link": "http://arxiv.org/abs/2412.01249v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Shadow of the (Hierarchical) Tree: Reconciling Symbolic and Predictive\n  Components of the Neural Code for Syntax", "abstract": "Natural language syntax can serve as a major test for how to integrate two\ninfamously distinct frameworks: symbolic representations and connectionist\nneural networks. Building on a recent neurocomputational architecture for\nsyntax (ROSE), I discuss the prospects of reconciling the neural code for\nhierarchical 'vertical' syntax with linear and predictive 'horizontal'\nprocesses via a hybrid neurosymbolic model. I argue that the former can be\naccounted for via the higher levels of ROSE in terms of vertical phrase\nstructure representations, while the latter can explain horizontal forms of\nlinguistic information via the tuning of the lower levels to statistical and\nperceptual inferences. One prediction of this is that artificial language\nmodels will contribute to the cognitive neuroscience of horizontal\nmorphosyntax, but much less so to hierarchically compositional structures. I\nclaim that this perspective helps resolve many current tensions in the\nliterature. Options for integrating these two neural codes are discussed, with\nparticular emphasis on how predictive coding mechanisms can serve as interfaces\nbetween symbolic oscillatory phase codes and population codes for the\nstatistics of linearized aspects of syntax. Lastly, I provide a neurosymbolic\nmathematical model for how to inject symbolic representations into a neural\nregime encoding lexico-semantic statistical features.", "published": "2024-12-02 08:44:16", "link": "http://arxiv.org/abs/2412.01276v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SiTSE: Sinhala Text Simplification Dataset and Evaluation", "abstract": "Text Simplification is a task that has been minimally explored for\nlow-resource languages. Consequently, there are only a few manually curated\ndatasets. In this paper, we present a human curated sentence-level text\nsimplification dataset for the Sinhala language. Our evaluation dataset\ncontains 1,000 complex sentences and corresponding 3,000 simplified sentences\nproduced by three different human annotators. We model the text simplification\ntask as a zero-shot and zero resource sequence-to-sequence (seq-seq) task on\nthe multilingual language models mT5 and mBART. We exploit auxiliary data from\nrelated seq-seq tasks and explore the possibility of using intermediate task\ntransfer learning (ITTL). Our analysis shows that ITTL outperforms the\npreviously proposed zero-resource methods for text simplification. Our findings\nalso highlight the challenges in evaluating text simplification systems, and\nsupport the calls for improved metrics for measuring the quality of automated\ntext simplification systems that would suit low-resource languages as well. Our\ncode and data are publicly available:\nhttps://github.com/brainsharks-fyp17/Sinhala-Text-Simplification-Dataset-and-Evaluation", "published": "2024-12-02 09:08:06", "link": "http://arxiv.org/abs/2412.01293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A 2-step Framework for Automated Literary Translation Evaluation: Its\n  Promises and Pitfalls", "abstract": "In this work, we propose and evaluate the feasibility of a two-stage pipeline\nto evaluate literary machine translation, in a fine-grained manner, from\nEnglish to Korean. The results show that our framework provides fine-grained,\ninterpretable metrics suited for literary translation and obtains a higher\ncorrelation with human judgment than traditional machine translation metrics.\nNonetheless, it still fails to match inter-human agreement, especially in\nmetrics like Korean Honorifics. We also observe that LLMs tend to favor\ntranslations generated by other LLMs, and we highlight the necessity of\ndeveloping more sophisticated evaluation methods to ensure accurate and\nculturally sensitive machine translation of literary works.", "published": "2024-12-02 10:07:01", "link": "http://arxiv.org/abs/2412.01340v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLASSLA-Express: a Train of CLARIN.SI Workshops on Language Resources\n  and Tools with Easily Expanding Route", "abstract": "This paper introduces the CLASSLA-Express workshop series as an innovative\napproach to disseminating linguistic resources and infrastructure provided by\nthe CLASSLA Knowledge Centre for South Slavic languages and the Slovenian\nCLARIN.SI infrastructure. The workshop series employs two key strategies: (1)\nconducting workshops directly in countries with interested audiences, and (2)\ndesigning the series for easy expansion to new venues. The first iteration of\nthe CLASSLA-Express workshop series encompasses 6 workshops in 5 countries. Its\ngoal is to share knowledge on the use of corpus querying tools, as well as the\nrecently-released CLASSLA-web corpora - the largest general corpora for South\nSlavic languages. In the paper, we present the design of the workshop series,\nits current scope and the effortless extensions of the workshop to new venues\nthat are already in sight.", "published": "2024-12-02 11:15:10", "link": "http://arxiv.org/abs/2412.01386v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Impromptu Cybercrime Euphemism Detection", "abstract": "Detecting euphemisms is essential for content security on various social\nmedia platforms, but existing methods designed for detecting euphemisms are\nineffective in impromptu euphemisms. In this work, we make a first attempt to\nan exploration of impromptu euphemism detection and introduce the Impromptu\nCybercrime Euphemisms Detection (ICED) dataset. Moreover, we propose a\ndetection framework tailored to this problem, which employs context\naugmentation modeling and multi-round iterative training. Our detection\nframework mainly consists of a coarse-grained and a fine-grained classification\nmodel. The coarse-grained classification model removes most of the harmless\ncontent in the corpus to be detected. The fine-grained model, impromptu\neuphemisms detector, integrates context augmentation and multi-round iterations\ntraining to better predicts the actual meaning of a masked token. In addition,\nwe leverage ChatGPT to evaluate the mode's capability. Experimental results\ndemonstrate that our approach achieves a remarkable 76-fold improvement\ncompared to the previous state-of-the-art euphemism detector.", "published": "2024-12-02 11:56:06", "link": "http://arxiv.org/abs/2412.01413v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Top-down Graph-based Tool for Modeling Classical Semantic Maps: A\n  Crosslinguistic Case Study of Supplementary Adverbs", "abstract": "Semantic map models (SMMs) construct a network-like conceptual space from\ncross-linguistic instances or forms, based on the connectivity hypothesis. This\napproach has been widely used to represent similarity and entailment\nrelationships in cross-linguistic concept comparisons. However, most SMMs are\nmanually built by human experts using bottom-up procedures, which are often\nlabor-intensive and time-consuming. In this paper, we propose a novel\ngraph-based algorithm that automatically generates conceptual spaces and SMMs\nin a top-down manner. The algorithm begins by creating a dense graph, which is\nsubsequently pruned into maximum spanning trees, selected according to metrics\nwe propose. These evaluation metrics include both intrinsic and extrinsic\nmeasures, considering factors such as network structure and the trade-off\nbetween precision and coverage. A case study on cross-linguistic supplementary\nadverbs demonstrates the effectiveness and efficiency of our model compared to\nhuman annotations and other automated methods. The tool is available at\nhttps://github.com/RyanLiut/SemanticMapModel.", "published": "2024-12-02 12:06:41", "link": "http://arxiv.org/abs/2412.01423v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Early Exit Is a Natural Capability in Transformer-based Models: An\n  Empirical Study on Early Exit without Joint Optimization", "abstract": "Large language models (LLMs) exhibit exceptional performance across various\ndownstream tasks. However, they encounter limitations due to slow inference\nspeeds stemming from their extensive parameters. The early exit (EE) is an\napproach that aims to accelerate auto-regressive decoding. EE generates outputs\nfrom intermediate layers instead of using the whole model, which offers a\npromising solution to this challenge. However, additional output layers and\njoint optimization used in conventional EE hinder the application of EE in\nLLMs.\n  In this paper, we explore the possibility of LLMs EE without additional\noutput layers and joint optimization. Our findings indicate that EE is a\nnatural capability within transformer-based models. While joint optimization\ndoes not give model EE capability, it must be employed to address challenges by\nimproving the accuracy of locating the optimal EE layer through gating\nfunctions. Additionally, our study reveals patterns in EE behavior from a\nsub-word perspective based on the LLaMA model and the potential possibility for\nEE based on sub-layers.", "published": "2024-12-02 12:46:34", "link": "http://arxiv.org/abs/2412.01455v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Headline-Guided Extractive Summarization for Thai News Articles", "abstract": "Text summarization is a process of condensing lengthy texts while preserving\ntheir essential information. Previous studies have predominantly focused on\nhigh-resource languages, while low-resource languages like Thai have received\nless attention. Furthermore, earlier extractive summarization models for Thai\ntexts have primarily relied on the article's body, without considering the\nheadline. This omission can result in the exclusion of key sentences from the\nsummary. To address these limitations, we propose CHIMA, an extractive\nsummarization model that incorporates the contextual information of the\nheadline for Thai news articles. Our model utilizes a pre-trained language\nmodel to capture complex language semantics and assigns a probability to each\nsentence to be included in the summary. By leveraging the headline to guide\nsentence selection, CHIMA enhances the model's ability to recover important\nsentences and discount irrelevant ones. Additionally, we introduce two\nstrategies for aggregating headline-body similarities, simple average and\nharmonic mean, providing flexibility in sentence selection to accommodate\nvarying writing styles. Experiments on publicly available Thai news datasets\ndemonstrate that CHIMA outperforms baseline models across ROUGE, BLEU, and F1\nscores. These results highlight the effectiveness of incorporating the\nheadline-body similarities as model guidance. The results also indicate an\nenhancement in the model's ability to recall critical sentences, even those\nscattered throughout the middle or end of the article. With this potential,\nheadline-guided extractive summarization offers a promising approach to improve\nthe quality and relevance of summaries for Thai news articles.", "published": "2024-12-02 15:43:10", "link": "http://arxiv.org/abs/2412.01624v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can We Afford The Perfect Prompt? Balancing Cost and Accuracy with the\n  Economical Prompting Index", "abstract": "As prompt engineering research rapidly evolves, evaluations beyond accuracy\nare crucial for developing cost-effective techniques. We present the Economical\nPrompting Index (EPI), a novel metric that combines accuracy scores with token\nconsumption, adjusted by a user-specified cost concern level to reflect\ndifferent resource constraints. Our study examines 6 advanced prompting\ntechniques, including Chain-of-Thought, Self-Consistency, and Tree of Thoughts,\nacross 10 widely-used language models and 4 diverse datasets. We demonstrate\nthat approaches such as Self-Consistency often provide statistically\ninsignificant gains while becoming cost-prohibitive. For example, on\nhigh-performing models like Claude 3.5 Sonnet, the EPI of simpler techniques\nlike Chain-of-Thought (0.72) surpasses more complex methods like\nSelf-Consistency (0.64) at slight cost concern levels. Our findings suggest a\nreevaluation of complex prompting strategies in resource-constrained scenarios,\npotentially reshaping future research priorities and improving\ncost-effectiveness for end-users.", "published": "2024-12-02 16:34:18", "link": "http://arxiv.org/abs/2412.01690v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Resource Efficient and Interpretable Bias Mitigation in Large\n  Language Models", "abstract": "Although large language models (LLMs) have demonstrated their effectiveness\nin a wide range of applications, they have also been observed to perpetuate\nunwanted biases present in the training data, potentially leading to harm for\nmarginalized communities. In this paper, we mitigate bias by leveraging small\nbiased and anti-biased expert models to obtain a debiasing signal that will be\nadded to the LLM output at decoding-time. This approach combines resource\nefficiency with interpretability and can be optimized for mitigating specific\ntypes of bias, depending on the target use case. Experiments on mitigating\ngender, race, and religion biases show a reduction in bias on several local and\nglobal bias metrics while preserving language model performance.", "published": "2024-12-02 16:56:08", "link": "http://arxiv.org/abs/2412.01711v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SAUP: Situation Awareness Uncertainty Propagation on LLM Agent", "abstract": "Large language models (LLMs) integrated into multistep agent systems enable\ncomplex decision-making processes across various applications. However, their\noutputs often lack reliability, making uncertainty estimation crucial. Existing\nuncertainty estimation methods primarily focus on final-step outputs, which\nfail to account for cumulative uncertainty over the multistep decision-making\nprocess and the dynamic interactions between agents and their environments. To\naddress these limitations, we propose SAUP (Situation Awareness Uncertainty\nPropagation), a novel framework that propagates uncertainty through each step\nof an LLM-based agent's reasoning process. SAUP incorporates situational\nawareness by assigning situational weights to each step's uncertainty during\nthe propagation. Our method, compatible with various one-step uncertainty\nestimation techniques, provides a comprehensive and accurate uncertainty\nmeasure. Extensive experiments on benchmark datasets demonstrate that SAUP\nsignificantly outperforms existing state-of-the-art methods, achieving up to\n20% improvement in AUROC.", "published": "2024-12-02 01:31:13", "link": "http://arxiv.org/abs/2412.01033v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automated Extraction of Acronym-Expansion Pairs from Scientific Papers", "abstract": "This project addresses challenges posed by the widespread use of\nabbreviations and acronyms in digital texts. We propose a novel method that\ncombines document preprocessing, regular expressions, and a large language\nmodel to identify abbreviations and map them to their corresponding expansions.\nThe regular expressions alone are often insufficient to extract expansions, at\nwhich point our approach leverages GPT-4 to analyze the text surrounding the\nacronyms. By limiting the analysis to only a small portion of the surrounding\ntext, we mitigate the risk of obtaining incorrect or multiple expansions for an\nacronym. There are several known challenges in processing text with acronyms,\nincluding polysemous acronyms, non-local and ambiguous acronyms. Our approach\nenhances the precision and efficiency of NLP techniques by addressing these\nissues with automated acronym identification and disambiguation. This study\nhighlights the challenges of working with PDF files and the importance of\ndocument preprocessing. Furthermore, the results of this work show that neither\nregular expressions nor GPT-4 alone can perform well. Regular expressions are\nsuitable for identifying acronyms but have limitations in finding their\nexpansions within the paper due to a variety of formats used for expressing\nacronym-expansion pairs and the tendency of authors to omit expansions within\nthe text. GPT-4, on the other hand, is an excellent tool for obtaining\nexpansions but struggles with correctly identifying all relevant acronyms.\nAdditionally, GPT-4 poses challenges due to its probabilistic nature, which may\nlead to slightly different results for the same input. Our algorithm employs\npreprocessing to eliminate irrelevant information from the text, regular\nexpressions for identifying acronyms, and a large language model to help find\nacronym expansions to provide the most accurate and consistent results.", "published": "2024-12-02 04:05:49", "link": "http://arxiv.org/abs/2412.01093v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Indexing Economic Fluctuation Narratives from Keiki Watchers Survey", "abstract": "In this paper, we design indices of economic fluctuation narratives derived\nfrom economic surveys. Companies, governments, and investors rely on key\nmetrics like GDP and industrial production indices to predict economic trends.\nHowever, they have yet to effectively leverage the wealth of information\ncontained in economic text, such as causal relationships, in their economic\nforecasting. Therefore, we design indices of economic fluctuation from economic\nsurveys by using our previously proposed narrative framework. From the\nevaluation results, it is observed that the proposed indices had a stronger\ncorrelation with cumulative lagging diffusion index than other types of\ndiffusion indices.", "published": "2024-12-02 08:32:02", "link": "http://arxiv.org/abs/2412.01265v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MuLan: Adapting Multilingual Diffusion Models for Hundreds of Languages\n  with Negligible Cost", "abstract": "In this work, we explore a cost-effective framework for multilingual image\ngeneration. We find that, unlike models tuned on high-quality images with\nmultilingual annotations, leveraging text encoders pre-trained on widely\navailable, noisy Internet image-text pairs significantly enhances data\nefficiency in text-to-image (T2I) generation across multiple languages. Based\non this insight, we introduce MuLan, Multi-Language adapter, a lightweight\nlanguage adapter with fewer than 20M parameters, trained alongside a frozen\ntext encoder and image diffusion model. Compared to previous multilingual T2I\nmodels, this framework offers: (1) Cost efficiency. Using readily accessible\nEnglish data and off-the-shelf multilingual text encoders minimizes the\ntraining cost; (2) High performance. Achieving comparable generation\ncapabilities in over 110 languages with CLIP similarity scores nearly matching\nthose in English (38.61 for English vs. 37.61 for other languages); and (3)\nBroad applicability. Seamlessly integrating with compatible community tools\nlike LoRA, LCM, ControlNet, and IP-Adapter, expanding its potential use cases.", "published": "2024-12-02 08:38:19", "link": "http://arxiv.org/abs/2412.01271v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The \"LLM World of Words\" English free association norms generated by\n  large language models", "abstract": "Free associations have been extensively used in cognitive psychology and\nlinguistics for studying how conceptual knowledge is organized. Recently, the\npotential of applying a similar approach for investigating the knowledge\nencoded in LLMs has emerged, specifically as a method for investigating LLM\nbiases. However, the absence of large-scale LLM-generated free association\nnorms that are comparable with human-generated norms is an obstacle to this new\nresearch direction. To address this limitation, we create a new dataset of\nLLM-generated free association norms modeled after the \"Small World of Words\"\n(SWOW) human-generated norms consisting of approximately 12,000 cue words. We\nprompt three LLMs, namely Mistral, Llama3, and Haiku, with the same cues as\nthose in the SWOW norms to generate three novel comparable datasets, the \"LLM\nWorld of Words\" (LWOW). Using both SWOW and LWOW norms, we construct cognitive\nnetwork models of semantic memory that represent the conceptual knowledge\npossessed by humans and LLMs. We demonstrate how these datasets can be used for\ninvestigating implicit biases in humans and LLMs, such as the harmful gender\nstereotypes that are prevalent both in society and LLM outputs.", "published": "2024-12-02 09:54:14", "link": "http://arxiv.org/abs/2412.01330v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Long-Term Prediction of Type 2 Diabetes Microvascular\n  Complications", "abstract": "Electronic healthcare records (EHR) contain a huge wealth of data that can\nsupport the prediction of clinical outcomes. EHR data is often stored and\nanalysed using clinical codes (ICD10, SNOMED), however these can differ across\nregistries and healthcare providers. Integrating data across systems involves\nmapping between different clinical ontologies requiring domain expertise, and\nat times resulting in data loss. To overcome this, code-agnostic models have\nbeen proposed. We assess the effectiveness of a code-agnostic representation\napproach on the task of long-term microvascular complication prediction for\nindividuals living with Type 2 Diabetes. Our method encodes individual EHRs as\ntext using fine-tuned, pretrained clinical language models. Leveraging\nlarge-scale EHR data from the UK, we employ a multi-label approach to\nsimultaneously predict the risk of microvascular complications across 1-, 5-,\nand 10-year windows. We demonstrate that a code-agnostic approach outperforms a\ncode-based model and illustrate that performance is better with longer\nprediction windows but is biased to the first occurring complication. Overall,\nwe highlight that context length is vitally important for model performance.\nThis study highlights the possibility of including data from across different\nclinical ontologies and is a starting point for generalisable clinical models.", "published": "2024-12-02 09:54:51", "link": "http://arxiv.org/abs/2412.01331v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Understanding the World's Museums through Vision-Language Reasoning", "abstract": "Museums serve as vital repositories of cultural heritage and historical\nartifacts spanning diverse epochs, civilizations, and regions, preserving\nwell-documented collections. Data reveal key attributes such as age, origin,\nmaterial, and cultural significance. Understanding museum exhibits from their\nimages requires reasoning beyond visual features. In this work, we facilitate\nsuch reasoning by (a) collecting and curating a large-scale dataset of 65M\nimages and 200M question-answer pairs in the standard museum catalog format for\nexhibits from all around the world; (b) training large vision-language models\non the collected dataset; (c) benchmarking their ability on five visual\nquestion answering tasks. The complete dataset is labeled by museum experts,\nensuring the quality as well as the practical significance of the labels. We\ntrain two VLMs from different categories: the BLIP model, with vision-language\naligned embeddings, but lacking the expressive power of large language models,\nand the LLaVA model, a powerful instruction-tuned LLM enriched with\nvision-language reasoning capabilities. Through exhaustive experiments, we\nprovide several insights on the complex and fine-grained understanding of\nmuseum exhibits. In particular, we show that some questions whose answers can\noften be derived directly from visual features are well answered by both types\nof models. On the other hand, questions that require the grounding of the\nvisual features in repositories of human knowledge are better answered by the\nlarge vision-language models, thus demonstrating their superior capacity to\nperform the desired reasoning. Find our dataset, benchmarks, and source code\nat: https://github.com/insait-institute/Museum-65", "published": "2024-12-02 10:54:31", "link": "http://arxiv.org/abs/2412.01370v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Adapting Large Language Models to Log Analysis with Interpretable Domain\n  Knowledge", "abstract": "The increasing complexity of computer systems necessitates innovative\napproaches to fault and error management, going beyond traditional manual log\nanalysis. While existing solutions using large language models (LLMs) show\npromise, they are limited by a gap between natural and domain-specific\nlanguages, which restricts their effectiveness in real-world applications. Our\napproach addresses these limitations by integrating interpretable domain\nknowledge into open-source LLMs through continual pre-training (CPT), enhancing\nperformance on log tasks while retaining natural language processing\ncapabilities. We created a comprehensive dataset, NLPLog, with over 250,000\nquestion-answer pairs to facilitate this integration. Our model, SuperLog,\ntrained with this dataset, achieves the best performance across four log\nanalysis tasks, surpassing the second-best model by an average of 12.01%. Our\ncontributions include a novel CPT paradigm that significantly improves model\nperformance, the development of SuperLog with state-of-the-art results, and the\nrelease of a large-scale dataset to support further research in this domain.", "published": "2024-12-02 11:05:31", "link": "http://arxiv.org/abs/2412.01377v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Efficient LLM Inference using Dynamic Input Pruning and Cache-Aware\n  Masking", "abstract": "While mobile devices provide ever more compute power, improvements in DRAM\nbandwidth are much slower. This is unfortunate for large language model (LLM)\ntoken generation, which is heavily memory-bound. Previous work has proposed to\nleverage natural dynamic activation sparsity in ReLU-activated LLMs to reduce\neffective DRAM bandwidth per token. However, more recent LLMs use SwiGLU\ninstead of ReLU, which results in little inherent sparsity. While SwiGLU\nactivations can be pruned based on magnitude, the resulting sparsity patterns\nare difficult to predict, rendering previous approaches ineffective. To\ncircumvent this issue, our work introduces Dynamic Input Pruning (DIP): a\npredictor-free dynamic sparsification approach, which preserves accuracy with\nminimal fine-tuning. DIP can further use lightweight LoRA adapters to regain\nsome performance lost during sparsification. Lastly, we describe a novel\ncache-aware masking strategy, which considers the cache state and activation\nmagnitude to further increase cache hit rate, improving LLM token rate on\nmobile devices. DIP outperforms other methods in terms of accuracy, memory and\nthroughput trade-offs across simulated hardware settings. On Phi-3-Medium, DIP\nachieves a 46\\% reduction in memory and 40\\% increase in throughput with $<$\n0.1 loss in perplexity when compared to streaming the dense model from Flash.\nThe open source code for HW simulator, methods, and experiments in this paper\nis available at https://github.com/Qualcomm-AI-research/dynamic-sparsity .", "published": "2024-12-02 11:07:51", "link": "http://arxiv.org/abs/2412.01380v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Towards Cross-Lingual Audio Abuse Detection in Low-Resource Settings\n  with Few-Shot Learning", "abstract": "Online abusive content detection, particularly in low-resource settings and\nwithin the audio modality, remains underexplored. We investigate the potential\nof pre-trained audio representations for detecting abusive language in\nlow-resource languages, in this case, in Indian languages using Few Shot\nLearning (FSL). Leveraging powerful representations from models such as Wav2Vec\nand Whisper, we explore cross-lingual abuse detection using the ADIMA dataset\nwith FSL. Our approach integrates these representations within the\nModel-Agnostic Meta-Learning (MAML) framework to classify abusive language in\n10 languages. We experiment with various shot sizes (50-200) evaluating the\nimpact of limited data on performance. Additionally, a feature visualization\nstudy was conducted to better understand model behaviour. This study highlights\nthe generalization ability of pre-trained models in low-resource scenarios and\noffers valuable insights into detecting abusive language in multilingual\ncontexts.", "published": "2024-12-02 11:51:19", "link": "http://arxiv.org/abs/2412.01408v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PLD+: Accelerating LLM inference by leveraging Language Model Artifacts", "abstract": "To reduce the latency associated with autoretrogressive LLM inference,\nspeculative decoding has emerged as a novel decoding paradigm, where future\ntokens are drafted and verified in parallel. However, the practical deployment\nof speculative decoding is hindered by its requirements for additional\ncomputational resources and fine-tuning, which limits its out-of-the-box\nusability. To address these challenges, we present PLD+, a suite of novel\nalgorithms developed to accelerate the inference process of LLMs, particularly\nfor input-guided tasks. These tasks, which include code editing, text editing,\nsummarization, etc., often feature outputs with substantial overlap with their\ninputs-an attribute PLD+ is designed to exploit. PLD+ also leverages the\nartifacts (attention and hidden states) generated during inference to\naccelerate inference speed. We test our approach on five input-guided tasks and\nthrough extensive experiments we find that PLD+ outperforms all tuning-free\napproaches. In the greedy setting, it even outperforms the state-of-the-art\ntuning-dependent approach EAGLE on four of the tasks. (by a margin of upto 2.31\nin terms of avg. speedup). Our approach is tuning free, does not require any\nadditional compute and can easily be used for accelerating inference of any\nLLM.", "published": "2024-12-02 12:36:27", "link": "http://arxiv.org/abs/2412.01447v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scaling Law for Language Models Training Considering Batch Size", "abstract": "Large language models (LLMs) have made remarkable advances in recent years,\nwith scaling laws playing a critical role in this rapid progress. In this\npaper, we empirically investigate how a critical hyper-parameter, i.e., the\nglobal batch size, influences the LLM training prdocess. We begin by training\nlanguage models ranging from 125 million to 2.6 billion parameters, using up to\n300 billion high-quality tokens. Through these experiments, we establish a\nbasic scaling law on model size and training data amount. We then examine how\nvarying batch sizes and learning rates affect the convergence and\ngeneralization of these models. Our analysis yields batch size scaling laws\nunder two different cases: with a fixed compute budget, and with a fixed amount\nof training data. Extrapolation experiments on models of increasing sizes\nvalidate our predicted laws, which provides guidance for optimizing LLM\ntraining strategies under specific resource constraints.", "published": "2024-12-02 13:58:35", "link": "http://arxiv.org/abs/2412.01505v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Medchain: Bridging the Gap Between LLM Agents and Clinical Practice\n  through Interactive Sequential Benchmarking", "abstract": "Clinical decision making (CDM) is a complex, dynamic process crucial to\nhealthcare delivery, yet it remains a significant challenge for artificial\nintelligence systems. While Large Language Model (LLM)-based agents have been\ntested on general medical knowledge using licensing exams and knowledge\nquestion-answering tasks, their performance in the CDM in real-world scenarios\nis limited due to the lack of comprehensive testing datasets that mirror actual\nmedical practice. To address this gap, we present MedChain, a dataset of 12,163\nclinical cases that covers five key stages of clinical workflow. MedChain\ndistinguishes itself from existing benchmarks with three key features of\nreal-world clinical practice: personalization, interactivity, and\nsequentiality. Further, to tackle real-world CDM challenges, we also propose\nMedChain-Agent, an AI system that integrates a feedback mechanism and a\nMCase-RAG module to learn from previous cases and adapt its responses.\nMedChain-Agent demonstrates remarkable adaptability in gathering information\ndynamically and handling sequential clinical tasks, significantly outperforming\nexisting approaches. The relevant dataset and code will be released upon\nacceptance of this paper.", "published": "2024-12-02 15:25:02", "link": "http://arxiv.org/abs/2412.01605v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NYT-Connections: A Deceptively Simple Text Classification Task that\n  Stumps System-1 Thinkers", "abstract": "Large Language Models (LLMs) have shown impressive performance on various\nbenchmarks, yet their ability to engage in deliberate reasoning remains\nquestionable. We present NYT-Connections, a collection of 358 simple word\nclassification puzzles derived from the New York Times Connections game. This\nbenchmark is designed to penalize quick, intuitive \"System 1\" thinking,\nisolating fundamental reasoning skills. We evaluated six recent LLMs, a simple\nmachine learning heuristic, and humans across three configurations:\nsingle-attempt, multiple attempts without hints, and multiple attempts with\ncontextual hints. Our findings reveal a significant performance gap: even\ntop-performing LLMs like GPT-4 fall short of human performance by nearly 30%.\nNotably, advanced prompting techniques such as Chain-of-Thought and\nSelf-Consistency show diminishing returns as task difficulty increases.\nNYT-Connections uniquely combines linguistic isolation, resistance to intuitive\nshortcuts, and regular updates to mitigate data leakage, offering a novel tool\nfor assessing LLM reasoning capabilities.", "published": "2024-12-02 15:41:47", "link": "http://arxiv.org/abs/2412.01621v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WikiHint: A Human-Annotated Dataset for Hint Ranking and Generation", "abstract": "The use of Large Language Models (LLMs) has increased significantly with\nusers frequently asking questions to chatbots. In the time when information is\nreadily accessible, it is crucial to stimulate and preserve human cognitive\nabilities and maintain strong reasoning skills. This paper addresses such\nchallenges by promoting the use of hints as an alternative or a supplement to\ndirect answers. We first introduce a manually constructed hint dataset,\nWikiHint, which is based on Wikipedia and includes 5,000 hints created for\n1,000 questions. We then finetune open-source LLMs such as LLaMA-3.1 for hint\ngeneration in answer-aware and answeragnostic contexts. We assess the\neffectiveness of the hints with human participants who answer questions with\nand without the aid of hints. Additionally, we introduce a lightweight\nevaluation method, HintRank, to evaluate and rank hints in both answeraware and\nanswer-agnostic settings. Our findings show that (a) the dataset helps generate\nmore effective hints, (b) including answer information along with questions\ngenerally improves quality of generated hints, and (c) encoder-based models\nperform better than decoder-based models in hint ranking.", "published": "2024-12-02 15:44:19", "link": "http://arxiv.org/abs/2412.01626v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Concept Based Continuous Prompts for Interpretable Text Classification", "abstract": "Continuous prompts have become widely adopted for augmenting performance\nacross a wide range of natural language tasks. However, the underlying\nmechanism of this enhancement remains obscure. Previous studies rely on\nindividual words for interpreting continuous prompts, which lacks comprehensive\nsemantic understanding. Drawing inspiration from Concept Bottleneck Models, we\npropose a framework for interpreting continuous prompts by decomposing them\ninto human-readable concepts. Specifically, to ensure the feasibility of the\ndecomposition, we demonstrate that a corresponding concept embedding matrix and\na coefficient matrix can always be found to replace the prompt embedding\nmatrix. Then, we employ GPT-4o to generate a concept pool and choose potential\ncandidate concepts that are discriminative and representative using a novel\nsubmodular optimization algorithm. Experiments demonstrate that our framework\ncan achieve similar results as the original P-tuning and word-based approaches\nusing only a few concepts while providing more plausible results. Our code is\navailable at https://github.com/qq31415926/CD.", "published": "2024-12-02 15:56:08", "link": "http://arxiv.org/abs/2412.01644v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Neurosymbolic Fast and Slow Architecture for Graph Coloring", "abstract": "Constraint Satisfaction Problems (CSPs) present significant challenges to\nartificial intelligence due to their intricate constraints and the necessity\nfor precise solutions. Existing symbolic solvers are often slow, and prior\nresearch has shown that Large Language Models (LLMs) alone struggle with CSPs\nbecause of their complexity. To bridge this gap, we build upon the existing\nSOFAI architecture (or SOFAI-v1), which adapts Daniel Kahneman's ''Thinking,\nFast and Slow'' cognitive model to AI. Our enhanced architecture, SOFAI-v2,\nintegrates refined metacognitive governance mechanisms to improve adaptability\nacross complex domains, specifically tailored for solving CSPs like graph\ncoloring. SOFAI-v2 combines a fast System 1 (S1) based on LLMs with a\ndeliberative System 2 (S2) governed by a metacognition module. S1's initial\nsolutions, often limited by non-adherence to constraints, are enhanced through\nmetacognitive governance, which provides targeted feedback and examples to\nadapt S1 to CSP requirements. If S1 fails to solve the problem, metacognition\nstrategically invokes S2, ensuring accurate and reliable solutions. With\nempirical results, we show that SOFAI-v2 for graph coloring problems achieves a\n16.98% increased success rate and is 32.42% faster than symbolic solvers.", "published": "2024-12-02 17:47:13", "link": "http://arxiv.org/abs/2412.01752v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "GETAE: Graph information Enhanced deep neural NeTwork ensemble\n  ArchitecturE for fake news detection", "abstract": "In today's digital age, fake news has become a major problem that has serious\nconsequences, ranging from social unrest to political upheaval. To address this\nissue, new methods for detecting and mitigating fake news are required. In this\nwork, we propose to incorporate contextual and network-aware features into the\ndetection process. This involves analyzing not only the content of a news\narticle but also the context in which it was shared and the network of users\nwho shared it, i.e., the information diffusion. Thus, we propose GETAE,\n\\underline{G}raph Information \\underline{E}nhanced Deep Neural\nNe\\underline{t}work Ensemble \\underline{A}rchitectur\\underline{E} for Fake News\nDetection, a novel ensemble architecture that uses textual content together\nwith the social interactions to improve fake news detection. GETAE contains two\nBranches: the Text Branch and the Propagation Branch. The Text Branch uses Word\nand Transformer Embeddings and a Deep Neural Network based on feed-forward and\nbidirectional Recurrent Neural Networks (\\textsc{[Bi]RNN}) for learning novel\ncontextual features and creating a novel Text Content Embedding. The\nPropagation Branch considers the information propagation within the graph\nnetwork and proposes a Deep Learning architecture that employs Node Embeddings\nto create novel Propagation Embedding. GETAE Ensemble combines the two novel\nembeddings, i.e., Text Content Embedding and Propagation Embedding, to create a\nnovel \\textit{Propagation-Enhanced Content Embedding} which is afterward used\nfor classification. The experimental results obtained on two real-world\npublicly available datasets, i.e., Twitter15 and Twitter16, prove that using\nthis approach improves fake news detection and outperforms state-of-the-art\nmodels.", "published": "2024-12-02 18:59:50", "link": "http://arxiv.org/abs/2412.01825v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "The use of large language models to enhance cancer clinical trial\n  educational materials", "abstract": "Cancer clinical trials often face challenges in recruitment and engagement\ndue to a lack of participant-facing informational and educational resources.\nThis study investigated the potential of Large Language Models (LLMs),\nspecifically GPT4, in generating patient-friendly educational content from\nclinical trial informed consent forms. Using data from ClinicalTrials.gov, we\nemployed zero-shot learning for creating trial summaries and one-shot learning\nfor developing multiple-choice questions, evaluating their effectiveness\nthrough patient surveys and crowdsourced annotation. Results showed that\nGPT4-generated summaries were both readable and comprehensive, and may improve\npatients' understanding and interest in clinical trials. The multiple-choice\nquestions demonstrated high accuracy and agreement with crowdsourced\nannotators. For both resource types, hallucinations were identified that\nrequire ongoing human oversight. The findings demonstrate the potential of LLMs\n\"out-of-the-box\" to support the generation of clinical trial education\nmaterials with minimal trial-specific engineering, but implementation with a\nhuman-in-the-loop is still needed to avoid misinformation risks.", "published": "2024-12-02 20:31:27", "link": "http://arxiv.org/abs/2412.01955v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Free Process Rewards without Process Labels", "abstract": "Different from its counterpart outcome reward models (ORMs), which evaluate\nthe entire responses, a process reward model (PRM) scores a reasoning\ntrajectory step by step, providing denser and more fine grained rewards.\nHowever, training a PRM requires labels annotated at every intermediate step,\npresenting significant challenges for both manual and automatic data\ncollection. This paper aims to address this challenge. Both theoretically and\nempirically, we show that an \\textit{implicit PRM} can be obtained at no\nadditional cost, by simply training an ORM on the cheaper response-level\nlabels. The only assumption is to parameterize the outcome reward as the\nlog-likelihood ratios of the policy and reference models, which can be\noptimized regardless of the specific choice of loss objectives. In experiments,\nwe instantiate our implicit PRMs with various objectives and evaluate their\nperformance on MATH. We show that our implicit PRM outperforms a strong\nMCTS-based baseline \\textit{\\'a la} Math-Shepherd using less than $1/38$ of the\ntraining data. Its performance can be further improved with majority voting. We\nfurther find that scaling up instructions and responses benefits our implicit\nPRM, and the latter brings a larger gain. Particularly, we find that our\nimplicit PRM, when instantiated with the cross-entropy (CE) loss, is more\ndata-efficient and can keep improving generation models even when trained with\nonly one response per instruction, the setup that suffers from extreme data\nscarcity and imbalance. Further, instructions should be relevant to downstream\ntasks while the diversity of responses does not bring gains. Surprisingly,\ntraining on extra Math-Shepherd step labels brings no further improvements to\nour implicit PRM trained on only outcome data. We hope that our work will\nencourage a rethinking of PRM training approaches and contribute to making\ntraining PRMs more accessible.", "published": "2024-12-02 21:20:02", "link": "http://arxiv.org/abs/2412.01981v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Real-Time Multilingual Sign Language Processing", "abstract": "Sign Language Processing (SLP) is an interdisciplinary field comprised of\nNatural Language Processing (NLP) and Computer Vision. It is focused on the\ncomputational understanding, translation, and production of signed languages.\nTraditional approaches have often been constrained by the use of gloss-based\nsystems that are both language-specific and inadequate for capturing the\nmultidimensional nature of sign language. These limitations have hindered the\ndevelopment of technology capable of processing signed languages effectively.\n  This thesis aims to revolutionize the field of SLP by proposing a simple\nparadigm that can bridge this existing technological gap. We propose the use of\nSignWiring, a universal sign language transcription notation system, to serve\nas an intermediary link between the visual-gestural modality of signed\nlanguages and text-based linguistic representations.\n  We contribute foundational libraries and resources to the SLP community,\nthereby setting the stage for a more in-depth exploration of the tasks of sign\nlanguage translation and production. These tasks encompass the translation of\nsign language from video to spoken language text and vice versa. Through\nempirical evaluations, we establish the efficacy of our transcription method as\na pivot for enabling faster, more targeted research, that can lead to more\nnatural and accurate translations across a range of languages.\n  The universal nature of our transcription-based paradigm also paves the way\nfor real-time, multilingual applications in SLP, thereby offering a more\ninclusive and accessible approach to language technology. This is a significant\nstep toward universal accessibility, enabling a wider reach of AI-driven\nlanguage technologies to include the deaf and hard-of-hearing community.", "published": "2024-12-02 21:51:41", "link": "http://arxiv.org/abs/2412.01991v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Detecting Memorization in Large Language Models", "abstract": "Large language models (LLMs) have achieved impressive results in natural\nlanguage processing but are prone to memorizing portions of their training\ndata, which can compromise evaluation metrics, raise privacy concerns, and\nlimit generalization. Traditional methods for detecting memorization rely on\noutput probabilities or loss functions, often lacking precision due to\nconfounding factors like common language patterns. In this paper, we introduce\nan analytical method that precisely detects memorization by examining neuron\nactivations within the LLM. By identifying specific activation patterns that\ndifferentiate between memorized and not memorized tokens, we train\nclassification probes that achieve near-perfect accuracy. The approach can also\nbe applied to other mechanisms, such as repetition, as demonstrated in this\nstudy, highlighting its versatility. Intervening on these activations allows us\nto suppress memorization without degrading overall performance, enhancing\nevaluation integrity by ensuring metrics reflect genuine generalization.\nAdditionally, our method supports large-scale labeling of tokens and sequences,\ncrucial for next-generation AI models, improving training efficiency and\nresults. Our findings contribute to model interpretability and offer practical\ntools for analyzing and controlling internal mechanisms in LLMs.", "published": "2024-12-02 00:17:43", "link": "http://arxiv.org/abs/2412.01014v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Evaluating Automated Radiology Report Quality through Fine-Grained\n  Phrasal Grounding of Clinical Findings", "abstract": "Several evaluation metrics have been developed recently to automatically\nassess the quality of generative AI reports for chest radiographs based only on\ntextual information using lexical, semantic, or clinical named entity\nrecognition methods. In this paper, we develop a new method of report quality\nevaluation by first extracting fine-grained finding patterns capturing the\nlocation, laterality, and severity of a large number of clinical findings. We\nthen performed phrasal grounding to localize their associated anatomical\nregions on chest radiograph images. The textual and visual measures are then\ncombined to rate the quality of the generated reports. We present results that\ncompare this evaluation metric with other textual metrics on a gold standard\ndataset derived from the MIMIC collection and show its robustness and\nsensitivity to factual errors.", "published": "2024-12-02 01:27:47", "link": "http://arxiv.org/abs/2412.01031v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Advancing Speech Language Models by Scaling Supervised Fine-Tuning with\n  Over 60,000 Hours of Synthetic Speech Dialogue Data", "abstract": "The GPT-4o represents a significant milestone in enabling real-time\ninteraction with large language models (LLMs) through speech, its remarkable\nlow latency and high fluency not only capture attention but also stimulate\nresearch interest in the field. This real-time speech interaction is\nparticularly valuable in scenarios requiring rapid feedback and immediate\nresponses, dramatically enhancing user experience. However, there is a notable\nlack of research focused on real-time large speech language models,\nparticularly for Chinese. In this work, we present KE-Omni, a seamless large\nspeech language model built upon Ke-SpeechChat, a large-scale high-quality\nsynthetic speech interaction dataset consisting of 7 million Chinese and\nEnglish conversations, featuring 42,002 speakers, and totaling over 60,000\nhours, This contributes significantly to the advancement of research and\ndevelopment in this field. The demos can be accessed at\n\\url{https://huggingface.co/spaces/KE-Team/KE-Omni}.", "published": "2024-12-02 03:31:46", "link": "http://arxiv.org/abs/2412.01078v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "First numerical observation of the Berezinskii-Kosterlitz-Thouless\n  transition in language models", "abstract": "Several power-law critical properties involving different statistics in\nnatural languages -- reminiscent of scaling properties of physical systems at\nor near phase transitions -- have been documented for decades.\n  The recent rise of large language models (LLMs) has added further evidence\nand excitement by providing intriguing similarities with notions in physics\nsuch as scaling laws and emergent abilities.\n  However, specific instances of classes of generative language models that\nexhibit phase transitions, as understood by the statistical physics community,\nare lacking.\n  In this work, inspired by the one-dimensional Potts model in statistical\nphysics we construct a simple probabilistic language model that falls under the\nclass of context sensitive grammars (CSG), and numerically demonstrate an\nunambiguous phase transition in the framework of a natural language model.\n  We explicitly show that a precisely defined order parameter -- that captures\nsymbol frequency biases in the sentences generated by the language model --\nchanges from strictly 0 to a strictly nonzero value (in the infinite-length\nlimit of sentences), implying a mathematical singularity arising when tuning\nthe parameter of the stochastic language model we consider.\n  Furthermore, we identify the phase transition as a variant of the\nBerezinskii-Kosterlitz-Thouless (BKT) transition, which is known to exhibit\ncritical properties not only at the transition point but also in the entire\nphase.\n  This finding leads to the possibility that critical properties in natural\nlanguages may not require careful fine-tuning nor self-organized criticality,\nbut is generically explained by the underlying connection between language\nstructures and the BKT phases.", "published": "2024-12-02 07:32:32", "link": "http://arxiv.org/abs/2412.01212v1", "categories": ["stat.ML", "cond-mat.stat-mech", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Yi-Lightning Technical Report", "abstract": "This technical report presents Yi-Lightning, our latest flagship large\nlanguage model (LLM). It achieves exceptional performance, ranking 6th overall\non Chatbot Arena, with particularly strong results (2nd to 4th place) in\nspecialized categories including Chinese, Math, Coding, and Hard Prompts.\nYi-Lightning leverages an enhanced Mixture-of-Experts (MoE) architecture,\nfeaturing advanced expert segmentation and routing mechanisms coupled with\noptimized KV-caching techniques. Our development process encompasses\ncomprehensive pre-training, supervised fine-tuning (SFT), and reinforcement\nlearning from human feedback (RLHF), where we devise deliberate strategies for\nmulti-stage training, synthetic data construction, and reward modeling.\nFurthermore, we implement RAISE (Responsible AI Safety Engine), a\nfour-component framework to address safety issues across pre-training,\npost-training, and serving phases. Empowered by our scalable super-computing\ninfrastructure, all these innovations substantially reduce training, deployment\nand inference costs while maintaining high-performance standards. With further\nevaluations on public academic benchmarks, Yi-Lightning demonstrates\ncompetitive performance against top-tier LLMs, while we observe a notable\ndisparity between traditional, static benchmark results and real-world, dynamic\nhuman preferences. This observation prompts a critical reassessment of\nconventional benchmarks' utility in guiding the development of more intelligent\nand powerful AI systems for practical applications. Yi-Lightning is now\navailable through our developer platform at https://platform.lingyiwanwu.com.", "published": "2024-12-02 08:22:56", "link": "http://arxiv.org/abs/2412.01253v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring ReAct Prompting for Task-Oriented Dialogue: Insights and\n  Shortcomings", "abstract": "Large language models (LLMs) gained immense popularity due to their\nimpressive capabilities in unstructured conversations. Empowering LLMs with\nadvanced prompting strategies such as reasoning and acting (ReAct) (Yao et al.,\n2022) has shown promise in solving complex tasks traditionally requiring\nreinforcement learning. In this work, we apply the ReAct strategy to guide LLMs\nperforming task-oriented dialogue (TOD). We evaluate ReAct-based LLMs\n(ReAct-LLMs) both in simulation and with real users. While ReAct-LLMs severely\nunderperform state-of-the-art approaches on success rate in simulation, this\ndifference becomes less pronounced in human evaluation. Moreover, compared to\nthe baseline, humans report higher subjective satisfaction with ReAct-LLM\ndespite its lower success rate, most likely thanks to its natural and\nconfidently phrased responses.", "published": "2024-12-02 08:30:22", "link": "http://arxiv.org/abs/2412.01262v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "CPRM: A LLM-based Continual Pre-training Framework for Relevance\n  Modeling in Commercial Search", "abstract": "Relevance modeling between queries and items stands as a pivotal component in\ncommercial search engines, directly affecting the user experience. Given the\nremarkable achievements of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, LLM-based relevance modeling is gradually\nbeing adopted within industrial search systems. Nevertheless, foundational LLMs\nlack domain-specific knowledge and do not fully exploit the potential of\nin-context learning. Furthermore, structured item text remains underutilized,\nand there is a shortage in the supply of corresponding queries and background\nknowledge. We thereby propose CPRM (Continual Pre-training for Relevance\nModeling), a framework designed for the continual pre-training of LLMs to\naddress these issues. Our CPRM framework includes three modules: 1) employing\nboth queries and multi-field item to jointly pre-train for enhancing domain\nknowledge, 2) applying in-context pre-training, a novel approach where LLMs are\npre-trained on a sequence of related queries or items, and 3) conducting\nreading comprehension on items to produce associated domain knowledge and\nbackground information (e.g., generating summaries and corresponding queries)\nto further strengthen LLMs. Results on offline experiments and online A/B\ntesting demonstrate that our model achieves convincing performance compared to\nstrong baselines.", "published": "2024-12-02 08:35:54", "link": "http://arxiv.org/abs/2412.01269v5", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Multi-Facet Blending for Faceted Query-by-Example Retrieval", "abstract": "With the growing demand to fit fine-grained user intents, faceted\nquery-by-example (QBE), which retrieves similar documents conditioned on\nspecific facets, has gained recent attention. However, prior approaches mainly\ndepend on document-level comparisons using basic indicators like citations due\nto the lack of facet-level relevance datasets; yet, this limits their use to\ncitation-based domains and fails to capture the intricacies of facet\nconstraints. In this paper, we propose a multi-facet blending (FaBle)\naugmentation method, which exploits modularity by decomposing and recomposing\nto explicitly synthesize facet-specific training sets. We automatically\ndecompose documents into facet units and generate (ir)relevant pairs by\nleveraging LLMs' intrinsic distinguishing capabilities; then, dynamically\nrecomposing the units leads to facet-wise relevance-informed document pairs.\nOur modularization eliminates the need for pre-defined facet knowledge or\nlabels. Further, to prove the FaBle's efficacy in a new domain beyond\ncitation-based scientific paper retrieval, we release a benchmark dataset for\neducational exam item QBE. FaBle augmentation on 1K documents remarkably\nassists training in obtaining facet conditional embeddings.", "published": "2024-12-02 12:32:19", "link": "http://arxiv.org/abs/2412.01443v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM\n  World", "abstract": "Loneliness, or the lack of fulfilling relationships, significantly impacts a\nperson's mental and physical well-being and is prevalent worldwide. Previous\nresearch suggests that large language models (LLMs) may help mitigate\nloneliness. However, we argue that the use of widespread LLMs like ChatGPT is\nmore prevalent--and riskier, as they are not designed for this purpose. To\nexplore this, we analysed user interactions with ChatGPT, particularly those\noutside of its marketed use as task-oriented assistant. In dialogues classified\nas lonely, users frequently (37%) sought advice or validation, and received\ngood engagement. However, ChatGPT failed in sensitive scenarios, like\nresponding appropriately to suicidal ideation or trauma. We also observed a 35%\nhigher incidence of toxic content, with women being 22 times more likely to be\ntargeted than men. Our findings underscore ethical and legal questions about\nthis technology, and note risks like radicalisation or further isolation. We\nconclude with recommendations for research and industry to address loneliness.", "published": "2024-12-02 15:39:00", "link": "http://arxiv.org/abs/2412.01617v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "R-Bot: An LLM-based Query Rewrite System", "abstract": "Query rewrite is essential for optimizing SQL queries to improve their\nexecution efficiency without changing their results. Traditionally, this task\nhas been tackled through heuristic and learning-based methods, each with its\nlimitations in terms of inferior quality and low robustness. Recent\nadvancements in LLMs offer a new paradigm by leveraging their superior natural\nlanguage and code comprehension abilities. Despite their potential, directly\napplying LLMs like GPT-4 has faced challenges due to problems such as\nhallucinations, where the model might generate inaccurate or irrelevant\nresults. To address this, we propose R-Bot, an LLM-based query rewrite system\nwith a systematic approach. We first design a multi-source rewrite evidence\npreparation pipeline to generate query rewrite evidences for guiding LLMs to\navoid hallucinations. We then propose a hybrid structure-semantics retrieval\nmethod that combines structural and semantic analysis to retrieve the most\nrelevant rewrite evidences for effectively answering an online query. We next\npropose a step-by-step LLM rewrite method that iteratively leverages the\nretrieved evidences to select and arrange rewrite rules with self-reflection.\nWe conduct comprehensive experiments on widely used benchmarks, and demonstrate\nthe superior performance of our system, R-Bot, surpassing state-of-the-art\nquery rewrite methods.", "published": "2024-12-02 16:13:04", "link": "http://arxiv.org/abs/2412.01661v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Are We There Yet? Revealing the Risks of Utilizing Large Language Models\n  in Scholarly Peer Review", "abstract": "Scholarly peer review is a cornerstone of scientific advancement, but the\nsystem is under strain due to increasing manuscript submissions and the\nlabor-intensive nature of the process. Recent advancements in large language\nmodels (LLMs) have led to their integration into peer review, with promising\nresults such as substantial overlaps between LLM- and human-generated reviews.\nHowever, the unchecked adoption of LLMs poses significant risks to the\nintegrity of the peer review system. In this study, we comprehensively analyze\nthe vulnerabilities of LLM-generated reviews by focusing on manipulation and\ninherent flaws. Our experiments show that injecting covert deliberate content\ninto manuscripts allows authors to explicitly manipulate LLM reviews, leading\nto inflated ratings and reduced alignment with human reviews. In a simulation,\nwe find that manipulating 5% of the reviews could potentially cause 12% of the\npapers to lose their position in the top 30% rankings. Implicit manipulation,\nwhere authors strategically highlight minor limitations in their papers,\nfurther demonstrates LLMs' susceptibility compared to human reviewers, with a\n4.5 times higher consistency with disclosed limitations. Additionally, LLMs\nexhibit inherent flaws, such as potentially assigning higher ratings to\nincomplete papers compared to full papers and favoring well-known authors in\nsingle-blind review process. These findings highlight the risks of\nover-reliance on LLMs in peer review, underscoring that we are not yet ready\nfor widespread adoption and emphasizing the need for robust safeguards.", "published": "2024-12-02 16:55:03", "link": "http://arxiv.org/abs/2412.01708v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Query Performance Explanation through Large Language Model for HTAP\n  Systems", "abstract": "In hybrid transactional and analytical processing (HTAP) systems, users often\nstruggle to understand why query plans from one engine (OLAP or OLTP) perform\nsignificantly slower than those from another. Although optimizers provide plan\ndetails via the EXPLAIN function, these explanations are frequently too\ntechnical for non-experts and offer limited insights into performance\ndifferences across engines. To address this, we propose a novel framework that\nleverages large language models (LLMs) to explain query performance in HTAP\nsystems. Built on Retrieval-Augmented Generation (RAG), our framework\nconstructs a knowledge base that stores historical query executions and\nexpert-curated explanations. To enable efficient retrieval of relevant\nknowledge, query plans are embedded using a lightweight tree-CNN classifier.\nThis augmentation allows the LLM to generate clear, context-aware explanations\nof performance differences between engines. Our approach demonstrates the\npotential of LLMs in hybrid engine systems, paving the way for further\nadvancements in database optimization and user support.", "published": "2024-12-02 16:55:07", "link": "http://arxiv.org/abs/2412.01709v1", "categories": ["cs.DB", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Random Tree Model of Meaningful Memory", "abstract": "Traditional studies of memory for meaningful narratives focus on specific\nstories and their semantic structures but do not address common quantitative\nfeatures of recall across different narratives. We introduce a statistical\nensemble of random trees to represent narratives as hierarchies of key points,\nwhere each node is a compressed representation of its descendant leaves, which\nare the original narrative segments. Recall is modeled as constrained by\nworking memory capacity from this hierarchical structure. Our analytical\nsolution aligns with observations from large-scale narrative recall\nexperiments. Specifically, our model explains that (1) average recall length\nincreases sublinearly with narrative length, and (2) individuals summarize\nincreasingly longer narrative segments in each recall sentence. Additionally,\nthe theory predicts that for sufficiently long narratives, a universal,\nscale-invariant limit emerges, where the fraction of a narrative summarized by\na single recall sentence follows a distribution independent of narrative\nlength.", "published": "2024-12-02 18:50:27", "link": "http://arxiv.org/abs/2412.01806v3", "categories": ["cond-mat.stat-mech", "cs.AI", "cs.CL"], "primary_category": "cond-mat.stat-mech"}
{"title": "COSMOS: Cross-Modality Self-Distillation for Vision Language\n  Pre-training", "abstract": "Vision-Language Models (VLMs) trained with contrastive loss have achieved\nsignificant advancements in various vision and language tasks. However, the\nglobal nature of the contrastive loss makes VLMs focus predominantly on\nforeground objects, neglecting other crucial information in the image, which\nlimits their effectiveness in downstream tasks. To address these challenges, we\npropose COSMOS: CrOSs-MOdality Self-distillation for vision-language\npre-training that integrates a novel text-cropping strategy and cross-attention\nmodule into a self-supervised learning framework. We create global and local\nviews of images and texts (i.e., multi-modal augmentations), which are\nessential for self-distillation in VLMs. We further introduce a cross-attention\nmodule, enabling COSMOS to learn comprehensive cross-modal representations\noptimized via a cross-modality self-distillation loss. COSMOS consistently\noutperforms previous strong baselines on various zero-shot downstream tasks,\nincluding retrieval, classification, and semantic segmentation. Additionally,\nit surpasses CLIP-based models trained on larger datasets in visual perception\nand contextual understanding tasks. Code is available at\nhttps://github.com/ExplainableML/cosmos.", "published": "2024-12-02 18:56:06", "link": "http://arxiv.org/abs/2412.01814v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Composition of Experts: A Modular Compound AI System Leveraging Large\n  Language Models", "abstract": "Large Language Models (LLMs) have achieved remarkable advancements, but their\nmonolithic nature presents challenges in terms of scalability, cost, and\ncustomization. This paper introduces the Composition of Experts (CoE), a\nmodular compound AI system leveraging multiple expert LLMs. CoE leverages a\nrouter to dynamically select the most appropriate expert for a given input,\nenabling efficient utilization of resources and improved performance. We\nformulate the general problem of training a CoE and discuss inherent\ncomplexities associated with it. We propose a two-step routing approach to\naddress these complexities that first uses a router to classify the input into\ndistinct categories followed by a category-to-expert mapping to obtain desired\nexperts. CoE offers a flexible and cost-effective solution to build compound AI\nsystems. Our empirical evaluation demonstrates the effectiveness of CoE in\nachieving superior performance with reduced computational overhead. Given that\nCoE comprises of many expert LLMs it has unique system requirements for\ncost-effective serving. We present an efficient implementation of CoE\nleveraging SambaNova SN40L RDUs unique three-tiered memory architecture. CoEs\nobtained using open weight LLMs Qwen/Qwen2-7B-Instruct, google/gemma-2-9b-it,\ngoogle/gemma-2-27b-it, meta-llama/Llama-3.1-70B-Instruct and\nQwen/Qwen2-72B-Instruct achieve a score of $59.4$ with merely $31$ billion\naverage active parameters on Arena-Hard and a score of $9.06$ with $54$ billion\naverage active parameters on MT-Bench.", "published": "2024-12-02 07:43:21", "link": "http://arxiv.org/abs/2412.01868v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Self-Improvement in Language Models: The Sharpening Mechanism", "abstract": "Recent work in language modeling has raised the possibility of\nself-improvement, where a language models evaluates and refines its own\ngenerations to achieve higher performance without external feedback. It is\nimpossible for this self-improvement to create information that is not already\nin the model, so why should we expect that this will lead to improved\ncapabilities? We offer a new perspective on the capabilities of\nself-improvement through a lens we refer to as sharpening. Motivated by the\nobservation that language models are often better at verifying response quality\nthan they are at generating correct responses, we formalize self-improvement as\nusing the model itself as a verifier during post-training in order to\n``sharpen'' the model to one placing large mass on high-quality sequences,\nthereby amortizing the expensive inference-time computation of generating good\nsequences. We begin by introducing a new statistical framework for sharpening\nin which the learner aims to sharpen a pre-trained base policy via sample\naccess, and establish fundamental limits. Then we analyze two natural families\nof self-improvement algorithms based on SFT and RLHF. We find that (i) the\nSFT-based approach is minimax optimal whenever the initial model has sufficient\ncoverage, but (ii) the RLHF-based approach can improve over SFT-based\nself-improvement by leveraging online exploration, bypassing the need for\ncoverage. Finally, we empirically validate the sharpening mechanism via\ninference-time and amortization experiments. We view these findings as a\nstarting point toward a foundational understanding that can guide the design\nand evaluation of self-improvement algorithms.", "published": "2024-12-02 20:24:17", "link": "http://arxiv.org/abs/2412.01951v2", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "The Vulnerability of Language Model Benchmarks: Do They Accurately\n  Reflect True LLM Performance?", "abstract": "The pursuit of leaderboard rankings in Large Language Models (LLMs) has\ncreated a fundamental paradox: models excel at standardized tests while failing\nto demonstrate genuine language understanding and adaptability. Our systematic\nanalysis of NLP evaluation frameworks reveals pervasive vulnerabilities across\nthe evaluation spectrum, from basic metrics to complex benchmarks like GLUE and\nMMLU. These vulnerabilities manifest through benchmark exploitation, dataset\ncontamination, and evaluation bias, creating a false perception of progress in\nlanguage understanding capabilities. Through extensive review of contemporary\nevaluation approaches, we identify significant limitations in static benchmark\ndesigns, human evaluation protocols, and LLM-as-judge frameworks, all of which\ncompromise the reliability of current performance assessments. As LLM\ncapabilities evolve and existing benchmarks become redundant, we lay the\ngroundwork for new evaluation methods that resist manipulation, minimize data\ncontamination, and assess domain-specific tasks. This requires frameworks that\nare adapted dynamically, addressing current limitations and providing a more\naccurate reflection of LLM performance.", "published": "2024-12-02 20:49:21", "link": "http://arxiv.org/abs/2412.03597v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Mastering Board Games by External and Internal Planning with Language\n  Models", "abstract": "While large language models perform well on a range of complex tasks (e.g.,\ntext generation, question answering, summarization), robust multi-step planning\nand reasoning remains a considerable challenge for them. In this paper we show\nthat search-based planning can significantly improve LLMs' playing strength\nacross several board games (Chess, Fischer Random / Chess960, Connect Four, and\nHex). We introduce, compare and contrast two major approaches: In external\nsearch, the model guides Monte Carlo Tree Search (MCTS) rollouts and\nevaluations without calls to an external engine, and in internal search, the\nmodel directly generates in-context a linearized tree of potential futures and\na resulting final choice. Both build on a language model pre-trained on\nrelevant domain knowledge, capturing the transition and value functions across\nthese games. We find that our pre-training method minimizes hallucinations, as\nour model is highly accurate regarding state prediction and legal moves.\nAdditionally, both internal and external search indeed improve win-rates\nagainst state-of-the-art bots, even reaching Grandmaster-level performance in\nchess while operating on a similar move count search budget per decision as\nhuman Grandmasters. The way we combine search with domain knowledge is not\nspecific to board games, suggesting direct extensions into more general\nlanguage model inference and training techniques.", "published": "2024-12-02 18:56:51", "link": "http://arxiv.org/abs/2412.12119v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Social Media Data Mining With Natural Language Processing on Public\n  Dream Contents", "abstract": "The COVID-19 pandemic has significantly transformed global lifestyles,\nenforcing physical isolation and accelerating digital adoption for work,\neducation, and social interaction. This study examines the pandemic's impact on\nmental health by analyzing dream content shared on the Reddit r/Dreams\ncommunity. With over 374,000 subscribers, this platform offers a rich dataset\nfor exploring subconscious responses to the pandemic. Using statistical\nmethods, we assess shifts in dream positivity, negativity, and neutrality from\nthe pre-pandemic to post-pandemic era. To enhance our analysis, we fine-tuned\nthe LLaMA 3.1-8B model with labeled data, enabling precise sentiment\nclassification of dream content. Our findings aim to uncover patterns in dream\ncontent, providing insights into the psychological effects of the pandemic and\nits influence on subconscious processes. This research highlights the profound\nchanges in mental landscapes and the role of dreams as indicators of public\nwell-being during unprecedented times.", "published": "2024-12-02 02:34:02", "link": "http://arxiv.org/abs/2501.07839v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.SI", "I.2.7"], "primary_category": "cs.CY"}
{"title": "NLLG Quarterly arXiv Report 09/24: What are the most influential current\n  AI Papers?", "abstract": "The NLLG (Natural Language Learning & Generation) arXiv reports assist in\nnavigating the rapidly evolving landscape of NLP and AI research across cs.CL,\ncs.CV, cs.AI, and cs.LG categories. This fourth installment captures a\ntransformative period in AI history - from January 1, 2023, following ChatGPT's\ndebut, through September 30, 2024. Our analysis reveals substantial new\ndevelopments in the field - with 45% of the top 40 most-cited papers being new\nentries since our last report eight months ago and offers insights into\nemerging trends and major breakthroughs, such as novel multimodal\narchitectures, including diffusion and state space models. Natural Language\nProcessing (NLP; cs.CL) remains the dominant main category in the list of our\ntop-40 papers but its dominance is on the decline in favor of Computer vision\n(cs.CV) and general machine learning (cs.LG). This report also presents novel\nfindings on the integration of generative AI in academic writing, documenting\nits increasing adoption since 2022 while revealing an intriguing pattern:\ntop-cited papers show notably fewer markers of AI-generated content compared to\nrandom samples. Furthermore, we track the evolution of AI-associated language,\nidentifying declining trends in previously common indicators such as \"delve\".", "published": "2024-12-02 22:10:38", "link": "http://arxiv.org/abs/2412.12121v1", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.DL"}
{"title": "Detecting Spoof Voices in Asian Non-Native Speech: An Indonesian and\n  Thai Case Study", "abstract": "This study focuses on building effective spoofing countermeasures (CMs) for\nnon-native speech, specifically targeting Indonesian and Thai speakers. We\nconstructed a dataset comprising both native and non-native speech to\nfacilitate our research. Three key features (MFCC, LFCC, and CQCC) were\nextracted from the speech data, and three classic machine learning-based\nclassifiers (CatBoost, XGBoost, and GMM) were employed to develop robust\nspoofing detection systems using the native and combined (native and\nnon-native) speech data. This resulted in two types of CMs: Native and\nCombined. The performance of these CMs was evaluated on both native and\nnon-native speech datasets. Our findings reveal significant challenges faced by\nNative CM in handling non-native speech, highlighting the necessity for\ndomain-specific solutions. The proposed method shows improved detection\ncapabilities, demonstrating the importance of incorporating non-native speech\ndata into the training process. This work lays the foundation for more\neffective spoofing detection systems in diverse linguistic contexts.", "published": "2024-12-02 01:46:51", "link": "http://arxiv.org/abs/2412.01040v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "AlignFormer: Modality Matching Can Achieve Better Zero-shot\n  Instruction-Following Speech-LLM", "abstract": "Integrating speech into LLM (speech-LLM) has gaining increased attention\nrecently. The mainstream solution is to connect a well-trained speech encoder\nand LLM with a neural adapter. However, the length mismatch between the speech\nand text sequences are not well handled, leading to imperfect modality matching\nbetween the speech and text. In this work, we propose a novel neural adapter,\nAlignFormer, to reduce the length gap between the two modalities. AlignFormer\nconsists of CTC and dynamic-window QFormer layers, where the CTC alignment\nprovides the dynamic window information for qformer layers. The LLM backbone is\nfrozen in training to preserve its text capability, especially the instruction\nfollowing capability. When training with only the ASR data, the proposed\nAlignFormer unlocks the instruction following capability for speech-LLM and the\nmodel can perform zero-shot speech translation (ST) and speech question\nanswering (SQA) tasks. In fact, speech-LLM with AlignFormer can theoretically\nperform any tasks that the LLM backbone can deal with in the speech version. To\nevaluate the effectiveness of the instruction-following speech-LLM, we propose\nto use instruction following rate (IFR) and offer a systematic perspective for\nthe IFR evaluation. In addition, we find that the audio position in training\nwould affect the instruction following capability of speech-LLM and conduct an\nin-depth study on it. Our findings show that audio-first training achieves\nhigher IFR than instruction-first training. The AlignFormer can achieve a near\n100% IFR with audio-first training and game-changing improvements from zero to\nnon-zero IFR on some evaluation data with instruction-first training. We\nbelieve that this study is a big step towards the perfect speech and text\nmodality matching in the LLM embedding space.", "published": "2024-12-02 05:42:33", "link": "http://arxiv.org/abs/2412.01145v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Text-based Audio Retrieval by Learning from Similarities between Audio\n  Captions", "abstract": "This paper proposes to use similarities of audio captions for estimating\naudio-caption relevances to be used for training text-based audio retrieval\nsystems. Current audio-caption datasets (e.g., Clotho) contain audio samples\npaired with annotated captions, but lack relevance information about audio\nsamples and captions beyond the annotated ones. Besides, mainstream approaches\n(e.g., CLAP) usually treat the annotated pairs as positives and consider all\nother audio-caption combinations as negatives, assuming a binary relevance\nbetween audio samples and captions. To infer the relevance between audio\nsamples and arbitrary captions, we propose a method that computes non-binary\naudio-caption relevance scores based on the textual similarities of audio\ncaptions. We measure textual similarities of audio captions by calculating the\ncosine similarity of their Sentence-BERT embeddings and then transform these\nsimilarities into audio-caption relevance scores using a logistic function,\nthereby linking audio samples through their annotated captions to all other\ncaptions in the dataset. To integrate the computed relevances into training, we\nemploy a listwise ranking objective, where relevance scores are converted into\nprobabilities of ranking audio samples for a given textual query. We show the\neffectiveness of the proposed method by demonstrating improvements in\ntext-based audio retrieval compared to methods that use binary audio-caption\nrelevances for training.", "published": "2024-12-02 10:34:05", "link": "http://arxiv.org/abs/2412.01356v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "FreeCodec: A disentangled neural speech codec with fewer tokens", "abstract": "Neural speech codecs have gained great attention for their outstanding\nreconstruction with discrete token representations.\n  It is a crucial component in generative tasks such as speech coding and large\nlanguage models (LLM).\n  However, most works based on residual vector quantization perform worse with\nfewer tokens due to low coding efficiency for modeling complex coupled\ninformation.\n  In this paper, we propose a neural speech codec named FreeCodec which employs\na more effective encoding framework by decomposing intrinsic properties of\nspeech into different components:\n  1) a global vector is extracted as the timbre information,\n  2) a prosody encoder with a long stride level is used to model the prosody\ninformation,\n  3) the content information is from a content encoder.\n  Using different training strategies, FreeCodec achieves state-of-the-art\nperformance in reconstruction and disentanglement scenarios.\n  Results from subjective and objective experiments demonstrate that our\nframework outperforms existing methods.", "published": "2024-12-02 02:29:22", "link": "http://arxiv.org/abs/2412.01053v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Codec Language Model-based Zero-Shot Spontaneous Style TTS System\n  for CoVoC Challenge 2024", "abstract": "This paper describes the zero-shot spontaneous style TTS system for the\nISCSLP 2024 Conversational Voice Clone Challenge (CoVoC). We propose a\nLLaMA-based codec language model with a delay pattern to achieve spontaneous\nstyle voice cloning. To improve speech intelligibility, we introduce the\nClassifier-Free Guidance (CFG) strategy in the language model to strengthen\nconditional guidance on token prediction. To generate high-quality utterances,\nwe adopt effective data preprocessing operations and fine-tune our model with\nselected high-quality spontaneous speech data. The official evaluations in the\nCoVoC constrained track show that our system achieves the best speech\nnaturalness MOS of 3.80 and obtains considerable speech quality and speaker\nsimilarity results.", "published": "2024-12-02 04:17:42", "link": "http://arxiv.org/abs/2412.01100v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "HumekaFL: Automated Detection of Neonatal Asphyxia Using Federated\n  Learning", "abstract": "Birth Apshyxia (BA) is a severe condition characterized by insufficient\nsupply of oxygen to a newborn during the delivery. BA is one of the primary\ncauses of neonatal death in the world. Although there has been a decline in\nneonatal deaths over the past two decades, the developing world, particularly\nsub-Saharan Africa, continues to experience the highest under-five (<5)\nmortality rates. While evidence-based methods are commonly used to detect BA in\nAfrican healthcare settings, they can be subject to physician errors or delays\nin diagnosis, preventing timely interventions. Centralized Machine Learning\n(ML) methods demonstrated good performance in early detection of BA but require\nsensitive health data to leave their premises before training, which does not\nguarantee privacy and security. Healthcare institutions are therefore reluctant\nto adopt such solutions in Africa. To address this challenge, we suggest a\nfederated learning (FL)-based software architecture, a distributed learning\nmethod that prioritizes privacy and security by design. We have developed a\nuser-friendly and cost-effective mobile application embedding the FL pipeline\nfor early detection of BA. Our Federated SVM model outperformed centralized SVM\npipelines and Neural Networks (NN)-based methods in the existing literature", "published": "2024-12-02 06:10:11", "link": "http://arxiv.org/abs/2412.01167v1", "categories": ["cs.LG", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Deep Learning-Based Approach for Identification and Compensation of\n  Nonlinear Distortions in Parametric Array Loudspeakers", "abstract": "Compared to traditional electrodynamic loudspeakers, the parametric array\nloudspeaker (PAL) offers exceptional directivity for audio applications but\nsuffers from significant nonlinear distortions due to its inherent intricate\ndemodulation process. The Volterra filter-based approaches have been widely\nused to reduce these distortions, but the effectiveness is limited by its\ninverse filter's capability. Specifically, its pth-order inverse filter can\nonly compensate for nonlinearities up to the pth order, while the higher-order\nnonlinearities it introduces continue to generate lower-order harmonics. In\ncontrast, this paper introduces the modern deep learning methods for the first\ntime to address nonlinear identification and compensation for PAL systems.\nSpecifically, a feedforward variant of the WaveNet neural network, recognized\nfor its success in audio nonlinear system modeling, is utilized to identify and\ncompensate for distortions in a double sideband amplitude modulation-based PAL\nsystem. Experimental measurements from 250 Hz to 8 kHz demonstrate that our\nproposed approach significantly reduces both total harmonic distortion and\nintermodulation distortion of audio sound generated by PALs, achieving average\nreductions to 4.55% and 2.47%, respectively. This performance is notably\nsuperior to results obtained using the current state-of-the-art Volterra\nfilter-based methods. Our work opens new possibilities for improving the sound\nreproduction performance of PALs.", "published": "2024-12-02 04:00:10", "link": "http://arxiv.org/abs/2412.01092v1", "categories": ["eess.AS", "cs.SD", "cs.SY", "eess.SY"], "primary_category": "eess.AS"}
{"title": "OmniFlow: Any-to-Any Generation with Multi-Modal Rectified Flows", "abstract": "We introduce OmniFlow, a novel generative model designed for any-to-any\ngeneration tasks such as text-to-image, text-to-audio, and audio-to-image\nsynthesis. OmniFlow advances the rectified flow (RF) framework used in\ntext-to-image models to handle the joint distribution of multiple modalities.\nIt outperforms previous any-to-any models on a wide range of tasks, such as\ntext-to-image and text-to-audio synthesis. Our work offers three key\ncontributions: First, we extend RF to a multi-modal setting and introduce a\nnovel guidance mechanism, enabling users to flexibly control the alignment\nbetween different modalities in the generated outputs. Second, we propose a\nnovel architecture that extends the text-to-image MMDiT architecture of Stable\nDiffusion 3 and enables audio and text generation. The extended modules can be\nefficiently pretrained individually and merged with the vanilla text-to-image\nMMDiT for fine-tuning. Lastly, we conduct a comprehensive study on the design\nchoices of rectified flow transformers for large-scale audio and text\ngeneration, providing valuable insights into optimizing performance across\ndiverse modalities. The Code will be available at\nhttps://github.com/jacklishufan/OmniFlows.", "published": "2024-12-02 06:13:01", "link": "http://arxiv.org/abs/2412.01169v2", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Memory-Efficient Training for Deep Speaker Embedding Learning in Speaker\n  Verification", "abstract": "Recent speaker verification (SV) systems have shown a trend toward adopting\ndeeper speaker embedding extractors. Although deeper and larger neural networks\ncan significantly improve performance, their substantial memory requirements\nhinder training on consumer GPUs. In this paper, we explore a memory-efficient\ntraining strategy for deep speaker embedding learning in resource-constrained\nscenarios. Firstly, we conduct a systematic analysis of GPU memory allocation\nduring SV system training. Empirical observations show that activations and\noptimizer states are the main sources of memory consumption. For activations,\nwe design two types of reversible neural networks which eliminate the need to\nstore intermediate activations during back-propagation, thereby significantly\nreducing memory usage without performance loss. For optimizer states, we\nintroduce a dynamic quantization approach that replaces the original 32-bit\nfloating-point values with a dynamic tree-based 8-bit data type. Experimental\nresults on VoxCeleb demonstrate that the reversible variants of ResNets and\nDF-ResNets can perform training without the need to cache activations in GPU\nmemory. In addition, the 8-bit versions of SGD and Adam save 75% of memory\ncosts while maintaining performance compared to their 32-bit counterparts.\nFinally, a detailed comparison of memory usage and performance indicates that\nour proposed models achieve up to 16.2x memory savings, with nearly identical\nparameters and performance compared to the vanilla systems. In contrast to the\nprevious need for multiple high-end GPUs such as the A100, we can effectively\ntrain deep speaker embedding extractors with just one or two consumer-level\n2080Ti GPUs.", "published": "2024-12-02 06:57:46", "link": "http://arxiv.org/abs/2412.01195v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Linear stimulus reconstruction works on the KU Leuven audiovisual,\n  gaze-controlled auditory attention decoding dataset", "abstract": "In a recent paper, we presented the KU Leuven audiovisual, gaze-controlled\nauditory attention decoding (AV-GC-AAD) dataset, in which we recorded\nelectroencephalography (EEG) signals of participants attending to one out of\ntwo competing speakers under various audiovisual conditions. The main goal of\nthis dataset was to disentangle the direction of gaze from the direction of\nauditory attention, in order to reveal gaze-related shortcuts in existing\nspatial AAD algorithms that aim to decode the (direction of) auditory attention\ndirectly from the EEG. Various methods based on spatial AAD do not achieve\nsignificant above-chance performances on our AV-GC-AAD dataset, indicating that\npreviously reported results were mainly driven by eye gaze confounds in\nexisting datasets. Still, these adverse outcomes are often discarded for\nreasons that are attributed to the limitations of the AV-GC-AAD dataset, such\nas the limited amount of data to train a working model, too much data\nheterogeneity due to different audiovisual conditions, or participants\nallegedly being unable to focus their auditory attention under the complex\ninstructions. In this paper, we present the results of the linear stimulus\nreconstruction AAD algorithm and show that high AAD accuracy can be obtained\nwithin each individual condition and that the model generalizes across\nconditions, across new subjects, and even across datasets. Therefore, we\neliminate any doubts that the inadequacy of the AV-GC-AAD dataset is the\nprimary reason for the (spatial) AAD algorithms failing to achieve above-chance\nperformance when compared to other datasets. Furthermore, this report provides\na simple baseline evaluation procedure (including source code) that can serve\nas the minimal benchmark for all future AAD algorithms evaluated on this\ndataset.", "published": "2024-12-02 11:35:49", "link": "http://arxiv.org/abs/2412.01401v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Reject Threshold Adaptation for Open-Set Model Attribution of Deepfake\n  Audio", "abstract": "Open environment oriented open set model attribution of deepfake audio is an\nemerging research topic, aiming to identify the generation models of deepfake\naudio. Most previous work requires manually setting a rejection threshold for\nunknown classes to compare with predicted probabilities. However, models often\noverfit training instances and generate overly confident predictions. Moreover,\nthresholds that effectively distinguish unknown categories in the current\ndataset may not be suitable for identifying known and unknown categories in\nanother data distribution. To address the issues, we propose a novel framework\nfor open set model attribution of deepfake audio with rejection threshold\nadaptation (ReTA). Specifically, the reconstruction error learning module\ntrains by combining the representation of system fingerprints with labels\ncorresponding to either the target class or a randomly chosen other class\nlabel. This process generates matching and non-matching reconstructed samples,\nestablishing the reconstruction error distributions for each class and laying\nthe foundation for the reject threshold calculation module. The reject\nthreshold calculation module utilizes gaussian probability estimation to fit\nthe distributions of matching and non-matching reconstruction errors. It then\ncomputes adaptive reject thresholds for all classes through probability\nminimization criteria. The experimental results demonstrate the effectiveness\nof ReTA in improving the open set model attributes of deepfake audio.", "published": "2024-12-02 12:06:50", "link": "http://arxiv.org/abs/2412.01425v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TACO: Training-free Sound Prompted Segmentation via Semantically\n  Constrained Audio-visual CO-factorization", "abstract": "Large-scale pre-trained audio and image models demonstrate an unprecedented\ndegree of generalization, making them suitable for a wide range of\napplications. Here, we tackle the specific task of sound-prompted segmentation,\naiming to segment image regions corresponding to objects heard in an audio\nsignal. Most existing approaches tackle this problem by fine-tuning pre-trained\nmodels or by training additional modules specifically for the task. We adopt a\ndifferent strategy: we introduce a training-free approach that leverages\nNon-negative Matrix Factorization (NMF) to co-factorize audio and visual\nfeatures from pre-trained models so as to reveal shared interpretable concepts.\nThese concepts are passed on to an open-vocabulary segmentation model for\nprecise segmentation maps. By using frozen pre-trained models, our method\nachieves high generalization and establishes state-of-the-art performance in\nunsupervised sound-prompted segmentation, significantly surpassing previous\nunsupervised methods.", "published": "2024-12-02 13:39:49", "link": "http://arxiv.org/abs/2412.01488v2", "categories": ["eess.AS", "cs.LG", "eess.IV"], "primary_category": "eess.AS"}
{"title": "Generative AI-based data augmentation for improved bioacoustic\n  classification in noisy environments", "abstract": "1. Obtaining data to train robust artificial intelligence (AI)-based models\nfor species classification can be challenging, particularly for rare species.\nData augmentation can boost classification accuracy by increasing the diversity\nof training data and is cheaper to obtain than expert-labelled data. However,\nmany classic image-based augmentation techniques are not suitable for audio\nspectrograms. 2. We investigate two generative AI models as data augmentation\ntools to synthesise spectrograms and supplement audio data: Auxiliary\nClassifier Generative Adversarial Networks (ACGAN) and Denoising Diffusion\nProbabilistic Models (DDPMs). The latter performed particularly well in terms\nof both realism of generated spectrograms and accuracy in a resulting\nclassification task. 3. Alongside these new approaches, we present a new audio\ndata set of 640 hours of bird calls from wind farm sites in Ireland,\napproximately 800 samples of which have been labelled by experts. Wind farm\ndata are particularly challenging for classification models given the\nbackground wind and turbine noise. 4. Training an ensemble of classification\nmodels on real and synthetic data combined gave 92.6% accuracy (and 90.5% with\njust the real data) when compared with highly confident BirdNET predictions. 5.\nOur approach can be used to augment acoustic signals for more species and other\nland-use types, and has the potential to bring about a step-change in our\ncapacity to develop reliable AI-based detection of rare species. Our code is\navailable at https://github.com/gibbona1/ SpectrogramGenAI.", "published": "2024-12-02 14:20:26", "link": "http://arxiv.org/abs/2412.01530v1", "categories": ["cs.SD", "eess.AS", "stat.AP"], "primary_category": "cs.SD"}
{"title": "A Machine Hearing System for Robust Cough Detection Based on a\n  High-Level Representation of Band-Specific Audio Features", "abstract": "Cough is a protective reflex conveying information on the state of the\nrespiratory system. Cough assessment has been limited so far to subjective\nmeasurement tools or uncomfortable (i.e., non-wearable) cough monitors. This\nlimits the potential of real-time cough monitoring to improve respiratory care.\nObjective: This paper presents a machine hearing system for audio-based robust\ncough segmentation that can be easily deployed in mobile scenarios. Methods:\nCough detection is performed in two steps. First, a short-term spectral feature\nset is separately computed in five predefined frequency bands: [0, 0.5), [0.5,\n1), [1, 1.5), [1.5, 2), and [2, 5.5125] kHz. Feature selection and combination\nare then applied to make the short-term feature set robust enough in different\nnoisy scenarios. Second, high-level data representation is achieved by\ncomputing the mean and standard deviation of short-term descriptors in 300 ms\nlong-term frames. Finally, cough detection is carried out using a support\nvector machine trained with data from different noisy scenarios. The system is\nevaluated using a patient signal database which emulates three real-life\nscenarios in terms of noise content. Results: The system achieves 92.71%\nsensitivity, 88.58% specificity, and 90.69% Area Under Receiver Operating\nCharacteristic (ROC) curve (AUC), outperforming state-of-the-art methods.\nConclusion: Our research outcome paves the way to create a device for cough\nmonitoring in real-life situations. Significance: Our proposal is aligned with\na more comfortable and less disruptive patient monitoring, with benefits for\npatients (allows self-monitoring of cough symptoms), practitioners (e.g.,\nassessment of treatments or better clinical understanding of cough patterns),\nand national health systems (by reducing hospitalizations).", "published": "2024-12-02 22:05:10", "link": "http://arxiv.org/abs/2412.01996v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
