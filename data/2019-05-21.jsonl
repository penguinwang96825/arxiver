{"title": "Generating Logical Forms from Graph Representations of Text and Entities", "abstract": "Structured information about entities is critical for many semantic parsing\ntasks. We present an approach that uses a Graph Neural Network (GNN)\narchitecture to incorporate information about relevant entities and their\nrelations during parsing. Combined with a decoder copy mechanism, this approach\nprovides a conceptually simple mechanism to generate logical forms with\nentities. We demonstrate that this approach is competitive with the\nstate-of-the-art across several tasks without pre-training, and outperforms\nexisting approaches when combined with BERT pre-training.", "published": "2019-05-21 02:13:03", "link": "http://arxiv.org/abs/1905.08407v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Answering while Summarizing: Multi-task Learning for Multi-hop QA with\n  Evidence Extraction", "abstract": "Question answering (QA) using textual sources for purposes such as reading\ncomprehension (RC) has attracted much attention. This study focuses on the task\nof explainable multi-hop QA, which requires the system to return the answer\nwith evidence sentences by reasoning and gathering disjoint pieces of the\nreference texts. It proposes the Query Focused Extractor (QFE) model for\nevidence extraction and uses multi-task learning with the QA model. QFE is\ninspired by extractive summarization models; compared with the existing method,\nwhich extracts each evidence sentence independently, it sequentially extracts\nevidence sentences by using an RNN with an attention mechanism on the question\nsentence. It enables QFE to consider the dependency among the evidence\nsentences and cover important information in the question sentence.\nExperimental results show that QFE with a simple RC baseline model achieves a\nstate-of-the-art evidence extraction score on HotpotQA. Although designed for\nRC, it also achieves a state-of-the-art evidence extraction score on FEVER,\nwhich is a recognizing textual entailment task on a large textual database.", "published": "2019-05-21 09:23:56", "link": "http://arxiv.org/abs/1905.08511v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MultiWiki: Interlingual Text Passage Alignment in Wikipedia", "abstract": "In this article we address the problem of text passage alignment across\ninterlingual article pairs in Wikipedia. We develop methods that enable the\nidentification and interlinking of text passages written in different languages\nand containing overlapping information. Interlingual text passage alignment can\nenable Wikipedia editors and readers to better understand language-specific\ncontext of entities, provide valuable insights in cultural differences and\nbuild a basis for qualitative analysis of the articles. An important challenge\nin this context is the trade-off between the granularity of the extracted text\npassages and the precision of the alignment. Whereas short text passages can\nresult in more precise alignment, longer text passages can facilitate a better\noverview of the differences in an article pair. To better understand these\naspects from the user perspective, we conduct a user study at the example of\nthe German, Russian and the English Wikipedia and collect a user-annotated\nbenchmark. Then we propose MultiWiki -- a method that adopts an integrated\napproach to the text passage alignment using semantic similarity measures and\ngreedy algorithms and achieves precise results with respect to the user-defined\nalignment. MultiWiki demonstration is publicly available and currently supports\nfour language pairs.", "published": "2019-05-21 14:47:35", "link": "http://arxiv.org/abs/1905.08675v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMR Parsing as Sequence-to-Graph Transduction", "abstract": "We propose an attention-based model that treats AMR parsing as\nsequence-to-graph transduction. Unlike most AMR parsers that rely on\npre-trained aligners, external semantic resources, or data augmentation, our\nproposed parser is aligner-free, and it can be effectively trained with limited\namounts of labeled AMR data. Our experimental results outperform all previously\nreported SMATCH scores, on both AMR 2.0 (76.3% F1 on LDC2017T10) and AMR 1.0\n(70.2% F1 on LDC2014T12).", "published": "2019-05-21 15:41:18", "link": "http://arxiv.org/abs/1905.08704v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparative Analysis of Distributional Term Representations for Author\n  Profiling in Social Media", "abstract": "Author Profiling (AP) aims at predicting specific characteristics from a\ngroup of authors by analyzing their written documents. Many research has been\nfocused on determining suitable features for modeling writing patterns from\nauthors. Reported results indicate that content-based features continue to be\nthe most relevant and discriminant features for solving this task. Thus, in\nthis paper, we present a thorough analysis regarding the appropriateness of\ndifferent distributional term representations (DTR) for the AP task. In this\nregard, we introduce a novel framework for supervised AP using these\nrepresentations and, supported on it. We approach a comparative analysis of\nrepresentations such as DOR, TCOR, SSR, and word2vec in the AP problem. We also\ncompare the performance of the DTRs against classic approaches including\npopular topic-based methods. The obtained results indicate that DTRs are\nsuitable for solving the AP task in social media domains as they achieve\ncompetitive results while providing meaningful interpretability.", "published": "2019-05-21 17:54:09", "link": "http://arxiv.org/abs/1905.08780v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EventKG - the Hub of Event Knowledge on the Web - and Biographical\n  Timeline Generation", "abstract": "One of the key requirements to facilitate the semantic analytics of\ninformation regarding contemporary and historical events on the Web, in the\nnews and in social media is the availability of reference knowledge\nrepositories containing comprehensive representations of events, entities and\ntemporal relations. Existing knowledge graphs, with popular examples including\nDBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are\ninsufficient in terms of their coverage and completeness with respect to events\nand temporal relations. In this article we address this limitation, formalise\nthe concept of a temporal knowledge graph and present its instantiation -\nEventKG. EventKG is a multilingual event-centric temporal knowledge graph that\nincorporates over 690 thousand events and over 2.3 million temporal relations\nobtained from several large-scale knowledge graphs and semi-structured sources\nand makes them available through a canonical RDF representation. Whereas\npopular entities often possess hundreds of relations within a temporal\nknowledge graph such as EventKG, generating a concise overview of the most\nimportant temporal relations for a given entity is a challenging task. In this\narticle we demonstrate an application of EventKG to biographical timeline\ngeneration, where we adopt a distant supervision method to identify relations\nmost relevant for an entity biography. Our evaluation results provide insights\non the characteristics of EventKG and demonstrate the effectiveness of the\nproposed biographical timeline generation method.", "published": "2019-05-21 15:14:34", "link": "http://arxiv.org/abs/1905.08794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sample Efficient Text Summarization Using a Single Pre-Trained\n  Transformer", "abstract": "Language model (LM) pre-training has resulted in impressive performance and\nsample efficiency on a variety of language understanding tasks. However, it\nremains unclear how to best use pre-trained LMs for generation tasks such as\nabstractive summarization, particularly to enhance sample efficiency. In these\nsequence-to-sequence settings, prior work has experimented with loading\npre-trained weights into the encoder and/or decoder networks, but used\nnon-pre-trained encoder-decoder attention weights. We instead use a pre-trained\ndecoder-only network, where the same Transformer LM both encodes the source and\ngenerates the summary. This ensures that all parameters in the network,\nincluding those governing attention over source states, have been pre-trained\nbefore the fine-tuning step. Experiments on the CNN/Daily Mail dataset show\nthat our pre-trained Transformer LM substantially improves over pre-trained\nTransformer encoder-decoder networks in limited-data settings. For instance, it\nachieves 13.1 ROUGE-2 using only 1% of the training data (~3000 examples),\nwhile pre-trained encoder-decoder models score 2.3 ROUGE-2.", "published": "2019-05-21 19:13:16", "link": "http://arxiv.org/abs/1905.08836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Look Again at the Syntax: Relational Graph Convolutional Network for\n  Gendered Ambiguous Pronoun Resolution", "abstract": "Gender bias has been found in existing coreference resolvers. In order to\neliminate gender bias, a gender-balanced dataset Gendered Ambiguous Pronouns\n(GAP) has been released and the best baseline model achieves only 66.9% F1.\nBidirectional Encoder Representations from Transformers (BERT) has broken\nseveral NLP task records and can be used on GAP dataset. However, fine-tune\nBERT on a specific task is computationally expensive. In this paper, we propose\nan end-to-end resolver by combining pre-trained BERT with Relational Graph\nConvolutional Network (R-GCN). R-GCN is used for digesting structural syntactic\ninformation and learning better task-specific embeddings. Empirical results\ndemonstrate that, under explicit syntactic supervision and without the need to\nfine tune BERT, R-GCN's embeddings outperform the original BERT embeddings on\nthe coreference task. Our work significantly improves the snippet-context\nbaseline F1 score on GAP dataset from 66.9% to 80.3%. We participated in the\n2019 GAP Coreference Shared Task, and our codes are available online.", "published": "2019-05-21 20:56:50", "link": "http://arxiv.org/abs/1905.08868v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Seq-to-Seq Transformer Premised Temporal Convolutional Network for\n  Chinese Word Segmentation", "abstract": "The prevalent approaches of Chinese word segmentation task almost rely on the\nBi-LSTM neural network. However, the methods based the Bi-LSTM have some\ninherent drawbacks: hard to parallel computing, little efficient in applying\nthe Dropout method to inhibit the Overfitting and little efficient in capturing\nthe character information at the more distant site of a long sentence for the\nword segmentation task. In this work, we propose a sequence-to-sequence\ntransformer model for Chinese word segmentation, which is premised a type of\nconvolutional neural network named temporal convolutional network. The model\nuses the temporal convolutional network to construct an encoder, and uses one\nlayer of fully-connected neural network to build a decoder, and applies the\nDropout method to inhibit the Overfitting, and captures the character\ninformation at the distant site of a sentence by adding the layers of the\nencoder, and binds Conditional Random Fields model to train parameters, and\nuses the Viterbi algorithm to infer the final result of the Chinese word\nsegmentation. The experiments on traditional Chinese corpora and simplified\nChinese corpora show that the performance of Chinese word segmentation of the\nmodel is equivalent to the performance of the methods based the Bi-LSTM, and\nthe model has a tremendous growth in parallel computing than the models based\nthe Bi-LSTM.", "published": "2019-05-21 06:12:47", "link": "http://arxiv.org/abs/1905.08454v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generic Multilayer Network Data Analysis with the Fusion of Content and\n  Structure", "abstract": "Multi-feature data analysis (e.g., on Facebook, LinkedIn) is challenging\nespecially if one wants to do it efficiently and retain the flexibility by\nchoosing features of interest for analysis. Features (e.g., age, gender,\nrelationship, political view etc.) can be explicitly given from datasets, but\nalso can be derived from content (e.g., political view based on Facebook\nposts). Analysis from multiple perspectives is needed to understand the\ndatasets (or subsets of it) and to infer meaningful knowledge. For example, the\ninfluence of age, location, and marital status on political views may need to\nbe inferred separately (or in combination). In this paper, we adapt multilayer\nnetwork (MLN) analysis, a nontraditional approach, to model the Facebook\ndatasets, integrate content analysis, and conduct analysis, which is driven by\na list of desired application based queries. Our experimental analysis shows\nthe flexibility and efficiency of the proposed approach when modeling and\nanalyzing datasets with multiple features.", "published": "2019-05-21 13:41:47", "link": "http://arxiv.org/abs/1905.08635v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Transferable Multi-Domain State Generator for Task-Oriented Dialogue\n  Systems", "abstract": "Over-dependence on domain ontology and lack of knowledge sharing across\ndomains are two practical and yet less studied problems of dialogue state\ntracking. Existing approaches generally fall short in tracking unknown slot\nvalues during inference and often have difficulties in adapting to new domains.\nIn this paper, we propose a Transferable Dialogue State Generator (TRADE) that\ngenerates dialogue states from utterances using a copy mechanism, facilitating\nknowledge transfer when predicting (domain, slot, value) triplets not\nencountered during training. Our model is composed of an utterance encoder, a\nslot gate, and a state generator, which are shared across domains. Empirical\nresults demonstrate that TRADE achieves state-of-the-art joint goal accuracy of\n48.62% for the five domains of MultiWOZ, a human-human dialogue dataset. In\naddition, we show its transferring ability by simulating zero-shot and few-shot\ndialogue state tracking for unseen domains. TRADE achieves 60.58% joint goal\naccuracy in one of the zero-shot domains, and is able to adapt to few-shot\ncases without forgetting already trained domains.", "published": "2019-05-21 16:43:54", "link": "http://arxiv.org/abs/1905.08743v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Predicting TED Talk Ratings from Language and Prosody", "abstract": "We use the largest open repository of public speaking---TED Talks---to\npredict the ratings of the online viewers. Our dataset contains over 2200 TED\nTalk transcripts (includes over 200 thousand sentences), audio features and the\nassociated meta information including about 5.5 Million ratings from\nspontaneous visitors of the website. We propose three neural network\narchitectures and compare with statistical machine learning. Our experiments\nreveal that it is possible to predict all the 14 different ratings with an\naverage AUC of 0.83 using the transcripts and prosody features only. The\ndataset and the complete source code is available for further analysis.", "published": "2019-05-21 00:38:33", "link": "http://arxiv.org/abs/1906.03940v1", "categories": ["cs.MM", "cs.CL"], "primary_category": "cs.MM"}
{"title": "A Causality-Guided Prediction of the TED Talk Ratings from the\n  Speech-Transcripts using Neural Networks", "abstract": "Automated prediction of public speaking performance enables novel systems for\ntutoring public speaking skills. We use the largest open repository---TED\nTalks---to predict the ratings provided by the online viewers. The dataset\ncontains over 2200 talk transcripts and the associated meta information\nincluding over 5.5 million ratings from spontaneous visitors to the website. We\ncarefully removed the bias present in the dataset (e.g., the speakers'\nreputations, popularity gained by publicity, etc.) by modeling the data\ngenerating process using a causal diagram. We use a word sequence based\nrecurrent architecture and a dependency tree based recursive architecture as\nthe neural networks for predicting the TED talk ratings. Our neural network\nmodels can predict the ratings with an average F-score of 0.77 which largely\noutperforms the competitive baseline method.", "published": "2019-05-21 00:32:21", "link": "http://arxiv.org/abs/1905.08392v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Non-Autoregressive Neural Text-to-Speech", "abstract": "In this work, we propose ParaNet, a non-autoregressive seq2seq model that\nconverts text to spectrogram. It is fully convolutional and brings 46.7 times\nspeed-up over the lightweight Deep Voice 3 at synthesis, while obtaining\nreasonably good speech quality. ParaNet also produces stable alignment between\ntext and speech on the challenging test sentences by iteratively improving the\nattention in a layer-by-layer manner. Furthermore, we build the parallel\ntext-to-speech system and test various parallel neural vocoders, which can\nsynthesize speech from text through a single feed-forward pass. We also explore\na novel VAE-based approach to train the inverse autoregressive flow (IAF) based\nparallel vocoder from scratch, which avoids the need for distillation from a\nseparately trained WaveNet as previous work.", "published": "2019-05-21 06:36:15", "link": "http://arxiv.org/abs/1905.08459v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CNNs found to jump around more skillfully than RNNs: Compositional\n  generalization in seq2seq convolutional networks", "abstract": "Lake and Baroni (2018) introduced the SCAN dataset probing the ability of\nseq2seq models to capture compositional generalizations, such as inferring the\nmeaning of \"jump around\" 0-shot from the component words. Recurrent networks\n(RNNs) were found to completely fail the most challenging generalization cases.\nWe test here a convolutional network (CNN) on these tasks, reporting hugely\nimproved performance with respect to RNNs. Despite the big improvement, the CNN\nhas however not induced systematic rules, suggesting that the difference\nbetween compositional and non-compositional behaviour is not clear-cut.", "published": "2019-05-21 10:14:12", "link": "http://arxiv.org/abs/1905.08527v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Approximating probabilistic models as weighted finite automata", "abstract": "Weighted finite automata (WFA) are often used to represent probabilistic\nmodels, such as $n$-gram language models, since they are efficient for\nrecognition tasks in time and space. The probabilistic source to be represented\nas a WFA, however, may come in many forms. Given a generic probabilistic model\nover sequences, we propose an algorithm to approximate it as a weighted finite\nautomaton such that the Kullback-Leiber divergence between the source model and\nthe WFA target model is minimized. The proposed algorithm involves a counting\nstep and a difference of convex optimization step, both of which can be\nperformed efficiently. We demonstrate the usefulness of our approach on various\ntasks, including distilling $n$-gram models from neural models, building\ncompact language models, and building open-vocabulary character models. The\nalgorithms used for these experiments are available in an open-source software\nlibrary.", "published": "2019-05-21 15:36:54", "link": "http://arxiv.org/abs/1905.08701v3", "categories": ["cs.CL", "cs.FL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "A realistic and robust model for Chinese word segmentation", "abstract": "A realistic Chinese word segmentation tool must adapt to textual variations\nwith minimal training input and yet robust enough to yield reliable\nsegmentation result for all variants. Various lexicon-driven approaches to\nChinese segmentation, e.g. [1,16], achieve high f-scores yet require massive\ntraining for any variation. Text-driven approach, e.g. [12], can be easily\nadapted for domain and genre changes yet has difficulty matching the high\nf-scores of the lexicon-driven approaches. In this paper, we refine and\nimplement an innovative text-driven word boundary decision (WBD) segmentation\nmodel proposed in [15]. The WBD model treats word segmentation simply and\nefficiently as a binary decision on whether to realize the natural textual\nbreak between two adjacent characters as a word boundary. The WBD model allows\nsimple and quick training data preparation converting characters as contextual\nvectors for learning the word boundary decision. Machine learning experiments\nwith four different classifiers show that training with 1,000 vectors and 1\nmillion vectors achieve comparable and reliable results. In addition, when\napplied to SigHAN Bakeoff 3 competition data, the WBD model produces OOV recall\nrates that are higher than all published results. Unlike all previous work, our\nOOV recall rate is comparable to our own F-score. Both experiments support the\nclaim that the WBD model is a realistic model for Chinese word segmentation as\nit can be easily adapted for new variants with the robust result. In\nconclusion, we will discuss linguistic ramifications as well as future\nimplications for the WBD approach.", "published": "2019-05-21 16:22:47", "link": "http://arxiv.org/abs/1905.08732v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sampling from Stochastic Finite Automata with Applications to CTC\n  Decoding", "abstract": "Stochastic finite automata arise naturally in many language and speech\nprocessing tasks. They include stochastic acceptors, which represent certain\nprobability distributions over random strings. We consider the problem of\nefficient sampling: drawing random string variates from the probability\ndistribution represented by stochastic automata and transformations of those.\nWe show that path-sampling is effective and can be efficient if the\nepsilon-graph of a finite automaton is acyclic. We provide an algorithm that\nensures this by conflating epsilon-cycles within strongly connected components.\nSampling is also effective in the presence of non-injective transformations of\nstrings. We illustrate this in the context of decoding for Connectionist\nTemporal Classification (CTC), where the predictive probabilities yield\nauxiliary sequences which are transformed into shorter labeling strings. We can\nsample efficiently from the transformed labeling distribution and use this in\ntwo different strategies for finding the most probable CTC labeling.", "published": "2019-05-21 17:26:39", "link": "http://arxiv.org/abs/1905.08760v1", "categories": ["cs.CL", "cs.FL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Acoustic-to-Word Models with Conversational Context Information", "abstract": "Conversational context information, higher-level knowledge that spans across\nsentences, can help to recognize a long conversation. However, existing speech\nrecognition models are typically built at a sentence level, and thus it may not\ncapture important conversational context information. The recent progress in\nend-to-end speech recognition enables integrating context with other available\ninformation (e.g., acoustic, linguistic resources) and directly recognizing\nwords from speech. In this work, we present a direct acoustic-to-word,\nend-to-end speech recognition model capable of utilizing the conversational\ncontext to better process long conversations. We evaluate our proposed approach\non the Switchboard conversational speech corpus and show that our system\noutperforms a standard end-to-end speech recognition system.", "published": "2019-05-21 15:44:03", "link": "http://arxiv.org/abs/1905.08796v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Domain adaptation for part-of-speech tagging of noisy user-generated\n  text", "abstract": "The performance of a Part-of-speech (POS) tagger is highly dependent on the\ndomain ofthe processed text, and for many domains there is no or only very\nlittle training data available. This work addresses the problem of POS tagging\nnoisy user-generated text using a neural network. We propose an architecture\nthat trains an out-of-domain model on a large newswire corpus, and transfers\nthose weights by using them as a prior for a model trained on the target domain\n(a data-set of German Tweets) for which there is very little an-notations\navailable. The neural network has two standard bidirectional LSTMs at its core.\nHowever, we find it crucial to also encode a set of task-specific features, and\nto obtain reliable (source-domain and target-domain) word representations.\nExperiments with different regularization techniques such as early stopping,\ndropout and fine-tuning the domain adaptation prior weights are conducted. Our\nbest model uses external weights from the out-of-domain model, as well as\nfeature embeddings, pre-trained word and sub-word embeddings and achieves a\ntagging accuracy of slightly over 90%, improving on the previous state of the\nart for this task.", "published": "2019-05-21 10:33:06", "link": "http://arxiv.org/abs/1905.08920v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "DNN-Based Speech Presence Probability Estimation for Multi-Frame\n  Single-Microphone Speech Enhancement", "abstract": "Multi-frame approaches for single-microphone speech enhancement, e.g., the\nmulti-frame minimum-power-distortionless-response (MFMPDR) filter, are able to\nexploit speech correlations across neighboring time frames. In contrast to\nsingle-frame approaches such as the Wiener gain, it has been shown that\nmulti-frame approaches achieve a substantial noise reduction with hardly any\nspeech distortion, provided that an accurate estimate of the correlation\nmatrices and especially the speech interframe correlation (IFC) vector is\navailable. Typical estimation procedures of the IFC vector require an estimate\nof the speech presence probability (SPP) in each time-frequency (TF) bin. In\nthis paper, we propose to use a bi-directional long short-term memory deep\nneural network (DNN) to estimate the SPP for each TF bin. Aiming at achieving a\nrobust performance, the DNN is trained for various noise types and within a\nlarge signal-to-noise-ratio range. Experimental results show that the MFMPDR in\ncombination with the proposed data-driven SPP estimator yields an increased\nspeech quality compared to a state-of-the-art model-based SPP estimator.\nFurthermore, it is confirmed that exploiting interframe correlations in the\nMFMPDR is beneficial when compared to the Wiener gain especially in adverse\nscenarios.", "published": "2019-05-21 08:39:06", "link": "http://arxiv.org/abs/1905.08492v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A multi-room reverberant dataset for sound event localization and\n  detection", "abstract": "This paper presents the sound event localization and detection (SELD) task\nsetup for the DCASE 2019 challenge. The goal of the SELD task is to detect the\ntemporal activities of a known set of sound event classes, and further localize\nthem in space when active. As part of the challenge, a synthesized dataset with\neach sound event associated with a spatial coordinate represented using azimuth\nand elevation angles is provided. These sound events are spatialized using\nreal-life impulse responses collected at multiple spatial coordinates in five\ndifferent rooms with varying dimensions and material properties. A baseline\nSELD method employing a convolutional recurrent neural network is used to\ngenerate benchmark scores for this reverberant dataset. The benchmark scores\nare obtained using the recommended cross-validation setup.", "published": "2019-05-21 11:05:53", "link": "http://arxiv.org/abs/1905.08546v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Une ou deux composantes ? La r\u00e9ponse de la diffusion en ondelettes", "abstract": "With the aim of constructing a biologically plausible model of machine\nlistening, we study the representation of a multicomponent stationary signal by\na wavelet scattering network. First, we show that renormalizing second-order\nnodes by their first-order parents gives a simple numerical criterion to\nestablish whether two neighboring components will interfere psychoacoustically.\nSecondly, we generalize the `one or two components' framework to three sine\nwaves or more, and show that a network of depth $M = \\log_2 N$ suffices to\ncharacterize the relative amplitudes of the first $N$ terms in a Fourier\nseries, while enjoying properties of invariance to frequency transposition and\ncomponent-wise phase shifts.", "published": "2019-05-21 13:14:37", "link": "http://arxiv.org/abs/1905.08601v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Effective parameter estimation methods for an ExcitNet model in\n  generative text-to-speech systems", "abstract": "In this paper, we propose a high-quality generative text-to-speech (TTS)\nsystem using an effective spectrum and excitation estimation method. Our\nprevious research verified the effectiveness of the ExcitNet-based speech\ngeneration model in a parametric TTS framework. However, the challenge remains\nto build a high-quality speech synthesis system because auxiliary conditional\nfeatures estimated by a simple deep neural network often contain large\nprediction errors, and the errors are inevitably propagated throughout the\nautoregressive generation process of the ExcitNet vocoder. To generate more\nnatural speech signals, we exploited a sequence-to-sequence (seq2seq) acoustic\nmodel with an attention-based generative network (e.g., Tacotron 2) to estimate\nthe condition parameters of the ExcitNet vocoder. Because the seq2seq acoustic\nmodel accurately estimates spectral parameters, and because the ExcitNet model\neffectively generates the corresponding time-domain excitation signals,\ncombining these two models can synthesize natural speech signals. Furthermore,\nwe verified the merit of the proposed method in producing expressive speech\nsegments by adopting a global style token-based emotion embedding method. The\nexperimental results confirmed that the proposed system significantly\noutperforms the systems with a similarly configured conventional WaveNet\nvocoder and our best prior parametric TTS counterpart.", "published": "2019-05-21 08:24:06", "link": "http://arxiv.org/abs/1905.08486v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Bayesian Pitch Tracking Based on the Harmonic Model", "abstract": "Fundamental frequency is one of the most important characteristics of speech\nand audio signals. Harmonic model-based fundamental frequency estimators offer\na higher estimation accuracy and robustness against noise than the widely used\nautocorrelation-based methods. However, the traditional harmonic model-based\nestimators do not take the temporal smoothness of the fundamental frequency,\nthe model order, and the voicing into account as they process each data segment\nindependently. In this paper, a fully Bayesian fundamental frequency tracking\nalgorithm based on the harmonic model and a first-order Markov process model is\nproposed. Smoothness priors are imposed on the fundamental frequencies, model\norders, and voicing using first-order Markov process models. Using these Markov\nmodels, fundamental frequency estimation and voicing detection errors can be\nreduced. Using the harmonic model, the proposed fundamental frequency tracker\nhas an improved robustness to noise. An analytical form of the likelihood\nfunction, which can be computed efficiently, is derived. Compared to the\nstate-of-the-art neural network and non-parametric approaches, the proposed\nfundamental frequency tracking algorithm reduces the mean absolute errors and\ngross errors by 15\\% and 20\\% on the Keele pitch database and 36\\% and 26\\% on\nsustained /a/ sounds from a database of Parkinson's disease voices under 0 dB\nwhite Gaussian noise. A MATLAB version of the proposed algorithm is made freely\navailable for reproduction of the results\\footnote{An implementation of the\nproposed algorithm using MATLAB may be found in\n\\url{https://tinyurl.com/yxn4a543}", "published": "2019-05-21 11:24:16", "link": "http://arxiv.org/abs/1905.08557v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
