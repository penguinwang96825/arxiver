{"title": "Adapting predominant and novel sense discovery algorithms for\n  identifying corpus-specific sense differences", "abstract": "Word senses are not static and may have temporal, spatial or corpus-specific\nscopes. Identifying such scopes might benefit the existing WSD systems largely.\nIn this paper, while studying corpus specific word senses, we adapt three\nexisting predominant and novel-sense discovery algorithms to identify these\ncorpus-specific senses. We make use of text data available in the form of\nmillions of digitized books and newspaper archives as two different sources of\ncorpora and propose automated methods to identify corpus-specific word senses\nat various time points. We conduct an extensive and thorough human judgment\nexperiment to rigorously evaluate and compare the performance of these\napproaches. Post adaptation, the output of the three algorithms are in the same\nformat and the accuracy results are also comparable, with roughly 45-60% of the\nreported corpus-specific senses being judged as genuine.", "published": "2018-02-01 10:35:17", "link": "http://arxiv.org/abs/1802.00231v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emerging Language Spaces Learned From Massively Multilingual Corpora", "abstract": "Translations capture important information about languages that can be used\nas implicit supervision in learning linguistic properties and semantic\nrepresentations. In an information-centric view, translated texts may be\nconsidered as semantic mirrors of the original text and the significant\nvariations that we can observe across various languages can be used to\ndisambiguate a given expression using the linguistic signal that is grounded in\ntranslation. Parallel corpora consisting of massive amounts of human\ntranslations with a large linguistic variation can be applied to increase\nabstractions and we propose the use of highly multilingual machine translation\nmodels to find language-independent meaning representations. Our initial\nexperiments show that neural machine translation models can indeed learn in\nsuch a setup and we can show that the learning algorithm picks up information\nabout the relation between languages in order to optimize transfer leaning with\nshared parameters. The model creates a continuous language space that\nrepresents relationships in terms of geometric distances, which we can\nvisualize to illustrate how languages cluster according to language families\nand groups. Does this open the door for new ideas of data-driven language\ntypology with promising models and techniques in empirical cross-linguistic\nresearch?", "published": "2018-02-01 12:58:16", "link": "http://arxiv.org/abs/1802.00273v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Goal-Oriented Chatbot Dialog Management Bootstrapping with Transfer\n  Learning", "abstract": "Goal-Oriented (GO) Dialogue Systems, colloquially known as goal oriented\nchatbots, help users achieve a predefined goal (e.g. book a movie ticket)\nwithin a closed domain. A first step is to understand the user's goal by using\nnatural language understanding techniques. Once the goal is known, the bot must\nmanage a dialogue to achieve that goal, which is conducted with respect to a\nlearnt policy. The success of the dialogue system depends on the quality of the\npolicy, which is in turn reliant on the availability of high-quality training\ndata for the policy learning method, for instance Deep Reinforcement Learning.\n  Due to the domain specificity, the amount of available data is typically too\nlow to allow the training of good dialogue policies. In this paper we introduce\na transfer learning method to mitigate the effects of the low in-domain data\navailability. Our transfer learning based approach improves the bot's success\nrate by 20% in relative terms for distant domains and we more than double it\nfor close domains, compared to the model without transfer learning. Moreover,\nthe transfer learning chatbots learn the policy up to 5 to 10 times faster.\nFinally, as the transfer learning approach is complementary to additional\nprocessing such as warm-starting, we show that their joint application gives\nthe best outcomes.", "published": "2018-02-01 21:50:40", "link": "http://arxiv.org/abs/1802.00500v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Unified Deep Learning Architecture for Abuse Detection", "abstract": "Hate speech, offensive language, sexism, racism and other types of abusive\nbehavior have become a common phenomenon in many online social media platforms.\nIn recent years, such diverse abusive behaviors have been manifesting with\nincreased frequency and levels of intensity. This is due to the openness and\nwillingness of popular media platforms, such as Twitter and Facebook, to host\ncontent of sensitive or controversial topics. However, these platforms have not\nadequately addressed the problem of online abusive behavior, and their\nresponsiveness to the effective detection and blocking of such inappropriate\nbehavior remains limited.\n  In the present paper, we study this complex problem by following a more\nholistic approach, which considers the various aspects of abusive behavior. To\nmake the approach tangible, we focus on Twitter data and analyze user and\ntextual properties from different angles of abusive posting behavior. We\npropose a deep learning architecture, which utilizes a wide variety of\navailable metadata, and combines it with automatically-extracted hidden\npatterns within the text of the tweets, to detect multiple abusive behavioral\nnorms which are highly inter-related. We apply this unified architecture in a\nseamless, transparent fashion to detect different types of abusive behavior\n(hate speech, sexism vs. racism, bullying, sarcasm, etc.) without the need for\nany tuning of the model architecture for each task. We test the proposed\napproach with multiple datasets addressing different and multiple abusive\nbehaviors on Twitter. Our results demonstrate that it largely outperforms the\nstate-of-art methods (between 21 and 45\\% improvement in AUC, depending on the\ndataset).", "published": "2018-02-01 16:48:39", "link": "http://arxiv.org/abs/1802.00385v2", "categories": ["cs.CL", "cs.SI", "68T06", "K.4.2"], "primary_category": "cs.CL"}
{"title": "Adaptive Memory Networks", "abstract": "We present Adaptive Memory Networks (AMN) that processes input-question pairs\nto dynamically construct a network architecture optimized for lower inference\ntimes for Question Answering (QA) tasks. AMN processes the input story to\nextract entities and stores them in memory banks. Starting from a single bank,\nas the number of input entities increases, AMN learns to create new banks as\nthe entropy in a single bank becomes too high. Hence, after processing an\ninput-question(s) pair, the resulting network represents a hierarchical\nstructure where entities are stored in different banks, distanced by question\nrelevance. At inference, one or few banks are used, creating a tradeoff between\naccuracy and performance. AMN is enabled by dynamic networks that allow input\ndependent network creation and efficiency in dynamic mini-batching as well as\nour novel bank controller that allows learning discrete decision making with\nhigh accuracy. In our results, we demonstrate that AMN learns to create\nvariable depth networks depending on task complexity and reduces inference\ntimes for QA tasks.", "published": "2018-02-01 22:33:56", "link": "http://arxiv.org/abs/1802.00510v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Phonetic and Graphemic Systems for Multi-Genre Broadcast Transcription", "abstract": "State-of-the-art English automatic speech recognition systems typically use\nphonetic rather than graphemic lexicons. Graphemic systems are known to perform\nless well for English as the mapping from the written form to the spoken form\nis complicated. However, in recent years the representational power of\ndeep-learning based acoustic models has improved, raising interest in graphemic\nacoustic models for English, due to the simplicity of generating the lexicon.\nIn this paper, phonetic and graphemic models are compared for an English\nMulti-Genre Broadcast transcription task. A range of acoustic models based on\nlattice-free MMI training are constructed using phonetic and graphemic\nlexicons. For this task, it is found that having a long-span temporal history\nreduces the difference in performance between the two forms of models. In\naddition, system combination is examined, using parameter smoothing and\nhypothesis combination. As the combination approaches become more complicated\nthe difference between the phonetic and graphemic systems further decreases.\nFinally, for all configurations examined the combination of phonetic and\ngraphemic systems yields consistent gains.", "published": "2018-02-01 12:00:45", "link": "http://arxiv.org/abs/1802.00254v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Classifying medical notes into standard disease codes using Machine\n  Learning", "abstract": "We investigate the automatic classification of patient discharge notes into\nstandard disease labels. We find that Convolutional Neural Networks with\nAttention outperform previous algorithms used in this task, and suggest further\nareas for improvement.", "published": "2018-02-01 16:46:00", "link": "http://arxiv.org/abs/1802.00382v1", "categories": ["cs.LG", "cs.CL", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Disunited Nations? A Multiplex Network Approach to Detecting Preference\n  Affinity Blocs using Texts and Votes", "abstract": "This paper contributes to an emerging literature that models votes and text\nin tandem to better understand polarization of expressed preferences. It\nintroduces a new approach to estimate preference polarization in\nmultidimensional settings, such as international relations, based on\ndevelopments in the natural language processing and network science literatures\n-- namely word embeddings, which retain valuable syntactical qualities of human\nlanguage, and community detection in multilayer networks, which locates densely\nconnected actors across multiple, complex networks. We find that the employment\nof these tools in tandem helps to better estimate states' foreign policy\npreferences expressed in UN votes and speeches beyond that permitted by votes\nalone. The utility of these located affinity blocs is demonstrated through an\napplication to conflict onset in International Relations, though these tools\nwill be of interest to all scholars faced with the measurement of preferences\nand polarization in multidimensional settings.", "published": "2018-02-01 17:08:48", "link": "http://arxiv.org/abs/1802.00396v2", "categories": ["cs.CL", "cs.CY", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Dual Recurrent Attention Units for Visual Question Answering", "abstract": "Visual Question Answering (VQA) requires AI models to comprehend data in two\ndomains, vision and text. Current state-of-the-art models use learned attention\nmechanisms to extract relevant information from the input domains to answer a\ncertain question. Thus, robust attention mechanisms are essential for powerful\nVQA models. In this paper, we propose a recurrent attention mechanism and show\nits benefits compared to the traditional convolutional approach. We perform two\nablation studies to evaluate recurrent attention. First, we introduce a\nbaseline VQA model with visual attention and test the performance difference\nbetween convolutional and recurrent attention on the VQA 2.0 dataset. Secondly,\nwe design an architecture for VQA which utilizes dual (textual and visual)\nRecurrent Attention Units (RAUs). Using this model, we show the effect of all\npossible combinations of recurrent and convolutional dual attention. Our single\nmodel outperforms the first place winner on the VQA 2016 challenge and to the\nbest of our knowledge, it is the second best performing single model on the VQA\n1.0 dataset. Furthermore, our model noticeably improves upon the winner of the\nVQA 2017 challenge. Moreover, we experiment replacing attention mechanisms in\nstate-of-the-art models with our RAUs and show increased performance.", "published": "2018-02-01 09:35:33", "link": "http://arxiv.org/abs/1802.00209v3", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.NE", "stat.ML"], "primary_category": "cs.AI"}
{"title": "MaD TwinNet: Masker-Denoiser Architecture with Twin Networks for\n  Monaural Sound Source Separation", "abstract": "Monaural singing voice separation task focuses on the prediction of the\nsinging voice from a single channel music mixture signal. Current state of the\nart (SOTA) results in monaural singing voice separation are obtained with deep\nlearning based methods. In this work we present a novel deep learning based\nmethod that learns long-term temporal patterns and structures of a musical\npiece. We build upon the recently proposed Masker-Denoiser (MaD) architecture\nand we enhance it with the Twin Networks, a technique to regularize a recurrent\ngenerative network using a backward running copy of the network. We evaluate\nour method using the Demixing Secret Dataset and we obtain an increment to\nsignal-to-distortion ratio (SDR) of 0.37 dB and to signal-to-interference ratio\n(SIR) of 0.23 dB, compared to previous SOTA results.", "published": "2018-02-01 14:31:36", "link": "http://arxiv.org/abs/1802.00300v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Approximate Message Passing for Underdetermined Audio Source Separation", "abstract": "Approximate message passing (AMP) algorithms have shown great promise in\nsparse signal reconstruction due to their low computational requirements and\nfast convergence to an exact solution. Moreover, they provide a probabilistic\nframework that is often more intuitive than alternatives such as convex\noptimisation. In this paper, AMP is used for audio source separation from\nunderdetermined instantaneous mixtures. In the time-frequency domain, it is\ntypical to assume a priori that the sources are sparse, so we solve the\ncorresponding sparse linear inverse problem using AMP. We present a block-based\napproach that uses AMP to process multiple time-frequency points\nsimultaneously. Two algorithms known as AMP and vector AMP (VAMP) are evaluated\nin particular. Results show that they are promising in terms of artefact\nsuppression.", "published": "2018-02-01 16:41:09", "link": "http://arxiv.org/abs/1802.00380v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
