{"title": "Discovering Lexical Similarity Through Articulatory Feature-based\n  Phonetic Edit Distance", "abstract": "Lexical Similarity (LS) between two languages uncovers many interesting\nlinguistic insights such as genetic relationship, mutual intelligibility, and\nthe usage of one's vocabulary into other. There are various methods through\nwhich LS is evaluated. In the same regard, this paper presents a method of\nPhonetic Edit Distance (PED) that uses a soft comparison of letters using the\narticulatory features associated with them. The system converts the words into\nthe corresponding International Phonetic Alphabet (IPA), followed by the\nconversion of IPA into its set of articulatory features. Later, the lists of\nthe set of articulatory features are compared using the proposed method. As an\nexample, PED gives edit distance of German word vater and Persian word pidar as\n0.82; and similarly, Hebrew word shalom and Arabic word salaam as 0.93, whereas\nfor a juxtapose comparison, their IPA based edit distances are 4 and 2\nrespectively. Experiments are performed with six languages (Arabic, Hindi,\nMarathi, Persian, Sanskrit, and Urdu). In this regard, we extracted part of\nspeech wise word-lists from the Universal Dependency corpora and evaluated the\nLS for every pair of language. Thus, with the proposed approach, we find the\ngenetic affinity, similarity, and borrowing/loan-words despite having script\ndifferences and sound variation phenomena among these languages.", "published": "2020-08-16 09:28:37", "link": "http://arxiv.org/abs/2008.06865v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act\n  Recognition and Sentiment Classification", "abstract": "In dialog system, dialog act recognition and sentiment classification are two\ncorrelative tasks to capture speakers intentions, where dialog act and\nsentiment can indicate the explicit and the implicit intentions separately.\nMost of the existing systems either treat them as separate tasks or just\njointly model the two tasks by sharing parameters in an implicit way without\nexplicitly modeling mutual interaction and relation. To address this problem,\nwe propose a Deep Co-Interactive Relation Network (DCR-Net) to explicitly\nconsider the cross-impact and model the interaction between the two tasks by\nintroducing a co-interactive relation layer. In addition, the proposed relation\nlayer can be stacked to gradually capture mutual knowledge with multiple steps\nof interaction. Especially, we thoroughly study different relation layers and\ntheir effects. Experimental results on two public datasets (Mastodon and\nDailydialog) show that our model outperforms the state-of-the-art joint model\nby 4.3% and 3.4% in terms of F1 score on dialog act recognition task, 5.7% and\n12.4% on sentiment classification respectively. Comprehensive analysis\nempirically verifies the effectiveness of explicitly modeling the relation\nbetween the two tasks and the multi-steps interaction mechanism. Finally, we\nemploy the Bidirectional Encoder Representation from Transformer (BERT) in our\nframework, which can further boost our performance in both tasks.", "published": "2020-08-16 14:13:32", "link": "http://arxiv.org/abs/2008.06914v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adding Recurrence to Pretrained Transformers for Improved Efficiency and\n  Context Size", "abstract": "Fine-tuning a pretrained transformer for a downstream task has become a\nstandard method in NLP in the last few years. While the results from these\nmodels are impressive, applying them can be extremely computationally\nexpensive, as is pretraining new models with the latest architectures. We\npresent a novel method for applying pretrained transformer language models\nwhich lowers their memory requirement both at training and inference time. An\nadditional benefit is that our method removes the fixed context size constraint\nthat most transformer models have, allowing for more flexible use. When applied\nto the GPT-2 language model, we find that our method attains better perplexity\nthan an unmodified GPT-2 model on the PG-19 and WikiText-103 corpora, for a\ngiven amount of computation or memory.", "published": "2020-08-16 23:19:30", "link": "http://arxiv.org/abs/2008.07027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeVLBert: Learning Deconfounded Visio-Linguistic Representations", "abstract": "In this paper, we propose to investigate the problem of out-of-domain\nvisio-linguistic pretraining, where the pretraining data distribution differs\nfrom that of downstream data on which the pretrained model will be fine-tuned.\nExisting methods for this problem are purely likelihood-based, leading to the\nspurious correlations and hurt the generalization ability when transferred to\nout-of-domain downstream tasks. By spurious correlation, we mean that the\nconditional probability of one token (object or word) given another one can be\nhigh (due to the dataset biases) without robust (causal) relationships between\nthem. To mitigate such dataset biases, we propose a Deconfounded\nVisio-Linguistic Bert framework, abbreviated as DeVLBert, to perform\nintervention-based learning. We borrow the idea of the backdoor adjustment from\nthe research field of causality and propose several neural-network based\narchitectures for Bert-style out-of-domain pretraining. The quantitative\nresults on three downstream tasks, Image Retrieval (IR), Zero-shot IR, and\nVisual Question Answering, show the effectiveness of DeVLBert by boosting\ngeneralization ability.", "published": "2020-08-16 11:09:22", "link": "http://arxiv.org/abs/2008.06884v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Efficient Knowledge Graph Validation via Cross-Graph Representation\n  Learning", "abstract": "Recent advances in information extraction have motivated the automatic\nconstruction of huge Knowledge Graphs (KGs) by mining from large-scale text\ncorpus. However, noisy facts are unavoidably introduced into KGs that could be\ncaused by automatic extraction. To validate the correctness of facts (i.e.,\ntriplets) inside a KG, one possible approach is to map the triplets into vector\nrepresentations by capturing the semantic meanings of facts. Although many\nrepresentation learning approaches have been developed for knowledge graphs,\nthese methods are not effective for validation. They usually assume that facts\nare correct, and thus may overfit noisy facts and fail to detect such facts.\nTowards effective KG validation, we propose to leverage an external\nhuman-curated KG as auxiliary information source to help detect the errors in a\ntarget KG. The external KG is built upon human-curated knowledge repositories\nand tends to have high precision. On the other hand, although the target KG\nbuilt by information extraction from texts has low precision, it can cover new\nor domain-specific facts that are not in any human-curated repositories. To\ntackle this challenging task, we propose a cross-graph representation learning\nframework, i.e., CrossVal, which can leverage an external KG to validate the\nfacts in the target KG efficiently. This is achieved by embedding triplets\nbased on their semantic meanings, drawing cross-KG negative samples and\nestimating a confidence score for each triplet based on its degree of\ncorrectness. We evaluate the proposed framework on datasets across different\ndomains. Experimental results show that the proposed framework achieves the\nbest performance compared with the state-of-the-art methods on large-scale KGs.", "published": "2020-08-16 20:51:17", "link": "http://arxiv.org/abs/2008.06995v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "abstract": "Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.", "published": "2020-08-16 08:06:52", "link": "http://arxiv.org/abs/2008.06854v1", "categories": ["cs.CL", "cs.CY", "cs.MM"], "primary_category": "cs.CL"}
{"title": "TextDecepter: Hard Label Black Box Attack on Text Classifiers", "abstract": "Machine learning has been proven to be susceptible to carefully crafted\nsamples, known as adversarial examples. The generation of these adversarial\nexamples helps to make the models more robust and gives us an insight into the\nunderlying decision-making of these models. Over the years, researchers have\nsuccessfully attacked image classifiers in both, white and black-box settings.\nHowever, these methods are not directly applicable to texts as text data is\ndiscrete. In recent years, research on crafting adversarial examples against\ntextual applications has been on the rise. In this paper, we present a novel\napproach for hard-label black-box attacks against Natural Language Processing\n(NLP) classifiers, where no model information is disclosed, and an attacker can\nonly query the model to get a final decision of the classifier, without\nconfidence scores of the classes involved. Such an attack scenario applies to\nreal-world black-box models being used for security-sensitive applications such\nas sentiment analysis and toxic content detection.", "published": "2020-08-16 08:57:01", "link": "http://arxiv.org/abs/2008.06860v6", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Audio Dequantization for High Fidelity Audio Generation in Flow-based\n  Neural Vocoder", "abstract": "In recent works, a flow-based neural vocoder has shown significant\nimprovement in real-time speech generation task. The sequence of invertible\nflow operations allows the model to convert samples from simple distribution to\naudio samples. However, training a continuous density model on discrete audio\ndata can degrade model performance due to the topological difference between\nlatent and actual distribution. To resolve this problem, we propose audio\ndequantization methods in flow-based neural vocoder for high fidelity audio\ngeneration. Data dequantization is a well-known method in image generation but\nhas not yet been studied in the audio domain. For this reason, we implement\nvarious audio dequantization methods in flow-based neural vocoder and\ninvestigate the effect on the generated audio. We conduct various objective\nperformance assessments and subjective evaluation to show that audio\ndequantization can improve audio generation quality. From our experiments,\nusing audio dequantization produces waveform audio with better harmonic\nstructure and fewer digital artifacts.", "published": "2020-08-16 09:37:18", "link": "http://arxiv.org/abs/2008.06867v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "TopicBERT: A Transformer transfer learning based memory-graph approach\n  for multimodal streaming social media topic detection", "abstract": "Real time nature of social networks with bursty short messages and their\nrespective large data scale spread among vast variety of topics are research\ninterest of many researchers. These properties of social networks which are\nknown as 5'Vs of big data has led to many unique and enlightenment algorithms\nand techniques applied to large social networking datasets and data streams.\nMany of these researches are based on detection and tracking of hot topics and\ntrending social media events that help revealing many unanswered questions.\nThese algorithms and in some cases software products mostly rely on the nature\nof the language itself. Although, other techniques such as unsupervised data\nmining methods are language independent but many requirements for a\ncomprehensive solution are not met. Many research issues such as noisy\nsentences that adverse grammar and new online user invented words are\nchallenging maintenance of a good social network topic detection and tracking\nmethodology; The semantic relationship between words and in most cases,\nsynonyms are also ignored by many of these researches. In this research, we use\nTransformers combined with an incremental community detection algorithm.\nTransformer in one hand, provides the semantic relation between words in\ndifferent contexts. On the other hand, the proposed graph mining technique\nenhances the resulting topics with aid of simple structural rules. Named entity\nrecognition from multimodal data, image and text, labels the named entities\nwith entity type and the extracted topics are tuned using them. All operations\nof proposed system has been applied with big social data perspective under\nNoSQL technologies. In order to present a working and systematic solution, we\ncombined MongoDB with Neo4j as two major database systems of our work. The\nproposed system shows higher precision and recall compared to other methods in\nthree different datasets.", "published": "2020-08-16 10:39:50", "link": "http://arxiv.org/abs/2008.06877v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OpenFraming: We brought the ML; you bring the data. Interact with your\n  data and discover its frames", "abstract": "When journalists cover a news story, they can cover the story from multiple\nangles or perspectives. A news article written about COVID-19 for example,\nmight focus on personal preventative actions such as mask-wearing, while\nanother might focus on COVID-19's impact on the economy. These perspectives are\ncalled \"frames,\" which when used may influence public perception and opinion of\nthe issue. We introduce a Web-based system for analyzing and classifying frames\nin text documents. Our goal is to make effective tools for automatic frame\ndiscovery and labeling based on topic modeling and deep learning widely\naccessible to researchers from a diverse array of disciplines. To this end, we\nprovide both state-of-the-art pre-trained frame classification models on\nvarious issues as well as a user-friendly pipeline for training novel\nclassification models on user-provided corpora. Researchers can submit their\ndocuments and obtain frames of the documents. The degree of user involvement is\nflexible: they can run models that have been pre-trained on select issues;\nsubmit labeled documents and train a new model for frame classification; or\nsubmit unlabeled documents and obtain potential frames of the documents. The\ncode making up our system is also open-sourced and well-documented, making the\nsystem transparent and expandable. The system is available on-line at\nhttp://www.openframing.org and via our GitHub page\nhttps://github.com/davidatbu/openFraming .", "published": "2020-08-16 18:59:30", "link": "http://arxiv.org/abs/2008.06974v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Associative Memory Problem in Neurobiology and Machine Learning", "abstract": "Dense Associative Memories or modern Hopfield networks permit storage and\nreliable retrieval of an exponentially large (in the dimension of feature\nspace) number of memories. At the same time, their naive implementation is\nnon-biological, since it seemingly requires the existence of many-body synaptic\njunctions between the neurons. We show that these models are effective\ndescriptions of a more microscopic (written in terms of biological degrees of\nfreedom) theory that has additional (hidden) neurons and only requires two-body\ninteractions between them. For this reason our proposed microscopic theory is a\nvalid model of large associative memory with a degree of biological\nplausibility. The dynamics of our network and its reduced dimensional\nequivalent both minimize energy (Lyapunov) functions. When certain dynamical\nvariables (hidden neurons) are integrated out from our microscopic theory, one\ncan recover many of the models that were previously discussed in the\nliterature, e.g. the model presented in \"Hopfield Networks is All You Need\"\npaper. We also provide an alternative derivation of the energy function and the\nupdate rule proposed in the aforementioned paper and clarify the relationships\nbetween various models of this class.", "published": "2020-08-16 21:03:52", "link": "http://arxiv.org/abs/2008.06996v3", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "q-bio.NC"}
{"title": "ADL-MVDR: All deep learning MVDR beamformer for target speech separation", "abstract": "Speech separation algorithms are often used to separate the target speech\nfrom other interfering sources. However, purely neural network based speech\nseparation systems often cause nonlinear distortion that is harmful for\nautomatic speech recognition (ASR) systems. The conventional mask-based minimum\nvariance distortionless response (MVDR) beamformer can be used to minimize the\ndistortion, but comes with high level of residual noise. Furthermore, the\nmatrix operations (e.g., matrix inversion) involved in the conventional MVDR\nsolution are sometimes numerically unstable when jointly trained with neural\nnetworks. In this paper, we propose a novel all deep learning MVDR framework,\nwhere the matrix inversion and eigenvalue decomposition are replaced by two\nrecurrent neural networks (RNNs), to resolve both issues at the same time. The\nproposed method can greatly reduce the residual noise while keeping the target\nspeech undistorted by leveraging on the RNN-predicted frame-wise beamforming\nweights. The system is evaluated on a Mandarin audio-visual corpus and compared\nagainst several state-of-the-art (SOTA) speech separation systems. Experimental\nresults demonstrate the superiority of the proposed method across several\nobjective metrics and ASR accuracy.", "published": "2020-08-16 20:42:49", "link": "http://arxiv.org/abs/2008.06994v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Unsupervised Acoustic Unit Representation Learning for Voice Conversion\n  using WaveNet Auto-encoders", "abstract": "Unsupervised representation learning of speech has been of keen interest in\nrecent years, which is for example evident in the wide interest of the\nZeroSpeech challenges. This work presents a new method for learning frame level\nrepresentations based on WaveNet auto-encoders. Of particular interest in the\nZeroSpeech Challenge 2019 were models with discrete latent variable such as the\nVector Quantized Variational Auto-Encoder (VQVAE). However these models\ngenerate speech with relatively poor quality. In this work we aim to address\nthis with two approaches: first WaveNet is used as the decoder and to generate\nwaveform data directly from the latent representation; second, the low\ncomplexity of latent representations is improved with two alternative\ndisentanglement learning methods, namely instance normalization and sliced\nvector quantization. The method was developed and tested in the context of the\nrecent ZeroSpeech challenge 2020. The system output submitted to the challenge\nobtained the top position for naturalness (Mean Opinion Score 4.06), top\nposition for intelligibility (Character Error Rate 0.15), and third position\nfor the quality of the representation (ABX test score 12.5). These and further\nanalysis in this paper illustrates that quality of the converted speech and the\nacoustic units representation can be well balanced.", "published": "2020-08-16 12:16:29", "link": "http://arxiv.org/abs/2008.06892v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Computer-Generated Music for Tabletop Role-Playing Games", "abstract": "In this paper we present Bardo Composer, a system to generate background\nmusic for tabletop role-playing games. Bardo Composer uses a speech recognition\nsystem to translate player speech into text, which is classified according to a\nmodel of emotion. Bardo Composer then uses Stochastic Bi-Objective Beam Search,\na variant of Stochastic Beam Search that we introduce in this paper, with a\nneural model to generate musical pieces conveying the desired emotion. We\nperformed a user study with 116 participants to evaluate whether people are\nable to correctly identify the emotion conveyed in the pieces generated by the\nsystem. In our study we used pieces generated for Call of the Wild, a Dungeons\nand Dragons campaign available on YouTube. Our results show that human subjects\ncould correctly identify the emotion of the generated music pieces as\naccurately as they were able to identify the emotion of pieces written by\nhumans.", "published": "2020-08-16 21:53:49", "link": "http://arxiv.org/abs/2008.07009v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
