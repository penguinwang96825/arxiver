{"title": "A Side-by-side Comparison of Transformers for English Implicit Discourse\n  Relation Classification", "abstract": "Though discourse parsing can help multiple NLP fields, there has been no wide\nlanguage model search done on implicit discourse relation classification. This\nhinders researchers from fully utilizing public-available models in discourse\nanalysis. This work is a straightforward, fine-tuned discourse performance\ncomparison of seven pre-trained language models. We use PDTB-3, a popular\ndiscourse relation annotated dataset. Through our model search, we raise SOTA\nto 0.671 ACC and obtain novel observations. Some are contrary to what has been\nreported before (Shi and Demberg, 2019b), that sentence-level pre-training\nobjectives (NSP, SBO, SOP) generally fail to produce the best performing model\nfor implicit discourse relation classification. Counterintuitively,\nsimilar-sized PLMs with MLM and full attention led to better performance.", "published": "2023-07-07 04:12:25", "link": "http://arxiv.org/abs/2307.03378v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The distribution of discourse relations within and across turns in\n  spontaneous conversation", "abstract": "Time pressure and topic negotiation may impose constraints on how people\nleverage discourse relations (DRs) in spontaneous conversational contexts. In\nthis work, we adapt a system of DRs for written language to spontaneous\ndialogue using crowdsourced annotations from novice annotators. We then test\nwhether discourse relations are used differently across several types of\nmulti-utterance contexts. We compare the patterns of DR annotation within and\nacross speakers and within and across turns. Ultimately, we find that different\ndiscourse contexts produce distinct distributions of discourse relations, with\nsingle-turn annotations creating the most uncertainty for annotators.\nAdditionally, we find that the discourse relation annotations are of sufficient\nquality to predict from embeddings of discourse units.", "published": "2023-07-07 15:06:31", "link": "http://arxiv.org/abs/2307.03645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Testing the Predictions of Surprisal Theory in 11 Languages", "abstract": "A fundamental result in psycholinguistics is that less predictable words take\na longer time to process. One theoretical explanation for this finding is\nSurprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's\npredictability as its surprisal, i.e. its negative log-probability given a\ncontext. While evidence supporting the predictions of Surprisal Theory have\nbeen replicated widely, most have focused on a very narrow slice of data:\nnative English speakers reading English texts. Indeed, no comprehensive\nmultilingual analysis exists. We address this gap in the current literature by\ninvestigating the relationship between surprisal and reading times in eleven\ndifferent languages, distributed across five language families. Deriving\nestimates from language models trained on monolingual and multilingual corpora,\nwe test three predictions associated with surprisal theory: (i) whether\nsurprisal is predictive of reading times; (ii) whether expected surprisal, i.e.\ncontextual entropy, is predictive of reading times; (iii) and whether the\nlinking function between surprisal and reading times is linear. We find that\nall three predictions are borne out crosslinguistically. By focusing on a more\ndiverse set of languages, we argue that these results offer the most robust\nlink to-date between information theory and incremental language processing\nacross languages.", "published": "2023-07-07 15:37:50", "link": "http://arxiv.org/abs/2307.03667v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Automatic Quotation Attribution in Literary Novels", "abstract": "Current models for quotation attribution in literary novels assume varying\nlevels of available information in their training and test data, which poses a\nchallenge for in-the-wild inference. Here, we approach quotation attribution as\na set of four interconnected sub-tasks: character identification, coreference\nresolution, quotation identification, and speaker attribution. We benchmark\nstate-of-the-art models on each of these sub-tasks independently, using a large\ndataset of annotated coreferences and quotations in literary novels (the\nProject Dialogism Novel Corpus). We also train and evaluate models for the\nspeaker attribution task in particular, showing that a simple sequential\nprediction model achieves accuracy scores on par with state-of-the-art models.", "published": "2023-07-07 17:37:01", "link": "http://arxiv.org/abs/2307.03734v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Efficacy of Sampling Adapters", "abstract": "Sampling is a common strategy for generating text from probabilistic models,\nyet standard ancestral sampling often results in text that is incoherent or\nungrammatical. To alleviate this issue, various modifications to a model's\nsampling distribution, such as nucleus or top-k sampling, have been introduced\nand are now ubiquitously used in language generation systems. We propose a\nunified framework for understanding these techniques, which we term sampling\nadapters. Sampling adapters often lead to qualitatively better text, which\nraises the question: From a formal perspective, how are they changing the\n(sub)word-level distributions of language generation models? And why do these\nlocal changes lead to higher-quality text? We argue that the shift they enforce\ncan be viewed as a trade-off between precision and recall: while the model\nloses its ability to produce certain strings, its precision rate on desirable\ntext increases. While this trade-off is not reflected in standard metrics of\ndistribution quality (such as perplexity), we find that several\nprecision-emphasizing measures indeed indicate that sampling adapters can lead\nto probability distributions more aligned with the true distribution. Further,\nthese measures correlate with higher sequence-level quality scores,\nspecifically, Mauve.", "published": "2023-07-07 17:59:12", "link": "http://arxiv.org/abs/2307.03749v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic representations for fewer-shot relation extraction across\n  domains", "abstract": "Recent work has demonstrated the positive impact of incorporating linguistic\nrepresentations as additional context and scaffolding on the in-domain\nperformance of several NLP tasks. We extend this work by exploring the impact\nof linguistic representations on cross-domain performance in a few-shot\ntransfer setting. An important question is whether linguistic representations\nenhance generalizability by providing features that function as cross-domain\npivots. We focus on the task of relation extraction on three datasets of\nprocedural text in two domains, cooking and materials science. Our approach\naugments a popular transformer-based architecture by alternately incorporating\nsyntactic and semantic graphs constructed by freely available off-the-shelf\ntools. We examine their utility for enhancing generalization, and investigate\nwhether earlier findings, e.g. that semantic representations can be more\nhelpful than syntactic ones, extend to relation extraction in multiple domains.\nWe find that while the inclusion of these graphs results in significantly\nhigher performance in few-shot transfer, both types of graph exhibit roughly\nequivalent utility.", "published": "2023-07-07 20:35:12", "link": "http://arxiv.org/abs/2307.03823v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MDACE: MIMIC Documents Annotated with Code Evidence", "abstract": "We introduce a dataset for evidence/rationale extraction on an extreme\nmulti-label classification task over long medical documents. One such task is\nComputer-Assisted Coding (CAC) which has improved significantly in recent\nyears, thanks to advances in machine learning technologies. Yet simply\npredicting a set of final codes for a patient encounter is insufficient as CAC\nsystems are required to provide supporting textual evidence to justify the\nbilling codes. A model able to produce accurate and reliable supporting\nevidence for each code would be a tremendous benefit. However, a human\nannotated code evidence corpus is extremely difficult to create because it\nrequires specialized knowledge. In this paper, we introduce MDACE, the first\npublicly available code evidence dataset, which is built on a subset of the\nMIMIC-III clinical records. The dataset -- annotated by professional medical\ncoders -- consists of 302 Inpatient charts with 3,934 evidence spans and 52\nProfee charts with 5,563 evidence spans. We implemented several evidence\nextraction methods based on the EffectiveCAN model (Liu et al., 2021) to\nestablish baseline performance on this dataset. MDACE can be used to evaluate\ncode evidence extraction methods for CAC systems, as well as the accuracy and\ninterpretability of deep learning models for multi-label classification. We\nbelieve that the release of MDACE will greatly improve the understanding and\napplication of deep learning technologies for medical coding and document\nclassification.", "published": "2023-07-07 22:45:59", "link": "http://arxiv.org/abs/2307.03859v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Negative Transfer with Task Awareness for Sexism, Hate\n  Speech, and Toxic Language Detection", "abstract": "This paper proposes a novelty approach to mitigate the negative transfer\nproblem. In the field of machine learning, the common strategy is to apply the\nSingle-Task Learning approach in order to train a supervised model to solve a\nspecific task. Training a robust model requires a lot of data and a significant\namount of computational resources, making this solution unfeasible in cases\nwhere data are unavailable or expensive to gather. Therefore another solution,\nbased on the sharing of information between tasks, has been developed:\nMulti-Task Learning (MTL). Despite the recent developments regarding MTL, the\nproblem of negative transfer has still to be solved. Negative transfer is a\nphenomenon that occurs when noisy information is shared between tasks,\nresulting in a drop in performance. This paper proposes a new approach to\nmitigate the negative transfer problem based on the task awareness concept. The\nproposed approach results in diminishing the negative transfer together with an\nimprovement of performance over classic MTL solution. Moreover, the proposed\napproach has been implemented in two unified architectures to detect Sexism,\nHate Speech, and Toxic Language in text comments. The proposed architectures\nset a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks.", "published": "2023-07-07 04:10:37", "link": "http://arxiv.org/abs/2307.03377v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Derivative Free Weight-space Ensembling", "abstract": "Recent work suggests that interpolating between the weights of two\nspecialized language models can transfer knowledge between tasks in a way that\nmulti-task learning cannot. However, very few have explored interpolation\nbetween more than two models, where each has a distinct knowledge base. In this\npaper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new\nfew-sample task transfer approach for open-domain dialogue. Our framework\ncreates a set of diverse expert language models trained using a predefined set\nof source tasks. Next, we finetune each of the expert models on the target\ntask, approaching the target task from several distinct knowledge bases.\nFinally, we linearly interpolate between the model weights using a\ngradient-free-optimization algorithm, to efficiently find a good interpolation\nweighting. We demonstrate the effectiveness of the method on FETA-Friends\noutperforming the standard pretrain-finetune approach.", "published": "2023-07-07 10:42:44", "link": "http://arxiv.org/abs/2307.03506v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models as Batteries-Included Zero-Shot ESCO Skills\n  Matchers", "abstract": "Understanding labour market dynamics requires accurately identifying the\nskills required for and possessed by the workforce. Automation techniques are\nincreasingly being developed to support this effort. However, automatically\nextracting skills from job postings is challenging due to the vast number of\nexisting skills. The ESCO (European Skills, Competences, Qualifications and\nOccupations) framework provides a useful reference, listing over 13,000\nindividual skills. However, skills extraction remains difficult and accurately\nmatching job posts to the ESCO taxonomy is an open problem. In this work, we\npropose an end-to-end zero-shot system for skills extraction from job\ndescriptions based on large language models (LLMs). We generate synthetic\ntraining data for the entirety of ESCO skills and train a classifier to extract\nskill mentions from job posts. We also employ a similarity retriever to\ngenerate skill candidates which are then re-ranked using a second LLM. Using\nsynthetic data achieves an RP@10 score 10 points higher than previous distant\nsupervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22\npoints over previous methods. We also show that Framing the task as mock\nprogramming when prompting the LLM can lead to better performance than natural\nlanguage prompts, especially with weaker LLMs. We demonstrate the potential of\nintegrating large language models at both ends of skills matching pipelines.\nOur approach requires no human annotations and achieve extremely promising\nresults on skills extraction against ESCO.", "published": "2023-07-07 12:04:12", "link": "http://arxiv.org/abs/2307.03539v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Text Simplification of Scientific Texts for Non-Expert Readers", "abstract": "Reading levels are highly individual and can depend on a text's language, a\nperson's cognitive abilities, or knowledge on a topic. Text simplification is\nthe task of rephrasing a text to better cater to the abilities of a specific\ntarget reader group. Simplification of scientific abstracts helps non-experts\nto access the core information by bypassing formulations that require domain or\nexpert knowledge. This is especially relevant for, e.g., cancer patients\nreading about novel treatment options. The SimpleText lab hosts the\nsimplification of scientific abstracts for non-experts (Task 3) to advance this\nfield. We contribute three runs employing out-of-the-box summarization models\n(two based on T5, one based on PEGASUS) and one run using ChatGPT with complex\nphrase identification.", "published": "2023-07-07 13:05:11", "link": "http://arxiv.org/abs/2307.03569v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Brain in a Vat: On Missing Pieces Towards Artificial General\n  Intelligence in Large Language Models", "abstract": "In this perspective paper, we first comprehensively review existing\nevaluations of Large Language Models (LLMs) using both standardized tests and\nability-oriented benchmarks. We pinpoint several problems with current\nevaluation methods that tend to overstate the capabilities of LLMs. We then\narticulate what artificial general intelligence should encompass beyond the\ncapabilities of LLMs. We propose four characteristics of generally intelligent\nagents: 1) they can perform unlimited tasks; 2) they can generate new tasks\nwithin a context; 3) they operate based on a value system that underpins task\ngeneration; and 4) they have a world model reflecting reality, which shapes\ntheir interaction with the world. Building on this viewpoint, we highlight the\nmissing pieces in artificial general intelligence, that is, the unity of\nknowing and acting. We argue that active engagement with objects in the real\nworld delivers more robust signals for forming conceptual representations.\nAdditionally, knowledge acquisition isn't solely reliant on passive input but\nrequires repeated trials and errors. We conclude by outlining promising future\nresearch directions in the field of artificial general intelligence.", "published": "2023-07-07 13:58:16", "link": "http://arxiv.org/abs/2307.03762v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal\n  Prediction", "abstract": "When applied to open-domain question answering, large language models (LLMs)\nfrequently generate incorrect responses based on made-up facts, which are\ncalled $\\textit{hallucinations}$. Retrieval augmented generation (RAG) is a\npromising strategy to avoid hallucinations, but it does not provide guarantees\non its correctness. To address this challenge, we propose the Trustworthy\nRetrieval Augmented Question Answering, or $\\textit{TRAQ}$, which provides the\nfirst end-to-end statistical correctness guarantee for RAG. TRAQ uses conformal\nprediction, a statistical technique for constructing prediction sets that are\nguaranteed to contain the semantically correct response with high probability.\nAdditionally, TRAQ leverages Bayesian optimization to minimize the size of the\nconstructed sets. In an extensive experimental evaluation, we demonstrate that\nTRAQ provides the desired correctness guarantee while reducing prediction set\nsize by 16.2% on average compared to an ablation. The implementation is\navailable at $\\href{https://github.com/shuoli90/TRAQ.git}{TRAQ}$.", "published": "2023-07-07 02:42:06", "link": "http://arxiv.org/abs/2307.04642v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MultiQG-TI: Towards Question Generation from Multi-modal Sources", "abstract": "We study the new problem of automatic question generation (QG) from\nmulti-modal sources containing images and texts, significantly expanding the\nscope of most of the existing work that focuses exclusively on QG from only\ntextual sources. We propose a simple solution for our new problem, called\nMultiQG-TI, which enables a text-only question generator to process visual\ninput in addition to textual input. Specifically, we leverage an image-to-text\nmodel and an optical character recognition model to obtain the textual\ndescription of the image and extract any texts in the image, respectively, and\nthen feed them together with the input texts to the question generator. We only\nfine-tune the question generator while keeping the other components fixed. On\nthe challenging ScienceQA dataset, we demonstrate that MultiQG-TI significantly\noutperforms ChatGPT with few-shot prompting, despite having hundred-times less\ntrainable parameters. Additional analyses empirically confirm the necessity of\nboth visual and textual signals for QG and show the impact of various modeling\nchoices.", "published": "2023-07-07 08:14:15", "link": "http://arxiv.org/abs/2307.04643v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Why machines do not understand: A response to S\u00f8gaard", "abstract": "Some defenders of so-called `artificial intelligence' believe that machines\ncan understand language. In particular, S{\\o}gaard has argued in this journal\nfor a thesis of this sort, on the basis of the idea (1) that where there is\nsemantics there is also understanding and (2) that machines are not only\ncapable of what he calls `inferential semantics', but even that they can (with\nthe help of inputs from sensors) `learn' referential semantics\n\\parencite{sogaard:2022}. We show that he goes wrong because he pays\ninsufficient attention to the difference between language as used by humans and\nthe sequences of inert of symbols which arise when language is stored on hard\ndrives or in books in libraries.", "published": "2023-07-07 12:31:56", "link": "http://arxiv.org/abs/2307.04766v1", "categories": ["cs.CL", "cs.AI", "I.2.0"], "primary_category": "cs.CL"}
{"title": "Token-Level Serialized Output Training for Joint Streaming ASR and ST\n  Leveraging Textual Alignments", "abstract": "In real-world applications, users often require both translations and\ntranscriptions of speech to enhance their comprehension, particularly in\nstreaming scenarios where incremental generation is necessary. This paper\nintroduces a streaming Transformer-Transducer that jointly generates automatic\nspeech recognition (ASR) and speech translation (ST) outputs using a single\ndecoder. To produce ASR and ST content effectively with minimal latency, we\npropose a joint token-level serialized output training method that interleaves\nsource and target words by leveraging an off-the-shelf textual aligner.\nExperiments in monolingual (it-en) and multilingual (\\{de,es,it\\}-en) settings\ndemonstrate that our approach achieves the best quality-latency balance. With\nan average ASR latency of 1s and ST latency of 1.3s, our model shows no\ndegradation or even improves output quality compared to separate ASR and ST\nmodels, yielding an average improvement of 1.1 WER and 0.4 BLEU in the\nmultilingual case.", "published": "2023-07-07 02:26:18", "link": "http://arxiv.org/abs/2307.03354v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Evaluating Biased Attitude Associations of Language Models in an\n  Intersectional Context", "abstract": "Language models are trained on large-scale corpora that embed implicit biases\ndocumented in psychology. Valence associations (pleasantness/unpleasantness) of\nsocial groups determine the biased attitudes towards groups and concepts in\nsocial cognition. Building on this established literature, we quantify how\nsocial groups are valenced in English language models using a sentence template\nthat provides an intersectional context. We study biases related to age,\neducation, gender, height, intelligence, literacy, race, religion, sex, sexual\norientation, social class, and weight. We present a concept projection approach\nto capture the valence subspace through contextualized word embeddings of\nlanguage models. Adapting the projection-based approach to embedding\nassociation tests that quantify bias, we find that language models exhibit the\nmost biased attitudes against gender identity, social class, and sexual\norientation signals in language. We find that the largest and better-performing\nmodel that we study is also more biased as it effectively captures bias\nembedded in sociocultural data. We validate the bias evaluation method by\noverperforming on an intrinsic valence evaluation task. The approach enables us\nto measure complex intersectional biases as they are known to manifest in the\noutputs and applications of language models that perpetuate historical biases.\nMoreover, our approach contributes to design justice as it studies the\nassociations of groups underrepresented in language such as transgender and\nhomosexual individuals.", "published": "2023-07-07 03:01:56", "link": "http://arxiv.org/abs/2307.03360v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "AI-UPV at EXIST 2023 -- Sexism Characterization Using Large Language\n  Models Under The Learning with Disagreements Regime", "abstract": "With the increasing influence of social media platforms, it has become\ncrucial to develop automated systems capable of detecting instances of sexism\nand other disrespectful and hateful behaviors to promote a more inclusive and\nrespectful online environment. Nevertheless, these tasks are considerably\nchallenging considering different hate categories and the author's intentions,\nespecially under the learning with disagreements regime. This paper describes\nAI-UPV team's participation in the EXIST (sEXism Identification in Social\nneTworks) Lab at CLEF 2023. The proposed approach aims at addressing the task\nof sexism identification and characterization under the learning with\ndisagreements paradigm by training directly from the data with disagreements,\nwithout using any aggregated label. Yet, performances considering both soft and\nhard evaluations are reported. The proposed system uses large language models\n(i.e., mBERT and XLM-RoBERTa) and ensemble strategies for sexism identification\nand classification in English and Spanish. In particular, our system is\narticulated in three different pipelines. The ensemble approach outperformed\nthe individual large language models obtaining the best performances both\nadopting a soft and a hard label evaluation. This work describes the\nparticipation in all the three EXIST tasks, considering a soft evaluation, it\nobtained fourth place in Task 2 at EXIST and first place in Task 3, with the\nhighest ICM-Soft of -2.32 and a normalized ICM-Soft of 0.79. The source code of\nour approaches is publicly available at\nhttps://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement.", "published": "2023-07-07 04:49:26", "link": "http://arxiv.org/abs/2307.03385v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Quantifying the perceptual value of lexical and non-lexical channels in\n  speech", "abstract": "Speech is a fundamental means of communication that can be seen to provide\ntwo channels for transmitting information: the lexical channel of which words\nare said, and the non-lexical channel of how they are spoken. Both channels\nshape listener expectations of upcoming communication; however, directly\nquantifying their relative effect on expectations is challenging. Previous\nattempts require spoken variations of lexically-equivalent dialogue turns or\nconspicuous acoustic manipulations. This paper introduces a generalised\nparadigm to study the value of non-lexical information in dialogue across\nunconstrained lexical content. By quantifying the perceptual value of the\nnon-lexical channel with both accuracy and entropy reduction, we show that\nnon-lexical information produces a consistent effect on expectations of\nupcoming dialogue: even when it leads to poorer discriminative turn judgements\nthan lexical content alone, it yields higher consensus among participants.", "published": "2023-07-07 11:44:23", "link": "http://arxiv.org/abs/2307.03534v1", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through\n  Style-based Data Sampling", "abstract": "This paper describes our submission for the subjectivity detection task at\nthe CheckThat! Lab. To tackle class imbalances in the task, we have generated\nadditional training materials with GPT-3 models using prompts of different\nstyles from a subjectivity checklist based on journalistic perspective. We used\nthe extended training set to fine-tune language-specific transformer models.\nOur experiments in English, German and Turkish demonstrate that different\nsubjective styles are effective across all languages. In addition, we observe\nthat the style-based oversampling is better than paraphrasing in Turkish and\nEnglish. Lastly, the GPT-3 models sometimes produce lacklustre results when\ngenerating style-based texts in non-English languages.", "published": "2023-07-07 12:34:57", "link": "http://arxiv.org/abs/2307.03550v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug\n  Trafficking Detection on Social Media", "abstract": "Social media platforms such as Instagram and Twitter have emerged as critical\nchannels for drug marketing and illegal sale. Detecting and labeling online\nillicit drug trafficking activities becomes important in addressing this issue.\nHowever, the effectiveness of conventional supervised learning methods in\ndetecting drug trafficking heavily relies on having access to substantial\namounts of labeled data, while data annotation is time-consuming and\nresource-intensive. Furthermore, these models often face challenges in\naccurately identifying trafficking activities when drug dealers use deceptive\nlanguage and euphemisms to avoid detection. To overcome this limitation, we\nconduct the first systematic study on leveraging large language models (LLMs),\nsuch as ChatGPT, to detect illicit drug trafficking activities on social media.\nWe propose an analytical framework to compose \\emph{knowledge-informed\nprompts}, which serve as the interface that humans can interact with and use\nLLMs to perform the detection task. Additionally, we design a Monte Carlo\ndropout based prompt optimization method to further to improve performance and\ninterpretability. Our experimental findings demonstrate that the proposed\nframework outperforms other baseline language models in terms of drug\ntrafficking detection accuracy, showing a remarkable improvement of nearly\n12\\%. By integrating prior knowledge and the proposed prompts, ChatGPT can\neffectively identify and label drug trafficking activities on social networks,\neven in the presence of deceptive language and euphemisms used by drug dealers\nto evade detection. The implications of our research extend to social networks,\nemphasizing the importance of incorporating prior knowledge and scenario-based\nprompts into analytical tools to improve online security and public safety.", "published": "2023-07-07 16:15:59", "link": "http://arxiv.org/abs/2307.03699v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "INT-FP-QSim: Mixed Precision and Formats For Large Language Models and\n  Vision Transformers", "abstract": "The recent rise of large language models (LLMs) has resulted in increased\nefforts towards running LLMs at reduced precision. Running LLMs at lower\nprecision supports resource constraints and furthers their democratization,\nenabling users to run billion-parameter LLMs on their personal devices. To\nsupplement this ongoing effort, we propose INT-FP-QSim: an open-source\nsimulator that enables flexible evaluation of LLMs and vision transformers at\nvarious numerical precisions and formats. INT-FP-QSim leverages existing\nopen-source repositories such as TensorRT, QPytorch and AIMET for a combined\nsimulator that supports various floating point and integer formats. With the\nhelp of our simulator, we survey the impact of different numerical formats on\nthe performance of LLMs and vision transformers at 4-bit weights and 4-bit or\n8-bit activations. We also compare recently proposed methods like Adaptive\nBlock Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We\nhope INT-FP-QSim will enable researchers to flexibly simulate models at various\nprecisions to support further research in quantization of LLMs and vision\ntransformers.", "published": "2023-07-07 16:54:53", "link": "http://arxiv.org/abs/2307.03712v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "QIGen: Generating Efficient Kernels for Quantized Inference on Large\n  Language Models", "abstract": "We present ongoing work on a new automatic code generation approach for\nsupporting quantized generative inference on LLMs such as LLaMA or OPT on\noff-the-shelf CPUs. Our approach is informed by the target architecture and a\nperformance model, including both hardware characteristics and method-specific\naccuracy constraints. Results on CPU-based inference for LLaMA models show that\nour approach can lead to high performance and high accuracy, comparing\nfavorably to the best existing open-source solution. A preliminary\nimplementation is available at https://github.com/IST-DASLab/QIGen.", "published": "2023-07-07 17:46:08", "link": "http://arxiv.org/abs/2307.03738v1", "categories": ["cs.LG", "cs.CL", "cs.PF"], "primary_category": "cs.LG"}
{"title": "For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis\n  of a Watershed Moment in Iran's Gender Struggles", "abstract": "In this paper, we present a computational analysis of the Persian language\nTwitter discourse with the aim to estimate the shift in stance toward gender\nequality following the death of Mahsa Amini in police custody. We present an\nensemble active learning pipeline to train a stance classifier. Our novelty\nlies in the involvement of Iranian women in an active role as annotators in\nbuilding this AI system. Our annotators not only provide labels, but they also\nsuggest valuable keywords for more meaningful corpus creation as well as\nprovide short example documents for a guided sampling step. Our analyses\nindicate that Mahsa Amini's death triggered polarized Persian language\ndiscourse where both fractions of negative and positive tweets toward gender\nequality increased. The increase in positive tweets was slightly greater than\nthe increase in negative tweets. We also observe that with respect to account\ncreation time, between the state-aligned Twitter accounts and pro-protest\nTwitter accounts, pro-protest accounts are more similar to baseline Persian\nTwitter activity.", "published": "2023-07-07 19:39:15", "link": "http://arxiv.org/abs/2307.03764v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "RADAR: Robust AI-Text Detection via Adversarial Learning", "abstract": "Recent advances in large language models (LLMs) and the intensifying\npopularity of ChatGPT-like applications have blurred the boundary of\nhigh-quality text generation between humans and machines. However, in addition\nto the anticipated revolutionary changes to our technology and society, the\ndifficulty of distinguishing LLM-generated texts (AI-text) from human-generated\ntexts poses new challenges of misuse and fairness, such as fake content\ngeneration, plagiarism, and false accusations of innocent writers. While\nexisting works show that current AI-text detectors are not robust to LLM-based\nparaphrasing, this paper aims to bridge this gap by proposing a new framework\ncalled RADAR, which jointly trains a robust AI-text detector via adversarial\nlearning. RADAR is based on adversarial training of a paraphraser and a\ndetector. The paraphraser's goal is to generate realistic content to evade\nAI-text detection. RADAR uses the feedback from the detector to update the\nparaphraser, and vice versa. Evaluated with 8 different LLMs (Pythia, Dolly\n2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna) across 4 datasets,\nexperimental results show that RADAR significantly outperforms existing AI-text\ndetection methods, especially when paraphrasing is in place. We also identify\nthe strong transferability of RADAR from instruction-tuned LLMs to other LLMs,\nand evaluate the improved capability of RADAR via GPT-3.5-Turbo.", "published": "2023-07-07 21:13:27", "link": "http://arxiv.org/abs/2307.03838v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LaunchpadGPT: Language Model as Music Visualization Designer on\n  Launchpad", "abstract": "Launchpad is a musical instrument that allows users to create and perform\nmusic by pressing illuminated buttons. To assist and inspire the design of the\nLaunchpad light effect, and provide a more accessible approach for beginners to\ncreate music visualization with this instrument, we proposed the LaunchpadGPT\nmodel to generate music visualization designs on Launchpad automatically. Based\non the language model with excellent generation ability, our proposed\nLaunchpadGPT takes an audio piece of music as input and outputs the lighting\neffects of Launchpad-playing in the form of a video (Launchpad-playing video).\nWe collect Launchpad-playing videos and process them to obtain music and\ncorresponding video frame of Launchpad-playing as prompt-completion pairs, to\ntrain the language model. The experiment result shows the proposed method can\ncreate better music visualization than random generation methods and hold the\npotential for a broader range of music visualization applications. Our code is\navailable at https://github.com/yunlong10/LaunchpadGPT/.", "published": "2023-07-07 16:25:59", "link": "http://arxiv.org/abs/2307.04827v2", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Subjective Crowd Disagreements for Subjective Data: Uncovering\n  Meaningful CrowdOpinion with Population-level Learning", "abstract": "Human-annotated data plays a critical role in the fairness of AI systems,\nincluding those that deal with life-altering decisions or moderating\nhuman-created web/social media content. Conventionally, annotator disagreements\nare resolved before any learning takes place. However, researchers are\nincreasingly identifying annotator disagreement as pervasive and meaningful.\nThey also question the performance of a system when annotators disagree.\nParticularly when minority views are disregarded, especially among groups that\nmay already be underrepresented in the annotator population. In this paper, we\nintroduce \\emph{CrowdOpinion}\\footnote{Accepted for publication at ACL 2023},\nan unsupervised learning based approach that uses language features and label\ndistributions to pool similar items into larger samples of label distributions.\nWe experiment with four generative and one density-based clustering method,\napplied to five linear combinations of label distributions and features. We use\nfive publicly available benchmark datasets (with varying levels of annotator\ndisagreements) from social media (Twitter, Gab, and Reddit). We also experiment\nin the wild using a dataset from Facebook, where annotations come from the\nplatform itself by users reacting to posts. We evaluate \\emph{CrowdOpinion} as\na label distribution prediction task using KL-divergence and a single-label\nproblem using accuracy measures.", "published": "2023-07-07 22:09:46", "link": "http://arxiv.org/abs/2307.10189v1", "categories": ["cs.IR", "cs.CL", "cs.SI"], "primary_category": "cs.IR"}
{"title": "The CHiME-7 UDASE task: Unsupervised domain adaptation for\n  conversational speech enhancement", "abstract": "Supervised speech enhancement models are trained using artificially generated\nmixtures of clean speech and noise signals, which may not match real-world\nrecording conditions at test time. This mismatch can lead to poor performance\nif the test domain significantly differs from the synthetic training domain.\nThis paper introduces the unsupervised domain adaptation for conversational\nspeech enhancement (UDASE) task of the 7th CHiME challenge. This task aims to\nleverage real-world noisy speech recordings from the target domain for\nunsupervised domain adaptation of speech enhancement models. The target domain\ncorresponds to the multi-speaker reverberant conversational speech recordings\nof the CHiME-5 dataset, for which the ground-truth clean speech reference is\nunavailable. Given a CHiME-5 recording, the task is to estimate the clean,\npotentially multi-speaker, reverberant speech, removing the additive background\nnoise. We discuss the motivation for the CHiME-7 UDASE task and describe the\ndata, the task, and the baseline system.", "published": "2023-07-07 11:41:33", "link": "http://arxiv.org/abs/2307.03533v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Ethical Implications of Generative Audio Models: A Systematic\n  Literature Review", "abstract": "Generative audio models typically focus their applications in music and\nspeech generation, with recent models having human-like quality in their audio\noutput. This paper conducts a systematic literature review of 884 papers in the\narea of generative audio models in order to both quantify the degree to which\nresearchers in the field are considering potential negative impacts and\nidentify the types of ethical implications researchers in this area need to\nconsider. Though 65% of generative audio research papers note positive\npotential impacts of their work, less than 10% discuss any negative impacts.\nThis jarringly small percentage of papers considering negative impact is\nparticularly worrying because the issues brought to light by the few papers\ndoing so are raising serious ethical implications and concerns relevant to the\nbroader field such as the potential for fraud, deep-fakes, and copyright\ninfringement. By quantifying this lack of ethical consideration in generative\naudio research and identifying key areas of potential harm, this paper lays the\ngroundwork for future work in the field at a critical point in time in order to\nguide more conscientious research as this field progresses.", "published": "2023-07-07 22:00:32", "link": "http://arxiv.org/abs/2307.05527v1", "categories": ["cs.CY", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CY"}
