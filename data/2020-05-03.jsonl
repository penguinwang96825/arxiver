{"title": "How Can We Accelerate Progress Towards Human-like Linguistic\n  Generalization?", "abstract": "This position paper describes and critiques the Pretraining-Agnostic\nIdentically Distributed (PAID) evaluation paradigm, which has become a central\ntool for measuring progress in natural language understanding. This paradigm\nconsists of three stages: (1) pre-training of a word prediction model on a\ncorpus of arbitrary size; (2) fine-tuning (transfer learning) on a training set\nrepresenting a classification task; (3) evaluation on a test set drawn from the\nsame distribution as that training set. This paradigm favors simple, low-bias\narchitectures, which, first, can be scaled to process vast amounts of data, and\nsecond, can capture the fine-grained statistical properties of a particular\ndata set, regardless of whether those properties are likely to generalize to\nexamples of the task outside the data set. This contrasts with humans, who\nlearn language from several orders of magnitude less data than the systems\nfavored by this evaluation paradigm, and generalize to new tasks in a\nconsistent way. We advocate for supplementing or replacing PAID with paradigms\nthat reward architectures that generalize as quickly and robustly as humans.", "published": "2020-05-03 00:31:15", "link": "http://arxiv.org/abs/2005.00955v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bootstrapping Techniques for Polysynthetic Morphological Analysis", "abstract": "Polysynthetic languages have exceptionally large and sparse vocabularies,\nthanks to the number of morpheme slots and combinations in a word. This\ncomplexity, together with a general scarcity of written data, poses a challenge\nto the development of natural language technologies. To address this challenge,\nwe offer linguistically-informed approaches for bootstrapping a neural\nmorphological analyzer, and demonstrate its application to Kunwinjku, a\npolysynthetic Australian language. We generate data from a finite state\ntransducer to train an encoder-decoder model. We improve the model by\n\"hallucinating\" missing linguistic structure into the training data, and by\nresampling from a Zipf distribution to simulate a more natural distribution of\nmorphemes. The best model accounts for all instances of reduplication in the\ntest set and achieves an accuracy of 94.7% overall, a 10 percentage point\nimprovement over the FST baseline. This process demonstrates the feasibility of\nbootstrapping a neural morph analyzer from minimal resources.", "published": "2020-05-03 00:35:19", "link": "http://arxiv.org/abs/2005.00956v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Inference Calibration of Neural Machine Translation", "abstract": "Confidence calibration, which aims to make model predictions equal to the\ntrue correctness measures, is important for neural machine translation (NMT)\nbecause it is able to offer useful indicators of translation errors in the\ngenerated output. While prior studies have shown that NMT models trained with\nlabel smoothing are well-calibrated on the ground-truth training data, we find\nthat miscalibration still remains a severe challenge for NMT during inference\ndue to the discrepancy between training and inference. By carefully designing\nexperiments on three language pairs, our work provides in-depth analyses of the\ncorrelation between calibration and translation performance as well as\nlinguistic properties of miscalibration and reports a number of interesting\nfindings that might help humans better analyze, understand and improve NMT\nmodels. Based on these observations, we further propose a new graduated label\nsmoothing method that can improve both inference calibration and translation\nperformance.", "published": "2020-05-03 02:03:56", "link": "http://arxiv.org/abs/2005.00963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Faithful Neural Table-to-Text Generation with Content-Matching\n  Constraints", "abstract": "Text generation from a knowledge base aims to translate knowledge triples to\nnatural language descriptions. Most existing methods ignore the faithfulness\nbetween a generated text description and the original table, leading to\ngenerated information that goes beyond the content of the table. In this paper,\nfor the first time, we propose a novel Transformer-based generation framework\nto achieve the goal. The core techniques in our method to enforce faithfulness\ninclude a new table-text optimal-transport matching loss and a table-text\nembedding similarity loss based on the Transformer model. Furthermore, to\nevaluate faithfulness, we propose a new automatic metric specialized to the\ntable-to-text generation problem. We also provide detailed analysis on each\ncomponent of our model in our experiments. Automatic and human evaluations show\nthat our framework can significantly outperform state-of-the-art by a large\nmargin.", "published": "2020-05-03 02:54:26", "link": "http://arxiv.org/abs/2005.00969v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Morphological Paradigm Completion", "abstract": "We propose the task of unsupervised morphological paradigm completion. Given\nonly raw text and a lemma list, the task consists of generating the\nmorphological paradigms, i.e., all inflected forms, of the lemmas. From a\nnatural language processing (NLP) perspective, this is a challenging\nunsupervised task, and high-performing systems have the potential to improve\ntools for low-resource languages or to assist linguistic annotators. From a\ncognitive science perspective, this can shed light on how children acquire\nmorphological knowledge. We further introduce a system for the task, which\ngenerates morphological paradigms via the following steps: (i) EDIT TREE\nretrieval, (ii) additional lemma retrieval, (iii) paradigm size discovery, and\n(iv) inflection generation. We perform an evaluation on 14 typologically\ndiverse languages. Our system outperforms trivial baselines with ease and, for\nsome languages, even obtains a higher accuracy than minimally supervised\nsystems.", "published": "2020-05-03 02:56:05", "link": "http://arxiv.org/abs/2005.00970v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Second-Order TreeCRF for Neural Dependency Parsing", "abstract": "In the deep learning (DL) era, parsing models are extremely simplified with\nlittle hurt on performance, thanks to the remarkable capability of multi-layer\nBiLSTMs in context representation. As the most popular graph-based dependency\nparser due to its high efficiency and performance, the biaffine parser directly\nscores single dependencies under the arc-factorization assumption, and adopts a\nvery simple local token-wise cross-entropy training loss. This paper for the\nfirst time presents a second-order TreeCRF extension to the biaffine parser.\nFor a long time, the complexity and inefficiency of the inside-outside\nalgorithm hinder the popularity of TreeCRF. To address this issue, we propose\nan effective way to batchify the inside and Viterbi algorithms for direct large\nmatrix operation on GPUs, and to avoid the complex outside algorithm via\nefficient back-propagation. Experiments and analysis on 27 datasets from 13\nlanguages clearly show that techniques developed before the DL era, such as\nstructural learning (global TreeCRF loss) and high-order modeling are still\nuseful, and can further boost parsing performance over the state-of-the-art\nbiaffine parser, especially for partially annotated training data. We release\nour code at https://github.com/yzhangcs/crfpar.", "published": "2020-05-03 03:18:59", "link": "http://arxiv.org/abs/2005.00975v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Encoder-Decoder Models Can Benefit from Pre-trained Masked Language\n  Models in Grammatical Error Correction", "abstract": "This paper investigates how to effectively incorporate a pre-trained masked\nlanguage model (MLM), such as BERT, into an encoder-decoder (EncDec) model for\ngrammatical error correction (GEC). The answer to this question is not as\nstraightforward as one might expect because the previous common methods for\nincorporating a MLM into an EncDec model have potential drawbacks when applied\nto GEC. For example, the distribution of the inputs to a GEC model can be\nconsiderably different (erroneous, clumsy, etc.) from that of the corpora used\nfor pre-training MLMs; however, this issue is not addressed in the previous\nmethods. Our experiments show that our proposed method, where we first\nfine-tune a MLM with a given GEC corpus and then use the output of the\nfine-tuned MLM as additional features in the GEC model, maximizes the benefit\nof the MLM. The best-performing model achieves state-of-the-art performances on\nthe BEA-2019 and CoNLL-2014 benchmarks. Our code is publicly available at:\nhttps://github.com/kanekomasahiro/bert-gec.", "published": "2020-05-03 04:49:31", "link": "http://arxiv.org/abs/2005.00987v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Position Aware Decay Weighted Network for Aspect based Sentiment\n  Analysis", "abstract": "Aspect Based Sentiment Analysis (ABSA) is the task of identifying sentiment\npolarity of a text given another text segment or aspect. In ABSA, a text can\nhave multiple sentiments depending upon each aspect. Aspect Term Sentiment\nAnalysis (ATSA) is a subtask of ABSA, in which aspect terms are contained\nwithin the given sentence. Most of the existing approaches proposed for ATSA,\nincorporate aspect information through a different subnetwork thereby\noverlooking the advantage of aspect terms' presence within the sentence. In\nthis paper, we propose a model that leverages the positional information of the\naspect. The proposed model introduces a decay mechanism based on position. This\ndecay function mandates the contribution of input words for ABSA. The\ncontribution of a word declines as farther it is positioned from the aspect\nterms in the sentence. The performance is measured on two standard datasets\nfrom SemEval 2014 Task 4. In comparison with recent architectures, the\neffectiveness of the proposed model is demonstrated.", "published": "2020-05-03 09:22:03", "link": "http://arxiv.org/abs/2005.01027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Two-Stage Masked LM Method for Term Set Expansion", "abstract": "We tackle the task of Term Set Expansion (TSE): given a small seed set of\nexample terms from a semantic class, finding more members of that class. The\ntask is of great practical utility, and also of theoretical utility as it\nrequires generalization from few examples. Previous approaches to the TSE task\ncan be characterized as either distributional or pattern-based. We harness the\npower of neural masked language models (MLM) and propose a novel TSE algorithm,\nwhich combines the pattern-based and distributional approaches. Due to the\nsmall size of the seed set, fine-tuning methods are not effective, calling for\nmore creative use of the MLM. The gist of the idea is to use the MLM to first\nmine for informative patterns with respect to the seed set, and then to obtain\nmore members of the seed class by generalizing these patterns. Our method\noutperforms state-of-the-art TSE algorithms. Implementation is available at:\nhttps://github.com/ guykush/TermSetExpansion-MPB/", "published": "2020-05-03 12:06:06", "link": "http://arxiv.org/abs/2005.01063v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simplifying Paragraph-level Question Generation via Transformer Language\n  Models", "abstract": "Question generation (QG) is a natural language generation task where a model\nis trained to ask questions corresponding to some input text. Most recent\napproaches frame QG as a sequence-to-sequence problem and rely on additional\nfeatures and mechanisms to increase performance; however, these often increase\nmodel complexity, and can rely on auxiliary data unavailable in practical use.\nA single Transformer-based unidirectional language model leveraging transfer\nlearning can be used to produce high quality questions while disposing of\nadditional task-specific complexity. Our QG model, finetuned from GPT-2 Small,\noutperforms several paragraph-level QG baselines on the SQuAD dataset by 0.95\nMETEOR points. Human evaluators rated questions as easy to answer, relevant to\ntheir context paragraph, and corresponding well to natural human speech. Also\nintroduced is a new set of baseline scores on the RACE dataset, which has not\npreviously been used for QG tasks. Further experimentation with varying model\ncapacities and datasets with non-identification type questions is recommended\nin order to further verify the robustness of pretrained Transformer-based LMs\nas question generators.", "published": "2020-05-03 14:57:24", "link": "http://arxiv.org/abs/2005.01107v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emergence of Syntax Needs Minimal Supervision", "abstract": "This paper is a theoretical contribution to the debate on the learnability of\nsyntax from a corpus without explicit syntax-specific guidance. Our approach\noriginates in the observable structure of a corpus, which we use to define and\nisolate grammaticality (syntactic information) and meaning/pragmatics\ninformation. We describe the formal characteristics of an autonomous syntax and\nshow that it becomes possible to search for syntax-based lexical categories\nwith a simple optimization process, without any prior hypothesis on the form of\nthe model.", "published": "2020-05-03 15:38:33", "link": "http://arxiv.org/abs/2005.01119v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven\n  Cloze Reward", "abstract": "Sequence-to-sequence models for abstractive summarization have been studied\nextensively, yet the generated summaries commonly suffer from fabricated\ncontent, and are often found to be near-extractive. We argue that, to address\nthese issues, the summarizer should acquire semantic interpretation over input,\ne.g., via structured representation, to allow the generation of more\ninformative summaries. In this paper, we present ASGARD, a novel framework for\nAbstractive Summarization with Graph-Augmentation and semantic-driven RewarD.\nWe propose the use of dual encoders---a sequential document encoder and a\ngraph-structured encoder---to maintain the global context and local\ncharacteristics of entities, complementing each other. We further design a\nreward based on a multiple choice cloze test to drive the model to better\ncapture entity interactions. Results show that our models produce significantly\nhigher ROUGE scores than a variant without knowledge graph as input on both New\nYork Times and CNN/Daily Mail datasets. We also obtain better or comparable\nperformance compared to systems that are fine-tuned from large pretrained\nlanguage models. Human judges further rate our model outputs as more\ninformative and containing fewer unfaithful errors.", "published": "2020-05-03 18:23:06", "link": "http://arxiv.org/abs/2005.01159v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Similarity Analysis of Contextual Word Representation Models", "abstract": "This paper investigates contextual word representation models from the lens\nof similarity analysis. Given a collection of trained models, we measure the\nsimilarity of their internal representations and attention. Critically, these\nmodels come from vastly different architectures. We use existing and novel\nsimilarity measures that aim to gauge the level of localization of information\nin the deep models, and facilitate the investigation of which design factors\naffect model similarity, without requiring any external linguistic annotation.\nThe analysis reveals that models within the same family are more similar to one\nanother, as may be expected. Surprisingly, different architectures have rather\nsimilar representations, but different individual neurons. We also observed\ndifferences in information localization in lower and higher layers and found\nthat higher layers are more affected by fine-tuning on downstream tasks.", "published": "2020-05-03 19:48:15", "link": "http://arxiv.org/abs/2005.01172v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Influence Paths for Characterizing Subject-Verb Number Agreement in LSTM\n  Language Models", "abstract": "LSTM-based recurrent neural networks are the state-of-the-art for many\nnatural language processing (NLP) tasks. Despite their performance, it is\nunclear whether, or how, LSTMs learn structural features of natural languages\nsuch as subject-verb number agreement in English. Lacking this understanding,\nthe generality of LSTM performance on this task and their suitability for\nrelated tasks remains uncertain. Further, errors cannot be properly attributed\nto a lack of structural capability, training data omissions, or other\nexceptional faults. We introduce *influence paths*, a causal account of\nstructural properties as carried by paths across gates and neurons of a\nrecurrent neural network. The approach refines the notion of influence (the\nsubject's grammatical number has influence on the grammatical number of the\nsubsequent verb) into a set of gate or neuron-level paths. The set localizes\nand segments the concept (e.g., subject-verb agreement), its constituent\nelements (e.g., the subject), and related or interfering elements (e.g.,\nattractors). We exemplify the methodology on a widely-studied multi-layer LSTM\nlanguage model, demonstrating its accounting for subject-verb number agreement.\nThe results offer both a finer and a more complete view of an LSTM's handling\nof this structural aspect of the English language than prior results based on\ndiagnostic classifiers and ablation.", "published": "2020-05-03 21:10:31", "link": "http://arxiv.org/abs/2005.01190v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Limitations of Cross-lingual Encoders as Exposed by\n  Reference-Free Machine Translation Evaluation", "abstract": "Evaluation of cross-lingual encoders is usually performed either via\nzero-shot cross-lingual transfer in supervised downstream tasks or via\nunsupervised cross-lingual textual similarity. In this paper, we concern\nourselves with reference-free machine translation (MT) evaluation where we\ndirectly compare source texts to (sometimes low-quality) system translations,\nwhich represents a natural adversarial setup for multilingual encoders.\nReference-free evaluation holds the promise of web-scale comparison of MT\nsystems. We systematically investigate a range of metrics based on\nstate-of-the-art cross-lingual semantic representations obtained with\npretrained M-BERT and LASER. We find that they perform poorly as semantic\nencoders for reference-free MT evaluation and identify their two key\nlimitations, namely, (a) a semantic mismatch between representations of mutual\ntranslations and, more prominently, (b) the inability to punish\n\"translationese\", i.e., low-quality literal translations. We propose two\npartial remedies: (1) post-hoc re-alignment of the vector spaces and (2)\ncoupling of semantic-similarity based metrics with target-side language\nmodeling. In segment-level MT evaluation, our best metric surpasses\nreference-based BLEU by 5.7 correlation points.", "published": "2020-05-03 22:10:23", "link": "http://arxiv.org/abs/2005.01196v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Relationships Between the Grammatical Genders of Inanimate Nouns\n  and Their Co-Occurring Adjectives and Verbs", "abstract": "We use large-scale corpora in six different gendered languages, along with\ntools from NLP and information theory, to test whether there is a relationship\nbetween the grammatical genders of inanimate nouns and the adjectives used to\ndescribe those nouns. For all six languages, we find that there is a\nstatistically significant relationship. We also find that there are\nstatistically significant relationships between the grammatical genders of\ninanimate nouns and the verbs that take those nouns as direct objects, as\nindirect objects, and as subjects. We defer a deeper investigation of these\nrelationships for future work.", "published": "2020-05-03 22:49:44", "link": "http://arxiv.org/abs/2005.01204v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Aspect-Level Sentiment Analysis with Aspect Extraction", "abstract": "Aspect-based sentiment analysis (ABSA), a popular research area in NLP has\ntwo distinct parts -- aspect extraction (AE) and labeling the aspects with\nsentiment polarity (ALSA). Although distinct, these two tasks are highly\ncorrelated. The work primarily hypothesize that transferring knowledge from a\npre-trained AE model can benefit the performance of ALSA models. Based on this\nhypothesis, word embeddings are obtained during AE and subsequently, feed that\nto the ALSA model. Empirically, this work show that the added information\nsignificantly improves the performance of three different baseline ALSA models\non two distinct domains. This improvement also translates well across domains\nbetween AE and ALSA tasks.", "published": "2020-05-03 06:25:16", "link": "http://arxiv.org/abs/2005.06607v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Entities and Topics from News and Connecting Criminal Records", "abstract": "The goal of this paper is to summarize methodologies used in extracting\nentities and topics from a database of criminal records and from a database of\nnewspapers. Statistical models had successfully been used in studying the\ntopics of roughly 300,000 New York Times articles. In addition, these models\nhad also been used to successfully analyze entities related to people,\norganizations, and places (D Newman, 2006). Additionally, analytical\napproaches, especially in hotspot mapping, were used in some researches with an\naim to predict crime locations and circumstances in the future, and those\napproaches had been tested quite successfully (S Chainey, 2008). Based on the\ntwo above notions, this research was performed with the intention to apply data\nscience techniques in analyzing a big amount of data, selecting valuable\nintelligence, clustering violations depending on their types of crime, and\ncreating a crime graph that changes through time. In this research, the task\nwas to download criminal datasets from Kaggle and a collection of news articles\nfrom Kaggle and EAGER project databases, and then to merge these datasets into\none general dataset. The most important goal of this project was performing\nstatistical and natural language processing methods to extract entities and\ntopics as well as to group similar data points into correct clusters, in order\nto understand public data about U.S related crimes better.", "published": "2020-05-03 00:06:01", "link": "http://arxiv.org/abs/2005.00950v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Gender Gap in Natural Language Processing Research: Disparities in\n  Authorship and Citations", "abstract": "Disparities in authorship and citations across gender can have substantial\nadverse consequences not just on the disadvantaged genders, but also on the\nfield of study as a whole. Measuring gender gaps is a crucial step towards\naddressing them. In this work, we examine female first author percentages and\nthe citations to their papers in Natural Language Processing (1965 to 2019). We\ndetermine aggregate-level statistics using an existing manually curated\nauthor--gender list as well as first names strongly associated with a gender.\nWe find that only about 29% of first authors are female and only about 25% of\nlast authors are female. Notably, this percentage has not improved since the\nmid 2000s. We also show that, on average, female first authors are cited less\nthan male first authors, even when controlling for experience and area of\nresearch. Finally, we discuss the ethical considerations involved in automatic\ndemographic analysis.", "published": "2020-05-03 01:31:12", "link": "http://arxiv.org/abs/2005.00962v2", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation", "abstract": "Word embeddings derived from human-generated corpora inherit strong gender\nbias which can be further amplified by downstream models. Some commonly adopted\ndebiasing approaches, including the seminal Hard Debias algorithm, apply\npost-processing procedures that project pre-trained word embeddings into a\nsubspace orthogonal to an inferred gender subspace. We discover that\nsemantic-agnostic corpus regularities such as word frequency captured by the\nword embeddings negatively impact the performance of these algorithms. We\npropose a simple but effective technique, Double Hard Debias, which purifies\nthe word embeddings against such corpus regularities prior to inferring and\nremoving the gender subspace. Experiments on three bias mitigation benchmarks\nshow that our approach preserves the distributional semantics of the\npre-trained word embeddings while reducing gender bias to a significantly\nlarger degree than prior approaches.", "published": "2020-05-03 02:33:20", "link": "http://arxiv.org/abs/2005.00965v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Does Selective Mechanism Improve Self-Attention Networks?", "abstract": "Self-attention networks (SANs) with selective mechanism has produced\nsubstantial improvements in various NLP tasks by concentrating on a subset of\ninput words. However, the underlying reasons for their strong performance have\nnot been well explained. In this paper, we bridge the gap by assessing the\nstrengths of selective SANs (SSANs), which are implemented with a flexible and\nuniversal Gumbel-Softmax. Experimental results on several representative NLP\ntasks, including natural language inference, semantic role labelling, and\nmachine translation, show that SSANs consistently outperform the standard SANs.\nThrough well-designed probing experiments, we empirically validate that the\nimprovement of SSANs can be attributed in part to mitigating two commonly-cited\nweaknesses of SANs: word order encoding and structure modeling. Specifically,\nthe selective mechanism improves SANs by paying more attention to content words\nthat contribute to the meaning of the sentence. The code and data are released\nat https://github.com/xwgeng/SSAN.", "published": "2020-05-03 04:18:44", "link": "http://arxiv.org/abs/2005.00979v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Accurate Model for Predicting the (Graded) Effect of Context in Word\n  Similarity Based on Bert", "abstract": "Natural Language Processing (NLP) has been widely used in the semantic\nanalysis in recent years. Our paper mainly discusses a methodology to analyze\nthe effect that context has on human perception of similar words, which is the\nthird task of SemEval 2020. We apply several methods in calculating the\ndistance between two embedding vector generated by Bidirectional Encoder\nRepresentation from Transformer (BERT). Our team will_go won the 1st place in\nFinnish language track of subtask1, the second place in English track of\nsubtask1.", "published": "2020-05-03 06:48:35", "link": "http://arxiv.org/abs/2005.01006v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Data-to-Text Generation via Jointly Learning the Segmentation and\n  Correspondence", "abstract": "The neural attention model has achieved great success in data-to-text\ngeneration tasks. Though usually excelling at producing fluent text, it suffers\nfrom the problem of information missing, repetition and \"hallucination\". Due to\nthe black-box nature of the neural attention architecture, avoiding these\nproblems in a systematic way is non-trivial. To address this concern, we\npropose to explicitly segment target text into fragment units and align them\nwith their data correspondences. The segmentation and correspondence are\njointly learned as latent variables without any human annotations. We further\nimpose a soft statistical constraint to regularize the segmental granularity.\nThe resulting architecture maintains the same expressive power as neural\nattention models, while being able to generate fully interpretable outputs with\nseveral times less computational cost. On both E2E and WebNLG benchmarks, we\nshow the proposed model consistently outperforms its neural attention\ncounterparts.", "published": "2020-05-03 14:28:28", "link": "http://arxiv.org/abs/2005.01096v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Let Me Choose: From Verbal Context to Font Selection", "abstract": "In this paper, we aim to learn associations between visual attributes of\nfonts and the verbal context of the texts they are typically applied to.\nCompared to related work leveraging the surrounding visual context, we choose\nto focus only on the input text as this can enable new applications for which\nthe text is the only visual element in the document. We introduce a new\ndataset, containing examples of different topics in social media posts and ads,\nlabeled through crowd-sourcing. Due to the subjective nature of the task,\nmultiple fonts might be perceived as acceptable for an input text, which makes\nthis problem challenging. To this end, we investigate different end-to-end\nmodels to learn label distributions on crowd-sourced data and capture\ninter-subjectivity across all annotations.", "published": "2020-05-03 17:36:17", "link": "http://arxiv.org/abs/2005.01151v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tailoring and Evaluating the Wikipedia for in-Domain Comparable Corpora\n  Extraction", "abstract": "We propose an automatic language-independent graph-based method to build\n\\`a-la-carte article collections on user-defined domains from the Wikipedia.\nThe core model is based on the exploration of the encyclopaedia's category\ngraph and can produce both monolingual and multilingual comparable collections.\nWe run thorough experiments to assess the quality of the obtained corpora in 10\nlanguages and 743 domains. According to an extensive manual evaluation, our\ngraph-based model outperforms a retrieval-based approach and reaches an average\nprecision of 84% on in-domain articles. As manual evaluations are costly, we\nintroduce the concept of \"domainness\" and design several automatic metrics to\naccount for the quality of the collections. Our best metric for domainness\nshows a strong correlation with the human-judged precision, representing a\nreasonable automatic alternative to assess the quality of domain-specific\ncorpora. We release the WikiTailor toolkit with the implementation of the\nextraction methods, the evaluation measures and several utilities. WikiTailor\nmakes obtaining multilingual in-domain data from the Wikipedia easy.", "published": "2020-05-03 20:08:39", "link": "http://arxiv.org/abs/2005.01177v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Dynamic Programming Encoding for Subword Segmentation in Neural Machine\n  Translation", "abstract": "This paper introduces Dynamic Programming Encoding (DPE), a new segmentation\nalgorithm for tokenizing sentences into subword units. We view the subword\nsegmentation of output sentences as a latent variable that should be\nmarginalized out for learning and inference. A mixed character-subword\ntransformer is proposed, which enables exact log marginal likelihood estimation\nand exact MAP inference to find target segmentations with maximum posterior\nprobability. DPE uses a lightweight mixed character-subword transformer as a\nmeans of pre-processing parallel data to segment output sentences using dynamic\nprogramming. Empirical results on machine translation suggest that DPE is\neffective for segmenting output sentences and can be combined with BPE dropout\nfor stochastic segmentation of source sentences. DPE achieves an average\nimprovement of 0.9 BLEU over BPE (Sennrich et al., 2016) and an average\nimprovement of 0.55 BLEU over BPE dropout (Provilkov et al., 2019) on several\nWMT datasets including English <=> (German, Romanian, Estonian, Finnish,\nHungarian).", "published": "2020-05-03 05:00:50", "link": "http://arxiv.org/abs/2005.06606v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Out of the Echo Chamber: Detecting Countering Debate Speeches", "abstract": "An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin \"echo chambers\" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.", "published": "2020-05-03 18:02:10", "link": "http://arxiv.org/abs/2005.01157v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Correcting the Autocorrect: Context-Aware Typographical Error Correction\n  via Training Data Augmentation", "abstract": "In this paper, we explore the artificial generation of typographical errors\nbased on real-world statistics. We first draw on a small set of annotated data\nto compute spelling error statistics. These are then invoked to introduce\nerrors into substantially larger corpora. The generation methodology allows us\nto generate particularly challenging errors that require context-aware error\ndetection. We use it to create a set of English language error detection and\ncorrection datasets. Finally, we examine the effectiveness of machine learning\nmodels for detecting and correcting errors based on this data. The datasets are\navailable at http://typo.nlproc.org", "published": "2020-05-03 18:08:17", "link": "http://arxiv.org/abs/2005.01158v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
