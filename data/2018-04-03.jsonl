{"title": "Automatic Normalization of Word Variations in Code-Mixed Social Media\n  Text", "abstract": "Social media platforms such as Twitter and Facebook are becoming popular in\nmultilingual societies. This trend induces portmanteau of South Asian languages\nwith English. The blend of multiple languages as code-mixed data has recently\nbecome popular in research communities for various NLP tasks. Code-mixed data\nconsist of anomalies such as grammatical errors and spelling variations. In\nthis paper, we leverage the contextual property of words where the different\nspelling variation of words share similar context in a large noisy social media\ntext. We capture different variations of words belonging to same context in an\nunsupervised manner using distributed representations of words. Our experiments\nreveal that preprocessing of the code-mixed dataset based on our approach\nimproves the performance in state-of-the-art part-of-speech tagging\n(POS-tagging) and sentiment analysis tasks.", "published": "2018-04-03 03:19:31", "link": "http://arxiv.org/abs/1804.00804v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emotions are Universal: Learning Sentiment Based Representations of\n  Resource-Poor Languages using Siamese Networks", "abstract": "Machine learning approaches in sentiment analysis principally rely on the\nabundance of resources. To limit this dependence, we propose a novel method\ncalled Siamese Network Architecture for Sentiment Analysis (SNASA) to learn\nrepresentations of resource-poor languages by jointly training them with\nresource-rich languages using a siamese network.\n  SNASA model consists of twin Bi-directional Long Short-Term Memory Recurrent\nNeural Networks (Bi-LSTM RNN) with shared parameters joined by a contrastive\nloss function, based on a similarity metric. The model learns the sentence\nrepresentations of resource-poor and resource-rich language in a common\nsentiment space by using a similarity metric based on their individual\nsentiments. The model, hence, projects sentences with similar sentiment closer\nto each other and the sentences with different sentiment farther from each\nother. Experiments on large-scale datasets of resource-rich languages - English\nand Spanish and resource-poor languages - Hindi and Telugu reveal that SNASA\noutperforms the state-of-the-art sentiment analysis approaches based on\ndistributional semantics, semantic rules, lexicon lists and deep neural network\nrepresentations without sh", "published": "2018-04-03 03:19:36", "link": "http://arxiv.org/abs/1804.00805v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis of Code-Mixed Languages leveraging Resource Rich\n  Languages", "abstract": "Code-mixed data is an important challenge of natural language processing\nbecause its characteristics completely vary from the traditional structures of\nstandard languages.\n  In this paper, we propose a novel approach called Sentiment Analysis of\nCode-Mixed Text (SACMT) to classify sentences into their corresponding\nsentiment - positive, negative or neutral, using contrastive learning. We\nutilize the shared parameters of siamese networks to map the sentences of\ncode-mixed and standard languages to a common sentiment space. Also, we\nintroduce a basic clustering based preprocessing method to capture variations\nof code-mixed transliterated words. Our experiments reveal that SACMT\noutperforms the state-of-the-art approaches in sentiment analysis for\ncode-mixed text by 7.6% in accuracy and 10.1% in F-score.", "published": "2018-04-03 03:19:41", "link": "http://arxiv.org/abs/1804.00806v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Word Embeddings into Open Directory Project based\n  Large-scale Classification", "abstract": "Recently, implicit representation models, such as embedding or deep learning,\nhave been successfully adopted to text classification task due to their\noutstanding performance. However, these approaches are limited to small- or\nmoderate-scale text classification. Explicit representation models are often\nused in a large-scale text classification, like the Open Directory Project\n(ODP)-based text classification. However, the performance of these models is\nlimited to the associated knowledge bases. In this paper, we incorporate word\nembeddings into the ODP-based large-scale classification. To this end, we first\ngenerate category vectors, which represent the semantics of ODP categories by\njointly modeling word embeddings and the ODP-based text classification. We then\npropose a novel semantic similarity measure, which utilizes the category and\nword vectors obtained from the joint model and word embeddings, respectively.\nThe evaluation results clearly show the efficacy of our methodology in\nlarge-scale text classification. The proposed scheme exhibits significant\nimprovements of 10% and 28% in terms of macro-averaging F1-score and precision\nat k, respectively, over state-of-the-art techniques.", "published": "2018-04-03 05:09:32", "link": "http://arxiv.org/abs/1804.00828v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attentive Sequence-to-Sequence Learning for Diacritic Restoration of\n  Yor\u00f9b\u00e1 Language Text", "abstract": "Yor\\`ub\\'a is a widely spoken West African language with a writing system\nrich in tonal and orthographic diacritics. With very few exceptions, diacritics\nare omitted from electronic texts, due to limited device and application\nsupport. Diacritics provide morphological information, are crucial for lexical\ndisambiguation, pronunciation and are vital for any Yor\\`ub\\'a text-to-speech\n(TTS), automatic speech recognition (ASR) and natural language processing (NLP)\ntasks. Reframing Automatic Diacritic Restoration (ADR) as a machine translation\ntask, we experiment with two different attentive Sequence-to-Sequence neural\nmodels to process undiacritized text. On our evaluation dataset, this approach\nproduces diacritization error rates of less than 5%. We have released\npre-trained models, datasets and source-code as an open-source project to\nadvance efforts on Yor\\`ub\\'a language technology.", "published": "2018-04-03 05:33:38", "link": "http://arxiv.org/abs/1804.00832v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-lingual neural title generation for e-Commerce browse pages", "abstract": "To provide better access of the inventory to buyers and better search engine\noptimization, e-Commerce websites are automatically generating millions of\neasily searchable browse pages. A browse page consists of a set of slot\nname/value pairs within a given category, grouping multiple items which share\nsome characteristics. These browse pages require a title describing the content\nof the page. Since the number of browse pages are huge, manual creation of\nthese titles is infeasible. Previous statistical and neural approaches depend\nheavily on the availability of large amounts of data in a language. In this\nresearch, we apply sequence-to-sequence models to generate titles for high- &\nlow-resourced languages by leveraging transfer learning. We train these models\non multi-lingual data, thereby creating one joint model which can generate\ntitles in various different languages. Performance of the title generation\nsystem is evaluated on three different languages; English, German, and French,\nwith a particular focus on low-resourced French language.", "published": "2018-04-03 15:41:44", "link": "http://arxiv.org/abs/1804.01041v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning of Emoji-based Representations for Resource-Poor\n  Languages", "abstract": "The introduction of emojis (or emoticons) in social media platforms has given\nthe users an increased potential for expression. We propose a novel method\ncalled Classification of Emojis using Siamese Network Architecture (CESNA) to\nlearn emoji-based representations of resource-poor languages by jointly\ntraining them with resource-rich languages using a siamese network.\n  CESNA model consists of twin Bi-directional Long Short-Term Memory Recurrent\nNeural Networks (Bi-LSTM RNN) with shared parameters joined by a contrastive\nloss function based on a similarity metric. The model learns the\nrepresentations of resource-poor and resource-rich language in a common emoji\nspace by using a similarity metric based on the emojis present in sentences\nfrom both languages. The model, hence, projects sentences with similar emojis\ncloser to each other and the sentences with different emojis farther from one\nanother. Experiments on large-scale Twitter datasets of resource-rich languages\n- English and Spanish and resource-poor languages - Hindi and Telugu reveal\nthat CESNA outperforms the state-of-the-art emoji prediction approaches based\non distributional semantics, semantic rules, lexicon lists and deep neural\nnetwork representations without shared parameters.", "published": "2018-04-03 03:19:45", "link": "http://arxiv.org/abs/1804.01855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bi-Directional Block Self-Attention for Fast and Memory-Efficient\n  Sequence Modeling", "abstract": "Recurrent neural networks (RNN), convolutional neural networks (CNN) and\nself-attention networks (SAN) are commonly used to produce context-aware\nrepresentations. RNN can capture long-range dependency but is hard to\nparallelize and not time-efficient. CNN focuses on local dependency but does\nnot perform well on some tasks. SAN can model both such dependencies via highly\nparallelizable computation, but memory requirement grows rapidly in line with\nsequence length. In this paper, we propose a model, called \"bi-directional\nblock self-attention network (Bi-BloSAN)\", for RNN/CNN-free sequence encoding.\nIt requires as little memory as RNN but with all the merits of SAN. Bi-BloSAN\nsplits the entire sequence into blocks, and applies an intra-block SAN to each\nblock for modeling local context, then applies an inter-block SAN to the\noutputs for all blocks to capture long-range dependency. Thus, each SAN only\nneeds to process a short sequence, and only a small amount of memory is\nrequired. Additionally, we use feature-level attention to handle the variation\nof contexts around the same word, and use forward/backward masks to encode\ntemporal order information. On nine benchmark datasets for different NLP tasks,\nBi-BloSAN achieves or improves upon state-of-the-art accuracy, and shows better\nefficiency-memory trade-off than existing RNN/CNN/SAN.", "published": "2018-04-03 07:41:10", "link": "http://arxiv.org/abs/1804.00857v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph2Seq: Graph to Sequence Learning with Attention-based Neural\n  Networks", "abstract": "The celebrated Sequence to Sequence learning (Seq2Seq) technique and its\nnumerous variants achieve excellent performance on many tasks. However, many\nmachine learning tasks have inputs naturally represented as graphs; existing\nSeq2Seq models face a significant challenge in achieving accurate conversion\nfrom graph form to the appropriate sequence. To address this challenge, we\nintroduce a novel general end-to-end graph-to-sequence neural encoder-decoder\nmodel that maps an input graph to a sequence of vectors and uses an\nattention-based LSTM method to decode the target sequence from these vectors.\nOur method first generates the node and graph embeddings using an improved\ngraph-based neural network with a novel aggregation strategy to incorporate\nedge direction information in the node embeddings. We further introduce an\nattention mechanism that aligns node embeddings and the decoding sequence to\nbetter cope with large graphs. Experimental results on bAbI, Shortest Path, and\nNatural Language Generation tasks demonstrate that our model achieves\nstate-of-the-art performance and significantly outperforms existing graph\nneural networks, Seq2Seq, and Tree2Seq models; using the proposed\nbi-directional node embedding aggregation strategy, the model can converge\nrapidly to the optimal performance.", "published": "2018-04-03 04:47:22", "link": "http://arxiv.org/abs/1804.00823v4", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "AttnConvnet at SemEval-2018 Task 1: Attention-based Convolutional Neural\n  Networks for Multi-label Emotion Classification", "abstract": "In this paper, we propose an attention-based classifier that predicts\nmultiple emotions of a given sentence. Our model imitates human's two-step\nprocedure of sentence understanding and it can effectively represent and\nclassify sentences. With emoji-to-meaning preprocessing and extra lexicon\nutilization, we further improve the model performance. We train and evaluate\nour model with data provided by SemEval-2018 task 1-5, each sentence of which\nhas several labels among 11 given sentiments. Our model achieves 5-th/1-th rank\nin English/Spanish respectively.", "published": "2018-04-03 05:31:35", "link": "http://arxiv.org/abs/1804.00831v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Speech waveform synthesis from MFCC sequences with generative\n  adversarial networks", "abstract": "This paper proposes a method for generating speech from filterbank mel\nfrequency cepstral coefficients (MFCC), which are widely used in speech\napplications, such as ASR, but are generally considered unusable for speech\nsynthesis. First, we predict fundamental frequency and voicing information from\nMFCCs with an autoregressive recurrent neural net. Second, the spectral\nenvelope information contained in MFCCs is converted to all-pole filters, and a\npitch-synchronous excitation model matched to these filters is trained.\nFinally, we introduce a generative adversarial network -based noise model to\nadd a realistic high-frequency stochastic component to the modeled excitation\nsignal. The results show that high quality speech reconstruction can be\nobtained, given only MFCC information at test time.", "published": "2018-04-03 11:43:36", "link": "http://arxiv.org/abs/1804.00920v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "360\u00b0 Stance Detection", "abstract": "The proliferation of fake news and filter bubbles makes it increasingly\ndifficult to form an unbiased, balanced opinion towards a topic. To ameliorate\nthis, we propose 360{\\deg} Stance Detection, a tool that aggregates news with\nmultiple perspectives on a topic. It presents them on a spectrum ranging from\nsupport to opposition, enabling the user to base their opinion on multiple\npieces of diverse evidence.", "published": "2018-04-03 14:17:09", "link": "http://arxiv.org/abs/1804.00982v1", "categories": ["cs.CL", "cs.IR", "cs.SI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Real-Time Prediction of the Duration of Distribution System Outages", "abstract": "This paper addresses the problem of predicting duration of unplanned power\noutages, using historical outage records to train a series of neural network\npredictors. The initial duration prediction is made based on environmental\nfactors, and it is updated based on incoming field reports using natural\nlanguage processing to automatically analyze the text. Experiments using 15\nyears of outage records show good initial results and improved performance\nleveraging text. Case studies show that the language processing identifies\nphrases that point to outage causes and repair steps.", "published": "2018-04-03 23:10:36", "link": "http://arxiv.org/abs/1804.01189v2", "categories": ["cs.SY", "cs.CL", "math.OC", "stat.ML"], "primary_category": "cs.SY"}
{"title": "EmoRL: Continuous Acoustic Emotion Classification using Deep\n  Reinforcement Learning", "abstract": "Acoustically expressed emotions can make communication with a robot more\nefficient. Detecting emotions like anger could provide a clue for the robot\nindicating unsafe/undesired situations. Recently, several deep neural\nnetwork-based models have been proposed which establish new state-of-the-art\nresults in affective state evaluation. These models typically start processing\nat the end of each utterance, which not only requires a mechanism to detect the\nend of an utterance but also makes it difficult to use them in a real-time\ncommunication scenario, e.g. human-robot interaction. We propose the EmoRL\nmodel that triggers an emotion classification as soon as it gains enough\nconfidence while listening to a person speaking. As a result, we minimize the\nneed for segmenting the audio signal for classification and achieve lower\nlatency as the audio signal is processed incrementally. The method is\ncompetitive with the accuracy of a strong baseline model, while allowing much\nearlier prediction.", "published": "2018-04-03 09:21:11", "link": "http://arxiv.org/abs/1804.04053v1", "categories": ["cs.RO", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Socioeconomic Dependencies of Linguistic Patterns in Twitter: A\n  Multivariate Analysis", "abstract": "Our usage of language is not solely reliant on cognition but is arguably\ndetermined by myriad external factors leading to a global variability of\nlinguistic patterns. This issue, which lies at the core of sociolinguistics and\nis backed by many small-scale studies on face-to-face communication, is\naddressed here by constructing a dataset combining the largest French Twitter\ncorpus to date with detailed socioeconomic maps obtained from national census\nin France. We show how key linguistic variables measured in individual Twitter\nstreams depend on factors like socioeconomic status, location, time, and the\nsocial network of individuals. We found that (i) people of higher socioeconomic\nstatus, active to a greater degree during the daytime, use a more standard\nlanguage; (ii) the southern part of the country is more prone to use more\nstandard language than the northern one, while locally the used variety or\ndialect is determined by the spatial distribution of socioeconomic status; and\n(iii) individuals connected in the social network are closer linguistically\nthan disconnected ones, even after the effects of status homophily have been\nremoved. Our results inform sociolinguistic theory and may inspire novel\nlearning methods for the inference of socioeconomic status of people from the\nway they tweet.", "published": "2018-04-03 20:18:11", "link": "http://arxiv.org/abs/1804.01155v1", "categories": ["cs.CL", "cs.CY", "cs.SI", "physics.soc-ph", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Comparing the Max and Noisy-Or Pooling Functions in Multiple Instance\n  Learning for Weakly Supervised Sequence Learning Tasks", "abstract": "Many sequence learning tasks require the localization of certain events in\nsequences. Because it can be expensive to obtain strong labeling that specifies\nthe starting and ending times of the events, modern systems are often trained\nwith weak labeling without explicit timing information. Multiple instance\nlearning (MIL) is a popular framework for learning from weak labeling. In a\ncommon scenario of MIL, it is necessary to choose a pooling function to\naggregate the predictions for the individual steps of the sequences. In this\npaper, we compare the \"max\" and \"noisy-or\" pooling functions on a speech\nrecognition task and a sound event detection task. We find that max pooling is\nable to localize phonemes and sound events, while noisy-or pooling fails. We\nprovide a theoretical explanation of the different behavior of the two pooling\nfunctions on sequence learning tasks.", "published": "2018-04-03 19:53:08", "link": "http://arxiv.org/abs/1804.01146v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Music Genre Classification using Machine Learning Techniques", "abstract": "Categorizing music files according to their genre is a challenging task in\nthe area of music information retrieval (MIR). In this study, we compare the\nperformance of two classes of models. The first is a deep learning approach\nwherein a CNN model is trained end-to-end, to predict the genre label of an\naudio signal, solely using its spectrogram. The second approach utilizes\nhand-crafted features, both from the time domain and the frequency domain. We\ntrain four traditional machine learning classifiers with these features and\ncompare their performance. The features that contribute the most towards this\nmulti-class classification task are identified. The experiments are conducted\non the Audio set data set and we report an AUC value of 0.894 for an ensemble\nclassifier which combines the two proposed approaches.", "published": "2018-04-03 20:04:04", "link": "http://arxiv.org/abs/1804.01149v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
