{"title": "A new measure of risk using Fourier analysis", "abstract": "We use Fourier analysis to access risk in financial products. With it we\nanalyze price changes of e.g. stocks. Via Fourier analysis we scrutinize\nquantitatively whether the frequency of change is higher than a change in\n(conserved) company value would allow. If it is the case, it would be a clear\nindicator of speculation and with it risk. The entire methods or better its\napplication is fairly new. However, there were severe flaws in previous\nattempts; making the results (not the method) doubtful. We corrected all these\nmistakes by e.g. using Fourier transformation instead of discrete Fourier\nanalysis. Our analysis is reliable in the entire frequency band, even for\nfre-quency of 1/1d or higher if the prices are noted accordingly. For the\nstocks scrutinized we found that the price of stocks changes disproportionally\nwithin one week which clearly indicates spec-ulation. It would be an\ninteresting extension to apply the method to crypto currencies as these\ncurrencies have no conserved value which makes normal considerations of\nvolatility difficult.", "published": "2024-08-18 11:55:35", "link": "http://arxiv.org/abs/2408.10279v1", "categories": ["q-fin.ST", "91B05, 62P20", "G.m; G.3"], "primary_category": "q-fin.ST"}
{"title": "Crisis Alpha: A High-Performance Trading Algorithm Tested in Market Downturns", "abstract": "Forming quantitative portfolios using statistical risk models presents a\nsignificant challenge for hedge funds and portfolio managers. This research\ninvestigates three distinct statistical risk models to construct quantitative\nportfolios of 1,000 floating stocks in the US market. Utilizing five different\ninvestment strategies, these models are tested across four periods,\nencompassing the last three major financial crises: The Dot Com Bubble, Global\nFinancial Crisis, and Covid-19 market downturn. Backtests leverage the CRSP\ndataset from January 1990 through December 2023. The results demonstrate that\nthe proposed models consistently outperformed market excess returns across all\nperiods. These findings suggest that the developed risk models can serve as\nvaluable tools for asset managers, aiding in strategic decision-making and risk\nmanagement in various economic conditions.", "published": "2024-08-18 19:35:07", "link": "http://arxiv.org/abs/2409.14510v1", "categories": ["q-fin.PM", "q-fin.CP", "q-fin.RM", "q-fin.TR"], "primary_category": "q-fin.PM"}
{"title": "Fostering Natural Conversation in Large Language Models with NICO: a\n  Natural Interactive COnversation dataset", "abstract": "Benefiting from diverse instruction datasets, contemporary Large Language\nModels (LLMs) perform effectively as AI assistants in collaborating with\nhumans. However, LLMs still struggle to generate natural and colloquial\nresponses in real-world applications such as chatbots and psychological\ncounseling that require more human-like interactions. To address these\nlimitations, we introduce NICO, a Natural Interactive COnversation dataset in\nChinese. We first use GPT-4-turbo to generate dialogue drafts and make them\ncover 20 daily-life topics and 5 types of social interactions. Then, we hire\nworkers to revise these dialogues to ensure that they are free of grammatical\nerrors and unnatural utterances. We define two dialogue-level natural\nconversation tasks and two sentence-level tasks for identifying and rewriting\nunnatural sentences. Multiple open-source and closed-source LLMs are tested and\nanalyzed in detail. The experimental results highlight the challenge of the\ntasks and demonstrate how NICO can help foster the natural dialogue\ncapabilities of LLMs. The dataset will be released.", "published": "2024-08-18 02:06:25", "link": "http://arxiv.org/abs/2408.09330v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SkyScript-100M: 1,000,000,000 Pairs of Scripts and Shooting Scripts for\n  Short Drama", "abstract": "Generating high-quality shooting scripts containing information such as scene\nand shot language is essential for short drama script generation. We collect\n6,660 popular short drama episodes from the Internet, each with an average of\n100 short episodes, and the total number of short episodes is about 80,000,\nwith a total duration of about 2,000 hours and totaling 10 terabytes (TB). We\nperform keyframe extraction and annotation on each episode to obtain about\n10,000,000 shooting scripts. We perform 100 script restorations on the\nextracted shooting scripts based on our self-developed large short drama\ngeneration model SkyReels. This leads to a dataset containing 1,000,000,000\npairs of scripts and shooting scripts for short dramas, called SkyScript-100M.\nWe compare SkyScript-100M with the existing dataset in detail and demonstrate\nsome deeper insights that can be achieved based on SkyScript-100M. Based on\nSkyScript-100M, researchers can achieve several deeper and more far-reaching\nscript optimization goals, which may drive a paradigm shift in the entire field\nof text-to-video and significantly advance the field of short drama video\ngeneration. The data and code are available at\nhttps://github.com/vaew/SkyScript-100M.", "published": "2024-08-18 02:27:25", "link": "http://arxiv.org/abs/2408.09333v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Speakers and Addressees of Quotations in Novels with Prompt\n  Learning", "abstract": "Quotations in literary works, especially novels, are important to create\ncharacters, reflect character relationships, and drive plot development.\nCurrent research on quotation extraction in novels primarily focuses on\nquotation attribution, i.e., identifying the speaker of the quotation. However,\nthe addressee of the quotation is also important to construct the relationship\nbetween the speaker and the addressee. To tackle the problem of dataset\nscarcity, we annotate the first Chinese quotation corpus with elements\nincluding speaker, addressee, speaking mode and linguistic cue. We propose\nprompt learning-based methods for speaker and addressee identification based on\nfine-tuned pre-trained models. Experiments on both Chinese and English datasets\nshow the effectiveness of the proposed methods, which outperform methods based\non zero-shot and few-shot large language models.", "published": "2024-08-18 12:19:18", "link": "http://arxiv.org/abs/2408.09452v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Activated Parameter Locating via Causal Intervention for Model Merging", "abstract": "Model merging combines multiple homologous models into one model, achieving\nconvincing generalization without the necessity of additional training. A key\nchallenge in this problem is resolving parameter redundancies and conflicts\nacross multiple models. Existing models have demonstrated that dropping a\nportion of delta parameters can alleviate conflicts while maintaining\nperformance. However, these methods often drop parameters either randomly or\nbased on magnitude, overlooking task-specific information embedded in\nfine-tuned models. In this paper, we propose an Activated Parameter Locating\n(APL) method that utilizes causal intervention to estimate parameter\nimportance, enabling more precise parameter drops and better conflict\nmitigation. Moreover, to reduce the computational complexity associated with a\nlarge number of parameter partitions, we also introduce a theoretically\nsupported gradient approximation strategy for APL. Experiments on model merging\nwithin both in-domain and out-of-domain settings, along with associated\nanalyses, showcase the effectiveness of APL.", "published": "2024-08-18 14:00:00", "link": "http://arxiv.org/abs/2408.09485v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "No Such Thing as a General Learner: Language models and their dual\n  optimization", "abstract": "What role can the otherwise successful Large Language Models (LLMs) play in\nthe understanding of human cognition, and in particular in terms of informing\nlanguage acquisition debates? To contribute to this question, we first argue\nthat neither humans nor LLMs are general learners, in a variety of senses. We\nmake a novel case for how in particular LLMs follow a dual-optimization\nprocess: they are optimized during their training (which is typically compared\nto language acquisition), and modern LLMs have also been selected, through a\nprocess akin to natural selection in a species. From this perspective, we argue\nthat the performance of LLMs, whether similar or dissimilar to that of humans,\ndoes not weigh easily on important debates about the importance of human\ncognitive biases for language.", "published": "2024-08-18 17:01:42", "link": "http://arxiv.org/abs/2408.09544v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Threshold Filtering Packing for Supervised Fine-Tuning: Training Related\n  Samples within Packs", "abstract": "Packing for Supervised Fine-Tuning (SFT) in autoregressive models involves\nconcatenating data points of varying lengths until reaching the designed\nmaximum length to facilitate GPU processing. However, randomly concatenating\ndata points can lead to cross-contamination of sequences due to the significant\ndifference in their subject matter. The mainstream approaches in SFT ensure\nthat each token in the attention calculation phase only focuses on tokens\nwithin its own short sequence, without providing additional learning signals\nfor the preceding context. To address these challenges, we introduce Threshold\nFiltering Packing (TFP), a method that selects samples with related context\nwhile maintaining sufficient diversity within the same pack. Our experiments\nshow that TFP offers a simple-to-implement and scalable approach that\nsignificantly enhances SFT performance, with observed improvements of up to 7\\%\non GSM8K, 4\\% on HumanEval. Furthermore, results from bias benchmark datasets\nhighlight TFP's promising performance in improving fairness while also boosting\nprediction accuracy by 15\\%.", "published": "2024-08-18 01:59:41", "link": "http://arxiv.org/abs/2408.09327v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Concept Distillation from Strong to Weak Models via\n  Hypotheses-to-Theories Prompting", "abstract": "Hand-crafting high quality prompts to optimize the performance of language\nmodels is a complicated and labor-intensive process. Furthermore, when\nmigrating to newer, smaller, or weaker models (possibly due to latency or cost\ngains), prompts need to be updated to re-optimize the task performance. We\npropose Concept Distillation (CD), an automatic prompt optimization technique\nfor enhancing weaker models on complex tasks. CD involves: (1) collecting\nmistakes made by weak models with a base prompt (initialization), (2) using a\nstrong model to generate reasons for these mistakes and create rules/concepts\nfor weak models (induction), and (3) filtering these rules based on validation\nset performance and integrating them into the base prompt\n(deduction/verification). We evaluated CD on NL2Code and mathematical reasoning\ntasks, observing significant performance boosts for small and weaker language\nmodels. Notably, Mistral-7B's accuracy on Multi-Arith increased by 20%, and\nPhi-3-mini-3.8B's accuracy on HumanEval rose by 34%. Compared to other\nautomated methods, CD offers an effective, cost-efficient strategy for\nimproving weak models' performance on complex tasks and enables seamless\nworkload migration across different language models without compromising\nperformance.", "published": "2024-08-18 05:37:48", "link": "http://arxiv.org/abs/2408.09365v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Reward Difference Optimization For Sample Reweighting In Offline RLHF", "abstract": "With the rapid advances in Large Language Models (LLMs), aligning LLMs with\nhuman preferences become increasingly important. Although Reinforcement\nLearning with Human Feedback (RLHF) proves effective, it is complicated and\nhighly resource-intensive. As such, offline RLHF has been introduced as an\nalternative solution, which directly optimizes LLMs with ranking losses on a\nfixed preference dataset. Current offline RLHF only captures the \"ordinal\nrelationship\" between responses, overlooking the crucial aspect of how much one\nis preferred over the others. To address this issue, we propose a simple yet\neffective solution called Reward Difference Optimization, shorted as RDO.\nSpecifically, we introduce reward difference coefficients to reweigh sample\npairs in offline RLHF. We then develop a difference model which captures rich\ninteractions between a pair of responses for predicting these difference\ncoefficients. Experiments with 7B LLMs on the HH and TL;DR datasets\nsubstantiate the effectiveness of our method in both automatic metrics and\nhuman evaluation, thereby highlighting its potential for aligning LLMs with\nhuman intent and values", "published": "2024-08-18 07:04:16", "link": "http://arxiv.org/abs/2408.09385v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparison between the Structures of Word Co-occurrence and Word\n  Similarity Networks for Ill-formed and Well-formed Texts in Taiwan Mandarin", "abstract": "The study of word co-occurrence networks has attracted the attention of\nresearchers due to their potential significance as well as applications.\nUnderstanding the structure of word co-occurrence networks is therefore\nimportant to fully realize their significance and usages. In past studies, word\nco-occurrence networks built on well-formed texts have been found to possess\ncertain characteristics, including being small-world, following a two-regime\npower law distribution, and being generally disassortative. On the flip side,\npast studies have found that word co-occurrence networks built from ill-formed\ntexts such as microblog posts may behave differently from those built from\nwell-formed documents. While both kinds of word co-occurrence networks are\nsmall-world and disassortative, word co-occurrence networks built from\nill-formed texts are scale-free and follow the power law distribution instead\nof the two-regime power law distribution. However, since past studies on the\nbehavior of word co-occurrence networks built from ill-formed texts only\ninvestigated English, the universality of such characteristics remains to be\nseen among different languages. In addition, it is yet to be investigated\nwhether there could be possible similitude/differences between word\nco-occurrence networks and other potentially comparable networks. This study\ntherefore investigates and compares the structure of word co-occurrence\nnetworks and word similarity networks based on Taiwan Mandarin ill-formed\ninternet forum posts and compare them with those built with well-formed\njudicial judgments, and seeks to find out whether the three aforementioned\nproperties (scale-free, small-world, and disassortative) for ill-formed and\nwell-formed texts are universal among different languages and between word\nco-occurrence and word similarity networks.", "published": "2024-08-18 08:30:16", "link": "http://arxiv.org/abs/2408.09404v1", "categories": ["cs.CL", "cs.AI", "H.3.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "Challenges and Responses in the Practice of Large Language Models", "abstract": "This paper carefully summarizes extensive and profound questions from all\nwalks of life, focusing on the current high-profile AI field, covering multiple\ndimensions such as industry trends, academic research, technological innovation\nand business applications. This paper meticulously curates questions that are\nboth thought-provoking and practically relevant, providing nuanced and\ninsightful answers to each. To facilitate readers' understanding and reference,\nthis paper specifically classifies and organizes these questions systematically\nand meticulously from the five core dimensions of computing power\ninfrastructure, software architecture, data resources, application scenarios,\nand brain science. This work aims to provide readers with a comprehensive,\nin-depth and cutting-edge AI knowledge framework to help people from all walks\nof life grasp the pulse of AI development, stimulate innovative thinking, and\npromote industrial progress.", "published": "2024-08-18 09:15:11", "link": "http://arxiv.org/abs/2408.09416v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Distinguish Confusion in Legal Judgment Prediction via Revised Relation\n  Knowledge", "abstract": "Legal Judgment Prediction (LJP) aims to automatically predict a law case's\njudgment results based on the text description of its facts. In practice, the\nconfusing law articles (or charges) problem frequently occurs, reflecting that\nthe law cases applicable to similar articles (or charges) tend to be misjudged.\nAlthough some recent works based on prior knowledge solve this issue well, they\nignore that confusion also occurs between law articles with a high posterior\nsemantic similarity due to the data imbalance problem instead of only between\nthe prior highly similar ones, which is this work's further finding. This paper\nproposes an end-to-end model named \\textit{D-LADAN} to solve the above\nchallenges. On the one hand, D-LADAN constructs a graph among law articles\nbased on their text definition and proposes a graph distillation operation\n(GDO) to distinguish the ones with a high prior semantic similarity. On the\nother hand, D-LADAN presents a novel momentum-updated memory mechanism to\ndynamically sense the posterior similarity between law articles (or charges)\nand a weighted GDO to adaptively capture the distinctions for revising the\ninductive bias caused by the data imbalance problem. We perform extensive\nexperiments to demonstrate that D-LADAN significantly outperforms\nstate-of-the-art methods in accuracy and robustness.", "published": "2024-08-18 09:44:59", "link": "http://arxiv.org/abs/2408.09422v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FASST: Fast LLM-based Simultaneous Speech Translation", "abstract": "Simultaneous speech translation (SST) takes streaming speech input and\ngenerates text translation on the fly. Existing methods either have high\nlatency due to recomputation of input representations, or fall behind of\noffline ST in translation quality. In this paper, we propose FASST, a fast\nlarge language model based method for streaming speech translation. We propose\nblockwise-causal speech encoding and consistency mask, so that streaming speech\ninput can be encoded incrementally without recomputation. Furthermore, we\ndevelop a two-stage training strategy to optimize FASST for simultaneous\ninference. We evaluate FASST and multiple strong prior models on MuST-C\ndataset. Experiment results show that FASST achieves the best quality-latency\ntrade-off. It outperforms the previous best model by an average of 1.5 BLEU\nunder the same latency for English to Spanish translation.", "published": "2024-08-18 10:12:39", "link": "http://arxiv.org/abs/2408.09430v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HySem: A context length optimized LLM pipeline for unstructured tabular\n  extraction", "abstract": "Regulatory compliance reporting in the pharmaceutical industry relies on\ndetailed tables, but these are often under-utilized beyond compliance due to\ntheir unstructured format and arbitrary content. Extracting and semantically\nrepresenting tabular data is challenging due to diverse table presentations.\nLarge Language Models (LLMs) demonstrate substantial potential for semantic\nrepresentation, yet they encounter challenges related to accuracy and context\nsize limitations, which are crucial considerations for the industry\napplications. We introduce HySem, a pipeline that employs a novel context\nlength optimization technique to generate accurate semantic JSON\nrepresentations from HTML tables. This approach utilizes a custom fine-tuned\nmodel specifically designed for cost- and privacy-sensitive small and medium\npharmaceutical enterprises. Running on commodity hardware and leveraging\nopen-source models, HySem surpasses its peer open-source models in accuracy and\nprovides competitive performance when benchmarked against OpenAI GPT-4o and\neffectively addresses context length limitations, which is a crucial factor for\nsupporting larger tables.", "published": "2024-08-18 10:40:37", "link": "http://arxiv.org/abs/2408.09434v2", "categories": ["cs.CL", "cs.AI", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Hindi-BEIR : A Large Scale Retrieval Benchmark in Hindi", "abstract": "Given the large number of Hindi speakers worldwide, there is a pressing need\nfor robust and efficient information retrieval systems for Hindi. Despite\nongoing research, there is a lack of comprehensive benchmark for evaluating\nretrieval models in Hindi. To address this gap, we introduce the Hindi version\nof the BEIR benchmark, which includes a subset of English BEIR datasets\ntranslated to Hindi, existing Hindi retrieval datasets, and synthetically\ncreated datasets for retrieval. The benchmark is comprised of $15$ datasets\nspanning across $8$ distinct tasks. We evaluate state-of-the-art multilingual\nretrieval models on this benchmark to identify task and domain-specific\nchallenges and their impact on retrieval performance. By releasing this\nbenchmark and a set of relevant baselines, we enable researchers to understand\nthe limitations and capabilities of current Hindi retrieval models, promoting\nadvancements in this critical area. The datasets from Hindi-BEIR are publicly\navailable.", "published": "2024-08-18 10:55:04", "link": "http://arxiv.org/abs/2408.09437v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "WPN: An Unlearning Method Based on N-pair Contrastive Learning in\n  Language Models", "abstract": "Generative language models (LMs) offer numerous advantages but may produce\ninappropriate or harmful outputs due to the harmful knowledge acquired during\npre-training. This knowledge often manifests as undesirable correspondences,\nsuch as \"harmful prompts\" leading to \"harmful outputs,\" which our research aims\nto mitigate through unlearning techniques.However, existing unlearning methods\nbased on gradient ascent can significantly impair the performance of LMs. To\naddress this issue, we propose a novel approach called Weighted Positional\nN-pair (WPN) Learning, which leverages position-weighted mean pooling within an\nn-pair contrastive learning framework. WPN is designed to modify the output\ndistribution of LMs by eliminating specific harmful outputs (e.g., replacing\ntoxic responses with neutral ones), thereby transforming the model's behavior\nfrom \"harmful prompt-harmful output\" to \"harmful prompt-harmless\nresponse\".Experiments on OPT and GPT-NEO LMs show that WPN effectively reduces\nthe proportion of harmful responses, achieving a harmless rate of up to 95.8\\%\nwhile maintaining stable performance on nine common benchmarks (with less than\n2\\% degradation on average). Moreover, we provide empirical evidence to\ndemonstrate WPN's ability to weaken the harmful correspondences in terms of\ngeneralizability and robustness, as evaluated on out-of-distribution test sets\nand under adversarial attacks.", "published": "2024-08-18 12:37:03", "link": "http://arxiv.org/abs/2408.09459v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal\n  Conversational Aspect-based Sentiment Analysis", "abstract": "While existing Aspect-based Sentiment Analysis (ABSA) has received extensive\neffort and advancement, there are still gaps in defining a more holistic\nresearch target seamlessly integrating multimodality, conversation context,\nfine-granularity, and also covering the changing sentiment dynamics as well as\ncognitive causal rationales. This paper bridges the gaps by introducing a\nmultimodal conversational ABSA, where two novel subtasks are proposed: 1)\nPanoptic Sentiment Sextuple Extraction, panoramically recognizing holder,\ntarget, aspect, opinion, sentiment, rationale from multi-turn multi-party\nmultimodal dialogue. 2) Sentiment Flipping Analysis, detecting the dynamic\nsentiment transformation throughout the conversation with the causal reasons.\nTo benchmark the tasks, we construct PanoSent, a dataset annotated both\nmanually and automatically, featuring high quality, large scale, multimodality,\nmultilingualism, multi-scenarios, and covering both implicit and explicit\nsentiment elements. To effectively address the tasks, we devise a novel\nChain-of-Sentiment reasoning framework, together with a novel multimodal large\nlanguage model (namely Sentica) and a paraphrase-based verification mechanism.\nExtensive evaluations demonstrate the superiority of our methods over strong\nbaselines, validating the efficacy of all our proposed methods. The work is\nexpected to open up a new era for the ABSA community, and thus all our codes\nand data are open at https://PanoSent.github.io/", "published": "2024-08-18 13:51:01", "link": "http://arxiv.org/abs/2408.09481v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "REFINE-LM: Mitigating Language Model Stereotypes via Reinforcement\n  Learning", "abstract": "With the introduction of (large) language models, there has been significant\nconcern about the unintended bias such models may inherit from their training\ndata. A number of studies have shown that such models propagate gender\nstereotypes, as well as geographical and racial bias, among other biases. While\nexisting works tackle this issue by preprocessing data and debiasing\nembeddings, the proposed methods require a lot of computational resources and\nannotation effort while being limited to certain types of biases. To address\nthese issues, we introduce REFINE-LM, a debiasing method that uses\nreinforcement learning to handle different types of biases without any\nfine-tuning. By training a simple model on top of the word probability\ndistribution of a LM, our bias agnostic reinforcement learning method enables\nmodel debiasing without human annotations or significant computational\nresources. Experiments conducted on a wide range of models, including several\nLMs, show that our method (i) significantly reduces stereotypical biases while\npreserving LMs performance; (ii) is applicable to different types of biases,\ngeneralizing across contexts such as gender, ethnicity, religion, and\nnationality-based biases; and (iii) it is not expensive to train.", "published": "2024-08-18 14:08:31", "link": "http://arxiv.org/abs/2408.09489v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Revisiting the Graph Reasoning Ability of Large Language Models: Case\n  Studies in Translation, Connectivity and Shortest Path", "abstract": "Large Language Models (LLMs) have achieved great success in various reasoning\ntasks. In this work, we focus on the graph reasoning ability of LLMs. Although\ntheoretical studies proved that LLMs are capable of handling graph reasoning\ntasks, empirical evaluations reveal numerous failures. To deepen our\nunderstanding on this discrepancy, we revisit the ability of LLMs on three\nfundamental graph tasks: graph description translation, graph connectivity, and\nthe shortest-path problem. Our findings suggest that LLMs can fail to\nunderstand graph structures through text descriptions and exhibit varying\nperformance for all these three fundamental tasks. Meanwhile, we perform a\nreal-world investigation on knowledge graphs and make consistent observations\nwith our findings. The codes and datasets are available.", "published": "2024-08-18 16:26:39", "link": "http://arxiv.org/abs/2408.09529v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using ChatGPT to Score Essays and Short-Form Constructed Responses", "abstract": "This study aimed to determine if ChatGPT's large language models could match\nthe scoring accuracy of human and machine scores from the ASAP competition. The\ninvestigation focused on various prediction models, including linear\nregression, random forest, gradient boost, and boost. ChatGPT's performance was\nevaluated against human raters using quadratic weighted kappa (QWK) metrics.\nResults indicated that while ChatGPT's gradient boost model achieved QWKs close\nto human raters for some data sets, its overall performance was inconsistent\nand often lower than human scores. The study highlighted the need for further\nrefinement, particularly in handling biases and ensuring scoring fairness.\nDespite these challenges, ChatGPT demonstrated potential for scoring\nefficiency, especially with domain-specific fine-tuning. The study concludes\nthat ChatGPT can complement human scoring but requires additional development\nto be reliable for high-stakes assessments. Future research should improve\nmodel accuracy, address ethical considerations, and explore hybrid models\ncombining ChatGPT with empirical methods.", "published": "2024-08-18 16:51:28", "link": "http://arxiv.org/abs/2408.09540v1", "categories": ["cs.CL", "cs.AI", "I.7; I.3"], "primary_category": "cs.CL"}
{"title": "Grammatical Error Feedback: An Implicit Evaluation Approach", "abstract": "Grammatical feedback is crucial for consolidating second language (L2)\nlearning. Most research in computer-assisted language learning has focused on\nfeedback through grammatical error correction (GEC) systems, rather than\nexamining more holistic feedback that may be more useful for learners. This\nholistic feedback will be referred to as grammatical error feedback (GEF). In\nthis paper, we present a novel implicit evaluation approach to GEF that\neliminates the need for manual feedback annotations. Our method adopts a\ngrammatical lineup approach where the task is to pair feedback and essay\nrepresentations from a set of possible alternatives. This matching process can\nbe performed by appropriately prompting a large language model (LLM). An\nimportant aspect of this process, explored here, is the form of the lineup,\ni.e., the selection of foils. This paper exploits this framework to examine the\nquality and need for GEC to generate feedback, as well as the system used to\ngenerate feedback, using essays from the Cambridge Learner Corpus.", "published": "2024-08-18 18:31:55", "link": "http://arxiv.org/abs/2408.09565v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PhysBERT: A Text Embedding Model for Physics Scientific Literature", "abstract": "The specialized language and complex concepts in physics pose significant\nchallenges for information extraction through Natural Language Processing\n(NLP). Central to effective NLP applications is the text embedding model, which\nconverts text into dense vector representations for efficient information\nretrieval and semantic analysis. In this work, we introduce PhysBERT, the first\nphysics-specific text embedding model. Pre-trained on a curated corpus of 1.2\nmillion arXiv physics papers and fine-tuned with supervised data, PhysBERT\noutperforms leading general-purpose models on physics-specific tasks including\nthe effectiveness in fine-tuning for specific physics subdomains.", "published": "2024-08-18 19:18:12", "link": "http://arxiv.org/abs/2408.09574v1", "categories": ["physics.comp-ph", "cs.CL"], "primary_category": "physics.comp-ph"}
{"title": "Characterizing and Evaluating the Reliability of LLMs against Jailbreak\n  Attacks", "abstract": "Large Language Models (LLMs) have increasingly become pivotal in content\ngeneration with notable societal impact. These models hold the potential to\ngenerate content that could be deemed harmful.Efforts to mitigate this risk\ninclude implementing safeguards to ensure LLMs adhere to social ethics.However,\ndespite such measures, the phenomenon of \"jailbreaking\" -- where carefully\ncrafted prompts elicit harmful responses from models -- persists as a\nsignificant challenge. Recognizing the continuous threat posed by jailbreaking\ntactics and their repercussions for the trustworthy use of LLMs, a rigorous\nassessment of the models' robustness against such attacks is essential. This\nstudy introduces an comprehensive evaluation framework and conducts an\nlarge-scale empirical experiment to address this need. We concentrate on 10\ncutting-edge jailbreak strategies across three categories, 1525 questions from\n61 specific harmful categories, and 13 popular LLMs. We adopt multi-dimensional\nmetrics such as Attack Success Rate (ASR), Toxicity Score, Fluency, Token\nLength, and Grammatical Errors to thoroughly assess the LLMs' outputs under\njailbreak. By normalizing and aggregating these metrics, we present a detailed\nreliability score for different LLMs, coupled with strategic recommendations to\nreduce their susceptibility to such vulnerabilities. Additionally, we explore\nthe relationships among the models, attack strategies, and types of harmful\ncontent, as well as the correlations between the evaluation metrics, which\nproves the validity of our multifaceted evaluation framework. Our extensive\nexperimental results demonstrate a lack of resilience among all tested LLMs\nagainst certain strategies, and highlight the need to concentrate on the\nreliability facets of LLMs. We believe our study can provide valuable insights\ninto enhancing the security evaluation of LLMs against jailbreak within the\ndomain.", "published": "2024-08-18 01:58:03", "link": "http://arxiv.org/abs/2408.09326v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Improving and Assessing the Fidelity of Large Language Models Alignment\n  to Online Communities", "abstract": "Large language models (LLMs) have shown promise in representing individuals\nand communities, offering new ways to study complex social dynamics. However,\neffectively aligning LLMs with specific human groups and systematically\nassessing the fidelity of the alignment remains a challenge. This paper\npresents a robust framework for aligning LLMs with online communities via\ninstruction-tuning and comprehensively evaluating alignment across various\naspects of language, including authenticity, emotional tone, toxicity, and\nharm. We demonstrate the utility of our approach by applying it to online\ncommunities centered on dieting and body image. We administer an eating\ndisorder psychometric test to the aligned LLMs to reveal unhealthy beliefs and\nsuccessfully differentiate communities with varying levels of eating disorder\nrisk. Our results highlight the potential of LLMs in automated moderation and\nbroader applications in public health and social science research.", "published": "2024-08-18 05:41:36", "link": "http://arxiv.org/abs/2408.09366v2", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Game Development as Human-LLM Interaction", "abstract": "Game development is a highly specialized task that relies on a complex game\nengine powered by complex programming languages, preventing many gaming\nenthusiasts from handling it. This paper introduces the Chat Game Engine\n(ChatGE) powered by LLM, which allows everyone to develop a custom game using\nnatural language through Human-LLM interaction. To enable an LLM to function as\na ChatGE, we instruct it to perform the following processes in each turn: (1)\n$P_{script}$: configure the game script segment based on the user's input; (2)\n$P_{code}$: generate the corresponding code snippet based on the game script\nsegment; (3) $P_{utter}$: interact with the user, including guidance and\nfeedback. We propose a data synthesis pipeline based on LLM to generate game\nscript-code pairs and interactions from a few manually crafted seed data. We\npropose a three-stage progressive training strategy to transfer the\ndialogue-based LLM to our ChatGE smoothly. We construct a ChatGE for poker\ngames as a case study and comprehensively evaluate it from two perspectives:\ninteraction quality and code correctness.", "published": "2024-08-18 07:06:57", "link": "http://arxiv.org/abs/2408.09386v2", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Enhancing Startup Success Predictions in Venture Capital: A GraphRAG\n  Augmented Multivariate Time Series Method", "abstract": "In the Venture Capital (VC) industry, predicting the success of startups is\nchallenging due to limited financial data and the need for subjective revenue\nforecasts. Previous methods based on time series analysis often fall short as\nthey fail to incorporate crucial inter-company relationships such as\ncompetition and collaboration. To fill the gap, this paper aims to introduce a\nnovel approach using GraphRAG augmented time series model. With GraphRAG, time\nseries predictive methods are enhanced by integrating these vital relationships\ninto the analysis framework, allowing for a more dynamic understanding of the\nstartup ecosystem in venture capital. Our experimental results demonstrate that\nour model significantly outperforms previous models in startup success\npredictions.", "published": "2024-08-18 09:31:13", "link": "http://arxiv.org/abs/2408.09420v5", "categories": ["q-fin.CP", "cs.CL", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Reefknot: A Comprehensive Benchmark for Relation Hallucination\n  Evaluation, Analysis and Mitigation in Multimodal Large Language Models", "abstract": "Hallucination issues continue to affect multimodal large language models\n(MLLMs), with existing research mainly addressing object-level or\nattribute-level hallucinations, neglecting the more complex relation\nhallucinations that require advanced reasoning. Current benchmarks for relation\nhallucinations lack detailed evaluation and effective mitigation, and their\ndatasets often suffer from biases due to systematic annotation processes. To\naddress these challenges, we introduce Reefknot, a comprehensive benchmark\ntargeting relation hallucinations, comprising over 20,000 real-world samples.\nWe provide a systematic definition of relation hallucinations, integrating\nperceptive and cognitive perspectives, and construct a relation-based corpus\nusing the Visual Genome scene graph dataset. Our comparative evaluation reveals\nsignificant limitations in current MLLMs' ability to handle relation\nhallucinations. Additionally, we propose a novel confidence-based mitigation\nstrategy, which reduces the hallucination rate by an average of 9.75% across\nthree datasets, including Reefknot. Our work offers valuable insights for\nachieving trustworthy multimodal intelligence.", "published": "2024-08-18 10:07:02", "link": "http://arxiv.org/abs/2408.09429v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Image-Based Geolocation Using Large Vision-Language Models", "abstract": "Geolocation is now a vital aspect of modern life, offering numerous benefits\nbut also presenting serious privacy concerns. The advent of large\nvision-language models (LVLMs) with advanced image-processing capabilities\nintroduces new risks, as these models can inadvertently reveal sensitive\ngeolocation information. This paper presents the first in-depth study analyzing\nthe challenges posed by traditional deep learning and LVLM-based geolocation\nmethods. Our findings reveal that LVLMs can accurately determine geolocations\nfrom images, even without explicit geographic training.\n  To address these challenges, we introduce \\tool{}, an innovative framework\nthat significantly enhances image-based geolocation accuracy. \\tool{} employs a\nsystematic chain-of-thought (CoT) approach, mimicking human geoguessing\nstrategies by carefully analyzing visual and contextual cues such as vehicle\ntypes, architectural styles, natural landscapes, and cultural elements.\nExtensive testing on a dataset of 50,000 ground-truth data points shows that\n\\tool{} outperforms both traditional models and human benchmarks in accuracy.\nIt achieves an impressive average score of 4550.5 in the GeoGuessr game, with\nan 85.37\\% win rate, and delivers highly precise geolocation predictions, with\nthe closest distances as accurate as 0.3 km. Furthermore, our study highlights\nissues related to dataset integrity, leading to the creation of a more robust\ndataset and a refined framework that leverages LVLMs' cognitive capabilities to\nimprove geolocation precision. These findings underscore \\tool{}'s superior\nability to interpret complex visual data, the urgent need to address emerging\nsecurity vulnerabilities posed by LVLMs, and the importance of responsible AI\ndevelopment to ensure user privacy protection.", "published": "2024-08-18 13:39:43", "link": "http://arxiv.org/abs/2408.09474v1", "categories": ["cs.CR", "cs.CL", "cs.CV"], "primary_category": "cs.CR"}
{"title": "Out-of-distribution generalization via composition: a lens through\n  induction heads in Transformers", "abstract": "Large language models (LLMs) such as GPT-4 sometimes appear to be creative,\nsolving novel tasks often with a few demonstrations in the prompt. These tasks\nrequire the models to generalize on distributions different from those from\ntraining data -- which is known as out-of-distribution (OOD) generalization.\nDespite the tremendous success of LLMs, how they approach OOD generalization\nremains an open and underexplored question. We examine OOD generalization in\nsettings where instances are generated according to hidden rules, including\nin-context learning with symbolic reasoning. Models are required to infer the\nhidden rules behind input prompts without any fine-tuning.\n  We empirically examined the training dynamics of Transformers on a synthetic\nexample and conducted extensive experiments on a variety of pretrained LLMs,\nfocusing on a type of components known as induction heads. We found that OOD\ngeneralization and composition are tied together -- models can learn rules by\ncomposing two self-attention layers, thereby achieving OOD generalization.\nFurthermore, a shared latent subspace in the embedding (or feature) space acts\nas a bridge for composition by aligning early layers and later layers, which we\nrefer to as the common bridge representation hypothesis.", "published": "2024-08-18 14:52:25", "link": "http://arxiv.org/abs/2408.09503v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon\n  Agent Tasks with Large Language Model", "abstract": "Large Language Model (LLM)-based agents exhibit significant potential across\nvarious domains, operating as interactive systems that process environmental\nobservations to generate executable actions for target tasks. The effectiveness\nof these agents is significantly influenced by their memory mechanism, which\nrecords historical experiences as sequences of action-observation pairs. We\ncategorize memory into two types: cross-trial memory, accumulated across\nmultiple attempts, and in-trial memory (working memory), accumulated within a\nsingle attempt. While considerable research has optimized performance through\ncross-trial memory, the enhancement of agent performance through improved\nworking memory utilization remains underexplored. Instead, existing approaches\noften involve directly inputting entire historical action-observation pairs\ninto LLMs, leading to redundancy in long-horizon tasks. Inspired by human\nproblem-solving strategies, this paper introduces HiAgent, a framework that\nleverages subgoals as memory chunks to manage the working memory of LLM-based\nagents hierarchically. Specifically, HiAgent prompts LLMs to formulate subgoals\nbefore generating executable actions and enables LLMs to decide proactively to\nreplace previous subgoals with summarized observations, retaining only the\naction-observation pairs relevant to the current subgoal. Experimental results\nacross five long-horizon tasks demonstrate that HiAgent achieves a twofold\nincrease in success rate and reduces the average number of steps required by\n3.8. Additionally, our analysis shows that HiAgent consistently improves\nperformance across various steps, highlighting its robustness and\ngeneralizability. Project Page: https://github.com/HiAgent2024/HiAgent .", "published": "2024-08-18 17:59:49", "link": "http://arxiv.org/abs/2408.09559v1", "categories": ["cs.CL", "cs.AI", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Crossing New Frontiers: Knowledge-Augmented Large Language Model\n  Prompting for Zero-Shot Text-Based De Novo Molecule Design", "abstract": "Molecule design is a multifaceted approach that leverages computational\nmethods and experiments to optimize molecular properties, fast-tracking new\ndrug discoveries, innovative material development, and more efficient chemical\nprocesses. Recently, text-based molecule design has emerged, inspired by\nnext-generation AI tasks analogous to foundational vision-language models. Our\nstudy explores the use of knowledge-augmented prompting of large language\nmodels (LLMs) for the zero-shot text-conditional de novo molecular generation\ntask. Our approach uses task-specific instructions and a few demonstrations to\naddress distributional shift challenges when constructing augmented prompts for\nquerying LLMs to generate molecules consistent with technical descriptions. Our\nframework proves effective, outperforming state-of-the-art (SOTA) baseline\nmodels on benchmark datasets.", "published": "2024-08-18 11:37:19", "link": "http://arxiv.org/abs/2408.11866v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.BM"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Generation Meets Data-Driven Tabula Rasa Approach\n  for Temporal Knowledge Graph Forecasting", "abstract": "Pre-trained large language models (PLLMs) like OpenAI ChatGPT and Google\nGemini face challenges such as inaccurate factual recall, hallucinations,\nbiases, and future data leakage for temporal Knowledge Graph (tKG) forecasting.\nTo address these issues, we introduce sLA-tKGF (small-scale language assistant\nfor tKG forecasting), which utilizes Retrieval-Augmented Generation (RAG)\naided, custom-trained small-scale language models through a tabula rasa\napproach from scratch for effective tKG forecasting. Our framework constructs\nknowledge-infused prompts with relevant historical data from tKGs, web search\nresults, and PLLMs-generated textual descriptions to understand historical\nentity relationships prior to the target time. It leverages these external\nknowledge-infused prompts for deeper understanding and reasoning of\ncontext-specific semantic and temporal information to zero-shot prompt\nsmall-scale language models for more accurate predictions of future events\nwithin tKGs. It reduces hallucinations and mitigates distributional shift\nchallenges through comprehending changing trends over time. As a result, it\nenables more accurate and contextually grounded forecasts of future events\nwhile minimizing computational demands. Rigorous empirical studies demonstrate\nour framework robustness, scalability, and state-of-the-art (SOTA) performance\non benchmark datasets with interpretable and trustworthy tKG forecasting.", "published": "2024-08-18 11:52:24", "link": "http://arxiv.org/abs/2408.13273v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Agentic Retrieval-Augmented Generation for Time Series Analysis", "abstract": "Time series modeling is crucial for many applications, however, it faces\nchallenges such as complex spatio-temporal dependencies and distribution shifts\nin learning from historical context to predict task-specific outcomes. To\naddress these challenges, we propose a novel approach using an agentic\nRetrieval-Augmented Generation (RAG) framework for time series analysis. The\nframework leverages a hierarchical, multi-agent architecture where the master\nagent orchestrates specialized sub-agents and delegates the end-user request to\nthe relevant sub-agent. The sub-agents utilize smaller, pre-trained language\nmodels (SLMs) customized for specific time series tasks through fine-tuning\nusing instruction tuning and direct preference optimization, and retrieve\nrelevant prompts from a shared repository of prompt pools containing distilled\nknowledge about historical patterns and trends to improve predictions on new\ndata. Our proposed modular, multi-agent RAG approach offers flexibility and\nachieves state-of-the-art performance across major time series tasks by\ntackling complex challenges more effectively than task-specific customized\nmethods across benchmark datasets.", "published": "2024-08-18 11:47:55", "link": "http://arxiv.org/abs/2408.14484v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Transcription Prompt-based Efficient Audio Large Language Model for\n  Robust Speech Recognition", "abstract": "Audio-LLM introduces audio modality into a large language model (LLM) to\nenable a powerful LLM to recognize, understand, and generate audio. However,\nduring speech recognition in noisy environments, we observed the presence of\nillusions and repetition issues in audio-LLM, leading to substitution and\ninsertion errors. This paper proposes a transcription prompt-based audio-LLM by\nintroducing an ASR expert as a transcription tokenizer and a hybrid\nAutoregressive (AR) Non-autoregressive (NAR) decoding approach to solve the\nabove problems. Experiments on 10k-hour WenetSpeech Mandarin corpus show that\nour approach decreases 12.2% and 9.6% CER relatively on Test_Net and\nTest_Meeting evaluation sets compared with baseline. Notably, we reduce the\ndecoding repetition rate on the evaluation set to zero, showing that the\ndecoding repetition problem has been solved fundamentally.", "published": "2024-08-18 14:10:35", "link": "http://arxiv.org/abs/2408.09491v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Auptimize: Optimal Placement of Spatial Audio Cues for Extended Reality", "abstract": "Spatial audio in Extended Reality (XR) provides users with better awareness\nof where virtual elements are placed, and efficiently guides them to events\nsuch as notifications, system alerts from different windows, or approaching\navatars. Humans, however, are inaccurate in localizing sound cues, especially\nwith multiple sources due to limitations in human auditory perception such as\nangular discrimination error and front-back confusion. This decreases the\nefficiency of XR interfaces because users misidentify from which XR element a\nsound is coming. To address this, we propose Auptimize, a novel computational\napproach for placing XR sound sources, which mitigates such localization errors\nby utilizing the ventriloquist effect. Auptimize disentangles the sound source\nlocations from the visual elements and relocates the sound sources to optimal\npositions for unambiguous identification of sound cues, avoiding errors due to\ninter-source proximity and front-back confusion. Our evaluation shows that\nAuptimize decreases spatial audio-based source identification errors compared\nto playing sound cues at the paired visual-sound locations. We demonstrate the\napplicability of Auptimize for diverse spatial audio-based interactive XR\nscenarios.", "published": "2024-08-18 01:14:05", "link": "http://arxiv.org/abs/2408.09320v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.1; H.5.2; H.5.5"], "primary_category": "cs.HC"}
{"title": "Meta-Learning Empowered Meta-Face: Personalized Speaking Style\n  Adaptation for Audio-Driven 3D Talking Face Animation", "abstract": "Audio-driven 3D face animation is increasingly vital in live streaming and\naugmented reality applications. While remarkable progress has been observed,\nmost existing approaches are designed for specific individuals with predefined\nspeaking styles, thus neglecting the adaptability to varied speaking styles. To\naddress this limitation, this paper introduces MetaFace, a novel methodology\nmeticulously crafted for speaking style adaptation. Grounded in the novel\nconcept of meta-learning, MetaFace is composed of several key components: the\nRobust Meta Initialization Stage (RMIS) for fundamental speaking style\nadaptation, the Dynamic Relation Mining Neural Process (DRMN) for forging\nconnections between observed and unobserved speaking styles, and the Low-rank\nMatrix Memory Reduction Approach to enhance the efficiency of model\noptimization as well as learning style details. Leveraging these novel designs,\nMetaFace not only significantly outperforms robust existing baselines but also\nestablishes a new state-of-the-art, as substantiated by our experimental\nresults.", "published": "2024-08-18 04:42:43", "link": "http://arxiv.org/abs/2408.09357v1", "categories": ["cs.GR", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
