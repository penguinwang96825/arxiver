{"title": "Modeling human visual search: A combined Bayesian searcher and saliency map approach for eye movement guidance in natural scenes", "abstract": "Finding objects is essential for almost any daily-life visual task. Saliency models have been useful to predict fixation locations in natural images, but are static, i.e., they provide no information about the time-sequence of fixations. Nowadays, one of the biggest challenges in the field is to go beyond saliency maps to predict a sequence of fixations related to a visual task, such as searching for a given target. Bayesian observer models have been proposed for this task, as they represent visual search as an active sampling process. Nevertheless, they were mostly evaluated on artificial images, and how they adapt to natural images remains largely unexplored.\n  Here, we propose a unified Bayesian model for visual search guided by saliency maps as prior information. We validated our model with a visual search experiment in natural scenes recording eye movements. We show that, although state-of-the-art saliency models perform well in predicting the first two fixations in a visual search task, their performance degrades to chance afterward. This suggests that saliency maps alone are good to model bottom-up first impressions, but are not enough to explain the scanpaths when top-down task information is critical. Thus, we propose to use them as priors of Bayesian searchers. This approach leads to a behavior very similar to humans for the whole scanpath, both in the percentage of target found as a function of the fixation rank and the scanpath similarity, reproducing the entire sequence of eye movements.", "published": "2020-09-17 15:38:23", "link": "http://arxiv.org/abs/2009.08373v2", "categories": ["cs.AI", "cs.CV", "q-bio.NC"], "primary_category": "cs.AI"}
{"title": "Urban Traffic Flow Forecast Based on FastGCRNN", "abstract": "Traffic forecasting is an important prerequisite for the application of intelligent transportation systems in urban traffic networks. The existing works adopted RNN and CNN/GCN, among which GCRN is the state of art work, to characterize the temporal and spatial correlation of traffic flows. However, it is hard to apply GCRN to the large scale road networks due to high computational complexity. To address this problem, we propose to abstract the road network into a geometric graph and build a Fast Graph Convolution Recurrent Neural Network (FastGCRNN) to model the spatial-temporal dependencies of traffic flow. Specifically, We use FastGCN unit to efficiently capture the topological relationship between the roads and the surrounding roads in the graph with reducing the computational complexity through importance sampling, combine GRU unit to capture the temporal dependency of traffic flow, and embed the spatiotemporal features into Seq2Seq based on the Encoder-Decoder framework. Experiments on large-scale traffic data sets illustrate that the proposed method can greatly reduce computational complexity and memory consumption while maintaining relatively high accuracy.", "published": "2020-09-17 06:05:05", "link": "http://arxiv.org/abs/2009.08087v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deep Collective Learning: Learning Optimal Inputs and Weights Jointly in Deep Neural Networks", "abstract": "It is well observed that in deep learning and computer vision literature, visual data are always represented in a manually designed coding scheme (eg., RGB images are represented as integers ranging from 0 to 255 for each channel) when they are input to an end-to-end deep neural network (DNN) for any learning task. We boldly question whether the manually designed inputs are good for DNN training for different tasks and study whether the input to a DNN can be optimally learned end-to-end together with learning the weights of the DNN. In this paper, we propose the paradigm of {\\em deep collective learning} which aims to learn the weights of DNNs and the inputs to DNNs simultaneously for given tasks. We note that collective learning has been implicitly but widely used in natural language processing while it has almost never been studied in computer vision. Consequently, we propose the lookup vision networks (Lookup-VNets) as a solution to deep collective learning in computer vision. This is achieved by associating each color in each channel with a vector in lookup tables. As learning inputs in computer vision has almost never been studied in the existing literature, we explore several aspects of this question through varieties of experiments on image classification tasks. Experimental results on four benchmark datasets, i.e., CIFAR-10, CIFAR-100, Tiny ImageNet, and ImageNet (ILSVRC2012) have shown several surprising characteristics of Lookup-VNets and have demonstrated the advantages and promise of Lookup-VNets and deep collective learning.", "published": "2020-09-17 00:33:04", "link": "http://arxiv.org/abs/2009.07988v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "ShapeAssembly: Learning to Generate Programs for 3D Shape Structure Synthesis", "abstract": "Manually authoring 3D shapes is difficult and time consuming; generative models of 3D shapes offer compelling alternatives. Procedural representations are one such possibility: they offer high-quality and editable results but are difficult to author and often produce outputs with limited diversity. On the other extreme are deep generative models: given enough data, they can learn to generate any class of shape but their outputs have artifacts and the representation is not editable. In this paper, we take a step towards achieving the best of both worlds for novel 3D shape synthesis. We propose ShapeAssembly, a domain-specific \"assembly-language\" for 3D shape structures. ShapeAssembly programs construct shapes by declaring cuboid part proxies and attaching them to one another, in a hierarchical and symmetrical fashion. Its functions are parameterized with free variables, so that one program structure is able to capture a family of related shapes. We show how to extract ShapeAssembly programs from existing shape structures in the PartNet dataset. Then we train a deep generative model, a hierarchical sequence VAE, that learns to write novel ShapeAssembly programs. The program captures the subset of variability that is interpretable and editable. The deep model captures correlations across shape collections that are hard to express procedurally. We evaluate our approach by comparing shapes output by our generated programs to those from other recent shape structure synthesis models. We find that our generated shapes are more plausible and physically-valid than those of other methods. Additionally, we assess the latent spaces of these models, and find that ours is better structured and produces smoother interpolations. As an application, we use our generative model and differentiable program interpreter to infer and fit shape programs to unstructured geometry, such as point clouds.", "published": "2020-09-17 02:26:45", "link": "http://arxiv.org/abs/2009.08026v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Novel Parameter Estimation and Radar Detection Approaches for Multiple Point-like Targets: Designs and Comparisons", "abstract": "In this work, we develop and compare two innovative strategies for parameter estimation and radar detection of multiple point-like targets. The first strategy, which appears here for the first time, jointly exploits the maximum likelihood approach and Bayesian learning to estimate targets' parameters including their positions in terms of range bins. The second strategy relies on the intuition that for high signal-to-interference plus-noise ratio values, the energy of data containing target components projected onto the nominal steering direction should be higher than the energy of data affected by interference only. The adaptivity with respect to the interference covariance matrix is also considered exploiting a training data set collected in the proximity of the window under test. Finally, another important innovation aspect concerns the adaptive estimation of the unknown number of targets by means of the model order selection rules.", "published": "2020-09-17 14:24:16", "link": "http://arxiv.org/abs/2009.08329v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
