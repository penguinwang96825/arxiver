{"title": "Human-Centric Research for NLP: Towards a Definition and Guiding\n  Questions", "abstract": "With Human-Centric Research (HCR) we can steer research activities so that\nthe research outcome is beneficial for human stakeholders, such as end users.\nBut what exactly makes research human-centric? We address this question by\nproviding a working definition and define how a research pipeline can be split\ninto different stages in which human-centric components can be added.\nAdditionally, we discuss existing NLP with HCR components and define a series\nof guiding questions, which can serve as starting points for researchers\ninterested in exploring human-centric research approaches. We hope that this\nwork would inspire researchers to refine the proposed definition and to pose\nother questions that might be meaningful for achieving HCR.", "published": "2022-07-10 12:02:27", "link": "http://arxiv.org/abs/2207.04447v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Persuasion Detection: Video Games as an Invaluable Data\n  Source for NLP", "abstract": "Role-playing games (RPGs) have a considerable amount of text in video game\ndialogues. Quite often this text is semi-annotated by the game developers. In\nthis paper, we extract a multilingual dataset of persuasive dialogue from\nseveral RPGs. We show the viability of this data in building a persuasion\ndetection system using a natural language processing (NLP) model called BERT.\nWe believe that video games have a lot of unused potential as a datasource for\na variety of NLP tasks. The code and data described in this paper are available\non Zenodo.", "published": "2022-07-10 12:38:02", "link": "http://arxiv.org/abs/2207.04453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Myers-Briggs personality classification from social media text using\n  pre-trained language models", "abstract": "In Natural Language Processing, the use of pre-trained language models has\nbeen shown to obtain state-of-the-art results in many downstream tasks such as\nsentiment analysis, author identification and others. In this work, we address\nthe use of these methods for personality classification from text. Focusing on\nthe Myers-Briggs (MBTI) personality model, we describe a series of experiments\nin which the well-known Bidirectional Encoder Representations from Transformers\n(BERT) model is fine-tuned to perform MBTI classification. Our main findings\nsuggest that the current approach significantly outperforms well-known text\nclassification models based on bag-of-words and static word embeddings alike\nacross multiple evaluation scenarios, and generally outperforms previous work\nin the field.", "published": "2022-07-10 14:38:09", "link": "http://arxiv.org/abs/2207.04476v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Confused Contrastive Learning for Unsupervised Domain Adaptation", "abstract": "In this work, we study Unsupervised Domain Adaptation (UDA) in a challenging\nself-supervised approach. One of the difficulties is how to learn task\ndiscrimination in the absence of target labels. Unlike previous literature\nwhich directly aligns cross-domain distributions or leverages reverse gradient,\nwe propose Domain Confused Contrastive Learning (DCCL) to bridge the source and\nthe target domains via domain puzzles, and retain discriminative\nrepresentations after adaptation. Technically, DCCL searches for a most\ndomain-challenging direction and exquisitely crafts domain confused\naugmentations as positive pairs, then it contrastively encourages the model to\npull representations towards the other domain, thus learning more stable and\neffective domain invariances. We also investigate whether contrastive learning\nnecessarily helps with UDA when performing other data augmentations. Extensive\nexperiments demonstrate that DCCL significantly outperforms baselines.", "published": "2022-07-10 23:23:38", "link": "http://arxiv.org/abs/2207.04564v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language,\n  Vision, and Action", "abstract": "Goal-conditioned policies for robotic navigation can be trained on large,\nunannotated datasets, providing for good generalization to real-world settings.\nHowever, particularly in vision-based settings where specifying goals requires\nan image, this makes for an unnatural interface. Language provides a more\nconvenient modality for communication with robots, but contemporary methods\ntypically require expensive supervision, in the form of trajectories annotated\nwith language descriptions. We present a system, LM-Nav, for robotic navigation\nthat enjoys the benefits of training on unannotated large datasets of\ntrajectories, while still providing a high-level interface to the user. Instead\nof utilizing a labeled instruction following dataset, we show that such a\nsystem can be constructed entirely out of pre-trained models for navigation\n(ViNG), image-language association (CLIP), and language modeling (GPT-3),\nwithout requiring any fine-tuning or language-annotated robot data. We\ninstantiate LM-Nav on a real-world mobile robot and demonstrate long-horizon\nnavigation through complex, outdoor environments from natural language\ninstructions. For videos of our experiments, code release, and an interactive\nColab notebook that runs in your browser, please check out our project page\nhttps://sites.google.com/view/lmnav", "published": "2022-07-10 10:41:50", "link": "http://arxiv.org/abs/2207.04429v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Scaling up ML-based Black-box Planning with Partial STRIPS Models", "abstract": "A popular approach for sequential decision-making is to perform\nsimulator-based search guided with Machine Learning (ML) methods like policy\nlearning. On the other hand, model-relaxation heuristics can guide the search\neffectively if a full declarative model is available. In this work, we consider\nhow a practitioner can improve ML-based black-box planning on settings where a\ncomplete symbolic model is not available. We show that specifying an incomplete\nSTRIPS model that describes only part of the problem enables the use of\nrelaxation heuristics. Our findings on several planning domains suggest that\nthis is an effective way to improve ML-based black-box planning beyond\ncollecting more data or tuning ML architectures.", "published": "2022-07-10 14:55:16", "link": "http://arxiv.org/abs/2207.04479v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "FairDistillation: Mitigating Stereotyping in Language Models", "abstract": "Large pre-trained language models are successfully being used in a variety of\ntasks, across many languages. With this ever-increasing usage, the risk of\nharmful side effects also rises, for example by reproducing and reinforcing\nstereotypes. However, detecting and mitigating these harms is difficult to do\nin general and becomes computationally expensive when tackling multiple\nlanguages or when considering different biases. To address this, we present\nFairDistillation: a cross-lingual method based on knowledge distillation to\nconstruct smaller language models while controlling for specific biases. We\nfound that our distillation method does not negatively affect the downstream\nperformance on most tasks and successfully mitigates stereotyping and\nrepresentational harms. We demonstrate that FairDistillation can create fairer\nlanguage models at a considerably lower cost than alternative approaches.", "published": "2022-07-10 21:56:56", "link": "http://arxiv.org/abs/2207.04546v2", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Joint Analysis of Acoustic Scenes and Sound Events with Weakly labeled\n  Data", "abstract": "Considering that acoustic scenes and sound events are closely related to each\nother, in some previous papers, a joint analysis of acoustic scenes and sound\nevents utilizing multitask learning (MTL)-based neural networks was proposed.\nIn conventional methods, a strongly supervised scheme is applied to sound event\ndetection in MTL models, which requires strong labels of sound events in model\ntraining; however, annotating strong event labels is quite time-consuming. In\nthis paper, we thus propose a method for the joint analysis of acoustic scenes\nand sound events based on the MTL framework with weak labels of sound events.\nIn particular, in the proposed method, we introduce the multiple-instance\nlearning scheme for weakly supervised training of sound event detection and\nevaluate four pooling functions, namely, max pooling, average pooling,\nexponential softmax pooling, and attention pooling. Experimental results\nobtained using parts of the TUT Acoustic Scenes 2016/2017 and TUT Sound Events\n2016/2017 datasets show that the proposed MTL-based method with weak labels\noutperforms the conventional single-task-based scene classification and event\ndetection models with weak labels in terms of both the scene classification and\nevent detection performances.", "published": "2022-07-10 01:20:32", "link": "http://arxiv.org/abs/2207.04357v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Comparative Study of Self-supervised Speech Representation Based Voice\n  Conversion", "abstract": "We present a large-scale comparative study of self-supervised speech\nrepresentation (S3R)-based voice conversion (VC). In the context of\nrecognition-synthesis VC, S3Rs are attractive owing to their potential to\nreplace expensive supervised representations such as phonetic posteriorgrams\n(PPGs), which are commonly adopted by state-of-the-art VC systems. Using\nS3PRL-VC, an open-source VC software we previously developed, we provide a\nseries of in-depth objective and subjective analyses under three VC settings:\nintra-/cross-lingual any-to-one (A2O) and any-to-any (A2A) VC, using the voice\nconversion challenge 2020 (VCC2020) dataset. We investigated S3R-based VC in\nvarious aspects, including model type, multilinguality, and supervision. We\nalso studied the effect of a post-discretization process with k-means\nclustering and showed how it improves in the A2A setting. Finally, the\ncomparison with state-of-the-art VC systems demonstrates the competitiveness of\nS3R-based VC and also sheds light on the possible improving directions.", "published": "2022-07-10 01:02:22", "link": "http://arxiv.org/abs/2207.04356v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Proper Contrastive Self-supervised Learning Strategies For Music\n  Audio Representation", "abstract": "The common research goal of self-supervised learning is to extract a general\nrepresentation which an arbitrary downstream task would benefit from. In this\nwork, we investigate music audio representation learned from different\ncontrastive self-supervised learning schemes and empirically evaluate the\nembedded vectors on various music information retrieval (MIR) tasks where\ndifferent levels of the music perception are concerned. We analyze the results\nto discuss the proper direction of contrastive learning strategies for\ndifferent MIR tasks. We show that these representations convey a comprehensive\ninformation about the auditory characteristics of music in general, although\neach of the self-supervision strategies has its own effectiveness in certain\naspect of information.", "published": "2022-07-10 14:25:37", "link": "http://arxiv.org/abs/2207.04471v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Frequency Information Enhanced Channel Attention Module for\n  Speaker Representation Learning", "abstract": "Recently, attention mechanisms have been applied successfully in neural\nnetwork-based speaker verification systems. Incorporating the\nSqueeze-and-Excitation block into convolutional neural networks has achieved\nremarkable performance. However, it uses global average pooling (GAP) to simply\naverage the features along time and frequency dimensions, which is incapable of\npreserving sufficient speaker information in the feature maps. In this study,\nwe show that GAP is a special case of a discrete cosine transform (DCT) on\ntime-frequency domain mathematically using only the lowest frequency component\nin frequency decomposition. To strengthen the speaker information extraction\nability, we propose to utilize multi-frequency information and design two novel\nand effective attention modules, called Single-Frequency Single-Channel (SFSC)\nattention module and Multi-Frequency Single-Channel (MFSC) attention module.\nThe proposed attention modules can effectively capture more speaker information\nfrom multiple frequency components on the basis of DCT. We conduct\ncomprehensive experiments on the VoxCeleb datasets and a probe evaluation on\nthe 1st 48-UTD forensic corpus. Experimental results demonstrate that our\nproposed SFSC and MFSC attention modules can efficiently generate more\ndiscriminative speaker representations and outperform ResNet34-SE and\nECAPA-TDNN systems with relative 20.9% and 20.2% reduction in EER, without\nadding extra network parameters.", "published": "2022-07-10 21:19:36", "link": "http://arxiv.org/abs/2207.04540v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
