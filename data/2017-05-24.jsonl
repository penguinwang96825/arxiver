{"title": "Deep Investigation of Cross-Language Plagiarism Detection Methods", "abstract": "This paper is a deep investigation of cross-language plagiarism detection\nmethods on a new recently introduced open dataset, which contains parallel and\ncomparable collections of documents with multiple characteristics (different\ngenres, languages and sizes of texts). We investigate cross-language plagiarism\ndetection methods for 6 language pairs on 2 granularities of text units in\norder to draw robust conclusions on the best methods while deeply analyzing\ncorrelations across document styles and languages.", "published": "2017-05-24 15:50:47", "link": "http://arxiv.org/abs/1705.08828v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parsing with CYK over Distributed Representations", "abstract": "Syntactic parsing is a key task in natural language processing. This task has\nbeen dominated by symbolic, grammar-based parsers. Neural networks, with their\ndistributed representations, are challenging these methods. In this article we\nshow that existing symbolic parsing algorithms can cross the border and be\nentirely formulated over distributed representations. To this end we introduce\na version of the traditional Cocke-Younger-Kasami (CYK) algorithm, called\nD-CYK, which is entirely defined over distributed representations. Our D-CYK\nuses matrix multiplication on real number matrices of size independent of the\nlength of the input string. These operations are compatible with traditional\nneural networks. Experiments show that our D-CYK approximates the original CYK\nalgorithm. By showing that CYK can be entirely performed on distributed\nrepresentations, we open the way to the definition of recurrent layers of\nCYK-informed neural networks.", "published": "2017-05-24 16:22:13", "link": "http://arxiv.org/abs/1705.08843v2", "categories": ["cs.CL", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Joint PoS Tagging and Stemming for Agglutinative Languages", "abstract": "The number of word forms in agglutinative languages is theoretically infinite\nand this variety in word forms introduces sparsity in many natural language\nprocessing tasks. Part-of-speech tagging (PoS tagging) is one of these tasks\nthat often suffers from sparsity. In this paper, we present an unsupervised\nBayesian model using Hidden Markov Models (HMMs) for joint PoS tagging and\nstemming for agglutinative languages. We use stemming to reduce sparsity in PoS\ntagging. Two tasks are jointly performed to provide a mutual benefit in both\ntasks. Our results show that joint POS tagging and stemming improves PoS\ntagging scores. We present results for Turkish and Finnish as agglutinative\nlanguages and English as a morphologically poor language.", "published": "2017-05-24 19:44:35", "link": "http://arxiv.org/abs/1705.08942v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Deep Voice 2: Multi-Speaker Neural Text-to-Speech", "abstract": "We introduce a technique for augmenting neural text-to-speech (TTS) with\nlowdimensional trainable speaker embeddings to generate different voices from a\nsingle model. As a starting point, we show improvements over the two\nstate-ofthe-art approaches for single-speaker neural TTS: Deep Voice 1 and\nTacotron. We introduce Deep Voice 2, which is based on a similar pipeline with\nDeep Voice 1, but constructed with higher performance building blocks and\ndemonstrates a significant audio quality improvement over Deep Voice 1. We\nimprove Tacotron by introducing a post-processing neural vocoder, and\ndemonstrate a significant audio quality improvement. We then demonstrate our\ntechnique for multi-speaker speech synthesis for both Deep Voice 2 and Tacotron\non two multi-speaker TTS datasets. We show that a single neural TTS system can\nlearn hundreds of unique voices from less than half an hour of data per\nspeaker, while achieving high audio quality synthesis and preserving the\nspeaker identities almost perfectly.", "published": "2017-05-24 19:53:13", "link": "http://arxiv.org/abs/1705.08947v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Matroids Hitting Sets and Unsupervised Dependency Grammar Induction", "abstract": "This paper formulates a novel problem on graphs: find the minimal subset of\nedges in a fully connected graph, such that the resulting graph contains all\nspanning trees for a set of specifed sub-graphs. This formulation is motivated\nby an un-supervised grammar induction problem from computational linguistics.\nWe present a reduction to some known problems and algorithms from graph theory,\nprovide computational complexity results, and describe an approximation\nalgorithm.", "published": "2017-05-24 22:53:56", "link": "http://arxiv.org/abs/1705.08992v2", "categories": ["cs.DM", "cs.CL", "cs.DS", "F.4.2; G.2.2; I.2.8; F.1.3"], "primary_category": "cs.DM"}
