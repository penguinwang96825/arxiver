{"title": "Adapting to the Long Tail: A Meta-Analysis of Transfer Learning Research\n  for Language Understanding Tasks", "abstract": "Natural language understanding (NLU) has made massive progress driven by\nlarge benchmarks, but benchmarks often leave a long tail of infrequent\nphenomena underrepresented. We reflect on the question: have transfer learning\nmethods sufficiently addressed the poor performance of benchmark-trained models\non the long tail? We conceptualize the long tail using macro-level dimensions\n(e.g., underrepresented genres, topics, etc.), and perform a qualitative\nmeta-analysis of 100 representative papers on transfer learning research for\nNLU. Our analysis asks three questions: (i) Which long tail dimensions do\ntransfer learning studies target? (ii) Which properties of adaptation methods\nhelp improve performance on the long tail? (iii) Which methodological gaps have\ngreatest negative impact on long tail performance? Our answers highlight major\navenues for future research in transfer learning for the long tail. Lastly,\nusing our meta-analysis framework, we perform a case study comparing the\nperformance of various adaptation methods on clinical narratives, which\nprovides interesting insights that may enable us to make progress along these\nfuture avenues.", "published": "2021-11-02 02:58:45", "link": "http://arxiv.org/abs/2111.01340v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "System Combination for Grammatical Error Correction Based on Integer\n  Programming", "abstract": "In this paper, we propose a system combination method for grammatical error\ncorrection (GEC), based on nonlinear integer programming (IP). Our method\noptimizes a novel F score objective based on error types, and combines multiple\nend-to-end GEC systems. The proposed IP approach optimizes the selection of a\nsingle best system for each grammatical error type present in the data.\nExperiments of the IP approach on combining state-of-the-art standalone GEC\nsystems show that the combined system outperforms all standalone systems. It\nimproves F0.5 score by 3.61% when combining the two best participating systems\nin the BEA 2019 shared task, and achieves F0.5 score of 73.08%. We also perform\nexperiments to compare our IP approach with another state-of-the-art system\ncombination method for GEC, demonstrating IP's competitive combination\ncapability.", "published": "2021-11-02 10:08:46", "link": "http://arxiv.org/abs/2111.01465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detection of Hate Speech using BERT and Hate Speech Word Embedding with\n  Deep Model", "abstract": "The enormous amount of data being generated on the web and social media has\nincreased the demand for detecting online hate speech. Detecting hate speech\nwill reduce their negative impact and influence on others. A lot of effort in\nthe Natural Language Processing (NLP) domain aimed to detect hate speech in\ngeneral or detect specific hate speech such as religion, race, gender, or\nsexual orientation. Hate communities tend to use abbreviations, intentional\nspelling mistakes, and coded words in their communication to evade detection,\nadding more challenges to hate speech detection tasks. Thus, word\nrepresentation will play an increasingly pivotal role in detecting hate speech.\nThis paper investigates the feasibility of leveraging domain-specific word\nembedding in Bidirectional LSTM based deep model to automatically\ndetect/classify hate speech. Furthermore, we investigate the use of the\ntransfer learning language model (BERT) on hate speech problem as a binary\nclassification task. The experiments showed that domainspecific word embedding\nwith the Bidirectional LSTM based deep model achieved a 93% f1-score while BERT\nachieved up to 96% f1-score on a combined balanced dataset from available hate\nspeech datasets.", "published": "2021-11-02 11:42:54", "link": "http://arxiv.org/abs/2111.01515v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Text-based Phishing Detection", "abstract": "This paper reports on an experiment into text-based phishing detection using\nreadily available resources and without the use of semantics. The developed\nalgorithm is a modified version of previously published work that works with\nthe same tools. The results obtained in recognizing phishing emails are\nconsiderably better than the previously reported work; but the rate of text\nfalsely identified as phishing is slightly worse. It is expected that adding\nsemantic component will reduce the false positive rate while preserving the\ndetection accuracy.", "published": "2021-11-02 15:37:33", "link": "http://arxiv.org/abs/2111.01676v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "abstract": "Meta-learning considers the problem of learning an efficient learning process\nthat can leverage its past experience to accurately solve new tasks. However,\nthe efficacy of meta-learning crucially depends on the distribution of tasks\navailable for training, and this is often assumed to be known a priori or\nconstructed from limited supervised datasets. In this work, we aim to provide\ntask distributions for meta-learning by considering self-supervised tasks\nautomatically proposed from unlabeled text, to enable large-scale meta-learning\nin NLP. We design multiple distributions of self-supervised tasks by\nconsidering important aspects of task diversity, difficulty, type, domain, and\ncurriculum, and investigate how they affect meta-learning performance. Our\nanalysis shows that all these factors meaningfully alter the task distribution,\nsome inducing significant improvements in downstream few-shot accuracy of the\nmeta-learned models. Empirically, results on 20 downstream tasks show\nsignificant improvements in few-shot learning -- adding up to +4.2% absolute\naccuracy (on average) to the previous unsupervised meta-learning method, and\nperform comparably to supervised methods on the FewRel 2.0 benchmark.", "published": "2021-11-02 01:50:09", "link": "http://arxiv.org/abs/2111.01322v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Integrating Pretrained Language Model for Dialogue Policy Learning", "abstract": "Reinforcement Learning (RL) has been witnessed its potential for training a\ndialogue policy agent towards maximizing the accumulated rewards given from\nusers. However, the reward can be very sparse for it is usually only provided\nat the end of a dialog session, which causes unaffordable interaction\nrequirements for an acceptable dialog agent. Distinguished from many efforts\ndedicated to optimizing the policy and recovering the reward alternatively\nwhich suffers from easily getting stuck in local optima and model collapse, we\ndecompose the adversarial training into two steps: 1) we integrate a\npre-trained language model as a discriminator to judge whether the current\nsystem action is good enough for the last user action (i.e., \\textit{next\naction prediction}); 2) the discriminator gives and extra local dense reward to\nguide the agent's exploration. The experimental result demonstrates that our\nmethod significantly improves the complete rate (~4.4\\%) and success rate\n(~8.0\\%) of the dialogue system.", "published": "2021-11-02 07:16:03", "link": "http://arxiv.org/abs/2111.01398v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Review of Dialogue Systems: From Trained Monkeys to Stochastic Parrots", "abstract": "In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. Dialogue systems are\nincreasingly being designed to move beyond just imitating conversation and also\nimprove from such interactions over time. In this survey, we present a broad\noverview of methods developed to build dialogue systems over the years.\nDifferent use cases for dialogue systems ranging from task-based systems to\nopen domain chatbots motivate and necessitate specific systems. Starting from\nsimple rule-based systems, research has progressed towards increasingly complex\narchitectures trained on a massive corpus of datasets, like deep learning\nsystems. Motivated with the intuition of resembling human dialogues, progress\nhas been made towards incorporating emotions into the natural language\ngenerator, using reinforcement learning. While we see a trend of highly\nmarginal improvement on some metrics, we find that limited justification exists\nfor the metrics, and evaluation practices are not uniform. To conclude, we flag\nthese concerns and highlight possible research directions.", "published": "2021-11-02 08:07:55", "link": "http://arxiv.org/abs/2111.01414v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Translation using Diffusion Models", "abstract": "In this work, we show a novel method for neural machine translation (NMT),\nusing a denoising diffusion probabilistic model (DDPM), adjusted for textual\ndata, following recent advances in the field. We show that it's possible to\ntranslate sentences non-autoregressively using a diffusion model conditioned on\nthe source sentence. We also show that our model is able to translate between\npairs of languages unseen during training (zero-shot learning).", "published": "2021-11-02 10:14:17", "link": "http://arxiv.org/abs/2111.01471v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Effective and Imperceptible Adversarial Textual Attack via\n  Multi-objectivization", "abstract": "The field of adversarial textual attack has significantly grown over the last\nfew years, where the commonly considered objective is to craft adversarial\nexamples (AEs) that can successfully fool the target model. However, the\nimperceptibility of attacks, which is also essential for practical attackers,\nis often left out by previous studies. In consequence, the crafted AEs tend to\nhave obvious structural and semantic differences from the original\nhuman-written text, making them easily perceptible. In this work, we advocate\nleveraging multi-objectivization to address such issue. Specifically, we\nreformulate the problem of crafting AEs as a multi-objective optimization\nproblem, where the attack imperceptibility is considered as an auxiliary\nobjective. Then, we propose a simple yet effective evolutionary algorithm,\ndubbed HydraText, to solve this problem. To the best of our knowledge,\nHydraText is currently the only approach that can be effectively applied to\nboth score-based and decision-based attack settings. Exhaustive experiments\ninvolving 44237 instances demonstrate that HydraText consistently achieves\ncompetitive attack success rates and better attack imperceptibility than the\nrecently proposed attack approaches. A human evaluation study also shows that\nthe AEs crafted by HydraText are more indistinguishable from human-written\ntext. Finally, these AEs exhibit good transferability and can bring notable\nrobustness improvement to the target model by adversarial training.", "published": "2021-11-02 12:10:58", "link": "http://arxiv.org/abs/2111.01528v4", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "UQuAD1.0: Development of an Urdu Question Answering Training Data for\n  Machine Reading Comprehension", "abstract": "In recent years, low-resource Machine Reading Comprehension (MRC) has made\nsignificant progress, with models getting remarkable performance on various\nlanguage datasets. However, none of these models have been customized for the\nUrdu language. This work explores the semi-automated creation of the Urdu\nQuestion Answering Dataset (UQuAD1.0) by combining machine-translated SQuAD\nwith human-generated samples derived from Wikipedia articles and Urdu RC\nworksheets from Cambridge O-level books. UQuAD1.0 is a large-scale Urdu dataset\nintended for extractive machine reading comprehension tasks consisting of 49k\nquestion Answers pairs in question, passage, and answer format. In UQuAD1.0,\n45000 pairs of QA were generated by machine translation of the original\nSQuAD1.0 and approximately 4000 pairs via crowdsourcing. In this study, we used\ntwo types of MRC models: rule-based baseline and advanced Transformer-based\nmodels. However, we have discovered that the latter outperforms the others;\nthus, we have decided to concentrate solely on Transformer-based architectures.\nUsing XLMRoBERTa and multi-lingual BERT, we acquire an F1 score of 0.66 and\n0.63, respectively.", "published": "2021-11-02 12:25:04", "link": "http://arxiv.org/abs/2111.01543v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LMdiff: A Visual Diff Tool to Compare Language Models", "abstract": "While different language models are ubiquitous in NLP, it is hard to contrast\ntheir outputs and identify which contexts one can handle better than the other.\nTo address this question, we introduce LMdiff, a tool that visually compares\nprobability distributions of two models that differ, e.g., through finetuning,\ndistillation, or simply training with different parameter sizes. LMdiff allows\nthe generation of hypotheses about model behavior by investigating text\ninstances token by token and further assists in choosing these interesting text\ninstances by identifying the most interesting phrases from large corpora. We\nshowcase the applicability of LMdiff for hypothesis generation across multiple\ncase studies. A demo is available at http://lmdiff.net .", "published": "2021-11-02 13:17:20", "link": "http://arxiv.org/abs/2111.01582v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Personalized One-Shot Lipreading for an ALS Patient", "abstract": "Lipreading or visually recognizing speech from the mouth movements of a\nspeaker is a challenging and mentally taxing task. Unfortunately, multiple\nmedical conditions force people to depend on this skill in their day-to-day\nlives for essential communication. Patients suffering from Amyotrophic Lateral\nSclerosis (ALS) often lose muscle control, consequently their ability to\ngenerate speech and communicate via lip movements. Existing large datasets do\nnot focus on medical patients or curate personalized vocabulary relevant to an\nindividual. Collecting a large-scale dataset of a patient, needed to train\nmod-ern data-hungry deep learning models is, however, extremely challenging. In\nthis work, we propose a personalized network to lipread an ALS patient using\nonly one-shot examples. We depend on synthetically generated lip movements to\naugment the one-shot scenario. A Variational Encoder based domain adaptation\ntechnique is used to bridge the real-synthetic domain gap. Our approach\nsignificantly improves and achieves high top-5accuracy with 83.2% accuracy\ncompared to 62.6% achieved by comparable methods for the patient. Apart from\nevaluating our approach on the ALS patient, we also extend it to people with\nhearing impairment relying extensively on lip movements to communicate.", "published": "2021-11-02 17:03:29", "link": "http://arxiv.org/abs/2111.01740v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Language Semantics Interpretation with an Interaction-based Recurrent\n  Neural Networks", "abstract": "Text classification is a fundamental language task in Natural Language\nProcessing. A variety of sequential models is capable making good predictions\nyet there is lack of connection between language semantics and prediction\nresults. This paper proposes a novel influence score (I-score), a greedy search\nalgorithm called Backward Dropping Algorithm (BDA), and a novel feature\nengineering technique called the \"dagger technique\". First, the paper proposes\na novel influence score (I-score) to detect and search for the important\nlanguage semantics in text document that are useful for making good prediction\nin text classification tasks. Next, a greedy search algorithm called the\nBackward Dropping Algorithm is proposed to handle long-term dependencies in the\ndataset. Moreover, the paper proposes a novel engineering technique called the\n\"dagger technique\" that fully preserve the relationship between explanatory\nvariable and response variable. The proposed techniques can be further\ngeneralized into any feed-forward Artificial Neural Networks (ANNs) and\nConvolutional Neural Networks (CNNs), and any neural network. A real-world\napplication on the Internet Movie Database (IMDB) is used and the proposed\nmethods are applied to improve prediction performance with an 81% error\nreduction comparing with other popular peers if I-score and \"dagger technique\"\nare not implemented.", "published": "2021-11-02 00:39:21", "link": "http://arxiv.org/abs/2112.02997v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Transfer for Speech Processing using Acoustic Language\n  Similarity", "abstract": "Speech processing systems currently do not support the vast majority of\nlanguages, in part due to the lack of data in low-resource languages.\nCross-lingual transfer offers a compelling way to help bridge this digital\ndivide by incorporating high-resource data into low-resource systems. Current\ncross-lingual algorithms have shown success in text-based tasks and\nspeech-related tasks over some low-resource languages. However, scaling up\nspeech systems to support hundreds of low-resource languages remains unsolved.\nTo help bridge this gap, we propose a language similarity approach that can\nefficiently identify acoustic cross-lingual transfer pairs across hundreds of\nlanguages. We demonstrate the effectiveness of our approach in language family\nclassification, speech recognition, and speech synthesis tasks.", "published": "2021-11-02 01:55:17", "link": "http://arxiv.org/abs/2111.01326v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Classifier Training Efficiency for Automatic Cyberbullying\n  Detection with Feature Density", "abstract": "We study the effectiveness of Feature Density (FD) using different\nlinguistically-backed feature preprocessing methods in order to estimate\ndataset complexity, which in turn is used to comparatively estimate the\npotential performance of machine learning (ML) classifiers prior to any\ntraining. We hypothesise that estimating dataset complexity allows for the\nreduction of the number of required experiments iterations. This way we can\noptimize the resource-intensive training of ML models which is becoming a\nserious issue due to the increases in available dataset sizes and the ever\nrising popularity of models based on Deep Neural Networks (DNN). The problem of\nconstantly increasing needs for more powerful computational resources is also\naffecting the environment due to alarmingly-growing amount of CO2 emissions\ncaused by training of large-scale ML models. The research was conducted on\nmultiple datasets, including popular datasets, such as Yelp business review\ndataset used for training typical sentiment analysis models, as well as more\nrecent datasets trying to tackle the problem of cyberbullying, which, being a\nserious social problem, is also a much more sophisticated problem form the\npoint of view of linguistic representation. We use cyberbullying datasets\ncollected for multiple languages, namely English, Japanese and Polish. The\ndifference in linguistic complexity of datasets allows us to additionally\ndiscuss the efficacy of linguistically-backed word preprocessing.", "published": "2021-11-02 15:48:28", "link": "http://arxiv.org/abs/2111.01689v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Recent Advances in End-to-End Automatic Speech Recognition", "abstract": "Recently, the speech community is seeing a significant trend of moving from\ndeep neural network based hybrid modeling to end-to-end (E2E) modeling for\nautomatic speech recognition (ASR). While E2E models achieve the\nstate-of-the-art results in most benchmarks in terms of ASR accuracy, hybrid\nmodels are still used in a large proportion of commercial ASR systems at the\ncurrent time. There are lots of practical factors that affect the production\nmodel deployment decision. Traditional hybrid models, being optimized for\nproduction for decades, are usually good at these factors. Without providing\nexcellent solutions to all these factors, it is hard for E2E models to be\nwidely commercialized. In this paper, we will overview the recent advances in\nE2E models, focusing on technologies addressing those challenges from the\nindustry's perspective.", "published": "2021-11-02 15:49:20", "link": "http://arxiv.org/abs/2111.01690v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Assessing Effectiveness of Using Internal Signals for Check-Worthy Claim\n  Identification in Unlabeled Data for Automated Fact-Checking", "abstract": "While recent work on automated fact-checking has focused mainly on verifying\nand explaining claims, for which the list of claims is readily available,\nidentifying check-worthy claim sentences from a text remains challenging.\nCurrent claim identification models rely on manual annotations for each\nsentence in the text, which is an expensive task and challenging to conduct on\na frequent basis across multiple domains. This paper explores methodology to\nidentify check-worthy claim sentences from fake news articles, irrespective of\ndomain, without explicit sentence-level annotations. We leverage two internal\nsupervisory signals - headline and the abstractive summary - to rank the\nsentences based on semantic similarity. We hypothesize that this ranking\ndirectly correlates to the check-worthiness of the sentences. To assess the\neffectiveness of this hypothesis, we build pipelines that leverage the ranking\nof sentences based on either the headline or the abstractive summary. The\ntop-ranked sentences are used for the downstream fact-checking tasks of\nevidence retrieval and the article's veracity prediction by the pipeline. Our\nfindings suggest that the top 3 ranked sentences contain enough information for\nevidence-based fact-checking of a fake news article. We also show that while\nthe headline has more gisting similarity with how a fact-checking website\nwrites a claim, the summary-based pipeline is the most promising for an\nend-to-end fact-checking system.", "published": "2021-11-02 16:17:20", "link": "http://arxiv.org/abs/2111.01706v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "AVASpeech-SMAD: A Strongly Labelled Speech and Music Activity Detection\n  Dataset with Label Co-Occurrence", "abstract": "We propose a dataset, AVASpeech-SMAD, to assist speech and music activity\ndetection research. With frame-level music labels, the proposed dataset extends\nthe existing AVASpeech dataset, which originally consists of 45 hours of audio\nand speech activity labels. To the best of our knowledge, the proposed\nAVASpeech-SMAD is the first open-source dataset that features strong polyphonic\nlabels for both music and speech. The dataset was manually annotated and\nverified via an iterative cross-checking process. A simple automatic\nexamination was also implemented to further improve the quality of the labels.\nEvaluation results from two state-of-the-art SMAD systems are also provided as\na benchmark for future reference.", "published": "2021-11-02 01:40:32", "link": "http://arxiv.org/abs/2111.01320v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CycleGAN with Dual Adversarial Loss for Bone-Conducted Speech\n  Enhancement", "abstract": "Compared with air-conducted speech, bone-conducted speech has the unique\nadvantage of shielding background noise. Enhancement of bone-conducted speech\nhelps to improve its quality and intelligibility. In this paper, a novel\nCycleGAN with dual adversarial loss (CycleGAN-DAL) is proposed for\nbone-conducted speech enhancement. The proposed method uses an adversarial loss\nand a cycle-consistent loss simultaneously to learn forward and cyclic mapping,\nin which the adversarial loss is replaced with the classification adversarial\nloss and the defect adversarial loss to consolidate the forward mapping.\nCompared with conventional baseline methods, it can learn feature mapping\nbetween bone-conducted speech and target speech without additional\nair-conducted speech assistance. Moreover, the proposed method also avoids the\noversmooth problem which is occurred commonly in conventional statistical based\nmodels. Experimental results show that the proposed method outperforms baseline\nmethods such as CycleGAN, GMM, and BLSTM. Keywords: Bone-conducted speech\nenhancement, dual adversarial loss, Parallel CycleGAN, high frequency speech\nreconstruction", "published": "2021-11-02 08:42:50", "link": "http://arxiv.org/abs/2111.01430v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-input Architecture and Disentangled Representation Learning for\n  Multi-dimensional Modeling of Music Similarity", "abstract": "In the context of music information retrieval, similarity-based approaches\nare useful for a variety of tasks that benefit from a query-by-example\nscenario. Music however, naturally decomposes into a set of semantically\nmeaningful factors of variation. Current representation learning strategies\npursue the disentanglement of such factors from deep representations, resulting\nin highly interpretable models. This allows the modeling of music similarity\nperception, which is highly subjective and multi-dimensional. While the focus\nof prior work is on metadata driven notions of similarity, we suggest to\ndirectly model the human notion of multi-dimensional music similarity. To\nachieve this, we propose a multi-input deep neural network architecture, which\nsimultaneously processes mel-spectrogram, CENS-chromagram and tempogram in\norder to extract informative features for the different disentangled musical\ndimensions: genre, mood, instrument, era, tempo, and key. We evaluated the\nproposed music similarity approach using a triplet prediction task and found\nthat the proposed multi-input architecture outperforms a state of the art\nmethod. Furthermore, we present a novel multi-dimensional analysis in order to\nevaluate the influence of each disentangled dimension on the perception of\nmusic similarity.", "published": "2021-11-02 16:23:46", "link": "http://arxiv.org/abs/2111.01710v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Reduction of Subjective Listening Effort for TV Broadcast Signals with\n  Recurrent Neural Networks", "abstract": "Listening to the audio of TV broadcast signals can be challenging for\nhearing-impaired as well as normal-hearing listeners, especially when\nbackground sounds are prominent or too loud compared to the speech signal. This\ncan result in a reduced satisfaction and increased listening effort of the\nlisteners. Since the broadcast sound is usually premixed, we perform a\nsubjective evaluation for quantifying the potential of speech enhancement\nsystems based on audio source separation and recurrent neural networks (RNN).\nRecently, RNNs have shown promising results in the context of sound source\nseparation and real-time signal processing. In this paper, we separate the\nspeech from the background signals and remix the separated sounds at a higher\nsignal-to-noise ratio. This differs from classic speech enhancement, where\nusually only the extracted speech signal is exploited. The subjective\nevaluation with 20 normal-hearing subjects on real TV-broadcast material shows\nthat our proposed enhancement system is able to reduce the listening effort by\naround 2 points on a 13-point listening effort rating scale and increases the\nperceived sound quality compared to the original mixture.", "published": "2021-11-02 22:07:55", "link": "http://arxiv.org/abs/2111.01914v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Attention-Guided Generative Adversarial Network for Whisper to Normal\n  Speech Conversion", "abstract": "Whispered speech is a special way of pronunciation without using vocal cord\nvibration. A whispered speech does not contain a fundamental frequency, and its\nenergy is about 20dB lower than that of a normal speech. Converting a whispered\nspeech into a normal speech can improve speech quality and intelligibility. In\nthis paper, a novel attention-guided generative adversarial network model\nincorporating an autoencoder, a Siamese neural network, and an identity mapping\nloss function for whisper to normal speech conversion (AGAN-W2SC) is proposed.\nThe proposed method avoids the challenge of estimating the fundamental\nfrequency of the normal voiced speech converted from a whispered speech.\nSpecifically, the proposed model is more amendable to practical applications\nbecause it does not need to align speech features for training. Experimental\nresults demonstrate that the proposed AGAN-W2SC can obtain improved speech\nquality and intelligibility compared with dynamic-time-warping-based methods.", "published": "2021-11-02 03:00:19", "link": "http://arxiv.org/abs/2111.01342v1", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Design and Evaluation of Active Noise Control on Machinery Noise", "abstract": "Construction workers and residents live near around construction sites are\nexposed to noises that might cause hearing loss, high blood pressure, heart\ndisease, sleep disturbance and stress. Regulations has been carried out by\nnational governments to limit the maximum permissible noise levels for\nconstruction works. A four-channel active noise control system mounted on the\nopening of an enclosure is designed to prevent the machinery noise from\nspreading around and retaining the heat diffusion path. Multi-channel FxLMS\nalgorithm in time domain is implemented on the main controller. A Genelec\nspeaker is placed inside the box as the primary noise source to play back\ndifferent types of noises. Analyses and experiments are carried out to\ninvestigate the controllable frequency range of this ANC system in detail.\nConsiderable noise reduction performance is achieved for different recorded\npractical construction noises.", "published": "2021-11-02 15:11:20", "link": "http://arxiv.org/abs/2111.01652v1", "categories": ["eess.AS", "cs.SD", "cs.SY", "eess.SY"], "primary_category": "eess.AS"}
{"title": "Design of Tight Minimum-Sidelobe Windows by Riemannian Newton's Method", "abstract": "The short-time Fourier transform (STFT), or the discrete Gabor transform\n(DGT), has been extensively used in signal analysis and processing. Their\nproperties are characterized by a window function. For signal processing,\ndesigning a special window called tight window is important because it is known\nto make DGT-domain processing robust to error. In this paper, we propose a\nmethod of designing tight windows that minimize the sidelobe energy. It is\nformulated as a constrained spectral concentration problem, and a Newton's\nmethod on an oblique manifold is derived to efficiently obtain a solution. Our\nnumerical example showed that the proposed algorithm requires only several\niterations to reach a stationary point.", "published": "2021-11-02 13:43:29", "link": "http://arxiv.org/abs/2111.01593v2", "categories": ["eess.SP", "cs.NA", "eess.AS", "math.NA", "math.OC"], "primary_category": "eess.SP"}
