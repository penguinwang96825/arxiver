{"title": "A Unified Knowledge Graph Augmentation Service for Boosting\n  Domain-specific NLP Tasks", "abstract": "By focusing the pre-training process on domain-specific corpora, some\ndomain-specific pre-trained language models (PLMs) have achieved\nstate-of-the-art results. However, it is under-investigated to design a unified\nparadigm to inject domain knowledge in the PLM fine-tuning stage. We propose\nKnowledgeDA, a unified domain language model development service to enhance the\ntask-specific training procedure with domain knowledge graphs. Given\ndomain-specific task texts input, KnowledgeDA can automatically generate a\ndomain-specific language model following three steps: (i) localize domain\nknowledge entities in texts via an embedding-similarity approach; (ii) generate\naugmented samples by retrieving replaceable domain entity pairs from two views\nof both knowledge graph and training data; (iii) select high-quality augmented\nsamples for fine-tuning via confidence-based assessment. We implement a\nprototype of KnowledgeDA to learn language models for two domains, healthcare\nand software development. Experiments on domain-specific text classification\nand QA tasks verify the effectiveness and generalizability of KnowledgeDA.", "published": "2022-12-10 09:18:43", "link": "http://arxiv.org/abs/2212.05251v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Logic-guided Autoregressive Multi-hop Document Retrieval for\n  Fact Verification", "abstract": "A key component of fact verification is thevevidence retrieval, often from\nmultiple documents. Recent approaches use dense representations and condition\nthe retrieval of each document on the previously retrieved ones. The latter\nstep is performed over all the documents in the collection, requiring storing\ntheir dense representations in an index, thus incurring a high memory\nfootprint. An alternative paradigm is retrieve-and-rerank, where documents are\nretrieved using methods such as BM25, their sentences are reranked, and further\ndocuments are retrieved conditioned on these sentences, reducing the memory\nrequirements. However, such approaches can be brittle as they rely on\nheuristics and assume hyperlinks between documents. We propose a novel\nretrieve-and-rerank method for multi-hop retrieval, that consists of a\nretriever that jointly scores documents in the knowledge source and sentences\nfrom previously retrieved documents using an autoregressive formulation and is\nguided by a proof system based on natural logic that dynamically terminates the\nretrieval process if the evidence is deemed sufficient. This method is\ncompetitive with current state-of-the-art methods on FEVER, HoVer and\nFEVEROUS-S, while using $5$ to $10$ times less memory than competing systems.\nEvaluation on an adversarial dataset indicates improved stability of our\napproach compared to commonly deployed threshold-based methods. Finally, the\nproof system helps humans predict model decisions correctly more often than\nusing the evidence alone.", "published": "2022-12-10 11:32:38", "link": "http://arxiv.org/abs/2212.05276v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Punctuation Restoration for Singaporean Spoken Languages: English,\n  Malay, and Mandarin", "abstract": "This paper presents the work of restoring punctuation for ASR transcripts\ngenerated by multilingual ASR systems. The focus languages are English,\nMandarin, and Malay which are three of the most popular languages in Singapore.\nTo the best of our knowledge, this is the first system that can tackle\npunctuation restoration for these three languages simultaneously. Traditional\napproaches usually treat the task as a sequential labeling task, however, this\nwork adopts a slot-filling approach that predicts the presence and type of\npunctuation marks at each word boundary. The approach is similar to the\nMasked-Language Model approach employed during the pre-training stages of BERT,\nbut instead of predicting the masked word, our model predicts masked\npunctuation. Additionally, we find that using Jieba1 instead of only using the\nbuilt-in SentencePiece tokenizer of XLM-R can significantly improve the\nperformance of punctuating Mandarin transcripts. Experimental results on\nEnglish and Mandarin IWSLT2022 datasets and Malay News show that the proposed\napproach achieved state-of-the-art results for Mandarin with 73.8% F1-score\nwhile maintaining a reasonable F1-score for English and Malay, i.e. 74.7% and\n78% respectively. Our source code that allows reproducing the results and\nbuilding a simple web-based application for demonstration purposes is available\non Github.", "published": "2022-12-10 19:54:53", "link": "http://arxiv.org/abs/2212.05356v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topic-Aware Response Generation in Task-Oriented Dialogue with\n  Unstructured Knowledge Access", "abstract": "To alleviate the problem of structured databases' limited coverage, recent\ntask-oriented dialogue systems incorporate external unstructured knowledge to\nguide the generation of system responses. However, these usually use word or\nsentence level similarities to detect the relevant knowledge context, which\nonly partially capture the topical level relevance. In this paper, we examine\nhow to better integrate topical information in knowledge grounded task-oriented\ndialogue and propose ``Topic-Aware Response Generation'' (TARG), an end-to-end\nresponse generation model. TARG incorporates multiple topic-aware attention\nmechanisms to derive the importance weighting scheme over dialogue utterances\nand external knowledge sources towards a better understanding of the dialogue\nhistory. Experimental results indicate that TARG achieves state-of-the-art\nperformance in knowledge selection and response generation, outperforming\nprevious state-of-the-art by 3.2, 3.6, and 4.2 points in EM, F1 and BLEU-4\nrespectively on Doc2Dial, and performing comparably with previous work on\nDSTC9; both being knowledge-grounded task-oriented dialogue datasets.", "published": "2022-12-10 22:32:28", "link": "http://arxiv.org/abs/2212.05373v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Artificial Text Detection with Multiple Training Strategies", "abstract": "As the deep learning rapidly promote, the artificial texts created by\ngenerative models are commonly used in news and social media. However, such\nmodels can be abused to generate product reviews, fake news, and even fake\npolitical content. The paper proposes a solution for the Russian Artificial\nText Detection in the Dialogue shared task 2022 (RuATD 2022) to distinguish\nwhich model within the list is used to generate this text. We introduce the\nDeBERTa pre-trained language model with multiple training strategies for this\nshared task. Extensive experiments conducted on the RuATD dataset validate the\neffectiveness of our proposed method. Moreover, our submission ranked second\nplace in the evaluation phase for RuATD 2022 (Multi-Class).", "published": "2022-12-10 03:57:28", "link": "http://arxiv.org/abs/2212.05194v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LEAD: Liberal Feature-based Distillation for Dense Retrieval", "abstract": "Knowledge distillation is often used to transfer knowledge from a strong\nteacher model to a relatively weak student model. Traditional methods include\nresponse-based methods and feature-based methods. Response-based methods are\nwidely used but suffer from lower upper limits of performance due to their\nignorance of intermediate signals, while feature-based methods have constraints\non vocabularies, tokenizers and model architectures. In this paper, we propose\na liberal feature-based distillation method (LEAD). LEAD aligns the\ndistribution between the intermediate layers of teacher model and student\nmodel, which is effective, extendable, portable and has no requirements on\nvocabularies, tokenizers, or model architectures. Extensive experiments show\nthe effectiveness of LEAD on widely-used benchmarks, including MS MARCO Passage\nRanking, TREC 2019 DL Track, MS MARCO Document Ranking and TREC 2020 DL Track.\nOur code is available in https://github.com/microsoft/SimXNS/tree/main/LEAD.", "published": "2022-12-10 06:30:54", "link": "http://arxiv.org/abs/2212.05225v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Structured information extraction from complex scientific text with\n  fine-tuned large language models", "abstract": "Intelligently extracting and linking complex scientific information from\nunstructured text is a challenging endeavor particularly for those\ninexperienced with natural language processing. Here, we present a simple\nsequence-to-sequence approach to joint named entity recognition and relation\nextraction for complex hierarchical information in scientific text. The\napproach leverages a pre-trained large language model (LLM), GPT-3, that is\nfine-tuned on approximately 500 pairs of prompts (inputs) and completions\n(outputs). Information is extracted either from single sentences or across\nsentences in abstracts/passages, and the output can be returned as simple\nEnglish sentences or a more structured format, such as a list of JSON objects.\nWe demonstrate that LLMs trained in this way are capable of accurately\nextracting useful records of complex scientific knowledge for three\nrepresentative tasks in materials chemistry: linking dopants with their host\nmaterials, cataloging metal-organic frameworks, and general\nchemistry/phase/morphology/application information extraction. This approach\nrepresents a simple, accessible, and highly-flexible route to obtaining large\ndatabases of structured knowledge extracted from unstructured text. An online\ndemo is available at http://www.matscholar.com/info-extraction.", "published": "2022-12-10 07:51:52", "link": "http://arxiv.org/abs/2212.05238v1", "categories": ["cs.CL", "cond-mat.mtrl-sci", "I.7.m"], "primary_category": "cs.CL"}
{"title": "MAPS-KB: A Million-scale Probabilistic Simile Knowledge Base", "abstract": "The ability to understand and generate similes is an imperative step to\nrealize human-level AI. However, there is still a considerable gap between\nmachine intelligence and human cognition in similes, since deep models based on\nstatistical distribution tend to favour high-frequency similes. Hence, a\nlarge-scale symbolic knowledge base of similes is required, as it contributes\nto the modeling of diverse yet unpopular similes while facilitating additional\nevaluation and reasoning. To bridge the gap, we propose a novel framework for\nlarge-scale simile knowledge base construction, as well as two probabilistic\nmetrics which enable an improved understanding of simile phenomena in natural\nlanguage. Overall, we construct MAPS-KB, a million-scale probabilistic simile\nknowledge base, covering 4.3 million triplets over 0.4 million terms from 70 GB\ncorpora. We conduct sufficient experiments to justify the effectiveness and\nnecessity of the methods of our framework. We also apply MAPS-KB on three\ndownstream tasks to achieve state-of-the-art performance, further demonstrating\nthe value of MAPS-KB.", "published": "2022-12-10 10:06:05", "link": "http://arxiv.org/abs/2212.05254v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Identifying the Source of Vulnerability in Explanation Discrepancy: A\n  Case Study in Neural Text Classification", "abstract": "Some recent works observed the instability of post-hoc explanations when\ninput side perturbations are applied to the model. This raises the interest and\nconcern in the stability of post-hoc explanations. However, the remaining\nquestion is: is the instability caused by the neural network model or the\npost-hoc explanation method? This work explores the potential source that leads\nto unstable post-hoc explanations. To separate the influence from the model, we\npropose a simple output probability perturbation method. Compared to prior\ninput side perturbation methods, the output probability perturbation method can\ncircumvent the neural model's potential effect on the explanations and allow\nthe analysis on the explanation method. We evaluate the proposed method with\nthree widely-used post-hoc explanation methods (LIME (Ribeiro et al., 2016),\nKernel Shapley (Lundberg and Lee, 2017a), and Sample Shapley (Strumbelj and\nKononenko, 2010)). The results demonstrate that the post-hoc methods are\nstable, barely producing discrepant explanations under output probability\nperturbations. The observation suggests that neural network models may be the\nprimary source of fragile explanations.", "published": "2022-12-10 16:04:34", "link": "http://arxiv.org/abs/2212.05327v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Thinking Fast and Slow in Large Language Models", "abstract": "Large language models (LLMs) are currently at the forefront of intertwining\nAI systems with human communication and everyday life. Therefore, it is of\ngreat importance to evaluate their emerging abilities. In this study, we show\nthat LLMs like GPT-3 exhibit behavior that strikingly resembles human-like\nintuition - and the cognitive errors that come with it. However, LLMs with\nhigher cognitive capabilities, in particular ChatGPT and GPT-4, learned to\navoid succumbing to these errors and perform in a hyperrational manner. For our\nexperiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as\nsemantic illusions that were originally designed to investigate intuitive\ndecision-making in humans. Our study demonstrates that investigating LLMs with\nmethods from psychology has the potential to reveal otherwise unknown emergent\ntraits.", "published": "2022-12-10 05:07:30", "link": "http://arxiv.org/abs/2212.05206v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GPU-accelerated Guided Source Separation for Meeting Transcription", "abstract": "Guided source separation (GSS) is a type of target-speaker extraction method\nthat relies on pre-computed speaker activities and blind source separation to\nperform front-end enhancement of overlapped speech signals. It was first\nproposed during the CHiME-5 challenge and provided significant improvements\nover the delay-and-sum beamforming baseline. Despite its strengths, however,\nthe method has seen limited adoption for meeting transcription benchmarks\nprimarily due to its high computation time. In this paper, we describe our\nimproved implementation of GSS that leverages the power of modern GPU-based\npipelines, including batched processing of frequencies and segments, to provide\n300x speed-up over CPU-based inference. The improved inference time allows us\nto perform detailed ablation studies over several parameters of the GSS\nalgorithm -- such as context duration, number of channels, and noise class, to\nname a few. We provide end-to-end reproducible pipelines for speaker-attributed\ntranscription of popular meeting benchmarks: LibriCSS, AMI, and AliMeeting. Our\ncode and recipes are publicly available: https://github.com/desh2608/gss.", "published": "2022-12-10 11:20:17", "link": "http://arxiv.org/abs/2212.05271v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Variational Speech Waveform Compression to Catalyze Semantic\n  Communications", "abstract": "We propose a novel neural waveform compression method to catalyze emerging\nspeech semantic communications. By introducing nonlinear transform and\nvariational modeling, we effectively capture the dependencies within speech\nframes and estimate the probabilistic distribution of the speech feature more\naccurately, giving rise to better compression performance. In particular, the\nspeech signals are analyzed and synthesized by a pair of nonlinear transforms,\nyielding latent features. An entropy model with hyperprior is built to capture\nthe probabilistic distribution of latent features, followed with quantization\nand entropy coding. The proposed waveform codec can be optimized flexibly\ntowards arbitrary rate, and the other appealing feature is that it can be\neasily optimized for any differentiable loss function, including perceptual\nloss used in semantic communications. To further improve the fidelity, we\nincorporate residual coding to mitigate the degradation arising from\nquantization distortion at the latent space. Results indicate that achieving\nthe same performance, the proposed method saves up to 27% coding rate than\nwidely used adaptive multi-rate wideband (AMR-WB) codec as well as emerging\nneural waveform coding methods.", "published": "2022-12-10 12:52:59", "link": "http://arxiv.org/abs/2212.05294v2", "categories": ["cs.SD", "cs.IT", "eess.AS", "math.IT"], "primary_category": "cs.SD"}
{"title": "Leveraging Modality-specific Representations for Audio-visual Speech\n  Recognition via Reinforcement Learning", "abstract": "Audio-visual speech recognition (AVSR) has gained remarkable success for\nameliorating the noise-robustness of speech recognition. Mainstream methods\nfocus on fusing audio and visual inputs to obtain modality-invariant\nrepresentations. However, such representations are prone to over-reliance on\naudio modality as it is much easier to recognize than video modality in clean\nconditions. As a result, the AVSR model underestimates the importance of visual\nstream in face of noise corruption. To this end, we leverage visual\nmodality-specific representations to provide stable complementary information\nfor the AVSR task. Specifically, we propose a reinforcement learning (RL) based\nframework called MSRL, where the agent dynamically harmonizes\nmodality-invariant and modality-specific representations in the auto-regressive\ndecoding process. We customize a reward function directly related to\ntask-specific metrics (i.e., word error rate), which encourages the MSRL to\neffectively explore the optimal integration strategy. Experimental results on\nthe LRS3 dataset show that the proposed method achieves state-of-the-art in\nboth clean and various noisy conditions. Furthermore, we demonstrate the better\ngenerality of MSRL system than other baselines when test set contains unseen\nnoises.", "published": "2022-12-10 14:01:54", "link": "http://arxiv.org/abs/2212.05301v2", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Comparison of Audio Preprocessing Techniques and Deep Learning\n  Algorithms for Raga Recognition", "abstract": "Ragas form the foundation for Indian Classical Music. The task of Raga\nRecognition has gained traction in the Music Information Retrieval community in\nthe recent past, which can be attributed to the nuances of Indian Classical\nMusic that have resulted in a plethora of research problems in Computing. In\nthis work, we used two different digital audio signal processing techniques to\npreprocess audio samples of Carnatic classical ragas that were then processed\nby various Deep Learning models. Their results were compared in order to infer\nwhich DASP technique is better suited to the task of raga recognition. We\nobtained state of the art results, with our best model reaching a testing\naccuracy of 98.1%. We also compared each model ability to distinguish between\nsimilar ragas.", "published": "2022-12-10 16:51:12", "link": "http://arxiv.org/abs/2212.05335v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Synthetic Wave-Geometric Impulse Responses for Improved Speech\n  Dereverberation", "abstract": "We present a novel approach to improve the performance of learning-based\nspeech dereverberation using accurate synthetic datasets. Our approach is\ndesigned to recover the reverb-free signal from a reverberant speech signal. We\nshow that accurately simulating the low-frequency components of Room Impulse\nResponses (RIRs) is important to achieving good dereverberation. We use the GWA\ndataset that consists of synthetic RIRs generated in a hybrid fashion: an\naccurate wave-based solver is used to simulate the lower frequencies and\ngeometric ray tracing methods simulate the higher frequencies. We demonstrate\nthat speech dereverberation models trained on hybrid synthetic RIRs outperform\nmodels trained on RIRs generated by prior geometric ray tracing methods on four\nreal-world RIR datasets.", "published": "2022-12-10 20:15:23", "link": "http://arxiv.org/abs/2212.05360v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
