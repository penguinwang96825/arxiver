{"title": "BENGAL: An Automatic Benchmark Generator for Entity Recognition and\n  Linking", "abstract": "The manual creation of gold standards for named entity recognition and entity\nlinking is time- and resource-intensive. Moreover, recent works show that such\ngold standards contain a large proportion of mistakes in addition to being\ndifficult to maintain. We hence present BENGAL, a novel automatic generation of\nsuch gold standards as a complement to manually created benchmarks. The main\nadvantage of our benchmarks is that they can be readily generated at any time.\nThey are also cost-effective while being guaranteed to be free of annotation\nerrors. We compare the performance of 11 tools on benchmarks in English\ngenerated by BENGAL and on 16benchmarks created manually. We show that our\napproach can be ported easily across languages by presenting results achieved\nby 4 tools on both Brazilian Portuguese and Spanish. Overall, our results\nsuggest that our automatic benchmark generation approach can create varied\nbenchmarks that have characteristics similar to those of existing benchmarks.\nOur approach is open-source. Our experimental results are available at\nhttp://faturl.com/bengalexpinlg and the code at\nhttps://github.com/dice-group/BENGAL.", "published": "2017-10-24 10:15:58", "link": "http://arxiv.org/abs/1710.08691v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Clickbait Identification using Neural Networks", "abstract": "This paper presents the results of our participation in the Clickbait\nDetection Challenge 2017. The system relies on a fusion of neural networks,\nincorporating different types of available informations. It does not require\nany linguistic preprocessing, and hence generalizes more easily to new domains\nand languages. The final combined model achieves a mean squared error of\n0.0428, an accuracy of 0.826, and a F1 score of 0.564. According to the\nofficial evaluation metric the system ranked 6th of the 13 participating teams.", "published": "2017-10-24 12:11:07", "link": "http://arxiv.org/abs/1710.08721v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple Text Analytics Model To Assist Literary Criticism: comparative\n  approach and example on James Joyce against Shakespeare and the Bible", "abstract": "Literary analysis, criticism or studies is a largely valued field with\ndedicated journals and researchers which remains mostly within the humanities\nscope. Text analytics is the computer-aided process of deriving information\nfrom texts. In this article we describe a simple and generic model for\nperforming literary analysis using text analytics. The method relies on\nstatistical measures of: 1) token and sentence sizes and 2) Wordnet synset\nfeatures. These measures are then used in Principal Component Analysis where\nthe texts to be analyzed are observed against Shakespeare and the Bible,\nregarded as reference literature. The model is validated by analyzing selected\nworks from James Joyce (1882-1941), one of the most important writers of the\n20th century. We discuss the consistency of this approach, the reasons why we\ndid not use other techniques (e.g. part-of-speech tagging) and the ways by\nwhich the analysis model might be adapted and enhanced.", "published": "2017-10-24 16:08:58", "link": "http://arxiv.org/abs/1710.09233v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Multi-Label Classification for Improved Question Answering", "abstract": "A plethora of diverse approaches for question answering over RDF data have\nbeen developed in recent years. While the accuracy of these systems has\nincreased significantly over time, most systems still focus on particular types\nof questions or particular challenges in question answering. What is a curse\nfor single systems is a blessing for the combination of these systems. We show\nin this paper how machine learning techniques can be applied to create a more\naccurate question answering metasystem by reusing existing systems. In\nparticular, we develop a multi-label classification-based metasystem for\nquestion answering over 6 existing systems using an innovative set of 14\nquestion features. The metasystem outperforms the best single system by 14%\nF-measure on the recent QALD-6 benchmark. Furthermore, we analyzed the\ninfluence and correlation of the underlying features on the metasystem quality.", "published": "2017-10-24 07:40:16", "link": "http://arxiv.org/abs/1710.08634v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Scaling Text with the Class Affinity Model", "abstract": "Probabilistic methods for classifying text form a rich tradition in machine\nlearning and natural language processing. For many important problems, however,\nclass prediction is uninteresting because the class is known, and instead the\nfocus shifts to estimating latent quantities related to the text, such as\naffect or ideology. We focus on one such problem of interest, estimating the\nideological positions of 55 Irish legislators in the 1991 D\\'ail confidence\nvote. To solve the D\\'ail scaling problem and others like it, we develop a text\nmodeling framework that allows actors to take latent positions on a \"gray\"\nspectrum between \"black\" and \"white\" polar opposites. We are able to validate\nresults from this model by measuring the influences exhibited by individual\nwords, and we are able to quantify the uncertainty in the scaling estimates by\nusing a sentence-level block bootstrap. Applying our method to the D\\'ail\ndebate, we are able to scale the legislators between extreme pro-government and\npro-opposition in a way that reveals nuances in their speeches not captured by\ntheir votes or party affiliations.", "published": "2017-10-24 19:38:20", "link": "http://arxiv.org/abs/1710.08963v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "On the Conditioning of the Spherical Harmonic Matrix for Spatial Audio\n  Applications", "abstract": "In this paper, we attempt to study the conditioning of the Spherical Harmonic\nMatrix (SHM), which is widely used in the discrete, limited order orthogonal\nrepresentation of sound fields. SHM's has been widely used in the audio\napplications like spatial sound reproduction using loudspeakers, orthogonal\nrepresentation of Head Related Transfer Functions (HRTFs) etc. The conditioning\nbehaviour of the SHM depends on the sampling positions chosen in the 3D space.\nIdentification of the optimal sampling points in the continuous 3D space that\nresults in a well-conditioned SHM for any number of sampling points is a highly\nchallenging task. In this work, an attempt has been made to solve a discrete\nversion of the above problem using optimization based techniques. The discrete\nproblem is, to identify the optimal sampling points from a discrete set of\ndensely sampled positions of the 3D space, that minimizes the condition number\nof SHM. This method has been subsequently utilized for identifying the geometry\nof loudspeakers in the spatial sound reproduction, and in the selection of\nspatial sampling configurations for HRTF measurement. The application specific\nrequirements have been formulated as additional constraints of the optimization\nproblem. Recently developed mixed-integer optimization solvers have been used\nin solving the formulated problem. The performance of the obtained sampling\nposition in each application is compared with the existing configurations.\nObjective measures like condition number, D-measure, and spectral distortion\nare used to study the performance of the sampling configurations resulting from\nthe proposed and the existing methods. It is observed that the proposed\nsolution is able to find the sampling points that results in a better\nconditioned SHM and also maintains all the application specific requirements.", "published": "2017-10-24 07:33:43", "link": "http://arxiv.org/abs/1710.08633v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Inferring Room Semantics Using Acoustic Monitoring", "abstract": "Having knowledge of the environmental context of the user i.e. the knowledge\nof the users' indoor location and the semantics of their environment, can\nfacilitate the development of many of location-aware applications. In this\npaper, we propose an acoustic monitoring technique that infers semantic\nknowledge about an indoor space \\emph{over time,} using audio recordings from\nit. Our technique uses the impulse response of these spaces as well as the\nambient sounds produced in them in order to determine a semantic label for\nthem. As we process more recordings, we update our \\emph{confidence} in the\nassigned label. We evaluate our technique on a dataset of single-speaker human\nspeech recordings obtained in different types of rooms at three university\nbuildings. In our evaluation, the confidence\\emph{ }for the true label\ngenerally outstripped the confidence for all other labels and in some cases\nconverged to 100\\% with less than 30 samples.", "published": "2017-10-24 09:59:21", "link": "http://arxiv.org/abs/1710.08684v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficiently Trainable Text-to-Speech System Based on Deep Convolutional\n  Networks with Guided Attention", "abstract": "This paper describes a novel text-to-speech (TTS) technique based on deep\nconvolutional neural networks (CNN), without use of any recurrent units.\nRecurrent neural networks (RNN) have become a standard technique to model\nsequential data recently, and this technique has been used in some cutting-edge\nneural TTS techniques. However, training RNN components often requires a very\npowerful computer, or a very long time, typically several days or weeks. Recent\nother studies, on the other hand, have shown that CNN-based sequence synthesis\ncan be much faster than RNN-based techniques, because of high\nparallelizability. The objective of this paper is to show that an alternative\nneural TTS based only on CNN alleviate these economic costs of training. In our\nexperiment, the proposed Deep Convolutional TTS was sufficiently trained\novernight (15 hours), using an ordinary gaming PC equipped with two GPUs, while\nthe quality of the synthesized speech was almost acceptable.", "published": "2017-10-24 19:56:32", "link": "http://arxiv.org/abs/1710.08969v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
