{"title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?", "abstract": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning.", "published": "2025-05-14 17:59:35", "link": "http://arxiv.org/abs/2505.09614v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors", "abstract": "The use of Large Language Models (LLMs) in hardware design has taken off in\nrecent years, principally through its incorporation in tools that increase chip\ndesigner productivity. There has been considerable discussion about the use of\nLLMs in RTL specifications of chip designs, for which the two most popular\nlanguages are Verilog and VHDL. LLMs and their use in Verilog design has\nreceived significant attention due to the higher popularity of the language,\nbut little attention so far has been given to VHDL despite its continued\npopularity in the industry. There has also been little discussion about the\nunique needs of organizations that engage in high-performance processor design,\nand techniques to deploy AI solutions in these settings. In this paper, we\ndescribe our journey in developing a Large Language Model (LLM) specifically\nfor the purpose of explaining VHDL code, a task that has particular importance\nin an organization with decades of experience and assets in high-performance\nprocessor design. We show how we developed test sets specific to our needs and\nused them for evaluating models as we performed extended pretraining (EPT) of a\nbase LLM. Expert evaluation of the code explanations produced by the EPT model\nincreased to 69% compared to a base model rating of 43%. We further show how we\ndeveloped an LLM-as-a-judge to gauge models similar to expert evaluators. This\nled us to deriving and evaluating a host of new models, including an\ninstruction-tuned version of the EPT model with an expected expert evaluator\nrating of 71%. Our experiments also indicate that with the potential use of\nnewer base models, this rating can be pushed to 85% and beyond. We conclude\nwith a discussion on further improving the quality of hardware design LLMs\nusing exciting new developments in the Generative AI world.", "published": "2025-05-14 17:58:40", "link": "http://arxiv.org/abs/2505.09610v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models", "abstract": "Large Language Models (LLMs) are predominantly trained and aligned in ways\nthat reinforce Western-centric epistemologies and socio-cultural norms, leading\nto cultural homogenization and limiting their ability to reflect global\ncivilizational plurality. Existing benchmarking frameworks fail to adequately\ncapture this bias, as they rely on rigid, closed-form assessments that overlook\nthe complexity of cultural inclusivity. To address this, we introduce\nWorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity\n(GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our\napproach is grounded in the Multiplex Worldview proposed by Senturk et al.,\nwhich distinguishes between Uniplex models, reinforcing cultural\nhomogenization, and Multiplex models, which integrate diverse perspectives.\nWorldView-Bench measures Cultural Polarization, the exclusion of alternative\nperspectives, through free-form generative evaluation rather than conventional\ncategorical benchmarks. We implement applied multiplexity through two\nintervention strategies: (1) Contextually-Implemented Multiplex LLMs, where\nsystem prompts embed multiplexity principles, and (2) Multi-Agent System\n(MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing\ndistinct cultural perspectives collaboratively generate responses. Our results\ndemonstrate a significant increase in Perspectives Distribution Score (PDS)\nentropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs,\nalongside a shift toward positive sentiment (67.7%) and enhanced cultural\nbalance. These findings highlight the potential of multiplex-aware AI\nevaluation in mitigating cultural bias in LLMs, paving the way for more\ninclusive and ethically aligned AI systems.", "published": "2025-05-14 17:43:40", "link": "http://arxiv.org/abs/2505.09595v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "primary_category": "cs.CL"}
{"title": "PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning", "abstract": "Parameter-efficient fine-tuning (PEFT) methods have shown promise in adapting\nlarge language models, yet existing approaches exhibit counter-intuitive\nphenomena: integrating router into prompt tuning (PT) increases training\nefficiency yet does not improve performance universally; parameter reduction\nthrough matrix decomposition can improve performance in specific domains.\nMotivated by these observations and the modular nature of PT, we propose\nPT-MoE, a novel framework that integrates matrix decomposition with\nmixture-of-experts (MoE) routing for efficient PT. Results across 17 datasets\ndemonstrate that PT-MoE achieves state-of-the-art performance in both question\nanswering (QA) and mathematical problem solving tasks, improving F1 score by\n1.49 points over PT and 2.13 points over LoRA in QA tasks, while enhancing\nmathematical accuracy by 10.75 points over PT and 0.44 points over LoRA, all\nwhile using 25% fewer parameters than LoRA. Our analysis reveals that while PT\nmethods generally excel in QA tasks and LoRA-based methods in math datasets,\nthe integration of matrix decomposition and MoE in PT-MoE yields complementary\nbenefits: decomposition enables efficient parameter sharing across experts\nwhile MoE provides dynamic adaptation, collectively enabling PT-MoE to\ndemonstrate cross-task consistency and generalization abilities. These\nfindings, along with ablation studies on routing mechanisms and architectural\ncomponents, provide insights for future PEFT methods.", "published": "2025-05-14 16:16:36", "link": "http://arxiv.org/abs/2505.09519v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "abstract": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques.", "published": "2025-05-14 14:44:30", "link": "http://arxiv.org/abs/2505.09436v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Multilingual Machine Translation with Quantum Encoder Decoder Attention-based Convolutional Variational Circuits", "abstract": "Cloud-based multilingual translation services like Google Translate and\nMicrosoft Translator achieve state-of-the-art translation capabilities. These\nservices inherently use large multilingual language models such as GRU, LSTM,\nBERT, GPT, T5, or similar encoder-decoder architectures with attention\nmechanisms as the backbone. Also, new age natural language systems, for\ninstance ChatGPT and DeepSeek, have established huge potential in multiple\ntasks in natural language processing. At the same time, they also possess\noutstanding multilingual translation capabilities. However, these models use\nthe classical computing realm as a backend. QEDACVC (Quantum Encoder Decoder\nAttention-based Convolutional Variational Circuits) is an alternate solution\nthat explores the quantum computing realm instead of the classical computing\nrealm to study and demonstrate multilingual machine translation. QEDACVC\nintroduces the quantum encoder-decoder architecture that simulates and runs on\nquantum computing hardware via quantum convolution, quantum pooling, quantum\nvariational circuit, and quantum attention as software alterations. QEDACVC\nachieves an Accuracy of 82% when trained on the OPUS dataset for English,\nFrench, German, and Hindi corpora for multilingual translations.", "published": "2025-05-14 14:04:44", "link": "http://arxiv.org/abs/2505.09407v1", "categories": ["cs.CL", "cs.AI", "cs.ET"], "primary_category": "cs.CL"}
{"title": "Qwen3 Technical Report", "abstract": "In this work, we present Qwen3, the latest version of the Qwen model family.\nQwen3 comprises a series of large language models (LLMs) designed to advance\nperformance, efficiency, and multilingual capabilities. The Qwen3 series\nincludes models of both dense and Mixture-of-Expert (MoE) architectures, with\nparameter scales ranging from 0.6 to 235 billion. A key innovation in Qwen3 is\nthe integration of thinking mode (for complex, multi-step reasoning) and\nnon-thinking mode (for rapid, context-driven responses) into a unified\nframework. This eliminates the need to switch between different models--such as\nchat-optimized models (e.g., GPT-4o) and dedicated reasoning models (e.g.,\nQwQ-32B)--and enables dynamic mode switching based on user queries or chat\ntemplates. Meanwhile, Qwen3 introduces a thinking budget mechanism, allowing\nusers to allocate computational resources adaptively during inference, thereby\nbalancing latency and performance based on task complexity. Moreover, by\nleveraging the knowledge from the flagship models, we significantly reduce the\ncomputational resources required to build smaller-scale models, while ensuring\ntheir highly competitive performance. Empirical evaluations demonstrate that\nQwen3 achieves state-of-the-art results across diverse benchmarks, including\ntasks in code generation, mathematical reasoning, agent tasks, etc.,\ncompetitive against larger MoE models and proprietary models. Compared to its\npredecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119\nlanguages and dialects, enhancing global accessibility through improved\ncross-lingual understanding and generation capabilities. To facilitate\nreproducibility and community-driven research and development, all Qwen3 models\nare publicly accessible under Apache 2.0.", "published": "2025-05-14 13:41:34", "link": "http://arxiv.org/abs/2505.09388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs", "abstract": "We observe a novel phenomenon, contextual entrainment, across a wide range of\nlanguage models (LMs) and prompt settings, providing a new mechanistic\nperspective on how LMs become distracted by ``irrelevant'' contextual\ninformation in the input prompt. Specifically, LMs assign significantly higher\nlogits (or probabilities) to any tokens that have previously appeared in the\ncontext prompt, even for random tokens. This suggests that contextual\nentrainment is a mechanistic phenomenon, occurring independently of the\nrelevance or semantic relation of the tokens to the question or the rest of the\nsentence. We find statistically significant evidence that the magnitude of\ncontextual entrainment is influenced by semantic factors. Counterfactual\nprompts have a greater effect compared to factual ones, suggesting that while\ncontextual entrainment is a mechanistic phenomenon, it is modulated by semantic\nfactors.\n  We hypothesise that there is a circuit of attention heads -- the entrainment\nheads -- that corresponds to the contextual entrainment phenomenon. Using a\nnovel entrainment head discovery method based on differentiable masking, we\nidentify these heads across various settings. When we ``turn off'' these heads,\ni.e., set their outputs to zero, the effect of contextual entrainment is\nsignificantly attenuated, causing the model to generate output that capitulates\nto what it would produce if no distracting context were provided. Our discovery\nof contextual entrainment, along with our investigation into LM distraction via\nthe entrainment heads, marks a key step towards the mechanistic analysis and\nmitigation of the distraction problem.", "published": "2025-05-14 12:33:05", "link": "http://arxiv.org/abs/2505.09338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging", "abstract": "Augmenting large language models (LLMs) with external retrieval has become a\nstandard method to address their inherent knowledge cutoff limitations.\nHowever, traditional retrieval-augmented generation methods employ static,\npre-inference retrieval strategies, making them inadequate for complex tasks\ninvolving ambiguous, multi-step, or evolving information needs. Recent advances\nin test-time scaling techniques have demonstrated significant potential in\nenabling LLMs to dynamically interact with external tools, motivating the shift\ntoward adaptive inference-time retrieval. Inspired by Information Foraging\nTheory (IFT), we propose InForage, a reinforcement learning framework that\nformalizes retrieval-augmented reasoning as a dynamic information-seeking\nprocess. Unlike existing approaches, InForage explicitly rewards intermediate\nretrieval quality, encouraging LLMs to iteratively gather and integrate\ninformation through adaptive search behaviors. To facilitate training, we\nconstruct a human-guided dataset capturing iterative search and reasoning\ntrajectories for complex, real-world web tasks. Extensive evaluations across\ngeneral question answering, multi-hop reasoning tasks, and a newly developed\nreal-time web QA dataset demonstrate InForage's superior performance over\nbaseline methods. These results highlight InForage's effectiveness in building\nrobust, adaptive, and efficient reasoning agents.", "published": "2025-05-14 12:13:38", "link": "http://arxiv.org/abs/2505.09316v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Scalable Unsupervised Framework for multi-aspect labeling of Multilingual and Multi-Domain Review Data", "abstract": "Effectively analyzing online review data is essential across industries.\nHowever, many existing studies are limited to specific domains and languages or\ndepend on supervised learning approaches that require large-scale labeled\ndatasets. To address these limitations, we propose a multilingual, scalable,\nand unsupervised framework for cross-domain aspect detection. This framework is\ndesigned for multi-aspect labeling of multilingual and multi-domain review\ndata. In this study, we apply automatic labeling to Korean and English review\ndatasets spanning various domains and assess the quality of the generated\nlabels through extensive experiments. Aspect category candidates are first\nextracted through clustering, and each review is then represented as an\naspect-aware embedding vector using negative sampling. To evaluate the\nframework, we conduct multi-aspect labeling and fine-tune several pretrained\nlanguage models to measure the effectiveness of the automatically generated\nlabels. Results show that these models achieve high performance, demonstrating\nthat the labels are suitable for training. Furthermore, comparisons with\npublicly available large language models highlight the framework's superior\nconsistency and scalability when processing large-scale data. A human\nevaluation also confirms that the quality of the automatic labels is comparable\nto those created manually. This study demonstrates the potential of a robust\nmulti-aspect labeling approach that overcomes limitations of supervised methods\nand is adaptable to multilingual, multi-domain environments. Future research\nwill explore automatic review summarization and the integration of artificial\nintelligence agents to further improve the efficiency and depth of review\nanalysis.", "published": "2025-05-14 11:11:17", "link": "http://arxiv.org/abs/2505.09286v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How an unintended Side Effect of a Research Project led to Boosting the Power of UML", "abstract": "This paper describes the design, implementation and use of a new UML modeling\ntool that represents a significant advance over conventional tools. Among other\nthings, it allows the integration of class diagrams and object diagrams as well\nas the execution of objects. This not only enables new software architectures\ncharacterized by the integration of software with corresponding object models,\nbut is also ideal for use in teaching, as it provides students with a\nparticularly stimulating learning experience. A special feature of the project\nis that it has emerged from a long-standing international research project,\nwhich is aimed at a comprehensive multi-level architecture. The project is\ntherefore an example of how research can lead to valuable results that arise as\na side effect of other work.", "published": "2025-05-14 10:38:37", "link": "http://arxiv.org/abs/2505.09269v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases", "abstract": "In many real-world settings, machine learning models and interactive systems\nhave access to both structured knowledge, e.g., knowledge graphs or tables, and\nunstructured content, e.g., natural language documents. However, most rely on\neither. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking\nunstructured content to nodes within structured data, thereby enabling new\nstrategies for knowledge access and use. In this work, we present\nFocusedRetriever, a modular SKB-based framework for multi-hop question\nanswering. It integrates components (VSS-based entity search, LLM-based\ngeneration of Cypher queries and pairwise re-ranking) in a way that enables it\nto outperform state-of-the-art methods across all three STaRK benchmark test\nsets, covering diverse domains and multiple performance metrics. The average\nfirst-hit rate exceeds that of the second-best method by 25.7%.\nFocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to\nextract relational facts and entity attributes from unstructured text, (2) node\nset joins to filter answer candidates based on these extracted triplets and\nconstraints, (3) vector similarity search to retrieve and rank relevant\nunstructured content, and (4) the contextual capabilities of LLMs to finally\nrank the top-k answers. For generality, we only incorporate base LLMs in\nFocusedRetriever in our evaluation. However, our analysis of intermediate\nresults highlights several opportunities for further upgrades including\nfinetuning. The source code is publicly available at\nhttps://github.com/kramerlab/FocusedRetriever .", "published": "2025-05-14 09:35:56", "link": "http://arxiv.org/abs/2505.09246v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Ornithologist: Towards Trustworthy \"Reasoning\" about Central Bank Communications", "abstract": "I develop Ornithologist, a weakly-supervised textual classification system\nand measure the hawkishness and dovishness of central bank text. Ornithologist\nuses ``taxonomy-guided reasoning'', guiding a large language model with\nhuman-authored decision trees. This increases the transparency and\nexplainability of the system and makes it accessible to non-experts. It also\nreduces hallucination risk. Since it requires less supervision than traditional\nclassification systems, it can more easily be applied to other problems or\nsources of text (e.g. news) without much modification. Ornithologist\nmeasurements of hawkishness and dovishness of RBA communication carry\ninformation about the future of the cash rate path and of market expectations.", "published": "2025-05-14 02:36:26", "link": "http://arxiv.org/abs/2505.09083v1", "categories": ["econ.GN", "cs.CL", "q-fin.EC", "J.4; I.2.7"], "primary_category": "econ.GN"}
{"title": "CEC-Zero: Chinese Error Correction Solution Based on LLM", "abstract": "Recent advancements in large language models (LLMs) demonstrate exceptional\nChinese text processing capabilities, particularly in Chinese Spelling\nCorrection (CSC). While LLMs outperform traditional BERT-based models in\naccuracy and robustness, challenges persist in reliability and generalization.\nThis paper proposes CEC-Zero, a novel reinforcement learning (RL) framework\nenabling LLMs to self-correct through autonomous error strategy learning\nwithout external supervision. By integrating RL with LLMs' generative power,\nthe method eliminates dependency on annotated data or auxiliary models.\nExperiments reveal RL-enhanced LLMs achieve industry-viable accuracy and\nsuperior cross-domain generalization, offering a scalable solution for\nreliability optimization in Chinese NLP applications. This breakthrough\nfacilitates LLM deployment in practical Chinese text correction scenarios while\nestablishing a new paradigm for self-improving language models.", "published": "2025-05-14 02:35:47", "link": "http://arxiv.org/abs/2505.09082v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment", "abstract": "This paper introduces S-DAT (Synthetic-Divergent Association Task), a\nscalable, multilingual framework for automated assessment of divergent thinking\n(DT) -a core component of human creativity. Traditional creativity assessments\nare often labor-intensive, language-specific, and reliant on subjective human\nratings, limiting their scalability and cross-cultural applicability. In\ncontrast, S-DAT leverages large language models and advanced multilingual\nembeddings to compute semantic distance -- a language-agnostic proxy for DT. We\nevaluate S-DAT across eleven diverse languages, including English, Spanish,\nGerman, Russian, Hindi, and Japanese (Kanji, Hiragana, Katakana), demonstrating\nrobust and consistent scoring across linguistic contexts. Unlike prior DAT\napproaches, the S-DAT shows convergent validity with other DT measures and\ncorrect discriminant validity with convergent thinking. This cross-linguistic\nflexibility allows for more inclusive, global-scale creativity research,\naddressing key limitations of earlier approaches. S-DAT provides a powerful\ntool for fairer, more comprehensive evaluation of cognitive flexibility in\ndiverse populations and can be freely assessed online:\nhttps://sdat.iol.zib.de/.", "published": "2025-05-14 02:08:40", "link": "http://arxiv.org/abs/2505.09068v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias", "abstract": "Large Language Models (LLMs) represent a major step toward artificial general\nintelligence, significantly advancing our ability to interact with technology.\nWhile LLMs perform well on Natural Language Processing tasks -- such as\ntranslation, generation, code writing, and summarization -- questions remain\nabout their output similarity, variability, and ethical implications. For\ninstance, how similar are texts generated by the same model? How does this\ncompare across different models? And which models best uphold ethical\nstandards? To investigate, we used 5{,}000 prompts spanning diverse tasks like\ngeneration, explanation, and rewriting. This resulted in approximately 3\nmillion texts from 12 LLMs, including proprietary and open-source systems from\nOpenAI, Google, Microsoft, Meta, and Mistral. Key findings include: (1) outputs\nfrom the same LLM are more similar to each other than to human-written texts;\n(2) models like WizardLM-2-8x22b generate highly similar outputs, while GPT-4\nproduces more varied responses; (3) LLM writing styles differ significantly,\nwith Llama 3 and Mistral showing higher similarity, and GPT-4 standing out for\ndistinctiveness; (4) differences in vocabulary and tone underscore the\nlinguistic uniqueness of LLM-generated content; (5) some LLMs demonstrate\ngreater gender balance and reduced bias. These results offer new insights into\nthe behavior and diversity of LLM outputs, helping guide future development and\nethical evaluation.", "published": "2025-05-14 01:21:46", "link": "http://arxiv.org/abs/2505.09056v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Atomic Consistency Preference Optimization for Long-Form Question Answering", "abstract": "Large Language Models (LLMs) frequently produce factoid hallucinations -\nplausible yet incorrect answers. A common mitigation strategy is model\nalignment, which improves factual accuracy by training on curated factual and\nnon-factual pairs. However, this approach often relies on a stronger model\n(e.g., GPT-4) or an external knowledge base to assess factual correctness,\nwhich may not always be accessible. To address this, we propose Atomic\nConsistency Preference Optimization (ACPO), a self-supervised preference-tuning\nmethod that enhances factual accuracy without external supervision. ACPO\nleverages atomic consistency signals, i.e., the agreement of individual facts\nacross multiple stochastic responses, to identify high- and low-quality data\npairs for model alignment. By eliminating the need for costly GPT calls, ACPO\nprovides a scalable and efficient approach to improving factoid\nquestion-answering. Despite being self-supervised, empirical results\ndemonstrate that ACPO outperforms FactAlign, a strong supervised alignment\nbaseline, by 1.95 points on the LongFact and BioGen datasets, highlighting its\neffectiveness in enhancing factual reliability without relying on external\nmodels or knowledge bases.", "published": "2025-05-14 00:39:47", "link": "http://arxiv.org/abs/2505.09039v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference", "abstract": "As large language models (LLMs) spread across industries, understanding their\nenvironmental footprint at the inference level is no longer optional; it is\nessential. However, most existing studies exclude proprietary models, overlook\ninfrastructural variability and overhead, or focus solely on training, even as\ninference increasingly dominates AI's environmental impact. To bridge this gap,\nthis paper introduces a novel infrastructure-aware benchmarking framework for\nquantifying the environmental footprint of LLM inference across 30\nstate-of-the-art models as deployed in commercial data centers. Our framework\ncombines public API performance data with region-specific environmental\nmultipliers and statistical inference of hardware configurations. We\nadditionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank\nmodels by performance relative to environmental cost. Our results show that o3\nand DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33\nWh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and\nthat Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short\nGPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results\nin substantial annual environmental impacts. These include electricity use\ncomparable to 35,000 U.S. homes, freshwater evaporation matching the annual\ndrinking needs of 1.2 million people, and carbon emissions requiring a\nChicago-sized forest to offset. These findings illustrate a growing paradox:\nalthough individual queries are efficient, their global scale drives\ndisproportionate resource consumption. Our study provides a standardized,\nempirically grounded methodology for benchmarking the sustainability of LLM\ndeployments, laying a foundation for future environmental accountability in AI\ndevelopment and sustainability standards.", "published": "2025-05-14 17:47:00", "link": "http://arxiv.org/abs/2505.09598v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Variational Visual Question Answering", "abstract": "Despite remarkable progress in multimodal models for Visual Question\nAnswering (VQA), there remain major reliability concerns because the models can\noften be overconfident and miscalibrated, especially in out-of-distribution\n(OOD) settings. Plenty has been done to address such issues for unimodal\nmodels, but little work exists for multimodal cases. Here, we address\nunreliability in multimodal models by proposing a Variational VQA approach.\nSpecifically, instead of fine-tuning vision-language models by using AdamW, we\nemploy a recently proposed variational algorithm called IVON, which yields a\nposterior distribution over model parameters. Through extensive experiments, we\nshow that our approach improves calibration and abstentions without sacrificing\nthe accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce\nExpected Calibration Error by more than 50% compared to the AdamW baseline and\nraise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of\ndistribution shifts, the performance gain is even higher, achieving 8% Coverage\n(@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we\npresent variational learning as a viable option to enhance the reliability of\nmultimodal models.", "published": "2025-05-14 17:40:22", "link": "http://arxiv.org/abs/2505.09591v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Ethics and Persuasion in Reinforcement Learning from Human Feedback: A Procedural Rhetorical Approach", "abstract": "Since 2022, versions of generative AI chatbots such as ChatGPT and Claude\nhave been trained using a specialized technique called Reinforcement Learning\nfrom Human Feedback (RLHF) to fine-tune language model output using feedback\nfrom human annotators. As a result, the integration of RLHF has greatly\nenhanced the outputs of these large language models (LLMs) and made the\ninteractions and responses appear more \"human-like\" than those of previous\nversions using only supervised learning. The increasing convergence of human\nand machine-written text has potentially severe ethical, sociotechnical, and\npedagogical implications relating to transparency, trust, bias, and\ninterpersonal relations. To highlight these implications, this paper presents a\nrhetorical analysis of some of the central procedures and processes currently\nbeing reshaped by RLHF-enhanced generative AI chatbots: upholding language\nconventions, information seeking practices, and expectations for social\nrelationships. Rhetorical investigations of generative AI and LLMs have, to\nthis point, focused largely on the persuasiveness of the content generated.\nUsing Ian Bogost's concept of procedural rhetoric, this paper shifts the site\nof rhetorical investigation from content analysis to the underlying mechanisms\nof persuasion built into RLHF-enhanced LLMs. In doing so, this theoretical\ninvestigation opens a new direction for further inquiry in AI ethics that\nconsiders how procedures rerouted through AI-driven technologies might\nreinforce hegemonic language use, perpetuate biases, decontextualize learning,\nand encroach upon human relationships. It will therefore be of interest to\neducators, researchers, scholars, and the growing number of users of generative\nAI chatbots.", "published": "2025-05-14 17:29:19", "link": "http://arxiv.org/abs/2505.09576v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset", "abstract": "Unifying image understanding and generation has gained growing attention in\nrecent research on multimodal models. Although design choices for image\nunderstanding have been extensively studied, the optimal model architecture and\ntraining recipe for a unified framework with image generation remain\nunderexplored. Motivated by the strong potential of autoregressive and\ndiffusion models for high-quality generation and scalability, we conduct a\ncomprehensive study of their use in unified multimodal settings, with emphasis\non image representations, modeling objectives, and training strategies.\nGrounded in these investigations, we introduce a novel approach that employs a\ndiffusion transformer to generate semantically rich CLIP image features, in\ncontrast to conventional VAE-based representations. This design yields both\nhigher training efficiency and improved generative quality. Furthermore, we\ndemonstrate that a sequential pretraining strategy for unified models-first\ntraining on image understanding and subsequently on image generation-offers\npractical advantages by preserving image understanding capability while\ndeveloping strong image generation ability. Finally, we carefully curate a\nhigh-quality instruction-tuning dataset BLIP3o-60k for image generation by\nprompting GPT-4o with a diverse set of captions covering various scenes,\nobjects, human gestures, and more. Building on our innovative model design,\ntraining recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art\nunified multimodal models. BLIP3-o achieves superior performance across most of\nthe popular benchmarks spanning both image understanding and generation tasks.\nTo facilitate future research, we fully open-source our models, including code,\nmodel weights, training scripts, and pretraining and instruction tuning\ndatasets.", "published": "2025-05-14 17:11:07", "link": "http://arxiv.org/abs/2505.09568v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using Implicit Neural Representations", "abstract": "High-resolution slice-to-volume reconstruction (SVR) from multiple\nmotion-corrupted low-resolution 2D slices constitutes a critical step in\nimage-based diagnostics of moving subjects, such as fetal brain Magnetic\nResonance Imaging (MRI). Existing solutions struggle with image artifacts and\nsevere subject motion or require slice pre-alignment to achieve satisfying\nreconstruction performance. We propose a novel SVR method to enable fast and\naccurate MRI reconstruction even in cases of severe image and motion\ncorruption. Our approach performs motion correction, outlier handling, and\nsuper-resolution reconstruction with all operations being entirely based on\nimplicit neural representations. The model can be initialized with\ntask-specific priors through fully self-supervised meta-learning on either\nsimulated or real-world data. In extensive experiments including over 480\nreconstructions of simulated and clinical MRI brain data from different\ncenters, we prove the utility of our method in cases of severe subject motion\nand image artifacts. Our results demonstrate improvements in reconstruction\nquality, especially in the presence of severe motion, compared to\nstate-of-the-art methods, and up to 50% reduction in reconstruction time.", "published": "2025-05-14 17:07:37", "link": "http://arxiv.org/abs/2505.09565v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Learning Long-Context Diffusion Policies via Past-Token Prediction", "abstract": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x.", "published": "2025-05-14 17:00:47", "link": "http://arxiv.org/abs/2505.09561v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators", "abstract": "End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered\nsignificant attention in the speech domain. However, the evaluation of spoken\ndialogue models' conversational performance has largely been overlooked. This\nis primarily due to the intelligent chatbots convey a wealth of non-textual\ninformation which cannot be easily measured using text-based language models\nlike ChatGPT. To address this gap, we propose WavReward, a reward feedback\nmodel based on audio language models that can evaluate both the IQ and EQ of\nspoken dialogue systems with speech input. Specifically, 1) based on audio\nlanguage models, WavReward incorporates the deep reasoning process and the\nnonlinear reward mechanism for post-training. By utilizing multi-sample\nfeedback via the reinforcement learning algorithm, we construct a specialized\nevaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a\npreference dataset used to train WavReward. ChatReward-30K includes both\ncomprehension and generation aspects of spoken dialogue models. These scenarios\nspan various tasks, such as text-based chats, nine acoustic attributes of\ninstruction chats, and implicit chats. WavReward outperforms previous\nstate-of-the-art evaluation models across multiple spoken dialogue scenarios,\nachieving a substantial improvement about Qwen2.5-Omni in objective accuracy\nfrom 55.1$\\%$ to 91.5$\\%$. In subjective A/B testing, WavReward also leads by a\nmargin of 83$\\%$. Comprehensive ablation studies confirm the necessity of each\ncomponent of WavReward. All data and code will be publicly at\nhttps://github.com/jishengpeng/WavReward after the paper is accepted.", "published": "2025-05-14 16:54:15", "link": "http://arxiv.org/abs/2505.09558v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs", "abstract": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs. We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments.", "published": "2025-05-14 16:15:58", "link": "http://arxiv.org/abs/2505.09518v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput", "abstract": "In this paper, we introduce Flash-VL 2B, a novel approach to optimizing\nVision-Language Models (VLMs) for real-time applications, targeting ultra-low\nlatency and high throughput without sacrificing accuracy. Leveraging advanced\narchitectural enhancements and efficient computational strategies, Flash-VL 2B\nis designed to maximize throughput by reducing processing time while\nmaintaining competitive performance across multiple vision-language benchmarks.\nOur approach includes tailored architectural choices, token compression\nmechanisms, data curation, training schemes, and a novel image processing\ntechnique called implicit semantic stitching that effectively balances\ncomputational load and model performance. Through extensive evaluations on 11\nstandard VLM benchmarks, we demonstrate that Flash-VL 2B achieves\nstate-of-the-art results in both speed and accuracy, making it a promising\nsolution for deployment in resource-constrained environments and large-scale\nreal-time applications.", "published": "2025-05-14 15:45:17", "link": "http://arxiv.org/abs/2505.09498v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Preserving Plasticity in Continual Learning with Adaptive Linearity Injection", "abstract": "Loss of plasticity in deep neural networks is the gradual reduction in a\nmodel's capacity to incrementally learn and has been identified as a key\nobstacle to learning in non-stationary problem settings. Recent work has shown\nthat deep linear networks tend to be resilient towards loss of plasticity.\nMotivated by this observation, we propose Adaptive Linearization (AdaLin), a\ngeneral approach that dynamically adapts each neuron's activation function to\nmitigate plasticity loss. Unlike prior methods that rely on regularization or\nperiodic resets, AdaLin equips every neuron with a learnable parameter and a\ngating mechanism that injects linearity into the activation function based on\nits gradient flow. This adaptive modulation ensures sufficient gradient signal\nand sustains continual learning without introducing additional hyperparameters\nor requiring explicit task boundaries. When used with conventional activation\nfunctions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can\nsignificantly improve performance on standard benchmarks, including Random\nLabel and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split\nCIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such\nas class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in\nmitigating plasticity loss in off-policy reinforcement learning agents. We\nperform a systematic set of ablations that show that neuron-level adaptation is\ncrucial for good performance and analyze a number of metrics in the network\nthat might be correlated to loss of plasticity.", "published": "2025-05-14 15:36:51", "link": "http://arxiv.org/abs/2505.09486v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities", "abstract": "The integration of foundation models (FMs) into robotics has enabled robots\nto understand natural language and reason about the semantics in their\nenvironments. However, existing FM-enabled robots primary operate in\nclosed-world settings, where the robot is given a full prior map or has a full\nview of its workspace. This paper addresses the deployment of FM-enabled robots\nin the field, where missions often require a robot to operate in large-scale\nand unstructured environments. To effectively accomplish these missions, robots\nmust actively explore their environments, navigate obstacle-cluttered terrain,\nhandle unexpected sensor inputs, and operate with compute constraints. We\ndiscuss recent deployments of SPINE, our LLM-enabled autonomy framework, in\nfield robotic settings. To the best of our knowledge, we present the first\ndemonstration of large-scale LLM-enabled robot planning in unstructured\nenvironments with several kilometers of missions. SPINE is agnostic to a\nparticular LLM, which allows us to distill small language models capable of\nrunning onboard size, weight and power (SWaP) limited platforms. Via\npreliminary model distillation work, we then present the first language-driven\nUAV planner using on-device language models. We conclude our paper by proposing\nseveral promising directions for future research.", "published": "2025-05-14 15:28:43", "link": "http://arxiv.org/abs/2505.09477v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A 2D Semantic-Aware Position Encoding for Vision Transformers", "abstract": "Vision transformers have demonstrated significant advantages in computer\nvision tasks due to their ability to capture long-range dependencies and\ncontextual relationships through self-attention. However, existing position\nencoding techniques, which are largely borrowed from natural language\nprocessing, fail to effectively capture semantic-aware positional relationships\nbetween image patches. Traditional approaches like absolute position encoding\nand relative position encoding primarily focus on 1D linear position\nrelationship, often neglecting the semantic similarity between distant yet\ncontextually related patches. These limitations hinder model generalization,\ntranslation equivariance, and the ability to effectively handle repetitive or\nstructured patterns in images. In this paper, we propose 2-Dimensional\nSemantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding\nmethod with semantic awareness that dynamically adapts position representations\nby leveraging local content instead of fixed linear position relationship or\nspatial coordinates. Our method enhances the model's ability to generalize\nacross varying image resolutions and scales, improves translation equivariance,\nand better aggregates features for visually similar but spatially distant\npatches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the\ngap between position encoding and perceptual similarity, thereby improving\nperformance on computer vision tasks.", "published": "2025-05-14 15:17:34", "link": "http://arxiv.org/abs/2505.09466v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Quantum state-agnostic work extraction (almost) without dissipation", "abstract": "We investigate work extraction protocols designed to transfer the maximum\npossible energy to a battery using sequential access to $N$ copies of an\nunknown pure qubit state. The core challenge is designing interactions to\noptimally balance two competing goals: charging of the battery optimally using\nthe qubit in hand, and acquiring more information by qubit to improve energy\nharvesting in subsequent rounds. Here, we leverage exploration-exploitation\ntrade-off in reinforcement learning to develop adaptive strategies achieving\nenergy dissipation that scales only poly-logarithmically in $N$. This\nrepresents an exponential improvement over current protocols based on full\nstate tomography.", "published": "2025-05-14 15:07:58", "link": "http://arxiv.org/abs/2505.09456v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Evaluating GPT- and Reasoning-based Large Language Models on Physics Olympiad Problems: Surpassing Human Performance and Implications for Educational Assessment", "abstract": "Large language models (LLMs) are now widely accessible, reaching learners at\nall educational levels. This development has raised concerns that their use may\ncircumvent essential learning processes and compromise the integrity of\nestablished assessment formats. In physics education, where problem solving\nplays a central role in instruction and assessment, it is therefore essential\nto understand the physics-specific problem-solving capabilities of LLMs. Such\nunderstanding is key to informing responsible and pedagogically sound\napproaches to integrating LLMs into instruction and assessment. This study\ntherefore compares the problem-solving performance of a general-purpose LLM\n(GPT-4o, using varying prompting techniques) and a reasoning-optimized model\n(o1-preview) with that of participants of the German Physics Olympiad, based on\na set of well-defined Olympiad problems. In addition to evaluating the\ncorrectness of the generated solutions, the study analyzes characteristic\nstrengths and limitations of LLM-generated solutions. The findings of this\nstudy indicate that both tested LLMs (GPT-4o and o1-preview) demonstrate\nadvanced problem-solving capabilities on Olympiad-type physics problems, on\naverage outperforming the human participants. Prompting techniques had little\neffect on GPT-4o's performance, while o1-preview almost consistently\noutperformed both GPT-4o and the human benchmark. Based on these findings, the\nstudy discusses implications for the design of summative and formative\nassessment in physics education, including how to uphold assessment integrity\nand support students in critically engaging with LLMs.", "published": "2025-05-14 14:46:32", "link": "http://arxiv.org/abs/2505.09438v1", "categories": ["physics.ed-ph", "cs.AI"], "primary_category": "physics.ed-ph"}
{"title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records", "abstract": "Pre-training on image-text colonoscopy records offers substantial potential\nfor improving endoscopic image analysis, but faces challenges including\nnon-informative background images, complex medical terminology, and ambiguous\nmulti-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised\nframework that enhances Contrastive Language-Image Pre-training (CLIP) for this\ndomain. Endo-CLIP's three-stage framework--cleansing, attunement, and\nunification--addresses these challenges by (1) removing background frames, (2)\nleveraging large language models to extract clinical attributes for\nfine-grained contrastive learning, and (3) employing patient-level\ncross-attention to resolve multi-polyp ambiguities. Extensive experiments\ndemonstrate that Endo-CLIP significantly outperforms state-of-the-art\npre-training methods in zero-shot and few-shot polyp detection and\nclassification, paving the way for more accurate and clinically relevant\nendoscopic analysis.", "published": "2025-05-14 14:43:31", "link": "http://arxiv.org/abs/2505.09435v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Counterfactual Strategies for Markov Decision Processes", "abstract": "Counterfactuals are widely used in AI to explain how minimal changes to a\nmodel's input can lead to a different output. However, established methods for\ncomputing counterfactuals typically focus on one-step decision-making, and are\nnot directly applicable to sequential decision-making tasks. This paper fills\nthis gap by introducing counterfactual strategies for Markov Decision Processes\n(MDPs). During MDP execution, a strategy decides which of the enabled actions\n(with known probabilistic effects) to execute next. Given an initial strategy\nthat reaches an undesired outcome with a probability above some limit, we\nidentify minimal changes to the initial strategy to reduce that probability\nbelow the limit. We encode such counterfactual strategies as solutions to\nnon-linear optimization problems, and further extend our encoding to synthesize\ndiverse counterfactual strategies. We evaluate our approach on four real-world\ndatasets and demonstrate its practical viability in sophisticated sequential\ndecision-making tasks.", "published": "2025-05-14 14:07:27", "link": "http://arxiv.org/abs/2505.09412v1", "categories": ["cs.AI", "I.2.m"], "primary_category": "cs.AI"}
{"title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "abstract": "The rapid rise of large language models (LLMs) has shifted artificial\nintelligence (AI) research toward agentic systems, motivating the use of weaker\nand more flexible notions of agency. However, this shift raises key questions\nabout the extent to which LLM-based agents replicate human strategic reasoning,\nparticularly in game-theoretic settings. In this context, we examine the role\nof agentic sophistication in shaping artificial reasoners' performance by\nevaluating three agent designs: a simple game-theoretic model, an unstructured\nLLM-as-agent model, and an LLM integrated into a traditional agentic framework.\nUsing guessing games as a testbed, we benchmarked these agents against human\nparticipants across general reasoning patterns and individual role-based\nobjectives. Furthermore, we introduced obfuscated game scenarios to assess\nagents' ability to generalise beyond training distributions. Our analysis,\ncovering over 2000 reasoning samples across 25 agent configurations, shows that\nhuman-inspired cognitive structures can enhance LLM agents' alignment with\nhuman strategic behaviour. Still, the relationship between agentic design\ncomplexity and human-likeness is non-linear, highlighting a critical dependence\non underlying LLM capabilities and suggesting limits to simple architectural\naugmentation.", "published": "2025-05-14 13:51:24", "link": "http://arxiv.org/abs/2505.09396v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting", "abstract": "Typhoon trajectory forecasting is essential for disaster preparedness but\nremains computationally demanding due to the complexity of atmospheric dynamics\nand the resource requirements of deep learning models. Quantum-Train (QT), a\nhybrid quantum-classical framework that leverages quantum neural networks\n(QNNs) to generate trainable parameters exclusively during training,\neliminating the need for quantum hardware at inference time. Building on QT's\nsuccess across multiple domains, including image classification, reinforcement\nlearning, flood prediction, and large language model (LLM) fine-tuning, we\nintroduce Quantum Parameter Adaptation (QPA) for efficient typhoon forecasting\nmodel learning. Integrated with an Attention-based Multi-ConvGRU model, QPA\nenables parameter-efficient training while maintaining predictive accuracy.\nThis work represents the first application of quantum machine learning (QML) to\nlarge-scale typhoon trajectory prediction, offering a scalable and\nenergy-efficient approach to climate modeling. Our results demonstrate that QPA\nsignificantly reduces the number of trainable parameters while preserving\nperformance, making high-performance forecasting more accessible and\nsustainable through hybrid quantum-classical learning.", "published": "2025-05-14 13:50:44", "link": "http://arxiv.org/abs/2505.09395v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units", "abstract": "Sparse wearable inertial measurement units (IMUs) have gained popularity for\nestimating 3D human motion. However, challenges such as pose ambiguity, data\ndrift, and limited adaptability to diverse bodies persist. To address these\nissues, we propose UMotion, an uncertainty-driven, online fusing-all state\nestimation framework for 3D human shape and pose estimation, supported by six\nintegrated, body-worn ultra-wideband (UWB) distance sensors with IMUs. UWB\nsensors measure inter-node distances to infer spatial relationships, aiding in\nresolving pose ambiguities and body shape variations when combined with\nanthropometric data. Unfortunately, IMUs are prone to drift, and UWB sensors\nare affected by body occlusions. Consequently, we develop a tightly coupled\nUnscented Kalman Filter (UKF) framework that fuses uncertainties from sensor\ndata and estimated human motion based on individual body shape. The UKF\niteratively refines IMU and UWB measurements by aligning them with uncertain\nhuman motion constraints in real-time, producing optimal estimates for each.\nExperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of UMotion in stabilizing sensor data and the improvement over\nstate of the art in pose accuracy.", "published": "2025-05-14 13:48:36", "link": "http://arxiv.org/abs/2505.09393v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization", "abstract": "Federated semantic segmentation enables pixel-level classification in images\nthrough collaborative learning while maintaining data privacy. However,\nexisting research commonly overlooks the fine-grained class relationships\nwithin the semantic space when addressing heterogeneous problems, particularly\ndomain shift. This oversight results in ambiguities between class\nrepresentation. To overcome this challenge, we propose a novel federated\nsegmentation framework that strikes class consistency, termed FedSaaS.\nSpecifically, we introduce class exemplars as a criterion for both local- and\nglobal-level class representations. On the server side, the uploaded class\nexemplars are leveraged to model class prototypes, which supervise global\nbranch of clients, ensuring alignment with global-level representation. On the\nclient side, we incorporate an adversarial mechanism to harmonize contributions\nof global and local branches, leading to consistent output. Moreover,\nmultilevel contrastive losses are employed on both sides to enforce consistency\nbetween two-level representations in the same semantic space. Extensive\nexperiments on several driving scene segmentation datasets demonstrate that our\nframework outperforms state-of-the-art methods, significantly improving average\nsegmentation accuracy and effectively addressing the class-consistency\nrepresentation problem.", "published": "2025-05-14 13:38:30", "link": "http://arxiv.org/abs/2505.09385v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Voice Timbre Attribute Detection 2025 Challenge Evaluation Plan", "abstract": "Voice timbre refers to the unique quality or character of a person's voice\nthat distinguishes it from others as perceived by human hearing. The Voice\nTimbre Attribute Detection (VtaD) 2025 challenge focuses on explaining the\nvoice timbre attribute in a comparative manner. In this challenge, the human\nimpression of voice timbre is verbalized with a set of sensory descriptors,\nincluding bright, coarse, soft, magnetic, and so on. The timbre is explained\nfrom the comparison between two voices in their intensity within a specific\ndescriptor dimension. The VtaD 2025 challenge starts in May and culminates in a\nspecial proposal at the NCMMSC2025 conference in October 2025 in Zhenjiang,\nChina.", "published": "2025-05-14 13:35:53", "link": "http://arxiv.org/abs/2505.09382v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform", "abstract": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback.", "published": "2025-05-14 13:33:38", "link": "http://arxiv.org/abs/2505.09380v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TensorRL-QAS: Reinforcement learning with tensor networks for scalable quantum architecture search", "abstract": "Variational quantum algorithms hold the promise to address meaningful quantum\nproblems already on noisy intermediate-scale quantum hardware, but they face\nthe challenge of designing quantum circuits that both solve the target problem\nand comply with device limitations. Quantum architecture search (QAS) automates\nthis design process, with reinforcement learning (RL) emerging as a promising\napproach. Yet, RL-based QAS methods encounter significant scalability issues,\nas computational and training costs grow rapidly with the number of qubits,\ncircuit depth, and noise, severely impacting performance. To address these\nchallenges, we introduce $\\textit{TensorRL-QAS}$, a scalable framework that\ncombines tensor network (TN) methods with RL for designing quantum circuits. By\nwarm-starting the architecture search with a matrix product state approximation\nof the target solution, TensorRL-QAS effectively narrows the search space to\nphysically meaningful circuits, accelerating convergence to the desired\nsolution. Tested on several quantum chemistry problems of up to 12-qubit,\nTensorRL-QAS achieves up to a 10-fold reduction in CNOT count and circuit depth\ncompared to baseline methods, while maintaining or surpassing chemical\naccuracy. It reduces function evaluations by up to 100-fold, accelerates\ntraining episodes by up to $98\\%$, and achieves up to $50\\%$ success\nprobability for 10-qubit systems-far exceeding the $<1\\%$ rates of baseline\napproaches. Robustness and versatility are demonstrated both in the noiseless\nand noisy scenarios, where we report a simulation of up to 8-qubit. These\nadvancements establish TensorRL-QAS as a promising candidate for a scalable and\nefficient quantum circuit discovery protocol on near-term quantum hardware.", "published": "2025-05-14 13:23:34", "link": "http://arxiv.org/abs/2505.09371v1", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG"], "primary_category": "quant-ph"}
{"title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks", "abstract": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces.", "published": "2025-05-14 12:40:34", "link": "http://arxiv.org/abs/2505.09344v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures", "abstract": "The rapid scaling of large language models (LLMs) has unveiled critical\nlimitations in current hardware architectures, including constraints in memory\ncapacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3,\ntrained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model\nco-design can effectively address these challenges, enabling cost-efficient\ntraining and inference at scale. This paper presents an in-depth analysis of\nthe DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting\nkey innovations such as Multi-head Latent Attention (MLA) for enhanced memory\nefficiency, Mixture of Experts (MoE) architectures for optimized\ncomputation-communication trade-offs, FP8 mixed-precision training to unlock\nthe full potential of hardware capabilities, and a Multi-Plane Network Topology\nto minimize cluster-level network overhead. Building on the hardware\nbottlenecks encountered during DeepSeek-V3's development, we engage in a\nbroader discussion with academic and industry peers on potential future\nhardware directions, including precise low-precision computation units,\nscale-up and scale-out convergence, and innovations in low-latency\ncommunication fabrics. These insights underscore the critical role of hardware\nand model co-design in meeting the escalating demands of AI workloads, offering\na practical blueprint for innovation in next-generation AI systems.", "published": "2025-05-14 12:39:03", "link": "http://arxiv.org/abs/2505.09343v1", "categories": ["cs.DC", "cs.AI", "cs.AR"], "primary_category": "cs.DC"}
{"title": "Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems", "abstract": "Machine learning is a key tool for Android malware detection, effectively\nidentifying malicious patterns in apps. However, ML-based detectors are\nvulnerable to evasion attacks, where small, crafted changes bypass detection.\nDespite progress in adversarial defenses, the lack of comprehensive evaluation\nframeworks in binary-constrained domains limits understanding of their\nrobustness. We introduce two key contributions. First, Prioritized Binary\nRounding, a technique to convert continuous perturbations into binary feature\nspaces while preserving high attack success and low perturbation size. Second,\nthe sigma-binary attack, a novel adversarial method for binary domains,\ndesigned to achieve attack goals with minimal feature changes. Experiments on\nthe Malscan dataset show that sigma-binary outperforms existing attacks and\nexposes key vulnerabilities in state-of-the-art defenses. Defenses equipped\nwith adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant\nbrittleness, with attack success rates exceeding 90% using fewer than 10\nfeature modifications and reaching 100% with just 20. Adversarially trained\ndefenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small\nbudgets but remains vulnerable to unrestricted perturbations, with attack\nsuccess rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates\nstrong robustness against state-of-the-art gradient-based adversarial attacks\nby maintaining an attack success rate below 16.55%, the sigma-binary attack\nsignificantly outperforms these methods, achieving a 94.56% success rate under\nunrestricted perturbations. These findings highlight the critical need for\nprecise method like sigma-binary to expose hidden vulnerabilities in existing\ndefenses and support the development of more resilient malware detection\nsystems.", "published": "2025-05-14 12:38:43", "link": "http://arxiv.org/abs/2505.09342v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "68", "I.2.1"], "primary_category": "cs.CR"}
{"title": "Access Controls Will Solve the Dual-Use Dilemma", "abstract": "AI safety systems face a dual-use dilemma. Since the same request can be\neither harmless or harmful depending on who made it and why, if the system\nmakes decisions based solely on the request's content, it will refuse some\nlegitimate queries and let pass harmful ones. To address this, we propose a\nconceptual access control framework, based on verified user credentials (such\nas institutional affiliation) and classifiers that assign model outputs to risk\ncategories (such as advanced virology). The system permits responses only when\nthe user's verified credentials match the category's requirements. For\nimplementation of the model output classifiers, we introduce a theoretical\napproach utilizing small, gated expert modules integrated into the generator\nmodel, trained with gradient routing, that enable efficient risk detection\nwithout the capability gap problems of external monitors. While open questions\nremain about the verification mechanisms, risk categories, and the technical\nimplementation, our framework makes the first step toward enabling granular\ngovernance of AI capabilities: verified users gain access to specialized\nknowledge without arbitrary restrictions, while adversaries are blocked from\nit. This contextual approach reconciles model utility with robust safety,\naddressing the dual-use dilemma.", "published": "2025-05-14 12:38:08", "link": "http://arxiv.org/abs/2505.09341v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis", "abstract": "Scaling up model and data size have demonstrated impressive performance\nimprovement over a wide range of tasks. Despite extensive studies on scaling\nbehaviors for general-purpose tasks, medical images exhibit substantial\ndifferences from natural data. It remains unclear the key factors in developing\nmedical vision foundation models at scale due to the absence of an extensive\nunderstanding of scaling behavior in the medical domain. In this paper, we\nexplored the scaling behavior across model sizes, training algorithms, data\nsizes, and imaging modalities in developing scalable medical vision foundation\nmodels by self-supervised learning. To support scalable pretraining, we\nintroduce BioVFM-21M, a large-scale biomedical image dataset encompassing a\nwide range of biomedical image modalities and anatomies. We observed that\nscaling up does provide benefits but varies across tasks. Additional analysis\nreveals several factors correlated with scaling benefits. Finally, we propose\nBioVFM, a large-scale medical vision foundation model pretrained on 21 million\nbiomedical images, which outperforms the previous state-of-the-art foundation\nmodels across 12 medical benchmarks. Our results highlight that while scaling\nup is beneficial for pursuing better performance, task characteristics, data\ndiversity, pretraining methods, and computational efficiency remain critical\nconsiderations for developing scalable medical foundation models.", "published": "2025-05-14 12:25:41", "link": "http://arxiv.org/abs/2505.09329v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Neural Video Compression using 2D Gaussian Splatting", "abstract": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space.", "published": "2025-05-14 12:23:53", "link": "http://arxiv.org/abs/2505.09324v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance", "abstract": "Ensuring fairness is critical when applying artificial intelligence to\nhigh-stakes domains such as healthcare, where predictive models trained on\nimbalanced and demographically skewed data risk exacerbating existing\ndisparities. Federated learning (FL) enables privacy-preserving collaboration\nacross institutions, but remains vulnerable to both algorithmic bias and\nsubgroup imbalance - particularly when multiple sensitive attributes intersect.\nWe propose FedIDA (Fed erated Learning for Imbalance and D isparity A\nwareness), a framework-agnostic method that combines fairness-aware\nregularization with group-conditional oversampling. FedIDA supports multiple\nsensitive attributes and heterogeneous data distributions without altering the\nconvergence behavior of the underlying FL algorithm. We provide theoretical\nanalysis establishing fairness improvement bounds using Lipschitz continuity\nand concentration inequalities, and show that FedIDA reduces the variance of\nfairness metrics across test sets. Empirical results on both benchmark and\nreal-world clinical datasets confirm that FedIDA consistently improves fairness\nwhile maintaining competitive predictive performance, demonstrating its\neffectiveness for equitable and privacy-preserving modeling in healthcare. The\nsource code is available on GitHub.", "published": "2025-05-14 11:22:54", "link": "http://arxiv.org/abs/2505.09295v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "abstract": "This study evaluates and extends the findings made by Piatti et al., who\nintroduced GovSim, a simulation framework designed to assess the cooperative\ndecision-making capabilities of large language models (LLMs) in\nresource-sharing scenarios. By replicating key experiments, we validate claims\nregarding the performance of large models, such as GPT-4-turbo, compared to\nsmaller models. The impact of the universalization principle is also examined,\nwith results showing that large models can achieve sustainable cooperation,\nwith or without the principle, while smaller models fail without it. In\naddition, we provide multiple extensions to explore the applicability of the\nframework to new settings. We evaluate additional models, such as DeepSeek-V3\nand GPT-4o-mini, to test whether cooperative behavior generalizes across\ndifferent architectures and model sizes. Furthermore, we introduce new\nsettings: we create a heterogeneous multi-agent environment, study a scenario\nusing Japanese instructions, and explore an \"inverse environment\" where agents\nmust cooperate to mitigate harmful resource distributions. Our results confirm\nthat the benchmark can be applied to new models, scenarios, and languages,\noffering valuable insights into the adaptability of LLMs in complex cooperative\ntasks. Moreover, the experiment involving heterogeneous multi-agent systems\ndemonstrates that high-performing models can influence lower-performing ones to\nadopt similar behaviors. This finding has significant implications for other\nagent-based applications, potentially enabling more efficient use of\ncomputational resources and contributing to the development of more effective\ncooperative AI systems.", "published": "2025-05-14 11:15:14", "link": "http://arxiv.org/abs/2505.09289v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning", "abstract": "Zero- and few-shot visual anomaly segmentation relies on powerful\nvision-language models that detect unseen anomalies using manually designed\ntextual prompts. However, visual representations are inherently independent of\nlanguage. In this paper, we explore the potential of a pure visual foundation\nmodel as an alternative to widely used vision-language models for universal\nvisual anomaly segmentation. We present a novel paradigm that unifies anomaly\nsegmentation into change segmentation. This paradigm enables us to leverage\nlarge-scale synthetic image pairs, featuring object-level and local region\nchanges, derived from existing image datasets, which are independent of target\nanomaly datasets. We propose a one-prompt Meta-learning framework for Universal\nAnomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and\nthen generalizes well to segment any novel or unseen visual anomalies in the\nreal world. To handle geometrical variations between prompt and query images,\nwe propose a soft feature alignment module that bridges paired-image change\nperception and single-image semantic segmentation. This is the first work to\nachieve universal anomaly segmentation using a pure vision model without\nrelying on special anomaly detection datasets and pre-trained visual-language\nmodels. Our method effectively and efficiently segments any anomalies with only\none normal image prompt and enjoys training-free without guidance from\nlanguage. Our MetaUAS significantly outperforms previous zero-shot, few-shot,\nand even full-shot anomaly segmentation methods. The code and pre-trained\nmodels are available at https://github.com/gaobb/MetaUAS.", "published": "2025-05-14 10:25:26", "link": "http://arxiv.org/abs/2505.09265v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt", "abstract": "Unsupervised reconstruction networks using self-attention transformers have\nachieved state-of-the-art performance for multi-class (unified) anomaly\ndetection with a single model. However, these self-attention reconstruction\nmodels primarily operate on target features, which may result in perfect\nreconstruction for both normal and anomaly features due to high consistency\nwith context, leading to failure in detecting anomalies. Additionally, these\nmodels often produce inaccurate anomaly segmentation due to performing\nreconstruction in a low spatial resolution latent space. To enable\nreconstruction models enjoying high efficiency while enhancing their\ngeneralization for unified anomaly detection, we propose a simple yet effective\nmethod that reconstructs normal features and restores anomaly features with\njust One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP\nallows for the first time to reconstruct or restore anomalies with just one\nnormal image prompt, effectively boosting unified anomaly detection\nperformance. Furthermore, we propose a supervised refiner that regresses\nreconstruction errors by using both real normal and synthesized anomalous\nimages, which significantly improves pixel-level anomaly segmentation. OneNIP\noutperforms previous methods on three industry anomaly detection benchmarks:\nMVTec, BTAD, and VisA. The code and pre-trained models are available at\nhttps://github.com/gaobb/OneNIP.", "published": "2025-05-14 10:25:14", "link": "http://arxiv.org/abs/2505.09264v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation", "abstract": "Anomaly detection is a practical and challenging task due to the scarcity of\nanomaly samples in industrial inspection. Some existing anomaly detection\nmethods address this issue by synthesizing anomalies with noise or external\ndata. However, there is always a large semantic gap between synthetic and\nreal-world anomalies, resulting in weak performance in anomaly detection. To\nsolve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen)\nmethod, which guides the diffusion model to generate realistic and diverse\nanomalies with only a few real anomalies, thereby benefiting training anomaly\ndetection models. Specifically, our work is divided into three stages. In the\nfirst stage, we learn the anomaly distribution based on a few given real\nanomalies and inject the learned knowledge into an embedding. In the second\nstage, we use the embedding and given bounding boxes to guide the diffusion\nmodel to generate realistic and diverse anomalies on specific objects (or\ntextures). In the final stage, we propose a weakly-supervised anomaly detection\nmethod to train a more powerful model with generated anomalies. Our method\nbuilds upon DRAEM and DesTSeg as the foundation model and conducts experiments\non the commonly used industrial anomaly detection dataset, MVTec. The\nexperiments demonstrate that our generated anomalies effectively improve the\nmodel performance of both anomaly classification and segmentation tasks\nsimultaneously, \\eg, DRAEM and DseTSeg achieved a 5.8\\% and 1.5\\% improvement\nin AU-PR metric on segmentation task, respectively. The code and generated\nanomalous data are available at https://github.com/gaobb/AnoGen.", "published": "2025-05-14 10:25:06", "link": "http://arxiv.org/abs/2505.09263v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling", "abstract": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science.", "published": "2025-05-14 10:23:22", "link": "http://arxiv.org/abs/2505.09262v1", "categories": ["physics.chem-ph", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "physics.chem-ph"}
{"title": "Educational impacts of generative artificial intelligence on learning and performance of engineering students in China", "abstract": "With the rapid advancement of generative artificial intelligence(AI), its\npotential applications in higher education have attracted significant\nattention. This study investigated how 148 students from diverse engineering\ndisciplines and regions across China used generative AI, focusing on its impact\non their learning experience and the opportunities and challenges it poses in\nengineering education. Based on the surveyed data, we explored four key areas:\nthe frequency and application scenarios of AI use among engineering students,\nits impact on students' learning and performance, commonly encountered\nchallenges in using generative AI, and future prospects for its adoption in\nengineering education. The results showed that more than half of the\nparticipants reported a positive impact of generative AI on their learning\nefficiency, initiative, and creativity, with nearly half believing it also\nenhanced their independent thinking. However, despite acknowledging improved\nstudy efficiency, many felt their actual academic performance remained largely\nunchanged and expressed concerns about the accuracy and domain-specific\nreliability of generative AI. Our findings provide a first-hand insight into\nthe current benefits and challenges generative AI brings to students,\nparticularly Chinese engineering students, while offering several\nrecommendations, especially from the students' perspective, for effectively\nintegrating generative AI into engineering education.", "published": "2025-05-14 07:52:54", "link": "http://arxiv.org/abs/2505.09208v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "InvDesFlow-AL: Active Learning-based Workflow for Inverse Design of Functional Materials", "abstract": "Developing inverse design methods for functional materials with specific\nproperties is critical to advancing fields like renewable energy, catalysis,\nenergy storage, and carbon capture. Generative models based on diffusion\nprinciples can directly produce new materials that meet performance\nconstraints, thereby significantly accelerating the material design process.\nHowever, existing methods for generating and predicting crystal structures\noften remain limited by low success rates. In this work, we propose a novel\ninverse material design generative framework called InvDesFlow-AL, which is\nbased on active learning strategies. This framework can iteratively optimize\nthe material generation process to gradually guide it towards desired\nperformance characteristics. In terms of crystal structure prediction, the\nInvDesFlow-AL model achieves an RMSE of 0.0423 {\\AA}, representing an 32.96%\nimprovement in performance compared to exsisting generative models.\nAdditionally, InvDesFlow-AL has been successfully validated in the design of\nlow-formation-energy and low-Ehull materials. It can systematically generate\nmaterials with progressively lower formation energies while continuously\nexpanding the exploration across diverse chemical spaces. These results fully\ndemonstrate the effectiveness of the proposed active learning-driven generative\nmodel in accelerating material discovery and inverse design. To further prove\nthe effectiveness of this method, we took the search for BCS superconductors\nunder ambient pressure as an example explored by InvDesFlow-AL. As a result, we\nsuccessfully identified Li\\(_2\\)AuH\\(_6\\) as a conventional BCS superconductor\nwith an ultra-high transition temperature of 140 K. This discovery provides\nstrong empirical support for the application of inverse design in materials\nscience.", "published": "2025-05-14 07:29:06", "link": "http://arxiv.org/abs/2505.09203v1", "categories": ["cond-mat.mtrl-sci", "cond-mat.supr-con", "cs.AI", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection", "abstract": "The core challenge in Camouflage Object Detection (COD) lies in the\nindistinguishable similarity between targets and backgrounds in terms of color,\ntexture, and shape. This causes existing methods to either lose edge details\n(such as hair-like fine structures) due to over-reliance on global semantic\ninformation or be disturbed by similar backgrounds (such as vegetation\npatterns) when relying solely on local features. We propose DRRNet, a\nfour-stage architecture characterized by a \"context-detail-fusion-refinement\"\npipeline to address these issues. Specifically, we introduce an Omni-Context\nFeature Extraction Module to capture global camouflage patterns and a Local\nDetail Extraction Module to supplement microstructural information for the\nfull-scene context module. We then design a module for forming dual\nrepresentations of scene understanding and structural awareness, which fuses\npanoramic features and local features across various scales. In the decoder, we\nalso introduce a reverse refinement module that leverages spatial edge priors\nand frequency-domain noise suppression to perform a two-stage inverse\nrefinement of the output. By applying two successive rounds of inverse\nrefinement, the model effectively suppresses background interference and\nenhances the continuity of object boundaries. Experimental results demonstrate\nthat DRRNet significantly outperforms state-of-the-art methods on benchmark\ndatasets. Our code is available at https://github.com/jerrySunning/DRRNet.", "published": "2025-05-14 06:03:53", "link": "http://arxiv.org/abs/2505.09168v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "An Initial Exploration of Default Images in Text-to-Image Generation", "abstract": "In the creative practice of text-to-image generation (TTI), images are\ngenerated from text prompts. However, TTI models are trained to always yield an\noutput, even if the prompt contains unknown terms. In this case, the model may\ngenerate what we call \"default images\": images that closely resemble each other\nacross many unrelated prompts. We argue studying default images is valuable for\ndesigning better solutions for TTI and prompt engineering. In this paper, we\nprovide the first investigation into default images on Midjourney, a popular\nimage generator. We describe our systematic approach to create input prompts\ntriggering default images, and present the results of our initial experiments\nand several small-scale ablation studies. We also report on a survey study\ninvestigating how default images affect user satisfaction. Our work lays the\nfoundation for understanding default images in TTI and highlights challenges\nand future research directions.", "published": "2025-05-14 05:59:23", "link": "http://arxiv.org/abs/2505.09166v1", "categories": ["cs.HC", "cs.AI", "H.5.m; I.2.m"], "primary_category": "cs.HC"}
{"title": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning", "abstract": "Current applications of self-supervised learning to wireless channel\nrepresentation often borrow paradigms developed for text and image processing,\nwithout fully addressing the unique characteristics and constraints of wireless\ncommunications. Aiming to fill this gap, we first propose WiMAE (Wireless\nMasked Autoencoder), a transformer-based encoder-decoder foundation model\npretrained on a realistic open-source multi-antenna wireless channel dataset.\nBuilding upon this foundation, we develop ContraWiMAE, which enhances WiMAE by\nincorporating a contrastive learning objective alongside the reconstruction\ntask in a unified multi-task framework. By warm-starting from pretrained WiMAE\nweights and generating positive pairs via noise injection, the contrastive\ncomponent enables the model to capture both structural and discriminative\nfeatures, enhancing representation quality beyond what reconstruction alone can\nachieve. Through extensive evaluation on unseen scenarios, we demonstrate the\neffectiveness of both approaches across multiple downstream tasks, with\nContraWiMAE showing further improvements in linear separability and\nadaptability in diverse wireless environments. Comparative evaluations against\na state-of-the-art wireless channel foundation model confirm the superior\nperformance and data efficiency of our models, highlighting their potential as\npowerful baselines for future research in self-supervised wireless channel\nrepresentation learning.", "published": "2025-05-14 05:45:22", "link": "http://arxiv.org/abs/2505.09160v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor", "abstract": "We propose ELIS, a serving system for Large Language Models (LLMs) featuring\nan Iterative Shortest Remaining Time First (ISRTF) scheduler designed to\nefficiently manage inference tasks with the shortest remaining tokens. Current\nLLM serving systems often employ a first-come-first-served scheduling strategy,\nwhich can lead to the \"head-of-line blocking\" problem. To overcome this\nlimitation, it is necessary to predict LLM inference times and apply a shortest\njob first scheduling strategy. However, due to the auto-regressive nature of\nLLMs, predicting the inference latency is challenging. ELIS addresses this\nchallenge by training a response length predictor for LLMs using the BGE model,\nan encoder-based state-of-the-art model. Additionally, we have devised the\nISRTF scheduling strategy, an optimization of shortest remaining time first\ntailored to existing LLM iteration batching. To evaluate our work in an\nindustrial setting, we simulate streams of requests based on our study of\nreal-world user LLM serving trace records. Furthermore, we implemented ELIS as\na cloud-native scheduler system on Kubernetes to evaluate its performance in\nproduction environments. Our experimental results demonstrate that ISRTF\nreduces the average job completion time by up to 19.6%.", "published": "2025-05-14 04:50:00", "link": "http://arxiv.org/abs/2505.09142v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Fair Clustering via Alignment", "abstract": "Algorithmic fairness in clustering aims to balance the proportions of\ninstances assigned to each cluster with respect to a given sensitive attribute.\nWhile recently developed fair clustering algorithms optimize clustering\nobjectives under specific fairness constraints, their inherent complexity or\napproximation often results in suboptimal clustering utility or numerical\ninstability in practice. To resolve these limitations, we propose a new fair\nclustering algorithm based on a novel decomposition of the fair K-means\nclustering objective function. The proposed algorithm, called Fair Clustering\nvia Alignment (FCA), operates by alternately (i) finding a joint probability\ndistribution to align the data from different protected groups, and (ii)\noptimizing cluster centers in the aligned space. A key advantage of FCA is that\nit theoretically guarantees approximately optimal clustering utility for any\ngiven fairness level without complex constraints, thereby enabling high-utility\nfair clustering in practice. Experiments show that FCA outperforms existing\nmethods by (i) attaining a superior trade-off between fairness level and\nclustering utility, and (ii) achieving near-perfect fairness without numerical\ninstability.", "published": "2025-05-14 04:29:09", "link": "http://arxiv.org/abs/2505.09131v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes", "abstract": "The deployment of traditional deep learning models in high-risk security\ntasks in an unlabeled, data-non-exploitable video intelligence environment\nfaces significant challenges. In this paper, we propose a lightweight anomaly\ndetection framework based on color features for surveillance video clips in a\nhigh sensitivity tactical mission, aiming to quickly identify and interpret\npotential threat events under resource-constrained and data-sensitive\nconditions. The method fuses unsupervised KMeans clustering with RGB channel\nhistogram modeling to achieve composite detection of structural anomalies and\ncolor mutation signals in key frames. The experiment takes an operation\nsurveillance video occurring in an African country as a research sample, and\nsuccessfully identifies multiple highly anomalous frames related to high-energy\nlight sources, target presence, and reflective interference under the condition\nof no access to the original data. The results show that this method can be\neffectively used for tactical assassination warning, suspicious object\nscreening and environmental drastic change monitoring with strong deployability\nand tactical interpretation value. The study emphasizes the importance of color\nfeatures as low semantic battlefield signal carriers, and its battlefield\nintelligent perception capability will be further extended by combining graph\nneural networks and temporal modeling in the future.", "published": "2025-05-14 04:24:37", "link": "http://arxiv.org/abs/2505.09129v1", "categories": ["cs.CV", "cs.AI", "es: 68T10, 68T05, 62H35, 68U10", "I.4.9; I.5.1; I.2.10"], "primary_category": "cs.CV"}
{"title": "PreCare: Designing AI Assistants for Advance Care Planning (ACP) to Enhance Personal Value Exploration, Patient Knowledge, and Decisional Confidence", "abstract": "Advance Care Planning (ACP) allows individuals to specify their preferred\nend-of-life life-sustaining treatments before they become incapacitated by\ninjury or terminal illness (e.g., coma, cancer, dementia). While online ACP\noffers high accessibility, it lacks key benefits of clinical consultations,\nincluding personalized value exploration, immediate clarification of decision\nconsequences. To bridge this gap, we conducted two formative studies: 1)\nshadowed and interviewed 3 ACP teams consisting of physicians, nurses, and\nsocial workers (18 patients total), and 2) interviewed 14 users of ACP\nwebsites. Building on these insights, we designed PreCare in collaboration with\n6 ACP professionals. PreCare is a website with 3 AI-driven assistants designed\nto guide users through exploring personal values, gaining ACP knowledge, and\nsupporting informed decision-making. A usability study (n=12) showed that\nPreCare achieved a System Usability Scale (SUS) rating of excellent. A\ncomparative evaluation (n=12) showed that PreCare's AI assistants significantly\nimproved exploration of personal values, knowledge, and decisional confidence,\nand was preferred by 92% of participants.", "published": "2025-05-14 03:53:35", "link": "http://arxiv.org/abs/2505.09115v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer", "abstract": "Decision Transformers (DT) play a crucial role in modern reinforcement\nlearning, leveraging offline datasets to achieve impressive results across\nvarious domains. However, DT requires high-quality, comprehensive data to\nperform optimally. In real-world applications, the lack of training data and\nthe scarcity of optimal behaviours make training on offline datasets\nchallenging, as suboptimal data can hinder performance. To address this, we\npropose the Counterfactual Reasoning Decision Transformer (CRDT), a novel\nframework inspired by counterfactual reasoning. CRDT enhances DT ability to\nreason beyond known data by generating and utilizing counterfactual\nexperiences, enabling improved decision-making in unseen scenarios. Experiments\nacross Atari and D4RL benchmarks, including scenarios with limited data and\naltered dynamics, demonstrate that CRDT outperforms conventional DT approaches.\nAdditionally, reasoning counterfactually allows the DT agent to obtain\nstitching abilities, combining suboptimal trajectories, without architectural\nmodifications. These results highlight the potential of counterfactual\nreasoning to enhance reinforcement learning agents' performance and\ngeneralization capabilities.", "published": "2025-05-14 03:45:16", "link": "http://arxiv.org/abs/2505.09114v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Air-Ground Collaboration for Language-Specified Missions in Unknown Environments", "abstract": "As autonomous robotic systems become increasingly mature, users will want to\nspecify missions at the level of intent rather than in low-level detail.\nLanguage is an expressive and intuitive medium for such mission specification.\nHowever, realizing language-guided robotic teams requires overcoming\nsignificant technical hurdles. Interpreting and realizing language-specified\nmissions requires advanced semantic reasoning. Successful heterogeneous robots\nmust effectively coordinate actions and share information across varying\nviewpoints. Additionally, communication between robots is typically\nintermittent, necessitating robust strategies that leverage communication\nopportunities to maintain coordination and achieve mission objectives. In this\nwork, we present a first-of-its-kind system where an unmanned aerial vehicle\n(UAV) and an unmanned ground vehicle (UGV) are able to collaboratively\naccomplish missions specified in natural language while reacting to changes in\nspecification on the fly. We leverage a Large Language Model (LLM)-enabled\nplanner to reason over semantic-metric maps that are built online and\nopportunistically shared between an aerial and a ground robot. We consider\ntask-driven navigation in urban and rural areas. Our system must infer\nmission-relevant semantics and actively acquire information via semantic\nmapping. In both ground and air-ground teaming experiments, we demonstrate our\nsystem on seven different natural-language specifications at up to\nkilometer-scale navigation.", "published": "2025-05-14 03:33:46", "link": "http://arxiv.org/abs/2505.09108v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis", "abstract": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio.", "published": "2025-05-14 02:52:16", "link": "http://arxiv.org/abs/2505.09091v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision", "abstract": "Recent advancements in deep neural networks (DNNs), particularly large-scale\nlanguage models, have demonstrated remarkable capabilities in image and natural\nlanguage understanding. Although scaling up model parameters with increasing\nvolume of training data has progressively improved DNN capabilities, achieving\ncomplex cognitive abilities - such as understanding abstract concepts,\nreasoning, and adapting to novel scenarios, which are intrinsic to human\ncognition - remains a major challenge. In this study, we show that\nbrain-in-the-loop supervised learning, utilizing a small set of brain signals,\ncan effectively transfer human conceptual structures to DNNs, significantly\nenhancing their comprehension of abstract and even unseen concepts.\nExperimental results further indicate that the enhanced cognitive capabilities\nlead to substantial performance gains in challenging tasks, including\nfew-shot/zero-shot learning and out-of-distribution recognition, while also\nyielding highly interpretable concept representations. These findings highlight\nthat human-in-the-loop supervision can effectively augment the complex\ncognitive abilities of large models, offering a promising pathway toward\ndeveloping more human-like cognitive abilities in artificial systems.", "published": "2025-05-14 02:39:10", "link": "http://arxiv.org/abs/2505.09085v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation", "abstract": "Contemporary approaches to agent-based modeling (ABM) of social systems have\ntraditionally emphasized rule-based behaviors, limiting their ability to\ncapture nuanced dynamics by moving beyond predefined rules and leveraging\ncontextual understanding from LMs of human social interaction. This paper\npresents SALM (Social Agent LM Framework), a novel approach for integrating\nlanguage models (LMs) into social network simulation that achieves\nunprecedented temporal stability in multi-agent scenarios. Our primary\ncontributions include: (1) a hierarchical prompting architecture enabling\nstable simulation beyond 4,000 timesteps while reducing token usage by 73%, (2)\nan attention-based memory system achieving 80% cache hit rates (95% CI [78%,\n82%]) with sub-linear memory growth of 9.5%, and (3) formal bounds on\npersonality stability. Through extensive validation against SNAP ego networks,\nwe demonstrate the first LLM-based framework capable of modeling long-term\nsocial phenomena while maintaining empirically validated behavioral fidelity.", "published": "2025-05-14 02:29:46", "link": "http://arxiv.org/abs/2505.09081v1", "categories": ["cs.SI", "cs.AI", "cs.MA"], "primary_category": "cs.SI"}
{"title": "Variational Prefix Tuning for Diverse and Accurate Code Summarization Using Pre-trained Language Models", "abstract": "Recent advancements in source code summarization have leveraged\ntransformer-based pre-trained models, including Large Language Models of Code\n(LLMCs), to automate and improve the generation of code summaries. However,\nexisting methods often focus on generating a single high-quality summary for a\ngiven source code, neglecting scenarios where the generated summary might be\ninadequate and alternative options are needed. In this paper, we introduce\nVariational Prefix Tuning (VPT), a novel approach that enhances pre-trained\nmodels' ability to generate diverse yet accurate sets of summaries, allowing\nthe user to choose the most suitable one for the given source code. Our method\nintegrates a Conditional Variational Autoencoder (CVAE) framework as a modular\ncomponent into pre-trained models, enabling us to model the distribution of\nobserved target summaries and sample continuous embeddings to be used as\nprefixes to steer the generation of diverse outputs during decoding.\nImportantly, we construct our method in a parameter-efficient manner,\neliminating the need for expensive model retraining, especially when using\nLLMCs. Furthermore, we employ a bi-criteria reranking method to select a subset\nof generated summaries, optimizing both the diversity and the accuracy of the\noptions presented to users. We present extensive experimental evaluations using\nwidely used datasets and current state-of-the-art pre-trained code\nsummarization models to demonstrate the effectiveness of our approach and its\nadaptability across models.", "published": "2025-05-14 01:46:56", "link": "http://arxiv.org/abs/2505.09062v1", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.7"], "primary_category": "cs.SE"}
{"title": "RT-cache: Efficient Robot Trajectory Retrieval System", "abstract": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation.", "published": "2025-05-14 00:41:44", "link": "http://arxiv.org/abs/2505.09040v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing", "abstract": "Audio-Visual Video Parsing (AVVP) entails the challenging task of localizing\nboth uni-modal events (i.e., those occurring exclusively in either the visual\nor acoustic modality of a video) and multi-modal events (i.e., those occurring\nin both modalities concurrently). Moreover, the prohibitive cost of annotating\ntraining data with the class labels of all these events, along with their start\nand end times, imposes constraints on the scalability of AVVP techniques unless\nthey can be trained in a weakly-supervised setting, where only\nmodality-agnostic, video-level labels are available in the training data. To\nthis end, recently proposed approaches seek to generate segment-level\npseudo-labels to better guide model training. However, the absence of\ninter-segment dependencies when generating these pseudo-labels and the general\nbias towards predicting labels that are absent in a segment limit their\nperformance. This work proposes a novel approach towards overcoming these\nweaknesses called Uncertainty-weighted Weakly-supervised Audio-visual Video\nParsing (UWAV). Additionally, our innovative approach factors in the\nuncertainty associated with these estimated pseudo-labels and incorporates a\nfeature mixup based training regularization for improved training. Empirical\nresults show that UWAV outperforms state-of-the-art methods for the AVVP task\non multiple metrics, across two different datasets, attesting to its\neffectiveness and generalizability.", "published": "2025-05-14 17:59:55", "link": "http://arxiv.org/abs/2505.09615v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "LightLab: Controlling Light Sources in Images with Diffusion Models", "abstract": "We present a simple, yet effective diffusion-based method for fine-grained,\nparametric control over light sources in an image. Existing relighting methods\neither rely on multiple input views to perform inverse rendering at inference\ntime, or fail to provide explicit control over light changes. Our method\nfine-tunes a diffusion model on a small set of real raw photograph pairs,\nsupplemented by synthetically rendered images at scale, to elicit its\nphotorealistic prior for relighting. We leverage the linearity of light to\nsynthesize image pairs depicting controlled light changes of either a target\nlight source or ambient illumination. Using this data and an appropriate\nfine-tuning scheme, we train a model for precise illumination changes with\nexplicit control over light intensity and color. Lastly, we show how our method\ncan achieve compelling light editing results, and outperforms existing methods\nbased on user preference.", "published": "2025-05-14 17:57:27", "link": "http://arxiv.org/abs/2505.09608v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "Don't Forget your Inverse DDIM for Image Editing", "abstract": "The field of text-to-image generation has undergone significant advancements\nwith the introduction of diffusion models. Nevertheless, the challenge of\nediting real images persists, as most methods are either computationally\nintensive or produce poor reconstructions. This paper introduces SAGE\n(Self-Attention Guidance for image Editing) - a novel technique leveraging\npre-trained diffusion models for image editing. SAGE builds upon the DDIM\nalgorithm and incorporates a novel guidance mechanism utilizing the\nself-attention layers of the diffusion U-Net. This mechanism computes a\nreconstruction objective based on attention maps generated during the inverse\nDDIM process, enabling efficient reconstruction of unedited regions without the\nneed to precisely reconstruct the entire input image. Thus, SAGE directly\naddresses the key challenges in image editing. The superiority of SAGE over\nother methods is demonstrated through quantitative and qualitative evaluations\nand confirmed by a statistically validated comprehensive user study, in which\nall 47 surveyed users preferred SAGE over competing methods. Additionally, SAGE\nranks as the top-performing method in seven out of 10 quantitative analyses and\nsecures second and third places in the remaining three.", "published": "2025-05-14 17:15:03", "link": "http://arxiv.org/abs/2505.09571v1", "categories": ["cs.CV", "I.2.10; I.5.0"], "primary_category": "cs.CV"}
{"title": "Using Foundation Models as Pseudo-Label Generators for Pre-Clinical 4D Cardiac CT Segmentation", "abstract": "Cardiac image segmentation is an important step in many cardiac image\nanalysis and modeling tasks such as motion tracking or simulations of cardiac\nmechanics. While deep learning has greatly advanced segmentation in clinical\nsettings, there is limited work on pre-clinical imaging, notably in porcine\nmodels, which are often used due to their anatomical and physiological\nsimilarity to humans. However, differences between species create a domain\nshift that complicates direct model transfer from human to pig data.\n  Recently, foundation models trained on large human datasets have shown\npromise for robust medical image segmentation; yet their applicability to\nporcine data remains largely unexplored. In this work, we investigate whether\nfoundation models can generate sufficiently accurate pseudo-labels for pig\ncardiac CT and propose a simple self-training approach to iteratively refine\nthese labels. Our method requires no manually annotated pig data, relying\ninstead on iterative updates to improve segmentation quality. We demonstrate\nthat this self-training process not only enhances segmentation accuracy but\nalso smooths out temporal inconsistencies across consecutive frames. Although\nour results are encouraging, there remains room for improvement, for example by\nincorporating more sophisticated self-training strategies and by exploring\nadditional foundation models and other cardiac imaging technologies.", "published": "2025-05-14 17:07:30", "link": "http://arxiv.org/abs/2505.09564v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Camera-Only 3D Panoptic Scene Completion for Autonomous Driving through Differentiable Object Shapes", "abstract": "Autonomous vehicles need a complete map of their surroundings to plan and\nact. This has sparked research into the tasks of 3D occupancy prediction, 3D\nscene completion, and 3D panoptic scene completion, which predict a dense map\nof the ego vehicle's surroundings as a voxel grid. Scene completion extends\noccupancy prediction by predicting occluded regions of the voxel grid, and\npanoptic scene completion further extends this task by also distinguishing\nobject instances within the same class; both aspects are crucial for path\nplanning and decision-making. However, 3D panoptic scene completion is\ncurrently underexplored. This work introduces a novel framework for 3D panoptic\nscene completion that extends existing 3D semantic scene completion models. We\npropose an Object Module and Panoptic Module that can easily be integrated with\n3D occupancy and scene completion methods presented in the literature. Our\napproach leverages the available annotations in occupancy benchmarks, allowing\nindividual object shapes to be learned as a differentiable problem. The code is\navailable at https://github.com/nicolamarinello/OffsetOcc .", "published": "2025-05-14 17:05:12", "link": "http://arxiv.org/abs/2505.09562v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Contactless Cardiac Pulse Monitoring Using Event Cameras", "abstract": "Time event cameras are a novel technology for recording scene information at\nextremely low latency and with low power consumption. Event cameras output a\nstream of events that encapsulate pixel-level light intensity changes within\nthe scene, capturing information with a higher dynamic range and temporal\nresolution than traditional cameras. This study investigates the contact-free\nreconstruction of an individual's cardiac pulse signal from time event\nrecording of their face using a supervised convolutional neural network (CNN)\nmodel. An end-to-end model is trained to extract the cardiac signal from a\ntwo-dimensional representation of the event stream, with model performance\nevaluated based on the accuracy of the calculated heart rate. The experimental\nresults confirm that physiological cardiac information in the facial region is\neffectively preserved within the event stream, showcasing the potential of this\nnovel sensor for remote heart rate monitoring. The model trained on event\nframes achieves a root mean square error (RMSE) of 3.32 beats per minute (bpm)\ncompared to the RMSE of 2.92 bpm achieved by the baseline model trained on\nstandard camera frames. Furthermore, models trained on event frames generated\nat 60 and 120 FPS outperformed the 30 FPS standard camera results, achieving an\nRMSE of 2.54 and 2.13 bpm, respectively.", "published": "2025-05-14 16:24:22", "link": "http://arxiv.org/abs/2505.09529v1", "categories": ["cs.CV", "cs.ET", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Conformal Bounds on Full-Reference Image Quality for Imaging Inverse Problems", "abstract": "In imaging inverse problems, we would like to know how close the recovered\nimage is to the true image in terms of full-reference image quality (FRIQ)\nmetrics like PSNR, SSIM, LPIPS, etc. This is especially important in\nsafety-critical applications like medical imaging, where knowing that, say, the\nSSIM was poor could potentially avoid a costly misdiagnosis. But since we don't\nknow the true image, computing FRIQ is non-trivial. In this work, we combine\nconformal prediction with approximate posterior sampling to construct bounds on\nFRIQ that are guaranteed to hold up to a user-specified error probability. We\ndemonstrate our approach on image denoising and accelerated magnetic resonance\nimaging (MRI) problems. Code is available at\nhttps://github.com/jwen307/quality_uq.", "published": "2025-05-14 16:23:26", "link": "http://arxiv.org/abs/2505.09528v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spec2VolCAMU-Net: A Spectrogram-to-Volume Model for EEG-to-fMRI Reconstruction based on Multi-directional Time-Frequency Convolutional Attention Encoder and Vision-Mamba U-Net", "abstract": "High-resolution functional magnetic resonance imaging (fMRI) is essential for\nmapping human brain activity; however, it remains costly and logistically\nchallenging. If comparable volumes could be generated directly from widely\navailable scalp electroencephalography (EEG), advanced neuroimaging would\nbecome significantly more accessible. Existing EEG-to-fMRI generators rely on\nplain CNNs that fail to capture cross-channel time-frequency cues or on heavy\ntransformer/GAN decoders that strain memory and stability. We propose\nSpec2VolCAMU-Net, a lightweight spectrogram-to-volume generator that confronts\nthese issues via a Multi-directional Time-Frequency Convolutional Attention\nEncoder, stacking temporal, spectral and joint convolutions with\nself-attention, and a Vision-Mamba U-Net decoder whose linear-time state-space\nblocks enable efficient long-range spatial modelling. Trained end-to-end with a\nhybrid SSI-MSE loss, Spec2VolCAMU-Net achieves state-of-the-art fidelity on\nthree public benchmarks, recording SSIMs of 0.693 on NODDI, 0.725 on Oddball\nand 0.788 on CN-EPFL, representing improvements of 14.5%, 14.9%, and 16.9%\nrespectively over previous best SSIM scores. Furthermore, it achieves\ncompetitive PSNR scores, particularly excelling on the CN-EPFL dataset with a\n4.6% improvement over the previous best PSNR, thus striking a better balance in\nreconstruction quality. The proposed model is lightweight and efficient, making\nit suitable for real-time applications in clinical and research settings. The\ncode is available at https://github.com/hdy6438/Spec2VolCAMU-Net.", "published": "2025-05-14 16:18:21", "link": "http://arxiv.org/abs/2505.09521v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing", "abstract": "Face Anti-Spoofing (FAS) is essential for the security of facial recognition\nsystems in diverse scenarios such as payment processing and surveillance.\nCurrent multimodal FAS methods often struggle with effective generalization,\nmainly due to modality-specific biases and domain shifts. To address these\nchallenges, we introduce the \\textbf{M}ulti\\textbf{m}odal \\textbf{D}enoising\nand \\textbf{A}lignment (\\textbf{MMDA}) framework. By leveraging the zero-shot\ngeneralization capability of CLIP, the MMDA framework effectively suppresses\nnoise in multimodal data through denoising and alignment mechanisms, thereby\nsignificantly enhancing the generalization performance of cross-modal\nalignment. The \\textbf{M}odality-\\textbf{D}omain Joint \\textbf{D}ifferential\n\\textbf{A}ttention (\\textbf{MD2A}) module in MMDA concurrently mitigates the\nimpacts of domain and modality noise by refining the attention mechanism based\non extracted common noise features. Furthermore, the \\textbf{R}epresentation\n\\textbf{S}pace \\textbf{S}oft (\\textbf{RS2}) Alignment strategy utilizes the\npre-trained CLIP model to align multi-domain multimodal data into a generalized\nrepresentation space in a flexible manner, preserving intricate representations\nand enhancing the model's adaptability to various unseen conditions. We also\ndesign a \\textbf{U}-shaped \\textbf{D}ual \\textbf{S}pace \\textbf{A}daptation\n(\\textbf{U-DSA}) module to enhance the adaptability of representations while\nmaintaining generalization performance. These improvements not only enhance the\nframework's generalization capabilities but also boost its ability to represent\ncomplex representations. Our experimental results on four benchmark datasets\nunder different evaluation protocols demonstrate that the MMDA framework\noutperforms existing state-of-the-art methods in terms of cross-domain\ngeneralization and multimodal detection accuracy. The code will be released\nsoon.", "published": "2025-05-14 15:36:44", "link": "http://arxiv.org/abs/2505.09484v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Pixels: Leveraging the Language of Soccer to Improve Spatio-Temporal Action Detection in Broadcast Videos", "abstract": "State-of-the-art spatio-temporal action detection (STAD) methods show\npromising results for extracting soccer events from broadcast videos. However,\nwhen operated in the high-recall, low-precision regime required for exhaustive\nevent coverage in soccer analytics, their lack of contextual understanding\nbecomes apparent: many false positives could be resolved by considering a\nbroader sequence of actions and game-state information. In this work, we\naddress this limitation by reasoning at the game level and improving STAD\nthrough the addition of a denoising sequence transduction task. Sequences of\nnoisy, context-free player-centric predictions are processed alongside clean\ngame state information using a Transformer-based encoder-decoder model. By\nmodeling extended temporal context and reasoning jointly over team-level\ndynamics, our method leverages the \"language of soccer\" - its tactical\nregularities and inter-player dependencies - to generate \"denoised\" sequences\nof actions. This approach improves both precision and recall in low-confidence\nregimes, enabling more reliable event extraction from broadcast video and\ncomplementing existing pixel-based methods.", "published": "2025-05-14 15:05:36", "link": "http://arxiv.org/abs/2505.09455v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy", "abstract": "Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally\ninvasive diagnostic procedure. However, an aspiration needle tracker addressing\nrapid reciprocating motion is still missing. MrTrack, an aspiration needle\ntracker with a mamba-based register mechanism, is proposed. MrTrack leverages a\nMamba-based register extractor to sequentially distill global context from each\nhistorical search map, storing these temporal cues in a register bank. The\nMamba-based register retriever then retrieves temporal prompts from the\nregister bank to provide external cues when current vision features are\ntemporarily unusable due to rapid reciprocating motion and imaging degradation.\nA self-supervised register diversify loss is proposed to encourage feature\ndiversity and dimension independence within the learned register, mitigating\nfeature collapse. Comprehensive experiments conducted on both motorized and\nmanual aspiration datasets demonstrate that MrTrack not only outperforms\nstate-of-the-art trackers in accuracy and robustness but also achieves superior\ninference efficiency.", "published": "2025-05-14 15:01:59", "link": "http://arxiv.org/abs/2505.09450v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient LiDAR Reflectance Compression via Scanning Serialization", "abstract": "Reflectance attributes in LiDAR point clouds provide essential information\nfor downstream tasks but remain underexplored in neural compression methods. To\naddress this, we introduce SerLiC, a serialization-based neural compression\nframework to fully exploit the intrinsic characteristics of LiDAR reflectance.\nSerLiC first transforms 3D LiDAR point clouds into 1D sequences via scan-order\nserialization, offering a device-centric perspective for reflectance analysis.\nEach point is then tokenized into a contextual representation comprising its\nsensor scanning index, radial distance, and prior reflectance, for effective\ndependencies exploration. For efficient sequential modeling, Mamba is\nincorporated with a dual parallelization scheme, enabling simultaneous\nautoregressive dependency capture and fast processing. Extensive experiments\ndemonstrate that SerLiC attains over 2x volume reduction against the original\nreflectance data, outperforming the state-of-the-art method by up to 22%\nreduction of compressed bits while using only 2% of its parameters. Moreover, a\nlightweight version of SerLiC achieves > 10 fps (frames per second) with just\n111K parameters, which is attractive for real-world applications.", "published": "2025-05-14 14:38:40", "link": "http://arxiv.org/abs/2505.09433v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "MoRAL: Motion-aware Multi-Frame 4D Radar and LiDAR Fusion for Robust 3D Object Detection", "abstract": "Reliable autonomous driving systems require accurate detection of traffic\nparticipants. To this end, multi-modal fusion has emerged as an effective\nstrategy. In particular, 4D radar and LiDAR fusion methods based on multi-frame\nradar point clouds have demonstrated the effectiveness in bridging the point\ndensity gap. However, they often neglect radar point clouds' inter-frame\nmisalignment caused by object movement during accumulation and do not fully\nexploit the object dynamic information from 4D radar. In this paper, we propose\nMoRAL, a motion-aware multi-frame 4D radar and LiDAR fusion framework for\nrobust 3D object detection. First, a Motion-aware Radar Encoder (MRE) is\ndesigned to compensate for inter-frame radar misalignment from moving objects.\nLater, a Motion Attention Gated Fusion (MAGF) module integrate radar motion\nfeatures to guide LiDAR features to focus on dynamic foreground objects.\nExtensive evaluations on the View-of-Delft (VoD) dataset demonstrate that MoRAL\noutperforms existing methods, achieving the highest mAP of 73.30% in the entire\narea and 88.68% in the driving corridor. Notably, our method also achieves the\nbest AP of 69.67% for pedestrians in the entire area and 96.25% for cyclists in\nthe driving corridor.", "published": "2025-05-14 14:23:33", "link": "http://arxiv.org/abs/2505.09422v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models", "abstract": "Face anti-spoofing (FAS) is crucial for protecting facial recognition systems\nfrom presentation attacks. Previous methods approached this task as a\nclassification problem, lacking interpretability and reasoning behind the\npredicted results. Recently, multimodal large language models (MLLMs) have\nshown strong capabilities in perception, reasoning, and decision-making in\nvisual tasks. However, there is currently no universal and comprehensive MLLM\nand dataset specifically designed for FAS task. To address this gap, we propose\nFaceShield, a MLLM for FAS, along with the corresponding pre-training and\nsupervised fine-tuning (SFT) datasets, FaceShield-pre10K and FaceShield-sft45K.\nFaceShield is capable of determining the authenticity of faces, identifying\ntypes of spoofing attacks, providing reasoning for its judgments, and detecting\nattack areas. Specifically, we employ spoof-aware vision perception (SAVP) that\nincorporates both the original image and auxiliary information based on prior\nknowledge. We then use an prompt-guided vision token masking (PVTM) strategy to\nrandom mask vision tokens, thereby improving the model's generalization\nability. We conducted extensive experiments on three benchmark datasets,\ndemonstrating that FaceShield significantly outperforms previous deep learning\nmodels and general MLLMs on four FAS tasks, i.e., coarse-grained\nclassification, fine-grained classification, reasoning, and attack\nlocalization. Our instruction datasets, protocols, and codes will be released\nsoon.", "published": "2025-05-14 14:10:43", "link": "http://arxiv.org/abs/2505.09415v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians", "abstract": "Current learning-based methods predict NeRF or 3D Gaussians from point clouds\nto achieve photo-realistic rendering but still depend on categorical priors,\ndense point clouds, or additional refinements. Hence, we introduce a novel\npoint cloud rendering method by predicting 2D Gaussians from point clouds. Our\nmethod incorporates two identical modules with an entire-patch architecture\nenabling the network to be generalized to multiple datasets. The module\nnormalizes and initializes the Gaussians utilizing the point cloud information\nincluding normals, colors and distances. Then, splitting decoders are employed\nto refine the initial Gaussians by duplicating them and predicting more\naccurate results, making our methodology effectively accommodate sparse point\nclouds as well. Once trained, our approach exhibits direct generalization to\npoint clouds across different categories. The predicted Gaussians are employed\ndirectly for rendering without additional refinement on the rendered images,\nretaining the benefits of 2D Gaussians. We conduct extensive experiments on\nvarious datasets, and the results demonstrate the superiority and\ngeneralization of our method, which achieves SOTA performance. The code is\navailable at\nhttps://github.com/murcherful/GauPCRender}{https://github.com/murcherful/GauPCRender.", "published": "2025-05-14 14:10:09", "link": "http://arxiv.org/abs/2505.09413v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FreeDriveRF: Monocular RGB Dynamic NeRF without Poses for Autonomous Driving via Point-Level Dynamic-Static Decoupling", "abstract": "Dynamic scene reconstruction for autonomous driving enables vehicles to\nperceive and interpret complex scene changes more precisely. Dynamic Neural\nRadiance Fields (NeRFs) have recently shown promising capability in scene\nmodeling. However, many existing methods rely heavily on accurate poses inputs\nand multi-sensor data, leading to increased system complexity. To address this,\nwe propose FreeDriveRF, which reconstructs dynamic driving scenes using only\nsequential RGB images without requiring poses inputs. We innovatively decouple\ndynamic and static parts at the early sampling level using semantic\nsupervision, mitigating image blurring and artifacts. To overcome the\nchallenges posed by object motion and occlusion in monocular camera, we\nintroduce a warped ray-guided dynamic object rendering consistency loss,\nutilizing optical flow to better constrain the dynamic modeling process.\nAdditionally, we incorporate estimated dynamic flow to constrain the pose\noptimization process, improving the stability and accuracy of unbounded scene\nreconstruction. Extensive experiments conducted on the KITTI and Waymo datasets\ndemonstrate the superior performance of our method in dynamic scene modeling\nfor autonomous driving.", "published": "2025-05-14 14:02:49", "link": "http://arxiv.org/abs/2505.09406v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Text-driven Motion Generation: Overview, Challenges and Directions", "abstract": "Text-driven motion generation offers a powerful and intuitive way to create\nhuman movements directly from natural language. By removing the need for\npredefined motion inputs, it provides a flexible and accessible approach to\ncontrolling animated characters. This makes it especially useful in areas like\nvirtual reality, gaming, human-computer interaction, and robotics. In this\nreview, we first revisit the traditional perspective on motion synthesis, where\nmodels focused on predicting future poses from observed initial sequences,\noften conditioned on action labels. We then provide a comprehensive and\nstructured survey of modern text-to-motion generation approaches, categorizing\nthem from two complementary perspectives: (i) architectural, dividing methods\ninto VAE-based, diffusion-based, and hybrid models; and (ii) motion\nrepresentation, distinguishing between discrete and continuous motion\ngeneration strategies. In addition, we explore the most widely used datasets,\nevaluation methods, and recent benchmarks that have shaped progress in this\narea. With this survey, we aim to capture where the field currently stands,\nbring attention to its key challenges and limitations, and highlight promising\ndirections for future exploration. We hope this work offers a valuable starting\npoint for researchers and practitioners working to push the boundaries of\nlanguage-driven human motion synthesis.", "published": "2025-05-14 13:33:12", "link": "http://arxiv.org/abs/2505.09379v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MAKE: Multi-Aspect Knowledge-Enhanced Vision-Language Pretraining for Zero-shot Dermatological Assessment", "abstract": "Dermatological diagnosis represents a complex multimodal challenge that\nrequires integrating visual features with specialized clinical knowledge. While\nvision-language pretraining (VLP) has advanced medical AI, its effectiveness in\ndermatology is limited by text length constraints and the lack of structured\ntexts. In this paper, we introduce MAKE, a Multi-Aspect Knowledge-Enhanced\nvision-language pretraining framework for zero-shot dermatological tasks.\nRecognizing that comprehensive dermatological descriptions require multiple\nknowledge aspects that exceed standard text constraints, our framework\nintroduces: (1) a multi-aspect contrastive learning strategy that decomposes\nclinical narratives into knowledge-enhanced sub-texts through large language\nmodels, (2) a fine-grained alignment mechanism that connects subcaptions with\ndiagnostically relevant image features, and (3) a diagnosis-guided weighting\nscheme that adaptively prioritizes different sub-captions based on clinical\nsignificance prior. Through pretraining on 403,563 dermatological image-text\npairs collected from education resources, MAKE significantly outperforms\nstate-of-the-art VLP models on eight datasets across zero-shot skin disease\nclassification, concept annotation, and cross-modal retrieval tasks. Our code\nwill be made publicly available at https: //github.com/SiyuanYan1/MAKE.", "published": "2025-05-14 13:24:08", "link": "http://arxiv.org/abs/2505.09372v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo", "abstract": "Standard benchmarks for optical flow, scene flow, and stereo vision\nalgorithms generally focus on model accuracy rather than robustness to image\ncorruptions like noise or rain. Hence, the resilience of models to such\nreal-world perturbations is largely unquantified. To address this, we present\nRobustSpring, a comprehensive dataset and benchmark for evaluating robustness\nto image corruptions for optical flow, scene flow, and stereo models.\nRobustSpring applies 20 different image corruptions, including noise, blur,\ncolor changes, quality degradations, and weather distortions, in a time-,\nstereo-, and depth-consistent manner to the high-resolution Spring dataset,\ncreating a suite of 20,000 corrupted images that reflect challenging\nconditions. RobustSpring enables comparisons of model robustness via a new\ncorruption robustness metric. Integration with the Spring benchmark enables\npublic two-axis evaluations of both accuracy and robustness. We benchmark a\ncurated selection of initial models, observing that accurate models are not\nnecessarily robust and that robustness varies widely by corruption type.\nRobustSpring is a new computer vision benchmark that treats robustness as a\nfirst-class citizen to foster models that combine accuracy with resilience. It\nwill be available at https://spring-benchmark.org.", "published": "2025-05-14 13:21:34", "link": "http://arxiv.org/abs/2505.09368v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis", "abstract": "The success of deep learning in computer vision over the past decade has\nhinged on large labeled datasets and strong pretrained models. In data-scarce\nsettings, the quality of these pretrained models becomes crucial for effective\ntransfer learning. Image classification and self-supervised learning have\ntraditionally been the primary methods for pretraining CNNs and\ntransformer-based architectures. Recently, the rise of text-to-image generative\nmodels, particularly those using denoising diffusion in a latent space, has\nintroduced a new class of foundational models trained on massive, captioned\nimage datasets. These models' ability to generate realistic images of unseen\ncontent suggests they possess a deep understanding of the visual world. In this\nwork, we present Marigold, a family of conditional generative models and a\nfine-tuning protocol that extracts the knowledge from pretrained latent\ndiffusion models like Stable Diffusion and adapts them for dense image analysis\ntasks, including monocular depth estimation, surface normals prediction, and\nintrinsic decomposition. Marigold requires minimal modification of the\npre-trained latent diffusion model's architecture, trains with small synthetic\ndatasets on a single GPU over a few days, and demonstrates state-of-the-art\nzero-shot generalization. Project page:\nhttps://marigoldcomputervision.github.io", "published": "2025-05-14 13:07:03", "link": "http://arxiv.org/abs/2505.09358v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "APR-Transformer: Initial Pose Estimation for Localization in Complex Environments through Absolute Pose Regression", "abstract": "Precise initialization plays a critical role in the performance of\nlocalization algorithms, especially in the context of robotics, autonomous\ndriving, and computer vision. Poor localization accuracy is often a consequence\nof inaccurate initial poses, particularly noticeable in GNSS-denied\nenvironments where GPS signals are primarily relied upon for initialization.\nRecent advances in leveraging deep neural networks for pose regression have led\nto significant improvements in both accuracy and robustness, especially in\nestimating complex spatial relationships and orientations. In this paper, we\nintroduce APR-Transformer, a model architecture inspired by state-of-the-art\nmethods, which predicts absolute pose (3D position and 3D orientation) using\neither image or LiDAR data. We demonstrate that our proposed method achieves\nstate-of-the-art performance on established benchmark datasets such as the\nRadar Oxford Robot-Car and DeepLoc datasets. Furthermore, we extend our\nexperiments to include our custom complex APR-BeIntelli dataset. Additionally,\nwe validate the reliability of our approach in GNSS-denied environments by\ndeploying the model in real-time on an autonomous test vehicle. This showcases\nthe practical feasibility and effectiveness of our approach. The source code is\navailable at:https://github.com/GT-ARC/APR-Transformer.", "published": "2025-05-14 13:06:42", "link": "http://arxiv.org/abs/2505.09356v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Unsupervised Multiview Contrastive Language-Image Joint Learning with Pseudo-Labeled Prompts Via Vision-Language Model for 3D/4D Facial Expression Recognition", "abstract": "In this paper, we introduce MultiviewVLM, a vision-language model designed\nfor unsupervised contrastive multiview representation learning of facial\nemotions from 3D/4D data. Our architecture integrates pseudo-labels derived\nfrom generated textual prompts to guide implicit alignment of emotional\nsemantics. To capture shared information across multi-views, we propose a joint\nembedding space that aligns multiview representations without requiring\nexplicit supervision. We further enhance the discriminability of our model\nthrough a novel multiview contrastive learning strategy that leverages stable\npositive-negative pair sampling. A gradient-friendly loss function is\nintroduced to promote smoother and more stable convergence, and the model is\noptimized for distributed training to ensure scalability. Extensive experiments\ndemonstrate that MultiviewVLM outperforms existing state-of-the-art methods and\ncan be easily adapted to various real-world applications with minimal\nmodifications.", "published": "2025-05-14 12:31:21", "link": "http://arxiv.org/abs/2505.09336v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DCSNet: A Lightweight Knowledge Distillation-Based Model with Explainable AI for Lung Cancer Diagnosis from Histopathological Images", "abstract": "Lung cancer is a leading cause of cancer-related deaths globally, where early\ndetection and accurate diagnosis are critical for improving survival rates.\nWhile deep learning, particularly convolutional neural networks (CNNs), has\nrevolutionized medical image analysis by detecting subtle patterns indicative\nof early-stage lung cancer, its adoption faces challenges. These models are\noften computationally expensive and require significant resources, making them\nunsuitable for resource constrained environments. Additionally, their lack of\ntransparency hinders trust and broader adoption in sensitive fields like\nhealthcare. Knowledge distillation addresses these challenges by transferring\nknowledge from large, complex models (teachers) to smaller, lightweight models\n(students). We propose a knowledge distillation-based approach for lung cancer\ndetection, incorporating explainable AI (XAI) techniques to enhance model\ntransparency. Eight CNNs, including ResNet50, EfficientNetB0, EfficientNetB3,\nand VGG16, are evaluated as teacher models. We developed and trained a\nlightweight student model, Distilled Custom Student Network (DCSNet) using\nResNet50 as the teacher. This approach not only ensures high diagnostic\nperformance in resource-constrained settings but also addresses transparency\nconcerns, facilitating the adoption of AI-driven diagnostic tools in\nhealthcare.", "published": "2025-05-14 12:28:45", "link": "http://arxiv.org/abs/2505.09334v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Q-space Guided Collaborative Attention Translation Network for Flexible Diffusion-Weighted Images Synthesis", "abstract": "This study, we propose a novel Q-space Guided Collaborative Attention\nTranslation Networks (Q-CATN) for multi-shell, high-angular resolution DWI\n(MS-HARDI) synthesis from flexible q-space sampling, leveraging the commonly\nacquired structural MRI data. Q-CATN employs a collaborative attention\nmechanism to effectively extract complementary information from multiple\nmodalities and dynamically adjust its internal representations based on\nflexible q-space information, eliminating the need for fixed sampling schemes.\nAdditionally, we introduce a range of task-specific constraints to preserve\nanatomical fidelity in DWI, enabling Q-CATN to accurately learn the intrinsic\nrelationships between directional DWI signal distributions and q-space.\nExtensive experiments on the Human Connectome Project (HCP) dataset demonstrate\nthat Q-CATN outperforms existing methods, including 1D-qDL, 2D-qDL, MESC-SD,\nand QGAN, in estimating parameter maps and fiber tracts both quantitatively and\nqualitatively, while preserving fine-grained details. Notably, its ability to\naccommodate flexible q-space sampling highlights its potential as a promising\ntoolkit for clinical and research applications. Our code is available at\nhttps://github.com/Idea89560041/Q-CATN.", "published": "2025-05-14 12:23:07", "link": "http://arxiv.org/abs/2505.09323v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "TransDiffuser: End-to-end Trajectory Generation with Decorrelated Multi-modal Representation for Autonomous Driving", "abstract": "In recent years, diffusion model has shown its potential across diverse\ndomains from vision generation to language modeling. Transferring its\ncapabilities to modern autonomous driving systems has also emerged as a\npromising direction.In this work, we propose TransDiffuser, an encoder-decoder\nbased generative trajectory planning model for end-to-end autonomous driving.\nThe encoded scene information serves as the multi-modal conditional input of\nthe denoising decoder. To tackle the mode collapse dilemma in generating\nhigh-quality diverse trajectories, we introduce a simple yet effective\nmulti-modal representation decorrelation optimization mechanism during the\ntraining process.TransDiffuser achieves PDMS of 94.85 on the NAVSIM benchmark,\nsurpassing previous state-of-the-art methods without any anchor-based prior\ntrajectories.", "published": "2025-05-14 12:10:41", "link": "http://arxiv.org/abs/2505.09315v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Predicting butterfly species presence from satellite imagery using soft contrastive regularisation", "abstract": "The growing demand for scalable biodiversity monitoring methods has fuelled\ninterest in remote sensing data, due to its widespread availability and\nextensive coverage. Traditionally, the application of remote sensing to\nbiodiversity research has focused on mapping and monitoring habitats, but with\nincreasing availability of large-scale citizen-science wildlife observation\ndata, recent methods have started to explore predicting multi-species presence\ndirectly from satellite images. This paper presents a new data set for\npredicting butterfly species presence from satellite data in the United\nKingdom. We experimentally optimise a Resnet-based model to predict\nmulti-species presence from 4-band satellite images, and find that this model\nespecially outperforms the mean rate baseline for locations with high species\nbiodiversity. To improve performance, we develop a soft, supervised contrastive\nregularisation loss that is tailored to probabilistic labels (such as\nspecies-presence data), and demonstrate that this improves prediction accuracy.\nIn summary, our new data set and contrastive regularisation method contribute\nto the open challenge of accurately predicting species biodiversity from remote\nsensing data, which is key for efficient biodiversity monitoring.", "published": "2025-05-14 11:42:09", "link": "http://arxiv.org/abs/2505.09306v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Recent Advances in Medical Imaging Segmentation: A Survey", "abstract": "Medical imaging is a cornerstone of modern healthcare, driving advancements\nin diagnosis, treatment planning, and patient care. Among its various tasks,\nsegmentation remains one of the most challenging problem due to factors such as\ndata accessibility, annotation complexity, structural variability, variation in\nmedical imaging modalities, and privacy constraints. Despite recent progress,\nachieving robust generalization and domain adaptation remains a significant\nhurdle, particularly given the resource-intensive nature of some proposed\nmodels and their reliance on domain expertise. This survey explores\ncutting-edge advancements in medical image segmentation, focusing on\nmethodologies such as Generative AI, Few-Shot Learning, Foundation Models, and\nUniversal Models. These approaches offer promising solutions to longstanding\nchallenges. We provide a comprehensive overview of the theoretical foundations,\nstate-of-the-art techniques, and recent applications of these methods. Finally,\nwe discuss inherent limitations, unresolved issues, and future research\ndirections aimed at enhancing the practicality and accessibility of\nsegmentation models in medical imaging. We are maintaining a\n\\href{https://github.com/faresbougourzi/Awesome-DL-for-Medical-Imaging-Segmentation}{GitHub\nRepository} to continue tracking and updating innovations in this field.", "published": "2025-05-14 10:48:37", "link": "http://arxiv.org/abs/2505.09274v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Test-Time Augmentation for Pose-invariant Face Recognition", "abstract": "The goal of this paper is to enhance face recognition performance by\naugmenting head poses during the testing phase. Existing methods often rely on\ntraining on frontalised images or learning pose-invariant representations, yet\nboth approaches typically require re-training and testing for each dataset,\ninvolving a substantial amount of effort. In contrast, this study proposes\nPose-TTA, a novel approach that aligns faces at inference time without\nadditional training. To achieve this, we employ a portrait animator that\ntransfers the source image identity into the pose of a driving image. Instead\nof frontalising a side-profile face -- which can introduce distortion --\nPose-TTA generates matching side-profile images for comparison, thereby\nreducing identity information loss. Furthermore, we propose a weighted feature\naggregation strategy to address any distortions or biases arising from the\nsynthetic data, thus enhancing the reliability of the augmented images.\nExtensive experiments on diverse datasets and with various pre-trained face\nrecognition models demonstrate that Pose-TTA consistently improves inference\nperformance. Moreover, our method is straightforward to integrate into existing\nface recognition pipelines, as it requires no retraining or fine-tuning of the\nunderlying recognition models.", "published": "2025-05-14 10:11:35", "link": "http://arxiv.org/abs/2505.09256v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Zero-Shot Multi-modal Large Language Model v.s. Supervised Deep Learning: A Comparative Study on CT-Based Intracranial Hemorrhage Subtyping", "abstract": "Introduction: Timely identification of intracranial hemorrhage (ICH) subtypes\non non-contrast computed tomography is critical for prognosis prediction and\ntherapeutic decision-making, yet remains challenging due to low contrast and\nblurring boundaries. This study evaluates the performance of zero-shot\nmulti-modal large language models (MLLMs) compared to traditional deep learning\nmethods in ICH binary classification and subtyping. Methods: We utilized a\ndataset provided by RSNA, comprising 192 NCCT volumes. The study compares\nvarious MLLMs, including GPT-4o, Gemini 2.0 Flash, and Claude 3.5 Sonnet V2,\nwith conventional deep learning models, including ResNet50 and Vision\nTransformer. Carefully crafted prompts were used to guide MLLMs in tasks such\nas ICH presence, subtype classification, localization, and volume estimation.\nResults: The results indicate that in the ICH binary classification task,\ntraditional deep learning models outperform MLLMs comprehensively. For subtype\nclassification, MLLMs also exhibit inferior performance compared to traditional\ndeep learning models, with Gemini 2.0 Flash achieving an macro-averaged\nprecision of 0.41 and a macro-averaged F1 score of 0.31. Conclusion: While\nMLLMs excel in interactive capabilities, their overall accuracy in ICH\nsubtyping is inferior to deep networks. However, MLLMs enhance interpretability\nthrough language interactions, indicating potential in medical imaging\nanalysis. Future efforts will focus on model refinement and developing more\nprecise MLLMs to improve performance in three-dimensional medical image\nprocessing.", "published": "2025-05-14 09:54:46", "link": "http://arxiv.org/abs/2505.09252v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Surrogate Model for the Forward Design of Multi-layered Metasurface-based Radar Absorbing Structures", "abstract": "Metasurface-based radar absorbing structures (RAS) are highly preferred for\napplications like stealth technology, electromagnetic (EM) shielding, etc. due\nto their capability to achieve frequency selective absorption characteristics\nwith minimal thickness and reduced weight penalty. However, the conventional\napproach for the EM design and optimization of these structures relies on\nforward simulations, using full wave simulation tools, to predict the\nelectromagnetic (EM) response of candidate meta atoms. This process is\ncomputationally intensive, extremely time consuming and requires exploration of\nlarge design spaces. To overcome this challenge, we propose a surrogate model\nthat significantly accelerates the prediction of EM responses of multi-layered\nmetasurface-based RAS. A convolutional neural network (CNN) based architecture\nwith Huber loss function has been employed to estimate the reflection\ncharacteristics of the RAS model. The proposed model achieved a cosine\nsimilarity of 99.9% and a mean square error of 0.001 within 1000 epochs of\ntraining. The efficiency of the model has been established via full wave\nsimulations as well as experiment where it demonstrated significant reduction\nin computational time while maintaining high predictive accuracy.", "published": "2025-05-14 09:54:00", "link": "http://arxiv.org/abs/2505.09251v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PDE: Gene Effect Inspired Parameter Dynamic Evolution for Low-light Image Enhancement", "abstract": "Low-light image enhancement (LLIE) is a fundamental task in computational\nphotography, aiming to improve illumination, reduce noise, and enhance image\nquality. While recent advancements focus on designing increasingly complex\nneural network models, we observe a peculiar phenomenon: resetting certain\nparameters to random values unexpectedly improves enhancement performance for\nsome images. Drawing inspiration from biological genes, we term this phenomenon\nthe gene effect. The gene effect limits enhancement performance, as even random\nparameters can sometimes outperform learned ones, preventing models from fully\nutilizing their capacity. In this paper, we investigate the reason and propose\na solution. Based on our observations, we attribute the gene effect to static\nparameters, analogous to how fixed genetic configurations become maladaptive\nwhen environments change. Inspired by biological evolution, where adaptation to\nnew environments relies on gene mutation and recombination, we propose\nparameter dynamic evolution (PDE) to adapt to different images and mitigate the\ngene effect. PDE employs a parameter orthogonal generation technique and the\ncorresponding generated parameters to simulate gene recombination and gene\nmutation, separately. Experiments validate the effectiveness of our techniques.\nThe code will be released to the public.", "published": "2025-05-14 07:14:25", "link": "http://arxiv.org/abs/2505.09196v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression", "abstract": "Recent forward prediction-based learned video compression (LVC) methods have\nachieved impressive results, even surpassing VVC reference software VTM under\nthe Low Delay B (LDB) configuration. In contrast, learned bidirectional video\ncompression (BVC) remains underexplored and still lags behind its forward-only\ncounterparts. This performance gap is mainly due to the limited ability to\nextract diverse and accurate contexts: most existing BVCs primarily exploit\ntemporal motion while neglecting non-local correlations across frames.\nMoreover, they lack the adaptability to dynamically suppress harmful contexts\narising from fast motion or occlusion. To tackle these challenges, we propose\nBiECVC, a BVC framework that incorporates diversified local and non-local\ncontext modeling along with adaptive context gating. For local context\nenhancement, BiECVC reuses high-quality features from lower layers and aligns\nthem using decoded motion vectors without introducing extra motion overhead.To\nmodel non-local dependencies efficiently, we adopt a linear attention mechanism\nthat balances performance and complexity. To further mitigate the impact of\ninaccurate context prediction, we introduce Bidirectional Context Gating,\ninspired by data-dependent decay in recent autoregressive language models, to\ndynamically filter contextual information based on conditional coding results.\nExtensive experiments demonstrate that BiECVC achieves state-of-the-art\nperformance, reducing the bit-rate by 13.4% and 15.7% compared to VTM 13.2\nunder the Random Access (RA) configuration with intra periods of 32 and 64,\nrespectively. To our knowledge, BiECVC is the first learned video codec to\nsurpass VTM 13.2 RA across all standard test datasets. Code will be available\nat https://github.com/JiangWeibeta/ECVC.", "published": "2025-05-14 06:55:37", "link": "http://arxiv.org/abs/2505.09193v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Zero-shot Quantization: A Comprehensive Survey", "abstract": "Network quantization has proven to be a powerful approach to reduce the\nmemory and computational demands of deep learning models for deployment on\nresource-constrained devices. However, traditional quantization methods often\nrely on access to training data, which is impractical in many real-world\nscenarios due to privacy, security, or regulatory constraints. Zero-shot\nQuantization (ZSQ) emerges as a promising solution, achieving quantization\nwithout requiring any real data. In this paper, we provide a comprehensive\noverview of ZSQ methods and their recent advancements. First, we provide a\nformal definition of the ZSQ problem and highlight the key challenges. Then, we\ncategorize the existing ZSQ methods into classes based on data generation\nstrategies, and analyze their motivations, core ideas, and key takeaways.\nLastly, we suggest future research directions to address the remaining\nlimitations and advance the field of ZSQ. To the best of our knowledge, this\npaper is the first in-depth survey on ZSQ.", "published": "2025-05-14 06:39:01", "link": "http://arxiv.org/abs/2505.09188v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System", "abstract": "The growing complexity and scale of visual model pre-training have made\ndeveloping and deploying multi-task computer-aided diagnosis (CAD) systems\nincreasingly challenging and resource-intensive. Furthermore, the medical\nimaging community lacks an open-source CAD platform to enable the rapid\ncreation of efficient and extendable diagnostic models. To address these\nissues, we propose UniCAD, a unified architecture that leverages the robust\ncapabilities of pre-trained vision foundation models to seamlessly handle both\n2D and 3D medical images while requiring only minimal task-specific parameters.\nUniCAD introduces two key innovations: (1) Efficiency: A low-rank adaptation\nstrategy is employed to adapt a pre-trained visual model to the medical image\ndomain, achieving performance on par with fully fine-tuned counterparts while\nintroducing only 0.17% trainable parameters. (2) Plug-and-Play: A modular\narchitecture that combines a frozen foundation model with multiple\nplug-and-play experts, enabling diverse tasks and seamless functionality\nexpansion. Building on this unified CAD architecture, we establish an\nopen-source platform where researchers can share and access lightweight CAD\nexperts, fostering a more equitable and efficient research ecosystem.\nComprehensive experiments across 12 diverse medical datasets demonstrate that\nUniCAD consistently outperforms existing methods in both accuracy and\ndeployment efficiency. The source code and project page are available at\nhttps://mii-laboratory.github.io/UniCAD/.", "published": "2025-05-14 06:21:27", "link": "http://arxiv.org/abs/2505.09178v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Optimizing Urban Critical Green Space Development Using Machine Learning", "abstract": "This paper presents a novel framework for prioritizing urban green space\ndevelopment in Tehran using diverse socio-economic, environmental, and\nsensitivity indices. The indices were derived from various sources including\nGoogle Earth Engine, air pollution measurements, municipal reports and the\nWeather Research & Forecasting (WRF) model. The WRF model was used to estimate\nthe air temperature at a 1 km resolution due to insufficient meteorological\nstations, yielding RMSE and MAE values of 0.96{\\deg}C and 0.92{\\deg}C,\nrespectively. After data preparation, several machine learning models were used\nfor binary vegetation cover classification including XGBoost, LightGBM, Random\nForest (RF) and Extra Trees. RF achieved the highest performance, exceeding 94%\nin Overall Accuracy, Recall, and F1-score. Then, the probability of areas\nlacking vegetation cover was assessed using socio-economic, environmental and\nsensitivity indices. This resulted in the RF generating an urban green space\ndevelopment prioritization map. Feature Importance Analysis revealed that the\nmost significant indices were nightly land surface temperature (LST) and\nsensitive population. Finally, the framework performance was validated through\nmicroclimate simulation to assess the critical areas after and before the green\nspace development by green roofs. The simulation demonstrated reducing air\ntemperature by up to 0.67{\\deg}C after utilizing the green roof technology in\ncritical areas. As a result, this framework provides a valuable tool for urban\nplanners to develop green spaces.", "published": "2025-05-14 06:13:23", "link": "http://arxiv.org/abs/2505.09175v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection", "abstract": "Current multimodal large language models (MLLMs) struggle to understand\ncircuit schematics due to their limited recognition capabilities. This could be\nattributed to the lack of high-quality schematic-netlist training data.\nExisting work such as AMSnet applies schematic parsing to generate netlists.\nHowever, these methods rely on hard-coded heuristics and are difficult to apply\nto complex or noisy schematics in this paper. We therefore propose a novel net\ndetection mechanism based on segmentation with high robustness. The proposed\nmethod also recovers positional information, allowing digital reconstruction of\nschematics. We then expand AMSnet dataset with schematic images from various\nsources and create AMSnet 2.0. AMSnet 2.0 contains 2,686 circuits with\nschematic images, Spectre-formatted netlists, OpenAccess digital schematics,\nand positional information for circuit components and nets, whereas AMSnet only\nincludes 792 circuits with SPICE netlists but no digital schematics.", "published": "2025-05-14 05:32:55", "link": "http://arxiv.org/abs/2505.09155v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TopoDiT-3D: Topology-Aware Diffusion Transformer with Bottleneck Structure for 3D Point Cloud Generation", "abstract": "Recent advancements in Diffusion Transformer (DiT) models have significantly\nimproved 3D point cloud generation. However, existing methods primarily focus\non local feature extraction while overlooking global topological information,\nsuch as voids, which are crucial for maintaining shape consistency and\ncapturing complex geometries. To address this limitation, we propose\nTopoDiT-3D, a Topology-Aware Diffusion Transformer with a bottleneck structure\nfor 3D point cloud generation. Specifically, we design the bottleneck structure\nutilizing Perceiver Resampler, which not only offers a mode to integrate\ntopological information extracted through persistent homology into feature\nlearning, but also adaptively filters out redundant local features to improve\ntraining efficiency. Experimental results demonstrate that TopoDiT-3D\noutperforms state-of-the-art models in visual quality, diversity, and training\nefficiency. Furthermore, TopoDiT-3D demonstrates the importance of rich\ntopological information for 3D point cloud generation and its synergy with\nconventional local feature learning. Videos and code are available at\nhttps://github.com/Zechao-Guan/TopoDiT-3D.", "published": "2025-05-14 04:48:22", "link": "http://arxiv.org/abs/2505.09140v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond General Prompts: Automated Prompt Refinement using Contrastive Class Alignment Scores for Disambiguating Objects in Vision-Language Models", "abstract": "Vision-language models (VLMs) offer flexible object detection through natural\nlanguage prompts but suffer from performance variability depending on prompt\nphrasing. In this paper, we introduce a method for automated prompt refinement\nusing a novel metric called the Contrastive Class Alignment Score (CCAS), which\nranks prompts based on their semantic alignment with a target object class\nwhile penalizing similarity to confounding classes. Our method generates\ndiverse prompt candidates via a large language model and filters them through\nCCAS, computed using prompt embeddings from a sentence transformer. We evaluate\nour approach on challenging object categories, demonstrating that our automatic\nselection of high-precision prompts improves object detection accuracy without\nthe need for additional model training or labeled data. This scalable and\nmodel-agnostic pipeline offers a principled alternative to manual prompt\nengineering for VLM-based detection systems.", "published": "2025-05-14 04:43:36", "link": "http://arxiv.org/abs/2505.09139v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Promoting SAM for Camouflaged Object Detection via Selective Key Point-based Guidance", "abstract": "Big model has emerged as a new research paradigm that can be applied to\nvarious down-stream tasks with only minor effort for domain adaption.\nCorrespondingly, this study tackles Camouflaged Object Detection (COD)\nleveraging the Segment Anything Model (SAM). The previous studies declared that\nSAM is not workable for COD but this study reveals that SAM works if promoted\nproperly, for which we devise a new framework to render point promotions:\nFirst, we develop the Promotion Point Targeting Network (PPT-net) to leverage\nmulti-scale features in predicting the probabilities of camouflaged objects'\npresences at given candidate points over the image. Then, we develop a key\npoint selection (KPS) algorithm to deploy both positive and negative point\npromotions contrastively to SAM to guide the segmentation. It is the first work\nto facilitate big model for COD and achieves plausible results experimentally\nover the existing methods on 3 data sets under 6 metrics. This study\ndemonstrates an off-the-shelf methodology for COD by leveraging SAM, which\ngains advantage over designing professional models from scratch, not only in\nperformance, but also in turning the problem to a less challenging task, that\nis, seeking informative but not exactly precise promotions.", "published": "2025-05-14 04:09:28", "link": "http://arxiv.org/abs/2505.09123v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning", "abstract": "Traditional scene graphs primarily focus on spatial relationships, limiting\nvision-language models' (VLMs) ability to reason about complex interactions in\nvisual scenes. This paper addresses two key challenges: (1) conventional\ndetection-to-construction methods produce unfocused, contextually irrelevant\nrelationship sets, and (2) existing approaches fail to form persistent memories\nfor generalizing interaction reasoning to new scenes. We propose\nInteraction-augmented Scene Graph Reasoning (ISGR), a framework that enhances\nVLMs' interactional reasoning through three complementary components. First,\nour dual-stream graph constructor combines SAM-powered spatial relation\nextraction with interaction-aware captioning to generate functionally salient\nscene graphs with spatial grounding. Second, we employ targeted interaction\nqueries to activate VLMs' latent knowledge of object functionalities,\nconverting passive recognition into active reasoning about how objects work\ntogether. Finally, we introduce a lone-term memory reinforcement learning\nstrategy with a specialized interaction-focused reward function that transforms\ntransient patterns into long-term reasoning heuristics. Extensive experiments\ndemonstrate that our approach significantly outperforms baseline methods on\ninteraction-heavy reasoning benchmarks, with particularly strong improvements\non complex scene understanding tasks. The source code can be accessed at\nhttps://github.com/open_upon_acceptance.", "published": "2025-05-14 04:04:23", "link": "http://arxiv.org/abs/2505.09118v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis", "abstract": "Due to the deformability of garments, generating a large amount of\nhigh-quality data for robotic garment manipulation tasks is highly challenging.\nIn this paper, we present a synthetic garment dataset that can be used for\nrobotic garment folding. We begin by constructing geometric garment templates\nbased on keypoints and applying generative models to generate realistic texture\npatterns. Leveraging these keypoint annotations, we generate folding\ndemonstrations in simulation and train folding policies via closed-loop\nimitation learning. To improve robustness, we propose KG-DAgger, which uses a\nkeypoint-based strategy to generate demonstration data for recovering from\nfailures. KG-DAgger significantly improves the model performance, boosting the\nreal-world success rate by 25\\%. After training with 15K trajectories (about 2M\nimage-action pairs), the model achieves a 75\\% success rate in the real world.\nExperiments in both simulation and real-world settings validate the\neffectiveness of our proposed framework.", "published": "2025-05-14 03:34:30", "link": "http://arxiv.org/abs/2505.09109v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions", "abstract": "Lane Keeping Assist (LKA) is widely adopted in modern vehicles, yet its\nreal-world performance remains underexplored due to proprietary systems and\nlimited data access. This paper presents OpenLKA, the first open, large-scale\ndataset for LKA evaluation and improvement. It includes 400 hours of driving\ndata from 50+ production vehicle models, collected through extensive road\ntesting in Tampa, Florida and global contributions from the Comma.ai driving\ncommunity. The dataset spans a wide range of challenging scenarios, including\ncomplex road geometries, degraded lane markings, adverse weather, lighting\nconditions and surrounding traffic. The dataset is multimodal, comprising: i)\nfull CAN bus streams, decoded using custom reverse-engineered DBC files to\nextract key LKA events (e.g., system disengagements, lane detection failures);\nii) synchronized high-resolution dash-cam video; iii) real-time outputs from\nOpenpilot, providing accurate estimates of road curvature and lane positioning;\niv) enhanced scene annotations generated by Vision Language Models, describing\nlane visibility, pavement quality, weather, lighting, and traffic conditions.\nBy integrating vehicle-internal signals with high-fidelity perception and rich\nsemantic context, OpenLKA provides a comprehensive platform for benchmarking\nthe real-world performance of production LKA systems, identifying\nsafety-critical operational scenarios, and assessing the readiness of current\nroad infrastructure for autonomous driving. The dataset is publicly available\nat: https://github.com/OpenLKA/OpenLKA.", "published": "2025-05-14 02:53:50", "link": "http://arxiv.org/abs/2505.09092v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "2D-3D Attention and Entropy for Pose Robust 2D Facial Recognition", "abstract": "Despite recent advances in facial recognition, there remains a fundamental\nissue concerning degradations in performance due to substantial perspective\n(pose) differences between enrollment and query (probe) imagery. Therefore, we\npropose a novel domain adaptive framework to facilitate improved performances\nacross large discrepancies in pose by enabling image-based (2D) representations\nto infer properties of inherently pose invariant point cloud (3D)\nrepresentations. Specifically, our proposed framework achieves better pose\ninvariance by using (1) a shared (joint) attention mapping to emphasize common\npatterns that are most correlated between 2D facial images and 3D facial data\nand (2) a joint entropy regularizing loss to promote better\nconsistency$\\unicode{x2014}$enhancing correlations among the intersecting 2D\nand 3D representations$\\unicode{x2014}$by leveraging both attention maps. This\nframework is evaluated on FaceScape and ARL-VTF datasets, where it outperforms\ncompetitive methods by achieving profile (90$\\unicode{x00b0}$$\\unicode{x002b}$)\nTAR @ 1$\\unicode{x0025}$ FAR improvements of at least 7.1$\\unicode{x0025}$ and\n1.57$\\unicode{x0025}$, respectively.", "published": "2025-05-14 02:17:53", "link": "http://arxiv.org/abs/2505.09073v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Linear Search with Probabilistic Detection and Variable Speeds", "abstract": "We present results on new variants of the famous linear search (or cow-path)\nproblem that involves an agent searching for a target with unknown position on\nthe infinite line. We consider the variant where the agent can move either at\nspeed $1$ or at a slower speed $v \\in [0, 1)$. When traveling at the slower\nspeed $v$, the agent is guaranteed to detect the target upon passing through\nits location. When traveling at speed $1$, however, the agent, upon passing\nthrough the target's location, detects it with probability $p \\in [0, 1]$. We\npresent algorithms and provide upper bounds for the competitive ratios for\nthree cases separately: when $p=0$, $v=0$, and when $p,v \\in (0,1)$. We also\nprove that the provided algorithm for the $p=0$ case is optimal.", "published": "2025-05-14 14:33:16", "link": "http://arxiv.org/abs/2505.09429v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Distance-aware Self-adaptive Graph Convolution for Fine-grained Hierarchical Recommendation", "abstract": "Graph Convolutional Networks (GCNs) are widely used to improve recommendation\naccuracy and performance by effectively learning the representations of user\nand item nodes. However, two major challenges remain: (1) the lack of further\noptimization in the graph representation structure and (2) insufficient\nattention given to the varying contributions of different convolutional\nlayers.This paper proposes SAGCN, a distance-based adaptive hierarchical\naggregation method that refines the aggregation process through differentiated\nrepresentation metrics. SAGCN introduces a detailed approach to multilayer\ninformation aggregation and representation space optimization, enabling the\nmodel to learn hierarchical embedding weights based on the distance between\nhierarchical representations. This innovation allows for more precise\ncross-layer information aggregation, improves the model's ability to capture\nhierarchical embeddings, and optimizes the representation space structure.\nAdditionally, the objective loss function is refined to better align with\nrecommendation tasks.Extensive experiments conducted on four real-world\ndatasets demonstrate significant improvements, including over a 5% increase on\nYelp and a 5.58% increase in Recall@10 on the ML_1M dataset.", "published": "2025-05-14 17:39:34", "link": "http://arxiv.org/abs/2505.09590v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "GlobalMood: A cross-cultural benchmark for music emotion recognition", "abstract": "Human annotations of mood in music are essential for music generation and\nrecommender systems. However, existing datasets predominantly focus on Western\nsongs with mood terms derived from English, which may limit generalizability\nacross diverse linguistic and cultural backgrounds. To address this, we\nintroduce `GlobalMood', a novel cross-cultural benchmark dataset comprising\n1,180 songs sampled from 59 countries, with large-scale annotations collected\nfrom 2,519 individuals across five culturally and linguistically distinct\nlocations: U.S., France, Mexico, S. Korea, and Egypt. Rather than imposing\npredefined mood categories, we implement a bottom-up, participant-driven\napproach to organically elicit culturally specific music-related mood terms. We\nthen recruit another pool of human participants to collect 988,925 ratings for\nthese culture-specific descriptors. Our analysis confirms the presence of a\nvalence-arousal structure shared across cultures, yet also reveals significant\ndivergences in how certain mood terms, despite being dictionary equivalents,\nare perceived cross-culturally. State-of-the-art multimodal models benefit\nsubstantially from fine-tuning on our cross-culturally balanced dataset, as\nevidenced by improved alignment with human evaluations - particularly in\nnon-English contexts. More broadly, our findings inform the ongoing debate on\nthe universality versus cultural specificity of emotional descriptors, and our\nmethodology can contribute to other multimodal and cross-lingual research.", "published": "2025-05-14 16:32:45", "link": "http://arxiv.org/abs/2505.09539v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "FACTors: A New Dataset for Studying the Fact-checking Ecosystem", "abstract": "Our fight against false information is spearheaded by fact-checkers. They\ninvestigate the veracity of claims and document their findings as fact-checking\nreports. With the rapid increase in the amount of false information circulating\nonline, the use of automation in fact-checking processes aims to strengthen\nthis ecosystem by enhancing scalability. Datasets containing fact-checked\nclaims play a key role in developing such automated solutions. However, to the\nbest of our knowledge, there is no fact-checking dataset at the ecosystem\nlevel, covering claims from a sufficiently long period of time and sourced from\na wide range of actors reflecting the entire ecosystem that admittedly follows\nwidely-accepted codes and principles of fact-checking. We present a new dataset\nFACTors, the first to fill this gap by presenting ecosystem-level data on\nfact-checking. It contains 118,112 claims from 117,993 fact-checking reports in\nEnglish (co-)authored by 1,953 individuals and published during the period of\n1995-2025 by 39 fact-checking organisations that are active signatories of the\nIFCN (International Fact-Checking Network) and/or EFCSN (European Fact-Checking\nStandards Network). It contains 7,327 overlapping claims investigated by\nmultiple fact-checking organisations, corresponding to 2,977 unique claims. It\nallows to conduct new ecosystem-level studies of the fact-checkers\n(organisations and individuals). To demonstrate the usefulness of FACTors, we\npresent three example applications, including a first-of-its-kind statistical\nanalysis of the fact-checking ecosystem, examining the political inclinations\nof the fact-checking organisations, and attempting to assign a credibility\nscore to each organisation based on the findings of the statistical analysis\nand political leanings. Our methods for constructing FACTors are generic and\ncan be used to maintain a live dataset that can be updated dynamically.", "published": "2025-05-14 14:10:22", "link": "http://arxiv.org/abs/2505.09414v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Diffusion Recommender Models and the Illusion of Progress: A Concerning Study of Reproducibility and a Conceptual Mismatch", "abstract": "Countless new machine learning models are published every year and are\nreported to significantly advance the state-of-the-art in \\emph{top-n}\nrecommendation. However, earlier reproducibility studies indicate that progress\nin this area may be quite limited. Specifically, various widespread\nmethodological issues, e.g., comparisons with untuned baseline models, have led\nto an \\emph{illusion of progress}. In this work, our goal is to examine whether\nthese problems persist in today's research. To this end, we aim to reproduce\nthe latest advancements reported from applying modern Denoising Diffusion\nProbabilistic Models to recommender systems, focusing on four models published\nat the top-ranked SIGIR conference in 2023 and 2024. Our findings are\nconcerning, revealing persistent methodological problems. Alarmingly, through\nexperiments, we find that the latest recommendation techniques based on\ndiffusion models, despite their computational complexity and substantial carbon\nfootprint, are consistently outperformed by simpler existing models.\nFurthermore, we identify key mismatches between the characteristics of\ndiffusion models and those of the traditional \\emph{top-n} recommendation task,\nraising doubts about their suitability for recommendation. We also note that,\nin the papers we analyze, the generative capabilities of these models are\nconstrained to a minimum. Overall, our results and continued methodological\nissues call for greater scientific rigor and a disruptive change in the\nresearch and publication culture in this area.", "published": "2025-05-14 13:13:53", "link": "http://arxiv.org/abs/2505.09364v1", "categories": ["cs.IR", "cs.LG", "cs.NE"], "primary_category": "cs.IR"}
{"title": "HMamba: Hyperbolic Mamba for Sequential Recommendation", "abstract": "Sequential recommendation systems have become a cornerstone of personalized\nservices, adept at modeling the temporal evolution of user preferences by\ncapturing dynamic interaction sequences. Existing approaches predominantly rely\non traditional models, including RNNs and Transformers. Despite their success\nin local pattern recognition, Transformer-based methods suffer from quadratic\ncomputational complexity and a tendency toward superficial attention patterns,\nlimiting their ability to infer enduring preference hierarchies in sequential\nrecommendation data. Recent advances in Mamba-based sequential models introduce\nlinear-time efficiency but remain constrained by Euclidean geometry, failing to\nleverage the intrinsic hyperbolic structure of recommendation data. To bridge\nthis gap, we propose Hyperbolic Mamba, a novel architecture that unifies the\nefficiency of Mamba's selective state space mechanism with hyperbolic\ngeometry's hierarchical representational power. Our framework introduces (1) a\nhyperbolic selective state space that maintains curvature-aware sequence\nmodeling and (2) stabilized Riemannian operations to enable scalable training.\nExperiments across four benchmarks demonstrate that Hyperbolic Mamba achieves\n3-11% improvement while retaining Mamba's linear-time efficiency, enabling\nreal-world deployment. This work establishes a new paradigm for efficient,\nhierarchy-aware sequential modeling.", "published": "2025-05-14 07:34:36", "link": "http://arxiv.org/abs/2505.09205v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Display Content, Display Methods and Evaluation Methods of the HCI in Explainable Recommender Systems: A Survey", "abstract": "Explainable Recommender Systems (XRS) aim to provide users with\nunderstandable reasons for the recommendations generated by these systems,\nrepresenting a crucial research direction in artificial intelligence (AI).\nRecent research has increasingly focused on the algorithms, display, and\nevaluation methodologies of XRS. While current research and reviews primarily\nemphasize the algorithmic aspects, with fewer studies addressing the\nHuman-Computer Interaction (HCI) layer of XRS. Additionally, existing reviews\nlack a unified taxonomy for XRS and there is insufficient attention given to\nthe emerging area of short video recommendations. In this study, we synthesize\nexisting literature and surveys on XRS, presenting a unified framework for its\nresearch and development. The main contributions are as follows: 1) We adopt a\nlifecycle perspective to systematically summarize the technologies and methods\nused in XRS, addressing challenges posed by the diversity and complexity of\nalgorithmic models and explanation techniques. 2) For the first time, we\nhighlight the application of multimedia, particularly video-based explanations,\nalong with its potential, technical pathways, and challenges in XRS. 3) We\nprovide a structured overview of evaluation methods from both qualitative and\nquantitative dimensions. These findings provide valuable insights for the\nsystematic design, progress, and testing of XRS.", "published": "2025-05-14 01:48:59", "link": "http://arxiv.org/abs/2505.09065v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "Item Level Exploration Traffic Allocation in Large-scale Recommendation Systems", "abstract": "This paper contributes to addressing the item cold start problem in\nlarge-scale recommender systems, focusing on how to efficiently gain initial\nvisibility for newly ingested content. We propose an exploration system\ndesigned to efficiently allocate impressions to these fresh items. Our approach\nleverages a learned probabilistic model to predict an item's discoverability,\nwhich then informs a scalable and adaptive traffic allocation strategy. This\nsystem intelligently distributes exploration budgets, optimizing for the\nlong-term benefit of the recommendation platform. The impact is a demonstrably\nmore efficient cold-start process, leading to a significant increase in the\ndiscoverability of new content and ultimately enriching the item corpus\navailable for exploitation, as evidenced by its successful deployment in a\nlarge-scale production environment.", "published": "2025-05-14 00:05:04", "link": "http://arxiv.org/abs/2505.09033v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Improved Sample Upper and Lower Bounds for Trace Estimation of Quantum State Powers", "abstract": "As often emerges in various basic quantum properties such as entropy, the\ntrace of quantum state powers $\\operatorname{tr}(\\rho^q)$ has attracted a lot\nof attention. The recent work of Liu and Wang (SODA 2025) showed that\n$\\operatorname{tr}(\\rho^q)$ can be estimated to within additive error\n$\\varepsilon$ with a dimension-independent sample complexity of $\\widetilde\nO(1/\\varepsilon^{3+\\frac{2}{q-1}})$ for any constant $q > 1$, where only an\n$\\Omega(1/\\varepsilon)$ lower bound was given. In this paper, we significantly\nimprove the sample complexity of estimating $\\operatorname{tr}(\\rho^q)$ in both\nthe upper and lower bounds. In particular:\n  - For $q > 2$, we settle the sample complexity with matching upper and lower\nbounds $\\widetilde \\Theta(1/\\varepsilon^2)$.\n  - For $1 < q < 2$, we provide an upper bound $\\widetilde\nO(1/\\varepsilon^{\\frac{2}{q-1}})$, with a lower bound\n$\\Omega(1/\\varepsilon^{\\max\\{\\frac{1}{q-1}, 2\\}})$ for dimension-independent\nestimators, implying there is only room for a quadratic improvement.\n  Our upper bounds are obtained by (non-plug-in) quantum estimators based on\nweak Schur sampling, in sharp contrast to the prior approach based on quantum\nsingular value transformation and samplizer.", "published": "2025-05-14 17:06:33", "link": "http://arxiv.org/abs/2505.09563v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Optimizing the Decoding Probability and Coverage Ratio of Composite DNA", "abstract": "This paper studies two problems that are motivated by the novel recent\napproach of composite DNA that takes advantage of the DNA synthesis property\nwhich generates a huge number of copies for every synthesized strand. Under\nthis paradigm, every composite symbols does not store a single nucleotide but a\nmixture of the four DNA nucleotides. The first problem studies the expected\nnumber of strand reads in order to decode a composite strand or a group of\ncomposite strands. In the second problem, our goal is study how to carefully\nchoose a fixed number of mixtures of the DNA nucleotides such that the decoding\nprobability by the maximum likelihood decoder is maximized.", "published": "2025-05-14 16:28:34", "link": "http://arxiv.org/abs/2505.09533v1", "categories": ["cs.IT", "math.IT", "H.1.1"], "primary_category": "cs.IT"}
{"title": "Function-Correcting $b$-symbol Codes for Locally $(\u03bb, \u03c1,b)$-Functions", "abstract": "The family of functions plays a central role in the design and effectiveness\nof function-correcting codes. By focusing on a well-defined family of\nfunctions, function-correcting codes can be constructed with minimal length\nwhile still ensuring full error detection or correction within that family. In\nthis paper, we explore locally ($\\lambda,\\rho$)-functions and develop\nfunction-correcting codes using these functions for $b$-symbol read channels.\nWe establish the recurrence relation between the optimal redundancy of $(f,t)$\n-function-correcting codes for the $(b+1)$-read and $b$-read channels. We\nestablish an upper bound on the redundancy of general locally ($\\lambda,\\rho$,\n$b$)-function-correcting codes by linking it to the minimum achievable length\nof $b$-symbol error-correcting codes and traditional Hamming-metric codes,\ngiven a fixed number of codewords and a specified minimum distance.\nSpecifically, we present explicit upper bounds for the classes of\n($4,2t,b$)-local functions and ($2^b,2t,b$)-local functions. Additionally, for\nthe case where $b=1$, we show that a ($3,2t,1$)-local function achieves the\noptimal redundancy of $3t$ under certain conditions. Moreover, we explicitly\ninvestigate locality and redundancy for the weight distribution function.", "published": "2025-05-14 15:22:42", "link": "http://arxiv.org/abs/2505.09473v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Index Modulated Affine Frequency Division Multiplexing With Spread Spectrum", "abstract": "The recently proposed affine frequency division multiplexing (AFDM) is a new\ntransmission waveform that has shown excellent performance in high-mobility\nenvironments, making it a sensible option for the next-generation wireless\nnetworks. In this paper, we investigate an energy-efficient index modulation\nscheme for AFDM by leveraging spread spectrum, referred to as IM-AFDM-SS, to\ncombat the interference caused by the doubly dispersive channels. Specifically,\nthe information bits are conveyed by the transmitted symbols as well as the\nindices of the selected spreading codes in our proposed IM-AFDM-SS scheme. To\navoid extensive computations, we also develop a lowcomplexity maximal ratio\ncombining (MRC) detector algorithm, which recovers the spreading codes first\nand demodulates the symbols afterwards. Moreover, an upper bound on the bit\nerror rate (BER) of the proposed IM-AFDM-SS system with maximumlikelihood (ML)\ndetection is derived. Numerical results demonstrate the superiority of the\nproposed IM-AFDM-SS system over the classical AFDM spread spectrum (AFDM-SS)\nand the existing index modulated AFDM (IM-AFDM) systems.", "published": "2025-05-14 13:50:41", "link": "http://arxiv.org/abs/2505.09394v1", "categories": ["cs.IT", "cs.NA", "math.IT", "math.NA"], "primary_category": "cs.IT"}
{"title": "Theoretical and Experimental Assessment of Large Beam Codebook at mmWave Devices: How Much is Enough?", "abstract": "Modern millimeter wave (mmWave) transceivers come with a large number of\nantennas, each of which can support thousands of phase shifter configurations.\nThis capability enables beam sweeping with fine angular resolution, but results\nin large codebook sizes that can span more than six orders of magnitude. On the\nother hand, the mobility of user terminals and their randomly changing\norientations require constantly adjusting the beam direction. A key focus of\nrecent research has been on the design of beam sweeping codebooks that balance\na trade-off between the achievable gain and the beam search time, governed by\nthe codebook size. In this paper, we investigate the extent to which a large\ncodebook can be reduced to fewer steering vectors while covering the entire\nangular space and maintaining performance close to the maximum array gain. We\nderive a closed-form expression for the angular coverage range of a steering\nvector, subject to maintaining a gain loss within \\(\\gamma\\) dB (e.g., 2\\, dB)\nwith respect to the maximum gain achieved by an infinitely large codebook. We\ndemonstrate, both theoretically and experimentally, that a large beam-steering\ncodebooks (such as the \\(1024^{16}\\) set considered in our experiment) can be\nreduced to just a few steering vectors. This framework serves as a proof that\nonly a few steering vectors are sufficient to achieve near-maximum gain,\nchallenging the common belief that a large codebook with fine angular\nresolution is essential to fully reap the benefits of an antenna array.", "published": "2025-05-14 05:52:06", "link": "http://arxiv.org/abs/2505.09162v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Statistical Mean Estimation with Coded Relayed Observations", "abstract": "We consider a problem of statistical mean estimation in which the samples are\nnot observed directly, but are instead observed by a relay (``teacher'') that\ntransmits information through a memoryless channel to the decoder\n(``student''), who then produces the final estimate. We consider the minimax\nestimation error in the large deviations regime, and establish achievable error\nexponents that are tight in broad regimes of the estimation accuracy and\nchannel quality. In contrast, two natural baseline methods are shown to yield\nstrictly suboptimal error exponents. We initially focus on Bernoulli sources\nand binary symmetric channels, and then generalize to sub-Gaussian and\nheavy-tailed settings along with arbitrary discrete memoryless channels.", "published": "2025-05-14 03:07:05", "link": "http://arxiv.org/abs/2505.09098v1", "categories": ["cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "primary_category": "cs.IT"}
{"title": "Adaptively-weighted Nearest Neighbors for Matrix Completion", "abstract": "In this technical note, we introduce and analyze AWNN: an adaptively weighted\nnearest neighbor method for performing matrix completion. Nearest neighbor (NN)\nmethods are widely used in missing data problems across multiple disciplines\nsuch as in recommender systems and for performing counterfactual inference in\npanel data settings. Prior works have shown that in addition to being very\nintuitive and easy to implement, NN methods enjoy nice theoretical guarantees.\nHowever, the performance of majority of the NN methods rely on the appropriate\nchoice of the radii and the weights assigned to each member in the nearest\nneighbor set and despite several works on nearest neighbor methods in the past\ntwo decades, there does not exist a systematic approach of choosing the radii\nand the weights without relying on methods like cross-validation. AWNN\naddresses this challenge by judiciously balancing the bias variance trade off\ninherent in weighted nearest-neighbor regression. We provide theoretical\nguarantees for the proposed method under minimal assumptions and support the\ntheory via synthetic experiments.", "published": "2025-05-14 17:59:17", "link": "http://arxiv.org/abs/2505.09612v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "DataMIL: Selecting Data for Robot Imitation Learning with Datamodels", "abstract": "Recently, the robotics community has amassed ever larger and more diverse\ndatasets to train generalist robot policies. However, while these policies\nachieve strong mean performance across a variety of tasks, they often\nunderperform on individual, specialized tasks and require further tuning on\nnewly acquired task-specific data. Combining task-specific data with carefully\ncurated subsets of large prior datasets via co-training can produce better\nspecialized policies, but selecting data naively may actually harm downstream\nperformance. To address this, we introduce DataMIL, a policy-driven data\nselection framework built on the datamodels paradigm that reasons about data\nselection in an end-to-end manner, using the policy itself to identify which\ndata points will most improve performance. Unlike standard practices that\nfilter data using human notions of quality (e.g., based on semantic or visual\nsimilarity), DataMIL directly optimizes data selection for task success,\nallowing us to select data that enhance the policy while dropping data that\ndegrade it. To avoid performing expensive rollouts in the environment during\nselection, we use a novel surrogate loss function on task-specific data,\nallowing us to use DataMIL in the real world without degrading performance. We\nvalidate our approach on a suite of more than 60 simulation and real-world\nmanipulation tasks - most notably showing successful data selection from the\nOpen X-Embodiment datasets-demonstrating consistent gains in success rates and\nsuperior performance over multiple baselines. Our results underscore the\nimportance of end-to-end, performance-aware data selection for unlocking the\npotential of large prior datasets in robotics. More information at\nhttps://robin-lab.cs.utexas.edu/datamodels4imitation/", "published": "2025-05-14 17:55:10", "link": "http://arxiv.org/abs/2505.09603v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Adversarial Suffix Filtering: a Defense Pipeline for LLMs", "abstract": "Large Language Models (LLMs) are increasingly embedded in autonomous systems\nand public-facing environments, yet they remain susceptible to jailbreak\nvulnerabilities that may undermine their security and trustworthiness.\nAdversarial suffixes are considered to be the current state-of-the-art\njailbreak, consistently outperforming simpler methods and frequently succeeding\neven in black-box settings. Existing defenses rely on access to the internal\narchitecture of models limiting diverse deployment, increase memory and\ncomputation footprints dramatically, or can be bypassed with simple prompt\nengineering methods. We introduce $\\textbf{Adversarial Suffix Filtering}$\n(ASF), a lightweight novel model-agnostic defensive pipeline designed to\nprotect LLMs against adversarial suffix attacks. ASF functions as an input\npreprocessor and sanitizer that detects and filters adversarially crafted\nsuffixes in prompts, effectively neutralizing malicious injections. We\ndemonstrate that ASF provides comprehensive defense capabilities across both\nblack-box and white-box attack settings, reducing the attack efficacy of\nstate-of-the-art adversarial suffix generation methods to below 4%, while only\nminimally affecting the target model's capabilities in non-adversarial\nscenarios.", "published": "2025-05-14 17:52:10", "link": "http://arxiv.org/abs/2505.09602v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Online Isolation Forest", "abstract": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection.", "published": "2025-05-14 17:42:50", "link": "http://arxiv.org/abs/2505.09593v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Rhomboid Tiling for Geometric Graph Deep Learning", "abstract": "Graph Neural Networks (GNNs) have proven effective for learning from\ngraph-structured data through their neighborhood-based message passing\nframework. Many hierarchical graph clustering pooling methods modify this\nframework by introducing clustering-based strategies, enabling the construction\nof more expressive and powerful models. However, all of these message passing\nframework heavily rely on the connectivity structure of graphs, limiting their\nability to capture the rich geometric features inherent in geometric graphs. To\naddress this, we propose Rhomboid Tiling (RT) clustering, a novel clustering\nmethod based on the rhomboid tiling structure, which performs clustering by\nleveraging the complex geometric information of the data and effectively\nextracts its higher-order geometric structures. Moreover, we design RTPool, a\nhierarchical graph clustering pooling model based on RT clustering for graph\nclassification tasks. The proposed model demonstrates superior performance,\noutperforming 21 state-of-the-art competitors on all the 7 benchmark datasets.", "published": "2025-05-14 17:37:15", "link": "http://arxiv.org/abs/2505.09586v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SAD Neural Networks: Divergent Gradient Flows and Asymptotic Optimality via o-minimal Structures", "abstract": "We study gradient flows for loss landscapes of fully connected feed forward\nneural networks with commonly used continuously differentiable activation\nfunctions such as the logistic, hyperbolic tangent, softplus or GELU function.\nWe prove that the gradient flow either converges to a critical point or\ndiverges to infinity while the loss converges to an asymptotic critical value.\nMoreover, we prove the existence of a threshold $\\varepsilon>0$ such that the\nloss value of any gradient flow initialized at most $\\varepsilon$ above the\noptimal level converges to it. For polynomial target functions and sufficiently\nbig architecture and data set, we prove that the optimal loss value is zero and\ncan only be realized asymptotically. From this setting, we deduce our main\nresult that any gradient flow with sufficiently good initialization diverges to\ninfinity. Our proof heavily relies on the geometry of o-minimal structures. We\nconfirm these theoretical findings with numerical experiments and extend our\ninvestigation to real-world scenarios, where we observe an analogous behavior.", "published": "2025-05-14 17:15:11", "link": "http://arxiv.org/abs/2505.09572v1", "categories": ["cs.LG", "math.LO", "math.OC", "stat.ML", "Primary 68T05, Secondary 68T07, 26B40, 03C64, 03C98"], "primary_category": "cs.LG"}
{"title": "Scalable Computations for Generalized Mixed Effects Models with Crossed Random Effects Using Krylov Subspace Methods", "abstract": "Mixed effects models are widely used for modeling data with hierarchically\ngrouped structures and high-cardinality categorical predictor variables.\nHowever, for high-dimensional crossed random effects, current standard\ncomputations relying on Cholesky decompositions can become prohibitively slow.\nIn this work, we present novel Krylov subspace-based methods that address\nseveral existing computational bottlenecks. Among other things, we\ntheoretically analyze and empirically evaluate various preconditioners for the\nconjugate gradient and stochastic Lanczos quadrature methods, derive new\nconvergence results, and develop computationally efficient methods for\ncalculating predictive variances. Extensive experiments using simulated and\nreal-world data sets show that our proposed methods scale much better than\nCholesky-based computations, for instance, achieving a runtime reduction of\napproximately two orders of magnitudes for both estimation and prediction.\nMoreover, our software implementation is up to 10'000 times faster and more\nstable than state-of-the-art implementations such as lme4 and glmmTMB when\nusing default settings. Our methods are implemented in the free C++ software\nlibrary GPBoost with high-level Python and R packages.", "published": "2025-05-14 16:50:19", "link": "http://arxiv.org/abs/2505.09552v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Distilling Realizable Students from Unrealizable Teachers", "abstract": "We study policy distillation under privileged information, where a student\npolicy with only partial observations must learn from a teacher with full-state\naccess. A key challenge is information asymmetry: the student cannot directly\naccess the teacher's state space, leading to distributional shifts and policy\ndegradation. Existing approaches either modify the teacher to produce\nrealizable but sub-optimal demonstrations or rely on the student to explore\nmissing information independently, both of which are inefficient. Our key\ninsight is that the student should strategically interact with the teacher\n--querying only when necessary and resetting from recovery states --to stay on\na recoverable path within its own observation space. We introduce two methods:\n(i) an imitation learning approach that adaptively determines when the student\nshould query the teacher for corrections, and (ii) a reinforcement learning\napproach that selects where to initialize training for efficient exploration.\nWe validate our methods in both simulated and real-world robotic tasks,\ndemonstrating significant improvements over standard teacher-student baselines\nin training efficiency and final performance. The project website is available\nat : https://portal-cornell.github.io/CritiQ_ReTRy/", "published": "2025-05-14 16:45:51", "link": "http://arxiv.org/abs/2505.09546v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Depth-Based Local Center Clustering: A Framework for Handling Different Clustering Scenarios", "abstract": "Cluster analysis, or clustering, plays a crucial role across numerous\nscientific and engineering domains. Despite the wealth of clustering methods\nproposed over the past decades, each method is typically designed for specific\nscenarios and presents certain limitations in practical applications. In this\npaper, we propose depth-based local center clustering (DLCC). This novel method\nmakes use of data depth, which is known to produce a center-outward ordering of\nsample points in a multivariate space. However, data depth typically fails to\ncapture the multimodal characteristics of {data}, something of the utmost\nimportance in the context of clustering. To overcome this, DLCC makes use of a\nlocal version of data depth that is based on subsets of {data}. From this,\nlocal centers can be identified as well as clusters of varying shapes.\nFurthermore, we propose a new internal metric based on density-based clustering\nto evaluate clustering performance on {non-convex clusters}. Overall, DLCC is a\nflexible clustering approach that seems to overcome some limitations of\ntraditional clustering methods, thereby enhancing data analysis capabilities\nacross a wide range of application scenarios.", "published": "2025-05-14 16:08:11", "link": "http://arxiv.org/abs/2505.09516v1", "categories": ["stat.ME", "cs.LG", "stat.AP"], "primary_category": "stat.ME"}
{"title": "Deep-SITAR: A SITAR-Based Deep Learning Framework for Growth Curve Modeling via Autoencoders", "abstract": "Several approaches have been developed to capture the complexity and\nnonlinearity of human growth. One widely used is the Super Imposition by\nTranslation and Rotation (SITAR) model, which has become popular in studies of\nadolescent growth. SITAR is a shape-invariant mixed-effects model that\nrepresents the shared growth pattern of a population using a natural cubic\nspline mean curve while incorporating three subject-specific random effects --\ntiming, size, and growth intensity -- to account for variations among\nindividuals. In this work, we introduce a supervised deep learning framework\nbased on an autoencoder architecture that integrates a deep neural network\n(neural network) with a B-spline model to estimate the SITAR model. In this\napproach, the encoder estimates the random effects for each individual, while\nthe decoder performs a fitting based on B-splines similar to the classic SITAR\nmodel. We refer to this method as the Deep-SITAR model. This innovative\napproach enables the prediction of the random effects of new individuals\nentering a population without requiring a full model re-estimation. As a\nresult, Deep-SITAR offers a powerful approach to predicting growth\ntrajectories, combining the flexibility and efficiency of deep learning with\nthe interpretability of traditional mixed-effects models.", "published": "2025-05-14 15:55:16", "link": "http://arxiv.org/abs/2505.09506v1", "categories": ["stat.ML", "cs.LG", "F.2.2; I.2.7"], "primary_category": "stat.ML"}
{"title": "Towards Fair In-Context Learning with Tabular Foundation Models", "abstract": "Tabular foundational models have exhibited strong in-context learning (ICL)\ncapabilities on structured data, allowing them to make accurate predictions on\ntest sets without parameter updates, using training examples as context. This\nemerging approach positions itself as a competitive alternative to traditional\ngradient-boosted tree methods. However, while biases in conventional machine\nlearning models are well documented, it remains unclear how these biases\nmanifest in tabular ICL. The paper investigates the fairness implications of\ntabular ICL and explores three preprocessing strategies--correlation removal,\ngroup-balanced demonstration selection, and uncertainty-based demonstration\nselection--to address bias. Comprehensive experiments indicate that\nuncertainty-based demonstration selection consistently enhances group fairness\nof in-context predictions. The source code for reproducing the results of this\nwork can be found at https://github.com/patrikken/Fair-TabICL.", "published": "2025-05-14 15:53:14", "link": "http://arxiv.org/abs/2505.09503v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Layered Unlearning for Adversarial Relearning", "abstract": "Our goal is to understand how post-training methods, such as fine-tuning,\nalignment, and unlearning, modify language model behavior and representations.\nWe are particularly interested in the brittle nature of these modifications\nthat makes them easy to bypass through prompt engineering or relearning. Recent\nresults suggest that post-training induces shallow context-dependent\n``circuits'' that suppress specific response patterns. This could be one\nexplanation for the brittleness of post-training. To test this hypothesis, we\ndesign an unlearning algorithm, Layered Unlearning (LU), that creates distinct\ninhibitory mechanisms for a growing subset of the data. By unlearning the first\n$i$ folds while retaining the remaining $k - i$ at the $i$th of $k$ stages, LU\nlimits the ability of relearning on a subset of data to recover the full\ndataset. We evaluate LU through a combination of synthetic and large language\nmodel (LLM) experiments. We find that LU improves robustness to adversarial\nrelearning for several different unlearning methods. Our results contribute to\nthe state-of-the-art of machine unlearning and provide insight into the effect\nof post-training updates.", "published": "2025-05-14 15:50:45", "link": "http://arxiv.org/abs/2505.09500v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Reinforcement Learning for Individual Optimal Policy from Heterogeneous Data", "abstract": "Offline reinforcement learning (RL) aims to find optimal policies in dynamic\nenvironments in order to maximize the expected total rewards by leveraging\npre-collected data. Learning from heterogeneous data is one of the fundamental\nchallenges in offline RL. Traditional methods focus on learning an optimal\npolicy for all individuals with pre-collected data from a single episode or\nhomogeneous batch episodes, and thus, may result in a suboptimal policy for a\nheterogeneous population. In this paper, we propose an individualized offline\npolicy optimization framework for heterogeneous time-stationary Markov decision\nprocesses (MDPs). The proposed heterogeneous model with individual latent\nvariables enables us to efficiently estimate the individual Q-functions, and\nour Penalized Pessimistic Personalized Policy Learning (P4L) algorithm\nguarantees a fast rate on the average regret under a weak partial coverage\nassumption on behavior policies. In addition, our simulation studies and a real\ndata application demonstrate the superior numerical performance of the proposed\nmethod compared with existing methods.", "published": "2025-05-14 15:44:10", "link": "http://arxiv.org/abs/2505.09496v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Fairness-aware Bayes optimal functional classification", "abstract": "Algorithmic fairness has become a central topic in machine learning, and\nmitigating disparities across different subpopulations has emerged as a rapidly\ngrowing research area. In this paper, we systematically study the\nclassification of functional data under fairness constraints, ensuring the\ndisparity level of the classifier is controlled below a pre-specified\nthreshold. We propose a unified framework for fairness-aware functional\nclassification, tackling an infinite-dimensional functional space, addressing\nkey challenges from the absence of density ratios and intractability of\nposterior probabilities, and discussing unique phenomena in functional\nclassification. We further design a post-processing algorithm, Fair Functional\nLinear Discriminant Analysis classifier (Fair-FLDA), which targets at\nhomoscedastic Gaussian processes and achieves fairness via group-wise\nthresholding. Under weak structural assumptions on eigenspace, theoretical\nguarantees on fairness and excess risk controls are established. As a\nbyproduct, our results cover the excess risk control of the standard FLDA as a\nspecial case, which, to the best of our knowledge, is first time seen. Our\ntheoretical findings are complemented by extensive numerical experiments on\nsynthetic and real datasets, highlighting the practicality of our designed\nalgorithm.", "published": "2025-05-14 15:22:09", "link": "http://arxiv.org/abs/2505.09471v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Variational Rank Reduction Autoencoder", "abstract": "Deterministic Rank Reduction Autoencoders (RRAEs) enforce by construction a\nregularization on the latent space by applying a truncated SVD. While this\nregularization makes Autoencoders more powerful, using them for generative\npurposes is counter-intuitive due to their deterministic nature. On the other\nhand, Variational Autoencoders (VAEs) are well known for their generative\nabilities by learning a probabilistic latent space. In this paper, we present\nVariational Rank Reduction Autoencoders (VRRAEs), a model that leverages the\nadvantages of both RRAEs and VAEs. Our claims and results show that when\ncarefully sampling the latent space of RRAEs and further regularizing with the\nKullback-Leibler (KL) divergence (similarly to VAEs), VRRAEs outperform RRAEs\nand VAEs. Additionally, we show that the regularization induced by the SVD not\nonly makes VRRAEs better generators than VAEs, but also reduces the possibility\nof posterior collapse. Our results include a synthetic dataset of a small size\nthat showcases the robustness of VRRAEs against collapse, and three real-world\ndatasets; the MNIST, CelebA, and CIFAR-10, over which VRRAEs are shown to\noutperform both VAEs and RRAEs on many random generation and interpolation\ntasks based on the FID score.", "published": "2025-05-14 15:08:28", "link": "http://arxiv.org/abs/2505.09458v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenche-Young Losses", "abstract": "Surrogate regret bounds bridge the gap between the convergence rates of\nsurrogate and target losses, with linear bounds favorable for their lossless\nregret transfer. While convex smooth surrogate losses are appealing in\nparticular due to the efficient estimation and optimization, the existence of a\ntrade-off between the smoothness and linear regret bound has been believed in\nthe community. That being said, the better optimization and estimation\nproperties of convex smooth surrogate losses may inevitably deteriorate after\nundergoing the regret transfer onto a target loss. We overcome this dilemma for\narbitrary discrete target losses by constructing a convex smooth surrogate\nloss, which entails a linear surrogate regret bound composed with a tailored\nprediction link. The construction is based on Fenchel-Young losses generated by\nthe convolutional negentropy, which are equivalent to the infimal convolution\nof a generalized negentropy and the target Bayes risk. Consequently, the\ninfimal convolution enables us to derive a smooth loss while maintaining the\nsurrogate regret bound linear. We additionally benefit from the infimal\nconvolution to have a consistent estimator of the underlying class probability.\nOur results are overall a novel demonstration of how convex analysis penetrates\ninto optimization and statistical efficiency in risk minimization.", "published": "2025-05-14 14:37:32", "link": "http://arxiv.org/abs/2505.09432v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU", "abstract": "We present a method for training multi-task vision-language robotic diffusion\npolicies that reduces training time and memory usage by an order of magnitude.\nThis improvement arises from a previously underexplored distinction between\naction diffusion and the image diffusion techniques that inspired it: image\ngeneration targets are high-dimensional, while robot actions lie in a much\nlower-dimensional space. Meanwhile, the vision-language conditions for action\ngeneration remain high-dimensional. Our approach, Mini-Diffuser, exploits this\nasymmetry by introducing Level-2 minibatching, which pairs multiple noised\naction samples with each vision-language condition, instead of the conventional\none-to-one sampling strategy. To support this batching scheme, we introduce\narchitectural adaptations to the diffusion transformer that prevent information\nleakage across samples while maintaining full conditioning access. In RLBench\nsimulations, Mini-Diffuser achieves 95\\% of the performance of state-of-the-art\nmulti-task diffusion policies, while using only 5\\% of the training time and\n7\\% of the memory. Real-world experiments further validate that Mini-Diffuser\npreserves the key strengths of diffusion-based policies, including the ability\nto model multimodal action distributions and produce behavior conditioned on\ndiverse perceptual inputs. Code available at\ngithub.com/utomm/mini-diffuse-actor.", "published": "2025-05-14 14:34:40", "link": "http://arxiv.org/abs/2505.09430v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation", "abstract": "Large Language Models (LLMs) show growing promise in autonomous driving by\nreasoning over complex traffic scenarios to generate path plans. However, their\ntendencies toward overconfidence, and hallucinations raise critical safety\nconcerns. We introduce SafePath, a modular framework that augments LLM-based\npath planning with formal safety guarantees using conformal prediction.\nSafePath operates in three stages. In the first stage, we use an LLM that\ngenerates a set of diverse candidate paths, exploring possible trajectories\nbased on agent behaviors and environmental cues. In the second stage, SafePath\nfilters out high-risk trajectories while guaranteeing that at least one safe\noption is included with a user-defined probability, through a multiple-choice\nquestion-answering formulation that integrates conformal prediction. In the\nfinal stage, our approach selects the path with the lowest expected collision\nrisk when uncertainty is low or delegates control to a human when uncertainty\nis high. We theoretically prove that SafePath guarantees a safe trajectory with\na user-defined probability, and we show how its human delegation rate can be\ntuned to balance autonomy and safety. Extensive experiments on nuScenes and\nHighway-env show that SafePath reduces planning uncertainty by 77\\% and\ncollision rates by up to 70\\%, demonstrating effectiveness in making LLM-driven\npath planning more safer.", "published": "2025-05-14 14:28:24", "link": "http://arxiv.org/abs/2505.09427v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Independent Component Analysis by Robust Distance Correlation", "abstract": "Independent component analysis (ICA) is a powerful tool for decomposing a\nmultivariate signal or distribution into fully independent sources, not just\nuncorrelated ones. Unfortunately, most approaches to ICA are not robust against\noutliers. Here we propose a robust ICA method called RICA, which estimates the\ncomponents by minimizing a robust measure of dependence between multivariate\nrandom variables. The dependence measure used is the distance correlation\n(dCor). In order to make it more robust we first apply a new transformation\ncalled the bowl transform, which is bounded, one-to-one, continuous, and maps\nfar outliers to points close to the origin. This preserves the crucial property\nthat a zero dCor implies independence. RICA estimates the independent sources\nsequentially, by looking for the component that has the smallest dCor with the\nremainder. RICA is strongly consistent and has the usual parametric rate of\nconvergence. Its robustness is investigated by a simulation study, in which it\ngenerally outperforms its competitors. The method is illustrated on three\napplications, including the well-known cocktail party problem.", "published": "2025-05-14 14:25:43", "link": "http://arxiv.org/abs/2505.09425v1", "categories": ["stat.CO", "cs.LG"], "primary_category": "stat.CO"}
{"title": "Personalized Control for Lower Limb Prosthesis Using Kolmogorov-Arnold Networks", "abstract": "Objective: This paper investigates the potential of learnable activation\nfunctions in Kolmogorov-Arnold Networks (KANs) for personalized control in a\nlower-limb prosthesis. In addition, user-specific vs. pooled training data is\nevaluated to improve machine learning (ML) and Deep Learning (DL) performance\nfor turn intent prediction.\n  Method: Inertial measurement unit (IMU) data from the shank were collected\nfrom five individuals with lower-limb amputation performing turning tasks in a\nlaboratory setting. Ability to classify an upcoming turn was evaluated for\nMultilayer Perceptron (MLP), Kolmogorov-Arnold Network (KAN), convolutional\nneural network (CNN), and fractional Kolmogorov-Arnold Networks (FKAN). The\ncomparison of MLP and KAN (for ML models) and FKAN and CNN (for DL models)\nassessed the effectiveness of learnable activation functions. Models were\ntrained separately on user-specific and pooled data to evaluate the impact of\ntraining data on their performance.\n  Results: Learnable activation functions in KAN and FKAN did not yield\nsignificant improvement compared to MLP and CNN, respectively. Training on\nuser-specific data yielded superior results compared to pooled data for ML\nmodels ($p < 0.05$). In contrast, no significant difference was observed\nbetween user-specific and pooled training for DL models.\n  Significance: These findings suggest that learnable activation functions may\ndemonstrate distinct advantages in datasets involving more complex tasks and\nlarger volumes. In addition, pooled training showed comparable performance to\nuser-specific training in DL models, indicating that model training for\nprosthesis control can utilize data from multiple participants.", "published": "2025-05-14 13:18:57", "link": "http://arxiv.org/abs/2505.09366v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ARCANE -- Early Detection of Interplanetary Coronal Mass Ejections", "abstract": "Interplanetary coronal mass ejections (ICMEs) are major drivers of space\nweather disturbances, posing risks to both technological infrastructure and\nhuman activities. Automatic detection of ICMEs in solar wind in situ data is\nessential for early warning systems. While several methods have been proposed\nto identify these structures in time series data, robust real-time detection\nremains a significant challenge. In this work, we present ARCANE - the first\nframework explicitly designed for early ICME detection in streaming solar wind\ndata under realistic operational constraints, enabling event identification\nwithout requiring observation of the full structure. Our approach evaluates the\nstrengths and limitations of detection models by comparing a machine\nlearning-based method to a threshold-based baseline. The ResUNet++ model,\npreviously validated on science data, significantly outperforms the baseline,\nparticularly in detecting high-impact events, while retaining solid performance\non lower-impact cases. Notably, we find that using real-time solar wind (RTSW)\ndata instead of high-resolution science data leads to only minimal performance\ndegradation. Despite the challenges of operational settings, our detection\npipeline achieves an F1 score of 0.53, with an average detection delay of 21.5%\nof the event's duration while only seeing a minimal amount of data. As more\ndata becomes available, the performance increases significantly. These results\nmark a substantial step forward in automated space weather monitoring and lay\nthe groundwork for enhanced real-time forecasting capabilities.", "published": "2025-05-14 13:17:45", "link": "http://arxiv.org/abs/2505.09365v1", "categories": ["physics.space-ph", "astro-ph.IM", "astro-ph.SR", "cs.LG"], "primary_category": "physics.space-ph"}
{"title": "Efficient Mixed Precision Quantization in Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) have become essential for handling large-scale\ngraph applications. However, the computational demands of GNNs necessitate the\ndevelopment of efficient methods to accelerate inference. Mixed precision\nquantization emerges as a promising solution to enhance the efficiency of GNN\narchitectures without compromising prediction performance. Compared to\nconventional deep learning architectures, GNN layers contain a wider set of\ncomponents that can be quantized, including message passing functions,\naggregation functions, update functions, the inputs, learnable parameters, and\noutputs of these functions. In this paper, we introduce a theorem for efficient\nquantized message passing to aggregate integer messages. It guarantees\nnumerical equality of the aggregated messages using integer values with respect\nto those obtained with full (FP32) precision. Based on this theorem, we\nintroduce the Mixed Precision Quantization for GNN (MixQ-GNN) framework, which\nflexibly selects effective integer bit-widths for all components within GNN\nlayers. Our approach systematically navigates the wide set of possible\nbit-width combinations, addressing the challenge of optimizing efficiency while\naiming at maintaining comparable prediction performance. MixQ-GNN integrates\nwith existing GNN quantization methods, utilizing their graph structure\nadvantages to achieve higher prediction performance. On average, MixQ-GNN\nachieved reductions in bit operations of 5.5x for node classification and 5.1x\nfor graph classification compared to architectures represented in FP32\nprecision.", "published": "2025-05-14 13:11:39", "link": "http://arxiv.org/abs/2505.09361v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploiting the Potential Supervision Information of Clean Samples in Partial Label Learning", "abstract": "Diminishing the impact of false-positive labels is critical for conducting\ndisambiguation in partial label learning. However, the existing disambiguation\nstrategies mainly focus on exploiting the characteristics of individual partial\nlabel instances while neglecting the strong supervision information of clean\nsamples randomly lying in the datasets. In this work, we show that clean\nsamples can be collected to offer guidance and enhance the confidence of the\nmost possible candidates. Motivated by the manner of the differentiable count\nloss strat- egy and the K-Nearest-Neighbor algorithm, we proposed a new\ncalibration strategy called CleanSE. Specifically, we attribute the most\nreliable candidates with higher significance under the assumption that for each\nclean sample, if its label is one of the candidates of its nearest neighbor in\nthe representation space, it is more likely to be the ground truth of its\nneighbor. Moreover, clean samples offer help in characterizing the sample\ndistributions by restricting the label counts of each label to a specific\ninterval. Extensive experiments on 3 synthetic benchmarks and 5 real-world PLL\ndatasets showed this calibration strategy can be applied to most of the\nstate-of-the-art PLL methods as well as enhance their performance.", "published": "2025-05-14 13:04:55", "link": "http://arxiv.org/abs/2505.09354v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MUST: Multi-Scale Structural-Temporal Link Prediction Model for UAV Ad Hoc Networks", "abstract": "Link prediction in unmanned aerial vehicle (UAV) ad hoc networks (UANETs)\naims to predict the potential formation of future links between UAVs. In\nadversarial environments where the route information of UAVs is unavailable,\npredicting future links must rely solely on the observed historical topological\ninformation of UANETs. However, the highly dynamic and sparse nature of UANET\ntopologies presents substantial challenges in effectively capturing meaningful\nstructural and temporal patterns for accurate link prediction. Most existing\nlink prediction methods focus on temporal dynamics at a single structural scale\nwhile neglecting the effects of sparsity, resulting in insufficient information\ncapture and limited applicability to UANETs. In this paper, we propose a\nmulti-scale structural-temporal link prediction model (MUST) for UANETs.\nSpecifically, we first employ graph attention networks (GATs) to capture\nstructural features at multiple levels, including the individual UAV level, the\nUAV community level, and the overall network level. Then, we use long\nshort-term memory (LSTM) networks to learn the temporal dynamics of these\nmulti-scale structural features. Additionally, we address the impact of\nsparsity by introducing a sophisticated loss function during model\noptimization. We validate the performance of MUST using several UANET datasets\ngenerated through simulations. Extensive experimental results demonstrate that\nMUST achieves state-of-the-art link prediction performance in highly dynamic\nand sparse UANETs.", "published": "2025-05-14 12:26:46", "link": "http://arxiv.org/abs/2505.09331v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Accelerating Machine Learning Systems via Category Theory: Applications to Spherical Attention for Gene Regulatory Networks", "abstract": "How do we enable artificial intelligence models to improve themselves? This\nis central to exponentially improving generalized artificial intelligence\nmodels, which can improve their own architecture to handle new problem domains\nin an efficient manner that leverages the latest hardware. However, current\nautomated compilation methods are poor, and efficient algorithms require years\nof human development. In this paper, we use neural circuit diagrams, based in\ncategory theory, to prove a general theorem related to deep learning\nalgorithms, guide the development of a novel attention algorithm catered to the\ndomain of gene regulatory networks, and produce a corresponding efficient\nkernel. The algorithm we propose, spherical attention, shows that neural\ncircuit diagrams enable a principled and systematic method for reasoning about\ndeep learning architectures and providing high-performance code. By replacing\nSoftMax with an $L^2$ norm as suggested by diagrams, it overcomes the special\nfunction unit bottleneck of standard attention while retaining the streaming\nproperty essential to high-performance. Our diagrammatically derived\n\\textit{FlashSign} kernel achieves comparable performance to the\nstate-of-the-art, fine-tuned FlashAttention algorithm on an A100, and\n$3.6\\times$ the performance of PyTorch. Overall, this investigation shows\nneural circuit diagrams' suitability as a high-level framework for the\nautomated development of efficient, novel artificial intelligence\narchitectures.", "published": "2025-05-14 12:24:22", "link": "http://arxiv.org/abs/2505.09326v1", "categories": ["math.CT", "cs.LG", "q-bio.MN"], "primary_category": "math.CT"}
{"title": "Detecting Sybil Addresses in Blockchain Airdrops: A Subgraph-based Feature Propagation and Fusion Approach", "abstract": "Sybil attacks pose a significant security threat to blockchain ecosystems,\nparticularly in token airdrop events. This paper proposes a novel sybil address\nidentification method based on subgraph feature extraction lightGBM. The method\nfirst constructs a two-layer deep transaction subgraph for each address, then\nextracts key event operation features according to the lifecycle of sybil\naddresses, including the time of first transaction, first gas acquisition,\nparticipation in airdrop activities, and last transaction. These temporal\nfeatures effectively capture the consistency of sybil address behavior\noperations. Additionally, the method extracts amount and network structure\nfeatures, comprehensively describing address behavior patterns and network\ntopology through feature propagation and fusion. Experiments conducted on a\ndataset containing 193,701 addresses (including 23,240 sybil addresses) show\nthat this method outperforms existing approaches in terms of precision, recall,\nF1 score, and AUC, with all metrics exceeding 0.9. The methods and results of\nthis study can be further applied to broader blockchain security areas such as\ntransaction manipulation identification and token liquidity risk assessment,\ncontributing to the construction of a more secure and fair blockchain\necosystem.", "published": "2025-05-14 12:04:26", "link": "http://arxiv.org/abs/2505.09313v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Neural Multivariate Regression: Qualitative Insights from the Unconstrained Feature Model", "abstract": "The Unconstrained Feature Model (UFM) is a mathematical framework that\nenables closed-form approximations for minimal training loss and related\nperformance measures in deep neural networks (DNNs). This paper leverages the\nUFM to provide qualitative insights into neural multivariate regression, a\ncritical task in imitation learning, robotics, and reinforcement learning.\nSpecifically, we address two key questions: (1) How do multi-task models\ncompare to multiple single-task models in terms of training performance? (2)\nCan whitening and normalizing regression targets improve training performance?\nThe UFM theory predicts that multi-task models achieve strictly smaller\ntraining MSE than multiple single-task models when the same or stronger\nregularization is applied to the latter, and our empirical results confirm\nthese findings. Regarding whitening and normalizing regression targets, the UFM\ntheory predicts that they reduce training MSE when the average variance across\nthe target dimensions is less than one, and our empirical results once again\nconfirm these findings. These findings highlight the UFM as a powerful\nframework for deriving actionable insights into DNN design and data\npre-processing strategies.", "published": "2025-05-14 11:52:45", "link": "http://arxiv.org/abs/2505.09308v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adaptive Noise Resilient Keyword Spotting Using One-Shot Learning", "abstract": "Keyword spotting (KWS) is a key component of smart devices, enabling\nefficient and intuitive audio interaction. However, standard KWS systems\ndeployed on embedded devices often suffer performance degradation under\nreal-world operating conditions. Resilient KWS systems address this issue by\nenabling dynamic adaptation, with applications such as adding or replacing\nkeywords, adjusting to specific users, and improving noise robustness. However,\ndeploying resilient, standalone KWS systems with low latency on\nresource-constrained devices remains challenging due to limited memory and\ncomputational resources. This study proposes a low computational approach for\ncontinuous noise adaptation of pretrained neural networks used for KWS\nclassification, requiring only 1-shot learning and one epoch. The proposed\nmethod was assessed using two pretrained models and three real-world noise\nsources at signal-to-noise ratios (SNRs) ranging from 24 to -3 dB. The adapted\nmodels consistently outperformed the pretrained models across all scenarios,\nespecially at SNR $\\leq$ 18 dB, achieving accuracy improvements of 4.9% to\n46.0%. These results highlight the efficacy of the proposed methodology while\nbeing lightweight enough for deployment on resource-constrained devices.", "published": "2025-05-14 11:39:47", "link": "http://arxiv.org/abs/2505.09304v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On the Learning with Augmented Class via Forests", "abstract": "Decision trees and forests have achieved successes in various real\napplications, most working with all testing classes known in training data. In\nthis work, we focus on learning with augmented class via forests, where an\naugmented class may appear in testing data yet not in training data. We\nincorporate information of augmented class into trees' splitting, i.e., a new\nsplitting criterion, called augmented Gini impurity, is introduced to exploit\nsome unlabeled data from testing distribution. We then develop the approach\nnamed Learning with Augmented Class via Forests (LACForest), which constructs\nshallow forests based on the augmented Gini impurity and then splits forests\nwith pseudo-labeled augmented instances for better performance. We also develop\ndeep neural forests with a novel optimization objective based on our augmented\nGini impurity, so as to utilize the representation power of neural networks for\nforests. Theoretically, we present the convergence analysis for augmented Gini\nimpurity, and finally conduct experiments to verify the effectiveness of our\napproaches. The code is available at https://github.com/nju-xuf/LACForest/.", "published": "2025-05-14 11:22:22", "link": "http://arxiv.org/abs/2505.09294v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Ranking-Based At-Risk Student Prediction Using Federated Learning and Differential Features", "abstract": "Digital textbooks are widely used in various educational contexts, such as\nuniversity courses and online lectures. Such textbooks yield learning log data\nthat have been used in numerous educational data mining (EDM) studies for\nstudent behavior analysis and performance prediction. However, these studies\nhave faced challenges in integrating confidential data, such as academic\nrecords and learning logs, across schools due to privacy concerns.\nConsequently, analyses are often conducted with data limited to a single\nschool, which makes developing high-performing and generalizable models\ndifficult. This study proposes a method that combines federated learning and\ndifferential features to address these issues. Federated learning enables model\ntraining without centralizing data, thereby preserving student privacy.\nDifferential features, which utilize relative values instead of absolute\nvalues, enhance model performance and generalizability. To evaluate the\nproposed method, a model for predicting at-risk students was trained using data\nfrom 1,136 students across 12 courses conducted over 4 years, and validated on\nhold-out test data from 5 other courses. Experimental results demonstrated that\nthe proposed method addresses privacy concerns while achieving performance\ncomparable to that of models trained via centralized learning in terms of Top-n\nprecision, nDCG, and PR-AUC. Furthermore, using differential features improved\nprediction performance across all evaluation datasets compared to\nnon-differential approaches. The trained models were also applicable for early\nprediction, achieving high performance in detecting at-risk students in earlier\nstages of the semester within the validation datasets.", "published": "2025-05-14 11:12:30", "link": "http://arxiv.org/abs/2505.09287v1", "categories": ["cs.LG", "cs.CY", "I.2; I.6; K.3"], "primary_category": "cs.LG"}
{"title": "Generating Full-field Evolution of Physical Dynamics from Irregular Sparse Observations", "abstract": "Modeling and reconstructing multidimensional physical dynamics from sparse\nand off-grid observations presents a fundamental challenge in scientific\nresearch. Recently, diffusion-based generative modeling shows promising\npotential for physical simulation. However, current approaches typically\noperate on on-grid data with preset spatiotemporal resolution, but struggle\nwith the sparsely observed and continuous nature of real-world physical\ndynamics. To fill the gaps, we present SDIFT, Sequential DIffusion in\nFunctional Tucker space, a novel framework that generates full-field evolution\nof physical dynamics from irregular sparse observations. SDIFT leverages the\nfunctional Tucker model as the latent space representer with proven universal\napproximation property, and represents observations as latent functions and\nTucker core sequences. We then construct a sequential diffusion model with\ntemporally augmented UNet in the functional Tucker space, denoising noise drawn\nfrom a Gaussian process to generate the sequence of core tensors.\n  At the posterior sampling stage, we propose a Message-Passing Posterior\nSampling mechanism, enabling conditional generation of the entire sequence\nguided by observations at limited time steps. We validate SDIFT on three\nphysical systems spanning astronomical (supernova explosions, light-year\nscale), environmental (ocean sound speed fields, kilometer scale), and\nmolecular (organic liquid, millimeter scale) domains, demonstrating significant\nimprovements in both reconstruction accuracy and computational efficiency\ncompared to state-of-the-art approaches.", "published": "2025-05-14 11:09:15", "link": "http://arxiv.org/abs/2505.09284v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Enhanced Photonic Chip Design via Interpretable Machine Learning Techniques", "abstract": "Photonic chip design has seen significant advancements with the adoption of\ninverse design methodologies, offering flexibility and efficiency in optimizing\ndevice performance. However, the black-box nature of the optimization\napproaches, such as those used in inverse design in order to minimize a loss\nfunction or maximize coupling efficiency, poses challenges in understanding the\noutputs. This challenge is prevalent in machine learning-based optimization\nmethods, which can suffer from the same lack of transparency. To this end,\ninterpretability techniques address the opacity of optimization models. In this\nwork, we apply interpretability techniques from machine learning, with the aim\nof gaining understanding of inverse design optimization used in designing\nphotonic components, specifically two-mode multiplexers. We base our\nmethodology on the widespread interpretability technique known as local\ninterpretable model-agnostic explanations, or LIME. As a result, LIME-informed\ninsights point us to more effective initial conditions, directly improving\ndevice performance. This demonstrates that interpretability methods can do more\nthan explain models -- they can actively guide and enhance the inverse-designed\nphotonic components. Our results demonstrate the ability of interpretable\ntechniques to reveal underlying patterns in the inverse design process, leading\nto the development of better-performing components.", "published": "2025-05-14 10:32:50", "link": "http://arxiv.org/abs/2505.09266v1", "categories": ["physics.optics", "cs.LG", "quant-ph"], "primary_category": "physics.optics"}
{"title": "Stable and Convexified Information Bottleneck Optimization via Symbolic Continuation and Entropy-Regularized Trajectories", "abstract": "The Information Bottleneck (IB) method frequently suffers from unstable\noptimization, characterized by abrupt representation shifts near critical\npoints of the IB trade-off parameter, beta. In this paper, I introduce a novel\napproach to achieve stable and convex IB optimization through symbolic\ncontinuation and entropy-regularized trajectories. I analytically prove\nconvexity and uniqueness of the IB solution path when an entropy regularization\nterm is included, and demonstrate how this stabilizes representation learning\nacross a wide range of \\b{eta} values. Additionally, I provide extensive\nsensitivity analyses around critical points (beta) with statistically robust\nuncertainty quantification (95% confidence intervals). The open-source\nimplementation, experimental results, and reproducibility framework included in\nthis work offer a clear path for practical deployment and future extension of\nmy proposed method.", "published": "2025-05-14 09:27:09", "link": "http://arxiv.org/abs/2505.09239v1", "categories": ["cs.LG", "68T05, 90C25, 94A15", "I.2.6; G.1.6; H.1.1"], "primary_category": "cs.LG"}
{"title": "Optimal Transport-Based Domain Adaptation for Rotated Linear Regression", "abstract": "Optimal Transport (OT) has proven effective for domain adaptation (DA) by\naligning distributions across domains with differing statistical properties.\nBuilding on the approach of Courty et al. (2016), who mapped source data to the\ntarget domain for improved model transfer, we focus on a supervised DA problem\ninvolving linear regression models under rotational shifts. This ongoing work\nconsiders cases where source and target domains are related by a\nrotation-common in applications like sensor calibration or image orientation.\nWe show that in $\\mathbb{R}^2$ , when using a p-norm cost with $p $\\ge$ 2$, the\noptimal transport map recovers the underlying rotation. Based on this, we\npropose an algorithm that combines K-means clustering, OT, and singular value\ndecomposition (SVD) to estimate the rotation angle and adapt the regression\nmodel. This method is particularly effective when the target domain is sparsely\nsampled, leveraging abundant source data for improved generalization. Our\ncontributions offer both theoretical and practical insights into OT-based model\nadaptation under geometric transformations.", "published": "2025-05-14 09:06:40", "link": "http://arxiv.org/abs/2505.09229v1", "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "Birch SGD: A Tree Graph Framework for Local and Asynchronous SGD Methods", "abstract": "We propose a new unifying framework, Birch SGD, for analyzing and designing\ndistributed SGD methods. The central idea is to represent each method as a\nweighted directed tree, referred to as a computation tree. Leveraging this\nrepresentation, we introduce a general theoretical result that reduces\nconvergence analysis to studying the geometry of these trees. This perspective\nyields a purely graph-based interpretation of optimization dynamics, offering a\nnew and intuitive foundation for method development. Using Birch SGD, we design\neight new methods and analyze them alongside previously known ones, with at\nleast six of the new methods shown to have optimal computational time\ncomplexity. Our research leads to two key insights: (i) all methods share the\nsame \"iteration rate\" of $O\\left(\\frac{(R + 1) L \\Delta}{\\varepsilon} +\n\\frac{\\sigma^2 L \\Delta}{\\varepsilon^2}\\right)$, where $R$ the maximum \"tree\ndistance\" along the main branch of a tree; and (ii) different methods exhibit\ndifferent trade-offs-for example, some update iterates more frequently,\nimproving practical performance, while others are more communication-efficient\nor focus on other aspects. Birch SGD serves as a unifying framework for\nnavigating these trade-offs. We believe these results provide a unified\nfoundation for understanding, analyzing, and designing efficient asynchronous\nand parallel optimization methods.", "published": "2025-05-14 08:37:45", "link": "http://arxiv.org/abs/2505.09218v1", "categories": ["cs.LG", "cs.DC", "math.OC"], "primary_category": "cs.LG"}
{"title": "The Larger the Merrier? Efficient Large AI Model Inference in Wireless Edge Networks", "abstract": "The growing demand for large artificial intelligence model (LAIM) services is\ndriving a paradigm shift from traditional cloud-based inference to edge-based\ninference for low-latency, privacy-preserving applications. In particular,\nedge-device co-inference, which partitions LAIMs between edge devices and\nservers, has emerged as a promising strategy for resource-efficient LAIM\nexecution in wireless networks. In this paper, we investigate a pruning-aware\nLAIM co-inference scheme, where a pre-trained LAIM is pruned and partitioned\ninto on-device and on-server sub-models for deployment. For analysis, we first\nprove that the LAIM output distortion is upper bounded by its parameter\ndistortion. Then, we derive a lower bound on parameter distortion via\nrate-distortion theory, analytically capturing the relationship between pruning\nratio and co-inference performance. Next, based on the analytical results, we\nformulate an LAIM co-inference distortion bound minimization problem by jointly\noptimizing the pruning ratio, transmit power, and computation frequency under\nsystem latency, energy, and available resource constraints. Moreover, we\npropose an efficient algorithm to tackle the considered highly non-convex\nproblem. Finally, extensive simulations demonstrate the effectiveness of the\nproposed design. In particular, model parameter distortion is shown to provide\na reliable bound on output distortion. Also, the proposed joint pruning ratio\nand resource management design achieves superior performance in balancing\ntrade-offs among inference performance, system latency, and energy consumption\ncompared with benchmark schemes, such as fully on-device and on-server\ninference. Moreover, the split point is shown to play a critical role in system\nperformance optimization under heterogeneous and resource-limited edge\nenvironments.", "published": "2025-05-14 08:18:55", "link": "http://arxiv.org/abs/2505.09214v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quotient Complex Transformer (QCformer) for Perovskite Data Analysis", "abstract": "The discovery of novel functional materials is crucial in addressing the\nchallenges of sustainable energy generation and climate change. Hybrid\norganic-inorganic perovskites (HOIPs) have gained attention for their\nexceptional optoelectronic properties in photovoltaics. Recently, geometric\ndeep learning, particularly graph neural networks (GNNs), has shown strong\npotential in predicting material properties and guiding material design.\nHowever, traditional GNNs often struggle to capture the periodic structures and\nhigher-order interactions prevalent in such systems. To address these\nlimitations, we propose a novel representation based on quotient complexes\n(QCs) and introduce the Quotient Complex Transformer (QCformer) for material\nproperty prediction. A material structure is modeled as a quotient complex,\nwhich encodes both pairwise and many-body interactions via simplices of varying\ndimensions and captures material periodicity through a quotient operation. Our\nmodel leverages higher-order features defined on simplices and processes them\nusing a simplex-based Transformer module. We pretrain QCformer on benchmark\ndatasets such as the Materials Project and JARVIS, and fine-tune it on HOIP\ndatasets. The results show that QCformer outperforms state-of-the-art models in\nHOIP property prediction, demonstrating its effectiveness. The quotient complex\nrepresentation and QCformer model together contribute a powerful new tool for\npredictive modeling of perovskite materials.", "published": "2025-05-14 06:13:14", "link": "http://arxiv.org/abs/2505.09174v1", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "primary_category": "cs.LG"}
{"title": "Online Learning of Neural Networks", "abstract": "We study online learning of feedforward neural networks with the sign\nactivation function that implement functions from the unit ball in\n$\\mathbb{R}^d$ to a finite label set $\\{1, \\ldots, Y\\}$.\n  First, we characterize a margin condition that is sufficient and in some\ncases necessary for online learnability of a neural network: Every neuron in\nthe first hidden layer classifies all instances with some margin $\\gamma$\nbounded away from zero. Quantitatively, we prove that for any net, the optimal\nmistake bound is at most approximately $\\mathtt{TS}(d,\\gamma)$, which is the\n$(d,\\gamma)$-totally-separable-packing number, a more restricted variation of\nthe standard $(d,\\gamma)$-packing number. We complement this result by\nconstructing a net on which any learner makes $\\mathtt{TS}(d,\\gamma)$ many\nmistakes. We also give a quantitative lower bound of approximately\n$\\mathtt{TS}(d,\\gamma) \\geq \\max\\{1/(\\gamma \\sqrt{d})^d, d\\}$ when $\\gamma \\geq\n1/2$, implying that for some nets and input sequences every learner will err\nfor $\\exp(d)$ many times, and that a dimension-free mistake bound is almost\nalways impossible.\n  To remedy this inevitable dependence on $d$, it is natural to seek additional\nnatural restrictions to be placed on the network, so that the dependence on $d$\nis removed. We study two such restrictions. The first is the multi-index model,\nin which the function computed by the net depends only on $k \\ll d$ orthonormal\ndirections. We prove a mistake bound of approximately $(1.5/\\gamma)^{k + 2}$ in\nthis model. The second is the extended margin assumption. In this setting, we\nassume that all neurons (in all layers) in the network classify every ingoing\ninput from previous layer with margin $\\gamma$ bounded away from zero. In this\nmodel, we prove a mistake bound of approximately $(\\log Y)/ \\gamma^{O(L)}$,\nwhere L is the depth of the network.", "published": "2025-05-14 06:03:07", "link": "http://arxiv.org/abs/2505.09167v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Bridging Theory and Experiment in Materials Discovery: Machine-Learning-Assisted Prediction of Synthesizable Structures", "abstract": "Even though thermodynamic energy-based crystal structure prediction (CSP) has\nrevolutionized materials discovery, the energy-driven CSP approaches often\nstruggle to identify experimentally realizable metastable materials synthesized\nthrough kinetically controlled pathways, creating a critical gap between\ntheoretical predictions and experimental synthesis. Here, we propose a\nsynthesizability-driven CSP framework that integrates symmetry-guided structure\nderivation with a Wyckoff encode-based machine-learning model, allowing for the\nefficient localization of subspaces likely to yield highly synthesizable\nstructures. Within the identified promising subspaces, a structure-based\nsynthesizability evaluation model, fine-tuned using recently synthesized\nstructures to enhance predictive accuracy, is employed in conjunction with ab\ninitio calculations to systematically identify synthesizable candidates. The\nframework successfully reproduces 13 experimentally known XSe (X = Sc, Ti, Mn,\nFe, Ni, Cu, Zn) structures, demonstrating its effectiveness in predicting\nsynthesizable structures. Notably, 92,310 structures are filtered from the\n554,054 candidates predicted by GNoME, exhibiting great potential for promising\nsynthesizability. Additionally, eight thermodynamically favorable Hf-X-O (X =\nTi, V, and Mn) structures have been identified, among which three HfV$_2$O$_7$\ncandidates exhibit high synthesizability, presenting viable candidates for\nexperimental realization and potentially associated with experimentally\nobserved temperature-induced phase transitions. This work establishes a\ndata-driven paradigm for machine-learning-assisted inorganic materials\nsynthesis, highlighting its potential to bridge the gap between computational\npredictions and experimental realization while unlocking new opportunities for\nthe targeted discovery of novel functional materials.", "published": "2025-05-14 05:48:55", "link": "http://arxiv.org/abs/2505.09161v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Scaling Gaussian Process Regression with Full Derivative Observations", "abstract": "We present a scalable Gaussian Process (GP) method that can fit and predict\nfull derivative observations called DSoftKI. It extends SoftKI, a method that\napproximates a kernel via softmax interpolation from learned interpolation\npoint locations, to the setting with derivatives. DSoftKI enhances SoftKI's\ninterpolation scheme to incorporate the directional orientation of\ninterpolation points relative to the data. This enables the construction of a\nscalable approximate kernel, including its first and second-order derivatives,\nthrough interpolation. We evaluate DSoftKI on a synthetic function benchmark\nand high-dimensional molecular force field prediction (100-1000 dimensions),\ndemonstrating that DSoftKI is accurate and can scale to larger datasets with\nfull derivative observations than previously possible.", "published": "2025-05-14 04:35:26", "link": "http://arxiv.org/abs/2505.09134v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sequential Treatment Effect Estimation with Unmeasured Confounders", "abstract": "This paper studies the cumulative causal effects of sequential treatments in\nthe presence of unmeasured confounders. It is a critical issue in sequential\ndecision-making scenarios where treatment decisions and outcomes dynamically\nevolve over time. Advanced causal methods apply transformer as a backbone to\nmodel such time sequences, which shows superiority in capturing long time\ndependence and periodic patterns via attention mechanism. However, even they\ncontrol the observed confounding, these estimators still suffer from unmeasured\nconfounders, which influence both treatment assignments and outcomes. How to\nadjust the latent confounding bias in sequential treatment effect estimation\nremains an open challenge. Therefore, we propose a novel Decomposing Sequential\nInstrumental Variable framework for CounterFactual Regression (DSIV-CFR),\nrelying on a common negative control assumption. Specifically, an instrumental\nvariable (IV) is a special negative control exposure, while the previous\noutcome serves as a negative control outcome. This allows us to recover the IVs\nlatent in observation variables and estimate sequential treatment effects via a\ngeneralized moment condition. We conducted experiments on 4 datasets and\nachieved significant performance in one- and multi-step prediction, supported\nby which we can identify optimal treatments for dynamic systems.", "published": "2025-05-14 03:42:43", "link": "http://arxiv.org/abs/2505.09113v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Toward Malicious Clients Detection in Federated Learning", "abstract": "Federated learning (FL) enables multiple clients to collaboratively train a\nglobal machine learning model without sharing their raw data. However, the\ndecentralized nature of FL introduces vulnerabilities, particularly to\npoisoning attacks, where malicious clients manipulate their local models to\ndisrupt the training process. While Byzantine-robust aggregation rules have\nbeen developed to mitigate such attacks, they remain inadequate against more\nadvanced threats. In response, recent advancements have focused on FL detection\ntechniques to identify potentially malicious participants. Unfortunately, these\nmethods often misclassify numerous benign clients as threats or rely on\nunrealistic assumptions about the server's capabilities. In this paper, we\npropose a novel algorithm, SafeFL, specifically designed to accurately identify\nmalicious clients in FL. The SafeFL approach involves the server collecting a\nseries of global models to generate a synthetic dataset, which is then used to\ndistinguish between malicious and benign models based on their behavior.\nExtensive testing demonstrates that SafeFL outperforms existing methods,\noffering superior efficiency and accuracy in detecting malicious clients.", "published": "2025-05-14 03:36:36", "link": "http://arxiv.org/abs/2505.09110v1", "categories": ["cs.CR", "cs.DC", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Argus: Federated Non-convex Bilevel Learning over 6G Space-Air-Ground Integrated Network", "abstract": "The space-air-ground integrated network (SAGIN) has recently emerged as a\ncore element in the 6G networks. However, traditional centralized and\nsynchronous optimization algorithms are unsuitable for SAGIN due to\ninfrastructureless and time-varying environments. This paper aims to develop a\nnovel Asynchronous algorithm a.k.a. Argus for tackling non-convex and\nnon-smooth decentralized federated bilevel learning over SAGIN. The proposed\nalgorithm allows networked agents (e.g. autonomous aerial vehicles) to tackle\nbilevel learning problems in time-varying networks asynchronously, thereby\naverting stragglers from impeding the overall training speed. We provide a\ntheoretical analysis of the iteration complexity, communication complexity, and\ncomputational complexity of Argus. Its effectiveness is further demonstrated\nthrough numerical experiments.", "published": "2025-05-14 03:28:19", "link": "http://arxiv.org/abs/2505.09106v1", "categories": ["cs.LG", "68T07", "I.2"], "primary_category": "cs.LG"}
{"title": "Imitation Learning for Adaptive Control of a Virtual Soft Exoglove", "abstract": "The use of wearable robots has been widely adopted in rehabilitation training\nfor patients with hand motor impairments. However, the uniqueness of patients'\nmuscle loss is often overlooked. Leveraging reinforcement learning and a\nbiologically accurate musculoskeletal model in simulation, we propose a\ncustomized wearable robotic controller that is able to address specific muscle\ndeficits and to provide compensation for hand-object manipulation tasks. Video\ndata of a same subject performing human grasping tasks is used to train a\nmanipulation model through learning from demonstration. This manipulation model\nis subsequently fine-tuned to perform object-specific interaction tasks. The\nmuscle forces in the musculoskeletal manipulation model are then weakened to\nsimulate neurological motor impairments, which are later compensated by the\nactuation of a virtual wearable robotics glove. Results shows that integrating\nthe virtual wearable robotic glove provides shared assistance to support the\nhand manipulator with weakened muscle forces. The learned exoglove controller\nachieved an average of 90.5\\% of the original manipulation proficiency.", "published": "2025-05-14 03:09:21", "link": "http://arxiv.org/abs/2505.09099v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Generating time-consistent dynamics with discriminator-guided image diffusion models", "abstract": "Realistic temporal dynamics are crucial for many video generation, processing\nand modelling applications, e.g. in computational fluid dynamics, weather\nprediction, or long-term climate simulations. Video diffusion models (VDMs) are\nthe current state-of-the-art method for generating highly realistic dynamics.\nHowever, training VDMs from scratch can be challenging and requires large\ncomputational resources, limiting their wider application. Here, we propose a\ntime-consistency discriminator that enables pretrained image diffusion models\nto generate realistic spatiotemporal dynamics. The discriminator guides the\nsampling inference process and does not require extensions or finetuning of the\nimage diffusion model. We compare our approach against a VDM trained from\nscratch on an idealized turbulence simulation and a real-world global\nprecipitation dataset. Our approach performs equally well in terms of temporal\nconsistency, shows improved uncertainty calibration and lower biases compared\nto the VDM, and achieves stable centennial-scale climate simulations at daily\ntime steps.", "published": "2025-05-14 02:51:10", "link": "http://arxiv.org/abs/2505.09089v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Comparative Review of RNA Language Models", "abstract": "Given usefulness of protein language models (LMs) in structure and functional\ninference, RNA LMs have received increased attentions in the last few years.\nHowever, these RNA models are often not compared against the same standard.\nHere, we divided RNA LMs into three classes (pretrained on multiple RNA types\n(especially noncoding RNAs), specific-purpose RNAs, and LMs that unify RNA with\nDNA or proteins or both) and compared 13 RNA LMs along with 3 DNA and 1 protein\nLMs as controls in zero-shot prediction of RNA secondary structure and\nfunctional classification. Results shows that the models doing well on\nsecondary structure prediction often perform worse in function classification\nor vice versa, suggesting that more balanced unsupervised training is needed.", "published": "2025-05-14 02:40:13", "link": "http://arxiv.org/abs/2505.09087v1", "categories": ["q-bio.BM", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "AdaFortiTran: An Adaptive Transformer Model for Robust OFDM Channel Estimation", "abstract": "Deep learning models for channel estimation in Orthogonal Frequency Division\nMultiplexing (OFDM) systems often suffer from performance degradation under\nfast-fading channels and low-SNR scenarios. To address these limitations, we\nintroduce the Adaptive Fortified Transformer (AdaFortiTran), a novel model\nspecifically designed to enhance channel estimation in challenging\nenvironments. Our approach employs convolutional layers that exploit locality\nbias to capture strong correlations between neighboring channel elements,\ncombined with a transformer encoder that applies the global Attention mechanism\nto channel patches. This approach effectively models both long-range\ndependencies and spectro-temporal interactions within single OFDM frames. We\nfurther augment the model's adaptability by integrating nonlinear\nrepresentations of available channel statistics SNR, delay spread, and Doppler\nshift as priors. A residual connection is employed to merge global features\nfrom the transformer with local features from early convolutional processing,\nfollowed by final convolutional layers to refine the hierarchical channel\nrepresentation. Despite its compact architecture, AdaFortiTran achieves up to 6\ndB reduction in mean squared error (MSE) compared to state-of-the-art models.\nTested across a wide range of Doppler shifts (200-1000 Hz), SNRs (0 to 25 dB),\nand delay spreads (50-300 ns), it demonstrates superior robustness in\nhigh-mobility environments.", "published": "2025-05-14 02:22:37", "link": "http://arxiv.org/abs/2505.09076v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Risk Bounds For Distributional Regression", "abstract": "This work examines risk bounds for nonparametric distributional regression\nestimators. For convex-constrained distributional regression, general upper\nbounds are established for the continuous ranked probability score (CRPS) and\nthe worst-case mean squared error (MSE) across the domain. These theoretical\nresults are applied to isotonic and trend filtering distributional regression,\nyielding convergence rates consistent with those for mean estimation.\nFurthermore, a general upper bound is derived for distributional regression\nunder non-convex constraints, with a specific application to neural\nnetwork-based estimators. Comprehensive experiments on both simulated and real\ndata validate the theoretical contributions, demonstrating their practical\neffectiveness.", "published": "2025-05-14 02:22:12", "link": "http://arxiv.org/abs/2505.09075v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Single-shot prediction of parametric partial differential equations", "abstract": "We introduce Flexi-VAE, a data-driven framework for efficient single-shot\nforecasting of nonlinear parametric partial differential equations (PDEs),\neliminating the need for iterative time-stepping while maintaining high\naccuracy and stability. Flexi-VAE incorporates a neural propagator that\nadvances latent representations forward in time, aligning latent evolution with\nphysical state reconstruction in a variational autoencoder setting. We evaluate\ntwo propagation strategies, the Direct Concatenation Propagator (DCP) and the\nPositional Encoding Propagator (PEP), and demonstrate, through\nrepresentation-theoretic analysis, that DCP offers superior long-term\ngeneralization by fostering disentangled and physically meaningful latent\nspaces. Geometric diagnostics, including Jacobian spectral analysis, reveal\nthat propagated latent states reside in regions of lower decoder sensitivity\nand more stable local geometry than those derived via direct encoding,\nenhancing robustness for long-horizon predictions. We validate Flexi-VAE on\ncanonical PDE benchmarks, the 1D viscous Burgers equation and the 2D\nadvection-diffusion equation, achieving accurate forecasts across wide\nparametric ranges. The model delivers over 50x CPU and 90x GPU speedups\ncompared to autoencoder-LSTM baselines for large temporal shifts. These results\nposition Flexi-VAE as a scalable and interpretable surrogate modeling tool for\naccelerating high-fidelity simulations in computational fluid dynamics (CFD)\nand other parametric PDE-driven applications, with extensibility to\nhigher-dimensional and more complex systems.", "published": "2025-05-14 01:48:26", "link": "http://arxiv.org/abs/2505.09063v1", "categories": ["cs.LG", "cs.NA", "math.NA", "68T07"], "primary_category": "cs.LG"}
{"title": "Design of a Formation Control System to Assist Human Operators in Flying a Swarm of Robotic Blimps", "abstract": "Formation control is essential for swarm robotics, enabling coordinated\nbehavior in complex environments. In this paper, we introduce a novel formation\ncontrol system for an indoor blimp swarm using a specialized leader-follower\napproach enhanced with a dynamic leader-switching mechanism. This strategy\nallows any blimp to take on the leader role, distributing maneuvering demands\nacross the swarm and enhancing overall formation stability. Only the leader\nblimp is manually controlled by a human operator, while follower blimps use\nonboard monocular cameras and a laser altimeter for relative position and\naltitude estimation. A leader-switching scheme is proposed to assist the human\noperator to maintain stability of the swarm, especially when a sharp turn is\nperformed. Experimental results confirm that the leader-switching mechanism\neffectively maintains stable formations and adapts to dynamic indoor\nenvironments while assisting human operator.", "published": "2025-05-14 16:03:01", "link": "http://arxiv.org/abs/2505.09511v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Streaming Multi-agent Pathfinding", "abstract": "The task of the multi-agent pathfinding (MAPF) problem is to navigate a team\nof agents from their start point to the goal points. However, this setup is\nunsuitable in the assembly line scenario, which is periodic with a long working\nhour. To address this issue, the study formalizes the streaming MAPF (S-MAPF)\nproblem, which assumes that the agents in the same agent stream have a periodic\nstart time and share the same action sequence. The proposed solution, Agent\nStream Conflict-Based Search (ASCBS), is designed to tackle this problem by\nincorporating a cyclic vertex/edge constraint to handle conflicts.\nAdditionally, this work explores the potential usage of the disjoint splitting\nstrategy within ASCBS. Experimental results indicate that ASCBS surpasses\ntraditional MAPF solvers in terms of runtime for scenarios with prolonged\nworking hours.", "published": "2025-05-14 15:22:38", "link": "http://arxiv.org/abs/2505.09472v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Second-order invariant-domain preserving approximation to the multi-species Euler equations", "abstract": "This work is concerned with constructing a second-order, invariant-domain\npreserving approximation of the compressible multi-species Euler equations\nwhere each species is modeled by an ideal gas equation of state. We give the\nfull solution to the Riemann problem and derive its maximum wave speed. The\nmaximum wave speed is used in constructing a first-order invariant-domain\npreserving approximation. We then extend the methodology to second-order\naccuracy and detail a convex limiting technique which is used for preserving\nthe invariant domain. Finally, the numerical method is verified with analytical\nsolutions and then validated with several benchmarks and laboratory\nexperiments.", "published": "2025-05-14 17:30:40", "link": "http://arxiv.org/abs/2505.09581v1", "categories": ["math.NA", "cs.NA", "65M60, 65M12, 35L50, 35L65, 76M10"], "primary_category": "math.NA"}
{"title": "Primal-dual splitting methods for phase-field surfactant model with moving contact lines", "abstract": "Surfactants have important effects on the dynamics of droplets on solid\nsurfaces, which has inspired many industrial applications. Phase-field\nsurfactant model with moving contact lines (PFS-MCL) has been employed to\ninvestigate the complex droplet dynamics with surfactants, while its numerical\nsimulation remains challenging due to the coupling of gradient flows with\nrespect to transport distances involving nonlinear and degenerate mobilities.\nWe propose a novel structure-preserving variational scheme for PFS-MCL model\nwith the dynamic boundary condition based on the minimizing movement scheme and\noptimal transport theory for Wasserstein gradient flows. The proposed scheme\nconsists of a series of convex minimization problems and can be efficiently\nsolved by our proposed primal-dual splitting method and its accelerated\nversions. By respecting the underlying PDE's variational structure with respect\nto the transport distance, the proposed scheme is proved to inherits the\ndesirable properties including original energy dissipation, bound-preserving,\nand mass conservation. Through a suite of numerical simulations, we validate\nthe performance of the proposed scheme and investigate the effects of\nsurfactants on the droplet dynamics.", "published": "2025-05-14 15:20:53", "link": "http://arxiv.org/abs/2505.09469v1", "categories": ["math.NA", "cs.NA", "math.OC", "physics.comp-ph", "35A15, 35Q35, 35Q70, 47J25, 47J35, 65K10, 76M30"], "primary_category": "math.NA"}
{"title": "Injectivity of boundary integral operator in direct-indirect mixed Burton-Miller equation for wave scattering problems with transmissive circular inclusion", "abstract": "This study proves that the injectivity condition for the integral operator of\nthe direct-indirect mixed Burton-Miller (BM) boundary integral equation (BIE)\nfor Helmholtz transmission problems is identical to that for the ordinary BM\nBIE for Helmholtz transmission problems with a transmissive circular inclusion.\nAlthough some numerical methods based on the direct-indirect mixed BM BIE can\nbe computed faster than the ordinary BM BIE, its well-posedness has been\nunclear. This study resolves a part of the well-posedness, namely the\ninjectivity of the integral operator with a transmissive circular inclusion.", "published": "2025-05-14 08:34:31", "link": "http://arxiv.org/abs/2505.09217v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "Quasi-3D beam theory based on equilibrium stress definition and mixed element model for accurate analysis of functionally graded beams", "abstract": "This paper presents a novel quasi-3D theory and the corresponding mixed beam\nelement model to achieve accurate solutions for functionally graded beams. The\nkey innovations include the development of equilibrium-based stress\nexpressions, the modified cross-sectional stiffness matrix, and the mixed beam\nelement model based on semi-analytical definition of internal force fields. In\ncontrast to the conventional quasi-3D theory where stress expressions are\nderived from constitutive equations and geometric relations, the stress\nexpressions in this study are derived from the differential equilibrium\nequations among stresses, ensuring strict adherence of stress solutions to\nequilibrium conditions. To incorporate the influence of equilibrium-derived\nstress distributions, the modified cross-sectional stiffness matrix is derived,\nenhancing the theoretical and practical feasibility of the beam model. For beam\nelement construction, the mixed variational principle of two-field variables is\nemployed, with generalized internal forces and generalized displacements\nregarded as two independent fields. Especially, semi-analytical internal force\nfields, which partially satisfy the differential equilibrium equations, are\nintroduced to improve the element performance. Numerical examples are conducted\nto verify the accuracy and effectiveness of the proposed theory and beam\nelement.", "published": "2025-05-14 04:15:14", "link": "http://arxiv.org/abs/2505.09127v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Derivative-free optimization is competitive for aerodynamic design optimization in moderate dimensions", "abstract": "Aerodynamic design optimization is an important problem in aircraft design\nthat depends on the interplay between a numerical optimizer and a high-fidelity\nflow physics solver. Derivative-based, first and (quasi) second order,\noptimization techniques are the de facto choice, particularly given the\navailability of the adjoint method and its ability to efficiently compute\ngradients at the cost of just one solution of the forward problem. However,\nimplementation of the adjoint method requires careful mathematical treatment,\nand its sensitivity to changes in mesh quality limits widespread applicability.\nDerivative-free approaches are often overlooked for large scale optimization,\nciting their lack of scalability in higher dimensions and/or the lack of\npractical interest in globally optimal solutions that they often target.\nHowever, breaking free from an adjoint solver can be paradigm-shifting in\nbroadening the applicability of aerodynamic design optimization. We provide a\nsystematic benchmarking of a select sample of widely used derivative-based and\nderivative-free optimization algorithms on the design optimization of three\ncanonical aerodynamic bodies, namely, the NACA0012 and RAE2822 airfoils, and\nthe ONERAM6 wing. Our results demonstrate that derivative-free methods are\ncompetitive with derivative-based methods, while outperforming them\nconsistently in the high-dimensional setting. These findings highlight the\npractical competitiveness of modern derivative-free strategies, offering a\nscalable and robust alternative for aerodynamic design optimization when\nadjoint-based gradients are unavailable or unreliable.", "published": "2025-05-14 02:51:02", "link": "http://arxiv.org/abs/2505.09088v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Vertex-based auxiliary space multigrid method and its application to linear elasticity equations", "abstract": "In this paper, a vertex-based auxiliary space multigrid(V-ASMG) method as a\npreconditioner of the PCG method is proposed for solving the large sparse\nlinear equations derived from the linear elasticity equations. The main key of\nsuch V-ASMG method lies in an auxiliary region-tree structure based on the\ngeometrically regular subdivision. The computational complexity of building\nsuch a region-tree is $\\mathcal{O}\\left(q N\\log_2 N\\right)$, where $N$ is the\nnumber of the given original grid vertices and $q$ is the power of the ratio of\nthe maximum distance $d_{max}$ to minimum distance $d_{min}$ between the given\noriginal grid vertices. The process of constructing the auxiliary region-tree\nis similar to the method in [17], but the selection of the representative\npoints is changed. To be more specific, instead of choosing the barycenters,\nthe correspondence between each grid layer is constructed based on the position\nrelationship of the grid vertices. There are two advantages for this approach:\nthe first is its simplicity, there is no need to deal with hanging points when\nbuilding the auxiliary region-tree, and it is possible to construct the\nrestriction/prolongation operator directly by using the bilinear interpolation\nfunction, and it is easy to be generalized to other problems as well, due to\nall the information we need is only the grid vertices; the second is its strong\nconvergence, the corresponding relative residual can quickly converge to the\ngiven tolerance(It is taken to be $10^{-6}$ in this paper), thus obtaining the\ndesired numerical solution. Two- and three-dimensional numerical experiments\nare given to verify the strong convergence of the proposed V-ASMG method as a\npreconditioner of the PCG method.", "published": "2025-05-14 01:48:47", "link": "http://arxiv.org/abs/2505.09064v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A federated Kaczmarz algorithm", "abstract": "In this paper, we propose a federated algorithm for solving large linear\nsystems that is inspired by the classic randomized Kaczmarz algorithm. We\nprovide convergence guarantees of the proposed method, and as a corollary of\nour analysis, we provide a new proof for the convergence of the classic\nrandomized Kaczmarz method. We demonstrate experimentally the behavior of our\nmethod when applied to related problems. For underdetermined systems, we\ndemonstrate that our algorithm can be used for sparse approximation. For\ninconsistent systems, we demonstrate that our algorithm converges to a horizon\nof the least squares solution. Finally, we apply our algorithm to real data and\nshow that it is consistent with the selection of Lasso, while still offering\nthe computational advantages of the Kaczmarz framework and thresholding-based\nalgorithms in the federated setting.", "published": "2025-05-14 01:46:00", "link": "http://arxiv.org/abs/2505.09061v1", "categories": ["math.NA", "cs.NA", "65F10 (Primary)"], "primary_category": "math.NA"}
{"title": "Fast Learning in Quantitative Finance with Extreme Learning Machine", "abstract": "This paper demonstrates that a broad class of problems in quantitative\nfinance, including those previously addressed using deep neural networks, can\nbe efficiently solved using single-layer neural networks without iterative\ngradient-based training, namely extreme learning machine (ELM). ELM utilizes a\nsingle-layer network with randomly initialized hidden nodes and analytically\ncomputed output weights obtained via convex optimization, enabling rapid\ntraining and inference. Both supervised and unsupervised learning tasks are\nexplored.\n  In supervised learning, ELM is employed to learn parametric option pricing\nfunctions, predict intraday stock returns, and complete implied volatility\nsurfaces. Compared with deep neural networks, Gaussian process regression, and\nlogistic regression, ELM achieves higher computational speed, comparable\naccuracy, and superior generalization.\n  In unsupervised learning, ELM numerically solves Black-Scholes-type PDEs, and\noutperforms Physics-Informed Neural Networks in training speed without losing\nprecision. The approximation and generalization abilities of ELM are briefly\ndiscussed.\n  The findings establish ELM as a practical and efficient tool for various\ntasks in quantitative finance.", "published": "2025-05-14 16:49:47", "link": "http://arxiv.org/abs/2505.09551v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Monte-Carlo Option Pricing in Quantum Parallel", "abstract": "Financial derivative pricing is a significant challenge in finance, involving\nthe valuation of instruments like options based on underlying assets. While\nsome cases have simple solutions, many require complex classical computational\nmethods like Monte Carlo simulations and numerical techniques. However, as\nderivative complexities increase, these methods face limitations in\ncomputational power. Cases involving Non-Vanilla Basket pricing, American\nOptions, and derivative portfolio risk analysis need extensive computations in\nhigher-dimensional spaces, posing challenges for classical computers.\n  Quantum computing presents a promising avenue by harnessing quantum\nsuperposition and entanglement, allowing the handling of high-dimensional\nspaces effectively. In this paper, we introduce a self-contained and\nall-encompassing quantum algorithm that operates without reliance on oracles or\npresumptions. More specifically, we develop an effective stochastic method for\nsimulating exponentially many potential asset paths in quantum parallel,\nleading to a highly accurate final distribution of stock prices. Furthermore,\nwe demonstrate how this algorithm can be extended to price more complex options\nand analyze risk within derivative portfolios.", "published": "2025-05-14 15:10:27", "link": "http://arxiv.org/abs/2505.09459v1", "categories": ["q-fin.CP", "quant-ph"], "primary_category": "q-fin.CP"}
{"title": "FLUXLAYER: High-Performance Design for Cross-chain Fragmented Liquidity", "abstract": "Autonomous Market Makers (AMMs) rely on arbitrage to facilitate passive price\nupdates. Liquidity fragmentation poses a complex challenge across different\nblockchain networks.\n  This paper proposes FluxLayer, a solution to mitigate fragmented liquidity\nand capture the maximum extractable value (MEV) in a cross-chain environment.\nFluxLayer is a three-layer framework that integrates a settlement layer, an\nintent layer, and an under-collateralised leverage lending vault mechanism. Our\nevaluation demonstrates that FluxLayer can effectively enhance cross-chain MEV\nby capturing more arbitrage opportunities, reducing costs, and improving\noverall liquidity.", "published": "2025-05-14 14:23:56", "link": "http://arxiv.org/abs/2505.09423v1", "categories": ["q-fin.CP", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Gatheral double stochastic volatility model with Skorokhod reflection", "abstract": "We investigate the Gatheral model of double mean-reverting stochastic\nvolatility, in which the drift term itself follows a mean-reverting process,\nand the overall model exhibits mean-reverting behavior. We demonstrate that\nsuch processes can attain values arbitrarily close to zero and remain near zero\nfor extended periods, making them practically and statistically\nindistinguishable from zero. To address this issue, we propose a modified model\nincorporating Skorokhod reflection, which preserves the model's flexibility\nwhile preventing volatility from approaching zero.", "published": "2025-05-14 06:30:33", "link": "http://arxiv.org/abs/2505.09184v1", "categories": ["q-fin.MF", "math.PR", "q-fin.PR", "60H10, 91G30, 91G80"], "primary_category": "q-fin.MF"}
{"title": "Omni-R1: Do You Really Need Audio to Fine-Tune Your Audio LLM?", "abstract": "We propose Omni-R1 which fine-tunes a recent multi-modal LLM, Qwen2.5-Omni,\non an audio question answering dataset with the reinforcement learning method\nGRPO. This leads to new State-of-the-Art performance on the recent MMAU\nbenchmark. Omni-R1 achieves the highest accuracies on the sounds, music,\nspeech, and overall average categories, both on the Test-mini and Test-full\nsplits. To understand the performance improvement, we tested models both with\nand without audio and found that much of the performance improvement from GRPO\ncould be attributed to better text-based reasoning. We also made a surprising\ndiscovery that fine-tuning without audio on a text-only dataset was effective\nat improving the audio-based performance.", "published": "2025-05-14 14:47:16", "link": "http://arxiv.org/abs/2505.09439v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SingNet: Towards a Large-Scale, Diverse, and In-the-Wild Singing Voice Dataset", "abstract": "The lack of a publicly-available large-scale and diverse dataset has long\nbeen a significant bottleneck for singing voice applications like Singing Voice\nSynthesis (SVS) and Singing Voice Conversion (SVC). To tackle this problem, we\npresent SingNet, an extensive, diverse, and in-the-wild singing voice dataset.\nSpecifically, we propose a data processing pipeline to extract ready-to-use\ntraining data from sample packs and songs on the internet, forming 3000 hours\nof singing voices in various languages and styles. Furthermore, to facilitate\nthe use and demonstrate the effectiveness of SingNet, we pre-train and\nopen-source various state-of-the-art (SOTA) models on Wav2vec2, BigVGAN, and\nNSF-HiFiGAN based on our collected singing voice data. We also conduct\nbenchmark experiments on Automatic Lyric Transcription (ALT), Neural Vocoder,\nand Singing Voice Conversion (SVC). Audio demos are available at:\nhttps://singnet-dataset.github.io/.", "published": "2025-05-14 12:24:05", "link": "http://arxiv.org/abs/2505.09325v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On Properties of Phase-Conjugation Focusing for Large Intelligent Surface Applications -- Part I: Vertical Polarization", "abstract": "Large intelligent surface (LIS) is one promising path to leverage 6G\nperformance in sub-10 GHz bands. This two-part paper explores the properties of\nphase-conjugation focusing for a simplified LIS setup with a two-dimensional\n(2D) circular antenna array and a user antenna located within the array\naperture in the same plane. In Part I of this article, we assume vertical\npolarization for all antenna elements, whereas Part II assumes horizontal\npolarization. In Part I, we focus on the effect of array radius on the peak\ngain, 3 dB focusing width, and sidelobes for two types of circular arrays. The\nnumerical results show that the gain minimum is located at the array center.\nThe peak gain varies by less than 0.5 dB for focal points located within 2 from\nthe array center. Similarly, the focal width and sidelobe level are also stable\nwithin this region, irrespective of array radius. From 2 from the center to the\narray edge, the closer proximity of the focal points to some array elements\nthan other elements results in more drastic changes in these NFF properties.\nFinally, full-wave simulation using Ansys HFSS is used to partially validate\nthe numerical results.", "published": "2025-05-14 17:48:36", "link": "http://arxiv.org/abs/2505.09599v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Properties of Phase-Conjugation Focusing for Large Intelligent Surface Applications -- Part II: Horizontal Polarization", "abstract": "Near-field focusing (NFF) forms the basis for several applications of large\nintelligent surface (LIS) in sub-10 GHz bands, including wireless\ncommunications, wireless power transfer, positioning, and sensing. In this\ntwo-part paper, Part I analyzed the properties of phase conjugation NFF for\nvertically polarized antennas, in a circular array configuration. In Part II of\nthis article, we continue to study phase conjugation NFF for circular arrays,\nbut for horizontally polarized antennas. We investigate the focusing\ncharacteristics of a circular array in two distinct configurations. The\nnumerical results show that the first configuration where all the antenna\nelements (including the user antenna) are aligned offers significant better\nperformance in terms of peak gain, 3 dB focal width and sidelobe level,\nrelative to the second configuration where the broadside of the elements faces\nthe array center. This result points to the beneficial use of orthogonally\noriented horizontally polarized antenna at the user to allow for flexible\npolarization alignment with the fixed array orientation. In addition, the\nvertical polarized circular array of Part I may be merged with the first\nconfiguration of Part II to provide optimal NFF to a randomly oriented user\nequipment with a polarization reconfigurable tripole antenna.", "published": "2025-05-14 17:43:14", "link": "http://arxiv.org/abs/2505.09594v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Wearable Tracking of Eye and Body Movements During Breaching Training: Towards Real-Time Blast Injury Monitoring", "abstract": "Repeated exposure to blast overpressure in occupational settings has been\nassociated with changes in cognitive and psychological health, as well as\ndeficits in neurosensory subsystems. In this work, we describe a wearable\nsystem to simultaneously monitor physiology and blast exposure levels and\ndemonstrate how this system can identify individualized exposure levels\ncorresponding to acute physiological response to blast exposure. Machine\nlearning was used to develop a dose-response model that fused multiple\nphysiological measures (electrooculuography, gait, and balance) into a single\nrisk score by predicting the level of blast exposure on held-out subjects\n(Fused model, R = 0.60). We found that blast events with peak pressure levels\nas low as 0.25 psi could be related to physiological changes and hence may\ncontribute to blast injury. We also identified an individual subject with\ndeteriorating reaction time scores that consistently showed a rapid and\nanomalous change in physiology-based risk scores after exposure to low-level\nblast events. Our results suggest that the wearable approach to blast\nmonitoring is viable in weapons training environments as a complement to more\ndirect but sparsely administered brain health assessments, potentially viable\nin austere environments, and that fusing multiple physiological signals can\nimprove sensitivity.", "published": "2025-05-14 15:59:44", "link": "http://arxiv.org/abs/2505.09508v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Empirical Study on Near-Field and Spatial Non-Stationarity Modeling for THz XL-MIMO Channel in Indoor Scenario", "abstract": "Terahertz (THz) extremely large-scale MIMO (XL-MIMO) is considered a key\nenabling technology for 6G and beyond due to its advantages such as wide\nbandwidth and high beam gain. As the frequency and array size increase, users\nare more likely to fall within the near-field (NF) region, where the far-field\nplane-wave assumption no longer holds. This also introduces spatial\nnon-stationarity (SnS), as different antenna elements observe distinct\nmultipath characteristics. Therefore, this paper proposes a THz XL-MIMO channel\nmodel that accounts for both NF propagation and SnS, validated using channel\nmeasurement data. In this work, we first conduct THz XL-MIMO channel\nmeasurements at 100 GHz and 132 GHz using 301- and 531-element ULAs in indoor\nenvironments, revealing pronounced NF effects characterized by nonlinear\ninter-element phase variations, as well as element-dependent delay and angle\nshifts. Moreover, the SnS phenomenon is observed, arising not only from\nblockage but also from inconsistent reflection or scattering. Based on these\nobservations, a hybrid NF channel modeling approach combining the\nscatterer-excited point-source model and the specular reflection model is\nproposed to capture nonlinear phase variation. For SnS modeling, amplitude\nattenuation factors (AAFs) are introduced to characterize the continuous\nvariation of path power across the array. By analyzing the statistical\ndistribution and spatial autocorrelation properties of AAFs, a statistical\nrank-matching-based method is proposed for their generation. Finally, the model\nis validated using measured data. Evaluation across metrics such as entropy\ncapacity, condition number, spatial correlation, channel gain, Rician K-factor,\nand RMS delay spread confirms that the proposed model closely aligns with\nmeasurements and effectively characterizes the essential features of THz\nXL-MIMO channels.", "published": "2025-05-14 13:54:05", "link": "http://arxiv.org/abs/2505.09398v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Optimum and Adaptive Complex-Valued Bilinear Filters", "abstract": "The identification of nonlinear systems is a frequent task in digital signal\nprocessing. Such nonlinear systems may be grouped into many sub-classes,\nwhereby numerous nonlinear real-world systems can be approximated as bilinear\n(BL) models. Therefore, various optimum and adaptive BL filters have been\nintroduced in recent years. Further, in many applications such as\ncommunications and radar, complex-valued (CV) BL systems in combination with CV\nsignals may occur. Hence, in this work, we investigate the extension of\nreal-valued (RV) BL filters to CV BL filters. First, we derive CV BL filters by\napplying two or four RV BL filters, and compare them with respect to their\ncomputational complexity and performance. Second, we introduce novel fully CV\nBL filters, such as the CV BL Wiener filter (WF), the CV BL least squares (LS)\nfilter, the CV BL least mean squares (LMS) filter, the CV BL normalized LMS\n(NLMS) filter, and the CV BL recursive least squares (RLS) filter. Finally,\nthese filters are applied to identify multiple-input-single-output (MISO)\nsystems and Hammerstein models.", "published": "2025-05-14 08:25:05", "link": "http://arxiv.org/abs/2505.09215v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Trellis Waveform Shaping for Sidelobe Reduction in Integrated Sensing and Communications: A Duality with PAPR Mitigation", "abstract": "A key challenge in integrated sensing and communications (ISAC) is the\nsynthesis of waveforms that can modulate communication messages and achieve\ngood sensing performance simultaneously. In ISAC systems, standard\ncommunication waveforms can be adapted for sensing, as the sensing receiver\n(co-located with the transmitter) has knowledge of the communication message\nand consequently the waveform. However, the randomness of communications may\nresult in waveforms that have high sidelobes masking weak targets. Thus, it is\ndesirable to refine communication waveforms to improve the sensing performance\nby reducing the integrated sidelobe levels (ISL). This is similar to the\npeak-to-average power ratio (PAPR) mitigation in orthogonal frequency division\nmultiplexing (OFDM), in which the OFDM-modulated waveform needs to be refined\nto reduce the PAPR. In this paper, inspired by PAPR reduction algorithms in\nOFDM, we employ trellis shaping in OFDM-based ISAC systems to refine waveforms\nfor specific sensing metrics using convolutional codes and Viterbi decoding. In\nsuch a scheme, the communication data is encoded and then mapped to the\nsignaling constellation in different subcarriers, such that the time-domain\nsidelobes are reduced. An interesting observation is that sidelobe reduction in\nOFDM-based ISAC is dual to PAPR reduction in OFDM, thereby sharing a similar\nsignaling structure. Numerical simulations and hardware software defined radio\nUSRP experiments are carried out to demonstrate the effectiveness of the\nproposed trellis shaping approach.", "published": "2025-05-14 06:12:10", "link": "http://arxiv.org/abs/2505.09173v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Automated SAR ADC Sizing Using Analytical Equations", "abstract": "Conventional analog and mixed-signal (AMS) circuit designs heavily rely on\nmanual effort, which is time-consuming and labor-intensive. This paper presents\na fully automated design methodology for Successive Approximation Register\n(SAR) Analog-to-Digital Converters (ADCs) from performance specifications to\ncomplete transistor sizing. To tackle the high-dimensional sizing problem, we\npropose a dual optimization scheme. The system-level optimization iteratively\npartitions the overall requirements and analytically maps them to subcircuit\ndesign specifications, while local optimization loops determines the\nsubcircuits' design parameters. The dependency graph-based framework serializes\nthe simulations for verification, knowledge-based calculations, and transistor\nsizing optimization in topological order, which eliminates the need for human\nintervention. We demonstrate the effectiveness of the proposed methodology\nthrough two case studies with varying performance specifications, achieving\nhigh SNDR and low power consumption while meeting all the specified design\nconstraints.", "published": "2025-05-14 06:10:40", "link": "http://arxiv.org/abs/2505.09172v1", "categories": ["cs.AR", "eess.SP"], "primary_category": "cs.AR"}
{"title": "Sensing-Assisted Channel Prediction in Complex Wireless Environments: An LLM-Based Approach", "abstract": "This letter studies the sensing-assisted channel prediction for a\nmulti-antenna orthogonal frequency division multiplexing (OFDM) system\noperating in realistic and complex wireless environments. In this system,an\nintegrated sensing and communication (ISAC) transmitter leverages the\nmono-static sensing capability to facilitate the prediction of its bi-static\ncommunication channel, by exploiting the fact that the sensing and\ncommunication channels share the same physical environment involving shared\nscatterers. Specifically, we propose a novel large language model (LLM)-based\nchannel prediction approach,which adapts pre-trained text-based LLM to handle\nthe complex-matrix-form channel state information (CSI) data. This approach\nutilizes the LLM's strong ability to capture the intricate spatiotemporal\nrelationships between the multi-path sensing and communication channels, and\nthus efficiently predicts upcoming communication CSI based on historical\ncommunication and sensing CSI data. Experimental results show that the proposed\nLLM-based approach significantly outperforms conventional deep learning-based\nmethods and the benchmark scheme without sensing assistance.", "published": "2025-05-14 04:50:00", "link": "http://arxiv.org/abs/2505.09141v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Mainlobe Jamming Suppression Using MIMO-STCA Radar", "abstract": "Radar jamming suppression, particularly against mainlobe jamming, has become\na critical focus in modern radar systems. This article investigates advanced\nmainlobe jamming suppression techniques utilizing a novel multiple-input\nmultiple-output space-time coding array (MIMO-STCA) radar. Extending the\ncapabilities of traditional MIMO radar, the MIMO-STCA framework introduces\nadditional degrees of freedom (DoFs) in the range domain through the\nutilization of transmit time delays, offering enhanced resilience against\ninterference. One of the key challenges in mainlobe jamming scenarios is the\ndifficulty in obtaining interference-plus-noise samples that are free from\ntarget signal contamination. To address this, the study introduces a cumulative\nsampling-based non-homogeneous sample selection (CS-NHSS) algorithm to remove\ntarget-contaminated samples, ensuring accurate interference-plus-noise\ncovariance matrix estimation and effective noise subspace separation. Building\non this, the subsequent step is to apply the proposed noise subspace-based\njamming mitigation (NSJM) algorithm, which leverages the orthogonality between\nnoise and jamming subspace for effective jamming mitigation. However, NSJM\nperformance can degrade due to spatial frequency mismatches caused by DoA or\nrange quantization errors. To overcome this limitation, the study further\nproposes the robust jamming mitigation via noise subspace (RJNS) algorithm,\nincorporating adaptive beampattern control to achieve a flat-top mainlobe and\nbroadened nulls, enhancing both anti-jamming effectiveness and robustness under\nnon-ideal conditions. Simulation results verify the effectiveness of the\nproposed algorithms. Significant improvements in mainlobe jamming suppression\nare demonstrated through transmit-receive beampattern analysis and enhanced\nsignal-to-interference-plus-noise ratio (SINR) curve.", "published": "2025-05-14 03:41:23", "link": "http://arxiv.org/abs/2505.09112v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression", "abstract": "Recent forward prediction-based learned video compression (LVC) methods have\nachieved impressive results, even surpassing VVC reference software VTM under\nthe Low Delay B (LDB) configuration. In contrast, learned bidirectional video\ncompression (BVC) remains underexplored and still lags behind its forward-only\ncounterparts. This performance gap is mainly due to the limited ability to\nextract diverse and accurate contexts: most existing BVCs primarily exploit\ntemporal motion while neglecting non-local correlations across frames.\nMoreover, they lack the adaptability to dynamically suppress harmful contexts\narising from fast motion or occlusion. To tackle these challenges, we propose\nBiECVC, a BVC framework that incorporates diversified local and non-local\ncontext modeling along with adaptive context gating. For local context\nenhancement, BiECVC reuses high-quality features from lower layers and aligns\nthem using decoded motion vectors without introducing extra motion overhead. To\nmodel non-local dependencies efficiently, we adopt a linear attention mechanism\nthat balances performance and complexity. To further mitigate the impact of\ninaccurate context prediction, we introduce Bidirectional Context Gating,\ninspired by data-dependent decay in recent autoregressive language models, to\ndynamically filter contextual information based on conditional coding results.\nExtensive experiments demonstrate that BiECVC achieves state-of-the-art\nperformance, reducing the bit-rate by 13.4% and 15.7% compared to VTM 13.2\nunder the Random Access (RA) configuration with intra periods of 32 and 64,\nrespectively. To our knowledge, BiECVC is the first learned video codec to\nsurpass VTM 13.2 RA across all standard test datasets. Code will be available\nat https://github.com/JiangWeibeta/ECVC.", "published": "2025-05-14 06:55:37", "link": "http://arxiv.org/abs/2505.09193v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System", "abstract": "The growing complexity and scale of visual model pre-training have made\ndeveloping and deploying multi-task computer-aided diagnosis (CAD) systems\nincreasingly challenging and resource-intensive. Furthermore, the medical\nimaging community lacks an open-source CAD platform to enable the rapid\ncreation of efficient and extendable diagnostic models. To address these\nissues, we propose UniCAD, a unified architecture that leverages the robust\ncapabilities of pre-trained vision foundation models to seamlessly handle both\n2D and 3D medical images while requiring only minimal task-specific parameters.\nUniCAD introduces two key innovations: (1) Efficiency: A low-rank adaptation\nstrategy is employed to adapt a pre-trained visual model to the medical image\ndomain, achieving performance on par with fully fine-tuned counterparts while\nintroducing only 0.17% trainable parameters. (2) Plug-and-Play: A modular\narchitecture that combines a frozen foundation model with multiple\nplug-and-play experts, enabling diverse tasks and seamless functionality\nexpansion. Building on this unified CAD architecture, we establish an\nopen-source platform where researchers can share and access lightweight CAD\nexperts, fostering a more equitable and efficient research ecosystem.\nComprehensive experiments across 12 diverse medical datasets demonstrate that\nUniCAD consistently outperforms existing methods in both accuracy and\ndeployment efficiency. The source code and project page are available at\nhttps://mii-laboratory.github.io/UniCAD/.", "published": "2025-05-14 06:21:27", "link": "http://arxiv.org/abs/2505.09178v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Fair In-Context Learning with Tabular Foundation Models", "abstract": "Tabular foundational models have exhibited strong in-context learning (ICL)\ncapabilities on structured data, allowing them to make accurate predictions on\ntest sets without parameter updates, using training examples as context. This\nemerging approach positions itself as a competitive alternative to traditional\ngradient-boosted tree methods. However, while biases in conventional machine\nlearning models are well documented, it remains unclear how these biases\nmanifest in tabular ICL. The paper investigates the fairness implications of\ntabular ICL and explores three preprocessing strategies--correlation removal,\ngroup-balanced demonstration selection, and uncertainty-based demonstration\nselection--to address bias. Comprehensive experiments indicate that\nuncertainty-based demonstration selection consistently enhances group fairness\nof in-context predictions. The source code for reproducing the results of this\nwork can be found at https://github.com/patrikken/Fair-TabICL.", "published": "2025-05-14 15:53:14", "link": "http://arxiv.org/abs/2505.09503v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenchel-Young Losses", "abstract": "Surrogate regret bounds, also known as excess risk bounds, bridge the gap\nbetween the convergence rates of surrogate and target losses, with linear\nbounds favorable for their lossless regret transfer. While convex smooth\nsurrogate losses are appealing in particular due to the efficient estimation\nand optimization, the existence of a trade-off between the smoothness and\nlinear regret bound has been believed in the community. That being said, the\nbetter optimization and estimation properties of convex smooth surrogate losses\nmay inevitably deteriorate after undergoing the regret transfer onto a target\nloss. We overcome this dilemma for arbitrary discrete target losses by\nconstructing a convex smooth surrogate loss, which entails a linear surrogate\nregret bound composed with a tailored prediction link. The construction is\nbased on Fenchel-Young losses generated by the convolutional negentropy, which\nare equivalent to the infimal convolution of a generalized negentropy and the\ntarget Bayes risk. Consequently, the infimal convolution enables us to derive a\nsmooth loss while maintaining the surrogate regret bound linear. We\nadditionally benefit from the infimal convolution to have a consistent\nestimator of the underlying class probability. Our results are overall a novel\ndemonstration of how convex analysis penetrates into optimization and\nstatistical efficiency in risk minimization.", "published": "2025-05-14 14:37:32", "link": "http://arxiv.org/abs/2505.09432v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation", "abstract": "Large Language Models (LLMs) show growing promise in autonomous driving by\nreasoning over complex traffic scenarios to generate path plans. However, their\ntendencies toward overconfidence, and hallucinations raise critical safety\nconcerns. We introduce SafePath, a modular framework that augments LLM-based\npath planning with formal safety guarantees using conformal prediction.\nSafePath operates in three stages. In the first stage, we use an LLM that\ngenerates a set of diverse candidate paths, exploring possible trajectories\nbased on agent behaviors and environmental cues. In the second stage, SafePath\nfilters out high-risk trajectories while guaranteeing that at least one safe\noption is included with a user-defined probability, through a multiple-choice\nquestion-answering formulation that integrates conformal prediction. In the\nfinal stage, our approach selects the path with the lowest expected collision\nrisk when uncertainty is low or delegates control to a human when uncertainty\nis high. We theoretically prove that SafePath guarantees a safe trajectory with\na user-defined probability, and we show how its human delegation rate can be\ntuned to balance autonomy and safety. Extensive experiments on nuScenes and\nHighway-env show that SafePath reduces planning uncertainty by 77\\% and\ncollision rates by up to 70\\%, demonstrating effectiveness in making LLM-driven\npath planning more safer.", "published": "2025-05-14 14:28:24", "link": "http://arxiv.org/abs/2505.09427v2", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Generating time-consistent dynamics with discriminator-guided image diffusion models", "abstract": "Realistic temporal dynamics are crucial for many video generation, processing\nand modelling applications, e.g. in computational fluid dynamics, weather\nprediction, or long-term climate simulations. Video diffusion models (VDMs) are\nthe current state-of-the-art method for generating highly realistic dynamics.\nHowever, training VDMs from scratch can be challenging and requires large\ncomputational resources, limiting their wider application. Here, we propose a\ntime-consistency discriminator that enables pretrained image diffusion models\nto generate realistic spatiotemporal dynamics. The discriminator guides the\nsampling inference process and does not require extensions or finetuning of the\nimage diffusion model. We compare our approach against a VDM trained from\nscratch on an idealized turbulence simulation and a real-world global\nprecipitation dataset. Our approach performs equally well in terms of temporal\nconsistency, shows improved uncertainty calibration and lower biases compared\nto the VDM, and achieves stable centennial-scale climate simulations at daily\ntime steps.", "published": "2025-05-14 02:51:10", "link": "http://arxiv.org/abs/2505.09089v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quasi-3D beam theory based on equilibrium stress definition and mixed element model for accurate analysis of functionally graded beams", "abstract": "This paper presents a novel quasi-3D theory and the corresponding mixed beam\nelement model to achieve accurate solutions for functionally graded beams. The\nkey innovations include the development of equilibrium-based stress\nexpressions, the modified cross-sectional stiffness matrix, and the mixed beam\nelement model based on semi-analytical definition of internal force fields. In\ncontrast to the conventional quasi-3D theory where stress expressions are\nderived from constitutive equations and geometric relations, the stress\nexpressions in this study are derived from the differential equilibrium\nequations among stresses, ensuring strict adherence of stress solutions to\nequilibrium conditions. To incorporate the influence of equilibrium-derived\nstress distributions, the modified cross-sectional stiffness matrix is derived,\nenhancing the theoretical and practical feasibility of the beam model. For beam\nelement construction, the mixed variational principle of two-field variables is\nemployed, with generalized internal forces and generalized displacements\nregarded as two independent fields. Especially, semi-analytical internal force\nfields, which partially satisfy the differential equilibrium equations, are\nintroduced to improve the element performance. Numerical examples are conducted\nto verify the accuracy and effectiveness of the proposed theory and beam\nelement.", "published": "2025-05-14 04:15:14", "link": "http://arxiv.org/abs/2505.09127v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "abstract": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies.", "published": "2025-05-14 23:31:17", "link": "http://arxiv.org/abs/2505.09855v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "abstract": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge.", "published": "2025-05-14 23:24:22", "link": "http://arxiv.org/abs/2505.09852v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning", "abstract": "Each year, tens of millions of essays are written and graded in college-level\nEnglish courses. Students are asked to analyze literary and cultural texts\nthrough a process known as close reading, in which they gather textual details\nto formulate evidence-based arguments. Despite being viewed as a basis for\ncritical thinking and widely adopted as a required element of university\ncoursework, close reading has never been evaluated on large language models\n(LLMs), and multi-discipline benchmarks like MMLU do not include literature as\na subject. To fill this gap, we present KRISTEVA, the first close reading\nbenchmark for evaluating interpretive reasoning, consisting of 1331\nmultiple-choice questions adapted from classroom data. With KRISTEVA, we\npropose three progressively more difficult sets of tasks to approximate\ndifferent elements of the close reading process, which we use to test how well\nLLMs may seem to understand and reason about literary works: 1) extracting\nstylistic features, 2) retrieving relevant contextual information from\nparametric knowledge, and 3) multi-hop reasoning between style and external\ncontexts. Our baseline results find that, while state-of-the-art LLMs possess\nsome college-level close reading competency (accuracy 49.7% - 69.7%), their\nperformances still trail those of experienced human evaluators on 10 out of our\n11 tasks.", "published": "2025-05-14 22:04:46", "link": "http://arxiv.org/abs/2505.09825v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the generalization of LLM truth directions on conversational formats", "abstract": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings.", "published": "2025-05-14 21:21:08", "link": "http://arxiv.org/abs/2505.09807v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "abstract": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL.", "published": "2025-05-14 20:44:29", "link": "http://arxiv.org/abs/2505.09794v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey on Large Language Models in Multimodal Recommender Systems", "abstract": "Multimodal recommender systems (MRS) integrate heterogeneous user and item\ndata, such as text, images, and structured information, to enhance\nrecommendation performance. The emergence of large language models (LLMs)\nintroduces new opportunities for MRS by enabling semantic reasoning, in-context\nlearning, and dynamic input handling. Compared to earlier pre-trained language\nmodels (PLMs), LLMs offer greater flexibility and generalisation capabilities\nbut also introduce challenges related to scalability and model accessibility.\nThis survey presents a comprehensive review of recent work at the intersection\nof LLMs and MRS, focusing on prompting strategies, fine-tuning methods, and\ndata adaptation techniques. We propose a novel taxonomy to characterise\nintegration patterns, identify transferable techniques from related\nrecommendation domains, provide an overview of evaluation metrics and datasets,\nand point to possible future directions. We aim to clarify the emerging role of\nLLMs in multimodal recommendation and support future research in this rapidly\nevolving field.", "published": "2025-05-14 20:15:52", "link": "http://arxiv.org/abs/2505.09777v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "abstract": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores.", "published": "2025-05-14 19:00:27", "link": "http://arxiv.org/abs/2505.09738v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "abstract": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis.", "published": "2025-05-14 18:32:18", "link": "http://arxiv.org/abs/2505.09724v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts", "abstract": "Large language models (LLMs) excel at generating long-form responses, but\nevaluating their factuality remains challenging due to complex inter-sentence\ndependencies within the generated facts. Prior solutions predominantly follow a\ndecompose-decontextualize-verify pipeline but often fail to capture essential\ncontext and miss key relational facts. In this paper, we introduce VeriFact, a\nfactuality evaluation framework designed to enhance fact extraction by\nidentifying and resolving incomplete and missing facts to support more accurate\nverification results. Moreover, we introduce FactRBench , a benchmark that\nevaluates both precision and recall in long-form model responses, whereas prior\nwork primarily focuses on precision. FactRBench provides reference fact sets\nfrom advanced LLMs and human-written answers, enabling recall assessment.\nEmpirical evaluations show that VeriFact significantly enhances fact\ncompleteness and preserves complex facts with critical relational information,\nresulting in more accurate factuality evaluation. Benchmarking various open-\nand close-weight LLMs on FactRBench indicate that larger models within same\nmodel family improve precision and recall, but high precision does not always\ncorrelate with high recall, underscoring the importance of comprehensive\nfactuality assessment.", "published": "2025-05-14 18:02:37", "link": "http://arxiv.org/abs/2505.09701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "System Prompt Optimization with Meta-Learning", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance.", "published": "2025-05-14 16:46:15", "link": "http://arxiv.org/abs/2505.09666v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling", "abstract": "Wildfires have become increasingly frequent, irregular, and severe in recent\nyears. Understanding how affected populations perceive and respond during\nwildfire crises is critical for timely and empathetic disaster response. Social\nmedia platforms offer a crowd-sourced channel to capture evolving public\ndiscourse, providing hyperlocal information and insight into public sentiment.\nThis study analyzes Reddit discourse during the 2025 Los Angeles wildfires,\nspanning from the onset of the disaster to full containment. We collect 385\nposts and 114,879 comments related to the Palisades and Eaton fires. We adopt\ntopic modeling methods to identify the latent topics, enhanced by large\nlanguage models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we\ndevelop a hierarchical framework to categorize latent topics, consisting of two\nmain categories, Situational Awareness (SA) and Crisis Narratives (CN). The\nvolume of SA category closely aligns with real-world fire progressions, peaking\nwithin the first 2-5 days as the fires reach the maximum extent. The most\nfrequent co-occurring category set of public health and safety, loss and\ndamage, and emergency resources expands on a wide range of health-related\nlatent topics, including environmental health, occupational health, and one\nhealth. Grief signals and mental health risks consistently accounted for 60\npercentage and 40 percentage of CN instances, respectively, with the highest\ntotal volume occurring at night. This study contributes the first annotated\nsocial media dataset on the 2025 LA fires, and introduces a scalable\nmulti-layer framework that leverages topic modeling for crisis discourse\nanalysis. By identifying persistent public health concerns, our results can\ninform more empathetic and adaptive strategies for disaster response, public\nhealth communication, and future research in comparable climate-related\ndisaster events.", "published": "2025-05-14 16:31:08", "link": "http://arxiv.org/abs/2505.09665v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Large Language Models Are More Persuasive Than Incentivized Human Persuaders", "abstract": "We directly compare the persuasion capabilities of a frontier large language\nmodel (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an\ninteractive, real-time conversational quiz setting. In this preregistered,\nlarge-scale incentivized experiment, participants (quiz takers) completed an\nonline quiz where persuaders (either humans or LLMs) attempted to persuade quiz\ntakers toward correct or incorrect answers. We find that LLM persuaders\nachieved significantly higher compliance with their directional persuasion\nattempts than incentivized human persuaders, demonstrating superior persuasive\ncapabilities in both truthful (toward correct answers) and deceptive (toward\nincorrect answers) contexts. We also find that LLM persuaders significantly\nincreased quiz takers' accuracy, leading to higher earnings, when steering quiz\ntakers toward correct answers, and significantly decreased their accuracy,\nleading to lower earnings, when steering them toward incorrect answers.\nOverall, our findings suggest that AI's persuasion capabilities already exceed\nthose of humans that have real-money bonuses tied to performance. Our findings\nof increasingly capable AI persuaders thus underscore the urgency of emerging\nalignment and governance frameworks.", "published": "2025-05-14 14:31:33", "link": "http://arxiv.org/abs/2505.09662v1", "categories": ["cs.CL", "I.2.7; H.1.2; K.4.1; H.5.2"], "primary_category": "cs.CL"}
{"title": "DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models", "abstract": "Recent advances in reinforcement learning for language model post-training,\nsuch as Group Relative Policy Optimization (GRPO), have shown promise in\nlow-resource settings. However, GRPO typically relies on solution-level and\nscalar reward signals that fail to capture the semantic diversity among sampled\ncompletions. This leads to what we identify as a diversity-quality\ninconsistency, where distinct reasoning paths may receive indistinguishable\nrewards. To address this limitation, we propose $\\textit{Diversity-aware Reward\nAdjustment}$ (DRA), a method that explicitly incorporates semantic diversity\ninto the reward computation. DRA uses Submodular Mutual Information (SMI) to\ndownweight redundant completions and amplify rewards for diverse ones. This\nencourages better exploration during learning, while maintaining stable\nexploitation of high-quality samples. Our method integrates seamlessly with\nboth GRPO and its variant DR.~GRPO, resulting in $\\textit{DRA-GRPO}$ and\n$\\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning\nbenchmarks and find that it outperforms recent strong baselines. It achieves\nstate-of-the-art performance with an average accuracy of 58.2%, using only\n7,000 fine-tuning samples and a total training cost of approximately $55. The\ncode is available at https://github.com/xiwenc1/DRA-GRPO.", "published": "2025-05-14 02:02:32", "link": "http://arxiv.org/abs/2505.09655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LiDDA: Data Driven Attribution at LinkedIn", "abstract": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields.", "published": "2025-05-14 23:54:57", "link": "http://arxiv.org/abs/2505.09861v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Causal Predictive Optimization and Generation for Business AI", "abstract": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field.", "published": "2025-05-14 23:12:20", "link": "http://arxiv.org/abs/2505.09847v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values", "abstract": "The design and implementation of unit tests is a complex task many\nprogrammers neglect. This research evaluates the potential of Large Language\nModels (LLMs) in automatically generating test cases, comparing them with\nmanual tests. An optimized prompt was developed, that integrates code and\nrequirements, covering critical cases such as equivalence partitions and\nboundary values. The strengths and weaknesses of LLMs versus trained\nprogrammers were compared through quantitative metrics and manual qualitative\nanalysis. The results show that the effectiveness of LLMs depends on\nwell-designed prompts, robust implementation, and precise requirements.\nAlthough flexible and promising, LLMs still require human supervision. This\nwork highlights the importance of manual qualitative analysis as an essential\ncomplement to automation in unit test evaluation.", "published": "2025-05-14 22:22:15", "link": "http://arxiv.org/abs/2505.09830v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "$XX^{t}$ Can Be Faster", "abstract": "We present a new algorithm RXTX that computes product of matrix by its\ntranspose $XX^{t}$. RXTX uses $5\\%$ less multiplications and additions than\nState-of-the-Art and achieves accelerations even for small sizes of matrix $X$.\nThe algorithm was discovered by combining Machine Learning-based search methods\nwith Combinatorial Optimization.", "published": "2025-05-14 21:31:44", "link": "http://arxiv.org/abs/2505.09814v1", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.SC", "68Q25, 68T20", "F.2.1; I.1.2"], "primary_category": "cs.DS"}
{"title": "Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models", "abstract": "Clustering patient subgroups is essential for personalized care and efficient\nresource use. Traditional clustering methods struggle with high-dimensional,\nheterogeneous healthcare data and lack contextual understanding. This study\nevaluates Large Language Model (LLM) based clustering against classical methods\nusing a pediatric sepsis dataset from a low-income country (LIC), containing\n2,686 records with 28 numerical and 119 categorical variables. Patient records\nwere serialized into text with and without a clustering objective. Embeddings\nwere generated using quantized LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B with\nlow-rank adaptation(LoRA), and Stella-En-400M-V5 models. K-means clustering was\napplied to these embeddings. Classical comparisons included K-Medoids\nclustering on UMAP and FAMD-reduced mixed data. Silhouette scores and\nstatistical tests evaluated cluster quality and distinctiveness.\nStella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLAMA 3.1 8B\nwith the clustering objective performed better with higher number of clusters,\nidentifying subgroups with distinct nutritional, clinical, and socioeconomic\nprofiles. LLM-based methods outperformed classical techniques by capturing\nricher context and prioritizing key features. These results highlight potential\nof LLMs for contextual phenotyping and informed decision-making in\nresource-limited settings.", "published": "2025-05-14 21:05:40", "link": "http://arxiv.org/abs/2505.09805v1", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "stat.AP"], "primary_category": "q-bio.QM"}
{"title": "Virtual Dosimetrists: A Radiotherapy Training \"Flight Simulator\"", "abstract": "Effective education in radiotherapy plan quality review requires a robust,\nregularly updated set of examples and the flexibility to demonstrate multiple\npossible planning approaches and their consequences. However, the current\nclinic-based paradigm does not support these needs. To address this, we have\ndeveloped 'Virtual Dosimetrist' models that can both generate training examples\nof suboptimal treatment plans and then allow trainees to improve the plan\nquality through simple natural language prompts, as if communicating with a\ndosimetrist. The dose generation and modification process is accurate, rapid,\nand requires only modest resources. This work is the first to combine dose\ndistribution prediction with natural language processing; providing a robust\npipeline for both generating suboptimal training plans and allowing trainees to\npractice their critical plan review and improvement skills that addresses the\nchallenges of the current clinic-based paradigm.", "published": "2025-05-14 20:47:13", "link": "http://arxiv.org/abs/2505.09796v1", "categories": ["physics.med-ph", "cs.AI"], "primary_category": "physics.med-ph"}
{"title": "Few-Shot Learning of Visual Compositional Concepts through Probabilistic Schema Induction", "abstract": "The ability to learn new visual concepts from limited examples is a hallmark\nof human cognition. While traditional category learning models represent each\nexample as an unstructured feature vector, compositional concept learning is\nthought to depend on (1) structured representations of examples (e.g., directed\ngraphs consisting of objects and their relations) and (2) the identification of\nshared relational structure across examples through analogical mapping. Here,\nwe introduce Probabilistic Schema Induction (PSI), a prototype model that\nemploys deep learning to perform analogical mapping over structured\nrepresentations of only a handful of examples, forming a compositional concept\ncalled a schema. In doing so, PSI relies on a novel conception of similarity\nthat weighs object-level similarity and relational similarity, as well as a\nmechanism for amplifying relations relevant to classification, analogous to\nselective attention parameters in traditional models. We show that PSI produces\nhuman-like learning performance and outperforms two controls: a prototype model\nthat uses unstructured feature vectors extracted from a deep learning model,\nand a variant of PSI with weaker structured representations. Notably, we find\nthat PSI's human-like performance is driven by an adaptive strategy that\nincreases relational similarity over object-level similarity and upweights the\ncontribution of relations that distinguish classes. These findings suggest that\nstructured representations and analogical mapping are critical to modeling\nrapid human-like learning of compositional visual concepts, and demonstrate how\ndeep learning can be leveraged to create psychological models.", "published": "2025-05-14 23:43:57", "link": "http://arxiv.org/abs/2505.09859v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models", "abstract": "Computer-assisted interventions can improve intra-operative guidance,\nparticularly through deep learning methods that harness the spatiotemporal\ninformation in surgical videos. However, the severe data imbalance often found\nin surgical video datasets hinders the development of high-performing models.\nIn this work, we aim to overcome the data imbalance by synthesizing surgical\nvideos. We propose a unique two-stage, text-conditioned diffusion-based method\nto generate high-fidelity surgical videos for under-represented classes. Our\napproach conditions the generation process on text prompts and decouples\nspatial and temporal modeling by utilizing a 2D latent diffusion model to\ncapture spatial content and then integrating temporal attention layers to\nensure temporal consistency. Furthermore, we introduce a rejection sampling\nstrategy to select the most suitable synthetic samples, effectively augmenting\nexisting datasets to address class imbalance. We evaluate our method on two\ndownstream tasks-surgical action recognition and intra-operative event\nprediction-demonstrating that incorporating synthetic videos from our approach\nsubstantially enhances model performance. We open-source our implementation at\nhttps://gitlab.com/nct_tso_public/surgvgen.", "published": "2025-05-14 23:43:29", "link": "http://arxiv.org/abs/2505.09858v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ImplicitStainer: Data-Efficient Medical Image Translation for Virtual Antibody-based Tissue Staining Using Local Implicit Functions", "abstract": "Hematoxylin and eosin (H&E) staining is a gold standard for microscopic\ndiagnosis in pathology. However, H&E staining does not capture all the\ndiagnostic information that may be needed. To obtain additional molecular\ninformation, immunohistochemical (IHC) stains highlight proteins that mark\nspecific cell types, such as CD3 for T-cells or CK8/18 for epithelial cells.\nWhile IHC stains are vital for prognosis and treatment guidance, they are\ntypically only available at specialized centers and time consuming to acquire,\nleading to treatment delays for patients. Virtual staining, enabled by deep\nlearning-based image translation models, provides a promising alternative by\ncomputationally generating IHC stains from H&E stained images. Although many\nGAN and diffusion based image to image (I2I) translation methods have been used\nfor virtual staining, these models treat image patches as independent data\npoints, which results in increased and more diverse data requirements for\neffective generation. We present ImplicitStainer, a novel approach that\nleverages local implicit functions to improve image translation, specifically\nvirtual staining performance, by focusing on pixel-level predictions. This\nmethod enhances robustness to variations in dataset sizes, delivering\nhigh-quality results even with limited data. We validate our approach on two\ndatasets using a comprehensive set of metrics and benchmark it against over\nfifteen state-of-the-art GAN- and diffusion based models. Full Code and models\ntrained will be released publicly via Github upon acceptance.", "published": "2025-05-14 22:22:52", "link": "http://arxiv.org/abs/2505.09831v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes", "abstract": "Obtaining large-scale medical data, annotated or unannotated, is challenging\ndue to stringent privacy regulations and data protection policies. In addition,\nannotating medical images requires that domain experts manually delineate\nanatomical structures, making the process both time-consuming and costly. As a\nresult, semi-supervised methods have gained popularity for reducing annotation\ncosts. However, the performance of semi-supervised methods is heavily dependent\non the availability of unannotated data, and their effectiveness declines when\nsuch data are scarce or absent. To overcome this limitation, we propose a\nsimple, yet effective and computationally efficient approach for medical image\nsegmentation that leverages only existing annotations. We propose BoundarySeg ,\na multi-task framework that incorporates organ boundary prediction as an\nauxiliary task to full organ segmentation, leveraging consistency between the\ntwo task predictions to provide additional supervision. This strategy improves\nsegmentation accuracy, especially in low data regimes, allowing our method to\nachieve performance comparable to or exceeding state-of-the-art semi supervised\napproaches all without relying on unannotated data or increasing computational\ndemands. Code will be released upon acceptance.", "published": "2025-05-14 22:15:41", "link": "http://arxiv.org/abs/2505.09829v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dyadic Mamba: Long-term Dyadic Human Motion Synthesis", "abstract": "Generating realistic dyadic human motion from text descriptions presents\nsignificant challenges, particularly for extended interactions that exceed\ntypical training sequence lengths. While recent transformer-based approaches\nhave shown promising results for short-term dyadic motion synthesis, they\nstruggle with longer sequences due to inherent limitations in positional\nencoding schemes. In this paper, we introduce Dyadic Mamba, a novel approach\nthat leverages State-Space Models (SSMs) to generate high-quality dyadic human\nmotion of arbitrary length. Our method employs a simple yet effective\narchitecture that facilitates information flow between individual motion\nsequences through concatenation, eliminating the need for complex\ncross-attention mechanisms. We demonstrate that Dyadic Mamba achieves\ncompetitive performance on standard short-term benchmarks while significantly\noutperforming transformer-based approaches on longer sequences. Additionally,\nwe propose a new benchmark for evaluating long-term motion synthesis quality,\nproviding a standardized framework for future research. Our results demonstrate\nthat SSM-based architectures offer a promising direction for addressing the\nchallenging task of long-term dyadic human motion synthesis from text\ndescriptions.", "published": "2025-05-14 22:12:34", "link": "http://arxiv.org/abs/2505.09827v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visual Feedback of Pattern Separability Improves Myoelectric Decoding Performance of Upper Limb Prostheses", "abstract": "State-of-the-art upper limb myoelectric prostheses often use pattern\nrecognition (PR) control systems that translate electromyography (EMG) signals\ninto desired movements. As prosthesis movement complexity increases, users\noften struggle to produce sufficiently distinct EMG patterns for reliable\nclassification. Existing training typically involves heuristic, trial-and-error\nuser adjustments to static decoder boundaries. Goal: We introduce the Reviewer,\na 3D visual interface projecting EMG signals directly into the decoder's\nclassification space, providing intuitive, real-time insight into PR algorithm\nbehavior. This structured feedback reduces cognitive load and fosters mutual,\ndata-driven adaptation between user-generated EMG patterns and decoder\nboundaries. Methods: A 10-session study with 12 able-bodied participants\ncompared PR performance after motor-based training and updating using the\nReviewer versus conventional virtual arm visualization. Performance was\nassessed using a Fitts law task that involved the aperture of the cursor and\nthe control of orientation. Results: Participants trained with the Reviewer\nachieved higher completion rates, reduced overshoot, and improved path\nefficiency and throughput compared to the standard visualization group.\nSignificance: The Reviewer introduces decoder-informed motor training,\nfacilitating immediate and consistent PR-based myoelectric control\nimprovements. By iteratively refining control through real-time feedback, this\napproach reduces reliance on trial-and-error recalibration, enabling a more\nadaptive, self-correcting training framework. Conclusion: The 3D visual\nfeedback significantly improves PR control in novice operators through\nstructured training, enabling feedback-driven adaptation and reducing reliance\non extensive heuristic adjustments.", "published": "2025-05-14 21:47:28", "link": "http://arxiv.org/abs/2505.09819v1", "categories": ["cs.HC", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.HC"}
{"title": "A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium", "abstract": "The left atrium (LA) plays a pivotal role in modulating left ventricular\nfilling, but our comprehension of its hemodynamics is significantly limited by\nthe constraints of conventional ultrasound analysis. 4D flow magnetic resonance\nimaging (4D Flow MRI) holds promise for enhancing our understanding of atrial\nhemodynamics. However, the low velocities within the LA and the limited spatial\nresolution of 4D Flow MRI make analyzing this chamber challenging. Furthermore,\nthe absence of dedicated computational frameworks, combined with diverse\nacquisition protocols and vendors, complicates gathering large cohorts for\nstudying the prognostic value of hemodynamic parameters provided by 4D Flow\nMRI. In this study, we introduce the first open-source computational framework\ntailored for the analysis of 4D Flow MRI in the LA, enabling comprehensive\nqualitative and quantitative analysis of advanced hemodynamic parameters. Our\nframework proves robust to data from different centers of varying quality,\nproducing high-accuracy automated segmentations (Dice $>$ 0.9 and Hausdorff 95\n$<$ 3 mm), even with limited training data. Additionally, we conducted the\nfirst comprehensive assessment of energy, vorticity, and pressure parameters in\nthe LA across a spectrum of disorders to investigate their potential as\nprognostic biomarkers.", "published": "2025-05-14 19:09:17", "link": "http://arxiv.org/abs/2505.09746v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On Alternating 6-Cycles in Edge-Coloured Graphs", "abstract": "In this short note, we use flag algebras to prove that the number of colour\nalternating 6-cycles in a red/blue colouring of a large clique is\nasymptotically maximized by a uniformly random colouring. This settles the\nfirst open case of a problem of Basit, Granet, Horsley, K\\\"undgen and Staden.", "published": "2025-05-14 21:23:06", "link": "http://arxiv.org/abs/2505.09809v1", "categories": ["math.CO", "cs.DM", "05C35"], "primary_category": "math.CO"}
{"title": "Beyond Pairwise Learning-To-Rank At Airbnb", "abstract": "There are three fundamental asks from a ranking algorithm: it should scale to\nhandle a large number of items, sort items accurately by their utility, and\nimpose a total order on the items for logical consistency. But here's the\ncatch-no algorithm can achieve all three at the same time. We call this\nlimitation the SAT theorem for ranking algorithms. Given the dilemma, how can\nwe design a practical system that meets user needs? Our current work at Airbnb\nprovides an answer, with a working solution deployed at scale. We start with\npairwise learning-to-rank (LTR) models-the bedrock of search ranking tech\nstacks today. They scale linearly with the number of items ranked and perform\nstrongly on metrics like NDCG by learning from pairwise comparisons. They are\nat a sweet spot of performance vs. cost, making them an ideal choice for\nseveral industrial applications. However, they have a drawback-by ignoring\ninteractions between items, they compromise on accuracy. To improve accuracy,\nwe create a \"true\" pairwise LTR model-one that captures interactions between\nitems during pairwise comparisons. But accuracy comes at the expense of\nscalability and total order, and we discuss strategies to counter these\nchallenges. For greater accuracy, we take each item in the search result, and\ncompare it against the rest of the items along two dimensions: (1) Superiority:\nHow strongly do searchers prefer the given item over the remaining ones? (2)\nSimilarity: How similar is the given item to all the other items? This forms\nthe basis of our \"all-pairwise\" LTR framework, which factors in interactions\nacross all items at once. Looking at items on the search result page all\ntogether-superiority and similarity combined-gives us a deeper understanding of\nwhat searchers truly want. We quantify the resulting improvements in searcher\nexperience through offline and online experiments at Airbnb.", "published": "2025-05-14 20:45:29", "link": "http://arxiv.org/abs/2505.09795v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "The Impact of International Collaborations with Highly Publishing Countries in Computer Science", "abstract": "This paper analyzes international collaborations in Computer Science,\nfocusing on three major players: China, the European Union, and the United\nStates. Drawing from a comprehensive literature review, we examine\ncollaboration patterns, research impact, retraction rates, and the role of the\nDevelopment Index in shaping research outcomes. Our findings show that while\nChina, the EU, and the US lead global research efforts, other regions are\nnarrowing the gap in publication volume. Collaborations involving these key\nregions tend to have lower retraction rates, reflecting stronger adherence to\nscientific standards. We also find that countries with a Very High Development\nIndex contribute to research with higher citation rates and fewer retractions.\nOverall, this study highlights the value of international collaboration and the\nimportance of inclusive, ethical practices in advancing global research in\nComputer Science.", "published": "2025-05-14 20:15:45", "link": "http://arxiv.org/abs/2505.09776v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "ZENN: A Thermodynamics-Inspired Computational Framework for Heterogeneous Data-Driven Modeling", "abstract": "Traditional entropy-based methods - such as cross-entropy loss in\nclassification problems - have long been essential tools for quantifying\nuncertainty and disorder in data and developing artificial intelligence\nalgorithms. However, the rapid growth of data across various domains has\nintroduced new challenges, particularly the integration of heterogeneous\ndatasets with intrinsic disparities. In this paper, we extend zentropy theory\ninto the data science domain by introducing intrinsic entropy, enabling more\neffective learning from heterogeneous data sources. We propose a\nzentropy-enhanced neural network (ZENN) that simultaneously learns both energy\nand intrinsic entropy components, capturing the underlying structure of\nmulti-source data. To support this, we redesign the neural network architecture\nto better reflect the intrinsic properties and variability inherent in diverse\ndatasets. We demonstrate the effectiveness of ZENN on classification tasks and\nenergy landscape reconstructions, showing its superior generalization\ncapabilities and robustness-particularly in predicting high-order derivatives.\nAs a practical application, we employ ZENN to reconstruct the Helmholtz energy\nlandscape of Fe3Pt using data generated from DFT and capture key material\nbehaviors, including negative thermal expansion and the critical point in the\ntemperature-pressure space. Overall, our study introduces a novel approach for\ndata-driven machine learning grounded in zentropy theory, highlighting ZENN as\na versatile and robust deep learning framework for scientific problems\ninvolving complex, heterogeneous datasets.", "published": "2025-05-14 23:23:28", "link": "http://arxiv.org/abs/2505.09851v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence", "abstract": "As demand for intelligent services rises and edge devices become more\ncapable, distributed learning at the network edge has emerged as a key enabling\ntechnology. While existing paradigms like federated learning (FL) and\ndecentralized FL (DFL) enable privacy-preserving distributed learning in many\nscenarios, they face potential challenges in connectivity and synchronization\nimposed by resource-constrained and infrastructure-less environments. While\nmore robust, gossip learning (GL) algorithms have generally been designed for\nhomogeneous data distributions and may not suit all contexts. This paper\nintroduces Chisme, a novel suite of protocols designed to address the\nchallenges of implementing robust intelligence in the network edge,\ncharacterized by heterogeneous data distributions, episodic connectivity, and\nlack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and\nasynchronous GL (Chisme-GL) variants that enable collaborative yet\ndecentralized model training that considers underlying data heterogeneity. We\nintroduce a data similarity heuristic that allows agents to opportunistically\ninfer affinity with each other using the existing communication of model\nupdates in decentralized FL and GL. We leverage the heuristic to extend DFL's\nmodel aggregation and GL's model merge mechanisms for better personalized\ntraining while maintaining collaboration. While Chisme-DFL is a synchronous\ndecentralized approach whose resource utilization scales linearly with network\nsize, Chisme-GL is fully asynchronous and has a lower, constant resource\nrequirement independent of network size. We demonstrate that Chisme methods\noutperform their standard counterparts in model training over distributed and\nheterogeneous data in network scenarios ranging from less connected and\nreliable networks to fully connected and lossless networks.", "published": "2025-05-14 23:29:09", "link": "http://arxiv.org/abs/2505.09854v1", "categories": ["cs.LG", "cs.ET", "cs.MA", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Hamilton's Rule for Enabling Altruism in Multi-Agent Systems", "abstract": "This paper explores the application of Hamilton's rule to altruistic\ndecision-making in multi-agent systems. Inspired by biological altruism, we\nintroduce a framework that evaluates when individual agents should incur costs\nto benefit their neighbors. By adapting Hamilton's rule, we define agent\n``fitness\" in terms of task productivity rather than genetic survival. We\nformalize altruistic decision-making through a graph-based model of multi-agent\ninteractions and propose a solution using collaborative control Lyapunov\nfunctions. The approach ensures that altruistic behaviors contribute to the\ncollective goal-reaching efficiency of the system. We illustrate this framework\non a multi-agent way-point navigation problem, where we show through simulation\nhow agent importance levels influence altruistic decision-making, leading to\nimproved coordination in navigation tasks.", "published": "2025-05-14 22:54:42", "link": "http://arxiv.org/abs/2505.09841v1", "categories": ["cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "On Signed Network Coordination Games", "abstract": "We study binary-action pairwise-separable network games that encompass both\ncoordinating and anti-coordinating behaviors. Our model is grounded in an\nunderlying directed signed graph, where each link is associated with a weight\nthat describes the strenght and nature of the interaction. The utility for each\nagent is an aggregation of pairwise terms determined by the weights of the\nsigned graph in addition to an individual bias term. We consider a scenario\nthat assumes the presence of a prominent 'cohesive' subset of players, who are\neither connected exclusively by positive weights, or forms a structurally\nbalanced subset that can be bipartitioned into two adversarial subcommunities\nwith positive intra-community and negative inter-community edges. Given the\nproperties of the game restricted to the remaining players, our results\nguarantee the existence of Nash equilibria characterized by a consensus or,\nrespectively, a polarization within the first group, as well as their stability\nunder best response transitions. Our results can be interpreted as robustness\nresults, building on the supermodular properties of coordination games and on a\nnovel use of the concept of graph cohesiveness.", "published": "2025-05-14 20:51:34", "link": "http://arxiv.org/abs/2505.09799v1", "categories": ["cs.GT", "cs.MA", "cs.SI", "cs.SY", "eess.SY"], "primary_category": "cs.GT"}
{"title": "Community-based Multi-Agent Reinforcement Learning with Transfer and Active Exploration", "abstract": "We propose a new framework for multi-agent reinforcement learning (MARL),\nwhere the agents cooperate in a time-evolving network with latent community\nstructures and mixed memberships. Unlike traditional neighbor-based or fixed\ninteraction graphs, our community-based framework captures flexible and\nabstract coordination patterns by allowing each agent to belong to multiple\noverlapping communities. Each community maintains shared policy and value\nfunctions, which are aggregated by individual agents according to personalized\nmembership weights. We also design actor-critic algorithms that exploit this\nstructure: agents inherit community-level estimates for policy updates and\nvalue learning, enabling structured information sharing without requiring\naccess to other agents' policies. Importantly, our approach supports both\ntransfer learning by adapting to new agents or tasks via membership estimation,\nand active learning by prioritizing uncertain communities during exploration.\nTheoretically, we establish convergence guarantees under linear function\napproximation for both actor and critic updates. To our knowledge, this is the\nfirst MARL framework that integrates community structure, transferability, and\nactive learning with provable guarantees.", "published": "2025-05-14 19:42:43", "link": "http://arxiv.org/abs/2505.09756v1", "categories": ["cs.LG", "cs.MA", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "High-Order Hermite Optimization: Fast and Exact Gradient Computation in Open-Loop Quantum Optimal Control using a Discrete Adjoint Approach", "abstract": "This work introduces the High-Order Hermite Optimization (HOHO) method, an\nopen-loop discrete adjoint method for quantum optimal control. Our method is\nthe first of its kind to efficiently compute exact (discrete) gradients when\nusing continuous, parameterized control pulses while solving the forward\nequations (e.g. Schrodinger's equation or the Linblad master equation) with an\narbitrarily high-order Hermite Runge-Kutta method. The HOHO method is\nimplemented in QuantumGateDesign.jl, an open-source software package for the\nJulia programming language, which we use to perform numerical experiments\ncomparing the method to Juqbox.jl. For realistic model problems we observe\nspeedups up to 775x.", "published": "2025-05-14 23:41:22", "link": "http://arxiv.org/abs/2505.09857v1", "categories": ["math.NA", "cs.NA", "quant-ph"], "primary_category": "math.NA"}
{"title": "Efficient Calculation of Modified Bessel Functions of the First Kind, $I_\u03bd (z)$, for Real Orders and Complex Arguments: Fortran Implementation with Double and Quadruple Precision", "abstract": "We present an efficient self-contained algorithm for computing the modified\nBessel function of the first kind $I_{\\nu}(z)$, implemented in a robust Fortran\ncode supporting double and quadruple (quad) precision. The algorithm overcomes\nthe limitations of Algorithm 644, which is restricted to double precision and\napplies overly conservative underflow and overflow thresholds, leading to\nfailures in large parameter regions. Accuracy is validated against\nhigh-precision Maple calculations, and benchmarking shows execution time\nreductions to 54%-80% of Algorithm 644 (in double precision). Quad precision\nenhances numerical stability and broadens the domain of computations, making\nthe implementation well suited for high-precision applications in physics and\nengineering. This work also provides a foundation for the development of\nefficient algorithms for other Bessel functions.", "published": "2025-05-14 20:00:25", "link": "http://arxiv.org/abs/2505.09770v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion", "abstract": "This work presents a methodology for reconstructing the spatial distribution\nof the neutron flux in a nuclear reactor, leveraging real-time measurements\nobtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation\ninherently defines the problem of estimating a scalar field within a domain\nbased on boundary data, making it a natural mathematical framework for this\ntask. The main challenge lies in deriving the Green's function specific to the\ndomain and the neutron diffusion process. While analytical solutions for\nGreen's functions exist for simplified geometries, their derivation of complex,\nheterogeneous domains-such as a nuclear reactor-requires a numerical approach.\nThe objective of this work is to demonstrate the well-posedness of the\ndata-driven Green's function approximation by formulating and solving the K-H\nequation as an inverse problem. After establishing the symmetry properties that\nthe Green's function must satisfy, the K-H equation is derived from the\none-speed neutron diffusion model. This is followed by a comprehensive\ndescription of the procedure for interpreting sensor readings and implementing\nthe neutron flux reconstruction algorithm. Finally, the existence and\nuniqueness of the Green's function inferred from the sampled data are\ndemonstrated, ensuring the reliability of the proposed method and its\npredictions.", "published": "2025-05-14 19:53:09", "link": "http://arxiv.org/abs/2505.09766v1", "categories": ["math.NA", "cs.AI", "cs.NA"], "primary_category": "math.NA"}
{"title": "Connections between convex optimization algorithms and subspace correction methods", "abstract": "We show that a broad range of convex optimization algorithms, including\nalternating projection, operator splitting, and multiplier methods, can be\nsystematically derived from the framework of subspace correction methods via\nconvex duality. To formalize this connection, we introduce the notion of\ndualization, a process that transforms an iterative method for the dual problem\ninto an equivalent method for the primal problem. This concept establishes new\nconnections across these algorithmic classes, encompassing both well-known and\nnew methods. In particular, we show that classical algorithms such as the von\nNeumann, Dykstra, Peaceman--Rachford, and Douglas--Rachford methods can be\ninterpreted as dualizations of subspace correction methods applied to\nappropriate dual formulations. Beyond unifying existing methods, our framework\nenables the systematic development of new algorithms for convex optimization.\nFor instance, we derive parallel variants of alternating projection and\noperator splitting methods, as dualizations of parallel subspace correction\nmethods, that are well-suited for large-scale problems on modern computing\narchitectures and offer straightforward convergence guarantees. We also propose\nnew alternating direction method of multipliers-type algorithms, derived as\ndualizations of certain operator splitting methods. These algorithms naturally\nensure convergence even in the multi-block setting, where the conventional\nmethod does not guarantee convergence when applied to more than two blocks.\nThis unified perspective not only facilitates algorithm design and the transfer\nof theoretical results but also opens new avenues for research and innovation\nin convex optimization.", "published": "2025-05-14 19:53:07", "link": "http://arxiv.org/abs/2505.09765v1", "categories": ["math.OC", "cs.NA", "math.NA", "90C46, 49M27, 68W15, 65N55, 90C25"], "primary_category": "math.OC"}
{"title": "Accelerating Fast Ewald Summation with Prolates for Molecular Dynamics Simulations", "abstract": "Fast Ewald summation is the most widely used approach for computing\nlong-range Coulomb interactions in molecular dynamics (MD) simulations. While\nthe asymptotic scaling is nearly optimal, its performance on parallel\narchitectures is dominated by the global communication required for the\nunderlying fast Fourier transform (FFT). Here, we develop a novel method, ESP -\nEwald summation with prolate spheroidal wave functions (PSWFs) - that, for a\nfixed precision, sharply reduces the size of this transform by performing the\nEwald split via a PSWF. In addition, PSWFs minimize the cost of spreading and\ninterpolation steps that move information between the particles and the\nunderlying uniform grid. We have integrated the ESP method into two widely-used\nopen-source MD packages: LAMMPS and GROMACS. Detailed benchmarks show that this\nreduces the cost of computing far-field electrostatic interactions by an order\nof magnitude, leading to better strong scaling with respect to number of cores.\nThe total execution time is reduced by a factor of 2 to 3 when using more than\none thousand cores, even after optimally tuning the existing internal\nparameters in the native codes. We validate the accelerated codes in realistic\nlong-time biological simulations.", "published": "2025-05-14 18:36:05", "link": "http://arxiv.org/abs/2505.09727v1", "categories": ["math.NA", "cs.NA", "physics.bio-ph"], "primary_category": "math.NA"}
{"title": "LatticeVision: Image to Image Networks for Modeling Non-Stationary Spatial Data", "abstract": "In many scientific and industrial applications, we are given a handful of\ninstances (a 'small ensemble') of a spatially distributed quantity (a 'field')\nbut would like to acquire many more. For example, a large ensemble of global\ntemperature sensitivity fields from a climate model can help farmers, insurers,\nand governments plan appropriately. When acquiring more data is prohibitively\nexpensive -- as is the case with climate models -- statistical emulation offers\nan efficient alternative for simulating synthetic yet realistic fields.\nHowever, parameter inference using maximum likelihood estimation (MLE) is\ncomputationally prohibitive, especially for large, non-stationary fields. Thus,\nmany recent works train neural networks to estimate parameters given spatial\nfields as input, sidestepping MLE completely. In this work we focus on a\npopular class of parametric, spatially autoregressive (SAR) models. We make a\nsimple yet impactful observation; because the SAR parameters can be arranged on\na regular grid, both inputs (spatial fields) and outputs (model parameters) can\nbe viewed as images. Using this insight, we demonstrate that image-to-image\n(I2I) networks enable faster and more accurate parameter estimation for a class\nof non-stationary SAR models with unprecedented complexity.", "published": "2025-05-14 20:59:10", "link": "http://arxiv.org/abs/2505.09803v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Learning Multi-Attribute Differential Graphs with Non-Convex Penalties", "abstract": "We consider the problem of estimating differences in two multi-attribute\nGaussian graphical models (GGMs) which are known to have similar structure,\nusing a penalized D-trace loss function with non-convex penalties. The GGM\nstructure is encoded in its precision (inverse covariance) matrix. Existing\nmethods for multi-attribute differential graph estimation are based on a group\nlasso penalized loss function. In this paper, we consider a penalized D-trace\nloss function with non-convex (log-sum and smoothly clipped absolute deviation\n(SCAD)) penalties. Two proximal gradient descent methods are presented to\noptimize the objective function. Theoretical analysis establishing sufficient\nconditions for consistency in support recovery, convexity and estimation in\nhigh-dimensional settings is provided. We illustrate our approaches with\nnumerical examples based on synthetic and real data.", "published": "2025-05-14 19:19:09", "link": "http://arxiv.org/abs/2505.09748v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Forests for Differences: Robust Causal Inference Beyond Parametric DiD", "abstract": "This paper introduces the Difference-in-Differences Bayesian Causal Forest\n(DiD-BCF), a novel non-parametric model addressing key challenges in DiD\nestimation, such as staggered adoption and heterogeneous treatment effects.\nDiD-BCF provides a unified framework for estimating Average (ATE),\nGroup-Average (GATE), and Conditional Average Treatment Effects (CATE). A core\ninnovation, its Parallel Trends Assumption (PTA)-based reparameterization,\nenhances estimation accuracy and stability in complex panel data settings.\nExtensive simulations demonstrate DiD-BCF's superior performance over\nestablished benchmarks, particularly under non-linearity, selection biases, and\neffect heterogeneity. Applied to U.S. minimum wage policy, the model uncovers\nsignificant conditional treatment effect heterogeneity related to county\npopulation, insights obscured by traditional methods. DiD-BCF offers a robust\nand versatile tool for more nuanced causal inference in modern DiD\napplications.", "published": "2025-05-14 18:06:51", "link": "http://arxiv.org/abs/2505.09706v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "On Measuring Intrinsic Causal Attributions in Deep Neural Networks", "abstract": "Quantifying the causal influence of input features within neural networks has\nbecome a topic of increasing interest. Existing approaches typically assess\ndirect, indirect, and total causal effects. This work treats NNs as structural\ncausal models (SCMs) and extends our focus to include intrinsic causal\ncontributions (ICC). We propose an identifiable generative post-hoc framework\nfor quantifying ICC. We also draw a relationship between ICC and Sobol'\nindices. Our experiments on synthetic and real-world datasets demonstrate that\nICC generates more intuitive and reliable explanations compared to existing\nglobal explanation techniques.", "published": "2025-05-14 12:59:04", "link": "http://arxiv.org/abs/2505.09660v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Theoretical Model of Acoustic Power Transfer Through Solids", "abstract": "Acoustic Power Transfer is a relatively new technology. It is a modern type\nof a wireless interface, where data signals and supply voltages are\ntransmitted, with the use of mechanical waves, through a medium. The simplest\napplication of such systems is the measurement of frequency response for audio\nspeakers. It consists of a variable signal generator, a measuring amplifier\nwhich drives an acoustic source and the loudspeaker driver. The receiver\ncontains a microphone circuit with a level recorder. Acoustic Power Transfer\ncould have many applications, such as: Cochlear Implants, Sonar Systems and\nWireless Charging. However, it is a new technology, thus it needs further\ninvestigation.", "published": "2025-05-14 20:22:30", "link": "http://arxiv.org/abs/2505.09784v1", "categories": ["cs.SD", "eess.AS", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Introducing voice timbre attribute detection", "abstract": "This paper focuses on explaining the timbre conveyed by speech signals and\nintroduces a task termed voice timbre attribute detection (vTAD). In this task,\nvoice timbre is explained with a set of sensory attributes describing its human\nperception. A pair of speech utterances is processed, and their intensity is\ncompared in a designated timbre descriptor. Moreover, a framework is proposed,\nwhich is built upon the speaker embeddings extracted from the speech\nutterances. The investigation is conducted on the VCTK-RVA dataset.\nExperimental examinations on the ECAPA-TDNN and FACodec speaker encoders\ndemonstrated that: 1) the ECAPA-TDNN speaker encoder was more capable in the\nseen scenario, where the testing speakers were included in the training set; 2)\nthe FACodec speaker encoder was superior in the unseen scenario, where the\ntesting speakers were not part of the training, indicating enhanced\ngeneralization capability. The VCTK-RVA dataset and open-source code are\navailable on the website https://github.com/vTAD2025-Challenge/vTAD.", "published": "2025-05-14 13:46:46", "link": "http://arxiv.org/abs/2505.09661v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Kronecker-Structured Graphs from Smooth Signals", "abstract": "Graph learning, or network inference, is a prominent problem in graph signal\nprocessing (GSP). GSP generalizes the Fourier transform to non-Euclidean\ndomains, and graph learning is pivotal to applying GSP when these domains are\nunknown. With the recent prevalence of multi-way data, there has been growing\ninterest in product graphs that naturally factorize dependencies across\ndifferent ways. However, the types of graph products that can be learned are\nstill limited for modeling diverse dependency structures. In this paper, we\nstudy the problem of learning a Kronecker-structured product graph from smooth\nsignals. Unlike the more commonly used Cartesian product, the Kronecker product\nmodels dependencies in a more intricate, non-separable way, but posits harder\nconstraints on the graph learning problem. To tackle this non-convex problem,\nwe propose an alternating scheme to optimize each factor graph and provide\ntheoretical guarantees for its asymptotic convergence. The proposed algorithm\nis also modified to learn factor graphs of the strong product. We conduct\nexperiments on synthetic and real-world graphs and demonstrate our approach's\nefficacy and superior performance compared to existing methods.", "published": "2025-05-14 21:53:37", "link": "http://arxiv.org/abs/2505.09822v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Implicit Neural Representation of Waveform Measurements in Power Systems Waveform Data Analysis", "abstract": "There is currently a paradigm shift in several power system monitoring\napplications, such as incipient fault detection and monitoring inverter-based\nresources, to transition from traditional phasor analytics to more informative\nwaveform analytics. This paper contributes to this transition by developing a\nnovel approach to modeling voltage and current waveform measurements using\nimplicit neural representations (INRs). INRs are continuous function\napproximators that are recently used in vision and signal processing. The\nproposed INR models are specifically designed to meet the requirements of\nwaveform analytics in power systems, such as by using sinusoidal activation\nfunctions that capture the periodic nature of voltage and current waveforms. We\nalso propose extended models that can efficiently represent correlated\nwaveforms, such as three-phase waveforms and synchro-waveforms. Real-world case\nstudies demonstrate the effectiveness of the proposed INR models in terms of\naccuracy (<1-2% MSE) and model size (4-6x compression). We also investigate the\napplication of INR models in oscillation monitoring, for single mode\noscillations and dual mode modulated oscillations.", "published": "2025-05-14 20:31:55", "link": "http://arxiv.org/abs/2505.09789v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "THz-Band Near-Field RIS Channel Modeling for Linear Channel Estimation", "abstract": "Reconfigurable intelligent surface (RIS)-aided terahertz (THz)-band\ncommunications are promising enablers for future wireless networks. However,\narray densification at high frequencies introduces significant challenges in\naccurate channel modeling and estimation, particularly with THz-specific\nfading, mutual coupling (MC), spatial correlation, and near-field effects. In\nthis work, we model THz outdoor small-scale fading channels using the mixture\ngamma (MG) distribution, considering absorption losses, spherical wave\npropagation, MC, and spatial correlation across large base stations and RISs.\nWe derive the distribution of the cascaded RIS-aided channel and investigate\nlinear channel estimation techniques, analyzing the impact of various channel\nparameters. Numerical results based on precise THz parameters reveal that\naccounting for spatial correlation, MC, and near-field modeling substantially\nenhances estimation accuracy, especially in ultra-massive arrays and\nshort-range scenarios. These results underscore the importance of incorporating\nthese effects for precise, physically consistent channel modeling.", "published": "2025-05-14 19:54:15", "link": "http://arxiv.org/abs/2505.09767v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "FAS-LLM: Large Language Model-Based Channel Prediction for OTFS-Enabled Satellite-FAS Links", "abstract": "This paper proposes FAS-LLM, a novel large language model (LLM)-based\narchitecture for predicting future channel states in Orthogonal Time Frequency\nSpace (OTFS)-enabled satellite downlinks equipped with fluid antenna systems\n(FAS). The proposed method introduces a two-stage channel compression strategy\ncombining reference-port selection and separable principal component analysis\n(PCA) to extract compact, delay-Doppler-aware representations from\nhigh-dimensional OTFS channels. These representations are then embedded into a\nLoRA-adapted LLM, enabling efficient time-series forecasting of channel\ncoefficients. Performance evaluations demonstrate that FAS-LLM outperforms\nclassical baselines including GRU, LSTM, and Transformer models, achieving up\nto 10 dB normalized mean squared error (NMSE) improvement and threefold root\nmean squared error (RMSE) reduction across prediction horizons. Furthermore,\nthe predicted channels preserve key physical-layer characteristics, enabling\nnear-optimal performance in ergodic capacity, spectral efficiency, and outage\nprobability across a wide range of signal-to-noise ratios (SNRs). These results\nhighlight the potential of LLM-based forecasting for delay-sensitive and\nenergy-efficient link adaptation in future satellite IoT networks.", "published": "2025-05-14 19:31:27", "link": "http://arxiv.org/abs/2505.09751v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Efficient Near-Field Beam Focusing Merging Orthogonal Matching Pursuit and CVX for Large Intelligent Surface Applications", "abstract": "In this paper, an efficient near-field beamforming method is proposed to\nsupport the large intelligent surfaces (LIS) that are expected to be widely\ndeployed in 6G networks. This approach avoids directly applying convex (CVX)\noptimization for sparse selection in large-size array matrices, as such methods\noften lead to excessive computational time due to blind searching to satisfy a\nseries of objective functions. First, based on the objective function, we\nprioritize a key component and employ the orthogonal matching pursuit (OMP)\nmethod to pre-select potential sparse target positions. To ensure focal\nsymmetry, a coordinate mirror symmetry approach is adopted, meaning that\nselection is performed only in the first quadrant, while the remaining\nquadrants are determined through mirror symmetry relative to the first\nquadrant. This significantly reduces computational complexity at an early\nstage. Next, CVX is applied based on the pre-selected sparse array. Once a\npredefined threshold is met, a solution is obtained that satisfies the\nconstraints of the beamfocusing. The results demonstrate that, compared with\nconventional methods, this approach improves efficiency by 15.12 times with 121\nelements and 96.73 times with 441 elements. The proposed method demonstrates\nnot only satisfactory performance but also considerable potential as a beam\nfocusing technique for large-scale near-field array systems.", "published": "2025-05-14 18:12:56", "link": "http://arxiv.org/abs/2505.09711v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Adversarial Attack on Large Language Models using Exponentiated Gradient Descent", "abstract": "As Large Language Models (LLMs) are widely used, understanding them\nsystematically is key to improving their safety and realizing their full\npotential. Although many models are aligned using techniques such as\nreinforcement learning from human feedback (RLHF), they are still vulnerable to\njailbreaking attacks. Some of the existing adversarial attack methods search\nfor discrete tokens that may jailbreak a target model while others try to\noptimize the continuous space represented by the tokens of the model's\nvocabulary. While techniques based on the discrete space may prove to be\ninefficient, optimization of continuous token embeddings requires projections\nto produce discrete tokens, which might render them ineffective. To fully\nutilize the constraints and the structures of the space, we develop an\nintrinsic optimization technique using exponentiated gradient descent with the\nBregman projection method to ensure that the optimized one-hot encoding always\nstays within the probability simplex. We prove the convergence of the technique\nand implement an efficient algorithm that is effective in jailbreaking several\nwidely used LLMs. We demonstrate the efficacy of the proposed technique using\nfive open-source LLMs on four openly available datasets. The results show that\nthe technique achieves a higher success rate with great efficiency compared to\nthree other state-of-the-art jailbreaking techniques. The source code for our\nimplementation is available at:\nhttps://github.com/sbamit/Exponentiated-Gradient-Descent-LLM-Attack", "published": "2025-05-14 21:50:46", "link": "http://arxiv.org/abs/2505.09820v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Interim Report on Human-Guided Adaptive Hyperparameter Optimization with Multi-Fidelity Sprints", "abstract": "This case study applies a phased hyperparameter optimization process to\ncompare multitask natural language model variants that utilize multiphase\nlearning rate scheduling and optimizer parameter grouping. We employ short,\nBayesian optimization sessions that leverage multi-fidelity, hyperparameter\nspace pruning, progressive halving, and a degree of human guidance. We utilize\nthe Optuna TPE sampler and Hyperband pruner, as well as the Scikit-Learn\nGaussian process minimization. Initially, we use efficient low-fidelity sprints\nto prune the hyperparameter space. Subsequent sprints progressively increase\ntheir model fidelity and employ hyperband pruning for efficiency. A second\naspect of our approach is using a meta-learner to tune threshold values to\nresolve classification probabilities during inference. We demonstrate our\nmethod on a collection of variants of the 2021 Joint Entity and Relation\nExtraction model proposed by Eberts and Ulges.", "published": "2025-05-14 20:38:44", "link": "http://arxiv.org/abs/2505.09792v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models", "abstract": "Spiking Large Language Models (LLMs) have emerged as an energy-efficient\nalternative to conventional LLMs through their event-driven computation. To\neffectively obtain spiking LLMs, researchers develop different ANN-to-SNN\nconversion methods by leveraging pre-trained ANN parameters while inheriting\nthe energy efficiency of SNN. However, existing conversion methods struggle\nwith extreme activation outliers and incompatible nonlinear operations of\nANN-based LLMs. To address this, we propose a loss-less ANN-SNN conversion for\nfully spike-driven LLMs, termed LAS. Specifically, LAS introduces two novel\nneurons to convert the activation outlier and nonlinear operation of ANN-based\nLLMs. Moreover, LAS tailors the spike-equivalent Transformer components for\nspiking LLMs, which can ensure full spiking conversion without any loss of\nperformance. Experimental results on six language models and two\nvision-language models demonstrate that LAS achieves loss-less conversion.\nNotably, on OPT-66B, LAS even improves the accuracy of 2\\% on the WSC task. In\naddition, the parameter and ablation studies further verify the effectiveness\nof LAS. The source code is available at https://github.com/lc783/LAS", "published": "2025-05-14 06:18:08", "link": "http://arxiv.org/abs/2505.09659v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EnerVerse-AC: Envisioning Embodied Environments with Action Condition", "abstract": "Robotic imitation learning has advanced from solving static tasks to\naddressing dynamic interaction scenarios, but testing and evaluation remain\ncostly and challenging due to the need for real-time interaction with dynamic\nenvironments. We propose EnerVerse-AC (EVAC), an action-conditional world model\nthat generates future visual observations based on an agent's predicted\nactions, enabling realistic and controllable robotic inference. Building on\nprior architectures, EVAC introduces a multi-level action-conditioning\nmechanism and ray map encoding for dynamic multi-view image generation while\nexpanding training data with diverse failure trajectories to improve\ngeneralization. As both a data engine and evaluator, EVAC augments\nhuman-collected trajectories into diverse datasets and generates realistic,\naction-conditioned video observations for policy testing, eliminating the need\nfor physical robots or complex simulations. This approach significantly reduces\ncosts while maintaining high fidelity in robotic manipulation evaluation.\nExtensive experiments validate the effectiveness of our method. Code,\ncheckpoints, and datasets can be found at\n<https://annaj2178.github.io/EnerverseAC.github.io>.", "published": "2025-05-14 18:30:53", "link": "http://arxiv.org/abs/2505.09723v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Diffusion Recommender Models and the Illusion of Progress: A Concerning Study of Reproducibility and a Conceptual Mismatch", "abstract": "Countless new machine learning models are published every year and are\nreported to significantly advance the state-of-the-art in \\emph{top-n}\nrecommendation. However, earlier reproducibility studies indicate that progress\nin this area may be quite limited. Specifically, various widespread\nmethodological issues, e.g., comparisons with untuned baseline models, have led\nto an \\emph{illusion of progress}. In this work, our goal is to examine whether\nthese problems persist in today's research. To this end, we aim to reproduce\nthe latest advancements reported from applying modern Denoising Diffusion\nProbabilistic Models to recommender systems, focusing on four models published\nat the top-ranked SIGIR conference in 2023 and 2024. Our findings are\nconcerning, revealing persistent methodological problems. Alarmingly, through\nexperiments, we find that the latest recommendation techniques based on\ndiffusion models, despite their computational complexity and substantial carbon\nfootprint, are consistently outperformed by simpler existing models.\nFurthermore, we identify key mismatches between the characteristics of\ndiffusion models and those of the traditional \\emph{top-n} recommendation task,\nraising doubts about their suitability for recommendation. We also note that,\nin the papers we analyze, the generative capabilities of these models are\nconstrained to a minimum. Overall, our results and continued methodological\nissues call for greater scientific rigor and a disruptive change in the\nresearch and publication culture in this area.", "published": "2025-05-14 13:13:53", "link": "http://arxiv.org/abs/2505.09364v2", "categories": ["cs.IR", "cs.LG", "cs.NE"], "primary_category": "cs.IR"}
{"title": "High-Order Hermite Optimization: Fast and Exact Gradient Computation in Open-Loop Quantum Optimal Control using a Discrete Adjoint Approach", "abstract": "This work introduces the High-Order Hermite Optimization (HOHO) method, an\nopen-loop discrete adjoint method for quantum optimal control. Our method is\nthe first of its kind to efficiently compute exact (discrete) gradients when\nusing continuous, parameterized control pulses while solving the forward\nequations (e.g. Schrodinger's equation or the Linblad master equation) with an\narbitrarily high-order Hermite Runge-Kutta method. The HOHO method is\nimplemented in\n[QuantumGateDesign.jl](https://github.com/leespen1/QuantumGateDesign.jl), an\nopen-source software package for the Julia programming language, which we use\nto perform numerical experiments comparing the method to\n[Juqbox.jl](https://github.com/LLNL/Juqbox.jl). For realistic model problems we\nobserve speedups up to 775x.", "published": "2025-05-14 23:41:22", "link": "http://arxiv.org/abs/2505.09857v2", "categories": ["math.NA", "cs.NA", "quant-ph"], "primary_category": "math.NA"}
{"title": "Beyond Pairwise Learning-To-Rank At Airbnb", "abstract": "There are three fundamental asks from a ranking algorithm: it should scale to\nhandle a large number of items, sort items accurately by their utility, and\nimpose a total order on the items for logical consistency. But here's the\ncatch-no algorithm can achieve all three at the same time. We call this\nlimitation the SAT theorem for ranking algorithms. Given the dilemma, how can\nwe design a practical system that meets user needs? Our current work at Airbnb\nprovides an answer, with a working solution deployed at scale. We start with\npairwise learning-to-rank (LTR) models-the bedrock of search ranking tech\nstacks today. They scale linearly with the number of items ranked and perform\nstrongly on metrics like NDCG by learning from pairwise comparisons. They are\nat a sweet spot of performance vs. cost, making them an ideal choice for\nseveral industrial applications. However, they have a drawback-by ignoring\ninteractions between items, they compromise on accuracy. To improve accuracy,\nwe create a \"true\" pairwise LTR model-one that captures interactions between\nitems during pairwise comparisons. But accuracy comes at the expense of\nscalability and total order, and we discuss strategies to counter these\nchallenges. For greater accuracy, we take each item in the search result, and\ncompare it against the rest of the items along two dimensions: (1) Superiority:\nHow strongly do searchers prefer the given item over the remaining ones? (2)\nSimilarity: How similar is the given item to all the other items? This forms\nthe basis of our \"all-pairwise\" LTR framework, which factors in interactions\nacross all items at once. Looking at items on the search result page all\ntogether-superiority and similarity combined-gives us a deeper understanding of\nwhat searchers truly want. We quantify the resulting improvements in searcher\nexperience through offline and online experiments at Airbnb.", "published": "2025-05-14 20:45:29", "link": "http://arxiv.org/abs/2505.09795v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "abstract": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques.", "published": "2025-05-14 14:44:30", "link": "http://arxiv.org/abs/2505.09436v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion", "abstract": "This work presents a methodology for reconstructing the spatial distribution\nof the neutron flux in a nuclear reactor, leveraging real-time measurements\nobtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation\ninherently defines the problem of estimating a scalar field within a domain\nbased on boundary data, making it a natural mathematical framework for this\ntask. The main challenge lies in deriving the Green's function specific to the\ndomain and the neutron diffusion process. While analytical solutions for\nGreen's functions exist for simplified geometries, their derivation of complex,\nheterogeneous domains-such as a nuclear reactor-requires a numerical approach.\nThe objective of this work is to demonstrate the well-posedness of the\ndata-driven Green's function approximation by formulating and solving the K-H\nequation as an inverse problem. After establishing the symmetry properties that\nthe Green's function must satisfy, the K-H equation is derived from the\none-speed neutron diffusion model. This is followed by a comprehensive\ndescription of the procedure for interpreting sensor readings and implementing\nthe neutron flux reconstruction algorithm. Finally, the existence and\nuniqueness of the Green's function inferred from the sampled data are\ndemonstrated, ensuring the reliability of the proposed method and its\npredictions.", "published": "2025-05-14 19:53:09", "link": "http://arxiv.org/abs/2505.09766v2", "categories": ["math.NA", "cs.AI", "cs.NA"], "primary_category": "math.NA"}
{"title": "Quasi-3D beam theory based on equilibrium stress definition and mixed element model for accurate analysis of functionally graded beams", "abstract": "This paper presents a novel quasi-3D theory and the corresponding mixed beam\nelement model to achieve accurate solutions for functionally graded beams. The\nkey innovations include the development of equilibrium-based stress\nexpressions, the modified cross-sectional stiffness matrix, and the mixed beam\nelement model based on semi-analytical definition of internal force fields. In\ncontrast to the conventional quasi-3D theory where stress expressions are\nderived from constitutive equations and geometric relations, the stress\nexpressions in this study are derived from the differential equilibrium\nequations among stresses, ensuring strict adherence of stress solutions to\nequilibrium conditions. To incorporate the influence of equilibrium-derived\nstress distributions, the modified cross-sectional stiffness matrix is derived,\nenhancing the theoretical and practical feasibility of the beam model. For beam\nelement construction, the mixed variational principle of two-field variables is\nemployed, with generalized internal forces and generalized displacements\nregarded as two independent fields. Especially, semi-analytical internal force\nfields, which partially satisfy the differential equilibrium equations, are\nintroduced to improve the element performance. Numerical examples are conducted\nto verify the accuracy and effectiveness of the proposed theory and beam\nelement.", "published": "2025-05-14 04:15:14", "link": "http://arxiv.org/abs/2505.09127v3", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "TARGET: Benchmarking Table Retrieval for Generative Tasks", "abstract": "The data landscape is rich with structured data, often of high value to\norganizations, driving important applications in data analysis and machine\nlearning. Recent progress in representation learning and generative models for\nsuch data has led to the development of natural language interfaces to\nstructured data, including those leveraging text-to-SQL. Contextualizing\ninteractions, either through conversational interfaces or agentic components,\nin structured data through retrieval-augmented generation can provide\nsubstantial benefits in the form of freshness, accuracy, and comprehensiveness\nof answers. The key question is: how do we retrieve the right table(s) for the\nanalytical query or task at hand? To this end, we introduce TARGET: a benchmark\nfor evaluating TAble Retrieval for GEnerative Tasks. With TARGET we analyze the\nretrieval performance of different retrievers in isolation, as well as their\nimpact on downstream tasks. We find that dense embedding-based retrievers far\noutperform a BM25 baseline which is less effective than it is for retrieval\nover unstructured text. We also surface the sensitivity of retrievers across\nvarious metadata (e.g., missing table titles), and demonstrate a stark\nvariation of retrieval performance across datasets and tasks. TARGET is\navailable at https://target-benchmark.github.io.", "published": "2025-05-14 19:39:46", "link": "http://arxiv.org/abs/2505.11545v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.IR"}
