{"title": "Investigating Label Bias in Beam Search for Open-ended Text Generation", "abstract": "Beam search is an effective and widely used decoding algorithm in many\nsequence-to-sequence (seq2seq) text generation tasks. However, in open-ended\ntext generation, beam search is often found to produce repetitive and generic\ntexts, sampling-based decoding algorithms like top-k sampling and nucleus\nsampling are more preferred. Standard seq2seq models suffer from label bias due\nto its locally normalized probability formulation. This paper provides a series\nof empirical evidence that label bias is a major reason for such degenerate\nbehaviors of beam search. By combining locally normalized maximum likelihood\nestimation and globally normalized sequence-level training, label bias can be\nreduced with almost no sacrifice in perplexity. To quantitatively measure label\nbias, we test the model's ability to discriminate the groundtruth text and a\nset of context-agnostic distractors. We conduct experiments on large-scale\nresponse generation datasets. Results show that beam search can produce more\ndiverse and meaningful texts with our approach, in terms of both automatic and\nhuman evaluation metrics. Our analysis also suggests several future working\ndirections towards the grand challenge of open-ended text generation.", "published": "2020-05-22 05:17:53", "link": "http://arxiv.org/abs/2005.11009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Segmentation for Technical Support Problems", "abstract": "Technical support problems are often long and complex. They typically contain\nuser descriptions of the problem, the setup, and steps for attempted\nresolution. Often they also contain various non-natural language text elements\nlike outputs of commands, snippets of code, error messages or stack traces.\nThese elements contain potentially crucial information for problem resolution.\nHowever, they cannot be correctly parsed by tools designed for natural\nlanguage. In this paper, we address the problem of segmentation for technical\nsupport questions. We formulate the problem as a sequence labelling task, and\nstudy the performance of state of the art approaches. We compare this against\nan intuitive contextual sentence-level classification baseline, and a state of\nthe art supervised text-segmentation approach. We also introduce a novel\ncomponent of combining contextual embeddings from multiple language models\npre-trained on different data sources, which achieves a marked improvement over\nusing embeddings from a single pre-trained language model. Finally, we also\ndemonstrate the usefulness of such segmentation with improvements on the\ndownstream task of answer retrieval.", "published": "2020-05-22 08:29:06", "link": "http://arxiv.org/abs/2005.11055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bootstrapping Named Entity Recognition in E-Commerce with Positive\n  Unlabeled Learning", "abstract": "Named Entity Recognition (NER) in domains like e-commerce is an understudied\nproblem due to the lack of annotated datasets. Recognizing novel entity types\nin this domain, such as products, components, and attributes, is challenging\nbecause of their linguistic complexity and the low coverage of existing\nknowledge resources. To address this problem, we present a bootstrapped\npositive-unlabeled learning algorithm that integrates domain-specific\nlinguistic features to quickly and efficiently expand the seed dictionary. The\nmodel achieves an average F1 score of 72.02% on a novel dataset of product\ndescriptions, an improvement of 3.63% over a baseline BiLSTM classifier, and in\nparticular exhibits better recall (4.96% on average).", "published": "2020-05-22 09:35:30", "link": "http://arxiv.org/abs/2005.11075v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Living Machines: A study of atypical animacy", "abstract": "This paper proposes a new approach to animacy detection, the task of\ndetermining whether an entity is represented as animate in a text. In\nparticular, this work is focused on atypical animacy and examines the scenario\nin which typically inanimate objects, specifically machines, are given animate\nattributes. To address it, we have created the first dataset for atypical\nanimacy detection, based on nineteenth-century sentences in English, with\nmachines represented as either animate or inanimate. Our method builds on\nrecent innovations in language modeling, specifically BERT contextualized word\nembeddings, to better capture fine-grained contextual properties of words. We\npresent a fully unsupervised pipeline, which can be easily adapted to different\ncontexts, and report its performance on an established animacy dataset and our\nnewly introduced resource. We show that our method provides a substantially\nmore accurate characterization of atypical animacy, especially when applied to\nhighly complex forms of language use.", "published": "2020-05-22 12:35:18", "link": "http://arxiv.org/abs/2005.11140v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simplify-then-Translate: Automatic Preprocessing for Black-Box Machine\n  Translation", "abstract": "Black-box machine translation systems have proven incredibly useful for a\nvariety of applications yet by design are hard to adapt, tune to a specific\ndomain, or build on top of. In this work, we introduce a method to improve such\nsystems via automatic pre-processing (APP) using sentence simplification. We\nfirst propose a method to automatically generate a large in-domain paraphrase\ncorpus through back-translation with a black-box MT system, which is used to\ntrain a paraphrase model that \"simplifies\" the original sentence to be more\nconducive for translation. The model is used to preprocess source sentences of\nmultiple low-resource language pairs. We show that this preprocessing leads to\nbetter translation performance as compared to non-preprocessed source\nsentences. We further perform side-by-side human evaluation to verify that\ntranslations of the simplified sentences are better than the original ones.\nFinally, we provide some guidance on recommended language pairs for generating\nthe simplification model corpora by investigating the relationship between ease\nof translation of a language pair (as measured by BLEU) and quality of the\nresulting simplification model from back-translations of this language pair (as\nmeasured by SARI), and tie this into the downstream task of low-resource\ntranslation.", "published": "2020-05-22 14:15:53", "link": "http://arxiv.org/abs/2005.11197v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Generative Approach to Titling and Clustering Wikipedia Sections", "abstract": "We evaluate the performance of transformer encoders with various decoders for\ninformation organization through a new task: generation of section headings for\nWikipedia articles. Our analysis shows that decoders containing attention\nmechanisms over the encoder output achieve high-scoring results by generating\nextractive text. In contrast, a decoder without attention better facilitates\nsemantic encoding and can be used to generate section embeddings. We\nadditionally introduce a new loss function, which further encourages the\ndecoder to generate high-quality embeddings.", "published": "2020-05-22 14:49:07", "link": "http://arxiv.org/abs/2005.11216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Character-level Transformer-based Neural Machine Translation", "abstract": "Neural machine translation (NMT) is nowadays commonly applied at the subword\nlevel, using byte-pair encoding. A promising alternative approach focuses on\ncharacter-level translation, which simplifies processing pipelines in NMT\nconsiderably. This approach, however, must consider relatively longer\nsequences, rendering the training process prohibitively expensive. In this\npaper, we discuss a novel, Transformer-based approach, that we compare, both in\nspeed and in quality to the Transformer at subword and character levels, as\nwell as previously developed character-level models. We evaluate our models on\n4 language pairs from WMT'15: DE-EN, CS-EN, FI-EN and RU-EN. The proposed novel\narchitecture can be trained on a single GPU and is 34% percent faster than the\ncharacter-level Transformer; still, the obtained results are at least on par\nwith it. In addition, our proposed model outperforms the subword-level model in\nFI-EN and shows close results in CS-EN. To stimulate further research in this\narea and close the gap with subword-level NMT, we make all our code and models\npublicly available.", "published": "2020-05-22 15:40:43", "link": "http://arxiv.org/abs/2005.11239v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Discussion Tracker Corpus of Collaborative Argumentation", "abstract": "Although Natural Language Processing (NLP) research on argument mining has\nadvanced considerably in recent years, most studies draw on corpora of\nasynchronous and written texts, often produced by individuals. Few published\ncorpora of synchronous, multi-party argumentation are available. The Discussion\nTracker corpus, collected in American high school English classes, is an\nannotated dataset of transcripts of spoken, multi-party argumentation. The\ncorpus consists of 29 multi-party discussions of English literature transcribed\nfrom 985 minutes of audio. The transcripts were annotated for three dimensions\nof collaborative argumentation: argument moves (claims, evidence, and\nexplanations), specificity (low, medium, high) and collaboration (e.g.,\nextensions of and disagreements about others' ideas). In addition to providing\ndescriptive statistics on the corpus, we provide performance benchmarks and\nassociated code for predicting each dimension separately, illustrate the use of\nthe multiple annotations in the corpus to improve performance via multi-task\nlearning, and finally discuss other ways the corpus might be used to further\nNLP research.", "published": "2020-05-22 18:27:28", "link": "http://arxiv.org/abs/2005.11344v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Open Domain Event Trigger Identification using Adversarial\n  Domain Adaptation", "abstract": "We tackle the task of building supervised event trigger identification models\nwhich can generalize better across domains. Our work leverages the adversarial\ndomain adaptation (ADA) framework to introduce domain-invariance. ADA uses\nadversarial training to construct representations that are predictive for\ntrigger identification, but not predictive of the example's domain. It requires\nno labeled data from the target domain, making it completely unsupervised.\nExperiments with two domains (English literature and news) show that ADA leads\nto an average F1 score improvement of 3.9 on out-of-domain data. Our best\nperforming model (BERT-A) reaches 44-49 F1 across both domains, using no\nlabeled target data. Preliminary experiments reveal that finetuning on 1%\nlabeled data, followed by self-training leads to substantial improvement,\nreaching 51.5 and 67.2 F1 on literature and news respectively.", "published": "2020-05-22 19:19:50", "link": "http://arxiv.org/abs/2005.11355v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer-based Context-aware Sarcasm Detection in Conversation\n  Threads from Social Media", "abstract": "We present a transformer-based sarcasm detection model that accounts for the\ncontext from the entire conversation thread for more robust predictions. Our\nmodel uses deep transformer layers to perform multi-head attentions among the\ntarget utterance and the relevant context in the thread. The context-aware\nmodels are evaluated on two datasets from social media, Twitter and Reddit, and\nshow 3.1% and 7.0% improvements over their baselines. Our best models give the\nF1-scores of 79.0% and 75.0% for the Twitter and Reddit datasets respectively,\nbecoming one of the highest performing systems among 36 participants in this\nshared task.", "published": "2020-05-22 23:41:35", "link": "http://arxiv.org/abs/2005.11424v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "RUSSE'2020: Findings of the First Taxonomy Enrichment Task for the\n  Russian language", "abstract": "This paper describes the results of the first shared task on taxonomy\nenrichment for the Russian language. The participants were asked to extend an\nexisting taxonomy with previously unseen words: for each new word their systems\nshould provide a ranked list of possible (candidate) hypernyms. In comparison\nto the previous tasks for other languages, our competition has a more realistic\ntask setting: new words were provided without definitions. Instead, we provided\na textual corpus where these new terms occurred. For this evaluation campaign,\nwe developed a new evaluation dataset based on unpublished RuWordNet data. The\nshared task features two tracks: \"nouns\" and \"verbs\". 16 teams participated in\nthe task demonstrating high results with more than half of them outperforming\nthe provided baseline.", "published": "2020-05-22 13:30:37", "link": "http://arxiv.org/abs/2005.11176v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "L2R2: Leveraging Ranking for Abductive Reasoning", "abstract": "The abductive natural language inference task ($\\alpha$NLI) is proposed to\nevaluate the abductive reasoning ability of a learning system. In the\n$\\alpha$NLI task, two observations are given and the most plausible hypothesis\nis asked to pick out from the candidates. Existing methods simply formulate it\nas a classification problem, thus a cross-entropy log-loss objective is used\nduring training. However, discriminating true from false does not measure the\nplausibility of a hypothesis, for all the hypotheses have a chance to happen,\nonly the probabilities are different. To fill this gap, we switch to a ranking\nperspective that sorts the hypotheses in order of their plausibilities. With\nthis new perspective, a novel $L2R^2$ approach is proposed under the\nlearning-to-rank framework. Firstly, training samples are reorganized into a\nranking form, where two observations and their hypotheses are treated as the\nquery and a set of candidate documents respectively. Then, an ESIM model or\npre-trained language model, e.g. BERT or RoBERTa, is obtained as the scoring\nfunction. Finally, the loss functions for the ranking task can be either\npair-wise or list-wise for training. The experimental results on the ART\ndataset reach the state-of-the-art in the public leaderboard.", "published": "2020-05-22 15:01:23", "link": "http://arxiv.org/abs/2005.11223v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "SentPWNet: A Unified Sentence Pair Weighting Network for Task-specific\n  Sentence Embedding", "abstract": "Pair-based metric learning has been widely adopted to learn sentence\nembedding in many NLP tasks such as semantic text similarity due to its\nefficiency in computation. Most existing works employed a sequence encoder\nmodel and utilized limited sentence pairs with a pair-based loss to learn\ndiscriminating sentence representation. However, it is known that the sentence\nrepresentation can be biased when the sampled sentence pairs deviate from the\ntrue distribution of all sentence pairs. In this paper, our theoretical\nanalysis shows that existing works severely suffered from a good pair sampling\nand instance weighting strategy. Instead of one time pair selection and\nlearning on equal weighted pairs, we propose a unified locality weighting and\nlearning framework to learn task-specific sentence embedding. Our model,\nSentPWNet, exploits the neighboring spatial distribution of each sentence as\nlocality weight to indicate the informative level of sentence pair. Such weight\nis updated along with pair-loss optimization in each round, ensuring the model\nkeep learning the most informative sentence pairs. Extensive experiments on\nfour public available datasets and a self-collected place search benchmark with\n1.4 million places clearly demonstrate that our model consistently outperforms\nexisting sentence embedding methods with comparable efficiency.", "published": "2020-05-22 18:32:35", "link": "http://arxiv.org/abs/2005.11347v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Open-Retrieval Conversational Question Answering", "abstract": "Conversational search is one of the ultimate goals of information retrieval.\nRecent research approaches conversational search by simplified settings of\nresponse ranking and conversational question answering, where an answer is\neither selected from a given candidate set or extracted from a given passage.\nThese simplifications neglect the fundamental role of retrieval in\nconversational search. To address this limitation, we introduce an\nopen-retrieval conversational question answering (ORConvQA) setting, where we\nlearn to retrieve evidence from a large collection before extracting answers,\nas a further step towards building functional conversational search systems. We\ncreate a dataset, OR-QuAC, to facilitate research on ORConvQA. We build an\nend-to-end system for ORConvQA, featuring a retriever, a reranker, and a reader\nthat are all based on Transformers. Our extensive experiments on OR-QuAC\ndemonstrate that a learnable retriever is crucial for ORConvQA. We further show\nthat our system can make a substantial improvement when we enable history\nmodeling in all system components. Moreover, we show that the reranker\ncomponent contributes to the model performance by providing a regularization\neffect. Finally, further in-depth analyses are performed to provide new\ninsights into ORConvQA.", "published": "2020-05-22 19:39:50", "link": "http://arxiv.org/abs/2005.11364v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "abstract": "Large pre-trained language models have been shown to store factual knowledge\nin their parameters, and achieve state-of-the-art results when fine-tuned on\ndownstream NLP tasks. However, their ability to access and precisely manipulate\nknowledge is still limited, and hence on knowledge-intensive tasks, their\nperformance lags behind task-specific architectures. Additionally, providing\nprovenance for their decisions and updating their world knowledge remain open\nresearch problems. Pre-trained models with a differentiable access mechanism to\nexplicit non-parametric memory can overcome this issue, but have so far been\nonly investigated for extractive downstream tasks. We explore a general-purpose\nfine-tuning recipe for retrieval-augmented generation (RAG) -- models which\ncombine pre-trained parametric and non-parametric memory for language\ngeneration. We introduce RAG models where the parametric memory is a\npre-trained seq2seq model and the non-parametric memory is a dense vector index\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\nformulations, one which conditions on the same retrieved passages across the\nwhole generated sequence, the other can use different passages per token. We\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\ntasks and set the state-of-the-art on three open domain QA tasks, outperforming\nparametric seq2seq models and task-specific retrieve-and-extract architectures.\nFor language generation tasks, we find that RAG models generate more specific,\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\nbaseline.", "published": "2020-05-22 21:34:34", "link": "http://arxiv.org/abs/2005.11401v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoAID: COVID-19 Healthcare Misinformation Dataset", "abstract": "As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID.", "published": "2020-05-22 19:08:14", "link": "http://arxiv.org/abs/2006.00885v3", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "NAUTILUS: a Versatile Voice Cloning System", "abstract": "We introduce a novel speech synthesis system, called NAUTILUS, that can\ngenerate speech with a target voice either from a text input or a reference\nutterance of an arbitrary source speaker. By using a multi-speaker speech\ncorpus to train all requisite encoders and decoders in the initial training\nstage, our system can clone unseen voices using untranscribed speech of target\nspeakers on the basis of the backpropagation algorithm. Moreover, depending on\nthe data circumstance of the target speaker, the cloning strategy can be\nadjusted to take advantage of additional data and modify the behaviors of\ntext-to-speech (TTS) and/or voice conversion (VC) systems to accommodate the\nsituation. We test the performance of the proposed framework by using deep\nconvolution layers to model the encoders, decoders and WaveNet vocoder.\nEvaluations show that it achieves comparable quality with state-of-the-art TTS\nand VC systems when cloning with just five minutes of untranscribed speech.\nMoreover, it is demonstrated that the proposed framework has the ability to\nswitch between TTS and VC with high speaker consistency, which will be useful\nfor many applications.", "published": "2020-05-22 05:00:20", "link": "http://arxiv.org/abs/2005.11004v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Intent Mining from past conversations for conversational agent", "abstract": "Conversational systems are of primary interest in the AI community. Chatbots\nare increasingly being deployed to provide round-the-clock support and to\nincrease customer engagement. Many of the commercial bot building frameworks\nfollow a standard approach that requires one to build and train an intent model\nto recognize a user input. Intent models are trained in a supervised setting\nwith a collection of textual utterance and intent label pairs. Gathering a\nsubstantial and wide coverage of training data for different intent is a\nbottleneck in the bot building process. Moreover, the cost of labeling a\nhundred to thousands of conversations with intent is a time consuming and\nlaborious job. In this paper, we present an intent discovery framework that\ninvolves 4 primary steps: Extraction of textual utterances from a conversation\nusing a pre-trained domain agnostic Dialog Act Classifier (Data Extraction),\nautomatic clustering of similar user utterances (Clustering), manual annotation\nof clusters with an intent label (Labeling) and propagation of intent labels to\nthe utterances from the previous step, which are not mapped to any cluster\n(Label Propagation); to generate intent training data from raw conversations.\nWe have introduced a novel density-based clustering algorithm ITER-DBSCAN for\nunbalanced data clustering. Subject Matter Expert (Annotators with domain\nexpertise) manually looks into the clustered user utterances and provides an\nintent label for discovery. We conducted user studies to validate the\neffectiveness of the trained intent model generated in terms of coverage of\nintents, accuracy and time saving concerning manual annotation. Although the\nsystem is developed for building an intent model for the conversational system,\nthis framework can also be used for a short text clustering or as a labeling\nframework.", "published": "2020-05-22 05:29:13", "link": "http://arxiv.org/abs/2005.11014v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Robust Layout-aware IE for Visually Rich Documents with Pre-trained\n  Language Models", "abstract": "Many business documents processed in modern NLP and IR pipelines are visually\nrich: in addition to text, their semantics can also be captured by visual\ntraits such as layout, format, and fonts. We study the problem of information\nextraction from visually rich documents (VRDs) and present a model that\ncombines the power of large pre-trained language models and graph neural\nnetworks to efficiently encode both textual and visual information in business\ndocuments. We further introduce new fine-tuning objectives to improve in-domain\nunsupervised fine-tuning to better utilize large amount of unlabeled in-domain\ndata. We experiment on real world invoice and resume data sets and show that\nthe proposed method outperforms strong text-based RoBERTa baselines by 6.3%\nabsolute F1 on invoices and 4.7% absolute F1 on resumes. When evaluated in a\nfew-shot setting, our method requires up to 30x less annotation data than the\nbaseline to achieve the same level of performance at ~90% F1.", "published": "2020-05-22 06:04:50", "link": "http://arxiv.org/abs/2005.11017v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Classification and Clustering of arXiv Documents, Sections, and\n  Abstracts, Comparing Encodings of Natural and Mathematical Language", "abstract": "In this paper, we show how selecting and combining encodings of natural and\nmathematical language affect classification and clustering of documents with\nmathematical content. We demonstrate this by using sets of documents, sections,\nand abstracts from the arXiv preprint server that are labeled by their subject\nclass (mathematics, computer science, physics, etc.) to compare different\nencodings of text and formulae and evaluate the performance and runtimes of\nselected classification and clustering algorithms. Our encodings achieve\nclassification accuracies up to $82.8\\%$ and cluster purities up to $69.4\\%$\n(number of clusters equals number of classes), and $99.9\\%$ (unspecified number\nof clusters) respectively. We observe a relatively low correlation between text\nand math similarity, which indicates the independence of text and formulae and\nmotivates treating them as separate features of a document. The classification\nand clustering can be employed, e.g., for document search and recommendation.\nFurthermore, we show that the computer outperforms a human expert when\nclassifying documents. Finally, we evaluate and discuss multi-label\nclassification and formula semantification.", "published": "2020-05-22 06:16:32", "link": "http://arxiv.org/abs/2005.11021v1", "categories": ["cs.DL", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.DL"}
{"title": "Interacting with Explanations through Critiquing", "abstract": "Using personalized explanations to support recommendations has been shown to\nincrease trust and perceived quality. However, to actually obtain better\nrecommendations, there needs to be a means for users to modify the\nrecommendation criteria by interacting with the explanation. We present a novel\ntechnique using aspect markers that learns to generate personalized\nexplanations of recommendations from review texts, and we show that human users\nsignificantly prefer these explanations over those produced by state-of-the-art\ntechniques. Our work's most important innovation is that it allows users to\nreact to a recommendation by critiquing the textual explanation: removing\n(symmetrically adding) certain aspects they dislike or that are no longer\nrelevant (symmetrically that are of interest). The system updates its user\nmodel and the resulting recommendations according to the critique. This is\nbased on a novel unsupervised critiquing method for single- and multi-step\ncritiquing with textual explanations. Experiments on two real-world datasets\nshow that our system is the first to achieve good performance in adapting to\nthe preferences expressed in multi-step critiquing.", "published": "2020-05-22 09:03:06", "link": "http://arxiv.org/abs/2005.11067v4", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "GeoCoV19: A Dataset of Hundreds of Millions of Multilingual COVID-19\n  Tweets with Location Information", "abstract": "The past several years have witnessed a huge surge in the use of social media\nplatforms during mass convergence events such as health emergencies, natural or\nhuman-induced disasters. These non-traditional data sources are becoming vital\nfor disease forecasts and surveillance when preparing for epidemic and pandemic\noutbreaks. In this paper, we present GeoCoV19, a large-scale Twitter dataset\ncontaining more than 524 million multilingual tweets posted over a period of 90\ndays since February 1, 2020. Moreover, we employ a gazetteer-based approach to\ninfer the geolocation of tweets. We postulate that this large-scale,\nmultilingual, geolocated social media data can empower the research communities\nto evaluate how societies are collectively coping with this unprecedented\nglobal crisis as well as to develop computational methods to address challenges\nsuch as identifying fake news, understanding communities' knowledge gaps,\nbuilding disease forecast and surveillance models, among others.", "published": "2020-05-22 13:30:42", "link": "http://arxiv.org/abs/2005.11177v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.IR"], "primary_category": "cs.SI"}
{"title": "End-to-end Named Entity Recognition from English Speech", "abstract": "Named entity recognition (NER) from text has been a widely studied problem\nand usually extracts semantic information from text. Until now, NER from speech\nis mostly studied in a two-step pipeline process that includes first applying\nan automatic speech recognition (ASR) system on an audio sample and then\npassing the predicted transcript to a NER tagger. In such cases, the error does\nnot propagate from one step to another as both the tasks are not optimized in\nan end-to-end (E2E) fashion. Recent studies confirm that integrated approaches\n(e.g., E2E ASR) outperform sequential ones (e.g., phoneme based ASR). In this\npaper, we introduce a first publicly available NER annotated dataset for\nEnglish speech and present an E2E approach, which jointly optimizes the ASR and\nNER tagger components. Experimental results show that the proposed E2E approach\noutperforms the classical two-step approach. We also discuss how NER from\nspeech can be used to handle out of vocabulary (OOV) words in an ASR system.", "published": "2020-05-22 13:39:14", "link": "http://arxiv.org/abs/2005.11184v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Low-Latency Sequence-to-Sequence Speech Recognition and Translation by\n  Partial Hypothesis Selection", "abstract": "Encoder-decoder models provide a generic architecture for\nsequence-to-sequence tasks such as speech recognition and translation. While\noffline systems are often evaluated on quality metrics like word error rates\n(WER) and BLEU, latency is also a crucial factor in many practical use-cases.\nWe propose three latency reduction techniques for chunk-based incremental\ninference and evaluate their efficiency in terms of accuracy-latency trade-off.\nOn the 300-hour How2 dataset, we reduce latency by 83% to 0.8 second by\nsacrificing 1% WER (6% rel.) compared to offline transcription. Although our\nexperiments use the Transformer, the hypothesis selection strategies are\napplicable to other encoder-decoder models. To avoid expensive re-computation,\nwe use a unidirectionally-attending encoder. After an adaptation procedure to\npartial sequences, the unidirectional model performs on-par with the original\nmodel. We further show that our approach is also applicable to low-latency\nspeech translation. On How2 English-Portuguese speech translation, we reduce\nlatency to 0.7 second (-84% rel.) while incurring a loss of 2.4 BLEU points (5%\nrel.) compared to the offline system.", "published": "2020-05-22 13:42:54", "link": "http://arxiv.org/abs/2005.11185v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Givenness Hierarchy Theoretic Cognitive Status Filtering", "abstract": "For language-capable interactive robots to be effectively introduced into\nhuman society, they must be able to naturally and efficiently communicate about\nthe objects, locations, and people found in human environments. An important\naspect of natural language communication is the use of pronouns. Ac-cording to\nthe linguistic theory of the Givenness Hierarchy(GH), humans use pronouns due\nto implicit assumptions about the cognitive statuses their referents have in\nthe minds of their conversational partners. In previous work, Williams et al.\npresented the first computational implementation of the full GH for the purpose\nof robot language understanding, leveraging a set of rules informed by the GH\nliterature. However, that approach was designed specifically for language\nunderstanding,oriented around GH-inspired memory structures used to assess what\nentities are candidate referents given a particular cognitive status. In\ncontrast, language generation requires a model in which cognitive status can be\nassessed for a given entity. We present and compare two such models of\ncognitive status: a rule-based Finite State Machine model directly informed by\nthe GH literature and a Cognitive Status Filter designed to more flexibly\nhandle uncertainty. The models are demonstrated and evaluated using a\nsilver-standard English subset of the OFAI Multimodal Task Description Corpus.", "published": "2020-05-22 16:44:14", "link": "http://arxiv.org/abs/2005.11267v1", "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Comparative Study of Machine Learning Models and BERT on SQuAD", "abstract": "This study aims to provide a comparative analysis of performance of certain\nmodels popular in machine learning and the BERT model on the Stanford Question\nAnswering Dataset (SQuAD). The analysis shows that the BERT model, which was\nonce state-of-the-art on SQuAD, gives higher accuracy in comparison to other\nmodels. However, BERT requires a greater execution time even when only 100\nsamples are used. This shows that with increasing accuracy more amount of time\nis invested in training the data. Whereas in case of preliminary machine\nlearning models, execution time for full data is lower but accuracy is\ncompromised.", "published": "2020-05-22 17:58:30", "link": "http://arxiv.org/abs/2005.11313v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Med-BERT: pre-trained contextualized embeddings on large-scale\n  structured electronic health records for disease prediction", "abstract": "Deep learning (DL) based predictive models from electronic health records\n(EHR) deliver impressive performance in many clinical tasks. Large training\ncohorts, however, are often required to achieve high accuracy, hindering the\nadoption of DL-based models in scenarios with limited training data size.\nRecently, bidirectional encoder representations from transformers (BERT) and\nrelated models have achieved tremendous successes in the natural language\nprocessing domain. The pre-training of BERT on a very large training corpus\ngenerates contextualized embeddings that can boost the performance of models\ntrained on smaller datasets. We propose Med-BERT, which adapts the BERT\nframework for pre-training contextualized embedding models on structured\ndiagnosis data from 28,490,650 patients EHR dataset. Fine-tuning experiments\nare conducted on two disease-prediction tasks: (1) prediction of heart failure\nin patients with diabetes and (2) prediction of pancreatic cancer from two\nclinical databases. Med-BERT substantially improves prediction accuracy,\nboosting the area under receiver operating characteristics curve (AUC) by\n2.02-7.12%. In particular, pre-trained Med-BERT substantially improves the\nperformance of tasks with very small fine-tuning training sets (300-500\nsamples) boosting the AUC by more than 20% or equivalent to the AUC of 10 times\nlarger training set. We believe that Med-BERT will benefit disease-prediction\nstudies with small local training datasets, reduce data collection expenses,\nand accelerate the pace of artificial intelligence aided healthcare.", "published": "2020-05-22 05:07:17", "link": "http://arxiv.org/abs/2005.12833v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Automatic Discovery of Novel Intents & Domains from Text Utterances", "abstract": "One of the primary tasks in Natural Language Understanding (NLU) is to\nrecognize the intents as well as domains of users' spoken and written language\nutterances. Most existing research formulates this as a supervised\nclassification problem with a closed-world assumption, i.e. the domains or\nintents to be identified are pre-defined or known beforehand. Real-world\napplications however increasingly encounter dynamic, rapidly evolving\nenvironments with newly emerging intents and domains, about which no\ninformation is known during model training. We propose a novel framework,\nADVIN, to automatically discover novel domains and intents from large volumes\nof unlabeled data. We first employ an open classification model to identify all\nutterances potentially consisting of a novel intent. Next, we build a knowledge\ntransfer component with a pairwise margin loss function. It learns\ndiscriminative deep features to group together utterances and discover multiple\nlatent intent categories within them in an unsupervised manner. We finally\nhierarchically link mutually related intents into domains, forming an\nintent-domain taxonomy. ADVIN significantly outperforms baselines on three\nbenchmark datasets, and real user utterances from a commercial voice-powered\nagent.", "published": "2020-05-22 00:47:10", "link": "http://arxiv.org/abs/2006.01208v1", "categories": ["cs.CL", "cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LEAP Submission to CHiME-6 ASR Challenge}", "abstract": "This paper reports the LEAP submission to the CHiME-6 challenge. The CHiME-6\nAutomatic Speech Recognition (ASR) challenge Track 1 involved the recognition\nof speech in noisy and reverberant acoustic conditions in home environments\nwith multiple-party interactions. For the challenge submission, the LEAP system\nused extensive data augmentation and a factorized time-delay neural network\n(TDNN) architecture. We also explored a neural architecture that interleaved\nthe TDNN layers with LSTM layers. The submitted system improved the Kaldi\nrecipe by 2% in terms of relative word-error-rate improvements.", "published": "2020-05-22 16:14:06", "link": "http://arxiv.org/abs/2005.11258v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "LibriMix: An Open-Source Dataset for Generalizable Speech Separation", "abstract": "In recent years, wsj0-2mix has become the reference dataset for\nsingle-channel speech separation. Most deep learning-based speech separation\nmodels today are benchmarked on it. However, recent studies have shown\nimportant performance drops when models trained on wsj0-2mix are evaluated on\nother, similar datasets. To address this generalization issue, we created\nLibriMix, an open-source alternative to wsj0-2mix, and to its noisy extension,\nWHAM!. Based on LibriSpeech, LibriMix consists of two- or three-speaker\nmixtures combined with ambient noise samples from WHAM!. Using Conv-TasNet, we\nachieve competitive performance on all LibriMix versions. In order to fairly\nevaluate across datasets, we introduce a third test set based on VCTK for\nspeech and WHAM! for noise. Our experiments show that the generalization error\nis smaller for models trained with LibriMix than with WHAM!, in both clean and\nnoisy conditions. Aiming towards evaluation in more realistic,\nconversation-like scenarios, we also release a sparsely overlapping version of\nLibriMix's test set.", "published": "2020-05-22 16:26:54", "link": "http://arxiv.org/abs/2005.11262v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment\n  Search", "abstract": "Recently, text-to-speech (TTS) models such as FastSpeech and ParaNet have\nbeen proposed to generate mel-spectrograms from text in parallel. Despite the\nadvantage, the parallel TTS models cannot be trained without guidance from\nautoregressive TTS models as their external aligners. In this work, we propose\nGlow-TTS, a flow-based generative model for parallel TTS that does not require\nany external aligner. By combining the properties of flows and dynamic\nprogramming, the proposed model searches for the most probable monotonic\nalignment between text and the latent representation of speech on its own. We\ndemonstrate that enforcing hard monotonic alignments enables robust TTS, which\ngeneralizes to long utterances, and employing generative flows enables fast,\ndiverse, and controllable speech synthesis. Glow-TTS obtains an\norder-of-magnitude speed-up over the autoregressive model, Tacotron 2, at\nsynthesis with comparable speech quality. We further show that our model can be\neasily extended to a multi-speaker setting.", "published": "2020-05-22 12:06:46", "link": "http://arxiv.org/abs/2005.11129v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Identify Speakers in Cocktail Parties with End-to-End Attention", "abstract": "In scenarios where multiple speakers talk at the same time, it is important\nto be able to identify the talkers accurately. This paper presents an\nend-to-end system that integrates speech source extraction and speaker\nidentification, and proposes a new way to jointly optimize these two parts by\nmax-pooling the speaker predictions along the channel dimension. Residual\nattention permits us to learn spectrogram masks that are optimized for the\npurpose of speaker identification, while residual forward connections permit\ndilated convolution with a sufficiently large context window to guarantee\ncorrect streaming across syllable boundaries. End-to-end training results in a\nsystem that recognizes one speaker in a two-speaker broadcast speech mixture\nwith 99.9% accuracy and both speakers with 93.9% accuracy, and that recognizes\nall speakers in three-speaker scenarios with 81.2% accuracy.", "published": "2020-05-22 22:15:16", "link": "http://arxiv.org/abs/2005.11408v2", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Microphone Array Based Surveillance Audio Classification", "abstract": "The work assessed seven classical classifiers and two beamforming algorithms\nfor detecting surveillance sound events. The tests included the use of AWGN\nwith -10 dB to 30 dB SNR. Data Augmentation was also employed to improve\nalgorithms' performance. The results showed that the combination of SVM and\nDelay-and-Sum (DaS) scored the best accuracy (up to 86.0\\%), but had high\ncomputational cost ($\\approx $ 402 ms), mainly due to DaS. The use of SGD also\nseems to be a good alternative since it has achieved good accuracy either (up\nto 85.3\\%), but with quicker processing time ($\\approx$ 165 ms).", "published": "2020-05-22 18:35:08", "link": "http://arxiv.org/abs/2005.11348v1", "categories": ["eess.AS", "cs.LG", "eess.SP", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Speaker diarization with session-level speaker embedding refinement\n  using graph neural networks", "abstract": "Deep speaker embedding models have been commonly used as a building block for\nspeaker diarization systems; however, the speaker embedding model is usually\ntrained according to a global loss defined on the training data, which could be\nsub-optimal for distinguishing speakers locally in a specific meeting session.\nIn this work we present the first use of graph neural networks (GNNs) for the\nspeaker diarization problem, utilizing a GNN to refine speaker embeddings\nlocally using the structural information between speech segments inside each\nsession. The speaker embeddings extracted by a pre-trained model are remapped\ninto a new embedding space, in which the different speakers within a single\nsession are better separated. The model is trained for linkage prediction in a\nsupervised manner by minimizing the difference between the affinity matrix\nconstructed by the refined embeddings and the ground-truth adjacency matrix.\nSpectral clustering is then applied on top of the refined embeddings. We show\nthat the clustering performance of the refined speaker embeddings outperforms\nthe original embeddings significantly on both simulated and real meeting data,\nand our system achieves the state-of-the-art result on the NIST SRE 2000\nCALLHOME database.", "published": "2020-05-22 19:52:51", "link": "http://arxiv.org/abs/2005.11371v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
