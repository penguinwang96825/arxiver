{"title": "Incremental Knowledge Base Construction Using DeepDive", "abstract": "Populating a database with unstructured information is a long-standing\nproblem in industry and research that encompasses problems of extraction,\ncleaning, and integration. Recent names used for this problem include dealing\nwith dark data and knowledge base construction (KBC). In this work, we describe\nDeepDive, a system that combines database and machine learning ideas to help\ndevelop KBC systems, and we present techniques to make the KBC process more\nefficient. We observe that the KBC process is iterative, and we develop\ntechniques to incrementally produce inference results for KBC systems. We\npropose two methods for incremental inference, based respectively on sampling\nand variational techniques. We also study the tradeoff space of these methods\nand develop a simple rule-based optimizer. DeepDive includes all of these\ncontributions, and we evaluate DeepDive on five KBC systems, showing that it\ncan speed up KBC inference tasks by up to two orders of magnitude with\nnegligible impact on quality.", "published": "2015-02-03 04:16:24", "link": "http://arxiv.org/abs/1502.00731v4", "categories": ["cs.DB", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Open System Categorical Quantum Semantics in Natural Language Processing", "abstract": "Originally inspired by categorical quantum mechanics (Abramsky and Coecke,\nLiCS'04), the categorical compositional distributional model of natural\nlanguage meaning of Coecke, Sadrzadeh and Clark provides a conceptually\nmotivated procedure to compute the meaning of a sentence, given its grammatical\nstructure within a Lambek pregroup and a vectorial representation of the\nmeaning of its parts. The predictions of this first model have outperformed\nthat of other models in mainstream empirical language processing tasks on large\nscale data. Moreover, just like CQM allows for varying the model in which we\ninterpret quantum axioms, one can also vary the model in which we interpret\nword meaning.\n  In this paper we show that further developments in categorical quantum\nmechanics are relevant to natural language processing too. Firstly, Selinger's\nCPM-construction allows for explicitly taking into account lexical ambiguity\nand distinguishing between the two inherently different notions of homonymy and\npolysemy. In terms of the model in which we interpret word meaning, this means\na passage from the vector space model to density matrices. Despite this change\nof model, standard empirical methods for comparing meanings can be easily\nadopted, which we demonstrate by a small-scale experiment on real-world data.\nThis experiment moreover provides preliminary evidence of the validity of our\nproposed new model for word meaning.\n  Secondly, commutative classical structures as well as their non-commutative\ncounterparts that arise in the image of the CPM-construction allow for encoding\nrelative pronouns, verbs and adjectives, and finally, iteration of the\nCPM-construction, something that has no counterpart in the quantum realm,\nenables one to accommodate both entailment and ambiguity.", "published": "2015-02-03 12:16:19", "link": "http://arxiv.org/abs/1502.00831v2", "categories": ["cs.CL", "cs.LO", "math.CT", "math.QA"], "primary_category": "cs.CL"}
