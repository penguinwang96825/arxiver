{"title": "Paraphrase Generation from Latent-Variable PCFGs for Semantic Parsing", "abstract": "One of the limitations of semantic parsing approaches to open-domain question\nanswering is the lexicosyntactic gap between natural language questions and\nknowledge base entries -- there are many ways to ask a question, all with the\nsame answer. In this paper we propose to bridge this gap by generating\nparaphrases of the input question with the goal that at least one of them will\nbe correctly mapped to a knowledge-base query. We introduce a novel grammar\nmodel for paraphrase generation that does not require any sentence-aligned\nparaphrase corpus. Our key idea is to leverage the flexibility and scalability\nof latent-variable probabilistic context-free grammars to sample paraphrases.\nWe do an extrinsic evaluation of our paraphrases by plugging them into a\nsemantic parser for Freebase. Our evaluation experiments on the WebQuestions\nbenchmark dataset show that the performance of the semantic parser\nsignificantly improves over strong baselines.", "published": "2016-01-22 16:50:22", "link": "http://arxiv.org/abs/1601.06068v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speech vocoding for laboratory phonology", "abstract": "Using phonological speech vocoding, we propose a platform for exploring\nrelations between phonology and speech processing, and in broader terms, for\nexploring relations between the abstract and physical structures of a speech\nsignal. Our goal is to make a step towards bridging phonology and speech\nprocessing and to contribute to the program of Laboratory Phonology. We show\nthree application examples for laboratory phonology: compositional phonological\nspeech modelling, a comparison of phonological systems and an experimental\nphonological parametric text-to-speech (TTS) system. The featural\nrepresentations of the following three phonological systems are considered in\nthis work: (i) Government Phonology (GP), (ii) the Sound Pattern of English\n(SPE), and (iii) the extended SPE (eSPE). Comparing GP- and eSPE-based vocoded\nspeech, we conclude that the latter achieves slightly better results than the\nformer. However, GP - the most compact phonological speech representation -\nperforms comparably to the systems with a higher number of phonological\nfeatures. The parametric TTS based on phonological speech representation, and\ntrained from an unlabelled audiobook in an unsupervised manner, achieves\nintelligibility of 85% of the state-of-the-art parametric speech synthesis. We\nenvision that the presented approach paves the way for researchers in both\nfields to form meaningful hypotheses that are explicitly testable using the\nconcepts developed and exemplified in this paper. On the one hand, laboratory\nphonologists might test the applied concepts of their theoretical models, and\non the other hand, the speech processing community may utilize the concepts\ndeveloped for the theoretical phonological models for improvements of the\ncurrent state-of-the-art applications.", "published": "2016-01-22 13:22:10", "link": "http://arxiv.org/abs/1601.05991v3", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "GeoTextTagger: High-Precision Location Tagging of Textual Documents\n  using a Natural Language Processing Approach", "abstract": "Location tagging, also known as geotagging or geolocation, is the process of\nassigning geographical coordinates to input data. In this paper we present an\nalgorithm for location tagging of textual documents. Our approach makes use of\nprevious work in natural language processing by using a state-of-the-art\npart-of-speech tagger and named entity recognizer to find blocks of text which\nmay refer to locations. A knowledge base (OpenStreatMap) is then used to find a\nlist of possible locations for each block. Finally, one location is chosen for\neach block by assigning distance-based scores to each location and repeatedly\nselecting the location and block with the best score. We tested our geolocation\nalgorithm with Wikipedia articles about topics with a well-defined geographical\nlocation that are geotagged by the articles' authors, where classification\napproaches have achieved median errors as low as 11 km, with attainable\naccuracy limited by the class size. Our approach achieved a 10th percentile\nerror of 490 metres and median error of 54 kilometres on the Wikipedia dataset\nwe used. When considering the five location tags with the greatest scores, 50%\nof articles were assigned at least one tag within 8.5 kilometres of the\narticle's author-assigned true location. We also tested our approach on Twitter\nmessages that are tagged with the location from which the message was sent.\nTwitter texts are challenging because they are short and unstructured and often\ndo not contain words referring to the location they were sent from, but we\nobtain potentially useful results. We explain how we use the Spark framework\nfor data analytics to collect and process our test data. In general,\nclassification-based approaches for location tagging may be reaching their\nupper accuracy limit, but our precision-focused approach has high accuracy for\nsome texts and shows significant potential for improvement overall.", "published": "2016-01-22 07:09:54", "link": "http://arxiv.org/abs/1601.05893v1", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Exploiting Low-dimensional Structures to Enhance DNN Based Acoustic\n  Modeling in Speech Recognition", "abstract": "We propose to model the acoustic space of deep neural network (DNN)\nclass-conditional posterior probabilities as a union of low-dimensional\nsubspaces. To that end, the training posteriors are used for dictionary\nlearning and sparse coding. Sparse representation of the test posteriors using\nthis dictionary enables projection to the space of training data. Relying on\nthe fact that the intrinsic dimensions of the posterior subspaces are indeed\nvery small and the matrix of all posteriors belonging to a class has a very low\nrank, we demonstrate how low-dimensional structures enable further enhancement\nof the posteriors and rectify the spurious errors due to mismatch conditions.\nThe enhanced acoustic modeling method leads to improvements in continuous\nspeech recognition task using hybrid DNN-HMM (hidden Markov model) framework in\nboth clean and noisy conditions, where upto 15.4% relative reduction in word\nerror rate (WER) is achieved.", "published": "2016-01-22 10:02:47", "link": "http://arxiv.org/abs/1601.05936v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Why Do Urban Legends Go Viral?", "abstract": "Urban legends are a genre of modern folklore, consisting of stories about\nrare and exceptional events, just plausible enough to be believed, which tend\nto propagate inexorably across communities. In our view, while urban legends\nrepresent a form of \"sticky\" deceptive text, they are marked by a tension\nbetween the credible and incredible. They should be credible like a news\narticle and incredible like a fairy tale to go viral. In particular we will\nfocus on the idea that urban legends should mimic the details of news (who,\nwhere, when) to be credible, while they should be emotional and readable like a\nfairy tale to be catchy and memorable. Using NLP tools we will provide a\nquantitative analysis of these prototypical characteristics. We also lay out\nsome machine learning experiments showing that it is possible to recognize an\nurban legend using just these simple features.", "published": "2016-01-22 17:33:28", "link": "http://arxiv.org/abs/1601.06081v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
