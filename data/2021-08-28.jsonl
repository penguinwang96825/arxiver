{"title": "Self-training Improves Pre-training for Few-shot Learning in\n  Task-oriented Dialog Systems", "abstract": "As the labeling cost for different modules in task-oriented dialog (ToD)\nsystems is expensive, a major challenge is to train different modules with the\nleast amount of labeled data. Recently, large-scale pre-trained language\nmodels, have shown promising results for few-shot learning in ToD. In this\npaper, we devise a self-training approach to utilize the abundant unlabeled\ndialog data to further improve state-of-the-art pre-trained models in few-shot\nlearning scenarios for ToD systems. Specifically, we propose a self-training\napproach that iteratively labels the most confident unlabeled data to train a\nstronger Student model. Moreover, a new text augmentation technique (GradAug)\nis proposed to better train the Student by replacing non-crucial tokens using a\nmasked language model. We conduct extensive experiments and present analyses on\nfour downstream tasks in ToD, including intent classification, dialog state\ntracking, dialog act prediction, and response selection. Empirical results\ndemonstrate that the proposed self-training approach consistently improves\nstate-of-the-art pre-trained models (BERT, ToD-BERT) when only a small number\nof labeled data are available.", "published": "2021-08-28 07:22:06", "link": "http://arxiv.org/abs/2108.12589v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Oh My Mistake!: Toward Realistic Dialogue State Tracking including\n  Turnback Utterances", "abstract": "The primary purpose of dialogue state tracking (DST), a critical component of\nan end-to-end conversational system, is to build a model that responds well to\nreal-world situations. Although we often change our minds from time to time\nduring ordinary conversations, current benchmark datasets do not adequately\nreflect such occurrences and instead consist of over-simplified conversations,\nin which no one changes their mind during a conversation. As the main question\ninspiring the present study, \"Are current benchmark datasets sufficiently\ndiverse to handle casual conversations in which one changes their mind after a\ncertain topic is over?\" We found that the answer is \"No\" because DST models\ncannot refer to previous user preferences when template-based turnback\nutterances are injected into the dataset. Even in the the simplest\nmind-changing (turnback) scenario, the performance of DST models significantly\ndegenerated. However, we found that this performance degeneration can be\nrecovered when the turnback scenarios are explicitly designed in the training\nset, implying that the problem is not with the DST models but rather with the\nconstruction of the benchmark dataset.", "published": "2021-08-28 12:10:50", "link": "http://arxiv.org/abs/2108.12637v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transfer Learning for Multi-lingual Tasks -- a Survey", "abstract": "These days different platforms such as social media provide their clients\nfrom different backgrounds and languages the possibility to connect and\nexchange information. It is not surprising anymore to see comments from\ndifferent languages in posts published by international celebrities or data\nproviders. In this era, understanding cross languages content and\nmultilingualism in natural language processing (NLP) are hot topics, and\nmultiple efforts have tried to leverage existing technologies in NLP to tackle\nthis challenging research problem. In this survey, we provide a comprehensive\noverview of the existing literature with a focus on transfer learning\ntechniques in multilingual tasks. We also identify potential opportunities for\nfurther research in this domain.", "published": "2021-08-28 20:29:43", "link": "http://arxiv.org/abs/2110.02052v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QACE: Asking Questions to Evaluate an Image Caption", "abstract": "In this paper, we propose QACE, a new metric based on Question Answering for\nCaption Evaluation. QACE generates questions on the evaluated caption and\nchecks its content by asking the questions on either the reference caption or\nthe source image. We first develop QACE-Ref that compares the answers of the\nevaluated caption to its reference, and report competitive results with the\nstate-of-the-art metrics. To go further, we propose QACE-Img, which asks the\nquestions directly on the image, instead of reference. A Visual-QA system is\nnecessary for QACE-Img. Unfortunately, the standard VQA models are framed as a\nclassification among only a few thousand categories. Instead, we propose\nVisual-T5, an abstractive VQA system. The resulting metric, QACE-Img is\nmulti-modal, reference-less, and explainable. Our experiments show that\nQACE-Img compares favorably w.r.t. other reference-less metrics. We will\nrelease the pre-trained models to compute QACE.", "published": "2021-08-28 03:04:28", "link": "http://arxiv.org/abs/2108.12560v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Goal-driven text descriptions for images", "abstract": "A big part of achieving Artificial General Intelligence(AGI) is to build a\nmachine that can see and listen like humans. Much work has focused on designing\nmodels for image classification, video classification, object detection, pose\nestimation, speech recognition, etc., and has achieved significant progress in\nrecent years thanks to deep learning. However, understanding the world is not\nenough. An AI agent also needs to know how to talk, especially how to\ncommunicate with a human. While perception (vision, for example) is more common\nacross animal species, the use of complicated language is unique to humans and\nis one of the most important aspects of intelligence.\n  In this thesis, we focus on generating textual output given visual input. In\nChapter 3, we focus on generating the referring expression, a text description\nfor an object in the image so that a receiver can infer which object is being\ndescribed. We use a comprehension machine to directly guide the generated\nreferring expressions to be more discriminative. In Chapter 4, we introduce a\nmethod that encourages discriminability in image caption generation. We show\nthat more discriminative captioning models generate more descriptive captions.\nIn Chapter 5, we study how training objectives and sampling methods affect the\nmodels' ability to generate diverse captions. We find that a popular captioning\ntraining strategy will be detrimental to the diversity of generated captions.\nIn Chapter 6, we propose a model that can control the length of generated\ncaptions. By changing the desired length, one can influence the style and\ndescriptiveness of the captions. Finally, in Chapter 7, we rank/generate\ninformative image tags according to their information utility. The proposed\nmethod better matches what humans think are the most important tags for the\nimages.", "published": "2021-08-28 05:10:38", "link": "http://arxiv.org/abs/2108.12575v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Distilling the Knowledge of Large-scale Generative Models into Retrieval\n  Models for Efficient Open-domain Conversation", "abstract": "Despite the remarkable performance of large-scale generative models in\nopen-domain conversation, they are known to be less practical for building\nreal-time conversation systems due to high latency. On the other hand,\nretrieval models could return responses with much lower latency but show\ninferior performance to the large-scale generative models since the\nconversation quality is bounded by the pre-defined response set. To take\nadvantage of both approaches, we propose a new training method called G2R\n(Generative-to-Retrieval distillation) that preserves the efficiency of a\nretrieval model while leveraging the conversational ability of a large-scale\ngenerative model by infusing the knowledge of the generative model into the\nretrieval model. G2R consists of two distinct techniques of distillation: the\ndata-level G2R augments the dialogue dataset with additional responses\ngenerated by the large-scale generative model, and the model-level G2R\ntransfers the response quality score assessed by the generative model to the\nscore of the retrieval model by the knowledge distillation loss. Through\nextensive experiments including human evaluation, we demonstrate that our\nretrieval-based conversation system trained with G2R shows a substantially\nimproved performance compared to the baseline retrieval model while showing\nsignificantly lower inference latency than the large-scale generative models.", "published": "2021-08-28 05:39:07", "link": "http://arxiv.org/abs/2108.12582v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigation of Diachronic Bias in Fake News Detection Dataset", "abstract": "Fake news causes significant damage to society.To deal with these fake news,\nseveral studies on building detection models and arranging datasets have been\nconducted. Most of the fake news datasets depend on a specific time period.\nConsequently, the detection models trained on such a dataset have difficulty\ndetecting novel fake news generated by political changes and social changes;\nthey may possibly result in biased output from the input, including specific\nperson names and organizational names. We refer to this problem as\n\\textbf{Diachronic Bias} because it is caused by the creation date of news in\neach dataset. In this study, we confirm the bias, especially proper nouns\nincluding person names, from the deviation of phrase appearances in each\ndataset. Based on these findings, we propose masking methods using Wikidata to\nmitigate the influence of person names and validate whether they make fake news\ndetection models robust through experiments with in-domain and out-of-domain\ndata.", "published": "2021-08-28 08:25:29", "link": "http://arxiv.org/abs/2108.12601v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WALNUT: A Benchmark on Semi-weakly Supervised Learning for Natural\n  Language Understanding", "abstract": "Building machine learning models for natural language understanding (NLU)\ntasks relies heavily on labeled data. Weak supervision has been proven valuable\nwhen large amount of labeled data is unavailable or expensive to obtain.\nExisting works studying weak supervision for NLU either mostly focus on a\nspecific task or simulate weak supervision signals from ground-truth labels. It\nis thus hard to compare different approaches and evaluate the benefit of weak\nsupervision without access to a unified and systematic benchmark with diverse\ntasks and real-world weak labeling rules. In this paper, we propose such a\nbenchmark, named WALNUT (semi-WeAkly supervised Learning for Natural language\nUnderstanding Testbed), to advocate and facilitate research on weak supervision\nfor NLU. WALNUT consists of NLU tasks with different types, including\ndocument-level and token-level prediction tasks. WALNUT is the first\nsemi-weakly supervised learning benchmark for NLU, where each task contains\nweak labels generated by multiple real-world weak sources, together with a\nsmall set of clean labels. We conduct baseline evaluations on WALNUT to\nsystematically evaluate the effectiveness of various weak supervision methods\nand model architectures. Our results demonstrate the benefit of weak\nsupervision for low-resource NLU tasks and highlight interesting patterns\nacross tasks. We expect WALNUT to stimulate further research on methodologies\nto leverage weak supervision more effectively. The benchmark and code for\nbaselines are available at \\url{aka.ms/walnut_benchmark}.", "published": "2021-08-28 08:33:23", "link": "http://arxiv.org/abs/2108.12603v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HeadlineCause: A Dataset of News Headlines for Detecting Causalities", "abstract": "Detecting implicit causal relations in texts is a task that requires both\ncommon sense and world knowledge. Existing datasets are focused either on\ncommonsense causal reasoning or explicit causal relations. In this work, we\npresent HeadlineCause, a dataset for detecting implicit causal relations\nbetween pairs of news headlines. The dataset includes over 5000 headline pairs\nfrom English news and over 9000 headline pairs from Russian news labeled\nthrough crowdsourcing. The pairs vary from totally unrelated or belonging to\nthe same general topic to the ones including causation and refutation\nrelations. We also present a set of models and experiments that demonstrates\nthe dataset validity, including a multilingual XLM-RoBERTa based model for\ncausality detection and a GPT-2 based model for possible effects prediction.", "published": "2021-08-28 11:12:49", "link": "http://arxiv.org/abs/2108.12626v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Layer-wise Model Pruning based on Mutual Information", "abstract": "The proposed pruning strategy offers merits over weight-based pruning\ntechniques: (1) it avoids irregular memory access since representations and\nmatrices can be squeezed into their smaller but dense counterparts, leading to\ngreater speedup; (2) in a manner of top-down pruning, the proposed method\noperates from a more global perspective based on training signals in the top\nlayer, and prunes each layer by propagating the effect of global signals\nthrough layers, leading to better performances at the same sparsity level.\nExtensive experiments show that at the same sparsity level, the proposed\nstrategy offers both greater speedup and higher performances than weight-based\npruning methods (e.g., magnitude pruning, movement pruning).", "published": "2021-08-28 07:51:47", "link": "http://arxiv.org/abs/2108.12594v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Smoothing Dialogue States for Open Conversational Machine Reading", "abstract": "Conversational machine reading (CMR) requires machines to communicate with\nhumans through multi-turn interactions between two salient dialogue states of\ndecision making and question generation processes. In open CMR settings, as the\nmore realistic scenario, the retrieved background knowledge would be noisy,\nwhich results in severe challenges in the information transmission. Existing\nstudies commonly train independent or pipeline systems for the two subtasks.\nHowever, those methods are trivial by using hard-label decisions to activate\nquestion generation, which eventually hinders the model performance. In this\nwork, we propose an effective gating strategy by smoothing the two dialogue\nstates in only one decoder and bridge decision making and question generation\nto provide a richer dialogue state reference. Experiments on the OR-ShARC\ndataset show the effectiveness of our method, which achieves new\nstate-of-the-art results.", "published": "2021-08-28 08:04:28", "link": "http://arxiv.org/abs/2108.12599v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
