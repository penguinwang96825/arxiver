{"title": "ZZU-NLP at SIGHAN-2024 dimABSA Task: Aspect-Based Sentiment Analysis\n  with Coarse-to-Fine In-context Learning", "abstract": "The DimABSA task requires fine-grained sentiment intensity prediction for\nrestaurant reviews, including scores for Valence and Arousal dimensions for\neach Aspect Term. In this study, we propose a Coarse-to-Fine In-context\nLearning(CFICL) method based on the Baichuan2-7B model for the DimABSA task in\nthe SIGHAN 2024 workshop. Our method improves prediction accuracy through a\ntwo-stage optimization process. In the first stage, we use fixed in-context\nexamples and prompt templates to enhance the model's sentiment recognition\ncapability and provide initial predictions for the test data. In the second\nstage, we encode the Opinion field using BERT and select the most similar\ntraining data as new in-context examples based on similarity. These examples\ninclude the Opinion field and its scores, as well as related opinion words and\ntheir average scores. By filtering for sentiment polarity, we ensure that the\nexamples are consistent with the test data. Our method significantly improves\nprediction accuracy and consistency by effectively utilizing training data and\noptimizing in-context examples, as validated by experimental results.", "published": "2024-07-22 02:54:46", "link": "http://arxiv.org/abs/2407.15341v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Minimum Bayes Risk Decoding with Multi-Prompt", "abstract": "While instruction fine-tuned LLMs are effective text generators, sensitivity\nto prompt construction makes performance unstable and sub-optimal in practice.\nRelying on a single \"best\" prompt cannot capture all differing approaches to a\ngeneration problem. Using this observation, we propose multi-prompt decoding,\nwhere many candidate generations are decoded from a prompt bank at\ninference-time. To ensemble candidates, we use Minimum Bayes Risk (MBR)\ndecoding, which selects a final output using a trained value metric. We show\nmulti-prompt improves MBR across a comprehensive set of conditional generation\ntasks, and show this is a result of estimating a more diverse and higher\nquality candidate space than that of a single prompt. Further experiments\nconfirm multi-prompt improves generation across tasks, models and metrics.", "published": "2024-07-22 02:57:10", "link": "http://arxiv.org/abs/2407.15343v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAVEN-Fact: A Large-scale Event Factuality Detection Dataset", "abstract": "Event Factuality Detection (EFD) task determines the factuality of textual\nevents, i.e., classifying whether an event is a fact, possibility, or\nimpossibility, which is essential for faithfully understanding and utilizing\nevent knowledge. However, due to the lack of high-quality large-scale data,\nevent factuality detection is under-explored in event understanding research,\nwhich limits the development of EFD community. To address these issues and\nprovide faithful event understanding, we introduce MAVEN-Fact, a large-scale\nand high-quality EFD dataset based on the MAVEN dataset. MAVEN-Fact includes\nfactuality annotations of 112,276 events, making it the largest EFD dataset.\nExtensive experiments demonstrate that MAVEN-Fact is challenging for both\nconventional fine-tuned models and large language models (LLMs). Thanks to the\ncomprehensive annotations of event arguments and relations in MAVEN, MAVEN-Fact\nalso supports some further analyses and we find that adopting event arguments\nand relations helps in event factuality detection for fine-tuned models but\ndoes not benefit LLMs. Furthermore, we preliminarily study an application case\nof event factuality detection and find it helps in mitigating event-related\nhallucination in LLMs. Our dataset and codes can be obtained from\n\\url{https://github.com/lcy2723/MAVEN-FACT}", "published": "2024-07-22 03:43:46", "link": "http://arxiv.org/abs/2407.15352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UF-HOBI at \"Discharge Me!\": A Hybrid Solution for Discharge Summary\n  Generation Through Prompt-based Tuning of GatorTronGPT Models", "abstract": "Automatic generation of discharge summaries presents significant challenges\ndue to the length of clinical documentation, the dispersed nature of patient\ninformation, and the diverse terminology used in healthcare. This paper\npresents a hybrid solution for generating discharge summary sections as part of\nour participation in the \"Discharge Me!\" Challenge at the BioNLP 2024 Shared\nTask. We developed a two-stage generation method using both extractive and\nabstractive techniques, in which we first apply name entity recognition (NER)\nto extract key clinical concepts, which are then used as input for a\nprompt-tuning-based GatorTronGPT model to generate coherent text for two\nimportant sections including \"Brief Hospital Course\" and \"Discharge\nInstructions\". Our system was ranked 5th in this challenge, achieving an\noverall score of 0.284. The results demonstrate the effectiveness of our hybrid\nsolution in improving the quality of automated discharge section generation.", "published": "2024-07-22 04:02:45", "link": "http://arxiv.org/abs/2407.15359v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dissecting Multiplication in Transformers: Insights into LLMs", "abstract": "Transformer-based large language models have achieved remarkable performance\nacross various natural language processing tasks. However, they often struggle\nwith seemingly easy tasks like arithmetic despite their vast capabilities. This\nstark disparity raise human's concerns about their safe and ethical use, hinder\ntheir widespread adoption.In this paper, we focus on a typical arithmetic task,\ninteger multiplication, to explore and explain the imperfection of transformers\nin this domain. We provide comprehensive analysis of a vanilla transformer\ntrained to perform n-digit integer multiplication. Our observations indicate\nthat the model decomposes multiplication task into multiple parallel subtasks,\nsequentially optimizing each subtask for each digit to complete the final\nmultiplication. Based on observation and analysis, we infer the reasons of\ntransformers deficiencies in multiplication tasks lies in their difficulty in\ncalculating successive carryovers and caching intermediate results, and\nconfirmed this inference through experiments. Guided by these findings, we\npropose improvements to enhance transformers performance on multiplication\ntasks. These enhancements are validated through rigorous testing and\nmathematical modeling, not only enhance transformer's interpretability, but\nalso improve its performance, e.g., we achieve over 99.9% accuracy on 5-digit\ninteger multiplication with a tiny transformer, outperform LLMs GPT-4. Our\nmethod contributes to the broader fields of model understanding and\ninterpretability, paving the way for analyzing more complex tasks and\nTransformer models. This work underscores the importance of explainable AI,\nhelping to build trust in large language models and promoting their adoption in\ncritical applications.", "published": "2024-07-22 04:07:26", "link": "http://arxiv.org/abs/2407.15360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Development of a Comprehensive Spanish Dictionary for Phonetic and\n  Lexical Tagging in Socio-phonetic Research (ESPADA)", "abstract": "Pronunciation dictionaries are an important component in the process of\nspeech forced alignment. The accuracy of these dictionaries has a strong effect\non the aligned speech data since they help the mapping between orthographic\ntranscriptions and acoustic signals. In this paper, I present the creation of a\ncomprehensive pronunciation dictionary in Spanish (ESPADA) that can be used in\nmost of the dialect variants of Spanish data. Current dictionaries focus on\nspecific regional variants, but with the flexible nature of our tool, it can be\nreadily applied to capture the most common phonetic differences across major\ndialectal variants. We propose improvements to current pronunciation\ndictionaries as well as mapping other relevant annotations such as\nmorphological and lexical information. In terms of size, it is currently the\nmost complete dictionary with more than 628,000 entries, representing words\nfrom 16 countries. All entries come with their corresponding pronunciations,\nmorphological and lexical tagging, and other relevant information for phonetic\nanalysis: stress patterns, phonotactics, IPA transcriptions, and more. This\naims to equip socio-phonetic researchers with a complete open-source tool that\nenhances dialectal research within socio-phonetic frameworks in the Spanish\nlanguage.", "published": "2024-07-22 04:51:33", "link": "http://arxiv.org/abs/2407.15375v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLaST: Improved End-to-end Speech Translation System Leveraged by Large\n  Language Models", "abstract": "We introduces LLaST, a framework for building high-performance Large Language\nmodel based Speech-to-text Translation systems. We address the limitations of\nend-to-end speech translation(E2E ST) models by exploring model architecture\ndesign and optimization techniques tailored for LLMs. Our approach includes\nLLM-based speech translation architecture design, ASR-augmented training,\nmultilingual data augmentation, and dual-LoRA optimization. Our approach\ndemonstrates superior performance on the CoVoST-2 benchmark and showcases\nexceptional scaling capabilities powered by LLMs. We believe this effective\nmethod will serve as a strong baseline for speech translation and provide\ninsights for future improvements of the LLM-based speech translation framework.\nWe release the data, code and models in https://github.com/openaudiolab/LLaST.", "published": "2024-07-22 06:42:00", "link": "http://arxiv.org/abs/2407.15415v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Developing a Reliable, Fast, General-Purpose Hallucination Detection and\n  Mitigation Service", "abstract": "Hallucination, a phenomenon where large language models (LLMs) produce output\nthat is factually incorrect or unrelated to the input, is a major challenge for\nLLM applications that require accuracy and dependability. In this paper, we\nintroduce a reliable and high-speed production system aimed at detecting and\nrectifying the hallucination issue within LLMs. Our system encompasses named\nentity recognition (NER), natural language inference (NLI), span-based\ndetection (SBD), and an intricate decision tree-based process to reliably\ndetect a wide range of hallucinations in LLM responses. Furthermore, we have\ncrafted a rewriting mechanism that maintains an optimal mix of precision,\nresponse time, and cost-effectiveness. We detail the core elements of our\nframework and underscore the paramount challenges tied to response time,\navailability, and performance metrics, which are crucial for real-world\ndeployment of these technologies. Our extensive evaluation, utilizing offline\ndata and live production traffic, confirms the efficacy of our proposed\nframework and service.", "published": "2024-07-22 07:48:30", "link": "http://arxiv.org/abs/2407.15441v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparison of Language Modeling and Translation as Multilingual\n  Pretraining Objectives", "abstract": "Pretrained language models (PLMs) display impressive performances and have\ncaptured the attention of the NLP community. Establishing best practices in\npretraining has, therefore, become a major focus of NLP research, especially\nsince insights gained from monolingual English models may not necessarily apply\nto more complex multilingual models. One significant caveat of the current\nstate of the art is that different works are rarely comparable: they often\ndiscuss different parameter counts, training data, and evaluation methodology.\n  This paper proposes a comparison of multilingual pretraining objectives in a\ncontrolled methodological environment. We ensure that training data and model\narchitectures are comparable, and discuss the downstream performances across 6\nlanguages that we observe in probing and fine-tuning scenarios. We make two key\nobservations: (1) the architecture dictates which pretraining objective is\noptimal; (2) multilingual translation is a very effective pretraining objective\nunder the right conditions. We make our code, data, and model weights available\nat \\texttt{\\url{https://github.com/Helsinki-NLP/lm-vs-mt}}.", "published": "2024-07-22 09:16:30", "link": "http://arxiv.org/abs/2407.15489v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Refining Corpora from a Model Calibration Perspective for Chinese\n  Spelling Correction", "abstract": "Chinese Spelling Correction (CSC) commonly lacks large-scale high-quality\ncorpora, due to the labor-intensive labeling of spelling errors in real-life\nhuman writing or typing scenarios. Two data augmentation methods are widely\nadopted: (1) \\textit{Random Replacement} with the guidance of confusion sets\nand (2) \\textit{OCR/ASR-based Generation} that simulates character misusing.\nHowever, both methods inevitably introduce noisy data (e.g., false spelling\nerrors), potentially leading to over-correction. By carefully analyzing the two\ntypes of corpora, we find that though the latter achieves more robust\ngeneralization performance, the former yields better-calibrated CSC models. We\nthen provide a theoretical analysis of this empirical observation, based on\nwhich a corpus refining strategy is proposed. Specifically, OCR/ASR-based data\nsamples are fed into a well-calibrated CSC model trained on random\nreplacement-based corpora and then filtered based on prediction confidence. By\nlearning a simple BERT-based model on the refined OCR/ASR-based corpus, we set\nup impressive state-of-the-art performance on three widely-used benchmarks,\nwhile significantly alleviating over-correction (e.g., lowering false positive\npredictions).", "published": "2024-07-22 09:26:35", "link": "http://arxiv.org/abs/2407.15498v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SETTP: Style Extraction and Tunable Inference via Dual-level\n  Transferable Prompt Learning", "abstract": "Text style transfer, an important research direction in natural language\nprocessing, aims to adapt the text to various preferences but often faces\nchallenges with limited resources. In this work, we introduce a novel method\ntermed Style Extraction and Tunable Inference via Dual-level Transferable\nPrompt Learning (SETTP) for effective style transfer in low-resource scenarios.\nFirst, SETTP learns source style-level prompts containing fundamental style\ncharacteristics from high-resource style transfer. During training, the source\nstyle-level prompts are transferred through an attention module to derive a\ntarget style-level prompt for beneficial knowledge provision in low-resource\nstyle transfer. Additionally, we propose instance-level prompts obtained by\nclustering the target resources based on the semantic content to reduce\nsemantic bias. We also propose an automated evaluation approach of style\nsimilarity based on alignment with human evaluations using ChatGPT-4. Our\nexperiments across three resourceful styles show that SETTP requires only\n1/20th of the data volume to achieve performance comparable to state-of-the-art\nmethods. In tasks involving scarce data like writing style and role style,\nSETTP outperforms previous methods by 16.24\\%.", "published": "2024-07-22 11:34:48", "link": "http://arxiv.org/abs/2407.15556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Retrieval Augmented Generation with\n  Chain-of-Thought", "abstract": "Since the launch of ChatGPT at the end of 2022, generative dialogue models\nrepresented by ChatGPT have quickly become essential tools in daily life. As\nuser expectations increase, enhancing the capability of generative dialogue\nmodels to solve complex problems has become a focal point of current research.\nThis paper delves into the effectiveness of the RAFT (Retrieval Augmented\nFine-Tuning) method in improving the performance of Generative dialogue models.\nRAFT combines chain-of-thought with model supervised fine-tuning (SFT) and\nretrieval augmented generation (RAG), which significantly enhanced the model's\ninformation extraction and logical reasoning abilities. We evaluated the RAFT\nmethod across multiple datasets and analysed its performance in various\nreasoning tasks, including long-form QA and short-form QA tasks, tasks in both\nChinese and English, and supportive and comparison reasoning tasks. Notably, it\naddresses the gaps in previous research regarding long-form QA tasks and\nChinese datasets. Moreover, we also evaluate the benefit of the\nchain-of-thought (CoT) in the RAFT method. This work offers valuable insights\nfor studies focused on enhancing the performance of generative dialogue models.", "published": "2024-07-22 11:55:14", "link": "http://arxiv.org/abs/2407.15569v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StylusAI: Stylistic Adaptation for Robust German Handwritten Text\n  Generation", "abstract": "In this study, we introduce StylusAI, a novel architecture leveraging\ndiffusion models in the domain of handwriting style generation. StylusAI is\nspecifically designed to adapt and integrate the stylistic nuances of one\nlanguage's handwriting into another, particularly focusing on blending English\nhandwriting styles into the context of the German writing system. This approach\nenables the generation of German text in English handwriting styles and German\nhandwriting styles into English, enriching machine-generated handwriting\ndiversity while ensuring that the generated text remains legible across both\nlanguages. To support the development and evaluation of StylusAI, we present\nthe \\lq{Deutscher Handschriften-Datensatz}\\rq~(DHSD), a comprehensive dataset\nencompassing 37 distinct handwriting styles within the German language. This\ndataset provides a fundamental resource for training and benchmarking in the\nrealm of handwritten text generation. Our results demonstrate that StylusAI not\nonly introduces a new method for style adaptation in handwritten text\ngeneration but also surpasses existing models in generating handwriting samples\nthat improve both text quality and stylistic fidelity, evidenced by its\nperformance on the IAM database and our newly proposed DHSD. Thus, StylusAI\nrepresents a significant advancement in the field of handwriting style\ngeneration, offering promising avenues for future research and applications in\ncross-linguistic style adaptation for languages with similar scripts.", "published": "2024-07-22 13:08:30", "link": "http://arxiv.org/abs/2407.15608v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counter Turing Test ($CT^2$): Investigating AI-Generated Text Detection\n  for Hindi -- Ranking LLMs based on Hindi AI Detectability Index ($ADI_{hi}$)", "abstract": "The widespread adoption of Large Language Models (LLMs) and awareness around\nmultilingual LLMs have raised concerns regarding the potential risks and\nrepercussions linked to the misapplication of AI-generated text, necessitating\nincreased vigilance. While these models are primarily trained for English,\ntheir extensive training on vast datasets covering almost the entire web,\nequips them with capabilities to perform well in numerous other languages.\nAI-Generated Text Detection (AGTD) has emerged as a topic that has already\nreceived immediate attention in research, with some initial methods having been\nproposed, soon followed by the emergence of techniques to bypass detection. In\nthis paper, we report our investigation on AGTD for an indic language Hindi.\nOur major contributions are in four folds: i) examined 26 LLMs to evaluate\ntheir proficiency in generating Hindi text, ii) introducing the AI-generated\nnews article in Hindi ($AG_{hi}$) dataset, iii) evaluated the effectiveness of\nfive recently proposed AGTD techniques: ConDA, J-Guard, RADAR, RAIDAR and\nIntrinsic Dimension Estimation for detecting AI-generated Hindi text, iv)\nproposed Hindi AI Detectability Index ($ADI_{hi}$) which shows a spectrum to\nunderstand the evolving landscape of eloquence of AI-generated text in Hindi.\nThe code and dataset is available at\nhttps://github.com/ishank31/Counter_Turing_Test", "published": "2024-07-22 15:00:23", "link": "http://arxiv.org/abs/2407.15694v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?", "abstract": "Language agents, built on top of language models (LMs), are systems that can\ninteract with complex environments, such as the open web. In this work, we\nexamine whether such agents can perform realistic and time-consuming tasks on\nthe web, e.g., monitoring real-estate markets or locating relevant nearby\nbusinesses. We introduce AssistantBench, a challenging new benchmark consisting\nof 214 realistic tasks that can be automatically evaluated, covering different\nscenarios and domains. We find that AssistantBench exposes the limitations of\ncurrent systems, including language models and retrieval-augmented language\nmodels, as no model reaches an accuracy of more than 26 points. While\nclosed-book LMs perform well in terms of accuracy, they exhibit low precision\nand tend to hallucinate facts. State-of-the-art web agents reach a score of\nnear zero. Additionally, we introduce SeePlanAct (SPA), a new web agent that\nsignificantly outperforms previous agents, and an ensemble of SPA and\nclosed-book models reaches the best overall performance. Moreover, we analyze\nfailures of current systems and highlight that open web navigation remains a\nmajor challenge.", "published": "2024-07-22 15:18:45", "link": "http://arxiv.org/abs/2407.15711v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OMoS-QA: A Dataset for Cross-Lingual Extractive Question Answering in a\n  German Migration Context", "abstract": "When immigrating to a new country, it is easy to feel overwhelmed by the need\nto obtain information on financial support, housing, schooling, language\ncourses, and other issues. If relocation is rushed or even forced, the\nnecessity for high-quality answers to such questions is all the more urgent.\nOfficial immigration counselors are usually overbooked, and online systems\ncould guide newcomers to the requested information or a suitable counseling\nservice.\n  To this end, we present OMoS-QA, a dataset of German and English questions\npaired with relevant trustworthy documents and manually annotated answers,\nspecifically tailored to this scenario. Questions are automatically generated\nwith an open-source large language model (LLM) and answer sentences are\nselected by crowd workers with high agreement. With our data, we conduct a\ncomparison of 5 pretrained LLMs on the task of extractive question answering\n(QA) in German and English. Across all models and both languages, we find high\nprecision and low-to-mid recall in selecting answer sentences, which is a\nfavorable trade-off to avoid misleading users. This performance even holds up\nwhen the question language does not match the document language. When it comes\nto identifying unanswerable questions given a context, there are larger\ndifferences between the two languages.", "published": "2024-07-22 15:40:17", "link": "http://arxiv.org/abs/2407.15736v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Structured Insights from Financial News: An Augmented LLM\n  Driven Approach", "abstract": "Financial news plays a crucial role in decision-making processes across the\nfinancial sector, yet the efficient processing of this information into a\nstructured format remains challenging. This paper presents a novel approach to\nfinancial news processing that leverages Large Language Models (LLMs) to\novercome limitations that previously prevented the extraction of structured\ndata from unstructured financial news. We introduce a system that extracts\nrelevant company tickers from raw news article content, performs sentiment\nanalysis at the company level, and generates summaries, all without relying on\npre-structured data feeds. Our methodology combines the generative capabilities\nof LLMs, and recent prompting techniques, with a robust validation framework\nthat uses a tailored string similarity approach. Evaluation on a dataset of\n5530 financial news articles demonstrates the effectiveness of our approach,\nwith 90% of articles not missing any tickers compared with current data\nproviders, and 22% of articles having additional relevant tickers. In addition\nto this paper, the methodology has been implemented at scale with the resulting\nprocessed data made available through a live API endpoint, which is updated in\nreal-time with the latest news. To the best of our knowledge, we are the first\ndata provider to offer granular, per-company sentiment analysis from news\narticles, enhancing the depth of information available to market participants.\nWe also release the evaluation dataset of 5530 processed articles as a static\nfile, which we hope will facilitate further research leveraging financial news.", "published": "2024-07-22 16:47:31", "link": "http://arxiv.org/abs/2407.15788v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Multilingual Fine-Grained News Headline Hallucination Detection", "abstract": "The popularity of automated news headline generation has surged with\nadvancements in pre-trained language models. However, these models often suffer\nfrom the ``hallucination'' problem, where the generated headline is not fully\nsupported by its source article. Efforts to address this issue have\npredominantly focused on English, using over-simplistic classification schemes\nthat overlook nuanced hallucination types. In this study, we introduce the\nfirst multilingual, fine-grained news headline hallucination detection dataset\nthat contains over 11 thousand pairs in 5 languages, each annotated with\ndetailed hallucination types by experts. We conduct extensive experiments on\nthis dataset under two settings. First, we implement several supervised\nfine-tuning approaches as preparatory solutions and demonstrate this dataset's\nchallenges and utilities. Second, we test various large language models'\nin-context learning abilities and propose two novel techniques,\nlanguage-dependent demonstration selection and coarse-to-fine prompting, to\nboost the few-shot hallucination detection performance in terms of the\nexample-F1 metric. We release this dataset to foster further research in\nmultilingual, fine-grained headline hallucination detection.", "published": "2024-07-22 18:37:53", "link": "http://arxiv.org/abs/2407.15975v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SocialQuotes: Learning Contextual Roles of Social Media Quotes on the\n  Web", "abstract": "Web authors frequently embed social media to support and enrich their\ncontent, creating the potential to derive web-based, cross-platform social\nmedia representations that can enable more effective social media retrieval\nsystems and richer scientific analyses. As step toward such capabilities, we\nintroduce a novel language modeling framework that enables automatic annotation\nof roles that social media entities play in their embedded web context. Using\nrelated communication theory, we liken social media embeddings to quotes,\nformalize the page context as structured natural language signals, and identify\na taxonomy of roles for quotes within the page context. We release\nSocialQuotes, a new data set built from the Common Crawl of over 32 million\nsocial quotes, 8.3k of them with crowdsourced quote annotations. Using\nSocialQuotes and the accompanying annotations, we provide a role classification\ncase study, showing reasonable performance with modern-day LLMs, and exposing\nexplainable aspects of our framework via page content ablations. We also\nclassify a large batch of un-annotated quotes, revealing interesting\ncross-domain, cross-platform role distributions on the web.", "published": "2024-07-22 19:21:01", "link": "http://arxiv.org/abs/2407.16007v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Boosting Reward Model with Preference-Conditional Multi-Aspect Synthetic\n  Data Generation", "abstract": "Reward models (RMs) are crucial for aligning large language models (LLMs)\nwith human preferences. They are trained using preference datasets where each\nexample consists of one input prompt, two responses, and a preference label. As\ncurating a high-quality human labeled preference dataset is both time-consuming\nand expensive, people often rely on existing powerful LLMs for preference label\ngeneration. This can potentially introduce noise and impede RM training. In\nthis work, we present RMBoost, a novel synthetic preference data generation\nparadigm to boost reward model quality. Unlike traditional methods, which\ngenerate two responses before obtaining the preference label, RMBoost first\ngenerates one response and selects a preference label, followed by generating\nthe second more (or less) preferred response conditioned on the pre-selected\npreference label and the first response. This approach offers two main\nadvantages. First, RMBoost reduces labeling noise since preference pairs are\nconstructed intentionally. Second, RMBoost facilitates the creation of more\ndiverse responses by incorporating various quality aspects (e.g., helpfulness,\nrelevance, completeness) into the prompts. We conduct extensive experiments\nacross three diverse datasets and demonstrate that RMBoost outperforms other\nsynthetic preference data generation techniques and significantly boosts the\nperformance of four distinct reward models.", "published": "2024-07-22 19:21:55", "link": "http://arxiv.org/abs/2407.16008v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KaPQA: Knowledge-Augmented Product Question-Answering", "abstract": "Question-answering for domain-specific applications has recently attracted\nmuch interest due to the latest advancements in large language models (LLMs).\nHowever, accurately assessing the performance of these applications remains a\nchallenge, mainly due to the lack of suitable benchmarks that effectively\nsimulate real-world scenarios. To address this challenge, we introduce two\nproduct question-answering (QA) datasets focused on Adobe Acrobat and Photoshop\nproducts to help evaluate the performance of existing models on domain-specific\nproduct QA tasks. Additionally, we propose a novel knowledge-driven RAG-QA\nframework to enhance the performance of the models in the product QA task. Our\nexperiments demonstrated that inducing domain knowledge through query\nreformulation allowed for increased retrieval and generative performance when\ncompared to standard RAG-QA methods. This improvement, however, is slight, and\nthus illustrates the challenge posed by the datasets introduced.", "published": "2024-07-22 22:14:56", "link": "http://arxiv.org/abs/2407.16073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Customized Retrieval Augmented Generation and Benchmarking for EDA Tool\n  Documentation QA", "abstract": "Retrieval augmented generation (RAG) enhances the accuracy and reliability of\ngenerative AI models by sourcing factual information from external databases,\nwhich is extensively employed in document-grounded question-answering (QA)\ntasks. Off-the-shelf RAG flows are well pretrained on general-purpose\ndocuments, yet they encounter significant challenges when being applied to\nknowledge-intensive vertical domains, such as electronic design automation\n(EDA). This paper addresses such issue by proposing a customized RAG framework\nalong with three domain-specific techniques for EDA tool documentation QA,\nincluding a contrastive learning scheme for text embedding model fine-tuning, a\nreranker distilled from proprietary LLM, and a generative LLM fine-tuned with\nhigh-quality domain corpus. Furthermore, we have developed and released a\ndocumentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced\nRTL-to-GDSII design platform. Experimental results demonstrate that our\nproposed RAG flow and techniques have achieved superior performance on ORD-QA\nas well as on a commercial tool, compared with state-of-the-arts. The ORD-QA\nbenchmark and the training dataset for our customized RAG flow are open-source\nat https://github.com/lesliepy99/RAG-EDA.", "published": "2024-07-22 03:44:27", "link": "http://arxiv.org/abs/2407.15353v2", "categories": ["cs.CL", "cs.AR"], "primary_category": "cs.CL"}
{"title": "A Network Analysis Approach to Conlang Research Literature", "abstract": "The field of conlang has evidenced an important growth in the last decades.\nThis has been the product of a wide interest in the use and study of conlangs\nfor artistic purposes. However, one important question is what it is happening\nwith conlang in the academic world. This paper aims to have an overall\nunderstanding of the literature on conlang research. With this we aim to give a\nrealistic picture of the field in present days. We have implemented a\ncomputational linguistic approach, combining bibliometrics and network analysis\nto examine all publications available in the Scopus database. Analysing over\n2300 academic publications since 1927 until 2022, we have found that Esperanto\nis by far the most documented conlang. Three main authors have contributed to\nthis: Garv\\'ia R., Fiedler S., and Blanke D. The 1970s and 1980s have been the\ndecades where the foundations of current research have been built. In terms of\nmethodologies, language learning and experimental linguistics are the ones\ncontributing to most to the preferred approaches of study in the field. We\npresent the results and discuss our limitations and future work.", "published": "2024-07-22 04:40:45", "link": "http://arxiv.org/abs/2407.15370v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "ILiAD: An Interactive Corpus for Linguistic Annotated Data from Twitter\n  Posts", "abstract": "Social Media platforms have offered invaluable opportunities for linguistic\nresearch. The availability of up-to-date data, coming from any part in the\nworld, and coming from natural contexts, has allowed researchers to study\nlanguage in real time. One of the fields that has made great use of social\nmedia platforms is Corpus Linguistics. There is currently a wide range of\nprojects which have been able to successfully create corpora from social media.\nIn this paper, we present the development and deployment of a linguistic corpus\nfrom Twitter posts in English, coming from 26 news agencies and 27 individuals.\nThe main goal was to create a fully annotated English corpus for linguistic\nanalysis. We include information on morphology and syntax, as well as NLP\nfeatures such as tokenization, lemmas, and n- grams. The information is\npresented through a range of powerful visualisations for users to explore\nlinguistic patterns in the corpus. With this tool, we aim to contribute to the\narea of language technologies applied to linguistic research.", "published": "2024-07-22 04:48:04", "link": "http://arxiv.org/abs/2407.15374v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "ALLaM: Large Language Models for Arabic and English", "abstract": "We present ALLaM: Arabic Large Language Model, a series of large language\nmodels to support the ecosystem of Arabic Language Technologies (ALT). ALLaM is\ncarefully trained considering the values of language alignment and knowledge\ntransfer at scale. Our autoregressive decoder-only architecture models\ndemonstrate how second-language acquisition via vocabulary expansion and\npretraining on a mixture of Arabic and English text can steer a model towards a\nnew language (Arabic) without any catastrophic forgetting in the original\nlanguage (English). Furthermore, we highlight the effectiveness of using\nparallel/translated data to aid the process of knowledge alignment between\nlanguages. Finally, we show that extensive alignment with human preferences can\nsignificantly enhance the performance of a language model compared to models of\na larger scale with lower quality alignment. ALLaM achieves state-of-the-art\nperformance in various Arabic benchmarks, including MMLU Arabic, ACVA, and\nArabic Exams. Our aligned models improve both in Arabic and English from their\nbase aligned models.", "published": "2024-07-22 05:35:17", "link": "http://arxiv.org/abs/2407.15390v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Text-to-Battery Recipe: A language modeling-based protocol for automatic\n  battery recipe extraction and retrieval", "abstract": "Recent studies have increasingly applied natural language processing (NLP) to\nautomatically extract experimental research data from the extensive battery\nmaterials literature. Despite the complex process involved in battery\nmanufacturing -- from material synthesis to cell assembly -- there has been no\ncomprehensive study systematically organizing this information. In response, we\npropose a language modeling-based protocol, Text-to-Battery Recipe (T2BR), for\nthe automatic extraction of end-to-end battery recipes, validated using a case\nstudy on batteries containing LiFePO4 cathode material. We report machine\nlearning-based paper filtering models, screening 2,174 relevant papers from the\nkeyword-based search results, and unsupervised topic models to identify 2,876\nparagraphs related to cathode synthesis and 2,958 paragraphs related to cell\nassembly. Then, focusing on the two topics, two deep learning-based named\nentity recognition models are developed to extract a total of 30 entities --\nincluding precursors, active materials, and synthesis methods -- achieving F1\nscores of 88.18% and 94.61%. The accurate extraction of entities enables the\nsystematic generation of 165 end-toend recipes of LiFePO4 batteries. Our\nprotocol and results offer valuable insights into specific trends, such as\nassociations between precursor materials and synthesis methods, or combinations\nbetween different precursor materials. We anticipate that our findings will\nserve as a foundational knowledge base for facilitating battery-recipe\ninformation retrieval. The proposed protocol will significantly accelerate the\nreview of battery material literature and catalyze innovations in battery\ndesign and development.", "published": "2024-07-22 08:15:02", "link": "http://arxiv.org/abs/2407.15459v1", "categories": ["cs.CL", "cond-mat.mtrl-sci"], "primary_category": "cs.CL"}
{"title": "Compensate Quantization Errors+: Quantized Models Are Inquisitive\n  Learners", "abstract": "Large Language Models (LLMs) showcase remarkable performance and robust\ndeductive capabilities, yet their expansive size complicates deployment and\nraises environmental concerns due to substantial resource consumption. The\nrecent development of a quantization technique known as Learnable\nSingular-value Increment (LSI) has addressed some of these quantization\nchallenges. Leveraging insights from LSI and our extensive research, we have\ndeveloped innovative methods that enhance the performance of quantized LLMs,\nparticularly in low-bit settings. Our methods consistently deliver\nstate-of-the-art results across various quantization scenarios and offer deep\ntheoretical insights into the quantization process, elucidating the potential\nof quantized models for widespread application.", "published": "2024-07-22 09:45:16", "link": "http://arxiv.org/abs/2407.15508v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Attention Is All You Need But You Don't Need All Of It For Inference of\n  Large Language Models", "abstract": "The inference demand for LLMs has skyrocketed in recent months, and serving\nmodels with low latencies remains challenging due to the quadratic input length\ncomplexity of the attention layers. In this work, we investigate the effect of\ndropping MLP and attention layers at inference time on the performance of\nLlama-v2 models. We find that dropping dreeper attention layers only marginally\ndecreases performance but leads to the best speedups alongside dropping entire\nlayers. For example, removing 33\\% of attention layers in a 13B Llama2 model\nresults in a 1.8\\% drop in average performance over the OpenLLM benchmark. We\nalso observe that skipping layers except the latter layers reduces performances\nfor more layers skipped, except for skipping the attention layers.", "published": "2024-07-22 10:09:05", "link": "http://arxiv.org/abs/2407.15516v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Unsupervised Robust Cross-Lingual Entity Alignment via Neighbor Triple\n  Matching with Entity and Relation Texts", "abstract": "Cross-lingual entity alignment (EA) enables the integration of multiple\nknowledge graphs (KGs) across different languages, providing users with\nseamless access to diverse and comprehensive knowledge. Existing methods,\nmostly supervised, face challenges in obtaining labeled entity pairs. To\naddress this, recent studies have shifted towards self-supervised and\nunsupervised frameworks. Despite their effectiveness, these approaches have\nlimitations: (1) Relation passing: mainly focusing on the entity while\nneglecting the semantic information of relations, (2) Isomorphic assumption:\nassuming isomorphism between source and target graphs, which leads to noise and\nreduced alignment accuracy, and (3) Noise vulnerability: susceptible to noise\nin the textual features, especially when encountering inconsistent translations\nor Out-of-Vocabulary (OOV) problems. In this paper, we propose ERAlign, an\nunsupervised and robust cross-lingual EA pipeline that jointly performs\nEntity-level and Relation-level Alignment by neighbor triple matching strategy\nusing semantic textual features of relations and entities. Its refinement step\niteratively enhances results by fusing entity-level and relation-level\nalignments based on neighbor triple matching. The additional verification step\nexamines the entities' neighbor triples as the linearized text. This\nAlign-then-Verify pipeline rigorously assesses alignment results, achieving\nnear-perfect alignment even in the presence of noisy textual features of\nentities. Our extensive experiments demonstrate that the robustness and general\napplicability of ERAlign improved the accuracy and effectiveness of EA tasks,\ncontributing significantly to knowledge-oriented applications.", "published": "2024-07-22 12:25:48", "link": "http://arxiv.org/abs/2407.15588v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can GPT-4 learn to analyse moves in research article abstracts?", "abstract": "One of the most powerful and enduring ideas in written discourse analysis is\nthat genres can be described in terms of the moves which structure a writer's\npurpose. Considerable research has sought to identify these distinct\ncommunicative acts, but analyses have been beset by problems of subjectivity,\nreliability and the time-consuming need for multiple coders to confirm\nanalyses. In this paper we employ the affordances of GPT-4 to automate the\nannotation process by using natural language prompts. Focusing on abstracts\nfrom articles in four applied linguistics journals, we devise prompts which\nenable the model to identify moves effectively. The annotated outputs of these\nprompts were evaluated by two assessors with a third addressing disagreements.\nThe results show that an 8-shot prompt was more effective than one using two,\nconfirming that the inclusion of examples illustrating areas of variability can\nenhance GPT-4's ability to recognize multiple moves in a single sentence and\nreduce bias related to textual position. We suggest that GPT-4 offers\nconsiderable potential in automating this annotation process, when human actors\nwith domain specific linguistic expertise inform the prompting process.", "published": "2024-07-22 13:14:27", "link": "http://arxiv.org/abs/2407.15612v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Psychometric Alignment: Capturing Human Knowledge Distributions via\n  Language Models", "abstract": "Language models (LMs) are increasingly used to simulate human-like responses\nin scenarios where accurately mimicking a population's behavior can guide\ndecision-making, such as in developing educational materials and designing\npublic policies. The objective of these simulations is for LMs to capture the\nvariations in human responses, rather than merely providing the expected\ncorrect answers. Prior work has shown that LMs often generate unrealistically\naccurate responses, but there are no established metrics to quantify how\nclosely the knowledge distribution of LMs aligns with that of humans. To\naddress this, we introduce \"psychometric alignment,\" a metric that measures the\nextent to which LMs reflect human knowledge distribution. Assessing this\nalignment involves collecting responses from both LMs and humans to the same\nset of test items and using Item Response Theory to analyze the differences in\nitem functioning between the groups. We demonstrate that our metric can capture\nimportant variations in populations that traditional metrics, like differences\nin accuracy, fail to capture. We apply this metric to assess existing LMs for\ntheir alignment with human knowledge distributions across three real-world\ndomains. We find significant misalignment between LMs and human populations,\nthough using persona-based prompts can improve alignment. Interestingly,\nsmaller LMs tend to achieve greater psychometric alignment than larger LMs.\nFurther, training LMs on human response data from the target distribution\nenhances their psychometric alignment on unseen test items, but the\neffectiveness of such training varies across domains.", "published": "2024-07-22 14:02:59", "link": "http://arxiv.org/abs/2407.15645v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Supporting the Digital Autonomy of Elders Through LLM Assistance", "abstract": "The internet offers tremendous access to services, social connections, and\nneeded products. However, to those without sufficient experience, engaging with\nbusinesses and friends across the internet can be daunting due to the ever\npresent danger of scammers and thieves, to say nothing of the myriad of\npotential computer viruses. Like a forest rich with both edible and poisonous\nplants, those familiar with the norms inhabit it safely with ease while\nnewcomers need a guide. However, reliance on a human digital guide can be\ntaxing and often impractical. We propose and pilot a simple but unexplored\nidea: could an LLM provide the necessary support to help the elderly who are\nseparated by the digital divide safely achieve digital autonomy?", "published": "2024-07-22 15:01:45", "link": "http://arxiv.org/abs/2407.15695v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "DStruct2Design: Data and Benchmarks for Data Structure Driven Generative\n  Floor Plan Design", "abstract": "Text conditioned generative models for images have yielded impressive\nresults. Text conditioned floorplan generation as a special type of raster\nimage generation task also received particular attention. However there are\nmany use cases in floorpla generation where numerical properties of the\ngenerated result are more important than the aesthetics. For instance, one\nmight want to specify sizes for certain rooms in a floorplan and compare the\ngenerated floorplan with given specifications Current approaches, datasets and\ncommonly used evaluations do not support these kinds of constraints. As such,\nan attractive strategy is to generate an intermediate data structure that\ncontains numerical properties of a floorplan which can be used to generate the\nfinal floorplan image. To explore this setting we (1) construct a new dataset\nfor this data-structure to data-structure formulation of floorplan generation\nusing two popular image based floorplan datasets RPLAN and ProcTHOR-10k, and\nprovide the tools to convert further procedurally generated ProcTHOR floorplan\ndata into our format. (2) We explore the task of floorplan generation given a\npartial or complete set of constraints and we design a series of metrics and\nbenchmarks to enable evaluating how well samples generated from models respect\nthe constraints. (3) We create multiple baselines by finetuning a large\nlanguage model (LLM), Llama3, and demonstrate the feasibility of using\nfloorplan data structure conditioned LLMs for the problem of floorplan\ngeneration respecting numerical constraints. We hope that our new datasets and\nbenchmarks will encourage further research on different ways to improve the\nperformance of LLMs and other generative modelling techniques for generating\ndesigns where quantitative constraints are only partially specified, but must\nbe respected.", "published": "2024-07-22 15:27:55", "link": "http://arxiv.org/abs/2407.15723v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FSboard: Over 3 million characters of ASL fingerspelling collected via\n  smartphones", "abstract": "Progress in machine understanding of sign languages has been slow and\nhampered by limited data. In this paper, we present FSboard, an American Sign\nLanguage fingerspelling dataset situated in a mobile text entry use case,\ncollected from 147 paid and consenting Deaf signers using Pixel 4A selfie\ncameras in a variety of environments. Fingerspelling recognition is an\nincomplete solution that is only one small part of sign language translation,\nbut it could provide some immediate benefit to Deaf/Hard of Hearing signers as\nmore broadly capable technology develops. At >3 million characters in length\nand >250 hours in duration, FSboard is the largest fingerspelling recognition\ndataset to date by a factor of >10x. As a simple baseline, we finetune 30 Hz\nMediaPipe Holistic landmark inputs into ByT5-Small and achieve 11.1% Character\nError Rate (CER) on a test set with unique phrases and signers. This quality\ndegrades gracefully when decreasing frame rate and excluding face/body\nlandmarks: plausible optimizations to help models run on device in real time.", "published": "2024-07-22 17:20:22", "link": "http://arxiv.org/abs/2407.15806v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "RazorAttention: Efficient KV Cache Compression Through Retrieval Heads", "abstract": "The memory and computational demands of Key-Value (KV) cache present\nsignificant challenges for deploying long-context language models. Previous\napproaches attempt to mitigate this issue by selectively dropping tokens, which\nirreversibly erases critical information that might be needed for future\nqueries. In this paper, we propose a novel compression technique for KV cache\nthat preserves all token information. Our investigation reveals that: i) Most\nattention heads primarily focus on the local context; ii) Only a few heads,\ndenoted as retrieval heads, can essentially pay attention to all input tokens.\nThese key observations motivate us to use separate caching strategy for\nattention heads. Therefore, we propose RazorAttention, a training-free KV cache\ncompression algorithm, which maintains a full cache for these crucial retrieval\nheads and discards the remote tokens in non-retrieval heads. Furthermore, we\nintroduce a novel mechanism involving a \"compensation token\" to further recover\nthe information in the dropped tokens. Extensive evaluations across a diverse\nset of large language models (LLMs) demonstrate that RazorAttention achieves a\nreduction in KV cache size by over 70% without noticeable impacts on\nperformance. Additionally, RazorAttention is compatible with FlashAttention,\nrendering it an efficient and plug-and-play solution that enhances LLM\ninference efficiency without overhead or retraining of the original model.", "published": "2024-07-22 01:12:23", "link": "http://arxiv.org/abs/2407.15891v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Leveraging Large Language Models to Geolocate Linguistic Variations in\n  Social Media Posts", "abstract": "Geolocalization of social media content is the task of determining the\ngeographical location of a user based on textual data, that may show linguistic\nvariations and informal language. In this project, we address the GeoLingIt\nchallenge of geolocalizing tweets written in Italian by leveraging large\nlanguage models (LLMs). GeoLingIt requires the prediction of both the region\nand the precise coordinates of the tweet. Our approach involves fine-tuning\npre-trained LLMs to simultaneously predict these geolocalization aspects. By\nintegrating innovative methodologies, we enhance the models' ability to\nunderstand the nuances of Italian social media text to improve the\nstate-of-the-art in this domain. This work is conducted as part of the Large\nLanguage Models course at the Bertinoro International Spring School 2024. We\nmake our code publicly available on GitHub\nhttps://github.com/dawoz/geolingit-biss2024.", "published": "2024-07-22 20:54:35", "link": "http://arxiv.org/abs/2407.16047v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmarks as Microscopes: A Call for Model Metrology", "abstract": "Modern language models (LMs) pose a new challenge in capability assessment.\nStatic benchmarks inevitably saturate without providing confidence in the\ndeployment tolerances of LM-based systems, but developers nonetheless claim\nthat their models have generalized traits such as reasoning or open-domain\nlanguage understanding based on these flawed metrics. The science and practice\nof LMs requires a new approach to benchmarking which measures specific\ncapabilities with dynamic assessments. To be confident in our metrics, we need\na new discipline of model metrology -- one which focuses on how to generate\nbenchmarks that predict performance under deployment. Motivated by our\nevaluation criteria, we outline how building a community of model metrology\npractitioners -- one focused on building tools and studying how to measure\nsystem capabilities -- is the best way to meet these needs to and add clarity\nto the AI discussion.", "published": "2024-07-22 17:52:12", "link": "http://arxiv.org/abs/2407.16711v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Unlocking the Potential: Benchmarking Large Language Models in Water\n  Engineering and Research", "abstract": "Recent advancements in Large Language Models (LLMs) have sparked interest in\ntheir potential applications across various fields. This paper embarked on a\npivotal inquiry: Can existing LLMs effectively serve as \"water expert models\"\nfor water engineering and research tasks? This study was the first to evaluate\nLLMs' contributions across various water engineering and research tasks by\nestablishing a domain-specific benchmark suite, namely, WaterER. Herein, we\nprepared 983 tasks related to water engineering and research, categorized into\n\"wastewater treatment\", \"environmental restoration\", \"drinking water treatment\nand distribution\", \"sanitation\", \"anaerobic digestion\" and \"contaminants\nassessment\". We evaluated the performance of seven LLMs (i.e., GPT-4, GPT-3.5,\nGemini, GLM-4, ERNIE, QWEN and Llama3) on these tasks. We highlighted the\nstrengths of GPT-4 in handling diverse and complex tasks of water engineering\nand water research, the specialized capabilities of Gemini in academic\ncontexts, Llama3's strongest capacity to answer Chinese water engineering\nquestions and the competitive performance of Chinese-oriented models like\nGLM-4, ERNIE and QWEN in some water engineering tasks. More specifically,\ncurrent LLMs excelled particularly in generating precise research gaps for\npapers on \"contaminants and related water quality monitoring and assessment\".\nAdditionally, they were more adept at creating appropriate titles for research\npapers on \"treatment processes for wastewaters\", \"environmental restoration\",\nand \"drinking water treatment\". Overall, this study pioneered evaluating LLMs\nin water engineering and research by introducing the WaterER benchmark to\nassess the trustworthiness of their predictions. This standardized evaluation\nframework would also drive future advancements in LLM technology by using\ntargeting datasets, propelling these models towards becoming true \"water\nexpert\".", "published": "2024-07-22 12:32:22", "link": "http://arxiv.org/abs/2407.21045v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Promises and Pitfalls of Generative Masked Language Modeling:\n  Theoretical Framework and Practical Guidelines", "abstract": "Autoregressive language models are the currently dominant paradigm for text\ngeneration, but they have some fundamental limitations that cannot be remedied\nby scale-for example inherently sequential and unidirectional generation. While\nalternate classes of models have been explored, we have limited mathematical\nunderstanding of their fundamental power and limitations. In this paper we\nfocus on Generative Masked Language Models (GMLMs), a non-autoregressive\nparadigm in which we train a model to fit conditional probabilities of the data\ndistribution via masking, which are subsequently used as inputs to a Markov\nChain to draw samples from the model, These models empirically strike a\npromising speed-quality trade-off as each step can be typically parallelized by\ndecoding the entire sequence in parallel. We develop a mathematical framework\nfor analyzing and improving such models which sheds light on questions of\nsample complexity and inference speed and quality. Empirically, we adapt the T5\nmodel for iteratively-refined parallel decoding, achieving 2-3x speedup in\nmachine translation with minimal sacrifice in quality compared with\nautoregressive models. We run careful ablation experiments to give\nrecommendations on key design choices, and make fine-grained observations on\nthe common error modes in connection with our theory. Our mathematical analyses\nand empirical observations characterize both potentials and limitations of this\napproach, and can be applied to future works on improving understanding and\nperformance of GMLMs. Our codes are released at\nhttps://github.com/google-research/google-research/tree/master/padir", "published": "2024-07-22 18:00:00", "link": "http://arxiv.org/abs/2407.21046v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Learning for Economists", "abstract": "Deep learning provides powerful methods to impute structured information from\nlarge-scale, unstructured text and image datasets. For example, economists\nmight wish to detect the presence of economic activity in satellite images, or\nto measure the topics or entities mentioned in social media, the congressional\nrecord, or firm filings. This review introduces deep neural networks, covering\nmethods such as classifiers, regression models, generative AI, and embedding\nmodels. Applications include classification, document digitization, record\nlinkage, and methods for data exploration in massive scale text and image\ncorpora. When suitable methods are used, deep learning models can be cheap to\ntune and can scale affordably to problems involving millions or billions of\ndata points.. The review is accompanied by a companion website, EconDL, with\nuser-friendly demo notebooks, software resources, and a knowledge base that\nprovides technical details and additional applications.", "published": "2024-07-22 02:53:18", "link": "http://arxiv.org/abs/2407.15339v3", "categories": ["econ.GN", "cs.CL", "cs.CV", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Knowledge Acquisition Disentanglement for Knowledge-based Visual\n  Question Answering with Large Language Models", "abstract": "Knowledge-based Visual Question Answering (KVQA) requires both image and\nworld knowledge to answer questions. Current methods first retrieve knowledge\nfrom the image and external knowledge base with the original complex question,\nthen generate answers with Large Language Models (LLMs). However, since the\noriginal question contains complex elements that require knowledge from\ndifferent sources, acquiring different kinds of knowledge in a coupled manner\nmay confuse models and hinder them from retrieving precise knowledge.\nFurthermore, the ``forward-only'' answering process fails to explicitly capture\nthe knowledge needs of LLMs, which can further hurt answering quality. To cope\nwith the above limitations, we propose DKA: Disentangled Knowledge Acquisition\nfrom LLM feedback, a training-free framework that disentangles knowledge\nacquisition to avoid confusion and uses LLM's feedback to specify the required\nknowledge. Specifically, DKA requires LLMs to specify what knowledge they need\nto answer the question and decompose the original complex question into two\nsimple sub-questions: Image-based sub-question and Knowledge-based\nsub-question. Then we use the two sub-questions to retrieve knowledge from the\nimage and knowledge base, respectively. In this way, two knowledge acquisition\nmodels can focus on the content that corresponds to them and avoid disturbance\nof irrelevant elements in the original complex question, which can help to\nprovide more precise knowledge and better align the knowledge needs of LLMs to\nyield correct answers. Experiments on benchmark datasets show that DKA\nsignificantly outperforms SOTA models. To facilitate future research, our data\nand code are available at \\url{https://github.com/Lackel/DKA}.", "published": "2024-07-22 03:05:32", "link": "http://arxiv.org/abs/2407.15346v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "LLMExplainer: Large Language Model based Bayesian Inference for Graph\n  Explanation Generation", "abstract": "Recent studies seek to provide Graph Neural Network (GNN) interpretability\nvia multiple unsupervised learning models. Due to the scarcity of datasets,\ncurrent methods easily suffer from learning bias. To solve this problem, we\nembed a Large Language Model (LLM) as knowledge into the GNN explanation\nnetwork to avoid the learning bias problem. We inject LLM as a Bayesian\nInference (BI) module to mitigate learning bias. The efficacy of the BI module\nhas been proven both theoretically and experimentally. We conduct experiments\non both synthetic and real-world datasets. The innovation of our work lies in\ntwo parts: 1. We provide a novel view of the possibility of an LLM functioning\nas a Bayesian inference to improve the performance of existing algorithms; 2.\nWe are the first to discuss the learning bias issues in the GNN explanation\nproblem.", "published": "2024-07-22 03:36:38", "link": "http://arxiv.org/abs/2407.15351v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Walking in Others' Shoes: How Perspective-Taking Guides Large Language\n  Models in Reducing Toxicity and Bias", "abstract": "The common toxicity and societal bias in contents generated by large language\nmodels (LLMs) necessitate strategies to reduce harm. Present solutions often\ndemand white-box access to the model or substantial training, which is\nimpractical for cutting-edge commercial LLMs. Moreover, prevailing prompting\nmethods depend on external tool feedback and fail to simultaneously lessen\ntoxicity and bias. Motivated by social psychology principles, we propose a\nnovel strategy named \\textbf{perspective-taking prompting (\\textsc{PeT})} that\ninspires LLMs to integrate diverse human perspectives and self-regulate their\nresponses. This self-correction mechanism can significantly diminish toxicity\n(up to $89\\%$) and bias (up to $73\\%$) in LLMs' responses. Rigorous evaluations\nand ablation studies are conducted on two commercial LLMs (ChatGPT and GLM) and\nthree open-source LLMs, revealing \\textsc{PeT}'s superiority in producing less\nharmful responses, outperforming five strong baselines.", "published": "2024-07-22 04:25:01", "link": "http://arxiv.org/abs/2407.15366v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Imposter.AI: Adversarial Attacks with Hidden Intentions towards Aligned\n  Large Language Models", "abstract": "With the development of large language models (LLMs) like ChatGPT, both their\nvast applications and potential vulnerabilities have come to the forefront.\nWhile developers have integrated multiple safety mechanisms to mitigate their\nmisuse, a risk remains, particularly when models encounter adversarial inputs.\nThis study unveils an attack mechanism that capitalizes on human conversation\nstrategies to extract harmful information from LLMs. We delineate three pivotal\nstrategies: (i) decomposing malicious questions into seemingly innocent\nsub-questions; (ii) rewriting overtly malicious questions into more covert,\nbenign-sounding ones; (iii) enhancing the harmfulness of responses by prompting\nmodels for illustrative examples. Unlike conventional methods that target\nexplicit malicious responses, our approach delves deeper into the nature of the\ninformation provided in responses. Through our experiments conducted on\nGPT-3.5-turbo, GPT-4, and Llama2, our method has demonstrated a marked efficacy\ncompared to conventional attack methods. In summary, this work introduces a\nnovel attack method that outperforms previous approaches, raising an important\nquestion: How to discern whether the ultimate intent in a dialogue is\nmalicious?", "published": "2024-07-22 06:04:29", "link": "http://arxiv.org/abs/2407.15399v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Empirical Capacity Model for Self-Attention Neural Networks", "abstract": "Large pretrained self-attention neural networks, or transformers, have been\nvery successful in various tasks recently. The performance of a model on a\ngiven task depends on its ability to memorize and generalize the training data.\nLarge transformer models, which may have billions of parameters, in theory have\na huge capacity to memorize content. However, the current algorithms for the\noptimization fall short of the theoretical capacity, and the capacity is also\nhighly dependent on the content. In this paper, we focus on the memory capacity\nof these models obtained using common training algorithms and synthetic\ntraining data. Based on the results, we derive an empirical capacity model\n(ECM) for a generic transformer. The ECM can be used to design task-specific\ntransformer models with an optimal number of parameters in cases where the\ntarget memorization capability of the task can be defined.", "published": "2024-07-22 07:02:15", "link": "http://arxiv.org/abs/2407.15425v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fundamental Limits of Prompt Compression: A Rate-Distortion Framework\n  for Black-Box Language Models", "abstract": "We formalize the problem of prompt compression for large language models\n(LLMs) and present a framework to unify token-level prompt compression methods\nwhich create hard prompts for black-box models. We derive the distortion-rate\nfunction for this setup as a linear program, and provide an efficient algorithm\nto compute this fundamental limit via the dual of the linear program. Using the\ndistortion-rate function as the baseline, we study the performance of existing\ncompression schemes on a synthetic dataset consisting of prompts generated from\na Markov chain, natural language queries, and their respective answers. Our\nempirical analysis demonstrates the criticality of query-aware prompt\ncompression, where the compressor has knowledge of the downstream task/query\nfor the black-box LLM. We show that there is a large gap between the\nperformance of current prompt compression methods and the optimal strategy, and\npropose Adaptive QuerySelect, a query-aware, variable-rate adaptation of a\nprior work to close the gap. We extend our experiments to a small natural\nlanguage dataset to further confirm our findings on our synthetic dataset.", "published": "2024-07-22 09:40:13", "link": "http://arxiv.org/abs/2407.15504v2", "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Latent Adversarial Training Improves Robustness to Persistent Harmful\n  Behaviors in LLMs", "abstract": "Large language models (LLMs) can often be made to behave in undesirable ways\nthat they are explicitly fine-tuned not to. For example, the LLM red-teaming\nliterature has produced a wide variety of 'jailbreaking' techniques to elicit\nharmful text from models that were fine-tuned to be harmless. Recent work on\nred-teaming, model editing, and interpretability suggests that this challenge\nstems from how (adversarial) fine-tuning largely serves to suppress rather than\nremove undesirable capabilities from LLMs. Prior work has introduced latent\nadversarial training (LAT) as a way to improve robustness to broad classes of\nfailures. These prior works have considered untargeted latent space attacks\nwhere the adversary perturbs latent activations to maximize loss on examples of\ndesirable behavior. Untargeted LAT can provide a generic type of robustness but\ndoes not leverage information about specific failure modes. Here, we experiment\nwith targeted LAT where the adversary seeks to minimize loss on a specific\ncompeting task. We find that it can augment a wide variety of state-of-the-art\nmethods. First, we use targeted LAT to improve robustness to jailbreaks,\noutperforming a strong R2D2 baseline with orders of magnitude less compute.\nSecond, we use it to more effectively remove backdoors with no knowledge of the\ntrigger. Finally, we use it to more effectively unlearn knowledge for specific\nundesirable tasks in a way that is also more robust to re-learning. Overall,\nour results suggest that targeted LAT can be an effective tool for defending\nagainst harmful behaviors from LLMs.", "published": "2024-07-22 11:19:14", "link": "http://arxiv.org/abs/2407.15549v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RadioRAG: Factual large language models for enhanced diagnostics in\n  radiology using online retrieval augmented generation", "abstract": "Large language models (LLMs) often generate outdated or inaccurate\ninformation based on static training datasets. Retrieval augmented generation\n(RAG) mitigates this by integrating outside data sources. While previous RAG\nsystems used pre-assembled, fixed databases with limited flexibility, we have\ndeveloped Radiology RAG (RadioRAG), an end-to-end framework that retrieves data\nfrom authoritative radiologic online sources in real-time. We evaluate the\ndiagnostic accuracy of various LLMs when answering radiology-specific questions\nwith and without access to additional online information via RAG. Using 80\nquestions from the RSNA Case Collection across radiologic subspecialties and 24\nadditional expert-curated questions with reference standard answers, LLMs\n(GPT-3.5-turbo, GPT-4, Mistral-7B, Mixtral-8x7B, and Llama3 [8B and 70B]) were\nprompted with and without RadioRAG in a zero-shot inference scenario RadioRAG\nretrieved context-specific information from www.radiopaedia.org in real-time.\nAccuracy was investigated. Statistical analyses were performed using\nbootstrapping. The results were further compared with human performance.\nRadioRAG improved diagnostic accuracy across most LLMs, with relative accuracy\nincreases ranging up to 54% for different LLMs. It matched or exceeded non-RAG\nmodels and the human radiologist in question answering across radiologic\nsubspecialties, particularly in breast imaging and emergency radiology.\nHowever, the degree of improvement varied among models; GPT-3.5-turbo and\nMixtral-8x7B-instruct-v0.1 saw notable gains, while Mistral-7B-instruct-v0.2\nshowed no improvement, highlighting variability in RadioRAG's effectiveness.\nLLMs benefit when provided access to domain-specific data beyond their training\ndata. For radiology, RadioRAG establishes a robust framework that substantially\nimproves diagnostic accuracy and factuality in radiological question answering.", "published": "2024-07-22 13:29:56", "link": "http://arxiv.org/abs/2407.15621v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Have Compositional Ability? An Investigation\n  into Limitations and Scalability", "abstract": "Large language models (LLMs) have emerged as powerful tools for many AI\nproblems and exhibit remarkable in-context learning (ICL) capabilities.\nCompositional ability, solving unseen complex tasks that combine two or more\nsimple tasks, is an essential reasoning ability for Artificial General\nIntelligence. Despite the tremendous success of LLMs, how they approach\ncomposite tasks, especially those not encountered during the pretraining phase,\nremains an open and largely underexplored question. In this study, we delve\ninto the ICL capabilities of LLMs on composite tasks, with only simple tasks as\nin-context examples. We develop a test suite of composite tasks including\nlinguistic and logical challenges and perform empirical studies across\ndifferent LLM families. We observe that models exhibit divergent behaviors: (1)\nFor simpler composite tasks that apply distinct mapping mechanisms to different\ninput segments, the models demonstrate decent compositional ability, while\nscaling up the model enhances this ability; (2) for more complex composite\ntasks involving reasoning multiple steps, where each step represents one task,\nmodels typically underperform, and scaling up generally provides no\nimprovements. We offer theoretical analysis in a simplified setting, explaining\nthat models exhibit compositional capability when the task handles different\ninput parts separately. We believe our work sheds new light on the capabilities\nof LLMs in solving composite tasks regarding the nature of the tasks and model\nscale. Our dataset and code are available at\n{\\url{https://github.com/OliverXUZY/LLM_Compose}}.", "published": "2024-07-22 15:22:34", "link": "http://arxiv.org/abs/2407.15720v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LongVideoBench: A Benchmark for Long-context Interleaved Video-Language\n  Understanding", "abstract": "Large multimodal models (LMMs) are processing increasingly longer and richer\ninputs. Albeit the progress, few public benchmark is available to measure such\ndevelopment. To mitigate this gap, we introduce LongVideoBench, a\nquestion-answering benchmark that features video-language interleaved inputs up\nto an hour long. Our benchmark includes 3,763 varying-length web-collected\nvideos with their subtitles across diverse themes, designed to comprehensively\nevaluate LMMs on long-term multimodal understanding. To achieve this, we\ninterpret the primary challenge as to accurately retrieve and reason over\ndetailed multimodal information from long inputs. As such, we formulate a novel\nvideo question-answering task termed referring reasoning. Specifically, as part\nof the question, it contains a referring query that references related video\ncontexts, called referred context. The model is then required to reason over\nrelevant video details from the referred context. Following the paradigm of\nreferring reasoning, we curate 6,678 human-annotated multiple-choice questions\nin 17 fine-grained categories, establishing one of the most comprehensive\nbenchmarks for long-form video understanding. Evaluations suggest that the\nLongVideoBench presents significant challenges even for the most advanced\nproprietary models (e.g. GPT-4o, Gemini-1.5-Pro, GPT-4-Turbo), while their\nopen-source counterparts show an even larger performance gap. In addition, our\nresults indicate that model performance on the benchmark improves only when\nthey are capable of processing more frames, positioning LongVideoBench as a\nvaluable benchmark for evaluating future-generation long-context LMMs.", "published": "2024-07-22 16:00:55", "link": "http://arxiv.org/abs/2407.15754v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Conditional Language Policy: A General Framework for Steerable\n  Multi-Objective Finetuning", "abstract": "Reward-based finetuning is crucial for aligning language policies with\nintended behaviors (e.g., creativity and safety). A key challenge is to develop\nsteerable language models that trade-off multiple (conflicting) objectives in a\nflexible and efficient manner. This paper presents Conditional Language Policy\n(CLP), a general framework for finetuning language models on multiple\nobjectives. Building on techniques from multi-task training and\nparameter-efficient finetuning, CLP learn steerable models that effectively\ntrade-off conflicting objectives at inference time. Notably, this does not\nrequire training or maintaining multiple models to achieve different trade-offs\nbetween the objectives. Through extensive experiments and ablations on two\nsummarization datasets, we show that CLP learns steerable language models that\noutperform and Pareto-dominate the existing approaches for multi-objective\nfinetuning.", "published": "2024-07-22 16:13:38", "link": "http://arxiv.org/abs/2407.15762v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Perceptions of Linguistic Uncertainty by Language Models and Humans", "abstract": "_Uncertainty expressions_ such as \"probably\" or \"highly unlikely\" are\npervasive in human language. While prior work has established that there is\npopulation-level agreement in terms of how humans quantitatively interpret\nthese expressions, there has been little inquiry into the abilities of language\nmodels in the same context. In this paper, we investigate how language models\nmap linguistic expressions of uncertainty to numerical responses. Our approach\nassesses whether language models can employ theory of mind in this setting:\nunderstanding the uncertainty of another agent about a particular statement,\nindependently of the model's own certainty about that statement. We find that 7\nout of 10 models are able to map uncertainty expressions to probabilistic\nresponses in a human-like manner. However, we observe systematically different\nbehavior depending on whether a statement is actually true or false. This\nsensitivity indicates that language models are substantially more susceptible\nto bias based on their prior knowledge (as compared to humans). These findings\nraise important questions and have broad implications for human-AI and AI-AI\ncommunication.", "published": "2024-07-22 17:26:12", "link": "http://arxiv.org/abs/2407.15814v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue\n  Language Modeling", "abstract": "Spoken dialogue plays a crucial role in human-AI interactions, necessitating\ndialogue-oriented spoken language models (SLMs). To develop versatile SLMs,\nlarge-scale and diverse speech datasets are essential. Additionally, to ensure\nhiqh-quality speech generation, the data must be spontaneous like in-wild data\nand must be acoustically clean with noise removed. Despite the critical need,\nno open-source corpus meeting all these criteria has been available. This study\naddresses this gap by constructing and releasing a large-scale spoken dialogue\ncorpus, named Japanese Corpus for Human-AI Talks (J-CHAT), which is publicly\naccessible. Furthermore, this paper presents a language-independent method for\ncorpus construction and describes experiments on dialogue generation using SLMs\ntrained on J-CHAT. Experimental results indicate that the collected data from\nmultiple domains by our method improve the naturalness and meaningfulness of\ndialogue generation.", "published": "2024-07-22 17:46:50", "link": "http://arxiv.org/abs/2407.15828v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "dMel: Speech Tokenization made Simple", "abstract": "Large language models have revolutionized natural language processing by\nleveraging self-supervised pretraining on vast textual data. Inspired by this\nsuccess, researchers have investigated complicated speech tokenization methods\nto discretize continuous speech signals so that language modeling techniques\ncan be applied to speech data. However, existing approaches either model\nsemantic (content) tokens, potentially losing acoustic information, or model\nacoustic tokens, risking the loss of semantic (content) information. Having\nmultiple token types also complicates the architecture and requires additional\npretraining. Here we show that discretizing mel-filterbank channels into\ndiscrete intensity bins produces a simple representation (dMel), that performs\nbetter than other existing speech tokenization methods. Using an LM-style\ntransformer architecture for speech-text modeling, we comprehensively evaluate\ndifferent speech tokenization methods on speech recognition (ASR) and speech\nsynthesis (TTS). Our results demonstrate the effectiveness of dMel in achieving\nhigh performance on both tasks within a unified framework, paving the way for\nefficient and effective joint modeling of speech and text.", "published": "2024-07-22 17:51:53", "link": "http://arxiv.org/abs/2407.15835v2", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multimodal Input Aids a Bayesian Model of Phonetic Learning", "abstract": "One of the many tasks facing the typically-developing child language learner\nis learning to discriminate between the distinctive sounds that make up words\nin their native language. Here we investigate whether multimodal\ninformation--specifically adult speech coupled with video frames of speakers'\nfaces--benefits a computational model of phonetic learning. We introduce a\nmethod for creating high-quality synthetic videos of speakers' faces for an\nexisting audio corpus. Our learning model, when both trained and tested on\naudiovisual inputs, achieves up to a 8.1% relative improvement on a phoneme\ndiscrimination battery compared to a model trained and tested on audio-only\ninput. It also outperforms the audio model by up to 3.9% when both are tested\non audio-only data, suggesting that visual information facilitates the\nacquisition of acoustic distinctions. Visual information is especially\nbeneficial in noisy audio environments, where an audiovisual model closes 67%\nof the loss in discrimination performance of the audio model in noise relative\nto a non-noisy environment. These results demonstrate that visual information\nbenefits an ideal learner and illustrate some of the ways that children might\nbe able to leverage visual cues when learning to discriminate speech sounds.", "published": "2024-07-22 19:00:11", "link": "http://arxiv.org/abs/2407.15992v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Enhancing Temporal Understanding in LLMs for Semi-structured Tables", "abstract": "Temporal reasoning over tabular data presents substantial challenges for\nlarge language models (LLMs), as evidenced by recent research. In this study,\nwe conduct a comprehensive analysis of temporal datasets to pinpoint the\nspecific limitations of LLMs. Our investigation leads to enhancements in\nTempTabQA, a dataset specifically designed for tabular temporal question\nanswering. We provide critical insights for improving LLM performance in\ntemporal reasoning tasks with tabular data. Furthermore, we introduce a novel\napproach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings\ndemonstrate that our method significantly improves evidence-based reasoning\nacross various models. Additionally, our experimental results reveal that\nindirect supervision with auxiliary data substantially boosts model performance\nin these tasks. This work contributes to a deeper understanding of LLMs'\ntemporal reasoning abilities over tabular data and promotes advancements in\ntheir application across diverse fields.", "published": "2024-07-22 20:13:10", "link": "http://arxiv.org/abs/2407.16030v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CP-Prompt: Composition-Based Cross-modal Prompting for\n  Domain-Incremental Continual Learning", "abstract": "The key challenge of cross-modal domain-incremental learning (DIL) is to\nenable the learning model to continuously learn from novel data with different\nfeature distributions under the same task without forgetting old ones. However,\nexisting top-performing methods still cause high forgetting rates, by lacking\nintra-domain knowledge extraction and inter-domain common prompting strategy.\nIn this paper, we propose a simple yet effective framework, CP-Prompt, by\ntraining limited parameters to instruct a pre-trained model to learn new\ndomains and avoid forgetting existing feature distributions. CP-Prompt captures\nintra-domain knowledge by compositionally inserting personalized prompts on\nmulti-head self-attention layers and then learns the inter-domain knowledge\nwith a common prompting strategy. CP-Prompt shows superiority compared with\nstate-of-the-art baselines among three widely evaluated DIL tasks. The source\ncode is available at https://github.com/dannis97500/CP_Prompt.", "published": "2024-07-22 04:07:12", "link": "http://arxiv.org/abs/2407.21043v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging LLM Reasoning Enhances Personalized Recommender Systems", "abstract": "Recent advancements have showcased the potential of Large Language Models\n(LLMs) in executing reasoning tasks, particularly facilitated by\nChain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve\nclear, definitive answers and logical chains of thought, the application of LLM\nreasoning in recommendation systems (RecSys) presents a distinct challenge.\nRecSys tasks revolve around subjectivity and personalized preferences, an\nunder-explored domain in utilizing LLMs' reasoning capabilities. Our study\nexplores several aspects to better understand reasoning for RecSys and\ndemonstrate how task quality improves by utilizing LLM reasoning in both\nzero-shot and finetuning settings. Additionally, we propose RecSAVER\n(Recommender Systems Automatic Verification and Evaluation of Reasoning) to\nautomatically assess the quality of LLM reasoning responses without the\nrequirement of curated gold references or human raters. We show that our\nframework aligns with real human judgment on the coherence and faithfulness of\nreasoning responses. Overall, our work shows that incorporating reasoning into\nRecSys can improve personalized tasks, paving the way for further advancements\nin recommender system methodologies.", "published": "2024-07-22 20:18:50", "link": "http://arxiv.org/abs/2408.00802v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Impacts of Anthropomorphizing Large Language Models in Learning\n  Environments", "abstract": "Large Language Models (LLMs) are increasingly being used in learning\nenvironments to support teaching-be it as learning companions or as tutors.\nWith our contribution, we aim to discuss the implications of the\nanthropomorphization of LLMs in learning environments on educational theory to\nbuild a foundation for more effective learning outcomes and understand their\nemotional impact on learners. According to the media equation, people tend to\nrespond to media in the same way as they would respond to another person. A\nstudy conducted by the Georgia Institute of Technology showed that chatbots can\nbe successfully implemented in learning environments. In this study, learners\nin selected online courses were unable to distinguish the chatbot from a \"real\"\nteacher. As LLM-based chatbots such as OpenAI's GPT series are increasingly\nused in educational tools, it is important to understand how the attribution\nprocesses to LLM-based chatbots in terms of anthropomorphization affect\nlearners' emotions.", "published": "2024-07-22 06:28:54", "link": "http://arxiv.org/abs/2408.03945v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Knowledge Mechanisms in Large Language Models: A Survey and Perspective", "abstract": "Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial\nfor advancing towards trustworthy AGI. This paper reviews knowledge mechanism\nanalysis from a novel taxonomy including knowledge utilization and evolution.\nKnowledge utilization delves into the mechanism of memorization, comprehension\nand application, and creation. Knowledge evolution focuses on the dynamic\nprogression of knowledge within individual and group LLMs. Moreover, we discuss\nwhat knowledge LLMs have learned, the reasons for the fragility of parametric\nknowledge, and the potential dark knowledge (hypothesis) that will be\nchallenging to address. We hope this work can help understand knowledge in LLMs\nand provide insights for future research.", "published": "2024-07-22 06:15:59", "link": "http://arxiv.org/abs/2407.15017v4", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Schr\u00f6dinger Bridge for Generative Speech Enhancement", "abstract": "This paper proposes a generative speech enhancement model based on\nSchr\\\"odinger bridge (SB). The proposed model is employing a tractable SB to\nformulate a data-to-data process between the clean speech distribution and the\nobserved noisy speech distribution. The model is trained with a data prediction\nloss, aiming to recover the complex-valued clean speech coefficients, and an\nauxiliary time-domain loss is used to improve training of the model. The\neffectiveness of the proposed SB-based model is evaluated in two different\nspeech enhancement tasks: speech denoising and speech dereverberation. The\nexperimental results demonstrate that the proposed SB-based outperforms\ndiffusion-based models in terms of speech quality metrics and ASR performance,\ne.g., resulting in relative word error rate reduction of 20% for denoising and\n6% for dereverberation compared to the best baseline model. The proposed model\nalso demonstrates improved efficiency, achieving better quality than the\nbaselines for the same number of sampling steps and with a reduced\ncomputational cost.", "published": "2024-07-22 22:17:20", "link": "http://arxiv.org/abs/2407.16074v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "SELM: Enhancing Speech Emotion Recognition for Out-of-Domain Scenarios", "abstract": "Speech Emotion Recognition (SER) has been traditionally formulated as a\nclassification task. However, emotions are generally a spectrum whose\ndistribution varies from situation to situation leading to poor Out-of-Domain\n(OOD) performance. We take inspiration from statistical formulation of\nAutomatic Speech Recognition (ASR) and formulate the SER task as generating the\nmost likely sequence of text tokens to infer emotion. The formulation breaks\nSER into predicting acoustic model features weighted by language model\nprediction. As an instance of this approach, we present SELM, an\naudio-conditioned language model for SER that predicts different emotion views.\nWe train SELM on curated speech emotion corpus and test it on three OOD\ndatasets (RAVDESS, CREMAD, IEMOCAP) not used in training. SELM achieves\nsignificant improvements over the state-of-the-art baselines, with 17% and 7%\nrelative accuracy gains for RAVDESS and CREMA-D, respectively. Moreover, SELM\ncan further boost its performance by Few-Shot Learning using a few annotated\nexamples. The results highlight the effectiveness of our SER formulation,\nespecially to improve performance in OOD scenarios.", "published": "2024-07-22 00:01:20", "link": "http://arxiv.org/abs/2407.15300v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EMO-Codec: An In-Depth Look at Emotion Preservation capacity of Legacy\n  and Neural Codec Models With Subjective and Objective Evaluations", "abstract": "The neural codec model reduces speech data transmission delay and serves as\nthe foundational tokenizer for speech language models (speech LMs). Preserving\nemotional information in codecs is crucial for effective communication and\ncontext understanding. However, there is a lack of studies on emotion loss in\nexisting codecs. This paper evaluates neural and legacy codecs using subjective\nand objective methods on emotion datasets like IEMOCAP. Our study identifies\nwhich codecs best preserve emotional information under various bitrate\nscenarios. We found that training codec models with both English and Chinese\ndata had limited success in retaining emotional information in Chinese.\nAdditionally, resynthesizing speech through these codecs degrades the\nperformance of speech emotion recognition (SER), particularly for emotions like\nsadness, depression, fear, and disgust. Human listening tests confirmed these\nfindings. This work guides future speech technology developments to ensure new\ncodecs maintain the integrity of emotional information in speech.", "published": "2024-07-22 08:14:16", "link": "http://arxiv.org/abs/2407.15458v4", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Computer Audition: From Task-Specific Machine Learning to Foundation\n  Models", "abstract": "Foundation models (FMs) are increasingly spearheading recent advances on a\nvariety of tasks that fall under the purview of computer audition -- the use of\nmachines to understand sounds. They feature several advantages over traditional\npipelines: among others, the ability to consolidate multiple tasks in a single\nmodel, the option to leverage knowledge from other modalities, and the\nreadily-available interaction with human users. Naturally, these promises have\ncreated substantial excitement in the audio community, and have led to a wave\nof early attempts to build new, general-purpose foundation models for audio. In\nthe present contribution, we give an overview of computational audio analysis\nas it transitions from traditional pipelines towards auditory foundation\nmodels. Our work highlights the key operating principles that underpin those\nmodels, and showcases how they can accommodate multiple tasks that the audio\ncommunity previously tackled separately.", "published": "2024-07-22 14:41:29", "link": "http://arxiv.org/abs/2407.15672v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Can all variations within the unified mask-based beamformer framework\n  achieve identical peak extraction performance?", "abstract": "This study investigates mask-based beamformers (BFs), which estimate filters\nfor target sound extraction (TSE) using time-frequency masks. Although multiple\nmask-based BFs have been proposed, no consensus has been reached on which one\noffers the best target-extraction performance. Previously, we found that\nmaximum signal-to-noise ratio and minimum mean square error (MSE) BFs can\nachieve the same extraction performance as the theoretical upper-bound\nperformance, with each BF containing a different optimal mask. However, two\nissues remained unsolved: only two BFs were covered, excluding the minimum\nvariance distortionless response BF, and ideal scaling (IS) was employed to\nideally adjust the output scale, which is not applicable to realistic\nscenarios. To address these issues, this study proposes a unified framework for\nmask-based BFs comprising two processes: filter estimation that can cover all\npossible BFs and scaling applicable to realistic scenarios by employing a mask\nto generate a scaling reference. Based on the operators and covariance matrices\nused in BF formulas, all possible BFs can be classified into 12 variations,\nincluding two new ones. Optimal masks for both processes are obtained by\nminimizing the MSE between the target and BF output. The experimental results\nusing the CHiME-4 dataset suggested that 1) all 12 variations can achieve the\ntheoretical upper-bound performance, and 2) mask-based scaling can behave like\nIS, even when constraining the temporal mean of a non-negative mask to one.\nThese results can be explained by considering the practical parameter count of\nthe masks. These findings contribute to 1) designing a TSE system, 2) improving\nscaling accuracy through mask-based scaling, and 3) estimating the extraction\nperformance of a BF.", "published": "2024-07-22 00:37:40", "link": "http://arxiv.org/abs/2407.15310v2", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Integrating IP Broadcasting with Audio Tags: Workflow and Challenges", "abstract": "The broadcasting industry is increasingly adopting IP techniques,\nrevolutionising both live and pre-recorded content production, from news\ngathering to live music events. IP broadcasting allows for the transport of\naudio and video signals in an easily configurable way, aligning with modern\nnetworking techniques. This shift towards an IP workflow allows for much\ngreater flexibility, not only in routing signals but with the integration of\ntools using standard web development techniques. One possible tool could\ninclude the use of live audio tagging, which has a number of uses in the\nproduction of content. These include from automated closed captioning to\nidentifying unwanted sound events within a scene. In this paper, we describe\nthe process of containerising an audio tagging model into a microservice, a\nsmall segregated code module that can be integrated into a multitude of\ndifferent network setups. The goal is to develop a modular, accessible, and\nflexible tool capable of seamless deployment into broadcasting workflows of all\nsizes, from small productions to large corporations. Challenges surrounding\nlatency of the selected audio tagging model and its effect on the usefulness of\nthe end product are discussed.", "published": "2024-07-22 07:00:21", "link": "http://arxiv.org/abs/2407.15423v2", "categories": ["eess.AS", "cs.AI", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DSP-informed bandwidth extension using locally-conditioned excitation\n  and linear time-varying filter subnetworks", "abstract": "In this paper, we propose a dual-stage architecture for bandwidth extension\n(BWE) increasing the effective sampling rate of speech signals from 8 kHz to 48\nkHz. Unlike existing end-to-end deep learning models, our proposed method\nexplicitly models BWE using excitation and linear time-varying (LTV) filter\nstages. The excitation stage broadens the spectrum of the input, while the\nfiltering stage properly shapes it based on outputs from an acoustic feature\npredictor. To this end, an acoustic feature loss term can implicitly promote\nthe excitation subnetwork to produce white spectra in the upper frequency band\nto be synthesized. Experimental results demonstrate that the added inductive\nbias provided by our approach can improve upon BWE results using the generators\nfrom both SEANet or HiFi-GAN as exciters, and that our means of adapting\nprocessing with acoustic feature predictions is more effective than that used\nin HiFi-GAN-2. Secondary contributions include extensions of the SEANet model\nto accommodate local conditioning information, as well as the application of\nHiFi-GAN-2 for the BWE problem.", "published": "2024-07-22 13:36:12", "link": "http://arxiv.org/abs/2407.15624v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Generating Sample-Based Musical Instruments Using Neural Audio Codec\n  Language Models", "abstract": "In this paper, we propose and investigate the use of neural audio codec\nlanguage models for the automatic generation of sample-based musical\ninstruments based on text or reference audio prompts. Our approach extends a\ngenerative audio framework to condition on pitch across an 88-key spectrum,\nvelocity, and a combined text/audio embedding. We identify maintaining timbral\nconsistency within the generated instruments as a major challenge. To tackle\nthis issue, we introduce three distinct conditioning schemes. We analyze our\nmethods through objective metrics and human listening tests, demonstrating that\nour approach can produce compelling musical instruments. Specifically, we\nintroduce a new objective metric to evaluate the timbral consistency of the\ngenerated instruments and adapt the average Contrastive Language-Audio\nPretraining (CLAP) score for the text-to-instrument case, noting that its naive\napplication is unsuitable for assessing this task. Our findings reveal a\ncomplex interplay between timbral consistency, the quality of generated\nsamples, and their correspondence to the input prompt.", "published": "2024-07-22 13:59:58", "link": "http://arxiv.org/abs/2407.15641v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robustness of Speech Separation Models for Similar-pitch Speakers", "abstract": "Single-channel speech separation is a crucial task for enhancing speech\nrecognition systems in multi-speaker environments. This paper investigates the\nrobustness of state-of-the-art Neural Network models in scenarios where the\npitch differences between speakers are minimal. Building on earlier findings by\nDitter and Gerkmann, which identified a significant performance drop for the\n2018 Chimera++ under similar-pitch conditions, our study extends the analysis\nto more recent and sophisticated Neural Network models. Our experiments reveal\nthat modern models have substantially reduced the performance gap for matched\ntraining and testing conditions. However, a substantial performance gap\npersists under mismatched conditions, with models performing well for large\npitch differences but showing worse performance if the speakers' pitches are\nsimilar. These findings motivate further research into the generalizability of\nspeech separation models to similar-pitch speakers and unseen data.", "published": "2024-07-22 15:55:08", "link": "http://arxiv.org/abs/2407.15749v1", "categories": ["eess.AS", "cs.LG", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Annealed Multiple Choice Learning: Overcoming limitations of\n  Winner-takes-all with annealing", "abstract": "We introduce Annealed Multiple Choice Learning (aMCL) which combines\nsimulated annealing with MCL. MCL is a learning framework handling ambiguous\ntasks by predicting a small set of plausible hypotheses. These hypotheses are\ntrained using the Winner-takes-all (WTA) scheme, which promotes the diversity\nof the predictions. However, this scheme may converge toward an arbitrarily\nsuboptimal local minimum, due to the greedy nature of WTA. We overcome this\nlimitation using annealing, which enhances the exploration of the hypothesis\nspace during training. We leverage insights from statistical physics and\ninformation theory to provide a detailed description of the model training\ntrajectory. Additionally, we validate our algorithm by extensive experiments on\nsynthetic datasets, on the standard UCI benchmark, and on speech separation.", "published": "2024-07-22 12:16:56", "link": "http://arxiv.org/abs/2407.15580v3", "categories": ["cs.LG", "cs.SD", "eess.AS", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
