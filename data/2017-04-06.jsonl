{"title": "MRA - Proof of Concept of a Multilingual Report Annotator Web\n  Application", "abstract": "MRA (Multilingual Report Annotator) is a web application that translates\nRadiology text and annotates it with RadLex terms. Its goal is to explore the\nsolution of translating non-English Radiology reports as a way to solve the\nproblem of most of the Text Mining tools being developed for English. In this\nbrief paper we explain the language barrier problem and shortly describe the\napplication. MRA can be found at https://github.com/lasigeBioTM/MRA .", "published": "2017-04-06 08:32:16", "link": "http://arxiv.org/abs/1704.01748v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Question Generation from Text: A Preliminary Study", "abstract": "Automatic question generation aims to generate questions from a text passage\nwhere the generated questions can be answered by certain sub-spans of the given\npassage. Traditional methods mainly use rigid heuristic rules to transform a\nsentence into related questions. In this work, we propose to apply the neural\nencoder-decoder model to generate meaningful and diverse questions from natural\nlanguage sentences. The encoder reads the input text and the answer position,\nto produce an answer-aware input representation, which is fed to the decoder to\ngenerate an answer focused question. We conduct a preliminary study on neural\nquestion generation from text with the SQuAD dataset, and the experiment\nresults show that our method can produce fluent and diverse questions.", "published": "2017-04-06 11:44:07", "link": "http://arxiv.org/abs/1704.01792v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Interplay of Semantics and Morphology in Word Embeddings", "abstract": "We explore the ability of word embeddings to capture both semantic and\nmorphological similarity, as affected by the different types of linguistic\nproperties (surface form, lemma, morphological tag) used to compose the\nrepresentation of each word. We train several models, where each uses a\ndifferent subset of these properties to compose its representations. By\nevaluating the models on semantic and morphological measures, we reveal some\nuseful insights on the relationship between semantics and morphology.", "published": "2017-04-06 17:07:40", "link": "http://arxiv.org/abs/1704.01938v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-space Variational Encoder-Decoders for Semi-supervised Labeled\n  Sequence Transduction", "abstract": "Labeled sequence transduction is a task of transforming one sequence into\nanother sequence that satisfies desiderata specified by a set of labels. In\nthis paper we propose multi-space variational encoder-decoders, a new model for\nlabeled sequence transduction with semi-supervised learning. The generative\nmodel can use neural networks to handle both discrete and continuous latent\nvariables to exploit various features of data. Experiments show that our model\nprovides not only a powerful supervised framework but also can effectively take\nadvantage of the unlabeled data. On the SIGMORPHON morphological inflection\nbenchmark, our model outperforms single-model state-of-art results by a large\nmargin for the majority of languages.", "published": "2017-04-06 02:36:56", "link": "http://arxiv.org/abs/1704.01691v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Syntactic Neural Model for General-Purpose Code Generation", "abstract": "We consider the problem of parsing natural language descriptions into source\ncode written in a general-purpose programming language like Python. Existing\ndata-driven methods treat this problem as a language generation task without\nconsidering the underlying syntax of the target programming language. Informed\nby previous work in semantic parsing, in this paper we propose a novel neural\narchitecture powered by a grammar model to explicitly capture the target syntax\nas prior knowledge. Experiments find this an effective way to scale up to\ngeneration of complex programs from natural language descriptions, achieving\nstate-of-the-art results that well outperform previous code generation and\nsemantic parsing approaches.", "published": "2017-04-06 03:13:46", "link": "http://arxiv.org/abs/1704.01696v1", "categories": ["cs.CL", "cs.PL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "An Automated Text Categorization Framework based on Hyperparameter\n  Optimization", "abstract": "A great variety of text tasks such as topic or spam identification, user\nprofiling, and sentiment analysis can be posed as a supervised learning problem\nand tackle using a text classifier. A text classifier consists of several\nsubprocesses, some of them are general enough to be applied to any supervised\nlearning problem, whereas others are specifically designed to tackle a\nparticular task, using complex and computational expensive processes such as\nlemmatization, syntactic analysis, etc. Contrary to traditional approaches, we\npropose a minimalistic and wide system able to tackle text classification tasks\nindependent of domain and language, namely microTC. It is composed by some easy\nto implement text transformations, text representations, and a supervised\nlearning algorithm. These pieces produce a competitive classifier even in the\ndomain of informally written text. We provide a detailed description of microTC\nalong with an extensive experimental comparison with relevant state-of-the-art\nmethods. mircoTC was compared on 30 different datasets. Regarding accuracy,\nmicroTC obtained the best performance in 20 datasets while achieves competitive\nresults in the remaining 10. The compared datasets include several problems\nlike topic and polarity classification, spam detection, user profiling and\nauthorship attribution. Furthermore, it is important to state that our approach\nallows the usage of the technology even without knowledge of machine learning\nand natural language processing.", "published": "2017-04-06 18:01:22", "link": "http://arxiv.org/abs/1704.01975v2", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
