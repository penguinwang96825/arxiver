{"title": "Role of temporal inference in the recognition of textual inference", "abstract": "This project is a part of nature language processing and its aims to develop\na system of recognition inference text-appointed TIMINF. This type of system\ncan detect, given two portions of text, if a text is semantically deducted from\nthe other. We focused on making the inference time in this type of system. For\nthat we have built and analyzed a body built from questions collected through\nthe web. This study has enabled us to classify different types of times\ninferences and for designing the architecture of TIMINF which seeks to\nintegrate a module inference time in a detection system inference text. We also\nassess the performance of sorties TIMINF system on a test corpus with the same\nstrategy adopted in the challenge RTE.", "published": "2013-02-18 15:28:51", "link": "http://arxiv.org/abs/1302.5645v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Explaining Zipf's Law via Mental Lexicon", "abstract": "The Zipf's law is the major regularity of statistical linguistics that served\nas a prototype for rank-frequency relations and scaling laws in natural\nsciences. Here we show that the Zipf's law -- together with its applicability\nfor a single text and its generalizations to high and low frequencies including\nhapax legomena -- can be derived from assuming that the words are drawn into\nthe text with random probabilities. Their apriori density relates, via the\nBayesian statistics, to general features of the mental lexicon of the author\nwho produced the text.", "published": "2013-02-18 18:38:05", "link": "http://arxiv.org/abs/1302.4383v1", "categories": ["physics.data-an", "cond-mat.stat-mech", "cs.CL"], "primary_category": "physics.data-an"}
{"title": "Unveiling the relationship between complex networks metrics and word\n  senses", "abstract": "The automatic disambiguation of word senses (i.e., the identification of\nwhich of the meanings is used in a given context for a word that has multiple\nmeanings) is essential for such applications as machine translation and\ninformation retrieval, and represents a key step for developing the so-called\nSemantic Web. Humans disambiguate words in a straightforward fashion, but this\ndoes not apply to computers. In this paper we address the problem of Word Sense\nDisambiguation (WSD) by treating texts as complex networks, and show that word\nsenses can be distinguished upon characterizing the local structure around\nambiguous words. Our goal was not to obtain the best possible disambiguation\nsystem, but we nevertheless found that in half of the cases our approach\noutperforms traditional shallow methods. We show that the hierarchical\nconnectivity and clustering of words are usually the most relevant features for\nWSD. The results reported here shine light on the relationship between semantic\nand structural parameters of complex networks. They also indicate that when\ncombined with traditional techniques the complex network approach may be useful\nto enhance the discrimination of senses in large texts", "published": "2013-02-18 21:34:59", "link": "http://arxiv.org/abs/1302.4465v1", "categories": ["physics.soc-ph", "cs.CL", "cs.SI", "physics.data-an"], "primary_category": "physics.soc-ph"}
{"title": "Word sense disambiguation via high order of learning in complex networks", "abstract": "Complex networks have been employed to model many real systems and as a\nmodeling tool in a myriad of applications. In this paper, we use the framework\nof complex networks to the problem of supervised classification in the word\ndisambiguation task, which consists in deriving a function from the supervised\n(or labeled) training data of ambiguous words. Traditional supervised data\nclassification takes into account only topological or physical features of the\ninput data. On the other hand, the human (animal) brain performs both low- and\nhigh-level orders of learning and it has facility to identify patterns\naccording to the semantic meaning of the input data. In this paper, we apply a\nhybrid technique which encompasses both types of learning in the field of word\nsense disambiguation and show that the high-level order of learning can really\nimprove the accuracy rate of the model. This evidence serves to demonstrate\nthat the internal structures formed by the words do present patterns that,\ngenerally, cannot be correctly unveiled by only traditional techniques.\nFinally, we exhibit the behavior of the model for different weights of the low-\nand high-level classifiers by plotting decision boundaries. This study helps\none to better understand the effectiveness of the model.", "published": "2013-02-18 22:06:52", "link": "http://arxiv.org/abs/1302.4471v1", "categories": ["physics.soc-ph", "cs.CL", "cs.SI", "physics.data-an"], "primary_category": "physics.soc-ph"}
