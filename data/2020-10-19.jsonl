{"title": "SciSummPip: An Unsupervised Scientific Paper Summarization Pipeline", "abstract": "The Scholarly Document Processing (SDP) workshop is to encourage more efforts\non natural language understanding of scientific task. It contains three shared\ntasks and we participate in the LongSumm shared task. In this paper, we\ndescribe our text summarization system, SciSummPip, inspired by SummPip (Zhao\net al., 2020) that is an unsupervised text summarization system for\nmulti-document in news domain. Our SciSummPip includes a transformer-based\nlanguage model SciBERT (Beltagy et al., 2019) for contextual sentence\nrepresentation, content selection with PageRank (Page et al., 1999), sentence\ngraph construction with both deep and linguistic information, sentence graph\nclustering and within-graph summary generation. Our work differs from previous\nmethod in that content selection and a summary length constraint is applied to\nadapt to the scientific domain. The experiment results on both training dataset\nand blind test dataset show the effectiveness of our method, and we empirically\nverify the robustness of modules used in SciSummPip with BERTScore (Zhang et\nal., 2019a).", "published": "2020-10-19 03:29:21", "link": "http://arxiv.org/abs/2010.09190v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Infusing Sequential Information into Conditional Masked Translation\n  Model with Self-Review Mechanism", "abstract": "Non-autoregressive models generate target words in a parallel way, which\nachieve a faster decoding speed but at the sacrifice of translation accuracy.\nTo remedy a flawed translation by non-autoregressive models, a promising\napproach is to train a conditional masked translation model (CMTM), and refine\nthe generated results within several iterations. Unfortunately, such approach\nhardly considers the \\textit{sequential dependency} among target words, which\ninevitably results in a translation degradation. Hence, instead of solely\ntraining a Transformer-based CMTM, we propose a Self-Review Mechanism to infuse\nsequential information into it. Concretely, we insert a left-to-right mask to\nthe same decoder of CMTM, and then induce it to autoregressively review whether\neach generated word from CMTM is supposed to be replaced or kept. The\nexperimental results (WMT14 En$\\leftrightarrow$De and WMT16\nEn$\\leftrightarrow$Ro) demonstrate that our model uses dramatically less\ntraining computations than the typical CMTM, as well as outperforms several\nstate-of-the-art non-autoregressive models by over 1 BLEU. Through knowledge\ndistillation, our model even surpasses a typical left-to-right Transformer\nmodel, while significantly speeding up decoding.", "published": "2020-10-19 03:38:56", "link": "http://arxiv.org/abs/2010.09194v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Auto-Encoding Variational Bayes for Inferring Topics and Visualization", "abstract": "Visualization and topic modeling are widely used approaches for text\nanalysis. Traditional visualization methods find low-dimensional\nrepresentations of documents in the visualization space (typically 2D or 3D)\nthat can be displayed using a scatterplot. In contrast, topic modeling aims to\ndiscover topics from text, but for visualization, one needs to perform a\npost-hoc embedding using dimensionality reduction methods. Recent approaches\npropose using a generative model to jointly find topics and visualization,\nallowing the semantics to be infused in the visualization space for a\nmeaningful interpretation. A major challenge that prevents these methods from\nbeing used practically is the scalability of their inference algorithms. We\npresent, to the best of our knowledge, the first fast Auto-Encoding Variational\nBayes based inference method for jointly inferring topics and visualization.\nSince our method is black box, it can handle model changes efficiently with\nlittle mathematical rederivation effort. We demonstrate the efficiency and\neffectiveness of our method on real-world large datasets and compare it with\nexisting baselines.", "published": "2020-10-19 05:57:11", "link": "http://arxiv.org/abs/2010.09233v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dimsum @LaySumm 20: BART-based Approach for Scientific Document\n  Summarization", "abstract": "Lay summarization aims to generate lay summaries of scientific papers\nautomatically. It is an essential task that can increase the relevance of\nscience for all of society. In this paper, we build a lay summary generation\nsystem based on the BART model. We leverage sentence labels as extra\nsupervision signals to improve the performance of lay summarization. In the\nCL-LaySumm 2020 shared task, our model achieves 46.00\\% Rouge1-F1 score.", "published": "2020-10-19 06:36:11", "link": "http://arxiv.org/abs/2010.09252v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The RELX Dataset and Matching the Multilingual Blanks for Cross-Lingual\n  Relation Classification", "abstract": "Relation classification is one of the key topics in information extraction,\nwhich can be used to construct knowledge bases or to provide useful information\nfor question answering. Current approaches for relation classification are\nmainly focused on the English language and require lots of training data with\nhuman annotations. Creating and annotating a large amount of training data for\nlow-resource languages is impractical and expensive. To overcome this issue, we\npropose two cross-lingual relation classification models: a baseline model\nbased on Multilingual BERT and a new multilingual pretraining setup, which\nsignificantly improves the baseline with distant supervision. For evaluation,\nwe introduce a new public benchmark dataset for cross-lingual relation\nclassification in English, French, German, Spanish, and Turkish, called RELX.\nWe also provide the RELX-Distant dataset, which includes hundreds of thousands\nof sentences with relations from Wikipedia and Wikidata collected by distant\nsupervision for these languages. Our code and data are available at:\nhttps://github.com/boun-tabi/RELX", "published": "2020-10-19 11:08:16", "link": "http://arxiv.org/abs/2010.09381v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Pretraining for Neural Machine Translation Using Elastic\n  Weight Consolidation", "abstract": "This work presents our ongoing research of unsupervised pretraining in neural\nmachine translation (NMT). In our method, we initialize the weights of the\nencoder and decoder with two language models that are trained with monolingual\ndata and then fine-tune the model on parallel data using Elastic Weight\nConsolidation (EWC) to avoid forgetting of the original language modeling\ntasks. We compare the regularization by EWC with the previous work that focuses\non regularization by language modeling objectives. The positive result is that\nusing EWC with the decoder achieves BLEU scores similar to the previous work.\nHowever, the model converges 2-3 times faster and does not require the original\nunlabeled training data during the fine-tuning stage. In contrast, the\nregularization using EWC is less effective if the original and new tasks are\nnot closely related. We show that initializing the bidirectional NMT encoder\nwith a left-to-right language model and forcing the model to remember the\noriginal left-to-right language modeling task limits the learning capacity of\nthe encoder for the whole bidirectional context.", "published": "2020-10-19 11:51:45", "link": "http://arxiv.org/abs/2010.09403v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Heads-up! Unsupervised Constituency Parsing via Self-Attention Heads", "abstract": "Transformer-based pre-trained language models (PLMs) have dramatically\nimproved the state of the art in NLP across many tasks. This has led to\nsubstantial interest in analyzing the syntactic knowledge PLMs learn. Previous\napproaches to this question have been limited, mostly using test suites or\nprobes. Here, we propose a novel fully unsupervised parsing approach that\nextracts constituency trees from PLM attention heads. We rank transformer\nattention heads based on their inherent properties, and create an ensemble of\nhigh-ranking heads to produce the final tree. Our method is adaptable to\nlow-resource languages, as it does not rely on development sets, which can be\nexpensive to annotate. Our experiments show that the proposed method often\noutperform existing approaches if there is no development set present. Our\nunsupervised parser can also be used as a tool to analyze the grammars PLMs\nlearn implicitly. For this, we use the parse trees induced by our method to\ntrain a neural PCFG and compare it to a grammar derived from a human-annotated\ntreebank.", "published": "2020-10-19 13:51:40", "link": "http://arxiv.org/abs/2010.09517v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Better Distractions: Transformer-based Distractor Generation and\n  Multiple Choice Question Filtering", "abstract": "For the field of education, being able to generate semantically correct and\neducationally relevant multiple choice questions (MCQs) could have a large\nimpact. While question generation itself is an active research topic,\ngenerating distractors (the incorrect multiple choice options) receives much\nless attention. A missed opportunity, since there is still a lot of room for\nimprovement in this area. In this work, we train a GPT-2 language model to\ngenerate three distractors for a given question and text context, using the\nRACE dataset. Next, we train a BERT language model to answer MCQs, and use this\nmodel as a filter, to select only questions that can be answered and therefore\npresumably make sense. To evaluate our work, we start by using text generation\nmetrics, which show that our model outperforms earlier work on distractor\ngeneration (DG) and achieves state-of-the-art performance. Also, by calculating\nthe question answering ability, we show that larger base models lead to better\nperformance. Moreover, we conducted a human evaluation study, which confirmed\nthe quality of the generated questions, but showed no statistically significant\neffect of the QA filter.", "published": "2020-10-19 15:23:24", "link": "http://arxiv.org/abs/2010.09598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Terminology Constraints in Automatic Post-Editing", "abstract": "Users of machine translation (MT) may want to ensure the use of specific\nlexical terminologies. While there exist techniques for incorporating\nterminology constraints during inference for MT, current APE approaches cannot\nensure that they will appear in the final translation. In this paper, we\npresent both autoregressive and non-autoregressive models for lexically\nconstrained APE, demonstrating that our approach enables preservation of 95% of\nthe terminologies and also improves translation quality on English-German\nbenchmarks. Even when applied to lexically constrained MT output, our approach\nis able to improve preservation of the terminologies. However, we show that our\nmodels do not learn to copy constraints systematically and suggest a simple\ndata augmentation technique that leads to improved performance and robustness.", "published": "2020-10-19 15:44:03", "link": "http://arxiv.org/abs/2010.09608v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study for Vietnamese Constituency Parsing with Pre-training", "abstract": "In this work, we use a span-based approach for Vietnamese constituency\nparsing. Our method follows the self-attention encoder architecture and a chart\ndecoder using a CKY-style inference algorithm. We present analyses of the\nexperiment results of the comparison of our empirical method using pre-training\nmodels XLM-Roberta and PhoBERT on both Vietnamese datasets VietTreebank and\nNIIVTB1. The results show that our model with XLM-Roberta archived the\nsignificantly F1-score better than other pre-training models, VietTreebank at\n81.19% and NIIVTB1 at 85.70%.", "published": "2020-10-19 16:02:00", "link": "http://arxiv.org/abs/2010.09623v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptive Attentional Network for Few-Shot Knowledge Graph Completion", "abstract": "Few-shot Knowledge Graph (KG) completion is a focus of current research,\nwhere each task aims at querying unseen facts of a relation given its few-shot\nreference entity pairs. Recent attempts solve this problem by learning static\nrepresentations of entities and references, ignoring their dynamic properties,\ni.e., entities may exhibit diverse roles within task relations, and references\nmay make different contributions to queries. This work proposes an adaptive\nattentional network for few-shot KG completion by learning adaptive entity and\nreference representations. Specifically, entities are modeled by an adaptive\nneighbor encoder to discern their task-oriented roles, while references are\nmodeled by an adaptive query-aware aggregator to differentiate their\ncontributions. Through the attention mechanism, both entities and references\ncan capture their fine-grained semantic meanings, and thus render more\nexpressive representations. This will be more predictive for knowledge\nacquisition in the few-shot scenario. Evaluation in link prediction on two\npublic datasets shows that our approach achieves new state-of-the-art results\nwith different few-shot sizes.", "published": "2020-10-19 16:27:48", "link": "http://arxiv.org/abs/2010.09638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Summary-Oriented Question Generation for Informational Queries", "abstract": "Users frequently ask simple factoid questions for question answering (QA)\nsystems, attenuating the impact of myriad recent works that support more\ncomplex questions. Prompting users with automatically generated suggested\nquestions (SQs) can improve user understanding of QA system capabilities and\nthus facilitate more effective use. We aim to produce self-explanatory\nquestions that focus on main document topics and are answerable with variable\nlength passages as appropriate. We satisfy these requirements by using a\nBERT-based Pointer-Generator Network trained on the Natural Questions (NQ)\ndataset. Our model shows SOTA performance of SQ generation on the NQ dataset\n(20.1 BLEU-4). We further apply our model on out-of-domain news articles,\nevaluating with a QA system due to the lack of gold questions and demonstrate\nthat our model produces better SQs for news articles -- with further\nconfirmation via a human evaluation.", "published": "2020-10-19 17:30:08", "link": "http://arxiv.org/abs/2010.09692v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subtitles to Segmentation: Improving Low-Resource Speech-to-Text\n  Translation Pipelines", "abstract": "In this work, we focus on improving ASR output segmentation in the context of\nlow-resource language speech-to-text translation. ASR output segmentation is\ncrucial, as ASR systems segment the input audio using purely acoustic\ninformation and are not guaranteed to output sentence-like segments. Since most\nMT systems expect sentences as input, feeding in longer unsegmented passages\ncan lead to sub-optimal performance. We explore the feasibility of using\ndatasets of subtitles from TV shows and movies to train better ASR segmentation\nmodels. We further incorporate part-of-speech (POS) tag and dependency label\ninformation (derived from the unsegmented ASR outputs) into our segmentation\nmodel. We show that this noisy syntactic information can improve model\naccuracy. We evaluate our models intrinsically on segmentation quality and\nextrinsically on downstream MT performance, as well as downstream tasks\nincluding cross-lingual information retrieval (CLIR) tasks and human relevance\nassessments. Our model shows improved performance on downstream tasks for\nLithuanian and Bulgarian.", "published": "2020-10-19 17:32:40", "link": "http://arxiv.org/abs/2010.09693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Transfer in Zero-Shot Cross-Language Entity Linking", "abstract": "Cross-language entity linking grounds mentions in multiple languages to a\nsingle-language knowledge base. We propose a neural ranking architecture for\nthis task that uses multilingual BERT representations of the mention and the\ncontext in a neural network. We find that the multilingual ability of BERT\nleads to robust performance in monolingual and multilingual settings.\nFurthermore, we explore zero-shot language transfer and find surprisingly\nrobust performance. We investigate the zero-shot degradation and find that it\ncan be partially mitigated by a proposed auxiliary training objective, but that\nthe remaining error can best be attributed to domain shift rather than language\ntransfer.", "published": "2020-10-19 20:08:26", "link": "http://arxiv.org/abs/2010.09828v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SmartTriage: A system for personalized patient data capture,\n  documentation generation, and decision support", "abstract": "Symptom checkers have emerged as an important tool for collecting symptoms\nand diagnosing patients, minimizing the involvement of clinical personnel. We\ndeveloped a machine-learning-backed system, SmartTriage, which goes beyond\nconventional symptom checking through a tight bi-directional integration with\nthe electronic medical record (EMR). Conditioned on EMR-derived patient\nhistory, our system identifies the patient's chief complaint from a free-text\nentry and then asks a series of discrete questions to obtain relevant\nsymptomatology. The patient-specific data are used to predict detailed\nICD-10-CM codes as well as medication, laboratory, and imaging orders. Patient\nresponses and clinical decision support (CDS) predictions are then inserted\nback into the EMR. To train the machine learning components of SmartTriage, we\nemployed novel data sets of over 25 million primary care encounters and 1\nmillion patient free-text reason-for-visit entries. These data sets were used\nto construct: (1) a long short-term memory (LSTM) based patient history\nrepresentation, (2) a fine-tuned transformer model for chief complaint\nextraction, (3) a random forest model for question sequencing, and (4) a\nfeed-forward network for CDS predictions. In total, our system supports 337\npatient chief complaints, which together make up $>90\\%$ of all primary care\nencounters at Kaiser Permanente.", "published": "2020-10-19 22:45:27", "link": "http://arxiv.org/abs/2010.09905v3", "categories": ["cs.CL", "J.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "Knowledge-guided Open Attribute Value Extraction with Reinforcement\n  Learning", "abstract": "Open attribute value extraction for emerging entities is an important but\nchallenging task. A lot of previous works formulate the problem as a\n\\textit{question-answering} (QA) task. While the collections of articles from\nweb corpus provide updated information about the emerging entities, the\nretrieved texts can be noisy, irrelevant, thus leading to inaccurate answers.\nEffectively filtering out noisy articles as well as bad answers is the key to\nimproving extraction accuracy. Knowledge graph (KG), which contains rich, well\norganized information about entities, provides a good resource to address the\nchallenge. In this work, we propose a knowledge-guided reinforcement learning\n(RL) framework for open attribute value extraction. Informed by relevant\nknowledge in KG, we trained a deep Q-network to sequentially compare extracted\nanswers to improve extraction accuracy. The proposed framework is applicable to\ndifferent information extraction system. Our experimental results show that our\nmethod outperforms the baselines by 16.5 - 27.8\\%.", "published": "2020-10-19 03:28:27", "link": "http://arxiv.org/abs/2010.09189v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Multi-hop Question Generation with Graph Convolutional Network", "abstract": "Multi-hop Question Generation (QG) aims to generate answer-related questions\nby aggregating and reasoning over multiple scattered evidence from different\nparagraphs. It is a more challenging yet under-explored task compared to\nconventional single-hop QG, where the questions are generated from the sentence\ncontaining the answer or nearby sentences in the same paragraph without complex\nreasoning. To address the additional challenges in multi-hop QG, we propose\nMulti-Hop Encoding Fusion Network for Question Generation (MulQG), which does\ncontext encoding in multiple hops with Graph Convolutional Network and encoding\nfusion via an Encoder Reasoning Gate. To the best of our knowledge, we are the\nfirst to tackle the challenge of multi-hop reasoning over paragraphs without\nany sentence-level information. Empirical results on HotpotQA dataset\ndemonstrate the effectiveness of our method, in comparison with baselines on\nautomatic evaluation metrics. Moreover, from the human evaluation, our proposed\nmodel is able to generate fluent questions with high completeness and\noutperforms the strongest baseline by 20.8% in the multi-hop evaluation. The\ncode is publicly available at\nhttps://github.com/HLTCHKUST/MulQG}{https://github.com/HLTCHKUST/MulQG .", "published": "2020-10-19 06:15:36", "link": "http://arxiv.org/abs/2010.09240v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Query-aware Tip Generation for Vertical Search", "abstract": "As a concise form of user reviews, tips have unique advantages to explain the\nsearch results, assist users' decision making, and further improve user\nexperience in vertical search scenarios. Existing work on tip generation does\nnot take query into consideration, which limits the impact of tips in search\nscenarios. To address this issue, this paper proposes a query-aware tip\ngeneration framework, integrating query information into encoding and\nsubsequent decoding processes. Two specific adaptations of Transformer and\nRecurrent Neural Network (RNN) are proposed. For Transformer, the query impact\nis incorporated into the self-attention computation of both the encoder and the\ndecoder. As for RNN, the query-aware encoder adopts a selective network to\ndistill query-relevant information from the review, while the query-aware\ndecoder integrates the query information into the attention computation during\ndecoding. The framework consistently outperforms the competing methods on both\npublic and real-world industrial datasets. Last but not least, online\ndeployment experiments on Dianping demonstrate the advantage of the proposed\nframework for tip generation as well as its online business values.", "published": "2020-10-19 06:48:40", "link": "http://arxiv.org/abs/2010.09254v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Global Attention for Name Tagging", "abstract": "Many name tagging approaches use local contextual information with much\nsuccess, but fail when the local context is ambiguous or limited. We present a\nnew framework to improve name tagging by utilizing local, document-level, and\ncorpus-level contextual information. We retrieve document-level context from\nother sentences within the same document and corpus-level context from\nsentences in other topically related documents. We propose a model that learns\nto incorporate document-level and corpus-level contextual information alongside\nlocal contextual information via global attentions, which dynamically weight\ntheir respective contextual information, and gating mechanisms, which determine\nthe influence of this information. Extensive experiments on benchmark datasets\nshow the effectiveness of our approach, which achieves state-of-the-art results\nfor Dutch, German, and Spanish on the CoNLL-2002 and CoNLL-2003 datasets.", "published": "2020-10-19 07:27:15", "link": "http://arxiv.org/abs/2010.09270v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BERTnesia: Investigating the capture and forgetting of knowledge in BERT", "abstract": "Probing complex language models has recently revealed several insights into\nlinguistic and semantic patterns found in the learned representations. In this\npaper, we probe BERT specifically to understand and measure the relational\nknowledge it captures. We utilize knowledge base completion tasks to probe\nevery layer of pre-trained as well as fine-tuned BERT (ranking, question\nanswering, NER). Our findings show that knowledge is not just contained in\nBERT's final layers. Intermediate layers contribute a significant amount\n(17-60%) to the total knowledge found. Probing intermediate layers also reveals\nhow different types of knowledge emerge at varying rates. When BERT is\nfine-tuned, relational knowledge is forgotten but the extent of forgetting is\nimpacted by the fine-tuning objective but not the size of the dataset. We found\nthat ranking models forget the least and retain more knowledge in their final\nlayer. We release our code on github to repeat the experiments.", "published": "2020-10-19 08:46:30", "link": "http://arxiv.org/abs/2010.09313v2", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Understanding Unnatural Questions Improves Reasoning over Text", "abstract": "Complex question answering (CQA) over raw text is a challenging task. A\nprominent approach to this task is based on the programmer-interpreter\nframework, where the programmer maps the question into a sequence of reasoning\nactions which is then executed on the raw text by the interpreter. Learning an\neffective CQA model requires large amounts of human-annotated data,consisting\nof the ground-truth sequence of reasoning actions, which is time-consuming and\nexpensive to collect at scale. In this paper, we address the challenge of\nlearning a high-quality programmer (parser) by projecting natural\nhuman-generated questions into unnatural machine-generated questions which are\nmore convenient to parse. We firstly generate synthetic (question,action\nsequence) pairs by a data generator, and train a semantic parser that\nassociates synthetic questions with their corresponding action sequences. To\ncapture the diversity when applied tonatural questions, we learn a projection\nmodel to map natural questions into their most similar unnatural questions for\nwhich the parser can work well. Without any natural training data, our\nprojection model provides high-quality action sequences for the CQA task.\nExperimental results show that the QA model trained exclusively with synthetic\ndata generated by our method outperforms its state-of-the-art counterpart\ntrained on human-labeled data.", "published": "2020-10-19 10:22:16", "link": "http://arxiv.org/abs/2010.09366v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Revisiting Modularized Multilingual NMT to Meet Industrial Demands", "abstract": "The complete sharing of parameters for multilingual translation (1-1) has\nbeen the mainstream approach in current research. However, degraded performance\ndue to the capacity bottleneck and low maintainability hinders its extensive\nadoption in industries. In this study, we revisit the multilingual neural\nmachine translation model that only share modules among the same languages (M2)\nas a practical alternative to 1-1 to satisfy industrial requirements. Through\ncomprehensive experiments, we identify the benefits of multi-way training and\ndemonstrate that the M2 can enjoy these benefits without suffering from the\ncapacity bottleneck. Furthermore, the interlingual space of the M2 allows\nconvenient modification of the model. By leveraging trained modules, we find\nthat incrementally added modules exhibit better performance than singly trained\nmodels. The zero-shot performance of the added modules is even comparable to\nsupervised models. Our findings suggest that the M2 can be a competent\ncandidate for multilingual translation in industries.", "published": "2020-10-19 11:51:04", "link": "http://arxiv.org/abs/2010.09402v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Image Captioning with Visual Object Representations Grounded in the\n  Textual Modality", "abstract": "We present our work in progress exploring the possibilities of a shared\nembedding space between textual and visual modality. Leveraging the textual\nnature of object detection labels and the hypothetical expressiveness of\nextracted visual object representations, we propose an approach opposite to the\ncurrent trend, grounding of the representations in the word embedding space of\nthe captioning system instead of grounding words or sentences in their\nassociated images. Based on the previous work, we apply additional grounding\nlosses to the image captioning training objective aiming to force visual object\nrepresentations to create more heterogeneous clusters based on their class\nlabel and copy a semantic structure of the word embedding space. In addition,\nwe provide an analysis of the learned object vector space projection and its\nimpact on the IC system performance. With only slight change in performance,\ngrounded models reach the stopping criterion during training faster than the\nunconstrained model, needing about two to three times less training updates.\nAdditionally, an improvement in structural correlation between the word\nembeddings and both original and projected object vectors suggests that the\ngrounding is actually mutual.", "published": "2020-10-19 12:21:38", "link": "http://arxiv.org/abs/2010.09413v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Diving Deep into Context-Aware Neural Machine Translation", "abstract": "Context-aware neural machine translation (NMT) is a promising direction to\nimprove the translation quality by making use of the additional context, e.g.,\ndocument-level translation, or having meta-information. Although there exist\nvarious architectures and analyses, the effectiveness of different\ncontext-aware NMT models is not well explored yet. This paper analyzes the\nperformance of document-level NMT models on four diverse domains with a varied\namount of parallel document-level bilingual data. We conduct a comprehensive\nset of experiments to investigate the impact of document-level NMT. We find\nthat there is no single best approach to document-level NMT, but rather that\ndifferent architectures come out on top on different tasks. Looking at\ntask-specific problems, such as pronoun resolution or headline translation, we\nfind improvements in the context-aware systems, even in cases where the\ncorpus-level metrics like BLEU show no significant improvement. We also show\nthat document-level back-translation significantly helps to compensate for the\nlack of document-level bi-texts.", "published": "2020-10-19 13:23:12", "link": "http://arxiv.org/abs/2010.09482v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multimodal Research in Vision and Language: A Review of Current and\n  Emerging Trends", "abstract": "Deep Learning and its applications have cascaded impactful research and\ndevelopment with a diverse range of modalities present in the real-world data.\nMore recently, this has enhanced research interests in the intersection of the\nVision and Language arena with its numerous applications and fast-paced growth.\nIn this paper, we present a detailed overview of the latest trends in research\npertaining to visual and language modalities. We look at its applications in\ntheir task formulations and how to solve various problems related to semantic\nperception and content generation. We also address task-specific trends, along\nwith their evaluation strategies and upcoming challenges. Moreover, we shed\nsome light on multi-disciplinary patterns and insights that have emerged in the\nrecent past, directing this field towards more modular and transparent\nintelligent systems. This survey identifies key trends gravitating recent\nliterature in VisLang research and attempts to unearth directions that the\nfield is heading towards.", "published": "2020-10-19 13:55:10", "link": "http://arxiv.org/abs/2010.09522v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Cold-start Active Learning through Self-supervised Language Modeling", "abstract": "Active learning strives to reduce annotation costs by choosing the most\ncritical examples to label. Typically, the active learning strategy is\ncontingent on the classification model. For instance, uncertainty sampling\ndepends on poorly calibrated model confidence scores. In the cold-start\nsetting, active learning is impractical because of model instability and data\nscarcity. Fortunately, modern NLP provides an additional source of information:\npre-trained language models. The pre-training loss can find examples that\nsurprise the model and should be labeled for efficient fine-tuning. Therefore,\nwe treat the language modeling loss as a proxy for classification uncertainty.\nWith BERT, we develop a simple strategy based on the masked language modeling\nloss that minimizes labeling costs for text classification. Compared to other\nbaselines, our approach reaches higher accuracy within less sampling iterations\nand computation time.", "published": "2020-10-19 14:09:17", "link": "http://arxiv.org/abs/2010.09535v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Drug Repurposing for COVID-19 via Knowledge Graph Completion", "abstract": "Objective: To discover candidate drugs to repurpose for COVID-19 using\nliterature-derived knowledge and knowledge graph completion methods. Methods:\nWe propose a novel, integrative, and neural network-based literature-based\ndiscovery (LBD) approach to identify drug candidates from both PubMed and\nCOVID-19-focused research literature. Our approach relies on semantic triples\nextracted using SemRep (via SemMedDB). We identified an informative subset of\nsemantic triples using filtering rules and an accuracy classifier developed on\na BERT variant, and used this subset to construct a knowledge graph. Five SOTA,\nneural knowledge graph completion algorithms were used to predict drug\nrepurposing candidates. The models were trained and assessed using a time\nslicing approach and the predicted drugs were compared with a list of drugs\nreported in the literature and evaluated in clinical trials. These models were\ncomplemented by a discovery pattern-based approach. Results: Accuracy\nclassifier based on PubMedBERT achieved the best performance (F1= 0.854) in\nclassifying semantic predications. Among five knowledge graph completion\nmodels, TransE outperformed others (MR = 0.923, Hits@1=0.417). Some known drugs\nlinked to COVID-19 in the literature were identified, as well as some candidate\ndrugs that have not yet been studied. Discovery patterns enabled generation of\nplausible hypotheses regarding the relationships between the candidate drugs\nand COVID-19. Among them, five highly ranked and novel drugs (paclitaxel, SB\n203580, alpha 2-antiplasmin, pyrrolidine dithiocarbamate, and butylated\nhydroxytoluene) with their mechanistic explanations were further discussed.\nConclusion: We show that an LBD approach can be feasible for discovering drug\ncandidates for COVID-19, and for generating mechanistic explanations. Our\napproach can be generalized to other diseases as well as to other clinical\nquestions.", "published": "2020-10-19 15:30:51", "link": "http://arxiv.org/abs/2010.09600v2", "categories": ["cs.CL", "cs.IR", "I.2.4; I.2.7"], "primary_category": "cs.CL"}
{"title": "PySBD: Pragmatic Sentence Boundary Disambiguation", "abstract": "In this paper, we present a rule-based sentence boundary disambiguation\nPython package that works out-of-the-box for 22 languages. We aim to provide a\nrealistic segmenter which can provide logical sentences even when the format\nand domain of the input text is unknown. In our work, we adapt the Golden Rules\nSet (a language-specific set of sentence boundary exemplars) originally\nimplemented as a ruby gem - pragmatic_segmenter - which we ported to Python\nwith additional improvements and functionality. PySBD passes 97.92% of the\nGolden Rule Set exemplars for English, an improvement of 25% over the next best\nopen-source Python tool.", "published": "2020-10-19 16:56:03", "link": "http://arxiv.org/abs/2010.09657v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Effects of Parameter Norm Growth During Transformer Training: Inductive\n  Bias from Gradient Descent", "abstract": "The capacity of neural networks like the widely adopted transformer is known\nto be very high. Evidence is emerging that they learn successfully due to\ninductive bias in the training routine, typically a variant of gradient descent\n(GD). To better understand this bias, we study the tendency for transformer\nparameters to grow in magnitude ($\\ell_2$ norm) during training, and its\nimplications for the emergent representations within self attention layers.\nEmpirically, we document norm growth in the training of transformer language\nmodels, including T5 during its pretraining. As the parameters grow in\nmagnitude, we prove that the network approximates a discretized network with\nsaturated activation functions. Such \"saturated\" networks are known to have a\nreduced capacity compared to the full network family that can be described in\nterms of formal languages and automata. Our results suggest saturation is a new\ncharacterization of an inductive bias implicit in GD of particular interest for\nNLP. We leverage the emergent discrete structure in a saturated transformer to\nanalyze the role of different attention heads, finding that some focus locally\non a small number of positions, while other heads compute global averages,\nallowing counting. We believe understanding the interplay between these two\ncapabilities may shed further light on the structure of computation within\nlarge transformers.", "published": "2020-10-19 17:40:38", "link": "http://arxiv.org/abs/2010.09697v5", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Technical Question Answering across Tasks and Domains", "abstract": "Building automatic technical support system is an important yet challenge\ntask. Conceptually, to answer a user question on a technical forum, a human\nexpert has to first retrieve relevant documents, and then read them carefully\nto identify the answer snippet. Despite huge success the researchers have\nachieved in coping with general domain question answering (QA), much less\nattentions have been paid for investigating technical QA. Specifically,\nexisting methods suffer from several unique challenges (i) the question and\nanswer rarely overlaps substantially and (ii) very limited data size. In this\npaper, we propose a novel framework of deep transfer learning to effectively\naddress technical QA across tasks and domains. To this end, we present an\nadjustable joint learning approach for document retrieval and reading\ncomprehension tasks. Our experiments on the TechQA demonstrates superior\nperformance compared with state-of-the-art methods.", "published": "2020-10-19 18:39:30", "link": "http://arxiv.org/abs/2010.09780v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deriving Commonsense Inference Tasks from Interactive Fictions", "abstract": "Commonsense reasoning simulates the human ability to make presumptions about\nour physical world, and it is an indispensable cornerstone in building general\nAI systems. We propose a new commonsense reasoning dataset based on human's\ninteractive fiction game playings as human players demonstrate plentiful and\ndiverse commonsense reasoning. The new dataset mitigates several limitations of\nthe prior art. Experiments show that our task is solvable to human experts with\nsufficient commonsense knowledge but poses challenges to existing machine\nreading models, with a big performance gap of more than 30%.", "published": "2020-10-19 19:02:34", "link": "http://arxiv.org/abs/2010.09788v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Explainable Automated Fact-Checking for Public Health Claims", "abstract": "Fact-checking is the task of verifying the veracity of claims by assessing\ntheir assertions against credible evidence. The vast majority of fact-checking\nstudies focus exclusively on political claims. Very little research explores\nfact-checking for other topics, specifically subject matters for which\nexpertise is required. We present the first study of explainable fact-checking\nfor claims which require specific expertise. For our case study we choose the\nsetting of public health. To support this case study we construct a new dataset\nPUBHEALTH of 11.8K claims accompanied by journalist crafted, gold standard\nexplanations (i.e., judgments) to support the fact-check labels for claims. We\nexplore two tasks: veracity prediction and explanation generation. We also\ndefine and evaluate, with humans and computationally, three coherence\nproperties of explanation quality. Our results indicate that, by training on\nin-domain data, gains can be made in explainable, automated fact-checking for\nclaims which require specific expertise.", "published": "2020-10-19 23:51:33", "link": "http://arxiv.org/abs/2010.09926v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Expressive Rules Provide Explainability and Assist Human\n  Experts Grasping New Domains", "abstract": "Approaching new data can be quite deterrent; you do not know how your\ncategories of interest are realized in it, commonly, there is no labeled data\nat hand, and the performance of domain adaptation methods is unsatisfactory.\n  Aiming to assist domain experts in their first steps into a new task over a\nnew corpus, we present an unsupervised approach to reveal complex rules which\ncluster the unexplored corpus by its prominent categories (or facets).\n  These rules are human-readable, thus providing an important ingredient which\nhas become in short supply lately - explainability. Each rule provides an\nexplanation for the commonality of all the texts it clusters together.\n  We present an extensive evaluation of the usefulness of these rules in\nidentifying target categories, as well as a user study which assesses their\ninterpretability.", "published": "2020-10-19 13:07:15", "link": "http://arxiv.org/abs/2010.09459v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "End-to-End Text-to-Speech using Latent Duration based on VQ-VAE", "abstract": "Explicit duration modeling is a key to achieving robust and efficient\nalignment in text-to-speech synthesis (TTS). We propose a new TTS framework\nusing explicit duration modeling that incorporates duration as a discrete\nlatent variable to TTS and enables joint optimization of whole modules from\nscratch. We formulate our method based on conditional VQ-VAE to handle discrete\nduration in a variational autoencoder and provide a theoretical explanation to\njustify our method. In our framework, a connectionist temporal classification\n(CTC) -based force aligner acts as the approximate posterior, and\ntext-to-duration works as the prior in the variational autoencoder. We\nevaluated our proposed method with a listening test and compared it with other\nTTS methods based on soft-attention or explicit duration modeling. The results\nshowed that our systems rated between soft-attention-based methods\n(Transformer-TTS, Tacotron2) and explicit duration modeling-based methods\n(Fastspeech).", "published": "2020-10-19 15:34:49", "link": "http://arxiv.org/abs/2010.09602v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adversarial Training for Code Retrieval with Question-Description\n  Relevance Regularization", "abstract": "Code retrieval is a key task aiming to match natural and programming\nlanguages. In this work, we propose adversarial learning for code retrieval,\nthat is regularized by question-description relevance. First, we adapt a simple\nadversarial learning technique to generate difficult code snippets given the\ninput question, which can help the learning of code retrieval that faces\nbi-modal and data-scarce challenges. Second, we propose to leverage\nquestion-description relevance to regularize adversarial learning, such that a\ngenerated code snippet should contribute more to the code retrieval training\nloss, only if its paired natural language description is predicted to be less\nrelevant to the user given question. Experiments on large-scale code retrieval\ndatasets of two programming languages show that our adversarial learning method\nis able to improve the performance of state-of-the-art models. Moreover, using\nan additional duplicate question prediction model to regularize adversarial\nlearning further improves the performance, and this is more effective than\nusing the duplicated questions in strong multi-task learning baselines", "published": "2020-10-19 19:32:03", "link": "http://arxiv.org/abs/2010.09803v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.PL"], "primary_category": "cs.CL"}
{"title": "ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular\n  Property Prediction", "abstract": "GNNs and chemical fingerprints are the predominant approaches to representing\nmolecules for property prediction. However, in NLP, transformers have become\nthe de-facto standard for representation learning thanks to their strong\ndownstream task transfer. In parallel, the software ecosystem around\ntransformers is maturing rapidly, with libraries like HuggingFace and BertViz\nenabling streamlined training and introspection. In this work, we make one of\nthe first attempts to systematically evaluate transformers on molecular\nproperty prediction tasks via our ChemBERTa model. ChemBERTa scales well with\npretraining dataset size, offering competitive downstream performance on\nMoleculeNet and useful attention-based visualization modalities. Our results\nsuggest that transformers offer a promising avenue of future work for molecular\nrepresentation learning and property prediction. To facilitate these efforts,\nwe release a curated dataset of 77M SMILES from PubChem suitable for\nlarge-scale self-supervised pretraining.", "published": "2020-10-19 21:41:41", "link": "http://arxiv.org/abs/2010.09885v2", "categories": ["cs.LG", "cs.CL", "physics.chem-ph", "q-bio.BM", "I.2.7; I.2.1; J.2; J.3"], "primary_category": "cs.LG"}
{"title": "ColloQL: Robust Cross-Domain Text-to-SQL Over Search Queries", "abstract": "Translating natural language utterances to executable queries is a helpful\ntechnique in making the vast amount of data stored in relational databases\naccessible to a wider range of non-tech-savvy end users. Prior work in this\narea has largely focused on textual input that is linguistically correct and\nsemantically unambiguous. However, real-world user queries are often succinct,\ncolloquial, and noisy, resembling the input of a search engine. In this work,\nwe introduce data augmentation techniques and a sampling-based content-aware\nBERT model (ColloQL) to achieve robust text-to-SQL modeling over natural\nlanguage search (NLS) questions. Due to the lack of evaluation data, we curate\na new dataset of NLS questions and demonstrate the efficacy of our approach.\nColloQL's superior performance extends to well-formed text, achieving 84.9%\n(logical) and 90.7% (execution) accuracy on the WikiSQL dataset, making it, to\nthe best of our knowledge, the highest performing model that does not use\nexecution guided decoding.", "published": "2020-10-19 23:53:17", "link": "http://arxiv.org/abs/2010.09927v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages", "abstract": "This work presents a seemingly simple but effective technique to improve\nlow-resource ASR systems for phonetic languages. By identifying sets of\nacoustically similar graphemes in these languages, we first reduce the output\nalphabet of the ASR system using linguistically meaningful reductions and then\nreconstruct the original alphabet using a standalone module. We demonstrate\nthat this lessens the burden and improves the performance of low-resource\nend-to-end ASR systems (because only reduced-alphabet predictions are needed)\nand that it is possible to design a very simple but effective reconstruction\nmodule that recovers sequences in the original alphabet from sequences in the\nreduced alphabet. We present a finite state transducer-based reconstruction\nmodule that operates on the 1-best ASR hypothesis in the reduced alphabet. We\ndemonstrate the efficacy of our proposed technique using ASR systems for two\nIndian languages, Gujarati and Telugu. With access to only 10 hrs of speech\ndata, we obtain relative WER reductions of up to 7% compared to systems that do\nnot use any reduction.", "published": "2020-10-19 08:59:58", "link": "http://arxiv.org/abs/2010.09322v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Learnable Spectro-temporal Receptive Fields for Robust Voice Type\n  Discrimination", "abstract": "Voice Type Discrimination (VTD) refers to discrimination between regions in a\nrecording where speech was produced by speakers that are physically within\nproximity of the recording device (\"Live Speech\") from speech and other types\nof audio that were played back such as traffic noise and television broadcasts\n(\"Distractor Audio\"). In this work, we propose a deep-learning-based VTD system\nthat features an initial layer of learnable spectro-temporal receptive fields\n(STRFs). Our approach is also shown to provide very strong performance on a\nsimilar spoofing detection task in the ASVspoof 2019 challenge. We evaluate our\napproach on a new standardized VTD database that was collected to support\nresearch in this area. In particular, we study the effect of using learnable\nSTRFs compared to static STRFs or unconstrained kernels. We also show that our\nsystem consistently improves a competitive baseline system across a wide range\nof signal-to-noise ratios on spoofing detection in the presence of VTD\ndistractor noise.", "published": "2020-10-19 00:29:02", "link": "http://arxiv.org/abs/2010.09151v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Multi-channel target speech extraction with channel decorrelation and\n  target speaker adaptation", "abstract": "The end-to-end approaches for single-channel target speech extraction have\nattracted widespread attention. However, the studies for end-to-end\nmulti-channel target speech extraction are still relatively limited. In this\nwork, we propose two methods for exploiting the multi-channel spatial\ninformation to extract the target speech. The first one is using a target\nspeech adaptation layer in a parallel encoder architecture. The second one is\ndesigning a channel decorrelation mechanism to extract the inter-channel\ndifferential information to enhance the multi-channel encoder representation.\nWe compare the proposed methods with two strong state-of-the-art baselines.\nExperimental results on the multi-channel reverberant WSJ0 2-mix dataset\ndemonstrate that our proposed methods achieve up to 11.2% and 11.5% relative\nimprovements in SDR and SiSDR respectively, which are the best reported results\non this task to the best of our knowledge.", "published": "2020-10-19 03:30:02", "link": "http://arxiv.org/abs/2010.09191v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "DiDiSpeech: A Large Scale Mandarin Speech Corpus", "abstract": "This paper introduces a new open-sourced Mandarin speech corpus, called\nDiDiSpeech. It consists of about 800 hours of speech data at 48kHz sampling\nrate from 6000 speakers and the corresponding texts. All speech data in the\ncorpus is recorded in quiet environment and is suitable for various speech\nprocessing tasks, such as voice conversion, multi-speaker text-to-speech and\nautomatic speech recognition. We conduct experiments with multiple speech tasks\nand evaluate the performance, showing that it is promising to use the corpus\nfor both academic research and practical application. The corpus is available\nat https://outreach.didichuxing.com/research/opendata/.", "published": "2020-10-19 07:38:36", "link": "http://arxiv.org/abs/2010.09275v4", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "BIRD: Big Impulse Response Dataset", "abstract": "This paper introduces BIRD, the Big Impulse Response Dataset. This open\ndataset consists of 100,000 multichannel room impulse responses (RIRs)\ngenerated from simulations using the Image Method, making it the largest\nmultichannel open dataset currently available. These RIRs can be used toperform\nefficient online data augmentation for scenarios that involve two microphones\nand multiple sound sources. The paper also introduces use cases to illustrate\nhow BIRD can perform data augmentation with existing speech corpora.", "published": "2020-10-19 23:55:48", "link": "http://arxiv.org/abs/2010.09930v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Attention-based scaling adaptation for target speech extraction", "abstract": "The target speech extraction has attracted widespread attention in recent\nyears. In this work, we focus on investigating the dynamic interaction between\ndifferent mixtures and the target speaker to exploit the discriminative target\nspeaker clues. We propose a special attention mechanism without introducing any\nadditional parameters in a scaling adaptation layer to better adapt the network\ntowards extracting the target speech. Furthermore, by introducing a mixture\nembedding matrix pooling method, our proposed attention-based scaling\nadaptation (ASA) can exploit the target speaker clues in a more efficient way.\nExperimental results on the spatialized reverberant WSJ0 2-mix dataset\ndemonstrate that the proposed method can improve the performance of the target\nspeech extraction effectively. Furthermore, we find that under the same network\nconfigurations, the ASA in a single-channel condition can achieve competitive\nperformance gains as that achieved from two-channel mixtures with\ninter-microphone phase difference (IPD) features.", "published": "2020-10-19 03:36:01", "link": "http://arxiv.org/abs/2010.10923v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Ensemble Chinese End-to-End Spoken Language Understanding for Abnormal\n  Event Detection from audio stream", "abstract": "Conventional spoken language understanding (SLU) consist of two stages, the\nfirst stage maps speech to text by automatic speech recognition (ASR), and the\nsecond stage maps text to intent by natural language understanding (NLU).\nEnd-to-end SLU maps speech directly to intent through a single deep learning\nmodel. Previous end-to-end SLU models are primarily used for English\nenvironment due to lacking large scale SLU dataset in Chines, and use only one\nASR model to extract features from speech. With the help of Kuaishou\ntechnology, a large scale SLU dataset in Chinese is collected to detect\nabnormal event in their live audio stream. Based on this dataset, this paper\nproposed a ensemble end-to-end SLU model used for Chinese environment. This\nensemble SLU models extracted hierarchies features using multiple pre-trained\nASR models, leading to better representation of phoneme level and word level\ninformation. This proposed approached achieve 9.7% increase of accuracy\ncompared to previous end-to-end SLU model.", "published": "2020-10-19 05:59:14", "link": "http://arxiv.org/abs/2010.09235v2", "categories": ["cs.MM", "cs.LG", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Fast accuracy estimation of deep learning based multi-class musical\n  source separation", "abstract": "Music source separation represents the task of extracting all the instruments\nfrom a given song. Recent breakthroughs on this challenge have gravitated\naround a single dataset, MUSDB, only limited to four instrument classes. Larger\ndatasets and more instruments are costly and time-consuming in collecting data\nand training deep neural networks (DNNs). In this work, we propose a fast\nmethod to evaluate the separability of instruments in any dataset without\ntraining and tuning a DNN. This separability measure helps to select\nappropriate samples for the efficient training of neural networks. Based on the\noracle principle with an ideal ratio mask, our approach is an excellent proxy\nto estimate the separation performances of state-of-the-art deep learning\napproaches such as TasNet or Open-Unmix. Our results contribute to revealing\ntwo essential points for audio source separation: 1) the ideal ratio mask,\nalthough light and straightforward, provides an accurate measure of the audio\nseparability performance of recent neural nets, and 2) new end-to-end learning\nmethods such as Tasnet, that operate directly on waveforms, are, in fact,\ninternally building a Time-Frequency (TF) representation, so that they\nencounter the same limitations as the TF based-methods when separating audio\npattern overlapping in the TF plane.", "published": "2020-10-19 13:05:08", "link": "http://arxiv.org/abs/2010.09453v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CLAR: Contrastive Learning of Auditory Representations", "abstract": "Learning rich visual representations using contrastive self-supervised\nlearning has been extremely successful. However, it is still a major question\nwhether we could use a similar approach to learn superior auditory\nrepresentations. In this paper, we expand on prior work (SimCLR) to learn\nbetter auditory representations. We (1) introduce various data augmentations\nsuitable for auditory data and evaluate their impact on predictive performance,\n(2) show that training with time-frequency audio features substantially\nimproves the quality of the learned representations compared to raw signals,\nand (3) demonstrate that training with both supervised and contrastive losses\nsimultaneously improves the learned representations compared to self-supervised\npre-training followed by supervised fine-tuning. We illustrate that by\ncombining all these methods and with substantially less labeled data, our\nframework (CLAR) achieves significant improvement on prediction performance\ncompared to supervised approach. Moreover, compared to self-supervised\napproach, our framework converges faster with significantly better\nrepresentations.", "published": "2020-10-19 14:15:31", "link": "http://arxiv.org/abs/2010.09542v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MicAugment: One-shot Microphone Style Transfer", "abstract": "A crucial aspect for the successful deployment of audio-based models\n\"in-the-wild\" is the robustness to the transformations introduced by\nheterogeneous acquisition conditions. In this work, we propose a method to\nperform one-shot microphone style transfer. Given only a few seconds of audio\nrecorded by a target device, MicAugment identifies the transformations\nassociated to the input acquisition pipeline and uses the learned\ntransformations to synthesize audio as if it were recorded under the same\nconditions as the target audio. We show that our method can successfully apply\nthe style transfer to real audio and that it significantly increases model\nrobustness when used as data augmentation in the downstream tasks.", "published": "2020-10-19 16:56:04", "link": "http://arxiv.org/abs/2010.09658v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Multi-Window Data Augmentation Approach for Speech Emotion Recognition", "abstract": "We present a Multi-Window Data Augmentation (MWA-SER) approach for speech\nemotion recognition. MWA-SER is a unimodal approach that focuses on two key\nconcepts; designing the speech augmentation method and building the deep\nlearning model to recognize the underlying emotion of an audio signal. Our\nproposed multi-window augmentation approach generates additional data samples\nfrom the speech signal by employing multiple window sizes in the audio feature\nextraction process. We show that our augmentation method, combined with a deep\nlearning model, improves speech emotion recognition performance. We evaluate\nthe performance of our approach on three benchmark datasets: IEMOCAP, SAVEE,\nand RAVDESS. We show that the multi-window model improves the SER performance\nand outperforms a single-window model. The notion of finding the best window\nsize is an essential step in audio feature extraction. We perform extensive\nexperimental evaluations to find the best window choice and explore the\nwindowing effect for SER analysis.", "published": "2020-10-19 22:15:03", "link": "http://arxiv.org/abs/2010.09895v4", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
