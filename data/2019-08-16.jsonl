{"title": "Quoref: A Reading Comprehension Dataset with Questions Requiring\n  Coreferential Reasoning", "abstract": "Machine comprehension of texts longer than a single sentence often requires\ncoreference resolution. However, most current reading comprehension benchmarks\ndo not contain complex coreferential phenomena and hence fail to evaluate the\nability of models to resolve coreference. We present a new crowdsourced dataset\ncontaining more than 24K span-selection questions that require resolving\ncoreference among entities in over 4.7K English paragraphs from Wikipedia.\nObtaining questions focused on such phenomena is challenging, because it is\nhard to avoid lexical cues that shortcut complex reasoning. We deal with this\nissue by using a strong baseline model as an adversary in the crowdsourcing\nloop, which helps crowdworkers avoid writing questions with exploitable surface\ncues. We show that state-of-the-art reading comprehension models perform\nsignificantly worse than humans on this benchmark---the best model performance\nis 70.5 F1, while the estimated human performance is 93.4 F1.", "published": "2019-08-16 00:59:44", "link": "http://arxiv.org/abs/1908.05803v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition for Nepali Language", "abstract": "Named Entity Recognition have been studied for different languages like\nEnglish, German, Spanish and many others but no study have focused on Nepali\nlanguage. In this paper we propose a neural based Nepali NER using latest\nstate-of-the-art architecture based on grapheme-level which doesn't require any\nhand-crafted features and no data pre-processing. Our novel neural based model\ngained relative improvement of 33% to 50% compared to feature based SVM model\nand up to 10% improvement over state-of-the-art neural based model developed\nfor languages beside Nepali.", "published": "2019-08-16 03:14:43", "link": "http://arxiv.org/abs/1908.05828v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pushing the Limits of Low-Resource Morphological Inflection", "abstract": "Recent years have seen exceptional strides in the task of automatic\nmorphological inflection generation. However, for a long tail of languages the\nnecessary resources are hard to come by, and state-of-the-art neural methods\nthat work well under higher resource settings perform poorly in the face of a\npaucity of data. In response, we propose a battery of improvements that greatly\nimprove performance under such low-resource conditions. First, we present a\nnovel two-step attention architecture for the inflection decoder. In addition,\nwe investigate the effects of cross-lingual transfer from single and multiple\nlanguages, as well as monolingual data hallucination. The macro-averaged\naccuracy of our models outperforms the state-of-the-art by 15 percentage\npoints. Also, we identify the crucial factors for success with cross-lingual\ntransfer for morphological inflection: typological similarity and a common\nrepresentation across languages.", "published": "2019-08-16 04:15:32", "link": "http://arxiv.org/abs/1908.05838v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sketch-Driven Regular Expression Generation from Natural Language and\n  Examples", "abstract": "Recent systems for converting natural language descriptions into regular\nexpressions (regexes) have achieved some success, but typically deal with\nshort, formulaic text and can only produce simple regexes. Realworld regexes\nare complex, hard to describe with brief sentences, and sometimes require\nexamples to fully convey the user's intent. We present a framework for regex\nsynthesis in this setting where both natural language (NL) and examples are\navailable. First, a semantic parser (either grammar-based or neural) maps the\nnatural language description into an intermediate sketch, which is an\nincomplete regex containing holes to denote missing components. Then a program\nsynthesizer searches over the regex space defined by the sketch and finds a\nregex that is consistent with the given string examples. Our semantic parser\ncan be trained purely from weak supervision based on correctness of the\nsynthesized regex, or it can leverage heuristically-derived sketches. We\nevaluate on two prior datasets (Kushman and Barzilay, 2013; Locascio et al.,\n2016) and a real-world dataset from Stack Overflow. Our system achieves\nstate-of-the-art performance on the prior datasets and solves 57% of the\nreal-world dataset, which existing neural systems completely fail on.", "published": "2019-08-16 05:09:57", "link": "http://arxiv.org/abs/1908.05848v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning Over Paragraph Effects in Situations", "abstract": "A key component of successfully reading a passage of text is the ability to\napply knowledge gained from the passage to a new situation. In order to\nfacilitate progress on this kind of reading, we present ROPES, a challenging\nbenchmark for reading comprehension targeting Reasoning Over Paragraph Effects\nin Situations. We target expository language describing causes and effects\n(e.g., \"animal pollinators increase efficiency of fertilization in flowers\"),\nas they have clear implications for new situations. A system is presented a\nbackground passage containing at least one of these relations, a novel\nsituation that uses this background, and questions that require reasoning about\neffects of the relationships in the background passage in the context of the\nsituation. We collect background passages from science textbooks and Wikipedia\nthat contain such phenomena, and ask crowd workers to author situations,\nquestions, and answers, resulting in a 14,322 question dataset. We analyze the\nchallenges of this task and evaluate the performance of state-of-the-art\nreading comprehension models. The best model performs only slightly better than\nrandomly guessing an answer of the correct type, at 61.6% F1, well below the\nhuman performance of 89.0%.", "published": "2019-08-16 05:36:04", "link": "http://arxiv.org/abs/1908.05852v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-Shot Dialogue Generation Without Annotated Data: A Transfer Learning\n  Approach", "abstract": "Learning with minimal data is one of the key challenges in the development of\npractical, production-ready goal-oriented dialogue systems. In a real-world\nenterprise setting where dialogue systems are developed rapidly and are\nexpected to work robustly for an ever-growing variety of domains, products, and\nscenarios, efficient learning from a limited number of examples becomes\nindispensable.\n  In this paper, we introduce a technique to achieve state-of-the-art dialogue\ngeneration performance in a few-shot setup, without using any annotated data.\nWe do this by leveraging background knowledge from a larger, more highly\nrepresented dialogue source --- namely, the MetaLWOz dataset. We evaluate our\nmodel on the Stanford Multi-Domain Dialogue Dataset, consisting of human-human\ngoal-oriented dialogues in in-car navigation, appointment scheduling, and\nweather information domains.\n  We show that our few-shot approach achieves state-of-the art results on that\ndataset by consistently outperforming the previous best model in terms of BLEU\nand Entity F1 scores, while being more data-efficient by not requiring any data\nannotation.", "published": "2019-08-16 05:48:41", "link": "http://arxiv.org/abs/1908.05854v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "BERT-Based Multi-Head Selection for Joint Entity-Relation Extraction", "abstract": "In this paper, we report our method for the Information Extraction task in\n2019 Language and Intelligence Challenge. We incorporate BERT into the\nmulti-head selection framework for joint entity-relation extraction. This model\nextends existing approaches from three perspectives. First, BERT is adopted as\na feature extraction layer at the bottom of the multi-head selection framework.\nWe further optimize BERT by introducing a semantic-enhanced task during BERT\npre-training. Second, we introduce a large-scale Baidu Baike corpus for entity\nrecognition pre-training, which is of weekly supervised learning since there is\nno actual named entity label. Third, soft label embedding is proposed to\neffectively transmit information between entity recognition and relation\nextraction. Combining these three contributions, we enhance the information\nextracting ability of the multi-head selection model and achieve F1-score 0.876\non testset-1 with a single model. By ensembling four variants of our model, we\nfinally achieve F1 score 0.892 (1st place) on testset-1 and F1 score 0.8924\n(2nd place) on testset-2.", "published": "2019-08-16 09:29:43", "link": "http://arxiv.org/abs/1908.05908v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Word and Subword Units in Unsupervised Machine Translation\n  Using Language Model Rescoring", "abstract": "This paper describes CAiRE's submission to the unsupervised machine\ntranslation track of the WMT'19 news shared task from German to Czech. We\nleverage a phrase-based statistical machine translation (PBSMT) model and a\npre-trained language model to combine word-level neural machine translation\n(NMT) and subword-level NMT models without using any parallel data. We propose\nto solve the morphological richness problem of languages by training byte-pair\nencoding (BPE) embeddings for German and Czech separately, and they are aligned\nusing MUSE (Conneau et al., 2018). To ensure the fluency and consistency of\ntranslations, a rescoring mechanism is proposed that reuses the pre-trained\nlanguage model to select the translation candidates generated through beam\nsearch. Moreover, a series of pre-processing and post-processing approaches are\napplied to improve the quality of final translations.", "published": "2019-08-16 10:44:25", "link": "http://arxiv.org/abs/1908.05925v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Sequence-to-Sequence Models Perceive Language Styles?", "abstract": "Style is ubiquitous in our daily language uses, while what is language style\nto learning machines? In this paper, by exploiting the second-order statistics\nof semantic vectors of different corpora, we present a novel perspective on\nthis question via style matrix, i.e. the covariance matrix of semantic vectors,\nand explain for the first time how Sequence-to-Sequence models encode style\ninformation innately in its semantic vectors. As an application, we devise a\nlearning-free text style transfer algorithm, which explicitly constructs a pair\nof transfer operators from the style matrices for style transfer. Moreover, our\nalgorithm is also observed to be flexible enough to transfer out-of-domain\nsentences. Extensive experimental evidence justifies the informativeness of\nstyle matrix and the competitive performance of our proposed style transfer\nalgorithm with the state-of-the-art methods.", "published": "2019-08-16 12:38:05", "link": "http://arxiv.org/abs/1908.05947v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Densely Connected Graph Convolutional Networks for Graph-to-Sequence\n  Learning", "abstract": "We focus on graph-to-sequence learning, which can be framed as transducing\ngraph structures to sequences for text generation. To capture structural\ninformation associated with graphs, we investigate the problem of encoding\ngraphs using graph convolutional networks (GCNs). Unlike various existing\napproaches where shallow architectures were used for capturing local structural\ninformation only, we introduce a dense connection strategy, proposing a novel\nDensely Connected Graph Convolutional Networks (DCGCNs). Such a deep\narchitecture is able to integrate both local and non-local features to learn a\nbetter structural representation of a graph. Our model outperforms the\nstate-of-the-art neural models significantly on AMRto-text generation and\nsyntax-based neural machine translation.", "published": "2019-08-16 12:58:16", "link": "http://arxiv.org/abs/1908.05957v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simplify the Usage of Lexicon in Chinese NER", "abstract": "Recently, many works have tried to augment the performance of Chinese named\nentity recognition (NER) using word lexicons. As a representative, Lattice-LSTM\n(Zhang and Yang, 2018) has achieved new benchmark results on several public\nChinese NER datasets. However, Lattice-LSTM has a complex model architecture.\nThis limits its application in many industrial areas where real-time NER\nresponses are needed.\n  In this work, we propose a simple but effective method for incorporating the\nword lexicon into the character representations. This method avoids designing a\ncomplicated sequence modeling architecture, and for any neural NER model, it\nrequires only subtle adjustment of the character representation layer to\nintroduce the lexicon information. Experimental studies on four benchmark\nChinese NER datasets show that our method achieves an inference speed up to\n6.15 times faster than those of state-ofthe-art methods, along with a better\nperformance. The experimental results also show that the proposed method can be\neasily incorporated with pre-trained models like BERT.", "published": "2019-08-16 13:35:24", "link": "http://arxiv.org/abs/1908.05969v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transductive Auxiliary Task Self-Training for Neural Multi-Task Models", "abstract": "Multi-task learning and self-training are two common ways to improve a\nmachine learning model's performance in settings with limited training data.\nDrawing heavily on ideas from those two approaches, we suggest transductive\nauxiliary task self-training: training a multi-task model on (i) a combination\nof main and auxiliary task training data, and (ii) test instances with\nauxiliary task labels which a single-task version of the model has previously\ngenerated. We perform extensive experiments on 86 combinations of languages and\ntasks. Our results are that, on average, transductive auxiliary task\nself-training improves absolute accuracy by up to 9.56% over the pure\nmulti-task model for dependency relation tagging and by up to 13.03% for\nsemantic tagging.", "published": "2019-08-16 19:31:13", "link": "http://arxiv.org/abs/1908.06136v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UDS--DFKI Submission to the WMT2019 Similar Language Translation Shared\n  Task", "abstract": "In this paper we present the UDS-DFKI system submitted to the Similar\nLanguage Translation shared task at WMT 2019. The first edition of this shared\ntask featured data from three pairs of similar languages: Czech and Polish,\nHindi and Nepali, and Portuguese and Spanish. Participants could choose to\nparticipate in any of these three tracks and submit system outputs in any\ntranslation direction. We report the results obtained by our system in\ntranslating from Czech to Polish and comment on the impact of out-of-domain\ntest data in the performance of our system. UDS-DFKI achieved competitive\nperformance ranking second among ten teams in Czech to Polish translation.", "published": "2019-08-16 19:36:57", "link": "http://arxiv.org/abs/1908.06138v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving CAT Tools in the Translation Workflow: New Approaches and\n  Evaluation", "abstract": "This paper describes strategies to improve an existing web-based\ncomputer-aided translation (CAT) tool entitled CATaLog Online. CATaLog Online\nprovides a post-editing environment with simple yet helpful project management\ntools. It offers translation suggestions from translation memories (TM),\nmachine translation (MT), and automatic post-editing (APE) and records detailed\nlogs of post-editing activities. To test the new approaches proposed in this\npaper, we carried out a user study on an English--German translation task using\nCATaLog Online. User feedback revealed that the users preferred using CATaLog\nOnline over existing CAT tools in some respects, especially by selecting the\noutput of the MT system and taking advantage of the color scheme for TM\nsuggestions.", "published": "2019-08-16 19:38:39", "link": "http://arxiv.org/abs/1908.06140v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Transference Architecture for Automatic Post-Editing", "abstract": "In automatic post-editing (APE) it makes sense to condition post-editing (pe)\ndecisions on both the source (src) and the machine translated text (mt) as\ninput. This has led to multi-source encoder based APE approaches. A research\nchallenge now is the search for architectures that best support the capture,\npreparation and provision of src and mt information and its integration with pe\ndecisions. In this paper we present a new multi-source APE model, called\ntransference. Unlike previous approaches, it (i) uses a transformer encoder\nblock for src, (ii) followed by a decoder block, but without masking for\nself-attention on mt, which effectively acts as second encoder combining src ->\nmt, and (iii) feeds this representation into a final decoder block generating\npe. Our model outperforms the state-of-the-art by 1 BLEU point on the WMT 2016,\n2017, and 2018 English--German APE shared tasks (PBSMT and NMT). We further\ninvestigate the importance of our newly introduced second encoder and find that\na too small amount of layers does hurt the performance, while reducing the\nnumber of layers of the decoder does not matter much.", "published": "2019-08-16 20:09:11", "link": "http://arxiv.org/abs/1908.06151v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Conceptual-Contextual Embeddings for Medical Text", "abstract": "External knowledge is often useful for natural language understanding tasks.\nWe introduce a contextual text representation model called\nConceptual-Contextual (CC) embeddings, which incorporates structured knowledge\ninto text representations. Unlike entity embedding methods, our approach\nencodes a knowledge graph into a context model. CC embeddings can be easily\nreused for a wide range of tasks just like pre-trained language models. Our\nmodel effectively encodes the huge UMLS database by leveraging semantic\ngeneralizability. Experiments on electronic health records (EHRs) and medical\ntext processing benchmarks showed our model gives a major boost to the\nperformance of supervised medical NLP tasks.", "published": "2019-08-16 23:27:25", "link": "http://arxiv.org/abs/1908.06203v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PubLayNet: largest dataset ever for document layout analysis", "abstract": "Recognizing the layout of unstructured digital documents is an important step\nwhen parsing the documents into structured machine-readable format for\ndownstream applications. Deep neural networks that are developed for computer\nvision have been proven to be an effective method to analyze layout of document\nimages. However, document layout datasets that are currently publicly available\nare several magnitudes smaller than established computing vision datasets.\nModels have to be trained by transfer learning from a base model that is\npre-trained on a traditional computer vision dataset. In this paper, we develop\nthe PubLayNet dataset for document layout analysis by automatically matching\nthe XML representations and the content of over 1 million PDF articles that are\npublicly available on PubMed Central. The size of the dataset is comparable to\nestablished computer vision datasets, containing over 360 thousand document\nimages, where typical document layout elements are annotated. The experiments\ndemonstrate that deep neural networks trained on PubLayNet accurately recognize\nthe layout of scientific articles. The pre-trained models are also a more\neffective base mode for transfer learning on a different document domain. We\nrelease the dataset (https://github.com/ibm-aur-nlp/PubLayNet) to support\ndevelopment and evaluation of more advanced models for document layout\nanalysis.", "published": "2019-08-16 00:40:08", "link": "http://arxiv.org/abs/1908.07836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dually Interactive Matching Network for Personalized Response Selection\n  in Retrieval-Based Chatbots", "abstract": "This paper proposes a dually interactive matching network (DIM) for\npresenting the personalities of dialogue agents in retrieval-based chatbots.\nThis model develops from the interactive matching network (IMN) which models\nthe matching degree between a context composed of multiple utterances and a\nresponse candidate. Compared with previous persona fusion approaches which\nenhance the representation of a context by calculating its similarity with a\ngiven persona, the DIM model adopts a dual matching architecture, which\nperforms interactive matching between responses and contexts and between\nresponses and personas respectively for ranking response candidates.\nExperimental results on PERSONA-CHAT dataset show that the DIM model\noutperforms its baseline model, i.e., IMN with persona fusion, by a margin of\n14.5% and outperforms the current state-of-the-art model by a margin of 27.7%\nin terms of top-1 accuracy hits@1.", "published": "2019-08-16 06:15:18", "link": "http://arxiv.org/abs/1908.05859v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bidirectional Context-Aware Hierarchical Attention Network for Document\n  Understanding", "abstract": "The Hierarchical Attention Network (HAN) has made great strides, but it\nsuffers a major limitation: at level 1, each sentence is encoded in complete\nisolation. In this work, we propose and compare several modifications of HAN in\nwhich the sentence encoder is able to make context-aware attentional decisions\n(CAHAN). Furthermore, we propose a bidirectional document encoder that\nprocesses the document forwards and backwards, using the preceding and\nfollowing sentences as context. Experiments on three large-scale sentiment and\ntopic classification datasets show that the bidirectional version of CAHAN\noutperforms HAN everywhere, with only a modest increase in computation time.\nWhile results are promising, we expect the superiority of CAHAN to be even more\nevident on tasks requiring a deeper understanding of the input documents, such\nas abstractive summarization. Code is publicly available.", "published": "2019-08-16 15:20:04", "link": "http://arxiv.org/abs/1908.06006v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatically Identifying Comparator Groups on Twitter for Digital\n  Epidemiology of Pregnancy Outcomes", "abstract": "Despite the prevalence of adverse pregnancy outcomes such as miscarriage,\nstillbirth, birth defects, and preterm birth, their causes are largely unknown.\nWe seek to advance the use of social media for observational studies of\npregnancy outcomes by developing a natural language processing pipeline for\nautomatically identifying users from which to select comparator groups on\nTwitter. We annotated 2361 tweets by users who have announced their pregnancy\non Twitter, which were used to train and evaluate supervised machine learning\nalgorithms as a basis for automatically detecting women who have reported that\ntheir pregnancy had reached term and their baby was born at a normal weight.\nUpon further processing the tweet-level predictions of a majority voting-based\nensemble classifier, the pipeline achieved a user-level F1-score of 0.933, with\na precision of 0.947 and a recall of 0.920. Our pipeline will be deployed to\nidentify large comparator groups for studying pregnancy outcomes on Twitter.", "published": "2019-08-16 15:21:34", "link": "http://arxiv.org/abs/1908.06015v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Few-shot Text Classification with Distributional Signatures", "abstract": "In this paper, we explore meta-learning for few-shot text classification.\nMeta-learning has shown strong performance in computer vision, where low-level\npatterns are transferable across learning tasks. However, directly applying\nthis approach to text is challenging--lexical features highly informative for\none task may be insignificant for another. Thus, rather than learning solely\nfrom words, our model also leverages their distributional signatures, which\nencode pertinent word occurrence patterns. Our model is trained within a\nmeta-learning framework to map these signatures into attention scores, which\nare then used to weight the lexical representations of words. We demonstrate\nthat our model consistently outperforms prototypical networks learned on\nlexical knowledge (Snell et al., 2017) in both few-shot text classification and\nrelation classification by a significant margin across six benchmark datasets\n(20.0% on average in 1-shot classification).", "published": "2019-08-16 15:46:14", "link": "http://arxiv.org/abs/1908.06039v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CFO: A Framework for Building Production NLP Systems", "abstract": "This paper introduces a novel orchestration framework, called CFO\n(COMPUTATION FLOW ORCHESTRATOR), for building, experimenting with, and\ndeploying interactive NLP (Natural Language Processing) and IR (Information\nRetrieval) systems to production environments. We then demonstrate a question\nanswering system built using this framework which incorporates state-of-the-art\nBERT based MRC (Machine Reading Comprehension) with IR components to enable\nend-to-end answer retrieval. Results from the demo system are shown to be high\nquality in both academic and industry domain specific settings. Finally, we\ndiscuss best practices when (pre-)training BERT based MRC models for production\nsystems.", "published": "2019-08-16 18:19:59", "link": "http://arxiv.org/abs/1908.06121v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Empirical Evaluation of Multi-task Learning in Deep Neural Networks for\n  Natural Language Processing", "abstract": "Multi-Task Learning (MTL) aims at boosting the overall performance of each\nindividual task by leveraging useful information contained in multiple related\ntasks. It has shown great success in natural language processing (NLP).\nCurrently, a number of MLT architectures and learning mechanisms have been\nproposed for various NLP tasks. However, there is no systematic exploration and\ncomparison of different MLT architectures and learning mechanisms for their\nstrong performance in-depth. In this paper, we conduct a thorough examination\nof typical MTL methods on a broad range of representative NLP tasks. Our\nprimary goal is to understand the merits and demerits of existing MTL methods\nin NLP tasks, thus devising new hybrid architectures intended to combine their\nstrengths.", "published": "2019-08-16 03:16:40", "link": "http://arxiv.org/abs/1908.07820v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Attending to Future Tokens For Bidirectional Sequence Generation", "abstract": "Neural sequence generation is typically performed token-by-token and\nleft-to-right. Whenever a token is generated only previously produced tokens\nare taken into consideration. In contrast, for problems such as sequence\nclassification, bidirectional attention, which takes both past and future\ntokens into consideration, has been shown to perform much better. We propose to\nmake the sequence generation process bidirectional by employing special\nplaceholder tokens. Treated as a node in a fully connected graph, a placeholder\ntoken can take past and future tokens into consideration when generating the\nactual output token. We verify the effectiveness of our approach experimentally\non two conversational tasks where the proposed bidirectional model outperforms\ncompetitive baselines by a large margin.", "published": "2019-08-16 10:00:45", "link": "http://arxiv.org/abs/1908.05915v2", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Shallow Domain Adaptive Embeddings for Sentiment Analysis", "abstract": "This paper proposes a way to improve the performance of existing algorithms\nfor text classification in domains with strong language semantics. We propose a\ndomain adaptation layer learns weights to combine a generic and a domain\nspecific (DS) word embedding into a domain adapted (DA) embedding. The DA word\nembeddings are then used as inputs to a generic encoder + classifier framework\nto perform a downstream task such as classification. This adaptation layer is\nparticularly suited to datasets that are modest in size, and which are,\ntherefore, not ideal candidates for (re)training a deep neural network\narchitecture. Results on binary and multi-class classification tasks using\npopular encoder architectures, including current state-of-the-art methods (with\nand without the shallow adaptation layer) show the effectiveness of the\nproposed approach.", "published": "2019-08-16 20:25:13", "link": "http://arxiv.org/abs/1908.06082v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text", "abstract": "The recent success of natural language understanding (NLU) systems has been\ntroubled by results highlighting the failure of these models to generalize in a\nsystematic and robust way. In this work, we introduce a diagnostic benchmark\nsuite, named CLUTRR, to clarify some key issues related to the robustness and\nsystematicity of NLU systems. Motivated by classic work on inductive logic\nprogramming, CLUTRR requires that an NLU system infer kinship relations between\ncharacters in short stories. Successful performance on this task requires both\nextracting relationships between entities, as well as inferring the logical\nrules governing these relationships. CLUTRR allows us to precisely measure a\nmodel's ability for systematic generalization by evaluating on held-out\ncombinations of logical rules, and it allows us to evaluate a model's\nrobustness by adding curated noise facts. Our empirical results highlight a\nsubstantial performance gap between state-of-the-art NLU models (e.g., BERT and\nMAC) and a graph neural network model that works directly with symbolic\ninputs---with the graph-based model exhibiting both stronger generalization and\ngreater robustness.", "published": "2019-08-16 21:12:15", "link": "http://arxiv.org/abs/1908.06177v2", "categories": ["cs.LG", "cs.CL", "cs.LO", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CommentsRadar: Dive into Unique Data on All Comments on the Web", "abstract": "We introduce an entity-centric search engineCommentsRadarthatpairs entity\nqueries with articles and user opinions covering a widerange of topics from top\ncommented sites. The engine aggregatesarticles and comments for these articles,\nextracts named entities,links them together and with knowledge base entries,\nperformssentiment analysis, and aggregates the results, aiming to mine\nfortemporal trends and other insights. In this work, we present thegeneral\nengine, discuss the models used for all steps of this pipeline,and introduce\nseveral case studies that discover important insightsfrom online commenting\ndata.", "published": "2019-08-16 13:01:30", "link": "http://arxiv.org/abs/1908.07069v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Sub-Spectrogram Segmentation for Environmental Sound Classification via\n  Convolutional Recurrent Neural Network and Score Level Fusion", "abstract": "Environmental Sound Classification (ESC) is an important and challenging\nproblem, and feature representation is a critical and even decisive factor in\nESC. Feature representation ability directly affects the accuracy of sound\nclassification. Therefore, the ESC performance is heavily dependent on the\neffectiveness of representative features extracted from the environmental\nsounds. In this paper, we propose a subspectrogram segmentation based ESC\nclassification framework. In addition, we adopt the proposed Convolutional\nRecurrent Neural Network (CRNN) and score level fusion to jointly improve the\nclassification accuracy. Extensive truncation schemes are evaluated to find the\noptimal number and the corresponding band ranges of sub-spectrograms. Based on\nthe numerical experiments, the proposed framework can achieve 81.9% ESC\nclassification accuracy on the public dataset ESC-50, which provides 9.1%\naccuracy improvement over traditional baseline schemes.", "published": "2019-08-16 06:39:31", "link": "http://arxiv.org/abs/1908.05863v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Generating Ambisonics Using Audio-Visual Cue for Virtual Reality", "abstract": "Ambisonics i.e., a full-sphere surround sound, is quintessential with\n360-degree visual content to provide a realistic virtual reality (VR)\nexperience. While 360-degree visual content capture gained a tremendous boost\nrecently, the estimation of corresponding spatial sound is still challenging\ndue to the required sound-field microphones or information about the\nsound-source locations. In this paper, we introduce a novel problem of\ngenerating Ambisonics in 360-degree videos using the audio-visual cue. With\nthis aim, firstly, a novel 360-degree audio-visual video dataset of 265 videos\nis introduced with annotated sound-source locations. Secondly, a pipeline is\ndesigned for an automatic Ambisonic estimation problem. Benefiting from the\ndeep learning-based audio-visual feature-embedding and prediction modules, our\npipeline estimates the 3D sound-source locations and further use such locations\nto encode to the B-format. To benchmark our dataset and pipeline, we\nadditionally propose evaluation criteria to investigate the performance using\ndifferent 360-degree input representations. Our results demonstrate the\nefficacy of the proposed pipeline and open up a new area of research in\n360-degree audio-visual analysis for future investigations.", "published": "2019-08-16 14:49:30", "link": "http://arxiv.org/abs/1908.06752v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Survey on Deep Neural Networks in Speech and Vision Systems", "abstract": "This survey presents a review of state-of-the-art deep neural network\narchitectures, algorithms, and systems in vision and speech applications.\nRecent advances in deep artificial neural network algorithms and architectures\nhave spurred rapid innovation and development of intelligent vision and speech\nsystems. With availability of vast amounts of sensor data and cloud computing\nfor processing and training of deep neural networks, and with increased\nsophistication in mobile and embedded technology, the next-generation\nintelligent systems are poised to revolutionize personal and commercial\ncomputing. This survey begins by providing background and evolution of some of\nthe most successful deep learning models for intelligent vision and speech\nsystems to date. An overview of large-scale industrial research and development\nefforts is provided to emphasize future trends and prospects of intelligent\nvision and speech systems. Robust and efficient intelligent systems demand\nlow-latency and high fidelity in resource-constrained hardware platforms such\nas mobile devices, robots, and automobiles. Therefore, this survey also\nprovides a summary of key challenges and recent successes in running deep\nneural networks on hardware-restricted platforms, i.e. within limited memory,\nbattery life, and processing capabilities. Finally, emerging applications of\nvision and speech across disciplines such as affective computing, intelligent\ntransportation, and precision medicine are discussed. To our knowledge, this\npaper provides one of the most comprehensive surveys on the latest developments\nin intelligent vision and speech applications from the perspectives of both\nsoftware and hardware systems. Many of these emerging technologies using deep\nneural networks show tremendous promise to revolutionize research and\ndevelopment for future vision and speech systems.", "published": "2019-08-16 16:40:49", "link": "http://arxiv.org/abs/1908.07656v2", "categories": ["cs.CV", "cs.LG", "cs.NE", "cs.SD", "eess.AS", "eess.SP", "stat.ML"], "primary_category": "cs.CV"}
