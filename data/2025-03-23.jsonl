{"title": "ShED-HD: A Shannon Entropy Distribution Framework for Lightweight Hallucination Detection on Edge Devices", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities on a\nbroad array of NLP tasks, but their tendency to produce\nhallucinations$\\unicode{x2013}$plausible-sounding but factually incorrect\ncontent$\\unicode{x2013}$poses severe challenges in high-stakes domains.\nExisting hallucination detection methods either bear the computational cost of\nmultiple inference passes or sacrifice accuracy for efficiency with single-pass\napproaches, neither of which is ideal in resource-constrained environments such\nas edge devices. We propose the Shannon Entropy Distribution Hallucination\nDetector (ShED-HD), a novel hallucination detection framework that bridges this\ngap by classifying sequence-level entropy patterns using a lightweight BiLSTM\narchitecture with single-headed attention. In contrast to prior approaches,\nShED-HD efficiently detects distinctive uncertainty patterns across entire\noutput sequences, preserving contextual awareness. Through in-depth evaluation\non three datasets (BioASQ, TriviaQA, and Jeopardy Questions), we show that\nShED-HD significantly outperforms other computationally efficient approaches in\nthe out-of-distribution setting, while achieving comparable performance in the\nin-distribution setting. ShED-HD facilitates hallucination detection that is\nlow-cost, accurate, and generalizable, improving the credibility of content\ngenerated by LLMs in resource-constrained environments where trustworthy AI\nfunctionality is crucial.", "published": "2025-03-23 23:47:26", "link": "http://arxiv.org/abs/2503.18242v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mapping Hymns and Organizing Concepts in the Rigveda: Quantitatively Connecting the Vedic Suktas", "abstract": "Accessing and gaining insight into the Rigveda poses a non-trivial challenge\ndue to its extremely ancient Sanskrit language, poetic structure, and large\nvolume of text. By using NLP techniques, this study identified topics and\nsemantic connections of hymns within the Rigveda that were corroborated by\nseven well-known groupings of hymns. The 1,028 suktas (hymns) from the modern\nEnglish translation of the Rigveda by Jamison and Brereton were preprocessed\nand sukta-level embeddings were obtained using, i) a novel adaptation of LSA,\npresented herein, ii) SBERT, and iii) Doc2Vec embeddings. Following an UMAP\ndimension reduction of the vectors, the network of suktas was formed using\nk-nearest neighbours. Then, community detection of topics in the sukta networks\nwas performed with the Louvain, Leiden, and label propagation methods, whose\nstatistical significance of the formed topics were determined using an\nappropriate null distribution. Only the novel adaptation of LSA using the\nLeiden method, had detected sukta topic networks that were significant (z =\n2.726, p < .01) with a modularity score of 0.944. Of the seven famous sukta\ngroupings analyzed (e.g., creation, funeral, water, etc.) the LSA derived\nnetwork was successful in all seven cases, while Doc2Vec was not significant\nand failed to detect the relevant suktas. SBERT detected four of the famous\nsuktas as separate groups, but mistakenly combined three of them into a single\nmixed group. Also, the SBERT network was not statistically significant.", "published": "2025-03-23 22:01:12", "link": "http://arxiv.org/abs/2503.18226v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoupling Angles and Strength in Low-rank Adaptation", "abstract": "Parameter-Efficient FineTuning (PEFT) methods have recently gained\nsignificant popularity thanks to the widespread availability of large-scale\npretrained models. These methods allow for quick adaptation to downstream tasks\nwith minimal computational cost. However, popular finetuning methods such as\nLoRA exhibit limited robustness when it comes to hyperparameter choices or\nextended training regimes, preventing optimal out-of-the-box performance. In\ncontrast, bounded approaches, such as ETHER, provide greater robustness but are\nlimited to extremely low-rank adaptations and fixed-strength transformations,\nreducing their adaptation expressive power. In this work, we propose Decoupled\nLow-rank Adaptation (DeLoRA), a novel finetuning method that normalizes and\nscales learnable low-rank matrices. By bounding the distance of the\ntransformation, DeLoRA effectively decouples the angular learning from the\nadaptation strength, enhancing robustness without compromising performance.\nThrough evaluations on subject-driven image generation, natural language\nunderstanding, and instruction tuning, we show that DeLoRA matches or surpasses\nperformance of competing PEFT methods, while exhibiting stronger robustness.\nCode is available at https://github.com/ExplainableML/DeLoRA.", "published": "2025-03-23 22:00:56", "link": "http://arxiv.org/abs/2503.18225v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "LakotaBERT: A Transformer-based Model for Low Resource Lakota Language", "abstract": "Lakota, a critically endangered language of the Sioux people in North\nAmerica, faces significant challenges due to declining fluency among younger\ngenerations. This paper introduces LakotaBERT, the first large language model\n(LLM) tailored for Lakota, aiming to support language revitalization efforts.\nOur research has two primary objectives: (1) to create a comprehensive Lakota\nlanguage corpus and (2) to develop a customized LLM for Lakota. We compiled a\ndiverse corpus of 105K sentences in Lakota, English, and parallel texts from\nvarious sources, such as books and websites, emphasizing the cultural\nsignificance and historical context of the Lakota language. Utilizing the\nRoBERTa architecture, we pre-trained our model and conducted comparative\nevaluations against established models such as RoBERTa, BERT, and multilingual\nBERT. Initial results demonstrate a masked language modeling accuracy of 51%\nwith a single ground truth assumption, showcasing performance comparable to\nthat of English-based models. We also evaluated the model using additional\nmetrics, such as precision and F1 score, to provide a comprehensive assessment\nof its capabilities. By integrating AI and linguistic methodologies, we aspire\nto enhance linguistic diversity and cultural resilience, setting a valuable\nprecedent for leveraging technology in the revitalization of other endangered\nindigenous languages.", "published": "2025-03-23 21:31:12", "link": "http://arxiv.org/abs/2503.18212v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Topic Trends in COVID-19 Research Literature using Non-Negative Matrix Factorization", "abstract": "In this work, we apply topic modeling using Non-Negative Matrix Factorization\n(NMF) on the COVID-19 Open Research Dataset (CORD-19) to uncover the underlying\nthematic structure and its evolution within the extensive body of COVID-19\nresearch literature. NMF factorizes the document-term matrix into two\nnon-negative matrices, effectively representing the topics and their\ndistribution across the documents. This helps us see how strongly documents\nrelate to topics and how topics relate to words. We describe the complete\nmethodology which involves a series of rigorous pre-processing steps to\nstandardize the available text data while preserving the context of phrases,\nand subsequently feature extraction using the term frequency-inverse document\nfrequency (tf-idf), which assigns weights to words based on their frequency and\nrarity in the dataset. To ensure the robustness of our topic model, we conduct\na stability analysis. This process assesses the stability scores of the NMF\ntopic model for different numbers of topics, enabling us to select the optimal\nnumber of topics for our analysis. Through our analysis, we track the evolution\nof topics over time within the CORD-19 dataset. Our findings contribute to the\nunderstanding of the knowledge structure of the COVID-19 research landscape,\nproviding a valuable resource for future research in this field.", "published": "2025-03-23 19:37:52", "link": "http://arxiv.org/abs/2503.18182v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GINGER: Grounded Information Nugget-Based Generation of Responses", "abstract": "Retrieval-augmented generation (RAG) faces challenges related to factual\ncorrectness, source attribution, and response completeness. To address them, we\npropose a modular pipeline for grounded response generation that operates on\ninformation nuggets-minimal, atomic units of relevant information extracted\nfrom retrieved documents. The multistage pipeline encompasses nugget detection,\nclustering, ranking, top cluster summarization, and fluency enhancement. It\nguarantees grounding in specific facts, facilitates source attribution, and\nensures maximum information inclusion within length constraints. Extensive\nexperiments on the TREC RAG'24 dataset evaluated with the AutoNuggetizer\nframework demonstrate that GINGER achieves state-of-the-art performance on this\nbenchmark.", "published": "2025-03-23 19:10:23", "link": "http://arxiv.org/abs/2503.18174v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Automated Causal Loop Diagram Generation: Enhancing System Dynamics Modeling through Curated Prompting Techniques", "abstract": "Transforming a dynamic hypothesis into a causal loop diagram (CLD) is crucial\nfor System Dynamics Modelling. Extracting key variables and causal\nrelationships from text to build a CLD is often challenging and time-consuming\nfor novice modelers, limiting SD tool adoption. This paper introduces and tests\na method for automating the translation of dynamic hypotheses into CLDs using\nlarge language models (LLMs) with curated prompting techniques. We first\ndescribe how LLMs work and how they can make the inferences needed to build\nCLDs using a standard digraph structure. Next, we develop a set of simple\ndynamic hypotheses and corresponding CLDs from leading SD textbooks. We then\ncompare the four different combinations of prompting techniques, evaluating\ntheir performance against CLDs labeled by expert modelers. Results show that\nfor simple model structures and using curated prompting techniques, LLMs can\ngenerate CLDs of a similar quality to expert-built ones, accelerating CLD\ncreation.", "published": "2025-03-23 18:57:51", "link": "http://arxiv.org/abs/2503.21798v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Unmasking Deceptive Visuals: Benchmarking Multimodal Large Language Models on Misleading Chart Question Answering", "abstract": "Misleading chart visualizations, which intentionally manipulate data\nrepresentations to support specific claims, can distort perceptions and lead to\nincorrect conclusions. Despite decades of research, misleading visualizations\nremain a widespread and pressing issue. Recent advances in multimodal large\nlanguage models (MLLMs) have demonstrated strong chart comprehension\ncapabilities, yet no existing work has systematically evaluated their ability\nto detect and interpret misleading charts. This paper introduces the Misleading\nChart Question Answering (Misleading ChartQA) Benchmark, a large-scale\nmultimodal dataset designed to assess MLLMs in identifying and reasoning about\nmisleading charts. It contains over 3,000 curated examples, covering 21 types\nof misleaders and 10 chart types. Each example includes standardized chart\ncode, CSV data, and multiple-choice questions with labeled explanations,\nvalidated through multi-round MLLM checks and exhausted expert human review. We\nbenchmark 16 state-of-the-art MLLMs on our dataset, revealing their limitations\nin identifying visually deceptive practices. We also propose a novel pipeline\nthat detects and localizes misleaders, enhancing MLLMs' accuracy in misleading\nchart interpretation. Our work establishes a foundation for advancing\nMLLM-driven misleading chart comprehension. We publicly release the sample\ndataset to support further research in this critical area.", "published": "2025-03-23 18:56:33", "link": "http://arxiv.org/abs/2503.18172v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Negative Sampling Approaches for Neural Topic Models", "abstract": "Negative sampling has emerged as an effective technique that enables deep\nlearning models to learn better representations by introducing the paradigm of\nlearn-to-compare. The goal of this approach is to add robustness to deep\nlearning models to learn better representation by comparing the positive\nsamples against the negative ones. Despite its numerous demonstrations in\nvarious areas of computer vision and natural language processing, a\ncomprehensive study of the effect of negative sampling in an unsupervised\ndomain like topic modeling has not been well explored. In this paper, we\npresent a comprehensive analysis of the impact of different negative sampling\nstrategies on neural topic models. We compare the performance of several\npopular neural topic models by incorporating a negative sampling technique in\nthe decoder of variational autoencoder-based neural topic models. Experiments\non four publicly available datasets demonstrate that integrating negative\nsampling into topic models results in significant enhancements across multiple\naspects, including improved topic coherence, richer topic diversity, and more\naccurate document classification. Manual evaluations also indicate that the\ninclusion of negative sampling into neural topic models enhances the quality of\nthe generated topics. These findings highlight the potential of negative\nsampling as a valuable tool for advancing the effectiveness of neural topic\nmodels.", "published": "2025-03-23 18:39:01", "link": "http://arxiv.org/abs/2503.18167v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SRMIR: Shadow Reward Models Based on Introspective Reasoning for LLM Alignment", "abstract": "Aligning large language models (LLMs) with human preferences and values is\nvital for application. However, current alignment methods face three main\nlimitations: (1) reliance on costly human annotation; (2) alignment tax; (3)\nshallow alignment vulnerable to jailbreak attacks. Additionally, current\nalignment datasets often suffer from uneven distributions, leading to\noverrepresentation of some topics and neglect of others. To address these\nissues, we propose SRMIR (Shadow Reward Models Based on Introspective\nReasoning), inspired by shadow models in membership inference attacks. We first\nconstruct a balanced safety Chain of Draft (CoD) dataset across $7$ harmful\ntypes with structured prompt leveraging the introspective reasoning\ncapabilities of LLMs, then train a set of specialized reward models to guide\npolicy optimization through Group Relative Policy Optimization (GRPO). We apply\ntwo strategies, linear combination and categorized approach, to integrate\nshadow reward models for policy optimization. By comparison, we find that the\nlatter achieves superior alignment despite higher computational costs.\nExperiments across several LLMs demonstrate SRMIR significantly outperforms\nexisting methods.", "published": "2025-03-23 16:40:29", "link": "http://arxiv.org/abs/2503.18991v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MathAgent: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection", "abstract": "Mathematical error detection in educational settings presents a significant\nchallenge for Multimodal Large Language Models (MLLMs), requiring a\nsophisticated understanding of both visual and textual mathematical content\nalong with complex reasoning capabilities. Though effective in mathematical\nproblem-solving, MLLMs often struggle with the nuanced task of identifying and\ncategorizing student errors in multimodal mathematical contexts. Therefore, we\nintroduce MathAgent, a novel Mixture-of-Math-Agent framework designed\nspecifically to address these challenges. Our approach decomposes error\ndetection into three phases, each handled by a specialized agent: an image-text\nconsistency validator, a visual semantic interpreter, and an integrative error\nanalyzer. This architecture enables more accurate processing of mathematical\ncontent by explicitly modeling relationships between multimodal problems and\nstudent solution steps. We evaluate MathAgent on real-world educational data,\ndemonstrating approximately 5% higher accuracy in error step identification and\n3% improvement in error categorization compared to baseline models. Besides,\nMathAgent has been successfully deployed in an educational platform that has\nserved over one million K-12 students, achieving nearly 90% student\nsatisfaction while generating significant cost savings by reducing manual error\ndetection.", "published": "2025-03-23 16:25:08", "link": "http://arxiv.org/abs/2503.18132v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GeoBenchX: Benchmarking LLMs for Multistep Geospatial Tasks", "abstract": "In this paper, we establish a benchmark for evaluating large language models\n(LLMs) on multi-step geospatial tasks relevant to commercial GIS practitioners.\nWe assess seven leading commercial LLMs (Sonnet 3.5 and 3.7, Haiku 3.5, Gemini\n2.0, GPT-4o, GPT-4o mini, and o3-mini) using a simple tool-calling agent\nequipped with 23 geospatial functions. Our benchmark comprises tasks across\nfour categories of increasing complexity, with both solvable and intentionally\nunsolvable tasks to test hallucination rejection. We develop an LLM-as-Judge\nevaluation framework to compare agent solutions against reference\nimplementations. Results show Sonnet 3.5 and GPT-4o achieve the best overall\nperformance, with Claude models excelling on solvable tasks while OpenAI models\nbetter identify unsolvable scenarios. We observe significant differences in\ntoken usage, with Anthropic models consuming substantially more tokens than\ncompetitors. Common errors include misunderstanding geometrical relationships,\nrelying on outdated knowledge, and inefficient data manipulation. The resulting\nbenchmark set, evaluation framework, and data generation pipeline are released\nas open-source resources, providing one more standardized method for ongoing\nevaluation of LLMs for GeoAI.", "published": "2025-03-23 16:20:14", "link": "http://arxiv.org/abs/2503.18129v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Detection of Somali-written Fake News and Toxic Messages on the Social Media Using Transformer-based Language Models", "abstract": "The fact that everyone with a social media account can create and share\ncontent, and the increasing public reliance on social media platforms as a news\nand information source bring about significant challenges such as\nmisinformation, fake news, harmful content, etc. Although human content\nmoderation may be useful to an extent and used by these platforms to flag\nposted materials, the use of AI models provides a more sustainable, scalable,\nand effective way to mitigate these harmful contents. However, low-resourced\nlanguages such as the Somali language face limitations in AI automation,\nincluding scarce annotated training datasets and lack of language models\ntailored to their unique linguistic characteristics. This paper presents part\nof our ongoing research work to bridge some of these gaps for the Somali\nlanguage. In particular, we created two human-annotated social-media-sourced\nSomali datasets for two downstream applications, fake news \\& toxicity\nclassification, and developed a transformer-based monolingual Somali language\nmodel (named SomBERTa) -- the first of its kind to the best of our knowledge.\nSomBERTa is then fine-tuned and evaluated on toxic content, fake news and news\ntopic classification datasets. Comparative evaluation analysis of the proposed\nmodel against related multilingual models (e.g., AfriBERTa, AfroXLMR, etc)\ndemonstrated that SomBERTa consistently outperformed these comparators in both\nfake news and toxic content classification tasks while achieving the best\naverage accuracy (87.99%) across all tasks. This research contributes to Somali\nNLP by offering a foundational language model and a replicable framework for\nother low-resource languages, promoting digital and AI inclusivity and\nlinguistic diversity.", "published": "2025-03-23 15:45:31", "link": "http://arxiv.org/abs/2503.18117v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AgentRxiv: Towards Collaborative Autonomous Research", "abstract": "Progress in scientific discovery is rarely the result of a single \"Eureka\"\nmoment, but is rather the product of hundreds of scientists incrementally\nworking together toward a common goal. While existing agent workflows are\ncapable of producing research autonomously, they do so in isolation, without\nthe ability to continuously improve upon prior research results. To address\nthese challenges, we introduce AgentRxiv-a framework that lets LLM agent\nlaboratories upload and retrieve reports from a shared preprint server in order\nto collaborate, share insights, and iteratively build on each other's research.\nWe task agent laboratories to develop new reasoning and prompting techniques\nand find that agents with access to their prior research achieve higher\nperformance improvements compared to agents operating in isolation (11.4%\nrelative improvement over baseline on MATH-500). We find that the best\nperforming strategy generalizes to benchmarks in other domains (improving on\naverage by 3.3%). Multiple agent laboratories sharing research through\nAgentRxiv are able to work together towards a common goal, progressing more\nrapidly than isolated laboratories, achieving higher overall accuracy (13.7%\nrelative improvement over baseline on MATH-500). These findings suggest that\nautonomous agents may play a role in designing future AI systems alongside\nhumans. We hope that AgentRxiv allows agents to collaborate toward research\ngoals and enables researchers to accelerate discovery.", "published": "2025-03-23 15:16:42", "link": "http://arxiv.org/abs/2503.18102v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Clarifying Misconceptions in COVID-19 Vaccine Sentiment and Stance Analysis and Their Implications for Vaccine Hesitancy Mitigation: A Systematic Review", "abstract": "Background Advances in machine learning (ML) models have increased the\ncapability of researchers to detect vaccine hesitancy in social media using\nNatural Language Processing (NLP). A considerable volume of research has\nidentified the persistence of COVID-19 vaccine hesitancy in discourse shared on\nvarious social media platforms. Methods Our objective in this study was to\nconduct a systematic review of research employing sentiment analysis or stance\ndetection to study discourse towards COVID-19 vaccines and vaccination spread\non Twitter (officially known as X since 2023). Following registration in the\nPROSPERO international registry of systematic reviews, we searched papers\npublished from 1 January 2020 to 31 December 2023 that used supervised machine\nlearning to assess COVID-19 vaccine hesitancy through stance detection or\nsentiment analysis on Twitter. We categorized the studies according to a\ntaxonomy of five dimensions: tweet sample selection approach, self-reported\nstudy type, classification typology, annotation codebook definitions, and\ninterpretation of results. We analyzed if studies using stance detection report\ndifferent hesitancy trends than those using sentiment analysis by examining how\nCOVID-19 vaccine hesitancy is measured, and whether efforts were made to avoid\nmeasurement bias. Results Our review found that measurement bias is widely\nprevalent in studies employing supervised machine learning to analyze sentiment\nand stance toward COVID-19 vaccines and vaccination. The reporting errors are\nsufficiently serious that they hinder the generalisability and interpretation\nof these studies to understanding whether individual opinions communicate\nreluctance to vaccinate against SARS-CoV-2. Conclusion Improving the reporting\nof NLP methods is crucial to addressing knowledge gaps in vaccine hesitancy\ndiscourse.", "published": "2025-03-23 14:55:10", "link": "http://arxiv.org/abs/2503.18095v1", "categories": ["cs.CL", "cs.CY", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "$D^2LoRA$: Data-Driven LoRA Initialization for Low Resource Tasks", "abstract": "Tuning large language models is essential for optimizing their performance\nacross diverse applications, particularly in scenarios with limited data\navailability. Tuning large language models in scarce data scenarios is crucial,\nparticularly given that the convergence speed of the LoRA method is lower than\nthat of full fine-tuning. In this paper, we present an analysis of\npost-training methods including Supervised Fine-Tuning (SFT), Direct Preference\nOptimization (DPO), and Odds Ratio Preference Optimization (ORPO) within the\ncontext of task-specific learning using the LoRA method. Next we introduce\n$D^2LoRA$, a data-driven approach for initializing LoRA metrics that enhances\ntraining efficiency, especially in limited-data settings. Our experiments\ncompare $D^2LoRA$ with vanilla LoRA in terms of performance and catastrophic\nforgetting under extremely data-constrained conditions. The results demonstrate\nthat $D^2LoRA$ achieves a 1% improvement GSM8K benchmark and a 2-point\nimprovement in ROUGE score in title generation tasks. $D^2LoRA$ facilitates the\nadaptation of LLMs to multiple tasks even when task-specific data is scarce,\nthereby reducing training expenses and offering data cost.", "published": "2025-03-23 14:41:01", "link": "http://arxiv.org/abs/2503.18089v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach", "abstract": "Temporal information extraction from unstructured text is essential for\ncontextualizing events and deriving actionable insights, particularly in the\nmedical domain. We address the task of extracting clinical events and their\ntemporal relations using the well-studied I2B2 2012 Temporal Relations\nChallenge corpus. This task is inherently challenging due to complex clinical\nlanguage, long documents, and sparse annotations. We introduce GRAPHTREX, a\nnovel method integrating span-based entity-relation extraction, clinical large\npre-trained language models (LPLMs), and Heterogeneous Graph Transformers (HGT)\nto capture local and global dependencies. Our HGT component facilitates\ninformation propagation across the document through innovative global landmarks\nthat bridge distant entities. Our method improves the state-of-the-art with\n5.5% improvement in the tempeval $F_1$ score over the previous best and up to\n8.9% improvement on long-range relations, which presents a formidable\nchallenge. This work not only advances temporal information extraction but also\nlays the groundwork for improved diagnostic and prognostic models through\nenhanced temporal reasoning.", "published": "2025-03-23 14:34:49", "link": "http://arxiv.org/abs/2503.18085v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Multi-Model Adaptation of Speculative Decoding for Classification", "abstract": "The current study introduces a novel adaptation of speculative decoding,\nrepurposed from generation to classification tasks. We propose a multi-model\nframework employing up to three lightweight worker models and a single, more\nrobust judge model analogous to draft models and target model, respectively, in\nspeculative decoding. The worker models, tasked with the bulk of the\ncomputation, independently predict discrete class labels for a given input.\nWhen majority worker models agree on a label, it is accepted as the final\nlabel, optimizing efficiency by bypassing the computationally expensive judge\nmodel. In cases of disagreement, the judge model intervenes to resolve the\nlabel. This approach minimizes redundant computation, leverages the redundancy\nof multiple workers for confidence, and confines the judge model's role to\nchallenging cases, offering a practical balance of efficiency and accuracy. Our\nanalysis suggests that smaller out of the box instruction/chat finetuned worker\nmodels with 3 billion parameters (hereafter, 3B) demonstrate a level of\nalignment with judge models comparable to that of larger finetuned worker\nmodels with 7 billion parameters (hereafter, 7B) across both simple and higher\norder reasoning tasks. The top performing 3B worker model pair achieve an\nagreement rate of approximately 80-83% for sentiment and around 50-80% for\nsimilar ticket when compared to judge models. Additionally, 3B worker models\nprovide a speedup ranging from 2.8x to 9x relative to the judge models, while\n7B worker model combinations achieve a speedup ranging from 1.28x to 0.28x", "published": "2025-03-23 13:54:02", "link": "http://arxiv.org/abs/2503.18076v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the effectiveness of LLMs for automatic grading of open-ended questions in Spanish", "abstract": "Grading is a time-consuming and laborious task that educators must face. It\nis an important task since it provides feedback signals to learners, and it has\nbeen demonstrated that timely feedback improves the learning process. In recent\nyears, the irruption of LLMs has shed light on the effectiveness of automatic\ngrading. In this paper, we explore the performance of different LLMs and\nprompting techniques in automatically grading short-text answers to open-ended\nquestions. Unlike most of the literature, our study focuses on a use case where\nthe questions, answers, and prompts are all in Spanish. Experimental results\ncomparing automatic scores to those of human-expert evaluators show good\noutcomes in terms of accuracy, precision and consistency for advanced LLMs,\nboth open and proprietary. Results are notably sensitive to prompt styles,\nsuggesting biases toward certain words or content in the prompt. However, the\nbest combinations of models and prompt strategies, consistently surpasses an\naccuracy of 95% in a three-level grading task, which even rises up to more than\n98% when the it is simplified to a binary right or wrong rating problem, which\ndemonstrates the potential that LLMs have to implement this type of automation\nin education applications.", "published": "2025-03-23 13:43:27", "link": "http://arxiv.org/abs/2503.18072v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mind with Eyes: from Language Reasoning to Multimodal Reasoning", "abstract": "Language models have recently advanced into the realm of reasoning, yet it is\nthrough multimodal reasoning that we can fully unlock the potential to achieve\nmore comprehensive, human-like cognitive capabilities. This survey provides a\nsystematic overview of the recent multimodal reasoning approaches, categorizing\nthem into two levels: language-centric multimodal reasoning and collaborative\nmultimodal reasoning. The former encompasses one-pass visual perception and\nactive visual perception, where vision primarily serves a supporting role in\nlanguage reasoning. The latter involves action generation and state update\nwithin reasoning process, enabling a more dynamic interaction between\nmodalities. Furthermore, we analyze the technical evolution of these methods,\ndiscuss their inherent challenges, and introduce key benchmark tasks and\nevaluation metrics for assessing multimodal reasoning performance. Finally, we\nprovide insights into future research directions from the following two\nperspectives: (i) from visual-language reasoning to omnimodal reasoning and\n(ii) from multimodal reasoning to multimodal agents. This survey aims to\nprovide a structured overview that will inspire further advancements in\nmultimodal reasoning research.", "published": "2025-03-23 13:40:44", "link": "http://arxiv.org/abs/2503.18071v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long Is More Important Than Difficult for Training Reasoning Models", "abstract": "Difficult problems, which often result in long reasoning traces, are widely\nrecognized as key factors for enhancing the performance of reasoning models.\nHowever, such high-challenge problems are scarce, limiting the size of\navailable datasets. In this paper, we propose a simple method to decouple the\nreliance on problem difficulty. First, we empirically demonstrate that\nreasoning length, rather than problem difficulty, primarily influences the\nperformance of trained models. Second, we identify a scaling law on reasoning\nlength, showing that model performance increases in a log-linear fashion as the\nreasoning data length grows. Finally, we introduce a straightforward technique\nto generate reasoning data of arbitrary length, and show that synthesized data\nis effective for training reasoning models. After fine-tuning the\nQwen2.5-32B-Instruct language model on our Long1K dataset, we present our\nmodel, Long1K-32B, which achieves remarkable performance with only 1,000\ntraining samples, achieving 95.6\\% accuracy on MATH, and 71.1\\% on GPQA\noutperforming DeepSeek-R1-Distill-Qwen-32B. The model, code, and dataset are\nall open-sourced, available at https://huggingface.co/ZTss/LONG1.", "published": "2025-03-23 13:33:59", "link": "http://arxiv.org/abs/2503.18069v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unseen from Seen: Rewriting Observation-Instruction Using Foundation Models for Augmenting Vision-Language Navigation", "abstract": "Data scarcity is a long-standing challenge in the Vision-Language Navigation\n(VLN) field, which extremely hinders the generalization of agents to unseen\nenvironments. Previous works primarily rely on additional simulator data or\nweb-collected images/videos to improve the generalization. However, the\nsimulator environments still face limited diversity, and the web-collected data\noften requires extensive labor to remove the noise. In this paper, we propose a\nRewriting-driven AugMentation (RAM) paradigm for VLN, which directly creates\nthe unseen observation-instruction pairs via rewriting human-annotated training\ndata. Benefiting from our rewriting mechanism, new observation-instruction can\nbe obtained in both simulator-free and labor-saving manners to promote\ngeneralization. Specifically, we first introduce Object-Enriched Observation\nRewriting, where we combine Vision-Language Models (VLMs) and Large Language\nModels (LLMs) to derive rewritten object-enriched scene descriptions, enabling\nobservation synthesis with diverse objects and spatial layouts via\nText-to-Image Generation Models (T2IMs). Then, we propose Observation-Contrast\nInstruction Rewriting, which generates observation-aligned rewritten\ninstructions by requiring LLMs to reason the difference between original and\nnew observations. We further develop a mixing-then-focusing training strategy\nwith a random observation cropping scheme, effectively enhancing data\ndistribution diversity while suppressing augmentation data noise during\ntraining. Experiments on both the discrete environments (R2R, REVERIE, and R4R\ndatasets) and continuous environments (R2R-CE dataset) show the superior\nperformance and impressive generalization ability of our method. Code is\navailable at https://github.com/SaDil13/VLN-RAM.", "published": "2025-03-23 13:18:17", "link": "http://arxiv.org/abs/2503.18065v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Dynamic Task Vector Grouping for Efficient Multi-Task Prompt Tuning", "abstract": "Multi-task prompt tuning utilizes multiple high-resource source tasks to\nimprove performance on low-source target tasks. Existing approaches transfer\nthe soft prompt trained by combining all source tasks or a single\n``high-similar'' source task one-time-only. However, we find that the optimal\ntransfer performance often comes from a combination of source tasks, which is\nneither one nor all. Further, we find that the similarity between source and\ntarget tasks also changes dynamically during fine-tuning after transfering,\nmaking similarity calculation in the initiation stage inadequate. To address\nthese issues, we propose a method called Dynamic Task Vector Grouping (DTVG),\nwhose core ideas contain (1) measuring the task similarity with task vectors\ninstead of soft prompt, (2) grouping the optimal source task combination based\non two metrics: {\\it target similarity} and {\\it knowledge consistency}; (3)\ndynamically updating the combination in each iteration step. Extensive\nexperiments on the 26 NLP datasets under different settings demonstrate that\nDTVG effectively groups similar source tasks while reducing negative transfer,\nachieving the start-of-art performance.", "published": "2025-03-23 13:09:04", "link": "http://arxiv.org/abs/2503.18063v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating Recent Large Language Models for Vietnamese Machine Reading Comprehension", "abstract": "Large Language Models (LLMs) have shown remarkable proficiency in Machine\nReading Comprehension (MRC) tasks; however, their effectiveness for\nlow-resource languages like Vietnamese remains largely unexplored. In this\npaper, we fine-tune and evaluate two state-of-the-art LLMs: Llama 3 (8B\nparameters) and Gemma (7B parameters), on ViMMRC, a Vietnamese MRC dataset. By\nutilizing Quantized Low-Rank Adaptation (QLoRA), we efficiently fine-tune these\nmodels and compare their performance against powerful LLM-based baselines.\nAlthough our fine-tuned models are smaller than GPT-3 and GPT-3.5, they\noutperform both traditional BERT-based approaches and these larger models. This\ndemonstrates the effectiveness of our fine-tuning process, showcasing how\nmodern LLMs can surpass the capabilities of older models like BERT while still\nbeing suitable for deployment in resource-constrained environments. Through\nintensive analyses, we explore various aspects of model performance, providing\nvaluable insights into adapting LLMs for low-resource languages like\nVietnamese. Our study contributes to the advancement of natural language\nprocessing in low-resource languages, and we make our fine-tuned models\npublicly available at: https://huggingface.co/iaiuet.", "published": "2025-03-23 13:08:11", "link": "http://arxiv.org/abs/2503.18062v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "(G)I-DLE: Generative Inference via Distribution-preserving Logit Exclusion with KL Divergence Minimization for Constrained Decoding", "abstract": "We propose (G)I-DLE, a new approach to constrained decoding that leverages KL\ndivergence minimization to preserve the intrinsic conditional probability\ndistribution of autoregressive language models while excluding undesirable\ntokens. Unlike conventional methods that naively set banned tokens' logits to\n$-\\infty$, which can distort the conversion from raw logits to posterior\nprobabilities and increase output variance, (G)I-DLE re-normalizes the allowed\ntoken probabilities to minimize such distortion. We validate our method on the\nK2-Eval dataset, specifically designed to assess Korean language fluency,\nlogical reasoning, and cultural appropriateness. Experimental results on\nQwen2.5 models (ranging from 1.5B to 14B) demonstrate that G-IDLE not only\nboosts mean evaluation scores but also substantially reduces the variance of\noutput quality.", "published": "2025-03-23 12:37:14", "link": "http://arxiv.org/abs/2503.18050v1", "categories": ["cs.CE", "cs.CL"], "primary_category": "cs.CE"}
{"title": "Expanding the Boundaries of Vision Prior Knowledge in Multi-modal Large Language Models", "abstract": "Does the prior knowledge of the vision encoder constrain the capability\nboundary of Multi-modal Large Language Models (MLLMs)? While most existing\nresearch treats MLLMs as unified systems optimized through end-to-end training,\nthe impact of vision encoder's prior knowledge is seldom investigated. In this\nwork, we introduce a novel metric, $Rank_e$, to quantify the effect of the\nvision encoder's prior knowledge on MLLM performance. Our analysis reveals a\npositive correlation between prior knowledge and MLLM performance. Moreover, we\nfind that domain-specific fine-tuning using solely end-to-end visual question\nanswering (VQA) data is insufficient--particularly for entities with low\ninherent visual prior knowledge. To address this issue, we propose VisPRE\n(Vision Prior Remediation), a two-stage training framework that explicitly\nincorporates prior knowledge at the vision encoder level. Experimental results\ndemonstrate that augmenting vision encoder's prior knowledge substantially\nboosts the visual understanding capabilities of MLLMs, offering a novel and\neffective strategy for improving performance, especially in scenarios involving\nuncommon visual entities.", "published": "2025-03-23 11:33:09", "link": "http://arxiv.org/abs/2503.18034v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Personalized Language Models via Privacy-Preserving Evolutionary Model Merging", "abstract": "Personalization in large language models (LLMs) seeks to tailor models to\nindividual user or user group preferences. Prompt-based methods augment queries\nwith user preference information, whereas training-based methods directly\nencode preferences into model parameters for more effective personalization.\nDespite achieving some success in personalizing LLMs, prior methods often fail\nto directly optimize task-specific metrics and lack explicit\nprivacy-preservation mechanisms. To address these limitations, we propose\nPrivacy-Preserving Model Merging via Evolutionary Algorithms (PriME), a novel\napproach to personalization that employs gradient-free methods to directly\noptimize task-specific metrics while preserving user privacy. By incorporating\nprivacy preservation into optimization, PriME produces a personalized module\nthat effectively captures the target user's preferences while minimizing the\nprivacy risks for the users sharing their private information. Experiments on\nthe LaMP benchmark show that PriME outperforms both prompt-based and\ntraining-based methods, achieving up to a 45% performance improvement over the\nprior art. Further analysis shows that PriME achieves a significantly better\nprivacy-utility trade-off, highlighting the potential of evolutionary\napproaches for privacy-preserving LLM personalization.", "published": "2025-03-23 09:46:07", "link": "http://arxiv.org/abs/2503.18008v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Instructing the Architecture Search for Spatial-temporal Sequence Forecasting with LLM", "abstract": "Spatial-temporal sequence forecasting (STSF) is a long-standing research\nproblem with widespread real-world applications. Neural architecture search\n(NAS), which automates the neural network design, has been shown effective in\ntackling the STSF problem. However, the existing NAS methods for STSF focus on\ngenerating architectures in a time-consuming data-driven fashion, which heavily\nlimits their ability to use background knowledge and explore the complicated\nsearch trajectory. Large language models (LLMs) have shown remarkable ability\nin decision-making with comprehensive internal world knowledge, but how it\ncould benefit NAS for STSF remains unexplored. In this paper, we propose a\nnovel NAS method for STSF based on LLM. Instead of directly generate\narchitectures with LLM, We inspire the LLM's capability with a multi-level\nenhancement mechanism. Specifically, on the step-level, we decompose the\ngeneration task into decision steps with powerful prompt engineering and\ninspire LLM to serve as instructor for architecture search based on its\ninternal knowledge. On the instance-level, we utilize a one-step tuning\nframework to quickly evaluate the architecture instance and a memory bank to\ncumulate knowledge to improve LLM's search ability. On the task-level, we\npropose a two-stage architecture search, balancing the exploration stage and\noptimization stage, to reduce the possibility of being trapped in local optima.\nExtensive experimental results demonstrate that our method can achieve\ncompetitive effectiveness with superior efficiency against existing NAS methods\nfor STSF.", "published": "2025-03-23 08:59:04", "link": "http://arxiv.org/abs/2503.17994v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Trade-offs in Large Reasoning Models: An Empirical Analysis of Deliberative and Adaptive Reasoning over Foundational Capabilities", "abstract": "Recent advancements in Large Reasoning Models (LRMs), such as OpenAI's o1/o3\nand DeepSeek-R1, have demonstrated remarkable performance in specialized\nreasoning tasks through human-like deliberative thinking and long\nchain-of-thought reasoning. However, our systematic evaluation across various\nmodel families (DeepSeek, Qwen, and LLaMA) and scales (7B to 671B) reveals that\nacquiring these deliberative reasoning capabilities significantly reduces the\nfoundational capabilities of LRMs, including notable declines in helpfulness\nand harmlessness, alongside substantially increased inference costs.\nImportantly, we demonstrate that adaptive reasoning -- employing modes like\nZero-Thinking, Less-Thinking, and Summary-Thinking -- can effectively alleviate\nthese drawbacks. Our empirical insights underline the critical need for\ndeveloping more versatile LRMs capable of dynamically allocating inference-time\ncompute according to specific task characteristics.", "published": "2025-03-23 08:18:51", "link": "http://arxiv.org/abs/2503.17979v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Understanding the Effects of RLHF on the Quality and Detectability of LLM-Generated Texts", "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance on a\nrange of downstream NLP tasks by generating text that closely resembles human\nwriting. However, the ease of achieving this similarity raises concerns from\npotential malicious uses at scale by bad actors, as LLM-generated text becomes\nincreasingly difficult to discern from human text. Although detection methods\nhave been developed to address this issue, bad actors can further manipulate\nLLM-generated texts to make them less detectable. In this work, we study how\nfurther editing texts with Reinforcement Learning from Human Feedback (RLHF),\nwhich aligns model outputs with human preferences, affects (a) the quality of\ngenerated texts for two tasks, and (b) the performance of LLM-generated text\ndetectors, looking at both training-based and zero-shot detection methods.\nAlthough RLHF improves the quality of LLM-generated texts, we find that it also\ntends to produce more detectable, lengthy, and repetitive outputs.\nAdditionally, we observe that training-based detectors are vulnerable to short\ntexts and to texts that incorporate code, whereas zero-shot detectors exhibit\ngreater robustness.", "published": "2025-03-23 07:03:10", "link": "http://arxiv.org/abs/2503.17965v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Won: Establishing Best Practices for Korean Financial NLP", "abstract": "In this work, we present the first open leaderboard for evaluating Korean\nlarge language models focused on finance. Operated for about eight weeks, the\nleaderboard evaluated 1,119 submissions on a closed benchmark covering five\nMCQA categories: finance and accounting, stock price prediction, domestic\ncompany analysis, financial markets, and financial agent tasks and one\nopen-ended qa task. Building on insights from these evaluations, we release an\nopen instruction dataset of 80k instances and summarize widely used training\nstrategies observed among top-performing models. Finally, we introduce Won, a\nfully open and transparent LLM built using these best practices. We hope our\ncontributions help advance the development of better and safer financial LLMs\nfor Korean and other languages.", "published": "2025-03-23 06:52:38", "link": "http://arxiv.org/abs/2503.17963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human-AI Interaction and User Satisfaction: Empirical Evidence from Online Reviews of AI Products", "abstract": "Human-AI Interaction (HAI) guidelines and design principles have become\nincreasingly important in both industry and academia to guide the development\nof AI systems that align with user needs and expectations. However, large-scale\nempirical evidence on how HAI principles shape user satisfaction in practice\nremains limited. This study addresses that gap by analyzing over 100,000 user\nreviews of AI-related products from G2, a leading review platform for business\nsoftware and services. Based on widely adopted industry guidelines, we identify\nseven core HAI dimensions and examine their coverage and sentiment within the\nreviews. We find that the sentiment on four HAI dimensions-adaptability,\ncustomization, error recovery, and security-is positively associated with\noverall user satisfaction. Moreover, we show that engagement with HAI\ndimensions varies by professional background: Users with technical job roles\nare more likely to discuss system-focused aspects, such as reliability, while\nnon-technical users emphasize interaction-focused features like customization\nand feedback. Interestingly, the relationship between HAI sentiment and overall\nsatisfaction is not moderated by job role, suggesting that once an HAI\ndimension has been identified by users, its effect on satisfaction is\nconsistent across job roles.", "published": "2025-03-23 06:16:49", "link": "http://arxiv.org/abs/2503.17955v2", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "SLIDE: Sliding Localized Information for Document Extraction", "abstract": "Constructing accurate knowledge graphs from long texts and low-resource\nlanguages is challenging, as large language models (LLMs) experience degraded\nperformance with longer input chunks. This problem is amplified in low-resource\nsettings where data scarcity hinders accurate entity and relationship\nextraction. Contextual retrieval methods, while improving retrieval accuracy,\nstruggle with long documents. They truncate critical information in texts\nexceeding maximum context lengths of LLMs, significantly limiting knowledge\ngraph construction. We introduce SLIDE (Sliding Localized Information for\nDocument Extraction), a chunking method that processes long documents by\ngenerating local context through overlapping windows. SLIDE ensures that\nessential contextual information is retained, enhancing knowledge graph\nextraction from documents exceeding LLM context limits. It significantly\nimproves GraphRAG performance, achieving a 24% increase in entity extraction\nand a 39% improvement in relationship extraction for English. For Afrikaans, a\nlow-resource language, SLIDE achieves a 49% increase in entity extraction and\nan 82% improvement in relationship extraction. Furthermore, it improves upon\nstate-of-the-art in question-answering metrics such as comprehensiveness,\ndiversity and empowerment, demonstrating its effectiveness in multilingual and\nresource-constrained settings.", "published": "2025-03-23 06:00:39", "link": "http://arxiv.org/abs/2503.17952v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of the Role of Incompleteness and Ambiguity in Interactions with Large Language Models", "abstract": "Natural language as a medium for human-computer interaction has long been\nanticipated, has been undergoing a sea-change with the advent of Large Language\nModels (LLMs) with startling capacities for processing and generating language.\nMany of us now treat LLMs as modern-day oracles, asking it almost any kind of\nquestion. Unlike its Delphic predecessor, consulting an LLM does not have to be\na single-turn activity (ask a question, receive an answer, leave); and -- also\nunlike the Pythia -- it is widely acknowledged that answers from LLMs can be\nimproved with additional context. In this paper, we aim to study when we need\nmulti-turn interactions with LLMs to successfully get a question answered; or\nconclude that a question is unanswerable. We present a neural symbolic\nframework that models the interactions between human and LLM agents. Through\nthe proposed framework, we define incompleteness and ambiguity in the questions\nas properties deducible from the messages exchanged in the interaction, and\nprovide results from benchmark problems, in which the answer-correctness is\nshown to depend on whether or not questions demonstrate the presence of\nincompleteness or ambiguity (according to the properties we identify). Our\nresults show multi-turn interactions are usually required for datasets which\nhave a high proportion of incompleteness or ambiguous questions; and that that\nincreasing interaction length has the effect of reducing incompleteness or\nambiguity. The results also suggest that our measures of incompleteness and\nambiguity can be useful tools for characterising interactions with an LLM on\nquestion-answeringproblems", "published": "2025-03-23 04:34:30", "link": "http://arxiv.org/abs/2503.17936v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Experience Retrieval-Augmentation with Electronic Health Records Enables Accurate Discharge QA", "abstract": "To improve the reliability of Large Language Models (LLMs) in clinical\napplications, retrieval-augmented generation (RAG) is extensively applied to\nprovide factual medical knowledge. However, beyond general medical knowledge\nfrom open-ended datasets, clinical case-based knowledge is also critical for\neffective medical reasoning, as it provides context grounded in real-world\npatient experiences. Motivated by this, we propose Experience Retrieval\nAugmentation - ExpRAG framework based on Electronic Health Record (EHR), aiming\nto offer the relevant context from other patients' discharge reports. ExpRAG\nperforms retrieval through a coarse-to-fine process, utilizing an EHR-based\nreport ranker to efficiently identify similar patients, followed by an\nexperience retriever to extract task-relevant content for enhanced medical\nreasoning. To evaluate ExpRAG, we introduce DischargeQA, a clinical QA dataset\nwith 1,280 discharge-related questions across diagnosis, medication, and\ninstruction tasks. Each problem is generated using EHR data to ensure realistic\nand challenging scenarios. Experimental results demonstrate that ExpRAG\nconsistently outperforms a text-based ranker, achieving an average relative\nimprovement of 5.2%, highlighting the importance of case-based knowledge for\nmedical reasoning.", "published": "2025-03-23 04:26:06", "link": "http://arxiv.org/abs/2503.17933v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "STShield: Single-Token Sentinel for Real-Time Jailbreak Detection in Large Language Models", "abstract": "Large Language Models (LLMs) have become increasingly vulnerable to jailbreak\nattacks that circumvent their safety mechanisms. While existing defense methods\neither suffer from adaptive attacks or require computationally expensive\nauxiliary models, we present STShield, a lightweight framework for real-time\njailbroken judgement. STShield introduces a novel single-token sentinel\nmechanism that appends a binary safety indicator to the model's response\nsequence, leveraging the LLM's own alignment capabilities for detection. Our\nframework combines supervised fine-tuning on normal prompts with adversarial\ntraining using embedding-space perturbations, achieving robust detection while\npreserving model utility. Extensive experiments demonstrate that STShield\nsuccessfully defends against various jailbreak attacks, while maintaining the\nmodel's performance on legitimate queries. Compared to existing approaches,\nSTShield achieves superior defense performance with minimal computational\noverhead, making it a practical solution for real-world LLM deployment.", "published": "2025-03-23 04:23:07", "link": "http://arxiv.org/abs/2503.17932v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Debiasing Multimodal Large Language Models via Noise-Aware Preference Optimization", "abstract": "Multimodal Large Language Models excel in various tasks, yet often struggle\nwith modality bias, where the model tends to rely heavily on a single modality\nand overlook critical information in other modalities, which leads to incorrect\nfocus and generating irrelevant responses. In this paper, we propose using the\nparadigm of preference optimization to solve the modality bias problem,\nincluding RLAIFVBias, a debiased preference optimization dataset, and a Noise\nAware Preference Optimization algorithm. Specifically, we first construct the\ndataset by introducing perturbations to reduce the informational content of\ncertain modalities, compelling the model to rely on a specific modality when\ngenerating negative responses. To address the inevitable noise in automatically\nconstructed data, we combine the noise robust Mean Absolute Error with the\nBinary Cross Entropy in Direct Preference Optimization by a negative Box Cox\ntransformation, and dynamically adjust the algorithm noise robustness based on\nthe evaluated noise levels in the data. Extensive experiments validate our\napproach, demonstrating not only its effectiveness in mitigating modality bias\nbut also its significant role in minimizing hallucinations.", "published": "2025-03-23 04:00:11", "link": "http://arxiv.org/abs/2503.17928v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "WindowKV: Task-Adaptive Group-Wise KV Cache Window Selection for Efficient LLM Inference", "abstract": "With the advancements in long-context inference capabilities of large\nlanguage models (LLMs), the KV cache has become one of the foundational\ncomponents. However, its substantial GPU memory consumption makes KV cache\ncompression a key technique for enabling efficient LLM inference in industrial\nscenarios. While recent studies have focused on optimizing the memory occupied\nby the KV cache, they overlook two critical factors: preserving semantic\ncoherence and considering task-specific characteristic during compression. To\naddress these limitations, we propose a novel task-adaptive KV cache window\nselection method, WindowKV. WindowKV dynamically selects local semantic windows\nconsisting of consecutive tokens, according to task-specific characteristics,\nensuring the retained KV cache captures continuous, essential context.\nAdditionally, we introduce an intra-group layer KV cache indices sharing\nstrategy to reduce computational overhead, achieving a balance between\nperformance and efficiency. We rigorously evaluate WindowKV on the LongBench\nbenchmark, and the results demonstrate that it maintains a performance\ncomparable to full KV cache retention while using only 12% of the original KV\ncache, significantly reducing memory requirements. Furthermore, our method also\nachieves state-of-the-art results in the Needle-in-a-Haystack evaluation,\nhighlighting its effectiveness and robustness.", "published": "2025-03-23 03:36:52", "link": "http://arxiv.org/abs/2503.17922v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"Whose Side Are You On?\" Estimating Ideology of Political and News Content Using Large Language Models and Few-shot Demonstration Selection", "abstract": "The rapid growth of social media platforms has led to concerns about\nradicalization, filter bubbles, and content bias. Existing approaches to\nclassifying ideology are limited in that they require extensive human effort,\nthe labeling of large datasets, and are not able to adapt to evolving\nideological contexts. This paper explores the potential of Large Language\nModels (LLMs) for classifying the political ideology of online content in the\ncontext of the two-party US political spectrum through in-context learning\n(ICL). Our extensive experiments involving demonstration selection in\nlabel-balanced fashion, conducted on three datasets comprising news articles\nand YouTube videos, reveal that our approach significantly outperforms\nzero-shot and traditional supervised methods. Additionally, we evaluate the\ninfluence of metadata (e.g., content source and descriptions) on ideological\nclassification and discuss its implications. Finally, we show how providing the\nsource for political and non-political content influences the LLM's\nclassification.", "published": "2025-03-23 02:32:25", "link": "http://arxiv.org/abs/2503.20797v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan Generation", "abstract": "Despite recent success in applying large language models (LLMs) to electronic\nhealth records (EHR), most systems focus primarily on assessment rather than\ntreatment planning. We identify three critical limitations in current\napproaches: they generate treatment plans in a single pass rather than\nfollowing the sequential reasoning process used by clinicians; they rarely\nincorporate patient-specific historical context; and they fail to effectively\ndistinguish between subjective and objective clinical information. Motivated by\nthe SOAP methodology (Subjective, Objective, Assessment, Plan), we introduce\nMedPlan, a novel framework that structures LLM reasoning to align with\nreal-life clinician workflows. Our approach employs a two-stage architecture\nthat first generates a clinical assessment based on patient symptoms and\nobjective data, then formulates a structured treatment plan informed by this\nassessment and enriched with patient-specific information through\nretrieval-augmented generation. Comprehensive evaluation demonstrates that our\nmethod significantly outperforms baseline approaches in both assessment\naccuracy and treatment plan quality.", "published": "2025-03-23 02:03:56", "link": "http://arxiv.org/abs/2503.17900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Collaborating with AI Agents: Field Experiments on Teamwork, Productivity, and Performance", "abstract": "To uncover how AI agents change productivity, performance, and work\nprocesses, we introduce MindMeld: an experimentation platform enabling humans\nand AI agents to collaborate in integrative workspaces. In a large-scale\nmarketing experiment on the platform, 2310 participants were randomly assigned\nto human-human and human-AI teams, with randomized AI personality traits. The\nteams exchanged 183,691 messages, and created 63,656 image edits, 1,960,095 ad\ncopy edits, and 10,375 AI-generated images while producing 11,138 ads for a\nlarge think tank. Analysis of fine-grained communication, collaboration, and\nworkflow logs revealed that collaborating with AI agents increased\ncommunication by 137% and allowed humans to focus 23% more on text and image\ncontent generation messaging and 20% less on direct text editing. Humans on\nHuman-AI teams sent 23% fewer social messages, creating 60% greater\nproductivity per worker and higher-quality ad copy. In contrast, human-human\nteams produced higher-quality images, suggesting that AI agents require\nfine-tuning for multimodal workflows. AI personality prompt randomization\nrevealed that AI traits can complement human personalities to enhance\ncollaboration. For example, conscientious humans paired with open AI agents\nimproved image quality, while extroverted humans paired with conscientious AI\nagents reduced the quality of text, images, and clicks. In field tests of ad\ncampaigns with ~5M impressions, ads with higher image quality produced by human\ncollaborations and higher text quality produced by AI collaborations performed\nsignificantly better on click-through rate and cost per click metrics. Overall,\nads created by human-AI teams performed similarly to those created by\nhuman-human teams. Together, these results suggest AI agents can improve\nteamwork and productivity, especially when tuned to complement human traits.", "published": "2025-03-23 23:20:32", "link": "http://arxiv.org/abs/2503.18238v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Enhanced prediction of spine surgery outcomes using advanced machine learning techniques and oversampling methods", "abstract": "The study proposes an advanced machine learning approach to predict spine\nsurgery outcomes by incorporating oversampling techniques and grid search\noptimization. A variety of models including GaussianNB, ComplementNB, KNN,\nDecision Tree, and optimized versions with RandomOverSampler and SMOTE were\ntested on a dataset of 244 patients, which included pre-surgical, psychometric,\nsocioeconomic, and analytical variables. The enhanced KNN models achieved up to\n76% accuracy and a 67% F1-score, while grid-search optimization further\nimproved performance. The findings underscore the potential of these advanced\ntechniques to aid healthcare professionals in decision-making, with future\nresearch needed to refine these models on larger and more diverse datasets.", "published": "2025-03-23 22:39:19", "link": "http://arxiv.org/abs/2503.18996v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Adaptive Multi-Fidelity Reinforcement Learning for Variance Reduction in Engineering Design Optimization", "abstract": "Multi-fidelity Reinforcement Learning (RL) frameworks efficiently utilize\ncomputational resources by integrating analysis models of varying accuracy and\ncosts. The prevailing methodologies, characterized by transfer learning,\nhuman-inspired strategies, control variate techniques, and adaptive sampling,\npredominantly depend on a structured hierarchy of models. However, this\nreliance on a model hierarchy can exacerbate variance in policy learning when\nthe underlying models exhibit heterogeneous error distributions across the\ndesign space. To address this challenge, this work proposes a novel adaptive\nmulti-fidelity RL framework, in which multiple heterogeneous, non-hierarchical\nlow-fidelity models are dynamically leveraged alongside a high-fidelity model\nto efficiently learn a high-fidelity policy. Specifically, low-fidelity\npolicies and their experience data are adaptively used for efficient targeted\nlearning, guided by their alignment with the high-fidelity policy. The\neffectiveness of the approach is demonstrated in an octocopter design\noptimization problem, utilizing two low-fidelity models alongside a\nhigh-fidelity simulator. The results demonstrate that the proposed approach\nsubstantially reduces variance in policy learning, leading to improved\nconvergence and consistent high-quality solutions relative to traditional\nhierarchical multi-fidelity RL methods. Moreover, the framework eliminates the\nneed for manually tuning model usage schedules, which can otherwise introduce\nsignificant computational overhead. This positions the framework as an\neffective variance-reduction strategy for multi-fidelity RL, while also\nmitigating the computational and operational burden of manual fidelity\nscheduling.", "published": "2025-03-23 22:29:08", "link": "http://arxiv.org/abs/2503.18229v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PG-SAM: Prior-Guided SAM with Medical for Multi-organ Segmentation", "abstract": "Segment Anything Model (SAM) demonstrates powerful zero-shot capabilities;\nhowever, its accuracy and robustness significantly decrease when applied to\nmedical image segmentation. Existing methods address this issue through\nmodality fusion, integrating textual and image information to provide more\ndetailed priors. In this study, we argue that the granularity of text and the\ndomain gap affect the accuracy of the priors. Furthermore, the discrepancy\nbetween high-level abstract semantics and pixel-level boundary details in\nimages can introduce noise into the fusion process. To address this, we propose\nPrior-Guided SAM (PG-SAM), which employs a fine-grained modality prior aligner\nto leverage specialized medical knowledge for better modality alignment. The\ncore of our method lies in efficiently addressing the domain gap with\nfine-grained text from a medical LLM. Meanwhile, it also enhances the priors'\nquality after modality alignment, ensuring more accurate segmentation. In\naddition, our decoder enhances the model's expressive capabilities through\nmulti-level feature fusion and iterative mask optimizer operations, supporting\nunprompted learning. We also propose a unified pipeline that effectively\nsupplies high-quality semantic information to SAM. Extensive experiments on the\nSynapse dataset demonstrate that the proposed PG-SAM achieves state-of-the-art\nperformance. Our code is released at https://github.com/logan-0623/PG-SAM.", "published": "2025-03-23 22:06:07", "link": "http://arxiv.org/abs/2503.18227v3", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LLMs in the Classroom: Outcomes and Perceptions of Questions Written with the Aid of AI", "abstract": "We randomly deploy questions constructed with and without use of the LLM tool\nand gauge the ability of the students to correctly answer, as well as their\nability to correctly perceive the difference between human-authored and\nLLM-authored questions. In determining whether the questions written with the\naid of ChatGPT were consistent with the instructor's questions and source text,\nwe computed representative vectors of both the human and ChatGPT questions\nusing SBERT and compared cosine similarity to the course textbook. A\nnon-significant Mann-Whitney U test (z = 1.018, p = .309) suggests that\nstudents were unable to perceive whether questions were written with or without\nthe aid of ChatGPT. However, student scores on LLM-authored questions were\nalmost 9% lower (z = 2.702, p < .01). This result may indicate that either the\nAI questions were more difficult or that the students were more familiar with\nthe instructor's style of questions. Overall, the study suggests that while\nthere is potential for using LLM tools to aid in the construction of\nassessments, care must be taken to ensure that the questions are fair,\nwell-composed, and relevant to the course material.", "published": "2025-03-23 22:01:49", "link": "http://arxiv.org/abs/2503.18995v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "A Study on Neuro-Symbolic Artificial Intelligence: Healthcare Perspectives", "abstract": "Over the last few decades, Artificial Intelligence (AI) scientists have been\nconducting investigations to attain human-level performance by a machine in\naccomplishing a cognitive task. Within machine learning, the ultimate\naspiration is to attain Artificial General Intelligence (AGI) through a\nmachine. This pursuit has led to the exploration of two distinct AI paradigms.\nSymbolic AI, also known as classical or GOFAI (Good Old-Fashioned AI) and\nConnectionist (Sub-symbolic) AI, represented by Neural Systems, are two\nmutually exclusive paradigms. Symbolic AI excels in reasoning, explainability,\nand knowledge representation but faces challenges in processing complex\nreal-world data with noise. Conversely, deep learning (Black-Box systems)\nresearch breakthroughs in neural networks are notable, yet they lack reasoning\nand interpretability. Neuro-symbolic AI (NeSy), an emerging area of AI\nresearch, attempts to bridge this gap by integrating logical reasoning into\nneural networks, enabling them to learn and reason with symbolic\nrepresentations. While a long path, this strategy has made significant progress\ntowards achieving common sense reasoning by systems. This article conducts an\nextensive review of over 977 studies from prominent scientific databases (DBLP,\nACL, IEEExplore, Scopus, PubMed, ICML, ICLR), thoroughly examining the\nmultifaceted capabilities of Neuro-Symbolic AI, with a particular focus on its\nhealthcare applications, particularly in drug discovery, and Protein\nengineering research. The survey addresses vital themes, including reasoning,\nexplainability, integration strategies, 41 healthcare-related use cases,\nbenchmarking, datasets, current approach limitations from both healthcare and\nbroader perspectives, and proposed novel approaches for future experiments.", "published": "2025-03-23 21:33:38", "link": "http://arxiv.org/abs/2503.18213v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ViVa: Video-Trained Value Functions for Guiding Online RL from Diverse Data", "abstract": "Online reinforcement learning (RL) with sparse rewards poses a challenge\npartly because of the lack of feedback on states leading to the goal.\nFurthermore, expert offline data with reward signal is rarely available to\nprovide this feedback and bootstrap online learning. How can we guide online\nagents to the right solution without this on-task data? Reward shaping offers a\nsolution by providing fine-grained signal to nudge the policy towards the\noptimal solution. However, reward shaping often requires domain knowledge to\nhand-engineer heuristics for a specific goal. To enable more general and\ninexpensive guidance, we propose and analyze a data-driven methodology that\nautomatically guides RL by learning from widely available video data such as\nInternet recordings, off-task demonstrations, task failures, and undirected\nenvironment interaction. By learning a model of optimal goal-conditioned value\nfrom diverse passive data, we open the floor to scaling up and using various\ndata sources to model general goal-reaching behaviors relevant to guiding\nonline RL. Specifically, we use intent-conditioned value functions to learn\nfrom diverse videos and incorporate these goal-conditioned values into the\nreward. Our experiments show that video-trained value functions work well with\na variety of data sources, exhibit positive transfer from human video\npre-training, can generalize to unseen goals, and scale with dataset size.", "published": "2025-03-23 21:24:33", "link": "http://arxiv.org/abs/2503.18210v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FROG: Fair Removal on Graphs", "abstract": "As compliance with privacy regulations becomes increasingly critical, the\ngrowing demand for data privacy has highlighted the significance of machine\nunlearning in many real world applications, such as social network and\nrecommender systems, many of which can be represented as graph-structured data.\nHowever, existing graph unlearning algorithms indiscriminately modify edges or\nnodes from well-trained models without considering the potential impact of such\nstructural modifications on fairness. For example, forgetting links between\nnodes with different genders in a social network may exacerbate group\ndisparities, leading to significant fairness concerns. To address these\nchallenges, we propose a novel approach that jointly optimizes the graph\nstructure and the corresponding model for fair unlearning tasks.\nSpecifically,our approach rewires the graph to enhance unlearning efficiency by\nremoving redundant edges that hinder forgetting while preserving fairness\nthrough targeted edge augmentation. Additionally, we introduce a worst-case\nevaluation mechanism to assess the reliability of fair unlearning performance.\nExtensive experiments on real-world datasets demonstrate the effectiveness of\nthe proposed approach in achieving superior unlearning outcomes.", "published": "2025-03-23 20:39:53", "link": "http://arxiv.org/abs/2503.18197v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Exploring Energy Landscapes for Minimal Counterfactual Explanations: Applications in Cybersecurity and Beyond", "abstract": "Counterfactual explanations have emerged as a prominent method in Explainable\nArtificial Intelligence (XAI), providing intuitive and actionable insights into\nMachine Learning model decisions. In contrast to other traditional feature\nattribution methods that assess the importance of input variables,\ncounterfactual explanations focus on identifying the minimal changes required\nto alter a model's prediction, offering a ``what-if'' analysis that is close to\nhuman reasoning. In the context of XAI, counterfactuals enhance transparency,\ntrustworthiness and fairness, offering explanations that are not just\ninterpretable but directly applicable in the decision-making processes.\n  In this paper, we present a novel framework that integrates perturbation\ntheory and statistical mechanics to generate minimal counterfactual\nexplanations in explainable AI. We employ a local Taylor expansion of a Machine\nLearning model's predictive function and reformulate the counterfactual search\nas an energy minimization problem over a complex landscape. In sequence, we\nmodel the probability of candidate perturbations leveraging the Boltzmann\ndistribution and use simulated annealing for iterative refinement. Our approach\nsystematically identifies the smallest modifications required to change a\nmodel's prediction while maintaining plausibility. Experimental results on\nbenchmark datasets for cybersecurity in Internet of Things environments,\ndemonstrate that our method provides actionable, interpretable counterfactuals\nand offers deeper insights into model sensitivity and decision boundaries in\nhigh-dimensional spaces.", "published": "2025-03-23 19:48:37", "link": "http://arxiv.org/abs/2503.18185v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Adaptive Physics-informed Neural Networks: A Survey", "abstract": "Physics-informed neural networks (PINNs) have emerged as a promising approach\nto solving partial differential equations (PDEs) using neural networks,\nparticularly in data-scarce scenarios, due to their unsupervised training\ncapability. However, limitations related to convergence and the need for\nre-optimization with each change in PDE parameters hinder their widespread\nadoption across scientific and engineering applications. This survey reviews\nexisting research that addresses these limitations through transfer learning\nand meta-learning. The covered methods improve the training efficiency,\nallowing faster adaptation to new PDEs with fewer data and computational\nresources. While traditional numerical methods solve systems of differential\nequations directly, neural networks learn solutions implicitly by adjusting\ntheir parameters. One notable advantage of neural networks is their ability to\nabstract away from specific problem domains, allowing them to retain, discard,\nor adapt learned representations to efficiently address similar problems. By\nexploring the application of these techniques to PINNs, this survey identifies\npromising directions for future research to facilitate the broader adoption of\nPINNs in a wide range of scientific and engineering applications.", "published": "2025-03-23 19:33:05", "link": "http://arxiv.org/abs/2503.18181v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "HH4AI: A methodological Framework for AI Human Rights impact assessment under the EUAI ACT", "abstract": "This paper introduces the HH4AI Methodology, a structured approach to\nassessing the impact of AI systems on human rights, focusing on compliance with\nthe EU AI Act and addressing technical, ethical, and regulatory challenges. The\npaper highlights AIs transformative nature, driven by autonomy, data, and\ngoal-oriented design, and how the EU AI Act promotes transparency,\naccountability, and safety. A key challenge is defining and assessing\n\"high-risk\" AI systems across industries, complicated by the lack of\nuniversally accepted standards and AIs rapid evolution.\n  To address these challenges, the paper explores the relevance of ISO/IEC and\nIEEE standards, focusing on risk management, data quality, bias mitigation, and\ngovernance. It proposes a Fundamental Rights Impact Assessment (FRIA)\nmethodology, a gate-based framework designed to isolate and assess risks\nthrough phases including an AI system overview, a human rights checklist, an\nimpact assessment, and a final output phase. A filtering mechanism tailors the\nassessment to the system's characteristics, targeting areas like\naccountability, AI literacy, data governance, and transparency.\n  The paper illustrates the FRIA methodology through a fictional case study of\nan automated healthcare triage service. The structured approach enables\nsystematic filtering, comprehensive risk assessment, and mitigation planning,\neffectively prioritizing critical risks and providing clear remediation\nstrategies. This promotes better alignment with human rights principles and\nenhances regulatory compliance.", "published": "2025-03-23 19:10:14", "link": "http://arxiv.org/abs/2503.18994v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Self-Attention Diffusion Models for Zero-Shot Biomedical Image Segmentation: Unlocking New Frontiers in Medical Imaging", "abstract": "Producing high-quality segmentation masks for medical images is a fundamental\nchallenge in biomedical image analysis. Recent research has explored\nlarge-scale supervised training to enable segmentation across various medical\nimaging modalities and unsupervised training to facilitate segmentation without\ndense annotations. However, constructing a model capable of segmenting diverse\nmedical images in a zero-shot manner without any annotations remains a\nsignificant hurdle. This paper introduces the Attention Diffusion Zero-shot\nUnsupervised System (ADZUS), a novel approach that leverages self-attention\ndiffusion models for zero-shot biomedical image segmentation. ADZUS harnesses\nthe intrinsic capabilities of pre-trained diffusion models, utilizing their\ngenerative and discriminative potentials to segment medical images without\nrequiring annotated training data or prior domain-specific knowledge. The ADZUS\narchitecture is detailed, with its integration of self-attention mechanisms\nthat facilitate context-aware and detail-sensitive segmentations being\nhighlighted. Experimental results across various medical imaging datasets,\nincluding skin lesion segmentation, chest X-ray infection segmentation, and\nwhite blood cell segmentation, reveal that ADZUS achieves state-of-the-art\nperformance. Notably, ADZUS reached Dice scores ranging from 88.7\\% to 92.9\\%\nand IoU scores from 66.3\\% to 93.3\\% across different segmentation tasks,\ndemonstrating significant improvements in handling novel, unseen medical\nimagery. It is noteworthy that while ADZUS demonstrates high effectiveness, it\ndemands substantial computational resources and extended processing times. The\nmodel's efficacy in zero-shot settings underscores its potential to reduce\nreliance on costly annotations and seamlessly adapt to new medical imaging\ntasks, thereby expanding the diagnostic capabilities of AI-driven medical\nimaging technologies.", "published": "2025-03-23 18:47:12", "link": "http://arxiv.org/abs/2503.18170v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Strategic Prompt Pricing for AIGC Services: A User-Centric Approach", "abstract": "The rapid growth of AI-generated content (AIGC) services has created an\nurgent need for effective prompt pricing strategies, yet current approaches\noverlook users' strategic two-step decision-making process in selecting and\nutilizing generative AI models. This oversight creates two key technical\nchallenges: quantifying the relationship between user prompt capabilities and\ngeneration outcomes, and optimizing platform payoff while accounting for\nheterogeneous user behaviors. We address these challenges by introducing prompt\nambiguity, a theoretical framework that captures users' varying abilities in\nprompt engineering, and developing an Optimal Prompt Pricing (OPP) algorithm.\nOur analysis reveals a counterintuitive insight: users with higher prompt\nambiguity (i.e., lower capability) exhibit non-monotonic prompt usage patterns,\nfirst increasing then decreasing with ambiguity levels, reflecting complex\nchanges in marginal utility. Experimental evaluation using a character-level\nGPT-like model demonstrates that our OPP algorithm achieves up to 31.72%\nimprovement in platform payoff compared to existing pricing mechanisms,\nvalidating the importance of user-centric prompt pricing in AIGC services.", "published": "2025-03-23 18:41:06", "link": "http://arxiv.org/abs/2503.18168v1", "categories": ["cs.AI", "cs.CE"], "primary_category": "cs.AI"}
{"title": "SNRAware: Improved Deep Learning MRI Denoising with SNR Unit Training and G-factor Map Augmentation", "abstract": "To develop and evaluate a new deep learning MR denoising method that\nleverages quantitative noise distribution information from the reconstruction\nprocess to improve denoising performance and generalization.\n  This retrospective study trained 14 different transformer and convolutional\nmodels with two backbone architectures on a large dataset of 2,885,236 images\nfrom 96,605 cardiac retro-gated cine complex series acquired at 3T. The\nproposed training scheme, termed SNRAware, leverages knowledge of the MRI\nreconstruction process to improve denoising performance by simulating large,\nhigh quality, and diverse synthetic datasets, and providing quantitative\ninformation about the noise distribution to the model. In-distribution testing\nwas performed on a hold-out dataset of 3000 samples with performance measured\nusing PSNR and SSIM, with ablation comparison without the noise augmentation.\nOut-of-distribution tests were conducted on cardiac real-time cine, first-pass\ncardiac perfusion, and neuro and spine MRI, all acquired at 1.5T, to test model\ngeneralization across imaging sequences, dynamically changing contrast,\ndifferent anatomies, and field strengths. The best model found in the\nin-distribution test generalized well to out-of-distribution samples,\ndelivering 6.5x and 2.9x CNR improvement for real-time cine and perfusion\nimaging, respectively. Further, a model trained with 100% cardiac cine data\ngeneralized well to a T1 MPRAGE neuro 3D scan and T2 TSE spine MRI.", "published": "2025-03-23 18:16:36", "link": "http://arxiv.org/abs/2503.18162v1", "categories": ["physics.med-ph", "cs.AI", "cs.CV", "eess.IV"], "primary_category": "physics.med-ph"}
{"title": "Active Inference for Energy Control and Planning in Smart Buildings and Communities", "abstract": "Active Inference (AIF) is emerging as a powerful framework for\ndecision-making under uncertainty, yet its potential in engineering\napplications remains largely unexplored. In this work, we propose a novel\ndual-layer AIF architecture that addresses both building-level and\ncommunity-level energy management. By leveraging the free energy principle,\neach layer adapts to evolving conditions and handles partial observability\nwithout extensive sensor information and respecting data privacy. We validate\nthe continuous AIF model against both a perfect optimization baseline and a\nreinforcement learning-based approach. We also test the community AIF framework\nunder extreme pricing scenarios. The results highlight the model's robustness\nin handling abrupt changes. This study is the first to show how a distributed\nAIF works in engineering. It also highlights new opportunities for\nprivacy-preserving and uncertainty-aware control strategies in engineering\napplications.", "published": "2025-03-23 18:03:01", "link": "http://arxiv.org/abs/2503.18161v1", "categories": ["math.OC", "cs.AI", "cs.LG"], "primary_category": "math.OC"}
{"title": "DiffusionTalker: Efficient and Compact Speech-Driven 3D Talking Head via Personalizer-Guided Distillation", "abstract": "Real-time speech-driven 3D facial animation has been attractive in academia\nand industry. Traditional methods mainly focus on learning a deterministic\nmapping from speech to animation. Recent approaches start to consider the\nnondeterministic fact of speech-driven 3D face animation and employ the\ndiffusion model for the task. Existing diffusion-based methods can improve the\ndiversity of facial animation. However, personalized speaking styles conveying\naccurate lip language is still lacking, besides, efficiency and compactness\nstill need to be improved. In this work, we propose DiffusionTalker to address\nthe above limitations via personalizer-guided distillation. In terms of\npersonalization, we introduce a contrastive personalizer that learns identity\nand emotion embeddings to capture speaking styles from audio. We further\npropose a personalizer enhancer during distillation to enhance the influence of\nembeddings on facial animation. For efficiency, we use iterative distillation\nto reduce the steps required for animation generation and achieve more than 8x\nspeedup in inference. To achieve compactness, we distill the large teacher\nmodel into a smaller student model, reducing our model's storage by 86.4\\%\nwhile minimizing performance loss. After distillation, users can derive their\nidentity and emotion embeddings from audio to quickly create personalized\nanimations that reflect specific speaking styles. Extensive experiments are\nconducted to demonstrate that our method outperforms state-of-the-art methods.\nThe code will be released at: https://github.com/ChenVoid/DiffusionTalker.", "published": "2025-03-23 17:55:54", "link": "http://arxiv.org/abs/2503.18159v1", "categories": ["cs.CV", "cs.AI", "cs.SD"], "primary_category": "cs.CV"}
{"title": "Adoption of Watermarking for Generative AI Systems in Practice and Implications under the new EU AI Act", "abstract": "AI-generated images have become so good in recent years that individuals\ncannot distinguish them any more from \"real\" images. This development creates a\nseries of societal risks, and challenges our perception of what is true and\nwhat is not, particularly with the emergence of \"deep fakes\" that impersonate\nreal individuals. Watermarking, a technique that involves embedding identifying\ninformation within images to indicate their AI-generated nature, has emerged as\na primary mechanism to address the risks posed by AI-generated images. The\nimplementation of watermarking techniques is now becoming a legal requirement\nin many jurisdictions, including under the new 2024 EU AI Act. Despite the\nwidespread use of AI image generation systems, the current status of\nwatermarking implementation remains largely unexamined. Moreover, the practical\nimplications of the AI Act's watermarking requirements have not previously been\nstudied. The present paper therefore both provides an empirical analysis of 50\nof the most widely used AI systems for image generation, and embeds this\nempirical analysis into a legal analysis of the AI Act. We identify four\ncategories of generative AI image systems relevant under the AI Act, outline\nthe legal obligations for each category, and find that only a minority number\nof providers currently implement adequate watermarking practices.", "published": "2025-03-23 17:55:33", "link": "http://arxiv.org/abs/2503.18156v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Efficient Deep Learning Approaches for Processing Ultra-Widefield Retinal Imaging", "abstract": "Deep learning has emerged as the predominant solution for classifying medical\nimages. We intend to apply these developments to the ultra-widefield (UWF)\nretinal imaging dataset. Since UWF images can accurately diagnose various\nretina diseases, it is very important to clas sify them accurately and prevent\nthem with early treatment. However, processing images manually is\ntime-consuming and labor-intensive, and there are two challenges to automating\nthis process. First, high perfor mance usually requires high computational\nresources. Artificial intelli gence medical technology is better suited for\nplaces with limited medical resources, but using high-performance processing\nunits in such environ ments is challenging. Second, the problem of the accuracy\nof colour fun dus photography (CFP) methods. In general, the UWF method\nprovides more information for retinal diagnosis than the CFP method, but most\nof the research has been conducted based on the CFP method. Thus, we\ndemonstrate that these problems can be efficiently addressed in low performance\nunits using methods such as strategic data augmentation and model ensembles,\nwhich balance performance and computational re sources while utilizing UWF\nimages.", "published": "2025-03-23 17:43:24", "link": "http://arxiv.org/abs/2503.18151v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "LocDiffusion: Identifying Locations on Earth by Diffusing in the Hilbert Space", "abstract": "Image geolocalization is a fundamental yet challenging task, aiming at\ninferring the geolocation on Earth where an image is taken. Existing methods\napproach it either via grid-based classification or via image retrieval. Their\nperformance significantly suffers when the spatial distribution of test images\ndoes not align with such choices. To address these limitations, we propose to\nleverage diffusion as a mechanism for image geolocalization. To avoid the\nproblematic manifold reprojection step in diffusion, we developed a novel\nspherical positional encoding-decoding framework, which encodes points on a\nspherical surface (e.g., geolocations on Earth) into a Hilbert space of\nSpherical Harmonics coefficients and decodes points (geolocations) by\nmode-seeking. We call this type of position encoding Spherical Harmonics Dirac\nDelta (SHDD) Representation. We also propose a novel SirenNet-based\narchitecture called CS-UNet to learn the conditional backward process in the\nlatent SHDD space by minimizing a latent KL-divergence loss. We train a\nconditional latent diffusion model called LocDiffusion that generates\ngeolocations under the guidance of images -- to the best of our knowledge, the\nfirst generative model for image geolocalization by diffusing geolocation\ninformation in a hidden location embedding space. We evaluate our method\nagainst SOTA image geolocalization baselines. LocDiffusion achieves competitive\ngeolocalization performance and demonstrates significantly stronger\ngeneralizability to unseen geolocations.", "published": "2025-03-23 17:15:26", "link": "http://arxiv.org/abs/2503.18142v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Mitigating Reward Over-Optimization in RLHF via Behavior-Supported Regularization", "abstract": "Reinforcement learning from human feedback (RLHF) is an effective method for\naligning large language models (LLMs) with human values. However, reward\nover-optimization remains an open challenge leading to discrepancies between\nthe performance of LLMs under the reward model and the true human objectives. A\nprimary contributor to reward over-optimization is the extrapolation error that\narises when the reward model evaluates out-of-distribution (OOD) responses.\nHowever, current methods still fail to prevent the increasing frequency of OOD\nresponse generation during the reinforcement learning (RL) process and are not\neffective at handling extrapolation errors from OOD responses. In this work, we\npropose the Behavior-Supported Policy Optimization (BSPO) method to mitigate\nthe reward over-optimization issue. Specifically, we define behavior policy as\nthe next token distribution of the reward training dataset to model the\nin-distribution (ID) region of the reward model. Building on this, we introduce\nthe behavior-supported Bellman operator to regularize the value function,\npenalizing all OOD values without impacting the ID ones. Consequently, BSPO\nreduces the generation of OOD responses during the RL process, thereby avoiding\noverestimation caused by the reward model's extrapolation errors.\nTheoretically, we prove that BSPO guarantees a monotonic improvement of the\nsupported policy until convergence to the optimal behavior-supported policy.\nEmpirical results from extensive experiments show that BSPO outperforms\nbaselines in preventing reward over-optimization due to OOD evaluation and\nfinding the optimal ID policy.", "published": "2025-03-23 16:20:59", "link": "http://arxiv.org/abs/2503.18130v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Novel Two-Phase Cooperative Co-evolution Framework for Large-Scale Global Optimization with Complex Overlapping", "abstract": "Cooperative Co-evolution, through the decomposition of the problem space, is\na primary approach for solving large-scale global optimization problems.\nTypically, when the subspaces are disjoint, the algorithms demonstrate\nsignificantly both effectiveness and efficiency compared to non-decomposition\nalgorithms. However, the presence of overlapping variables complicates the\ndecomposition process and adversely affects the performance of cooperative\nco-evolution. In this study, we propose a novel two-phase cooperative\nco-evolution framework to address large-scale global optimization problems with\ncomplex overlapping. An effective method for decomposing overlapping problems,\ngrounded in their mathematical properties, is embedded within the framework.\nAdditionally, a customizable benchmark for overlapping problems is introduced\nto extend existing benchmarks and facilitate experimentation. Extensive\nexperiments demonstrate that the algorithm instantiated within our framework\nsignificantly outperforms existing algorithms. The results reveal the\ncharacteristics of overlapping problems and highlight the differing strengths\nof cooperative co-evolution and non-decomposition algorithms. Our work is\nopen-source and accessible at: https://github.com/GMC-DRL/HCC.", "published": "2025-03-23 13:21:11", "link": "http://arxiv.org/abs/2503.21797v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Learning to Interfere in Non-Orthogonal Multiple-Access Joint Source-Channel Coding", "abstract": "We consider multiple transmitters aiming to communicate their source signals\n(e.g., images) over a multiple access channel (MAC). Conventional communication\nsystems minimize interference by orthogonally allocating resources (time and/or\nbandwidth) among users, which limits their capacity. We introduce a machine\nlearning (ML)-aided wireless image transmission method that merges compression\nand channel coding using a multi-view autoencoder, which allows the\ntransmitters to use all the available channel resources simultaneously,\nresulting in a non-orthogonal multiple access (NOMA) scheme. The receiver must\nrecover all the images from the received superposed signal, while also\nassociating each image with its transmitter. Traditional ML models deal with\nindividual samples, whereas our model allows signals from different users to\ninterfere in order to leverage gains from NOMA under limited bandwidth and\npower constraints. We introduce a progressive fine-tuning algorithm that\ndoubles the number of users at each iteration, maintaining initial performance\nwith orthogonalized user-specific projections, which is then improved through\nfine-tuning steps. Remarkably, our method scales up to 16 users and beyond,\nwith only a 0.6% increase in the number of trainable parameters compared to a\nsingle-user model, significantly enhancing recovered image quality and\noutperforming existing NOMA-based methods over a wide range of datasets,\nmetrics, and channel conditions. Our approach paves the way for more efficient\nand robust multi-user communication systems, leveraging innovative ML\ncomponents and strategies.", "published": "2025-03-23 12:27:20", "link": "http://arxiv.org/abs/2504.03690v1", "categories": ["cs.NI", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.NI"}
{"title": "Decision from Suboptimal Classifiers: Excess Risk Pre- and Post-Calibration", "abstract": "Probabilistic classifiers are central for making informed decisions under\nuncertainty. Based on the maximum expected utility principle, optimal decision\nrules can be derived using the posterior class probabilities and\nmisclassification costs. Yet, in practice only learned approximations of the\noracle posterior probabilities are available. In this work, we quantify the\nexcess risk (a.k.a. regret) incurred using approximate posterior probabilities\nin batch binary decision-making. We provide analytical expressions for\nmiscalibration-induced regret ($R^{\\mathrm{CL}}$), as well as tight and\ninformative upper and lower bounds on the regret of calibrated classifiers\n($R^{\\mathrm{GL}}$). These expressions allow us to identify regimes where\nrecalibration alone addresses most of the regret, and regimes where the regret\nis dominated by the grouping loss, which calls for post-training beyond\nrecalibration. Crucially, both $R^{\\mathrm{CL}}$ and $R^{\\mathrm{GL}}$ can be\nestimated in practice using a calibration curve and a recent grouping loss\nestimator. On NLP experiments, we show that these quantities identify when the\nexpected gain of more advanced post-training is worth the operational cost.\nFinally, we highlight the potential of multicalibration approaches as efficient\nalternatives to costlier fine-tuning approaches.", "published": "2025-03-23 10:52:36", "link": "http://arxiv.org/abs/2503.18025v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Lost in Cultural Translation: Do LLMs Struggle with Math Across Cultural Contexts?", "abstract": "Large Language Models (LLMs) have significantly advanced various fields,\nparticularly coding, mathematical reasoning, and logical problem solving.\nHowever, a critical question remains: Do these mathematical reasoning abilities\npersist when LLMs are presented with culturally adapted math problems?\nSpecifically, how do LLMs perform when faced with math problems embedded in\ncultural contexts that have no significant representation in main stream\nweb-scale AI training data? To explore this, we generated six synthetic\ncultural datasets from GSM8K, a widely used benchmark for assessing LLMs'\nmathematical reasoning skills. While preserving the mathematical logic and\nnumerical values of the original GSM8K test set, we modify cultural elements\nsuch as personal names, food items, place names, etc. These culturally adapted\ndatasets provide a more reliable framework for evaluating LLMs' mathematical\nreasoning under shifting cultural contexts. Our findings reveal that LLMs\nstruggle with math problems when cultural references change, even though the\nunderlying mathematical structure remains constant. Smaller models exhibit\ngreater performance drops compared to larger models. Interestingly, our results\nalso suggest that cultural familiarity can enhance mathematical reasoning. Even\nmodels with no explicit mathematical training but exposure to relevant cultural\ncontexts sometimes outperform larger, mathematically proficient models on\nculturally embedded math problems. This study highlights the impact of cultural\ncontext on the mathematical reasoning abilities of LLMs, underscoring the need\nfor more diverse and representative training data to improve robustness in\nreal-world applications. The benchmark data sets and script for reproducing the\nresults are available at\nhttps://github.com/akarim23131/Lost_in_Cultural_Translation", "published": "2025-03-23 10:35:39", "link": "http://arxiv.org/abs/2503.18018v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning", "abstract": "Large Vision-Language Models (LVLMs) typically follow a two-stage training\nparadigm-pretraining and supervised fine-tuning. Recently, preference\noptimization, derived from the language domain, has emerged as an effective\npost-training reinforcement strategy to enhance capabilities of LVLMs. However,\nconstructing high-quality human-annotated preference data and developing robust\nreward models to mimic these preferences are both costly and challenging.\nMotivated by this observation, we propose Vision-R1, a novel vision-guided\nR1-like reinforcement learning algorithm for LVLMs that rewards models with\ndefinitive vision feedback. It only leverages curated instruction data,\neliminating the need for specialized reward models and handcrafted preference\ndatasets. We incorporate a criterion-driven reward function that further\nintegrates multi-dimensional feedback to evaluate model completions\ncomprehensively based on the vision task logic. Furthermore, we introduce a\nprogressive rule refinement strategy that dynamically adjusts the reward\ncriteria during training, enabling continuous model improvement and mitigating\nreward hacking. Extensive experiments on both in-distribution and\nout-of-distribution benchmarks demonstrate that fine-tuning the 7B LVLMs with\nVision-R1 achieves consistent performance gains, with even up to 50%\nimprovement and surpassing the state-of-the-art 10x size model.", "published": "2025-03-23 10:21:14", "link": "http://arxiv.org/abs/2503.18013v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SG-Tailor: Inter-Object Commonsense Relationship Reasoning for Scene Graph Manipulation", "abstract": "Scene graphs capture complex relationships among objects, serving as strong\npriors for content generation and manipulation. Yet, reasonably manipulating\nscene graphs -- whether by adding nodes or modifying edges -- remains a\nchallenging and untouched task. Tasks such as adding a node to the graph or\nreasoning about a node's relationships with all others are computationally\nintractable, as even a single edge modification can trigger conflicts due to\nthe intricate interdependencies within the graph. To address these challenges,\nwe introduce SG-Tailor, an autoregressive model that predicts the conflict-free\nrelationship between any two nodes. SG-Tailor not only infers inter-object\nrelationships, including generating commonsense edges for newly added nodes but\nalso resolves conflicts arising from edge modifications to produce coherent,\nmanipulated graphs for downstream tasks. For node addition, the model queries\nthe target node and other nodes from the graph to predict the appropriate\nrelationships. For edge modification, SG-Tailor employs a Cut-And-Stitch\nstrategy to solve the conflicts and globally adjust the graph. Extensive\nexperiments demonstrate that SG-Tailor outperforms competing methods by a large\nmargin and can be seamlessly integrated as a plug-in module for scene\ngeneration and robotic manipulation tasks.", "published": "2025-03-23 09:11:04", "link": "http://arxiv.org/abs/2503.18988v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Predicting Multitasking in Manual and Automated Driving with Optimal Supervisory Control", "abstract": "Modern driving involves interactive technologies that can divert attention,\nincreasing the risk of accidents. This paper presents a computational cognitive\nmodel that simulates human multitasking while driving. Based on optimal\nsupervisory control theory, the model predicts how multitasking adapts to\nvariations in driving demands, interactive tasks, and automation levels. Unlike\nprevious models, it accounts for context-dependent multitasking across\ndifferent degrees of driving automation. The model predicts longer in-car\nglances on straight roads and shorter glances during curves. It also\nanticipates increased glance durations with driver aids such as lane-centering\nassistance and their interaction with environmental demands. Validated against\ntwo empirical datasets, the model offers insights into driver multitasking amid\nevolving in-car technologies and automation.", "published": "2025-03-23 08:56:53", "link": "http://arxiv.org/abs/2503.17993v1", "categories": ["cs.HC", "cs.AI", "cs.LG", "H.1.2"], "primary_category": "cs.HC"}
{"title": "Metaphor-based Jailbreaking Attacks on Text-to-Image Models", "abstract": "To mitigate misuse, text-to-image~(T2I) models commonly incorporate safety\nfilters to prevent the generation of sensitive images. Unfortunately, recent\njailbreaking attack methods use LLMs to generate adversarial prompts that\neffectively bypass safety filters while generating sensitive images, revealing\nthe safety vulnerabilities within the T2I model. However, existing LLM-based\nattack methods lack explicit guidance, relying on substantial queries to\nachieve a successful attack, which limits their practicality in real-world\nscenarios. In this work, we introduce \\textbf{MJA}, a \\textbf{m}etaphor-based\n\\textbf{j}ailbreaking \\textbf{a}ttack method inspired by the Taboo game, aiming\nto balance the attack effectiveness and query efficiency by generating\nmetaphor-based adversarial prompts. Specifically, MJA consists of two modules:\nan LLM-based multi-agent generation module~(MLAG) and an adversarial prompt\noptimization module~(APO). MLAG decomposes the generation of metaphor-based\nadversarial prompts into three subtasks: metaphor retrieval, context matching,\nand adversarial prompt generation. Subsequently, MLAG coordinates three\nLLM-based agents to generate diverse adversarial prompts by exploring various\nmetaphors and contexts. To enhance the attack efficiency, APO first trains a\nsurrogate model to predict the attack results of adversarial prompts and then\ndesigns an acquisition strategy to adaptively identify optimal adversarial\nprompts. Experiments demonstrate that MJA achieves better attack effectiveness\nwhile requiring fewer queries compared to baseline methods. Moreover, our\nadversarial prompts exhibit strong transferability across various open-source\nand commercial T2I models. \\textcolor{red}{This paper includes model-generated\ncontent that may contain offensive or distressing material.}", "published": "2025-03-23 08:40:39", "link": "http://arxiv.org/abs/2503.17987v1", "categories": ["cs.CR", "cs.AI", "cs.CV"], "primary_category": "cs.CR"}
{"title": "Optimizing Navigation And Chemical Application in Precision Agriculture With Deep Reinforcement Learning And Conditional Action Tree", "abstract": "This paper presents a novel reinforcement learning (RL)-based planning scheme\nfor optimized robotic management of biotic stresses in precision agriculture.\nThe framework employs a hierarchical decision-making structure with conditional\naction masking, where high-level actions direct the robot's exploration, while\nlow-level actions optimize its navigation and efficient chemical spraying in\naffected areas. The key objectives of optimization include improving the\ncoverage of infected areas with limited battery power and reducing chemical\nusage, thus preventing unnecessary spraying of healthy areas of the field. Our\nnumerical experimental results demonstrate that the proposed method,\nHierarchical Action Masking Proximal Policy Optimization (HAM-PPO),\nsignificantly outperforms baseline practices, such as LawnMower navigation +\nindiscriminate spraying (Carpet Spray), in terms of yield recovery and resource\nefficiency. HAM-PPO consistently achieves higher yield recovery percentages and\nlower chemical costs across a range of infection scenarios. The framework also\nexhibits robustness to observation noise and generalizability under diverse\nenvironmental conditions, adapting to varying infection ranges and spatial\ndistribution patterns.", "published": "2025-03-23 08:38:13", "link": "http://arxiv.org/abs/2503.17985v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Taste More, Taste Better: Diverse Data and Strong Model Boost Semi-Supervised Crowd Counting", "abstract": "Semi-supervised crowd counting is crucial for addressing the high annotation\ncosts of densely populated scenes. Although several methods based on\npseudo-labeling have been proposed, it remains challenging to effectively and\naccurately utilize unlabeled data. In this paper, we propose a novel framework\ncalled Taste More Taste Better (TMTB), which emphasizes both data and model\naspects. Firstly, we explore a data augmentation technique well-suited for the\ncrowd counting task. By inpainting the background regions, this technique can\neffectively enhance data diversity while preserving the fidelity of the entire\nscenes. Secondly, we introduce the Visual State Space Model as backbone to\ncapture the global context information from crowd scenes, which is crucial for\nextremely crowded, low-light, and adverse weather scenarios. In addition to the\ntraditional regression head for exact prediction, we employ an Anti-Noise\nclassification head to provide less exact but more accurate supervision, since\nthe regression head is sensitive to noise in manual annotations. We conduct\nextensive experiments on four benchmark datasets and show that our method\noutperforms state-of-the-art methods by a large margin. Code is publicly\navailable on https://github.com/syhien/taste_more_taste_better.", "published": "2025-03-23 08:38:01", "link": "http://arxiv.org/abs/2503.17984v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Co-SemDepth: Fast Joint Semantic Segmentation and Depth Estimation on Aerial Images", "abstract": "Understanding the geometric and semantic properties of the scene is crucial\nin autonomous navigation and particularly challenging in the case of Unmanned\nAerial Vehicle (UAV) navigation. Such information may be by obtained by\nestimating depth and semantic segmentation maps of the surrounding environment\nand for their practical use in autonomous navigation, the procedure must be\nperformed as close to real-time as possible. In this paper, we leverage\nmonocular cameras on aerial robots to predict depth and semantic maps in\nlow-altitude unstructured environments. We propose a joint deep-learning\narchitecture that can perform the two tasks accurately and rapidly, and\nvalidate its effectiveness on MidAir and Aeroscapes benchmark datasets. Our\njoint-architecture proves to be competitive or superior to the other single and\njoint architecture methods while performing its task fast predicting 20.2 FPS\non a single NVIDIA quadro p5000 GPU and it has a low memory footprint. All\ncodes for training and prediction can be found on this link:\nhttps://github.com/Malga-Vision/Co-SemDepth", "published": "2025-03-23 08:25:07", "link": "http://arxiv.org/abs/2503.17982v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Balanced Direction from Multifarious Choices: Arithmetic Meta-Learning for Domain Generalization", "abstract": "Domain generalization is proposed to address distribution shift, arising from\nstatistical disparities between training source and unseen target domains. The\nwidely used first-order meta-learning algorithms demonstrate strong performance\nfor domain generalization by leveraging the gradient matching theory, which\naims to establish balanced parameters across source domains to reduce\noverfitting to any particular domain. However, our analysis reveals that there\nare actually numerous directions to achieve gradient matching, with current\nmethods representing just one possible path. These methods actually overlook\nanother critical factor that the balanced parameters should be close to the\ncentroid of optimal parameters of each source domain. To address this, we\npropose a simple yet effective arithmetic meta-learning with\narithmetic-weighted gradients. This approach, while adhering to the principles\nof gradient matching, promotes a more precise balance by estimating the\ncentroid between domain-specific optimal parameters. Experimental results\nvalidate the effectiveness of our strategy.", "published": "2025-03-23 08:24:28", "link": "http://arxiv.org/abs/2503.18987v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "PIM: Physics-Informed Multi-task Pre-training for Improving Inertial Sensor-Based Human Activity Recognition", "abstract": "Human activity recognition (HAR) with deep learning models relies on large\namounts of labeled data, often challenging to obtain due to associated cost,\ntime, and labor. Self-supervised learning (SSL) has emerged as an effective\napproach to leverage unlabeled data through pretext tasks, such as masked\nreconstruction and multitask learning with signal processing-based data\naugmentations, to pre-train encoder models. However, such methods are often\nderived from computer vision approaches that disregard physical mechanisms and\nconstraints that govern wearable sensor data and the phenomena they reflect. In\nthis paper, we propose a physics-informed multi-task pre-training (PIM)\nframework for IMU-based HAR. PIM generates pre-text tasks based on the\nunderstanding of basic physical aspects of human motion: including movement\nspeed, angles of movement, and symmetry between sensor placements. Given a\nsensor signal, we calculate corresponding features using physics-based\nequations and use them as pretext tasks for SSL. This enables the model to\ncapture fundamental physical characteristics of human activities, which is\nespecially relevant for multi-sensor systems. Experimental evaluations on four\nHAR benchmark datasets demonstrate that the proposed method outperforms\nexisting state-of-the-art methods, including data augmentation and masked\nreconstruction, in terms of accuracy and F1 score. We have observed gains of\nalmost 10\\% in macro f1 score and accuracy with only 2 to 8 labeled examples\nper class and up to 3% when there is no reduction in the amount of training\ndata.", "published": "2025-03-23 08:16:01", "link": "http://arxiv.org/abs/2503.17978v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Shot Sequence Ordering for Video Editing: Benchmarks, Metrics, and Cinematology-Inspired Computing Methods", "abstract": "With the rising popularity of short video platforms, the demand for video\nproduction has increased substantially. However, high-quality video creation\ncontinues to rely heavily on professional editing skills and a nuanced\nunderstanding of visual language. To address this challenge, the Shot Sequence\nOrdering (SSO) task in AI-assisted video editing has emerged as a pivotal\napproach for enhancing video storytelling and the overall viewing experience.\nNevertheless, the progress in this field has been impeded by a lack of publicly\navailable benchmark datasets. In response, this paper introduces two novel\nbenchmark datasets, AVE-Order and ActivityNet-Order. Additionally, we employ\nthe Kendall Tau distance as an evaluation metric for the SSO task and propose\nthe Kendall Tau Distance-Cross Entropy Loss. We further introduce the concept\nof Cinematology Embedding, which incorporates movie metadata and shot labels as\nprior knowledge into the SSO model, and constructs the AVE-Meta dataset to\nvalidate the method's effectiveness. Experimental results indicate that the\nproposed loss function and method substantially enhance SSO task accuracy. All\ndatasets are publicly accessible at https://github.com/litchiar/ShotSeqBench.", "published": "2025-03-23 08:04:45", "link": "http://arxiv.org/abs/2503.17975v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SplitFrozen: Split Learning with Device-side Model Frozen for Fine-Tuning LLM on Heterogeneous Resource-Constrained Devices", "abstract": "Fine-tuning large language models (LLMs) on private, on-device data can\nempower tailored personalized AI agents. However, fine-tuning LLMs on\nresource-constrained edge devices faces significant challenges, including\nexcessive computation overhead, device heterogeneity, and data imbalance. This\npaper proposes SplitFrozen, a split learning framework that enables efficient\nLLM fine-tuning by strategically freezing device-side model layers while\ncentralizing parameter-efficient fine-tuning on the server. Our framework\npartitions LLMs into device-side frozen layers and server-side fine-tuning\nlayers, where heterogeneous resource-constrained devices execute only forward\npropagation. To minimize server-side training costs, we integrate Low-Rank\nAdaptation (LoRA) into the server-side layers. A pipeline parallelism strategy\nfurther optimizes training efficiency by decoupling device-server computations\nand leveraging decomposed backward propagation. Experiments on GPT-2 with the\nMRPC, MNLI-matched, and SST-2 datasets demonstrate that SplitFrozen outperforms\nFedLoRA and SplitLoRA by 69.4\\% model accuracy under extremely imbalanced data,\nwhile reducing up to 86.8\\% device-side computations and 50.2\\% total training\ntime. Experiments also validate the scalability of SplitFrozen on content\ngeneration task using Llama-3.2 model on GSM8K dataset.", "published": "2025-03-23 08:03:44", "link": "http://arxiv.org/abs/2503.18986v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Videos", "abstract": "Creating a physical digital twin of a real-world object has immense potential\nin robotics, content creation, and XR. In this paper, we present PhysTwin, a\nnovel framework that uses sparse videos of dynamic objects under interaction to\nproduce a photo- and physically realistic, real-time interactive virtual\nreplica. Our approach centers on two key components: (1) a physics-informed\nrepresentation that combines spring-mass models for realistic physical\nsimulation, generative shape models for geometry, and Gaussian splats for\nrendering; and (2) a novel multi-stage, optimization-based inverse modeling\nframework that reconstructs complete geometry, infers dense physical\nproperties, and replicates realistic appearance from videos. Our method\nintegrates an inverse physics framework with visual perception cues, enabling\nhigh-fidelity reconstruction even from partial, occluded, and limited\nviewpoints. PhysTwin supports modeling various deformable objects, including\nropes, stuffed animals, cloth, and delivery packages. Experiments show that\nPhysTwin outperforms competing methods in reconstruction, rendering, future\nprediction, and simulation under novel interactions. We further demonstrate its\napplications in interactive real-time simulation and model-based robotic motion\nplanning.", "published": "2025-03-23 07:49:19", "link": "http://arxiv.org/abs/2503.17973v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "LoRA Subtraction for Drift-Resistant Space in Exemplar-Free Continual Learning", "abstract": "In continual learning (CL), catastrophic forgetting often arises due to\nfeature drift. This challenge is particularly prominent in the exemplar-free\ncontinual learning (EFCL) setting, where samples from previous tasks cannot be\nretained, making it difficult to preserve prior knowledge. To address this\nissue, some EFCL methods aim to identify feature spaces that minimize the\nimpact on previous tasks while accommodating new ones. However, they rely on\nstatic features or outdated statistics stored from old tasks, which prevents\nthem from capturing the dynamic evolution of the feature space in CL, leading\nto performance degradation over time. In this paper, we introduce the\nDrift-Resistant Space (DRS), which effectively handles feature drifts without\nrequiring explicit feature modeling or the storage of previous tasks. A novel\nparameter-efficient fine-tuning approach called Low-Rank Adaptation Subtraction\n(LoRA-) is proposed to develop the DRS. This method subtracts the LoRA weights\nof old tasks from the initial pre-trained weight before processing new task\ndata to establish the DRS for model training. Therefore, LoRA- enhances\nstability, improves efficiency, and simplifies implementation. Furthermore,\nstabilizing feature drifts allows for better plasticity by learning with a\ntriplet loss. Our method consistently achieves state-of-the-art results,\nespecially for long task sequences, across multiple datasets.", "published": "2025-03-23 07:38:53", "link": "http://arxiv.org/abs/2503.18985v2", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The Misinterpretable Evidence Conveyed by Arbitrary Codes", "abstract": "Evidence Theory is a mathematical framework for handling imprecise reasoning\nin the context of a judge evaluating testimonies or a detective evaluating\ncues, rather than a gambler playing games of chance. In comparison to\nProbability Theory, it is better equipped to deal with ambiguous information\nand novel possibilities. Furthermore, arrival and evaluation of testimonies\nimplies a communication channel.\n  This paper explores the possibility of employing Evidence Theory to represent\narbitrary communication codes between and within living organisms. In this\npaper, different schemes are explored for living organisms incapable of\nanticipation, animals sufficiently sophisticated to be capable of\nextrapolation, and humans capable of reading one other's minds.", "published": "2025-03-23 07:31:26", "link": "http://arxiv.org/abs/2503.18984v1", "categories": ["cs.AI", "nlin.AO"], "primary_category": "cs.AI"}
{"title": "Dynamic Gradient Sparse Update for Edge Training", "abstract": "Training on edge devices enables personalized model fine-tuning to enhance\nreal-world performance and maintain data privacy. However, the gradient\ncomputation for backpropagation in the training requires significant memory\nbuffers to store intermediate features and compute losses. This is unacceptable\nfor memory-constrained edge devices such as microcontrollers. To tackle this\nissue, we propose a training acceleration method using dynamic gradient sparse\nupdates. This method updates the important channels and layers only and skips\ngradient computation for the less important channels and layers to reduce\nmemory usage for each update iteration. In addition, the channel selection is\ndynamic for different iterations to traverse most of the parameters in the\nupdate layers along the time dimension for better performance. The experimental\nresult shows that the proposed method enables an ImageNet pre-trained\nMobileNetV2 trained on CIFAR-10 to achieve an accuracy of 85.77\\% while\nupdating only 2\\% of convolution weights within 256KB on-chip memory. This\nresults in a remarkable 98\\% reduction in feature memory usage compared to\ndense model training.", "published": "2025-03-23 06:32:12", "link": "http://arxiv.org/abs/2503.17959v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "Confronting Catastrophic Risk: The International Obligation to Regulate Artificial Intelligence", "abstract": "While artificial intelligence (AI) holds enormous promise, many experts in\nthe field are warning that there is a non-trivial chance that the development\nof AI poses an existential threat to humanity. Existing regulatory initiative\ndo not address this threat but merely instead focus on discrete AI-related\nrisks such as consumer safety, cybersecurity, data protection, and privacy. In\nthe absence of regulatory action to address the possible risk of human\nextinction by AI, the question arises: What legal obligations, if any, does\npublic international law impose on states to regulate its development. Grounded\nin the precautionary principle, we argue that there exists an international\nobligation to mitigate the threat of human extinction by AI. Often invoked in\nrelation to environmental regulation and the regulation of potentially harmful\ntechnologies, the principle holds that in situations where there is the\npotential for significant harm, even in the absence of full scientific\ncertainty, preventive measures should not be postponed if delayed action may\nresult in irreversible consequences. We argue that the precautionary principle\nis a general principle of international law and, therefore, that there is a\npositive obligation on states under the right to life within international\nhuman rights law to proactively take regulatory action to mitigate the\npotential existential risk of AI. This is significant because, if an\ninternational obligation to regulate the development of AI can be established\nunder international law, then the basic legal framework would be in place to\naddress this evolving threat.", "published": "2025-03-23 06:24:45", "link": "http://arxiv.org/abs/2503.18983v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Generative Data Imputation for Sparse Learner Performance Data Using Generative Adversarial Imputation Networks", "abstract": "Learner performance data collected by Intelligent Tutoring Systems (ITSs),\nsuch as responses to questions, is essential for modeling and predicting\nlearners' knowledge states. However, missing responses due to skips or\nincomplete attempts create data sparsity, challenging accurate assessment and\npersonalized instruction. To address this, we propose a generative imputation\napproach using Generative Adversarial Imputation Networks (GAIN). Our method\nfeatures a three-dimensional (3D) framework (learners, questions, and\nattempts), flexibly accommodating various sparsity levels. Enhanced by\nconvolutional neural networks and optimized with a least squares loss function,\nthe GAIN-based method aligns input and output dimensions to question-attempt\nmatrices along the learners' dimension. Extensive experiments using datasets\nfrom AutoTutor Adult Reading Comprehension (ARC), ASSISTments, and MATHia\ndemonstrate that our approach significantly outperforms tensor factorization\nand alternative GAN methods in imputation accuracy across different attempt\nscenarios. Bayesian Knowledge Tracing (BKT) further validates the effectiveness\nof the imputed data by estimating learning parameters: initial knowledge\n(P(L0)), learning rate (P(T)), guess rate (P(G)), and slip rate (P(S)). Results\nindicate the imputed data enhances model fit and closely mirrors original\ndistributions, capturing underlying learning behaviors reliably.\nKullback-Leibler (KL) divergence assessments confirm minimal divergence,\nshowing the imputed data preserves essential learning characteristics\neffectively. These findings underscore GAIN's capability as a robust imputation\ntool in ITSs, alleviating data sparsity and supporting adaptive, individualized\ninstruction, ultimately leading to more precise and responsive learner\nassessments and improved educational outcomes.", "published": "2025-03-23 06:11:53", "link": "http://arxiv.org/abs/2503.18982v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FedSKD: Aggregation-free Model-heterogeneous Federated Learning using Multi-dimensional Similarity Knowledge Distillation", "abstract": "Federated learning (FL) enables privacy-preserving collaborative model\ntraining without direct data sharing. Model-heterogeneous FL (MHFL) extends\nthis paradigm by allowing clients to train personalized models with\nheterogeneous architectures tailored to their computational resources and\napplication-specific needs. However, existing MHFL methods predominantly rely\non centralized aggregation, which introduces scalability and efficiency\nbottlenecks, or impose restrictions requiring partially identical model\narchitectures across clients. While peer-to-peer (P2P) FL removes server\ndependence, it suffers from model drift and knowledge dilution, limiting its\neffectiveness in heterogeneous settings. To address these challenges, we\npropose FedSKD, a novel MHFL framework that facilitates direct knowledge\nexchange through round-robin model circulation, eliminating the need for\ncentralized aggregation while allowing fully heterogeneous model architectures\nacross clients. FedSKD's key innovation lies in multi-dimensional similarity\nknowledge distillation, which enables bidirectional cross-client knowledge\ntransfer at batch, pixel/voxel, and region levels for heterogeneous models in\nFL. This approach mitigates catastrophic forgetting and model drift through\nprogressive reinforcement and distribution alignment while preserving model\nheterogeneity. Extensive evaluations on fMRI-based autism spectrum disorder\ndiagnosis and skin lesion classification demonstrate that FedSKD outperforms\nstate-of-the-art heterogeneous and homogeneous FL baselines, achieving superior\npersonalization (client-specific accuracy) and generalization\n(cross-institutional adaptability). These findings underscore FedSKD's\npotential as a scalable and robust solution for real-world medical federated\nlearning applications.", "published": "2025-03-23 05:33:10", "link": "http://arxiv.org/abs/2503.18981v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CLCR: Contrastive Learning-based Constraint Reordering for Efficient MILP Solving", "abstract": "Constraint ordering plays a critical role in the efficiency of Mixed-Integer\nLinear Programming (MILP) solvers, particularly for large-scale problems where\npoorly ordered constraints trigger increased LP iterations and suboptimal\nsearch trajectories. This paper introduces CLCR (Contrastive Learning-based\nConstraint Reordering), a novel framework that systematically optimizes\nconstraint ordering to accelerate MILP solving. CLCR first clusters constraints\nbased on their structural patterns and then employs contrastive learning with a\npointer network to optimize their sequence, preserving problem equivalence\nwhile improving solver efficiency. Experiments on benchmarks show CLCR reduces\nsolving time by 30% and LP iterations by 25% on average, without sacrificing\nsolution accuracy. This work demonstrates the potential of data-driven\nconstraint ordering to enhance optimization models, offering a new paradigm for\nbridging mathematical programming with machine learning.", "published": "2025-03-23 05:01:43", "link": "http://arxiv.org/abs/2504.03688v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "CAE: Repurposing the Critic as an Explorer in Deep Reinforcement Learning", "abstract": "Exploration remains a critical challenge in reinforcement learning, as many\nexisting methods either lack theoretical guarantees or fall short of practical\neffectiveness. In this paper, we introduce CAE, a lightweight algorithm that\nrepurposes the value networks in standard deep RL algorithms to drive\nexploration without introducing additional parameters. CAE utilizes any linear\nmulti-armed bandit technique and incorporates an appropriate scaling strategy,\nenabling efficient exploration with provable sub-linear regret bounds and\npractical stability. Notably, it is simple to implement, requiring only around\n10 lines of code. In complex tasks where learning an effective value network\nproves challenging, we propose CAE+, an extension of CAE that incorporates an\nauxiliary network. This extension increases the parameter count by less than 1%\nwhile maintaining implementation simplicity, adding only about 10 additional\nlines of code. Experiments on MuJoCo and MiniHack show that both CAE and CAE+\noutperform state-of-the-art baselines, bridging the gap between theoretical\nrigor and practical efficiency.", "published": "2025-03-23 04:59:24", "link": "http://arxiv.org/abs/2503.18980v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Physics-Guided Multi-Fidelity DeepONet for Data-Efficient Flow Field Prediction", "abstract": "This study presents an enhanced multi-fidelity deep operator network\n(DeepONet) framework for efficient spatio-temporal flow field prediction, with\nparticular emphasis on practical scenarios where high-fidelity data is scarce.\nWe introduce several key innovations to improve the framework's efficiency and\naccuracy. First, we enhance the DeepONet architecture by incorporating a merge\nnetwork that enables more complex feature interactions between operator and\ncoordinate spaces, achieving a 50.4% reduction in prediction error compared to\ntraditional dot-product operations. We further optimize the architecture\nthrough temporal positional encoding and point-based sampling strategies,\nachieving a 7.57% improvement in prediction accuracy while reducing training\ntime by 96% through efficient sampling and automatic mixed precision training.\nBuilding upon this foundation, we develop a transfer learning-based\nmulti-fidelity framework that leverages knowledge from pre-trained low-fidelity\nmodels to guide high-fidelity predictions. Our approach freezes the pre-trained\nbranch and trunk networks while making only the merge network trainable during\nhigh-fidelity training, preserving valuable low-fidelity representations while\nefficiently adapting to high-fidelity features. Through systematic\ninvestigation, we demonstrate that this fine-tuning strategy not only\nsignificantly outperforms linear probing and full-tuning alternatives but also\nsurpasses conventional multi-fidelity frameworks by up to 76%, while achieving\nup to 43.7% improvement in prediction accuracy compared to single-fidelity\ntraining. The core contribution lies in our novel time-derivative guided\nsampling approach: it maintains prediction accuracy equivalent to models\ntrained with the full dataset while requiring only 60% of the original\nhigh-fidelity samples.", "published": "2025-03-23 04:48:18", "link": "http://arxiv.org/abs/2503.17941v1", "categories": ["physics.flu-dyn", "cs.AI"], "primary_category": "physics.flu-dyn"}
{"title": "WLB-LLM: Workload-Balanced 4D Parallelism for Large Language Model Training", "abstract": "In this work, we present WLB-LLM, a workLoad-balanced 4D parallelism for\nlarge language model training. We first thoroughly analyze the workload\nimbalance issue in LLM training and identify two primary sources of imbalance\nat the pipeline parallelism and context parallelism levels. Then, to address\nthe imbalance issue, at the pipeline parallelism level, WLB-LLM incorporates a\nworkload-aware variable-length document packing method to balance the\ncomputation and communication workload across micro-batches. Additionally, at\nthe context parallelism level, WLB-LLM introduces a novel fine-grained\nper-document sharding strategy, ensuring each worker within a context\nparallelism group has an identical workload. Comprehensive experiments under\ndifferent model scales demonstrate that WLB-LLM significantly mitigates the\nworkload imbalance during 4D parallelism LLM training and achieves an average\nspeedup of 1.23x when applying WLB-LLM in our internal LLM training framework.", "published": "2025-03-23 03:40:45", "link": "http://arxiv.org/abs/2503.17924v1", "categories": ["cs.DC", "cs.AI", "cs.LG", "I.2.11"], "primary_category": "cs.DC"}
{"title": "Cat-AIR: Content and Task-Aware All-in-One Image Restoration", "abstract": "All-in-one image restoration seeks to recover high-quality images from\nvarious types of degradation using a single model, without prior knowledge of\nthe corruption source. However, existing methods often struggle to effectively\nand efficiently handle multiple degradation types. We present Cat-AIR, a novel\n\\textbf{C}ontent \\textbf{A}nd \\textbf{T}ask-aware framework for\n\\textbf{A}ll-in-one \\textbf{I}mage \\textbf{R}estoration. Cat-AIR incorporates\nan alternating spatial-channel attention mechanism that adaptively balances the\nlocal and global information for different tasks. Specifically, we introduce\ncross-layer channel attentions and cross-feature spatial attentions that\nallocate computations based on content and task complexity. Furthermore, we\npropose a smooth learning strategy that allows for seamless adaptation to new\nrestoration tasks while maintaining performance on existing ones. Extensive\nexperiments demonstrate that Cat-AIR achieves state-of-the-art results across a\nwide range of restoration tasks, requiring fewer FLOPs than previous methods,\nestablishing new benchmarks for efficient all-in-one image restoration.", "published": "2025-03-23 03:25:52", "link": "http://arxiv.org/abs/2503.17915v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Payload-Aware Intrusion Detection with CMAE and Large Language Models", "abstract": "Intrusion Detection Systems (IDS) are crucial for identifying malicious\ntraffic, yet traditional signature-based methods struggle with zero-day attacks\nand high false positive rates. AI-driven packet-capture analysis offers a\npromising alternative. However, existing approaches rely heavily on flow-based\nor statistical features, limiting their ability to detect fine-grained attack\npatterns. This study proposes Xavier-CMAE, an enhanced Convolutional Multi-Head\nAttention Ensemble (CMAE) model that improves detection accuracy while reducing\ncomputational overhead. By replacing Word2Vec embeddings with a Hex2Int\ntokenizer and Xavier initialization, Xavier-CMAE eliminates pre-training,\naccelerates training, and achieves 99.971% accuracy with a 0.018% false\npositive rate, outperforming Word2Vec-based methods. Additionally, we introduce\nLLM-CMAE, which integrates pre-trained Large Language Model (LLM) tokenizers\ninto CMAE. While LLMs enhance feature extraction, their computational cost\nhinders real-time detection. LLM-CMAE balances efficiency and performance,\nreaching 99.969% accuracy with a 0.019% false positive rate. This work advances\nAI-powered IDS by (1) introducing a payload-based detection framework, (2)\nenhancing efficiency with Xavier-CMAE, and (3) integrating LLM tokenizers for\nimproved real-time detection.", "published": "2025-03-23 02:56:32", "link": "http://arxiv.org/abs/2503.20798v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by Selective State Space Model", "abstract": "Unsupervised graph-level anomaly detection (UGLAD) is a critical and\nchallenging task across various domains, such as social network analysis,\nanti-cancer drug discovery, and toxic molecule identification. However,\nexisting methods often struggle to capture the long-range dependencies\nefficiently and neglect the spectral information. Recently, selective State\nSpace Models (SSMs), particularly Mamba, have demonstrated remarkable\nadvantages in capturing long-range dependencies with linear complexity and a\nselection mechanism. Motivated by their success across various domains, we\npropose GLADMamba, a novel framework that adapts the selective state space\nmodel into UGLAD field. We design View-Fused Mamba (VFM) with a\nMamba-Transformer-style architecture to efficiently fuse information from\ndifferent views with a selective state mechanism. We also design\nSpectrum-Guided Mamba (SGM) with a Mamba-Transformer-style architecture to\nleverage the Rayleigh quotient to guide the embedding refining process.\nGLADMamba can dynamically focus on anomaly-related information while discarding\nirrelevant information for anomaly detection. To the best of our knowledge,\nthis is the first work to introduce Mamba and explicit spectral information to\nUGLAD. Extensive experiments on 12 real-world datasets demonstrate that\nGLADMamba outperforms existing state-of-the-art methods, achieving superior\nperformance in UGLAD. The code is available at\nhttps://github.com/Yali-F/GLADMamba.", "published": "2025-03-23 02:40:17", "link": "http://arxiv.org/abs/2503.17903v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Threshold Crossings as Tail Events for Catastrophic AI Risk", "abstract": "We analyse circumstances in which bifurcation-driven jumps in AI systems are\nassociated with emergent heavy-tailed outcome distributions. By analysing how a\ncontrol parameter's random fluctuations near a catastrophic threshold generate\nextreme outcomes, we demonstrate in what circumstances the probability of a\nsudden, large-scale, transition aligns closely with the tail probability of the\nresulting damage distribution. Our results contribute to research in\nmonitoring, mitigation and control of AI systems when seeking to manage\npotentially catastrophic AI risk.", "published": "2025-03-23 02:01:09", "link": "http://arxiv.org/abs/2503.18979v2", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Generative AI for Validating Physics Laws", "abstract": "We present generative artificial intelligence (AI) to empirically validate\nfundamental laws of physics, focusing on the Stefan-Boltzmann law linking\nstellar temperature and luminosity. Our approach simulates counterfactual\nluminosities under hypothetical temperature regimes for each individual star\nand iteratively refines the temperature-luminosity relationship in a deep\nlearning architecture. We use Gaia DR3 data and find that, on average,\ntemperature's effect on luminosity increases with stellar radius and decreases\nwith absolute magnitude, consistent with theoretical predictions. By framing\nphysics laws as causal problems, our method offers a novel, data-driven\napproach to refine theoretical understanding and inform evidence-based policy\nand practice.", "published": "2025-03-23 00:57:26", "link": "http://arxiv.org/abs/2503.17894v2", "categories": ["astro-ph.SR", "astro-ph.GA", "cs.AI"], "primary_category": "astro-ph.SR"}
{"title": "A unified convention for achievement positional games", "abstract": "We introduce achievement positional games, a convention for positional games\nwhich encompasses the Maker-Maker and Maker-Breaker conventions. We consider\ntwo hypergraphs, one red and one blue, on the same vertex set. Two players,\nLeft and Right, take turns picking a previously unpicked vertex. Whoever first\nfills an edge of their color, blue for Left or red for Right, wins the game\n(draws are possible). We establish general properties of such games. In\nparticular, we show that a lot of principles which hold for Maker-Maker games\ngeneralize to achievement positional games. We also study the algorithmic\ncomplexity of deciding whether Left has a winning strategy as first player when\nall blue edges have size at mot $p$ and all red edges have size at most $q$.\nThis problem is in P for $p,q \\leq 2$, but it is NP-hard for $p \\geq 3$ and\n$q=2$, coNP-complete for $p=2$ and $q \\geq 3$, and PSPACE-complete for $p,q\n\\geq 3$. A consequence of this last result is that, in the Maker-Maker\nconvention, deciding whether the first player has a winning strategy on a\nhypergraph of rank 4 after one round of (non-optimal) play is PSPACE-complete.", "published": "2025-03-23 18:27:13", "link": "http://arxiv.org/abs/2503.18163v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "Linear, nested, and quadratic ordered measures: Computation and incorporation into optimization problems", "abstract": "In this paper we address a unified mathematical optimization framework to\ncompute a wide range of measures used in most operations research and data\nscience contexts. The goal is to embed such metrics within general optimization\nmodels allowing their efficient computation. We assess the usefulness of this\napproach applying it to three different families of measures, namely linear,\nnested, and quadratic ordered measures. Computational results are reported\nshowing the efficiency and accuracy of our methods as compared with standard\nimplementations in numerical software packages. Finally, we illustrate this\nmethodology by computing a number of optimal solutions with respect to\ndifferent metrics on three well-known linear and combinatorial optimization\nproblems: scenario analysis in linear programming, the traveling salesman and\nthe weighted multicover set problem.", "published": "2025-03-23 15:04:38", "link": "http://arxiv.org/abs/2503.18097v1", "categories": ["math.OC", "cs.DM", "stat.CO", "90C", "G.2.0"], "primary_category": "math.OC"}
{"title": "MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps", "abstract": "Monitoring wildlife is essential for ecology and ethology, especially in\nlight of the increasing human impact on ecosystems. Camera traps have emerged\nas habitat-centric sensors enabling the study of wildlife populations at scale\nwith minimal disturbance. However, the lack of annotated video datasets limits\nthe development of powerful video understanding models needed to process the\nvast amount of fieldwork data collected. To advance research in wild animal\nbehavior monitoring we present MammAlps, a multimodal and multi-view dataset of\nwildlife behavior monitoring from 9 camera-traps in the Swiss National Park.\nMammAlps contains over 14 hours of video with audio, 2D segmentation maps and\n8.5 hours of individual tracks densely labeled for species and behavior. Based\non 6135 single animal clips, we propose the first hierarchical and multimodal\nanimal behavior recognition benchmark using audio, video and reference scene\nsegmentation maps as inputs. Furthermore, we also propose a second\necology-oriented benchmark aiming at identifying activities, species, number of\nindividuals and meteorological conditions from 397 multi-view and long-term\necological events, including false positive triggers. We advocate that both\ntasks are complementary and contribute to bridging the gap between machine\nlearning and ecology. Code and data are available at:\nhttps://github.com/eceo-epfl/MammAlps", "published": "2025-03-23 21:51:58", "link": "http://arxiv.org/abs/2503.18223v1", "categories": ["cs.CV", "cs.IR", "q-bio.NC", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "Causality-Aware Next Location Prediction Framework based on Human Mobility Stratification", "abstract": "Human mobility data are fused with multiple travel patterns and hidden\nspatiotemporal patterns are extracted by integrating user, location, and time\ninformation to improve next location prediction accuracy. In existing next\nlocation prediction methods, different causal relationships that result from\npatterns in human mobility data are ignored, which leads to confounding\ninformation that can have a negative effect on predictions. Therefore, this\nstudy introduces a causality-aware framework for next location prediction,\nfocusing on human mobility stratification for travel patterns. In our research,\na novel causal graph is developed that describes the relationships between\nvarious input variables. We use counterfactuals to enhance the indirect effects\nin our causal graph for specific travel patterns: non-anchor targeted travels.\nThe proposed framework is designed as a plug-and-play module that integrates\nmultiple next location prediction paradigms. We tested our proposed framework\nusing several state-of-the-art models and human mobility datasets, and the\nresults reveal that the proposed module improves the prediction performance. In\naddition, we provide results from the ablation study and quantitative study to\ndemonstrate the soundness of our causal graph and its ability to further\nenhance the interpretability of the current next location prediction models.", "published": "2025-03-23 19:30:24", "link": "http://arxiv.org/abs/2503.18179v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "BERTDetect: A Neural Topic Modelling Approach for Android Malware Detection", "abstract": "Web access today occurs predominantly through mobile devices, with Android\nrepresenting a significant share of the mobile device market. This widespread\nusage makes Android a prime target for malicious attacks. Despite efforts to\ncombat malicious attacks through tools like Google Play Protect and antivirus\nsoftware, new and evolved malware continues to infiltrate Android devices.\nSource code analysis is effective but limited, as attackers quickly abandon old\nmalware for new variants to evade detection. Therefore, there is a need for\nalternative methods that complement source code analysis. Prior research\ninvestigated clustering applications based on their descriptions and identified\noutliers in these clusters by API usage as malware. However, these works often\nused traditional techniques such as Latent Dirichlet Allocation (LDA) and\nk-means clustering, that do not capture the nuanced semantic structures present\nin app descriptions. To this end, in this paper, we propose BERTDetect, which\nleverages the BERTopic neural topic modelling to effectively capture the latent\ntopics in app descriptions. The resulting topic clusters are comparatively more\ncoherent than previous methods and represent the app functionalities well. Our\nresults demonstrate that BERTDetect outperforms other baselines, achieving ~10%\nrelative improvement in F1 score.", "published": "2025-03-23 12:09:44", "link": "http://arxiv.org/abs/2503.18043v1", "categories": ["cs.CR", "cs.IR"], "primary_category": "cs.CR"}
{"title": "SUNAR: Semantic Uncertainty based Neighborhood Aware Retrieval for Complex QA", "abstract": "Complex question-answering (QA) systems face significant challenges in\nretrieving and reasoning over information that addresses multi-faceted queries.\nWhile large language models (LLMs) have advanced the reasoning capabilities of\nthese systems, the bounded-recall problem persists, where procuring all\nrelevant documents in first-stage retrieval remains a challenge. Missing\npertinent documents at this stage leads to performance degradation that cannot\nbe remedied in later stages, especially given the limited context windows of\nLLMs which necessitate high recall at smaller retrieval depths. In this paper,\nwe introduce SUNAR, a novel approach that leverages LLMs to guide a\nNeighborhood Aware Retrieval process. SUNAR iteratively explores a neighborhood\ngraph of documents, dynamically promoting or penalizing documents based on\nuncertainty estimates from interim LLM-generated answer candidates. We validate\nour approach through extensive experiments on two complex QA datasets. Our\nresults show that SUNAR significantly outperforms existing retrieve-and-reason\nbaselines, achieving up to a 31.84% improvement in performance over existing\nstate-of-the-art methods for complex QA.", "published": "2025-03-23 08:50:44", "link": "http://arxiv.org/abs/2503.17990v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Tutorial on Six-Dimensional Movable Antenna Enhanced Wireless Networks: Synergizing Positionable and Rotatable Antennas", "abstract": "Six-dimensional movable antenna (6DMA) is a new\n  and revolutionary technique that fully exploits the wireless\n  channel spatial variations at the transmitter/receiver by flexibly\n  adjusting the three-dimensional (3D) positions and/or 3D rotations\n  of antennas/antenna surfaces (sub-arrays), thereby improving the performance\nof wireless\n  networks cost-effectively without the need to deploy additional\n  antennas. It is thus expected that\n  the integration of new 6DMAs into future sixth-generation (6G) wireless\nnetworks will fundamentally enhance\n  antenna agility and adaptability, and introduce new degrees\n  of freedom (DoFs) for system design. Despite its great potential,\n  6DMA faces new challenges to be efficiently implemented in wireless\n  networks, including corresponding architectures, antenna position and\nrotation optimization, channel estimation,\n  and system design from both communication and sensing perspectives. In\n  this paper, we provide a tutorial on 6DMA-enhanced wireless\n  networks to address the above issues by unveiling associated new channel\nmodels, hardware implementations and\n  practical position/rotation constraints, as well as various appealing\napplications in\n  wireless networks. Moreover, we discuss two special cases of 6DMA, namely,\nrotatable 6DMA with fixed antenna position and positionable 6DMA with fixed\nantenna rotation, and highlight their respective design challenges and\napplications.\n  We further present prototypes developed for 6DMA-enhanced communication along\nwith experimental results obtained with these prototypes. Finally, we outline\npromising directions for further investigation.", "published": "2025-03-23 23:28:18", "link": "http://arxiv.org/abs/2503.18240v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Channel Capacity Saturation Point and Beamforming Acceleration for Near-Field XL-MIMO Multiuser Communications", "abstract": "One of the most important technologies in the fifth generation (5G) and the\nsixth generation (6G) is massive multiple input multiple outputs (MIMO) or\nextremely large-scale MIMO (XL-MIMO). With the evolving high-frequency\ntechnologies in millimeter band or tereHz band, the communication scene is\nchanging into near-field rather than the conventional far-field scenario. In\nthis letter, instead of advertising the XL-MIMO in the near-field, we appeal\nthat a limit should be set on the size of the antenna array, beyond which the\nchannel capacity will not show a significant increase. We show capacity\nsaturation point can be analytically determined. Moreover, we propose a new\nbeamforming algorithm that relieve the heavy computation due to the large\nantenna size even around the saturation point. Numerical results are provided\nto validate our analysis and show the performance of our newly proposed\nbeamforming scheme.", "published": "2025-03-23 15:47:27", "link": "http://arxiv.org/abs/2503.18118v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Dynamic structural resilience of international staple food trade networks", "abstract": "It is important to maintain the resilient international food trade network\nfor food security. We have constructed the international trade networks of\nmaize, rice, soybean, and wheat based on bilateral flows data between\neconomies. Drawing on information theory, we have measured their dynamic\nresilience based on efficiency and redundancy during 1986 to 2022. We have also\ninvestigated the impact of economies and relationships on their resilience.\nOverall, we argue that rice and soybean trade networks deserve more attention\nwhile resilience in maize and wheat shows a steady upward trend. Meanwhile, our\nfindings emphasize the importance of diversity of trade flows and partners for\nenhancing resilience. Currently, for example, excessively high monopolization\nof soybean trade may not be beneficial for its resilience. Also, we have found\nthat major exporters and relationships between geographically bordering\neconomies have greater impact on the resilience. Moreover, we have confirmed\nthe existence of different network structures with the optimal resilience as\nrelationships are removed cumulatively, which may be an informative guide for\nthe international food trade.", "published": "2025-03-23 09:34:23", "link": "http://arxiv.org/abs/2503.18004v1", "categories": ["physics.soc-ph", "cs.IT", "math.IT"], "primary_category": "physics.soc-ph"}
{"title": "Agentic Business Process Management: The Past 30 Years And Practitioners' Future Perspectives", "abstract": "With the advent of generative Artificial Intelligence (genAI), the notion of\nan agent has seen a resurgence in popularity. This has also led to speculation\nabout the extent to which business process management, as a discipline and\nresearch field, may impact and be impacted by the deployment of genAI-based\nagents. To better ground such speculations into the state-of-the-art, we draw\nfrom the past 30 years of research on agents and business process management to\nestablish the concept of Agentic Business Process Management (agentic BPM) that\nis only loosely coupled to the genAI hype. We conduct a series of interviews\nwith BPM practitioners to explore their understanding, expectations, and\nconcerns related to agent autonomy, adaptability, human collaboration, and\ngovernance in processes. The findings reflect both challenges with respect to\ndata inconsistencies, manual interventions, identification of process\nbottlenecks, actionability of process improvements, as well as the\nopportunities of enhanced efficiency, predictive process insights and proactive\ndecision-making support. While the technology offers potential benefits,\npractitioners also anticipate risks such as biases, over-reliance, lack of\ntransparency, and job displacement within organizations. These concerns\nunderscore the need for a robust methodological framework for managing agents\nin organizations.", "published": "2025-03-23 20:15:24", "link": "http://arxiv.org/abs/2504.03693v1", "categories": ["cs.SE", "cs.MA", "D.2.9; I.2.11"], "primary_category": "cs.SE"}
{"title": "Unleashing the power of text for credit default prediction: Comparing human-written and generative AI-refined texts", "abstract": "This study explores the integration of a representative large language model,\nChatGPT, into lending decision-making with a focus on credit default\nprediction. Specifically, we use ChatGPT to analyse and interpret loan\nassessments written by loan officers and generate refined versions of these\ntexts. Our comparative analysis reveals significant differences between\ngenerative artificial intelligence (AI)-refined and human-written texts in\nterms of text length, semantic similarity, and linguistic representations.\nUsing deep learning techniques, we show that incorporating unstructured text\ndata, particularly ChatGPT-refined texts, alongside conventional structured\ndata significantly enhances credit default predictions. Furthermore, we\ndemonstrate how the contents of both human-written and ChatGPT-refined\nassessments contribute to the models' prediction and show that the effect of\nessential words is highly context-dependent. Moreover, we find that ChatGPT's\nanalysis of borrower delinquency contributes the most to improving predictive\naccuracy. We also evaluate the business impact of the models based on\nhuman-written and ChatGPT-refined texts, and find that, in most cases, the\nlatter yields higher profitability than the former. This study provides\nvaluable insights into the transformative potential of generative AI in\nfinancial services.", "published": "2025-03-23 11:07:24", "link": "http://arxiv.org/abs/2503.18029v1", "categories": ["q-fin.RM", "q-fin.CP"], "primary_category": "q-fin.RM"}
{"title": "Financial Wind Tunnel: A Retrieval-Augmented Market Simulator", "abstract": "Market simulator tries to create high-quality synthetic financial data that\nmimics real-world market dynamics, which is crucial for model development and\nrobust assessment. Despite continuous advancements in simulation methodologies,\nmarket fluctuations vary in terms of scale and sources, but existing frameworks\noften excel in only specific tasks. To address this challenge, we propose\nFinancial Wind Tunnel (FWT), a retrieval-augmented market simulator designed to\ngenerate controllable, reasonable, and adaptable market dynamics for model\ntesting. FWT offers a more comprehensive and systematic generative capability\nacross different data frequencies. By leveraging a retrieval method to discover\ncross-sectional information as the augmented condition, our diffusion-based\nsimulator seamlessly integrates both macro- and micro-level market patterns.\nFurthermore, our framework allows the simulation to be controlled with wide\napplicability, including causal generation through \"what-if\" prompts or\nunprecedented cross-market trend synthesis. Additionally, we develop an\nautomated optimizer for downstream quantitative models, using stress testing of\nsimulated scenarios via FWT to enhance returns while controlling risks.\nExperimental results demonstrate that our approach enables the generalizable\nand reliable market simulation, significantly improve the performance and\nadaptability of downstream models, particularly in highly complex and volatile\nmarket conditions. Our code and data sample is available at\nhttps://anonymous.4open.science/r/fwt_-E852", "published": "2025-03-23 03:10:13", "link": "http://arxiv.org/abs/2503.17909v1", "categories": ["cs.CE", "cs.LG", "q-fin.CP"], "primary_category": "cs.CE"}
{"title": "Agent-Based Models for Two Stocks with Superhedging", "abstract": "An agent-based modelling methodology for the joint price evolution of two\nstocks is put forward. The method models future multidimensional price\ntrajectories reflecting how a class of agents rebalance their portfolios in an\noperational way by reacting to how stocks' charts unfold. Prices are expressed\nin units of a third stock that acts as numeraire. The methodology is robust, in\nparticular, it does not depend on any prior probability or analytical\nassumptions and it is based on constructing scenarios/trajectories. A main\ningredient is a superhedging interpretation that provides relative superhedging\nprices between the two modelled stocks. The operational nature of the\nmethodology gives objective conditions for the validity of the model and so\nimplies realistic risk-rewards profiles for the agent's operations.\nSuperhedging computations are performed with a dynamic programming algorithm\ndeployed on a graph data structure. Null subsets of the trajectory space are\ndirectly related to arbitrage opportunities (i.e. there is no need for\nprobabilistic considerations) that may emerge during the trajectory set\nconstruction. It follows that the superhedging algorithm handles null sets in a\nrigorous and intuitive way. Superhedging and underhedging bounds are kept\nrelevant to the investor by means of a worst case pruning method and, as an\nalternative, a theory supported pruning that relies on a new notion of small\narbitrage.", "published": "2025-03-23 18:33:59", "link": "http://arxiv.org/abs/2503.18165v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Generating realistic metaorders from public data", "abstract": "This paper introduces a novel algorithm for generating realistic metaorders\nfrom public trade data, addressing a longstanding challenge in price impact\nresearch that has traditionally relied on proprietary datasets. Our method\neffectively recovers all established stylized facts of metaorders impact, such\nas the Square Root Law, the concave profile during metaorder execution, and the\npost-execution decay. This algorithm not only overcomes the dependence on\nproprietary data, a major barrier to research reproducibility, but also enables\nthe creation of larger and more robust datasets that may increase the quality\nof empirical studies. Our findings strongly suggest that average realized\nshort-term price impact is not due to information revelation (as in the Kyle\nframework) but has a mechanical origin which could explain the universality of\nthe Square Root Law.", "published": "2025-03-23 20:47:24", "link": "http://arxiv.org/abs/2503.18199v2", "categories": ["q-fin.TR", "q-fin.PM"], "primary_category": "q-fin.TR"}
{"title": "Informer in Algorithmic Investment Strategies on High Frequency Bitcoin Data", "abstract": "The article investigates the usage of Informer architecture for building\nautomated trading strategies for high frequency Bitcoin data. Three strategies\nusing Informer model with different loss functions: Root Mean Squared Error\n(RMSE), Generalized Mean Absolute Directional Loss (GMADL) and Quantile loss,\nare proposed and evaluated against the Buy and Hold benchmark and two benchmark\nstrategies based on technical indicators. The evaluation is conducted using\ndata of various frequencies: 5 minute, 15 minute, and 30 minute intervals, over\nthe 6 different periods. Although the Informer-based model with Quantile loss\ndid not outperform the benchmark, two other models achieved better results. The\nperformance of the model using RMSE loss worsens when used with higher\nfrequency data while the model that uses novel GMADL loss function is\nbenefiting from higher frequency data and when trained on 5 minute interval it\nbeat all the other strategies on most of the testing periods. The primary\ncontribution of this study is the application and assessment of the RMSE,\nGMADL, and Quantile loss functions with the Informer model to forecast future\nreturns, subsequently using these forecasts to develop automated trading\nstrategies. The research provides evidence that employing an Informer model\ntrained with the GMADL loss function can result in superior trading outcomes\ncompared to the buy-and-hold approach.", "published": "2025-03-23 15:00:13", "link": "http://arxiv.org/abs/2503.18096v1", "categories": ["q-fin.TR", "cs.LG", "cs.NE", "q-fin.PM"], "primary_category": "q-fin.TR"}
{"title": "A Simple Strategy to Deal with Toxic Flow", "abstract": "We model the trading activity between a broker and her clients (informed and\nuninformed traders) as an infinite-horizon stochastic control problem. We\nderive the broker's optimal dealing strategy in closed form and use this to\nintroduce an algorithm that bypasses the need to calibrate individual\nparameters, so the dealing strategy can be executed in real-world trading\nenvironments. Finally, we characterise the discount in the price of liquidity a\nbroker offers clients. The discount strikes the optimal balance between\nmaximising the order flow from the broker's clients and minimising adverse\nselection losses to the informed traders.", "published": "2025-03-23 09:39:18", "link": "http://arxiv.org/abs/2503.18005v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "A State-of-the-Art Review on Acoustic Preservation of Historical Worship Spaces through Auralization", "abstract": "Historical Worship Spaces (HWS) are significant architectural landmarks which\nhold both cultural and spiritual value. The acoustic properties of these spaces\nplay a crucial role in historical and contemporary religious liturgies,\nrituals, and ceremonies, as well as in the performance of sacred music.\nHowever, the original acoustic characteristics of these spaces are often at\nrisk due to repurposing, renovations, natural disasters, or deterioration over\ntime. This paper presents a comprehensive review of the current state of\nresearch on the acquisition, analysis, and synthesis of acoustics, with a focus\non HWS. An example case study of the Nassau chapel in Brussels, Belgium, is\npresented to demonstrate the application of these techniques for the\npreservation and auralization of historical worship space acoustics. The paper\nconcludes with a discussion of the challenges and opportunities in the field,\nand outlines future research directions.", "published": "2025-03-23 10:39:51", "link": "http://arxiv.org/abs/2503.18022v1", "categories": ["eess.AS", "cs.SD", "eess.SP", "I.6.0, J.5"], "primary_category": "eess.AS"}
{"title": "Elevating Robust Multi-Talker ASR by Decoupling Speaker Separation and Speech Recognition", "abstract": "Despite the tremendous success of automatic speech recognition (ASR) with the\nintroduction of deep learning, its performance is still unsatisfactory in many\nreal-world multi-talker scenarios. Speaker separation excels in separating\nindividual talkers but, as a frontend, it introduces processing artifacts that\ndegrade the ASR backend trained on clean speech. As a result, mainstream robust\nASR systems train the backend on noisy speech to avoid processing artifacts. In\nthis work, we propose to decouple the training of the speaker separation\nfrontend and the ASR backend, with the latter trained on clean speech only. Our\ndecoupled system achieves 5.1% word error rates (WER) on the Libri2Mix dev/test\nsets, significantly outperforming other multi-talker ASR baselines. Its\neffectiveness is also demonstrated with the state-of-the-art 7.60%/5.74% WERs\non 1-ch and 6-ch SMS-WSJ. Furthermore, on recorded LibriCSS, we achieve the\nspeaker-attributed WER of 2.92%. These state-of-the-art results suggest that\ndecoupling speaker separation and recognition is an effective approach to\nelevate robust multi-talker ASR.", "published": "2025-03-23 00:00:23", "link": "http://arxiv.org/abs/2503.17886v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
