{"title": "Fact-based Text Editing", "abstract": "We propose a novel text editing task, referred to as \\textit{fact-based text\nediting}, in which the goal is to revise a given document to better describe\nthe facts in a knowledge base (e.g., several triples). The task is important in\npractice because reflecting the truth is a common requirement in text editing.\nFirst, we propose a method for automatically generating a dataset for research\non fact-based text editing, where each instance consists of a draft text, a\nrevised text, and several facts represented in triples. We apply the method\ninto two public table-to-text datasets, obtaining two new datasets consisting\nof 233k and 37k instances, respectively. Next, we propose a new neural network\narchitecture for fact-based text editing, called \\textsc{FactEditor}, which\nedits a draft text by referring to given facts using a buffer, a stream, and a\nmemory. A straightforward approach to address the problem would be to employ an\nencoder-decoder model. Our experimental results on the two datasets show that\n\\textsc{FactEditor} outperforms the encoder-decoder approach in terms of\nfidelity and fluency. The results also show that \\textsc{FactEditor} conducts\ninference faster than the encoder-decoder approach.", "published": "2020-07-02 06:50:30", "link": "http://arxiv.org/abs/2007.00916v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IIE-NLP-NUT at SemEval-2020 Task 4: Guiding PLM with Prompt Template\n  Reconstruction Strategy for ComVE", "abstract": "This paper introduces our systems for the first two subtasks of SemEval\nTask4: Commonsense Validation and Explanation. To clarify the intention for\njudgment and inject contrastive information for selection, we propose the input\nreconstruction strategy with prompt templates. Specifically, we formalize the\nsubtasks into the multiple-choice question answering format and construct the\ninput with the prompt templates, then, the final prediction of question\nanswering is considered as the result of subtasks. Experimental results show\nthat our approaches achieve significant performance compared with the baseline\nsystems. Our approaches secure the third rank on both official test sets of the\nfirst two subtasks with an accuracy of 96.4 and an accuracy of 94.3\nrespectively.", "published": "2020-07-02 06:59:53", "link": "http://arxiv.org/abs/2007.00924v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Project PIAF: Building a Native French Question-Answering Dataset", "abstract": "Motivated by the lack of data for non-English languages, in particular for\nthe evaluation of downstream tasks such as Question Answering, we present a\nparticipatory effort to collect a native French Question Answering Dataset.\nFurthermore, we describe and publicly release the annotation tool developed for\nour collection effort, along with the data obtained and preliminary baselines.", "published": "2020-07-02 08:59:15", "link": "http://arxiv.org/abs/2007.00968v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Processing South Asian Languages Written in the Latin Script: the\n  Dakshina Dataset", "abstract": "This paper describes the Dakshina dataset, a new resource consisting of text\nin both the Latin and native scripts for 12 South Asian languages. The dataset\nincludes, for each language: 1) native script Wikipedia text; 2) a romanization\nlexicon; and 3) full sentence parallel data in both a native script of the\nlanguage and the basic Latin alphabet. We document the methods used for\npreparation and selection of the Wikipedia text in each language; collection of\nattested romanizations for sampled lexicons; and manual romanization of\nheld-out sentences from the native script collections. We additionally provide\nbaseline results on several tasks made possible by the dataset, including\nsingle word transliteration, full sentence transliteration, and language\nmodeling of native script and romanized text. Keywords: romanization,\ntransliteration, South Asian languages", "published": "2020-07-02 14:57:28", "link": "http://arxiv.org/abs/2007.01176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequential Domain Adaptation through Elastic Weight Consolidation for\n  Sentiment Analysis", "abstract": "Elastic Weight Consolidation (EWC) is a technique used in overcoming\ncatastrophic forgetting between successive tasks trained on a neural network.\nWe use this phenomenon of information sharing between tasks for domain\nadaptation. Training data for tasks such as sentiment analysis (SA) may not be\nfairly represented across multiple domains. Domain Adaptation (DA) aims to\nbuild algorithms that leverage information from source domains to facilitate\nperformance on an unseen target domain. We propose a model-independent\nframework - Sequential Domain Adaptation (SDA). SDA draws on EWC for training\non successive source domains to move towards a general domain solution, thereby\nsolving the problem of domain adaptation. We test SDA on convolutional,\nrecurrent, and attention-based architectures. Our experiments show that the\nproposed framework enables simple architectures such as CNNs to outperform\ncomplex state-of-the-art models in domain adaptation of SA. In addition, we\nobserve that the effectiveness of a harder first Anti-Curriculum ordering of\nsource domains leads to maximum performance.", "published": "2020-07-02 15:21:56", "link": "http://arxiv.org/abs/2007.01189v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Bayesian Multilingual Document Model for Zero-shot Topic\n  Identification and Discovery", "abstract": "In this paper, we present a Bayesian multilingual document model for learning\nlanguage-independent document embeddings. The model is an extension of BaySMM\n[Kesiraju et al 2020] to the multilingual scenario. It learns to represent the\ndocument embeddings in the form of Gaussian distributions, thereby encoding the\nuncertainty in its covariance. We propagate the learned uncertainties through\nlinear classifiers that benefit zero-shot cross-lingual topic identification.\nOur experiments on 17 languages show that the proposed multilingual Bayesian\ndocument model performs competitively, when compared to other systems based on\nlarge-scale neural networks (LASER, XLM-R, mUSE) on 8 high-resource languages,\nand outperforms these systems on 9 mid-resource languages. We revisit\ncross-lingual topic identification in zero-shot settings by taking a deeper\ndive into current datasets, baseline systems and the languages covered. We\nidentify shortcomings in the existing evaluation protocol (MLDoc dataset), and\npropose a robust alternative scheme, while also extending the cross-lingual\nexperimental setup to 17 languages. Finally, we consolidate the observations\nfrom all our experiments, and discuss points that can potentially benefit the\nfuture research works in applications relying on cross-lingual transfers.", "published": "2020-07-02 19:55:08", "link": "http://arxiv.org/abs/2007.01359v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Novel BGCapsule Network for Text Classification", "abstract": "Several text classification tasks such as sentiment analysis, news\ncategorization, multi-label classification and opinion classification are\nchallenging problems even for modern deep learning networks. Recently, Capsule\nNetworks (CapsNets) are proposed for image classification. It has been shown\nthat CapsNets have several advantages over Convolutional Neural Networks\n(CNNs), while their validity in the domain of text has been less explored. In\nthis paper, we propose a novel hybrid architecture viz., BGCapsule, which is a\nCapsule model preceded by an ensemble of Bidirectional Gated Recurrent Units\n(BiGRU) for several text classification tasks. We employed an ensemble of\nBidirectional GRUs for feature extraction layer preceding the primary capsule\nlayer. The hybrid architecture, after performing basic pre-processing steps,\nconsists of five layers: an embedding layer based on GloVe, a BiGRU based\nensemble layer, a primary capsule layer, a flatten layer and fully connected\nReLU layer followed by a fully connected softmax layer. In order to evaluate\nthe effectiveness of BGCapsule, we conducted extensive experiments on five\nbenchmark datasets (ranging from 10,000 records to 700,000 records) including\nMovie Review (MR Imdb 2005), AG News dataset, Dbpedia ontology dataset, Yelp\nReview Full dataset and Yelp review polarity dataset. These benchmarks cover\nseveral text classification tasks such as news categorization, sentiment\nanalysis, multiclass classification, multi-label classification and opinion\nclassification. We found that our proposed architecture (BGCapsule) achieves\nbetter accuracy compared to the existing methods without the help of any\nexternal linguistic knowledge such as positive sentiment keywords and negative\nsentiment keywords. Further, BGCapsule converged faster compared to other\nextant techniques.", "published": "2020-07-02 06:07:29", "link": "http://arxiv.org/abs/2007.04302v1", "categories": ["cs.CL", "68T07, 68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Lightme: Analysing Language in Internet Support Groups for Mental Health", "abstract": "Background: Assisting moderators to triage harmful posts in Internet Support\nGroups is relevant to ensure its safe use. Automated text classification\nmethods analysing the language expressed in posts of online forums is a\npromising solution. Methods: Natural Language Processing and Machine Learning\ntechnologies were used to build a triage post classifier using a dataset from\nReachout mental health forum for young people. Results: When comparing with the\nstate-of-the-art, a solution mainly based on features from lexical resources,\nreceived the best classification performance for the crisis posts (52%), which\nis the most severe class. Six salient linguistic characteristics were found\nwhen analysing the crisis post; 1) posts expressing hopelessness, 2) short\nposts expressing concise negative emotional responses, 3) long posts expressing\nvariations of emotions, 4) posts expressing dissatisfaction with available\nhealth services, 5) posts utilising storytelling, and 6) posts expressing users\nseeking advice from peers during a crisis. Conclusion: It is possible to build\na competitive triage classifier using features derived only from the textual\ncontent of the post. Further research needs to be done in order to translate\nour quantitative and qualitative findings into features, as it may improve\noverall performance.", "published": "2020-07-02 01:25:22", "link": "http://arxiv.org/abs/2007.00824v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLNDE: Enhancing Neural Sequence Taggers with Attention and Noisy\n  Channel for Robust Pharmacological Entity Detection", "abstract": "Named entity recognition has been extensively studied on English news texts.\nHowever, the transfer to other domains and languages is still a challenging\nproblem. In this paper, we describe the system with which we participated in\nthe first subtrack of the PharmaCoNER competition of the BioNLP Open Shared\nTasks 2019. Aiming at pharmacological entity detection in Spanish texts, the\ntask provides a non-standard domain and language setting. However, we propose\nan architecture that requires neither language nor domain expertise. We treat\nthe task as a sequence labeling task and experiment with attention-based\nembedding selection and the training on automatically annotated data to further\nimprove our system's performance. Our system achieves promising results,\nespecially by combining the different techniques, and reaches up to 88.6% F1 in\nthe competition.", "published": "2020-07-02 11:17:16", "link": "http://arxiv.org/abs/2007.01022v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLNDE: The Neither-Language-Nor-Domain-Experts' Way of Spanish Medical\n  Document De-Identification", "abstract": "Natural language processing has huge potential in the medical domain which\nrecently led to a lot of research in this field. However, a prerequisite of\nsecure processing of medical documents, e.g., patient notes and clinical\ntrials, is the proper de-identification of privacy-sensitive information. In\nthis paper, we describe our NLNDE system, with which we participated in the\nMEDDOCAN competition, the medical document anonymization task of IberLEF 2019.\nWe address the task of detecting and classifying protected health information\nfrom Spanish data as a sequence-labeling problem and investigate different\nembedding methods for our neural network. Despite dealing in a non-standard\nlanguage and domain setting, the NLNDE system achieves promising results in the\ncompetition.", "published": "2020-07-02 11:30:32", "link": "http://arxiv.org/abs/2007.01030v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bidirectional Encoder Representations from Transformers (BERT): A\n  sentiment analysis odyssey", "abstract": "The purpose of the study is to investigate the relative effectiveness of four\ndifferent sentiment analysis techniques: (1) unsupervised lexicon-based model\nusing Sent WordNet; (2) traditional supervised machine learning model using\nlogistic regression; (3) supervised deep learning model using Long Short-Term\nMemory (LSTM); and, (4) advanced supervised deep learning models using\nBidirectional Encoder Representations from Transformers (BERT). We use publicly\navailable labeled corpora of 50,000 movie reviews originally posted on internet\nmovie database (IMDB) for analysis using Sent WordNet lexicon, logistic\nregression, LSTM, and BERT. The first three models were run on CPU based system\nwhereas BERT was run on GPU based system. The sentiment classification\nperformance was evaluated based on accuracy, precision, recall, and F1 score.\nThe study puts forth two key insights: (1) relative efficacy of four highly\nadvanced and widely used sentiment analysis techniques; (2) undisputed\nsuperiority of pre-trained advanced supervised deep learning BERT model in\nsentiment analysis from text data. This study provides professionals in\nanalytics industry and academicians working on text analysis key insight\nregarding comparative classification performance evaluation of key sentiment\nanalysis techniques, including the recently developed BERT. This is the first\nresearch endeavor to compare the advanced pre-trained supervised deep learning\nmodel of BERT vis-\\`a-vis other sentiment analysis models of LSTM, logistic\nregression, and Sent WordNet.", "published": "2020-07-02 14:23:57", "link": "http://arxiv.org/abs/2007.01127v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Leveraging Passage Retrieval with Generative Models for Open Domain\n  Question Answering", "abstract": "Generative models for open domain question answering have proven to be\ncompetitive, without resorting to external knowledge. While promising, this\napproach requires to use models with billions of parameters, which are\nexpensive to train and query. In this paper, we investigate how much these\nmodels can benefit from retrieving text passages, potentially containing\nevidence. We obtain state-of-the-art results on the Natural Questions and\nTriviaQA open benchmarks. Interestingly, we observe that the performance of\nthis method significantly improves when increasing the number of retrieved\npassages. This is evidence that generative models are good at aggregating and\ncombining evidence from multiple passages.", "published": "2020-07-02 17:44:57", "link": "http://arxiv.org/abs/2007.01282v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting Ongoing Events Using Contextual Word and Sentence Embeddings", "abstract": "This paper introduces the Ongoing Event Detection (OED) task, which is a\nspecific Event Detection task where the goal is to detect ongoing event\nmentions only, as opposed to historical, future, hypothetical, or other forms\nor events that are neither fresh nor current. Any application that needs to\nextract structured information about ongoing events from unstructured texts can\ntake advantage of an OED system. The main contribution of this paper are the\nfollowing: (1) it introduces the OED task along with a dataset manually labeled\nfor the task; (2) it presents the design and implementation of an RNN model for\nthe task that uses BERT embeddings to define contextual word and contextual\nsentence embeddings as attributes, which to the best of our knowledge were\nnever used before for detecting ongoing events in news; (3) it presents an\nextensive empirical evaluation that includes (i) the exploration of different\narchitectures and hyperparameters, (ii) an ablation test to study the impact of\neach attribute, and (iii) a comparison with a replication of a state-of-the-art\nmodel. The results offer several insights into the importance of contextual\nembeddings and indicate that the proposed approach is effective in the OED\ntask, outperforming the baseline models.", "published": "2020-07-02 20:44:05", "link": "http://arxiv.org/abs/2007.01379v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Facts as Experts: Adaptable and Interpretable Neural Memory over\n  Symbolic Knowledge", "abstract": "Massive language models are the core of modern NLP modeling and have been\nshown to encode impressive amounts of commonsense and factual information.\nHowever, that knowledge exists only within the latent parameters of the model,\ninaccessible to inspection and interpretation, and even worse, factual\ninformation memorized from the training corpora is likely to become stale as\nthe world changes. Knowledge stored as parameters will also inevitably exhibit\nall of the biases inherent in the source materials. To address these problems,\nwe develop a neural language model that includes an explicit interface between\nsymbolically interpretable factual information and subsymbolic neural\nknowledge. We show that this model dramatically improves performance on two\nknowledge-intensive question-answering tasks. More interestingly, the model can\nbe updated without re-training by manipulating its symbolic representations. In\nparticular this model allows us to add new facts and overwrite existing ones in\nways that are not possible for earlier models.", "published": "2020-07-02 03:05:41", "link": "http://arxiv.org/abs/2007.00849v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can We Achieve More with Less? Exploring Data Augmentation for Toxic\n  Comment Classification", "abstract": "This paper tackles one of the greatest limitations in Machine Learning: Data\nScarcity. Specifically, we explore whether high accuracy classifiers can be\nbuilt from small datasets, utilizing a combination of data augmentation\ntechniques and machine learning algorithms. In this paper, we experiment with\nEasy Data Augmentation (EDA) and Backtranslation, as well as with three popular\nlearning algorithms, Logistic Regression, Support Vector Machine (SVM), and\nBidirectional Long Short-Term Memory Network (Bi-LSTM). For our\nexperimentation, we utilize the Wikipedia Toxic Comments dataset so that in the\nprocess of exploring the benefits of data augmentation, we can develop a model\nto detect and classify toxic speech in comments to help fight back against\ncyberbullying and online harassment. Ultimately, we found that data\naugmentation techniques can be used to significantly boost the performance of\nclassifiers and are an excellent strategy to combat lack of data in NLP\nproblems.", "published": "2020-07-02 04:43:31", "link": "http://arxiv.org/abs/2007.00875v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data Augmenting Contrastive Learning of Speech Representations in the\n  Time Domain", "abstract": "Contrastive Predictive Coding (CPC), based on predicting future segments of\nspeech based on past segments is emerging as a powerful algorithm for\nrepresentation learning of speech signal. However, it still under-performs\nother methods on unsupervised evaluation benchmarks. Here, we introduce\nWavAugment, a time-domain data augmentation library and find that applying\naugmentation in the past is generally more efficient and yields better\nperformances than other methods. We find that a combination of pitch\nmodification, additive noise and reverberation substantially increase the\nperformance of CPC (relative improvement of 18-22%), beating the reference\nLibri-light results with 600 times less data. Using an out-of-domain dataset,\ntime-domain data augmentation can push CPC to be on par with the state of the\nart on the Zero Speech Benchmark 2017. We also show that time-domain data\naugmentation consistently improves downstream limited-supervision phoneme\nclassification tasks by a factor of 12-15% relative.", "published": "2020-07-02 09:59:51", "link": "http://arxiv.org/abs/2007.00991v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Semi-Supervised NMF-CNN For Sound Event Detection", "abstract": "In this paper, a combinative approach using Nonnegative Matrix Factorization\n(NMF) and Convolutional Neural Network (CNN) is proposed for audio clip Sound\nEvent Detection (SED). The main idea begins with the use of NMF to approximate\nstrong labels for the weakly labeled data. Subsequently, using the approximated\nstrongly labeled data, two different CNNs are trained in a semi-supervised\nframework where one CNN is used for clip-level prediction and the other for\nframe-level prediction. Based on this idea, our model can achieve an\nevent-based F1-score of 45.7% on the Detection and Classification of Acoustic\nScenes and Events (DCASE) 2020 Challenge Task 4 validation dataset. By\nensembling models through averaging the posterior outputs, event-based F1-score\ncan be increased to 48.6%. By comparing with the baseline model, our proposed\nmodels outperform the baseline model by over 8%. By testing our models on the\nDCASE 2020 Challenge Task 4 test set, our models can achieve an event-based\nF1-score of 44.4% while our ensembled system can achieve an event-based\nF1-score of 46.3%. Such results have a minimum margin of 7% over the baseline\nsystem which demonstrates the robustness of our proposed method on different\ndatasets.", "published": "2020-07-02 06:31:39", "link": "http://arxiv.org/abs/2007.00908v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Polyphonic sound event detection based on convolutional recurrent neural\n  networks with semi-supervised loss function for DCASE challenge 2020 task 4", "abstract": "This report proposes a polyphonic sound event detection (SED) method for the\nDCASE 2020 Challenge Task 4. The proposed SED method is based on\nsemi-supervised learning to deal with the different combination of training\ndatasets such as weakly labeled dataset, unlabeled dataset, and strongly\nlabeled synthetic dataset. Especially, the target label of each audio clip from\nweakly labeled or unlabeled dataset is first predicted by using the mean\nteacher model that is the DCASE 2020 baseline. The data with predicted labels\nare used for training the proposed SED model, which consists of CNNs with skip\nconnections and self-attention mechanism, followed by RNNs. In order to\ncompensate for the erroneous prediction of weakly labeled and unlabeled data, a\nsemi-supervised loss function is employed for the proposed SED model. In this\nwork, several versions of the proposed SED model are implemented and evaluated\non the validation set according to the different parameter setting for the\nsemi-supervised loss function, and then an ensemble model that combines\nfive-fold validation models is finally selected as our final model.", "published": "2020-07-02 07:55:18", "link": "http://arxiv.org/abs/2007.00947v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spot the conversation: speaker diarisation in the wild", "abstract": "The goal of this paper is speaker diarisation of videos collected 'in the\nwild'. We make three key contributions. First, we propose an automatic\naudio-visual diarisation method for YouTube videos. Our method consists of\nactive speaker detection using audio-visual methods and speaker verification\nusing self-enrolled speaker models. Second, we integrate our method into a\nsemi-automatic dataset creation pipeline which significantly reduces the number\nof hours required to annotate videos with diarisation labels. Finally, we use\nthis pipeline to create a large-scale diarisation dataset called VoxConverse,\ncollected from 'in the wild' videos, which we will release publicly to the\nresearch community. Our dataset consists of overlapping speech, a large and\ndiverse speaker pool, and challenging background conditions.", "published": "2020-07-02 15:55:54", "link": "http://arxiv.org/abs/2007.01216v3", "categories": ["cs.SD", "cs.CV", "eess.AS", "eess.IV"], "primary_category": "cs.SD"}
{"title": "Channel Compression: Rethinking Information Redundancy among Channels in\n  CNN Architecture", "abstract": "Model compression and acceleration are attracting increasing attentions due\nto the demand for embedded devices and mobile applications. Research on\nefficient convolutional neural networks (CNNs) aims at removing feature\nredundancy by decomposing or optimizing the convolutional calculation. In this\nwork, feature redundancy is assumed to exist among channels in CNN\narchitectures, which provides some leeway to boost calculation efficiency.\nAiming at channel compression, a novel convolutional construction named compact\nconvolution is proposed to embrace the progress in spatial convolution, channel\ngrouping and pooling operation. Specifically, the depth-wise separable\nconvolution and the point-wise interchannel operation are utilized to\nefficiently extract features. Different from the existing channel compression\nmethod which usually introduces considerable learnable weights, the proposed\ncompact convolution can reduce feature redundancy with no extra parameters.\nWith the point-wise interchannel operation, compact convolutions implicitly\nsqueeze the channel dimension of feature maps. To explore the rules on reducing\nchannel redundancy in neural networks, the comparison is made among different\npoint-wise interchannel operations. Moreover, compact convolutions are extended\nto tackle with multiple tasks, such as acoustic scene classification, sound\nevent detection and image classification. The extensive experiments demonstrate\nthat our compact convolution not only exhibits high effectiveness in several\nmultimedia tasks, but also can be efficiently implemented by benefiting from\nparallel computation.", "published": "2020-07-02 10:58:54", "link": "http://arxiv.org/abs/2007.01696v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
