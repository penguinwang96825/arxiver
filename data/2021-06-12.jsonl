{"title": "Study of sampling methods in sentiment analysis of imbalanced data", "abstract": "This work investigates the application of sampling methods for sentiment\nanalysis on two different highly imbalanced datasets. One dataset contains\nonline user reviews from the cooking platform Epicurious and the other contains\ncomments given to the Planned Parenthood organization. In both these datasets,\nthe classes of interest are rare. Word n-grams were used as features from these\ndatasets. A feature selection technique based on information gain is first\napplied to reduce the number of features to a manageable space. A number of\ndifferent sampling methods were then applied to mitigate the class imbalance\nproblem which are then analyzed.", "published": "2021-06-12 03:16:18", "link": "http://arxiv.org/abs/2106.06673v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Combinatory Constituency Parsing", "abstract": "We propose two fast neural combinatory models for constituency parsing:\nbinary and multi-branching. Our models decompose the bottom-up parsing process\ninto 1) classification of tags, labels, and binary orientations or chunks and\n2) vector composition based on the computed orientations or chunks. These\nmodels have theoretical sub-quadratic complexity and empirical linear\ncomplexity. The binary model achieves an F1 score of 92.54 on Penn Treebank,\nspeeding at 1327.2 sents/sec. Both the models with XLNet provide near\nstate-of-the-art accuracies for English. Syntactic branching tendency and\nheadedness of a language are observed during the training and inference\nprocesses for Penn Treebank, Chinese Treebank, and Keyaki Treebank (Japanese).", "published": "2021-06-12 05:14:16", "link": "http://arxiv.org/abs/2106.06689v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Unsupervised Dialogue Topic Segmentation with Utterance-Pair\n  Coherence Scoring", "abstract": "Dialogue topic segmentation is critical in several dialogue modeling\nproblems. However, popular unsupervised approaches only exploit surface\nfeatures in assessing topical coherence among utterances. In this work, we\naddress this limitation by leveraging supervisory signals from the\nutterance-pair coherence scoring task. First, we present a simple yet effective\nstrategy to generate a training corpus for utterance-pair coherence scoring.\nThen, we train a BERT-based neural utterance-pair coherence model with the\nobtained training corpus. Finally, such model is used to measure the topical\nrelevance between utterances, acting as the basis of the segmentation\ninference. Experiments on three public datasets in English and Chinese\ndemonstrate that our proposal outperforms the state-of-the-art baselines.", "published": "2021-06-12 08:49:20", "link": "http://arxiv.org/abs/2106.06719v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating External POS Tagger for Punctuation Restoration", "abstract": "Punctuation restoration is an important post-processing step in automatic\nspeech recognition. Among other kinds of external information, part-of-speech\n(POS) taggers provide informative tags, suggesting each input token's syntactic\nrole, which has been shown to be beneficial for the punctuation restoration\ntask. In this work, we incorporate an external POS tagger and fuse its\npredicted labels into the existing language model to provide syntactic\ninformation. Besides, we propose sequence boundary sampling (SBS) to learn\npunctuation positions more efficiently as a sequence tagging task. Experimental\nresults show that our methods can consistently obtain performance gains and\nachieve a new state-of-the-art on the common IWSLT benchmark. Further ablation\nstudies illustrate that both large pre-trained language models and the external\nPOS tagger take essential parts to improve the model's performance.", "published": "2021-06-12 09:58:06", "link": "http://arxiv.org/abs/2106.06731v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Sentence-level Hierarchical BERT Model for Document Classification\n  with Limited Labelled Data", "abstract": "Training deep learning models with limited labelled data is an attractive\nscenario for many NLP tasks, including document classification. While with the\nrecent emergence of BERT, deep learning language models can achieve reasonably\ngood performance in document classification with few labelled instances, there\nis a lack of evidence in the utility of applying BERT-like models on long\ndocument classification. This work introduces a long-text-specific model -- the\nHierarchical BERT Model (HBM) -- that learns sentence-level features of the\ntext and works well in scenarios with limited labelled data. Various evaluation\nexperiments have demonstrated that HBM can achieve higher performance in\ndocument classification than the previous state-of-the-art methods with only 50\nto 200 labelled instances, especially when documents are long. Also, as an\nextra benefit of HBM, the salient sentences identified by learned HBM are\nuseful as explanations for labelling documents based on a user study.", "published": "2021-06-12 10:45:24", "link": "http://arxiv.org/abs/2106.06738v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guiding Teacher Forcing with Seer Forcing for Neural Machine Translation", "abstract": "Although teacher forcing has become the main training paradigm for neural\nmachine translation, it usually makes predictions only conditioned on past\ninformation, and hence lacks global planning for the future. To address this\nproblem, we introduce another decoder, called seer decoder, into the\nencoder-decoder framework during training, which involves future information in\ntarget predictions. Meanwhile, we force the conventional decoder to simulate\nthe behaviors of the seer decoder via knowledge distillation. In this way, at\ntest the conventional decoder can perform like the seer decoder without the\nattendance of it. Experiment results on the Chinese-English, English-German and\nEnglish-Romanian translation tasks show our method can outperform competitive\nbaselines significantly and achieves greater improvements on the bigger data\nsets. Besides, the experiments also prove knowledge distillation the best way\nto transfer knowledge from the seer decoder to the conventional decoder\ncompared to adversarial learning and L2 regularization.", "published": "2021-06-12 11:38:40", "link": "http://arxiv.org/abs/2106.06751v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Every Bite Is an Experience: Key Point Analysis of Business Reviews", "abstract": "Previous work on review summarization focused on measuring the sentiment\ntoward the main aspects of the reviewed product or business, or on creating a\ntextual summary. These approaches provide only a partial view of the data:\naspect-based sentiment summaries lack sufficient explanation or justification\nfor the aspect rating, while textual summaries do not quantify the significance\nof each element, and are not well-suited for representing conflicting views.\nRecently, Key Point Analysis (KPA) has been proposed as a summarization\nframework that provides both textual and quantitative summary of the main\npoints in the data. We adapt KPA to review data by introducing Collective Key\nPoint Mining for better key point extraction; integrating sentiment analysis\ninto KPA; identifying good key point candidates for review summaries; and\nleveraging the massive amount of available reviews and their metadata. We show\nempirically that these novel extensions of KPA substantially improve its\nperformance. We demonstrate that promising results can be achieved without any\ndomain-specific annotation, while human supervision can lead to further\nimprovement.", "published": "2021-06-12 12:22:12", "link": "http://arxiv.org/abs/2106.06758v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Parallel Corpora to Improve Multilingual Embedding based\n  Document and Sentence Alignment", "abstract": "Multilingual sentence representations pose a great advantage for low-resource\nlanguages that do not have enough data to build monolingual models on their\nown. These multilingual sentence representations have been separately exploited\nby few research for document and sentence alignment. However, most of the\nlow-resource languages are under-represented in these pre-trained models. Thus,\nin the context of low-resource languages, these models have to be fine-tuned\nfor the task at hand, using additional data sources. This paper presents a\nweighting mechanism that makes use of available small-scale parallel corpora to\nimprove the performance of multilingual sentence representations on document\nand sentence alignment. Experiments are conducted with respect to two\nlow-resource languages, Sinhala and Tamil. Results on a newly created dataset\nof Sinhala-English, Tamil-English, and Sinhala-Tamil show that this new\nweighting mechanism significantly improves both document and sentence\nalignment. This dataset, as well as the source-code, is publicly released.", "published": "2021-06-12 13:00:10", "link": "http://arxiv.org/abs/2106.06766v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Translation into Low-resource Language Varieties", "abstract": "State-of-the-art machine translation (MT) systems are typically trained to\ngenerate the \"standard\" target language; however, many languages have multiple\nvarieties (regional varieties, dialects, sociolects, non-native varieties) that\nare different from the standard language. Such varieties are often\nlow-resource, and hence do not benefit from contemporary NLP solutions, MT\nincluded. We propose a general framework to rapidly adapt MT systems to\ngenerate language varieties that are close to, but different from, the standard\ntarget language, using no parallel (source--variety) data. This also includes\nadaptation of MT systems to low-resource typologically-related target\nlanguages. We experiment with adapting an English--Russian MT system to\ngenerate Ukrainian and Belarusian, an English--Norwegian Bokm{\\aa}l system to\ngenerate Nynorsk, and an English--Arabic system to generate four Arabic\ndialects, obtaining significant improvements over competitive baselines.", "published": "2021-06-12 15:28:53", "link": "http://arxiv.org/abs/2106.06797v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Pseudo Label-wise Attention Network for Automatic ICD Coding", "abstract": "Automatic International Classification of Diseases (ICD) coding is defined as\na kind of text multi-label classification problem, which is difficult because\nthe number of labels is very large and the distribution of labels is\nunbalanced. The label-wise attention mechanism is widely used in automatic ICD\ncoding because it can assign weights to every word in full Electronic Medical\nRecords (EMR) for different ICD codes. However, the label-wise attention\nmechanism is computational redundant and costly. In this paper, we propose a\npseudo label-wise attention mechanism to tackle the problem. Instead of\ncomputing different attention modes for different ICD codes, the pseudo\nlabel-wise attention mechanism automatically merges similar ICD codes and\ncomputes only one attention mode for the similar ICD codes, which greatly\ncompresses the number of attention modes and improves the predicted accuracy.\nIn addition, we apply a more convenient and effective way to obtain the ICD\nvectors, and thus our model can predict new ICD codes by calculating the\nsimilarities between EMR vectors and ICD vectors. Extensive experiments show\nthe superior performance of our model. On the public MIMIC-III dataset and\nprivate Xiangya dataset, our model achieves micro f1 of 0.583 and 0.806,\nrespectively, which outperforms other competing models. Furthermore, we verify\nthe ability of our model in predicting new ICD codes. The case study shows how\npseudo label-wise attention works, and demonstrates the effectiveness of pseudo\nlabel-wise attention mechanism.", "published": "2021-06-12 17:03:27", "link": "http://arxiv.org/abs/2106.06822v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Transformer Language Models Predict Psychometric Properties?", "abstract": "Transformer-based language models (LMs) continue to advance state-of-the-art\nperformance on NLP benchmark tasks, including tasks designed to mimic\nhuman-inspired \"commonsense\" competencies. To better understand the degree to\nwhich LMs can be said to have certain linguistic reasoning skills, researchers\nare beginning to adapt the tools and concepts of the field of psychometrics.\nBut to what extent can the benefits flow in the other direction? I.e., can LMs\nbe of use in predicting what the psychometric properties of test items will be\nwhen those items are given to human participants? We gather responses from\nnumerous human participants and LMs (transformer and non-transformer-based) on\na broad diagnostic test of linguistic competencies. We then use the responses\nto calculate standard psychometric properties of the items in the diagnostic\ntest, using the human responses and the LM responses separately. We then\ndetermine how well these two sets of predictions match. We find cases in which\ntransformer-based LMs predict psychometric properties consistently well in\ncertain categories but consistently poorly in others, thus providing new\ninsights into fundamental similarities and differences between human and LM\nreasoning.", "published": "2021-06-12 20:05:33", "link": "http://arxiv.org/abs/2106.06849v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Rule Out Monolingual Speakers: A Method For Crowdsourcing Machine\n  Translation Data", "abstract": "High-performing machine translation (MT) systems can help overcome language\nbarriers while making it possible for everyone to communicate and use language\ntechnologies in the language of their choice. However, such systems require\nlarge amounts of parallel sentences for training, and translators can be\ndifficult to find and expensive. Here, we present a data collection strategy\nfor MT which, in contrast, is cheap and simple, as it does not require\nbilingual speakers. Based on the insight that humans pay specific attention to\nmovements, we use graphics interchange formats (GIFs) as a pivot to collect\nparallel sentences from monolingual annotators. We use our strategy to collect\ndata in Hindi, Tamil and English. As a baseline, we also collect data using\nimages as a pivot. We perform an intrinsic evaluation by manually evaluating a\nsubset of the sentence pairs and an extrinsic evaluation by finetuning mBART on\nthe collected data. We find that sentences collected via GIFs are indeed of\nhigher quality.", "published": "2021-06-12 22:29:54", "link": "http://arxiv.org/abs/2106.06875v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Explaining the Deep Natural Language Processing by Mining Textual\n  Interpretable Features", "abstract": "Despite the high accuracy offered by state-of-the-art deep natural-language\nmodels (e.g. LSTM, BERT), their application in real-life settings is still\nwidely limited, as they behave like a black-box to the end-user. Hence,\nexplainability is rapidly becoming a fundamental requirement of\nfuture-generation data-driven systems based on deep-learning approaches.\nSeveral attempts to fulfill the existing gap between accuracy and\ninterpretability have been done. However, robust and specialized xAI\n(Explainable Artificial Intelligence) solutions tailored to deep\nnatural-language models are still missing. We propose a new framework, named\nT-EBAnO, which provides innovative prediction-local and class-based\nmodel-global explanation strategies tailored to black-box deep natural-language\nmodels. Given a deep NLP model and the textual input data, T-EBAnO provides an\nobjective, human-readable, domain-specific assessment of the reasons behind the\nautomatic decision-making process. Specifically, the framework extracts sets of\ninterpretable features mining the inner knowledge of the model. Then, it\nquantifies the influence of each feature during the prediction process by\nexploiting the novel normalized Perturbation Influence Relation index at the\nlocal level and the novel Global Absolute Influence and Global Relative\nInfluence indexes at the global level. The effectiveness and the quality of the\nlocal and global explanations obtained with T-EBAnO are proved on (i) a\nsentiment analysis task performed by a fine-tuned BERT model, and (ii) a toxic\ncomment classification task performed by an LSTM model.", "published": "2021-06-12 06:25:09", "link": "http://arxiv.org/abs/2106.06697v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompting Contrastive Explanations for Commonsense Reasoning Tasks", "abstract": "Many commonsense reasoning NLP tasks involve choosing between one or more\npossible answers to a question or prompt based on knowledge that is often\nimplicit. Large pretrained language models (PLMs) can achieve near-human\nperformance on such tasks, while providing little human-interpretable evidence\nof the underlying reasoning they use. In this work, we show how to use these\nsame models to generate such evidence: inspired by the contrastive nature of\nhuman explanations, we use PLMs to complete explanation prompts which contrast\nalternatives according to the key attribute(s) required to justify the correct\nanswer (for example, peanuts are usually salty while raisins are sweet).\nConditioning model decisions on these explanations improves performance on two\ncommonsense reasoning benchmarks, as compared to previous non-contrastive\nalternatives. These explanations are also judged by humans to be more relevant\nfor solving the task, and facilitate a novel method to evaluate explanation\nfaithfulfness.", "published": "2021-06-12 17:06:13", "link": "http://arxiv.org/abs/2106.06823v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Entity Disambiguation and the Role of Popularity in\n  Retrieval-Based NLP", "abstract": "Retrieval is a core component for open-domain NLP tasks. In open-domain\ntasks, multiple entities can share a name, making disambiguation an inherent\nyet under-explored problem. We propose an evaluation benchmark for assessing\nthe entity disambiguation capabilities of these retrievers, which we call\nAmbiguous Entity Retrieval (AmbER) sets. We define an AmbER set as a collection\nof entities that share a name along with queries about those entities. By\ncovering the set of entities for polysemous names, AmbER sets act as a\nchallenging test of entity disambiguation. We create AmbER sets for three\npopular open-domain tasks: fact checking, slot filling, and question answering,\nand evaluate a diverse set of retrievers. We find that the retrievers exhibit\npopularity bias, significantly under-performing on rarer entities that share a\nname, e.g., they are twice as likely to retrieve erroneous documents on queries\nfor the less popular entity under the same name. These experiments on AmbER\nsets show their utility as an evaluation tool and highlight the weaknesses of\npopular retrieval systems.", "published": "2021-06-12 18:27:18", "link": "http://arxiv.org/abs/2106.06830v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Scalable Approach for Normalizing E-commerce Text Attributes (SANTA)", "abstract": "In this paper, we present SANTA, a scalable framework to automatically\nnormalize E-commerce attribute values (e.g. \"Win 10 Pro\") to a fixed set of\npre-defined canonical values (e.g. \"Windows 10\"). Earlier works on attribute\nnormalization focused on fuzzy string matching (also referred as syntactic\nmatching in this paper). In this work, we first perform an extensive study of\nnine syntactic matching algorithms and establish that 'cosine' similarity leads\nto best results, showing 2.7% improvement over commonly used Jaccard index.\nNext, we argue that string similarity alone is not sufficient for attribute\nnormalization as many surface forms require going beyond syntactic matching\n(e.g. \"720p\" and \"HD\" are synonyms). While semantic techniques like\nunsupervised embeddings (e.g. word2vec/fastText) have shown good results in\nword similarity tasks, we observed that they perform poorly to distinguish\nbetween close canonical forms, as these close forms often occur in similar\ncontexts. We propose to learn token embeddings using a twin network with\ntriplet loss. We propose an embedding learning task leveraging raw attribute\nvalues and product titles to learn these embeddings in a self-supervised\nfashion. We show that providing supervision using our proposed task improves\nover both syntactic and unsupervised embeddings based techniques for attribute\nnormalization. Experiments on a real-world attribute normalization dataset of\n50 attributes show that the embeddings trained using our proposed approach\nobtain 2.3% improvement over best string matching and 19.3% improvement over\nbest unsupervised embeddings.", "published": "2021-06-12 08:45:56", "link": "http://arxiv.org/abs/2106.09493v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Assessing Multilingual Fairness in Pre-trained Multimodal\n  Representations", "abstract": "Recently pre-trained multimodal models, such as CLIP, have shown exceptional\ncapabilities towards connecting images and natural language. The textual\nrepresentations in English can be desirably transferred to multilingualism and\nsupport downstream multimodal tasks for different languages. Nevertheless, the\nprinciple of multilingual fairness is rarely scrutinized: do multilingual\nmultimodal models treat languages equally? Are their performances biased\ntowards particular languages? To answer these questions, we view language as\nthe fairness recipient and introduce two new fairness notions, multilingual\nindividual fairness and multilingual group fairness, for pre-trained multimodal\nmodels. Multilingual individual fairness requires that text snippets expressing\nsimilar semantics in different languages connect similarly to images, while\nmultilingual group fairness requires equalized predictive performance across\nlanguages. We characterize the extent to which pre-trained multilingual\nvision-and-language representations are individually fair across languages.\nHowever, extensive experiments demonstrate that multilingual representations do\nnot satisfy group fairness: (1) there is a severe multilingual accuracy\ndisparity issue; (2) the errors exhibit biases across languages conditioning\nthe group of people in the images, including race, gender and age.", "published": "2021-06-12 03:57:05", "link": "http://arxiv.org/abs/2106.06683v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Engineering Knowledge Graph from Patent Database", "abstract": "We propose a large, scalable engineering knowledge graph, comprising sets of\n(entity, relationship, entity) triples that are real-world engineering facts\nfound in the patent database. We apply a set of rules based on the syntactic\nand lexical properties of claims in a patent document to extract facts. We\naggregate these facts within each patent document and integrate the aggregated\nsets of facts across the patent database to obtain the engineering knowledge\ngraph. Such a knowledge graph is expected to support inference, reasoning, and\nrecalling in various engineering tasks. The knowledge graph has a greater size\nand coverage in comparison with the previously used knowledge graphs and\nsemantic networks in the engineering literature.", "published": "2021-06-12 10:54:31", "link": "http://arxiv.org/abs/2106.06739v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.IR"}
{"title": "Predicting the Ordering of Characters in Japanese Historical Documents", "abstract": "Japan is a unique country with a distinct cultural heritage, which is\nreflected in billions of historical documents that have been preserved.\nHowever, the change in Japanese writing system in 1900 made these documents\ninaccessible for the general public. A major research project has been to make\nthese historical documents accessible and understandable. An increasing amount\nof research has focused on the character recognition task and the location of\ncharacters on image, yet less research has focused on how to predict the\nsequential ordering of the characters. This is because sequence in classical\nJapanese is very different from modern Japanese. Ordering characters into a\nsequence is important for making the document text easily readable and\nsearchable. Additionally, it is a necessary step for any kind of natural\nlanguage processing on the data (e.g. machine translation, language modeling,\nand word embeddings). We explore a few approaches to the task of predicting the\nsequential ordering of the characters: one using simple hand-crafted rules,\nanother using hand-crafted rules with adaptive thresholds, and another using a\ndeep recurrent sequence model trained with teacher forcing. We provide a\nquantitative and qualitative comparison of these techniques as well as their\ndistinct trade-offs. Our best-performing system has an accuracy of 98.65\\% and\nhas a perfect accuracy on 49\\% of the books in our dataset, suggesting that the\ntechnique is able to predict the order of the characters well enough for many\ntasks.", "published": "2021-06-12 14:39:20", "link": "http://arxiv.org/abs/2106.06786v1", "categories": ["cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social\n  Media", "abstract": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.", "published": "2021-06-12 16:26:04", "link": "http://arxiv.org/abs/2106.06811v1", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "A Low-Compexity Deep Learning Framework For Acoustic Scene\n  Classification", "abstract": "In this paper, we presents a low-complexity deep learning frameworks for\nacoustic scene classification (ASC). The proposed framework can be separated\ninto three main steps: Front-end spectrogram extraction, back-end\nclassification, and late fusion of predicted probabilities. First, we use Mel\nfilter, Gammatone filter and Constant Q Transfrom (CQT) to transform raw audio\nsignal into spectrograms, where both frequency and temporal features are\npresented. Three spectrograms are then fed into three individual back-end\nconvolutional neural networks (CNNs), classifying into ten urban scenes.\nFinally, a late fusion of three predicted probabilities obtained from three\nCNNs is conducted to achieve the final classification result. To reduce the\ncomplexity of our proposed CNN network, we apply two model compression\ntechniques: model restriction and decomposed convolution. Our extensive\nexperiments, which are conducted on DCASE 2021 (IEEE AASP Challenge on\nDetection and Classification of Acoustic Scenes and Events) Task 1A development\ndataset, achieve a low-complexity CNN based framework with 128 KB trainable\nparameters and the best classification accuracy of 66.7%, improving DCASE\nbaseline by 19.0%", "published": "2021-06-12 19:20:39", "link": "http://arxiv.org/abs/2106.06838v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Learning Frameworks Applied For Audio-Visual Scene Classification", "abstract": "In this paper, we present deep learning frameworks for audio-visual scene\nclassification (SC) and indicate how individual visual and audio features as\nwell as their combination affect SC performance. Our extensive experiments,\nwhich are conducted on DCASE (IEEE AASP Challenge on Detection and\nClassification of Acoustic Scenes and Events) Task 1B development dataset,\nachieve the best classification accuracy of 82.2%, 91.1%, and 93.9% with audio\ninput only, visual input only, and both audio-visual input, respectively. The\nhighest classification accuracy of 93.9%, obtained from an ensemble of\naudio-based and visual-based frameworks, shows an improvement of 16.5% compared\nwith DCASE baseline.", "published": "2021-06-12 19:37:42", "link": "http://arxiv.org/abs/2106.06840v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving weakly supervised sound event detection with self-supervised\n  auxiliary tasks", "abstract": "While multitask and transfer learning has shown to improve the performance of\nneural networks in limited data settings, they require pretraining of the model\non large datasets beforehand. In this paper, we focus on improving the\nperformance of weakly supervised sound event detection in low data and noisy\nsettings simultaneously without requiring any pretraining task. To that extent,\nwe propose a shared encoder architecture with sound event detection as a\nprimary task and an additional secondary decoder for a self-supervised\nauxiliary task. We empirically evaluate the proposed framework for weakly\nsupervised sound event detection on a remix dataset of the DCASE 2019 task 1\nacoustic scene data with DCASE 2018 Task 2 sounds event data under 0, 10 and 20\ndB SNR. To ensure we retain the localisation information of multiple sound\nevents, we propose a two-step attention pooling mechanism that provides a\ntime-frequency localisation of multiple audio events in the clip. The proposed\nframework with two-step attention outperforms existing benchmark models by\n22.3%, 12.8%, 5.9% on 0, 10 and 20 dB SNR respectively. We carry out an\nablation study to determine the contribution of the auxiliary task and two-step\nattention pooling to the SED performance improvement.", "published": "2021-06-12 20:28:22", "link": "http://arxiv.org/abs/2106.06858v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Continuous Wavelet Vocoder-based Decomposition of Parametric Speech\n  Waveform Synthesis", "abstract": "To date, various speech technology systems have adopted the vocoder approach,\na method for synthesizing speech waveform that shows a major role in the\nperformance of statistical parametric speech synthesis. WaveNet one of the best\nmodels that nearly resembles the human voice, has to generate a waveform in a\ntime consuming sequential manner with an extremely complex structure of its\nneural networks.", "published": "2021-06-12 20:55:44", "link": "http://arxiv.org/abs/2106.06863v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
