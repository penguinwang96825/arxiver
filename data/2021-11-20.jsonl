{"title": "Combining Data-driven Supervision with Human-in-the-loop Feedback for\n  Entity Resolution", "abstract": "The distribution gap between training datasets and data encountered in\nproduction is well acknowledged. Training datasets are often constructed over a\nfixed period of time and by carefully curating the data to be labeled. Thus,\ntraining datasets may not contain all possible variations of data that could be\nencountered in real-world production environments. Tasked with building an\nentity resolution system - a model that identifies and consolidates data points\nthat represent the same person - our first model exhibited a clear\ntraining-production performance gap. In this case study, we discuss our\nhuman-in-the-loop enabled, data-centric solution to closing the\ntraining-production performance divergence. We conclude with takeaways that\napply to data-centric learning at large.", "published": "2021-11-20 02:22:12", "link": "http://arxiv.org/abs/2111.10497v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Processing Matters: SRPH-Konvergen AI's Machine Translation System\n  for WMT'21", "abstract": "In this paper, we describe the submission of the joint Samsung Research\nPhilippines-Konvergen AI team for the WMT'21 Large Scale Multilingual\nTranslation Task - Small Track 2. We submit a standard Seq2Seq Transformer\nmodel to the shared task without any training or architecture tricks, relying\nmainly on the strength of our data preprocessing techniques to boost\nperformance. Our final submission model scored 22.92 average BLEU on the\nFLORES-101 devtest set, and scored 22.97 average BLEU on the contest's hidden\ntest set, ranking us sixth overall. Despite using only a standard Transformer,\nour model ranked first in Indonesian to Javanese, showing that data\npreprocessing matters equally, if not more, than cutting edge model\narchitectures and training techniques.", "published": "2021-11-20 03:56:37", "link": "http://arxiv.org/abs/2111.10513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph-augmented Learning to Rank for Querying Large-scale Knowledge\n  Graph", "abstract": "Knowledge graph question answering (KGQA) based on information retrieval aims\nto answer a question by retrieving answer from a large-scale knowledge graph.\nMost existing methods first roughly retrieve the knowledge subgraphs (KSG) that\nmay contain candidate answer, and then search for the exact answer in the KSG.\nHowever, the KSG may contain thousands of candidate nodes since the knowledge\ngraph involved in querying is often of large scale, thus decreasing the\nperformance of answer selection. To tackle this problem, we first propose to\npartition the retrieved KSG to several smaller sub-KSGs via a new subgraph\npartition algorithm and then present a graph-augmented learning to rank model\nto select the top-ranked sub-KSGs from them. Our proposed model combines a\nnovel subgraph matching networks to capture global interactions in both\nquestion and subgraphs, and an Enhanced Bilateral Multi-Perspective Matching\nmodel is proposed to capture local interactions. Finally, we apply an answer\nselection model on the full KSG and the top-ranked sub-KSGs respectively to\nvalidate the effectiveness of our proposed graph-augmented learning to rank\nmethod. The experimental results on multiple benchmark datasets have\ndemonstrated the effectiveness of our approach.", "published": "2021-11-20 08:27:37", "link": "http://arxiv.org/abs/2111.10541v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Textbook to triples: Creating knowledge graph in the form of triples\n  from AI TextBook", "abstract": "A knowledge graph is an essential and trending technology with great\napplications in entity recognition, search, or question answering. There are a\nplethora of methods in natural language processing for performing the task of\nNamed entity recognition; however, there are very few methods that could\nprovide triples for a domain-specific text. In this paper, an effort has been\nmade towards developing a system that could convert the text from a given\ntextbook into triples that can be used to visualize as a knowledge graph and\nuse for further applications. The initial assessment and evaluation gave\npromising results with an F1 score of 82%.", "published": "2021-11-20 22:28:23", "link": "http://arxiv.org/abs/2111.10692v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Triples-to-Text Generation with Reinforcement Learning Based\n  Graph-augmented Neural Networks", "abstract": "Considering a collection of RDF triples, the RDF-to-text generation task aims\nto generate a text description. Most previous methods solve this task using a\nsequence-to-sequence model or using a graph-based model to encode RDF triples\nand to generate a text sequence. Nevertheless, these approaches fail to clearly\nmodel the local and global structural information between and within RDF\ntriples. Moreover, the previous methods also face the non-negligible problem of\nlow faithfulness of the generated text, which seriously affects the overall\nperformance of these models. To solve these problems, we propose a model\ncombining two new graph-augmented structural neural encoders to jointly learn\nboth local and global structural information in the input RDF triples. To\nfurther improve text faithfulness, we innovatively introduce a reinforcement\nlearning (RL) reward based on information extraction (IE). We first extract\ntriples from the generated text using a pretrained IE model and regard the\ncorrect number of the extracted triples as the additional RL reward.\nExperimental results on two benchmark datasets demonstrate that our proposed\nmodel outperforms the state-of-the-art baselines, and the additional\nreinforcement learning reward does help to improve the faithfulness of the\ngenerated text.", "published": "2021-11-20 08:41:54", "link": "http://arxiv.org/abs/2111.10545v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Tagging Consistency and Entity Coverage for Chemical\n  Identification in Full-text Articles", "abstract": "This paper is a technical report on our system submitted to the chemical\nidentification task of the BioCreative VII Track 2 challenge. The main feature\nof this challenge is that the data consists of full-text articles, while\ncurrent datasets usually consist of only titles and abstracts. To effectively\naddress the problem, we aim to improve tagging consistency and entity coverage\nusing various methods such as majority voting within the same articles for\nnamed entity recognition (NER) and a hybrid approach that combines a dictionary\nand a neural model for normalization. In the experiments on the NLM-Chem\ndataset, we show that our methods improve models' performance, particularly in\nterms of recall. Finally, in the official evaluation of the challenge, our\nsystem was ranked 1st in NER by significantly outperforming the baseline model\nand more than 80 submissions from 16 teams.", "published": "2021-11-20 13:13:58", "link": "http://arxiv.org/abs/2111.10584v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised Prototype Topic Model with Discriminative Seed Words:\n  Modifying the Category Prior by Self-exploring Supervised Signals", "abstract": "Dataless text classification, i.e., a new paradigm of weakly supervised\nlearning, refers to the task of learning with unlabeled documents and a few\npredefined representative words of categories, known as seed words. The recent\ngenerative dataless methods construct document-specific category priors by\nusing seed word occurrences only, however, such category priors often contain\nvery limited and even noisy supervised signals. To remedy this problem, in this\npaper we propose a novel formulation of category prior. First, for each\ndocument, we consider its label membership degree by not only counting seed\nword occurrences, but also using a novel prototype scheme, which captures\npseudo-nearest neighboring categories. Second, for each label, we consider its\nfrequency prior knowledge of the corpus, which is also a discriminative\nknowledge for classification. By incorporating the proposed category prior into\nthe previous generative dataless method, we suggest a novel generative dataless\nmethod, namely Weakly Supervised Prototype Topic Model (WSPTM). The\nexperimental results on real-world datasets demonstrate that WSPTM outperforms\nthe existing baseline methods.", "published": "2021-11-20 00:00:56", "link": "http://arxiv.org/abs/2112.03009v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Language Patterns in a Medical Licensure Exam Item Bank", "abstract": "This study examines the use of natural language processing (NLP) models to\nevaluate whether language patterns used by item writers in a medical licensure\nexam might contain evidence of biased or stereotypical language. This type of\nbias in item language choices can be particularly impactful for items in a\nmedical licensure assessment, as it could pose a threat to content validity and\ndefensibility of test score validity evidence. To the best of our knowledge,\nthis is the first attempt using machine learning (ML) and NLP to explore\nlanguage bias on a large item bank. Using a prediction algorithm trained on\nclusters of similar item stems, we demonstrate that our approach can be used to\nreview large item banks for potential biased language or stereotypical patient\ncharacteristics in clinical science vignettes. The findings may guide the\ndevelopment of methods to address stereotypical language patterns found in test\nitems and enable an efficient updating of those items, if needed, to reflect\ncontemporary norms, thereby improving the evidence to support the validity of\nthe test scores.", "published": "2021-11-20 02:45:35", "link": "http://arxiv.org/abs/2111.10501v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Switching Independent Vector Analysis and Its Extension to Blind and\n  Spatially Guided Convolutional Beamforming Algorithms", "abstract": "This paper develops a framework that can perform denoising, dereverberation,\nand source separation accurately by using a relatively small number of\nmicrophones. It has been empirically confirmed that Independent Vector Analysis\n(IVA) can blindly separate N sources from their sound mixture even with diffuse\nnoise when a sufficiently large number (=M) of microphones are available (i.e.,\nM>>N). However, the estimation accuracy seriously degrades as the number of\nmicrophones, or more specifically M-N (>=0), decreases. To overcome this\nlimitation of IVA, we propose switching IVA (swIVA) in this paper. With swIVA,\ntime frames of an observed signal with time-varying characteristics are\nclustered into several groups, each of which can be well handled by IVA using a\nsmall number of microphones, and thus accurate estimation can be achieved by\napplying IVA individually to each of the groups. Conventionally, a switching\nmechanism was introduced into a beamformer; however, no blind source separation\nalgorithms with a switching mechanism have been successfully developed until\nthis paper. In order to incorporate dereverberation capability, this paper\nfurther extends swIVA to blind Convolutional beamforming algorithm (swCIVA). It\nintegrates swIVA and switching Weighted Prediction Error-based dereverberation\n(swWPE) in a jointly optimal way. We show that both swIVA and swCIVA can be\noptimized effectively based on blind signal processing, and that their\nperformance can be further improved using a spatial guide for the\ninitialization. Experiments show that both proposed methods largely outperform\nconventional IVA and its Convolutional beamforming extension (CIVA) in terms of\nobjective signal quality and automatic speech recognition scores when using a\nrelatively small number of microphones.", "published": "2021-11-20 12:31:40", "link": "http://arxiv.org/abs/2111.10574v2", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Deep Spoken Keyword Spotting: An Overview", "abstract": "Spoken keyword spotting (KWS) deals with the identification of keywords in\naudio streams and has become a fast-growing technology thanks to the paradigm\nshift introduced by deep learning a few years ago. This has allowed the rapid\nembedding of deep KWS in a myriad of small electronic devices with different\npurposes like the activation of voice assistants. Prospects suggest a sustained\ngrowth in terms of social use of this technology. Thus, it is not surprising\nthat deep KWS has become a hot research topic among speech scientists, who\nconstantly look for KWS performance improvement and computational complexity\nreduction. This context motivates this paper, in which we conduct a literature\nreview into deep spoken KWS to assist practitioners and researchers who are\ninterested in this technology. Specifically, this overview has a comprehensive\nnature by covering a thorough analysis of deep KWS systems (which includes\nspeech features, acoustic modeling and posterior handling), robustness methods,\napplications, datasets, evaluation metrics, performance of deep KWS systems and\naudio-visual KWS. The analysis performed in this paper allows us to identify a\nnumber of directions for future research, including directions adopted from\nautomatic speech recognition research and directions that are unique to the\nproblem of spoken KWS.", "published": "2021-11-20 13:46:57", "link": "http://arxiv.org/abs/2111.10592v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Implicit Acoustic Echo Cancellation for Keyword Spotting and\n  Device-Directed Speech Detection", "abstract": "In many speech-enabled human-machine interaction scenarios, user speech can\noverlap with the device playback audio. In these instances, the performance of\ntasks such as keyword-spotting (KWS) and device-directed speech detection (DDD)\ncan degrade significantly. To address this problem, we propose an implicit\nacoustic echo cancellation (iAEC) framework where a neural network is trained\nto exploit the additional information from a reference microphone channel to\nlearn to ignore the interfering signal and improve detection performance. We\nstudy this framework for the tasks of KWS and DDD on, respectively, an\naugmented version of Google Speech Commands v2 and a real-world Alexa device\ndataset. Notably, we show a 56% reduction in false-reject rate for the DDD task\nduring device playback conditions. We also show comparable or superior\nperformance over a strong end-to-end neural echo cancellation + KWS baseline\nfor the KWS task with an order of magnitude less computational requirements.", "published": "2021-11-20 17:21:16", "link": "http://arxiv.org/abs/2111.10639v4", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Acoustical Analysis of Speech Under Physical Stress in Relation to\n  Physical Activities and Physical Literacy", "abstract": "Human speech production encompasses physiological processes that naturally\nreact to physic stress. Stress caused by physical activity (PA), e.g., running,\nmay lead to significant changes in a person's speech. The major changes are\nrelated to the aspects of pitch level, speaking rate, pause pattern, and\nbreathiness. The extent of change depends presumably on physical fitness and\nwell-being of the person, as well as intensity of PA. The general wellness of a\nperson is further related to his/her physical literacy (PL), which refers to a\nholistic description of engagement in PA. This paper presents the development\nof a Cantonese speech database that contains audio recordings of speech before\nand after physical exercises of different intensity levels. The corpus design\nand data collection process are described. Preliminary results of acoustical\nanalysis are presented to illustrate the impact of PA on pitch level, pitch\nrange, speaking and articulation rate, and time duration of pauses. It is also\nnoted that the effect of PA is correlated to some of the PA and PL measures.", "published": "2021-11-20 16:58:26", "link": "http://arxiv.org/abs/2111.12566v2", "categories": ["q-bio.QM", "cs.SD", "eess.AS"], "primary_category": "q-bio.QM"}
