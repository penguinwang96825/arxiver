{"title": "Naver Labs Europe's Systems for the WMT19 Machine Translation Robustness\n  Task", "abstract": "This paper describes the systems that we submitted to the WMT19 Machine\nTranslation robustness task. This task aims to improve MT's robustness to noise\nfound on social media, like informal language, spelling mistakes and other\northographic variations. The organizers provide parallel data extracted from a\nsocial media website in two language pairs: French-English and Japanese-English\n(in both translation directions). The goal is to obtain the best scores on\nunseen test sets from the same source, according to automatic metrics (BLEU)\nand human evaluation. We proposed one single and one ensemble system for each\ntranslation direction. Our ensemble models ranked first in all language pairs,\naccording to BLEU evaluation. We discuss the pre-processing choices that we\nmade, and present our solutions for robustness to noise and domain adaptation.", "published": "2019-07-15 13:19:44", "link": "http://arxiv.org/abs/1907.06488v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Facebook FAIR's WMT19 News Translation Task Submission", "abstract": "This paper describes Facebook FAIR's submission to the WMT19 shared news\ntranslation task. We participate in two language pairs and four language\ndirections, English <-> German and English <-> Russian. Following our\nsubmission from last year, our baseline systems are large BPE-based transformer\nmodels trained with the Fairseq sequence modeling toolkit which rely on sampled\nback-translations. This year we experiment with different bitext data filtering\nschemes, as well as with adding filtered back-translated data. We also ensemble\nand fine-tune our models on domain-specific data, then decode using noisy\nchannel model reranking. Our submissions are ranked first in all four\ndirections of the human evaluation campaign. On En->De, our system\nsignificantly outperforms other systems as well as human translations. This\nsystem improves upon our WMT'18 submission by 4.5 BLEU points.", "published": "2019-07-15 17:22:54", "link": "http://arxiv.org/abs/1907.06616v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLOSS: Generative Latent Optimization of Sentence Representations", "abstract": "We propose a method to learn unsupervised sentence representations in a\nnon-compositional manner based on Generative Latent Optimization. Our approach\ndoes not impose any assumptions on how words are to be combined into a sentence\nrepresentation. We discuss a simple Bag of Words model as well as a variant\nthat models word positions. Both are trained to reconstruct the sentence based\non a latent code and our model can be used to generate text. Experiments show\nlarge improvements over the related Paragraph Vectors. Compared to uSIF, we\nachieve a relative improvement of 5% when trained on the same data and our\nmethod performs competitively to Sent2vec while trained on 30 times less data.", "published": "2019-07-15 09:23:49", "link": "http://arxiv.org/abs/1907.06385v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigation on N-gram Approximated RNNLMs for Recognition of\n  Morphologically Rich Speech", "abstract": "Recognition of Hungarian conversational telephone speech is challenging due\nto the informal style and morphological richness of the language. Recurrent\nNeural Network Language Model (RNNLM) can provide remedy for the high\nperplexity of the task; however, two-pass decoding introduces a considerable\nprocessing delay. In order to eliminate this delay we investigate approaches\naiming at the complexity reduction of RNNLM, while preserving its accuracy. We\ncompare the performance of conventional back-off n-gram language models (BNLM),\nBNLM approximation of RNNLMs (RNN-BNLM) and RNN n-grams in terms of perplexity\nand word error rate (WER). Morphological richness is often addressed by using\nstatistically derived subwords - morphs - in the language models, hence our\ninvestigations are extended to morph-based models, as well. We found that using\nRNN-BNLMs 40% of the RNNLM perplexity reduction can be recovered, which is\nroughly equal to the performance of a RNN 4-gram model. Combining morph-based\nmodeling and approximation of RNNLM, we were able to achieve 8% relative WER\nreduction and preserve real-time operation of our conversational telephone\nspeech recognition system.", "published": "2019-07-15 10:07:07", "link": "http://arxiv.org/abs/1907.06407v3", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Ranking sentences from product description & bullets for better search", "abstract": "Products in an ecommerce catalog contain information-rich fields like\ndescription and bullets that can be useful to extract entities (attributes)\nusing NER based systems. However, these fields are often verbose and contain\nlot of information that is not relevant from a search perspective. Treating\neach sentence within these fields equally can lead to poor full text match and\nintroduce problems in extracting attributes to develop ontologies, semantic\nsearch etc. To address this issue, we describe two methods based on extractive\nsummarization with reinforcement learning by leveraging information in product\ntitles and search click through logs to rank sentences from bullets,\ndescription, etc. Finally, we compare the accuracy of these two models.", "published": "2019-07-15 04:48:34", "link": "http://arxiv.org/abs/1907.06330v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Joint Language Identification of Code-Switching Speech using Attention\n  based E2E Network", "abstract": "Language identification (LID) has relevance in many speech processing\napplications. For the automatic recognition of code-switching speech, the\nconventional approaches often employ an LID system for detecting the languages\npresent within an utterance. In the existing works, the LID on code-switching\nspeech involves modelling of the underlying languages separately. In this work,\nwe propose a joint modelling based LID system for code-switching speech. To\nachieve the same, an attention-based end-to-end (E2E) network has been\nexplored. For the development and evaluation of the proposed approach, a\nrecently created Hindi-English code-switching corpus has been used. For the\ncontrast purpose, an LID system employing the connectionist temporal\nclassification-based E2E network is also developed. On comparing both the LID\nsystems, the attention based approach is noted to result in better LID\naccuracy. The effective location of code-switching boundaries within the\nutterance by the proposed approach has been demonstrated by plotting the\nattention weights of E2E network.", "published": "2019-07-15 06:30:15", "link": "http://arxiv.org/abs/1907.06342v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "RaKUn: Rank-based Keyword extraction via Unsupervised learning and Meta\n  vertex aggregation", "abstract": "Keyword extraction is used for summarizing the content of a document and\nsupports efficient document retrieval, and is as such an indispensable part of\nmodern text-based systems. We explore how load centrality, a graph-theoretic\nmeasure applied to graphs derived from a given text can be used to efficiently\nidentify and rank keywords. Introducing meta vertices (aggregates of existing\nvertices) and systematic redundancy filters, the proposed method performs on\npar with state-of-the-art for the keyword extraction task on 14 diverse\ndatasets. The proposed method is unsupervised, interpretable and can also be\nused for document visualization.", "published": "2019-07-15 12:10:24", "link": "http://arxiv.org/abs/1907.06458v3", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Asking Clarifying Questions in Open-Domain Information-Seeking\n  Conversations", "abstract": "Users often fail to formulate their complex information needs in a single\nquery. As a consequence, they may need to scan multiple result pages or\nreformulate their queries, which may be a frustrating experience.\nAlternatively, systems can improve user satisfaction by proactively asking\nquestions of the users to clarify their information needs. Asking clarifying\nquestions is especially important in conversational systems since they can only\nreturn a limited number of (often only one) result(s). In this paper, we\nformulate the task of asking clarifying questions in open-domain\ninformation-seeking conversational systems. To this end, we propose an offline\nevaluation methodology for the task and collect a dataset, called Qulac,\nthrough crowdsourcing. Our dataset is built on top of the TREC Web Track\n2009-2012 data and consists of over 10K question-answer pairs for 198 TREC\ntopics with 762 facets. Our experiments on an oracle model demonstrate that\nasking only one good question leads to over 170% retrieval performance\nimprovement in terms of P@1, which clearly demonstrates the potential impact of\nthe task. We further propose a retrieval framework consisting of three\ncomponents: question retrieval, question selection, and document retrieval. In\nparticular, our question selection model takes into account the original query\nand previous question-answer interactions while selecting the next question.\nOur model significantly outperforms competitive baselines. To foster research\nin this area, we have made Qulac publicly available.", "published": "2019-07-15 15:45:37", "link": "http://arxiv.org/abs/1907.06554v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Towards Near-imperceptible Steganographic Text", "abstract": "We show that the imperceptibility of several existing linguistic\nsteganographic systems (Fang et al., 2017; Yang et al., 2018) relies on\nimplicit assumptions on statistical behaviors of fluent text. We formally\nanalyze them and empirically evaluate these assumptions. Furthermore, based on\nthese observations, we propose an encoding algorithm called patient-Huffman\nwith improved near-imperceptible guarantees.", "published": "2019-07-15 18:17:13", "link": "http://arxiv.org/abs/1907.06679v2", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Low-supervision urgency detection and transfer in short crisis messages", "abstract": "Humanitarian disasters have been on the rise in recent years due to the\neffects of climate change and socio-political situations such as the refugee\ncrisis. Technology can be used to best mobilize resources such as food and\nwater in the event of a natural disaster, by semi-automatically flagging tweets\nand short messages as indicating an urgent need. The problem is challenging not\njust because of the sparseness of data in the immediate aftermath of a\ndisaster, but because of the varying characteristics of disasters in developing\ncountries (making it difficult to train just one system) and the noise and\nquirks in social media. In this paper, we present a robust, low-supervision\nsocial media urgency system that adapts to arbitrary crises by leveraging both\nlabeled and unlabeled data in an ensemble setting. The system is also able to\nadapt to new crises where an unlabeled background corpus may not be available\nyet by utilizing a simple and effective transfer learning methodology.\nExperimentally, our transfer learning and low-supervision approaches are found\nto outperform viable baselines with high significance on myriad disaster\ndatasets.", "published": "2019-07-15 20:43:53", "link": "http://arxiv.org/abs/1907.06745v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Logic Conditionals, Supervenience, and Selection Tasks", "abstract": "Principles of cognitive economy would require that concepts about objects,\nproperties and relations should be introduced only if they simplify the\nconceptualisation of a domain. Unexpectedly, classic logic conditionals,\nspecifying structures holding within elements of a formal conceptualisation, do\nnot always satisfy this crucial principle. The paper argues that this\nrequirement is captured by supervenience, hereby further identified as a\nproperty necessary for compression. The resulting theory suggests an\nalternative explanation of the empirical experiences observable in Wason's\nselection tasks, associating human performance with conditionals on the ability\nof dealing with compression, rather than with logic necessity.", "published": "2019-07-15 22:16:00", "link": "http://arxiv.org/abs/1907.06773v2", "categories": ["cs.AI", "cs.CL", "cs.SC"], "primary_category": "cs.AI"}
{"title": "Investigating Target Set Reduction for End-to-End Speech Recognition of\n  Hindi-English Code-Switching Data", "abstract": "End-to-end (E2E) systems are fast replacing the conventional systems in the\ndomain of automatic speech recognition. As the target labels are learned\ndirectly from speech data, the E2E systems need a bigger corpus for effective\ntraining. In the context of code-switching task, the E2E systems face two\nchallenges: (i) the expansion of the target set due to multiple languages\ninvolved, and (ii) the lack of availability of sufficiently large\ndomain-specific corpus. Towards addressing those challenges, we propose an\napproach for reducing the number of target labels for reliable training of the\nE2E systems on limited data. The efficacy of the proposed approach has been\ndemonstrated on two prominent architectures, namely CTC-based and\nattention-based E2E networks. The experimental validations are performed on a\nrecently created Hindi-English code-switching corpus. For contrast purpose, the\nresults for the full target set based E2E system and a hybrid DNN-HMM system\nare also reported.", "published": "2019-07-15 06:34:28", "link": "http://arxiv.org/abs/1907.08293v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-modal Sentiment Analysis using Deep Canonical Correlation Analysis", "abstract": "This paper learns multi-modal embeddings from text, audio, and video\nviews/modes of data in order to improve upon down-stream sentiment\nclassification. The experimental framework also allows investigation of the\nrelative contributions of the individual views in the final multi-modal\nembedding. Individual features derived from the three views are combined into a\nmulti-modal embedding using Deep Canonical Correlation Analysis (DCCA) in two\nways i) One-Step DCCA and ii) Two-Step DCCA. This paper learns text embeddings\nusing BERT, the current state-of-the-art in text encoders. We posit that this\nhighly optimized algorithm dominates over the contribution of other views,\nthough each view does contribute to the final result. Classification tasks are\ncarried out on two benchmark datasets and on a new Debate Emotion data set, and\ntogether these demonstrate that the one-Step DCCA outperforms the current\nstate-of-the-art in learning multi-modal embeddings.", "published": "2019-07-15 21:48:28", "link": "http://arxiv.org/abs/1907.08696v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Integrating the Data Augmentation Scheme with Various Classifiers for\n  Acoustic Scene Modeling", "abstract": "This technical report describes the IOA team's submission for TASK1A of\nDCASE2019 challenge. Our acoustic scene classification (ASC) system adopts a\ndata augmentation scheme employing generative adversary networks. Two major\nclassifiers, 1D deep convolutional neural network integrated with scalogram\nfeatures and 2D fully convolutional neural network integrated with Mel filter\nbank features, are deployed in the scheme. Other approaches, such as adversary\ncity adaptation, temporal module based on discrete cosine transform and hybrid\narchitectures, have been developed for further fusion. The results of our\nexperiments indicates that the final fusion systems A-D could achieve an\naccuracy higher than 85% on the officially provided fold 1 evaluation dataset.", "published": "2019-07-15 08:17:34", "link": "http://arxiv.org/abs/1907.06639v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hierarchical Sequence to Sequence Voice Conversion with Limited Data", "abstract": "We present a voice conversion solution using recurrent sequence to sequence\nmodeling for DNNs. Our solution takes advantage of recent advances in attention\nbased modeling in the fields of Neural Machine Translation (NMT),\nText-to-Speech (TTS) and Automatic Speech Recognition (ASR). The problem\nconsists of converting between voices in a parallel setting when {\\it\n$<$source,target$>$} audio pairs are available. Our seq2seq architecture makes\nuse of a hierarchical encoder to summarize input audio frames. On the decoder\nside, we use an attention based architecture used in recent TTS works. Since\nthere is a dearth of large multispeaker voice conversion databases needed for\ntraining DNNs, we resort to training the network with a large single speaker\ndataset as an autoencoder. This is then adapted for the smaller multispeaker\nvoice conversion datasets available for voice conversion. In contrast with\nother voice conversion works that use $F_0$, duration and linguistic features,\nour system uses mel spectrograms as the audio representation. Output mel frames\nare converted back to audio using a wavenet vocoder.", "published": "2019-07-15 07:54:46", "link": "http://arxiv.org/abs/1907.07769v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
