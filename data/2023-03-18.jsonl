{"title": "Revisiting Automatic Question Summarization Evaluation in the Biomedical\n  Domain", "abstract": "Automatic evaluation metrics have been facilitating the rapid development of\nautomatic summarization methods by providing instant and fair assessments of\nthe quality of summaries. Most metrics have been developed for the general\ndomain, especially news and meeting notes, or other language-generation tasks.\nHowever, these metrics are applied to evaluate summarization systems in\ndifferent domains, such as biomedical question summarization. To better\nunderstand whether commonly used evaluation metrics are capable of evaluating\nautomatic summarization in the biomedical domain, we conduct human evaluations\nof summarization quality from four different aspects of a biomedical question\nsummarization task. Based on human judgments, we identify different noteworthy\nfeatures for current automatic metrics and summarization systems as well. We\nalso release a dataset of our human annotations to aid the research of\nsummarization evaluation metrics in the biomedical domain.", "published": "2023-03-18 04:28:01", "link": "http://arxiv.org/abs/2303.10328v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Partial Knowledge Base Inference in Biomedical Entity Linking", "abstract": "Biomedical entity linking (EL) consists of named entity recognition (NER) and\nnamed entity disambiguation (NED). EL models are trained on corpora labeled by\na predefined KB. However, it is a common scenario that only entities within a\nsubset of the KB are precious to stakeholders. We name this scenario partial\nknowledge base inference: training an EL model with one KB and inferring on the\npart of it without further training. In this work, we give a detailed\ndefinition and evaluation procedures for this practically valuable but\nsignificantly understudied scenario and evaluate methods from three\nrepresentative EL paradigms. We construct partial KB inference benchmarks and\nwitness a catastrophic degradation in EL performance due to dramatically\nprecision drop. Our findings reveal these EL paradigms can not correctly handle\nunlinkable mentions (NIL), so they are not robust to partial KB inference. We\nalso propose two simple-and-effective redemption methods to combat the NIL\nissue with little computational overhead. Codes are released at\nhttps://github.com/Yuanhy1997/PartialKB-EL.", "published": "2023-03-18 04:31:07", "link": "http://arxiv.org/abs/2303.10330v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Pre-trained Language Models in Simple Knowledge\n  Graph Question Answering", "abstract": "Large-scale pre-trained language models (PLMs) such as BERT have recently\nachieved great success and become a milestone in natural language processing\n(NLP). It is now the consensus of the NLP community to adopt PLMs as the\nbackbone for downstream tasks. In recent works on knowledge graph question\nanswering (KGQA), BERT or its variants have become necessary in their KGQA\nmodels. However, there is still a lack of comprehensive research and comparison\nof the performance of different PLMs in KGQA. To this end, we summarize two\nbasic KGQA frameworks based on PLMs without additional neural network modules\nto compare the performance of nine PLMs in terms of accuracy and efficiency. In\naddition, we present three benchmarks for larger-scale KGs based on the popular\nSimpleQuestions benchmark to investigate the scalability of PLMs. We carefully\nanalyze the results of all PLMs-based KGQA basic frameworks on these benchmarks\nand two other popular datasets, WebQuestionSP and FreebaseQA, and find that\nknowledge distillation techniques and knowledge enhancement methods in PLMs are\npromising for KGQA. Furthermore, we test ChatGPT, which has drawn a great deal\nof attention in the NLP community, demonstrating its impressive capabilities\nand limitations in zero-shot KGQA. We have released the code and benchmarks to\npromote the use of PLMs on KGQA.", "published": "2023-03-18 08:57:09", "link": "http://arxiv.org/abs/2303.10368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models", "abstract": "GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on,\nhave gained considerable attention due to their exceptional natural language\nprocessing capabilities. However, despite the abundance of research on the\ndifference in capabilities between GPT series models and fine-tuned models,\nthere has been limited attention given to the evolution of GPT series models'\ncapabilities over time. To conduct a comprehensive analysis of the capabilities\nof GPT series models, we select six representative models, comprising two GPT-3\nseries models (i.e., davinci and text-davinci-001) and four GPT-3.5 series\nmodels (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and\ngpt-3.5-turbo). We evaluate their performance on nine natural language\nunderstanding (NLU) tasks using 21 datasets. In particular, we compare the\nperformance and robustness of different models for each task under zero-shot\nand few-shot scenarios. Our extensive experiments reveal that the overall\nability of GPT series models on NLU tasks does not increase gradually as the\nmodels evolve, especially with the introduction of the RLHF training strategy.\nWhile this strategy enhances the models' ability to generate human-like\nresponses, it also compromises their ability to solve some tasks. Furthermore,\nour findings indicate that there is still room for improvement in areas such as\nmodel robustness.", "published": "2023-03-18 14:02:04", "link": "http://arxiv.org/abs/2303.10420v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Model Instruction Following: A Survey of Progresses and\n  Challenges", "abstract": "Task semantics can be expressed by a set of input-output examples or a piece\nof textual instruction. Conventional machine learning approaches for natural\nlanguage processing (NLP) mainly rely on the availability of large-scale sets\nof task-specific examples. Two issues arise: first, collecting task-specific\nlabeled examples does not apply to scenarios where tasks may be too complicated\nor costly to annotate, or the system is required to handle a new task\nimmediately; second, this is not user-friendly since end-users are probably\nmore willing to provide task description rather than a set of examples before\nusing the system. Therefore, the community is paying increasing interest in a\nnew supervision-seeking paradigm for NLP: learning to follow task instructions,\ni.e., instruction following. Despite its impressive progress, there are some\ncommon issues that the community struggles with. This survey paper tries to\nsummarize and provide insights to the current research on instruction\nfollowing, particularly, by answering the following questions: (i) What is task\ninstruction, and what instruction types exist? (ii) How to model instructions?\n(iii) What are popular instruction following datasets and evaluation metrics?\n(iv) What factors influence and explain the instructions' performance? (v) What\nchallenges remain in instruction following? To our knowledge, this is the first\ncomprehensive survey about instruction following.", "published": "2023-03-18 19:17:47", "link": "http://arxiv.org/abs/2303.10475v8", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Graph-Guided Reasoning Approach for Open-ended Commonsense Question\n  Answering", "abstract": "Recently, end-to-end trained models for multiple-choice commonsense question\nanswering (QA) have delivered promising results. However, such\nquestion-answering systems cannot be directly applied in real-world scenarios\nwhere answer candidates are not provided. Hence, a new benchmark challenge set\nfor open-ended commonsense reasoning (OpenCSR) has been recently released,\nwhich contains natural science questions without any predefined choices. On the\nOpenCSR challenge set, many questions require implicit multi-hop reasoning and\nhave a large decision space, reflecting the difficult nature of this task.\nExisting work on OpenCSR sorely focuses on improving the retrieval process,\nwhich extracts relevant factual sentences from a textual knowledge base,\nleaving the important and non-trivial reasoning task outside the scope. In this\nwork, we extend the scope to include a reasoner that constructs a\nquestion-dependent open knowledge graph based on retrieved supporting facts and\nemploys a sequential subgraph reasoning process to predict the answer. The\nsubgraph can be seen as a concise and compact graphical explanation of the\nprediction. Experiments on two OpenCSR datasets show that the proposed model\nachieves great performance on benchmark OpenCSR datasets.", "published": "2023-03-18 11:15:33", "link": "http://arxiv.org/abs/2303.10395v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Stop Words for Processing Software Engineering Documents: Do they\n  Matter?", "abstract": "Stop words, which are considered non-predictive, are often eliminated in\nnatural language processing tasks. However, the definition of uninformative\nvocabulary is vague, so most algorithms use general knowledge-based stop lists\nto remove stop words. There is an ongoing debate among academics about the\nusefulness of stop word elimination, especially in domain-specific settings. In\nthis work, we investigate the usefulness of stop word removal in a software\nengineering context. To do this, we replicate and experiment with three\nsoftware engineering research tools from related work. Additionally, we\nconstruct a corpus of software engineering domain-related text from 10,000\nStack Overflow questions and identify 200 domain-specific stop words using\ntraditional information-theoretic methods. Our results show that the use of\ndomain-specific stop words significantly improved the performance of research\ntools compared to the use of a general stop list and that 17 out of 19\nevaluation measures showed better performance.\n  Online appendix: https://zenodo.org/record/7865748", "published": "2023-03-18 15:39:23", "link": "http://arxiv.org/abs/2303.10439v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "GazeReader: Detecting Unknown Word Using Webcam for English as a Second\n  Language (ESL) Learners", "abstract": "Automatic unknown word detection techniques can enable new applications for\nassisting English as a Second Language (ESL) learners, thus improving their\nreading experiences. However, most modern unknown word detection methods\nrequire dedicated eye-tracking devices with high precision that are not easily\naccessible to end-users. In this work, we propose GazeReader, an unknown word\ndetection method only using a webcam. GazeReader tracks the learner's gaze and\nthen applies a transformer-based machine learning model that encodes the text\ninformation to locate the unknown word. We applied knowledge enhancement\nincluding term frequency, part of speech, and named entity recognition to\nimprove the performance. The user study indicates that the accuracy and\nF1-score of our method were 98.09% and 75.73%, respectively. Lastly, we\nexplored the design scope for ESL reading and discussed the findings.", "published": "2023-03-18 15:55:49", "link": "http://arxiv.org/abs/2303.10443v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language\n  Models", "abstract": "The pre-training and fine-tuning paradigm has contributed to a number of\nbreakthroughs in Natural Language Processing (NLP). Instead of directly\ntraining on a downstream task, language models are first pre-trained on large\ndatasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then\nfine-tuned on task-specific data (e.g., natural language generation, text\nsummarization, etc.). Scaling the model and dataset size has helped improve the\nperformance of LLMs, but unfortunately, this also lead to highly prohibitive\ncomputational costs. Pre-training LLMs often require orders of magnitude more\nFLOPs than fine-tuning and the model capacity often remains the same between\nthe two phases. To achieve training efficiency w.r.t training FLOPs, we propose\nto decouple the model capacity between the two phases and introduce Sparse\nPre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits\nof using unstructured weight sparsity to train only a subset of weights during\npre-training (Sparse Pre-training) and then recover the representational\ncapacity by allowing the zeroed weights to learn (Dense Fine-tuning). We\ndemonstrate that we can induce up to 75% sparsity into a 1.3B parameter GPT-3\nXL model resulting in a 2.5x reduction in pre-training FLOPs, without a\nsignificant loss in accuracy on the downstream tasks relative to the dense\nbaseline. By rigorously evaluating multiple downstream tasks, we also establish\na relationship between sparsity, task complexity and dataset size. Our work\npresents a promising direction to train large GPT models at a fraction of the\ntraining FLOPs using weight sparsity, while retaining the benefits of\npre-trained textual representations for downstream tasks.", "published": "2023-03-18 17:56:01", "link": "http://arxiv.org/abs/2303.10464v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning", "abstract": "Fine-tuning large pre-trained language models on downstream tasks has become\nan important paradigm in NLP. However, common practice fine-tunes all of the\nparameters in a pre-trained model, which becomes prohibitive when a large\nnumber of downstream tasks are present. Therefore, many fine-tuning methods are\nproposed to learn incremental updates of pre-trained weights in a parameter\nefficient way, e.g., low-rank increments. These methods often evenly distribute\nthe budget of incremental updates across all pre-trained weight matrices, and\noverlook the varying importance of different weight parameters. As a\nconsequence, the fine-tuning performance is suboptimal. To bridge this gap, we\npropose AdaLoRA, which adaptively allocates the parameter budget among weight\nmatrices according to their importance score. In particular, AdaLoRA\nparameterizes the incremental updates in the form of singular value\ndecomposition. Such a novel approach allows us to effectively prune the\nsingular values of unimportant updates, which is essentially to reduce their\nparameter budget but circumvent intensive exact SVD computations. We conduct\nextensive experiments with several pre-trained models on natural language\nprocessing, question answering, and natural language generation to validate the\neffectiveness of AdaLoRA. Results demonstrate that AdaLoRA manifests notable\nimprovement over baselines, especially in the low budget settings. Our code is\npublicly available at https://github.com/QingruZhang/AdaLoRA .", "published": "2023-03-18 22:36:25", "link": "http://arxiv.org/abs/2303.10512v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the rise of fear speech in online social media", "abstract": "Recently, social media platforms are heavily moderated to prevent the spread\nof online hate speech, which is usually fertile in toxic words and is directed\ntoward an individual or a community. Owing to such heavy moderation, newer and\nmore subtle techniques are being deployed. One of the most striking among these\nis fear speech. Fear speech, as the name suggests, attempts to incite fear\nabout a target community. Although subtle, it might be highly effective, often\npushing communities toward a physical conflict. Therefore, understanding their\nprevalence in social media is of paramount importance. This article presents a\nlarge-scale study to understand the prevalence of 400K fear speech and over\n700K hate speech posts collected from Gab.com. Remarkably, users posting a\nlarge number of fear speech accrue more followers and occupy more central\npositions in social networks than users posting a large number of hate speech.\nThey can also reach out to benign users more effectively than hate speech users\nthrough replies, reposts, and mentions. This connects to the fact that, unlike\nhate speech, fear speech has almost zero toxic content, making it look\nplausible. Moreover, while fear speech topics mostly portray a community as a\nperpetrator using a (fake) chain of argumentation, hate speech topics hurl\ndirect multitarget insults, thus pointing to why general users could be more\ngullible to fear speech. Our findings transcend even to other platforms\n(Twitter and Facebook) and thus necessitate using sophisticated moderation\npolicies and mass awareness to combat fear speech.", "published": "2023-03-18 02:46:49", "link": "http://arxiv.org/abs/2303.10311v1", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "NoisyHate: Benchmarking Content Moderation Machine Learning Models with\n  Human-Written Perturbations Online", "abstract": "Online texts with toxic content are a threat in social media that might cause\ncyber harassment. Although many platforms applied measures, such as machine\nlearning-based hate-speech detection systems, to diminish their effect, those\ntoxic content publishers can still evade the system by modifying the spelling\nof toxic words. Those modified words are also known as human-written text\nperturbations. Many research works developed certain techniques to generate\nadversarial samples to help the machine learning models obtain the ability to\nrecognize those perturbations. However, there is still a gap between those\nmachine-generated perturbations and human-written perturbations. In this paper,\nwe introduce a benchmark test set containing human-written perturbations online\nfor toxic speech detection models. We also recruited a group of workers to\nevaluate the quality of this test set and dropped low-quality samples.\nMeanwhile, to check if our perturbation can be normalized to its clean version,\nwe applied spell corrector algorithms on this dataset. Finally, we test this\ndata on state-of-the-art language models, such as BERT and RoBERTa, and black\nbox APIs, such as perspective API, to demonstrate the adversarial attack with\nreal human-written perturbations is still effective.", "published": "2023-03-18 14:54:57", "link": "http://arxiv.org/abs/2303.10430v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "A Deep Learning System for Domain-specific Speech Recognition", "abstract": "As human-machine voice interfaces provide easy access to increasingly\nintelligent machines, many state-of-the-art automatic speech recognition (ASR)\nsystems are proposed. However, commercial ASR systems usually have poor\nperformance on domain-specific speech especially under low-resource settings.\nThe author works with pre-trained DeepSpeech2 and Wav2Vec2 acoustic models to\ndevelop benefit-specific ASR systems. The domain-specific data are collected\nusing proposed semi-supervised learning annotation with little human\nintervention. The best performance comes from a fine-tuned Wav2Vec2-Large-LV60\nacoustic model with an external KenLM, which surpasses the Google and AWS ASR\nsystems on benefit-specific speech. The viability of using error prone ASR\ntranscriptions as part of spoken language understanding (SLU) is also\ninvestigated. Results of a benefit-specific natural language understanding\n(NLU) task show that the domain-specific fine-tuned ASR system can outperform\nthe commercial ASR systems even when its transcriptions have higher word error\nrate (WER), and the results between fine-tuned ASR and human transcriptions are\nsimilar.", "published": "2023-03-18 22:19:09", "link": "http://arxiv.org/abs/2303.10510v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Requirement Formalisation using Natural Language Processing and Machine\n  Learning: A Systematic Review", "abstract": "Improvement of software development methodologies attracts developers to\nautomatic Requirement Formalisation (RF) in the Requirement Engineering (RE)\nfield. The potential advantages by applying Natural Language Processing (NLP)\nand Machine Learning (ML) in reducing the ambiguity and incompleteness of\nrequirement written in natural languages is reported in different studies. The\ngoal of this paper is to survey and classify existing work on NLP and ML for\nRF, identifying challenges in this domain and providing promising future\nresearch directions. To achieve this, we conducted a systematic literature\nreview to outline the current state-of-the-art of NLP and ML techniques in RF\nby selecting 257 papers from common used libraries. The search result is\nfiltered by defining inclusion and exclusion criteria and 47 relevant studies\nbetween 2012 and 2022 are selected. We found that heuristic NLP approaches are\nthe most common NLP techniques used for automatic RF, primary operating on\nstructured and semi-structured data. This study also revealed that Deep\nLearning (DL) technique are not widely used, instead classical ML techniques\nare predominant in the surveyed studies. More importantly, we identified the\ndifficulty of comparing the performance of different approaches due to the lack\nof standard benchmark cases for RF.", "published": "2023-03-18 17:36:21", "link": "http://arxiv.org/abs/2303.13365v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Powerful and Extensible WFST Framework for RNN-Transducer Losses", "abstract": "This paper presents a framework based on Weighted Finite-State Transducers\n(WFST) to simplify the development of modifications for RNN-Transducer (RNN-T)\nloss. Existing implementations of RNN-T use CUDA-related code, which is hard to\nextend and debug. WFSTs are easy to construct and extend, and allow debugging\nthrough visualization. We introduce two WFST-powered RNN-T implementations: (1)\n\"Compose-Transducer\", based on a composition of the WFST graphs from acoustic\nand textual schema -- computationally competitive and easy to modify; (2)\n\"Grid-Transducer\", which constructs the lattice directly for further\ncomputations -- most compact, and computationally efficient. We illustrate the\nease of extensibility through introduction of a new W-Transducer loss -- the\nadaptation of the Connectionist Temporal Classification with Wild Cards.\nW-Transducer (W-RNNT) consistently outperforms the standard RNN-T in a\nweakly-supervised data setup with missing parts of transcriptions at the\nbeginning and end of utterances. All RNN-T losses are implemented with the k2\nframework and are available in the NeMo toolkit.", "published": "2023-03-18 10:36:33", "link": "http://arxiv.org/abs/2303.10384v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Zero-shot Sound Event Classification Using a Sound Attribute Vector with\n  Global and Local Feature Learning", "abstract": "This paper introduces a zero-shot sound event classification (ZS-SEC) method\nto identify sound events that have never occurred in training data. In our\nprevious work, we proposed a ZS-SEC method using sound attribute vectors\n(SAVs), where a deep neural network model infers attribute information that\ndescribes the sound of an event class instead of inferring its class label\ndirectly. Our previous method showed that it could classify unseen events to\nsome extent; however, the accuracy for unseen events was far inferior to that\nfor seen events. In this paper, we propose a new ZS-SEC method that can learn\ndiscriminative global features and local features simultaneously to enhance\nSAV-based ZS-SEC. In the proposed method, while the global features are learned\nin order to discriminate the event classes in the training data, the\nspectro-temporal local features are learned in order to regress the attribute\ninformation using attribute prototypes. The experimental results show that our\nproposed method can improve the accuracy of SAV-based ZS-SEC and can visualize\nthe region in the spectrogram related to each attribute.", "published": "2023-03-18 03:21:12", "link": "http://arxiv.org/abs/2303.10316v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Weight-sharing Supernet for Searching Specialized Acoustic Event\n  Classification Networks Across Device Constraints", "abstract": "Acoustic Event Classification (AEC) has been widely used in devices such as\nsmart speakers and mobile phones for home safety or accessibility support. As\nAEC models run on more and more devices with diverse computation resource\nconstraints, it became increasingly expensive to develop models that are tuned\nto achieve optimal accuracy/computation trade-off for each given computation\nresource constraint. In this paper, we introduce a Once-For-All (OFA) Neural\nArchitecture Search (NAS) framework for AEC. Specifically, we first train a\nweight-sharing supernet that supports different model architectures, followed\nby automatically searching for a model given specific computational resource\nconstraints. Our experimental results showed that by just training once, the\nresulting model from NAS significantly outperforms both models trained\nindividually from scratch and knowledge distillation (25.4% and 7.3% relative\nimprovement). We also found that the benefit of weight-sharing supernet\ntraining of ultra-small models comes not only from searching but from\noptimization.", "published": "2023-03-18 07:10:05", "link": "http://arxiv.org/abs/2303.10351v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multimodal Continuous Emotion Recognition: A Technical Report for ABAW5", "abstract": "We used two multimodal models for continuous valence-arousal recognition\nusing visual, audio, and linguistic information. The first model is the same as\nwe used in ABAW2 and ABAW3, which employs the leader-follower attention. The\nsecond model has the same architecture for spatial and temporal encoding. As\nfor the fusion block, it employs a compact and straightforward channel\nattention, borrowed from the End2You toolkit. Unlike our previous attempts that\nuse Vggish feature directly as the audio feature, this time we feed the\npre-trained VGG model using logmel-spectrogram and finetune it during the\ntraining. To make full use of the data and alleviate over-fitting,\ncross-validation is carried out. The code is available at\nhttps://github.com/sucv/ABAW3.", "published": "2023-03-18 04:50:07", "link": "http://arxiv.org/abs/2303.10335v2", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "EarCough: Enabling Continuous Subject Cough Event Detection on Hearables", "abstract": "Cough monitoring can enable new individual pulmonary health applications.\nSubject cough event detection is the foundation for continuous cough\nmonitoring. Recently, the rapid growth in smart hearables has opened new\nopportunities for such needs. This paper proposes EarCough, which enables\ncontinuous subject cough event detection on edge computing hearables by\nleveraging the always-on active noise cancellation (ANC) microphones.\nSpecifically, we proposed a lightweight end-to-end neural network model --\nEarCoughNet. To evaluate the effectiveness of our method, we constructed a\nsynchronous motion and audio dataset through a user study. Results show that\nEarCough achieved an accuracy of 95.4% and an F1-score of 92.9% with a space\nrequirement of only 385 kB. We envision EarCough as a low-cost add-on for\nfuture hearables to enable continuous subject cough event detection.", "published": "2023-03-18 16:03:32", "link": "http://arxiv.org/abs/2303.10445v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Content Adaptive Front End For Audio Classification", "abstract": "We propose a learnable content adaptive front end for audio signal\nprocessing. Before the modern advent of deep learning, we used fixed\nrepresentation non-learnable front-ends like spectrogram or mel-spectrogram\nwith/without neural architectures. With convolutional architectures supporting\nvarious applications such as ASR and acoustic scene understanding, a shift to a\nlearnable front ends occurred in which both the type of basis functions and the\nweight were learned from scratch and optimized for the particular task of\ninterest. With the shift to transformer-based architectures with no\nconvolutional blocks present, a linear layer projects small waveform patches\nonto a small latent dimension before feeding them to a transformer\narchitecture. In this work, we propose a way of computing a content-adaptive\nlearnable time-frequency representation. We pass each audio signal through a\nbank of convolutional filters, each giving a fixed-dimensional vector. It is\nakin to learning a bank of finite impulse-response filterbanks and passing the\ninput signal through the optimum filter bank depending on the content of the\ninput signal. A content-adaptive learnable time-frequency representation may be\nmore broadly applicable, beyond the experiments in this paper.", "published": "2023-03-18 16:09:10", "link": "http://arxiv.org/abs/2303.10446v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
