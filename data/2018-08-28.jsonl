{"title": "Evaluating the Utility of Hand-crafted Features in Sequence Labelling", "abstract": "Conventional wisdom is that hand-crafted features are redundant for deep\nlearning models, as they already learn adequate representations of text\nautomatically from corpora. In this work, we test this claim by proposing a new\nmethod for exploiting handcrafted features as part of a novel hybrid learning\napproach, incorporating a feature auto-encoder loss component. We evaluate on\nthe task of named entity recognition (NER), where we show that including manual\nfeatures for part-of-speech, word shapes and gazetteers can improve the\nperformance of a neural CRF model. We obtain a $F_1$ of 91.89 for the\nCoNLL-2003 English shared task, which significantly outperforms a collection of\nhighly competitive baseline models. We also present an ablation study showing\nthe importance of auto-encoding, over using features as either inputs or\noutputs alone, and moreover, show including the autoencoder components reduces\ntraining requirements to 60\\%, while retaining the same predictive accuracy.", "published": "2018-08-28 00:53:06", "link": "http://arxiv.org/abs/1808.09075v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disfluency Detection using a Noisy Channel Model and a Deep Neural\n  Language Model", "abstract": "This paper presents a model for disfluency detection in spontaneous speech\ntranscripts called LSTM Noisy Channel Model. The model uses a Noisy Channel\nModel (NCM) to generate n-best candidate disfluency analyses and a Long\nShort-Term Memory (LSTM) language model to score the underlying fluent\nsentences of each analysis. The LSTM language model scores, along with other\nfeatures, are used in a MaxEnt reranker to identify the most plausible\nanalysis. We show that using an LSTM language model in the reranking process of\nnoisy channel disfluency model improves the state-of-the-art in disfluency\ndetection.", "published": "2018-08-28 02:23:56", "link": "http://arxiv.org/abs/1808.09091v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disfluency Detection using Auto-Correlational Neural Networks", "abstract": "In recent years, the natural language processing community has moved away\nfrom task-specific feature engineering, i.e., researchers discovering ad-hoc\nfeature representations for various tasks, in favor of general-purpose methods\nthat learn the input representation by themselves. However, state-of-the-art\napproaches to disfluency detection in spontaneous speech transcripts currently\nstill depend on an array of hand-crafted features, and other representations\nderived from the output of pre-existing systems such as language models or\ndependency parsers. As an alternative, this paper proposes a simple yet\neffective model for automatic disfluency detection, called an\nauto-correlational neural network (ACNN). The model uses a convolutional neural\nnetwork (CNN) and augments it with a new auto-correlation operator at the\nlowest layer that can capture the kinds of \"rough copy\" dependencies that are\ncharacteristic of repair disfluencies in speech. In experiments, the ACNN model\noutperforms the baseline CNN on a disfluency detection task with a 5% increase\nin f-score, which is close to the previous best result on this task.", "published": "2018-08-28 02:28:12", "link": "http://arxiv.org/abs/1808.09092v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "N-ary Relation Extraction using Graph State LSTM", "abstract": "Cross-sentence $n$-ary relation extraction detects relations among $n$\nentities across multiple sentences. Typical methods formulate an input as a\n\\textit{document graph}, integrating various intra-sentential and\ninter-sentential dependencies. The current state-of-the-art method splits the\ninput graph into two DAGs, adopting a DAG-structured LSTM for each. Though\nbeing able to model rich linguistic knowledge by leveraging graph edges,\nimportant information can be lost in the splitting procedure. We propose a\ngraph-state LSTM model, which uses a parallel state to model each word,\nrecurrently enriching state values via message passing. Compared with DAG\nLSTMs, our graph LSTM keeps the original graph structure, and speeds up\ncomputation by allowing more parallelization. On a standard benchmark, our\nmodel shows the best result in the literature.", "published": "2018-08-28 03:37:39", "link": "http://arxiv.org/abs/1808.09101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "All You Need is \"Love\": Evading Hate-speech Detection", "abstract": "With the spread of social networks and their unfortunate use for hate speech,\nautomatic detection of the latter has become a pressing problem. In this paper,\nwe reproduce seven state-of-the-art hate speech detection models from prior\nwork, and show that they perform well only when tested on the same type of data\nthey were trained on. Based on these results, we argue that for successful hate\nspeech detection, model architecture is less important than the type of data\nand labeling criteria. We further show that all proposed detection techniques\nare brittle against adversaries who can (automatically) insert typos, change\nword boundaries or add innocuous words to the original hate speech. A\ncombination of these methods is also effective against Google Perspective -- a\ncutting-edge solution from industry. Our experiments demonstrate that\nadversarial training does not completely mitigate the attacks, and using\ncharacter-level features makes the models systematically more attack-resistant\nthan using word-level features.", "published": "2018-08-28 04:49:54", "link": "http://arxiv.org/abs/1808.09115v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive\n  Meaning Representations", "abstract": "By design, word embeddings are unable to model the dynamic nature of words'\nsemantics, i.e., the property of words to correspond to potentially different\nmeanings. To address this limitation, dozens of specialized meaning\nrepresentation techniques such as sense or contextualized embeddings have been\nproposed. However, despite the popularity of research on this topic, very few\nevaluation benchmarks exist that specifically focus on the dynamic semantics of\nwords. In this paper we show that existing models have surpassed the\nperformance ceiling of the standard evaluation dataset for the purpose, i.e.,\nStanford Contextual Word Similarity, and highlight its shortcomings. To address\nthe lack of a suitable benchmark, we put forward a large-scale Word in Context\ndataset, called WiC, based on annotations curated by experts, for generic\nevaluation of context-sensitive representations. WiC is released in\nhttps://pilehvar.github.io/wic/.", "published": "2018-08-28 05:16:35", "link": "http://arxiv.org/abs/1808.09121v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mapping Natural Language Commands to Web Elements", "abstract": "The web provides a rich, open-domain environment with textual, structural,\nand spatial properties. We propose a new task for grounding language in this\nenvironment: given a natural language command (e.g., \"click on the second\narticle\"), choose the correct element on the web page (e.g., a hyperlink or\ntext box). We collected a dataset of over 50,000 commands that capture various\nphenomena such as functional references (e.g. \"find who made this site\"),\nrelational reasoning (e.g. \"article by john\"), and visual reasoning (e.g.\n\"top-most article\"). We also implemented and analyzed three baseline models\nthat capture different phenomena present in the dataset.", "published": "2018-08-28 06:09:39", "link": "http://arxiv.org/abs/1808.09132v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Fast and Accurate Neural Discourse Segmentation", "abstract": "Discourse segmentation, which segments texts into Elementary Discourse Units,\nis a fundamental step in discourse analysis. Previous discourse segmenters rely\non complicated hand-crafted features and are not practical in actual use. In\nthis paper, we propose an end-to-end neural segmenter based on BiLSTM-CRF\nframework. To improve its accuracy, we address the problem of data\ninsufficiency by transferring a word representation model that is trained on a\nlarge corpus. We also propose a restricted self-attention mechanism in order to\ncapture useful information within a neighborhood. Experiments on the RST-DT\ncorpus show that our model is significantly faster than previous methods, while\nachieving new state-of-the-art performance.", "published": "2018-08-28 07:27:45", "link": "http://arxiv.org/abs/1808.09147v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guided Neural Language Generation for Abstractive Summarization using\n  Abstract Meaning Representation", "abstract": "Recent work on abstractive summarization has made progress with neural\nencoder-decoder architectures. However, such models are often challenged due to\ntheir lack of explicit semantic modeling of the source document and its\nsummary. In this paper, we extend previous work on abstractive summarization\nusing Abstract Meaning Representation (AMR) with a neural language generation\nstage which we guide using the source document. We demonstrate that this\nguidance improves summarization results by 7.4 and 10.5 points in ROUGE-2 using\ngold standard AMR parses and parses obtained from an off-the-shelf parser\nrespectively. We also find that the summarization performance using the latter\nis 2 ROUGE-2 points higher than that of a well-established neural\nencoder-decoder approach trained on a larger dataset. Code is available at\n\\url{https://github.com/sheffieldnlp/AMR2Text-summ}", "published": "2018-08-28 08:04:21", "link": "http://arxiv.org/abs/1808.09160v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysing the potential of seq-to-seq models for incremental\n  interpretation in task-oriented dialogue", "abstract": "We investigate how encoder-decoder models trained on a synthetic dataset of\ntask-oriented dialogues process disfluencies, such as hesitations and\nself-corrections. We find that, contrary to earlier results, disfluencies have\nvery little impact on the task success of seq-to-seq models with attention.\nUsing visualisation and diagnostic classifiers, we analyse the representations\nthat are incrementally built by the model, and discover that models develop\nlittle to no awareness of the structure of disfluencies. However, adding\ndisfluencies to the data appears to help the model create clearer\nrepresentations overall, as evidenced by the attention patterns the different\nmodels exhibit.", "published": "2018-08-28 09:00:37", "link": "http://arxiv.org/abs/1808.09178v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What do character-level models learn about morphology? The case of\n  dependency parsing", "abstract": "When parsing morphologically-rich languages with neural models, it is\nbeneficial to model input at the character level, and it has been claimed that\nthis is because character-level models learn morphology. We test these claims\nby comparing character-level models to an oracle with access to explicit\nmorphological analysis on twelve languages with varying morphological\ntypologies. Our results highlight many strengths of character-level models, but\nalso show that they are poor at disambiguating some words, particularly in the\nface of case syncretism. We then demonstrate that explicitly modeling\nmorphological case improves our best model, showing that character-level models\ncan benefit from targeted forms of explicit morphological modeling.", "published": "2018-08-28 09:02:48", "link": "http://arxiv.org/abs/1808.09180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why Do Neural Response Generation Models Prefer Universal Replies?", "abstract": "Recent advances in sequence-to-sequence learning reveal a purely data-driven\napproach to the response generation task. Despite its diverse applications,\nexisting neural models are prone to producing short and generic replies, making\nit infeasible to tackle open-domain challenges. In this research, we analyze\nthis critical issue in light of the model's optimization goal and the specific\ncharacteristics of the human-to-human dialog corpus. By decomposing the black\nbox into parts, a detailed analysis of the probability limit was conducted to\nreveal the reason behind these universal replies. Based on these analyses, we\npropose a max-margin ranking regularization term to avoid the models leaning to\nthese replies. Finally, empirical experiments on case studies and benchmarks\nwith several metrics validate this approach.", "published": "2018-08-28 09:11:49", "link": "http://arxiv.org/abs/1808.09187v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Aspect and Polarity Classification for Aspect-based Sentiment\n  Analysis with End-to-End Neural Networks", "abstract": "In this work, we propose a new model for aspect-based sentiment analysis. In\ncontrast to previous approaches, we jointly model the detection of aspects and\nthe classification of their polarity in an end-to-end trainable neural network.\nWe conduct experiments with different neural architectures and word\nrepresentations on the recent GermEval 2017 dataset. We were able to show\nconsiderable performance gains by using the joint modeling approach in all\nsettings compared to pipeline approaches. The combination of a convolutional\nneural network and fasttext embeddings outperformed the best submission of the\nshared task in 2017, establishing a new state of the art.", "published": "2018-08-28 11:53:05", "link": "http://arxiv.org/abs/1808.09238v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Card-660: Cambridge Rare Word Dataset - a Reliable Benchmark for\n  Infrequent Word Representation Models", "abstract": "Rare word representation has recently enjoyed a surge of interest, owing to\nthe crucial role that effective handling of infrequent words can play in\naccurate semantic understanding. However, there is a paucity of reliable\nbenchmarks for evaluation and comparison of these techniques. We show in this\npaper that the only existing benchmark (the Stanford Rare Word dataset) suffers\nfrom low-confidence annotations and limited vocabulary; hence, it does not\nconstitute a solid comparison framework. In order to fill this evaluation gap,\nwe propose CAmbridge Rare word Dataset (Card-660), an expert-annotated word\nsimilarity dataset which provides a highly reliable, yet challenging, benchmark\nfor rare word representation techniques. Through a set of experiments we show\nthat even the best mainstream word embeddings, with millions of words in their\nvocabularies, are unable to achieve performances higher than 0.43 (Pearson\ncorrelation) on the dataset, compared to a human-level upperbound of 0.90. We\nrelease the dataset and the annotation materials at\nhttps://pilehvar.github.io/card-660/.", "published": "2018-08-28 14:01:07", "link": "http://arxiv.org/abs/1808.09308v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Convolutional Neural Networks with Recurrent Neural Filters", "abstract": "We introduce a class of convolutional neural networks (CNNs) that utilize\nrecurrent neural networks (RNNs) as convolution filters. A convolution filter\nis typically implemented as a linear affine transformation followed by a\nnon-linear function, which fails to account for language compositionality. As a\nresult, it limits the use of high-order filters that are often warranted for\nnatural language processing tasks. In this work, we model convolution filters\nwith RNNs that naturally capture compositionality and long-term dependencies in\nlanguage. We show that simple CNN architectures equipped with recurrent neural\nfilters (RNFs) achieve results that are on par with the best published ones on\nthe Stanford Sentiment Treebank and two answer sentence selection datasets.", "published": "2018-08-28 14:13:26", "link": "http://arxiv.org/abs/1808.09315v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Theory of Mind in Question Answering", "abstract": "We propose a new dataset for evaluating question answering models with\nrespect to their capacity to reason about beliefs. Our tasks are inspired by\ntheory-of-mind experiments that examine whether children are able to reason\nabout the beliefs of others, in particular when those beliefs differ from\nreality. We evaluate a number of recent neural models with memory augmentation.\nWe find that all fail on our tasks, which require keeping track of inconsistent\nstates of the world; moreover, the models' accuracy decreases notably when\nrandom sentences are introduced to the tasks at test.", "published": "2018-08-28 15:16:17", "link": "http://arxiv.org/abs/1808.09352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Universal Dependency Parsing with a General Transition-Based DAG Parser", "abstract": "This paper presents our experiments with applying TUPA to the CoNLL 2018 UD\nshared task. TUPA is a general neural transition-based DAG parser, which we use\nto present the first experiments on recovering enhanced dependencies as part of\nthe general parsing task. TUPA was designed for parsing UCCA, a\ncross-linguistic semantic annotation scheme, exhibiting reentrancy,\ndiscontinuity and non-terminal nodes. By converting UD trees and graphs to a\nUCCA-like DAG format, we train TUPA almost without modification on the UD\nparsing task. The generic nature of our approach lends itself naturally to\nmultitask learning. Our code is available at\nhttps://github.com/CoNLL-UD-2018/HUJI", "published": "2018-08-28 15:19:33", "link": "http://arxiv.org/abs/1808.09354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rational Recurrences", "abstract": "Despite the tremendous empirical success of neural models in natural language\nprocessing, many of them lack the strong intuitions that accompany classical\nmachine learning approaches. Recently, connections have been shown between\nconvolutional neural networks (CNNs) and weighted finite state automata\n(WFSAs), leading to new interpretations and insights. In this work, we show\nthat some recurrent neural networks also share this connection to WFSAs. We\ncharacterize this connection formally, defining rational recurrences to be\nrecurrent hidden state update functions that can be written as the Forward\ncalculation of a finite set of WFSAs. We show that several recent neural models\nuse rational recurrences. Our analysis provides a fresh view of these models\nand facilitates devising new neural architectures that draw inspiration from\nWFSAs. We present one such model, which performs better than two recent\nbaselines on language modeling and text classification. Our results demonstrate\nthat transferring intuitions from classical models like WFSAs can be an\neffective approach to designing and understanding neural models.", "published": "2018-08-28 15:28:25", "link": "http://arxiv.org/abs/1808.09357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deriving Machine Attention from Human Rationales", "abstract": "Attention-based models are successful when trained on large amounts of data.\nIn this paper, we demonstrate that even in the low-resource scenario, attention\ncan be learned effectively. To this end, we start with discrete human-annotated\nrationales and map them into continuous attention. Our central hypothesis is\nthat this mapping is general across domains, and thus can be transferred from\nresource-rich domains to low-resource ones. Our model jointly learns a\ndomain-invariant representation and induces the desired mapping between\nrationales and attention. Our empirical results validate this hypothesis and\nshow that our approach delivers significant gains over state-of-the-art\nbaselines, yielding over 15% average error reduction on benchmark datasets.", "published": "2018-08-28 15:38:41", "link": "http://arxiv.org/abs/1808.09367v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Tree-based Decoder for Neural Machine Translation", "abstract": "Recent advances in Neural Machine Translation (NMT) show that adding\nsyntactic information to NMT systems can improve the quality of their\ntranslations. Most existing work utilizes some specific types of\nlinguistically-inspired tree structures, like constituency and dependency parse\ntrees. This is often done via a standard RNN decoder that operates on a\nlinearized target tree structure. However, it is an open question of what\nspecific linguistic formalism, if any, is the best structural representation\nfor NMT. In this paper, we (1) propose an NMT model that can naturally generate\nthe topology of an arbitrary tree structure on the target side, and (2)\nexperiment with various target tree structures. Our experiments show the\nsurprising result that our model delivers the best improvements with balanced\nbinary trees constructed without any linguistic knowledge; this model\noutperforms standard seq2seq models by up to 2.1 BLEU points, and other methods\nfor incorporating target-side syntax by up to 0.7 BLEU.", "published": "2018-08-28 15:52:19", "link": "http://arxiv.org/abs/1808.09374v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Back-Translation at Scale", "abstract": "An effective method to improve neural machine translation with monolingual\ndata is to augment the parallel training corpus with back-translations of\ntarget language sentences. This work broadens the understanding of\nback-translation and investigates a number of methods to generate synthetic\nsource sentences. We find that in all but resource poor settings\nback-translations obtained via sampling or noised beam outputs are most\neffective. Our analysis shows that sampling or noisy synthetic data gives a\nmuch stronger training signal than data generated by beam or greedy search. We\nalso compare how synthetic data compares to genuine bitext and study various\ndomain effects. Finally, we scale to hundreds of millions of monolingual\nsentences and achieve a new state of the art of 35 BLEU on the WMT'14\nEnglish-German test set.", "published": "2018-08-28 16:05:40", "link": "http://arxiv.org/abs/1808.09381v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Framing and Agenda-setting in Russian News: a Computational Analysis of\n  Intricate Political Strategies", "abstract": "Amidst growing concern over media manipulation, NLP attention has focused on\novert strategies like censorship and \"fake news'\". Here, we draw on two\nconcepts from the political science literature to explore subtler strategies\nfor government media manipulation: agenda-setting (selecting what topics to\ncover) and framing (deciding how topics are covered). We analyze 13 years (100K\narticles) of the Russian newspaper Izvestia and identify a strategy of\ndistraction: articles mention the U.S. more frequently in the month directly\nfollowing an economic downturn in Russia. We introduce embedding-based methods\nfor cross-lingually projecting English frames to Russian, and discover that\nthese articles emphasize U.S. moral failings and threats to the U.S. Our work\noffers new ways to identify subtle media manipulation strategies at the\nintersection of agenda-setting and framing.", "published": "2018-08-28 16:20:20", "link": "http://arxiv.org/abs/1808.09386v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Temporal Information Extraction by Predicting Relative Time-lines", "abstract": "The current leading paradigm for temporal information extraction from text\nconsists of three phases: (1) recognition of events and temporal expressions,\n(2) recognition of temporal relations among them, and (3) time-line\nconstruction from the temporal relations. In contrast to the first two phases,\nthe last phase, time-line construction, received little attention and is the\nfocus of this work. In this paper, we propose a new method to construct a\nlinear time-line from a set of (extracted) temporal relations. But more\nimportantly, we propose a novel paradigm in which we directly predict start and\nend-points for events from the text, constituting a time-line without going\nthrough the intermediate step of prediction of temporal relations as in earlier\nwork. Within this paradigm, we propose two models that predict in linear\ncomplexity, and a new training loss using TimeML-style annotations, yielding\npromising results.", "published": "2018-08-28 16:46:30", "link": "http://arxiv.org/abs/1808.09401v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Privacy-preserving Neural Representations of Text", "abstract": "This article deals with adversarial attacks towards deep learning systems for\nNatural Language Processing (NLP), in the context of privacy protection. We\nstudy a specific type of attack: an attacker eavesdrops on the hidden\nrepresentations of a neural text classifier and tries to recover information\nabout the input text. Such scenario may arise in situations when the\ncomputation of a neural network is shared across multiple devices, e.g. some\nhidden representation is computed by a user's device and sent to a cloud-based\nmodel. We measure the privacy of a hidden representation by the ability of an\nattacker to predict accurately specific private information from it and\ncharacterize the tradeoff between the privacy and the utility of neural\nrepresentations. Finally, we propose several defense methods based on modified\ntraining objectives and show that they improve the privacy of neural\nrepresentations.", "published": "2018-08-28 16:57:37", "link": "http://arxiv.org/abs/1808.09408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Role Labeling for Learner Chinese: the Importance of Syntactic\n  Parsing and L2-L1 Parallel Data", "abstract": "This paper studies semantic parsing for interlanguage (L2), taking semantic\nrole labeling (SRL) as a case task and learner Chinese as a case language. We\nfirst manually annotate the semantic roles for a set of learner texts to derive\na gold standard for automatic SRL. Based on the new data, we then evaluate\nthree off-the-shelf SRL systems, i.e., the PCFGLA-parser-based,\nneural-parser-based and neural-syntax-agnostic systems, to gauge how successful\nSRL for learner Chinese can be. We find two non-obvious facts: 1) the\nL1-sentence-trained systems performs rather badly on the L2 data; 2) the\nperformance drop from the L1 data to the L2 data of the two parser-based\nsystems is much smaller, indicating the importance of syntactic parsing in SRL\nfor interlanguages. Finally, the paper introduces a new agreement-based model\nto explore the semantic coherency information in the large-scale L2-L1 parallel\ndata. We then show such information is very effective to enhance SRL for\nlearner texts. Our model achieves an F-score of 72.06, which is a 2.02 point\nimprovement over the best baseline.", "published": "2018-08-28 16:57:47", "link": "http://arxiv.org/abs/1808.09409v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Well-formed Natural Language Questions", "abstract": "Understanding search queries is a hard problem as it involves dealing with\n\"word salad\" text ubiquitously issued by users. However, if a query resembles a\nwell-formed question, a natural language processing pipeline is able to perform\nmore accurate interpretation, thus reducing downstream compounding errors.\nHence, identifying whether or not a query is well formed can enhance query\nunderstanding. Here, we introduce a new task of identifying a well-formed\nnatural language question. We construct and release a dataset of 25,100\npublicly available questions classified into well-formed and non-wellformed\ncategories and report an accuracy of 70.7% on the test set. We also show that\nour classifier can be used to improve the performance of neural\nsequence-to-sequence models for generating questions for reading comprehension.", "published": "2018-08-28 17:20:51", "link": "http://arxiv.org/abs/1808.09419v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling\n  Language and Discourse", "abstract": "We release a corpus of 43 million atomic edits across 8 languages. These\nedits are mined from Wikipedia edit history and consist of instances in which a\nhuman editor has inserted a single contiguous phrase into, or deleted a single\ncontiguous phrase from, an existing sentence. We use the collected data to show\nthat the language generated during editing differs from the language that we\nobserve in standard corpora, and that models trained on edits encode different\naspects of semantics and discourse than models trained on raw, unstructured\ntext. We release the full corpus as a resource to aid ongoing research in\nsemantics, discourse, and representation learning.", "published": "2018-08-28 17:25:27", "link": "http://arxiv.org/abs/1808.09422v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graphene: A Context-Preserving Open Information Extraction System", "abstract": "We introduce Graphene, an Open IE system whose goal is to generate accurate,\nmeaningful and complete propositions that may facilitate a variety of\ndownstream semantic applications. For this purpose, we transform syntactically\ncomplex input sentences into clean, compact structures in the form of core\nfacts and accompanying contexts, while identifying the rhetorical relations\nthat hold between them in order to maintain their semantic relationship. In\nthat way, we preserve the context of the relational tuples extracted from a\nsource sentence, generating a novel lightweight semantic representation for\nOpen IE that enhances the expressiveness of the extracted propositions.", "published": "2018-08-28 18:00:44", "link": "http://arxiv.org/abs/1808.09463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The University of Cambridge's Machine Translation Systems for WMT18", "abstract": "The University of Cambridge submission to the WMT18 news translation task\nfocuses on the combination of diverse models of translation. We compare\nrecurrent, convolutional, and self-attention-based neural models on\nGerman-English, English-German, and Chinese-English. Our final system combines\nall neural models together with a phrase-based SMT system in an MBR-based\nscheme. We report small but consistent gains on top of strong Transformer\nensembles.", "published": "2018-08-28 18:02:31", "link": "http://arxiv.org/abs/1808.09465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning To Split and Rephrase From Wikipedia Edit History", "abstract": "Split and rephrase is the task of breaking down a sentence into shorter ones\nthat together convey the same meaning. We extract a rich new dataset for this\ntask by mining Wikipedia's edit history: WikiSplit contains one million\nnaturally occurring sentence rewrites, providing sixty times more distinct\nsplit examples and a ninety times larger vocabulary than the WebSplit corpus\nintroduced by Narayan et al. (2017) as a benchmark for this task. Incorporating\nWikiSplit as training data produces a model with qualitatively better\npredictions that score 32 BLEU points above the prior best result on the\nWebSplit benchmark.", "published": "2018-08-28 18:03:32", "link": "http://arxiv.org/abs/1808.09468v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Residualized Factor Adaptation for Community Social Media Prediction\n  Tasks", "abstract": "Predictive models over social media language have shown promise in capturing\ncommunity outcomes, but approaches thus far largely neglect the\nsocio-demographic context (e.g. age, education rates, race) of the community\nfrom which the language originates. For example, it may be inaccurate to assume\npeople in Mobile, Alabama, where the population is relatively older, will use\nwords the same way as those from San Francisco, where the median age is younger\nwith a higher rate of college education. In this paper, we present residualized\nfactor adaptation, a novel approach to community prediction tasks which both\n(a) effectively integrates community attributes, as well as (b) adapts\nlinguistic features to community attributes (factors). We use eleven\ndemographic and socioeconomic attributes, and evaluate our approach over five\ndifferent community-level predictive tasks, spanning health (heart disease\nmortality, percent fair/poor health), psychology (life satisfaction), and\neconomics (percent housing price increase, foreclosure rate). Our evaluation\nshows that residualized factor adaptation significantly improves 4 out of 5\ncommunity-level outcome predictions over prior state-of-the-art for\nincorporating socio-demographic contexts.", "published": "2018-08-28 18:23:56", "link": "http://arxiv.org/abs/1808.09479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Attend On Essential Terms: An Enhanced Retriever-Reader\n  Model for Open-domain Question Answering", "abstract": "Open-domain question answering remains a challenging task as it requires\nmodels that are capable of understanding questions and answers, collecting\nuseful information, and reasoning over evidence. Previous work typically\nformulates this task as a reading comprehension or entailment problem given\nevidence retrieved from search engines. However, existing techniques struggle\nto retrieve indirectly related evidence when no directly related evidence is\nprovided, especially for complex questions where it is hard to parse precisely\nwhat the question asks. In this paper we propose a retriever-reader model that\nlearns to attend on essential terms during the question answering process. We\nbuild (1) an essential term selector which first identifies the most important\nwords in a question, then reformulates the query and searches for related\nevidence; and (2) an enhanced reader that distinguishes between essential terms\nand distracting words to predict the answer. We evaluate our model on multiple\nopen-domain multiple-choice QA datasets, notably performing at the level of the\nstate-of-the-art on the AI2 Reasoning Challenge (ARC) dataset.", "published": "2018-08-28 18:48:30", "link": "http://arxiv.org/abs/1808.09492v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adapting Word Embeddings to New Languages with Morphological and\n  Phonological Subword Representations", "abstract": "Much work in Natural Language Processing (NLP) has been for resource-rich\nlanguages, making generalization to new, less-resourced languages challenging.\nWe present two approaches for improving generalization to low-resourced\nlanguages by adapting continuous word representations using linguistically\nmotivated subword units: phonemes, morphemes and graphemes. Our method requires\nneither parallel corpora nor bilingual dictionaries and provides a significant\ngain in performance over previous methods relying on these resources. We\ndemonstrate the effectiveness of our approaches on Named Entity Recognition for\nfour languages, namely Uyghur, Turkish, Bengali and Hindi, of which Uyghur and\nBengali are low resource languages, and also perform experiments on Machine\nTranslation. Exploiting subwords with transfer learning gives us a boost of\n+15.2 NER F1 for Uyghur and +9.7 F1 for Bengali. We also show improvements in\nthe monolingual setting where we achieve (avg.) +3 F1 and (avg.) +1.35 BLEU.", "published": "2018-08-28 19:11:20", "link": "http://arxiv.org/abs/1808.09500v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Matching Against a Corpus: New Applications and Methods", "abstract": "We consider the case of a domain expert who wishes to explore the extent to\nwhich a particular idea is expressed in a text collection. We propose the task\nof semantically matching the idea, expressed as a natural language proposition,\nagainst a corpus. We create two preliminary tasks derived from existing\ndatasets, and then introduce a more realistic one on disaster recovery designed\nfor emergency managers, whom we engaged in a user study. On the latter, we find\nthat a new model built from natural language entailment data produces\nhigher-quality matches than simple word-vector averaging, both on\nexpert-crafted queries and on ones produced by the subjects themselves. This\nwork provides a proof-of-concept for such applications of semantic matching and\nillustrates key challenges.", "published": "2018-08-28 19:15:57", "link": "http://arxiv.org/abs/1808.09502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Layer Trajectory LSTM", "abstract": "It is popular to stack LSTM layers to get better modeling power, especially\nwhen large amount of training data is available. However, an LSTM-RNN with too\nmany vanilla LSTM layers is very hard to train and there still exists the\ngradient vanishing issue if the network goes too deep. This issue can be\npartially solved by adding skip connections between layers, such as residual\nLSTM. In this paper, we propose a layer trajectory LSTM (ltLSTM) which builds a\nlayer-LSTM using all the layer outputs from a standard multi-layer time-LSTM.\nThis layer-LSTM scans the outputs from time-LSTMs, and uses the summarized\nlayer trajectory information for final senone classification. The\nforward-propagation of time-LSTM and layer-LSTM can be handled in two separate\nthreads in parallel so that the network computation time is the same as the\nstandard time-LSTM. With a layer-LSTM running through layers, a gated path is\nprovided from the output layer to the bottom layer, alleviating the gradient\nvanishing issue. Trained with 30 thousand hours of EN-US Microsoft internal\ndata, the proposed ltLSTM performed significantly better than the standard\nmulti-layer LSTM and residual LSTM, with up to 9.0% relative word error rate\nreduction across different tasks.", "published": "2018-08-28 20:13:18", "link": "http://arxiv.org/abs/1808.09522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Quantized Representations for Script Generation", "abstract": "Scripts define knowledge about how everyday scenarios (such as going to a\nrestaurant) are expected to unfold. One of the challenges to learning scripts\nis the hierarchical nature of the knowledge. For example, a suspect arrested\nmight plead innocent or guilty, and a very different track of events is then\nexpected to happen. To capture this type of information, we propose an\nautoencoder model with a latent space defined by a hierarchy of categorical\nvariables. We utilize a recently proposed vector quantization based approach,\nwhich allows continuous embeddings to be associated with each latent variable\nvalue. This permits the decoder to softly decide what portions of the latent\nhierarchy to condition on by attending over the value embeddings for a given\nsetting. Our model effectively encodes and generates scripts, outperforming a\nrecent language modeling-based method on several standard tasks, and allowing\nthe autoencoder model to achieve substantially lower perplexity scores compared\nto the previous language modeling-based method.", "published": "2018-08-28 20:53:56", "link": "http://arxiv.org/abs/1808.09542v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Semi-Supervised Learning for Deep Semantic Role Labeling", "abstract": "Neural models have shown several state-of-the-art performances on Semantic\nRole Labeling (SRL). However, the neural models require an immense amount of\nsemantic-role corpora and are thus not well suited for low-resource languages\nor domains. The paper proposes a semi-supervised semantic role labeling method\nthat outperforms the state-of-the-art in limited SRL training corpora. The\nmethod is based on explicitly enforcing syntactic constraints by augmenting the\ntraining objective with a syntactic-inconsistency loss component and uses\nSRL-unlabeled instances to train a joint-objective LSTM. On CoNLL-2012 English\nsection, the proposed semi-supervised training with 1%, 10% SRL-labeled data\nand varying amounts of SRL-unlabeled data achieves +1.58, +0.78 F1,\nrespectively, over the pre-trained models that were trained on SOTA\narchitecture with ELMo on the same SRL-labeled data. Additionally, by using the\nsyntactic-inconsistency loss on inference time, the proposed model achieves\n+3.67, +2.1 F1 over pre-trained model on 1%, 10% SRL-labeled data,\nrespectively.", "published": "2018-08-28 20:55:41", "link": "http://arxiv.org/abs/1808.09543v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Reference Training with Pseudo-References for Neural Translation\n  and Text Generation", "abstract": "Neural text generation, including neural machine translation, image\ncaptioning, and summarization, has been quite successful recently. However,\nduring training time, typically only one reference is considered for each\nexample, even though there are often multiple references available, e.g., 4\nreferences in NIST MT evaluations, and 5 references in image captioning data.\nWe first investigate several different ways of utilizing multiple human\nreferences during training. But more importantly, we then propose an algorithm\nto generate exponentially many pseudo-references by first compressing existing\nhuman references into lattices and then traversing them to generate new\npseudo-references. These approaches lead to substantial improvements over\nstrong baselines in both machine translation (+1.5 BLEU) and image captioning\n(+3.1 BLEU / +11.7 CIDEr).", "published": "2018-08-28 22:30:11", "link": "http://arxiv.org/abs/1808.09564v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and\n  Stopping Criteria for Neural Machine Translation", "abstract": "Beam search is widely used in neural machine translation, and usually\nimproves translation quality compared to greedy search. It has been widely\nobserved that, however, beam sizes larger than 5 hurt translation quality. We\nexplain why this happens, and propose several methods to address this problem.\nFurthermore, we discuss the optimal stopping criteria for these methods.\nResults show that our hyperparameter-free methods outperform the widely-used\nhyperparameter-free heuristic of length normalization by +2.0 BLEU, and achieve\nthe best results among all methods on Chinese-to-English translation.", "published": "2018-08-28 23:50:22", "link": "http://arxiv.org/abs/1808.09582v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Quantum Many-body Wave Function Inspired Language Modeling Approach", "abstract": "The recently proposed quantum language model (QLM) aimed at a principled\napproach to modeling term dependency by applying the quantum probability\ntheory. The latest development for a more effective QLM has adopted word\nembeddings as a kind of global dependency information and integrated the\nquantum-inspired idea in a neural network architecture. While these\nquantum-inspired LMs are theoretically more general and also practically\neffective, they have two major limitations. First, they have not taken into\naccount the interaction among words with multiple meanings, which is common and\nimportant in understanding natural language text. Second, the integration of\nthe quantum-inspired LM with the neural network was mainly for effective\ntraining of parameters, yet lacking a theoretical foundation accounting for\nsuch integration. To address these two issues, in this paper, we propose a\nQuantum Many-body Wave Function (QMWF) inspired language modeling approach. The\nQMWF inspired LM can adopt the tensor product to model the aforesaid\ninteraction among words. It also enables us to reveal the inherent necessity of\nusing Convolutional Neural Network (CNN) in QMWF language modeling.\nFurthermore, our approach delivers a simple algorithm to represent and match\ntext/sentence pairs. Systematic evaluation shows the effectiveness of the\nproposed QMWF-LM algorithm, in comparison with the state of the art\nquantum-inspired LMs and a couple of CNN-based methods, on three typical\nQuestion Answering (QA) datasets.", "published": "2018-08-28 13:39:44", "link": "http://arxiv.org/abs/1808.09891v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Learning of Syntactic Structure with Invertible Neural\n  Projections", "abstract": "Unsupervised learning of syntactic structure is typically performed using\ngenerative models with discrete latent variables and multinomial parameters. In\nmost cases, these models have not leveraged continuous word representations. In\nthis work, we propose a novel generative model that jointly learns discrete\nsyntactic structure and continuous word representations in an unsupervised\nfashion by cascading an invertible neural network with a structured generative\nprior. We show that the invertibility condition allows for efficient exact\ninference and marginal likelihood computation in our model so long as the prior\nis well-behaved. In experiments we instantiate our approach with both Markov\nand tree-structured priors, evaluating on two tasks: part-of-speech (POS)\ninduction, and unsupervised dependency parsing without gold POS annotation. On\nthe Penn Treebank, our Markov-structured model surpasses state-of-the-art\nresults on POS induction. Similarly, we find that our tree-structured model\nachieves state-of-the-art performance on unsupervised dependency parsing for\nthe difficult training condition where neither gold POS annotation nor\npunctuation-based constraints are available.", "published": "2018-08-28 04:33:25", "link": "http://arxiv.org/abs/1808.09111v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bridging Knowledge Gaps in Neural Entailment via Symbolic Models", "abstract": "Most textual entailment models focus on lexical gaps between the premise text\nand the hypothesis, but rarely on knowledge gaps. We focus on filling these\nknowledge gaps in the Science Entailment task, by leveraging an external\nstructured knowledge base (KB) of science facts. Our new architecture combines\nstandard neural entailment models with a knowledge lookup module. To facilitate\nthis lookup, we propose a fact-level decomposition of the hypothesis, and\nverifying the resulting sub-facts against both the textual premise and the\nstructured KB. Our model, NSnet, learns to aggregate predictions from these\nheterogeneous data formats. On the SciTail dataset, NSnet outperforms a simpler\ncombination of the two predictions by 3% and the base entailment model by 5%.", "published": "2018-08-28 14:45:47", "link": "http://arxiv.org/abs/1808.09333v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Xu: An Automated Query Expansion and Optimization Tool", "abstract": "The exponential growth of information on the Internet is a big challenge for\ninformation retrieval systems towards generating relevant results. Novel\napproaches are required to reformat or expand user queries to generate a\nsatisfactory response and increase recall and precision. Query expansion (QE)\nis a technique to broaden users' queries by introducing additional tokens or\nphrases based on some semantic similarity metrics. The tradeoff is the added\ncomputational complexity to find semantically similar words and a possible\nincrease in noise in information retrieval. Despite several research efforts on\nthis topic, QE has not yet been explored enough and more work is needed on\nsimilarity matching and composition of query terms with an objective to\nretrieve a small set of most appropriate responses. QE should be scalable,\nfast, and robust in handling complex queries with a good response time and\nnoise ceiling. In this paper, we propose Xu, an automated QE technique, using\nhigh dimensional clustering of word vectors and Datamuse API, an open source\nquery engine to find semantically similar words. We implemented Xu as a command\nline tool and evaluated its performances using datasets containing news\narticles and human-generated QEs. The evaluation results show that Xu was\nbetter than Datamuse by achieving about 88% accuracy with reference to the\nhuman-generated QE.", "published": "2018-08-28 15:18:14", "link": "http://arxiv.org/abs/1808.09353v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "What Makes Reading Comprehension Questions Easier?", "abstract": "A challenge in creating a dataset for machine reading comprehension (MRC) is\nto collect questions that require a sophisticated understanding of language to\nanswer beyond using superficial cues. In this work, we investigate what makes\nquestions easier across recent 12 MRC datasets with three question styles\n(answer extraction, description, and multiple choice). We propose to employ\nsimple heuristics to split each dataset into easy and hard subsets and examine\nthe performance of two baseline models for each of the subsets. We then\nmanually annotate questions sampled from each subset with both validity and\nrequisite reasoning skills to investigate which skills explain the difference\nbetween easy and hard questions. From this study, we observed that (i) the\nbaseline performances for the hard subsets remarkably degrade compared to those\nof entire datasets, (ii) hard questions require knowledge inference and\nmultiple-sentence reasoning in comparison with easy questions, and (iii)\nmultiple-choice questions tend to require a broader range of reasoning skills\nthan answer extraction and description questions. These results suggest that\none might overestimate recent advances in MRC.", "published": "2018-08-28 16:17:43", "link": "http://arxiv.org/abs/1808.09384v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KDSL: a Knowledge-Driven Supervised Learning Framework for Word Sense\n  Disambiguation", "abstract": "We propose KDSL, a new word sense disambiguation (WSD) framework that\nutilizes knowledge to automatically generate sense-labeled data for supervised\nlearning. First, from WordNet, we automatically construct a semantic knowledge\nbase called DisDict, which provides refined feature words that highlight the\ndifferences among word senses, i.e., synsets. Second, we automatically generate\nnew sense-labeled data by DisDict from unlabeled corpora. Third, these\ngenerated data, together with manually labeled data and unlabeled data, are fed\nto a neural framework conducting supervised and unsupervised learning jointly\nto model the semantic relations among synsets, feature words and their\ncontexts. The experimental results show that KDSL outperforms several\nrepresentative state-of-the-art methods on various major benchmarks.\nInterestingly, it performs relatively well even when manually labeled data is\nunavailable, thus provides a potential solution for similar tasks in a lack of\nmanual annotations.", "published": "2018-08-28 12:20:37", "link": "http://arxiv.org/abs/1808.09888v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interpretation of Natural Language Rules in Conversational Machine\n  Reading", "abstract": "Most work in machine reading focuses on question answering problems where the\nanswer is directly expressed in the text to read. However, many real-world\nquestion answering problems require the reading of text not because it contains\nthe literal answer, but because it contains a recipe to derive an answer\ntogether with the reader's background knowledge. One example is the task of\ninterpreting regulations to answer \"Can I...?\" or \"Do I have to...?\" questions\nsuch as \"I am working in Canada. Do I have to carry on paying UK National\nInsurance?\" after reading a UK government website about this topic. This task\nrequires both the interpretation of rules and the application of background\nknowledge. It is further complicated due to the fact that, in practice, most\nquestions are underspecified, and a human assistant will regularly have to ask\nclarification questions such as \"How long have you been working abroad?\" when\nthe answer cannot be directly derived from the question and text. In this\npaper, we formalise this task and develop a crowd-sourcing strategy to collect\n32k task instances based on real-world rules and crowd-generated questions and\nscenarios. We analyse the challenges of this task and assess its difficulty by\nevaluating the performance of rule-based and machine-learning baselines. We\nobserve promising results when no background knowledge is necessary, and\nsubstantial room for improvement whenever background knowledge is needed.", "published": "2018-08-28 19:44:51", "link": "http://arxiv.org/abs/1809.01494v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Discriminative Latent-Variable Model for Bilingual Lexicon Induction", "abstract": "We introduce a novel discriminative latent variable model for bilingual\nlexicon induction. Our model combines the bipartite matching dictionary prior\nof Haghighi et al. (2008) with a representation-based approach (Artetxe et al.,\n2017). To train the model, we derive an efficient Viterbi EM algorithm. We\nprovide empirical results on six language pairs under two metrics and show that\nthe prior improves the induced bilingual lexicons. We also demonstrate how\nprevious work may be viewed as a similarly fashioned latent-variable model,\nalbeit with a different prior.", "published": "2018-08-28 14:47:33", "link": "http://arxiv.org/abs/1808.09334v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning", "abstract": "This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving\nthe effectiveness and robustness of Deep Dyna-Q (DDQ), a recently proposed\nframework that extends the Dyna-Q algorithm to integrate planning for\ntask-completion dialogue policy learning. To obviate DDQ's high dependency on\nthe quality of simulated experiences, we incorporate an RNN-based discriminator\nin D3Q to differentiate simulated experience from real user experience in order\nto control the quality of training data. Experiments show that D3Q\nsignificantly outperforms DDQ by controlling the quality of simulated\nexperience used for planning. The effectiveness and robustness of D3Q is\nfurther demonstrated in a domain extension setting, where the agent's\ncapability of adapting to a changing environment is tested.", "published": "2018-08-28 17:59:08", "link": "http://arxiv.org/abs/1808.09442v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Explaining Character-Aware Neural Networks for Word-Level Prediction: Do\n  They Discover Linguistic Rules?", "abstract": "Character-level features are currently used in different neural network-based\nnatural language processing algorithms. However, little is known about the\ncharacter-level patterns those models learn. Moreover, models are often\ncompared only quantitatively while a qualitative analysis is missing. In this\npaper, we investigate which character-level patterns neural networks learn and\nif those patterns coincide with manually-defined word segmentations and\nannotations. To that end, we extend the contextual decomposition technique\n(Murdoch et al. 2018) to convolutional neural networks which allows us to\ncompare convolutional neural networks and bidirectional long short-term memory\nnetworks. We evaluate and compare these models for the task of morphological\ntagging on three morphologically different languages and show that these models\nimplicitly discover understandable linguistic rules. Our implementation can be\nfound at https://github.com/FredericGodin/ContextualDecomposition-NLP .", "published": "2018-08-28 21:44:26", "link": "http://arxiv.org/abs/1808.09551v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using Monte Carlo dropout for non-stationary noise reduction from speech", "abstract": "In this work, we propose the use of dropout as a Bayesian estimator for\nincreasing the generalizability of a deep neural network (DNN) for speech\nenhancement. By using Monte Carlo (MC) dropout, we show that the DNN performs\nbetter enhancement in unseen noise and SNR conditions. The DNN is trained on\nspeech corrupted with Factory2, M109, Babble, Leopard and Volvo noises at SNRs\nof 0, 5 and 10 dB. Speech samples are obtained from the TIMIT database and\nnoises from NOISEX-92. In another experiment, we train five DNN models\nseparately on speech corrupted with Factory2, M109, Babble, Leopard and Volvo\nnoises, at 0, 5 and 10 dB SNRs. The model precision (estimated using MC\ndropout) is used as a proxy for squared error to dynamically select the best of\nthe DNN models based on their performance on each frame of test data. We\npropose an algorithm with a threshold on the model precision to switch between\nclassifier based model selection scheme and model precision based selection\nscheme. Testing is done on speech corrupted with unseen noises White, Pink and\nFactory1 and all five seen noises.", "published": "2018-08-28 17:46:11", "link": "http://arxiv.org/abs/1808.09432v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Contextual Audio-Visual Switching For Speech Enhancement in Real-World\n  Environments", "abstract": "Human speech processing is inherently multimodal, where visual cues (lip\nmovements) help to better understand the speech in noise. Lip-reading driven\nspeech enhancement significantly outperforms benchmark audio-only approaches at\nlow signal-to-noise ratios (SNRs). However, at high SNRs or low levels of\nbackground noise, visual cues become fairly less effective for speech\nenhancement. Therefore, a more optimal, context-aware audio-visual (AV) system\nis required, that contextually utilises both visual and noisy audio features\nand effectively accounts for different noisy conditions. In this paper, we\nintroduce a novel contextual AV switching component that contextually exploits\nAV cues with respect to different operating conditions to estimate clean audio,\nwithout requiring any SNR estimation. The switching module switches between\nvisual-only (V-only), audio-only (A-only), and both AV cues at low, high and\nmoderate SNR levels, respectively. The contextual AV switching component is\ndeveloped by integrating a convolutional neural network and long-short-term\nmemory network. For testing, the estimated clean audio features are utilised by\nthe developed novel enhanced visually derived Wiener filter for clean audio\npower spectrum estimation. The contextual AV speech enhancement method is\nevaluated under real-world scenarios using benchmark Grid and ChiME3 corpora.\nFor objective testing, perceptual evaluation of speech quality is used to\nevaluate the quality of the restored speech. For subjective testing, the\nstandard mean-opinion-score method is used. The critical analysis and\ncomparative study demonstrate the outperformance of proposed contextual AV\napproach, over A-only, V-only, spectral subtraction, and log-minimum mean\nsquare error based speech enhancement methods at both low and high SNRs,\nrevealing its capability to tackle spectro-temporal variation in any real-world\nnoisy condition.", "published": "2018-08-28 17:27:11", "link": "http://arxiv.org/abs/1808.09825v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
