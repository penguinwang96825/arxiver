{"title": "Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is\n  Needed?", "abstract": "The vast majority of today's large language models (LLMs) are\nEnglish-centric, having been pretrained predominantly on English text. Yet, in\norder to meet user expectations, models need to be able to respond\nappropriately in multiple languages once deployed in downstream applications.\nThis requires strong cross-lingual transfer abilities. In this work, we\ninvestigate the minimal amount of multilinguality required during finetuning to\nelicit cross-lingual generalisation in English-centric LLMs. In experiments\nacross four LLMs, we find that multilingual instruction tuning with as few as\ntwo to three languages is both necessary and sufficient to elicit effective\ncross-lingual generalisation, with the limiting factor being the degree to\nwhich a target language is seen during pretraining. Evaluations on five\ndifferent tasks further reveal that multilingual instruction tuning is most\nbeneficial for generative tasks that assume input/output language agreement,\nsuch as in chat settings, while being of less importance for highly structured\nclassification-style tasks. Our code and data is available at\nhttps://github.com/ZurichNLP/multilingual-instruction-tuning.", "published": "2023-12-20 00:49:52", "link": "http://arxiv.org/abs/2312.12683v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Consistency in Multimodal Dialogue System Using LLM with\n  Dialogue Scenario", "abstract": "This paper describes our dialogue system submitted to Dialogue Robot\nCompetition 2023. The system's task is to help a user at a travel agency decide\non a plan for visiting two sightseeing spots in Kyoto City that satisfy the\nuser. Our dialogue system is flexible and stable and responds to user\nrequirements by controlling dialogue flow according to dialogue scenarios. We\nalso improved user satisfaction by introducing motion and speech control based\non system utterances and user situations. In the preliminary round, our system\nwas ranked fifth in the impression evaluation and sixth in the plan evaluation\namong all 12 teams.", "published": "2023-12-20 07:15:04", "link": "http://arxiv.org/abs/2312.12808v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Stochastic Analysis of the Linguistic Provenance of English Place\n  Names", "abstract": "In English place name analysis, meanings are often derived from the\nresemblance of roots in place names to topographical features, proper names\nand/or habitation terms in one of the languages that have had an influence on\nEnglish place names. The problem here is that it is sometimes difficult to\ndetermine the base language to use to interpret the roots. The purpose of this\npaper is to stochastically determine the resemblance between 18799 English\nplace names and 84687 place names from Ireland, Scotland, Wales, Denmark,\nNorway, Sweden, France, Germany, the Netherlands and Ancient Rome. Each English\nplace name is ranked according to the extent to which it resembles place names\nfrom the other countries, and this provides a basis for determining the likely\nlanguage to use to interpret the place name. A number of observations can be\nmade using the ranking provided. In particular, it is found that `Harlington'\nis the most archetypically English place name in the English sample, and `Anna'\nis the least. Furthermore, it is found that the place names in the non-English\ndatasets are most similar to Norwegian place names and least similar to Welsh\nplace names.", "published": "2023-12-20 09:01:01", "link": "http://arxiv.org/abs/2312.12850v3", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks\n  for Chinese Large Language Models", "abstract": "As an indispensable ingredient of intelligence, commonsense reasoning is\ncrucial for large language models (LLMs) in real-world scenarios. In this\npaper, we propose CORECODE, a dataset that contains abundant commonsense\nknowledge manually annotated on dyadic dialogues, to evaluate the commonsense\nreasoning and commonsense conflict detection capabilities of Chinese LLMs. We\ncategorize commonsense knowledge in everyday conversations into three\ndimensions: entity, event, and social interaction. For easy and consistent\nannotation, we standardize the form of commonsense knowledge annotation in\nopen-domain dialogues as \"domain: slot = value\". A total of 9 domains and 37\nslots are defined to capture diverse commonsense knowledge. With these\npre-defined domains and slots, we collect 76,787 commonsense knowledge\nannotations from 19,700 dialogues through crowdsourcing. To evaluate and\nenhance the commonsense reasoning capability for LLMs on the curated dataset,\nwe establish a series of dialogue-level reasoning and detection tasks,\nincluding commonsense knowledge filling, commonsense knowledge generation,\ncommonsense conflict phrase detection, domain identification, slot\nidentification, and event causal inference. A wide variety of existing\nopen-source Chinese LLMs are evaluated with these tasks on our dataset.\nExperimental results demonstrate that these models are not competent to predict\nCORECODE's plentiful reasoning content, and even ChatGPT could only achieve\n0.275 and 0.084 accuracy on the domain identification and slot identification\ntasks under the zero-shot setting. We release the data and codes of CORECODE at\nhttps://github.com/danshi777/CORECODE to promote commonsense reasoning\nevaluation and study of LLMs in the context of daily conversations.", "published": "2023-12-20 09:06:18", "link": "http://arxiv.org/abs/2312.12853v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assaying on the Robustness of Zero-Shot Machine-Generated Text Detectors", "abstract": "To combat the potential misuse of Natural Language Generation (NLG)\ntechnology, a variety of algorithms have been developed for the detection of\nAI-generated texts. Traditionally, this task is treated as a binary\nclassification problem. Although supervised learning has demonstrated promising\nresults, acquiring labeled data for detection purposes poses real-world\nchallenges and the risk of overfitting. In an effort to address these issues,\nwe delve into the realm of zero-shot machine-generated text detection. Existing\nzero-shot detectors, typically designed for specific tasks or topics, often\nassume uniform testing scenarios, limiting their practicality. In our research,\nwe explore various advanced Large Language Models (LLMs) and their specialized\nvariants, contributing to this field in several ways. In empirical studies, we\nuncover a significant correlation between topics and detection performance.\nSecondly, we delve into the influence of topic shifts on zero-shot detectors.\nThese investigations shed light on the adaptability and robustness of these\ndetection methods across diverse topics. The code is available at\n\\url{https://github.com/yfzhang114/robustness-detection}.", "published": "2023-12-20 10:53:53", "link": "http://arxiv.org/abs/2312.12918v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Mindset: An MBTI Exploration of Large Language Models", "abstract": "We present a novel approach for integrating Myers-Briggs Type Indicator\n(MBTI) personality traits into large language models (LLMs), addressing the\nchallenges of personality consistency in personalized AI. Our method, \"Machine\nMindset,\" involves a two-phase fine-tuning and Direct Preference Optimization\n(DPO) to embed MBTI traits into LLMs. This approach ensures that models\ninternalize these traits, offering a stable and consistent personality profile.\nWe demonstrate the effectiveness of our models across various domains, showing\nalignment between model performance and their respective MBTI traits. The paper\nhighlights significant contributions in the development of personality datasets\nand a new training methodology for personality integration in LLMs, enhancing\nthe potential for personalized AI applications. We also open-sourced our model\nand part of the data at \\url{https://github.com/PKU-YuanGroup/Machine-Mindset}.", "published": "2023-12-20 12:59:31", "link": "http://arxiv.org/abs/2312.12999v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and\n  Optimisation", "abstract": "The advancement of natural language processing (NLP) has been significantly\nboosted by the development of transformer-based large language models (LLMs).\nThese models have revolutionized NLP tasks, particularly in code generation,\naiding developers in creating software with enhanced efficiency. Despite their\nadvancements, challenges in balancing code snippet generation with effective\ntest case generation and execution persist. To address these issues, this paper\nintroduces Multi-Agent Assistant Code Generation (AgentCoder), a novel solution\ncomprising a multi-agent framework with specialized agents: the programmer\nagent, the test designer agent, and the test executor agent. During the coding\nprocedure, the programmer agent will focus on the code generation and\nrefinement based on the test executor agent's feedback. The test designer agent\nwill generate test cases for the generated code, and the test executor agent\nwill run the code with the test cases and write the feedback to the programmer.\nThis collaborative system ensures robust code generation, surpassing the\nlimitations of single-agent models and traditional methodologies. Our extensive\nexperiments on 9 code generation models and 12 enhancement approaches showcase\nAgentCoder's superior performance over existing code generation models and\nprompt engineering techniques across various benchmarks. For example,\nAgentCoder (GPT-4) achieves 96.3\\% and 91.8\\% pass@1 in HumanEval and MBPP\ndatasets with an overall token overhead of 56.9K and 66.3K, while\nstate-of-the-art obtains only 90.2\\% and 78.9\\% pass@1 with an overall token\noverhead of 138.2K and 206.5K.", "published": "2023-12-20 13:22:41", "link": "http://arxiv.org/abs/2312.13010v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-augmented Multilingual Knowledge Editing", "abstract": "Knowledge represented in Large Language Models (LLMs) is quite often\nincorrect and can also become obsolete over time. Updating knowledge via\nfine-tuning is computationally resource-hungry and not reliable, and so\nknowledge editing (KE) has developed as an effective and economical alternative\nto inject new knowledge or to fix factual errors in LLMs. Although there has\nbeen considerable interest in this area, current KE research exclusively\nfocuses on the monolingual setting, typically in English. However, what happens\nif the new knowledge is supplied in one language, but we would like to query\nthe LLM in a different language? To address the problem of multilingual\nknowledge editing, we propose Retrieval-augmented Multilingual Knowledge Editor\n(ReMaKE) to update new knowledge in LLMs. ReMaKE can perform model-agnostic\nknowledge editing in multilingual settings. ReMaKE concatenates the new\nknowledge retrieved from a multilingual knowledge base with prompts. Our\nexperimental results show that ReMaKE outperforms baseline knowledge editing\nmethods by a significant margin and is the first KE method to work in a\nmultilingual setting. We provide our multilingual knowledge editing dataset\n(MzsRE) in 12 languages, which along with code, and additional project\ninformation is available at https://github.com/Vicky-Wil/ReMaKE.", "published": "2023-12-20 14:08:58", "link": "http://arxiv.org/abs/2312.13040v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Code Switching for Machine Translation using Language Models", "abstract": "Large language models (LLMs) have exerted a considerable impact on diverse\nlanguage-related tasks in recent years. Their demonstrated state-of-the-art\nperformance is achieved through methodologies such as zero-shot or few-shot\nprompting. These models undergo training on extensive datasets that encompass\nsegments of the Internet and subsequently undergo fine-tuning tailored to\nspecific tasks. Notably, they exhibit proficiency in tasks such as translation,\nsummarization, question answering, and creative writing, even in the absence of\nexplicit training for those particular tasks. While they have shown substantial\nimprovement in the multilingual tasks their performance in the code switching,\nespecially for machine translation remains relatively uncharted. In this paper,\nwe present an extensive study on the code switching task specifically for the\nmachine translation task comparing multiple LLMs. Our results indicate that\ndespite the LLMs having promising results in the certain tasks, the models with\nrelatively lesser complexity outperform the multilingual large language models\nin the machine translation task. We posit that the efficacy of multilingual\nlarge language models in contextual code switching is constrained by their\ntraining methodologies. In contrast, relatively smaller models, when trained\nand fine-tuned on bespoke datasets, may yield superior results in comparison to\nthe majority of multilingual models.", "published": "2023-12-20 16:40:33", "link": "http://arxiv.org/abs/2312.13179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent\n  Sentence Spaces", "abstract": "Deep generative neural networks, such as Variational AutoEncoders (VAEs),\noffer an opportunity to better understand and control language models from the\nperspective of sentence-level latent spaces. To combine the controllability of\nVAE latent spaces with the state-of-the-art performance of recent large\nlanguage models (LLMs), we present in this work LlaMaVAE, which combines\nexpressive encoder and decoder models (sentenceT5 and LlaMA) with a VAE\narchitecture, aiming to provide better text generation control to LLMs. In\naddition, to conditionally guide the VAE generation, we investigate a new\napproach based on flow-based invertible neural networks (INNs) named Invertible\nCVAE. Experimental results reveal that LlaMaVAE can outperform the previous\nstate-of-the-art VAE language model, Optimus, across various tasks, including\nlanguage modelling, semantic textual similarity and definition modelling.\nQualitative analysis on interpolation and traversal experiments also indicates\nan increased degree of semantic clustering and geometric consistency, which\nenables better generation control.", "published": "2023-12-20 17:25:23", "link": "http://arxiv.org/abs/2312.13208v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DSFormer: Effective Compression of Text-Transformers by Dense-Sparse\n  Weight Factorization", "abstract": "With the tremendous success of large transformer models in natural language\nunderstanding, down-sizing them for cost-effective deployments has become\ncritical. Recent studies have explored the low-rank weight factorization\ntechniques which are efficient to train, and apply out-of-the-box to any\ntransformer architecture. Unfortunately, the low-rank assumption tends to be\nover-restrictive and hinders the expressiveness of the compressed model. This\npaper proposes, DSFormer, a simple alternative factorization scheme which\nexpresses a target weight matrix as the product of a small dense and a\nsemi-structured sparse matrix. The resulting approximation is more faithful to\nthe weight distribution in transformers and therefore achieves a stronger\nefficiency-accuracy trade-off. Another concern with existing factorizers is\ntheir dependence on a task-unaware initialization step which degrades the\naccuracy of the resulting model. DSFormer addresses this issue through a novel\nStraight-Through Factorizer (STF) algorithm that jointly learns all the weight\nfactorizations to directly maximize the final task accuracy. Extensive\nexperiments on multiple natural language understanding benchmarks demonstrate\nthat DSFormer obtains up to 40% better compression than the state-of-the-art\nlow-rank factorizers, leading semi-structured sparsity baselines and popular\nknowledge distillation approaches. Our approach is also orthogonal to\nmainstream compressors and offers up to 50% additional compression when added\nto popular distilled, layer-shared and quantized transformers. We empirically\nevaluate the benefits of STF over conventional optimization practices.", "published": "2023-12-20 17:27:25", "link": "http://arxiv.org/abs/2312.13211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Time is Encoded in the Weights of Finetuned Language Models", "abstract": "We present time vectors, a simple tool to customize language models to new\ntime periods. Time vectors are created by finetuning a language model on data\nfrom a single time (e.g., a year or month), and then subtracting the weights of\nthe original pretrained model. This vector specifies a direction in weight\nspace that, as our experiments show, improves performance on text from that\ntime period. Time vectors specialized to adjacent time periods appear to be\npositioned closer together in a manifold. Using this structure, we interpolate\nbetween time vectors to induce new models that perform better on intervening\nand future time periods, without any additional training. We demonstrate the\nconsistency of our findings across different tasks, domains, model sizes, and\ntime scales. Our results suggest that time is encoded in the weight space of\nfinetuned models.", "published": "2023-12-20 20:04:45", "link": "http://arxiv.org/abs/2312.13401v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Imitation of Life: A Search Engine for Biologically Inspired Design", "abstract": "Biologically Inspired Design (BID), or Biomimicry, is a problem-solving\nmethodology that applies analogies from nature to solve engineering challenges.\nFor example, Speedo engineers designed swimsuits based on shark skin. Finding\nrelevant biological solutions for real-world problems poses significant\nchallenges, both due to the limited biological knowledge engineers and\ndesigners typically possess and to the limited BID resources. Existing BID\ndatasets are hand-curated and small, and scaling them up requires costly human\nannotations.\n  In this paper, we introduce BARcode (Biological Analogy Retriever), a search\nengine for automatically mining bio-inspirations from the web at scale. Using\nadvances in natural language understanding and data programming, BARcode\nidentifies potential inspirations for engineering challenges. Our experiments\ndemonstrate that BARcode can retrieve inspirations that are valuable to\nengineers and designers tackling real-world problems, as well as recover famous\nhistorical BID examples. We release data and code; we view BARcode as a step\ntowards addressing the challenges that have historically hindered the practical\napplication of BID to engineering innovation.", "published": "2023-12-20 00:45:27", "link": "http://arxiv.org/abs/2312.12681v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mini-GPTs: Efficient Large Language Models through Contextual Pruning", "abstract": "In AI research, the optimization of Large Language Models (LLMs) remains a\nsignificant challenge, crucial for advancing the field's practical applications\nand sustainability. Building upon the foundational work of Professor Song Han's\nlab at MIT, this paper introduces a novel approach in developing Mini-GPTs via\ncontextual pruning. Our methodology strategically prunes the computational\narchitecture of traditional LLMs, like Phi-1.5, focusing on retaining core\nfunctionalities while drastically reducing model sizes. We employ the technique\nacross diverse and complex datasets, including US law, Medical Q&A, Skyrim\ndialogue, English-Taiwanese translation, and Economics articles. The results\nunderscore the efficiency and effectiveness of contextual pruning, not merely\nas a theoretical concept but as a practical tool in developing domain-specific,\nresource-efficient LLMs. Contextual pruning is a promising method for building\ndomain-specific LLMs, and this research is a building block towards future\ndevelopment with more hardware compute, refined fine-tuning, and quantization.", "published": "2023-12-20 00:48:13", "link": "http://arxiv.org/abs/2312.12682v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Response Enhanced Semi-supervised Dialogue Query Generation", "abstract": "Leveraging vast and continually updated knowledge from the Internet has been\nconsidered an important ability for a dialogue system. Therefore, the dialogue\nquery generation task is proposed for generating search queries from dialogue\nhistories, which will be submitted to a search engine for retrieving relevant\nwebsites on the Internet. In this regard, previous efforts were devoted to\ncollecting conversations with annotated queries and training a query producer\n(QP) via standard supervised learning. However, these studies still face the\nchallenges of data scarcity and domain adaptation. To address these issues, in\nthis paper, we propose a semi-supervised learning framework -- SemiDQG, to\nimprove model performance with unlabeled conversations. Based on the\nobservation that the search query is typically related to the topic of dialogue\nresponse, we train a response-augmented query producer (RA) to provide rich and\neffective training signals for QP. We first apply a similarity-based query\nselection strategy to select high-quality RA-generated pseudo queries, which\nare used to construct pseudo instances for training QP and RA. Then, we adopt\nthe REINFORCE algorithm to further enhance QP, with RA-provided rewards as\nfine-grained training signals. Experimental results and in-depth analysis of\nthree benchmarks show the effectiveness of our framework in cross-domain and\nlow-resource scenarios. Particularly, SemiDQG significantly surpasses ChatGPT\nand competitive baselines. Our code is available at\n\\url{https://github.com/DeepLearnXMU/SemiDQG}.", "published": "2023-12-20 02:19:54", "link": "http://arxiv.org/abs/2312.12713v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning and Forgetting Unsafe Examples in Large Language Models", "abstract": "As the number of large language models (LLMs) released to the public grows,\nthere is a pressing need to understand the safety implications associated with\nthese models learning from third-party custom finetuning data. We explore the\nbehavior of LLMs finetuned on noisy custom data containing unsafe content,\nrepresented by datasets that contain biases, toxicity, and harmfulness, finding\nthat while aligned LLMs can readily learn this unsafe content, they also tend\nto forget it more significantly than other examples when subsequently finetuned\non safer content. Drawing inspiration from the discrepancies in forgetting, we\nintroduce the \"ForgetFilter\" algorithm, which filters unsafe data based on how\nstrong the model's forgetting signal is for that data. We demonstrate that the\nForgetFilter algorithm ensures safety in customized finetuning without\ncompromising downstream task performance, unlike sequential safety finetuning.\nForgetFilter outperforms alternative strategies like replay and moral\nself-correction in curbing LLMs' ability to assimilate unsafe content during\ncustom finetuning, e.g. 75% lower than not applying any safety measures and 62%\nlower than using self-correction in toxicity score.", "published": "2023-12-20 03:18:50", "link": "http://arxiv.org/abs/2312.12736v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fine-tuning Large Language Models for Adaptive Machine Translation", "abstract": "This paper presents the outcomes of fine-tuning Mistral 7B, a general-purpose\nlarge language model (LLM), for adaptive machine translation (MT). The\nfine-tuning process involves utilising a combination of zero-shot and one-shot\ntranslation prompts within the medical domain. The primary objective is to\nenhance real-time adaptive MT capabilities of Mistral 7B, enabling it to adapt\ntranslations to the required domain at inference time. The results,\nparticularly for Spanish-to-English MT, showcase the efficacy of the fine-tuned\nmodel, demonstrating quality improvements in both zero-shot and one-shot\ntranslation scenarios, surpassing Mistral 7B's baseline performance. Notably,\nthe fine-tuned Mistral outperforms ChatGPT \"gpt-3.5-turbo\" in zero-shot\ntranslation while achieving comparable one-shot translation quality. Moreover,\nthe zero-shot translation of the fine-tuned Mistral matches NLLB 3.3B's\nperformance, and its one-shot translation quality surpasses that of NLLB 3.3B.\nThese findings emphasise the significance of fine-tuning efficient LLMs like\nMistral 7B to yield high-quality zero-shot translations comparable to\ntask-oriented models like NLLB 3.3B. Additionally, the adaptive gains achieved\nin one-shot translation are comparable to those of commercial LLMs such as\nChatGPT. Our experiments demonstrate that, with a relatively small dataset of\n20,000 segments that incorporate a mix of zero-shot and one-shot prompts,\nfine-tuning significantly enhances Mistral's in-context learning ability,\nespecially for real-time adaptive MT.", "published": "2023-12-20 03:21:48", "link": "http://arxiv.org/abs/2312.12740v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ChatFDA: Medical Records Risk Assessment", "abstract": "In healthcare, the emphasis on patient safety and the minimization of medical\nerrors cannot be overstated. Despite concerted efforts, many healthcare\nsystems, especially in low-resource regions, still grapple with preventing\nthese errors effectively. This study explores a pioneering application aimed at\naddressing this challenge by assisting caregivers in gauging potential risks\nderived from medical notes. The application leverages data from openFDA,\ndelivering real-time, actionable insights regarding prescriptions. Preliminary\nanalyses conducted on the MIMIC-III \\cite{mimic} dataset affirm a proof of\nconcept highlighting a reduction in medical errors and an amplification in\npatient safety. This tool holds promise for drastically enhancing healthcare\noutcomes in settings with limited resources. To bolster reproducibility and\nfoster further research, the codebase underpinning our methodology is\naccessible on\nhttps://github.com/autonlab/2023.hackAuton/tree/main/prescription_checker. This\nis a submission for the 30th HackAuton CMU.", "published": "2023-12-20 03:40:45", "link": "http://arxiv.org/abs/2312.12746v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Spectral Prompt Tuning:Unveiling Unseen Classes for Zero-Shot Semantic\n  Segmentation", "abstract": "Recently, CLIP has found practical utility in the domain of pixel-level\nzero-shot segmentation tasks. The present landscape features two-stage\nmethodologies beset by issues such as intricate pipelines and elevated\ncomputational costs. While current one-stage approaches alleviate these\nconcerns and incorporate Visual Prompt Training (VPT) to uphold CLIP's\ngeneralization capacity, they still fall short in fully harnessing CLIP's\npotential for pixel-level unseen class demarcation and precise pixel\npredictions. To further stimulate CLIP's zero-shot dense prediction capability,\nwe propose SPT-SEG, a one-stage approach that improves CLIP's adaptability from\nimage to pixel. Specifically, we initially introduce Spectral Prompt Tuning\n(SPT), incorporating spectral prompts into the CLIP visual encoder's shallow\nlayers to capture structural intricacies of images, thereby enhancing\ncomprehension of unseen classes. Subsequently, we introduce the Spectral Guided\nDecoder (SGD), utilizing both high and low-frequency information to steer the\nnetwork's spatial focus towards more prominent classification features,\nenabling precise pixel-level prediction outcomes. Through extensive experiments\non two public datasets, we demonstrate the superiority of our method over\nstate-of-the-art approaches, performing well across all classes and\nparticularly excelling in handling unseen classes. Code is available\nat:https://github.com/clearxu/SPT.", "published": "2023-12-20 04:27:13", "link": "http://arxiv.org/abs/2312.12754v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large\n  Language Models", "abstract": "The emergence of various medical large language models (LLMs) in the medical\ndomain has highlighted the need for unified evaluation standards, as manual\nevaluation of LLMs proves to be time-consuming and labor-intensive. To address\nthis issue, we introduce MedBench, a comprehensive benchmark for the Chinese\nmedical domain, comprising 40,041 questions sourced from authentic examination\nexercises and medical reports of diverse branches of medicine. In particular,\nthis benchmark is composed of four key components: the Chinese Medical\nLicensing Examination, the Resident Standardization Training Examination, the\nDoctor In-Charge Qualification Examination, and real-world clinic cases\nencompassing examinations, diagnoses, and treatments. MedBench replicates the\neducational progression and clinical practice experiences of doctors in\nMainland China, thereby establishing itself as a credible benchmark for\nassessing the mastery of knowledge and reasoning abilities in medical language\nlearning models. We perform extensive experiments and conduct an in-depth\nanalysis from diverse perspectives, which culminate in the following findings:\n(1) Chinese medical LLMs underperform on this benchmark, highlighting the need\nfor significant advances in clinical knowledge and diagnostic precision. (2)\nSeveral general-domain LLMs surprisingly possess considerable medical\nknowledge. These findings elucidate both the capabilities and limitations of\nLLMs within the context of MedBench, with the ultimate goal of aiding the\nmedical research community.", "published": "2023-12-20 07:01:49", "link": "http://arxiv.org/abs/2312.12806v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Turning Dust into Gold: Distilling Complex Reasoning Capabilities from\n  LLMs by Leveraging Negative Data", "abstract": "Large Language Models (LLMs) have performed well on various reasoning tasks,\nbut their inaccessibility and numerous parameters hinder wide application in\npractice. One promising way is distilling the reasoning ability from LLMs to\nsmall models by the generated chain-of-thought reasoning paths. In some cases,\nhowever, LLMs may produce incorrect reasoning chains, especially when facing\ncomplex mathematical problems. Previous studies only transfer knowledge from\npositive samples and drop the synthesized data with wrong answers. In this\nwork, we illustrate the merit of negative data and propose a model\nspecialization framework to distill LLMs with negative samples besides positive\nones. The framework consists of three progressive steps, covering from training\nto inference stages, to absorb knowledge from negative data. We conduct\nextensive experiments across arithmetic reasoning tasks to demonstrate the role\nof negative data in distillation from LLM.", "published": "2023-12-20 08:28:36", "link": "http://arxiv.org/abs/2312.12832v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Resources for Dutch Large Language Modelling", "abstract": "Despite the rapid expansion of types of large language models, there remains\na notable gap in models specifically designed for the Dutch language. This gap\nis not only a shortage in terms of pretrained Dutch models but also in terms of\ndata, and benchmarks and leaderboards. This work provides a small step to\nimprove the situation. First, we introduce two fine-tuned variants of the Llama\n2 13B model. We first fine-tuned Llama 2 using Dutch-specific web-crawled data\nand subsequently refined this model further on multiple synthetic instruction\nand chat datasets. These datasets as well as the model weights are made\navailable. In addition, we provide a leaderboard to keep track of the\nperformance of (Dutch) models on a number of generation tasks, and we include\nresults of a number of state-of-the-art models, including our own. Finally we\nprovide a critical conclusion on what we believe is needed to push forward\nDutch language models and the whole eco-system around the models.", "published": "2023-12-20 09:06:06", "link": "http://arxiv.org/abs/2312.12852v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "In Generative AI we Trust: Can Chatbots Effectively Verify Political\n  Information?", "abstract": "This article presents a comparative analysis of the ability of two large\nlanguage model (LLM)-based chatbots, ChatGPT and Bing Chat, recently rebranded\nto Microsoft Copilot, to detect veracity of political information. We use AI\nauditing methodology to investigate how chatbots evaluate true, false, and\nborderline statements on five topics: COVID-19, Russian aggression against\nUkraine, the Holocaust, climate change, and LGBTQ+ related debates. We compare\nhow the chatbots perform in high- and low-resource languages by using prompts\nin English, Russian, and Ukrainian. Furthermore, we explore the ability of\nchatbots to evaluate statements according to political communication concepts\nof disinformation, misinformation, and conspiracy theory, using\ndefinition-oriented prompts. We also systematically test how such evaluations\nare influenced by source bias which we model by attributing specific claims to\nvarious political and social actors. The results show high performance of\nChatGPT for the baseline veracity evaluation task, with 72 percent of the cases\nevaluated correctly on average across languages without pre-training. Bing Chat\nperformed worse with a 67 percent accuracy. We observe significant disparities\nin how chatbots evaluate prompts in high- and low-resource languages and how\nthey adapt their evaluations to political communication concepts with ChatGPT\nproviding more nuanced outputs than Bing Chat. Finally, we find that for some\nveracity detection-related tasks, the performance of chatbots varied depending\non the topic of the statement or the source to which it is attributed. These\nfindings highlight the potential of LLM-based chatbots in tackling different\nforms of false information in online environments, but also points to the\nsubstantial variation in terms of how such potential is realized due to\nspecific factors, such as language of the prompt or the topic.", "published": "2023-12-20 15:17:03", "link": "http://arxiv.org/abs/2312.13096v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Exploring Multimodal Large Language Models for Radiology Report\n  Error-checking", "abstract": "This paper proposes one of the first clinical applications of multimodal\nlarge language models (LLMs) as an assistant for radiologists to check errors\nin their reports. We created an evaluation dataset from real-world radiology\ndatasets (including X-rays and CT scans). A subset of original reports was\nmodified to contain synthetic errors by introducing three types of mistakes:\n\"insert\", \"remove\", and \"substitute\". The evaluation contained two difficulty\nlevels: SIMPLE for binary error-checking and COMPLEX for identifying error\ntypes. At the SIMPLE level, our fine-tuned model significantly enhanced\nperformance by 47.4% and 25.4% on MIMIC-CXR and IU X-ray data, respectively.\nThis performance boost is also observed in unseen modality, CT scans, as the\nmodel performed 19.46% better than the baseline model. The model also surpassed\nthe domain expert's accuracy in the MIMIC-CXR dataset by 1.67%. Notably, among\nthe subsets (N=21) of the test set where a clinician did not achieve the\ncorrect conclusion, the LLaVA ensemble mode correctly identified 71.4% of these\ncases. However, all models performed poorly in identifying mistake types,\nunderscoring the difficulty of the COMPLEX level. This study marks a promising\nstep toward utilizing multimodal LLMs to enhance diagnostic accuracy in\nradiology. The ensemble model demonstrated comparable performance to\nclinicians, even capturing errors overlooked by humans.", "published": "2023-12-20 15:20:33", "link": "http://arxiv.org/abs/2312.13103v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "HCDIR: End-to-end Hate Context Detection, and Intensity Reduction model\n  for online comments", "abstract": "Warning: This paper contains examples of the language that some people may\nfind offensive.\n  Detecting and reducing hateful, abusive, offensive comments is a critical and\nchallenging task on social media. Moreover, few studies aim to mitigate the\nintensity of hate speech. While studies have shown that context-level semantics\nare crucial for detecting hateful comments, most of this research focuses on\nEnglish due to the ample datasets available. In contrast, low-resource\nlanguages, like Indian languages, remain under-researched because of limited\ndatasets. Contrary to hate speech detection, hate intensity reduction remains\nunexplored in high-resource and low-resource languages. In this paper, we\npropose a novel end-to-end model, HCDIR, for Hate Context Detection, and Hate\nIntensity Reduction in social media posts. First, we fine-tuned several\npre-trained language models to detect hateful comments to ascertain the\nbest-performing hateful comments detection model. Then, we identified the\ncontextual hateful words. Identification of such hateful words is justified\nthrough the state-of-the-art explainable learning model, i.e., Integrated\nGradient (IG). Lastly, the Masked Language Modeling (MLM) model has been\nemployed to capture domain-specific nuances to reduce hate intensity. We masked\nthe 50\\% hateful words of the comments identified as hateful and predicted the\nalternative words for these masked terms to generate convincing sentences. An\noptimal replacement for the original hate comments from the feasible sentences\nis preferred. Extensive experiments have been conducted on several recent\ndatasets using automatic metric-based evaluation (BERTScore) and thorough human\nevaluation. To enhance the faithfulness in human evaluation, we arranged a\ngroup of three human annotators with varied expertise.", "published": "2023-12-20 17:05:46", "link": "http://arxiv.org/abs/2312.13193v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A General Model for Aggregating Annotations Across Simple, Complex, and\n  Multi-Object Annotation Tasks", "abstract": "Human annotations are vital to supervised learning, yet annotators often\ndisagree on the correct label, especially as annotation tasks increase in\ncomplexity. A strategy to improve label quality is to ask multiple annotators\nto label the same item and aggregate their labels. Many aggregation models have\nbeen proposed for categorical or numerical annotation tasks, but far less work\nhas considered more complex annotation tasks involving open-ended,\nmultivariate, or structured responses. While a variety of bespoke models have\nbeen proposed for specific tasks, our work is the first to introduce\naggregation methods that generalize across many diverse complex tasks,\nincluding sequence labeling, translation, syntactic parsing, ranking, bounding\nboxes, and keypoints. This generality is achieved by devising a task-agnostic\nmethod to model distances between labels rather than the labels themselves.\n  This article extends our prior work with investigation of three new research\nquestions. First, how do complex annotation properties impact aggregation\naccuracy? Second, how should a task owner navigate the many modeling choices to\nmaximize aggregation accuracy? Finally, what diagnoses can verify that\naggregation models are specified correctly for the given data? To understand\nhow various factors impact accuracy and to inform model selection, we conduct\nsimulation studies and experiments on real, complex datasets. Regarding\ntesting, we introduce unit tests for aggregation models and present a suite of\nsuch tests to ensure that a given model is not mis-specified and exhibits\nexpected behavior.\n  Beyond investigating these research questions above, we discuss the\nfoundational concept of annotation complexity, present a new aggregation model\nas a bridge between traditional models and our own, and contribute a new\nsemi-supervised learning method for complex label aggregation that outperforms\nprior work.", "published": "2023-12-20 21:28:35", "link": "http://arxiv.org/abs/2312.13437v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BloomVQA: Assessing Hierarchical Multi-modal Comprehension", "abstract": "We propose a novel VQA dataset, BloomVQA, to facilitate comprehensive\nevaluation of large vision-language models on comprehension tasks. Unlike\ncurrent benchmarks that often focus on fact-based memorization and simple\nreasoning tasks without theoretical grounding, we collect multiple-choice\nsamples based on picture stories that reflect different levels of\ncomprehension, as laid out in Bloom's Taxonomy, a classic framework for\nlearning assessment widely adopted in education research. Our data maps to a\nnovel hierarchical graph representation which enables automatic data\naugmentation and novel measures characterizing model consistency. We perform\ngraded evaluation and reliability analysis on recent multi-modal models. In\ncomparison to low-level tasks, we observe decreased performance on tasks\nrequiring advanced comprehension and cognitive skills with up to 38.0\\% drop in\nVQA accuracy. In comparison to earlier models, GPT-4V demonstrates improved\naccuracy over all comprehension levels and shows a tendency of bypassing visual\ninputs especially for higher-level tasks. Current models also show consistency\npatterns misaligned with human comprehension in various scenarios,\ndemonstrating the need for improvement based on theoretically-grounded\ncriteria.", "published": "2023-12-20 02:22:49", "link": "http://arxiv.org/abs/2312.12716v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ALMANACS: A Simulatability Benchmark for Language Model Explainability", "abstract": "How do we measure the efficacy of language model explainability methods?\nWhile many explainability methods have been developed, they are typically\nevaluated on bespoke tasks, preventing an apples-to-apples comparison. To help\nfill this gap, we present ALMANACS, a language model explainability benchmark.\nALMANACS scores explainability methods on simulatability, i.e., how well the\nexplanations improve behavior prediction on new inputs. The ALMANACS scenarios\nspan twelve safety-relevant topics such as ethical reasoning and advanced AI\nbehaviors; they have idiosyncratic premises to invoke model-specific behavior;\nand they have a train-test distributional shift to encourage faithful\nexplanations. By using another language model to predict behavior based on the\nexplanations, ALMANACS is a fully automated benchmark. While not a replacement\nfor human evaluations, we aim for ALMANACS to be a complementary, automated\ntool that allows for fast, scalable evaluation. Using ALMANACS, we evaluate\ncounterfactual, rationalization, attention, and Integrated Gradients\nexplanations. Our results are sobering: when averaged across all topics, no\nexplanation method outperforms the explanation-free control. We conclude that\ndespite modest successes in prior work, developing an explanation method that\naids simulatability in ALMANACS remains an open challenge.", "published": "2023-12-20 03:44:18", "link": "http://arxiv.org/abs/2312.12747v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Lattice Rescoring Based on Large Ensemble of Complementary Neural\n  Language Models", "abstract": "We investigate the effectiveness of using a large ensemble of advanced neural\nlanguage models (NLMs) for lattice rescoring on automatic speech recognition\n(ASR) hypotheses. Previous studies have reported the effectiveness of combining\na small number of NLMs. In contrast, in this study, we combine up to eight\nNLMs, i.e., forward/backward long short-term memory/Transformer-LMs that are\ntrained with two different random initialization seeds. We combine these NLMs\nthrough iterative lattice generation. Since these NLMs work complementarily\nwith each other, by combining them one by one at each rescoring iteration,\nlanguage scores attached to given lattice arcs can be gradually refined.\nConsequently, errors of the ASR hypotheses can be gradually reduced. We also\ninvestigate the effectiveness of carrying over contextual information (previous\nrescoring results) across a lattice sequence of a long speech such as a lecture\nspeech. In experiments using a lecture speech corpus, by combining the eight\nNLMs and using context carry-over, we obtained a 24.4% relative word error rate\nreduction from the ASR 1-best baseline. For further comparison, we performed\nsimultaneous (i.e., non-iterative) NLM combination and 100-best rescoring using\nthe large ensemble of NLMs, which confirmed the advantage of lattice rescoring\nwith iterative NLM combination.", "published": "2023-12-20 04:52:24", "link": "http://arxiv.org/abs/2312.12764v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Segmenting Messy Text: Detecting Boundaries in Text Derived from\n  Historical Newspaper Images", "abstract": "Text segmentation, the task of dividing a document into sections, is often a\nprerequisite for performing additional natural language processing tasks.\nExisting text segmentation methods have typically been developed and tested\nusing clean, narrative-style text with segments containing distinct topics.\nHere we consider a challenging text segmentation task: dividing newspaper\nmarriage announcement lists into units of one announcement each. In many cases\nthe information is not structured into sentences, and adjacent segments are not\ntopically distinct from each other. In addition, the text of the announcements,\nwhich is derived from images of historical newspapers via optical character\nrecognition, contains many typographical errors. As a result, these\nannouncements are not amenable to segmentation with existing techniques. We\npresent a novel deep learning-based model for segmenting such text and show\nthat it significantly outperforms an existing state-of-the-art method on our\ntask.", "published": "2023-12-20 05:17:06", "link": "http://arxiv.org/abs/2312.12773v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "I.2.7; I.7.5"], "primary_category": "cs.CV"}
{"title": "Stable Distillation: Regularizing Continued Pre-training for\n  Low-Resource Automatic Speech Recognition", "abstract": "Continued self-supervised (SSL) pre-training for adapting existing SSL models\nto the target domain has shown to be extremely effective for low-resource\nAutomatic Speech Recognition (ASR). This paper proposes Stable Distillation, a\nsimple and novel approach for SSL-based continued pre-training that boosts ASR\nperformance in the target domain where both labeled and unlabeled data are\nlimited. Stable Distillation employs self-distillation as regularization for\ncontinued pre-training, alleviating the over-fitting issue, a common problem\ncontinued pre-training faces when the source and target domains differ.\nSpecifically, first, we perform vanilla continued pre-training on an initial\nSSL pre-trained model on the target domain ASR dataset and call it the teacher.\nNext, we take the same initial pre-trained model as a student to perform\ncontinued pre-training while enforcing its hidden representations to be close\nto that of the teacher (via MSE loss). This student is then used for downstream\nASR fine-tuning on the target dataset. In practice, Stable Distillation\noutperforms all our baselines by 0.8 - 7 WER when evaluated in various\nexperimental settings.", "published": "2023-12-20 06:02:12", "link": "http://arxiv.org/abs/2312.12783v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OCTOPUS: Open-vocabulary Content Tracking and Object Placement Using\n  Semantic Understanding in Mixed Reality", "abstract": "One key challenge in augmented reality is the placement of virtual content in\nnatural locations. Existing automated techniques are only able to work with a\nclosed-vocabulary, fixed set of objects. In this paper, we introduce a new\nopen-vocabulary method for object placement. Our eight-stage pipeline leverages\nrecent advances in segmentation models, vision-language models, and LLMs to\nplace any virtual object in any AR camera frame or scene. In a preliminary user\nstudy, we show that our method performs at least as well as human experts 57%\nof the time.", "published": "2023-12-20 07:34:20", "link": "http://arxiv.org/abs/2312.12815v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Big Tech influence over AI research revisited: memetic analysis of\n  attribution of ideas to affiliation", "abstract": "There exists a growing discourse around the domination of Big Tech on the\nlandscape of artificial intelligence (AI) research, yet our comprehension of\nthis phenomenon remains cursory. This paper aims to broaden and deepen our\nunderstanding of Big Tech's reach and power within AI research. It highlights\nthe dominance not merely in terms of sheer publication volume but rather in the\npropagation of new ideas or memes. Current studies often oversimplify the\nconcept of influence to the share of affiliations in academic papers, typically\nsourced from limited databases such as arXiv or specific academic conferences.\n  The main goal of this paper is to unravel the specific nuances of such\ninfluence, determining which AI ideas are predominantly driven by Big Tech\nentities. By employing network and memetic analysis on AI-oriented paper\nabstracts and their citation network, we are able to grasp a deeper insight\ninto this phenomenon. By utilizing two databases: OpenAlex and S2ORC, we are\nable to perform such analysis on a much bigger scale than previous attempts.\n  Our findings suggest that while Big Tech-affiliated papers are\ndisproportionately more cited in some areas, the most cited papers are those\naffiliated with both Big Tech and Academia. Focusing on the most contagious\nmemes, their attribution to specific affiliation groups (Big Tech, Academia,\nmixed affiliation) seems equally distributed between those three groups. This\nsuggests that the notion of Big Tech domination over AI research is\noversimplified in the discourse.", "published": "2023-12-20 09:45:44", "link": "http://arxiv.org/abs/2312.12881v2", "categories": ["physics.soc-ph", "cs.CL", "cs.SI"], "primary_category": "physics.soc-ph"}
{"title": "Benchmarking and Analyzing In-context Learning, Fine-tuning and\n  Supervised Learning for Biomedical Knowledge Curation: a focused study on\n  chemical entities of biological interest", "abstract": "Automated knowledge curation for biomedical ontologies is key to ensure that\nthey remain comprehensive, high-quality and up-to-date. In the era of\nfoundational language models, this study compares and analyzes three NLP\nparadigms for curation tasks: in-context learning (ICL), fine-tuning (FT), and\nsupervised learning (ML). Using the Chemical Entities of Biological Interest\n(ChEBI) database as a model ontology, three curation tasks were devised. For\nICL, three prompting strategies were employed with GPT-4, GPT-3.5, BioGPT.\nPubmedBERT was chosen for the FT paradigm. For ML, six embedding models were\nutilized for training Random Forest and Long-Short Term Memory models. Five\nsetups were designed to assess ML and FT model performance across different\ndata availability scenarios.Datasets for curation tasks included: task 1\n(620,386), task 2 (611,430), and task 3 (617,381), maintaining a 50:50 positive\nversus negative ratio. For ICL models, GPT-4 achieved best accuracy scores of\n0.916, 0.766 and 0.874 for tasks 1-3 respectively. In a direct comparison, ML\n(trained on ~260,000 triples) outperformed ICL in accuracy across all tasks.\n(accuracy differences: +.11, +.22 and +.17). Fine-tuned PubmedBERT performed\nsimilarly to leading ML models in tasks 1 & 2 (F1 differences: -.014 and\n+.002), but worse in task 3 (-.048). Simulations revealed performance declines\nin both ML and FT models with smaller and higher imbalanced training data.\nwhere ICL (particularly GPT-4) excelled in tasks 1 & 3. GPT-4 excelled in tasks\n1 and 3 with less than 6,000 triples, surpassing ML/FT. ICL underperformed\nML/FT in task 2.ICL-augmented foundation models can be good assistants for\nknowledge curation with correct prompting, however, not making ML and FT\nparadigms obsolete. The latter two require task-specific data to beat ICL. In\nsuch cases, ML relies on small pretrained embeddings, minimizing computational\ndemands.", "published": "2023-12-20 12:46:44", "link": "http://arxiv.org/abs/2312.12989v1", "categories": ["cs.LG", "cs.CL", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "FusDom: Combining In-Domain and Out-of-Domain Knowledge for Continuous\n  Self-Supervised Learning", "abstract": "Continued pre-training (CP) offers multiple advantages, like target domain\nadaptation and the potential to exploit the continuous stream of unlabeled data\navailable online. However, continued pre-training on out-of-domain\ndistributions often leads to catastrophic forgetting of previously acquired\nknowledge, leading to sub-optimal ASR performance. This paper presents FusDom,\na simple and novel methodology for SSL-based continued pre-training. FusDom\nlearns speech representations that are robust and adaptive yet not forgetful of\nconcepts seen in the past. Instead of solving the SSL pre-text task on the\noutput representations of a single model, FusDom leverages two identical\npre-trained SSL models, a teacher and a student, with a modified pre-training\nhead to solve the CP SSL pre-text task. This head employs a cross-attention\nmechanism between the representations of both models while only the student\nreceives gradient updates and the teacher does not. Finally, the student is\nfine-tuned for ASR. In practice, FusDom outperforms all our baselines across\nsettings significantly, with WER improvements in the range of 0.2 WER - 7.3 WER\nin the target domain while retaining the performance in the earlier domain.", "published": "2023-12-20 13:50:05", "link": "http://arxiv.org/abs/2312.13026v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Graphene: Infrastructure Security Posture Analysis with AI-generated\n  Attack Graphs", "abstract": "The rampant occurrence of cybersecurity breaches imposes substantial\nlimitations on the progress of network infrastructures, leading to compromised\ndata, financial losses, potential harm to individuals, and disruptions in\nessential services. The current security landscape demands the urgent\ndevelopment of a holistic security assessment solution that encompasses\nvulnerability analysis and investigates the potential exploitation of these\nvulnerabilities as attack paths. In this paper, we propose Graphene, an\nadvanced system designed to provide a detailed analysis of the security posture\nof computing infrastructures. Using user-provided information, such as device\ndetails and software versions, Graphene performs a comprehensive security\nassessment. This assessment includes identifying associated vulnerabilities and\nconstructing potential attack graphs that adversaries can exploit. Furthermore,\nGraphene evaluates the exploitability of these attack paths and quantifies the\noverall security posture through a scoring mechanism. The system takes a\nholistic approach by analyzing security layers encompassing hardware, system,\nnetwork, and cryptography. Furthermore, Graphene delves into the\ninterconnections between these layers, exploring how vulnerabilities in one\nlayer can be leveraged to exploit vulnerabilities in others. In this paper, we\npresent the end-to-end pipeline implemented in Graphene, showcasing the\nsystematic approach adopted for conducting this thorough security analysis.", "published": "2023-12-20 15:38:59", "link": "http://arxiv.org/abs/2312.13119v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Interactive Visual Task Learning for Robots", "abstract": "We present a framework for robots to learn novel visual concepts and tasks\nvia in-situ linguistic interactions with human users. Previous approaches have\neither used large pre-trained visual models to infer novel objects zero-shot,\nor added novel concepts along with their attributes and representations to a\nconcept hierarchy. We extend the approaches that focus on learning visual\nconcept hierarchies by enabling them to learn novel concepts and solve unseen\nrobotics tasks with them. To enable a visual concept learner to solve robotics\ntasks one-shot, we developed two distinct techniques. Firstly, we propose a\nnovel approach, Hi-Viscont(HIerarchical VISual CONcept learner for Task), which\naugments information of a novel concept to its parent nodes within a concept\nhierarchy. This information propagation allows all concepts in a hierarchy to\nupdate as novel concepts are taught in a continual learning setting. Secondly,\nwe represent a visual task as a scene graph with language annotations, allowing\nus to create novel permutations of a demonstrated task zero-shot in-situ. We\npresent two sets of results. Firstly, we compare Hi-Viscont with the baseline\nmodel (FALCON) on visual question answering(VQA) in three domains. While being\ncomparable to the baseline model on leaf level concepts, Hi-Viscont achieves an\nimprovement of over 9% on non-leaf concepts on average. We compare our model's\nperformance against the baseline FALCON model. Our framework achieves 33%\nimprovements in success rate metric, and 19% improvements in the object level\naccuracy compared to the baseline model. With both of these results we\ndemonstrate the ability of our model to learn tasks and concepts in a continual\nlearning setting on the robot.", "published": "2023-12-20 17:38:04", "link": "http://arxiv.org/abs/2312.13219v1", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "DSPy Assertions: Computational Constraints for Self-Refining Language\n  Model Pipelines", "abstract": "Chaining language model (LM) calls as composable modules is fueling a new way\nof programming, but ensuring LMs adhere to important constraints requires\nheuristic \"prompt engineering\". We introduce LM Assertions, a programming\nconstruct for expressing computational constraints that LMs should satisfy. We\nintegrate our constructs into the recent DSPy programming model for LMs, and\npresent new strategies that allow DSPy to compile programs with LM Assertions\ninto more reliable and accurate systems. We also propose strategies to use\nassertions at inference time for automatic self-refinement with LMs. We report\non four diverse case studies for text generation and find that LM Assertions\nimprove not only compliance with imposed rules but also downstream task\nperformance, passing constraints up to 164% more often and generating up to 37%\nmore higher-quality responses. Our reference implementation of LM Assertions is\nintegrated into DSPy at https://github.com/stanfordnlp/dspy", "published": "2023-12-20 19:13:26", "link": "http://arxiv.org/abs/2312.13382v2", "categories": ["cs.CL", "cs.AI", "cs.PL"], "primary_category": "cs.CL"}
{"title": "VADIS -- a VAriable Detection, Interlinking and Summarization system", "abstract": "The VADIS system addresses the demand of providing enhanced information\naccess in the domain of the social sciences. This is achieved by allowing users\nto search and use survey variables in context of their underlying research data\nand scholarly publications which have been interlinked with each other.", "published": "2023-12-20 21:02:09", "link": "http://arxiv.org/abs/2312.13423v1", "categories": ["cs.DL", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "WaveCoder: Widespread And Versatile Enhancement For Code Large Language\n  Models By Instruction Tuning", "abstract": "Recent work demonstrates that, after instruction tuning, Code Large Language\nModels (Code LLMs) can obtain impressive capabilities to address a wide range\nof code-related tasks. However, current instruction tuning methods for Code\nLLMs mainly focus on the traditional code generation task, resulting in poor\nperformance in complex multi-task scenarios. In this paper, we concentrate on\nmultiple code-related tasks and present WaveCoder, a series of Code LLMs\ntrained with Widespread And Versatile Enhanced instruction data. To enable the\nmodels to tackle complex code-related tasks, we propose a method to stably\ngenerate diverse, high-quality instruction data from open source code dataset\nin multi-task scenarios and obtain CodeSeaXDataset, a dataset comprising 19,915\ninstruction instances across 4 code-related tasks, which is aimed at improving\nthe generalization ability of Code LLM. Our experiments demonstrate that\nWaveCoder models significantly outperform other open-source models in terms of\nthe generalization ability across different code-related tasks. Moreover,\nWaveCoder-Ultra-6.7B presents the state-of-the-art generalization abilities on\na wide range of code-related tasks.", "published": "2023-12-20 09:02:29", "link": "http://arxiv.org/abs/2312.14187v5", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Explainable Multimodal Sentiment Analysis on Bengali Memes", "abstract": "Memes have become a distinctive and effective form of communication in the\ndigital era, attracting online communities and cutting across cultural\nbarriers. Even though memes are frequently linked with humor, they have an\namazing capacity to convey a wide range of emotions, including happiness,\nsarcasm, frustration, and more. Understanding and interpreting the sentiment\nunderlying memes has become crucial in the age of information. Previous\nresearch has explored text-based, image-based, and multimodal approaches,\nleading to the development of models like CAPSAN and PromptHate for detecting\nvarious meme categories. However, the study of low-resource languages like\nBengali memes remains scarce, with limited availability of publicly accessible\ndatasets. A recent contribution includes the introduction of the MemoSen\ndataset. However, the achieved accuracy is notably low, and the dataset suffers\nfrom imbalanced distribution. In this study, we employed a multimodal approach\nusing ResNet50 and BanglishBERT and achieved a satisfactory result of 0.71\nweighted F1-score, performed comparison with unimodal approaches, and\ninterpreted behaviors of the models using explainable artificial intelligence\n(XAI) techniques.", "published": "2023-12-20 17:15:10", "link": "http://arxiv.org/abs/2401.09446v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "dIR -- Discrete Information Retrieval: Conversational Search over\n  Unstructured (and Structured) Data with Large Language Models", "abstract": "Data is stored in both structured and unstructured form. Querying both, to\npower natural language conversations, is a challenge. This paper introduces\ndIR, Discrete Information Retrieval, providing a unified interface to query\nboth free text and structured knowledge. Specifically, a Large Language Model\n(LLM) transforms text into expressive representation. After the text is\nextracted into columnar form, it can then be queried via a text-to-SQL Semantic\nParser, with an LLM converting natural language into SQL. Where desired, such\nconversation may be effected by a multi-step reasoning conversational agent. We\nvalidate our approach via a proprietary question/answer data set, concluding\nthat dIR makes a whole new class of queries on free text possible when compared\nto traditionally fine-tuned dense-embedding-model-based Information Retrieval\n(IR) and SQL-based Knowledge Bases (KB). For sufficiently complex queries, dIR\ncan succeed where no other method stands a chance.", "published": "2023-12-20 18:41:44", "link": "http://arxiv.org/abs/2312.13264v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unconstrained Dysfluency Modeling for Dysfluent Speech Transcription and\n  Detection", "abstract": "Dysfluent speech modeling requires time-accurate and silence-aware\ntranscription at both the word-level and phonetic-level. However, current\nresearch in dysfluency modeling primarily focuses on either transcription or\ndetection, and the performance of each aspect remains limited. In this work, we\npresent an unconstrained dysfluency modeling (UDM) approach that addresses both\ntranscription and detection in an automatic and hierarchical manner. UDM\neliminates the need for extensive manual annotation by providing a\ncomprehensive solution. Furthermore, we introduce a simulated dysfluent dataset\ncalled VCTK++ to enhance the capabilities of UDM in phonetic transcription. Our\nexperimental results demonstrate the effectiveness and robustness of our\nproposed methods in both transcription and detection tasks.", "published": "2023-12-20 07:20:46", "link": "http://arxiv.org/abs/2312.12810v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CST-former: Transformer with Channel-Spectro-Temporal Attention for\n  Sound Event Localization and Detection", "abstract": "Sound event localization and detection (SELD) is a task for the\nclassification of sound events and the localization of direction of arrival\n(DoA) utilizing multichannel acoustic signals. Prior studies employ spectral\nand channel information as the embedding for temporal attention. However, this\nusage limits the deep neural network from extracting meaningful features from\nthe spectral or spatial domains. Therefore, our investigation in this paper\npresents a novel framework termed the Channel-Spectro-Temporal Transformer\n(CST-former) that bolsters SELD performance through the independent application\nof attention mechanisms to distinct domains. The CST-former architecture\nemploys distinct attention mechanisms to independently process channel,\nspectral, and temporal information. In addition, we propose an unfolded local\nembedding (ULE) technique for channel attention (CA) to generate informative\nembedding vectors including local spectral and temporal information. Empirical\nvalidation through experimentation on the 2022 and 2023 DCASE Challenge task3\ndatasets affirms the efficacy of employing attention mechanisms separated\nacross each domain and the benefit of ULE, in enhancing SELD performance.", "published": "2023-12-20 07:49:43", "link": "http://arxiv.org/abs/2312.12821v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Underwater Acoustic Signal Recognition Based on Salient Feature", "abstract": "With the rapid advancement of technology, the recognition of underwater\nacoustic signals in complex environments has become increasingly crucial.\nCurrently, mainstream underwater acoustic signal recognition relies primarily\non time-frequency analysis to extract spectral features, finding widespread\napplications in the field. However, existing recognition methods heavily depend\non expert systems, facing limitations such as restricted knowledge bases and\nchallenges in handling complex relationships. These limitations stem from the\ncomplexity and maintenance difficulties associated with rules or inference\nengines. Recognizing the potential advantages of deep learning in handling\nintricate relationships, this paper proposes a method utilizing neural networks\nfor underwater acoustic signal recognition. The proposed approach involves\ncontinual learning of features extracted from spectra for the classification of\nunderwater acoustic signals. Deep learning models can automatically learn\nabstract features from data and continually adjust weights during training to\nenhance classification performance.", "published": "2023-12-20 16:04:02", "link": "http://arxiv.org/abs/2312.13143v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Single-channel speech enhancement using learnable loss mixup", "abstract": "Generalization remains a major problem in supervised learning of\nsingle-channel speech enhancement. In this work, we propose learnable loss\nmixup (LLM), a simple and effortless training diagram, to improve the\ngeneralization of deep learning-based speech enhancement models. Loss mixup, of\nwhich learnable loss mixup is a special variant, optimizes a mixture of the\nloss functions of random sample pairs to train a model on virtual training data\nconstructed from these pairs of samples. In learnable loss mixup, by\nconditioning on the mixed data, the loss functions are mixed using a non-linear\nmixing function automatically learned via neural parameterization. Our\nexperimental results on the VCTK benchmark show that learnable loss mixup\nachieves 3.26 PESQ, outperforming the state-of-the-art.", "published": "2023-12-20 00:25:55", "link": "http://arxiv.org/abs/2312.17255v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Voxceleb-ESP: preliminary experiments detecting Spanish celebrities from\n  their voices", "abstract": "This paper presents VoxCeleb-ESP, a collection of pointers and timestamps to\nYouTube videos facilitating the creation of a novel speaker recognition\ndataset. VoxCeleb-ESP captures real-world scenarios, incorporating diverse\nspeaking styles, noises, and channel distortions. It includes 160 Spanish\ncelebrities spanning various categories, ensuring a representative distribution\nacross age groups and geographic regions in Spain. We provide two speaker trial\nlists for speaker identification tasks, each of them with same-video or\ndifferent-video target trials respectively, accompanied by a cross-lingual\nevaluation of ResNet pretrained models. Preliminary speaker identification\nresults suggest that the complexity of the detection task in VoxCeleb-ESP is\nequivalent to that of the original and much larger VoxCeleb in English.\nVoxCeleb-ESP contributes to the expansion of speaker recognition benchmarks\nwith a comprehensive and diverse dataset for the Spanish language.", "published": "2023-12-20 11:55:06", "link": "http://arxiv.org/abs/2401.09441v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
