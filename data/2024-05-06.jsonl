{"title": "Compressing Long Context for Enhancing RAG with AMR-based Concept\n  Distillation", "abstract": "Large Language Models (LLMs) have made significant strides in information\nacquisition. However, their overreliance on potentially flawed parametric\nknowledge leads to hallucinations and inaccuracies, particularly when handling\nlong-tail, domain-specific queries. Retrieval Augmented Generation (RAG)\naddresses this limitation by incorporating external, non-parametric knowledge.\nNevertheless, the retrieved long-context documents often contain noisy,\nirrelevant information alongside vital knowledge, negatively diluting LLMs'\nattention. Inspired by the supportive role of essential concepts in\nindividuals' reading comprehension, we propose a novel concept-based RAG\nframework with the Abstract Meaning Representation (AMR)-based concept\ndistillation algorithm. The proposed algorithm compresses the cluttered raw\nretrieved documents into a compact set of crucial concepts distilled from the\ninformative nodes of AMR by referring to reliable linguistic features. The\nconcepts explicitly constrain LLMs to focus solely on vital information in the\ninference process. We conduct extensive experiments on open-domain\nquestion-answering datasets to empirically evaluate the proposed method's\neffectiveness. The results indicate that the concept-based RAG framework\noutperforms other baseline methods, particularly as the number of supporting\ndocuments increases, while also exhibiting robustness across various backbone\nLLMs. This emphasizes the distilled concepts are informative for augmenting the\nRAG process by filtering out interference information. To the best of our\nknowledge, this is the first work introducing AMR to enhance the RAG,\npresenting a potential solution to augment inference performance with\nsemantic-based context compression.", "published": "2024-05-06 00:18:43", "link": "http://arxiv.org/abs/2405.03085v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in\n  Large Language Models", "abstract": "Detecting stereotypes and biases in Large Language Models (LLMs) is crucial\nfor enhancing fairness and reducing adverse impacts on individuals or groups\nwhen these models are applied. Traditional methods, which rely on embedding\nspaces or are based on probability metrics, fall short in revealing the nuanced\nand implicit biases present in various contexts. To address this challenge, we\npropose the FairMonitor framework and adopt a static-dynamic detection method\nfor a comprehensive evaluation of stereotypes and biases in LLMs. The static\ncomponent consists of a direct inquiry test, an implicit association test, and\nan unknown situation test, including 10,262 open-ended questions with 9\nsensitive factors and 26 educational scenarios. And it is effective for\nevaluating both explicit and implicit biases. Moreover, we utilize the\nmulti-agent system to construst the dynamic scenarios for detecting subtle\nbiases in more complex and realistic setting. This component detects the biases\nbased on the interaction behaviors of LLMs across 600 varied educational\nscenarios. The experimental results show that the cooperation of static and\ndynamic methods can detect more stereotypes and biased in LLMs.", "published": "2024-05-06 01:23:07", "link": "http://arxiv.org/abs/2405.03098v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Temporal Dynamics of Emotion and Cognition in Human Translation:\n  Integrating the Task Segment Framework and the HOF Taxonomy", "abstract": "The article develops a novel generative model of the human translating mind,\ngrounded in empirical translation process data. It posits three embedded\nprocessing layers that unfold concurrently in the human mind: sequences of\nroutinized/automated processes are observable in fluent translation production,\ncognitive/reflective thoughts lead to longer keystroke pauses, while\naffective/emotional states of the mind may be identified through characteristic\npatterns of typing and gazing. Utilizing data from the CRITT Translation\nProcess Research Database (TPR-DB), the article illustrates how the temporal\nstructure of keystroke and gaze data elicits the three assumed hidden mental\nprocessing strata. The article relates this embedded generative model to\nvarious theoretical frameworks, dual-process theories and Robinson's (2023)\nideosomatic theory of translation, opening exciting new theoretical horizons\nfor Cognitive Translation Studies, grounded in empirical data and evaluation.", "published": "2024-05-06 02:07:13", "link": "http://arxiv.org/abs/2405.03111v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CRAFT: Extracting and Tuning Cultural Instructions from the Wild", "abstract": "Large language models (LLMs) have rapidly evolved as the foundation of\nvarious natural language processing (NLP) applications. Despite their wide use\ncases, their understanding of culturally-related concepts and reasoning remains\nlimited. Meantime, there is a significant need to enhance these models'\ncultural reasoning capabilities, especially concerning underrepresented\nregions. This paper introduces a novel pipeline for extracting high-quality,\nculturally-related instruction tuning datasets from vast unstructured corpora.\nWe utilize a self-instruction generation pipeline to identify cultural concepts\nand trigger instruction. By integrating with a general-purpose instruction\ntuning dataset, our model demonstrates enhanced capabilities in recognizing and\nunderstanding regional cultural nuances, thereby enhancing its reasoning\ncapabilities. We conduct experiments across three regions: Singapore, the\nPhilippines, and the United States, achieving performance improvement of up to\n6%. Our research opens new avenues for extracting cultural instruction tuning\nsets directly from unstructured data, setting a precedent for future\ninnovations in the field.", "published": "2024-05-06 03:21:55", "link": "http://arxiv.org/abs/2405.03138v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Oracle-Checker Scheme for Evaluating a Generative Large Language Model", "abstract": "This work presents a novel approach called oracle-checker scheme for\nevaluating the answer given by a generative large language model (LLM). Two\ntypes of checkers are presented. The first type of checker follows the idea of\nproperty testing. The second type of checker follows the idea of program\nchecking. Their applications are demonstrated in two separate contexts, entity\nextraction and paraphrase decision, respectively.", "published": "2024-05-06 05:36:29", "link": "http://arxiv.org/abs/2405.03170v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Philosophical Introduction to Language Models - Part II: The Way\n  Forward", "abstract": "In this paper, the second of two companion pieces, we explore novel\nphilosophical questions raised by recent progress in large language models\n(LLMs) that go beyond the classical debates covered in the first part. We focus\nparticularly on issues related to interpretability, examining evidence from\ncausal intervention methods about the nature of LLMs' internal representations\nand computations. We also discuss the implications of multimodal and modular\nextensions of LLMs, recent debates about whether such systems may meet minimal\ncriteria for consciousness, and concerns about secrecy and reproducibility in\nLLM research. Finally, we discuss whether LLM-like systems may be relevant to\nmodeling aspects of human cognition, if their architectural characteristics and\nlearning scenario are adequately constrained.", "published": "2024-05-06 07:12:45", "link": "http://arxiv.org/abs/2405.03207v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous\n  Prompt Learning", "abstract": "Model editing aims to correct outdated or erroneous knowledge in large\nlanguage models (LLMs) without the need for costly retraining. Lifelong model\nediting is the most challenging task that caters to the continuous editing\nrequirements of LLMs. Prior works primarily focus on single or batch editing;\nnevertheless, these methods fall short in lifelong editing scenarios due to\ncatastrophic knowledge forgetting and the degradation of model performance.\nAlthough retrieval-based methods alleviate these issues, they are impeded by\nslow and cumbersome processes of integrating the retrieved knowledge into the\nmodel. In this work, we introduce RECIPE, a RetriEval-augmented ContInuous\nPrompt lEarning method, to boost editing efficacy and inference efficiency in\nlifelong learning. RECIPE first converts knowledge statements into short and\ninformative continuous prompts, prefixed to the LLM's input query embedding, to\nefficiently refine the response grounded on the knowledge. It further\nintegrates the Knowledge Sentinel (KS) that acts as an intermediary to\ncalculate a dynamic threshold, determining whether the retrieval repository\ncontains relevant knowledge. Our retriever and prompt encoder are jointly\ntrained to achieve editing properties, i.e., reliability, generality, and\nlocality. In our experiments, RECIPE is assessed extensively across multiple\nLLMs and editing datasets, where it achieves superior editing performance.\nRECIPE also demonstrates its capability to maintain the overall performance of\nLLMs alongside showcasing fast editing and inference speed.", "published": "2024-05-06 08:52:11", "link": "http://arxiv.org/abs/2405.03279v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explainable Fake News Detection With Large Language Model via Defense\n  Among Competing Wisdom", "abstract": "Most fake news detection methods learn latent feature representations based\non neural networks, which makes them black boxes to classify a piece of news\nwithout giving any justification. Existing explainable systems generate\nveracity justifications from investigative journalism, which suffer from\ndebunking delayed and low efficiency. Recent studies simply assume that the\njustification is equivalent to the majority opinions expressed in the wisdom of\ncrowds. However, the opinions typically contain some inaccurate or biased\ninformation since the wisdom of crowds is uncensored. To detect fake news from\na sea of diverse, crowded and even competing narratives, in this paper, we\npropose a novel defense-based explainable fake news detection framework.\nSpecifically, we first propose an evidence extraction module to split the\nwisdom of crowds into two competing parties and respectively detect salient\nevidences. To gain concise insights from evidences, we then design a\nprompt-based module that utilizes a large language model to generate\njustifications by inferring reasons towards two possible veracities. Finally,\nwe propose a defense-based inference module to determine veracity via modeling\nthe defense among these justifications. Extensive experiments conducted on two\nreal-world benchmarks demonstrate that our proposed method outperforms\nstate-of-the-art baselines in terms of fake news detection and provides\nhigh-quality justifications.", "published": "2024-05-06 11:24:13", "link": "http://arxiv.org/abs/2405.03371v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The high dimensional psychological profile and cultural bias of ChatGPT", "abstract": "Given the rapid advancement of large-scale language models, artificial\nintelligence (AI) models, like ChatGPT, are playing an increasingly prominent\nrole in human society. However, to ensure that artificial intelligence models\nbenefit human society, we must first fully understand the similarities and\ndifferences between the human-like characteristics exhibited by artificial\nintelligence models and real humans, as well as the cultural stereotypes and\nbiases that artificial intelligence models may exhibit in the process of\ninteracting with humans. This study first measured ChatGPT in 84 dimensions of\npsychological characteristics, revealing differences between ChatGPT and human\nnorms in most dimensions as well as in high-dimensional psychological\nrepresentations. Additionally, through the measurement of ChatGPT in 13\ndimensions of cultural values, it was revealed that ChatGPT's cultural value\npatterns are dissimilar to those of various countries/regions worldwide.\nFinally, an analysis of ChatGPT's performance in eight decision-making tasks\ninvolving interactions with humans from different countries/regions revealed\nthat ChatGPT exhibits clear cultural stereotypes in most decision-making tasks\nand shows significant cultural bias in third-party punishment and ultimatum\ngames. The findings indicate that, compared to humans, ChatGPT exhibits a\ndistinct psychological profile and cultural value orientation, and it also\nshows cultural biases and stereotypes in interpersonal decision-making. Future\nresearch endeavors should emphasize enhanced technical oversight and augmented\ntransparency in the database and algorithmic training procedures to foster more\nefficient cross-cultural communication and mitigate social disparities.", "published": "2024-05-06 11:45:59", "link": "http://arxiv.org/abs/2405.03387v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of\n  Large Language Models", "abstract": "Fine-tuned Large Language Models (LLMs) often suffer from overconfidence and\npoor calibration, particularly when fine-tuned on small datasets. To address\nthese challenges, we propose a simple combination of Low-Rank Adaptation (LoRA)\nwith Gaussian Stochastic Weight Averaging (SWAG), facilitating approximate\nBayesian inference in LLMs. Through extensive testing across several Natural\nLanguage Processing (NLP) benchmarks, we demonstrate that our straightforward\nand computationally efficient approach improves model generalization and\ncalibration competitively with comparable, more sophisticated methods for\nBayesian inference in LLMs. We further show that our method exhibits greater\nrobustness against distribution shift, as reflected in its improved performance\non out-of-distribution tasks.", "published": "2024-05-06 12:44:37", "link": "http://arxiv.org/abs/2405.03425v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAmmoTH2: Scaling Instructions from the Web", "abstract": "Instruction tuning improves the reasoning abilities of large language models\n(LLMs), with data quality and scalability being the crucial factors. Most\ninstruction tuning data come from human crowd-sourcing or GPT-4 distillation.\nWe propose a paradigm to efficiently harvest 10 million naturally existing\ninstruction data from the pre-training web corpus to enhance LLM reasoning. Our\napproach involves (1) recalling relevant documents, (2) extracting\ninstruction-response pairs, and (3) refining the extracted pairs using\nopen-source LLMs. Fine-tuning base LLMs on this dataset, we build MAmmoTH2\nmodels, which significantly boost performance on reasoning benchmarks. Notably,\nMAmmoTH2-7B's (Mistral) performance increases from 11% to 36.7% on MATH and\nfrom 36% to 68.4% on GSM8K without training on any in-domain data. Further\ntraining MAmmoTH2 on public instruction tuning datasets yields MAmmoTH2-Plus,\nachieving state-of-the-art performance on several reasoning and chatbot\nbenchmarks. Our work demonstrates how to harvest large-scale, high-quality\ninstruction data without costly human annotation or GPT-4 distillation,\nproviding a new paradigm for building better instruction tuning data.", "published": "2024-05-06 15:11:38", "link": "http://arxiv.org/abs/2405.03548v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards A Human-in-the-Loop LLM Approach to Collaborative Discourse\n  Analysis", "abstract": "LLMs have demonstrated proficiency in contextualizing their outputs using\nhuman input, often matching or beating human-level performance on a variety of\ntasks. However, LLMs have not yet been used to characterize synergistic\nlearning in students' collaborative discourse. In this exploratory work, we\ntake a first step towards adopting a human-in-the-loop prompt engineering\napproach with GPT-4-Turbo to summarize and categorize students' synergistic\nlearning during collaborative discourse. Our preliminary findings suggest\nGPT-4-Turbo may be able to characterize students' synergistic learning in a\nmanner comparable to humans and that our approach warrants further\ninvestigation.", "published": "2024-05-06 17:53:33", "link": "http://arxiv.org/abs/2405.03677v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Anti-Semitic Hate Speech using Transformer-based Large\n  Language Models", "abstract": "Academic researchers and social media entities grappling with the\nidentification of hate speech face significant challenges, primarily due to the\nvast scale of data and the dynamic nature of hate speech. Given the ethical and\npractical limitations of large predictive models like ChatGPT in directly\naddressing such sensitive issues, our research has explored alternative\nadvanced transformer-based and generative AI technologies since 2019.\nSpecifically, we developed a new data labeling technique and established a\nproof of concept targeting anti-Semitic hate speech, utilizing a variety of\ntransformer models such as BERT (arXiv:1810.04805), DistillBERT\n(arXiv:1910.01108), RoBERTa (arXiv:1907.11692), and LLaMA-2 (arXiv:2307.09288),\ncomplemented by the LoRA fine-tuning approach (arXiv:2106.09685). This paper\ndelineates and evaluates the comparative efficacy of these cutting-edge methods\nin tackling the intricacies of hate speech detection, highlighting the need for\nresponsible and carefully managed AI applications within sensitive contexts.", "published": "2024-05-06 19:00:31", "link": "http://arxiv.org/abs/2405.03794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ERAGent: Enhancing Retrieval-Augmented Language Models with Improved\n  Accuracy, Efficiency, and Personalization", "abstract": "Retrieval-augmented generation (RAG) for language models significantly\nimproves language understanding systems. The basic retrieval-then-read pipeline\nof response generation has evolved into a more extended process due to the\nintegration of various components, sometimes even forming loop structures.\nDespite its advancements in improving response accuracy, challenges like poor\nretrieval quality for complex questions that require the search of multifaceted\nsemantic information, inefficiencies in knowledge re-retrieval during long-term\nserving, and lack of personalized responses persist. Motivated by transcending\nthese limitations, we introduce ERAGent, a cutting-edge framework that embodies\nan advancement in the RAG area. Our contribution is the introduction of the\nsynergistically operated module: Enhanced Question Rewriter and Knowledge\nFilter, for better retrieval quality. Retrieval Trigger is incorporated to\ncurtail extraneous external knowledge retrieval without sacrificing response\nquality. ERAGent also personalizes responses by incorporating a learned user\nprofile. The efficiency and personalization characteristics of ERAGent are\nsupported by the Experiential Learner module which makes the AI assistant being\ncapable of expanding its knowledge and modeling user profile incrementally.\nRigorous evaluations across six datasets and three question-answering tasks\nprove ERAGent's superior accuracy, efficiency, and personalization, emphasizing\nits potential to advance the RAG field and its applicability in practical\nsystems.", "published": "2024-05-06 04:42:18", "link": "http://arxiv.org/abs/2405.06683v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multigenre AI-powered Story Composition", "abstract": "This paper shows how to construct genre patterns, whose purpose is to guide\ninteractive story composition in a way that enforces thematic consistency. To\nstart the discussion we argue, based on previous seminal works, for the\nexistence of five fundamental genres, namely comedy, romance - in the sense of\nepic plots, flourishing since the twelfth century -, tragedy, satire, and\nmystery. To construct the patterns, a simple two-phase process is employed:\nfirst retrieving examples that match our genre characterizations, and then\napplying a form of most specific generalization to the groups of examples in\norder to find their commonalities. In both phases, AI agents are instrumental,\nwith our PatternTeller prototype being called to operate the story composition\nprocess, offering the opportunity to generate stories from a given premise of\nthe user, to be developed under the guidance of the chosen pattern and trying\nto accommodate the user's suggestions along the composition stages.", "published": "2024-05-06 12:54:41", "link": "http://arxiv.org/abs/2405.06685v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hire Me or Not? Examining Language Model's Behavior with Occupation\n  Attributes", "abstract": "With the impressive performance in various downstream tasks, large language\nmodels (LLMs) have been widely integrated into production pipelines, like\nrecruitment and recommendation systems. A known issue of models trained on\nnatural language data is the presence of human biases, which can impact the\nfairness of the system. This paper investigates LLMs' behavior with respect to\ngender stereotypes, in the context of occupation decision making. Our framework\nis designed to investigate and quantify the presence of gender stereotypes in\nLLMs' behavior via multi-round question answering. Inspired by prior works, we\nconstruct a dataset by leveraging a standard occupation classification\nknowledge base released by authoritative agencies. We tested three LLMs\n(RoBERTa-large, GPT-3.5-turbo, and Llama2-70b-chat) and found that all models\nexhibit gender stereotypes analogous to human biases, but with different\npreferences. The distinct preferences of GPT-3.5-turbo and Llama2-70b-chat may\nimply the current alignment methods are insufficient for debiasing and could\nintroduce new biases contradicting the traditional gender stereotypes.", "published": "2024-05-06 18:09:32", "link": "http://arxiv.org/abs/2405.06687v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Emotional Trends from X platform using SenticNet: A\n  Comparative Analysis with Cryptocurrency Price", "abstract": "This study delves into the relationship between emotional trends from X\nplatform data and the market dynamics of well-known cryptocurrencies Cardano,\nBinance, Fantom, Matic, and Ripple over the period from October 2022 to March\n2023. Leveraging SenticNet, we identified emotions like Fear and Anxiety, Rage\nand Anger, Grief and Sadness, Delight and Pleasantness, Enthusiasm and\nEagerness, and Delight and Joy. Following data extraction, we segmented each\nmonth into bi-weekly intervals, replicating this process for price data\nobtained from Finance-Yahoo. Consequently, a comparative analysis was\nconducted, establishing connections between emotional trends observed across\nbi-weekly intervals and cryptocurrency prices, uncovering significant\ncorrelations between emotional sentiments and coin valuations.", "published": "2024-05-06 00:18:35", "link": "http://arxiv.org/abs/2405.03084v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Lory: Fully Differentiable Mixture-of-Experts for Autoregressive\n  Language Model Pre-training", "abstract": "Mixture-of-experts (MoE) models facilitate efficient scaling; however,\ntraining the router network introduces the challenge of optimizing a\nnon-differentiable, discrete objective. Recently, a fully-differentiable MoE\narchitecture, SMEAR, was proposed (Muqeeth et al., 2023), which softly merges\nexperts in the parameter space; nevertheless, its effectiveness was only\ndemonstrated in downstream fine-tuning on classification tasks. In this paper,\nwe present Lory, the first approach that scales such architectures to\nautoregressive language model pre-training. Lory introduces two key techniques:\n(1) a causal segment routing strategy that achieves high efficiency for expert\nmerging operations while preserving the autoregressive nature of language\nmodels; (2) a similarity-based data batching method that encourages expert\nspecialization by grouping similar documents in training instances. We\npre-train a series of Lory models on 150B tokens from scratch, with up to 32\nexperts and 30B (1.5B active) parameters. Experimental results show significant\nperformance gains over parameter-matched dense models on both perplexity\n(+13.9%) and a variety of downstream tasks (+1.5%-11.1%). Despite segment-level\nrouting, Lory models achieve competitive performance compared to\nstate-of-the-art MoE models with token-level routing. We further demonstrate\nthat the trained experts in Lory capture domain-level specialization without\nsupervision. Our work highlights the potential of fully-differentiable MoE\narchitectures for language model pre-training and advocates future research in\nthis area.", "published": "2024-05-06 03:06:33", "link": "http://arxiv.org/abs/2405.03133v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Vietnamese AI Generated Text Detection", "abstract": "In recent years, Large Language Models (LLMs) have become integrated into our\ndaily lives, serving as invaluable assistants in completing tasks. Widely\nembraced by users, the abuse of LLMs is inevitable, particularly in using them\nto generate text content for various purposes, leading to difficulties in\ndistinguishing between text generated by LLMs and that written by humans. In\nthis study, we present a dataset named ViDetect, comprising 6.800 samples of\nVietnamese essay, with 3.400 samples authored by humans and the remainder\ngenerated by LLMs, serving the purpose of detecting text generated by AI. We\nconducted evaluations using state-of-the-art methods, including ViT5, BartPho,\nPhoBERT, mDeberta V3, and mBERT. These results contribute not only to the\ngrowing body of research on detecting text generated by AI but also demonstrate\nthe adaptability and effectiveness of different methods in the Vietnamese\nlanguage context. This research lays the foundation for future advancements in\nAI-generated text detection and provides valuable insights for researchers in\nthe field of natural language processing.", "published": "2024-05-06 07:12:22", "link": "http://arxiv.org/abs/2405.03206v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AlphaMath Almost Zero: Process Supervision without Process", "abstract": "Although recent advancements in large language models (LLMs) have\nsignificantly improved their performance on various tasks, they still face\nchallenges with complex and symbolic multi-step reasoning, particularly in\nmathematical reasoning. To bolster the mathematical reasoning capabilities of\nLLMs, most existing efforts concentrate on seeking assistance from either\ndomain experts or GPT-4 for high-quality process-supervised data, which is not\nonly expensive but also labor-intensive. In our study, we propose an innovative\nframework, AlphaMath, that bypasses the need for process annotations (from\nhumans or GPTs) by leveraging Monte Carlo Tree Search (MCTS). This framework\nfocuses on unleashing the potential of a well-pretrained LLM to autonomously\nenhance its mathematical reasoning. Specifically, we integrate a value model\nwith the LLM, automatically generating both process supervision and step-level\nevaluation signals in MCTS. Furthermore, we propose an efficient inference\nstrategy, step-level beam search, where the value model is crafted to assist\nthe policy model (i.e., LLM) in navigating more effective reasoning paths,\nrather than solely relying on prior probabilities. The experimental results on\nboth in-domain and out-of-domain datasets demonstrate that even without GPT-4\nor human-annotated process supervision, our AlphaMath framework achieves\ncomparable or superior results to previous state-of-the-art methods.", "published": "2024-05-06 15:20:30", "link": "http://arxiv.org/abs/2405.03553v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enabling High-Sparsity Foundational Llama Models with Efficient\n  Pretraining and Deployment", "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP), but their size creates computational bottlenecks. We introduce a novel\napproach to create accurate, sparse foundational versions of performant LLMs\nthat achieve full accuracy recovery for fine-tuning tasks at up to 70%\nsparsity. We achieve this for the LLaMA-2 7B model by combining the SparseGPT\none-shot pruning method and sparse pretraining of those models on a subset of\nthe SlimPajama dataset mixed with a Python subset of The Stack dataset. We\nexhibit training acceleration due to sparsity on Cerebras CS-3 chips that\nclosely matches theoretical scaling. In addition, we establish inference\nacceleration of up to 3x on CPUs by utilizing Neural Magic's DeepSparse engine\nand 1.7x on GPUs through Neural Magic's nm-vllm engine. The above gains are\nrealized via sparsity alone, thus enabling further gains through additional use\nof quantization. Specifically, we show a total speedup on CPUs for\nsparse-quantized LLaMA models of up to 8.6x. We demonstrate these results\nacross diverse, challenging tasks, including chat, instruction following, code\ngeneration, arithmetic reasoning, and summarization to prove their generality.\nThis work paves the way for rapidly creating smaller and faster LLMs without\nsacrificing accuracy.", "published": "2024-05-06 16:03:32", "link": "http://arxiv.org/abs/2405.03594v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GREEN: Generative Radiology Report Evaluation and Error Notation", "abstract": "Evaluating radiology reports is a challenging problem as factual correctness\nis extremely important due to the need for accurate medical communication about\nmedical images. Existing automatic evaluation metrics either suffer from\nfailing to consider factual correctness (e.g., BLEU and ROUGE) or are limited\nin their interpretability (e.g., F1CheXpert and F1RadGraph). In this paper, we\nintroduce GREEN (Generative Radiology Report Evaluation and Error Notation), a\nradiology report generation metric that leverages the natural language\nunderstanding of language models to identify and explain clinically significant\nerrors in candidate reports, both quantitatively and qualitatively. Compared to\ncurrent metrics, GREEN offers: 1) a score aligned with expert preferences, 2)\nhuman interpretable explanations of clinically significant errors, enabling\nfeedback loops with end-users, and 3) a lightweight open-source method that\nreaches the performance of commercial counterparts. We validate our GREEN\nmetric by comparing it to GPT-4, as well as to error counts of 6 experts and\npreferences of 2 experts. Our method demonstrates not only higher correlation\nwith expert error counts, but simultaneously higher alignment with expert\npreferences when compared to previous approaches.", "published": "2024-05-06 16:04:03", "link": "http://arxiv.org/abs/2405.03595v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models Reveal Information Operation Goals, Tactics, and\n  Narrative Frames", "abstract": "Adversarial information operations can destabilize societies by undermining\nfair elections, manipulating public opinions on policies, and promoting scams.\nDespite their widespread occurrence and potential impacts, our understanding of\ninfluence campaigns is limited by manual analysis of messages and subjective\ninterpretation of their observable behavior. In this paper, we explore whether\nthese limitations can be mitigated with large language models (LLMs), using\nGPT-3.5 as a case-study for coordinated campaign annotation. We first use\nGPT-3.5 to scrutinize 126 identified information operations spanning over a\ndecade. We utilize a number of metrics to quantify the close (if imperfect)\nagreement between LLM and ground truth descriptions. We next extract\ncoordinated campaigns from two large multilingual datasets from X (formerly\nTwitter) that respectively discuss the 2022 French election and 2023 Balikaran\nPhilippine-U.S. military exercise in 2023. For each coordinated campaign, we\nuse GPT-3.5 to analyze posts related to a specific concern and extract goals,\ntactics, and narrative frames, both before and after critical events (such as\nthe date of an election). While the GPT-3.5 sometimes disagrees with subjective\ninterpretation, its ability to summarize and interpret demonstrates LLMs'\npotential to extract higher-order indicators from text to provide a more\ncomplete picture of the information campaigns compared to previous methods.", "published": "2024-05-06 17:59:07", "link": "http://arxiv.org/abs/2405.03688v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pose Priors from Language Models", "abstract": "We present a zero-shot pose optimization method that enforces accurate\nphysical contact constraints when estimating the 3D pose of humans. Our central\ninsight is that since language is often used to describe physical interaction,\nlarge pretrained text-based models can act as priors on pose estimation.\n  We can thus leverage this insight to improve pose estimation by converting\nnatural language descriptors, generated by a large multimodal model (LMM), into\ntractable losses to constrain the 3D pose optimization. Despite its simplicity,\nour method produces surprisingly compelling pose reconstructions of people in\nclose contact, correctly capturing the semantics of the social and physical\ninteractions. We demonstrate that our method rivals more complex\nstate-of-the-art approaches that require expensive human annotation of contact\npoints and training specialized models. Moreover, unlike previous approaches,\nour method provides a unified framework for resolving self-contact and\nperson-to-person contact.", "published": "2024-05-06 17:59:36", "link": "http://arxiv.org/abs/2405.03689v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GOVERN: Gradient Orientation Vote Ensemble for Multi-Teacher Reinforced\n  Distillation", "abstract": "Pre-trained language models have become an integral component of\nquestion-answering systems, achieving remarkable performance. However, for\npractical deployment, it is crucial to perform knowledge distillation to\nmaintain high performance while operating under computational constraints. In\nthis paper, we address a key question: given the importance of unsupervised\ndistillation for student model performance, how can knowledge from multiple\nteacher models be effectively ensemble during this stage without the guidance\nof labels? We propose a novel algorithm, GOVERN, to tackle this issue. GOVERN\nhas demonstrated significant improvements in both offline and online\nexperiments, enabling the student model to achieve results comparable to that\nof teacher ensembles. Our experiments show that GOVERN remarkably requires a\nmere 1\\% of the ensemble method's inference budget to achieve 99.5\\% of\nperformance. The proposed algorithm has been successfully deployed in a\nreal-world commercial question-answering system, demonstrating its real-world\napplicability.", "published": "2024-05-06 18:02:00", "link": "http://arxiv.org/abs/2405.03764v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Guylingo: The Republic of Guyana Creole Corpora", "abstract": "While major languages often enjoy substantial attention and resources, the\nlinguistic diversity across the globe encompasses a multitude of smaller,\nindigenous, and regional languages that lack the same level of computational\nsupport. One such region is the Caribbean. While commonly labeled as \"English\nspeaking\", the ex-British Caribbean region consists of a myriad of Creole\nlanguages thriving alongside English. In this paper, we present Guylingo: a\ncomprehensive corpus designed for advancing NLP research in the domain of\nCreolese (Guyanese English-lexicon Creole), the most widely spoken language in\nthe culturally rich nation of Guyana. We first outline our framework for\ngathering and digitizing this diverse corpus, inclusive of colloquial\nexpressions, idioms, and regional variations in a low-resource language. We\nthen demonstrate the challenges of training and evaluating NLP models for\nmachine translation in Creole. Lastly, we discuss the unique opportunities\npresented by recent NLP advancements for accelerating the formal adoption of\nCreole languages as official languages in the Caribbean.", "published": "2024-05-06 20:30:14", "link": "http://arxiv.org/abs/2405.03832v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Improving Customer Review Response Generation Based on LLMs", "abstract": "Previous studies have demonstrated that proactive interaction with user\nreviews has a positive impact on the perception of app users and encourages\nthem to submit revised ratings. Nevertheless, developers encounter challenges\nin managing a high volume of reviews, particularly in the case of popular apps\nwith a substantial influx of daily reviews. Consequently, there is a demand for\nautomated solutions aimed at streamlining the process of responding to user\nreviews. To address this, we have developed a new system for generating\nautomatic responses by leveraging user-contributed documents with the help of\nretrieval-augmented generation (RAG) and advanced Large Language Models (LLMs).\nOur solution, named SCRABLE, represents an adaptive customer review response\nautomation that enhances itself with self-optimizing prompts and a judging\nmechanism based on LLMs. Additionally, we introduce an automatic scoring\nmechanism that mimics the role of a human evaluator to assess the quality of\nresponses generated in customer review domains. Extensive experiments and\nanalyses conducted on real-world datasets reveal that our method is effective\nin producing high-quality responses, yielding improvement of more than 8.5%\ncompared to the baseline. Further validation through manual examination of the\ngenerated responses underscores the efficacy our proposed system.", "published": "2024-05-06 20:50:17", "link": "http://arxiv.org/abs/2405.03845v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Persona Inconstancy in Multi-Agent LLM Collaboration: Conformity,\n  Confabulation, and Impersonation", "abstract": "Multi-agent AI systems can be used for simulating collective decision-making\nin scientific and practical applications. They can also be used to introduce a\ndiverse group discussion step in chatbot pipelines, enhancing the cultural\nsensitivity of the chatbot's responses. These applications, however, are\npredicated on the ability of AI agents to reliably adopt assigned personas and\nmimic human interactions. To see whether LLM agents satisfy these requirements,\nwe examine AI agent ensembles engaged in cross-national collaboration and\ndebate by analyzing their private responses and chat transcripts. Our findings\nsuggest that multi-agent discussions can support collective AI decisions that\nmore often reflect diverse perspectives, yet this effect is tempered by the\nagents' susceptibility to conformity due to perceived peer pressure and\noccasional challenges in maintaining consistent personas and opinions.\nInstructions that encourage debate in support of one's opinions rather than\ncollaboration increase the rate of inconstancy. Without addressing the factors\nwe identify, the full potential of multi-agent frameworks for producing more\nculturally diverse AI outputs or more realistic simulations of group\ndecision-making may remain untapped.", "published": "2024-05-06 21:20:35", "link": "http://arxiv.org/abs/2405.03862v3", "categories": ["cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Word2World: Generating Stories and Worlds through Large Language Models", "abstract": "Large Language Models (LLMs) have proven their worth across a diverse\nspectrum of disciplines. LLMs have shown great potential in Procedural Content\nGeneration (PCG) as well, but directly generating a level through a pre-trained\nLLM is still challenging. This work introduces Word2World, a system that\nenables LLMs to procedurally design playable games through stories, without any\ntask-specific fine-tuning. Word2World leverages the abilities of LLMs to create\ndiverse content and extract information. Combining these abilities, LLMs can\ncreate a story for the game, design narrative, and place tiles in appropriate\nplaces to create coherent worlds and playable games. We test Word2World with\ndifferent LLMs and perform a thorough ablation study to validate each step. We\nopen-source the code at https://github.com/umair-nasir14/Word2World.", "published": "2024-05-06 14:21:52", "link": "http://arxiv.org/abs/2405.06686v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning\n  in Large Language Models", "abstract": "LLMs have been found to memorize training textual sequences and regurgitate\nverbatim said sequences during text generation time. This fact is known to be\nthe cause of privacy and related (e.g., copyright) problems. Unlearning in LLMs\nthen takes the form of devising new algorithms that will properly deal with\nthese side-effects of memorized data, while not hurting the model's utility. We\noffer a fresh perspective towards this goal, namely, that each textual sequence\nto be forgotten should be treated differently when being unlearned based on its\ndegree of memorization within the LLM. We contribute a new metric for measuring\nunlearning quality, an adversarial attack showing that SOTA algorithms lacking\nthis perspective fail for privacy, and two new unlearning methods based on\nGradient Ascent and Task Arithmetic, respectively. A comprehensive performance\nevaluation across an extensive suite of NLP tasks then mapped the solution\nspace, identifying the best solutions under different scales in model\ncapacities and forget set sizes and quantified the gains of the new approaches.", "published": "2024-05-06 01:21:50", "link": "http://arxiv.org/abs/2405.03097v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Quantifying the Capabilities of LLMs across Scale and Precision", "abstract": "Scale is often attributed as one of the factors that cause an increase in the\nperformance of LLMs, resulting in models with billion and trillion parameters.\nOne of the limitations of such large models is the high computational\nrequirements that limit their usage, deployment, and debugging in\nresource-constrained scenarios. Two commonly used alternatives to bypass these\nlimitations are to use the smaller versions of LLMs (e.g. Llama 7B instead of\nLlama 70B) and lower the memory requirements by using quantization. While these\napproaches effectively address the limitation of resources, their impact on\nmodel performance needs thorough examination. In this study, we perform a\ncomprehensive evaluation to investigate the effect of model scale and\nquantization on the performance. We experiment with two major families of\nopen-source instruct models ranging from 7 billion to 70 billion parameters.\nOur extensive zero-shot experiments across various tasks including natural\nlanguage understanding, reasoning, misinformation detection, and hallucination\nreveal that larger models generally outperform their smaller counterparts,\nsuggesting that scale remains an important factor in enhancing performance. We\nfound that larger models show exceptional resilience to precision reduction and\ncan maintain high accuracy even at 4-bit quantization for numerous tasks and\nthey serve as a better solution than using smaller models at high precision\nunder similar memory requirements.", "published": "2024-05-06 03:42:34", "link": "http://arxiv.org/abs/2405.03146v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Exploring the Potential of the Large Language Models (LLMs) in\n  Identifying Misleading News Headlines", "abstract": "In the digital age, the prevalence of misleading news headlines poses a\nsignificant challenge to information integrity, necessitating robust detection\nmechanisms. This study explores the efficacy of Large Language Models (LLMs) in\nidentifying misleading versus non-misleading news headlines. Utilizing a\ndataset of 60 articles, sourced from both reputable and questionable outlets\nacross health, science & tech, and business domains, we employ three LLMs-\nChatGPT-3.5, ChatGPT-4, and Gemini-for classification. Our analysis reveals\nsignificant variance in model performance, with ChatGPT-4 demonstrating\nsuperior accuracy, especially in cases with unanimous annotator agreement on\nmisleading headlines. The study emphasizes the importance of human-centered\nevaluation in developing LLMs that can navigate the complexities of\nmisinformation detection, aligning technical proficiency with nuanced human\njudgment. Our findings contribute to the discourse on AI ethics, emphasizing\nthe need for models that are not only technically advanced but also ethically\naligned and sensitive to the subtleties of human interpretation.", "published": "2024-05-06 04:06:45", "link": "http://arxiv.org/abs/2405.03153v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Advancing Multimodal Medical Capabilities of Gemini", "abstract": "Many clinical tasks require an understanding of specialized data, such as\nmedical images and genomics, which is not typically found in general-purpose\nlarge multimodal models. Building upon Gemini's multimodal models, we develop\nseveral models within the new Med-Gemini family that inherit core capabilities\nof Gemini and are optimized for medical use via fine-tuning with 2D and 3D\nradiology, histopathology, ophthalmology, dermatology and genomic data.\nMed-Gemini-2D sets a new standard for AI-based chest X-ray (CXR) report\ngeneration based on expert evaluation, exceeding previous best results across\ntwo separate datasets by an absolute margin of 1% and 12%, where 57% and 96% of\nAI reports on normal cases, and 43% and 65% on abnormal cases, are evaluated as\n\"equivalent or better\" than the original radiologists' reports. We demonstrate\nthe first ever large multimodal model-based report generation for 3D computed\ntomography (CT) volumes using Med-Gemini-3D, with 53% of AI reports considered\nclinically acceptable, although additional research is needed to meet expert\nradiologist reporting quality. Beyond report generation, Med-Gemini-2D\nsurpasses the previous best performance in CXR visual question answering (VQA)\nand performs well in CXR classification and radiology VQA, exceeding SoTA or\nbaselines on 17 of 20 tasks. In histopathology, ophthalmology, and dermatology\nimage classification, Med-Gemini-2D surpasses baselines across 18 out of 20\ntasks and approaches task-specific model performance. Beyond imaging,\nMed-Gemini-Polygenic outperforms the standard linear polygenic risk score-based\napproach for disease risk prediction and generalizes to genetically correlated\ndiseases for which it has never been trained. Although further development and\nevaluation are necessary in the safety-critical medical domain, our results\nhighlight the potential of Med-Gemini across a wide range of medical tasks.", "published": "2024-05-06 04:44:22", "link": "http://arxiv.org/abs/2405.03162v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice\n  Questions", "abstract": "Large Language Models (LLMs), such as the GPT-4 and LLaMA families, have\ndemonstrated considerable success across diverse tasks, including\nmultiple-choice questions (MCQs). However, these models exhibit a positional\nbias, particularly an even worse anchored bias in the GPT-2 family, where they\nconsistently favour the first choice 'A' in MCQs during inference. This\nanchored bias challenges the integrity of GPT-2's decision-making process, as\nit skews performance based on the position rather than the content of the\nchoices in MCQs. In this study, we utilise the mechanistic interpretability\napproach to identify the internal modules within GPT-2 models responsible for\nthis bias. We focus on the Multi-Layer Perceptron (MLP) layers and attention\nheads, using the \"logit lens\" method to trace and modify the specific value\nvectors that contribute to the bias. By updating these vectors within MLP and\nrecalibrating attention patterns to neutralise the preference for the first\nchoice 'A', we effectively mitigate the anchored bias. Our interventions not\nonly mitigate the bias but also improve the overall MCQ prediction accuracy for\nthe GPT-2 family across various datasets. This work represents the first\ncomprehensive mechanistic analysis of anchored bias in MCQs within the GPT-2\nmodels, introducing targeted, minimal-intervention strategies that\nsignificantly enhance GPT2 model robustness and accuracy in MCQs. Our code is\navailable at https://github.com/ruizheliUOA/Anchored_Bias_GPT2.", "published": "2024-05-06 07:10:09", "link": "http://arxiv.org/abs/2405.03205v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language\n  Models in the Context of the Pediatric Hypertension Guideline", "abstract": "This research focuses on evaluating the non-commercial open-source large\nlanguage models (LLMs) Meditron, MedAlpaca, Mistral, and Llama-2 for their\nefficacy in interpreting medical guidelines saved in PDF format. As a specific\ntest scenario, we applied these models to the guidelines for hypertension in\nchildren and adolescents provided by the European Society of Cardiology (ESC).\nLeveraging Streamlit, a Python library, we developed a user-friendly medical\ndocument chatbot tool (MedDoc-Bot). This tool enables authorized users to\nupload PDF files and pose questions, generating interpretive responses from\nfour locally stored LLMs. A pediatric expert provides a benchmark for\nevaluation by formulating questions and responses extracted from the ESC\nguidelines. The expert rates the model-generated responses based on their\nfidelity and relevance. Additionally, we evaluated the METEOR and chrF metric\nscores to assess the similarity of model responses to reference answers. Our\nstudy found that Llama-2 and Mistral performed well in metrics evaluation.\nHowever, Llama-2 was slower when dealing with text and tabular data. In our\nhuman evaluation, we observed that responses created by Mistral, Meditron, and\nLlama-2 exhibited reasonable fidelity and relevance. This study provides\nvaluable insights into the strengths and limitations of LLMs for future\ndevelopments in medical document interpretation. Open-Source Code:\nhttps://github.com/yaseen28/MedDoc-Bot", "published": "2024-05-06 11:11:23", "link": "http://arxiv.org/abs/2405.03359v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Large Language Models (LLMs) as Agents for Augmented Democracy", "abstract": "We explore an augmented democracy system built on off-the-shelf LLMs\nfine-tuned to augment data on citizen's preferences elicited over policies\nextracted from the government programs of the two main candidates of Brazil's\n2022 presidential election. We use a train-test cross-validation setup to\nestimate the accuracy with which the LLMs predict both: a subject's individual\npolitical choices and the aggregate preferences of the full sample of\nparticipants. At the individual level, we find that LLMs predict out of sample\npreferences more accurately than a \"bundle rule\", which would assume that\ncitizens always vote for the proposals of the candidate aligned with their\nself-reported political orientation. At the population level, we show that a\nprobabilistic sample augmented by an LLM provides a more accurate estimate of\nthe aggregate preferences of a population than the non-augmented probabilistic\nsample alone. Together, these results indicates that policy preference data\naugmented using LLMs can capture nuances that transcend party lines and\nrepresents a promising avenue of research for data augmentation.", "published": "2024-05-06 13:23:57", "link": "http://arxiv.org/abs/2405.03452v3", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Language-Image Models with 3D Understanding", "abstract": "Multi-modal large language models (MLLMs) have shown incredible capabilities\nin a variety of 2D vision and language tasks. We extend MLLMs' perceptual\ncapabilities to ground and reason about images in 3-dimensional space. To that\nend, we first develop a large-scale pre-training dataset for 2D and 3D called\nLV3D by combining multiple existing 2D and 3D recognition datasets under a\ncommon task formulation: as multi-turn question-answering. Next, we introduce a\nnew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure data\nscaling makes a strong 3D perception capability without 3D specific\narchitectural design or training objective. Cube-LLM exhibits intriguing\nproperties similar to LLMs: (1) Cube-LLM can apply chain-of-thought prompting\nto improve 3D understanding from 2D context information. (2) Cube-LLM can\nfollow complex and diverse instructions and adapt to versatile input and output\nformats. (3) Cube-LLM can be visually prompted such as 2D box or a set of\ncandidate 3D boxes from specialists. Our experiments on outdoor benchmarks\ndemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3\npoints of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7\npoints on the DriveLM dataset for complex reasoning about driving scenarios,\nrespectively. Cube-LLM also shows competitive results in general MLLM\nbenchmarks such as refCOCO for 2D grounding with (87.0) average score, as well\nas visual question answering benchmarks such as VQAv2, GQA, SQA, POPE, etc. for\ncomplex reasoning. Our project is available at\nhttps://janghyuncho.github.io/Cube-LLM.", "published": "2024-05-06 17:57:27", "link": "http://arxiv.org/abs/2405.03685v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "On Adversarial Examples for Text Classification by Perturbing Latent\n  Representations", "abstract": "Recently, with the advancement of deep learning, several applications in text\nclassification have advanced significantly. However, this improvement comes\nwith a cost because deep learning is vulnerable to adversarial examples. This\nweakness indicates that deep learning is not very robust. Fortunately, the\ninput of a text classifier is discrete. Hence, it can prevent the classifier\nfrom state-of-the-art attacks. Nonetheless, previous works have generated\nblack-box attacks that successfully manipulate the discrete values of the input\nto find adversarial examples. Therefore, instead of changing the discrete\nvalues, we transform the input into its embedding vector containing real values\nto perform the state-of-the-art white-box attacks. Then, we convert the\nperturbed embedding vector back into a text and name it an adversarial example.\nIn summary, we create a framework that measures the robustness of a text\nclassifier by using the gradients of the classifier.", "published": "2024-05-06 18:45:18", "link": "http://arxiv.org/abs/2405.03789v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "68T01, 68T50", "I.2.7"], "primary_category": "cs.LG"}
{"title": "QuakeBERT: Accurate Classification of Social Media Texts for Rapid\n  Earthquake Impact Assessment", "abstract": "Social media aids disaster response but suffers from noise, hindering\naccurate impact assessment and decision making for resilient cities, which few\nstudies considered. To address the problem, this study proposes the first\ndomain-specific LLM model and an integrated method for rapid earthquake impact\nassessment. First, a few categories are introduced to classify and filter\nmicroblogs considering their relationship to the physical and social impacts of\nearthquakes, and a dataset comprising 7282 earthquake-related microblogs from\ntwenty earthquakes in different locations is developed as well. Then, with a\nsystematic analysis of various influential factors, QuakeBERT, a\ndomain-specific large language model (LLM), is developed and fine-tuned for\naccurate classification and filtering of microblogs. Meanwhile, an integrated\nmethod integrating public opinion trend analysis, sentiment analysis, and\nkeyword-based physical impact quantification is introduced to assess both the\nphysical and social impacts of earthquakes based on social media texts.\nExperiments show that data diversity and data volume dominate the performance\nof QuakeBERT and increase the macro average F1 score by 27%, while the best\nclassification model QuakeBERT outperforms the CNN- or RNN-based models by\nimproving the macro average F1 score from 60.87% to 84.33%. Finally, the\nproposed approach is applied to assess two earthquakes with the same magnitude\nand focal depth. Results show that the proposed approach can effectively\nenhance the impact assessment process by accurate detection of noisy\nmicroblogs, which enables effective post-disaster emergency responses to create\nmore resilient cities.", "published": "2024-05-06 10:52:21", "link": "http://arxiv.org/abs/2405.06684v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Sora and V-JEPA Have Not Learned The Complete Real World Model -- A\n  Philosophical Analysis of Video AIs Through the Theory of Productive\n  Imagination", "abstract": "Sora from Open AI has shown exceptional performance, yet it faces scrutiny\nover whether its technological prowess equates to an authentic comprehension of\nreality. Critics contend that it lacks a foundational grasp of the world, a\ndeficiency V-JEPA from Meta aims to amend with its joint embedding approach.\nThis debate is vital for steering the future direction of Artificial General\nIntelligence(AGI). We enrich this debate by developing a theory of productive\nimagination that generates a coherent world model based on Kantian philosophy.\nWe identify three indispensable components of the coherent world model capable\nof genuine world understanding: representations of isolated objects, an a\npriori law of change across space and time, and Kantian categories. Our\nanalysis reveals that Sora is limited because of its oversight of the a priori\nlaw of change and Kantian categories, flaws that are not rectifiable through\nscaling up the training. V-JEPA learns the context-dependent aspect of the a\npriori law of change. Yet it fails to fully comprehend Kantian categories and\nincorporate experience, leading us to conclude that neither system currently\nachieves a comprehensive world understanding. Nevertheless, each system has\ndeveloped components essential to advancing an integrated AI productive\nimagination-understanding engine. Finally, we propose an innovative training\nframework for an AI productive imagination-understanding engine, centered\naround a joint embedding system designed to transform disordered perceptual\ninput into a structured, coherent world model. Our philosophical analysis\npinpoints critical challenges within contemporary video AI technologies and a\npathway toward achieving an AI system capable of genuine world understanding,\nsuch that it can be applied for reasoning and planning in the future.", "published": "2024-05-06 18:18:13", "link": "http://arxiv.org/abs/2407.10311v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "00-68", "K.m"], "primary_category": "cs.AI"}
{"title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software\n  Engineering", "abstract": "Language model (LM) agents are increasingly being used to automate\ncomplicated tasks in digital environments. Just as humans benefit from powerful\nsoftware applications, such as integrated development environments, for complex\ntasks like software engineering, we posit that LM agents represent a new\ncategory of end users with their own needs and abilities, and would benefit\nfrom specially-built interfaces to the software they use. We investigate how\ninterface design affects the performance of language model agents. As a result\nof this exploration, we introduce SWE-agent: a system that facilitates LM\nagents to autonomously use computers to solve software engineering tasks.\nSWE-agent's custom agent-computer interface (ACI) significantly enhances an\nagent's ability to create and edit code files, navigate entire repositories,\nand execute tests and other programs. We evaluate SWE-agent on SWE-bench and\nHumanEvalFix, achieving state-of-the-art performance on both with a pass@1 rate\nof 12.5% and 87.7%, respectively, far exceeding the previous state-of-the-art\nachieved with non-interactive LMs. Finally, we provide insight on how the\ndesign of the ACI can impact agents' behavior and performance.", "published": "2024-05-06 17:41:33", "link": "http://arxiv.org/abs/2405.15793v3", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Visual Language Model based Cross-modal Semantic Communication Systems", "abstract": "Semantic Communication (SC) has emerged as a novel communication paradigm in\nrecent years, successfully transcending the Shannon physical capacity limits\nthrough innovative semantic transmission concepts. Nevertheless, extant Image\nSemantic Communication (ISC) systems face several challenges in dynamic\nenvironments, including low semantic density, catastrophic forgetting, and\nuncertain Signal-to-Noise Ratio (SNR). To address these challenges, we propose\na novel Vision-Language Model-based Cross-modal Semantic Communication\n(VLM-CSC) system. The VLM-CSC comprises three novel components: (1) Cross-modal\nKnowledge Base (CKB) is used to extract high-density textual semantics from the\nsemantically sparse image at the transmitter and reconstruct the original image\nbased on textual semantics at the receiver. The transmission of high-density\nsemantics contributes to alleviating bandwidth pressure. (2) Memory-assisted\nEncoder and Decoder (MED) employ a hybrid long/short-term memory mechanism,\nenabling the semantic encoder and decoder to overcome catastrophic forgetting\nin dynamic environments when there is a drift in the distribution of semantic\nfeatures. (3) Noise Attention Module (NAM) employs attention mechanisms to\nadaptively adjust the semantic coding and the channel coding based on SNR,\nensuring the robustness of the CSC system. The experimental simulations\nvalidate the effectiveness, adaptability, and robustness of the CSC system.", "published": "2024-05-06 08:59:16", "link": "http://arxiv.org/abs/2407.00020v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.CV"}
{"title": "Automatic Assessment of Dysarthria Using Audio-visual Vowel Graph\n  Attention Network", "abstract": "Automatic assessment of dysarthria remains a highly challenging task due to\nhigh variability in acoustic signals and the limited data. Currently, research\non the automatic assessment of dysarthria primarily focuses on two approaches:\none that utilizes expert features combined with machine learning, and the other\nthat employs data-driven deep learning methods to extract representations.\nResearch has demonstrated that expert features are effective in representing\npathological characteristics, while deep learning methods excel at uncovering\nlatent features. Therefore, integrating the advantages of expert features and\ndeep learning to construct a neural network architecture based on expert\nknowledge may be beneficial for interpretability and assessment performance. In\nthis context, the present paper proposes a vowel graph attention network based\non audio-visual information, which effectively integrates the strengths of\nexpert knowledges and deep learning. Firstly, various features were combined as\ninputs, including knowledge based acoustical features and deep learning based\npre-trained representations. Secondly, the graph network structure based on\nvowel space theory was designed, allowing for a deep exploration of spatial\ncorrelations among vowels. Finally, visual information was incorporated into\nthe model to further enhance its robustness and generalizability. The method\nexhibited superior performance in regression experiments targeting Frenchay\nscores compared to existing approaches.", "published": "2024-05-06 08:21:33", "link": "http://arxiv.org/abs/2405.03254v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Determined Multichannel Blind Source Separation with Clustered Source\n  Model", "abstract": "The independent low-rank matrix analysis (ILRMA) method stands out as a\nprominent technique for multichannel blind audio source separation. It\nleverages nonnegative matrix factorization (NMF) and nonnegative canonical\npolyadic decomposition (NCPD) to model source parameters. While it effectively\ncaptures the low-rank structure of sources, the NMF model overlooks\ninter-channel dependencies. On the other hand, NCPD preserves intrinsic\nstructure but lacks interpretable latent factors, making it challenging to\nincorporate prior information as constraints. To address these limitations, we\nintroduce a clustered source model based on nonnegative block-term\ndecomposition (NBTD). This model defines blocks as outer products of vectors\n(clusters) and matrices (for spectral structure modeling), offering\ninterpretable latent vectors. Moreover, it enables straightforward integration\nof orthogonality constraints to ensure independence among source images.\nExperimental results demonstrate that our proposed method outperforms ILRMA and\nits extensions in anechoic conditions and surpasses the original ILRMA in\nsimulated reverberant environments.", "published": "2024-05-06 02:23:34", "link": "http://arxiv.org/abs/2405.03118v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MMGER: Multi-modal and Multi-granularity Generative Error Correction\n  with LLM for Joint Accent and Speech Recognition", "abstract": "Despite notable advancements in automatic speech recognition (ASR),\nperformance tends to degrade when faced with adverse conditions. Generative\nerror correction (GER) leverages the exceptional text comprehension\ncapabilities of large language models (LLM), delivering impressive performance\nin ASR error correction, where N-best hypotheses provide valuable information\nfor transcription prediction. However, GER encounters challenges such as fixed\nN-best hypotheses, insufficient utilization of acoustic information, and\nlimited specificity to multi-accent scenarios. In this paper, we explore the\napplication of GER in multi-accent scenarios. Accents represent deviations from\nstandard pronunciation norms, and the multi-task learning framework for\nsimultaneous ASR and accent recognition (AR) has effectively addressed the\nmulti-accent scenarios, making it a prominent solution. In this work, we\npropose a unified ASR-AR GER model, named MMGER, leveraging multi-modal\ncorrection, and multi-granularity correction. Multi-task ASR-AR learning is\nemployed to provide dynamic 1-best hypotheses and accent embeddings.\nMulti-modal correction accomplishes fine-grained frame-level correction by\nforce-aligning the acoustic features of speech with the corresponding\ncharacter-level 1-best hypothesis sequence. Multi-granularity correction\nsupplements the global linguistic information by incorporating regular 1-best\nhypotheses atop fine-grained multi-modal correction to achieve coarse-grained\nutterance-level correction. MMGER effectively mitigates the limitations of GER\nand tailors LLM-based ASR error correction for the multi-accent scenarios.\nExperiments conducted on the multi-accent Mandarin KeSpeech dataset demonstrate\nthe efficacy of MMGER, achieving a 26.72% relative improvement in AR accuracy\nand a 27.55% relative reduction in ASR character error rate, compared to a\nwell-established standard baseline.", "published": "2024-05-06 04:05:19", "link": "http://arxiv.org/abs/2405.03152v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "POPDG: Popular 3D Dance Generation with PopDanceSet", "abstract": "Generating dances that are both lifelike and well-aligned with music\ncontinues to be a challenging task in the cross-modal domain. This paper\nintroduces PopDanceSet, the first dataset tailored to the preferences of young\naudiences, enabling the generation of aesthetically oriented dances. And it\nsurpasses the AIST++ dataset in music genre diversity and the intricacy and\ndepth of dance movements. Moreover, the proposed POPDG model within the iDDPM\nframework enhances dance diversity and, through the Space Augmentation\nAlgorithm, strengthens spatial physical connections between human body joints,\nensuring that increased diversity does not compromise generation quality. A\nstreamlined Alignment Module is also designed to improve the temporal alignment\nbetween dance and music. Extensive experiments show that POPDG achieves SOTA\nresults on two datasets. Furthermore, the paper also expands on current\nevaluation metrics. The dataset and code are available at\nhttps://github.com/Luke-Luo1/POPDG.", "published": "2024-05-06 05:59:30", "link": "http://arxiv.org/abs/2405.03178v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Transhuman Ansambl - Voice Beyond Language", "abstract": "In this paper we present the design and development of the Transhuman\nAnsambl, a novel interactive singing-voice interface which senses its\nenvironment and responds to vocal input with vocalisations using human voice.\nDesigned for live performance with a human performer and as a standalone sound\ninstallation, the ansambl consists of sixteen bespoke virtual singers arranged\nin a circle. When performing live, the virtual singers listen to the human\nperformer and respond to their singing by reading pitch, intonation and volume\ncues. In a standalone sound installation mode, singers use ultrasonic distance\nsensors to sense audience presence. Developed as part of the 1st author's\npractice-based PhD and artistic practice as a live performer, this work employs\nthe singing-voice to explore voice interactions in HCI beyond language, and\ninnovative ways of live performing. How is technology supporting the effect of\nintimacy produced through voice? Does the act of surrounding the audience with\nresponsive virtual singers challenge the traditional roles of\nperformer-listener? To answer these questions, we draw upon the 1st author's\nexperience with the system, and the interdisciplinary field of voice studies\nthat consider the voice as the sound medium independent of language, capable of\nenacting a reciprocal connection between bodies.", "published": "2024-05-06 03:09:51", "link": "http://arxiv.org/abs/2405.03134v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Enhancing Aeroacoustic Wind Tunnel Studies through Massive Channel\n  Upscaling with MEMS Microphones", "abstract": "This paper presents a large 6~m x 3~m aperture 7200 MEMS microphone array.\nThe array is designed so that sub-arrays with optimized point spread functions\ncan be used for beamforming and thus, enable the research of source directivity\nin wind tunnel facilities. The total array consists of modular 800 microphone\npanels, each consisting of four unique PCB board designs. This modular\narchitecture allows for the time-synchronized measurement of an arbitrary\nnumber of panels and thus, aperture size and total number of sensors. The\npanels can be installed without a gap so that the array's microphone pattern\navoids high sidelobes in the point spread function. The array's capabilities\nare evaluated on a 1:9.5 airframe half model in an open wind tunnel at DNW-NWB.\nThe total source emission is quantified and the directivity is evaluated with\nbeamforming. Additional far-field microphones are employed to validate the\nresults.", "published": "2024-05-06 09:59:20", "link": "http://arxiv.org/abs/2405.03322v1", "categories": ["cs.SD", "eess.AS", "physics.ins-det"], "primary_category": "cs.SD"}
{"title": "Fully Reversing the Shoebox Image Source Method: From Impulse Responses\n  to Room Parameters", "abstract": "We present an algorithm that fully reverses the shoebox image source method\n(ISM), a popular and widely used room impulse response (RIR) simulator for\ncuboid rooms introduced by Allen and Berkley in 1979. More precisely, given a\ndiscrete multichannel RIR generated by the shoebox ISM for a microphone array\nof known geometry, the algorithm reliably recovers the 18 input parameters.\nThese are the 3D source position, the 3 dimensions of the room, the\n6-degrees-of-freedom room translation and orientation, and an absorption\ncoefficient for each of the 6 room boundaries. The approach builds on a\nrecently proposed gridless image source localization technique combined with\nnew procedures for room axes recovery and first-order-reflection\nidentification. Extensive simulated experiments reveal that near-exact recovery\nof all parameters is achieved for a 32-element, 8.4-cm-wide spherical\nmicrophone array and a sampling rate of 16~kHz using fully randomized input\nparameters within rooms of size 2X2X2 to 10X10X5 meters. Estimation errors\ndecay towards zero when increasing the array size and sampling rate. The method\nis also shown to strongly outperform a known baseline, and its ability to\nextrapolate RIRs at new positions is demonstrated. Crucially, the approach is\nstrictly limited to low-passed discrete RIRs simulated using the vanilla\nshoebox ISM. Nonetheless, it represents to our knowledge the first algorithmic\ndemonstration that this difficult inverse problem is in-principle fully\nsolvable over a wide range of configurations.", "published": "2024-05-06 11:43:49", "link": "http://arxiv.org/abs/2405.03385v2", "categories": ["cs.SD", "eess.AS", "eess.SP", "physics.class-ph"], "primary_category": "cs.SD"}
{"title": "Whispy: Adapting STT Whisper Models to Real-Time Environments", "abstract": "Large general-purpose transformer models have recently become the mainstay in\nthe realm of speech analysis. In particular, Whisper achieves state-of-the-art\nresults in relevant tasks such as speech recognition, translation, language\nidentification, and voice activity detection. However, Whisper models are not\ndesigned to be used in real-time conditions, and this limitation makes them\nunsuitable for a vast plethora of practical applications. In this paper, we\nintroduce Whispy, a system intended to bring live capabilities to the Whisper\npretrained models. As a result of a number of architectural optimisations,\nWhispy is able to consume live audio streams and generate high level, coherent\nvoice transcriptions, while still maintaining a low computational cost. We\nevaluate the performance of our system on a large repository of publicly\navailable speech datasets, investigating how the transcription mechanism\nintroduced by Whispy impacts on the Whisper output. Experimental results show\nhow Whispy excels in robustness, promptness, and accuracy.", "published": "2024-05-06 13:55:39", "link": "http://arxiv.org/abs/2405.03484v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Space Separable Distillation for Lightweight Acoustic Scene\n  Classification", "abstract": "Acoustic scene classification (ASC) is highly important in the real world.\nRecently, deep learning-based methods have been widely employed for acoustic\nscene classification. However, these methods are currently not lightweight\nenough as well as their performance is not satisfactory. To solve these\nproblems, we propose a deep space separable distillation network. Firstly, the\nnetwork performs high-low frequency decomposition on the log-mel spectrogram,\nsignificantly reducing computational complexity while maintaining model\nperformance. Secondly, we specially design three lightweight operators for ASC,\nincluding Separable Convolution (SC), Orthonormal Separable Convolution (OSC),\nand Separable Partial Convolution (SPC). These operators exhibit highly\nefficient feature extraction capabilities in acoustic scene classification\ntasks. The experimental results demonstrate that the proposed method achieves a\nperformance gain of 9.8% compared to the currently popular deep learning\nmethods, while also having smaller parameter count and computational\ncomplexity.", "published": "2024-05-06 15:41:41", "link": "http://arxiv.org/abs/2405.03567v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DeltaKWS: A 65nm 36nJ/Decision Bio-inspired Temporal-Sparsity-Aware\n  Digital Keyword Spotting IC with 0.6V Near-Threshold SRAM", "abstract": "This paper introduces DeltaKWS, to the best of our knowledge, the first\n$\\Delta$RNN-enabled fine-grained temporal sparsity-aware KWS IC for\nvoice-controlled devices. The 65 nm prototype chip features a number of\ntechniques to enhance performance, area, and power efficiencies, specifically:\n1) a bio-inspired delta-gated recurrent neural network ($\\Delta$RNN) classifier\nleveraging temporal similarities between neighboring feature vectors extracted\nfrom input frames and network hidden states, eliminating unnecessary operations\nand memory accesses; 2) an IIR BPF-based FEx that leverages mixed-precision\nquantization, low-cost computing structure and channel selection; 3) a 24 kB\n0.6 V near-$V_\\text{TH}$ weight SRAM that achieves 6.6X lower read power than\nthe foundry-provided SRAM. From chip measurement results, we show that the\nDeltaKWS achieves an 11/12-class GSCD accuracy of 90.5%/89.5% respectively and\nenergy consumption of 36 nJ/decision in 65 nm CMOS process. At 87% temporal\nsparsity, computing latency and energy/inference are reduced by 2.4X/3.4X,\nrespectively. The IIR BPF-based FEx, $\\Delta$RNN accelerator, and 24 kB\nnear-$V_\\text{TH}$ SRAM blocks occupy 0.084 mm$^{2}$, 0.319 mm$^{2}$, and 0.381\nmm$^{2}$ respectively (0.78 mm$^{2}$ in total).", "published": "2024-05-06 23:41:02", "link": "http://arxiv.org/abs/2405.03905v2", "categories": ["cs.AR", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.AR"}
