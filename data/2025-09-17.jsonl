{"title": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments", "abstract": "We present Apertus, a fully open suite of large language models (LLMs)\ndesigned to address two systemic shortcomings in today's open model ecosystem:\ndata compliance and multilingual representation. Unlike many prior models that\nrelease weights without reproducible data pipelines or regard for content-owner\nrights, Apertus models are pretrained exclusively on openly available data,\nretroactively respecting robots.txt exclusions and filtering for\nnon-permissive, toxic, and personally identifiable content. To mitigate risks\nof memorization, we adopt the Goldfish objective during pretraining, strongly\nsuppressing verbatim recall of data while retaining downstream task\nperformance. The Apertus models also expand multilingual coverage, training on\n15T tokens from over 1800 languages, with ~40% of pretraining data allocated to\nnon-English content. Released at 8B and 70B scales, Apertus approaches\nstate-of-the-art results among fully open models on multilingual benchmarks,\nrivalling or surpassing open-weight counterparts. Beyond model weights, we\nrelease all scientific artifacts from our development cycle with a permissive\nlicense, including data preparation scripts, checkpoints, evaluation suites,\nand training code, enabling transparent audit and extension.", "published": "2025-09-17 17:59:21", "link": "http://arxiv.org/abs/2509.14233v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language models' activations linearly encode training-order recency", "abstract": "We show that language models' activations linearly encode when information\nwas learned during training. Our setup involves creating a model with a known\ntraining order by sequentially fine-tuning Llama-3.2-1B on six disjoint but\notherwise similar datasets about named entities. We find that the average\nactivations of test samples for the six training datasets encode the training\norder: when projected into a 2D subspace, these centroids are arranged exactly\nin the order of training and lie on a straight line. Further, we show that\nlinear probes can accurately (~90%) distinguish \"early\" vs. \"late\" entities,\ngeneralizing to entities unseen during the probes' own training. The model can\nalso be fine-tuned to explicitly report an unseen entity's training stage (~80%\naccuracy). Interestingly, this temporal signal does not seem attributable to\nsimple differences in activation magnitudes, losses, or model confidence. Our\npaper demonstrates that models are capable of differentiating information by\nits acquisition time, and carries significant implications for how they might\nmanage conflicting data and respond to knowledge modifications.", "published": "2025-09-17 17:54:22", "link": "http://arxiv.org/abs/2509.14223v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing", "abstract": "Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing\ngenerative engines, such as LLM-based chatbots, by seamlessly integrating\nrelevant advertisements into their responses. At the core of GEM lies the\ngeneration and evaluation of ad-injected responses. However, existing\nbenchmarks are not specifically designed for this purpose, which limits future\nresearch. To address this gap, we propose GEM-Bench, the first comprehensive\nbenchmark for ad-injected response generation in GEM. GEM-Bench includes three\ncurated datasets covering both chatbot and search scenarios, a metric ontology\nthat captures multiple dimensions of user satisfaction and engagement, and\nseveral baseline solutions implemented within an extensible multi-agent\nframework. Our preliminary results indicate that, while simple prompt-based\nmethods achieve reasonable engagement such as click-through rate, they often\nreduce user satisfaction. In contrast, approaches that insert ads based on\npre-generated ad-free responses help mitigate this issue but introduce\nadditional overhead. These findings highlight the need for future research on\ndesigning more effective and efficient solutions for generating ad-injected\nresponses in GEM.", "published": "2025-09-17 17:53:43", "link": "http://arxiv.org/abs/2509.14221v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Dense Video Understanding with Gated Residual Tokenization", "abstract": "High temporal resolution is essential for capturing fine-grained details in\nvideo understanding. However, current video large language models (VLLMs) and\nbenchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or\nkeyframe selection, discarding dense temporal information. This compromise\navoids the high cost of tokenizing every frame, which otherwise leads to\nredundant computation and linear token growth as video length increases. While\nthis trade-off works for slowly changing content, it fails for tasks like\nlecture comprehension, where information appears in nearly every frame and\nrequires precise temporal alignment. To address this gap, we introduce Dense\nVideo Understanding (DVU), which enables high-FPS video comprehension by\nreducing both tokenization time and token overhead. Existing benchmarks are\nalso limited, as their QA pairs focus on coarse content changes. We therefore\npropose DIVE (Dense Information Video Evaluation), the first benchmark designed\nfor dense temporal reasoning. To make DVU practical, we present Gated Residual\nTokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated\nTokenization uses pixel-level motion estimation to skip static regions during\ntokenization, achieving sub-linear growth in token count and compute. (2)\nSemantic-Scene Intra-Tokenization Merging fuses tokens across static regions\nwithin a scene, further reducing redundancy while preserving dynamic semantics.\nExperiments on DIVE show that GRT outperforms larger VLLM baselines and scales\npositively with FPS. These results highlight the importance of dense temporal\ninformation and demonstrate that GRT enables efficient, scalable high-FPS video\nunderstanding.", "published": "2025-09-17 17:34:40", "link": "http://arxiv.org/abs/2509.14199v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Framing Migration: A Computational Analysis of UK Parliamentary Discourse", "abstract": "We present a large-scale computational analysis of migration-related\ndiscourse in UK parliamentary debates spanning over 75 years and compare it\nwith US congressional discourse. Using open-weight LLMs, we annotate each\nstatement with high-level stances toward migrants and track the net tone toward\nmigrants across time and political parties. For the UK, we extend this with a\nsemi-automated framework for extracting fine-grained narrative frames to\ncapture nuances of migration discourse. Our findings show that, while US\ndiscourse has grown increasingly polarised, UK parliamentary attitudes remain\nrelatively aligned across parties, with a persistent ideological gap between\nLabour and the Conservatives, reaching its most negative level in 2025. The\nanalysis of narrative frames in the UK parliamentary statements reveals a shift\ntoward securitised narratives such as border control and illegal immigration,\nwhile longer-term integration-oriented frames such as social integration have\ndeclined. Moreover, discussions of national law about immigration have been\nreplaced over time by international law and human rights, revealing nuances in\ndiscourse trends. Taken together broadly, our findings demonstrate how LLMs can\nsupport scalable, fine-grained discourse analysis in political and historical\ncontexts.", "published": "2025-09-17 17:31:57", "link": "http://arxiv.org/abs/2509.14197v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs", "abstract": "Personalized financial advice requires consideration of user goals,\nconstraints, risk tolerance, and jurisdiction. Prior LLM work has focused on\nsupport systems for investors and financial planners. Simultaneously, numerous\nrecent studies examine broader personal finance tasks, including budgeting,\ndebt management, retirement, and estate planning, through agentic pipelines\nthat incur high maintenance costs, yielding less than 25% of their expected\nfinancial returns. In this study, we introduce a novel and reproducible\nframework that integrates relevant financial context with behavioral finance\nstudies to construct supervision data for end-to-end advisors. Using this\nframework, we create a 19k sample reasoning dataset and conduct a comprehensive\nfine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test\nsplit and a blind LLM-jury study, we demonstrate that through careful data\ncuration and behavioral integration, our 8B model achieves performance\ncomparable to significantly larger baselines (14-32B parameters) across factual\naccuracy, fluency, and personalization metrics while incurring 80% lower costs\nthan the larger counterparts.", "published": "2025-09-17 17:12:38", "link": "http://arxiv.org/abs/2509.14180v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; J.4"], "primary_category": "cs.CL"}
{"title": "AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity", "abstract": "Recent advancements in multimodal large language models (MLLMs) have garnered\nsignificant attention, offering a promising pathway toward artificial general\nintelligence (AGI). Among the essential capabilities required for AGI,\ncreativity has emerged as a critical trait for MLLMs, with association serving\nas its foundation. Association reflects a model' s ability to think creatively,\nmaking it vital to evaluate and understand. While several frameworks have been\nproposed to assess associative ability, they often overlook the inherent\nambiguity in association tasks, which arises from the divergent nature of\nassociations and undermines the reliability of evaluations. To address this\nissue, we decompose ambiguity into two types-internal ambiguity and external\nambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative\nability while circumventing the ambiguity through a hybrid computational\nmethod. We then conduct extensive experiments on MLLMs, revealing a strong\npositive correlation between cognition and association. Additionally, we\nobserve that the presence of ambiguity in the evaluation process causes MLLMs'\nbehavior to become more random-like. Finally, we validate the effectiveness of\nour method in ensuring more accurate and reliable evaluations. See Project Page\nfor the data and codes.", "published": "2025-09-17 16:56:27", "link": "http://arxiv.org/abs/2509.14171v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset", "abstract": "We present CS-FLEURS, a new dataset for developing and evaluating\ncode-switched speech recognition and translation systems beyond high-resourced\nlanguages. CS-FLEURS consists of 4 test sets which cover in total 113 unique\ncode-switched language pairs across 52 languages: 1) a 14 X-English language\npair set with real voices reading synthetically generated code-switched\nsentences, 2) a 16 X-English language pair set with generative text-to-speech\n3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the\ngenerative text-to-speech, and 4) a 45 X-English lower-resourced language pair\ntest set with concatenative text-to-speech. Besides the four test sets,\nCS-FLEURS also provides a training set with 128 hours of generative\ntext-to-speech data across 16 X-English language pairs. Our hope is that\nCS-FLEURS helps to broaden the scope of future code-switched speech research.\nDataset link: https://huggingface.co/datasets/byan/cs-fleurs.", "published": "2025-09-17 16:45:22", "link": "http://arxiv.org/abs/2509.14161v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "When Avatars Have Personality: Effects on Engagement and Communication in Immersive Medical Training", "abstract": "While virtual reality (VR) excels at simulating physical environments, its\neffectiveness for training complex interpersonal skills is limited by a lack of\npsychologically plausible virtual humans. This is a critical gap in high-stakes\ndomains like medical education, where communication is a core competency. This\npaper introduces a framework that integrates large language models (LLMs) into\nimmersive VR to create medically coherent virtual patients with distinct,\nconsistent personalities, built on a modular architecture that decouples\npersonality from clinical data. We evaluated our system in a mixed-method,\nwithin-subjects study with licensed physicians who engaged in simulated\nconsultations. Results demonstrate that the approach is not only feasible but\nis also perceived by physicians as a highly rewarding and effective training\nenhancement. Furthermore, our analysis uncovers critical design principles,\nincluding a ``realism-verbosity paradox\" where less communicative agents can\nseem more artificial, and the need for challenges to be perceived as authentic\nto be instructive. This work provides a validated framework and key insights\nfor developing the next generation of socially intelligent VR training\nenvironments.", "published": "2025-09-17 16:13:37", "link": "http://arxiv.org/abs/2509.14132v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST", "abstract": "This report introduces Canary-1B-v2, a fast, robust multilingual model for\nAutomatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built\nwith a FastConformer encoder and Transformer decoder, it supports 25 languages\nprimarily European. The model was trained on 1.7M hours of total data samples,\nincluding Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce\nhallucinations for ASR and AST. We describe its two-stage pre-training and\nfine-tuning process with dynamic data balancing, as well as experiments with an\nnGPT encoder. Results show nGPT scales well with massive data, while\nFastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the\nNeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable\nsegment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2\noutperforms Whisper-large-v3 on English ASR while being 10x faster, and\ndelivers competitive multilingual ASR and AST performance against larger models\nlike Seamless-M4T-v2-large and LLM-based systems. We also release\nParakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the\nsame 25 languages with just 600M parameters.", "published": "2025-09-17 16:08:46", "link": "http://arxiv.org/abs/2509.14128v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework", "abstract": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by\nprompting intermediate steps, improving accuracy and robustness in arithmetic,\nlogic, and commonsense tasks. However, this benefit comes with high\ncomputational costs: longer outputs increase latency, memory usage, and\nKV-cache demands. These issues are especially critical in software engineering\ntasks where concise and deterministic outputs are required. To investigate\nthese trade-offs, we conduct an empirical study based on code generation\nbenchmarks. The results reveal that longer CoT does not always help. Excessive\nreasoning often causes truncation, accuracy drops, and latency up to five times\nhigher, with failed outputs consistently longer than successful ones. These\nfindings challenge the assumption that longer reasoning is inherently better\nand highlight the need for adaptive CoT control. Motivated by this, we propose\nSEER (Self-Enhancing Efficient Reasoning), an adaptive framework that\ncompresses CoT while preserving accuracy. SEER combines Best-of-N sampling with\ntask-aware adaptive filtering, dynamically adjusting thresholds based on\npre-inference outputs to reduce verbosity and computational overhead. We then\nevaluate SEER on three software engineering tasks and one math task. On\naverage, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,\nand eliminates most infinite loops. These results demonstrate SEER as a\npractical method to make CoT-enhanced LLMs more efficient and robust, even\nunder resource constraints.", "published": "2025-09-17 15:33:44", "link": "http://arxiv.org/abs/2509.14093v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching", "abstract": "Modern mobile CPU software pose challenges for conventional instruction cache\nreplacement policies due to their complex runtime behavior causing high reuse\ndistance between executions of the same instruction. Mobile code commonly\nsuffers from large amounts of stalls in the CPU frontend and thus starvation of\nthe rest of the CPU resources. Complexity of these applications and their code\nfootprint are projected to grow at a rate faster than available on-chip memory\ndue to power and area constraints, making conventional hardware-centric methods\nfor managing instruction caches to be inadequate. We present a novel\nsoftware-hardware co-design approach called TRRIP (Temperature-based\nRe-Reference Interval Prediction) that enables the compiler to analyze,\nclassify, and transform code based on \"temperature\" (hot/cold), and to provide\nthe hardware with a summary of code temperature information through a\nwell-defined OS interface based on using code page attributes. TRRIP's\nlightweight hardware extension employs code temperature attributes to optimize\nthe instruction cache replacement policy resulting in the eviction rate\nreduction of hot code. TRRIP is designed to be practical and adoptable in real\nmobile systems that have strict feature requirements on both the software and\nhardware components. TRRIP can reduce the L2 MPKI for instructions by 26.5%\nresulting in geomean speedup of 3.9%, on top of RRIP cache replacement running\nmobile code already optimized using PGO.", "published": "2025-09-17 14:42:38", "link": "http://arxiv.org/abs/2509.14041v1", "categories": ["cs.AR", "cs.CL", "cs.OS", "cs.PF"], "primary_category": "cs.AR"}
{"title": "SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation", "abstract": "Sign Language Translation (SLT) bridges the communication gap between deaf\npeople and hearing people, where dialogue provides crucial contextual cues to\naid in translation. Building on this foundational concept, this paper proposes\nQuestion-based Sign Language Translation (QB-SLT), a novel task that explores\nthe efficient integration of dialogue. Unlike gloss (sign language\ntranscription) annotations, dialogue naturally occurs in communication and is\neasier to annotate. The key challenge lies in aligning multimodality features\nwhile leveraging the context of the question to improve translation. To address\nthis issue, we propose a cross-modality Self-supervised Learning with Sigmoid\nSelf-attention Weighting (SSL-SSAW) fusion method for sign language\ntranslation. Specifically, we employ contrastive learning to align\nmultimodality features in QB-SLT, then introduce a Sigmoid Self-attention\nWeighting (SSAW) module for adaptive feature extraction from question and sign\nlanguage sequences. Additionally, we leverage available question text through\nself-supervised learning to enhance representation and translation\ncapabilities. We evaluated our approach on newly constructed CSL-Daily-QA and\nPHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,\neasily accessible question assistance can achieve or even surpass the\nperformance of gloss assistance. Furthermore, visualization results demonstrate\nthe effectiveness of incorporating dialogue in improving translation quality.", "published": "2025-09-17 14:37:59", "link": "http://arxiv.org/abs/2509.14036v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Multi-Agent Debate System Performance via Confidence Expression", "abstract": "Generative Large Language Models (LLMs) have demonstrated remarkable\nperformance across a wide range of tasks. Recent research has introduced\nMulti-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate\nhuman debate and thereby improve task performance. However, while some LLMs may\npossess superior knowledge or reasoning capabilities for specific tasks, they\noften struggle to clearly communicate this advantage during debates, in part\ndue to a lack of confidence expression. Moreover, inappropriate confidence\nexpression can cause agents in MAD systems to either stubbornly maintain\nincorrect beliefs or converge prematurely on suboptimal answers, ultimately\nreducing debate effectiveness and overall system performance. To address these\nchallenges, we propose incorporating confidence expression into MAD systems to\nallow LLMs to explicitly communicate their confidence levels. To validate this\napproach, we develop ConfMAD, a MAD framework that integrates confidence\nexpression throughout the debate process. Experimental results demonstrate the\neffectiveness of our method, and we further analyze how confidence influences\ndebate dynamics, offering insights into the design of confidence-aware MAD\nsystems.", "published": "2025-09-17 14:34:27", "link": "http://arxiv.org/abs/2509.14034v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models", "abstract": "Achieving human-level translations requires leveraging context to ensure\ncoherence and handle complex phenomena like pronoun disambiguation. Sparsity of\ncontextually rich examples in the standard training data has been hypothesized\nas the reason for the difficulty of context utilization. In this work, we\nsystematically validate this claim in both single- and multilingual settings by\nconstructing training datasets with a controlled proportions of contextually\nrelevant examples. We demonstrate a strong association between training data\nsparsity and model performance confirming sparsity as a key bottleneck.\nImportantly, we reveal that improvements in one contextual phenomenon do no\ngeneralize to others. While we observe some cross-lingual transfer, it is not\nsignificantly higher between languages within the same sub-family. Finally, we\npropose and empirically evaluate two training strategies designed to leverage\nthe available data. These strategies improve context utilization, resulting in\naccuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in\nsingle- and multilingual settings respectively.", "published": "2025-09-17 14:33:17", "link": "http://arxiv.org/abs/2509.14031v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality", "abstract": "Machine Translation (MT) has achieved remarkable performance, with growing\ninterest in speech translation and multimodal approaches. However, despite\nthese advancements, MT quality assessment remains largely text centric,\ntypically relying on human experts who read and compare texts. Since many\nreal-world MT applications (e.g Google Translate Voice Mode, iFLYTEK\nTranslator) involve translation being spoken rather printed or read, a more\nnatural way to assess translation quality would be through speech as opposed\ntext-only evaluations. This study compares text-only and audio-based\nevaluations of 10 MT systems from the WMT General MT Shared Task, using\ncrowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,\nperformed statistical significance testing and self-replication experiments to\ntest reliability and consistency of audio-based approach. Crowd-sourced\nassessments based on audio yield rankings largely consistent with text only\nevaluations but, in some cases, identify significant differences between\ntranslation systems. We attribute this to speech richer, more natural modality\nand propose incorporating speech-based assessments into future MT evaluation\nframeworks.", "published": "2025-09-17 14:27:17", "link": "http://arxiv.org/abs/2509.14023v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale", "abstract": "We present Hala, a family of Arabic-centric instruction and translation\nmodels built with our translate-and-tune pipeline. We first compress a strong\nAR$\\leftrightarrow$EN teacher to FP8 (yielding $\\sim$2$\\times$ higher\nthroughput with no quality loss) and use it to create high-fidelity bilingual\nsupervision. A lightweight language model LFM2-1.2B is then fine-tuned on this\ndata and used to translate high-quality English instruction sets into Arabic,\nproducing a million-scale corpus tailored to instruction following. We train\nHala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to\nbalance Arabic specialization with base-model strengths. On Arabic-centric\nbenchmarks, Hala achieves state-of-the-art results within both the \"nano\"\n($\\leq$2B) and \"small\" (7-9B) categories, outperforming their bases. We release\nmodels, data, evaluation, and recipes to accelerate research in Arabic NLP.", "published": "2025-09-17 14:19:28", "link": "http://arxiv.org/abs/2509.14008v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Early Stopping Chain-of-thoughts in Large Language Models", "abstract": "Reasoning large language models (LLMs) have demonstrated superior capacities\nin solving complicated problems by generating long chain-of-thoughts (CoT), but\nsuch a lengthy CoT incurs high inference costs. In this study, we introduce\nES-CoT, an inference-time method that shortens CoT generation by detecting\nanswer convergence and stopping early with minimal performance loss. At the end\nof each reasoning step, we prompt the LLM to output its current final answer,\ndenoted as a step answer. We then track the run length of consecutive identical\nstep answers as a measure of answer convergence. Once the run length exhibits a\nsharp increase and exceeds a minimum threshold, the generation is terminated.\nWe provide both empirical and theoretical support for this heuristic: step\nanswers steadily converge to the final answer, and large run-length jumps\nreliably mark this convergence. Experiments on five reasoning datasets across\nthree LLMs show that ES-CoT reduces the number of inference tokens by about\n41\\% on average while maintaining accuracy comparable to standard CoT. Further,\nES-CoT integrates seamlessly with self-consistency prompting and remains robust\nacross hyperparameter choices, highlighting it as a practical and effective\napproach for efficient reasoning.", "published": "2025-09-17 14:14:05", "link": "http://arxiv.org/abs/2509.14004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency", "abstract": "Recently, Test-Time Scaling (TTS) has gained increasing attention for\nimproving LLM reasoning performance at test time without retraining the model.\nA notable TTS technique is Self-Consistency (SC), which generates multiple\nreasoning chains in parallel and selects the final answer via majority voting.\nWhile effective, the order-of-magnitude computational overhead limits its broad\ndeployment. Prior attempts to accelerate SC mainly rely on model-based\nconfidence scores or heuristics with limited empirical support. For the first\ntime, we theoretically and empirically analyze the inefficiencies of SC and\nreveal actionable opportunities for improvement. Building on these insights, we\npropose Slim-SC, a step-wise pruning strategy that identifies and removes\nredundant chains using inter-chain similarity at the thought level. Experiments\non three STEM reasoning datasets and two recent LLM architectures show that\nSlim-SC reduces inference latency and KVC usage by up to 45% and 26%,\nrespectively, with R1-Distill, while maintaining or improving accuracy, thus\noffering a simple yet efficient TTS alternative for SC.", "published": "2025-09-17 14:00:51", "link": "http://arxiv.org/abs/2509.13990v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Long-context Reference-based MT Quality Estimation", "abstract": "In this paper, we present our submission to the Tenth Conference on Machine\nTranslation (WMT25) Shared Task on Automated Translation Quality Evaluation.\n  Our systems are built upon the COMET framework and trained to predict\nsegment-level Error Span Annotation (ESA) scores using augmented long-context\ndata.\n  To construct long-context training data, we concatenate in-domain,\nhuman-annotated sentences and compute a weighted average of their scores.\n  We integrate multiple human judgment datasets (MQM, SQM, and DA) by\nnormalising their scales and train multilingual regression models to predict\nquality scores from the source, hypothesis, and reference translations.\n  Experimental results show that incorporating long-context information\nimproves correlations with human judgments compared to models trained only on\nshort segments.", "published": "2025-09-17 13:52:45", "link": "http://arxiv.org/abs/2509.13980v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "abstract": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.", "published": "2025-09-17 13:38:40", "link": "http://arxiv.org/abs/2509.13968v1", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Enhancing Time Awareness in Generative Recommendation", "abstract": "Generative recommendation has emerged as a promising paradigm that formulates\nthe recommendations into a text-to-text generation task, harnessing the vast\nknowledge of large language models. However, existing studies focus on\nconsidering the sequential order of items and neglect to handle the temporal\ndynamics across items, which can imply evolving user preferences. To address\nthis limitation, we propose a novel model, Generative Recommender Using Time\nawareness (GRUT), effectively capturing hidden user preferences via various\ntemporal signals. We first introduce Time-aware Prompting, consisting of two\nkey contexts. The user-level temporal context models personalized temporal\npatterns across timestamps and time intervals, while the item-level transition\ncontext provides transition patterns across users. We also devise Trend-aware\nInference, a training-free method that enhances rankings by incorporating trend\ninformation about items with generation likelihood. Extensive experiments\ndemonstrate that GRUT outperforms state-of-the-art models, with gains of up to\n15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The\nsource code is available at https://github.com/skleee/GRUT.", "published": "2025-09-17 13:28:46", "link": "http://arxiv.org/abs/2509.13957v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "An Empirical Study on Failures in Automated Issue Solving", "abstract": "Automated issue solving seeks to autonomously identify and repair defective\ncode snippets across an entire codebase. SWE-Bench has emerged as the most\nwidely adopted benchmark for evaluating progress in this area. While LLM-based\nagentic tools show great promise, they still fail on a substantial portion of\ntasks. Moreover, current evaluations primarily report aggregate issue-solving\nrates, which obscure the underlying causes of success and failure, making it\nchallenging to diagnose model weaknesses or guide targeted improvements. To\nbridge this gap, we first analyze the performance and efficiency of three SOTA\ntools, spanning both pipeline-based and agentic architectures, in automated\nissue solving tasks of SWE-Bench-Verified under varying task characteristics.\nFurthermore, to move from high-level performance metrics to underlying cause\nanalysis, we conducted a systematic manual analysis of 150 failed instances.\nFrom this analysis, we developed a comprehensive taxonomy of failure modes\ncomprising 3 primary phases, 9 main categories, and 25 fine-grained\nsubcategories. Then we systematically analyze the distribution of the\nidentified failure modes, the results reveal distinct failure fingerprints\nbetween the two architectural paradigms, with the majority of agentic failures\nstemming from flawed reasoning and cognitive deadlocks. Motivated by these\ninsights, we propose a collaborative Expert-Executor framework. It introduces a\nsupervisory Expert agent tasked with providing strategic oversight and\ncourse-correction for a primary Executor agent. This architecture is designed\nto correct flawed reasoning and break the cognitive deadlocks that frequently\nlead to failure. Experiments show that our framework solves 22.2% of previously\nintractable issues for a leading single agent. These findings pave the way for\nbuilding more robust agents through diagnostic evaluation and collaborative\ndesign.", "published": "2025-09-17 13:07:52", "link": "http://arxiv.org/abs/2509.13941v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG", "abstract": "Multilingual Retrieval-Augmented Generation (mRAG) systems enable language\nmodels to answer knowledge-intensive queries with citation-supported responses\nacross languages. While such systems have been proposed, an open questions is\nwhether the mixture of different document languages impacts generation and\ncitation in unintended ways. To investigate, we introduce a controlled\nmethodology using model internals to measure language preference while holding\nother factors such as document relevance constant. Across eight languages and\nsix open-weight models, we find that models preferentially cite English sources\nwhen queries are in English, with this bias amplified for lower-resource\nlanguages and for documents positioned mid-context. Crucially, we find that\nmodels sometimes trade-off document relevance for language preference,\nindicating that citation choices are not always driven by informativeness\nalone. Our findings shed light on how language models leverage multilingual\ncontext and influence citation behavior.", "published": "2025-09-17 12:58:18", "link": "http://arxiv.org/abs/2509.13930v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Understand Word Senses?", "abstract": "Understanding the meaning of words in context is a fundamental capability for\nLarge Language Models (LLMs). Despite extensive evaluation efforts, the extent\nto which LLMs show evidence that they truly grasp word senses remains\nunderexplored. In this paper, we address this gap by evaluating both i) the\nWord Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,\ncomparing their performance to state-of-the-art systems specifically designed\nfor the task, and ii) the ability of two top-performing open- and closed-source\nLLMs to understand word senses in three generative settings: definition\ngeneration, free-form explanation, and example generation. Notably, we find\nthat, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve\nperformance on par with specialized WSD systems, while also demonstrating\ngreater robustness across domains and levels of difficulty. In the generation\ntasks, results reveal that LLMs can explain the meaning of words in context up\nto 98\\% accuracy, with the highest performance observed in the free-form\nexplanation task, which best aligns with their generative capabilities.", "published": "2025-09-17 11:11:27", "link": "http://arxiv.org/abs/2509.13905v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification", "abstract": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https://github.com/PRAISELab-PicusLab/CER", "published": "2025-09-17 10:31:09", "link": "http://arxiv.org/abs/2509.13888v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Combining Evidence and Reasoning for Biomedical Fact-Checking", "abstract": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https: //github.com/PRAISELab-PicusLab/CER.", "published": "2025-09-17 10:14:56", "link": "http://arxiv.org/abs/2509.13879v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs", "abstract": "Large language models (LLMs) can lead to undesired consequences when\nmisaligned with human values, especially in scenarios involving complex and\nsensitive social biases. Previous studies have revealed the misalignment of\nLLMs with human values using expert-designed or agent-based emulated bias\nscenarios. However, it remains unclear whether the alignment of LLMs with human\nvalues differs across different types of scenarios (e.g., scenarios containing\nnegative vs. non-negative questions). In this study, we investigate the\nalignment of LLMs with human values regarding social biases (HVSB) in different\ntypes of bias scenarios. Through extensive analysis of 12 LLMs from four model\nfamilies and four datasets, we demonstrate that LLMs with large model parameter\nscales do not necessarily have lower misalignment rate and attack success rate.\nMoreover, LLMs show a certain degree of alignment preference for specific types\nof scenarios and the LLMs from the same model family tend to have higher\njudgment consistency. In addition, we study the understanding capacity of LLMs\nwith their explanations of HVSB. We find no significant differences in the\nunderstanding of HVSB across LLMs. We also find LLMs prefer their own generated\nexplanations. Additionally, we endow smaller language models (LMs) with the\nability to explain HVSB. The generation results show that the explanations\ngenerated by the fine-tuned smaller LMs are more readable, but have a\nrelatively lower model agreeability.", "published": "2025-09-17 09:58:28", "link": "http://arxiv.org/abs/2509.13869v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection", "abstract": "Unsupervised anomalous sound detection aims to detect unknown anomalous\nsounds by training a model using only normal audio data. Despite advancements\nin self-supervised methods, the issue of frequent false alarms when handling\nsamples of the same type from different machines remains unresolved. This paper\nintroduces a novel training technique called one-stage supervised contrastive\nlearning (OS-SCL), which significantly addresses this problem by perturbing\nfeatures in the embedding space and employing a one-stage noisy supervised\ncontrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved\n94.64\\% AUC, 88.42\\% pAUC, and 89.24\\% mAUC using only Log-Mel features.\nAdditionally, a time-frequency feature named TFgram is proposed, which is\nextracted from raw audio. This feature effectively captures critical\ninformation for anomalous sound detection, ultimately achieving 95.71\\% AUC,\n90.23\\% pAUC, and 91.23\\% mAUC. The source code is available at:\n\\underline{www.github.com/huangswt/OS-SCL}.", "published": "2025-09-17 09:38:47", "link": "http://arxiv.org/abs/2509.13853v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models", "abstract": "Object hallucination in Large Vision-Language Models (LVLMs) significantly\nimpedes their real-world applicability. As the primary component for accurately\ninterpreting visual information, the choice of visual encoder is pivotal. We\nhypothesize that the diverse training paradigms employed by different visual\nencoders instill them with distinct inductive biases, which leads to their\ndiverse hallucination performances. Existing benchmarks typically focus on\ncoarse-grained hallucination detection and fail to capture the diverse\nhallucinations elaborated in our hypothesis. To systematically analyze these\neffects, we introduce VHBench-10, a comprehensive benchmark with approximately\n10,000 samples for evaluating LVLMs across ten fine-grained hallucination\ncategories. Our evaluations confirm encoders exhibit unique hallucination\ncharacteristics. Building on these insights and the suboptimality of simple\nfeature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.\nIt employs global visual features to generate routing signals, dynamically\naggregating visual features from multiple specialized experts. Comprehensive\nexperiments confirm the effectiveness of VisionWeaver in significantly reducing\nhallucinations and improving overall model performance.", "published": "2025-09-17 09:08:05", "link": "http://arxiv.org/abs/2509.13836v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Large Language Models Discriminate Against Speakers of German Dialects", "abstract": "Dialects represent a significant component of human culture and are found\nacross all regions of the world. In Germany, more than 40% of the population\nspeaks a regional dialect (Adler and Hansen, 2022). However, despite cultural\nimportance, individuals speaking dialects often face negative societal\nstereotypes. We examine whether such stereotypes are mirrored by large language\nmodels (LLMs). We draw on the sociolinguistic literature on dialect perception\nto analyze traits commonly associated with dialect speakers. Based on these\ntraits, we assess the dialect naming bias and dialect usage bias expressed by\nLLMs in two tasks: an association task and a decision task. To assess a model's\ndialect usage bias, we construct a novel evaluation corpus that pairs sentences\nfrom seven regional German dialects (e.g., Alemannic and Bavarian) with their\nstandard German counterparts. We find that: (1) in the association task, all\nevaluated LLMs exhibit significant dialect naming and dialect usage bias\nagainst German dialect speakers, reflected in negative adjective associations;\n(2) all models reproduce these dialect naming and dialect usage biases in their\ndecision making; and (3) contrary to prior work showing minimal bias with\nexplicit demographic mentions, we find that explicitly labeling linguistic\ndemographics--German dialect speakers--amplifies bias more than implicit cues\nlike dialect usage.", "published": "2025-09-17 09:05:37", "link": "http://arxiv.org/abs/2509.13835v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Findings of the Third Automatic Minuting (AutoMin) Challenge", "abstract": "This paper presents the third edition of AutoMin, a shared task on automatic\nmeeting summarization into minutes. In 2025, AutoMin featured the main task of\nminuting, the creation of structured meeting minutes, as well as a new task:\nquestion answering (QA) based on meeting transcripts.\n  The minuting task covered two languages, English and Czech, and two domains:\nproject meetings and European Parliament sessions. The QA task focused solely\non project meetings and was available in two settings: monolingual QA in\nEnglish, and cross-lingual QA, where questions were asked and answered in Czech\nbased on English meetings.\n  Participation in 2025 was more limited compared to previous years, with only\none team joining the minuting task and two teams participating in QA. However,\nas organizers, we included multiple baseline systems to enable a comprehensive\nevaluation of current (2025) large language models (LLMs) on both tasks.", "published": "2025-09-17 08:29:57", "link": "http://arxiv.org/abs/2509.13814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs", "abstract": "Large language models demonstrate impressive results across diverse tasks but\nare still known to hallucinate, generating linguistically plausible but\nincorrect answers to questions. Uncertainty quantification has been proposed as\na strategy for hallucination detection, but no existing black-box approach\nprovides estimates for both global and local uncertainty. The former attributes\nuncertainty to a batch of responses, while the latter attributes uncertainty to\nindividual responses. Current local methods typically rely on white-box access\nto internal model states, whilst black-box methods only provide global\nuncertainty estimates. We introduce a geometric framework to address this,\nbased on archetypal analysis of batches of responses sampled with only\nblack-box model access. At the global level, we propose Geometric Volume, which\nmeasures the convex hull volume of archetypes derived from response embeddings.\nAt the local level, we propose Geometric Suspicion, which ranks responses by\nreliability and enables hallucination reduction through preferential response\nselection. Unlike prior dispersion methods which yield only a single global\nscore, our approach provides semantic boundary points which have utility for\nattributing reliability to individual responses. Experiments show that our\nframework performs comparably to or better than prior methods on short form\nquestion-answering datasets, and achieves superior results on medical datasets\nwhere hallucinations carry particularly critical risks. We also provide\ntheoretical justification by proving a link between convex hull volume and\nentropy.", "published": "2025-09-17 08:28:07", "link": "http://arxiv.org/abs/2509.13813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages", "abstract": "This work sets the ground for studying how explicit grammatical gender\nassignment in job titles can affect the results of automatic job ranking\nsystems. We propose the usage of metrics for ranking comparison controlling for\ngender to evaluate gender bias in job title ranking systems, in particular RBO\n(Rank-Biased Overlap). We generate and share test sets for a job title matching\ntask in four grammatical gender languages, including occupations in masculine\nand feminine form and annotated by gender and matching relevance. We use the\nnew test sets and the proposed methodology to evaluate the gender bias of\nseveral out-of-the-box multilingual models to set as baselines, showing that\nall of them exhibit varying degrees of gender bias.", "published": "2025-09-17 08:17:28", "link": "http://arxiv.org/abs/2509.13803v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning", "abstract": "Efficient instruction tuning aims to enhance the ultimate performance of\nlarge language models (LLMs) trained on a given instruction dataset. Curriculum\nlearning as a typical data organization strategy has shown preliminary\neffectiveness in instruction tuning. However, current curriculum tuning methods\nsuffer from the curriculum rigidity, since they rely solely on static heuristic\ndifficulty metrics. These methods fail to adapt to the evolving capabilities of\nmodels during training, resulting in a fixed and potentially sub-optimal\nlearning trajectory. To address the issue, Competence-Aware Multi-Perspective\ncUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS\noffers several advantages: (1) Dynamic selection for sub-curriculum. (2)\nCompetency-aware adjustment to the curriculum schedule. (3) Multiple\ndifficulty-based scheduling. Extensive experiments prove the superior\nperformance of CAMPUS, compared to other state-of-the-art baselines for\nefficient instruction tuning.", "published": "2025-09-17 07:58:59", "link": "http://arxiv.org/abs/2509.13790v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications", "abstract": "This paper discusses our exploration of different data-efficient and\nparameter-efficient approaches to Arabic Dialect Identification (ADI). In\nparticular, we investigate various soft-prompting strategies, including\nprefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA\nreparameterizations. For the data-efficient strategy, we analyze hard prompting\nwith zero-shot and few-shot inferences to analyze the dialect identification\ncapabilities of Large Language Models (LLMs). For the parameter-efficient PEFT\napproaches, we conducted our experiments using Arabic-specific encoder models\non several major datasets. We also analyzed the n-shot inferences on\nopen-source decoder-only models, a general multilingual model (Phi-3.5), and an\nArabic-specific one(SILMA). We observed that the LLMs generally struggle to\ndifferentiate the dialectal nuances in the few-shot or zero-shot setups. The\nsoft-prompted encoder variants perform better, while the LoRA-based fine-tuned\nmodels perform best, even surpassing full fine-tuning.", "published": "2025-09-17 07:45:09", "link": "http://arxiv.org/abs/2509.13775v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "abstract": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.", "published": "2025-09-17 07:16:12", "link": "http://arxiv.org/abs/2509.13761v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Implementing a Logical Inference System for Japanese Comparatives", "abstract": "Natural Language Inference (NLI) involving comparatives is challenging\nbecause it requires understanding quantities and comparative relations\nexpressed by sentences. While some approaches leverage Large Language Models\n(LLMs), we focus on logic-based approaches grounded in compositional semantics,\nwhich are promising for robust handling of numerical and logical expressions.\nPrevious studies along these lines have proposed logical inference systems for\nEnglish comparatives. However, it has been pointed out that there are several\nmorphological and semantic differences between Japanese and English\ncomparatives. These differences make it difficult to apply such systems\ndirectly to Japanese comparatives. To address this gap, this study proposes\nccg-jcomp, a logical inference system for Japanese comparatives based on\ncompositional semantics. We evaluate the proposed system on a Japanese NLI\ndataset containing comparative expressions. We demonstrate the effectiveness of\nour system by comparing its accuracy with that of existing LLMs.", "published": "2025-09-17 06:37:10", "link": "http://arxiv.org/abs/2509.13734v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning", "abstract": "Large language models (LLMs) have achieved remarkable success in many natural\nlanguage processing (NLP) tasks. To achieve more accurate output, the prompts\nused to drive LLMs have become increasingly longer, which incurs higher\ncomputational costs. To address this prompt inflation problem, prompt\ncompression has been proposed. However, most existing methods require training\na small auxiliary model for compression, incurring a significant amount of\nadditional computation. To avoid this, we propose a two-stage, training-free\napproach, called Dual-Stage Progressive Compression (DSPC). In the\ncoarse-grained stage, semantic-related sentence filtering removes sentences\nwith low semantic value based on TF-IDF. In the fine-grained stage, token\nimportance is assessed using attention contribution, cross-model loss\ndifference, and positional importance, enabling the pruning of low-utility\ntokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct\nand GPT-3.5-Turbo under a constrained token budget and observe consistent\nimprovements. For instance, in the FewShot task of the Longbench dataset, DSPC\nachieves a performance of 49.17 by using only 3x fewer tokens, outperforming\nthe best state-of-the-art baseline LongLLMLingua by 7.76.", "published": "2025-09-17 06:18:46", "link": "http://arxiv.org/abs/2509.13723v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models", "abstract": "PURPOSE: Incident reports are an important tool for safety and quality\nimprovement in healthcare, but manual review is time-consuming and requires\nsubject matter expertise. Here we present a natural language processing (NLP)\nscreening tool to detect high-severity incident reports in radiation oncology\nacross two institutions.\n  METHODS AND MATERIALS: We used two text datasets to train and evaluate our\nNLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA\nSAFRON (SF), all of which had severity scores labeled by clinical content\nexperts. We trained and evaluated two types of models: baseline support vector\nmachines (SVM) and BlueBERT which is a large language model pretrained on\nPubMed abstracts and hospitalized patient data. We assessed for\ngeneralizability of our model in two ways. First, we evaluated models trained\nusing Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that\nwas first fine-tuned on Inst.-train then on SF-train before testing on SF-test\nset. To further analyze model performance, we also examined a subset of 59\nreports from our Inst. dataset, which were manually edited for clarity.\n  RESULTS Classification performance on the Inst. test achieved AUROC 0.82\nusing SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,\nperformance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56\nusing BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,\nimproved the performance on SF test to AUROC 0.78. Performance of SVM, and\nBlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and\n0.74) was similar to human performance (AUROC 0.81).\n  CONCLUSION: In summary, we successfully developed cross-institution NLP\nmodels on incident report text from radiation oncology centers. These models\nwere able to detect high-severity reports similarly to humans on a curated\ndataset.", "published": "2025-09-17 05:29:23", "link": "http://arxiv.org/abs/2509.13706v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models", "abstract": "Large Language Model (LLM) hallucination is a significant barrier to their\nreliable deployment. Current methods like Retrieval-Augmented Generation (RAG)\nare often reactive. We introduce **Dynamic Self-reinforcing Calibration for\nHallucination Suppression (DSCC-HS)**, a novel, proactive framework that\nintervenes during autoregressive decoding. Inspired by dual-process cognitive\ntheory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a\nFactual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During\ninference, these proxies dynamically steer a large target model by injecting a\nreal-time steering vector, which is the difference between FAP and HDP logits,\nat each decoding step. This plug-and-play approach requires no modification to\nthe target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS\nachieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%\nFactual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained\nthe highest FActScore of 46.50. These results validate DSCC-HS as a principled\nand efficient solution for enhancing LLM factuality.", "published": "2025-09-17 05:09:22", "link": "http://arxiv.org/abs/2509.13702v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes", "abstract": "Large language models (LLMs) excel at text generation, but their ability to\nhandle clinical classification tasks involving structured data, such as time\nseries, remains underexplored. In this work, we adapt instruction-tuned LLMs\nusing DSPy-based prompt optimization to process clinical notes and structured\nEHR inputs jointly. Our results show that this approach achieves performance on\npar with specialized multimodal systems while requiring less complexity and\noffering greater adaptability across tasks.", "published": "2025-09-17 05:02:14", "link": "http://arxiv.org/abs/2509.13696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?", "abstract": "Large Language Models (LLMs) perform remarkably well in Natural Language\nInference (NLI). However, NLI involving numerical and logical expressions\nremains challenging. Comparatives are a key linguistic phenomenon related to\nsuch inference, but the robustness of LLMs in handling them, especially in\nlanguages that are not dominant in the models' training data, such as Japanese,\nhas not been sufficiently explored. To address this gap, we construct a\nJapanese NLI dataset that focuses on comparatives and evaluate various LLMs in\nzero-shot and few-shot settings. Our results show that the performance of the\nmodels is sensitive to the prompt formats in the zero-shot setting and\ninfluenced by the gold labels in the few-shot examples. The LLMs also struggle\nto handle linguistic phenomena unique to Japanese. Furthermore, we observe that\nprompts containing logical semantic representations help the models predict the\ncorrect labels for inference problems that they struggle to solve even with\nfew-shot examples.", "published": "2025-09-17 04:56:51", "link": "http://arxiv.org/abs/2509.13695v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Context Fidelity via Native Retrieval-Augmented Reasoning", "abstract": "Large language models (LLMs) often struggle with context fidelity, producing\ninconsistent answers when responding to questions based on provided\ninformation. Existing approaches either rely on expensive supervised\nfine-tuning to generate evidence post-answer or train models to perform web\nsearches without necessarily improving utilization of the given context. We\npropose CARE, a novel native retrieval-augmented reasoning framework that\nteaches LLMs to explicitly integrate in-context evidence within their reasoning\nprocess with the model's own retrieval capabilities. Our method requires\nlimited labeled evidence data while significantly enhancing both retrieval\naccuracy and answer generation performance through strategically retrieved\nin-context tokens in the reasoning chain. Extensive experiments on multiple\nreal-world and counterfactual QA benchmarks demonstrate that our approach\nsubstantially outperforms supervised fine-tuning, traditional\nretrieval-augmented generation methods, and external retrieval solutions. This\nwork represents a fundamental advancement in making LLMs more accurate,\nreliable, and efficient for knowledge-intensive tasks.", "published": "2025-09-17 04:28:07", "link": "http://arxiv.org/abs/2509.13683v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation", "abstract": "Although significant progress has been made in many tasks within the field of\nNatural Language Processing (NLP), Controlled Text Generation (CTG) continues\nto face numerous challenges, particularly in achieving fine-grained conditional\ncontrol over generation. Additionally, in real scenario and online\napplications, cost considerations, scalability, domain knowledge learning and\nmore precise control are required, presenting more challenge for CTG. This\npaper introduces a novel and scalable framework, AgentCTG, which aims to\nenhance precise and complex control over the text generation by simulating the\ncontrol and regulation mechanisms in multi-agent workflows. We explore various\ncollaboration methods among different agents and introduce an auto-prompt\nmodule to further enhance the generation effectiveness. AgentCTG achieves\nstate-of-the-art results on multiple public datasets. To validate its\neffectiveness in practical applications, we propose a new challenging\nCharacter-Driven Rewriting task, which aims to convert the original text into\nnew text that conform to specific character profiles and simultaneously\npreserve the domain knowledge. When applied to online navigation with\nrole-playing, our approach significantly enhances the driving experience\nthrough improved content delivery. By optimizing the generation of contextually\nrelevant text, we enable a more immersive interaction within online\ncommunities, fostering greater personalization and user engagement.", "published": "2025-09-17 04:07:22", "link": "http://arxiv.org/abs/2509.13677v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction", "abstract": "The growing demand for automated writing assistance in diverse academic\ndomains highlights the need for robust Chinese Grammatical Error Correction\n(CGEC) systems that can adapt across disciplines. However, existing CGEC\nresearch largely lacks dedicated benchmarks for multi-disciplinary academic\nwriting, overlooking continual learning (CL) as a promising solution to handle\ndomain-specific linguistic variation and prevent catastrophic forgetting. To\nfill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning\nbenchmark for Chinese Literature Grammatical Error Correction, designed to\nevaluate adaptive CGEC across multiple academic fields. Our benchmark includes\n10,000 human-annotated sentences spanning 10 disciplines, each exhibiting\ndistinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating\ngrammatical error correction in a continual learning setting, simulating\nsequential exposure to diverse academic disciplines to reflect real-world\neditorial dynamics. We evaluate large language models under sequential tuning,\nparameter-efficient adaptation, and four representative CL algorithms, using\nboth standard GEC metrics and continual learning metrics adapted to task-level\nvariation. Experimental results reveal that regularization-based methods\nmitigate forgetting more effectively than replay-based or naive sequential\napproaches. Our benchmark provides a rigorous foundation for future research in\nadaptive grammatical error correction across diverse academic domains.", "published": "2025-09-17 03:54:52", "link": "http://arxiv.org/abs/2509.13672v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs", "abstract": "Ambiguity is pervasive in real-world questions, yet large language models\n(LLMs) often respond with confident answers rather than seeking clarification.\nIn this work, we show that question ambiguity is linearly encoded in the\ninternal representations of LLMs and can be both detected and controlled at the\nneuron level. During the model's pre-filling stage, we identify that a small\nnumber of neurons, as few as one, encode question ambiguity information. Probes\ntrained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance\non ambiguity detection and generalize across datasets, outperforming\nprompting-based and representation-based baselines. Layerwise analysis reveals\nthat AENs emerge from shallow layers, suggesting early encoding of ambiguity\nsignals in the model's processing pipeline. Finally, we show that through\nmanipulating AENs, we can control LLM's behavior from direct answering to\nabstention. Our findings reveal that LLMs form compact internal representations\nof question ambiguity, enabling interpretable and controllable behavior.", "published": "2025-09-17 03:34:35", "link": "http://arxiv.org/abs/2509.13664v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Privacy-Aware In-Context Learning for Large Language Models", "abstract": "Large language models (LLMs) have significantly transformed natural language\nunderstanding and generation, but they raise privacy concerns due to potential\nexposure of sensitive information. Studies have highlighted the risk of\ninformation leakage, where adversaries can extract sensitive information\nembedded in the prompts. In this work, we introduce a novel private prediction\nframework for generating high-quality synthetic text with strong privacy\nguarantees. Our approach leverages the Differential Privacy (DP) framework to\nensure worst-case theoretical bounds on information leakage without requiring\nany fine-tuning of the underlying models.The proposed method performs inference\non private records and aggregates the resulting per-token output distributions.\nThis enables the generation of longer and coherent synthetic text while\nmaintaining privacy guarantees. Additionally, we propose a simple blending\noperation that combines private and public inference to further enhance\nutility. Empirical evaluations demonstrate that our approach outperforms\nprevious state-of-the-art methods on in-context-learning (ICL) tasks, making it\na promising direction for privacy-preserving text generation while maintaining\nhigh utility.", "published": "2025-09-17 01:50:32", "link": "http://arxiv.org/abs/2509.13625v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning", "abstract": "Large language models are increasingly deployed across diverse applications.\nThis often includes tasks LLMs have not encountered during training. This\nimplies that enumerating and obtaining the high-quality training data for all\ntasks is infeasible. Thus, we often need to rely on transfer learning using\ndatasets with different characteristics, and anticipate out-of-distribution\nrequests. Motivated by this practical need, we propose an analysis framework,\nbuilding a transfer learning matrix and dimensionality reduction, to dissect\nthese cross-task interactions. We train and analyze 10 models to identify\nlatent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)\nand discover the side effects of the transfer learning. Our findings reveal\nthat performance improvements often defy explanations based on surface-level\ndataset similarity or source data quality. Instead, hidden statistical factors\nof the source dataset, such as class distribution and generation length\nproclivities, alongside specific linguistic features, are actually more\ninfluential. This work offers insights into the complex dynamics of transfer\nlearning, paving the way for more predictable and effective LLM adaptation.", "published": "2025-09-17 01:45:42", "link": "http://arxiv.org/abs/2509.13624v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "abstract": "The advent of multimodal agents facilitates effective interaction within\ngraphical user interface (GUI), especially in ubiquitous GUI control. However,\ntheir inability to reliably execute toggle control instructions remains a key\nbottleneck. To investigate this, we construct a state control benchmark with\nbinary toggle instructions from public datasets. Evaluations of existing agents\ndemonstrate their unreliability, particularly when the current toggle state\nalready matches the desired state. To address the challenge, we propose\nState-aware Reasoning (StaR), a training method that teaches agents to perceive\nthe current toggle state, analyze the desired state from the instruction, and\nact accordingly. Experiments on three multimodal agents demonstrate that StaR\ncan improve toggle instruction execution accuracy by over 30\\%. Further\nevaluations on three public benchmarks show that StaR also enhances general\ntask performance. Finally, evaluations on a dynamic environment highlight the\npotential of StaR for real-world applications. Code, benchmark, and\nStaR-enhanced agents are available at https://github.com/ZrW00/StaR.", "published": "2025-09-17 01:14:14", "link": "http://arxiv.org/abs/2509.13615v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training", "abstract": "Stochastic optimization powers the scalability of modern artificial\nintelligence, spanning machine learning, deep learning, reinforcement learning,\nand large language model training. Yet, existing theory remains largely\nconfined to Hilbert spaces, relying on inner-product frameworks and\northogonality. This paradigm fails to capture non-Euclidean settings, such as\nmirror descent on simplices, Bregman proximal methods for sparse learning,\nnatural gradient descent in information geometry, or\nKullback--Leibler-regularized language model training. Unlike Euclidean-based\nHilbert-space methods, this approach embraces general Banach spaces. This work\nintroduces a pioneering Banach--Bregman framework for stochastic iterations,\nestablishing Bregman geometry as a foundation for next-generation optimization.\nIt (i) provides a unified template via Bregman projections and Bregman--Fejer\nmonotonicity, encompassing stochastic approximation, mirror descent, natural\ngradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations\n($\\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and\nelucidating their acceleration effect; and (iii) delivers convergence theorems\nspanning almost-sure boundedness to geometric rates, validated on synthetic and\nreal-world tasks. Empirical studies across machine learning (UCI benchmarks),\ndeep learning (e.g., Transformer training), reinforcement learning\n(actor--critic), and large language models (WikiText-2 with distilGPT-2) show\nup to 20% faster convergence, reduced variance, and enhanced accuracy over\nclassical baselines. These results position Banach--Bregman geometry as a\ncornerstone unifying optimization theory and practice across core AI paradigms.", "published": "2025-09-17 17:50:59", "link": "http://arxiv.org/abs/2509.14216v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "abstract": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.", "published": "2025-09-17 17:30:58", "link": "http://arxiv.org/abs/2509.14195v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting", "abstract": "Representation learning techniques like contrastive learning have long been\nexplored in time series forecasting, mirroring their success in computer vision\nand natural language processing. Yet recent state-of-the-art (SOTA) forecasters\nseldom adopt these representation approaches because they have shown little\nperformance advantage. We challenge this view and demonstrate that explicit\nrepresentation alignment can supply critical information that bridges the\ndistributional gap between input histories and future targets. To this end, we\nintroduce TimeAlign, a lightweight, plug-and-play framework that learns\nauxiliary features via a simple reconstruction task and feeds them back to any\nbase forecaster. Extensive experiments across eight benchmarks verify its\nsuperior performance. Further studies indicate that the gains arises primarily\nfrom correcting frequency mismatches between historical inputs and future\noutputs. We also provide a theoretical justification for the effectiveness of\nTimeAlign in increasing the mutual information between learned representations\nand predicted targets. As it is architecture-agnostic and incurs negligible\noverhead, TimeAlign can serve as a general alignment module for modern deep\nlearning time-series forecasting systems. The code is available at\nhttps://github.com/TROUBADOUR000/TimeAlign.", "published": "2025-09-17 17:12:39", "link": "http://arxiv.org/abs/2509.14181v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning", "abstract": "With the rapid advancement of large language models and vision-language\nmodels, employing large models as Web Agents has become essential for automated\nweb interaction. However, training Web Agents with reinforcement learning faces\ncritical challenges including credit assignment misallocation, prohibitively\nhigh annotation costs, and reward sparsity. To address these issues, we propose\nTree-Guided Preference Optimization (TGPO), an offline reinforcement learning\nframework that proposes a tree-structured trajectory representation merging\nsemantically identical states across trajectories to eliminate label conflicts.\nOur framework incorporates a Process Reward Model that automatically generates\nfine-grained rewards through subgoal progress, redundancy detection, and action\nverification. Additionally, a dynamic weighting mechanism prioritizes\nhigh-impact decision points during training. Experiments on Online-Mind2Web and\nour self-constructed C-WebShop datasets demonstrate that TGPO significantly\noutperforms existing methods, achieving higher success rates with fewer\nredundant steps.", "published": "2025-09-17 16:58:44", "link": "http://arxiv.org/abs/2509.14172v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions", "abstract": "Vision Transformers (ViTs) achieve state-of-the-art performance in semantic\nsegmentation but are hindered by high computational and memory costs. To\naddress this, we propose STEP (SuperToken and Early-Pruning), a hybrid\ntoken-reduction framework that combines dynamic patch merging and token pruning\nto enhance efficiency without significantly compromising accuracy. At the core\nof STEP is dCTS, a lightweight CNN-based policy network that enables flexible\nmerging into superpatches. Encoder blocks integrate also early-exits to remove\nhigh-confident supertokens, lowering computational load. We evaluate our method\non high-resolution semantic segmentation benchmarks, including images up to\n1024 x 1024, and show that when dCTS is applied alone, the token count can be\nreduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching\nscheme. This yields a 2.6x reduction in computational cost and a 3.4x increase\nin throughput when using ViT-Large as the backbone. Applying the full STEP\nframework further improves efficiency, reaching up to a 4x reduction in\ncomputational complexity and a 1.7x gain in inference speed, with a maximum\naccuracy drop of no more than 2.0%. With the proposed STEP configurations, up\nto 40% of tokens can be confidently predicted and halted before reaching the\nfinal encoder layer.", "published": "2025-09-17 16:48:00", "link": "http://arxiv.org/abs/2509.14165v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing", "abstract": "Queen bee presence is essential for the health and stability of honeybee\ncolonies, yet current monitoring methods rely on manual inspections that are\nlabor-intensive, disruptive, and impractical for large-scale beekeeping. While\nrecent audio-based approaches have shown promise, they often require high power\nconsumption, complex preprocessing, and are susceptible to ambient noise. To\novercome these limitations, we propose a lightweight, multimodal system for\nqueen detection based on environmental sensor fusion-specifically, temperature,\nhumidity, and pressure differentials between the inside and outside of the\nhive. Our approach employs quantized decision tree inference on a commercial\nSTM32 microcontroller, enabling real-time, low-power edge computing without\ncompromising accuracy. We show that our system achieves over 99% queen\ndetection accuracy using only environmental inputs, with audio features\noffering no significant performance gain. This work presents a scalable and\nsustainable solution for non-invasive hive monitoring, paving the way for\nautonomous, precision beekeeping using off-the-shelf, energy-efficient\nhardware.", "published": "2025-09-17 15:05:15", "link": "http://arxiv.org/abs/2509.14061v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Machines are more productive than humans until they aren't, and vice versa", "abstract": "With the growth of artificial skills, organizations may increasingly confront\nwith the problem of optimizing skill policy decisions guided by economic\nprinciples. This paper addresses the underlying complexity of this challenge by\ndeveloping an in-silico framework based on Monte Carlo simulations grounded in\nempirical realism to analyze the economic impact of human and machine skills,\nindividually or jointly deployed, in the execution of tasks presenting varying\nlevels of complexity. Our results provide quantitative support for the\nestablished notions that automation tends to be the most economically-effective\nstrategy for tasks characterized by low-to-medium generalization difficulty,\nwhile automation struggles to match the economic utility of human skills in\nmore complex scenarios. Critically, our simulations highlight that combining\nhuman and machine skills can be the most effective strategy when a high level\nof generalization is required, but only if genuine augmentation is achieved. In\ncontrast, when failing to realize this synergy, the human-machine policy is\nseverely penalized by the inherent costs of its dual skill structure, causing\nit to destroy value and becoming the worst choice from an economic perspective.\nThe takeaway for decision-makers is unambiguous: simply allocating human and\nmachine skills to a task is insufficient, and a human-machine skill policy is\nneither a silver-bullet solution nor a low-risk compromise. Rather, it is a\ncritical opportunity to boost competitiveness that demands a strong\norganizational commitment to enabling augmentation. Also, our findings show\nthat improving the cost-effectiveness of machine skills over time, while\nuseful, does not replace the fundamental need to focus on achieving\naugmentation.", "published": "2025-09-17 15:03:39", "link": "http://arxiv.org/abs/2509.14057v1", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices", "abstract": "Convolutional Neural Networks (CNNs) have demonstrated exceptional\nperformance in audio tagging tasks. However, deploying these models on\nresource-constrained devices like the Raspberry Pi poses challenges related to\ncomputational efficiency and thermal management. In this paper, a comprehensive\nevaluation of multiple convolutional neural network (CNN) architectures for\naudio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D\nmodels from the Pretrained Audio Neural Networks (PANNs) framework, a\nConvNeXt-based model adapted for audio classification, as well as MobileNetV3\narchitectures. In addition, two PANNs-derived networks, CNN9 and CNN13,\nrecently proposed, are also evaluated. To enhance deployment efficiency and\nportability across diverse hardware platforms, all models are converted to the\nOpen Neural Network Exchange (ONNX) format. Unlike previous works that focus on\na single model, our analysis encompasses a broader range of architectures and\ninvolves continuous 24-hour inference sessions to assess performance stability.\nOur experiments reveal that, with appropriate model selection and optimization,\nit is possible to maintain consistent inference latency and manage thermal\nbehavior effectively over extended periods. These findings provide valuable\ninsights for deploying audio tagging models in real-world edge computing\nscenarios.", "published": "2025-09-17 14:53:56", "link": "http://arxiv.org/abs/2509.14049v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning", "abstract": "Learning from demonstration allows robots to acquire complex skills from\nhuman demonstrations, but conventional approaches often require large datasets\nand fail to generalize across coordinate transformations. In this paper, we\npropose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)\nlearning framework that enables robots to perform human-guided automated\ncontrol from a single motion prompt. A dataset-construction strategy based on\ncoordinate transformations is introduced that enforces invariance to\ntranslation, rotation, and scaling, while supporting multi-step predictions.\nMoreover, GeoGP is robust to variations in the user's motion prompt and\nsupports multi-skill autonomy. We validate the proposed approach through\nnumerical simulations with the designed user graphical interface and two\nreal-world robotic experiments, which demonstrate that the proposed method is\neffective, generalizes across tasks, and significantly reduces the\ndemonstration burden. Project page is available at:\nhttps://prompt2auto.github.io", "published": "2025-09-17 14:42:18", "link": "http://arxiv.org/abs/2509.14040v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction", "abstract": "Understanding disease similarity is critical for advancing diagnostics, drug\ndiscovery, and personalized treatment strategies. We present PhenoGnet, a novel\ngraph-based contrastive learning framework designed to predict disease\nsimilarity by integrating gene functional interaction networks with the Human\nPhenotype Ontology (HPO). PhenoGnet comprises two key components: an intra-view\nmodel that separately encodes gene and phenotype graphs using Graph\nConvolutional Networks (GCNs) and Graph Attention Networks (GATs), and a cross\nview model implemented as a shared weight multilayer perceptron (MLP) that\naligns gene and phenotype embeddings through contrastive learning. The model is\ntrained using known gene phenotype associations as positive pairs and randomly\nsampled unrelated pairs as negatives. Diseases are represented by the mean\nembeddings of their associated genes and/or phenotypes, and pairwise similarity\nis computed via cosine similarity. Evaluation on a curated benchmark of 1,100\nsimilar and 866 dissimilar disease pairs demonstrates strong performance, with\ngene based embeddings achieving an AUCPR of 0.9012 and AUROC of 0.8764,\noutperforming existing state of the art methods. Notably, PhenoGnet captures\nlatent biological relationships beyond direct overlap, offering a scalable and\ninterpretable solution for disease similarity prediction. These results\nunderscore its potential for enabling downstream applications in rare disease\nresearch and precision medicine.", "published": "2025-09-17 14:38:52", "link": "http://arxiv.org/abs/2509.14037v1", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "primary_category": "q-bio.GN"}
{"title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "abstract": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.", "published": "2025-09-17 14:31:18", "link": "http://arxiv.org/abs/2509.14030v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing", "abstract": "Diffusion models have shown remarkable progress in text-to-audio generation.\nHowever, text-guided audio editing remains in its early stages. This task\nfocuses on modifying the target content within an audio signal while preserving\nthe rest, thus demanding precise localization and faithful editing according to\nthe text prompt. Existing training-based and zero-shot methods that rely on\nfull-caption or costly optimization often struggle with complex editing or lack\npracticality. In this work, we propose a novel end-to-end efficient rectified\nflow matching-based diffusion framework for audio editing, and construct a\ndataset featuring overlapping multi-event audio to support training and\nbenchmarking in complex scenarios. Experiments show that our model achieves\nfaithful semantic alignment without requiring auxiliary captions or masks,\nwhile maintaining competitive editing quality across metrics.", "published": "2025-09-17 14:13:40", "link": "http://arxiv.org/abs/2509.14003v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "abstract": "We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),\na knowledge distillation approach that transfers region-level multimodal\nsemantics from a large vision-language teacher (e.g., LLaVa) into a lightweight\nvision-only object detector student (e.g., YOLO). A translation module maps\nstudent features into a joint space, where the training of the student and\ntranslator is guided by a dual-objective loss that enforces both local\nalignment and global relational consistency. Unlike prior approaches focused on\ndense or global alignment, MOCHA operates at the object level, enabling\nefficient transfer of semantics without modifying the teacher or requiring\ntextual input at inference. We validate our method across four personalized\ndetection benchmarks under few-shot regimes. Results show consistent gains over\nbaselines, with a +10.1 average score improvement. Despite its compact\narchitecture, MOCHA reaches performance on par with larger multimodal models,\nproving its suitability for real-world deployment.", "published": "2025-09-17 14:13:20", "link": "http://arxiv.org/abs/2509.14001v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response", "abstract": "Machine learning models used for distributed architectures consisting of\nservers and clients require large amounts of data to achieve high accuracy.\nData obtained from clients are collected on a central server for model\ntraining. However, storing data on a central server raises concerns about\nsecurity and privacy. To address this issue, a federated learning architecture\nhas been proposed. In federated learning, each client trains a local model\nusing its own data. The trained models are periodically transmitted to the\ncentral server. The server then combines the received models using federated\naggregation algorithms to obtain a global model. This global model is\ndistributed back to the clients, and the process continues in a cyclical\nmanner. Although preventing data from leaving the clients enhances security,\ncertain concerns still remain. Attackers can perform inference attacks on the\nobtained models to approximate the training dataset, potentially causing data\nleakage. In this study, differential privacy was applied to address the\naforementioned security vulnerability, and a performance analysis was\nconducted. The Data-Unaware Classification Based on Association (duCBA)\nalgorithm was used as the federated aggregation method. Differential privacy\nwas implemented on the data using the Randomized Response technique, and the\ntrade-off between security and performance was examined under different epsilon\nvalues. As the epsilon value decreased, the model accuracy declined, and class\nprediction imbalances were observed. This indicates that higher levels of\nprivacy do not always lead to practical outcomes and that the balance between\nsecurity and performance must be carefully considered.", "published": "2025-09-17 13:59:38", "link": "http://arxiv.org/abs/2509.13987v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology", "abstract": "Modern scientific discovery increasingly relies on workflows that process\ndata across the Edge, Cloud, and High Performance Computing (HPC) continuum.\nComprehensive and in-depth analyses of these data are critical for hypothesis\nvalidation, anomaly detection, reproducibility, and impactful findings.\nAlthough workflow provenance techniques support such analyses, at large scale,\nthe provenance data become complex and difficult to analyze. Existing systems\ndepend on custom scripts, structured queries, or static dashboards, limiting\ndata interaction. In this work, we introduce an evaluation methodology,\nreference architecture, and open-source implementation that leverages\ninteractive Large Language Model (LLM) agents for runtime data analysis. Our\napproach uses a lightweight, metadata-driven design that translates natural\nlanguage into structured provenance queries. Evaluations across LLaMA, GPT,\nGemini, and Claude, covering diverse query classes and a real-world chemistry\nworkflow, show that modular design, prompt tuning, and Retrieval-Augmented\nGeneration (RAG) enable accurate and insightful LLM agent responses beyond\nrecorded provenance.", "published": "2025-09-17 13:51:29", "link": "http://arxiv.org/abs/2509.13978v1", "categories": ["cs.DC", "cs.AI", "cs.DB", "68M14, 68M20, 68T07", "C.2.4; D.1.3; I.2.0"], "primary_category": "cs.DC"}
{"title": "DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models", "abstract": "Reasoning about spatial audio with large language models requires a spatial\naudio encoder as an acoustic front-end to obtain audio embeddings for further\nprocessing. Such an encoder needs to capture all information required to detect\nthe type of sound events, as well as the direction and distance of their\ncorresponding sources. Accomplishing this with a single audio encoder is\ndemanding as the information required for each of these tasks is mostly\nindependent of each other. As a result, the performance obtained with a single\nencoder is often worse than when using task-specific audio encoders. In this\nwork, we present DSpAST, a novel audio encoder based on SpatialAST that learns\ndisentangled representations of spatial audio while having only 0.2% additional\nparameters. Experiments on SpatialSoundQA with the spatial audio reasoning\nsystem BAT demonstrate that DSpAST significantly outperforms SpatialAST.", "published": "2025-09-17 12:51:51", "link": "http://arxiv.org/abs/2509.13927v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MAP: End-to-End Autonomous Driving with Map-Assisted Planning", "abstract": "In recent years, end-to-end autonomous driving has attracted increasing\nattention for its ability to jointly model perception, prediction, and planning\nwithin a unified framework. However, most existing approaches underutilize the\nonline mapping module, leaving its potential to enhance trajectory planning\nlargely untapped. This paper proposes MAP (Map-Assisted Planning), a novel\nmap-assisted end-to-end trajectory planning framework. MAP explicitly\nintegrates segmentation-based map features and the current ego status through a\nPlan-enhancing Online Mapping module, an Ego-status-guided Planning module, and\na Weight Adapter based on current ego status. Experiments conducted on the\nDAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%\nreduction in L2 displacement error, a 56.2% reduction in off-road rate, and a\n44.5% improvement in overall score compared to the UniV2X baseline, even\nwithout post-processing. Furthermore, it achieves top ranking in Track 2 of the\nEnd-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS\nWorkshop @CVPR2025, outperforming the second-best model by 39.5% in terms of\noverall score. These results highlight the effectiveness of explicitly\nleveraging semantic map features in planning and suggest new directions for\nimproving structure design in end-to-end autonomous driving systems. Our code\nis available at https://gitee.com/kymkym/map.git", "published": "2025-09-17 11:40:46", "link": "http://arxiv.org/abs/2509.13926v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "I.2.9; I.2.10"], "primary_category": "cs.RO"}
{"title": "Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction", "abstract": "This work explores the application of ensemble modeling to the\nmultidimensional regression problem of trajectory prediction for vehicles in\nurban environments. As newer and bigger state-of-the-art prediction models for\nautonomous driving continue to emerge, an important open challenge is the\nproblem of how to combine the strengths of these big models without the need\nfor costly re-training. We show how, perhaps surprisingly, combining\nstate-of-the-art deep learning models out-of-the-box (without retraining or\nfine-tuning) with a simple confidence-weighted average method can enhance the\noverall prediction. Indeed, while combining trajectory prediction models is not\nstraightforward, this simple approach enhances performance by 10% over the best\nprediction model, especially in the long-tailed metrics. We show that this\nperformance improvement holds on both the NuScenes and Argoverse datasets, and\nthat these improvements are made across the dataset distribution. The code for\nour work is open source.", "published": "2025-09-17 11:18:16", "link": "http://arxiv.org/abs/2509.13914v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning", "abstract": "Non-IID data and partial participation induce client drift and inconsistent\nlocal optima in federated learning, causing unstable convergence and accuracy\nloss. We present FedSSG, a stochastic sampling-guided, history-aware drift\nalignment method. FedSSG maintains a per-client drift memory that accumulates\nlocal model differences as a lightweight sketch of historical gradients;\ncrucially, it gates both the memory update and the local alignment term by a\nsmooth function of the observed/expected participation ratio (a\nphase-by-expectation signal derived from the server sampler). This\nstatistically grounded gate stays weak and smooth when sampling noise dominates\nearly, then strengthens once participation statistics stabilize, contracting\nthe local-global gap without extra communication. Across CIFAR-10/100 with\n100/500 clients and 2-15 percent participation, FedSSG consistently outperforms\nstrong drift-aware baselines and accelerates convergence; on our benchmarks it\nimproves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and\nabout +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about\n4.5x faster target-accuracy convergence on average. The method adds only O(d)\nclient memory and a constant-time gate, and degrades gracefully to a mild\nregularizer under near-IID or uniform sampling. FedSSG shows that sampling\nstatistics can be turned into a principled, history-aware phase control to\nstabilize and speed up federated training.", "published": "2025-09-17 10:43:05", "link": "http://arxiv.org/abs/2509.13895v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Synthetic Data Generation for Screen Time and App Usage", "abstract": "Smartphone usage data can provide valuable insights for understanding\ninteraction with technology and human behavior. However, collecting\nlarge-scale, in-the-wild smartphone usage logs is challenging due to high\ncosts, privacy concerns, under representative user samples and biases like\nnon-response that can skew results. These challenges call for exploring\nalternative approaches to obtain smartphone usage datasets. In this context,\nlarge language models (LLMs) such as Open AI's ChatGPT present a novel approach\nfor synthetic smartphone usage data generation, addressing limitations of\nreal-world data collection. We describe a case study on how four prompt\nstrategies influenced the quality of generated smartphone usage data. We\ncontribute with insights on prompt design and measures of data quality,\nreporting a prompting strategy comparison combining two factors, prompt level\nof detail (describing a user persona, describing the expected results\ncharacteristics) and seed data inclusion (with versus without an initial real\nusage example). Our findings suggest that using LLMs to generate structured and\nbehaviorally plausible smartphone use datasets is feasible for some use cases,\nespecially when using detailed prompts. Challenges remain in capturing diverse\nnuances of human behavioral patterns in a single synthetic dataset, and\nevaluating tradeoffs between data fidelity and diversity, suggesting the need\nfor use-case-specific evaluation metrics and future research with more diverse\nseed data and different LLM models.", "published": "2025-09-17 10:42:06", "link": "http://arxiv.org/abs/2509.13892v1", "categories": ["cs.HC", "cs.AI", "I.2; J.4"], "primary_category": "cs.HC"}
{"title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "abstract": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.", "published": "2025-09-17 10:19:06", "link": "http://arxiv.org/abs/2509.13880v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Masked Diffusion Models as Energy Minimization", "abstract": "We present a systematic theoretical framework that interprets masked\ndiffusion models (MDMs) as solutions to energy minimization problems in\ndiscrete optimal transport. Specifically, we prove that three distinct energy\nformulations--kinetic, conditional kinetic, and geodesic energy--are\nmathematically equivalent under the structure of MDMs, and that MDMs minimize\nall three when the mask schedule satisfies a closed-form optimality condition.\nThis unification not only clarifies the theoretical foundations of MDMs, but\nalso motivates practical improvements in sampling. By parameterizing\ninterpolation schedules via Beta distributions, we reduce the schedule design\nspace to a tractable 2D search, enabling efficient post-training tuning without\nmodel modification. Experiments on synthetic and real-world benchmarks\ndemonstrate that our energy-inspired schedules outperform hand-crafted\nbaselines, particularly in low-step sampling settings.", "published": "2025-09-17 09:57:31", "link": "http://arxiv.org/abs/2509.13866v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Understanding the Process of Human-AI Value Alignment", "abstract": "Background: Value alignment in computer science research is often used to\nrefer to the process of aligning artificial intelligence with humans, but the\nway the phrase is used often lacks precision. Objectives: In this paper, we\nconduct a systematic literature review to advance the understanding of value\nalignment in artificial intelligence by characterising the topic in the context\nof its research literature. We use this to suggest a more precise definition of\nthe term. Methods: We analyse 172 value alignment research articles that have\nbeen published in recent years and synthesise their content using thematic\nanalyses. Results: Our analysis leads to six themes: value alignment drivers &\napproaches; challenges in value alignment; values in value alignment; cognitive\nprocesses in humans and AI; human-agent teaming; and designing and developing\nvalue-aligned systems. Conclusions: By analysing these themes in the context of\nthe literature we define value alignment as an ongoing process between humans\nand autonomous agents that aims to express and implement abstract values in\ndiverse contexts, while managing the cognitive limits of both humans and AI\nagents and also balancing the conflicting ethical and political demands\ngenerated by the values in different groups. Our analysis gives rise to a set\nof research challenges and opportunities in the field of value alignment for\nfuture work.", "published": "2025-09-17 09:39:38", "link": "http://arxiv.org/abs/2509.13854v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Towards a Physics Foundation Model", "abstract": "Foundation models have revolutionized natural language processing through a\n``train once, deploy anywhere'' paradigm, where a single pre-trained model\nadapts to countless downstream tasks without retraining. Access to a Physics\nFoundation Model (PFM) would be transformative -- democratizing access to\nhigh-fidelity simulations, accelerating scientific discovery, and eliminating\nthe need for specialized solver development. Yet current physics-aware machine\nlearning approaches remain fundamentally limited to single, narrow domains and\nrequire retraining for each new system. We present the General Physics\nTransformer (GPhyT), trained on 1.8 TB of diverse simulation data, that\ndemonstrates foundation model capabilities are achievable for physics. Our key\ninsight is that transformers can learn to infer governing dynamics from\ncontext, enabling a single model to simulate fluid-solid interactions, shock\nwaves, thermal convection, and multi-phase dynamics without being told the\nunderlying equations. GPhyT achieves three critical breakthroughs: (1) superior\nperformance across multiple physics domains, outperforming specialized\narchitectures by up to 29x, (2) zero-shot generalization to entirely unseen\nphysical systems through in-context learning, and (3) stable long-term\npredictions through 50-timestep rollouts. By establishing that a single model\ncan learn generalizable physical principles from data alone, this work opens\nthe path toward a universal PFM that could transform computational science and\nengineering.", "published": "2025-09-17 08:19:57", "link": "http://arxiv.org/abs/2509.13805v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation", "abstract": "Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous\nspace operations such as rendezvous, docking, and in-orbit servicing. Hybrid\npipelines that combine object detection, keypoint regression, and\nPerspective-n-Point (PnP) solvers have recently achieved strong results on\nsynthetic datasets, yet their performance deteriorates sharply on real or\nlab-generated imagery due to the persistent synthetic-to-real domain gap.\nExisting unsupervised domain adaptation approaches aim to mitigate this issue\nbut often underperform when a modest number of labeled target samples are\navailable. In this work, we propose the first Supervised Domain Adaptation\n(SDA) framework tailored for SPE keypoint regression. Building on the Learning\nInvariant Representation and Risk (LIRR) paradigm, our method jointly optimizes\ndomain-invariant representations and task-specific risk using both labeled\nsynthetic and limited labeled real data, thereby reducing generalization error\nunder domain shift. Extensive experiments on the SPEED+ benchmark demonstrate\nthat our approach consistently outperforms source-only, fine-tuning, and oracle\nbaselines. Notably, with only 5% labeled target data, our method matches or\nsurpasses oracle performance trained on larger fractions of labeled data. The\nframework is lightweight, backbone-agnostic, and computationally efficient,\noffering a practical pathway toward robust and deployable spacecraft pose\nestimation in real-world space environments.", "published": "2025-09-17 08:03:05", "link": "http://arxiv.org/abs/2509.13792v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching", "abstract": "Recent advancements in Diffusion Transformers (DiTs) have established them as\nthe state-of-the-art method for video generation. However, their inherently\nsequential denoising process results in inevitable latency, limiting real-world\napplicability. Existing acceleration methods either compromise visual quality\ndue to architectural modifications or fail to reuse intermediate features at\nproper granularity. Our analysis reveals that DiT blocks are the primary\ncontributors to inference latency. Across diffusion timesteps, the feature\nvariations of DiT blocks exhibit a U-shaped pattern with high similarity during\nintermediate timesteps, which suggests substantial computational redundancy. In\nthis paper, we propose Block-Wise Caching (BWCache), a training-free method to\naccelerate DiT-based video generation. BWCache dynamically caches and reuses\nfeatures from DiT blocks across diffusion timesteps. Furthermore, we introduce\na similarity indicator that triggers feature reuse only when the differences\nbetween block features at adjacent timesteps fall below a threshold, thereby\nminimizing redundant computations while maintaining visual fidelity. Extensive\nexperiments on several video diffusion models demonstrate that BWCache achieves\nup to 2.24$\\times$ speedup with comparable visual quality.", "published": "2025-09-17 07:58:36", "link": "http://arxiv.org/abs/2509.13789v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis", "abstract": "Large Language Model Powered Multi-Agent Systems (MASs) are increasingly\nemployed to automate complex real-world problems, such as programming and\nscientific discovery. Despite their promising, MASs are not without their\nflaws. However, failure attribution in MASs - pinpointing the specific agent\nactions responsible for failures - remains underexplored and labor-intensive,\nposing significant challenges for debugging and system improvement. To bridge\nthis gap, we propose FAMAS, the first spectrum-based failure attribution\napproach for MASs, which operates through systematic trajectory replay and\nabstraction, followed by spectrum analysis.The core idea of FAMAS is to\nestimate, from variations across repeated MAS executions, the likelihood that\neach agent action is responsible for the failure. In particular, we propose a\nnovel suspiciousness formula tailored to MASs, which integrates two key factor\ngroups, namely the agent behavior group and the action behavior group, to\naccount for the agent activation patterns and the action activation patterns\nwithin the execution trajectories of MASs. Through expensive evaluations\nagainst 12 baselines on the Who and When benchmark, FAMAS demonstrates superior\nperformance by outperforming all the methods in comparison.", "published": "2025-09-17 07:50:44", "link": "http://arxiv.org/abs/2509.13782v1", "categories": ["cs.SE", "cs.AI", "cs.MA", "D.2.2; I.2.1"], "primary_category": "cs.SE"}
{"title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "abstract": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.", "published": "2025-09-17 07:43:14", "link": "http://arxiv.org/abs/2509.13773v1", "categories": ["cs.AI", "cs.IR", "I.2.7; I.2.10"], "primary_category": "cs.AI"}
{"title": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "abstract": "While Code Language Models (CLMs) have demonstrated superior performance in\nsoftware engineering tasks such as code generation and summarization, recent\nempirical studies reveal a critical privacy vulnerability: these models exhibit\nunintended memorization of sensitive training data, enabling verbatim\nreproduction of confidential information when specifically prompted. To address\nthis issue, several approaches, including training data de-duplication and\ndifferential privacy augmentation, have been proposed. However, these methods\nrequire full-model retraining for deployed CLMs, which incurs substantial\ncomputational costs. In this paper, we aim to answer the following research\nquestion: Can sensitive information memorized by CLMs be erased effectively and\nefficiently?\n  We conduct a pioneering investigation into erasing sensitive memorization in\nCLMs through machine unlearning - a post-hoc modification method that removes\nspecific information from trained models without requiring full retraining.\nSpecifically, we first quantify the memorization risks of sensitive data within\nCLM training datasets and curate a high-risk dataset of 50,000 sensitive\nmemorized samples as unlearning targets. We study two widely used gradient\nascent-based unlearning approaches: the vanilla and constraint-based methods,\nand introduce CodeEraser, an advanced variant that selectively unlearns\nsensitive memorized segments in code while preserving the structural integrity\nand functional correctness of the surrounding code. Extensive experiments on\nthree families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,\nvalidate the effectiveness and efficiency of CodeEraser in erasing targeted\nsensitive memorization while maintaining model utility.", "published": "2025-09-17 07:12:35", "link": "http://arxiv.org/abs/2509.13755v1", "categories": ["cs.SE", "cs.AI", "cs.CR"], "primary_category": "cs.SE"}
{"title": "State Space Models over Directed Graphs", "abstract": "Directed graphs are ubiquitous across numerous domains, where the\ndirectionality of edges encodes critical causal dependencies. However, existing\nGNNs and graph Transformers tailored for directed graphs face two major\nchallenges: (1) effectively capturing long-range causal dependencies derived\nfrom directed edges; (2) balancing accuracy and training efficiency when\nprocessing large-scale graph datasets. In recent years, state space models\n(SSMs) have achieved substantial progress in causal sequence tasks, and their\nvariants designed for graphs have demonstrated state-of-the-art accuracy while\nmaintaining high efficiency across various graph learning benchmarks. However,\nexisting graph state space models are exclusively designed for undirected\ngraphs, which limits their performance in directed graph learning. To this end,\nwe propose an innovative approach DirEgo2Token which sequentializes directed\ngraphs via k-hop ego graphs. This marks the first systematic extension of state\nspace models to the field of directed graph learning. Building upon this, we\ndevelop DirGraphSSM, a novel directed graph neural network architecture that\nimplements state space models on directed graphs via the message-passing\nmechanism. Experimental results demonstrate that DirGraphSSM achieves\nstate-of-the-art performance on three representative directed graph learning\ntasks while attaining competitive performance on two additional tasks with\n1.5$\\times $ to 2$\\times $ training speed improvements compared to existing\nstate-of-the-art models.", "published": "2025-09-17 06:39:18", "link": "http://arxiv.org/abs/2509.13735v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Mitigating Query Selection Bias in Referring Video Object Segmentation", "abstract": "Recently, query-based methods have achieved remarkable performance in\nReferring Video Object Segmentation (RVOS) by using textual static object\nqueries to drive cross-modal alignment. However, these static queries are\neasily misled by distractors with similar appearance or motion, resulting in\n\\emph{query selection bias}. To address this issue, we propose Triple Query\nFormer (TQF), which factorizes the referring query into three specialized\ncomponents: an appearance query for static attributes, an intra-frame\ninteraction query for spatial relations, and an inter-frame motion query for\ntemporal association. Instead of relying solely on textual embeddings, our\nqueries are dynamically constructed by integrating both linguistic cues and\nvisual guidance. Furthermore, we introduce two motion-aware aggregation modules\nthat enhance object token representations: Intra-frame Interaction Aggregation\nincorporates position-aware interactions among objects within a single frame,\nwhile Inter-frame Motion Aggregation leverages trajectory-guided alignment\nacross frames to ensure temporal coherence. Extensive experiments on multiple\nRVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our\nstructured query design and motion-aware aggregation modules.", "published": "2025-09-17 06:17:23", "link": "http://arxiv.org/abs/2509.13722v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "abstract": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.", "published": "2025-09-17 05:14:11", "link": "http://arxiv.org/abs/2509.13704v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion", "abstract": "Controllable, high-fidelity mesh editing remains a significant challenge in\n3D content creation. Existing generative methods often struggle with complex\ngeometries and fail to produce detailed results. We propose CraftMesh, a novel\nframework for high-fidelity generative mesh manipulation via Poisson Seamless\nFusion. Our key insight is to decompose mesh editing into a pipeline that\nleverages the strengths of 2D and 3D generative models: we edit a 2D reference\nimage, then generate a region-specific 3D mesh, and seamlessly fuse it into the\noriginal model. We introduce two core techniques: Poisson Geometric Fusion,\nwhich utilizes a hybrid SDF/Mesh representation with normal blending to achieve\nharmonious geometric integration, and Poisson Texture Harmonization for\nvisually consistent texture blending. Experimental results demonstrate that\nCraftMesh outperforms state-of-the-art methods, delivering superior global\nconsistency and local detail in complex editing tasks.", "published": "2025-09-17 04:35:48", "link": "http://arxiv.org/abs/2509.13688v1", "categories": ["cs.GR", "cs.AI"], "primary_category": "cs.GR"}
{"title": "Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations", "abstract": "Code generation models are widely used in software development, yet their\nsensitivity to prompt phrasing remains under-examined. Identical requirements\nexpressed with different emotions or communication styles can yield divergent\noutputs, while most benchmarks emphasize only peak performance. We present\nPromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically\nequivalent prompt variants with emotion and personality templates, and that\nevaluates stability using probability aware continuous scoring or using binary\npass rates when logits are unavailable. The results are aggregated into a\nproposed area under curve metric (AUC-E) for cross model comparison. Across 14\nmodels from three families (Llama, Qwen, and DeepSeek), our study shows that\nperformance and stability behave as largely decoupled optimization objectives,\nand it reveals architectural and scale related patterns that challenge common\nassumptions about model robustness. The framework supports rapid screening for\nclosed-source models as well as detailed stability analysis in research\nsettings. PromptSE enables practitioners to quantify performance stability\ntrade offs for deployment and model selection, positioning prompt stability as\na complementary evaluation dimension alongside performance and fairness, and\ncontributing to more trustworthy AI-assisted software development tools.", "published": "2025-09-17 04:17:42", "link": "http://arxiv.org/abs/2509.13680v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation", "abstract": "Recently, Referring Image Segmentation (RIS) frameworks that pair the\nMultimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)\nhave achieved impressive results. However, adapting MLLM to segmentation is\ncomputationally intensive, primarily due to visual token redundancy. We observe\nthat traditional patch-wise visual projectors struggle to strike a balance\nbetween reducing the number of visual tokens and preserving semantic clarity,\noften retaining overly long token sequences to avoid performance drops.\nInspired by text tokenizers, we propose a novel semantic visual projector that\nleverages semantic superpixels generated by SAM to identify \"visual words\" in\nan image. By compressing and projecting semantic superpixels as visual tokens,\nour approach adaptively shortens the token sequence according to scene\ncomplexity while minimizing semantic loss in compression. To mitigate loss of\ninformation, we propose a semantic superpixel positional embedding to\nstrengthen MLLM's awareness of superpixel geometry and position, alongside a\nsemantic superpixel aggregator to preserve both fine-grained details inside\nsuperpixels and global context outside. Experiments show that our method cuts\nvisual tokens by 93% without compromising performance, notably speeding up MLLM\ntraining and inference, and outperforming existing compressive visual\nprojectors on RIS.", "published": "2025-09-17 04:04:08", "link": "http://arxiv.org/abs/2509.13676v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring", "abstract": "The ocean is warming and acidifying, increasing the risk of mass mortality\nevents for temperature-sensitive shellfish such as oysters. This motivates the\ndevelopment of long-term monitoring systems. However, human labor is costly and\nlong-duration underwater work is highly hazardous, thus favoring robotic\nsolutions as a safer and more efficient option. To enable underwater robots to\nmake real-time, environment-aware decisions without human intervention, we must\nequip them with an intelligent \"brain.\" This highlights the need for\npersistent,wide-area, and low-cost benthic monitoring. To this end, we present\nDREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term\nunderwater exploration and habitat monitoring. The results show that our\nframework is highly efficient in finding and exploring target objects (e.g.,\noysters, shipwrecks) without prior location information. In the\noyster-monitoring task, our framework takes 31.5% less time than the previous\nbaseline with the same amount of oysters. Compared to the vanilla VLM, it uses\n23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our\nframework successfully explores and maps the wreck without collisions,\nrequiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,\nwhile the vanilla model achieves 60.23% average coverage in our shipwreck\nenvironments.", "published": "2025-09-17 03:35:52", "link": "http://arxiv.org/abs/2509.13666v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Deep Lookup Network", "abstract": "Convolutional neural networks are constructed with massive operations with\ndifferent types and are highly computationally intensive. Among these\noperations, multiplication operation is higher in computational complexity and\nusually requires {more} energy consumption with longer inference time than\nother operations, which hinders the deployment of convolutional neural networks\non mobile devices. In many resource-limited edge devices, complicated\noperations can be calculated via lookup tables to reduce computational cost.\nMotivated by this, in this paper, we introduce a generic and efficient lookup\noperation which can be used as a basic operation for the construction of neural\nnetworks. Instead of calculating the multiplication of weights and activation\nvalues, simple yet efficient lookup operations are adopted to compute their\nresponses. To enable end-to-end optimization of the lookup operation, we\nconstruct the lookup tables in a differentiable manner and propose several\ntraining strategies to promote their convergence. By replacing computationally\nexpensive multiplication operations with our lookup operations, we develop\nlookup networks for the image classification, image super-resolution, and point\ncloud classification tasks. It is demonstrated that our lookup networks can\nbenefit from the lookup operations to achieve higher efficiency in terms of\nenergy consumption and inference speed while maintaining competitive\nperformance to vanilla convolutional networks. Extensive experiments show that\nour lookup networks produce state-of-the-art performance on different tasks\n(both classification and regression tasks) and different data types (both\nimages and point clouds).", "published": "2025-09-17 03:31:41", "link": "http://arxiv.org/abs/2509.13662v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?", "abstract": "As software development practices increasingly adopt AI-powered tools,\nensuring that such tools can support secure coding has become critical. This\nstudy evaluates the effectiveness of GitHub Copilot's recently introduced code\nreview feature in detecting security vulnerabilities. Using a curated set of\nlabeled vulnerable code samples drawn from diverse open-source projects\nspanning multiple programming languages and application domains, we\nsystematically assessed Copilot's ability to identify and provide feedback on\ncommon security flaws. Contrary to expectations, our results reveal that\nCopilot's code review frequently fails to detect critical vulnerabilities such\nas SQL injection, cross-site scripting (XSS), and insecure deserialization.\nInstead, its feedback primarily addresses low-severity issues, such as coding\nstyle and typographical errors. These findings expose a significant gap between\nthe perceived capabilities of AI-assisted code review and its actual\neffectiveness in supporting secure development practices. Our results highlight\nthe continued necessity of dedicated security tools and manual code audits to\nensure robust software security.", "published": "2025-09-17 02:56:21", "link": "http://arxiv.org/abs/2509.13650v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis", "abstract": "Despite the significant progress of deep learning models in multitude of\napplications, their adaption in planning and policy related areas remains\nchallenging due to the black-box nature of these models. In this work, we\ndevelop a set of DeepLogit models that follow a novel sequentially constrained\napproach in estimating deep learning models for transport policy analysis. In\nthe first step of the proposed approach, we estimate a convolutional neural\nnetwork (CNN) model with only linear terms, which is equivalent of a\nlinear-in-parameter multinomial logit model. We then estimate other deep\nlearning models by constraining the parameters that need interpretability at\nthe values obtained in the linear-in-parameter CNN model and including higher\norder terms or by introducing advanced deep learning architectures like\nTransformers. Our approach can retain the interpretability of the selected\nparameters, yet provides significantly improved model accuracy than the\ndiscrete choice model. We demonstrate our approach on a transit route choice\nexample using real-world transit smart card data from Singapore. This study\nshows the potential for a unifying approach, where theory-based discrete choice\nmodel (DCM) and data-driven AI models can leverage each other's strengths in\ninterpretability and predictive power. With the availability of larger datasets\nand more complex constructions, such approach can lead to more accurate models\nusing discrete choice models while maintaining its applicability in planning\nand policy-related areas. Our code is available on\nhttps://github.com/jeremyoon/route-choice/ .", "published": "2025-09-17 02:08:34", "link": "http://arxiv.org/abs/2509.13633v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Secure, Scalable and Privacy Aware Data Strategy in Cloud", "abstract": "The enterprises today are faced with the tough challenge of processing,\nstoring large amounts of data in a secure, scalable manner and enabling\ndecision makers to make quick, informed data driven decisions. This paper\naddresses this challenge and develops an effective enterprise data strategy in\nthe cloud. Various components of an effective data strategy are discussed and\narchitectures addressing security, scalability and privacy aspects are\nprovided.", "published": "2025-09-17 01:56:07", "link": "http://arxiv.org/abs/2509.13627v1", "categories": ["cs.CR", "cs.AI", "cs.DC"], "primary_category": "cs.CR"}
{"title": "Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval", "abstract": "Access to reliable mental health information is vital for early help-seeking,\nyet expanding knowledge bases is resource-intensive and often misaligned with\nuser needs. This results in poor performance of retrieval systems when\npresented concerns are not covered or expressed in informal or contextualized\nlanguage. We present an AI-based gap-informed framework for corpus augmentation\nthat authentically identifies underrepresented topics (gaps) by overlaying\nnaturalistic user data such as forum posts in order to prioritize expansions\nbased on coverage and usefulness. In a case study, we compare Directed\n(gap-informed augmentations) with Non-Directed augmentation (random additions),\nevaluating the relevance and usefulness of retrieved information across four\nretrieval-augmented generation (RAG) pipelines. Directed augmentation achieved\nnear-optimal performance with modest expansions--requiring only a 42% increase\nfor Query Transformation, 74% for Reranking and Hierarchical, and 318% for\nBaseline--to reach ~95% of the performance of an exhaustive reference corpus.\nIn contrast, Non-Directed augmentation required substantially larger and thus\npractically infeasible expansions to achieve comparable performance (232%,\n318%, 403%, and 763%, respectively). These results show that strategically\ntargeted corpus growth can reduce content creation demands while sustaining\nhigh retrieval and provision quality, offering a scalable approach for building\ntrusted health information repositories and supporting generative AI\napplications in high-stakes domains.", "published": "2025-09-17 01:54:11", "link": "http://arxiv.org/abs/2509.13626v1", "categories": ["cs.IR", "cs.AI", "H.3.3; J.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "A reduced-order derivative-informed neural operator for subsurface fluid-flow", "abstract": "Neural operators have emerged as cost-effective surrogates for expensive\nfluid-flow simulators, particularly in computationally intensive tasks such as\npermeability inversion from time-lapse seismic data, and uncertainty\nquantification. In these applications, the fidelity of the surrogate's\ngradients with respect to system parameters is crucial, as the accuracy of\ndownstream tasks, such as optimization and Bayesian inference, relies directly\non the quality of the derivative information. Recent advances in\nphysics-informed methods have leveraged derivative information to improve\nsurrogate accuracy. However, incorporating explicit Jacobians can become\ncomputationally prohibitive, as the complexity typically scales quadratically\nwith the number of input parameters. To address this limitation, we propose\nDeFINO (Derivative-based Fisher-score Informed Neural Operator), a\nreduced-order, derivative-informed training framework. DeFINO integrates\nFourier neural operators (FNOs) with a novel derivative-based training strategy\nguided by the Fisher Information Matrix (FIM). By projecting Jacobians onto\ndominant eigen-directions identified by the FIM, DeFINO captures critical\nsensitivity information directly informed by observational data, significantly\nreducing computational expense. We validate DeFINO through synthetic\nexperiments in the context of subsurface multi-phase fluid-flow, demonstrating\nimprovements in gradient accuracy while maintaining robust forward predictions\nof underlying fluid dynamics. These results highlight DeFINO's potential to\noffer practical, scalable solutions for inversion problems in complex\nreal-world scenarios, all at substantially reduced computational cost.", "published": "2025-09-17 01:30:44", "link": "http://arxiv.org/abs/2509.13620v1", "categories": ["physics.comp-ph", "cs.AI", "cs.LG"], "primary_category": "physics.comp-ph"}
{"title": "Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation", "abstract": "Beyond general web-scale search, social network search uniquely enables users\nto retrieve information and discover potential connections within their social\ncontext. We introduce a framework of modernized Facebook Group Scoped Search by\nblending traditional keyword-based retrieval with embedding-based retrieval\n(EBR) to improve the search relevance and diversity of search results. Our\nsystem integrates semantic retrieval into the existing keyword search pipeline,\nenabling users to discover more contextually relevant group posts. To\nrigorously assess the impact of this blended approach, we introduce a novel\nevaluation framework that leverages large language models (LLMs) to perform\noffline relevance assessments, providing scalable and consistent quality\nbenchmarks. Our results demonstrate that the blended retrieval system\nsignificantly enhances user engagement and search quality, as validated by both\nonline metrics and LLM-based evaluation. This work offers practical insights\nfor deploying and evaluating advanced retrieval systems in large-scale,\nreal-world social platforms.", "published": "2025-09-17 00:22:08", "link": "http://arxiv.org/abs/2509.13603v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "GenExam: A Multidisciplinary Text-to-Image Exam", "abstract": "Exams are a fundamental test of expert-level intelligence and require\nintegrated understanding, reasoning, and generation. Existing exam-style\nbenchmarks mainly focus on understanding and reasoning tasks, and current\ngeneration benchmarks emphasize the illustration of world knowledge and visual\nconcepts, neglecting the evaluation of rigorous drawing exams. We introduce\nGenExam, the first benchmark for multidisciplinary text-to-image exams,\nfeaturing 1,000 samples across 10 subjects with exam-style prompts organized\nunder a four-level taxonomy. Each problem is equipped with ground-truth images\nand fine-grained scoring points to enable a precise evaluation of semantic\ncorrectness and visual plausibility. Experiments show that even\nstate-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve\nless than 15% strict scores, and most models yield almost 0%, suggesting the\ngreat challenge of our benchmark. By framing image generation as an exam,\nGenExam offers a rigorous assessment of models' ability to integrate knowledge,\nreasoning, and generation, providing insights on the path to general AGI.", "published": "2025-09-17 17:59:14", "link": "http://arxiv.org/abs/2509.14232v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cin\u00e9aste: A Fine-grained Contextual Movie Question Answering Benchmark", "abstract": "While recent advancements in vision-language models have improved video\nunderstanding, diagnosing their capacity for deep, narrative comprehension\nremains a challenge. Existing benchmarks often test short-clip recognition or\nuse template-based questions, leaving a critical gap in evaluating fine-grained\nreasoning over long-form narrative content. To address these gaps, we introduce\n$\\mathsf{Cin\\acute{e}aste}$, a comprehensive benchmark for long-form movie\nunderstanding. Our dataset comprises 3,119 multiple-choice question-answer\npairs derived from 1,805 scenes across 200 diverse movies, spanning five novel\nfine-grained contextual reasoning categories. We use GPT-4o to generate\ndiverse, context-rich questions by integrating visual descriptions, captions,\nscene titles, and summaries, which require deep narrative understanding. To\nensure high-quality evaluation, our pipeline incorporates a two-stage filtering\nprocess: Context-Independence filtering ensures questions require video\ncontext, while Contextual Veracity filtering validates factual consistency\nagainst the movie content, mitigating hallucinations. Experiments show that\nexisting MLLMs struggle on $\\mathsf{Cin\\acute{e}aste}$; our analysis reveals\nthat long-range temporal reasoning is a primary bottleneck, with the top\nopen-source model achieving only 63.15\\% accuracy. This underscores significant\nchallenges in fine-grained contextual understanding and the need for\nadvancements in long-form movie comprehension.", "published": "2025-09-17 17:58:06", "link": "http://arxiv.org/abs/2509.14227v1", "categories": ["cs.CV", "I.2.10; I.2.7"], "primary_category": "cs.CV"}
{"title": "MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping", "abstract": "Recent progress in dense SLAM has primarily targeted monocular setups, often\nat the expense of robustness and geometric coverage. We present MCGS-SLAM, the\nfirst purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting\n(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM\nfuses dense RGB inputs from multiple viewpoints into a unified, continuously\noptimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines\nposes and depths via dense photometric and geometric residuals, while a scale\nconsistency module enforces metric alignment across views using low-rank\npriors. The system supports RGB input and maintains real-time performance at\nlarge scale. Experiments on synthetic and real-world datasets show that\nMCGS-SLAM consistently yields accurate trajectories and photorealistic\nreconstructions, usually outperforming monocular baselines. Notably, the wide\nfield of view from multi-camera input enables reconstruction of side-view\nregions that monocular setups miss, critical for safe autonomous operation.\nThese results highlight the promise of multi-camera Gaussian Splatting SLAM for\nhigh-fidelity mapping in robotics and autonomous driving.", "published": "2025-09-17 17:27:53", "link": "http://arxiv.org/abs/2509.14191v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection", "abstract": "Vision-centric Bird's Eye View (BEV) perception holds considerable promise\nfor autonomous driving. Recent studies have prioritized efficiency or accuracy\nenhancements, yet the issue of domain shift has been overlooked, leading to\nsubstantial performance degradation upon transfer. We identify major domain\ngaps in real-world cross-domain scenarios and initiate the first effort to\naddress the Domain Adaptation (DA) challenge in multi-view 3D object detection\nfor BEV perception. Given the complexity of BEV perception approaches with\ntheir multiple components, domain shift accumulation across multi-geometric\nspaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain\nadaptation. In this paper, we introduce an innovative geometric-aware\nteacher-student framework, BEVUDA++, to diminish this issue, comprising a\nReliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.\nSpecifically, RDT effectively blends target LiDAR with dependable depth\npredictions to generate depth-aware information based on uncertainty\nestimation, enhancing the extraction of Voxel and BEV features that are\nessential for understanding the target domain. To collaboratively reduce the\ndomain shift, GCS maps features from multiple spaces into a unified geometric\nembedding space, thereby narrowing the gap in data distribution between the two\ndomains. Additionally, we introduce a novel Uncertainty-guided Exponential\nMoving Average (UEMA) to further reduce error accumulation due to domain shifts\ninformed by previously obtained uncertainty guidance. To demonstrate the\nsuperiority of our proposed method, we execute comprehensive experiments in\nfour cross-domain scenarios, securing state-of-the-art performance in BEV 3D\nobject detection tasks, e.g., 12.9\\% NDS and 9.5\\% mAP enhancement on Day-Night\nadaptation.", "published": "2025-09-17 16:31:40", "link": "http://arxiv.org/abs/2509.14151v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An Exploratory Study on Abstract Images and Visual Representations Learned from Them", "abstract": "Imagine living in a world composed solely of primitive shapes, could you\nstill recognise familiar objects? Recent studies have shown that abstract\nimages-constructed by primitive shapes-can indeed convey visual semantic\ninformation to deep learning models. However, representations obtained from\nsuch images often fall short compared to those derived from traditional raster\nimages. In this paper, we study the reasons behind this performance gap and\ninvestigate how much high-level semantic content can be captured at different\nabstraction levels. To this end, we introduce the Hierarchical Abstraction\nImage Dataset (HAID), a novel data collection that comprises abstract images\ngenerated from normal raster images at multiple levels of abstraction. We then\ntrain and evaluate conventional vision systems on HAID across various tasks\nincluding classification, segmentation, and object detection, providing a\ncomprehensive study between rasterised and abstract image representations. We\nalso discuss if the abstract image can be considered as a potentially effective\nformat for conveying visual semantic information and contributing to vision\ntasks.", "published": "2025-09-17 16:30:34", "link": "http://arxiv.org/abs/2509.14149v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook", "abstract": "This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim\nto bring together different approaches in multimodal machine learning and LLMs\nvia a large benchmark. We hope it better allows researchers to follow the\nstate-of-the-art in this very dynamic area. Meanwhile, a growing number of\ntestbeds have boosted the evolution of general-purpose large language models.\nThus, this year's MARS2 focuses on real-world and specialized scenarios to\nbroaden the multimodal reasoning applications of MLLMs. Our organizing team\nreleased two tailored datasets Lens and AdsQA as test sets, which support\ngeneral reasoning in 12 daily scenarios and domain-specific reasoning in\nadvertisement videos, respectively. We evaluated 40+ baselines that include\nboth generalist MLLMs and task-specific models, and opened up three competition\ntracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question\nAnswering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative\nAdvertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and\nindustrial institutions have registered and 40+ valid submissions (out of\n1200+) have been included in our ranking lists. Our datasets, code sets (40+\nbaselines and 15+ participants' methods), and rankings are publicly available\non the MARS2 workshop website and our GitHub organization page\nhttps://github.com/mars2workshop/, where our updates and announcements of\nupcoming events will be continuously provided.", "published": "2025-09-17 16:21:34", "link": "http://arxiv.org/abs/2509.14142v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection", "abstract": "Digital beautification through social media filters has become increasingly\npopular, raising concerns about the reliability of facial images and videos and\nthe effectiveness of automated face analysis. This issue is particularly\ncritical for digital manipulation detectors, systems aiming at distinguishing\nbetween genuine and manipulated data, especially in cases involving deepfakes\nand morphing attacks designed to deceive humans and automated facial\nrecognition. This study examines whether beauty filters impact the performance\nof deepfake and morphing attack detectors. We perform a comprehensive analysis,\nevaluating multiple state-of-the-art detectors on benchmark datasets before and\nafter applying various smoothing filters. Our findings reveal performance\ndegradation, highlighting vulnerabilities introduced by facial enhancements and\nunderscoring the need for robust detection models resilient to such\nalterations.", "published": "2025-09-17 15:59:44", "link": "http://arxiv.org/abs/2509.14120v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows", "abstract": "Accurate histopathological diagnosis often requires multiple differently\nstained tissue sections, a process that is time-consuming, labor-intensive, and\nenvironmentally taxing due to the use of multiple chemical stains. Recently,\nvirtual staining has emerged as a promising alternative that is faster,\ntissue-conserving, and environmentally friendly. However, existing virtual\nstaining methods face significant challenges in clinical applications,\nprimarily due to their reliance on well-aligned paired data. Obtaining such\ndata is inherently difficult because chemical staining processes can distort\ntissue structures, and a single tissue section cannot undergo multiple staining\nprocedures without damage or loss of information. As a result, most available\nvirtual staining datasets are either unpaired or roughly paired, making it\ndifficult for existing methods to achieve accurate pixel-level supervision. To\naddress this challenge, we propose a robust virtual staining framework\nfeaturing cascaded registration mechanisms to resolve spatial mismatches\nbetween generated outputs and their corresponding ground truth. Experimental\nresults demonstrate that our method significantly outperforms state-of-the-art\nmodels across five datasets, achieving an average improvement of 3.2% on\ninternal datasets and 10.1% on external datasets. Moreover, in datasets with\nsubstantial misalignment, our approach achieves a remarkable 23.8% improvement\nin peak signal-to-noise ratio compared to baseline models. The exceptional\nrobustness of the proposed method across diverse datasets simplifies the data\nacquisition process for virtual staining and offers new insights for advancing\nits development.", "published": "2025-09-17 15:58:59", "link": "http://arxiv.org/abs/2509.14119v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts", "abstract": "Self-supervised learning through masked autoencoders has attracted great\nattention for remote sensing (RS) foundation model (FM) development, enabling\nimproved representation learning across diverse sensors and downstream tasks.\nHowever, existing RS FMs often either suffer from substantial computational\ncomplexity during both training and inference or exhibit limited\nrepresentational capacity. These issues restrict their practical applicability\nin RS. To address this limitation, we propose an adaptation for enhancing the\nefficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism\ninto the FM. The integration of Soft MoEs into the FM allows modality-specific\nexpert specialization alongside shared cross-sensor representation learning. To\ndemonstrate the effectiveness of our adaptation, we apply it on the\nCross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor\nMixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic\ndescriptor-driven sampling strategy for the construction of a representative\nand diverse training set to train our CSMoE model. Extensive experiments on\nscene classification, semantic segmentation, and content-based image retrieval\ndemonstrate that our adaptation yields a reduction in computational\nrequirements while maintaining or improving representational performance.\nCompared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off\nbetween representational capacity, accuracy, and computational efficiency. On\naverage, CSMoE achieves more than twice the computational efficiency of\nexisting RS FMs, while maintaining competitive performance across all\nexperiments. These results show the effectiveness of the proposed adaptation\nfor creating computationally efficient RS FMs. The code for the model, the\ntraining set creation, and the model weights will be available at\nhttps://git.tu-berlin.de/rsim/csmoe.", "published": "2025-09-17 15:47:18", "link": "http://arxiv.org/abs/2509.14104v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing", "abstract": "Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,\nvisible, and audio-visual events without temporal annotations. Previous work\nhas emphasized refining global predictions through contrastive or collaborative\nlearning, but neglected stable segment-level supervision and class-aware\ncross-modal alignment. To address this, we propose two strategies: (1) an\nexponential moving average (EMA)-guided pseudo supervision framework that\ngenerates reliable segment-level masks via adaptive thresholds or top-k\nselection, offering stable temporal guidance beyond video-level labels; and (2)\na class-aware cross-modal agreement (CMA) loss that aligns audio and visual\nembeddings at reliable segment-class pairs, ensuring consistency across\nmodalities while preserving temporal structure. Evaluations on LLP and UnAV-100\ndatasets shows that our method achieves state-of-the-art (SOTA) performance\nacross multiple metrics.", "published": "2025-09-17 15:38:05", "link": "http://arxiv.org/abs/2509.14097v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration", "abstract": "Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary\nnovel categories, offering a scalable and annotation-efficient solution.\nTraditionally, most ZSAD works have been based on the CLIP model, which\nperforms anomaly detection by calculating the similarity between visual and\ntext embeddings. Recently, vision foundation models such as DINOv3 have\ndemonstrated strong transferable representation capabilities. In this work, we\nare the first to adapt DINOv3 for ZSAD. However, this adaptation presents two\nkey challenges: (i) the domain bias between large-scale pretraining data and\nanomaly detection tasks leads to feature misalignment; and (ii) the inherent\nbias toward global semantics in pretrained representations often leads to\nsubtle anomalies being misinterpreted as part of the normal foreground objects,\nrather than being distinguished as abnormal regions. To overcome these\nchallenges, we introduce AD-DINOv3, a novel vision-language multimodal\nframework designed for ZSAD. Specifically, we formulate anomaly detection as a\nmultimodal contrastive learning problem, where DINOv3 is employed as the visual\nbackbone to extract patch tokens and a CLS token, and the CLIP text encoder\nprovides embeddings for both normal and abnormal prompts. To bridge the domain\ngap, lightweight adapters are introduced in both modalities, enabling their\nrepresentations to be recalibrated for the anomaly detection task. Beyond this\nbaseline alignment, we further design an Anomaly-Aware Calibration Module\n(AACM), which explicitly guides the CLS token to attend to anomalous regions\nrather than generic foreground semantics, thereby enhancing discriminability.\nExtensive experiments on eight industrial and medical benchmarks demonstrate\nthat AD-DINOv3 consistently matches or surpasses state-of-the-art methods,\nverifying its superiority as a general zero-shot anomaly detection framework.", "published": "2025-09-17 15:29:25", "link": "http://arxiv.org/abs/2509.14084v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement", "abstract": "Current multi-object tracking (MOT) algorithms typically overlook issues\ninherent in low-quality videos, leading to significant degradation in tracking\nperformance when confronted with real-world image deterioration. Therefore,\nadvancing the application of MOT algorithms in real-world low-quality video\nscenarios represents a critical and meaningful endeavor. To address the\nchallenges posed by low-quality scenarios, inspired by vision-language models,\nthis paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking\nframework (VSE-MOT). Specifically, we first design a tri-branch architecture\nthat leverages a vision-language model to extract global visual semantic\ninformation from images and fuse it with query vectors. Subsequently, to\nfurther enhance the utilization of visual semantic information, we introduce\nthe Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion\nModule (VSFM). The MOT-Adapter adapts the extracted global visual semantic\ninformation to suit multi-object tracking tasks, while the VSFM improves the\nefficacy of feature fusion. Through extensive experiments, we validate the\neffectiveness and superiority of the proposed method in real-world low-quality\nvideo scenarios. Its tracking performance metrics outperform those of existing\nmethods by approximately 8% to 20%, while maintaining robust performance in\nconventional scenarios.", "published": "2025-09-17 15:04:45", "link": "http://arxiv.org/abs/2509.14060v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Wan-Animate: Unified Character Animation and Replacement with Holistic Replication", "abstract": "We introduce Wan-Animate, a unified framework for character animation and\nreplacement. Given a character image and a reference video, Wan-Animate can\nanimate the character by precisely replicating the expressions and movements of\nthe character in the video to generate high-fidelity character videos.\nAlternatively, it can integrate the animated character into the reference video\nto replace the original character, replicating the scene's lighting and color\ntone to achieve seamless environmental integration. Wan-Animate is built upon\nthe Wan model. To adapt it for character animation tasks, we employ a modified\ninput paradigm to differentiate between reference conditions and regions for\ngeneration. This design unifies multiple tasks into a common symbolic\nrepresentation. We use spatially-aligned skeleton signals to replicate body\nmotion and implicit facial features extracted from source images to reenact\nexpressions, enabling the generation of character videos with high\ncontrollability and expressiveness. Furthermore, to enhance environmental\nintegration during character replacement, we develop an auxiliary Relighting\nLoRA. This module preserves the character's appearance consistency while\napplying the appropriate environmental lighting and color tone. Experimental\nresults demonstrate that Wan-Animate achieves state-of-the-art performance. We\nare committed to open-sourcing the model weights and its source code.", "published": "2025-09-17 15:00:57", "link": "http://arxiv.org/abs/2509.14055v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings", "abstract": "Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy\n(RP) experience biochemical recurrence (BCR), characterized by increased\nprostate specific antigen (PSA) and associated with increased mortality.\nAccurate early prediction of BCR, at the time of RP, would contribute to prompt\nadaptive clinical decision-making and improved patient outcomes. In this work,\nwe propose prostate cancer BCR prediction via fused multi-modal embeddings\n(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and\npathology data, following an intermediate fusion configuration in combination\nwith Cox Proportional Hazard regressors. Quantitative evaluation of our\nproposed approach reveals superior performance, when compared with late fusion\nconfigurations, yielding a mean C-index of 0.861 ($\\sigma=0.112$) on the\ninternal 5-fold nested cross-validation framework, and a C-index of 0.7103 on\nthe hold out data of CHIMERA 2025 challenge validation leaderboard.", "published": "2025-09-17 14:54:29", "link": "http://arxiv.org/abs/2509.14051v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAIL-VL2 Technical Report", "abstract": "We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)\nfor comprehensive multimodal understanding and reasoning. As the successor to\nSAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B\nparameter scales across diverse image and video benchmarks, demonstrating\nstrong capabilities from fine-grained perception to complex reasoning. Three\ncore innovations drive its effectiveness. First, a large-scale data curation\npipeline with scoring and filtering strategies enhances both quality and\ndistribution across captioning, OCR, QA, and video data, improving training\nefficiency. Second, a progressive training framework begins with a powerful\npre-trained vision encoder (SAIL-ViT), advances through multimodal\npre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that\nsystematically strengthens model capabilities. Third, architectural advances\nextend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.\nWith these contributions, SAIL-VL2 demonstrates competitive performance across\n106 datasets and achieves state-of-the-art results on challenging reasoning\nbenchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass\nleaderboard, SAIL-VL2-2B ranks first among officially released open-source\nmodels under the 4B parameter scale, while serving as an efficient and\nextensible foundation for the open-source multimodal community.", "published": "2025-09-17 14:34:02", "link": "http://arxiv.org/abs/2509.14033v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments", "abstract": "Drone detection in visually complex environments remains challenging due to\nbackground clutter, small object scale, and camouflage effects. While generic\nobject detectors like YOLO exhibit strong performance in low-texture scenes,\ntheir effectiveness degrades in cluttered environments with low\nobject-background separability. To address these limitations, this work\npresents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework\nthat integrates generic object detection with camouflage object detection\ntechniques. Building upon the original architecture, the proposed iteration\nintroduces systematic advancements in training data composition, feature fusion\nstrategies, and backbone design. Specifically, the training process leverages\nlarge-scale, photo-realistic synthetic data, complemented by a small set of\nreal-world samples, to enhance robustness under visually complex conditions.\nThe contribution of intermediate multi-scale FEDER features is systematically\nevaluated, and detection performance is comprehensively benchmarked across\nmultiple YOLO-based backbone configurations. Empirical results indicate that\nintegrating intermediate FEDER features, in combination with backbone upgrades,\ncontributes to notable performance improvements. In the most promising\nconfiguration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER\nfeatures derived from the DWD module -- these enhancements lead to a FNR\nreduction of up to 39.1 percentage points and a mAP increase of up to 62.8\npercentage points at an IoU threshold of 0.5, compared to the initial baseline.", "published": "2025-09-17 14:21:00", "link": "http://arxiv.org/abs/2509.14012v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MetricNet: Recovering Metric Scale in Generative Navigation Policies", "abstract": "Generative navigation policies have made rapid progress in improving\nend-to-end learned navigation. Despite their promising results, this paradigm\nhas two structural problems. First, the sampled trajectories exist in an\nabstract, unscaled space without metric grounding. Second, the control strategy\ndiscards the full path, instead moving directly towards a single waypoint. This\nleads to short-sighted and unsafe actions, moving the robot towards obstacles\nthat a complete and correctly scaled path would circumvent. To address these\nissues, we propose MetricNet, an effective add-on for generative navigation\nthat predicts the metric distance between waypoints, grounding policy outputs\nin real-world coordinates. We evaluate our method in simulation with a new\nbenchmarking framework and show that executing MetricNet-scaled waypoints\nsignificantly improves both navigation and exploration performance. Beyond\nsimulation, we further validate our approach in real-world experiments.\nFinally, we propose MetricNav, which integrates MetricNet into a navigation\npolicy to guide the robot away from obstacles while still moving towards the\ngoal.", "published": "2025-09-17 13:37:13", "link": "http://arxiv.org/abs/2509.13965v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation", "abstract": "Visual counting is a fundamental yet challenging task, especially when users\nneed to count objects of a specific type in complex scenes. While recent\nmodels, including class-agnostic counting models and large vision-language\nmodels (VLMs), show promise in counting tasks, their ability to perform\nfine-grained, intent-driven counting remains unclear. In this paper, we\nintroduce PairTally, a benchmark dataset specifically designed to evaluate\nfine-grained visual counting. Each of the 681 high-resolution images in\nPairTally contains two object categories, requiring models to distinguish and\ncount based on subtle differences in shape, size, color, or semantics. The\ndataset includes both inter-category (distinct categories) and intra-category\n(closely related subcategories) settings, making it suitable for rigorous\nevaluation of selective counting capabilities. We benchmark a variety of\nstate-of-the-art models, including exemplar-based methods, language-prompted\nmodels, and large VLMs. Our results show that despite recent advances, current\nmodels struggle to reliably count what users intend, especially in fine-grained\nand visually ambiguous cases. PairTally provides a new foundation for\ndiagnosing and improving fine-grained visual counting systems.", "published": "2025-09-17 13:06:58", "link": "http://arxiv.org/abs/2509.13939v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Noise-Level Diffusion Guidance: Well Begun is Half Done", "abstract": "Diffusion models have achieved state-of-the-art image generation. However,\nthe random Gaussian noise used to start the diffusion process influences the\nfinal output, causing variations in image quality and prompt adherence.\nExisting noise-level optimization approaches generally rely on extra dataset\nconstruction, additional networks, or backpropagation-based optimization,\nlimiting their practicality. In this paper, we propose Noise Level Guidance\n(NLG), a simple, efficient, and general noise-level optimization approach that\nrefines initial noise by increasing the likelihood of its alignment with\ngeneral guidance - requiring no additional training data, auxiliary networks,\nor backpropagation. The proposed NLG approach provides a unified framework\ngeneralizable to both conditional and unconditional diffusion models,\naccommodating various forms of diffusion-level guidance. Extensive experiments\non five standard benchmarks demonstrate that our approach enhances output\ngeneration quality and input condition adherence. By seamlessly integrating\nwith existing guidance methods while maintaining computational efficiency, our\nmethod establishes NLG as a practical and scalable enhancement to diffusion\nmodels. Code can be found at\nhttps://github.com/harveymannering/NoiseLevelGuidance.", "published": "2025-09-17 13:05:59", "link": "http://arxiv.org/abs/2509.13936v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification", "abstract": "Diffusion models like Stable Diffusion have become prominent in visual\nsynthesis tasks due to their powerful customization capabilities, which also\nintroduce significant security risks, including deepfakes and copyright\ninfringement. In response, a class of methods known as protective perturbation\nemerged, which mitigates image misuse by injecting imperceptible adversarial\nnoise. However, purification can remove protective perturbations, thereby\nexposing images again to the risk of malicious forgery. In this work, we\nformalize the anti-purification task, highlighting challenges that hinder\nexisting approaches, and propose a simple diagnostic protective perturbation\nnamed AntiPure. AntiPure exposes vulnerabilities of purification within the\n\"purification-customization\" workflow, owing to two guidance mechanisms: 1)\nPatch-wise Frequency Guidance, which reduces the model's influence over\nhigh-frequency components in the purified image, and 2) Erroneous Timestep\nGuidance, which disrupts the model's denoising strategy across different\ntimesteps. With additional guidance, AntiPure embeds imperceptible\nperturbations that persist under representative purification settings,\nachieving effective post-customization distortion. Experiments show that, as a\nstress test for purification, AntiPure achieves minimal perceptual discrepancy\nand maximal distortion, outperforming other protective perturbation methods\nwithin the purification-customization workflow.", "published": "2025-09-17 11:30:13", "link": "http://arxiv.org/abs/2509.13922v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration", "abstract": "Large Vision-Language Models (LVLMs) have manifested strong visual question\nanswering capability. However, they still struggle with aligning the rationale\nand the generated answer, leading to inconsistent reasoning and incorrect\nresponses. To this end, this paper introduces the Self-Rationale Calibration\n(SRC) framework to iteratively calibrate the alignment between rationales and\nanswers. SRC begins by employing a lightweight \"rationale fine-tuning\"\napproach, which modifies the model's response format to require a rationale\nbefore deriving an answer without explicit prompts. Next, SRC searches for a\ndiverse set of candidate responses from the fine-tuned LVLMs for each sample,\nfollowed by a proposed pairwise scoring strategy using a tailored scoring\nmodel, R-Scorer, to evaluate both rationale quality and factual consistency of\ncandidates. Based on a confidence-weighted preference curation process, SRC\ndecouples the alignment calibration into a preference fine-tuning manner,\nleading to significant improvements of LVLMs in perception, reasoning, and\ngeneralization across multiple benchmarks. Our results emphasize the\nrationale-oriented alignment in exploring the potential of LVLMs.", "published": "2025-09-17 11:27:33", "link": "http://arxiv.org/abs/2509.13919v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation", "abstract": "Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point\nlabels for an unlabeled point cloud, given only a few labeled examples. To\nextract discriminative representations from the limited support set, existing\nmethods have constructed prototypes using conventional algorithms such as\nfarthest point sampling. However, we point out that its initial randomness\nsignificantly affects FS-PCS performance and that the prototype generation\nprocess remains underexplored despite its prevalence. This motivates us to\ninvestigate an advanced prototype generation method based on attention\nmechanism. Despite its potential, we found that vanilla module suffers from the\ndistributional gap between learnable prototypical tokens and support features.\nTo overcome this, we propose White Aggregation and Restoration Module (WARM),\nwhich resolves the misalignment by sandwiching cross-attention between\nwhitening and coloring transformations. Specifically, whitening aligns the\nsupport features to prototypical tokens before attention process, and\nsubsequently coloring restores the original distribution to the attended\ntokens. This simple yet effective design enables robust attention, thereby\ngenerating representative prototypes by capturing the semantic relationships\namong support features. Our method achieves state-of-the-art performance with a\nsignificant margin on multiple FS-PCS benchmarks, demonstrating its\neffectiveness through extensive experiments.", "published": "2025-09-17 11:13:16", "link": "http://arxiv.org/abs/2509.13907v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View", "abstract": "Hand tracking holds great promise for intuitive interaction paradigms, but\nframe-based methods often struggle to meet the requirements of accuracy, low\nlatency, and energy efficiency, especially in resource-constrained settings\nsuch as Extended Reality (XR) devices. Event cameras provide $\\mu$s-level\ntemporal resolution at mW-level power by asynchronously sensing brightness\nchanges. In this work, we present EvHand-FPV, a lightweight framework for\negocentric First-Person-View 3D hand tracking from a single event camera. We\nconstruct an event-based FPV dataset that couples synthetic training data with\n3D labels and real event data with 2D labels for evaluation to address the\nscarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based\nregion of interest (ROI) that localizes the hand region via geometric cues,\ncombined with an end-to-end mapping strategy that embeds ROI offsets into the\nnetwork to reduce computation without explicit reconstruction, and a multi-task\nlearning strategy with an auxiliary geometric feature head that improves\nrepresentations without test-time overhead. On our real FPV test set,\nEvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from\n11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It\nalso maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results\ndemonstrate accurate and efficient egocentric event-based hand tracking\nsuitable for on-device XR applications. The dataset and code are available at\nhttps://github.com/zen5x5/EvHand-FPV.", "published": "2025-09-17 10:23:30", "link": "http://arxiv.org/abs/2509.13883v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis", "abstract": "Pelvic fractures pose significant diagnostic challenges, particularly in\ncases where fracture signs are subtle or invisible on standard radiographs. To\naddress this, we introduce PelFANet, a dual-stream attention network that fuses\nraw pelvic X-rays with segmented bone images to improve fracture\nclassification. The network em-ploys Fused Attention Blocks (FABlocks) to\niteratively exchange and refine fea-tures from both inputs, capturing global\ncontext and localized anatomical detail. Trained in a two-stage pipeline with a\nsegmentation-guided approach, PelFANet demonstrates superior performance over\nconventional methods. On the AMERI dataset, it achieves 88.68% accuracy and\n0.9334 AUC on visible fractures, while generalizing effectively to invisible\nfracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained\non them. These results highlight the clini-cal potential of anatomy-aware\ndual-input architectures for robust fracture detec-tion, especially in\nscenarios with subtle radiographic presentations.", "published": "2025-09-17 10:06:08", "link": "http://arxiv.org/abs/2509.13873v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Distractor-Aware Memory-Based Visual Object Tracking", "abstract": "Recent emergence of memory-based video segmentation methods such as SAM2 has\nled to models with excellent performance in segmentation tasks, achieving\nleading results on numerous benchmarks. However, these modes are not fully\nadjusted for visual object tracking, where distractors (i.e., objects visually\nsimilar to the target) pose a key challenge. In this paper we propose a\ndistractor-aware drop-in memory module and introspection-based management\nmethod for SAM2, leading to DAM4SAM. Our design effectively reduces the\ntracking drift toward distractors and improves redetection capability after\nobject occlusion. To facilitate the analysis of tracking in the presence of\ndistractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM\noutperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results\non ten. Furthermore, integrating the proposed distractor-aware memory into a\nreal-time tracker EfficientTAM leads to 11% improvement and matches tracking\nquality of the non-real-time SAM2.1-L on multiple tracking and segmentation\nbenchmarks, while integration with edge-based tracker EdgeTAM delivers 4%\nperformance boost, demonstrating a very good generalization across\narchitectures.", "published": "2025-09-17 09:54:27", "link": "http://arxiv.org/abs/2509.13864v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction", "abstract": "X-ray Computed Laminography (CL) is essential for non-destructive inspection\nof plate-like structures in applications such as microchips and composite\nbattery materials, where traditional computed tomography (CT) struggles due to\ngeometric constraints. However, reconstructing high-quality volumes from\nlaminographic projections remains challenging, particularly under highly\nsparse-view acquisition conditions. In this paper, we propose a reconstruction\nalgorithm, namely LamiGauss, that combines Gaussian Splatting radiative\nrasterization with a dedicated detector-to-world transformation model\nincorporating the laminographic tilt angle. LamiGauss leverages an\ninitialization strategy that explicitly filters out common laminographic\nartifacts from the preliminary reconstruction, preventing redundant Gaussians\nfrom being allocated to false structures and thereby concentrating model\ncapacity on representing the genuine object. Our approach effectively optimizes\ndirectly from sparse projections, enabling accurate and efficient\nreconstruction with limited data. Extensive experiments on both synthetic and\nreal datasets demonstrate the effectiveness and superiority of the proposed\nmethod over existing techniques. LamiGauss uses only 3$\\%$ of full views to\nachieve superior performance over the iterative method optimized on a full\ndataset.", "published": "2025-09-17 09:53:47", "link": "http://arxiv.org/abs/2509.13863v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics", "abstract": "Dataset distillation aims to synthesize a compact dataset from the original\nlarge-scale one, enabling highly efficient learning while preserving\ncompetitive model performance. However, traditional techniques primarily\ncapture low-level visual features, neglecting the high-level semantic and\nstructural information inherent in images. In this paper, we propose EDITS, a\nnovel framework that exploits the implicit textual semantics within the image\ndata to achieve enhanced distillation. First, external texts generated by a\nVision Language Model (VLM) are fused with image features through a Global\nSemantic Query module, forming the prior clustered buffer. Local Semantic\nAwareness then selects representative samples from the buffer to construct\nimage and text prototypes, with the latter produced by guiding a Large Language\nModel (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype\nGuidance strategy generates the final synthetic dataset through a diffusion\nmodel. Extensive experiments confirm the effectiveness of our method.Source\ncode is available in: https://github.com/einsteinxia/EDITS.", "published": "2025-09-17 09:48:39", "link": "http://arxiv.org/abs/2509.13858v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap", "abstract": "Reliable global localization is critical for autonomous vehicles, especially\nin environments where GNSS is degraded or unavailable, such as urban canyons\nand tunnels. Although high-definition (HD) maps provide accurate priors, the\ncost of data collection, map construction, and maintenance limits scalability.\nOpenStreetMap (OSM) offers a free and globally available alternative, but its\ncoarse abstraction poses challenges for matching with sensor data. We propose\nInterKey, a cross-modal framework that leverages road intersections as\ndistinctive landmarks for global localization. Our method constructs compact\nbinary descriptors by jointly encoding road and building imprints from point\nclouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,\norientation determination, and area-equalized sampling strategies, enabling\nrobust cross-modal matching. Experiments on the KITTI dataset demonstrate that\nInterKey achieves state-of-the-art accuracy, outperforming recent baselines by\na large margin. The framework generalizes to sensors that can produce dense\nstructural point clouds, offering a scalable and cost-effective solution for\nrobust vehicle localization.", "published": "2025-09-17 09:46:57", "link": "http://arxiv.org/abs/2509.13857v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation", "abstract": "Feature caching has recently emerged as a promising method for diffusion\nmodel acceleration. It effectively alleviates the inefficiency problem caused\nby high computational requirements by caching similar features in the inference\nprocess of the diffusion model. In this paper, we analyze existing feature\ncaching methods from the perspective of information utilization, and point out\nthat relying solely on historical information will lead to constrained accuracy\nand speed performance. And we propose a novel paradigm that introduces future\ninformation via self-speculation based on the information similarity at the\nsame time step across different iteration times. Based on this paradigm, we\npresent \\textit{SpecDiff}, a training-free multi-level feature caching strategy\nincluding a cached feature selection algorithm and a multi-level feature\nclassification algorithm. (1) Feature selection algorithm based on\nself-speculative information. \\textit{SpecDiff} determines a dynamic importance\nscore for each token based on self-speculative information and historical\ninformation, and performs cached feature selection through the importance\nscore. (2) Multi-level feature classification algorithm based on feature\nimportance scores. \\textit{SpecDiff} classifies tokens by leveraging the\ndifferences in feature importance scores and introduces a multi-level feature\ncalculation strategy. Extensive experiments show that \\textit{SpecDiff}\nachieves average 2.80 \\times, 2.74 \\times , and 3.17\\times speedup with\nnegligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow\non NVIDIA A800-80GB GPU. By merging speculative and historical information,\n\\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing\nthe Pareto frontier of speedup and accuracy in the efficient diffusion model\ninference.", "published": "2025-09-17 09:24:40", "link": "http://arxiv.org/abs/2509.13848v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation", "abstract": "Many recent approaches in representation learning implicitly assume that\nuncorrelated views of a data point are sufficient to learn meaningful\nrepresentations for various downstream tasks. In this work, we challenge this\nassumption and demonstrate that meaningful structure in the latent space does\nnot emerge naturally. Instead, it must be explicitly induced. We propose a\nmethod that aligns representations from different views of the data to align\ncomplementary information without inducing false positives. Our experiments\nshow that our proposed self-supervised learning method, Consistent View\nAlignment, improves performance for downstream tasks, highlighting the critical\nrole of structured view alignment in learning effective representations. Our\nmethod achieved first and second place in the MICCAI 2025 SSL3D challenge when\nusing a Primus vision transformer and ResEnc convolutional neural network,\nrespectively. The code and pretrained model weights are released at\nhttps://github.com/Tenbatsu24/LatentCampus.", "published": "2025-09-17 09:23:52", "link": "http://arxiv.org/abs/2509.13846v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation", "abstract": "Semi-supervised learning has been employed to alleviate the need for\nextensive labeled data for histopathology image segmentation, but existing\nmethods struggle with noisy pseudo-labels due to ambiguous gland boundaries and\nmorphological misclassification. This paper introduces Semi-MOE, to the best of\nour knowledge, the first multi-task Mixture-of-Experts framework for\nsemi-supervised histopathology image segmentation. Our approach leverages three\nspecialized expert networks: A main segmentation expert, a signed distance\nfield regression expert, and a boundary prediction expert, each dedicated to\ncapturing distinct morphological features. Subsequently, the Multi-Gating\nPseudo-labeling module dynamically aggregates expert features, enabling a\nrobust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate\nmanual tuning while dynamically balancing multiple learning objectives, we\npropose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and\nCRAG benchmarks show that our method outperforms state-of-the-art approaches in\nlow-label settings, highlighting the potential of MoE-based architectures in\nadvancing semi-supervised segmentation. Our code is available at\nhttps://github.com/vnlvi2k3/Semi-MoE.", "published": "2025-09-17 09:03:04", "link": "http://arxiv.org/abs/2509.13834v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET", "abstract": "The classification of pixel spectra of hyperspectral images, i.e. spectral\nclassification, is used in many fields ranging from agricultural, over medical\nto remote sensing applications and is currently also expanding to areas such as\nautonomous driving. Even though for full hyperspectral images the\nbest-performing methods exploit spatial-spectral information, performing\nclassification solely on spectral information has its own advantages, e.g.\nsmaller model size and thus less data required for training. Moreover, spectral\ninformation is complementary to spatial information and improvements on either\npart can be used to improve spatial-spectral approaches in the future.\nRecently, 1D-Justo-LiuNet was proposed as a particularly efficient model with\nvery few parameters, which currently defines the state of the art in spectral\nclassification. However, we show that with limited training data the model\nperformance deteriorates. Therefore, we investigate MiniROCKET and\nHDC-MiniROCKET for spectral classification to mitigate that problem. The model\nextracts well-engineered features without trainable parameters in the feature\nextraction part and is therefore less vulnerable to limited training data. We\nshow that even though MiniROCKET has more parameters it outperforms\n1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the\ngeneral case", "published": "2025-09-17 08:22:23", "link": "http://arxiv.org/abs/2509.13809v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Masked Feature Modeling Enhances Adaptive Segmentation", "abstract": "Unsupervised domain adaptation (UDA) for semantic segmentation aims to\ntransfer models from a labeled source domain to an unlabeled target domain.\nWhile auxiliary self-supervised tasks-particularly contrastive learning-have\nimproved feature discriminability, masked modeling approaches remain\nunderexplored in this setting, largely due to architectural incompatibility and\nmisaligned optimization objectives. We propose Masked Feature Modeling (MFM), a\nnovel auxiliary task that performs feature masking and reconstruction directly\nin the feature space. Unlike existing masked modeling methods that reconstruct\nlow-level inputs or perceptual features (e.g., HOG or visual tokens), MFM\naligns its learning target with the main segmentation task, ensuring\ncompatibility with standard architectures like DeepLab and DAFormer without\nmodifying the inference pipeline. To facilitate effective reconstruction, we\nintroduce a lightweight auxiliary module, Rebuilder, which is trained jointly\nbut discarded during inference, adding zero computational overhead at test\ntime. Crucially, MFM leverages the segmentation decoder to classify the\nreconstructed features, tightly coupling the auxiliary objective with the\npixel-wise prediction task to avoid interference with the primary task.\nExtensive experiments across various architectures and UDA benchmarks\ndemonstrate that MFM consistently enhances segmentation performance, offering a\nsimple, efficient, and generalizable strategy for unsupervised domain-adaptive\nsemantic segmentation.", "published": "2025-09-17 08:16:05", "link": "http://arxiv.org/abs/2509.13801v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments", "abstract": "Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been\nextensively investigated for Global Navigation Satellite System (GNSS)-denied\nenvironments. However, existing retrieval-based approaches face limitations in\ndataset availability and persistent challenges including suboptimal real-time\nperformance, environmental sensitivity, and limited generalization capability,\nparticularly in dynamic or temporally varying environments. To overcome these\nlimitations, we present a large-scale Multi-Altitude Flight Segments dataset\n(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted\nAdaptive Particle Filter (SWA-PF) method. This approach integrates robust\nsemantic features from both UAV-captured images and satellite imagery through\ntwo key innovations: a semantic weighting mechanism and an optimized particle\nfiltering architecture. Evaluated using our dataset, the proposed method\nachieves 10x computational efficiency gain over feature extraction methods,\nmaintains global positioning errors below 10 meters, and enables rapid 4 degree\nof freedom (4-DoF) pose estimation within seconds using accessible\nlow-resolution satellite maps. Code and dataset will be available at\nhttps://github.com/YuanJiayuuu/SWA-PF.", "published": "2025-09-17 08:05:36", "link": "http://arxiv.org/abs/2509.13795v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling", "abstract": "Event cameras capture asynchronous pixel-level brightness changes with\nmicrosecond temporal resolution, offering unique advantages for high-speed\nvision tasks. Existing methods often convert event streams into intermediate\nrepresentations such as frames, voxel grids, or point clouds, which inevitably\nrequire predefined time windows and thus introduce window latency. Meanwhile,\npointwise detection methods face computational challenges that prevent\nreal-time efficiency due to their high computational cost. To overcome these\nlimitations, we propose the Variable-Rate Spatial Event Mamba, a novel\narchitecture that directly processes raw event streams without intermediate\nrepresentations. Our method introduces a lightweight causal spatial\nneighborhood encoder to efficiently capture local geometric relations, followed\nby Mamba-based state space models for scalable temporal modeling with linear\ncomplexity. During inference, a controller adaptively adjusts the processing\nspeed according to the event rate, achieving an optimal balance between window\nlatency and inference latency.", "published": "2025-09-17 07:55:37", "link": "http://arxiv.org/abs/2509.13784v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization", "abstract": "While the pursuit of higher accuracy in deepfake detection remains a central\ngoal, there is an increasing demand for precise localization of manipulated\nregions. Despite the remarkable progress made in classification-based\ndetection, accurately localizing forged areas remains a significant challenge.\nA common strategy is to incorporate forged region annotations during model\ntraining alongside manipulated images. However, such approaches often neglect\nthe complementary nature of local detail and global semantic context, resulting\nin suboptimal localization performance. Moreover, an often-overlooked aspect is\nthe fusion strategy between local and global predictions. Naively combining the\noutputs from both branches can amplify noise and errors, thereby undermining\nthe effectiveness of the localization.\n  To address these issues, we propose a novel approach that independently\npredicts manipulated regions using both local and global perspectives. We\nemploy morphological operations to fuse the outputs, effectively suppressing\nnoise while enhancing spatial coherence. Extensive experiments reveal the\neffectiveness of each module in improving the accuracy and robustness of\nforgery localization.", "published": "2025-09-17 07:46:07", "link": "http://arxiv.org/abs/2509.13776v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving", "abstract": "While reasoning technology like Chain of Thought (CoT) has been widely\nadopted in Vision Language Action (VLA) models, it demonstrates promising\ncapabilities in end to end autonomous driving. However, recent efforts to\nintegrate CoT reasoning often fall short in simple scenarios, introducing\nunnecessary computational overhead without improving decision quality. To\naddress this, we propose AdaThinkDrive, a novel VLA framework with a dual mode\nreasoning mechanism inspired by fast and slow thinking. First, our framework is\npretrained on large scale autonomous driving (AD) scenarios using both question\nanswering (QA) and trajectory datasets to acquire world knowledge and driving\ncommonsense. During supervised fine tuning (SFT), we introduce a two mode\ndataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the\nmodel to distinguish between scenarios that require reasoning. Furthermore, an\nAdaptive Think Reward strategy is proposed in conjunction with the Group\nRelative Policy Optimization (GRPO), which rewards the model for selectively\napplying CoT by comparing trajectory quality across different reasoning modes.\nExtensive experiments on the Navsim benchmark show that AdaThinkDrive achieves\na PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.\nMoreover, ablations show that AdaThinkDrive surpasses both the never Think and\nalways Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also\nreduces inference time by 14% compared to the always Think baseline,\ndemonstrating its ability to balance accuracy and efficiency through adaptive\nreasoning.", "published": "2025-09-17 07:35:39", "link": "http://arxiv.org/abs/2509.13769v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generative Image Coding with Diffusion Prior", "abstract": "As generative technologies advance, visual content has evolved into a complex\nmix of natural and AI-generated images, driving the need for more efficient\ncoding techniques that prioritize perceptual quality. Traditional codecs and\nlearned methods struggle to maintain subjective quality at high compression\nratios, while existing generative approaches face challenges in visual fidelity\nand generalization. To this end, we propose a novel generative coding framework\nleveraging diffusion priors to enhance compression performance at low bitrates.\nOur approach employs a pre-optimized encoder to generate generalized\ncompressed-domain representations, integrated with the pretrained model's\ninternal features via a lightweight adapter and an attentive fusion module.\nThis framework effectively leverages existing pretrained diffusion models and\nenables efficient adaptation to different pretrained models for new\nrequirements with minimal retraining costs. We also introduce a distribution\nrenormalization method to further enhance reconstruction fidelity. Extensive\nexperiments show that our method (1) outperforms existing methods in visual\nfidelity across low bitrates, (2) improves compression performance by up to 79%\nover H.266/VVC, and (3) offers an efficient solution for AI-generated content\nwhile being adaptable to broader content types.", "published": "2025-09-17 07:32:15", "link": "http://arxiv.org/abs/2509.13768v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI", "abstract": "Accurately segmenting articulatory structures in real-time magnetic resonance\nimaging (rtMRI) remains challenging, as most existing methods rely almost\nentirely on visual cues. Yet synchronized acoustic and phonological signals\nprovide complementary context that can enrich visual information and improve\nprecision. In this paper, we introduce VocSegMRI, a multimodal framework that\nintegrates video, audio, and phonological inputs through cross-attention fusion\nfor dynamic feature alignment. To further enhance cross-modal representation,\nwe incorporate a contrastive learning objective that improves segmentation\nperformance even when the audio modality is unavailable at inference. Evaluated\non a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art\nperformance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance\n(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.\nAblation studies confirm the contributions of cross-attention and contrastive\nlearning to segmentation precision and robustness. These results highlight the\nvalue of integrative multimodal modeling for accurate vocal tract analysis.", "published": "2025-09-17 07:32:00", "link": "http://arxiv.org/abs/2509.13767v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset", "abstract": "Visual degradation caused by rain streak artifacts in low-light conditions\nsignificantly hampers the performance of nighttime surveillance and autonomous\nnavigation. Existing image deraining techniques are primarily designed for\ndaytime conditions and perform poorly under nighttime illumination due to the\nspatial heterogeneity of rain distribution and the impact of light-dependent\nstripe visibility. In this paper, we propose a novel Nighttime Deraining\nLocation-enhanced Perceptual Network(NDLPNet) that effectively captures the\nspatial positional information and density distribution of rain streaks in\nlow-light environments. Specifically, we introduce a Position Perception Module\n(PPM) to capture and leverage spatial contextual information from input data,\nenhancing the model's capability to identify and recalibrate the importance of\ndifferent feature channels. The proposed nighttime deraining network can\neffectively remove the rain streaks as well as preserve the crucial background\ninformation. Furthermore, We construct a night scene rainy (NSR) dataset\ncomprising 900 image pairs, all based on real-world nighttime scenes, providing\na new benchmark for nighttime deraining task research. Extensive qualitative\nand quantitative experimental evaluations on both existing datasets and the NSR\ndataset consistently demonstrate our method outperform the state-of-the-art\n(SOTA) methods in nighttime deraining tasks. The source code and dataset is\navailable at https://github.com/Feecuin/NDLPNet.", "published": "2025-09-17 07:24:47", "link": "http://arxiv.org/abs/2509.13766v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Task-Aware Image Signal Processor for Advanced Visual Perception", "abstract": "In recent years, there has been a growing trend in computer vision towards\nexploiting RAW sensor data, which preserves richer information compared to\nconventional low-bit RGB images. Early studies mainly focused on enhancing\nvisual quality, while more recent efforts aim to leverage the abundant\ninformation in RAW data to improve the performance of visual perception tasks\nsuch as object detection and segmentation. However, existing approaches still\nface two key limitations: large-scale ISP networks impose heavy computational\noverhead, while methods based on tuning traditional ISP pipelines are\nrestricted by limited representational capacity.To address these issues, we\npropose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB\nframework that produces task-oriented representations for pretrained vision\nmodels. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small\nset of lightweight, multi-scale modulation operators that act at global,\nregional, and pixel scales to reshape image statistics across different spatial\nextents. This factorized control significantly expands the range of spatially\nvarying transforms that can be represented while keeping memory usage,\ncomputation, and latency tightly constrained. Evaluated on several RAW-domain\ndetection and segmentation benchmarks under both daytime and nighttime\nconditions, TA-ISP consistently improves downstream accuracy while markedly\nreducing parameter count and inference time, making it well suited for\ndeployment on resource-constrained devices.", "published": "2025-09-17 07:16:51", "link": "http://arxiv.org/abs/2509.13762v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Iterative Prompt Refinement for Safer Text-to-Image Generation", "abstract": "Text-to-Image (T2I) models have made remarkable progress in generating images\nfrom text prompts, but their output quality and safety still depend heavily on\nhow prompts are phrased. Existing safety methods typically refine prompts using\nlarge language models (LLMs), but they overlook the images produced, which can\nresult in unsafe outputs or unnecessary changes to already safe prompts. To\naddress this, we propose an iterative prompt refinement algorithm that uses\nVision Language Models (VLMs) to analyze both the input prompts and the\ngenerated images. By leveraging visual feedback, our method refines prompts\nmore effectively, improving safety while maintaining user intent and\nreliability comparable to existing LLM-based approaches. Additionally, we\nintroduce a new dataset labeled with both textual and visual safety signals\nusing off-the-shelf multi-modal LLM, enabling supervised fine-tuning.\nExperimental results demonstrate that our approach produces safer outputs\nwithout compromising alignment with user intent, offering a practical solution\nfor generating safer T2I content. Our code is available at\nhttps://github.com/ku-dmlab/IPR. \\textbf{\\textcolor{red}WARNING: This paper\ncontains examples of harmful or inappropriate images generated by models.", "published": "2025-09-17 07:16:06", "link": "http://arxiv.org/abs/2509.13760v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Controllable-Continuous Color Editing in Diffusion Model via Color Mapping", "abstract": "In recent years, text-driven image editing has made significant progress.\nHowever, due to the inherent ambiguity and discreteness of natural language,\ncolor editing still faces challenges such as insufficient precision and\ndifficulty in achieving continuous control. Although linearly interpolating the\nembedding vectors of different textual descriptions can guide the model to\ngenerate a sequence of images with varying colors, this approach lacks precise\ncontrol over the range of color changes in the output images. Moreover, the\nrelationship between the interpolation coefficient and the resulting image\ncolor is unknown and uncontrollable. To address these issues, we introduce a\ncolor mapping module that explicitly models the correspondence between the text\nembedding space and image RGB values. This module predicts the corresponding\nembedding vector based on a given RGB value, enabling precise color control of\nthe generated images while maintaining semantic consistency. Users can specify\na target RGB range to generate images with continuous color variations within\nthe desired range, thereby achieving finer-grained, continuous, and\ncontrollable color editing. Experimental results demonstrate that our method\nperforms well in terms of color continuity and controllability.", "published": "2025-09-17 07:12:51", "link": "http://arxiv.org/abs/2509.13756v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval", "abstract": "Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that\naims to retrieve the most relevant person images based on a given text query.\nThe key challenge in TIPR lies in achieving effective alignment between textual\nand visual modalities within a common latent space. To address this challenge,\nprior approaches incorporate attention mechanisms for implicit cross-modal\nlocal alignment. However, they lack the ability to verify whether all local\nfeatures are correctly aligned. Moreover, existing methods primarily focus on\nhard negative samples during model updates, with the goal of refining\ndistinctions between positive and negative pairs, often neglecting incorrectly\nmatched positive pairs. To alleviate these issues, we propose FMFA, a\ncross-modal Full-Mode Fine-grained Alignment framework, which enhances global\nmatching through explicit fine-grained alignment and existing implicit\nrelational reasoning -- hence the term ``full-mode\" -- without requiring\nadditional supervision. Specifically, we design an Adaptive Similarity\nDistribution Matching (A-SDM) module to rectify unmatched positive sample\npairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint\nembedding space, thereby achieving more precise global alignment. Additionally,\nwe introduce an Explicit Fine-grained Alignment (EFA) module, which makes up\nfor the lack of verification capability of implicit relational reasoning. EFA\nstrengthens explicit cross-modal fine-grained interactions by sparsifying the\nsimilarity matrix and employs a hard coding method for local alignment. Our\nproposed method is evaluated on three public datasets, achieving\nstate-of-the-art performance among all global matching methods. Our code is\navailable at https://github.com/yinhao1102/FMFA.", "published": "2025-09-17 07:12:05", "link": "http://arxiv.org/abs/2509.13754v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Generalized Visual Grounding with Instance-aware Joint Learning", "abstract": "Generalized visual grounding tasks, including Generalized Referring\nExpression Comprehension (GREC) and Segmentation (GRES), extend the classical\nvisual grounding paradigm by accommodating multi-target and non-target\nscenarios. Specifically, GREC focuses on accurately identifying all referential\nobjects at the coarse bounding box level, while GRES aims for achieve\nfine-grained pixel-level perception. However, existing approaches typically\ntreat these tasks independently, overlooking the benefits of jointly training\nGREC and GRES to ensure consistent multi-granularity predictions and streamline\nthe overall process. Moreover, current methods often treat GRES as a semantic\nsegmentation task, neglecting the crucial role of instance-aware capabilities\nand the necessity of ensuring consistent predictions between instance-level\nboxes and masks. To address these limitations, we propose InstanceVG, a\nmulti-task generalized visual grounding framework equipped with instance-aware\ncapabilities, which leverages instance queries to unify the joint and\nconsistency predictions of instance-level boxes and masks. To the best of our\nknowledge, InstanceVG is the first framework to simultaneously tackle both GREC\nand GRES while incorporating instance-aware capabilities into generalized\nvisual grounding. To instantiate the framework, we assign each instance query a\nprior reference point, which also serves as an additional basis for target\nmatching. This design facilitates consistent predictions of points, boxes, and\nmasks for the same instance. Extensive experiments obtained on ten datasets\nacross four tasks demonstrate that InstanceVG achieves state-of-the-art\nperformance, significantly surpassing the existing methods in various\nevaluation metrics. The code and model will be publicly available at\nhttps://github.com/Dmmm1997/InstanceVG.", "published": "2025-09-17 07:00:51", "link": "http://arxiv.org/abs/2509.13747v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry", "abstract": "Monocular depth estimation has been increasingly adopted in robotics and\nautonomous driving for its ability to infer scene geometry from a single\ncamera. In self-supervised monocular depth estimation frameworks, the network\njointly generates and exploits depth and pose estimates during training,\nthereby eliminating the need for depth labels. However, these methods remain\nchallenged by uncertainty in the input data, such as low-texture or dynamic\nregions, which can cause reduced depth accuracy. To address this, we introduce\nUM-Depth, a framework that combines motion- and uncertainty-aware refinement to\nenhance depth accuracy at dynamic object boundaries and in textureless regions.\nSpecifically, we develop a teacherstudent training strategy that embeds\nuncertainty estimation into both the training pipeline and network\narchitecture, thereby strengthening supervision where photometric signals are\nweak. Unlike prior motion-aware approaches that incur inference-time overhead\nand rely on additional labels or auxiliary networks for real-time generation,\nour method uses optical flow exclusively within the teacher network during\ntraining, which eliminating extra labeling demands and any runtime cost.\nExtensive experiments on the KITTI and Cityscapes datasets demonstrate the\neffectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves\nstate-of-the-art results in both self-supervised depth and pose estimation on\nthe KITTI datasets.", "published": "2025-09-17 05:51:07", "link": "http://arxiv.org/abs/2509.13713v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models", "abstract": "The rapid advancement of generative models, particularly diffusion-based\napproaches, has inadvertently facilitated their potential for misuse. Such\nmodels enable malicious exploiters to replicate artistic styles that capture an\nartist's creative labor, personal vision, and years of dedication in an\ninexpensive manner. This has led to a rise in the need and exploration of\nmethods for protecting artworks against style mimicry. Although generic\ndiffusion models can easily mimic an artistic style, finetuning amplifies this\ncapability, enabling the model to internalize and reproduce the style with\nhigher fidelity and control. We hypothesize that certain cross-attention layers\nexhibit heightened sensitivity to artistic styles. Sensitivity is measured\nthrough activation strengths of attention layers in response to style and\ncontent representations, and assessing their correlations with features\nextracted from external models. Based on our findings, we introduce an\nefficient and lightweight protection strategy, StyleProtect, that achieves\neffective style defense against fine-tuned diffusion models by updating only\nselected cross-attention layers. Our experiments utilize a carefully curated\nartwork dataset based on WikiArt, comprising representative works from 30\nartists known for their distinctive and influential styles and cartoon\nanimations from the Anita dataset. The proposed method demonstrates promising\nperformance in safeguarding unique styles of artworks and anime from malicious\ndiffusion customization, while maintaining competitive imperceptibility.", "published": "2025-09-17 05:39:34", "link": "http://arxiv.org/abs/2509.13711v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification", "abstract": "Effective and interpretable classification of medical images is a challenge\nin computer-aided diagnosis, especially in resource-limited clinical settings.\nThis study introduces spline-based Kolmogorov-Arnold Networks (KANs) for\naccurate medical image classification with limited, diverse datasets. The\nmodels include SBTAYLOR-KAN, integrating B-splines with Taylor series;\nSBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,\nembedding B-splines in Morlet wavelet transforms. These approaches leverage\nspline-based function approximation to capture both local and global\nnonlinearities. The models were evaluated on brain MRI, chest X-rays,\ntuberculosis X-rays, and skin lesion images without preprocessing,\ndemonstrating the ability to learn directly from raw data. Extensive\nexperiments, including cross-dataset validation and data reduction analysis,\nshowed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%\naccuracy, with a balanced F1-score, maintaining over 86% accuracy using only\n30% of the training data across three datasets. Despite class imbalance in the\nskin cancer dataset, experiments on both imbalanced and balanced versions\nshowed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.\nUnlike traditional CNNs, which require millions of parameters (e.g., ResNet50\nwith 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872\ntrainable parameters, making it more suitable for constrained medical\nenvironments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used\nfor interpretability, highlighting relevant regions in medical images. This\nframework provides a lightweight, interpretable, and generalizable solution for\nmedical image classification, addressing the challenges of limited datasets and\ndata-scarce scenarios in clinical AI applications.", "published": "2025-09-17 04:33:54", "link": "http://arxiv.org/abs/2509.13687v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras", "abstract": "As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)\nsegmentation has recently achieved remarkable progress with pinhole cameras.\nHowever, it is non-trivial to extend the existing methods to fisheye cameras\nwith severe geometric distortion, ambiguous multi-view correspondences and\nunstable temporal dynamics, all of which significantly degrade BEV performance.\nTo address these challenges, we propose FishBEV, a novel BEV segmentation\nframework specifically tailored for fisheye cameras. This framework introduces\nthree complementary innovations, including a Distortion-Resilient Multi-scale\nExtraction (DRME) backbone that learns robust features under distortion while\npreserving scale consistency, an Uncertainty-aware Spatial Cross-Attention\n(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view\nalignment, a Distance-aware Temporal Self-Attention (D-TSA) module that\nadaptively balances near field details and far field context to ensure temporal\ncoherence. Extensive experiments on the Synwoodscapes dataset demonstrate that\nFishBEV consistently outperforms SOTA baselines, regarding the performance\nevaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.", "published": "2025-09-17 04:26:36", "link": "http://arxiv.org/abs/2509.13681v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction", "abstract": "Estimating metric relative camera pose from a pair of images is of great\nimportance for 3D reconstruction and localisation. However, conventional\ntwo-view pose estimation methods are not metric, with camera translation known\nonly up to a scale, and struggle with wide baselines and textureless or\nreflective surfaces. This paper introduces GARPS, a training-free framework\nthat casts this problem as the direct alignment of two independently\nreconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and\na Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model\n(GMM) for each image. It then refines an initial pose from a feed-forward\ntwo-view pose estimator by optimising a differentiable GMM alignment objective.\nThis objective jointly considers geometric structure, view-independent colour,\nanisotropic covariance, and semantic feature consistency, and is robust to\nocclusions and texture-poor regions without requiring explicit 2D\ncorrespondences. Extensive experiments on the Real\\-Estate10K dataset\ndemonstrate that GARPS outperforms both classical and state-of-the-art\nlearning-based methods, including MASt3R. These results highlight the potential\nof bridging single-view perception with multi-view geometry to achieve robust\nand metric relative pose estimation.", "published": "2025-09-17 02:57:34", "link": "http://arxiv.org/abs/2509.13652v1", "categories": ["cs.CV", "I.4.8; I.4.5"], "primary_category": "cs.CV"}
{"title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "abstract": "We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that\nreframes interleaved image-text generation as a tool-use problem. LLM-I is\ndesigned to overcome the \"one-tool\" bottleneck of current unified models, which\nare limited to synthetic imagery and struggle with tasks requiring factual\ngrounding or programmatic precision. Our framework empowers a central LLM or\nMLLM agent to intelligently orchestrate a diverse toolkit of specialized visual\ntools, including online image search, diffusion-based generation, code\nexecution, and image editing. The agent is trained to select and apply these\ntools proficiently via a Reinforcement Learning (RL) framework that features a\nhybrid reward system combining rule-based logic with judgments from LLM and\nMLLM evaluators. Trained on a diverse new dataset using four different model\nbackbones, LLM-I demonstrates state-of-the-art performance, outperforming\nexisting methods by a large margin across four benchmarks. We also introduce a\nnovel test-time scaling strategy that provides further performance gains.\nProject Page: https://github.com/ByteDance-BandAI/LLM-I.", "published": "2025-09-17 02:33:29", "link": "http://arxiv.org/abs/2509.13642v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery", "abstract": "Accurate identification of deforestation from satellite images is essential\nin order to understand the geographical situation of an area. This paper\nintroduces a new distributed approach to identify as well as locate\ndeforestation across different clients using Federated Learning (FL). Federated\nLearning enables distributed network clients to collaboratively train a model\nwhile maintaining data privacy and security of the active users. In our\nframework, a client corresponds to an edge satellite center responsible for\nlocal data processing. Moreover, FL provides an advantage over centralized\ntraining method which requires combining data, thereby compromising with data\nsecurity of the clients. Our framework leverages the FLOWER framework with RAY\nframework to execute the distributed learning workload. Furthermore, efficient\nclient spawning is ensured by RAY as it can select definite amount of users to\ncreate an emulation environment. Our FL framework uses YOLOS-small (a Vision\nTransformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN\nwith a MobileNetV3 backbone models trained and tested on publicly available\ndatasets. Our approach provides us a different view for image\nsegmentation-based tasks on satellite imagery.", "published": "2025-09-17 01:57:13", "link": "http://arxiv.org/abs/2509.13631v1", "categories": ["cs.CV", "cs.DC", "14J60", "F.2.2; I.2.7"], "primary_category": "cs.CV"}
{"title": "SAMIR, an efficient registration framework via robust feature learning from SAM", "abstract": "Image registration is a fundamental task in medical image analysis.\nDeformations are often closely related to the morphological characteristics of\ntissues, making accurate feature extraction crucial. Recent weakly supervised\nmethods improve registration by incorporating anatomical priors such as\nsegmentation masks or landmarks, either as inputs or in the loss function.\nHowever, such weak labels are often not readily available, limiting their\npractical use. Motivated by the strong representation learning ability of\nvisual foundation models, this paper introduces SAMIR, an efficient medical\nimage registration framework that utilizes the Segment Anything Model (SAM) to\nenhance feature extraction. SAM is pretrained on large-scale natural image\ndatasets and can learn robust, general-purpose visual representations. Rather\nthan using raw input images, we design a task-specific adaptation pipeline\nusing SAM's image encoder to extract structure-aware feature embeddings,\nenabling more accurate modeling of anatomical consistency and deformation\npatterns. We further design a lightweight 3D head to refine features within the\nembedding space, adapting to local deformations in medical images.\nAdditionally, we introduce a Hierarchical Feature Consistency Loss to guide\ncoarse-to-fine feature matching and improve anatomical alignment. Extensive\nexperiments demonstrate that SAMIR significantly outperforms state-of-the-art\nmethods on benchmark datasets for both intra-subject cardiac image registration\nand inter-subject abdomen CT image registration, achieving performance\nimprovements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code\nwill be publicly available on GitHub following the acceptance of this paper.", "published": "2025-09-17 01:56:35", "link": "http://arxiv.org/abs/2509.13629v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rest2Visual: Predicting Visually Evoked fMRI from Resting-State Scans", "abstract": "Understanding how spontaneous brain activity relates to stimulus-driven\nneural responses is a fundamental challenge in cognitive neuroscience. While\ntask-based functional magnetic resonance imaging (fMRI) captures localized\nstimulus-evoked brain activation, its acquisition is costly, time-consuming,\nand difficult to scale across populations. In contrast, resting-state fMRI\n(rs-fMRI) is task-free and abundant, but lacks direct interpretability. We\nintroduce Rest2Visual, a conditional generative model that predicts visually\nevoked fMRI (ve-fMRI) from resting-state input and 2D visual stimuli. It\nfollows a volumetric encoder--decoder design, where multiscale 3D features from\nrs-fMRI are modulated by image embeddings via adaptive normalization, enabling\nspatially accurate, stimulus-specific activation synthesis. To enable model\ntraining, we construct a large-scale triplet dataset from the Natural Scenes\nDataset (NSD), aligning each rs-fMRI volume with stimulus images and their\ncorresponding ve-fMRI activation maps. Quantitative evaluation shows that the\npredicted activations closely match ground truth across standard similarity and\nrepresentational metrics, and support successful image reconstruction in\ndownstream decoding. Notably, the predicted maps preserve subject-specific\nstructure, demonstrating the model's capacity to generate individualized\nfunctional surrogates. Our results provide compelling evidence that\nindividualized spontaneous neural activity can be transformed into\nstimulus-aligned representations, opening new avenues for scalable, task-free\nfunctional brain modeling.", "published": "2025-09-17 01:08:03", "link": "http://arxiv.org/abs/2509.13612v1", "categories": ["q-bio.NC", "cs.CV"], "primary_category": "q-bio.NC"}
{"title": "A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms", "abstract": "In previous work, we introduced a 2D localization algorithm called CLAP,\nClustering to Localize Across $n$ Possibilities, which was used during our\nchampionship win in RoboCup 2024, an international autonomous humanoid soccer\ncompetition. CLAP is particularly recognized for its robustness against\noutliers, where clustering is employed to suppress noise and mitigate against\nerroneous feature matches. This clustering-based strategy provides an\nalternative to traditional outlier rejection schemes such as RANSAC, in which\ncandidates are validated by reprojection error across all data points. In this\npaper, CLAP is extended to a more general framework beyond 2D localization,\nspecifically to 3D localization and image stitching. We also show how CLAP,\nRANSAC, and Hough transforms are related. The generalization of CLAP is widely\napplicable to many different fields and can be a useful tool to deal with noise\nand uncertainty.", "published": "2025-09-17 00:29:27", "link": "http://arxiv.org/abs/2509.13605v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Gremban Expansion for Signed Networks: Algebraic and Combinatorial Foundations for Community-Faction Detection", "abstract": "This article deals with the characterization and detection of community and\nfaction structures in signed networks. We approach the study of these mesoscale\nstructures through the lens of the Gremban expansion. This graph operation\nlifts a signed graph to a larger unsigned graph, and allows the extension of\nstandard techniques from unsigned to signed graphs. We develop the\ncombinatorial and algebraic properties of the Gremban expansion, with a focus\non its inherent involutive symmetry. The main technical result is a bijective\ncorrespondence between symmetry-respecting cut-sets in the Gremban expansion,\nand regular cut-sets and frustration sets in the signed graph (i.e., the\ncombinatorial structures that underlie communities and factions respectively).\nThis result forms the basis for our new approach to community-faction detection\nin signed networks, which makes use of spectral clustering techniques that\nnaturally respect the required symmetries. We demonstrate how this approach\ndistinguishes the two mesoscale structures, how to generalize the approach to\nmulti-way clustering and discuss connections to network dynamical systems.", "published": "2025-09-17 17:28:44", "link": "http://arxiv.org/abs/2509.14193v1", "categories": ["cs.DM", "math.CO", "physics.soc-ph", "G.2; I.5"], "primary_category": "cs.DM"}
{"title": "The lonely runner conjecture holds for eight runners", "abstract": "We prove that the lonely runner conjecture holds for eight runners. Our proof\nrelies on a computer verification and on recent results that allow bounding the\nsize of a minimal counterexample. We note that our approach also applies to the\nknown cases with 4, 5, 6, and 7 runners. We expect that minor improvements to\nour approach could be enough to solve the cases of 9 or 10 runners.", "published": "2025-09-17 15:55:06", "link": "http://arxiv.org/abs/2509.14111v1", "categories": ["math.CO", "cs.DM", "math.NT"], "primary_category": "math.CO"}
{"title": "Smaller Circuits for Bit Addition", "abstract": "Bit addition arises virtually everywhere in digital circuits: arithmetic\noperations, increment/decrement operators, computing addresses and table\nindices, and so on. Since bit addition is such a basic task in Boolean circuit\nsynthesis, a lot of research has been done on constructing efficient circuits\nfor various special cases of it. A vast majority of these results are devoted\nto optimizing the circuit depth (also known as delay).\n  In this paper, we investigate the circuit size (also known as area) over the\nfull binary basis of bit addition. Though most of the known circuits are built\nfrom Half Adders and Full Adders, we show that, in many interesting scenarios,\nthese circuits have suboptimal size. Namely, we improve an upper bound $5n-3m$\nto $4.5n-2m$, where $n$ is the number of input bits and $m$ is the number of\noutput bits. In the regimes where $m$ is small compared to $n$ (for example,\nfor computing the sum of $n$ bits or multiplying two $n$-bit integers), this\nleads to $10\\%$ improvement.\n  We complement our theoretical result by an open-source implementation of\ngenerators producing circuits for bit addition and multiplication. The\ngenerators allow one to produce the corresponding circuits in two lines of code\nand to compare them to existing designs.", "published": "2025-09-17 13:37:53", "link": "http://arxiv.org/abs/2509.13966v1", "categories": ["cs.CC", "cs.DM", "cs.DS", "cs.LO"], "primary_category": "cs.CC"}
{"title": "4-uniform Maker-Breaker and Maker-Maker games are PSPACE-complete", "abstract": "We study two positional games where two players take turns picking a\npreviously unpicked vertex of a hypergraph $H$. We say a player fills an edge\nof $H$ if that player has picked all the vertices of that edge. In the\nMaker-Maker game, whoever first fills an edge wins, or we get a draw if no edge\nis filled. In the Maker-Breaker game, the first player aims at filling an edge\nwhile the second player aims at preventing the first player from filling an\nedge. We show that, for both games, deciding whether the first player has a\nwinning strategy is a PSPACE-complete problem even when restricted to 4-uniform\nhypergraphs. For the Maker-Maker game, this improves on a previous result for\nhypergraphs of rank 4. For the Maker-Breaker game, this improves on a previous\nresult for 5-uniform hypergraphs, and closes the complexity gap as the problem\nfor hypergraphs of rank 3 is known to be solvable in polynomial time.", "published": "2025-09-17 08:36:11", "link": "http://arxiv.org/abs/2509.13819v1", "categories": ["cs.DM", "cs.CC", "math.CO"], "primary_category": "cs.DM"}
{"title": "Hyper-Zagreb Indices of Hypergraphs with Application in Drug Design", "abstract": "Let $\\mathcal{H}$ be a hypergraph on the non-empty finite vertex set\n$V(\\mathcal{H})$ with the hyperedge set $E(\\mathcal{H})$, where each hyperedge\n$e \\in E(\\mathcal{H})$ is a subset of $V(\\mathcal{H})$ with at least two\nvertices. This paper introduces the first and second Hyper-Zagreb indices for\nhypergraphs, extending these well-known graph indices to hypergraphs. We\ndiscuss bounds on these indices for general hypergraphs, weak bipartite\nhypergraphs, hypertrees, $k$-uniform hypergraphs, $k$-uniform weak bipartite\nhypergraphs, and $k$-uniform hypertrees, characterizing the extremal\nhypergraphs that achieve these bounds. Additionally, we present a novel\napplication of these indices in drug design and bioactivity prediction,\ndemonstrating their utility in quantitative structure-activity relationship\n(QSAR) modeling.", "published": "2025-09-17 07:56:56", "link": "http://arxiv.org/abs/2509.13787v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) integrates external knowledge into large\nlanguage models to improve response quality. However, recent work has shown\nthat RAG systems are highly vulnerable to poisoning attacks, where malicious\ntexts are inserted into the knowledge database to influence model outputs.\nWhile several defenses have been proposed, they are often circumvented by more\nadaptive or sophisticated attacks.\n  This paper presents RAGOrigin, a black-box responsibility attribution\nframework designed to identify which texts in the knowledge database are\nresponsible for misleading or incorrect generations. Our method constructs a\nfocused attribution scope tailored to each misgeneration event and assigns a\nresponsibility score to each candidate text by evaluating its retrieval\nranking, semantic relevance, and influence on the generated response. The\nsystem then isolates poisoned texts using an unsupervised clustering method. We\nevaluate RAGOrigin across seven datasets and fifteen poisoning attacks,\nincluding newly developed adaptive poisoning strategies and multi-attacker\nscenarios. Our approach outperforms existing baselines in identifying poisoned\ncontent and remains robust under dynamic and noisy conditions. These results\nsuggest that RAGOrigin provides a practical and effective solution for tracing\nthe origins of corrupted knowledge in RAG systems.", "published": "2025-09-17 07:38:54", "link": "http://arxiv.org/abs/2509.13772v1", "categories": ["cs.CR", "cs.IR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Sequential Data Augmentation for Generative Recommendation", "abstract": "Generative recommendation plays a crucial role in personalized systems,\npredicting users' future interactions from their historical behavior sequences.\nA critical yet underexplored factor in training these models is data\naugmentation, the process of constructing training data from user interaction\nhistories. By shaping the training distribution, data augmentation directly and\noften substantially affects model generalization and performance. Nevertheless,\nin much of the existing work, this process is simplified, applied\ninconsistently, or treated as a minor design choice, without a systematic and\nprincipled understanding of its effects.\n  Motivated by our empirical finding that different augmentation strategies can\nyield large performance disparities, we conduct an in-depth analysis of how\nthey reshape training distributions and influence alignment with future targets\nand generalization to unseen inputs. To systematize this design space, we\npropose GenPAS, a generalized and principled framework that models augmentation\nas a stochastic sampling process over input-target pairs with three\nbias-controlled steps: sequence sampling, target sampling, and input sampling.\nThis formulation unifies widely used strategies as special cases and enables\nflexible control of the resulting training distribution. Our extensive\nexperiments on benchmark and industrial datasets demonstrate that GenPAS yields\nsuperior accuracy, data efficiency, and parameter efficiency compared to\nexisting strategies, providing practical guidance for principled training data\nconstruction in generative recommendation.", "published": "2025-09-17 02:53:25", "link": "http://arxiv.org/abs/2509.13648v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "PoPStat-COVID19: Leveraging Population Pyramids to Quantify Demographic Vulnerability to COVID-19", "abstract": "Understanding how population age structure shapes COVID-19 burden is crucial\nfor pandemic preparedness, yet common summary measures such as median age\nignore key distributional features like skewness, bimodality, and the\nproportional weight of high-risk cohorts. We extend the PoPStat framework,\noriginally devised to link entire population pyramids with cause-specific\nmortality by applying it to COVID-19. Using 2019 United Nations World\nPopulation Prospects age-sex distributions together with cumulative cases and\ndeaths per million recorded up to 5 May 2023 by Our World in Data, we calculate\nPoPDivergence (the Kullback-Leibler divergence from an optimised reference\npyramid) for 180+ countries and derive PoPStat-COVID19 as the Pearson\ncorrelation between that divergence and log-transformed incidence or mortality.\nOptimisation selects Malta's old-skewed pyramid as the reference, yielding\nstrong negative correlations for cases (r=-0.86, p<0.001, R^2=0.74) and deaths\n(r=-0.82, p<0.001, R^2=0.67). Sensitivity tests across twenty additional,\nsimilarly old-skewed references confirm that these associations are robust to\nreference choice. Benchmarking against eight standard indicators like gross\ndomestic product per capita, Gini index, Human Development Index, life\nexpectancy at birth, median age, population density, Socio-demographic Index,\nand Universal Health Coverage Index shows that PoPStat-COVID19 surpasses GDP\nper capita, median age, population density, and several other traditional\nmeasures, and outperforms every comparator for fatality burden. PoPStat-COVID19\ntherefore provides a concise, distribution-aware scalar for quantifying\ndemographic vulnerability to COVID-19.", "published": "2025-09-17 17:46:13", "link": "http://arxiv.org/abs/2509.14213v1", "categories": ["stat.AP", "cs.IT", "math.IT"], "primary_category": "stat.AP"}
{"title": "Conditions for equality and stability in Shannon's and Tao's entropy power inequalities", "abstract": "We show that there is equality in Shannon's Entropy Power Inequality (EPI) if\nand only if the random variables involved are Gaussian, assuming nothing beyond\nthe existence of differential entropies. This is done by justifying de Bruijn's\nidentity without a second moment assumption. Part of the proof also relies on a\nre-examination of an example of Bobkov and Chistyakov (2015), which shows that\nthere exists a random variable $X$ with finite differential entropy $h(X),$\nsuch that $h(X+Y) = \\infty$ for any independent random variable $Y$ with finite\nentropy. We prove that either $X$ has this property, or $h(X+Y)$ is finite for\nany independent $Y$ that does not have this property. Using this, we prove the\ncontinuity of $t \\mapsto h(X+\\sqrt{t}Z)$ at $t=0$, where $Z \\sim\n\\mathcal{N}(0,1)$ is independent of $X$, under minimal assumptions. We then\nestablish two stability results: A qualitative stability result for Shannon's\nEPI in terms of weak convergence under very mild moment conditions, and a\nquantitative stability result in Tao's discrete analogue of the EPI under\nlog-concavity. The proof for the first stability result is based on a\ncompactness argument, while the proof of the second uses the Cheeger inequality\nand leverages concentration properties of discrete log-concave distributions.", "published": "2025-09-17 14:26:41", "link": "http://arxiv.org/abs/2509.14021v1", "categories": ["math.PR", "cs.IT", "math.IT"], "primary_category": "math.PR"}
{"title": "Deriving Moments in the Age of Gossip Process from Percolation", "abstract": "This paper concerns fundamental identities in the study of age of information\n(AoI) in gossip networks. We recover known recursive identities for arbitrary\nkth moments of the age process based on the recent connection between AoI and\nfirst passage percolation. Apart from the connection to percolation, our proofs\nare more concise and can be followed using only elementary facts from\nprobability. Our argument generalizes some techniques known in the statistical\nphysics community, and we remark on connections to the Eden model.", "published": "2025-09-17 13:52:58", "link": "http://arxiv.org/abs/2509.13981v1", "categories": ["cs.IT", "math.IT", "math.PR"], "primary_category": "cs.IT"}
{"title": "Asymptotic Analysis of Nonlinear One-Bit Precoding in Massive MIMO Systems via Approximate Message Passing", "abstract": "Massive multiple-input multiple-output (MIMO) systems employing one-bit\ndigital-to-analog converters offer a hardware-efficient solution for wireless\ncommunications. However, the one-bit constraint poses significant challenges\nfor precoding design, as it transforms the problem into a discrete and\nnonconvex optimization task. In this paper, we investigate a widely adopted\n``convex-relaxation-then-quantization\" approach for nonlinear symbol-level\none-bit precoding. Specifically, we first solve a convex relaxation of the\ndiscrete minimum mean square error precoding problem, and then quantize the\nsolution to satisfy the one-bit constraint. To analyze the high-dimensional\nasymptotic performance of this scheme, we develop a novel analytical framework\nbased on approximate message passing (AMP). This framework enables us to derive\na closed-form expression for the symbol error probability (SEP) at the receiver\nside in the large-system limit, which provides a quantitative characterization\nof how model and system parameters affect the SEP performance. Our empirical\nresults suggest that the $\\ell_\\infty^2$ regularizer, when paired with an\noptimally chosen regularization parameter, achieves optimal SEP performance\nwithin a broad class of convex regularization functions. As a first step\ntowards a theoretical justification, we prove the optimality of the\n$\\ell_\\infty^2$ regularizer within the mixed $\\ell_\\infty^2$-$\\ell_2^2$\nregularization functions.", "published": "2025-09-17 13:25:45", "link": "http://arxiv.org/abs/2509.13955v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Reconfigurable Intelligent Surface-Assisted Multiuser Tracking and Signal Detection in ISAC", "abstract": "This paper investigates the multiuser tracking and signal detection problem\nin integrated sensing and communication (ISAC) systems with the assistance of\nreconfigurable intelligent surfaces (RISs). Due to the diverse and high user\nmobility, the tracking and signal detection performance can be significantly\ndeteriorated without choreographed user state (position and velocity) updating\nprinciple. To tackle this challenge, we manage to establish a comprehensive\nprobabilistic signal model to characterize the interdependencies among user\nstates, transmit signals, and received signals during the tracking procedure.\nBased on the Bayesian problem formulation, we further propose a novel hybrid\nvariational message passing algorithm for the online estimation of user states,\nwhich can iteratively update the posterior probabilities of user states during\neach tracking frame with computational efficiency. Numerical results are\nprovided to demonstrate that the proposed algorithm can significantly improve\nboth of the tracking and signal detection performance over the representative\nBayesian estimation counterparts.", "published": "2025-09-17 13:07:29", "link": "http://arxiv.org/abs/2509.13940v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "A Tight Quantum Algorithm for Multiple Collision Search", "abstract": "Searching for collisions in random functions is a fundamental computational\nproblem, with many applications in symmetric and asymmetric cryptanalysis. When\none searches for a single collision, the known quantum algorithms match the\nquery lower bound. This is not the case for the problem of finding multiple\ncollisions, despite its regular appearance as a sub-component in sieving-type\nalgorithms.\n  At EUROCRYPT 2019, Liu and Zhandry gave a query lower bound $\\Omega(2^{m/3 +\n2k/3})$ for finding $2^k$ collisions in a random function with m-bit output. At\nEUROCRYPT 2023, Bonnetain et al. gave a quantum algorithm matching this bound\nfor a large range of $m$ and $k$, but not all admissible values. Like many\nprevious collision-finding algorithms, theirs is based on the MNRS quantum walk\nframework, but it chains the walks by reusing the state after outputting a\ncollision.\n  In this paper, we give a new algorithm that tackles the remaining non-optimal\nrange, closing the problem. Our algorithm is tight (up to a polynomial factor)\nin queries, and also in time under a quantum RAM assumption. The idea is to\nextend the chained walk to a regime in which several collisions are returned at\neach step, and the ``walks'' themselves only perform a single diffusion layer.", "published": "2025-09-17 11:15:02", "link": "http://arxiv.org/abs/2509.13909v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "LINC: An In-Network Coding Approach to Tame Packet Loss in Hybrid Wireless-Fiber Backbones", "abstract": "The emergence of ultra-low latency applications, such as financial\ntransactions, has driven the development of hybrid backbone networks that rely\non fiber, satellite, and microwave links. Despite providing low latencies,\nthese hybrid networks suffer from occasional environmental packet loss caused\nby poor weather, construction, and line of sight blockage. Paradoxically,\ntoday's hybrid backbones rely on conventional transport protocols that take\npacket loss to signal network congestion, as opposed to transient environmental\nobstacles. A common approach to address this challenge is to use network coding\n(NC) between the end hosts to recover from these occasional packet loss events.\nHowever, current NC proposals assume full access to the end-hosts' stack to\nperform end-to-end encoding/decoding operations. In this paper, we introduce\nLINC, a novel system that provides in-network NC capabilities to mitigate\nenvironmental packet loss events without requiring cooperation from the end\nhosts. LINC uses a systematic block coding approach on a link-by-link basis,\nencoding and decoding packets inside the network. We model the tradeoff in\ngoodput between end-to-end retransmissions and redundant packets introduced by\nLINC, and propose an optimization formulation to determine the optimal choice\nof coding parameters. Our simulations on real-world backbone topologies\ndemonstrate that LINC reduces the end-to-end latency by up to 18% by\neliminating unnecessary retransmissions.", "published": "2025-09-17 05:57:17", "link": "http://arxiv.org/abs/2509.13714v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Clustering Strategies in Satellite-Aided Communications", "abstract": "With the rapid advancement of next-generation satellite networks, addressing\nclustering tasks, user grouping, and efficient link management has become\nincreasingly critical to optimize network performance and reduce interference.\nIn this paper, we provide a comprehensive overview of modern clustering\napproaches based on machine learning and heuristic algorithms. The experimental\nresults indicate that improved machine learning techniques and graph\ntheory-based methods deliver significantly better performance and scalability\nthan conventional clustering methods, such as the pure clustering algorithm\nexamined in previous research. These advantages are especially evident in\nlarge-scale satellite network scenarios. Furthermore, the paper outlines\npotential research directions and discusses integrated, multi-dimensional\nsolutions to enhance adaptability and efficiency in future satellite\ncommunication.", "published": "2025-09-17 05:09:16", "link": "http://arxiv.org/abs/2509.13701v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Uplink-Downlink Duality for Beamforming in Integrated Sensing and Communications", "abstract": "This paper considers the beamforming and power optimization problem for a\nclass of integrated sensing and communications (ISAC) problems that utilize the\ncommunication signals simultaneously for sensing. We formulate the problem of\nminimizing the Bayesian Cram\\'er-Rao bound (BCRB) on the mean-squared error of\nestimating a vector of parameters, while satisfying downlink\nsignal-to-interference-and-noise-ratio constraints for a set of communication\nusers at the same time. The proposed optimization framework comprises two key\nnew ingredients. First, we show that the BCRB minimization problem corresponds\nto maximizing beamforming power along certain sensing directions of interest.\nSecond, the classical uplink-downlink duality for multiple-input\nmultiple-output communications can be extended to the ISAC setting, but unlike\nthe classical communication problem, the dual uplink problem for ISAC may\nentail negative noise power and needs to include an extra condition on the\nuplink beamformers. This new duality theory opens doors for an efficient\niterative algorithm for optimizing power and beamformers for ISAC.", "published": "2025-09-17 03:28:42", "link": "http://arxiv.org/abs/2509.13661v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision", "abstract": "Where do learning signals come from when there is no ground truth in\npost-training? We propose turning exploration into supervision through Compute\nas Teacher (CaT), which converts the model's own exploration at inference-time\ninto reference-free supervision by synthesizing a single reference from a group\nof parallel rollouts and then optimizing toward it. Concretely, the current\npolicy produces a group of rollouts; a frozen anchor (the initial policy)\nreconciles omissions and contradictions to estimate a reference, turning extra\ninference-time compute into a teacher signal. We turn this into rewards in two\nregimes: (i) verifiable tasks use programmatic equivalence on final answers;\n(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria\nscored by an independent LLM judge, with reward given by the fraction\nsatisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge\nscores), synthesis may disagree with the majority and be correct even when all\nrollouts are wrong; performance scales with the number of rollouts. As a\ntest-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up\nto +27% on MATH-500; +12% on HealthBench). With reinforcement learning\n(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained\npolicy surpassing the initial teacher signal.", "published": "2025-09-17 17:59:42", "link": "http://arxiv.org/abs/2509.14234v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "NIRVANA: Structured pruning reimagined for large language models compression", "abstract": "Structured pruning of large language models (LLMs) offers substantial\nefficiency improvements by removing entire hidden units, yet current approaches\noften suffer from significant performance degradation, particularly in\nzero-shot settings, and necessitate costly recovery techniques such as\nsupervised fine-tuning (SFT) or adapter insertion. To address these critical\nshortcomings, we introduce NIRVANA, a novel pruning method explicitly designed\nto balance immediate zero-shot accuracy preservation with robust fine-tuning\ncapability. Leveraging a first-order saliency criterion derived from the Neural\nTangent Kernel under Adam optimization dynamics, NIRVANA provides a\ntheoretically grounded pruning strategy that respects essential model training\nbehaviors. To further address the unique challenges posed by structured\npruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across\nlayers and modules (attention vs. MLP), which adjusts pruning intensity between\nmodules in a globally balanced manner. Additionally, to mitigate the high\nsensitivity of pruning decisions to calibration data quality, we propose a\nsimple yet effective KL divergence-based calibration data selection strategy,\nensuring more reliable and task-agnostic pruning outcomes. Comprehensive\nexperiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA\noutperforms existing structured pruning methods under equivalent sparsity\nconstraints, providing a theoretically sound and practical approach to LLM\ncompression. The code is available at\nhttps://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.", "published": "2025-09-17 17:59:00", "link": "http://arxiv.org/abs/2509.14230v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Spacing Test for Fused Lasso", "abstract": "This study addresses the unresolved problem of selecting the regularization\nparameter in the fused lasso. In particular, we extend the framework of the\nSpacing Test proposed by Tibshirani et al. to the fused lasso, providing a\ntheoretical foundation for post-selection inference by characterizing the\nselection event as a polyhedral constraint. Based on the analysis of the\nsolution path of the fused lasso using a LARS-type algorithm, we derive exact\nconditional $p$-values for the selected change-points. Our method broadens the\napplicability of the Spacing Test from the standard lasso to fused penalty\nstructures. Furthermore, through numerical experiments comparing the proposed\nmethod with sequential versions of AIC and BIC as well as cross-validation, we\ndemonstrate that the proposed approach properly controls the type I error while\nachieving high detection power. This work offers a theoretically sound and\ncomputationally practical solution for parameter selection and post-selection\ninference in structured signal estimation problems. Keywords: Fused Lasso,\nRegularization parameter selection, Spacing Test for Lasso, Selective\ninference, Change-point detection", "published": "2025-09-17 17:58:28", "link": "http://arxiv.org/abs/2509.14229v1", "categories": ["math.ST", "cs.LG", "stat.TH"], "primary_category": "math.ST"}
{"title": "Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models", "abstract": "Source localization in a complex flow poses a significant challenge for\nmulti-robot teams tasked with localizing the source of chemical leaks or\ntracking the dispersion of an oil spill. The flow dynamics can be time-varying\nand chaotic, resulting in sporadic and intermittent sensor readings, and\ncomplex environmental geometries further complicate a team's ability to model\nand predict the dispersion. To accurately account for the physical processes\nthat drive the dispersion dynamics, robots must have access to computationally\nintensive numerical models, which can be difficult when onboard computation is\nlimited. We present a distributed mobile sensing framework for source\nlocalization in which each robot carries a machine-learned, finite element\nmodel of its environment to guide information-based sampling. The models are\nused to evaluate an approximate mutual information criterion to drive an\ninfotaxis control strategy, which selects sensing regions that are expected to\nmaximize informativeness for the source localization objective. Our approach\nachieves faster error reduction compared to baseline sensing strategies and\nresults in more accurate source localization compared to baseline machine\nlearning approaches.", "published": "2025-09-17 17:58:25", "link": "http://arxiv.org/abs/2509.14228v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics", "abstract": "Recent advances in generative artificial intelligence applications have\nraised new data security concerns. This paper focuses on defending diffusion\nmodels against membership inference attacks. This type of attack occurs when\nthe attacker can determine if a certain data point was used to train the model.\nAlthough diffusion models are intrinsically more resistant to membership\ninference attacks than other generative models, they are still susceptible. The\ndefense proposed here utilizes critically-damped higher-order Langevin\ndynamics, which introduces several auxiliary variables and a joint diffusion\nprocess along these variables. The idea is that the presence of auxiliary\nvariables mixes external randomness that helps to corrupt sensitive input data\nearlier on in the diffusion process. This concept is theoretically investigated\nand validated on a toy dataset and a speech dataset using the Area Under the\nReceiver Operating Characteristic (AUROC) curves and the FID metric.", "published": "2025-09-17 17:56:20", "link": "http://arxiv.org/abs/2509.14225v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems", "abstract": "Data-driven modeling of nonlinear dynamical systems is often hampered by\nmeasurement noise. We propose a denoising framework, called Runge-Kutta and\nTotal Variation Based Implicit Neural Representation (RKTV-INR), that\nrepresents the state trajectory with an implicit neural representation (INR)\nfitted directly to noisy observations. Runge-Kutta integration and total\nvariation are imposed as constraints to ensure that the reconstructed state is\na trajectory of a dynamical system that remains close to the original data. The\ntrained INR yields a clean, continuous trajectory and provides accurate\nfirst-order derivatives via automatic differentiation. These denoised states\nand derivatives are then supplied to Sparse Identification of Nonlinear\nDynamics (SINDy) to recover the governing equations. Experiments demonstrate\neffective noise suppression, precise derivative estimation, and reliable system\nidentification.", "published": "2025-09-17 17:51:43", "link": "http://arxiv.org/abs/2509.14219v1", "categories": ["cs.LG", "math.DS", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain", "abstract": "Learning and optimal control under robust Markov decision processes (MDPs)\nhave received increasing attention, yet most existing theory, algorithms, and\napplications focus on finite-horizon or discounted models. The average-reward\nformulation, while natural in many operations research and management contexts,\nremains underexplored. This is primarily because the dynamic programming\nfoundations are technically challenging and only partially understood, with\nseveral fundamental questions remaining open. This paper steps toward a general\nframework for average-reward robust MDPs by analyzing the constant-gain\nsetting. We study the average-reward robust control problem with possible\ninformation asymmetries between the controller and an S-rectangular adversary.\nOur analysis centers on the constant-gain robust Bellman equation, examining\nboth the existence of solutions and their relationship to the optimal average\nreward. Specifically, we identify when solutions to the robust Bellman equation\ncharacterize the optimal average reward and stationary policies, and we provide\nsufficient conditions ensuring solutions' existence. These findings expand the\ndynamic programming theory for average-reward robust MDPs and lay a foundation\nfor robust dynamic decision making under long-run average criteria in\noperational environments.", "published": "2025-09-17 17:36:06", "link": "http://arxiv.org/abs/2509.14203v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning", "abstract": "Residual-based adaptive strategies are widely used in scientific machine\nlearning but remain largely heuristic. We introduce a unifying variational\nframework that formalizes these methods by integrating convex transformations\nof the residual. Different transformations correspond to distinct objective\nfunctionals: exponential weights target the minimization of uniform error,\nwhile linear weights recover the minimization of quadratic error. Within this\nperspective, adaptive weighting is equivalent to selecting sampling\ndistributions that optimize the primal objective, thereby linking\ndiscretization choices directly to error metrics. This principled approach\nyields three benefits: (1) it enables systematic design of adaptive schemes\nacross norms, (2) reduces discretization error through variance reduction of\nthe loss estimator, and (3) enhances learning dynamics by improving the\ngradient signal-to-noise ratio. Extending the framework to operator learning,\nwe demonstrate substantial performance gains across optimizers and\narchitectures. Our results provide a theoretical justification of\nresidual-based adaptivity and establish a foundation for principled\ndiscretization and training strategies.", "published": "2025-09-17 17:34:03", "link": "http://arxiv.org/abs/2509.14198v1", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits", "abstract": "Analog and mixed-signal circuit design remains challenging due to the\nshortage of high-quality data and the difficulty of embedding domain knowledge\ninto automated flows. Traditional black-box optimization achieves sampling\nefficiency but lacks circuit understanding, which often causes evaluations to\nbe wasted in low-value regions of the design space. In contrast, learning-based\nmethods embed structural knowledge but are case-specific and costly to retrain.\nRecent attempts with large language models show potential, yet they often rely\non manual intervention, limiting generality and transparency. We propose\nTopoSizing, an end-to-end framework that performs robust circuit understanding\ndirectly from raw netlists and translates this knowledge into optimization\ngains. Our approach first applies graph algorithms to organize circuits into a\nhierarchical device-module-stage representation. LLM agents then execute an\niterative hypothesis-verification-refinement loop with built-in consistency\nchecks, producing explicit annotations. Verified insights are integrated into\nBayesian optimization through LLM-guided initial sampling and\nstagnation-triggered trust-region updates, improving efficiency while\npreserving feasibility.", "published": "2025-09-17 16:52:46", "link": "http://arxiv.org/abs/2509.14169v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework", "abstract": "Many critical healthcare decisions are challenged by the inability to measure\nkey underlying parameters. Glaucoma, a leading cause of irreversible blindness\ndriven by elevated intraocular pressure (IOP), provides a stark example. The\nprimary determinant of IOP, a tissue property called trabecular meshwork\npermeability, cannot be measured in vivo, forcing clinicians to depend on\nindirect surrogates. This clinical challenge is compounded by a broader\ncomputational one: developing predictive models for such ill-posed inverse\nproblems is hindered by a lack of ground-truth data and prohibitive cost of\nlarge-scale, high-fidelity simulations. We address both challenges with an\nend-to-end framework to noninvasively estimate unmeasurable variables from\nsparse, routine data. Our approach combines a multi-stage artificial\nintelligence architecture to functionally separate the problem; a novel data\ngeneration strategy we term PCDS that obviates the need for hundreds of\nthousands of costly simulations, reducing the effective computational time from\nyears to hours; and a Bayesian engine to quantify predictive uncertainty. Our\nframework deconstructs a single IOP measurement into its fundamental components\nfrom routine inputs only, yielding estimates for the unmeasurable tissue\npermeability and a patient's outflow facility. Our noninvasively estimated\noutflow facility achieved excellent agreement with state-of-the-art tonography\nwith precision comparable to direct physical instruments. Furthermore, the\nnewly derived permeability biomarker demonstrates high accuracy in stratifying\nclinical cohorts by disease risk, highlighting its diagnostic potential. More\nbroadly, our framework establishes a generalizable blueprint for solving\nsimilar inverse problems in other data-scarce, computationally-intensive\ndomains.", "published": "2025-09-17 16:50:23", "link": "http://arxiv.org/abs/2509.14167v1", "categories": ["cs.LG", "q-bio.QM", "stat.AP", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures", "abstract": "Diffusion models typically employ static or heuristic classifier-free\nguidance (CFG) schedules, which often fail to adapt across timesteps and noise\nconditions. In this work, we introduce a quantum reinforcement learning (QRL)\ncontroller that dynamically adjusts CFG at each denoising step. The controller\nadopts a hybrid quantum--classical actor--critic architecture: a shallow\nvariational quantum circuit (VQC) with ring entanglement generates policy\nfeatures, which are mapped by a compact multilayer perceptron (MLP) into\nGaussian actions over $\\Delta$CFG, while a classical critic estimates value\nfunctions. The policy is optimized using Proximal Policy Optimization (PPO)\nwith Generalized Advantage Estimation (GAE), guided by a reward that balances\nclassification confidence, perceptual improvement, and action regularization.\nExperiments on CIFAR-10 demonstrate that our QRL policy improves perceptual\nquality (LPIPS, PSNR, SSIM) while reducing parameter count compared to\nclassical RL actors and fixed schedules. Ablation studies on qubit number and\ncircuit depth reveal trade-offs between accuracy and efficiency, and extended\nevaluations confirm robust generation under long diffusion schedules.", "published": "2025-09-17 16:47:04", "link": "http://arxiv.org/abs/2509.14163v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "A Compositional Kernel Model for Feature Learning", "abstract": "We study a compositional variant of kernel ridge regression in which the\npredictor is applied to a coordinate-wise reweighting of the inputs. Formulated\nas a variational problem, this model provides a simple testbed for feature\nlearning in compositional architectures. From the perspective of variable\nselection, we show how relevant variables are recovered while noise variables\nare eliminated. We establish guarantees showing that both global minimizers and\nstationary points discard noise coordinates when the noise variables are\nGaussian distributed. A central finding is that $\\ell_1$-type kernels, such as\nthe Laplace kernel, succeed in recovering features contributing to nonlinear\neffects at stationary points, whereas Gaussian kernels recover only linear\nones.", "published": "2025-09-17 16:40:34", "link": "http://arxiv.org/abs/2509.14158v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy", "abstract": "Many incarcerated individuals face significant and complex challenges,\nincluding mental illness, substance dependence, and homelessness, yet jails and\nprisons are often poorly equipped to address these needs. With little support\nfrom the existing criminal justice system, these needs can remain untreated and\nworsen, often leading to further offenses and a cycle of incarceration with\nadverse outcomes both for the individual and for public safety, with\nparticularly large impacts on communities of color that continue to widen the\nalready extensive racial disparities in criminal justice outcomes. Responding\nto these failures, a growing number of criminal justice stakeholders are\nseeking to break this cycle through innovative approaches such as\ncommunity-driven and alternative approaches to policing, mentoring, community\nbuilding, restorative justice, pretrial diversion, holistic defense, and social\nservice connections. Here we report on a collaboration between Johnson County,\nKansas, and Carnegie Mellon University to perform targeted, proactive mental\nhealth outreach in an effort to reduce reincarceration rates.\n  This paper describes the data used, our predictive modeling approach and\nresults, as well as the design and analysis of a field trial conducted to\nconfirm our model's predictive power, evaluate the impact of this targeted\noutreach, and understand at what level of reincarceration risk outreach might\nbe most effective. Through this trial, we find that our model is highly\npredictive of new jail bookings, with more than half of individuals in the\ntrial's highest-risk group returning to jail in the following year. Outreach\nwas most effective among these highest-risk individuals, with impacts on mental\nhealth utilization, EMS dispatches, and criminal justice involvement.", "published": "2025-09-17 16:10:13", "link": "http://arxiv.org/abs/2509.14129v1", "categories": ["cs.LG", "cs.CY"], "primary_category": "cs.LG"}
{"title": "From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting", "abstract": "While neural networks are achieving high predictive accuracy in multi-horizon\nprobabilistic forecasting, understanding the underlying mechanisms that lead to\nfeature-conditioned outputs remains a significant challenge for forecasters. In\nthis work, we take a further step toward addressing this critical issue by\nintroducing the Quantile Neural Basis Model, which incorporates the\ninterpretability principles of Quantile Generalized Additive Models into an\nend-to-end neural network training framework. To this end, we leverage shared\nbasis decomposition and weight factorization, complementing Neural Models for\nLocation, Scale, and Shape by avoiding any parametric distributional\nassumptions. We validate our approach on day-ahead electricity price\nforecasting, achieving predictive performance comparable to distributional and\nquantile regression neural networks, while offering valuable insights into\nmodel behavior through the learned nonlinear mappings from input features to\noutput predictions across the horizon.", "published": "2025-09-17 15:55:59", "link": "http://arxiv.org/abs/2509.14113v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques", "abstract": "This study investigates classifier performance across EEG frequency bands\nusing various optimizers and evaluates efficient class prediction for the left\nand right hemispheres. Three neural network architectures - a deep dense\nnetwork, a shallow three-layer network, and a convolutional neural network\n(CNN) - are implemented and compared using the TensorFlow and PyTorch\nframeworks. Results indicate that the Adagrad and RMSprop optimizers\nconsistently perform well across different frequency bands, with Adadelta\nexhibiting robust performance in cross-model evaluations. Specifically, Adagrad\nexcels in the beta band, while RMSprop achieves superior performance in the\ngamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among\nthe models, the CNN demonstrates the second highest accuracy, particularly in\ncapturing spatial features of EEG data. The deep dense network shows\ncompetitive performance in learning complex patterns, whereas the shallow\nthree-layer network, sometimes being less accurate, provides computational\nefficiency. SHAP (Shapley Additive Explanations) plots are employed to identify\nefficient class prediction, revealing nuanced contributions of EEG frequency\nbands to model accuracy. Overall, the study highlights the importance of\noptimizer selection, model architecture, and EEG frequency band analysis in\nenhancing classifier performance and understanding feature importance in\nneuroimaging-based classification tasks.", "published": "2025-09-17 15:26:45", "link": "http://arxiv.org/abs/2509.14078v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Online Bayesian Risk-Averse Reinforcement Learning", "abstract": "In this paper, we study the Bayesian risk-averse formulation in reinforcement\nlearning (RL). To address the epistemic uncertainty due to a lack of data, we\nadopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the\nparameter uncertainty of the unknown underlying model. We derive the asymptotic\nnormality that characterizes the difference between the Bayesian risk value\nfunction and the original value function under the true unknown distribution.\nThe results indicate that the Bayesian risk-averse approach tends to\npessimistically underestimate the original value function. This discrepancy\nincreases with stronger risk aversion and decreases as more data become\navailable. We then utilize this adaptive property in the setting of online RL\nas well as online contextual multi-arm bandits (CMAB), a special case of online\nRL. We provide two procedures using posterior sampling for both the general RL\nproblem and the CMAB problem. We establish a sub-linear regret bound, with the\nregret defined as the conventional regret for both the RL and CMAB settings.\nAdditionally, we establish a sub-linear regret bound for the CMAB setting with\nthe regret defined as the Bayesian risk regret. Finally, we conduct numerical\nexperiments to demonstrate the effectiveness of the proposed algorithm in\naddressing epistemic uncertainty and verifying the theoretical properties.", "published": "2025-09-17 15:25:06", "link": "http://arxiv.org/abs/2509.14077v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Physics-based deep kernel learning for parameter estimation in high dimensional PDEs", "abstract": "Inferring parameters of high-dimensional partial differential equations\n(PDEs) poses significant computational and inferential challenges, primarily\ndue to the curse of dimensionality and the inherent limitations of traditional\nnumerical methods. This paper introduces a novel two-stage Bayesian framework\nthat synergistically integrates training, physics-based deep kernel learning\n(DKL) with Hamiltonian Monte Carlo (HMC) to robustly infer unknown PDE\nparameters and quantify their uncertainties from sparse, exact observations.\nThe first stage leverages physics-based DKL to train a surrogate model, which\njointly yields an optimized neural network feature extractor and robust initial\nestimates for the PDE parameters. In the second stage, with the neural network\nweights fixed, HMC is employed within a full Bayesian framework to efficiently\nsample the joint posterior distribution of the kernel hyperparameters and the\nPDE parameters. Numerical experiments on canonical and high-dimensional inverse\nPDE problems demonstrate that our framework accurately estimates parameters,\nprovides reliable uncertainty estimates, and effectively addresses challenges\nof data sparsity and model complexity, offering a robust and scalable tool for\ndiverse scientific and engineering applications.", "published": "2025-09-17 14:56:31", "link": "http://arxiv.org/abs/2509.14054v1", "categories": ["cs.CE", "cs.LG", "cs.NA", "math.NA", "68T05", "I.2.6"], "primary_category": "cs.CE"}
{"title": "On the Rate of Gaussian Approximation for Linear Regression Problems", "abstract": "In this paper, we consider the problem of Gaussian approximation for the\nonline linear regression task. We derive the corresponding rates for the\nsetting of a constant learning rate and study the explicit dependence of the\nconvergence rate upon the problem dimension $d$ and quantities related to the\ndesign matrix. When the number of iterations $n$ is known in advance, our\nresults yield the rate of normal approximation of order $\\sqrt{\\log{n}/n}$,\nprovided that the sample size $n$ is large enough.", "published": "2025-09-17 14:42:13", "link": "http://arxiv.org/abs/2509.14039v1", "categories": ["stat.ML", "cs.LG", "math.OC", "60F05, 62L20, 93E35"], "primary_category": "stat.ML"}
{"title": "Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation", "abstract": "We study the existence and computation of Nash equilibria in continuous\nstatic games where the players' admissible strategies are subject to shared\ncoupling constraints, i.e., constraints that depend on their \\emph{joint}\nstrategies. Specifically, we focus on a class of games characterized by\nplayerwise concave utilities and playerwise concave constraints. Prior results\non the existence of Nash equilibria are not applicable to this class, as they\nrely on strong assumptions such as joint convexity of the feasible set. By\nleveraging topological fixed point theory and novel structural insights into\nthe contractibility of feasible sets under playerwise concave constraints, we\ngive an existence proof for Nash equilibria under weaker conditions. Having\nestablished existence, we then focus on the computation of Nash equilibria via\nindependent gradient methods under the additional assumption that the utilities\nadmit a potential function. To account for the possibly nonconvex feasible\nregion, we employ a log barrier regularized gradient ascent with adaptive\nstepsizes. Starting from an initial feasible strategy profile and under exact\ngradient feedback, the proposed method converges to an $\\epsilon$-approximate\nconstrained Nash equilibrium within $\\mathcal{O}(\\epsilon^{-3})$ iterations.", "published": "2025-09-17 14:33:49", "link": "http://arxiv.org/abs/2509.14032v1", "categories": ["cs.GT", "cs.LG", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Deep Learning-Driven Peptide Classification in Biological Nanopores", "abstract": "A device capable of performing real time classification of proteins in a\nclinical setting would allow for inexpensive and rapid disease diagnosis. One\nsuch candidate for this technology are nanopore devices. These devices work by\nmeasuring a current signal that arises when a protein or peptide enters a\nnanometer-length-scale pore. Should this current be uniquely related to the\nstructure of the peptide and its interactions with the pore, the signals can be\nused to perform identification. While such a method would allow for real time\nidentification of peptides and proteins in a clinical setting, to date, the\ncomplexities of these signals limit their accuracy. In this work, we tackle the\nissue of classification by converting the current signals into scaleogram\nimages via wavelet transforms, capturing amplitude, frequency, and time\ninformation in a modality well-suited to machine learning algorithms. When\ntested on 42 peptides, our method achieved a classification accuracy of\n~$81\\,\\%$, setting a new state-of-the-art in the field and taking a step toward\npractical peptide/protein diagnostics at the point of care. In addition, we\ndemonstrate model transfer techniques that will be critical when deploying\nthese models into real hardware, paving the way to a new method for real-time\ndisease diagnosis.", "published": "2025-09-17 14:30:55", "link": "http://arxiv.org/abs/2509.14029v1", "categories": ["cs.LG", "eess.SP", "physics.comp-ph", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks", "abstract": "Variational quantum circuits (VQCs) are central to quantum machine learning,\nwhile recent progress in Kolmogorov-Arnold networks (KANs) highlights the power\nof learnable activation functions. We unify these directions by introducing\nquantum variational activation functions (QVAFs), realized through single-qubit\ndata re-uploading circuits called DatA Re-Uploading ActivatioNs (DARUANs). We\nshow that DARUAN with trainable weights in data pre-processing possesses an\nexponentially growing frequency spectrum with data repetitions, enabling an\nexponential reduction in parameter size compared with Fourier-based activations\nwithout loss of expressivity. Embedding DARUAN into KANs yields\nquantum-inspired KANs (QKANs), which retain the interpretability of KANs while\nimproving their parameter efficiency, expressivity, and generalization. We\nfurther introduce two novel techniques to enhance scalability, feasibility and\ncomputational efficiency, such as layer extension and hybrid QKANs (HQKANs) as\ndrop-in replacements of multi-layer perceptrons (MLPs) for feed-forward\nnetworks in large-scale models. We provide theoretical analysis and extensive\nexperiments on function regression, image classification, and autoregressive\ngenerative language modeling, demonstrating the efficiency and scalability of\nQKANs. DARUANs and QKANs offer a promising direction for advancing quantum\nmachine learning on both noisy intermediate-scale quantum (NISQ) hardware and\nclassical quantum simulators.", "published": "2025-09-17 14:28:42", "link": "http://arxiv.org/abs/2509.14026v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Differentially private federated learning for localized control of infectious disease dynamics", "abstract": "In times of epidemics, swift reaction is necessary to mitigate epidemic\nspreading. For this reaction, localized approaches have several advantages,\nlimiting necessary resources and reducing the impact of interventions on a\nlarger scale. However, training a separate machine learning (ML) model on a\nlocal scale is often not feasible due to limited available data. Centralizing\nthe data is also challenging because of its high sensitivity and privacy\nconstraints. In this study, we consider a localized strategy based on the\nGerman counties and communities managed by the related local health authorities\n(LHA). For the preservation of privacy to not oppose the availability of\ndetailed situational data, we propose a privacy-preserving forecasting method\nthat can assist public health experts and decision makers. ML methods with\nfederated learning (FL) train a shared model without centralizing raw data.\nConsidering the counties, communities or LHAs as clients and finding a balance\nbetween utility and privacy, we study a FL framework with client-level\ndifferential privacy (DP). We train a shared multilayer perceptron on sliding\nwindows of recent case counts to forecast the number of cases, while clients\nexchange only norm-clipped updates and the server aggregated updates with DP\nnoise. We evaluate the approach on COVID-19 data on county-level during two\nphases. As expected, very strict privacy yields unstable, unusable forecasts.\nAt a moderately strong level, the DP model closely approaches the non-DP model:\n$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in\nNovember 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,\nclient-level DP-FL can deliver useful county-level predictions with strong\nprivacy guarantees, and viable privacy budgets depend on epidemic phase,\nallowing privacy-compliant collaboration among health authorities for local\nforecasting.", "published": "2025-09-17 14:28:04", "link": "http://arxiv.org/abs/2509.14024v1", "categories": ["cs.LG", "68T07, 68P27, 92-08, 92-10"], "primary_category": "cs.LG"}
{"title": "Artificial neural networks ensemble methodology to predict significant wave height", "abstract": "The forecast of wave variables are important for several applications that\ndepend on a better description of the ocean state. Due to the chaotic behaviour\nof the differential equations which model this problem, a well know strategy to\novercome the difficulties is basically to run several simulations, by for\ninstance, varying the initial condition, and averaging the result of each of\nthese, creating an ensemble. Moreover, in the last few years, considering the\namount of available data and the computational power increase, machine learning\nalgorithms have been applied as surrogate to traditional numerical models,\nyielding comparative or better results. In this work, we present a methodology\nto create an ensemble of different artificial neural networks architectures,\nnamely, MLP, RNN, LSTM, CNN and a hybrid CNN-LSTM, which aims to predict\nsignificant wave height on six different locations in the Brazilian coast. The\nnetworks are trained using NOAA's numerical reforecast data and target the\nresidual between observational data and the numerical model output. A new\nstrategy to create the training and target datasets is demonstrated. Results\nshow that our framework is capable of producing high efficient forecast, with\nan average accuracy of $80\\%$, that can achieve up to $88\\%$ in the best case\nscenario, which means $5\\%$ reduction in error metrics if compared to NOAA's\nnumerical model, and a increasingly reduction of computational cost.", "published": "2025-09-17 14:25:57", "link": "http://arxiv.org/abs/2509.14020v1", "categories": ["physics.ao-ph", "cs.LG", "physics.data-an", "68T07, 86A05, 68T05", "I.2.6; J.2; G.3"], "primary_category": "physics.ao-ph"}
{"title": "Improving cosmological reach of a gravitational wave observatory using Deep Loop Shaping", "abstract": "Improved low-frequency sensitivity of gravitational wave observatories would\nunlock study of intermediate-mass black hole mergers, binary black hole\neccentricity, and provide early warnings for multi-messenger observations of\nbinary neutron star mergers. Today's mirror stabilization control injects\nharmful noise, constituting a major obstacle to sensitivity improvements. We\neliminated this noise through Deep Loop Shaping, a reinforcement learning\nmethod using frequency domain rewards. We proved our methodology on the LIGO\nLivingston Observatory (LLO). Our controller reduced control noise in the\n10--30Hz band by over 30x, and up to 100x in sub-bands surpassing the design\ngoal motivated by the quantum limit. These results highlight the potential of\nDeep Loop Shaping to improve current and future GW observatories, and more\nbroadly instrumentation and control systems.", "published": "2025-09-17 14:22:43", "link": "http://arxiv.org/abs/2509.14016v1", "categories": ["astro-ph.IM", "cs.LG", "cs.SY", "eess.SY", "gr-qc"], "primary_category": "astro-ph.IM"}
{"title": "Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations", "abstract": "Global Navigation Satellite Systems (GNSS) are increasingly disrupted by\nintentional jamming, degrading availability precisely when positioning and\ntiming must remain operational. We address this by reframing jamming mitigation\nas dynamic graph regression and introducing a receiver-centric deep temporal\ngraph network that predicts, and thus corrects, the receivers horizontal\ndeviation in real time. At each 1 Hz epoch, the satellite receiver environment\nis represented as a heterogeneous star graph (receiver center, tracked\nsatellites as leaves) with time varying attributes (e.g., SNR, azimuth,\nelevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM\n(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a\nshort history to output the 2D deviation vector applied for on the fly\ncorrection.\n  We evaluate on datasets from two distinct receivers under three jammer\nprofiles, continuous wave (cw), triple tone (cw3), and wideband FM, each\nexercised at six power levels between -45 and -70 dBm, with 50 repetitions per\nscenario (prejam/jam/recovery). Against strong multivariate time series\nbaselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains\nthe lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm\n(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and\n4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode\ndatasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),\noutperforming Seq2Point, MLP, and CNN. A split study shows superior data\nefficiency: with only 10\\% training data our approach remains well ahead of\nbaselines (20 cm vs. 36-42 cm).", "published": "2025-09-17 14:12:36", "link": "http://arxiv.org/abs/2509.14000v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Classification Filtering", "abstract": "We consider a streaming signal in which each sample is linked to a latent\nclass. We assume that multiple classifiers are available, each providing class\nprobabilities with varying degrees of accuracy. These classifiers are employed\nfollowing a straightforward and fixed policy. In this setting, we consider the\nproblem of fusing the output of the classifiers while incorporating the\ntemporal aspect to improve classification accuracy. We propose a state-space\nmodel and develop a filter tailored for realtime execution. We demonstrate the\neffectiveness of the proposed filter in an activity classification application\nbased on inertial measurement unit (IMU) data from a wearable device.", "published": "2025-09-17 13:48:40", "link": "http://arxiv.org/abs/2509.13975v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection", "abstract": "Objective: Epilepsy, a prevalent neurological disease, demands careful\ndiagnosis and continuous care. Seizure detection remains challenging, as\ncurrent clinical practice relies on expert analysis of electroencephalography,\nwhich is a time-consuming process and requires specialized knowledge.\nAddressing this challenge, this paper explores automated epileptic seizure\ndetection using deep learning, focusing on personalized continual learning\nmodels that adapt to each patient's unique electroencephalography signal\nfeatures, which evolve over time. Methods: In this context, our approach\naddresses the challenge of integrating new data into existing models without\ncatastrophic forgetting, a common issue in static deep learning models. We\npropose EpiSMART, a continual learning framework for seizure detection that\nuses a size-constrained replay buffer and an informed sample selection strategy\nto incrementally adapt to patient-specific electroencephalography signals. By\nselectively retaining high-entropy and seizure-predicted samples, our method\npreserves critical past information while maintaining high performance with\nminimal memory and computational requirements. Results: Validation on the\nCHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score\nover a trained baseline without updates in all other patients. On average,\nEpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,\nmaking it suitable for real-time deployment in wearable systems.\nConclusion:EpiSMART enables robust and personalized seizure detection under\nrealistic and resource-constrained conditions by effectively integrating new\ndata into existing models without degrading past knowledge. Significance: This\nframework advances automated seizure detection by providing a continual\nlearning approach that supports patient-specific adaptation and practical\ndeployment in wearable healthcare systems.", "published": "2025-09-17 13:47:45", "link": "http://arxiv.org/abs/2509.13974v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection", "abstract": "The deployment of unmanned aerial vehicles (UAVs) for reliable and\nenergy-efficient data collection from spatially distributed devices holds great\npromise in supporting diverse Internet of Things (IoT) applications.\nNevertheless, the limited endurance and communication range of UAVs necessitate\nintelligent trajectory planning. While reinforcement learning (RL) has been\nextensively explored for UAV trajectory optimization, its interactive nature\nentails high costs and risks in real-world environments. Offline RL mitigates\nthese issues but remains susceptible to unstable training and heavily rely on\nexpert-quality datasets. To address these challenges, we formulate a joint UAV\ntrajectory planning and resource allocation problem to maximize energy\nefficiency of data collection. The resource allocation subproblem is first\ntransformed into an equivalent linear programming formulation and solved\noptimally with polynomial-time complexity. Then, we propose a large language\nmodel (LLM)-empowered critic-regularized decision transformer (DT) framework,\ntermed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we\nincorporate critic networks to regularize the DT model training, thereby\nintegrating the sequence modeling capabilities of DT with critic-based value\nguidance to enable learning effective policies from suboptimal datasets.\nFurthermore, to mitigate the data-hungry nature of transformer models, we\nemploy a pre-trained LLM as the transformer backbone of the DT model and adopt\na parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid\nadaptation to UAV control tasks with small-scale dataset and low computational\noverhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark\nonline and offline RL methods, achieving up to 36.7\\% higher energy efficiency\nthan the current state-of-the-art DT approaches.", "published": "2025-09-17 13:05:08", "link": "http://arxiv.org/abs/2509.13934v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning", "abstract": "We consider the client selection problem in wireless Federated Learning (FL),\nwith the objective of reducing the total required time to achieve a certain\nlevel of learning accuracy. Since the server cannot observe the clients'\ndynamic states that can change their computation and communication efficiency,\nwe formulate client selection as a restless multi-armed bandit problem. We\npropose a scalable and efficient approach called the Whittle Index Learning in\nFederated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and\nupdate an approximated Whittle index associated with each client, and then\nselects the clients with the highest indices. Compared to existing approaches,\nWILF-Q does not require explicit knowledge of client state transitions or data\ndistributions, making it well-suited for deployment in practical FL settings.\nExperiment results demonstrate that WILF-Q significantly outperforms existing\nbaseline policies in terms of learning efficiency, providing a robust and\nefficient approach to client selection in wireless FL.", "published": "2025-09-17 13:04:14", "link": "http://arxiv.org/abs/2509.13933v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness", "abstract": "Ensuring fairness in machine learning models is critical, especially when\nbiases compound across intersecting protected attributes like race, gender, and\nage. While existing methods address fairness for single attributes, they fail\nto capture the nuanced, multiplicative biases faced by intersectional\nsubgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first\nframework to explicitly model intersectional fairness as a joint optimization\nproblem over the Cartesian product of sensitive attributes. APFEx combines\nthree key innovations- (1) an adaptive multi-objective optimizer that\ndynamically switches between Pareto cone projection, gradient weighting, and\nexploration strategies to navigate fairness-accuracy trade-offs, (2)\ndifferentiable intersectional fairness metrics enabling gradient-based\noptimization of non-smooth subgroup disparities, and (3) theoretical guarantees\nof convergence to Pareto-optimal solutions. Experiments on four real-world\ndatasets demonstrate APFEx's superiority, reducing fairness violations while\nmaintaining competitive accuracy. Our work bridges a critical gap in fair ML,\nproviding a scalable, model-agnostic solution for intersectional fairness.", "published": "2025-09-17 11:13:22", "link": "http://arxiv.org/abs/2509.13908v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates", "abstract": "Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art\nperformance in univariate forecasting on new time series simply by conditioned\non a brief history of past values. Their success demonstrates that large-scale\npretraining across diverse domains can acquire the inductive bias to generalize\nfrom temporal patterns in a brief history. However, most TSFMs are unable to\nleverage covariates -- future-available exogenous variables critical for\naccurate forecasting in many applications -- due to their domain-specific\nnature and the lack of associated inductive bias. We propose TFMAdapter, a\nlightweight, instance-level adapter that augments TSFMs with covariate\ninformation without fine-tuning. Instead of retraining, TFMAdapter operates on\nthe limited history provided during a single model call, learning a\nnon-parametric cascade that combines covariates with univariate TSFM forecasts.\nHowever, such learning would require univariate forecasts at all steps in the\nhistory, requiring too many calls to the TSFM. To enable training on the full\nhistorical context while limiting TSFM invocations, TFMAdapter uses a two-stage\nmethod: (1) generating pseudo-forecasts with a simple regression model, and (2)\ntraining a Gaussian Process regressor to refine predictions using both pseudo-\nand TSFM forecasts alongside covariates. Extensive experiments on real-world\ndatasets demonstrate that TFMAdapter consistently outperforms both foundation\nmodels and supervised baselines, achieving a 24-27\\% improvement over base\nfoundation models with minimal data and computational overhead. Our results\nhighlight the potential of lightweight adapters to bridge the gap between\ngeneric foundation models and domain-specific forecasting needs.", "published": "2025-09-17 11:13:14", "link": "http://arxiv.org/abs/2509.13906v1", "categories": ["cs.LG", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection", "abstract": "Foundation models such as Wav2Vec2 excel at representation learning in speech\ntasks, including audio deepfake detection. However, after being fine-tuned on a\nfixed set of bonafide and spoofed audio clips, they often fail to generalize to\nnovel deepfake methods not represented in training. To address this, we propose\na mixture-of-LoRA-experts approach that integrates multiple low-rank adapters\n(LoRA) into the model's attention layers. A routing mechanism selectively\nactivates specialized experts, enhancing adaptability to evolving deepfake\nattacks. Experimental results show that our method outperforms standard\nfine-tuning in both in-domain and out-of-domain scenarios, reducing equal error\nrates relative to baseline models. Notably, our best MoE-LoRA model lowers the\naverage out-of-domain EER from 8.55\\% to 6.08\\%, demonstrating its\neffectiveness in achieving generalizable audio deepfake detection.", "published": "2025-09-17 10:13:58", "link": "http://arxiv.org/abs/2509.13878v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Graph-Regularized Learning of Gaussian Mixture Models", "abstract": "We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in\ndistributed settings with heterogeneous and limited local data. The method\nexploits a provided similarity graph to guide parameter sharing among nodes,\navoiding the transfer of raw data. The resulting model allows for flexible\naggregation of neighbors' parameters and outperforms both centralized and\nlocally trained GMMs in heterogeneous, low-sample regimes.", "published": "2025-09-17 09:41:26", "link": "http://arxiv.org/abs/2509.13855v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction", "abstract": "Accurate prediction of permeability in porous media is essential for modeling\nsubsurface flow. While pure data-driven models offer computational efficiency,\nthey often lack generalization across scales and do not incorporate explicit\nphysical constraints. Pore network models (PNMs), on the other hand, are\nphysics-based and efficient but rely on idealized geometric assumptions to\nestimate pore-scale hydraulic conductance, limiting their accuracy in complex\nstructures. To overcome these limitations, we present an end-to-end\ndifferentiable hybrid framework that embeds a graph neural network (GNN) into a\nPNM. In this framework, the analytical formulas used for conductance\ncalculations are replaced by GNN-based predictions derived from pore and throat\nfeatures. The predicted conductances are then passed to the PNM solver for\npermeability computation. In this way, the model avoids the idealized geometric\nassumptions of PNM while preserving the physics-based flow calculations. The\nGNN is trained without requiring labeled conductance data, which can number in\nthe thousands per pore network; instead, it learns conductance values by using\na single scalar permeability as the training target. This is made possible by\nbackpropagating gradients through both the GNN (via automatic differentiation)\nand the PNM solver (via a discrete adjoint method), enabling fully coupled,\nend-to-end training. The resulting model achieves high accuracy and generalizes\nwell across different scales, outperforming both pure data-driven and\ntraditional PNM approaches. Gradient-based sensitivity analysis further reveals\nphysically consistent feature influences, enhancing model interpretability.\nThis approach offers a scalable and physically informed framework for\npermeability prediction in complex porous media, reducing model uncertainty and\nimproving accuracy.", "published": "2025-09-17 09:15:23", "link": "http://arxiv.org/abs/2509.13841v1", "categories": ["cs.LG", "physics.geo-ph"], "primary_category": "cs.LG"}
{"title": "Learning Minimal Representations of Many-Body Physics from Snapshots of a Quantum Simulator", "abstract": "Analog quantum simulators provide access to many-body dynamics beyond the\nreach of classical computation. However, extracting physical insights from\nexperimental data is often hindered by measurement noise, limited observables,\nand incomplete knowledge of the underlying microscopic model. Here, we develop\na machine learning approach based on a variational autoencoder (VAE) to analyze\ninterference measurements of tunnel-coupled one-dimensional Bose gases, which\nrealize the sine-Gordon quantum field theory. Trained in an unsupervised\nmanner, the VAE learns a minimal latent representation that strongly correlates\nwith the equilibrium control parameter of the system. Applied to\nnon-equilibrium protocols, the latent space uncovers signatures of frozen-in\nsolitons following rapid cooling, and reveals anomalous post-quench dynamics\nnot captured by conventional correlation-based methods. These results\ndemonstrate that generative models can extract physically interpretable\nvariables directly from noisy and sparse experimental data, providing\ncomplementary probes of equilibrium and non-equilibrium physics in quantum\nsimulators. More broadly, our work highlights how machine learning can\nsupplement established field-theoretical techniques, paving the way for\nscalable, data-driven discovery in quantum many-body systems.", "published": "2025-09-17 08:38:46", "link": "http://arxiv.org/abs/2509.13821v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment", "abstract": "Quantum Machine Learning (QML) offers a new paradigm for addressing complex\nfinancial problems intractable for classical methods. This work specifically\ntackles the challenge of few-shot credit risk assessment, a critical issue in\ninclusive finance where data scarcity and imbalance limit the effectiveness of\nconventional models. To address this, we design and implement a novel hybrid\nquantum-classical workflow. The methodology first employs an ensemble of\nclassical machine learning models (Logistic Regression, Random Forest, XGBoost)\nfor intelligent feature engineering and dimensionality reduction. Subsequently,\na Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as\nthe core classifier. This framework was evaluated through numerical simulations\nand deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting\nprocessor. On a real-world credit dataset of 279 samples, our QNN achieved a\nrobust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive\nAUC of 0.88 in the hardware experiment. This performance surpasses a suite of\nclassical benchmarks, with a particularly strong result on the recall metric.\nThis study provides a pragmatic blueprint for applying quantum computing to\ndata-constrained financial scenarios in the NISQ era and offers valuable\nempirical evidence supporting its potential in high-stakes applications like\ninclusive finance.", "published": "2025-09-17 08:36:05", "link": "http://arxiv.org/abs/2509.13818v1", "categories": ["cs.LG", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Circuit realization and hardware linearization of monotone operator equilibrium networks", "abstract": "It is shown that the port behavior of a resistor-diode network corresponds to\nthe solution of a ReLU monotone operator equilibrium network (a neural network\nin the limit of infinite depth), giving a parsimonious construction of a neural\nnetwork in analog hardware. We furthermore show that the gradient of such a\ncircuit can be computed directly in hardware, using a procedure we call\nhardware linearization. This allows the network to be trained in hardware,\nwhich we demonstrate with a device-level circuit simulation. We extend the\nresults to cascades of resistor-diode networks, which can be used to implement\nfeedforward and other asymmetric networks. We finally show that different\nnonlinear elements give rise to different activation functions, and introduce\nthe novel diode ReLU which is induced by a non-ideal diode model.", "published": "2025-09-17 08:03:15", "link": "http://arxiv.org/abs/2509.13793v1", "categories": ["eess.SY", "cs.LG", "cs.NE", "cs.SY", "math.OC", "65K10, 68T05, 93B30, 93D99"], "primary_category": "eess.SY"}
{"title": "Floating-Body Hydrodynamic Neural Networks", "abstract": "Fluid-structure interaction is common in engineering and natural systems,\nwhere floating-body motion is governed by added mass, drag, and background\nflows. Modeling these dissipative dynamics is difficult: black-box neural\nmodels regress state derivatives with limited interpretability and unstable\nlong-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks\n(FHNN), a physics-structured framework that predicts interpretable hydrodynamic\nparameters such as directional added masses, drag coefficients, and a\nstreamfunction-based flow, and couples them with analytic equations of motion.\nThis design constrains the hypothesis space, enhances interpretability, and\nstabilizes integration. On synthetic vortex datasets, FHNN achieves up to an\norder-of-magnitude lower error than Neural ODEs, recovers physically consistent\nflow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN\nmore effectively handles dissipative dynamics while preserving\ninterpretability, which bridges the gap between black-box learning and\ntransparent system identification.", "published": "2025-09-17 07:51:35", "link": "http://arxiv.org/abs/2509.13783v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning", "abstract": "Multi-view unsupervised feature selection (MUFS) has recently received\nincreasing attention for its promising ability in dimensionality reduction on\nmulti-view unlabeled data. Existing MUFS methods typically select\ndiscriminative features by capturing correlations between features and\nclustering labels. However, an important yet underexplored question remains:\n\\textit{Are such correlations sufficiently reliable to guide feature\nselection?} In this paper, we analyze MUFS from a causal perspective by\nintroducing a novel structural causal model, which reveals that existing\nmethods may select irrelevant features because they overlook spurious\ncorrelations caused by confounders. Building on this causal perspective, we\npropose a novel MUFS method called CAusal multi-view Unsupervised feature\nSelection leArning (CAUSA). Specifically, we first employ a generalized\nunsupervised spectral regression model that identifies informative features by\ncapturing dependencies between features and consensus clustering labels. We\nthen introduce a causal regularization module that can adaptively separate\nconfounders from multi-view data and simultaneously learn view-shared sample\nweights to balance confounder distributions, thereby mitigating spurious\ncorrelations. Thereafter, integrating both into a unified learning framework\nenables CAUSA to select causally informative features. Comprehensive\nexperiments demonstrate that CAUSA outperforms several state-of-the-art\nmethods. To our knowledge, this is the first in-depth study of causal\nmulti-view feature selection in the unsupervised setting.", "published": "2025-09-17 07:22:22", "link": "http://arxiv.org/abs/2509.13763v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting", "abstract": "Traffic forecasting represents a crucial problem within intelligent\ntransportation systems. In recent research, Large Language Models (LLMs) have\nemerged as a promising method, but their intrinsic design, tailored primarily\nfor sequential token processing, introduces notable challenges in effectively\ncapturing spatial dependencies. Specifically, the inherent limitations of LLMs\nin modeling spatial relationships and their architectural incompatibility with\ngraph-structured spatial data remain largely unaddressed. To overcome these\nlimitations, we introduce ST-LINK, a novel framework that enhances the\ncapability of Large Language Models to capture spatio-temporal dependencies.\nIts key components are Spatially-Enhanced Attention (SE-Attention) and the\nMemory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary\nposition embeddings to integrate spatial correlations as direct rotational\ntransformations within the attention mechanism. This approach maximizes spatial\nlearning while preserving the LLM's inherent sequential processing structure.\nMeanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to\ncapture complex temporal dependencies and improve the stability of long-term\nforecasting. Comprehensive experiments on benchmark datasets demonstrate that\nST-LINK surpasses conventional deep learning and LLM approaches, and\neffectively captures both regular traffic patterns and abrupt changes.", "published": "2025-09-17 07:11:45", "link": "http://arxiv.org/abs/2509.13753v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning", "abstract": "Federated learning (FL) faces a critical dilemma: existing protection\nmechanisms like differential privacy (DP) and homomorphic encryption (HE)\nenforce a rigid trade-off, forcing a choice between model utility and\ncomputational efficiency. This lack of flexibility hinders the practical\nimplementation. To address this, we introduce ParaAegis, a parallel protection\nframework designed to give practitioners flexible control over the\nprivacy-utility-efficiency balance. Our core innovation is a strategic model\npartitioning scheme. By applying lightweight DP to the less critical, low norm\nportion of the model while protecting the remainder with HE, we create a\ntunable system. A distributed voting mechanism ensures consensus on this\npartitioning. Theoretical analysis confirms the adjustments between efficiency\nand utility with the same privacy. Crucially, the experimental results\ndemonstrate that by adjusting the hyperparameters, our method enables flexible\nprioritization between model accuracy and training time.", "published": "2025-09-17 06:45:13", "link": "http://arxiv.org/abs/2509.13739v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data", "abstract": "Social anxiety is a common mental health condition linked to significant\nchallenges in academic, social, and occupational functioning. A core feature is\nelevated momentary (state) anxiety in social situations, yet little prior work\nhas measured or predicted fluctuations in this anxiety throughout the day.\nCapturing these intra-day dynamics is critical for designing real-time,\npersonalized interventions such as Just-In-Time Adaptive Interventions\n(JITAIs). To address this gap, we conducted a study with socially anxious\ncollege students (N=91; 72 after exclusions) using our custom smartwatch-based\nsystem over an average of 9.03 days (SD = 2.95). Participants received seven\necological momentary assessments (EMAs) per day to report state anxiety. We\ndeveloped a base model on over 10,000 days of external heart rate data,\ntransferred its representations to our dataset, and fine-tuned it to generate\nprobabilistic predictions. These were combined with trait-level measures in a\nmeta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety\ndetection in our dataset. To evaluate generalizability, we applied the training\napproach to a separate hold-out set from the TILES-18 dataset-the same dataset\nused for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%\nbalanced accuracy, outperforming prior work by at least 7%.", "published": "2025-09-17 06:21:11", "link": "http://arxiv.org/abs/2509.13725v1", "categories": ["cs.LG", "cs.CY"], "primary_category": "cs.LG"}
{"title": "A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks", "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving PDEs, yet existing uncertainty quantification (UQ) approaches for\nPINNs generally lack rigorous statistical guarantees. In this work, we bridge\nthis gap by introducing a distribution-free conformal prediction (CP) framework\nfor UQ in PINNs. This framework calibrates prediction intervals by constructing\nnonconformity scores on a calibration set, thereby yielding distribution-free\nuncertainty estimates with rigorous finite-sample coverage guarantees for\nPINNs. To handle spatial heteroskedasticity, we further introduce local\nconformal quantile estimation, enabling spatially adaptive uncertainty bands\nwhile preserving theoretical guarantee. Through systematic evaluations on\ntypical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz\nequations) and comprehensive testing across multiple uncertainty metrics, our\nresults demonstrate that the proposed framework achieves reliable calibration\nand locally adaptive uncertainty intervals, consistently outperforming\nheuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work\nintroduces a general framework that not only enhances calibration and\nreliability, but also opens new avenues for uncertainty-aware modeling of\ncomplex PDE systems.", "published": "2025-09-17 06:12:48", "link": "http://arxiv.org/abs/2509.13717v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Learning quantum many-body data locally: A provably scalable framework", "abstract": "Machine learning (ML) holds great promise for extracting insights from\ncomplex quantum many-body data obtained in quantum experiments. This approach\ncan efficiently solve certain quantum problems that are classically\nintractable, suggesting potential advantages of harnessing quantum data.\nHowever, addressing large-scale problems still requires significant amounts of\ndata beyond the limited computational resources of near-term quantum devices.\nWe propose a scalable ML framework called Geometrically Local Quantum Kernel\n(GLQK), designed to efficiently learn quantum many-body experimental data by\nleveraging the exponential decay of correlations, a phenomenon prevalent in\nnoncritical systems. In the task of learning an unknown polynomial of quantum\nexpectation values, we rigorously prove that GLQK substantially improves\npolynomial sample complexity in the number of qubits $n$, compared to the\nexisting shadow kernel, by constructing a feature space from local quantum\ninformation at the correlation length scale. This improvement is particularly\nnotable when each term of the target polynomial involves few local subsystems.\nRemarkably, for translationally symmetric data, GLQK achieves constant sample\ncomplexity, independent of $n$. We numerically demonstrate its high scalability\nin two learning tasks on quantum many-body phenomena. These results establish\nnew avenues for utilizing experimental data to advance the understanding of\nquantum many-body physics.", "published": "2025-09-17 05:26:11", "link": "http://arxiv.org/abs/2509.13705v1", "categories": ["quant-ph", "cond-mat.stat-mech", "cs.LG"], "primary_category": "quant-ph"}
{"title": "RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization", "abstract": "Accurate localized wireless channel modeling is a cornerstone of cellular\nnetwork optimization, enabling reliable prediction of network performance\nduring parameter tuning. Localized statistical channel modeling (LSCM) is the\nstate-of-the-art channel modeling framework tailored for cellular network\noptimization. However, traditional LSCM methods, which infer the channel's\nAngular Power Spectrum (APS) from Reference Signal Received Power (RSRP)\nmeasurements, suffer from critical limitations: they are typically confined to\nsingle-cell, single-grid and single-carrier frequency analysis and fail to\ncapture complex cross-domain interactions. To overcome these challenges, we\npropose RF-LSCM, a novel framework that models the channel APS by jointly\nrepresenting large-scale signal attenuation and multipath components within a\nradiance field. RF-LSCM introduces a multi-domain LSCM formulation with a\nphysics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the\ncross frequency generalization as well as a point-cloud-aided environment\nenhanced method to enable multi-cell and multi-grid channel modeling.\nFurthermore, to address the computational inefficiency of typical neural\nradiance fields, RF-LSCM leverages a low-rank tensor representation,\ncomplemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.\nThis efficient design significantly reduces GPU memory requirements and\ntraining time while preserving fine-grained accuracy. Extensive experiments on\nreal-world multi-cell datasets demonstrate that RF-LSCM significantly\noutperforms state-of-the-art methods, achieving up to a 30% reduction in mean\nabsolute error (MAE) for coverage prediction and a 22% MAE improvement by\neffectively fusing multi-frequency data.", "published": "2025-09-17 04:31:18", "link": "http://arxiv.org/abs/2509.13686v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient Last-Iterate Convergence in Regret Minimization via Adaptive Reward Transformation", "abstract": "Regret minimization is a powerful method for finding Nash equilibria in\nNormal-Form Games (NFGs) and Extensive-Form Games (EFGs), but it typically\nguarantees convergence only for the average strategy. However, computing the\naverage strategy requires significant computational resources or introduces\nadditional errors, limiting its practical applicability. The Reward\nTransformation (RT) framework was introduced to regret minimization to achieve\nlast-iterate convergence through reward function regularization. However, it\nfaces practical challenges: its performance is highly sensitive to manually\ntuned parameters, which often deviate from theoretical convergence conditions,\nleading to slow convergence, oscillations, or stagnation in local optima.\n  Inspired by previous work, we propose an adaptive technique to address these\nissues, ensuring better consistency between theoretical guarantees and\npractical performance for RT Regret Matching (RTRM), RT Counterfactual Regret\nMinimization (RTCFR), and their variants in solving NFGs and EFGs more\neffectively. Our adaptive methods dynamically adjust parameters, balancing\nexploration and exploitation while improving regret accumulation, ultimately\nenhancing asymptotic last-iterate convergence and achieving linear convergence.\nExperimental results demonstrate that our methods significantly accelerate\nconvergence, outperforming state-of-the-art algorithms.", "published": "2025-09-17 02:58:20", "link": "http://arxiv.org/abs/2509.13653v1", "categories": ["cs.GT", "cs.LG"], "primary_category": "cs.GT"}
{"title": "Controllable Pareto Trade-off between Fairness and Accuracy", "abstract": "The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work\nfocuses on finding a single \"optimal\" solution to balance the two objectives,\nwhich is limited considering the diverse solutions on the Pareto front. This\nwork intends to provide controllable trade-offs according to the user's\npreference of the two objectives, which is defined as a reference vector. To\nachieve this goal, we apply multi-objective optimization (MOO), which can find\nsolutions from various regions of the Pareto front. However, it is challenging\nto precisely control the trade-off due to the stochasticity of the training\nprocess and the high dimentional gradient vectors. Thus, we propose\nControllable Pareto Trade-off (CPT) that can effectively train models to\nperform different trade-offs according to users' preferences. CPT 1) stabilizes\nthe fairness update with a moving average of stochastic gradients to determine\nthe update direction, and 2) prunes the gradients by only keeping the gradients\nof the critical parameters. We evaluate CPT on hate speech detection and\noccupation classification tasks. Experiments show that CPT can achieve a\nhigher-quality set of solutions on the Pareto front than the baseline methods.\nIt also exhibits better controllability and can precisely follow the\nhuman-defined reference vectors.", "published": "2025-09-17 02:56:49", "link": "http://arxiv.org/abs/2509.13651v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images", "abstract": "This study introduces a novel method that transforms multimodal physiological\nsignalsphotoplethysmography (PPG), galvanic skin response (GSR), and\nacceleration (ACC) into 2D image matrices to enhance stress detection using\nconvolutional neural networks (CNNs). Unlike traditional approaches that\nprocess these signals separately or rely on fixed encodings, our technique\nfuses them into structured image representations that enable CNNs to capture\ntemporal and cross signal dependencies more effectively. This image based\ntransformation not only improves interpretability but also serves as a robust\nform of data augmentation. To further enhance generalization and model\nrobustness, we systematically reorganize the fused signals into multiple\nformats, combining them in a multi stage training pipeline. This approach\nsignificantly boosts classification performance. While demonstrated here in the\ncontext of stress detection, the proposed method is broadly applicable to any\ndomain involving multimodal physiological signals, paving the way for more\naccurate, personalized, and real time health monitoring through wearable\ntechnologies.", "published": "2025-09-17 02:18:51", "link": "http://arxiv.org/abs/2509.13636v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs", "abstract": "Federated learning (FL) has gained popularity as a privacy-preserving method\nof training machine learning models on decentralized networks. However to\nensure reliable operation of UAV-assisted FL systems, issues like as excessive\nenergy consumption, communication inefficiencies, and security vulnerabilities\nmust be solved. This paper proposes an innovative framework that integrates\nDigital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to\ntackle these challenges. UAVs act as mobile base stations, allowing scattered\ndevices to train FL models locally and upload model updates for aggregation. By\nincorporating DT technology, our approach enables real-time system monitoring\nand predictive maintenance, improving UAV network efficiency. Additionally,\nZero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification\nwithout exposing sensitive data. To optimize energy efficiency and resource\nmanagement, we introduce a dynamic allocation strategy that adjusts UAV flight\npaths, transmission power, and processing rates based on network conditions.\nUsing block coordinate descent and convex optimization techniques, our method\nsignificantly reduces system energy consumption by up to 29.6% compared to\nconventional FL approaches. Simulation results demonstrate improved learning\nperformance, security, and scalability, positioning this framework as a\npromising solution for next-generation UAV-based intelligent networks.", "published": "2025-09-17 02:10:34", "link": "http://arxiv.org/abs/2509.13634v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds", "abstract": "We study trade-offs between convergence rate and robustness to gradient\nerrors in first-order methods. Our focus is on generalized momentum methods\n(GMMs), a class that includes Nesterov's accelerated gradient, heavy-ball, and\ngradient descent. We allow stochastic gradient errors that may be adversarial\nand biased, and quantify robustness via the risk-sensitive index (RSI) from\nrobust control theory. For quadratic objectives with i.i.d. Gaussian noise, we\ngive closed-form expressions for RSI using 2x2 Riccati equations, revealing a\nPareto frontier between RSI and convergence rate over stepsize and momentum\nchoices. We prove a large-deviation principle for time-averaged suboptimality\nand show that the rate function is, up to scaling, the convex conjugate of the\nRSI. We further connect RSI to the $H_{\\infty}$-norm, showing that stronger\nworst-case robustness (smaller $H_{\\infty}$ norm) yields sharper decay of tail\nprobabilities. Beyond quadratics, under biased sub-Gaussian gradient errors, we\nderive non-asymptotic bounds on a finite-time analogue of the RSI, giving\nfinite-time high-probability guarantees and large-deviation bounds. We also\nobserve an analogous trade-off between RSI and convergence-rate bounds for\nsmooth strongly convex functions. To our knowledge, these are the first\nnon-asymptotic guarantees and risk-sensitive analysis of GMMs with biased\ngradients. Numerical experiments on robust regression illustrate the results.", "published": "2025-09-17 01:56:31", "link": "http://arxiv.org/abs/2509.13628v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Unsupervised Anomaly Detection in ALS EPICS Event Logs", "abstract": "This paper introduces an automated fault analysis framework for the Advanced\nLight Source (ALS) that processes real-time event logs from its EPICS control\nsystem. By treating log entries as natural language, we transform them into\ncontextual vector representations using semantic embedding techniques. A\nsequence-aware neural network, trained on normal operational data, assigns a\nreal-time anomaly score to each event. This method flags deviations from\nbaseline behavior, enabling operators to rapidly identify the critical event\nsequences that precede complex system failures.", "published": "2025-09-17 01:36:24", "link": "http://arxiv.org/abs/2509.13621v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection", "abstract": "As Large Multimodal Models (LMMs) become integral to daily digital life,\nunderstanding their safety architectures is a critical problem for AI\nAlignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a\nglobally deployed model, on the difficult task of multimodal hate speech\ndetection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase\ninvestigation on 500 samples to probe the model's reasoning and failure modes.\nOur central finding is the experimental identification of a \"Unimodal\nBottleneck,\" an architectural flaw where the model's advanced multimodal\nreasoning is systematically preempted by context-blind safety filters. A\nquantitative validation of 144 content policy refusals reveals that these\noverrides are triggered in equal measure by unimodal visual 50% and textual 50%\ncontent. We further demonstrate that this safety system is brittle, blocking\nnot only high-risk imagery but also benign, common meme formats, leading to\npredictable false positives. These findings expose a fundamental tension\nbetween capability and safety in state-of-the-art LMMs, highlighting the need\nfor more integrated, context-aware alignment strategies to ensure AI systems\ncan be deployed both safely and effectively.", "published": "2025-09-17 00:46:42", "link": "http://arxiv.org/abs/2509.13608v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Energy Efficient Multi Robot Package Delivery under Capacity-Constraints via Voronoi-Constrained Networks", "abstract": "We consider the problem of delivering multiple packages from a single pickup\ndepot to distinct goal locations using a homogeneous fleet of robots with\nlimited carrying capacity. We propose VCST-RCP, a Voronoi-Constrained Steiner\nTree Relay Coordination Planning framework that constructs sparse relay trunks\nusing Steiner tree optimization and then synthesizes robot-level pickup, relay,\nand delivery schedules. This framework reframes relays from incidental\nbyproducts into central elements of coordination, offering a contrast with\ntraditional delivery methods that rely on direct source-to-destination\ntransport. Extensive experiments show consistent improvements of up to 34%\ncompared to conventional baselines, underscoring the benefits of incorporating\nrelays into the delivery process. These improvements translate directly to\nenhanced energy efficiency in multi-robot delivery under capacity constraints,\nproviding a scalable framework for real-world logistics.", "published": "2025-09-17 16:08:42", "link": "http://arxiv.org/abs/2509.14127v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative Aerial Transport of Cable-Suspended Payloads", "abstract": "Collaborative transportation of cable-suspended payloads by teams of Unmanned\nAerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to\ndifferent payload shapes, and provide built-in compliance, making it attractive\nfor applications ranging from disaster relief to precision logistics. However,\nmulti-UAV coordination under disturbances, nonlinear payload dynamics, and\nslack--taut cable modes remains a challenging control problem. To our\nknowledge, no prior work has addressed these cable mode transitions in the\nmulti-UAV context, instead relying on simplifying rigid-link assumptions. We\npropose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for\nmulti-UAV cable-suspended payload transport. Simulation results demonstrate\nthat the learned policies can outperform classical decentralized controllers in\nterms of disturbance rejection and tracking precision, achieving an 80%\nrecovery rate from harsh conditions compared to 44% for the baseline method. We\nalso achieve successful zero-shot sim-to-real transfer and demonstrate that our\npolicies are highly robust under harsh conditions, including wind, random\nexternal disturbances, and transitions between slack and taut cable dynamics.\nThis work paves the way for autonomous, resilient UAV teams capable of\nexecuting complex payload missions in unstructured environments.", "published": "2025-09-17 16:06:59", "link": "http://arxiv.org/abs/2509.14126v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Sound Value Iteration for Simple Stochastic Games", "abstract": "Algorithmic analysis of Markov decision processes (MDP) and stochastic games\n(SG) in practice relies on value-iteration (VI) algorithms. Since basic VI does\nnot provide guarantees on the precision of the result, variants of VI have been\nproposed that offer such guarantees. In particular, sound value iteration (SVI)\nnot only provides precise lower and upper bounds on the result, but also\nconverges faster in the presence of probabilistic cycles. Unfortunately, it is\nneither applicable to SG, nor to MDP with end components. In this paper, we\nextend SVI and cover both cases. The technical challenge consists mainly in\nproper treatment of end components, which require different handling than in\nthe literature. Moreover, we provide several optimizations of SVI. Finally, we\nevaluate our prototype implementation experimentally to demonstrate its\npotential on systems with probabilistic cycles.", "published": "2025-09-17 15:55:08", "link": "http://arxiv.org/abs/2509.14112v1", "categories": ["cs.GT", "cs.MA"], "primary_category": "cs.GT"}
{"title": "TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped Modular Aerial Robot Systems", "abstract": "Modular Aerial Robot Systems (MARS) consist of multiple drone modules that\nare physically bound together to form a single structure for flight. Exploiting\nstructural redundancy, MARS can be reconfigured into different formations to\nmitigate unit or rotor failures and maintain stable flight. Prior work on MARS\nself-reconfiguration has solely focused on maximizing controllability margins\nto tolerate a single rotor or unit fault for rectangular-shaped MARS. We\npropose TransforMARS, a general fault-tolerant reconfiguration framework that\ntransforms arbitrarily shaped MARS under multiple rotor and unit faults while\nensuring continuous in-air stability. Specifically, we develop algorithms to\nfirst identify and construct minimum controllable assemblies containing faulty\nunits. We then plan feasible disassembly-assembly sequences to transport MARS\nunits or subassemblies to form target configuration. Our approach enables more\nflexible and practical feasible reconfiguration. We validate TransforMARS in\nchallenging arbitrarily shaped MARS configurations, demonstrating substantial\nimprovements over prior works in both the capacity of handling diverse\nconfigurations and the number of faults tolerated. The videos and source code\nof this work are available at the anonymous repository:\nhttps://anonymous.4open.science/r/TransforMARS-1030/", "published": "2025-09-17 14:28:23", "link": "http://arxiv.org/abs/2509.14025v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Repulsive Trajectory Modification and Conflict Resolution for Efficient Multi-Manipulator Motion Planning", "abstract": "We propose an efficient motion planning method designed to efficiently find\ncollision-free trajectories for multiple manipulators. While multi-manipulator\nsystems offer significant advantages, coordinating their motions is\ncomputationally challenging owing to the high dimensionality of their composite\nconfiguration space. Conflict-Based Search (CBS) addresses this by decoupling\nmotion planning, but suffers from subsequent conflicts incurred by resolving\nexisting conflicts, leading to an exponentially growing constraint tree of CBS.\nOur proposed method is based on repulsive trajectory modification within the\ntwo-level structure of CBS. Unlike conventional CBS variants, the low-level\nplanner applies a gradient descent approach using an Artificial Potential\nField. This field generates repulsive forces that guide the trajectory of the\nconflicting manipulator away from those of other robots. As a result,\nsubsequent conflicts are less likely to occur. Additionally, we develop a\nstrategy that, under a specific condition, directly attempts to find a\nconflict-free solution in a single step without growing the constraint tree.\nThrough extensive tests including physical robot experiments, we demonstrate\nthat our method consistently reduces the number of expanded nodes in the\nconstraint tree, achieves a higher success rate, and finds a solution faster\ncompared to Enhanced CBS and other state-of-the-art algorithms.", "published": "2025-09-17 10:20:19", "link": "http://arxiv.org/abs/2509.13882v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Inject, Fork, Compare: Defining an Interaction Vocabulary for Multi-Agent Simulation Platforms", "abstract": "LLM-based multi-agent simulations are a rapidly growing field of research,\nbut current simulations often lack clear modes for interaction and analysis,\nlimiting the \"what if\" scenarios researchers are able to investigate. In this\ndemo, we define three core operations for interacting with multi-agent\nsimulations: inject, fork, and compare. Inject allows researchers to introduce\nexternal events at any point during simulation execution. Fork creates\nindependent timeline branches from any timestamp, preserving complete state\nwhile allowing divergent exploration. Compare facilitates parallel observation\nof multiple branches, revealing how different interventions lead to distinct\nemergent behaviors. Together, these operations establish a vocabulary that\ntransforms linear simulation workflows into interactive, explorable spaces. We\ndemonstrate this vocabulary through a commodity market simulation with fourteen\nAI agents, where researchers can inject contrasting events and observe\ndivergent outcomes across parallel timelines. By defining these fundamental\noperations, we provide a starting point for systematic causal investigation in\nLLM-based agent simulations, moving beyond passive observation toward active\nexperimentation.", "published": "2025-09-17 05:42:36", "link": "http://arxiv.org/abs/2509.13712v1", "categories": ["cs.MA", "cs.HC"], "primary_category": "cs.MA"}
{"title": "A numerical scheme for a fully nonlinear free boundary problem", "abstract": "We propose a numerical method to approximate viscosity solutions of fully\nnonlinear free transmission problems. The method discretises a two-layer\nregularisation of a PDE, involving a functional and a vanishing parameter. The\nformer is handled via a fixed-point argument. We then prove that the numerical\nmethod converges to a one-parameter regularisation of the free boundary\nproblem. Regularity estimates enable us to take the vanishing limit of such a\nparameter and recover a viscosity solution of the free transmission problem.\nOur main contribution is the design of a computational strategy, based on\nfixed-point arguments and approximated problems, to solve fully nonlinear free\nboundary models. We finish the paper with two numerical examples to validate\nour method.", "published": "2025-09-17 16:31:37", "link": "http://arxiv.org/abs/2509.14150v1", "categories": ["math.NA", "cs.NA", "math.AP", "65N06, 35D40, 35R35"], "primary_category": "math.NA"}
{"title": "HYCO: Hybrid-Cooperative Learning for Data-Driven PDE Modeling", "abstract": "We present Hybrid-Cooperative Learning (HYCO), a hybrid modeling framework\nthat iteratively integrates physics-based and data-driven models through a\nmutual regularization mechanism. Unlike traditional approaches that impose\nphysical constraints directly on synthetic models, HYCO treats the physical and\nsynthetic components as co-trained agents: the physical and synthetic models\nare nudged toward agreement, while the synthetic model is enhanced to better\nfit the available data. This cooperative learning scheme is naturally\nparallelizable and improves robustness to noise as well as to sparse or\nheterogeneous data. Extensive numerical experiments on both static and\ntime-dependent problems demonstrate that HYCO outperforms classical\nphysics-based and data-driven methods, recovering accurate solutions and model\nparameters even under ill-posed conditions. The method also admits a natural\ngame-theoretic interpretation, enabling alternating optimization and paving the\nway for future theoretical developments.", "published": "2025-09-17 16:02:24", "link": "http://arxiv.org/abs/2509.14123v1", "categories": ["math.OC", "cs.NA", "math.AP", "math.NA", "00A71, 35R30, 41A27, 68T07, 91A12"], "primary_category": "math.OC"}
{"title": "Mixed finite element projection methods for the unsteady Brinkman equations", "abstract": "We present $H(\\text{div})$-conforming mixed finite element methods for the\nunsteady Brinkman equations for incompressible single-phase flow with fixed in\nspace porous solid inclusions. We employ a projection scheme with incremental\npressure correction, which requires at each time step the solution of a\npredictor and a projection problem. The predictor problem, which uses a\nstress-velocity mixed formulation, accounts for the viscous effects, while the\nprojection problem, which is based on a velocity-pressure mixed formulation,\naccounts for the incompressibility. The spatial discretization is based on the\nRaviart-Thomas or Brezzi-Douglas-Marini mixed finite element spaces on\nsimplicial grids. The velocity computed at the end of each time step is\npointwise divergence-free. Unconditional stability of the fully-discrete scheme\nand first order in time accuracy are established. Due the $H$(div)-conformity\nof the formulation, the methods are robust in both the Stokes and the Darcy\nregimes. In the specific code implementation, we discretize the computational\ndomain using generally unstructured triangular (in 2D) and tetrahedral (in 3D)\ngrids, and we use the Raviart--Thomas space $RT_1$, applying a second order\nmultipoint flux mixed finite element scheme with a quadrature rule that samples\nthe flux degrees of freedom. In the predictor problem this allows for a local\nelimination of the viscous stress and results in element-based symmetric and\npositive definite systems for each velocity component with $\\left(d+1\\right)$\ndegrees of freedom per simplex (where $d$ is the dimension of the problem). In\na similar way, we locally eliminate the corrected velocity in the projection\nproblem, and solve an element-based system for the pressure. A series of\nchallenging numerical experiments is presented to verify the convergence and\nperformance of the proposed scheme", "published": "2025-09-17 15:04:42", "link": "http://arxiv.org/abs/2509.14059v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Low-rank approximation of analytic kernels", "abstract": "Many algorithms in scientific computing and data science take advantage of\nlow-rank approximation of matrices and kernels, and understanding why\nnearly-low-rank structure occurs is essential for their analysis and further\ndevelopment. This paper provides a framework for bounding the best low-rank\napproximation error of matrices arising from samples of a kernel that is\nanalytically continuable in one of its variables to an open region of the\ncomplex plane. Elegantly, the low-rank approximations used in the proof are\ncomputable by rational interpolation using the roots and poles of Zolotarev\nrational functions, leading to a fast algorithm for their construction.", "published": "2025-09-17 14:24:47", "link": "http://arxiv.org/abs/2509.14017v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Hierarchical Importance Sampling for Estimating Occupation Time for SDE Solutions", "abstract": "This study considers the estimation of the complementary cumulative\ndistribution function of the occupation time (i.e., the time spent below a\nthreshold) for a process governed by a stochastic differential equation. The\nfocus is on the right tail, where the underlying event becomes rare, and using\nvariance reduction techniques is essential to obtain computationally efficient\nestimates. Building on recent developments that relate importance sampling (IS)\nto stochastic optimal control, this work develops an optimal single level IS\n(SLIS) estimator based on the solution of an auxiliary Hamilton Jacobi Bellman\n(HJB) partial differential equation (PDE). The cost of solving the HJB-PDE is\nincorporated into the total computational work, and an optimized trade off\nbetween preprocessing and sampling is proposed to minimize the overall cost.\nThe SLIS approach is extended to the multilevel setting to enhance efficiency,\nyielding a multilevel IS (MLIS) estimator. A necessary and sufficient condition\nunder which the MLIS method outperforms the SLIS method is established, and a\ncommon likelihood MLIS formulation is introduced that satisfies this condition\nunder appropriate regularity assumptions. The classical multilevel Monte Carlo\ncomplexity theory can be extended to accommodate settings where the\nsingle-level variance varies with the discretization level. As a special case,\nthe variance-decay behavior observed in the IS framework stems from the zero\nvariance property of the optimal control. Notably, the total work complexity of\nMLIS can be better than an order of two. Numerical experiments in the context\nof fade duration estimation demonstrate the benefits of the proposed approach\nand validate these theoretical results.", "published": "2025-09-17 13:20:26", "link": "http://arxiv.org/abs/2509.13950v1", "categories": ["math.NA", "cs.NA", "stat.CO"], "primary_category": "math.NA"}
{"title": "Semi-Discrete in Time Method for Time-Dependent Equations by Random Neural Basis", "abstract": "Neural network-based solvers for partial differential equations (PDEs) have\nattracted considerable attention, yet they often face challenges in accuracy\nand computational efficiency. In this work, we focus on time-dependent PDEs and\nobserve that coupling space and time in a single network can increase the\ndifficulty of approximation. To address this, we propose a semi-discrete in\ntime method (SDTM) which leverages classical numerical time integrators and\nrandom neural basis (RNB). Additional adaptive operations are introduced to\nenhance the network's ability to capture features across scales to ensure\nuniform approximation accuracy for multi-scale PDEs. Numerical experiments\ndemonstrate the framework's effectiveness and confirm the convergence of the\ntemporal integrator as well as the network's approximation performance.", "published": "2025-09-17 07:08:53", "link": "http://arxiv.org/abs/2509.13751v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Rare Event Simulation of Quantum Error-Correcting Circuits", "abstract": "We describe a practical approach for accessing the logical failure rates of\nquantum error-correcting (QEC) circuits under low physical (component) failure\nrate regimes. Standard Monte Carlo is often the de facto approach for studying\nthe failure rates of quantum circuits. However, in the study of fault-tolerant\nerror-correcting circuits, the ability to extend this approach to low physical\nfailure rates is limited. In particular, the use of Monte Carlo to access\ncircuits that are relatively large or have high correcting power becomes more\ndifficult as we lower the input failure rates of the individual components\n(gates) in the circuit. For these reasons, many simulations studying the\ncircuit model go no lower than end-to-end logical failure rates in the 10^{-6}\nregime. In this report, we outline an approach that borrows from earlier work\nby Bravyi and Vargo to the more complex circuit noise model. Earlier works\nstudied both the capacity and phenomenological noise models, but the work is\ninsufficient for generating similar simulations in the circuit-noise model. To\nthe best of our knowledge, our team is the first to develop a full prescription\nof the rare event simulation by splitting technique for the circuit-based noise\nmodel. We have also generated promising results that are confirmed by standard\nMonte Carlo simulation under an accessible regime. This work shows that we can\naccess noise in the circuit-model prescription of quantum error-correcting code\nto failure rates below 10^{-20} regime.", "published": "2025-09-17 04:12:14", "link": "http://arxiv.org/abs/2509.13678v1", "categories": ["quant-ph", "cs.NA", "math.NA", "math.PR"], "primary_category": "quant-ph"}
{"title": "p-multigrid method for the discontinuous Galerkin discretization of elliptic problems", "abstract": "In this paper, we propose a $W$-cycle $p$-multigrid method for solving the\n$p$-version symmetric interior penalty discontinuous Galerkin (SIPDG)\ndiscretization of elliptic problems. This SIPDG discretization employs\nhierarchical Legendre polynomial basis functions. Inspired by the uniform\nconvergence theory of the $W$-cycle $hp$-multigrid method in [P. F. Antonietti,\net al., SIAM J. Numer. Anal., 53 (2015)], we provide a rigorous convergence\nanalysis for the proposed $p$-multigrid method, considering both inherited and\nnon-inherited bilinear forms of SIPDG discretization. Our theoretical results\nshow significant improvement over [P. F. Antonietti, et al., SIAM J. Numer.\nAnal., 53 (2015)], reducing the required number of smoothing steps from\n$O(p^2)$ to $O(p)$, where $p$ is the polynomial degree of the discrete broken\npolynomial space. Moreover, the convergence rate remains independent of the\nmesh size. Several numerical experiments are presented to verify our\ntheoretical findings. Finally, we numerically verify the effectiveness of the\n$p$-multigrid method for unfitted finite element discretization in solving\nelliptic interface problems on general $C^{2} $-smooth interfaces.", "published": "2025-09-17 03:43:37", "link": "http://arxiv.org/abs/2509.13669v1", "categories": ["math.NA", "cs.NA", "65M60, 65N30, 65F08"], "primary_category": "math.NA"}
{"title": "Dynamic Inverse Optimization under Drift and Shocks: Theory, Regret Bounds, and Applications", "abstract": "The growing prevalence of drift and shocks in modern decision environments\nexposes a gap between classical optimization theory and real-world practice.\nStandard models assume fixed objectives, yet organizations from hospitals to\npower grids routinely adapt to shifting priorities, noisy data, and abrupt\ndisruptions. To address this gap, this study develops a dynamic inverse\noptimization framework that recovers hidden, time-varying preferences from\nobserved allocation trajectories. The framework unifies identifiability\nanalysis with regret guarantees conditions are established for existence and\nuniqueness of recovered parameters, and sharp static and dynamic regret bounds\nare derived to characterize responsiveness to gradual drift and sudden shocks.\nMethodologically, a drift-aware estimator grounded in convex analysis and\nonline learning theory is introduced, with finite-sample guarantees on recovery\naccuracy. Computational experiments in healthcare, energy, logistics, and\nfinance reveal heterogeneous recovery patterns, ranging from rapid resilience\nto persistent vulnerability. Overall, dynamic inverse optimization emerges as\nboth a theoretical contribution and a broadly applicable diagnostic tool for\nbenchmarking resilience, uncovering hidden behavioral shifts, and guiding\npolicy interventions in complex stochastic systems.", "published": "2025-09-17 15:27:19", "link": "http://arxiv.org/abs/2509.14080v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Holdout cross-validation for large non-Gaussian covariance matrix estimation using Weingarten calculus", "abstract": "Cross-validation is one of the most widely used methods for model selection\nand evaluation; its efficiency for large covariance matrix estimation appears\nrobust in practice, but little is known about the theoretical behavior of its\nerror. In this paper, we derive the expected Frobenius error of the holdout\nmethod, a particular cross-validation procedure that involves a single train\nand test split, for a generic rotationally invariant multiplicative noise\nmodel, therefore extending previous results to non-Gaussian data distributions.\nOur approach involves using the Weingarten calculus and the Ledoit-P\\'ech\\'e\nformula to derive the oracle eigenvalues in the high-dimensional limit. When\nthe population covariance matrix follows an inverse Wishart distribution, we\napproximate the expected holdout error, first with a linear shrinkage, then\nwith a quadratic shrinkage to approximate the oracle eigenvalues. Under the\nlinear approximation, we find that the optimal train-test split ratio is\nproportional to the square root of the matrix dimension. Then we compute Monte\nCarlo simulations of the holdout error for different distributions of the norm\nof the noise, such as the Gaussian, Student, and Laplace distributions and\nobserve that the quadratic approximation yields a substantial improvement,\nespecially around the optimal train-test split ratio. We also observe that a\nhigher fourth-order moment of the Euclidean norm of the noise vector sharpens\nthe holdout error curve near the optimal split and lowers the ideal train-test\nratio, making the choice of the train-test ratio more important when performing\nthe holdout method.", "published": "2025-09-17 11:34:15", "link": "http://arxiv.org/abs/2509.13923v1", "categories": ["q-fin.ST", "math.ST", "q-fin.RM", "stat.ML", "stat.TH"], "primary_category": "q-fin.ST"}
{"title": "Adaptive Off-Policy Inference for M-Estimators Under Model Misspecification", "abstract": "When data are collected adaptively, such as in bandit algorithms, classical\nstatistical approaches such as ordinary least squares and $M$-estimation will\noften fail to achieve asymptotic normality. Although recent lines of work have\nmodified the classical approaches to ensure valid inference on adaptively\ncollected data, most of these works assume that the model is correctly\nspecified. We propose a method that provides valid inference for M-estimators\nthat use adaptively collected bandit data with a (possibly) misspecified\nworking model. A key ingredient in our approach is the use of flexible machine\nlearning approaches to stabilize the variance induced by adaptive data\ncollection. A major novelty is that our procedure enables the construction of\nvalid confidence sets even in settings where treatment policies are unstable\nand non-converging, such as when there is no unique optimal arm and standard\nbandit algorithms are used. Empirical results on semi-synthetic datasets\nconstructed from the Osteoarthritis Initiative demonstrate that the method\nmaintains type I error control, while existing methods for inference in\nadaptive settings do not cover in the misspecified case.", "published": "2025-09-17 17:51:40", "link": "http://arxiv.org/abs/2509.14218v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.OT", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Imputation-Powered Inference", "abstract": "Modern multi-modal and multi-site data frequently suffer from blockwise\nmissingness, where subsets of features are missing for groups of individuals,\ncreating complex patterns that challenge standard inference methods. Existing\napproaches have critical limitations: complete-case analysis discards\ninformative data and is potentially biased; doubly robust estimators for\nnon-monotone missingness-where the missingness patterns are not nested subsets\nof one another-can be theoretically efficient but lack closed-form solutions\nand often fail to scale; and blackbox imputation can leverage partially\nobserved data to improve efficiency but provides no inferential guarantees when\nmisspecified. To address the limitations of these existing methods, we propose\nimputation-powered inference (IPI), a model-lean framework that combines the\nflexibility of blackbox imputation with bias correction using fully observed\ndata, drawing on ideas from prediction-powered inference and semiparametric\ninference. IPI enables valid and efficient M-estimation under missing\ncompletely at random (MCAR) blockwise missingness and improves subpopulation\ninference under a weaker assumption we formalize as first-moment MCAR, for\nwhich we also provide practical diagnostics. Simulation studies and a clinical\napplication demonstrate that IPI may substantially improve subpopulation\nefficiency relative to complete-case analysis, while maintaining statistical\nvalidity in settings where both doubly robust estimators and naive imputation\nfail to achieve nominal coverage.", "published": "2025-09-17 07:48:54", "link": "http://arxiv.org/abs/2509.13778v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Read to Hear: A Zero-Shot Pronunciation Assessment Using Textual Descriptions and LLMs", "abstract": "Automatic pronunciation assessment is typically performed by acoustic models\ntrained on audio-score pairs. Although effective, these systems provide only\nnumerical scores, without the information needed to help learners understand\ntheir errors. Meanwhile, large language models (LLMs) have proven effective in\nsupporting language learning, but their potential for assessing pronunciation\nremains unexplored. In this work, we introduce TextPA, a zero-shot, Textual\ndescription-based Pronunciation Assessment approach. TextPA utilizes\nhuman-readable representations of speech signals, which are fed into an LLM to\nassess pronunciation accuracy and fluency, while also providing reasoning\nbehind the assigned scores. Finally, a phoneme sequence match scoring method is\nused to refine the accuracy scores. Our work highlights a previously overlooked\ndirection for pronunciation assessment. Instead of relying on supervised\ntraining with audio-score examples, we exploit the rich pronunciation knowledge\nembedded in written text. Experimental results show that our approach is both\ncost-efficient and competitive in performance. Furthermore, TextPA\nsignificantly improves the performance of conventional audio-score-trained\nmodels on out-of-domain data by offering a complementary perspective.", "published": "2025-09-17 17:26:29", "link": "http://arxiv.org/abs/2509.14187v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "SV-Mixer: Replacing the Transformer Encoder with Lightweight MLPs for Self-Supervised Model Compression in Speaker Verification", "abstract": "Self-supervised learning (SSL) has pushed speaker verification accuracy close\nto state-of-the-art levels, but the Transformer backbones used in most SSL\nencoders hinder on-device and real-time deployment. Prior compression work\ntrims layer depth or width yet still inherits the quadratic cost of\nself-attention. We propose SV-Mixer, the first fully MLP-based student encoder\nfor SSL distillation. SV-Mixer replaces Transformer with three lightweight\nmodules: Multi-Scale Mixing for multi-resolution temporal features,\nLocal-Global Mixing for frame-to-utterance context, and Group Channel Mixing\nfor spectral subspaces. Distilled from WavLM, SV-Mixer outperforms a\nTransformer student by 14.6% while cutting parameters and GMACs by over half,\nand at 75% compression, it closely matches the teacher's performance. Our\nresults show that attention-free SSL students can deliver teacher-level\naccuracy with hardware-friendly footprints, opening the door to robust\non-device speaker verification.", "published": "2025-09-17 16:16:30", "link": "http://arxiv.org/abs/2509.14136v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Lightweight Fourier-based Network for Binaural Speech Enhancement with Spatial Cue Preservation", "abstract": "Binaural speech enhancement faces a severe trade-off challenge, where\nstate-of-the-art performance is achieved by computationally intensive\narchitectures, while lightweight solutions often come at the cost of\nsignificant performance degradation. To bridge this gap, we propose the Global\nAdaptive Fourier Network (GAF-Net), a lightweight deep complex network that\naims to establish a balance between performance and computational efficiency.\nThe GAF-Net architecture consists of three components. First, a dual-feature\nencoder combining short-time Fourier transform and gammatone features enhances\nthe robustness of acoustic representation. Second, a channel-independent\nglobally adaptive Fourier modulator efficiently captures long-term temporal\ndependencies while preserving the spatial cues. Finally, a dynamic gating\nmechanism is implemented to reduce processing artifacts. Experimental results\nshow that GAF-Net achieves competitive performance, particularly in terms of\nbinaural cues (ILD and IPD error) and objective intelligibility (MBSTOI), with\nfewer parameters and computational cost. These results confirm that GAF-Net\nprovides a feasible way to achieve high-fidelity binaural processing on\nresource-constrained devices.", "published": "2025-09-17 15:21:13", "link": "http://arxiv.org/abs/2509.14076v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Lightweight Implicit Neural Network for Binaural Audio Synthesis", "abstract": "High-fidelity binaural audio synthesis is crucial for immersive listening,\nbut existing methods require extensive computational resources, limiting their\nedge-device application. To address this, we propose the Lightweight Implicit\nNeural Network (LINN), a novel two-stage framework. LINN first generates\ninitial estimates using a time-domain warping, which is then refined by an\nImplicit Binaural Corrector (IBC) module. IBC is an implicit neural network\nthat predicts amplitude and phase corrections directly, resulting in a highly\ncompact model architecture. Experimental results show that LINN achieves\nstatistically comparable perceptual quality to the best-performing baseline\nmodel while significantly improving computational efficiency. Compared to the\nmost efficient existing method, LINN achieves a 72.7% reduction in parameters\nand significantly fewer compute operations (MACs). This demonstrates that our\napproach effectively addresses the trade-off between synthesis quality and\ncomputational efficiency, providing a new solution for high-fidelity\nedge-device spatial audio applications.", "published": "2025-09-17 15:16:09", "link": "http://arxiv.org/abs/2509.14069v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems", "abstract": "Instruction-guided text-to-speech (ITTS) enables users to control speech\ngeneration through natural language prompts, offering a more intuitive\ninterface than traditional TTS. However, the alignment between user style\ninstructions and listener perception remains largely unexplored. This work\nfirst presents a perceptual analysis of ITTS controllability across two\nexpressive dimensions (adverbs of degree and graded emotion intensity) and\ncollects human ratings on speaker age and word-level emphasis attributes. To\ncomprehensively reveal the instruction-perception gap, we provide a data\ncollection with large-scale human evaluations, named Expressive VOice Control\n(E-VOC) corpus. Furthermore, we reveal that (1) gpt-4o-mini-tts is the most\nreliable ITTS model with great alignment between instruction and generated\nutterances across acoustic dimensions. (2) The 5 analyzed ITTS systems tend to\ngenerate Adult voices even when the instructions ask to use child or Elderly\nvoices. (3) Fine-grained control remains a major challenge, indicating that\nmost ITTS systems have substantial room for improvement in interpreting\nslightly different attribute instructions.", "published": "2025-09-17 14:00:45", "link": "http://arxiv.org/abs/2509.13989v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Summary on The Multilingual Conversational Speech Language Model Challenge: Datasets, Tasks, Baselines, and Methods", "abstract": "This paper summarizes the Interspeech2025 Multilingual Conversational Speech\nLanguage Model (MLC-SLM) challenge, which aims to advance the exploration of\nbuilding effective multilingual conversational speech LLMs (SLLMs). We provide\na detailed description of the task settings for the MLC-SLM challenge, the\nreleased real-world multilingual conversational speech dataset totaling\napproximately 1,604 hours, and the baseline systems for participants. The\nMLC-SLM challenge attracts 78 teams from 13 countries to participate, with 489\nvalid leaderboard results and 14 technical reports for the two tasks. We\ndistill valuable insights on building multilingual conversational SLLMs based\non submissions from participants, aiming to contribute to the advancement of\nthe community.", "published": "2025-09-17 07:55:39", "link": "http://arxiv.org/abs/2509.13785v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Self-Guided Target Sound Extraction and Classification Through Universal Sound Separation Model and Multiple Clues", "abstract": "This paper introduces a multi-stage self-directed framework designed to\naddress the spatial semantic segmentation of sound scene (S5) task in the DCASE\n2025 Task 4 challenge. This framework integrates models focused on three\ndistinct tasks: Universal Sound Separation (USS), Single-label Classification\n(SC), and Target Sound Extraction (TSE). Initially, USS breaks down a complex\naudio mixture into separate source waveforms. Each of these separated waveforms\nis then processed by a SC block, generating two critical pieces of information:\nthe waveform itself and its corresponding class label. These serve as inputs\nfor the TSE stage, which isolates the source that matches this information.\nSince these inputs are produced within the system, the extraction target is\nidentified autonomously, removing the necessity for external guidance. The\nextracted waveform can be looped back into the classification task, creating a\ncycle of iterative refinement that progressively enhances both separability and\nlabeling accuracy. We thus call our framework a multi-stage self-guided system\ndue to these self-contained characteristics. On the official evaluation\ndataset, the proposed system achieves an 11.00 dB increase in class-aware\nsignal-to-distortion ratio improvement (CA-SDRi) and a 55.8\\% accuracy in label\nprediction, outperforming the ResUNetK baseline by 4.4 dB and 4.3\\%,\nrespectively, and achieving first place among all submissions.", "published": "2025-09-17 06:49:55", "link": "http://arxiv.org/abs/2509.13741v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A High-Quality and Low-Complexity Streamable Neural Speech Codec with Knowledge Distillation", "abstract": "While many current neural speech codecs achieve impressive reconstructed\nspeech quality, they often neglect latency and complexity considerations,\nlimiting their practical deployment in downstream tasks such as real-time\nspeech communication and efficient speech compression. In our previous work, we\nproposed StreamCodec, which enables streamable speech coding by leveraging\nmodel causalization and a scalar-vector-combined quantization strategy, but its\nreconstructed quality and complexity still have room for improvement.\nTherefore, this paper proposes an improved iteration of StreamCodec, named\nStreamCodec2. The StreamCodec2 supports streamable and lightweight speech\ncoding by adopting a fully causal architecture and reducing the convolutional\nchannels. To compensate for the speech quality degradation caused by model\ncausalization and pruning, we introduce a non-causal, high-complexity teacher\ncodec to guide the training of StreamCodec2 through knowledge distillation.\nExperimental results demonstrate that our proposed StreamCodec2, trained with\nthe knowledge distillation strategy, can achieve high-quality speech\nreconstruction while maintaining low latency (only 20 ms), low computational\ncomplexity (only 910 MFLOPs), and low model complexity (only 5.4 M parameters).", "published": "2025-09-17 03:46:26", "link": "http://arxiv.org/abs/2509.13670v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Distilled Low-Latency Neural Vocoder with Explicit Amplitude and Phase Prediction", "abstract": "The majority of mainstream neural vocoders primarily focus on speech quality\nand generation speed, while overlooking latency, which is a critical factor in\nreal-time applications. Excessive latency leads to noticeable delays in user\ninteraction, severely degrading the user experience and rendering such systems\nimpractical for real-time use. Therefore, this paper proposes DLL-APNet, a\nDistilled Low-Latency neural vocoder which first predicts the Amplitude and\nPhase spectra explicitly from input mel spectrogram and then reconstructs the\nspeech waveform via inverse short-time Fourier transform (iSTFT). The DLL-APNet\nvocoder leverages causal convolutions to constrain the utilization of\ninformation to current and historical contexts, effectively minimizing latency.\nTo mitigate speech quality degradation caused by causal constraints, a\nknowledge distillation strategy is proposed, where a pre-trained non-causal\nteacher vocoder guides intermediate feature generation of the causal student\nDLL-APNet vocoder. Experimental results demonstrate that the proposed DLL-APNet\nvocoder produces higher-quality speech than other causal vocoders, while\nrequiring fewer computational resources. Furthermore, the proposed DLL-APNet\nvocoder achieves speech quality on par with mainstream non-causal neural\nvocoders, validating its ability to deliver both high perceptual quality and\nlow latency.", "published": "2025-09-17 03:39:36", "link": "http://arxiv.org/abs/2509.13667v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Assessing Data Replication in Symbolic Music via Adapted Structural Similarity Index Measure", "abstract": "AI-generated music may inadvertently replicate samples from the training\ndata, raising concerns of plagiarism. Similarity measures can quantify such\nreplication, thereby offering supervision and guidance for music generation\nmodels. Existing similarity measure methods for symbolic music mainly target\nmelody repetition, leaving a gap in assessing complex music with rich textures\nand expressive performance characteristics. To address this gap, we introduce\nSSIMuse, the first adaptation of the Structural Similarity Index Measure (SSIM)\nfrom images to symbolic music. Specifically, we represent symbolic music as\nimage-like piano rolls in binary and velocity-based forms. Build upon these\nrepresentations, we reinterprete and suitably modify the SSIM components in the\nmusical context to develop two variants, i.e., SSIMuse-B and SSIMuse-V, for\nevaluating data replication in composition and dynamic performance,\nrespectively. Controlled experiments on synthetic samples from multiple\ndatasets show that SSIMuse can reliably detect exact replication at a\ngranularity of at least one bar. SSIMuse enables open evaluation of replication\nin music generation and draws attention to its broader ethical, social, legal,\nand economic implications. The code is available at\nhttps://github.com/Tayjsl97/SSIMuse.", "published": "2025-09-17 03:14:39", "link": "http://arxiv.org/abs/2509.13658v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Goal-Oriented Joint Source-Channel Coding: Distortion-Classification-Power Trade-off", "abstract": "Joint source-channel coding is a compelling paradigm when low-latency and\nlow-complexity communication is required. This work proposes a theoretical\nframework that integrates classification and anomaly detection within the\nconventional signal reconstruction objective. Assuming a Gaussian scalar source\nand constraining the encoder to piecewise linear mappings, we derive tractable\ndesign rules and explicitly characterize the trade-offs between distortion,\nclassification error, and transmission power.", "published": "2025-09-17 17:51:00", "link": "http://arxiv.org/abs/2509.14217v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Active Inference Framework for Closed-Loop Sensing, Communication, and Control in UAV Systems", "abstract": "Integrated sensing and communication (ISAC) is a core technology for 6G, and\nits application to closed-loop sensing, communication, and control (SCC)\nenables various services. Existing SCC solutions often treat sensing and\ncontrol separately, leading to suboptimal performance and resource usage. In\nthis work, we introduce the active inference framework (AIF) into SCC-enabled\nunmanned aerial vehicle (UAV) systems for joint state estimation, control, and\nsensing resource allocation. By formulating a unified generative model, the\nproblem reduces to minimizing variational free energy for inference and\nexpected free energy for action planning. Simulation results show that both\ncontrol cost and sensing cost are reduced relative to baselines.", "published": "2025-09-17 17:35:07", "link": "http://arxiv.org/abs/2509.14201v1", "categories": ["eess.SP", "cs.NI", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Quickest Change Detection with Cost-Constrained Experiment Design", "abstract": "In the classical quickest change detection problem, an observer performs only\none experiment to monitor a stochastic process. This paper considers the case\nwhere, at each observation time, the decision-maker needs to choose between\nmultiple experiments with different information qualities and costs. The goal\nis to minimize the worst-case average detection delay subject to false alarm\nand cost constraints. An algorithm called the 2E-CUSUM Algorithm has been\ndeveloped to achieve this goal for the two-experiment case. Extensions to\nmultiple-experiment designs are also studied, and 2E-CUSUM is extended\naccordingly. Data efficiency, where the observer has the choice not to perform\nan experiment, is explored as well. The proposed algorithms are analyzed and\nshown to be asymptotically optimal.", "published": "2025-09-17 17:20:26", "link": "http://arxiv.org/abs/2509.14186v1", "categories": ["eess.SP", "cs.SY", "eess.SY", "math.ST", "stat.ME", "stat.TH"], "primary_category": "eess.SP"}
{"title": "Hardware-Efficient Cognitive Radar: Multi-Target Detection with RL-Driven Transmissive RIS", "abstract": "Cognitive radar has emerged as a key paradigm for next-generation sensing,\nenabling adaptive, intelligent operation in dynamic and complex environments.\nYet, conventional cognitive multiple-input multiple-output (MIMO) radars offer\nstrong detection performance but suffer from high hardware complexity and power\ndemands. To overcome these limitations, we develop a reinforcement learning\n(RL)-based framework that leverages a transmissive reconfigurable intelligent\nsurface (TRIS) for adaptive beamforming. A state-action-reward-state-action\n(SARSA) agent tunes TRIS phase shifts to improve multi-target detection in low\nsignal-to-noise ratio (SNR) conditions while operating with far fewer radio\nfrequency (RF) chains. Simulations confirm that the proposed TRIS-RL radar\nmatches or, for large number of elements, even surpasses MIMO performance with\nreduced cost and energy requirements.", "published": "2025-09-17 16:43:26", "link": "http://arxiv.org/abs/2509.14160v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Novel Phase-Noise-Tolerant Variational-Autoencoder-Based Equalization Suitable for Space-Division-Multiplexed Transmission", "abstract": "We demonstrate the effectiveness of a novel phase-noise-tolerant,\nvariational-autoencoder-based equalization scheme for\nspace-division-multiplexed (SDM) transmission in an experiment over 150km of\nrandomly-coupled multi-core fibers.", "published": "2025-09-17 15:16:52", "link": "http://arxiv.org/abs/2509.14072v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Distributed Deep Learning with RIS Grouping for Accurate Cascaded Channel Estimation", "abstract": "Reconfigurable Intelligent Surface (RIS) panels are envisioned as a key\ntechnology for sixth-generation (6G) wireless networks, providing a\ncost-effective means to enhance coverage and spectral efficiency. A critical\nchallenge is the estimation of the cascaded base station (BS)-RIS-user channel,\nsince the passive nature of RIS elements prevents direct channel acquisition,\nincurring prohibitive pilot overhead, computational complexity, and energy\nconsumption. To address this, we propose a deep learning (DL)-based channel\nestimation framework that reduces pilot overhead by grouping RIS elements and\nreconstructing the cascaded channel from partial pilot observations.\nFurthermore, conventional DL models trained under single-user settings suffer\nfrom poor generalization across new user locations and propagation scenarios.\nWe develop a distributed machine learning (DML) strategy in which the BS and\nusers collaboratively train a shared neural network using diverse channel\ndatasets collected across the network, thereby achieving robust generalization.\nBuilding on this foundation, we design a hierarchical DML neural architecture\nthat first classifies propagation conditions and then employs scenario-specific\nfeature extraction to further improve estimation accuracy. Simulation results\nconfirm that the proposed framework substantially reduces pilot overhead and\ncomplexity while outperforming conventional methods and single-user models in\nchannel estimation accuracy. These results demonstrate the practicality and\neffectiveness of the proposed approach for 6G RIS-assisted systems.", "published": "2025-09-17 15:05:32", "link": "http://arxiv.org/abs/2509.14062v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AnyAccomp: Generalizable Accompaniment Generation via Quantized Melodic Bottleneck", "abstract": "Singing Accompaniment Generation (SAG) is the process of generating\ninstrumental music for a given clean vocal input. However, existing SAG\ntechniques use source-separated vocals as input and overfit to separation\nartifacts. This creates a critical train-test mismatch, leading to failure on\nclean, real-world vocal inputs. We introduce AnyAccomp, a framework that\nresolves this by decoupling accompaniment generation from source-dependent\nartifacts. AnyAccomp first employs a quantized melodic bottleneck, using a\nchromagram and a VQ-VAE to extract a discrete and timbre-invariant\nrepresentation of the core melody. A subsequent flow-matching model then\ngenerates the accompaniment conditioned on these robust codes. Experiments show\nAnyAccomp achieves competitive performance on separated-vocal benchmarks while\nsignificantly outperforming baselines on generalization test sets of clean\nstudio vocals and, notably, solo instrumental tracks. This demonstrates a\nqualitative leap in generalization, enabling robust accompaniment for\ninstruments - a task where existing models completely fail - and paving the way\nfor more versatile music co-creation tools. Demo audio and code:\nhttps://anyaccomp.github.io", "published": "2025-09-17 14:55:21", "link": "http://arxiv.org/abs/2509.14052v1", "categories": ["cs.SD", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Distributed Coherent Beamforming at 60 GHz Enabled by Optically-Established Coherence", "abstract": "We implement and experimentally demonstrate a 60 GHz distributed system\nleveraging an optical time synchronization system that provides precise time\nand frequency alignment between independent elements of the distributed mesh.\nUtilizing such accurate coherence, we perform receive beamforming with\ninterference rejection and transmit nulling. In these configurations, the\nsystem achieves a coherent gain over an incoherent network of N nodes,\nsignificantly improving the relevant signal power ratios. Our system\ndemonstrates extended array phase coherence times, enabling advanced\ntechniques. Results from over-the-air experiments demonstrate a 14.3 dB\nsignal-to-interference-plus-noise improvement in interference-laden scenarios\nwith a contributing 13.5 dB null towards interference in receive beamforming.\nIn transmit nulling, a signal-to-noise ratio (SNR) gain of 7.9 dB is measured\ntowards an intended receiver while maintaining an SNR reduction of 8.9 dB at\nanother receiver. These findings represent the use of distributed coherence in\nthe V band without the use of GPS timing.", "published": "2025-09-17 13:54:24", "link": "http://arxiv.org/abs/2509.13984v1", "categories": ["eess.SP", "physics.optics"], "primary_category": "eess.SP"}
{"title": "Adaptive and robust smartphone-based step detection in multiple sclerosis", "abstract": "Background: Many attempts to validate gait pipelines that process sensor data\nto detect gait events have focused on the detection of initial contacts only in\nsupervised settings using a single sensor. Objective: To evaluate the\nperformance of a gait pipeline in detecting initial/final contacts using a step\ndetection algorithm adaptive to different test settings, smartphone wear\nlocations, and gait impairment levels. Methods: In GaitLab (ISRCTN15993728),\nhealthy controls (HC) and people with multiple sclerosis (PwMS; Expanded\nDisability Status Scale 0.0-6.5) performed supervised Two-Minute Walk Test\n[2MWT] (structured in-lab overground and treadmill 2MWT) during two on-site\nvisits carrying six smartphones and unsupervised walking activities (structured\nand unstructured real-world walking) daily for 10-14 days using a single\nsmartphone. Reference gait data were collected with a motion capture system or\nGait Up sensors. The pipeline's performance in detecting initial/final contacts\nwas evaluated through F1 scores and absolute temporal error with respect to\nreference measurement systems. Results: We studied 35 HC and 93 PwMS.\nInitial/final contacts were accurately detected across all smartphone wear\nlocations. Median F1 scores for initial/final contacts on in-lab 2MWT were\n>=98.2%/96.5% in HC and >=98.5%/97.7% in PwMS. F1 scores remained high on\nstructured (HC: 100% [0.3%]/100% [0.2%]; PwMS: 99.5% [1.9%]/99.4% [2.5%]) and\nunstructured real-world walking (HC: 97.8% [2.6%]/97.8% [2.8%]; PwMS: 94.4%\n[6.2%]/94.0% [6.5%]). Median temporal errors were <=0.08 s. Neither age, sex,\ndisease severity, walking aid use, nor setting (outdoor/indoor) impacted\npipeline performance (all p>0.05). Conclusion: This gait pipeline accurately\nand consistently detects initial and final contacts in PwMS across different\nsmartphone locations and environments, highlighting its potential for\nreal-world gait assessment.", "published": "2025-09-17 13:34:51", "link": "http://arxiv.org/abs/2509.13961v1", "categories": ["eess.SP", "92C55, 68T10, 93C85", "I.5.4; J.3; H.1.2"], "primary_category": "eess.SP"}
{"title": "FFT-Free PAPR Reduction Methods for OFDM Signals", "abstract": "In this paper, we propose two low-complexity peak to average power\nratio(PAPR) reduction algorithms for orthogonal frequency division\nmultiplexing(OFDM) signals. The main content is as follows: First, a non-convex\noptimization model is established by minimizing the signal distortion power.\nThen, a customized alternating direction method of multipliers(ADMM) algorithm\nis proposed to solve the problem, named time domain ADMM(T-ADMM) along with an\nimproved version called T-ADMM with constrain update(TCU-ADMM). In the\nalgorithms, all subproblems can be solved analytically, and each iteration has\nlinear computational complexity. These algorithms circumvents the challenges\nposed by repeated fast Fourier transform(FFT) and inverse FFT(IFFT) operations\nin traditional PAPR reduction algorithms. Additionally, we prove that the\nT-ADMM algorithm is theoretically guaranteed convergent if proper parameter is\nchosen. Finally, simulation results demonstrate the effectiveness of the\nproposed methods.", "published": "2025-09-17 09:37:04", "link": "http://arxiv.org/abs/2509.13851v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Flow Matching-Based Active Learning for Radio Map Construction with Low-Altitude UAVs", "abstract": "The employment of unmanned aerial vehicles (UAVs) in the lowaltitude economy\nnecessitates precise and real-time radio maps for reliable communication and\nsafe navigation. However, constructing such maps is hindered by the\ninfeasibility of exhaustive measurements due to UAVs' limited flight endurance.\nTo address this, we propose a novel active learning framework for low-altitude\nradio map construction based on limited measurements. First, a Plug-and-Play\n(PnP)-refined flow matching algorithm is introduced, which leverages flow\nmatching as a powerful generative prior within a PnP scheme to reconstruct\nhigh-fidelity radio maps. Second, the generative nature of flow matching is\nexploited to quantify uncertainty by generating an ensemble of radio maps and\ncomputing the location-wise variance. The resulting uncertainty map guides a\nmulti-objective candidate selection and then a trajectory is planned via\nutility-aware path search (UAPS), directing the UAV to the most informative\nlocations while taking travel costs into account. Simulation results\ndemonstrate that our method significantly outperforms the baselines, achieving\nmore than a 70% reduction in normalized mean squared error (NMSE).", "published": "2025-09-17 08:44:03", "link": "http://arxiv.org/abs/2509.13822v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Domino: Dominant Path-based Compensation for Hardware Impairments in Modern WiFi Sensing", "abstract": "WiFi sensing faces a critical reliability challenge due to hardware-induced\nRF distortions, especially with modern, market-dominant WiFi cards supporting\n802.11ac/ax protocols. These cards employ sensitive automatic gain control and\nseparate RF chains, introducing complex and dynamic distortions that render\nexisting compensation methods ineffective. In this paper, we introduce Domino,\na new framework that transforms channel state information (CSI) into channel\nimpulse response (CIR) and leverages it for precise distortion compensation.\nDomino is built on the key insight that hardware-induced distortions impact all\nsignal paths uniformly, allowing the dominant static path to serve as a\nreliable reference for effective compensation through delay-domain processing.\nReal-world respiration monitoring experiments show that Domino achieves at\nleast 2x higher mean accuracy over existing methods, maintaining robust\nperformance with a median error below 0.24 bpm, even using a single antenna in\nboth direct line-of-sight and obstructed scenarios.", "published": "2025-09-17 08:22:03", "link": "http://arxiv.org/abs/2509.13807v1", "categories": ["eess.SP", "cs.NI"], "primary_category": "eess.SP"}
{"title": "Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization", "abstract": "As wireless communication systems advance toward Sixth Generation (6G) Radio\nAccess Networks (RAN), Deep Learning (DL)-based neural receivers are emerging\nas transformative solutions for Physical Layer (PHY) processing, delivering\nsuperior Block Error Rate (BLER) performance compared to traditional\nmodel-based approaches. Practical deployment on resource-constrained hardware,\nhowever, requires efficient quantization to reduce latency, energy, and memory\nwithout sacrificing reliability. We extend Post-Training Quantization (PTQ)\nbaselines with Quantization-Aware Training (QAT), which incorporates\nlow-precision simulation during training for robustness at ultra-low bitwidths.\nOur study applies QAT/PTQ to a neural receiver architecture and evaluates\nacross 3GPP Clustered Delay Line (CDL)-B/D channels in LoS and NLoS\nenvironments at user velocities up to 40 m/s. Results show that 4-bit and 8-bit\nQAT models achieve BLERs similar to that of FP32 models at 10% target BLER. QAT\nmodels are also shown to outperform PTQ models by up to 3 dB, and yield 8x\ncompression. These results demonstrate that QAT is a key enabler of\nlow-complexity and latency-constrained inference at the PHY layer, facilitating\nreal-time processing in 6G edge devices", "published": "2025-09-17 07:55:58", "link": "http://arxiv.org/abs/2509.13786v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Theoretical Validation of the Latent Optimally Partitioned-$\\ell_2/\\ell_1$ Penalty with Application to Angular Power Spectrum Estimation", "abstract": "This paper demonstrates that, in both theory and practice, the latent\noptimally partitioned (LOP)-$\\ell_2/\\ell_1$ penalty is effective for exploiting\nblock-sparsity without the knowledge of the concrete block structure. More\nprecisely, we first present a novel theoretical result showing that the\noptimized block partition in the LOP-$\\ell_2/\\ell_1$ penalty satisfy a\ncondition required for accurate recovery of block-sparse signals. Motivated by\nthis result, we present a new application of the LOP-$\\ell_2/\\ell_1$ penalty to\nestimation of angular power spectrum, which is block-sparse with unknown block\npartition, in MIMO communication systems. Numerical simulations show that the\nproposed use of block-sparsity with the LOP-$\\ell_2/\\ell_1$ penalty\nsignificantly improves the estimation accuracy of the angular power spectrum.", "published": "2025-09-17 07:00:08", "link": "http://arxiv.org/abs/2509.13745v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "GNSS Jamming and Spoofing Monitoring Using Low-Cost COTS Receivers", "abstract": "The Global Navigation Satellite System (GNSS) is increasingly vulnerable to\nradio frequency interference (RFI), including jamming and spoofing, which\nthreaten the integrity of navigation and timing services. This paper presents a\nmethodology for detecting and classifying RFI events using low-cost commercial\noff-the-shelf (COTS) GNSS receivers. By combining carrier-to-noise ratio (C/N0)\nmeasurements with a calibrated received power metric, a two-dimensional\ndetection space is constructed to identify and distinguish nominal, jammed,\nspoofed, and blocked signal conditions. The method is validated through both\ncontrolled jamming tests in Norway and real-world deployments in Poland, and\nthe Southeast Mediterranean which have experienced such conditions. Results\ndemonstrate that COTS-based detection, when properly calibrated, offers a\nviable and effective approach for GNSS RFI monitoring.", "published": "2025-09-17 00:01:28", "link": "http://arxiv.org/abs/2509.13600v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Dense Video Understanding with Gated Residual Tokenization", "abstract": "High temporal resolution is essential for capturing fine-grained details in\nvideo understanding. However, current video large language models (VLLMs) and\nbenchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or\nkeyframe selection, discarding dense temporal information. This compromise\navoids the high cost of tokenizing every frame, which otherwise leads to\nredundant computation and linear token growth as video length increases. While\nthis trade-off works for slowly changing content, it fails for tasks like\nlecture comprehension, where information appears in nearly every frame and\nrequires precise temporal alignment. To address this gap, we introduce Dense\nVideo Understanding (DVU), which enables high-FPS video comprehension by\nreducing both tokenization time and token overhead. Existing benchmarks are\nalso limited, as their QA pairs focus on coarse content changes. We therefore\npropose DIVE (Dense Information Video Evaluation), the first benchmark designed\nfor dense temporal reasoning. To make DVU practical, we present Gated Residual\nTokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated\nTokenization uses pixel-level motion estimation to skip static regions during\ntokenization, achieving sub-linear growth in token count and compute. (2)\nSemantic-Scene Intra-Tokenization Merging fuses tokens across static regions\nwithin a scene, further reducing redundancy while preserving dynamic semantics.\nExperiments on DIVE show that GRT outperforms larger VLLM baselines and scales\npositively with FPS. These results highlight the importance of dense temporal\ninformation and demonstrate that GRT enables efficient, scalable high-FPS video\nunderstanding.", "published": "2025-09-17 17:34:40", "link": "http://arxiv.org/abs/2509.14199v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "68T45, 68T07, 68T05, 68T10, 68T50, 68T09, 68U10, 68P20, 94A08,\n  94A34, 62H30, 62H35", "I.2.10; I.2.6; I.2.7; I.5.1; I.5.2; I.5.3; I.5.4; I.4.8; I.4.9;\n  I.4.2; H.3.1; H.3.3; H.3.4; H.5.1; H.5.2; H.2.8"], "primary_category": "cs.CV"}
{"title": "AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity", "abstract": "Recent advancements in multimodal large language models (MLLMs) have garnered\nsignificant attention, offering a promising pathway toward artificial general\nintelligence (AGI). Among the essential capabilities required for AGI,\ncreativity has emerged as a critical trait for MLLMs, with association serving\nas its foundation. Association reflects a model' s ability to think creatively,\nmaking it vital to evaluate and understand. While several frameworks have been\nproposed to assess associative ability, they often overlook the inherent\nambiguity in association tasks, which arises from the divergent nature of\nassociations and undermines the reliability of evaluations. To address this\nissue, we decompose ambiguity into two types-internal ambiguity and external\nambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative\nability while circumventing the ambiguity through a hybrid computational\nmethod. We then conduct extensive experiments on MLLMs, revealing a strong\npositive correlation between cognition and association. Additionally, we\nobserve that the presence of ambiguity in the evaluation process causes MLLMs'\nbehavior to become more random-like. Finally, we validate the effectiveness of\nour method in ensuring more accurate and reliable evaluations. See Project Page\nfor the data and codes.", "published": "2025-09-17 16:56:27", "link": "http://arxiv.org/abs/2509.14171v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection", "abstract": "Unsupervised anomalous sound detection aims to detect unknown anomalous\nsounds by training a model using only normal audio data. Despite advancements\nin self-supervised methods, the issue of frequent false alarms when handling\nsamples of the same type from different machines remains unresolved. This paper\nintroduces a novel training technique called one-stage supervised contrastive\nlearning (OS-SCL), which significantly addresses this problem by perturbing\nfeatures in the embedding space and employing a one-stage noisy supervised\ncontrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved\n94.64\\% AUC, 88.42\\% pAUC, and 89.24\\% mAUC using only Log-Mel features.\nAdditionally, a time-frequency feature named TFgram is proposed, which is\nextracted from raw audio. This feature effectively captures critical\ninformation for anomalous sound detection, ultimately achieving 95.71\\% AUC,\n90.23\\% pAUC, and 91.23\\% mAUC. The source code is available at:\n\\underline{www.github.com/huangswt/OS-SCL}.", "published": "2025-09-17 09:38:47", "link": "http://arxiv.org/abs/2509.13853v2", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications", "abstract": "This paper discusses our exploration of different data-efficient and\nparameter-efficient approaches to Arabic Dialect Identification (ADI). In\nparticular, we investigate various soft-prompting strategies, including\nprefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA\nreparameterizations. For the data-efficient strategy, we analyze hard prompting\nwith zero-shot and few-shot inferences to analyze the dialect identification\ncapabilities of Large Language Models (LLMs). For the parameter-efficient PEFT\napproaches, we conducted our experiments using Arabic-specific encoder models\non several major datasets. We also analyzed the n-shot inferences on\nopen-source decoder-only models, a general multilingual model (Phi-3.5), and an\nArabic-specific one(SILMA). We observed that the LLMs generally struggle to\ndifferentiate the dialectal nuances in the few-shot or zero-shot setups. The\nsoft-prompted encoder variants perform better, while the LoRA-based fine-tuned\nmodels perform best, even surpassing full fine-tuning.", "published": "2025-09-17 07:45:09", "link": "http://arxiv.org/abs/2509.13775v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning", "abstract": "Large language models (LLMs) have achieved remarkable success in many natural\nlanguage processing (NLP) tasks. To achieve more accurate output, the prompts\nused to drive LLMs have become increasingly longer, which incurs higher\ncomputational costs. To address this prompt inflation problem, prompt\ncompression has been proposed. However, most existing methods require training\na small auxiliary model for compression, incurring a significant amount of\nadditional computation. To avoid this, we propose a two-stage, training-free\napproach, called Dual-Stage Progressive Compression (DSPC). In the\ncoarse-grained stage, semantic-related sentence filtering removes sentences\nwith low semantic value based on TF-IDF. In the fine-grained stage, token\nimportance is assessed using attention contribution, cross-model loss\ndifference, and positional importance, enabling the pruning of low-utility\ntokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct\nand GPT-3.5-Turbo under a constrained token budget and observe consistent\nimprovements. For instance, in the FewShot task of the Longbench dataset, DSPC\nachieves a performance of 49.17 by using only 3x fewer tokens, outperforming\nthe best state-of-the-art baseline LongLLMLingua by 7.76.", "published": "2025-09-17 06:18:46", "link": "http://arxiv.org/abs/2509.13723v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machines are more productive than humans until they aren't, and vice versa", "abstract": "With the growth of artificial skills, organizations may increasingly confront\nwith the problem of optimizing skill policy decisions guided by economic\nprinciples. This paper addresses the underlying complexity of this challenge by\ndeveloping an in-silico framework based on Monte Carlo simulations grounded in\nempirical realism to analyze the economic impact of human and machine skills,\nindividually or jointly deployed, in the execution of tasks presenting varying\nlevels of complexity. Our results provide quantitative support for the\nestablished notions that automation tends to be the most economically-effective\nstrategy for tasks characterized by low-to-medium generalization difficulty,\nwhile automation may struggle to match the economic utility of human skills in\nmore complex scenarios. Critically, our simulations highlight that combining\nhuman and machine skills can be the most effective strategy when a high level\nof generalization is required, but only if genuine augmentation is achieved. In\ncontrast, when failing to realize this synergy, the human-machine policy is\nseverely penalized by the inherent costs of its dual skill structure, causing\nit to destroy value and becoming the worst choice from an economic perspective.\nThe takeaway for decision-makers is unambiguous: in contexts requiring high\ngeneralization capabilities, simply allocating human and machine skills to a\ntask is insufficient, and a human-machine skill policy is neither a\nsilver-bullet solution nor a low-risk compromise. Rather, it is a critical\nopportunity to boost competitiveness that demands a strong organizational\ncommitment to enabling augmentation. Also, our findings show that improving the\ncost-effectiveness of machine skills over time, while useful, does not replace\nthe fundamental need to focus on achieving augmentation.", "published": "2025-09-17 15:03:39", "link": "http://arxiv.org/abs/2509.14057v2", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching", "abstract": "Recent advancements in Diffusion Transformers (DiTs) have established them as\nthe state-of-the-art method for video generation. However, their inherently\nsequential denoising process results in inevitable latency, limiting real-world\napplicability. Existing acceleration methods either compromise visual quality\ndue to architectural modifications or fail to reuse intermediate features at\nproper granularity. Our analysis reveals that DiT blocks are the primary\ncontributors to inference latency. Across diffusion timesteps, the feature\nvariations of DiT blocks exhibit a U-shaped pattern with high similarity during\nintermediate timesteps, which suggests substantial computational redundancy. In\nthis paper, we propose Block-Wise Caching (BWCache), a training-free method to\naccelerate DiT-based video generation. BWCache dynamically caches and reuses\nfeatures from DiT blocks across diffusion timesteps. Furthermore, we introduce\na similarity indicator that triggers feature reuse only when the differences\nbetween block features at adjacent timesteps fall below a threshold, thereby\nminimizing redundant computations while maintaining visual fidelity. Extensive\nexperiments on several video diffusion models demonstrate that BWCache achieves\nup to 2.24$\\times$ speedup with comparable visual quality.", "published": "2025-09-17 07:58:36", "link": "http://arxiv.org/abs/2509.13789v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration", "abstract": "Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary\nnovel categories, offering a scalable and annotation-efficient solution.\nTraditionally, most ZSAD works have been based on the CLIP model, which\nperforms anomaly detection by calculating the similarity between visual and\ntext embeddings. Recently, vision foundation models such as DINOv3 have\ndemonstrated strong transferable representation capabilities. In this work, we\nare the first to adapt DINOv3 for ZSAD. However, this adaptation presents two\nkey challenges: (i) the domain bias between large-scale pretraining data and\nanomaly detection tasks leads to feature misalignment; and (ii) the inherent\nbias toward global semantics in pretrained representations often leads to\nsubtle anomalies being misinterpreted as part of the normal foreground objects,\nrather than being distinguished as abnormal regions. To overcome these\nchallenges, we introduce AD-DINOv3, a novel vision-language multimodal\nframework designed for ZSAD. Specifically, we formulate anomaly detection as a\nmultimodal contrastive learning problem, where DINOv3 is employed as the visual\nbackbone to extract patch tokens and a CLS token, and the CLIP text encoder\nprovides embeddings for both normal and abnormal prompts. To bridge the domain\ngap, lightweight adapters are introduced in both modalities, enabling their\nrepresentations to be recalibrated for the anomaly detection task. Beyond this\nbaseline alignment, we further design an Anomaly-Aware Calibration Module\n(AACM), which explicitly guides the CLS token to attend to anomalous regions\nrather than generic foreground semantics, thereby enhancing discriminability.\nExtensive experiments on eight industrial and medical benchmarks demonstrate\nthat AD-DINOv3 consistently matches or surpasses state-of-the-art methods.The\ncode will be available at https://github.com/Kaisor-Yuan/AD-DINOv3.", "published": "2025-09-17 15:29:25", "link": "http://arxiv.org/abs/2509.14084v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "4-uniform Maker-Breaker and Maker-Maker games are PSPACE-complete", "abstract": "We study two positional games where two players take turns picking a\npreviously unpicked vertex of a hypergraph $H$. We say a player fills an edge\nof $H$ if that player has picked all the vertices of that edge. In the\nMaker-Maker game, whoever first fills an edge wins, or we get a draw if no edge\nis filled. In the Maker-Breaker game, the first player aims at filling an edge\nwhile the second player aims at preventing the first player from filling an\nedge. We show that, for both games, deciding whether the first player has a\nwinning strategy is a PSPACE-complete problem even when restricted to 4-uniform\nhypergraphs. For the Maker-Maker game, this improves on a previous result for\nhypergraphs of rank 4. For the Maker-Breaker game, this improves on a previous\nresult for 5-uniform hypergraphs, and closes the complexity gap as the problem\nfor hypergraphs of rank 3 is known to be solvable in polynomial time.", "published": "2025-09-17 08:36:11", "link": "http://arxiv.org/abs/2509.13819v2", "categories": ["cs.DM", "cs.CC", "math.CO"], "primary_category": "cs.DM"}
{"title": "Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems", "abstract": "Instruction-guided text-to-speech (ITTS) enables users to control speech\ngeneration through natural language prompts, offering a more intuitive\ninterface than traditional TTS. However, the alignment between user style\ninstructions and listener perception remains largely unexplored. This work\nfirst presents a perceptual analysis of ITTS controllability across two\nexpressive dimensions (adverbs of degree and graded emotion intensity) and\ncollects human ratings on speaker age and word-level emphasis attributes. To\ncomprehensively reveal the instruction-perception gap, we provide a data\ncollection with large-scale human evaluations, named Expressive VOice Control\n(E-VOC) corpus. Furthermore, we reveal that (1) gpt-4o-mini-tts is the most\nreliable ITTS model with great alignment between instruction and generated\nutterances across acoustic dimensions. (2) The 5 analyzed ITTS systems tend to\ngenerate Adult voices even when the instructions ask to use child or Elderly\nvoices. (3) Fine-grained control remains a major challenge, indicating that\nmost ITTS systems have substantial room for improvement in interpreting\nslightly different attribute instructions.", "published": "2025-09-17 14:00:45", "link": "http://arxiv.org/abs/2509.13989v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Translate, then Detect: Leveraging Machine Translation for Cross-Lingual Toxicity Classification", "abstract": "Multilingual toxicity detection remains a significant challenge due to the\nscarcity of training data and resources for many languages. While prior work\nhas leveraged the translate-test paradigm to support cross-lingual transfer\nacross a range of classification tasks, the utility of translation in\nsupporting toxicity detection at scale remains unclear. In this work, we\nconduct a comprehensive comparison of translation-based and\nlanguage-specific/multilingual classification pipelines. We find that\ntranslation-based pipelines consistently outperform out-of-distribution\nclassifiers in 81.3% of cases (13 of 16 languages), with translation benefits\nstrongly correlated with both the resource level of the target language and the\nquality of the machine translation (MT) system. Our analysis reveals that\ntraditional classifiers outperform large language model (LLM) judges, with this\nadvantage being particularly pronounced for low-resource languages, where\ntranslate-classify methods dominate translate-judge approaches in 6 out of 7\ncases. We additionally show that MT-specific fine-tuning on LLMs yields lower\nrefusal rates compared to standard instruction-tuned models, but it can\nnegatively impact toxicity detection accuracy for low-resource languages. These\nfindings offer actionable guidance for practitioners developing scalable\nmultilingual content moderation systems.", "published": "2025-09-17 23:58:07", "link": "http://arxiv.org/abs/2509.14493v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "abstract": "Effective interactive tool use requires agents to master Tool Integrated\nReasoning (TIR): a complex process involving multi-turn planning and\nlong-context dialogue management. To train agents for this dynamic process,\nparticularly in multi-modal contexts, we introduce a sandbox environment for\nreinforcement learning (RL) that supports interleaved speech-text rollouts. Our\ncore strategy, Turn-level Adjudicated Reinforcement Learning (TARL), addresses\nthe challenge of credit assignment in long-horizon tasks by employing a Large\nLanguage Model (LLM) as a judge to provide turn-level evaluation. To enhance\nexploration, we integrate a mixed-task training curriculum with mathematical\nreasoning problems. This unified approach boosts the task pass rate on the\ntext-based $\\tau$-bench by over 6% compared to strong RL baselines. Crucially,\nwe demonstrate our framework's suitability for fine-tuning a multi-modal\nfoundation model for agentic tasks. By training a base multi-modal LLM on\ninterleaved speech-text rollouts, we equip it with tool-use abilities, paving\nthe way for more natural, voice-driven interactive agents.", "published": "2025-09-17 23:25:00", "link": "http://arxiv.org/abs/2509.14480v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Estimating Semantic Alphabet Size for LLM Uncertainty Quantification", "abstract": "Many black-box techniques for quantifying the uncertainty of large language\nmodels (LLMs) rely on repeated LLM sampling, which can be computationally\nexpensive. Therefore, practical applicability demands reliable estimation from\nfew samples. Semantic entropy (SE) is a popular sample-based uncertainty\nestimator with a discrete formulation attractive for the black-box setting.\nRecent extensions of semantic entropy exhibit improved LLM hallucination\ndetection, but do so with less interpretable methods that admit additional\nhyperparameters. For this reason, we revisit the canonical discrete semantic\nentropy estimator, finding that it underestimates the \"true\" semantic entropy,\nas expected from theory. We propose a modified semantic alphabet size\nestimator, and illustrate that using it to adjust discrete semantic entropy for\nsample coverage results in more accurate semantic entropy estimation in our\nsetting of interest. Furthermore, our proposed alphabet size estimator flags\nincorrect LLM responses as well or better than recent top-performing\napproaches, with the added benefit of remaining highly interpretable.", "published": "2025-09-17 23:16:39", "link": "http://arxiv.org/abs/2509.14478v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "abstract": "Large language models (LLMs) are increasingly deployed as task-oriented\nagents, where success depends on their ability to generate accurate function\ncalls under realistic, multilingual conditions. However, existing agent\nevaluations largely overlook cultural and linguistic diversity, often relying\non monolingual or naively translated benchmarks. We introduce Ticket-Bench, a\nbenchmark for multilingual agent evaluation in task-oriented scenarios.\nTicket-Bench simulates the domain of soccer ticket purchases across six major\nlanguages: Portuguese, English, Spanish, German, Italian, and French. Using\nlocalized teams, cities, and user profiles to provide a higher level of\nrealism. We evaluate a wide range of commercial and open-source LLMs, measuring\nfunction-calling accuracy and consistency across languages. Results show that\nreasoning-oriented models (e.g., GPT-5, Qwen3-235B) dominate performance but\nstill exhibit notable cross-lingual disparities. These findings underscore the\nneed for culturally aware, multilingual benchmarks to guide the development of\nrobust LLM agents.", "published": "2025-09-17 23:13:47", "link": "http://arxiv.org/abs/2509.14477v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not What the Doctor Ordered: Surveying LLM-based De-identification and Quantifying Clinical Information Loss", "abstract": "De-identification in the healthcare setting is an application of NLP where\nautomated algorithms are used to remove personally identifying information of\npatients (and, sometimes, providers). With the recent rise of generative large\nlanguage models (LLMs), there has been a corresponding rise in the number of\npapers that apply LLMs to de-identification. Although these approaches often\nreport near-perfect results, significant challenges concerning reproducibility\nand utility of the research papers persist. This paper identifies three key\nlimitations in the current literature: inconsistent reporting metrics hindering\ndirect comparisons, the inadequacy of traditional classification metrics in\ncapturing errors which LLMs may be more prone to (i.e., altering clinically\nrelevant information), and lack of manual validation of automated metrics which\naim to quantify these errors. To address these issues, we first present a\nsurvey of LLM-based de-identification research, highlighting the heterogeneity\nin reporting standards. Second, we evaluated a diverse set of models to\nquantify the extent of inappropriate removal of clinical information. Next, we\nconduct a manual validation of an existing evaluation metric to measure the\nremoval of clinical information, employing clinical experts to assess their\nefficacy. We highlight poor performance and describe the inherent limitations\nof such metrics in identifying clinically significant changes. Lastly, we\npropose a novel methodology for the detection of clinically relevant\ninformation removal.", "published": "2025-09-17 22:37:15", "link": "http://arxiv.org/abs/2509.14464v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Correct-Detect: Balancing Performance and Ambiguity Through the Lens of Coreference Resolution in LLMs", "abstract": "Large Language Models (LLMs) are intended to reflect human linguistic\ncompetencies. But humans have access to a broad and embodied context, which is\nkey in detecting and resolving linguistic ambiguities, even in isolated text\nspans. A foundational case of semantic ambiguity is found in the task of\ncoreference resolution: how is a pronoun related to an earlier person mention?\nThis capability is implicit in nearly every downstream task, and the presence\nof ambiguity at this level can alter performance significantly. We show that\nLLMs can achieve good performance with minimal prompting in both coreference\ndisambiguation and the detection of ambiguity in coreference, however, they\ncannot do both at the same time. We present the CORRECT-DETECT trade-off:\nthough models have both capabilities and deploy them implicitly, successful\nperformance balancing these two abilities remains elusive.", "published": "2025-09-17 22:12:30", "link": "http://arxiv.org/abs/2509.14456v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Simulating a Bias Mitigation Scenario in Large Language Models", "abstract": "Large Language Models (LLMs) have fundamentally transformed the field of\nnatural language processing; however, their vulnerability to biases presents a\nnotable obstacle that threatens both fairness and trust. This review offers an\nextensive analysis of the bias landscape in LLMs, tracing its roots and\nexpressions across various NLP tasks. Biases are classified into implicit and\nexplicit types, with particular attention given to their emergence from data\nsources, architectural designs, and contextual deployments. This study advances\nbeyond theoretical analysis by implementing a simulation framework designed to\nevaluate bias mitigation strategies in practice. The framework integrates\nmultiple approaches including data curation, debiasing during model training,\nand post-hoc output calibration and assesses their impact in controlled\nexperimental settings. In summary, this work not only synthesizes existing\nknowledge on bias in LLMs but also contributes original empirical validation\nthrough simulation of mitigation strategies.", "published": "2025-09-17 21:22:33", "link": "http://arxiv.org/abs/2509.14438v1", "categories": ["cs.CL", "cs.AI", "I.2"], "primary_category": "cs.CL"}
{"title": "Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG", "abstract": "Large language models (LLMs) have transformed natural language processing\n(NLP), enabling diverse applications by integrating large-scale pre-trained\nknowledge. However, their static knowledge limits dynamic reasoning over\nexternal information, especially in knowledge-intensive domains.\nRetrieval-Augmented Generation (RAG) addresses this challenge by combining\nretrieval mechanisms with generative modeling to improve contextual\nunderstanding. Traditional RAG systems suffer from disrupted contextual\nintegrity due to text chunking and over-reliance on semantic similarity for\nretrieval, often resulting in shallow and less accurate responses. We propose\nCausal-Counterfactual RAG, a novel framework that integrates explicit causal\ngraphs representing cause-effect relationships into the retrieval process and\nincorporates counterfactual reasoning grounded on the causal structure. Unlike\nconventional methods, our framework evaluates not only direct causal evidence\nbut also the counterfactuality of associated causes, combining results from\nboth to generate more robust, accurate, and interpretable answers. By\nleveraging causal pathways and associated hypothetical scenarios,\nCausal-Counterfactual RAG preserves contextual coherence, reduces\nhallucination, and enhances reasoning fidelity.", "published": "2025-09-17 21:18:47", "link": "http://arxiv.org/abs/2509.14435v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings", "abstract": "Word-level psycholinguistic norms lend empirical support to theories of\nlanguage processing. However, obtaining such human-based measures is not always\nfeasible or straightforward. One promising approach is to augment human norming\ndatasets by using Large Language Models (LLMs) to predict these characteristics\ndirectly, a practice that is rapidly gaining popularity in psycholinguistics\nand cognitive science. However, the novelty of this approach (and the relative\ninscrutability of LLMs) necessitates the adoption of rigorous methodologies\nthat guide researchers through this process, present the range of possible\napproaches, and clarify limitations that are not immediately apparent, but may,\nin some cases, render the use of LLMs impractical.\n  In this work, we present a comprehensive methodology for estimating word\ncharacteristics with LLMs, enriched with practical advice and lessons learned\nfrom our own experience. Our approach covers both the direct use of base LLMs\nand the fine-tuning of models, an alternative that can yield substantial\nperformance gains in certain scenarios. A major emphasis in the guide is the\nvalidation of LLM-generated data with human \"gold standard\" norms. We also\npresent a software framework that implements our methodology and supports both\ncommercial and open-weight models.\n  We illustrate the proposed approach with a case study on estimating word\nfamiliarity in English. Using base models, we achieved a Spearman correlation\nof 0.8 with human ratings, which increased to 0.9 when employing fine-tuned\nmodels. This methodology, framework, and set of best practices aim to serve as\na reference for future research on leveraging LLMs for psycholinguistic and\nlexical studies.", "published": "2025-09-17 20:11:23", "link": "http://arxiv.org/abs/2509.14405v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Taxonomy of Prompt Defects in LLM Systems", "abstract": "Large Language Models (LLMs) have become key components of modern software,\nwith prompts acting as their de-facto programming interface. However, prompt\ndesign remains largely empirical and small mistakes can cascade into\nunreliable, insecure, or inefficient behavior. This paper presents the first\nsystematic survey and taxonomy of prompt defects, recurring ways that prompts\nfail to elicit their intended behavior from LLMs. We organize defects along six\ndimensions: (1) Specification and Intent, (2) Input and Content, (3) Structure\nand Formatting, (4) Context and Memory, (5) Performance and Efficiency, and (6)\nMaintainability and Engineering. Each dimension is refined into fine-grained\nsubtypes, illustrated with concrete examples and root cause analysis. Grounded\nin software engineering principles, we show how these defects surface in real\ndevelopment workflows and examine their downstream effects. For every subtype,\nwe distill mitigation strategies that span emerging prompt engineering\npatterns, automated guardrails, testing harnesses, and evaluation frameworks.\nWe then summarize these strategies in a master taxonomy that links defect,\nimpact, and remedy. We conclude with open research challenges and a call for\nrigorous engineering-oriented methodologies to ensure that LLM-driven systems\nare dependable by design.", "published": "2025-09-17 20:11:22", "link": "http://arxiv.org/abs/2509.14404v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Annotating Training Data for Conditional Semantic Textual Similarity Measurement using Large Language Models", "abstract": "Semantic similarity between two sentences depends on the aspects considered\nbetween those sentences. To study this phenomenon, Deshpande et al. (2023)\nproposed the Conditional Semantic Textual Similarity (C-STS) task and annotated\na human-rated similarity dataset containing pairs of sentences compared under\ntwo different conditions. However, Tu et al. (2024) found various annotation\nissues in this dataset and showed that manually re-annotating a small portion\nof it leads to more accurate C-STS models. Despite these pioneering efforts,\nthe lack of large and accurately annotated C-STS datasets remains a blocker for\nmaking progress on this task as evidenced by the subpar performance of the\nC-STS models. To address this training data need, we resort to Large Language\nModels (LLMs) to correct the condition statements and similarity ratings in the\noriginal dataset proposed by Deshpande et al. (2023). Our proposed method is\nable to re-annotate a large training dataset for the C-STS task with minimal\nmanual effort. Importantly, by training a supervised C-STS model on our cleaned\nand re-annotated dataset, we achieve a 5.4% statistically significant\nimprovement in Spearman correlation. The re-annotated dataset is available at\nhttps://LivNLP.github.io/CSTS-reannotation.", "published": "2025-09-17 20:01:54", "link": "http://arxiv.org/abs/2509.14399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond the high score: Prosocial ability profiles of multi-agent populations", "abstract": "The development and evaluation of social capabilities in AI agents require\ncomplex environments where competitive and cooperative behaviours naturally\nemerge. While game-theoretic properties can explain why certain teams or agent\npopulations outperform others, more abstract behaviours, such as convention\nfollowing, are harder to control in training and evaluation settings. The\nMelting Pot contest is a social AI evaluation suite designed to assess the\ncooperation capabilities of AI systems. In this paper, we apply a Bayesian\napproach known as Measurement Layouts to infer the capability profiles of\nmulti-agent systems in the Melting Pot contest. We show that these capability\nprofiles not only predict future performance within the Melting Pot suite but\nalso reveal the underlying prosocial abilities of agents. Our analysis\nindicates that while higher prosocial capabilities sometimes correlate with\nbetter performance, this is not a universal trend-some lower-scoring agents\nexhibit stronger cooperation abilities. Furthermore, we find that\ntop-performing contest submissions are more likely to achieve high scores in\nscenarios where prosocial capabilities are not required. These findings,\ntogether with reports that the contest winner used a hard-coded solution\ntailored to specific environments, suggest that at least one top-performing\nteam may have optimised for conditions where cooperation was not necessary,\npotentially exploiting limitations in the evaluation framework. We provide\nrecommendations for improving the annotation of cooperation demands and propose\nfuture research directions to account for biases introduced by different\ntesting environments. Our results demonstrate that Measurement Layouts offer\nboth strong predictive accuracy and actionable insights, contributing to a more\ntransparent and generalisable approach to evaluating AI systems in complex\nsocial settings.", "published": "2025-09-17 23:29:39", "link": "http://arxiv.org/abs/2509.14485v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AToken: A Unified Tokenizer for Vision", "abstract": "We present AToken, the first unified visual tokenizer that achieves both\nhigh-fidelity reconstruction and semantic understanding across images, videos,\nand 3D assets. Unlike existing tokenizers that specialize in either\nreconstruction or understanding for single modalities, AToken encodes these\ndiverse visual inputs into a shared 4D latent space, unifying both tasks and\nmodalities in a single framework. Specifically, we introduce a pure transformer\narchitecture with 4D rotary position embeddings to process visual inputs of\narbitrary resolutions and temporal durations. To ensure stable training, we\nintroduce an adversarial-free training objective that combines perceptual and\nGram matrix losses, achieving state-of-the-art reconstruction quality. By\nemploying a progressive training curriculum, AToken gradually expands from\nsingle images, videos, and 3D, and supports both continuous and discrete latent\ntokens. AToken achieves 0.21 rFID with 82.2% ImageNet accuracy for images, 3.01\nrFVD with 32.6% MSRVTT retrieval for videos, and 28.19 PSNR with 90.9%\nclassification accuracy for 3D. In downstream applications, AToken enables both\nvisual generation tasks (e.g., image generation with continuous and discrete\ntokens, text-to-video generation, image-to-3D synthesis) and understanding\ntasks (e.g., multimodal LLMs), achieving competitive performance across all\nbenchmarks. These results shed light on the next-generation multimodal AI\nsystems built upon unified visual tokenization.", "published": "2025-09-17 23:11:18", "link": "http://arxiv.org/abs/2509.14476v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "From Mimicry to True Intelligence (TI) -- A New Paradigm for Artificial General Intelligence", "abstract": "The debate around Artificial General Intelligence (AGI) remains open due to\ntwo fundamentally different goals: replicating human-like performance versus\nreplicating human-like cognitive processes. We argue that current\nperformance-based definitions are inadequate because they provide no clear,\nmechanism-focused roadmap for research, and they fail to properly define the\nqualitative nature of genuine intelligence. Drawing inspiration from the human\nbrain, we propose a new paradigm that shifts the focus from external mimicry to\nthe development of foundational cognitive architectures. We define True\nIntelligence (TI) as a system characterized by six core components: embodied\nsensory fusion, core directives, dynamic schemata creation, a\nhighly-interconnected multi-expert architecture, an orchestration layer, and\nlastly, the unmeasurable quality of Interconnectedness, which we hypothesize\nresults in consciousness and a subjective experience. We propose a practical,\nfive-level taxonomy of AGI based on the number of the first five measurable\ncomponents a system exhibits. This framework provides a clear path forward with\ndevelopmental milestones that directly address the challenge of building\ngenuinely intelligent systems. We contend that once a system achieves Level-5\nAGI by implementing all five measurable components, the difference between it\nand TI remains as a purely philosophical debate. For practical purposes - and\ngiven theories indicate consciousness is an emergent byproduct of integrated,\nhigher-order cognition - we conclude that a fifth-level AGI is functionally and\npractically equivalent to TI. This work synthesizes diverse insights from\nanalytical psychology, schema theory, metacognition, modern brain architectures\nand latest works in AI to provide the first holistic, mechanism-based\ndefinition of AGI that offers a clear and actionable path for the research\ncommunity.", "published": "2025-09-17 23:08:36", "link": "http://arxiv.org/abs/2509.14474v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "VCBench: Benchmarking LLMs in Venture Capital", "abstract": "Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets\naccelerate progress toward artificial general intelligence (AGI). We introduce\nVCBench, the first benchmark for predicting founder success in venture capital\n(VC), a domain where signals are sparse, outcomes are uncertain, and even top\ninvestors perform modestly. At inception, the market index achieves a precision\nof 1.9%. Y Combinator outperforms the index by a factor of 1.7x, while tier-1\nfirms are 2.9x better. VCBench provides 9,000 anonymized founder profiles,\nstandardized to preserve predictive features while resisting identity leakage,\nwith adversarial tests showing more than 90% reduction in re-identification\nrisk. We evaluate nine state-of-the-art large language models (LLMs).\nDeepSeek-V3 delivers over six times the baseline precision, GPT-4o achieves the\nhighest F0.5, and most models surpass human benchmarks. Designed as a public\nand evolving resource available at vcbench.com, VCBench establishes a\ncommunity-driven standard for reproducible and privacy-preserving evaluation of\nAGI in early-stage venture forecasting.", "published": "2025-09-17 21:56:48", "link": "http://arxiv.org/abs/2509.14448v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "When Content is Goliath and Algorithm is David: The Style and Semantic Effects of Generative Search Engine", "abstract": "Generative search engines (GEs) leverage large language models (LLMs) to\ndeliver AI-generated summaries with website citations, establishing novel\ntraffic acquisition channels while fundamentally altering the search engine\noptimization landscape. To investigate the distinctive characteristics of GEs,\nwe collect data through interactions with Google's generative and conventional\nsearch platforms, compiling a dataset of approximately ten thousand websites\nacross both channels. Our empirical analysis reveals that GEs exhibit\npreferences for citing content characterized by significantly higher\npredictability for underlying LLMs and greater semantic similarity among\nselected sources. Through controlled experiments utilizing retrieval augmented\ngeneration (RAG) APIs, we demonstrate that these citation preferences emerge\nfrom intrinsic LLM tendencies to favor content aligned with their generative\nexpression patterns. Motivated by applications of LLMs to optimize website\ncontent, we conduct additional experimentation to explore how LLM-based content\npolishing by website proprietors alters AI summaries, finding that such\npolishing paradoxically enhances information diversity within AI summaries.\nFinally, to assess the user-end impact of LLM-induced information increases, we\ndesign a generative search engine and recruit Prolific participants to conduct\na randomized controlled experiment involving an information-seeking and writing\ntask. We find that higher-educated users exhibit minimal changes in their final\noutputs' information diversity but demonstrate significantly reduced task\ncompletion time when original sites undergo polishing. Conversely,\nlower-educated users primarily benefit through enhanced information density in\ntheir task outputs while maintaining similar completion times across\nexperimental groups.", "published": "2025-09-17 21:19:13", "link": "http://arxiv.org/abs/2509.14436v1", "categories": ["cs.IR", "cs.AI", "H.3.3; I.2.7; J.4"], "primary_category": "cs.IR"}
{"title": "Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs", "abstract": "Extending LLM context windows is crucial for long range tasks. RoPE-based\nposition interpolation (PI) methods like linear and frequency-aware scaling\nextend input lengths without retraining, while post-training quantization (PTQ)\nenables practical deployment. We show that combining PI with PTQ degrades\naccuracy due to coupled effects long context aliasing, dynamic range dilation,\naxis grid anisotropy, and outlier shifting that induce position-dependent logit\nnoise. We provide the first systematic analysis of PI plus PTQ and introduce\ntwo diagnostics: Interpolation Pressure (per-band phase scaling sensitivity)\nand Tail Inflation Ratios (outlier shift from short to long contexts). To\naddress this, we propose Q-ROAR, a RoPE-aware, weight-only stabilization that\ngroups RoPE dimensions into a few frequency bands and performs a small search\nover per-band scales for W_Q,W_K, with an optional symmetric variant to\npreserve logit scale. The diagnostics guided search uses a tiny long-context\ndev set and requires no fine-tuning, kernel, or architecture changes.\nEmpirically, Q-ROAR recovers up to 0.7% accuracy on standard tasks and reduces\nGovReport perplexity by more than 10%, while preserving short-context\nperformance and compatibility with existing inference stacks.", "published": "2025-09-17 19:50:16", "link": "http://arxiv.org/abs/2509.14391v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "eIQ Neutron: Redefining Edge-AI Inference with Integrated NPU and Compiler Innovations", "abstract": "Neural Processing Units (NPUs) are key to enabling efficient AI inference in\nresource-constrained edge environments. While peak tera operations per second\n(TOPS) is often used to gauge performance, it poorly reflects real-world\nperformance and typically rather correlates with higher silicon cost. To\naddress this, architects must focus on maximizing compute utilization, without\nsacrificing flexibility. This paper presents the eIQ Neutron efficient-NPU,\nintegrated into a commercial flagship MPU, alongside co-designed compiler\nalgorithms. The architecture employs a flexible, data-driven design, while the\ncompiler uses a constrained programming approach to optimize compute and data\nmovement based on workload characteristics. Compared to the leading embedded\nNPU and compiler stack, our solution achieves an average speedup of 1.8x (4x\npeak) at equal TOPS and memory resources across standard AI-benchmarks. Even\nagainst NPUs with double the compute and memory resources, Neutron delivers up\nto 3.3x higher performance.", "published": "2025-09-17 19:45:51", "link": "http://arxiv.org/abs/2509.14388v1", "categories": ["cs.AR", "cs.AI", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Class-invariant Test-Time Augmentation for Domain Generalization", "abstract": "Deep models often suffer significant performance degradation under\ndistribution shifts. Domain generalization (DG) seeks to mitigate this\nchallenge by enabling models to generalize to unseen domains. Most prior\napproaches rely on multi-domain training or computationally intensive test-time\nadaptation. In contrast, we propose a complementary strategy: lightweight\ntest-time augmentation. Specifically, we develop a novel Class-Invariant\nTest-Time Augmentation (CI-TTA) technique. The idea is to generate multiple\nvariants of each input image through elastic and grid deformations that\nnevertheless belong to the same class as the original input. Their predictions\nare aggregated through a confidence-guided filtering scheme that remove\nunreliable outputs, ensuring the final decision relies on consistent and\ntrustworthy cues. Extensive Experiments on PACS and Office-Home datasets\ndemonstrate consistent gains across different DG algorithms and backbones,\nhighlighting the effectiveness and generality of our approach.", "published": "2025-09-17 20:42:23", "link": "http://arxiv.org/abs/2509.14420v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "RLBind: Adversarial-Invariant Cross-Modal Alignment for Unified Robust Embeddings", "abstract": "Unified multi-modal encoders that bind vision, audio, and other sensors into\na shared embedding space are attractive building blocks for robot perception\nand decision-making. However, on-robot deployment exposes the vision branch to\nadversarial and natural corruptions, making robustness a prerequisite for\nsafety. Prior defenses typically align clean and adversarial features within\nCLIP-style encoders and overlook broader cross-modal correspondence, yielding\nmodest gains and often degrading zero-shot transfer. We introduce RLBind, a\ntwo-stage adversarial-invariant cross-modal alignment framework for robust\nunified embeddings. Stage 1 performs unsupervised fine-tuning on\nclean-adversarial pairs to harden the visual encoder. Stage 2 leverages\ncross-modal correspondence by minimizing the discrepancy between\nclean/adversarial features and a text anchor, while enforcing class-wise\ndistributional alignment across modalities. Extensive experiments on Image,\nAudio, Thermal, and Video data show that RLBind consistently outperforms the\nLanguageBind backbone and standard fine-tuning baselines in both clean accuracy\nand norm-bounded adversarial robustness. By improving resilience without\nsacrificing generalization, RLBind provides a practical path toward safer\nmulti-sensor perception stacks for embodied robots in navigation, manipulation,\nand other autonomy settings.", "published": "2025-09-17 19:35:52", "link": "http://arxiv.org/abs/2509.14383v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Keywords are not always the key: A metadata field analysis for natural language search on open data portals", "abstract": "Open data portals are essential for providing public access to open datasets.\nHowever, their search interfaces typically rely on keyword-based mechanisms and\na narrow set of metadata fields. This design makes it difficult for users to\nfind datasets using natural language queries. The problem is worsened by\nmetadata that is often incomplete or inconsistent, especially when users lack\nfamiliarity with domain-specific terminology. In this paper, we examine how\nindividual metadata fields affect the success of conversational dataset\nretrieval and whether LLMs can help bridge the gap between natural queries and\nstructured metadata. We conduct a controlled ablation study using simulated\nnatural language queries over real-world datasets to evaluate retrieval\nperformance under various metadata configurations. We also compare existing\ncontent of the metadata field 'description' with LLM-generated content,\nexploring how different prompting strategies influence quality and impact on\nsearch outcomes. Our findings suggest that dataset descriptions play a central\nrole in aligning with user intent, and that LLM-generated descriptions can\nsupport effective retrieval. These results highlight both the limitations of\ncurrent metadata practices and the potential of generative models to improve\ndataset discoverability in open data portals.", "published": "2025-09-17 22:14:27", "link": "http://arxiv.org/abs/2509.14457v1", "categories": ["cs.IR", "cs.DB", "cs.DL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Hashing-Baseline: Rethinking Hashing in the Age of Pretrained Models", "abstract": "Information retrieval with compact binary embeddings, also referred to as\nhashing, is crucial for scalable fast search applications, yet state-of-the-art\nhashing methods require expensive, scenario-specific training. In this work, we\nintroduce Hashing-Baseline, a strong training-free hashing method leveraging\npowerful pretrained encoders that produce rich pretrained embeddings. We\nrevisit classical, training-free hashing techniques: principal component\nanalysis, random orthogonal projection, and threshold binarization, to produce\na strong baseline for hashing. Our approach combines these techniques with\nfrozen embeddings from state-of-the-art vision and audio encoders to yield\ncompetitive retrieval performance without any additional learning or\nfine-tuning. To demonstrate the generality and effectiveness of this approach,\nwe evaluate it on standard image retrieval benchmarks as well as a newly\nintroduced benchmark for audio hashing.", "published": "2025-09-17 20:58:43", "link": "http://arxiv.org/abs/2509.14427v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Overview of the TREC 2024 NeuCLIR Track", "abstract": "The principal goal of the TREC Neural Cross-Language Information Retrieval\n(NeuCLIR) track is to study the effect of neural approaches on cross-language\ninformation access. The track has created test collections containing Chinese,\nPersian, and Russian news stories and Chinese academic abstracts. NeuCLIR\nincludes four task types: Cross-Language Information Retrieval (CLIR) from\nnews, Multilingual Information Retrieval (MLIR) from news, Report Generation\nfrom news, and CLIR from technical documents. A total of 274 runs were\nsubmitted by five participating teams (and as baselines by the track\ncoordinators) for eight tasks across these four task types. Task descriptions\nand the available results are presented.", "published": "2025-09-17 18:36:38", "link": "http://arxiv.org/abs/2509.14355v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Online Learning of Deceptive Policies under Intermittent Observation", "abstract": "In supervisory control settings, autonomous systems are not monitored\ncontinuously. Instead, monitoring often occurs at sporadic intervals within\nknown bounds. We study the problem of deception, where an agent pursues a\nprivate objective while remaining plausibly compliant with a supervisor's\nreference policy when observations occur. Motivated by the behavior of real,\nhuman supervisors, we situate the problem within Theory of Mind: the\nrepresentation of what an observer believes and expects to see. We show that\nTheory of Mind can be repurposed to steer online reinforcement learning (RL)\ntoward such deceptive behavior. We model the supervisor's expectations and\ndistill from them a single, calibrated scalar -- the expected evidence of\ndeviation if an observation were to happen now. This scalar combines how unlike\nthe reference and current action distributions appear, with the agent's belief\nthat an observation is imminent. Injected as a state-dependent weight into a\nKL-regularized policy improvement step within an online RL loop, this scalar\ninforms a closed-form update that smoothly trades off self-interest and\ncompliance, thus sidestepping hand-crafted or heuristic policies. In\nreal-world, real-time hardware experiments on marine (ASV) and aerial (UAV)\nnavigation, our ToM-guided RL runs online, achieves high return and success\nwith observed-trace evidence calibrated to the supervisor's expectations.", "published": "2025-09-17 22:06:01", "link": "http://arxiv.org/abs/2509.14453v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "The extended horizontal linear complementarity problem: iterative methods and error analysis", "abstract": "To the best of our knowledge, since the extended horizontal linear\ncomplementarity problem (EHLCP) was first introduced and studied by Kaneko in\n1977, no iterative methods or error analysis have been developed for it due to\nthe interdependence of its multiple unknowns in a 'chain-like' structure. This\npaper aims to address these gaps by:\n  (1) proposing an equivalent fixed-point formulation of the EHLCP by using a\nvariable transformation technique with the max-min function;\n  (2) developing efficient iterative methods for solving the EHLCP based on\nthis fixed-point form, along with their convergence analysis;\n  (3) deriving global error bounds and computable estimates for the EHLCP.\n  Several numerical examples from applications such as multicommodity market\nequilibrium and bilateral obstacle problems are given to demonstrate the\neffectiveness of the proposed methods and bounds.", "published": "2025-09-17 23:55:53", "link": "http://arxiv.org/abs/2509.14491v1", "categories": ["math.NA", "cs.NA", "90C33, 65G50, 65G20"], "primary_category": "math.NA"}
{"title": "Error analysis of a fully discrete structure-preserving finite element scheme for a diffuse-interface model of tumour growth", "abstract": "We develop a fully discrete structure-preserving finite element method for a\ndiffuse-interface model of tumour growth. The system couples a Cahn--Hilliard\ntype equation with a nonlinear reaction-diffusion equation for nutrient\nconcentration and admits a dissipative energy law at the continuous level. For\nthe discretisation, we employ a scalar auxiliary variable (SAV) formulation\ntogether with a mixed finite element method for the Cahn--Hilliard part and\nstandard conforming finite elements for the reaction-diffusion equation in\nspace, combined with a first-order Euler time-stepping scheme. The resulting\nmethod is linear, unconditionally energy-stable, mass-preserving, and inherits\na discrete energy dissipation law associated with the SAV-based approximate\nenergy functional, while requiring the solution of only linear systems at each\ntime step. Under suitable regularity assumptions on the exact solution, we\nderive rigorous error estimates in $L^2$, $H^1$, and $L^\\infty$ norms,\nestablishing first-order accuracy in time and optimal-order accuracy in space.\nA key step in this analysis is the proof of boundedness of the numerical\nsolutions in $L^\\infty$. Numerical experiments validate the theoretical\nconvergence rates and demonstrate the robustness of the method in capturing\ncharacteristic phenomena such as aggregation and chemotactic tumour growth.", "published": "2025-09-17 23:30:35", "link": "http://arxiv.org/abs/2509.14486v1", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65M60, 35Q92"], "primary_category": "math.NA"}
{"title": "A Neural Network for the Identical Kuramoto Equation: Architectural Considerations and Performance Evaluation", "abstract": "In this paper, we investigate the efficiency of Deep Neural Networks (DNNs)\nto approximate the solution of a nonlocal conservation law derived from the\nidentical-oscillator Kuramoto model, focusing on the evaluation of an\narchitectural choice and its impact on solution accuracy based on the energy\nnorm and computation time. Through systematic experimentation, we demonstrate\nthat network configuration parameters-specifically, activation function\nselection (tanh vs. sin vs. ReLU), network depth (4-8 hidden layers), width\n(64-256 neurons), and training methodology (collocation points, epoch\ncount)-significantly influence convergence characteristics. We observe that\ntanh activation yields stable convergence across configurations, whereas sine\nactivation can attain marginally lower errors and training times in isolated\ncases, but occasionally produce nonphysical artefacts. Our comparative analysis\nwith traditional numerical methods shows that optimally configured DNNs offer\ncompetitive accuracy with notably different computational trade-offs.\nFurthermore, we identify fundamental limitations of standard feed-forward\narchitectures when handling singular or piecewise-constant solutions, providing\nempirical evidence that such networks inherently oversmooth sharp features due\nto the natural function space limitations of standard activation functions.\nThis work contributes to the growing body of research on neural network-based\nscientific computing by providing practitioners with empirical guidelines for\nDNN implementation while illuminating fundamental theoretical constraints that\nmust be overcome to expand their applicability to more challenging physical\nsystems with discontinuities.", "published": "2025-09-17 19:37:01", "link": "http://arxiv.org/abs/2509.14384v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "On the extension of a class of Hermite bivariate interpolation problems", "abstract": "We characterize the sets of solvability for Hermite bivariate interpolation\nproblems when the sum of multiplicities is at most $2n + 2$, with $n$ the\ndegree of the polynomial space. This result extends an earlier theorem (2000)\nby one of the authors concerning the case $2n+1$. The latter theorem, in turn,\ncan be regarded as a natural generalization of a classical theorem of Severi\n(1921).", "published": "2025-09-17 18:40:28", "link": "http://arxiv.org/abs/2509.14359v1", "categories": ["math.NA", "cs.NA", "41A05, 41A63"], "primary_category": "math.NA"}
{"title": "Adaptive and Regime-Aware RL for Portfolio Optimization", "abstract": "This study proposes a regime-aware reinforcement learning framework for\nlong-horizon portfolio optimization. Moving beyond traditional feedforward and\nGARCH-based models, we design realistic environments where agents dynamically\nreallocate capital in response to latent macroeconomic regime shifts. Agents\nreceive hybrid observations and are trained using constrained reward functions\nthat incorporate volatility penalties, capital resets, and tail-risk shocks. We\nbenchmark multiple architectures, including PPO, LSTM-based PPO, and\nTransformer PPO, against classical baselines such as equal-weight and\nSharpe-optimized portfolios. Our agents demonstrate robust performance under\nfinancial stress. While Transformer PPO achieves the highest risk-adjusted\nreturns, LSTM variants offer a favorable trade-off between interpretability and\ntraining cost. The framework promotes regime-adaptive, explainable\nreinforcement learning for dynamic asset allocation.", "published": "2025-09-17 19:40:57", "link": "http://arxiv.org/abs/2509.14385v1", "categories": ["q-fin.PM", "q-fin.CP"], "primary_category": "q-fin.PM"}
{"title": "Predictive Performance of LSTM Networks on Sectoral Stocks in an Emerging Market: A Case Study of the Pakistan Stock Exchange", "abstract": "The application of deep learning models for stock price forecasting in\nemerging markets remains underexplored despite their potential to capture\ncomplex temporal dependencies. This study develops and evaluates a Long\nShort-Term Memory (LSTM) network model for predicting the closing prices of ten\nmajor stocks across diverse sectors of the Pakistan Stock Exchange (PSX).\nUtilizing historical OHLCV data and an extensive set of engineered technical\nindicators, we trained and validated the model on a multi-year dataset. Our\nresults demonstrate strong predictive performance ($R^2 > 0.87$) for stocks in\nstable, high-liquidity sectors such as power generation, cement, and\nfertilizers. Conversely, stocks characterized by high volatility, low\nliquidity, or sensitivity to external shocks (e.g., global oil prices)\npresented significant forecasting challenges. The study provides a replicable\nframework for LSTM-based forecasting in data-scarce emerging markets and\ndiscusses implications for investors and future research.", "published": "2025-09-17 20:07:27", "link": "http://arxiv.org/abs/2509.14401v1", "categories": ["q-fin.TR", "68T99 (Primary), 62M10 (Secondary)", "I.6.5"], "primary_category": "q-fin.TR"}
{"title": "FedAVOT: Exact Distribution Alignment in Federated Learning via Masked Optimal Transport", "abstract": "Federated Learning (FL) allows distributed model training without sharing raw\ndata, but suffers when client participation is partial. In practice, the\ndistribution of available users (\\emph{availability distribution} $q$) rarely\naligns with the distribution defining the optimization objective\n(\\emph{importance distribution} $p$), leading to biased and unstable updates\nunder classical FedAvg. We propose \\textbf{Fereated AVerage with Optimal\nTransport (\\textbf{FedAVOT})}, which formulates aggregation as a masked optimal\ntransport problem aligning $q$ and $p$. Using Sinkhorn scaling,\n\\textbf{FedAVOT} computes transport-based aggregation weights with provable\nconvergence guarantees. \\textbf{FedAVOT} achieves a standard\n$\\mathcal{O}(1/\\sqrt{T})$ rate under a nonsmooth convex FL setting, independent\nof the number of participating users per round. Our experiments confirm\ndrastically improved performance compared to FedAvg across heterogeneous,\nfairness-sensitive, and low-availability regimes, even when only two clients\nparticipate per round.", "published": "2025-09-17 21:35:16", "link": "http://arxiv.org/abs/2509.14444v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Channel Differential ASR for Robust Wearer Speech Recognition on Smart Glasses", "abstract": "With the growing adoption of wearable devices such as smart glasses for AI\nassistants, wearer speech recognition (WSR) is becoming increasingly critical\nto next-generation human-computer interfaces. However, in real environments,\ninterference from side-talk speech remains a significant challenge to WSR and\nmay cause accumulated errors for downstream tasks such as natural language\nprocessing. In this work, we introduce a novel multi-channel differential\nautomatic speech recognition (ASR) method for robust WSR on smart glasses. The\nproposed system takes differential inputs from different frontends that\ncomplement each other to improve the robustness of WSR, including a beamformer,\nmicrophone selection, and a lightweight side-talk detection model. Evaluations\non both simulated and real datasets demonstrate that the proposed system\noutperforms the traditional approach, achieving up to an 18.0% relative\nreduction in word error rate.", "published": "2025-09-17 21:05:36", "link": "http://arxiv.org/abs/2509.14430v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior", "abstract": "In this paper, we address the problem of single-microphone speech separation\nin the presence of ambient noise. We propose a generative unsupervised\ntechnique that directly models both clean speech and structured noise\ncomponents, training exclusively on these individual signals rather than noisy\nmixtures. Our approach leverages an audio-visual score model that incorporates\nvisual cues to serve as a strong generative speech prior. By explicitly\nmodelling the noise distribution alongside the speech distribution, we enable\neffective decomposition through the inverse problem paradigm. We perform speech\nseparation by sampling from the posterior distributions via a reverse diffusion\nprocess, which directly estimates and removes the modelled noise component to\nrecover clean constituent signals. Experimental results demonstrate promising\nperformance, highlighting the effectiveness of our direct noise modelling\napproach in challenging acoustic environments.", "published": "2025-09-17 19:25:35", "link": "http://arxiv.org/abs/2509.14379v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Network representations reveal structured uncertainty in music", "abstract": "Music, as a structured yet perceptually rich experience, can be modeled as a\nnetwork to uncover how humans encode and process auditory information. While\nnetwork-based representations of music are increasingly common, the impact of\nfeature selection on structural properties and cognitive alignment remains\nunderexplored. In this study, we evaluated eight network models, each\nconstructed from symbolic representations of piano compositions using distinct\ncombinations of pitch, octave, duration, and interval, designed to be\nrepresentative of existing approaches in the literature. By comparing these\nmodels through topological metrics, entropy analysis, and divergence with\nrespect to inferred cognitive representations, we assessed both their\nstructural and perceptual efficiency. Our findings reveal that simpler,\nfeature-specific models better match human perception, whereas complex,\nmultidimensional representations introduce cognitive inefficiencies. These\nresults support the view that humans rely on modular, parallel cognitive\nnetworks--an architecture consistent with theories of predictive processing and\nfree energy minimization. Moreover, we find that musical networks are\nstructurally organized to guide attention toward transitions that are both\nuncertain and inferable. The resulting structure concentrates uncertainty in a\nfew frequently visited nodes, creating local entropy gradients that alternate\nbetween stable and unpredictable regions, thereby enabling the expressive\ndynamics of tension and release that define the musical experience. These\nfindings show that network structures make the organization of uncertainty in\nmusic observable, offering new insight into how patterned flows of expectation\nshape perception, and open new directions for studying how musical structures\nevolve across genres, cultures, and historical periods through the lens of\nnetwork science.", "published": "2025-09-17 14:55:54", "link": "http://arxiv.org/abs/2509.14053v1", "categories": ["physics.soc-ph", "cs.SD", "eess.AS", "q-bio.NC"], "primary_category": "physics.soc-ph"}
{"title": "Deploying UDM Series in Real-Life Stuttered Speech Applications: A Clinical Evaluation Framework", "abstract": "Stuttered and dysfluent speech detection systems have traditionally suffered\nfrom the trade-off between accuracy and clinical interpretability. While\nend-to-end deep learning models achieve high performance, their black-box\nnature limits clinical adoption. This paper looks at the Unconstrained\nDysfluency Modeling (UDM) series-the current state-of-the-art framework\ndeveloped by Berkeley that combines modular architecture, explicit phoneme\nalignment, and interpretable outputs for real-world clinical deployment.\nThrough extensive experiments involving patients and certified speech-language\npathologists (SLPs), we demonstrate that UDM achieves state-of-the-art\nperformance (F1: 0.89+-0.04) while providing clinically meaningful\ninterpretability scores (4.2/5.0). Our deployment study shows 87% clinician\nacceptance rate and 34% reduction in diagnostic time. The results provide\nstrong evidence that UDM represents a practical pathway toward AI-assisted\nspeech therapy in clinical environments.", "published": "2025-09-17 14:28:29", "link": "http://arxiv.org/abs/2509.14304v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SpeechOp: Inference-Time Task Composition for Generative Speech Processing", "abstract": "While generative Text-to-Speech (TTS) systems leverage vast ``in-the-wild\"\ndata to achieve remarkable success, speech-to-speech processing tasks like\nenhancement face data limitations, which lead data-hungry generative approaches\nto distort speech content and speaker identity. To bridge this gap, we present\nSpeechOp, a multi-task latent diffusion model that transforms pre-trained TTS\nmodels into a universal speech processor capable of performing a wide range of\nspeech tasks and composing them in novel ways at inference time. By adapting a\npre-trained TTS model, SpeechOp inherits a rich understanding of natural\nspeech, accelerating training and improving S2S task quality, while\nsimultaneously enhancing core TTS performance. Finally, we introduce Implicit\nTask Composition (ITC), a novel pipeline where ASR-derived transcripts (e.g.,\nfrom Whisper) guide SpeechOp's enhancement via our principled inference-time\ntask composition. ITC achieves state-of-the-art content preservation by\nrobustly combining web-scale speech understanding with SpeechOp's generative\ncapabilities. Audio samples are available at\nhttps://justinlovelace.github.io/projects/speechop", "published": "2025-09-17 05:05:55", "link": "http://arxiv.org/abs/2509.14298v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Secure Blind Graph Signal Recovery and Adversary Detection Using Smoothness Maximization", "abstract": "In this letter, we propose a secure blind Graph Signal Recovery (GSR)\nalgorithm that can detect adversary nodes. Some unknown adversaries are assumed\nto be injecting false data at their respective nodes in the graph. The number\nand location of adversaries are not known in advance and the goal is to recover\nthe graph signal in the presence of measurement noise and False Data Injection\n(FDI) caused by the adversaries. Consequently, the proposed algorithm would be\na perfect candidate to solve this challenging problem. Moreover, due to the\npresence of malicious nodes, the proposed method serves as a secure GSR\nalgorithm. For adversary detection, a statistical measure based on differential\nsmoothness is used. Specifically, the difference between the current observed\nsmoothness and the average smoothness excluding the corresponding node. This\ngenuine statistical approach leads to an effective and low-complexity adversary\ndetector. In addition, following malicious node detection, the GSR is performed\nusing a variant of smoothness maximization, which is solved efficiently as a\nfractional optimization problem using a Dinkelbach's algorithm. Analysis of the\ndetector, which determines the optimum threshold of the detector is also\npresented. Simulation results show a significant improvement of the proposed\nmethod in signal recovery compared to the median GSR algorithm and other\ncompeting methods.", "published": "2025-09-17 21:58:47", "link": "http://arxiv.org/abs/2509.14449v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Biologically Plausible Online Hebbian Meta-Learning: Two-Timescale Local Rules for Spiking Neural Brain Interfaces", "abstract": "Brain-Computer Interfaces face challenges from neural signal instability and\nmemory constraints for real-time implantable applications. We introduce an\nonline SNN decoder using local three-factor learning rules with dual-timescale\neligibility traces that avoid backpropagation through time while maintaining\ncompetitive performance. Our approach combines error-modulated Hebbian updates,\nfast/slow trace consolidation, and adaptive learning rate control, requiring\nonly O(1) memory versus O(T) for BPTT methods. Evaluations on two primate\ndatasets achieve comparable decoding accuracy (Pearson $R \\geq 0.63$ Zenodo, $R\n\\geq 0.81$ MC Maze) with 28-35% memory reduction and faster convergence than\nBPTT-trained SNNs. Closed-loop simulations with synthetic neural populations\ndemonstrate adaptation to neural disruptions and learning from scratch without\noffline calibration. This work enables memory-efficient, continuously adaptive\nneural decoding suitable for resource-constrained implantable BCI systems.", "published": "2025-09-17 21:49:39", "link": "http://arxiv.org/abs/2509.14447v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Indoor Airflow Imaging Using Physics-Informed Background-Oriented Schlieren Tomography", "abstract": "We develop a framework for non-invasive volumetric indoor airflow estimation\nfrom a single viewpoint using background-oriented schlieren (BOS) measurements\nand physics-informed reconstruction. Our framework utilizes a light projector\nthat projects a pattern onto a target back-wall and a camera that observes\nsmall distortions in the light pattern. While the single-view BOS tomography\nproblem is severely ill-posed, our proposed framework addresses this using: (1)\nimproved ray tracing, (2) a physics-based light rendering approach and loss\nformulation, and (3) a physics-based regularization using a physics-informed\nneural network (PINN) to ensure that the reconstructed airflow is consistent\nwith the governing equations for buoyancy-driven flows.", "published": "2025-09-17 21:31:32", "link": "http://arxiv.org/abs/2509.14442v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Conditional Nearest Level Modulation for Improved Switching Dynamics in Asymmetric Multilevel Converters", "abstract": "Modular multilevel converters have promising applications in clean energy,\nelectric vehicles, and biomedical instrumentation, but need many modules to\nachieve fine output granularity, particularly of the voltage. Asymmetric\nmultilevel circuits introduce differences in module voltages so that the\nquantity of output levels grows exponentially with the number of modules.\nNearest-level modulation (NLM) is preferred over carrier-based methods in\nasymmetric circuits for its simplicity. However, the large number of output\nlevels can overwhelm NLM and cause excessive transistor switching on some\nmodules and output voltage spikes. We propose a conditional nearest-level\nmodulation (cNLM) by incorporating mathematical penalty models to regulate\nswitching dynamics. This approach improves output quality and reduces switching\nrates. Additionally, we present cNLM variations tailored for specific\nfunctions, such as enforcing a minimum switching interval. Experimental\nvalidation on an asymmetric multilevel prototype demonstrates that cNLM reduces\nthe total output distortion from 66.3% to 15.1% while cutting the switching\nrate to just 8% of the original NLM.", "published": "2025-09-17 20:07:46", "link": "http://arxiv.org/abs/2509.14402v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AToken: A Unified Tokenizer for Vision", "abstract": "We present AToken, the first unified visual tokenizer that achieves both\nhigh-fidelity reconstruction and semantic understanding across images, videos,\nand 3D assets. Unlike existing tokenizers that specialize in either\nreconstruction or understanding for single modalities, AToken encodes these\ndiverse visual inputs into a shared 4D latent space, unifying both tasks and\nmodalities in a single framework. Specifically, we introduce a pure transformer\narchitecture with 4D rotary position embeddings to process visual inputs of\narbitrary resolutions and temporal durations. To ensure stable training, we\nintroduce an adversarial-free training objective that combines perceptual and\nGram matrix losses, achieving state-of-the-art reconstruction quality. By\nemploying a progressive training curriculum, AToken gradually expands from\nsingle images, videos, and 3D, and supports both continuous and discrete latent\ntokens. AToken achieves 0.21 rFID with 82.2% ImageNet accuracy for images, 3.01\nrFVD with 40.2% MSRVTT retrieval for videos, and 28.28 PSNR with 90.9%\nclassification accuracy for 3D.. In downstream applications, AToken enables\nboth visual generation tasks (e.g., image generation with continuous and\ndiscrete tokens, text-to-video generation, image-to-3D synthesis) and\nunderstanding tasks (e.g., multimodal LLMs), achieving competitive performance\nacross all benchmarks. These results shed light on the next-generation\nmultimodal AI systems built upon unified visual tokenization.", "published": "2025-09-17 23:11:18", "link": "http://arxiv.org/abs/2509.14476v2", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "SAIL-VL2 Technical Report", "abstract": "We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)\nfor comprehensive multimodal understanding and reasoning. As the successor to\nSAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B\nparameter scales across diverse image and video benchmarks, demonstrating\nstrong capabilities from fine-grained perception to complex reasoning. Its\neffectiveness is driven by three core innovations. First, a large-scale data\ncuration pipeline with scoring and filtering strategies enhances both quality\nand distribution across captioning, OCR, QA, and video data, improving training\nefficiency. Second, a progressive training framework begins with a powerful\npre-trained vision encoder (SAIL-ViT), advances through multimodal\npre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that\nsystematically strengthens model capabilities. Third, architectural advances\nextend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.\nWith these contributions, SAIL-VL2 demonstrates competitive performance across\n106 datasets and achieves state-of-the-art results on challenging reasoning\nbenchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass\nleaderboard, SAIL-VL2-2B ranks first among officially released open-source\nmodels under the 4B parameter scale, while serving as an efficient and\nextensible foundation for the open-source multimodal community.", "published": "2025-09-17 14:34:02", "link": "http://arxiv.org/abs/2509.14033v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Online Learning of Deceptive Policies under Intermittent Observation", "abstract": "In supervisory control settings, autonomous systems are not monitored\ncontinuously. Instead, monitoring often occurs at sporadic intervals within\nknown bounds. We study the problem of deception, where an agent pursues a\nprivate objective while remaining plausibly compliant with a supervisor's\nreference policy when observations occur. Motivated by the behavior of real,\nhuman supervisors, we situate the problem within Theory of Mind: the\nrepresentation of what an observer believes and expects to see. We show that\nTheory of Mind can be repurposed to steer online reinforcement learning (RL)\ntoward such deceptive behavior. We model the supervisor's expectations and\ndistill from them a single, calibrated scalar -- the expected evidence of\ndeviation if an observation were to happen now. This scalar combines how unlike\nthe reference and current action distributions appear, with the agent's belief\nthat an observation is imminent. Injected as a state-dependent weight into a\nKL-regularized policy improvement step within an online RL loop, this scalar\ninforms a closed-form update that smoothly trades off self-interest and\ncompliance, thus sidestepping hand-crafted or heuristic policies. In\nreal-world, real-time hardware experiments on marine (ASV) and aerial (UAV)\nnavigation, our ToM-guided RL runs online, achieves high return and success\nwith observed-trace evidence calibrated to the supervisor's expectations.", "published": "2025-09-17 22:06:01", "link": "http://arxiv.org/abs/2509.14453v2", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Biologically Plausible Online Hebbian Meta-Learning: Two-Timescale Local Rules for Spiking Neural Brain Interfaces", "abstract": "Brain-Computer Interfaces face challenges from neural signal instability and\nmemory constraints for real-time implantable applications. We introduce an\nonline SNN decoder using local three-factor learning rules with dual-timescale\neligibility traces that avoid backpropagation through time while maintaining\ncompetitive performance. Our approach combines error-modulated Hebbian updates,\nfast/slow trace consolidation, and adaptive learning rate control, requiring\nonly O(1) memory versus O(T) for BPTT methods. Evaluations on two primate\ndatasets achieve comparable decoding accuracy (Pearson $R \\geq 0.63$ Zenodo, $R\n\\geq 0.81$ MC Maze) with 28-35% memory reduction and faster convergence than\nBPTT-trained SNNs. Closed-loop simulations with synthetic neural populations\ndemonstrate adaptation to neural disruptions and learning from scratch without\noffline calibration. This work enables memory-efficient, continuously adaptive\nneural decoding suitable for resource-constrained implantable BCI systems.", "published": "2025-09-17 21:49:39", "link": "http://arxiv.org/abs/2509.14447v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization", "abstract": "As wireless communication systems advance toward Sixth Generation (6G) Radio\nAccess Networks (RAN), Deep Learning (DL)-based neural receivers are emerging\nas transformative solutions for Physical Layer (PHY) processing, delivering\nsuperior Block Error Rate (BLER) performance compared to traditional\nmodel-based approaches. Practical deployment on resource-constrained hardware,\nhowever, requires efficient quantization to reduce latency, energy, and memory\nwithout sacrificing reliability. In this paper, we extend Post-Training\nQuantization (PTQ) by focusing on Quantization-Aware Training (QAT), which\nincorporates low-precision simulation during training for robustness at\nultra-low bitwidths. In particular, we develop a QAT methodology for a neural\nreceiver architecture and benchmark it against a PTQ approach across diverse\n3GPP Clustered Delay Line (CDL) channel profiles under both Line-of-Sight (LoS)\nand Non-LoS (NLoS) conditions, with user velocities up to 40 m/s. Results show\nthat 4-bit and 8-bit QAT models achieve BLERs comparable to FP32 models at a\n10% target BLER. Moreover, QAT models succeed in NLoS scenarios where PTQ\nmodels fail to reach the 10% BLER target, while also yielding an 8x\ncompression. These results with respect to full-precision demonstrate that QAT\nis a key enabler of low-complexity and latency-constrained inference at the PHY\nlayer, facilitating real-time processing in 6G edge devices.", "published": "2025-09-17 07:55:58", "link": "http://arxiv.org/abs/2509.13786v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Generating Plans for Belief-Desire-Intention (BDI) Agents Using Alternating-Time Temporal Logic (ATL)", "abstract": "Belief-Desire-Intention (BDI) is a framework for modelling agents based on\ntheir beliefs, desires, and intentions. Plans are a central component of BDI\nagents, and define sequences of actions that an agent must undertake to achieve\na certain goal. Existing approaches to plan generation often require\nsignificant manual effort, and are mainly focused on single-agent systems. As a\nresult, in this work, we have developed a tool that automatically generates BDI\nplans using Alternating-Time Temporal Logic (ATL). By using ATL, the plans\ngenerated accommodate for possible competition or cooperation between the\nagents in the system. We demonstrate the effectiveness of the tool by\ngenerating plans for an illustrative game that requires agent collaboration to\nachieve a shared goal. We show that the generated plans allow the agents to\nsuccessfully attain this goal.", "published": "2025-09-17 15:34:02", "link": "http://arxiv.org/abs/2509.15238v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Kernel Model Validation: How To Do It, And Why You Should Care", "abstract": "Gaussian Process (GP) models are popular tools in uncertainty quantification\n(UQ) because they purport to furnish functional uncertainty estimates that can\nbe used to represent model uncertainty. It is often difficult to state with\nprecision what probabilistic interpretation attaches to such an uncertainty,\nand in what way is it calibrated. Without such a calibration statement, the\nvalue of such uncertainty estimates is quite limited and qualitative. We\nmotivate the importance of proper probabilistic calibration of GP predictions\nby describing how GP predictive calibration failures can cause degraded\nconvergence properties in a target optimization algorithm called Targeted\nAdaptive Design (TAD). We discuss the interpretation of GP-generated\nuncertainty intervals in UQ, and how one may learn to trust them, through a\nformal procedure for covariance kernel validation that exploits the\nmultivariate normal nature of GP predictions. We give simple examples of GP\nregression misspecified 1-dimensional models, and discuss the situation with\nrespect to higher-dimensional models.", "published": "2025-09-17 18:35:00", "link": "http://arxiv.org/abs/2509.15244v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices", "abstract": "Convolutional Neural Networks (CNNs) have demonstrated exceptional\nperformance in audio tagging tasks. However, deploying these models on\nresource-constrained devices like the Raspberry Pi poses challenges related to\ncomputational efficiency and thermal management. In this paper, a comprehensive\nevaluation of multiple convolutional neural network (CNN) architectures for\naudio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D\nmodels from the Pretrained Audio Neural Networks (PANNs) framework, a\nConvNeXt-based model adapted for audio classification, as well as MobileNetV3\narchitectures. In addition, two PANNs-derived networks, CNN9 and CNN13,\nrecently proposed, are also evaluated. To enhance deployment efficiency and\nportability across diverse hardware platforms, all models are converted to the\nOpen Neural Network Exchange (ONNX) format. Unlike previous works that focus on\na single model, our analysis encompasses a broader range of architectures and\ninvolves continuous 24-hour inference sessions to assess performance stability.\nOur experiments reveal that, with appropriate model selection and optimization,\nit is possible to maintain consistent inference latency and manage thermal\nbehavior effectively over extended periods. These findings provide valuable\ninsights for deploying audio tagging models in real-world edge computing\nscenarios.", "published": "2025-09-17 14:53:56", "link": "http://arxiv.org/abs/2509.14049v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Rare Event Simulation of Quantum Error-Correcting Circuits", "abstract": "We describe a practical approach for accessing the logical failure rates of\nquantum error-correcting (QEC) circuits under low physical (component) failure\nrate regimes. Standard Monte Carlo is often the de facto approach for studying\nthe failure rates of quantum circuits. However, in the study of fault-tolerant\nerror-correcting circuits, the ability to extend this approach to low physical\nfailure rates is limited. In particular, the use of Monte Carlo to access\ncircuits that are relatively large or have high correcting power becomes more\ndifficult as we lower the input failure rates of the individual components\n(gates) in the circuit. For these reasons, many simulations studying the\ncircuit model go no lower than end-to-end logical failure rates in the 10^{-6}\nregime. In this report, we outline an approach that borrows from earlier work\nby Bravyi and Vargo to the more complex circuit noise model. Earlier works\nstudied both the capacity and phenomenological noise models, but the work is\ninsufficient for generating similar simulations in the circuit-noise model. To\nthe best of our knowledge, our team is the first to develop a full prescription\nof the rare event simulation by splitting technique for the circuit-based noise\nmodel. We have also generated promising results that are confirmed by standard\nMonte Carlo simulation under an accessible regime. This work shows that we can\naccess noise in the circuit-model prescription of quantum error-correcting code\nto failure rates below 10^{-20} regime.", "published": "2025-09-17 04:12:14", "link": "http://arxiv.org/abs/2509.13678v2", "categories": ["quant-ph", "cs.NA", "math.NA", "math.PR"], "primary_category": "quant-ph"}
{"title": "Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems", "abstract": "Instruction-guided text-to-speech (ITTS) enables users to control speech\ngeneration through natural language prompts, offering a more intuitive\ninterface than traditional TTS. However, the alignment between user style\ninstructions and listener perception remains largely unexplored. This work\nfirst presents a perceptual analysis of ITTS controllability across two\nexpressive dimensions (adverbs of degree and graded emotion intensity) and\ncollects human ratings on speaker age and word-level emphasis attributes. To\ncomprehensively reveal the instruction-perception gap, we provide a data\ncollection with large-scale human evaluations, named Expressive VOice Control\n(E-VOC) corpus. Furthermore, we reveal that (1) gpt-4o-mini-tts is the most\nreliable ITTS model with great alignment between instruction and generated\nutterances across acoustic dimensions. (2) The 5 analyzed ITTS systems tend to\ngenerate Adult voices even when the instructions ask to use child or Elderly\nvoices. (3) Fine-grained control remains a major challenge, indicating that\nmost ITTS systems have substantial room for improvement in interpreting\nslightly different attribute instructions.", "published": "2025-09-17 14:00:45", "link": "http://arxiv.org/abs/2509.13989v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Numerical solution of the unsteady Brinkman equations in the framework of $H$(div)-conforming finite element methods", "abstract": "We present projection-based mixed finite element methods for the solution of\nthe unsteady Brinkman equations for incompressible single-phase flow with fixed\nin space porous solid inclusions. At each time step the method requires the\nsolution of a predictor and a projection problem. The predictor problem, which\nuses a stress-velocity mixed formulation, accounts for the momentum balance,\nwhile the projection problem, which is based on a velocity-pressure mixed\nformulation, accounts for the incompressibility. The spatial discretization is\n$H$(div)-conforming and the velocity computed at the end of each time step is\npointwise divergence-free. Unconditional stability of the fully-discrete scheme\nand first order in time accuracy are established. Due to the\n$H$(div)-conformity of the formulation, the methods are robust in both the\nStokes and the Darcy regimes. In the specific code implementation, we\ndiscretize the computational domain using the Raviart--Thomas space $RT_1$ in\ntwo and three dimensions, applying a second-order accurate multipoint flux\nmixed finite element scheme with a quadrature rule that samples the flux\ndegrees of freedom. In the predictor problem this allows for a local\nelimination of the viscous stress and results in element-based symmetric and\npositive definite systems for each velocity component with $\\left(d+1\\right)$\ndegrees of freedom per simplex (where $d$ is the dimension of the problem). In\na similar way, we locally eliminate the corrected velocity in the projection\nproblem and solve an element-based system for the pressure. Numerical\nexperiments are presented to verify the convergence of the proposed scheme and\nillustrate its performance for several challenging applications, including\none-domain modeling of coupled free fluid and porous media flows and\nheterogeneous porous media with strong discontinuity of the porosity and\npermeability values.", "published": "2025-09-17 15:04:42", "link": "http://arxiv.org/abs/2509.14059v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Smaller Circuits for Bit Addition", "abstract": "Bit addition arises virtually everywhere in digital circuits: arithmetic\noperations, increment/decrement operators, computing addresses and table\nindices, and so on. Since bit addition is such a basic task in Boolean circuit\nsynthesis, a lot of research has been done on constructing efficient circuits\nfor various special cases of it. A vast majority of these results are devoted\nto optimizing the circuit depth (also known as delay).\n  In this paper, we investigate the circuit size (also known as area) over the\nfull binary basis of bit addition. Though most of the known circuits are built\nfrom Half Adders and Full Adders, we show that, in many interesting scenarios,\nthese circuits have suboptimal size. Namely, we improve an upper bound $5n-3m$\nto $4.5n-2m$, where $n$ is the number of input bits and $m$ is the number of\noutput bits. In the regimes where $m$ is small compared to $n$ (for example,\nfor computing the sum of $n$ bits or multiplying two $n$-bit integers), this\nleads to $10\\%$ improvement.\n  We complement our theoretical result by an open-source implementation of\ngenerators producing circuits for bit addition and multiplication. The\ngenerators allow one to produce the corresponding circuits in two lines of code\nand to compare them to existing designs.", "published": "2025-09-17 13:37:53", "link": "http://arxiv.org/abs/2509.13966v2", "categories": ["cs.CC", "cs.DM", "cs.DS", "cs.LO"], "primary_category": "cs.CC"}
{"title": "AEGIS: Automated Error Generation and Identification for Multi-Agent Systems", "abstract": "As Multi-Agent Systems (MAS) become increasingly autonomous and complex,\nunderstanding their error modes is critical for ensuring their reliability and\nsafety. However, research in this area has been severely hampered by the lack\nof large-scale, diverse datasets with precise, ground-truth error labels. To\naddress this bottleneck, we introduce \\textbf{AEGIS}, a novel framework for\n\\textbf{A}utomated \\textbf{E}rror \\textbf{G}eneration and\n\\textbf{I}dentification for Multi-Agent \\textbf{S}ystems. By systematically\ninjecting controllable and traceable errors into initially successful\ntrajectories, we create a rich dataset of realistic failures. This is achieved\nusing a context-aware, LLM-based adaptive manipulator that performs\nsophisticated attacks like prompt injection and response corruption to induce\nspecific, predefined error modes. We demonstrate the value of our dataset by\nexploring three distinct learning paradigms for the error identification task:\nSupervised Fine-Tuning, Reinforcement Learning, and Contrastive Learning. Our\ncomprehensive experiments show that models trained on AEGIS data achieve\nsubstantial improvements across all three learning paradigms. Notably, several\nof our fine-tuned models demonstrate performance competitive with or superior\nto proprietary systems an order of magnitude larger, validating our automated\ndata generation framework as a crucial resource for developing more robust and\ninterpretable multi-agent systems. Our project website is available at\nhttps://kfq20.github.io/AEGIS-Website.", "published": "2025-09-17 02:31:03", "link": "http://arxiv.org/abs/2509.14295v2", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG", "abstract": "Large language models (LLMs) have transformed natural language processing\n(NLP), enabling diverse applications by integrating large-scale pre-trained\nknowledge. However, their static knowledge limits dynamic reasoning over\nexternal information, especially in knowledge-intensive domains.\nRetrieval-Augmented Generation (RAG) addresses this challenge by combining\nretrieval mechanisms with generative modeling to improve contextual\nunderstanding. Traditional RAG systems suffer from disrupted contextual\nintegrity due to text chunking and over-reliance on semantic similarity for\nretrieval, often resulting in shallow and less accurate responses. We propose\nCausal-Counterfactual RAG, a novel framework that integrates explicit causal\ngraphs representing cause-effect relationships into the retrieval process and\nincorporates counterfactual reasoning grounded on the causal structure. Unlike\nconventional methods, our framework evaluates not only direct causal evidence\nbut also the counterfactuality of associated causes, combining results from\nboth to generate more robust, accurate, and interpretable answers. By\nleveraging causal pathways and associated hypothetical scenarios,\nCausal-Counterfactual RAG preserves contextual coherence, reduces\nhallucination, and enhances reasoning fidelity.", "published": "2025-09-17 21:18:47", "link": "http://arxiv.org/abs/2509.14435v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Aegis: Automated Error Generation and Identification for Multi-Agent Systems", "abstract": "As Multi-Agent Systems (MAS) become increasingly autonomous and complex,\nunderstanding their error modes is critical for ensuring their reliability and\nsafety. However, research in this area has been severely hampered by the lack\nof large-scale, diverse datasets with precise, ground-truth error labels. To\naddress this bottleneck, we introduce \\textbf{AEGIS}, a novel framework for\n\\textbf{A}utomated \\textbf{E}rror \\textbf{G}eneration and\n\\textbf{I}dentification for Multi-Agent \\textbf{S}ystems. By systematically\ninjecting controllable and traceable errors into initially successful\ntrajectories, we create a rich dataset of realistic failures. This is achieved\nusing a context-aware, LLM-based adaptive manipulator that performs\nsophisticated attacks like prompt injection and response corruption to induce\nspecific, predefined error modes. We demonstrate the value of our dataset by\nexploring three distinct learning paradigms for the error identification task:\nSupervised Fine-Tuning, Reinforcement Learning, and Contrastive Learning. Our\ncomprehensive experiments show that models trained on AEGIS data achieve\nsubstantial improvements across all three learning paradigms. Notably, several\nof our fine-tuned models demonstrate performance competitive with or superior\nto proprietary systems an order of magnitude larger, validating our automated\ndata generation framework as a crucial resource for developing more robust and\ninterpretable multi-agent systems. Our project website is available at\nhttps://kfq20.github.io/AEGIS-Website.", "published": "2025-09-17 02:31:03", "link": "http://arxiv.org/abs/2509.14295v3", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Fast and explicit European option pricing under tempered stable processes", "abstract": "We provide series expansions for the tempered stable densities and for the\nprice of European-style contracts in the exponential L\\'evy model driven by the\ntempered stable process. These formulas recover several popular option pricing\nmodels, and become particularly simple in some specific cases such as bilateral\nGamma process and one-sided TS process. When compared to traditional Fourier\npricing, our method has the advantage of being hyperparameter free. We also\nprovide a detailed numerical analysis and show that our technique is\ncompetitive with state-of-the-art pricing methods.", "published": "2025-09-17 16:01:01", "link": "http://arxiv.org/abs/2510.01211v1", "categories": ["q-fin.CP", "math.PR", "60G51, 60E07, 60E10, 30B20, 91G20"], "primary_category": "q-fin.CP"}
