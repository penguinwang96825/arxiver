{"title": "PronouncUR: An Urdu Pronunciation Lexicon Generator", "abstract": "State-of-the-art speech recognition systems rely heavily on three basic\ncomponents: an acoustic model, a pronunciation lexicon and a language model. To\nbuild these components, a researcher needs linguistic as well as technical\nexpertise, which is a barrier in low-resource domains. Techniques to construct\nthese three components without having expert domain knowledge are in great\ndemand. Urdu, despite having millions of speakers all over the world, is a\nlow-resource language in terms of standard publically available linguistic\nresources. In this paper, we present a grapheme-to-phoneme conversion tool for\nUrdu that generates a pronunciation lexicon in a form suitable for use with\nspeech recognition systems from a list of Urdu words. The tool predicts the\npronunciation of words using a LSTM-based model trained on a handcrafted expert\nlexicon of around 39,000 words and shows an accuracy of 64% upon internal\nevaluation. For external evaluation on a speech recognition task, we obtain a\nword error rate comparable to one achieved using a fully handcrafted expert\nlexicon.", "published": "2018-01-01 07:54:09", "link": "http://arxiv.org/abs/1801.00409v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sanskrit Sandhi Splitting using seq2(seq)^2", "abstract": "In Sanskrit, small words (morphemes) are combined to form compound words\nthrough a process known as Sandhi. Sandhi splitting is the process of splitting\na given compound word into its constituent morphemes. Although rules governing\nword splitting exists in the language, it is highly challenging to identify the\nlocation of the splits in a compound word. Though existing Sandhi splitting\nsystems incorporate these pre-defined splitting rules, they have a low accuracy\nas the same compound word might be broken down in multiple ways to provide\nsyntactically correct splits.\n  In this research, we propose a novel deep learning architecture called Double\nDecoder RNN (DD-RNN), which (i) predicts the location of the split(s) with 95%\naccuracy, and (ii) predicts the constituent words (learning the Sandhi\nsplitting rules) with 79.5% accuracy, outperforming the state-of-art by 20%.\nAdditionally, we show the generalization capability of our deep learning model,\nby showing competitive results in the problem of Chinese word segmentation, as\nwell.", "published": "2018-01-01 11:27:05", "link": "http://arxiv.org/abs/1801.00428v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated rating of recorded classroom presentations using speech\n  analysis in kazakh", "abstract": "Effective presentation skills can help to succeed in business, career and\nacademy. This paper presents the design of speech assessment during the oral\npresentation and the algorithm for speech evaluation based on criteria of\noptimal intonation. As the pace of the speech and its optimal intonation varies\nfrom language to language, developing an automatic identification of language\nduring the presentation is required. Proposed algorithm was tested with\npresentations delivered in Kazakh language. For testing purposes the features\nof Kazakh phonemes were extracted using MFCC and PLP methods and created a\nHidden Markov Model (HMM) [5], [5] of Kazakh phonemes. Kazakh vowel formants\nwere defined and the correlation between the deviation rate in fundamental\nfrequency and the liveliness of the speech to evaluate intonation of the\npresentation was analyzed. It was established that the threshold value between\nmonotone and dynamic speech is 0.16 and the error for intonation evaluation is\n19%.", "published": "2018-01-01 14:56:56", "link": "http://arxiv.org/abs/1801.00453v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Word Embeddings: Learning Entity and Concept Representations from\n  Large Scale Knowledge Bases", "abstract": "Text representations using neural word embeddings have proven effective in\nmany NLP applications. Recent researches adapt the traditional word embedding\nmodels to learn vectors of multiword expressions (concepts/entities). However,\nthese methods are limited to textual knowledge bases (e.g., Wikipedia). In this\npaper, we propose a novel and simple technique for integrating the knowledge\nabout concepts from two large scale knowledge bases of different structure\n(Wikipedia and Probase) in order to learn concept representations. We adapt the\nefficient skip-gram model to seamlessly learn from the knowledge in Wikipedia\ntext and Probase concept graph. We evaluate our concept embedding models on two\ntasks: (1) analogical reasoning, where we achieve a state-of-the-art\nperformance of 91% on semantic analogies, (2) concept categorization, where we\nachieve a state-of-the-art performance on two benchmark datasets achieving\ncategorization accuracy of 100% on one and 98% on the other. Additionally, we\npresent a case study to evaluate our model on unsupervised argument type\nidentification for neural semantic parsing. We demonstrate the competitive\naccuracy of our unsupervised method and its ability to better generalize to out\nof vocabulary entity mentions compared to the tedious and error prone methods\nwhich depend on gazetteers and regular expressions.", "published": "2018-01-01 03:43:30", "link": "http://arxiv.org/abs/1801.00388v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
