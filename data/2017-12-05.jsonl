{"title": "AWE-CM Vectors: Augmenting Word Embeddings with a Clinical Metathesaurus", "abstract": "In recent years, word embeddings have been surprisingly effective at\ncapturing intuitive characteristics of the words they represent. These vectors\nachieve the best results when training corpora are extremely large, sometimes\nbillions of words. Clinical natural language processing datasets, however, tend\nto be much smaller. Even the largest publicly-available dataset of medical\nnotes is three orders of magnitude smaller than the dataset of the oft-used\n\"Google News\" word vectors. In order to make up for limited training data\nsizes, we encode expert domain knowledge into our embeddings. Building on a\nprevious extension of word2vec, we show that generalizing the notion of a\nword's \"context\" to include arbitrary features creates an avenue for encoding\ndomain knowledge into word embeddings. We show that the word vectors produced\nby this method outperform their text-only counterparts across the board in\ncorrelation with clinical experts.", "published": "2017-12-05 03:11:07", "link": "http://arxiv.org/abs/1712.01460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence Mining and Pattern Analysis in Drilling Reports with Deep\n  Natural Language Processing", "abstract": "Drilling activities in the oil and gas industry have been reported over\ndecades for thousands of wells on a daily basis, yet the analysis of this text\nat large-scale for information retrieval, sequence mining, and pattern analysis\nis very challenging. Drilling reports contain interpretations written by\ndrillers from noting measurements in downhole sensors and surface equipment,\nand can be used for operation optimization and accident mitigation. In this\ninitial work, a methodology is proposed for automatic classification of\nsentences written in drilling reports into three relevant labels (EVENT,\nSYMPTOM and ACTION) for hundreds of wells in an actual field. Some of the main\nchallenges in the text corpus were overcome, which include the high frequency\nof technical symbols, mistyping/abbreviation of technical terms, and the\npresence of incomplete sentences in the drilling reports. We obtain\nstate-of-the-art classification accuracy within this technical language and\nillustrate advanced queries enabled by the tool.", "published": "2017-12-05 04:49:58", "link": "http://arxiv.org/abs/1712.01476v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Semantic Role Labeling with Self-Attention", "abstract": "Semantic Role Labeling (SRL) is believed to be a crucial step towards natural\nlanguage understanding and has been widely studied. Recent years, end-to-end\nSRL with recurrent neural networks (RNN) has gained increasing attention.\nHowever, it remains a major challenge for RNNs to handle structural information\nand long range dependencies. In this paper, we present a simple and effective\narchitecture for SRL which aims to address these problems. Our model is based\non self-attention which can directly capture the relationships between two\ntokens regardless of their distance. Our single model achieves F$_1=83.4$ on\nthe CoNLL-2005 shared task dataset and F$_1=82.7$ on the CoNLL-2012 shared task\ndataset, which outperforms the previous state-of-the-art results by $1.8$ and\n$1.0$ F$_1$ score respectively. Besides, our model is computationally\nefficient, and the parsing speed is 50K tokens per second on a single Titan X\nGPU.", "published": "2017-12-05 11:48:51", "link": "http://arxiv.org/abs/1712.01586v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phylogenetics of Indo-European Language families via an\n  Algebro-Geometric Analysis of their Syntactic Structures", "abstract": "Using Phylogenetic Algebraic Geometry, we analyze computationally the\nphylogenetic tree of subfamilies of the Indo-European language family, using\ndata of syntactic structures. The two main sources of syntactic data are the\nSSWL database and Longobardi's recent data of syntactic parameters. We compute\nphylogenetic invariants and likelihood functions for two sets of Germanic\nlanguages, a set of Romance languages, a set of Slavic languages and a set of\nearly Indo-European languages, and we compare the results with what is known\nthrough historical linguistics.", "published": "2017-12-05 15:55:27", "link": "http://arxiv.org/abs/1712.01719v2", "categories": ["cs.CL", "91F20, 14M12, 92B10, 13P25"], "primary_category": "cs.CL"}
{"title": "Capturing Reliable Fine-Grained Sentiment Associations by Crowdsourcing\n  and Best-Worst Scaling", "abstract": "Access to word-sentiment associations is useful for many applications,\nincluding sentiment analysis, stance detection, and linguistic analysis.\nHowever, manually assigning fine-grained sentiment association scores to words\nhas many challenges with respect to keeping annotations consistent. We apply\nthe annotation technique of Best-Worst Scaling to obtain real-valued sentiment\nassociation scores for words and phrases in three different domains: general\nEnglish, English Twitter, and Arabic Twitter. We show that on all three domains\nthe ranking of words by sentiment remains remarkably consistent even when the\nannotation process is repeated with a different set of annotators. We also, for\nthe first time, determine the minimum difference in sentiment association that\nis perceptible to native speakers of a language.", "published": "2017-12-05 16:28:37", "link": "http://arxiv.org/abs/1712.01741v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Best-Worst Scaling More Reliable than Rating Scales: A Case Study on\n  Sentiment Intensity Annotation", "abstract": "Rating scales are a widely used method for data annotation; however, they\npresent several challenges, such as difficulty in maintaining inter- and\nintra-annotator consistency. Best-worst scaling (BWS) is an alternative method\nof annotation that is claimed to produce high-quality annotations while keeping\nthe required number of annotations similar to that of rating scales. However,\nthe veracity of this claim has never been systematically established. Here for\nthe first time, we set up an experiment that directly compares the rating scale\nmethod with BWS. We show that with the same total number of annotations, BWS\nproduces significantly more reliable results than the rating scale.", "published": "2017-12-05 17:13:48", "link": "http://arxiv.org/abs/1712.01765v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Effect of Negators, Modals, and Degree Adverbs on Sentiment\n  Composition", "abstract": "Negators, modals, and degree adverbs can significantly affect the sentiment\nof the words they modify. Often, their impact is modeled with simple\nheuristics; although, recent work has shown that such heuristics do not capture\nthe true sentiment of multi-word phrases. We created a dataset of phrases that\ninclude various negators, modals, and degree adverbs, as well as their\ncombinations. Both the phrases and their constituent content words were\nannotated with real-valued scores of sentiment association. Using phrasal terms\nin the created dataset, we analyze the impact of individual modifiers and the\naverage effect of the groups of modifiers on overall sentiment. We find that\nthe effect of modifiers varies substantially among the members of the same\ngroup. Furthermore, each individual modifier can affect sentiment words in\ndifferent ways. Therefore, solutions based on statistical learning seem more\npromising than fixed hand-crafted rules on the task of automatic sentiment\nprediction.", "published": "2017-12-05 18:17:43", "link": "http://arxiv.org/abs/1712.01794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One for All: Towards Language Independent Named Entity Linking", "abstract": "Entity linking (EL) is the task of disambiguating mentions in text by\nassociating them with entries in a predefined database of mentions (persons,\norganizations, etc). Most previous EL research has focused mainly on one\nlanguage, English, with less attention being paid to other languages, such as\nSpanish or Chinese. In this paper, we introduce LIEL, a Language Independent\nEntity Linking system, which provides an EL framework which, once trained on\none language, works remarkably well on a number of different languages without\nchange. LIEL makes a joint global prediction over the entire document,\nemploying a discriminative reranking framework with many domain and\nlanguage-independent feature functions. Experiments on numerous benchmark\ndatasets, show that the proposed system, once trained on one language, English,\noutperforms several state-of-the-art systems in English (by 4 points) and the\ntrained model also works very well on Spanish (14 points better than a\ncompetitor system), demonstrating the viability of the approach.", "published": "2017-12-05 18:21:24", "link": "http://arxiv.org/abs/1712.01797v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Cross-Lingual Entity Linking", "abstract": "A major challenge in Entity Linking (EL) is making effective use of\ncontextual information to disambiguate mentions to Wikipedia that might refer\nto different entities in different contexts. The problem exacerbates with\ncross-lingual EL which involves linking mentions written in non-English\ndocuments to entries in the English Wikipedia: to compare textual clues across\nlanguages we need to compute similarity between textual fragments across\nlanguages. In this paper, we propose a neural EL model that trains fine-grained\nsimilarities and dissimilarities between the query and candidate document from\nmultiple perspectives, combined with convolution and tensor networks. Further,\nwe show that this English-trained system can be applied, in zero-shot learning,\nto other languages by making surprisingly effective use of multi-lingual\nembeddings. The proposed system has strong empirical evidence yielding\nstate-of-the-art results in English as well as cross-lingual: Spanish and\nChinese TAC 2015 datasets.", "published": "2017-12-05 18:43:57", "link": "http://arxiv.org/abs/1712.01813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation by Generating Multiple Linguistic Factors", "abstract": "Factored neural machine translation (FNMT) is founded on the idea of using\nthe morphological and grammatical decomposition of the words (factors) at the\noutput side of the neural network. This architecture addresses two well-known\nproblems occurring in MT, namely the size of target language vocabulary and the\nnumber of unknown tokens produced in the translation. FNMT system is designed\nto manage larger vocabulary and reduce the training time (for systems with\nequivalent target language vocabulary size). Moreover, we can produce\ngrammatically correct words that are not part of the vocabulary. FNMT model is\nevaluated on IWSLT'15 English to French task and compared to the baseline\nword-based and BPE-based NMT systems. Promising qualitative and quantitative\nresults (in terms of BLEU and METEOR) are reported.", "published": "2017-12-05 18:53:49", "link": "http://arxiv.org/abs/1712.01821v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Strong Baselines for Simple Question Answering over Knowledge Graphs\n  with and without Neural Networks", "abstract": "We examine the problem of question answering over knowledge graphs, focusing\non simple questions that can be answered by the lookup of a single fact.\nAdopting a straightforward decomposition of the problem into entity detection,\nentity linking, relation prediction, and evidence combination, we explore\nsimple yet strong baselines. On the popular SimpleQuestions dataset, we find\nthat basic LSTMs and GRUs plus a few heuristics yield accuracies that approach\nthe state of the art, and techniques that do not use neural networks also\nperform reasonably well. These results show that gains from sophisticated deep\nlearning techniques proposed in the literature are quite modest and that some\nprevious models exhibit unnecessary complexity.", "published": "2017-12-05 23:38:00", "link": "http://arxiv.org/abs/1712.01969v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Storytelling via Generative Adversarial Imitation Learning", "abstract": "Deriving event storylines is an effective summarization method to succinctly\norganize extensive information, which can significantly alleviate the pain of\ninformation overload. The critical challenge is the lack of widely recognized\ndefinition of storyline metric. Prior studies have developed various approaches\nbased on different assumptions about users' interests. These works can extract\ninteresting patterns, but their assumptions do not guarantee that the derived\npatterns will match users' preference. On the other hand, their exclusiveness\nof single modality source misses cross-modality information. This paper\nproposes a method, multimodal imitation learning via generative adversarial\nnetworks(MIL-GAN), to directly model users' interests as reflected by various\ndata. In particular, the proposed model addresses the critical challenge by\nimitating users' demonstrated storylines. Our proposed model is designed to\nlearn the reward patterns given user-provided storylines and then applies the\nlearned policy to unseen data. The proposed approach is demonstrated to be\ncapable of acquiring the user's implicit intent and outperforming competing\nmethods by a substantial margin with a user study.", "published": "2017-12-05 02:51:35", "link": "http://arxiv.org/abs/1712.01455v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "EmTaggeR: A Word Embedding Based Novel Method for Hashtag Recommendation\n  on Twitter", "abstract": "The hashtag recommendation problem addresses recommending (suggesting) one or\nmore hashtags to explicitly tag a post made on a given social network platform,\nbased upon the content and context of the post. In this work, we propose a\nnovel methodology for hashtag recommendation for microblog posts, specifically\nTwitter. The methodology, EmTaggeR, is built upon a training-testing framework\nthat builds on the top of the concept of word embedding. The training phase\ncomprises of learning word vectors associated with each hashtag, and deriving a\nword embedding for each hashtag. We provide two training procedures, one in\nwhich each hashtag is trained with a separate word embedding model applicable\nin the context of that hashtag, and another in which each hashtag obtains its\nembedding from a global context. The testing phase constitutes computing the\naverage word embedding of the test post, and finding the similarity of this\nembedding with the known embeddings of the hashtags. The tweets that contain\nthe most-similar hashtag are extracted, and all the hashtags that appear in\nthese tweets are ranked in terms of embedding similarity scores. The top-K\nhashtags that appear in this ranked list, are recommended for the given test\npost. Our system produces F1 score of 50.83%, improving over the LDA baseline\nby around 6.53 times, outperforming the best-performing system known in the\nliterature that provides a lift of 6.42 times. EmTaggeR is a fast, scalable and\nlightweight system, which makes it practical to deploy in real-life\napplications.", "published": "2017-12-05 10:29:14", "link": "http://arxiv.org/abs/1712.01562v1", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "State-of-the-art Speech Recognition With Sequence-to-Sequence Models", "abstract": "Attention-based encoder-decoder architectures such as Listen, Attend, and\nSpell (LAS), subsume the acoustic, pronunciation and language model components\nof a traditional automatic speech recognition (ASR) system into a single neural\nnetwork. In previous work, we have shown that such architectures are comparable\nto state-of-theart ASR systems on dictation tasks, but it was not clear if such\narchitectures would be practical for more challenging tasks such as voice\nsearch. In this work, we explore a variety of structural and optimization\nimprovements to our LAS model which significantly improve performance. On the\nstructural side, we show that word piece models can be used instead of\ngraphemes. We also introduce a multi-head attention architecture, which offers\nimprovements over the commonly-used single-head attention. On the optimization\nside, we explore synchronous training, scheduled sampling, label smoothing, and\nminimum word error rate optimization, which are all shown to improve accuracy.\nWe present results with a unidirectional LSTM encoder for streaming\nrecognition. On a 12, 500 hour voice search task, we find that the proposed\nchanges improve the WER from 9.2% to 5.6%, while the best conventional system\nachieves 6.7%; on a dictation task our model achieves a WER of 4.1% compared to\n5% for the conventional system.", "published": "2017-12-05 17:24:05", "link": "http://arxiv.org/abs/1712.01769v6", "categories": ["cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Improving the Performance of Online Neural Transducer Models", "abstract": "Having a sequence-to-sequence model which can operate in an online fashion is\nimportant for streaming applications such as Voice Search. Neural transducer is\na streaming sequence-to-sequence model, but has shown a significant degradation\nin performance compared to non-streaming models such as Listen, Attend and\nSpell (LAS). In this paper, we present various improvements to NT.\nSpecifically, we look at increasing the window over which NT computes\nattention, mainly by looking backwards in time so the model still remains\nonline. In addition, we explore initializing a NT model from a LAS-trained\nmodel so that it is guided with a better alignment. Finally, we explore\nincluding stronger language models such as using wordpiece models, and applying\nan external LM during the beam search. On a Voice Search task, we find with\nthese improvements we can get NT to match the performance of LAS.", "published": "2017-12-05 18:34:56", "link": "http://arxiv.org/abs/1712.01807v1", "categories": ["cs.CL", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Minimum Word Error Rate Training for Attention-based\n  Sequence-to-Sequence Models", "abstract": "Sequence-to-sequence models, such as attention-based models in automatic\nspeech recognition (ASR), are typically trained to optimize the cross-entropy\ncriterion which corresponds to improving the log-likelihood of the data.\nHowever, system performance is usually measured in terms of word error rate\n(WER), not log-likelihood. Traditional ASR systems benefit from discriminative\nsequence training which optimizes criteria such as the state-level minimum\nBayes risk (sMBR) which are more closely related to WER. In the present work,\nwe explore techniques to train attention-based models to directly minimize\nexpected word error rate. We consider two loss functions which approximate the\nexpected number of word errors: either by sampling from the model, or by using\nN-best lists of decoded hypotheses, which we find to be more effective than the\nsampling-based method. In experimental evaluations, we find that the proposed\ntraining procedure improves performance by up to 8.2% relative to the baseline\nsystem. This allows us to train grapheme-based, uni-directional attention-based\nmodels which match the performance of a traditional, state-of-the-art,\ndiscriminative sequence-trained system on a mobile voice-search task.", "published": "2017-12-05 18:52:18", "link": "http://arxiv.org/abs/1712.01818v1", "categories": ["cs.CL", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "No Need for a Lexicon? Evaluating the Value of the Pronunciation Lexica\n  in End-to-End Models", "abstract": "For decades, context-dependent phonemes have been the dominant sub-word unit\nfor conventional acoustic modeling systems. This status quo has begun to be\nchallenged recently by end-to-end models which seek to combine acoustic,\npronunciation, and language model components into a single neural network. Such\nsystems, which typically predict graphemes or words, simplify the recognition\nprocess since they remove the need for a separate expert-curated pronunciation\nlexicon to map from phoneme-based units to words. However, there has been\nlittle previous work comparing phoneme-based versus grapheme-based sub-word\nunits in the end-to-end modeling framework, to determine whether the gains from\nsuch approaches are primarily due to the new probabilistic model, or from the\njoint learning of the various components with grapheme-based units.\n  In this work, we conduct detailed experiments which are aimed at quantifying\nthe value of phoneme-based pronunciation lexica in the context of end-to-end\nmodels. We examine phoneme-based end-to-end models, which are contrasted\nagainst grapheme-based ones on a large vocabulary English Voice-search task,\nwhere we find that graphemes do indeed outperform phonemes. We also compare\ngrapheme and phoneme-based approaches on a multi-dialect English task, which\nonce again confirm the superiority of graphemes, greatly simplifying the system\nfor recognizing multiple dialects.", "published": "2017-12-05 19:02:28", "link": "http://arxiv.org/abs/1712.01864v1", "categories": ["cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "FlagIt: A System for Minimally Supervised Human Trafficking Indicator\n  Mining", "abstract": "In this paper, we describe and study the indicator mining problem in the\nonline sex advertising domain. We present an in-development system, FlagIt\n(Flexible and adaptive generation of Indicators from text), which combines the\nbenefits of both a lightweight expert system and classical semi-supervision\n(heuristic re-labeling) with recently released state-of-the-art unsupervised\ntext embeddings to tag millions of sentences with indicators that are highly\ncorrelated with human trafficking. The FlagIt technology stack is open source.\nOn preliminary evaluations involving five indicators, FlagIt illustrates\npromising performance compared to several alternatives. The system is being\nactively developed, refined and integrated into a domain-specific search system\nused by over 200 law enforcement agencies to combat human trafficking, and is\nbeing aggressively extended to mine at least six more indicators with minimal\nprogramming effort. FlagIt is a good example of a system that operates in\nlimited label settings, and that requires creative combinations of established\nmachine learning techniques to produce outputs that could be used by real-world\nnon-technical analysts.", "published": "2017-12-05 21:15:48", "link": "http://arxiv.org/abs/1712.03086v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Multi-Dialect Speech Recognition With A Single Sequence-To-Sequence\n  Model", "abstract": "Sequence-to-sequence models provide a simple and elegant solution for\nbuilding speech recognition systems by folding separate components of a typical\nsystem, namely acoustic (AM), pronunciation (PM) and language (LM) models into\na single neural network. In this work, we look at one such sequence-to-sequence\nmodel, namely listen, attend and spell (LAS), and explore the possibility of\ntraining a single model to serve different English dialects, which simplifies\nthe process of training multi-dialect systems without the need for separate AM,\nPM and LMs for each dialect. We show that simply pooling the data from all\ndialects into one LAS model falls behind the performance of a model fine-tuned\non each dialect. We then look at incorporating dialect-specific information\ninto the model, both by modifying the training targets by inserting the dialect\nsymbol at the end of the original grapheme sequence and also feeding a 1-hot\nrepresentation of the dialect information into all layers of the model.\nExperimental results on seven English dialects show that our proposed system is\neffective in modeling dialect variations within a single LAS model,\noutperforming a LAS model trained individually on each of the seven dialects by\n3.1 ~ 16.5% relative.", "published": "2017-12-05 09:39:18", "link": "http://arxiv.org/abs/1712.01541v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-speaker Recognition in Cocktail Party Problem", "abstract": "This paper proposes an original statistical decision theory to accomplish a\nmulti-speaker recognition task in cocktail party problem. This theory relies on\nan assumption that the varied frequencies of speakers obey Gaussian\ndistribution and the relationship of their voiceprints can be represented by\nEuclidean distance vectors. This paper uses Mel-Frequency Cepstral Coefficients\nto extract the feature of a voice in judging whether a speaker is included in a\nmulti-speaker environment and distinguish who the speaker should be. Finally, a\nthirteen-dimension constellation drawing is established by mapping from\nManhattan distances of speakers in order to take a thorough consideration about\ngross influential factors.", "published": "2017-12-05 16:28:51", "link": "http://arxiv.org/abs/1712.01742v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Learning to Fuse Music Genres with Generative Adversarial Dual Learning", "abstract": "FusionGAN is a novel genre fusion framework for music generation that\nintegrates the strengths of generative adversarial networks and dual learning.\nIn particular, the proposed method offers a dual learning extension that can\neffectively integrate the styles of the given domains. To efficiently quantify\nthe difference among diverse domains and avoid the vanishing gradient issue,\nFusionGAN provides a Wasserstein based metric to approximate the distance\nbetween the target domain and the existing domains. Adopting the Wasserstein\ndistance, a new domain is created by combining the patterns of the existing\ndomains using adversarial learning. Experimental results on public music\ndatasets demonstrated that our approach could effectively merge two genres.", "published": "2017-12-05 02:53:27", "link": "http://arxiv.org/abs/1712.01456v1", "categories": ["cs.LG", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
