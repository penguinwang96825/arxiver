{"title": "Generative Adversarial Zero-Shot Relational Learning for Knowledge\n  Graphs", "abstract": "Large-scale knowledge graphs (KGs) are shown to become more important in\ncurrent information systems. To expand the coverage of KGs, previous studies on\nknowledge graph completion need to collect adequate training instances for\nnewly-added relations. In this paper, we consider a novel formulation,\nzero-shot learning, to free this cumbersome curation. For newly-added\nrelations, we attempt to learn their semantic features from their text\ndescriptions and hence recognize the facts of unseen relations with no examples\nbeing seen. For this purpose, we leverage Generative Adversarial Networks\n(GANs) to establish the connection between text and knowledge graph domain: The\ngenerator learns to generate the reasonable relation embeddings merely with\nnoisy text descriptions. Under this setting, zero-shot learning is naturally\nconverted to a traditional supervised classification task. Empirically, our\nmethod is model-agnostic that could be potentially applied to any version of KG\nembeddings, and consistently yields performance improvements on NELL and Wiki\ndataset.", "published": "2020-01-08 01:19:08", "link": "http://arxiv.org/abs/2001.02332v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Neural Approach to Discourse Relation Signal Detection", "abstract": "Previous data-driven work investigating the types and distributions of\ndiscourse relation signals, including discourse markers such as 'however' or\nphrases such as 'as a result' has focused on the relative frequencies of signal\nwords within and outside text from each discourse relation. Such approaches do\nnot allow us to quantify the signaling strength of individual instances of a\nsignal on a scale (e.g. more or less discourse-relevant instances of 'and'), to\nassess the distribution of ambiguity for signals, or to identify words that\nhinder discourse relation identification in context ('anti-signals' or\n'distractors'). In this paper we present a data-driven approach to signal\ndetection using a distantly supervised neural network and develop a metric,\nDelta s (or 'delta-softmax'), to quantify signaling strength. Ranging between\n-1 and 1 and relying on recent advances in contextualized words embeddings, the\nmetric represents each word's positive or negative contribution to the\nidentifiability of a relation in specific instances in context. Based on an\nEnglish corpus annotated for discourse relations using Rhetorical Structure\nTheory and signal type annotations anchored to specific tokens, our analysis\nexamines the reliability of the metric, the places where it overlaps with and\ndiffers from human judgments, and the implications for identifying features\nthat neural models may need in order to perform better on automatic discourse\nrelation classification.", "published": "2020-01-08 05:14:49", "link": "http://arxiv.org/abs/2001.02380v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LTP: A New Active Learning Strategy for CRF-Based Named Entity\n  Recognition", "abstract": "In recent years, deep learning has achieved great success in many natural\nlanguage processing tasks including named entity recognition. The shortcoming\nis that a large amount of manually-annotated data is usually required. Previous\nstudies have demonstrated that active learning could elaborately reduce the\ncost of data annotation, but there is still plenty of room for improvement. In\nreal applications we found existing uncertainty-based active learning\nstrategies have two shortcomings. Firstly, these strategies prefer to choose\nlong sequence explicitly or implicitly, which increase the annotation burden of\nannotators. Secondly, some strategies need to invade the model and modify to\ngenerate some additional information for sample selection, which will increase\nthe workload of the developer and increase the training/prediction time of the\nmodel. In this paper, we first examine traditional active learning strategies\nin a specific case of BiLstm-CRF that has widely used in named entity\nrecognition on several typical datasets. Then we propose an uncertainty-based\nactive learning strategy called Lowest Token Probability (LTP) which combines\nthe input and output of CRF to select informative instance. LTP is simple and\npowerful strategy that does not favor long sequences and does not need to\ninvade the model. We test LTP on multiple datasets, and the experiments show\nthat LTP performs slightly better than traditional strategies with obviously\nless annotation tokens on both sentence-level accuracy and entity-level\nF1-score. Related code have been release on https://github.com/HIT-ICES/AL-NER", "published": "2020-01-08 13:44:10", "link": "http://arxiv.org/abs/2001.02524v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Natural Language Instructions to Complex Processes: Issues in\n  Chaining Trigger Action Rules", "abstract": "Automation services for complex business processes usually require a high\nlevel of information technology literacy. There is a strong demand for a\nsmartly assisted process automation (IPA: intelligent process automation)\nservice that enables even general users to easily use advanced automation. A\nnatural language interface for such automation is expected as an elemental\ntechnology for the IPA realization. The workflow targeted by IPA is generally\ncomposed of a combination of multiple tasks. However, semantic parsing, one of\nthe natural language processing methods, for such complex workflows has not yet\nbeen fully studied. The reasons are that (1) the formal expression and grammar\nof the workflow required for semantic analysis have not been sufficiently\nexamined and (2) the dataset of the workflow formal expression with its\ncorresponding natural language description required for learning workflow\nsemantics did not exist. This paper defines a new grammar for complex workflows\nwith chaining machine-executable meaning representations for semantic parsing.\nThe representations are at a high abstraction level. Additionally, an approach\nto creating datasets is proposed based on this grammar.", "published": "2020-01-08 11:44:47", "link": "http://arxiv.org/abs/2001.02462v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "REST: A Thread Embedding Approach for Identifying and Classifying\n  User-specified Information in Security Forums", "abstract": "How can we extract useful information from a security forum? We focus on\nidentifying threads of interest to a security professional: (a) alerts of\nworrisome events, such as attacks, (b) offering of malicious services and\nproducts, (c) hacking information to perform malicious acts, and (d) useful\nsecurity-related experiences. The analysis of security forums is in its infancy\ndespite several promising recent works. Novel approaches are needed to address\nthe challenges in this domain: (a) the difficulty in specifying the \"topics\" of\ninterest efficiently, and (b) the unstructured and informal nature of the text.\nWe propose, REST, a systematic methodology to: (a) identify threads of interest\nbased on a, possibly incomplete, bag of words, and (b) classify them into one\nof the four classes above. The key novelty of the work is a multi-step weighted\nembedding approach: we project words, threads and classes in appropriate\nembedding spaces and establish relevance and similarity there. We evaluate our\nmethod with real data from three security forums with a total of 164k posts and\n21K threads. First, REST robustness to initial keyword selection can extend the\nuser-provided keyword set and thus, it can recover from missing keywords.\nSecond, REST categorizes the threads into the classes of interest with superior\naccuracy compared to five other methods: REST exhibits an accuracy between\n63.3-76.9%. We see our approach as a first step for harnessing the wealth of\ninformation of online forums in a user-friendly way, since the user can loosely\nspecify her keywords of interest.", "published": "2020-01-08 18:04:52", "link": "http://arxiv.org/abs/2001.02660v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "SirenLess: reveal the intention behind news", "abstract": "News articles tend to be increasingly misleading nowadays, preventing readers\nfrom making subjective judgments towards certain events. While some machine\nlearning approaches have been proposed to detect misleading news, most of them\nare black boxes that provide limited help for humans in decision making. In\nthis paper, we present SirenLess, a visual analytical system for misleading\nnews detection by linguistic features. The system features article explorer, a\nnovel interactive tool that integrates news metadata and linguistic features to\nreveal semantic structures of news articles and facilitate textual analysis. We\nuse SirenLess to analyze 18 news articles from different sources and summarize\nsome helpful patterns for misleading news detection. A user study with\njournalism professionals and university students is conducted to confirm the\nusefulness and effectiveness of our system.", "published": "2020-01-08 20:36:17", "link": "http://arxiv.org/abs/2001.02731v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "A Correspondence Analysis Framework for Author-Conference\n  Recommendations", "abstract": "For many years, achievements and discoveries made by scientists are made\naware through research papers published in appropriate journals or conferences.\nOften, established scientists and especially newbies are caught up in the\ndilemma of choosing an appropriate conference to get their work through. Every\nscientific conference and journal is inclined towards a particular field of\nresearch and there is a vast multitude of them for any particular field.\nChoosing an appropriate venue is vital as it helps in reaching out to the right\naudience and also to further one's chance of getting their paper published. In\nthis work, we address the problem of recommending appropriate conferences to\nthe authors to increase their chances of acceptance. We present three different\napproaches for the same involving the use of social network of the authors and\nthe content of the paper in the settings of dimensionality reduction and topic\nmodeling. In all these approaches, we apply Correspondence Analysis (CA) to\nderive appropriate relationships between the entities in question, such as\nconferences and papers. Our models show promising results when compared with\nexisting methods such as content-based filtering, collaborative filtering and\nhybrid filtering.", "published": "2020-01-08 18:52:39", "link": "http://arxiv.org/abs/2001.02669v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "cs.SI", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Streaming automatic speech recognition with the transformer model", "abstract": "Encoder-decoder based sequence-to-sequence models have demonstrated\nstate-of-the-art results in end-to-end automatic speech recognition (ASR).\nRecently, the transformer architecture, which uses self-attention to model\ntemporal context information, has been shown to achieve significantly lower\nword error rates (WERs) compared to recurrent neural network (RNN) based system\narchitectures. Despite its success, the practical usage is limited to offline\nASR tasks, since encoder-decoder architectures typically require an entire\nspeech utterance as input. In this work, we propose a transformer based\nend-to-end ASR system for streaming ASR, where an output must be generated\nshortly after each spoken word. To achieve this, we apply time-restricted\nself-attention for the encoder and triggered attention for the encoder-decoder\nattention mechanism. Our proposed streaming transformer architecture achieves\n2.8% and 7.2% WER for the \"clean\" and \"other\" test data of LibriSpeech, which\nto our knowledge is the best published streaming end-to-end ASR result for this\ntask.", "published": "2020-01-08 18:58:02", "link": "http://arxiv.org/abs/2001.02674v5", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Audio Inpainting: Revisited and Reweighted", "abstract": "We deal with the problem of sparsity-based audio inpainting, i.e. filling in\nthe missing segments of audio. A consequence of the approaches based on\nmathematical optimization is the insufficient amplitude of the signal in the\nfilled gaps. Remaining in the framework based on sparsity and convex\noptimization, we propose improvements to audio inpainting, aiming at\ncompensating for such an energy loss. The new ideas are based on different\ntypes of weighting, both in the coefficient and the time domains. We show that\nour propositions improve the inpainting performance in terms of both the SNR\nand ODG.", "published": "2020-01-08 12:36:34", "link": "http://arxiv.org/abs/2001.02480v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Emo-CNN for Perceiving Stress from Audio Signals: A Brain Chemistry\n  Approach", "abstract": "Emotion plays a key role in many applications like healthcare, to gather\npatients emotional behavior. There are certain emotions which are given more\nimportance due to their effectiveness in understanding human feelings. In this\npaper, we propose an approach that models human stress from audio signals. The\nresearch challenge in speech emotion detection is defining the very meaning of\nstress and being able to categorize it in a precise manner. Supervised Machine\nLearning models, including state of the art Deep Learning classification\nmethods, rely on the availability of clean and labelled data. One of the\nproblems in affective computation and emotion detection is the limited amount\nof annotated data of stress. The existing labelled stress emotion datasets are\nhighly subjective to the perception of the annotator.\n  We address the first issue of feature selection by exploiting the use of\ntraditional MFCC features in Convolutional Neural Network. Our experiments show\nthat Emo-CNN consistently and significantly outperforms the popular existing\nmethods over multiple datasets. It achieves 90.2% categorical accuracy on the\nEmo-DB dataset. To tackle the second and the more significant problem of\nsubjectivity in stress labels, we use Lovheim's cube, which is a 3-dimensional\nprojection of emotions. The cube aims at explaining the relationship between\nthese neurotransmitters and the positions of emotions in 3D space. The learnt\nemotion representations from the Emo-CNN are mapped to the cube using three\ncomponent PCA (Principal Component Analysis) which is then used to model human\nstress. This proposed approach not only circumvents the need for labelled\nstress data but also complies with the psychological theory of emotions given\nby Lovheim's cube. We believe that this work is the first step towards creating\na connection between Artificial Intelligence and the chemistry of human\nemotions.", "published": "2020-01-08 01:01:48", "link": "http://arxiv.org/abs/2001.02329v1", "categories": ["cs.HC", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Automatic Melody Harmonization with Triad Chords: A Comparative Study", "abstract": "Several prior works have proposed various methods for the task of automatic\nmelody harmonization, in which a model aims to generate a sequence of chords to\nserve as the harmonic accompaniment of a given multiple-bar melody sequence. In\nthis paper, we present a comparative study evaluating and comparing the\nperformance of a set of canonical approaches to this task, including a template\nmatching based model, a hidden Markov based model, a genetic algorithm based\nmodel, and two deep learning based models. The evaluation is conducted on a\ndataset of 9,226 melody/chord pairs we newly collect for this study,\nconsidering up to 48 triad chords, using a standardized training/test split. We\nreport the result of an objective evaluation using six different metrics and a\nsubjective study with 202 participants.", "published": "2020-01-08 03:47:33", "link": "http://arxiv.org/abs/2001.02360v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
