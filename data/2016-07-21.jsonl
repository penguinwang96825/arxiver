{"title": "Exploring phrase-compositionality in skip-gram models", "abstract": "In this paper, we introduce a variation of the skip-gram model which jointly\nlearns distributed word vector representations and their way of composing to\nform phrase embeddings. In particular, we propose a learning procedure that\nincorporates a phrase-compositionality function which can capture how we want\nto compose phrases vectors from their component word vectors. Our experiments\nshow improvement in word and phrase similarity tasks as well as syntactic tasks\nlike dependency parsing using the proposed joint models.", "published": "2016-07-21 06:49:02", "link": "http://arxiv.org/abs/1607.06208v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Perspective on Sentiment Analysis", "abstract": "Sentiment Analysis (SA) is indeed a fascinating area of research which has\nstolen the attention of researchers as it has many facets and more importantly\nit promises economic stakes in the corporate and governance sector. SA has been\nstemmed out of text analytics and established itself as a separate identity and\na domain of research. The wide ranging results of SA have proved to influence\nthe way some critical decisions are taken. Hence, it has become relevant in\nthorough understanding of the different dimensions of the input, output and the\nprocesses and approaches of SA.", "published": "2016-07-21 07:48:08", "link": "http://arxiv.org/abs/1607.06221v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Opinion Mining in Online Reviews About Distance Education Programs", "abstract": "The popularity of distance education programs is increasing at a fast pace.\nEn par with this development, online communication in fora, social media and\nreviewing platforms between students is increasing as well. Exploiting this\ninformation to support fellow students or institutions requires to extract the\nrelevant opinions in order to automatically generate reports providing an\noverview of pros and cons of different distance education programs. We report\non an experiment involving distance education experts with the goal to develop\na dataset of reviews annotated with relevant categories and aspects in each\ncategory discussed in the specific review together with an indication of the\nsentiment.\n  Based on this experiment, we present an approach to extract general\ncategories and specific aspects under discussion in a review together with\ntheir sentiment. We frame this task as a multi-label hierarchical text\nclassification problem and empirically investigate the performance of different\nclassification architectures to couple the prediction of a category with the\nprediction of particular aspects in this category. We evaluate different\narchitectures and show that a hierarchical approach leads to superior results\nin comparison to a flat model which makes decisions independently.", "published": "2016-07-21 12:43:21", "link": "http://arxiv.org/abs/1607.06299v1", "categories": ["cs.CL", "68T50", "K.3.1; I.2.7; H.2.8"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey on Cross-modal Retrieval", "abstract": "In recent years, cross-modal retrieval has drawn much attention due to the\nrapid growth of multimodal data. It takes one type of data as the query to\nretrieve relevant data of another type. For example, a user can use a text to\nretrieve relevant pictures or videos. Since the query and its retrieved results\ncan be of different modalities, how to measure the content similarity between\ndifferent modalities of data remains a challenge. Various methods have been\nproposed to deal with such a problem. In this paper, we first review a number\nof representative methods for cross-modal retrieval and classify them into two\nmain groups: 1) real-valued representation learning, and 2) binary\nrepresentation learning. Real-valued representation learning methods aim to\nlearn real-valued common representations for different modalities of data. To\nspeed up the cross-modal retrieval, a number of binary representation learning\nmethods are proposed to map different modalities of data into a common Hamming\nspace. Then, we introduce several multimodal datasets in the community, and\nshow the experimental results on two commonly used multimodal datasets. The\ncomparison reveals the characteristic of different kinds of cross-modal\nretrieval methods, which is expected to benefit both practical applications and\nfuture research. Finally, we discuss open problems and future research\ndirections.", "published": "2016-07-21 07:20:44", "link": "http://arxiv.org/abs/1607.06215v1", "categories": ["cs.MM", "cs.CL", "cs.IR"], "primary_category": "cs.MM"}
{"title": "Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain\n  Factoid Question Answering", "abstract": "While question answering (QA) with neural network, i.e. neural QA, has\nachieved promising results in recent years, lacking of large scale real-word QA\ndataset is still a challenge for developing and evaluating neural QA system. To\nalleviate this problem, we propose a large scale human annotated real-world QA\ndataset WebQA with more than 42k questions and 556k evidences. As existing\nneural QA methods resolve QA either as sequence generation or\nclassification/ranking problem, they face challenges of expensive softmax\ncomputation, unseen answers handling or separate candidate answer generation\ncomponent. In this work, we cast neural QA as a sequence labeling problem and\npropose an end-to-end sequence labeling model, which overcomes all the above\nchallenges. Experimental results on WebQA show that our model outperforms the\nbaselines significantly with an F1 score of 74.69% with word-based input, and\nthe performance drops only 3.72 F1 points with more challenging character-based\ninput.", "published": "2016-07-21 11:40:50", "link": "http://arxiv.org/abs/1607.06275v2", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word\n  Embeddings", "abstract": "The blind application of machine learning runs the risk of amplifying biases\npresent in data. Such a danger is facing us with word embedding, a popular\nframework to represent text data as vectors which has been used in many machine\nlearning and natural language processing tasks. We show that even word\nembeddings trained on Google News articles exhibit female/male gender\nstereotypes to a disturbing extent. This raises concerns because their\nwidespread use, as we describe, often tends to amplify these biases.\nGeometrically, gender bias is first shown to be captured by a direction in the\nword embedding. Second, gender neutral words are shown to be linearly separable\nfrom gender definition words in the word embedding. Using these properties, we\nprovide a methodology for modifying an embedding to remove gender stereotypes,\nsuch as the association between between the words receptionist and female,\nwhile maintaining desired associations such as between the words queen and\nfemale. We define metrics to quantify both direct and indirect gender biases in\nembeddings, and develop algorithms to \"debias\" the embedding. Using\ncrowd-worker evaluation as well as standard benchmarks, we empirically\ndemonstrate that our algorithms significantly reduce gender bias in embeddings\nwhile preserving the its useful properties such as the ability to cluster\nrelated concepts and to solve analogy tasks. The resulting embeddings can be\nused in applications without amplifying gender bias.", "published": "2016-07-21 22:26:20", "link": "http://arxiv.org/abs/1607.06520v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
