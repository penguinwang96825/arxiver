{"title": "Why Does Surprisal From Larger Transformer-Based Language Models Provide\n  a Poorer Fit to Human Reading Times?", "abstract": "This work presents a detailed linguistic analysis into why larger\nTransformer-based pre-trained language models with more parameters and lower\nperplexity nonetheless yield surprisal estimates that are less predictive of\nhuman reading times. First, regression analyses show a strictly monotonic,\npositive log-linear relationship between perplexity and fit to reading times\nfor the more recently released five GPT-Neo variants and eight OPT variants on\ntwo separate datasets, replicating earlier results limited to just GPT-2 (Oh et\nal., 2022). Subsequently, analysis of residual errors reveals a systematic\ndeviation of the larger variants, such as underpredicting reading times of\nnamed entities and making compensatory overpredictions for reading times of\nfunction words such as modals and conjunctions. These results suggest that the\npropensity of larger Transformer-based models to 'memorize' sequences during\ntraining makes their surprisal estimates diverge from humanlike expectations,\nwhich warrants caution in using pre-trained language models to study human\nlanguage processing.", "published": "2022-12-23 03:57:54", "link": "http://arxiv.org/abs/2212.12131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dubbing in Practice: A Large Scale Study of Human Localization With\n  Insights for Automatic Dubbing", "abstract": "We investigate how humans perform the task of dubbing video content from one\nlanguage into another, leveraging a novel corpus of 319.57 hours of video from\n54 professionally produced titles. This is the first such large-scale study we\nare aware of. The results challenge a number of assumptions commonly made in\nboth qualitative literature on human dubbing and machine-learning literature on\nautomatic dubbing, arguing for the importance of vocal naturalness and\ntranslation quality over commonly emphasized isometric (character length) and\nlip-sync constraints, and for a more qualified view of the importance of\nisochronic (timing) constraints. We also find substantial influence of the\nsource-side audio on human dubs through channels other than the words of the\ntranslation, pointing to the need for research on ways to preserve speech\ncharacteristics, as well as semantic transfer such as emphasis/emotion, in\nautomatic dubbing systems.", "published": "2022-12-23 04:12:52", "link": "http://arxiv.org/abs/2212.12137v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CinPatent: Datasets for Patent Classification", "abstract": "Patent classification is the task that assigns each input patent into several\ncodes (classes). Due to its high demand, several datasets and methods have been\nintroduced. However, the lack of both systematic performance comparison of\nbaselines and access to some datasets creates a gap for the task. To fill the\ngap, we introduce two new datasets in English and Japanese collected by using\nCPC codes. The English dataset includes 45,131 patent documents with 425 labels\nand the Japanese dataset contains 54,657 documents with 523 labels. To\nfacilitate the next studies, we compare the performance of strong multi-label\ntext classification methods on the two datasets. Experimental results show that\nAttentionXML is consistently better than other strong baselines. The ablation\nstudy is also conducted in two aspects: the contribution of different parts\n(title, abstract, description, and claims) of a patent and the behavior of\nbaselines in terms of performance with different training data segmentation. We\nrelease the two new datasets with the code of the baselines.", "published": "2022-12-23 08:23:32", "link": "http://arxiv.org/abs/2212.12192v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discovering Customer-Service Dialog System with Semi-Supervised Learning\n  and Coarse-to-Fine Intent Detection", "abstract": "Task-oriented dialog(TOD) aims to assist users in achieving specific goals\nthrough multi-turn conversation. Recently, good results have been obtained\nbased on large pre-trained models. However, the labeled-data scarcity hinders\nthe efficient development of TOD systems at scale. In this work, we constructed\na weakly supervised dataset based on a teacher/student paradigm that leverages\na large collection of unlabelled dialogues. Furthermore, we built a modular\ndialogue system and integrated coarse-to-fine grained classification for user\nintent detection. Experiments show that our method can reach the dialog goal\nwith a higher success rate and generate more coherent responses.", "published": "2022-12-23 14:36:43", "link": "http://arxiv.org/abs/2212.12363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalizable Natural Language Processing Framework for Migraine\n  Reporting from Social Media", "abstract": "Migraine is a high-prevalence and disabling neurological disorder. However,\ninformation migraine management in real-world settings could be limited to\ntraditional health information sources. In this paper, we (i) verify that there\nis substantial migraine-related chatter available on social media (Twitter and\nReddit), self-reported by migraine sufferers; (ii) develop a\nplatform-independent text classification system for automatically detecting\nself-reported migraine-related posts, and (iii) conduct analyses of the\nself-reported posts to assess the utility of social media for studying this\nproblem. We manually annotated 5750 Twitter posts and 302 Reddit posts. Our\nsystem achieved an F1 score of 0.90 on Twitter and 0.93 on Reddit. Analysis of\ninformation posted by our 'migraine cohort' revealed the presence of a plethora\nof relevant information about migraine therapies and patient sentiments\nassociated with them. Our study forms the foundation for conducting an in-depth\nanalysis of migraine-related information using social media data.", "published": "2022-12-23 16:29:34", "link": "http://arxiv.org/abs/2212.12454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Content Rating Classification for Fan Fiction", "abstract": "Content ratings can enable audiences to determine the suitability of various\nmedia products. With the recent advent of fan fiction, the critical issue of\nfan fiction content ratings has emerged. Whether fan fiction content ratings\nare done voluntarily or required by regulation, there is the need to automate\nthe content rating classification. The problem is to take fan fiction text and\ndetermine the appropriate content rating. Methods for other domains, such as\nonline books, have been attempted though none have been applied to fan fiction.\nWe propose natural language processing techniques, including traditional and\ndeep learning methods, to automatically determine the content rating. We show\nthat these methods produce poor accuracy results for multi-classification. We\nthen demonstrate that treating the problem as a binary classification problem\nproduces better accuracy. Finally, we believe and provide some evidence that\nthe current approach of self-annotating has led to incorrect labels limiting\nclassification results.", "published": "2022-12-23 17:40:03", "link": "http://arxiv.org/abs/2212.12496v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MicroBERT: Effective Training of Low-resource Monolingual BERTs through\n  Parameter Reduction and Multitask Learning", "abstract": "Transformer language models (TLMs) are critical for most NLP tasks, but they\nare difficult to create for low-resource languages because of how much\npretraining data they require. In this work, we investigate two techniques for\ntraining monolingual TLMs in a low-resource setting: greatly reducing TLM size,\nand complementing the masked language modeling objective with two\nlinguistically rich supervised tasks (part-of-speech tagging and dependency\nparsing). Results from 7 diverse languages indicate that our model, MicroBERT,\nis able to produce marked improvements in downstream task evaluations relative\nto a typical monolingual TLM pretraining approach. Specifically, we find that\nmonolingual MicroBERT models achieve gains of up to 18% for parser LAS and 11%\nfor NER F1 compared to a multilingual baseline, mBERT, while having less than\n1% of its parameter count. We conclude reducing TLM parameter count and using\nlabeled data for pretraining low-resource TLMs can yield large quality benefits\nand in some cases produce models that outperform multilingual approaches.", "published": "2022-12-23 18:18:20", "link": "http://arxiv.org/abs/2212.12510v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Transition-based Parsing of Library Deprecations", "abstract": "This paper tackles the challenging problem of automating code updates to fix\ndeprecated API usages of open source libraries by analyzing their release\nnotes. Our system employs a three-tier architecture: first, a web crawler\nservice retrieves deprecation documentation from the web; then a specially\nbuilt parser processes those text documents into tree-structured\nrepresentations; finally, a client IDE plugin locates and fixes identified\ndeprecated usages of libraries in a given codebase. The focus of this paper in\nparticular is the parsing component. We introduce a novel transition-based\nparser in two variants: based on a classical feature engineered classifier and\na neural tree encoder. To confirm the effectiveness of our method, we gathered\nand labeled a set of 426 API deprecations from 7 well-known Python data science\nlibraries, and demonstrated our approach decisively outperforms a non-trivial\nneural machine translation baseline.", "published": "2022-12-23 20:48:33", "link": "http://arxiv.org/abs/2212.12584v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finetuning for Sarcasm Detection with a Pruned Dataset", "abstract": "Sarcasm is a form of irony that involves saying or writing something that is\nopposite or opposite to what one really means, often in a humorous or mocking\nway. It is often used to mock or mock someone or something, or to be humorous\nor amusing. Sarcasm is usually conveyed through tone of voice, facial\nexpressions, or other forms of nonverbal communication, but it can also be\nindicated by the use of certain words or phrases that are typically associated\nwith irony or humor. Sarcasm detection is difficult because it relies on\ncontext and non-verbal cues. It can also be culturally specific, subjective and\nambiguous. In this work, we fine-tune the RoBERTa based sarcasm detection model\npresented in Abaskohi et al. [2022] to get to within 0.02 F1 of the\nstate-of-the-art (Hercog et al. [2022]) on the iSarcasm dataset (Oprea and\nMagdy [2019]). This performance is achieved by augmenting iSarcasm with a\npruned version of the Self Annotated Reddit Corpus (SARC) (Khodak et al.\n[2017]). Our pruned version is 100 times smaller than the subset of SARC used\nto train the state-of-the-art model.", "published": "2022-12-23 08:59:30", "link": "http://arxiv.org/abs/2212.12213v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Judgement's Premises Towards Key Points", "abstract": "Key Point Analysis(KPA) is a relatively new task in NLP that combines\nsummarization and classification by extracting argumentative key points (KPs)\nfor a topic from a collection of texts and categorizing their closeness to the\ndifferent arguments. In our work, we focus on the legal domain and develop\nmethods that identify and extract KPs from premises derived from texts of\njudgments. The first method is an adaptation to an existing state-of-the-art\nmethod, and the two others are new methods that we developed from scratch. We\npresent our methods and examples of their outputs, as well a comparison between\nthem. The full evaluation of our results is done in the matching task -- match\nbetween the generated KPs to arguments (premises).", "published": "2022-12-23 10:20:58", "link": "http://arxiv.org/abs/2212.12238v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Raw Emotional Dataset with Aggregation Mechanism", "abstract": "We present a new data set for speech emotion recognition (SER) tasks called\nDusha. The corpus contains approximately 350 hours of data, more than 300 000\naudio recordings with Russian speech and their transcripts. Therefore it is the\nbiggest open bi-modal data collection for SER task nowadays. It is annotated\nusing a crowd-sourcing platform and includes two subsets: acted and real-life.\nActed subset has a more balanced class distribution than the unbalanced\nreal-life part consisting of audio podcasts. So the first one is suitable for\nmodel pre-training, and the second is elaborated for fine-tuning purposes,\nmodel approbation, and validation. This paper describes pre-processing routine,\nannotation, and experiment with a baseline model to demonstrate some actual\nmetrics which could be obtained with the Dusha data set.", "published": "2022-12-23 11:31:02", "link": "http://arxiv.org/abs/2212.12266v1", "categories": ["eess.AS", "62-07", "I.2.7"], "primary_category": "eess.AS"}
{"title": "EarSpy: Spying Caller Speech and Identity through Tiny Vibrations of\n  Smartphone Ear Speakers", "abstract": "Eavesdropping from the user's smartphone is a well-known threat to the user's\nsafety and privacy. Existing studies show that loudspeaker reverberation can\ninject speech into motion sensor readings, leading to speech eavesdropping.\nWhile more devastating attacks on ear speakers, which produce much smaller\nscale vibrations, were believed impossible to eavesdrop with zero-permission\nmotion sensors. In this work, we revisit this important line of reach. We\nexplore recent trends in smartphone manufacturers that include extra/powerful\nspeakers in place of small ear speakers, and demonstrate the feasibility of\nusing motion sensors to capture such tiny speech vibrations. We investigate the\nimpacts of these new ear speakers on built-in motion sensors and examine the\npotential to elicit private speech information from the minute vibrations. Our\ndesigned system EarSpy can successfully detect word regions, time, and\nfrequency domain features and generate a spectrogram for each word region. We\ntrain and test the extracted data using classical machine learning algorithms\nand convolutional neural networks. We found up to 98.66% accuracy in gender\ndetection, 92.6% detection in speaker detection, and 56.42% detection in digit\ndetection (which is 5X more significant than the random selection (10%)). Our\nresult unveils the potential threat of eavesdropping on phone conversations\nfrom ear speakers using motion sensors.", "published": "2022-12-23 05:05:09", "link": "http://arxiv.org/abs/2212.12151v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fractal Patterns in Music", "abstract": "If our aesthetic preferences are affected by fractal geometry of nature,\nscaling regularities would be expected to appear in all art forms, including\nmusic. While a variety of statistical tools have been proposed to analyze time\nseries in sound, no consensus has as yet emerged regarding the most meaningful\nmeasure of complexity in music, or how to discern fractal patterns in\ncompositions in the first place. Here we offer a new approach based on\nself-similarity of the melodic lines recurring at various temporal scales. In\ncontrast to the statistical analyses advanced in recent literature, the\nproposed method does not depend on averaging within time-windows and is\ndistinctively local. The corresponding definition of the fractal dimension is\nbased on the temporal scaling hierarchy and depends on the tonal contours of\nthe musical motifs. The new concepts are tested on musical 'renditions' of the\nCantor Set and Koch Curve, and then applied to a number of carefully selected\nmasterful compositions spanning five centuries of music making.", "published": "2022-12-23 17:41:25", "link": "http://arxiv.org/abs/2212.12497v1", "categories": ["nlin.PS", "cs.SD", "eess.AS"], "primary_category": "nlin.PS"}
