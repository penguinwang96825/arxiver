{"title": "Attenuating Bias in Word Vectors", "abstract": "Word vector representations are well developed tools for various NLP and\nMachine Learning tasks and are known to retain significant semantic and\nsyntactic structure of languages. But they are prone to carrying and amplifying\nbias which can perpetrate discrimination in various applications. In this work,\nwe explore new simple ways to detect the most stereotypically gendered words in\nan embedding and remove the bias from them. We verify how names are masked\ncarriers of gender bias and then use that as a tool to attenuate bias in\nembeddings. Further, we extend this property of names to show how names can be\nused to detect other types of bias in the embeddings such as bias based on\nrace, ethnicity, and age.", "published": "2019-01-23 00:25:48", "link": "http://arxiv.org/abs/1901.07656v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Sensitive Malicious Spelling Error Correction", "abstract": "Misspelled words of the malicious kind work by changing specific keywords and\nare intended to thwart existing automated applications for cyber-environment\ncontrol such as harassing content detection on the Internet and email spam\ndetection. In this paper, we focus on malicious spelling correction, which\nrequires an approach that relies on the context and the surface forms of\ntargeted keywords. In the context of two applications--profanity detection and\nemail spam detection--we show that malicious misspellings seriously degrade\ntheir performance. We then propose a context-sensitive approach for malicious\nspelling correction using word embeddings and demonstrate its superior\nperformance compared to state-of-the-art spell checkers.", "published": "2019-01-23 02:11:11", "link": "http://arxiv.org/abs/1901.07688v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Essay Scoring based on Two-Stage Learning", "abstract": "Current state-of-art feature-engineered and end-to-end Automated Essay Score\n(AES) methods are proven to be unable to detect adversarial samples, e.g. the\nessays composed of permuted sentences and the prompt-irrelevant essays.\nFocusing on the problem, we develop a Two-Stage Learning Framework (TSLF) which\nintegrates the advantages of both feature-engineered and end-to-end AES models.\nIn experiments, we compare TSLF against a number of strong baselines, and the\nresults demonstrate the effectiveness and robustness of our models. TSLF\nsurpasses all the baselines on five-eighths of prompts and achieves new\nstate-of-the-art average performance when without negative samples. After\nadding some adversarial essays to the original datasets, TSLF outperforms the\nfeature-engineered and end-to-end baselines to a great extent, and shows great\nrobustness.", "published": "2019-01-23 06:37:12", "link": "http://arxiv.org/abs/1901.07744v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context based Analysis of Lexical Semantics for Hindi Language", "abstract": "A word having multiple senses in a text introduces the lexical semantic task\nto find out which particular sense is appropriate for the given context. One\nsuch task is Word sense disambiguation which refers to the identification of\nthe most appropriate meaning of the polysemous word in a given context using\ncomputational algorithms. The language processing research in Hindi, the\nofficial language of India, and other Indian languages is restricted by\nunavailability of the standard corpus. For Hindi word sense disambiguation\nalso, the large corpus is not available. In this work, we prepared the text\ncontaining new senses of certain words leading to the enrichment of the\nsense-tagged Hindi corpus of sixty polysemous words. Furthermore, we analyzed\ntwo novel lexical associations for Hindi word sense disambiguation based on the\ncontextual features of the polysemous word. The evaluation of these methods is\ncarried out over learning algorithms and favorable results are achieved.", "published": "2019-01-23 13:23:10", "link": "http://arxiv.org/abs/1901.07867v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the State-of-the-Art of End-to-End Natural Language\n  Generation: The E2E NLG Challenge", "abstract": "This paper provides a comprehensive analysis of the first shared task on\nEnd-to-End Natural Language Generation (NLG) and identifies avenues for future\nresearch based on the results. This shared task aimed to assess whether recent\nend-to-end NLG systems can generate more complex output by learning from\ndatasets containing higher lexical richness, syntactic complexity and diverse\ndiscourse phenomena. Introducing novel automatic and human metrics, we compare\n62 systems submitted by 17 institutions, covering a wide range of approaches,\nincluding machine learning architectures -- with the majority implementing\nsequence-to-sequence models (seq2seq) -- as well as systems based on\ngrammatical rules and templates. Seq2seq-based systems have demonstrated a\ngreat potential for NLG in the challenge. We find that seq2seq systems\ngenerally score high in terms of word-overlap metrics and human evaluations of\nnaturalness -- with the winning SLUG system (Juraska et al., 2018) being\nseq2seq-based. However, vanilla seq2seq models often fail to correctly express\na given meaning representation if they lack a strong semantic control mechanism\napplied during decoding. Moreover, seq2seq models can be outperformed by\nhand-engineered systems in terms of overall quality, as well as complexity,\nlength and diversity of outputs. This research has influenced, inspired and\nmotivated a number of recent studies outwith the original competition, which we\nalso summarise as part of this paper.", "published": "2019-01-23 14:54:53", "link": "http://arxiv.org/abs/1901.07931v3", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Sentiment and Sarcasm Classification with Multitask Learning", "abstract": "Sentiment classification and sarcasm detection are both important natural\nlanguage processing (NLP) tasks. Sentiment is always coupled with sarcasm where\nintensive emotion is expressed. Nevertheless, most literature considers them as\ntwo separate tasks. We argue that knowledge in sarcasm detection can also be\nbeneficial to sentiment classification and vice versa. We show that these two\ntasks are correlated, and present a multi-task learning-based framework using a\ndeep neural network that models this correlation to improve the performance of\nboth tasks in a multi-task learning setting. Our method outperforms the state\nof the art by 3-4% in the benchmark dataset.", "published": "2019-01-23 17:18:50", "link": "http://arxiv.org/abs/1901.08014v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TransferTransfo: A Transfer Learning Approach for Neural Network Based\n  Conversational Agents", "abstract": "We introduce a new approach to generative data-driven dialogue systems (e.g.\nchatbots) called TransferTransfo which is a combination of a Transfer learning\nbased training scheme and a high-capacity Transformer model. Fine-tuning is\nperformed by using a multi-task objective which combines several unsupervised\nprediction tasks. The resulting fine-tuned model shows strong improvements over\nthe current state-of-the-art end-to-end conversational models like memory\naugmented seq2seq and information-retrieval models. On the privately held\nPERSONA-CHAT dataset of the Conversational Intelligence Challenge 2, this\napproach obtains a new state-of-the-art, with respective perplexity, Hits@1 and\nF1 metrics of 16.28 (45 % absolute improvement), 80.7 (46 % absolute\nimprovement) and 19.5 (20 % absolute improvement).", "published": "2019-01-23 22:08:01", "link": "http://arxiv.org/abs/1901.08149v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Relation Classification via Bidirectional LSTM Networks with\n  Entity-aware Attention using Latent Entity Typing", "abstract": "Classifying semantic relations between entity pairs in sentences is an\nimportant task in Natural Language Processing (NLP). Most previous models for\nrelation classification rely on the high-level lexical and syntactic features\nobtained by NLP tools such as WordNet, dependency parser, part-of-speech (POS)\ntagger, and named entity recognizers (NER). In addition, state-of-the-art\nneural models based on attention mechanisms do not fully utilize information of\nentity that may be the most crucial features for relation classification. To\naddress these issues, we propose a novel end-to-end recurrent neural model\nwhich incorporates an entity-aware attention mechanism with a latent entity\ntyping (LET) method. Our model not only utilizes entities and their latent\ntypes as features effectively but also is more interpretable by visualizing\nattention mechanisms applied to our model and results of LET. Experimental\nresults on the SemEval-2010 Task 8, one of the most popular relation\nclassification task, demonstrate that our model outperforms existing\nstate-of-the-art models without any high-level features.", "published": "2019-01-23 23:19:45", "link": "http://arxiv.org/abs/1901.08163v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Product-Aware Answer Generation in E-Commerce Question-Answering", "abstract": "In e-commerce portals, generating answers for product-related questions has\nbecome a crucial task. In this paper, we propose the task of product-aware\nanswer generation, which tends to generate an accurate and complete answer from\nlarge-scale unlabeled e-commerce reviews and product attributes. Unlike\nexisting question-answering problems, answer generation in e-commerce confronts\nthree main challenges: (1) Reviews are informal and noisy; (2) joint modeling\nof reviews and key-value product attributes is challenging; (3) traditional\nmethods easily generate meaningless answers. To tackle above challenges, we\npropose an adversarial learning based model, named PAAG, which is composed of\nthree components: a question-aware review representation module, a key-value\nmemory network encoding attributes, and a recurrent neural network as a\nsequence generator. Specifically, we employ a convolutional discriminator to\ndistinguish whether our generated answer matches the facts. To extract the\nsalience part of reviews, an attention-based review reader is proposed to\ncapture the most relevant words given the question. Conducted on a large-scale\nreal-world e-commerce dataset, our extensive experiments verify the\neffectiveness of each module in our proposed model. Moreover, our experiments\nshow that our model achieves the state-of-the-art performance in terms of both\nautomatic metrics and human evaluations.", "published": "2019-01-23 02:33:52", "link": "http://arxiv.org/abs/1901.07696v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Attentive Model for Headline Generation", "abstract": "Headline generation is a special type of text summarization task. While the\namount of available training data for this task is almost unlimited, it still\nremains challenging, as learning to generate headlines for news articles\nimplies that the model has strong reasoning about natural language. To overcome\nthis issue, we applied recent Universal Transformer architecture paired with\nbyte-pair encoding technique and achieved new state-of-the-art results on the\nNew York Times Annotated corpus with ROUGE-L F1-score 24.84 and ROUGE-2\nF1-score 13.48. We also present the new RIA corpus and reach ROUGE-L F1-score\n36.81 and ROUGE-2 F1-score 22.15 on it.", "published": "2019-01-23 09:39:45", "link": "http://arxiv.org/abs/1901.07786v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AspeRa: Aspect-based Rating Prediction Model", "abstract": "We propose a novel end-to-end Aspect-based Rating Prediction model (AspeRa)\nthat estimates user rating based on review texts for the items and at the same\ntime discovers coherent aspects of reviews that can be used to explain\npredictions or profile users. The AspeRa model uses max-margin losses for joint\nitem and user embedding learning and a dual-headed architecture; it\nsignificantly outperforms recently proposed state-of-the-art models such as\nDeepCoNN, HFT, NARRE, and TransRev on two real world data sets of user reviews.\nWith qualitative examination of the aspects and quantitative evaluation of\nrating prediction models based on these aspects, we show how aspect embeddings\ncan be used in a recommender system.", "published": "2019-01-23 11:38:15", "link": "http://arxiv.org/abs/1901.07829v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Phonetic-enriched Text Representation for Chinese Sentiment Analysis\n  with Reinforcement Learning", "abstract": "The Chinese pronunciation system offers two characteristics that distinguish\nit from other languages: deep phonemic orthography and intonation variations.\nWe are the first to argue that these two important properties can play a major\nrole in Chinese sentiment analysis. Particularly, we propose two effective\nfeatures to encode phonetic information. Next, we develop a Disambiguate\nIntonation for Sentiment Analysis (DISA) network using a reinforcement network.\nIt functions as disambiguating intonations for each Chinese character (pinyin).\nThus, a precise phonetic representation of Chinese is learned. Furthermore, we\nalso fuse phonetic features with textual and visual features in order to mimic\nthe way humans read and understand Chinese text. Experimental results on five\ndifferent Chinese sentiment analysis datasets show that the inclusion of\nphonetic features significantly and consistently improves the performance of\ntextual and visual representations and outshines the state-of-the-art Chinese\ncharacter level representations.", "published": "2019-01-23 13:53:24", "link": "http://arxiv.org/abs/1901.07880v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Tool for Spatio-Temporal Analysis of Social Anxiety with Twitter Data", "abstract": "In this paper, we present a tool for analyzing spatio-temporal distribution\nof social anxiety. Twitter, one of the most popular social network services,\nhas been chosen as data source for analysis of social anxiety. Tweets (posted\non the Twitter) contain various emotions and thus these individual emotions\nreflect social atmosphere and public opinion, which are often dependent on\nspatial and temporal factors. The reason why we choose anxiety among various\nemotions is that anxiety is very important emotion that is useful for observing\nand understanding social events of communities. We develop a machine learning\nbased tool to analyze the changes of social atmosphere spatially and\ntemporally. Our tool classifies whether each Tweet contains anxious content or\nnot, and also estimates degree of Tweet anxiety. Furthermore, it also\nvisualizes spatio-temporal distribution of anxiety as a form of web\napplication, which is incorporated with physical map, word cloud, search engine\nand chart viewer. Our tool is applied to a big tweet data in South Korea to\nillustrate its usefulness for exploring social atmosphere and public opinion\nspatio-temporally.", "published": "2019-01-23 22:37:11", "link": "http://arxiv.org/abs/1901.08158v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "NLSC: Unrestricted Natural Language-based Service Composition through\n  Sentence Embeddings", "abstract": "Current approaches for service composition (assemblies of atomic services)\nrequire developers to use: (a) domain-specific semantics to formalize services\nthat restrict the vocabulary for their descriptions, and (b) translation\nmechanisms for service retrieval to convert unstructured user requests to\nstrongly-typed semantic representations. In our work, we argue that effort to\ndeveloping service descriptions, request translations, and matching mechanisms\ncould be reduced using unrestricted natural language; allowing both: (1)\nend-users to intuitively express their needs using natural language, and (2)\nservice developers to develop services without relying on syntactic/semantic\ndescription languages. Although there are some natural language-based service\ncomposition approaches, they restrict service retrieval to syntactic/semantic\nmatching. With recent developments in Machine learning and Natural Language\nProcessing, we motivate the use of Sentence Embeddings by leveraging richer\nsemantic representations of sentences for service description, matching and\nretrieval. Experimental results show that service composition development\neffort may be reduced by more than 44\\% while keeping a high precision/recall\nwhen matching high-level user requests with low-level service method\ninvocations.", "published": "2019-01-23 14:18:26", "link": "http://arxiv.org/abs/1901.07910v3", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "A Question-Entailment Approach to Question Answering", "abstract": "One of the challenges in large-scale information retrieval (IR) is to develop\nfine-grained and domain-specific methods to answer natural language questions.\nDespite the availability of numerous sources and datasets for answer retrieval,\nQuestion Answering (QA) remains a challenging problem due to the difficulty of\nthe question understanding and answer extraction tasks. One of the promising\ntracks investigated in QA is to map new questions to formerly answered\nquestions that are `similar'. In this paper, we propose a novel QA approach\nbased on Recognizing Question Entailment (RQE) and we describe the QA system\nand resources that we built and evaluated on real medical questions. First, we\ncompare machine learning and deep learning methods for RQE using different\nkinds of datasets, including textual inference, question similarity and\nentailment in both the open and clinical domains. Second, we combine IR models\nwith the best RQE method to select entailed questions and rank the retrieved\nanswers. To study the end-to-end QA approach, we built the MedQuAD collection\nof 47,457 question-answer pairs from trusted medical sources, that we introduce\nand share in the scope of this paper. Following the evaluation process used in\nTREC 2017 LiveQA, we find that our approach exceeds the best results of the\nmedical task with a 29.8% increase over the best official score. The evaluation\nresults also support the relevance of question entailment for QA and highlight\nthe effectiveness of combining IR and RQE for future QA efforts. Our findings\nalso show that relying on a restricted set of reliable answer sources can bring\na substantial improvement in medical QA.", "published": "2019-01-23 19:02:27", "link": "http://arxiv.org/abs/1901.08079v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "68T50"], "primary_category": "cs.CL"}
{"title": "\"Is this an example image?\" -- Predicting the Relative Abstractness\n  Level of Image and Text", "abstract": "Successful multimodal search and retrieval requires the automatic\nunderstanding of semantic cross-modal relations, which, however, is still an\nopen research problem. Previous work has suggested the metrics cross-modal\nmutual information and semantic correlation to model and predict cross-modal\nsemantic relations of image and text. In this paper, we present an approach to\npredict the (cross-modal) relative abstractness level of a given image-text\npair, that is whether the image is an abstraction of the text or vice versa.\nFor this purpose, we introduce a new metric that captures this specific\nrelationship between image and text at the Abstractness Level (ABS). We present\na deep learning approach to predict this metric, which relies on an autoencoder\narchitecture that allows us to significantly reduce the required amount of\nlabeled training data. A comprehensive set of publicly available scientific\ndocuments has been gathered. Experimental results on a challenging test set\ndemonstrate the feasibility of the approach.", "published": "2019-01-23 13:42:02", "link": "http://arxiv.org/abs/1901.07878v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Generalization of Spoofing Countermeasures: a Case Study with ASVspoof\n  2015 and BTAS 2016 Corpora", "abstract": "Voice-based biometric systems are highly prone to spoofing attacks. Recently,\nvarious countermeasures have been developed for detecting different kinds of\nattacks such as replay, speech synthesis (SS) and voice conversion (VC). Most\nof the existing studies are conducted with a specific training set defined by\nthe evaluation protocol. However, for realistic scenarios, selecting\nappropriate training data is an open challenge for the system administrator.\nMotivated by this practical concern, this work investigates the generalization\ncapability of spoofing countermeasures in restricted training conditions where\nspeech from a broad attack types are left out in the training database. We\ndemonstrate that different spoofing types have considerably different\ngeneralization capabilities. For this study, we analyze the performance using\ntwo kinds of features, mel-frequency cepstral coefficients (MFCCs) which are\nconsidered as baseline and recently proposed constant Q cepstral coefficients\n(CQCCs). The experiments are conducted with standard Gaussian mixture model -\nmaximum likelihood (GMM-ML) classifier on two recently released spoofing\ncorpora: ASVspoof 2015 and BTAS 2016 that includes cross-corpora performance\nanalysis. Feature-level analysis suggests that static and dynamic coefficients\nof spectral features, both are important for detecting spoofing attacks in the\nreal-life condition.", "published": "2019-01-23 17:55:39", "link": "http://arxiv.org/abs/1901.08025v1", "categories": ["cs.MM", "eess.AS"], "primary_category": "cs.MM"}
