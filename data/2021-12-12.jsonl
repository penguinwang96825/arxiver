{"title": "Injecting Numerical Reasoning Skills into Knowledge Base Question\n  Answering Models", "abstract": "Embedding-based methods are popular for Knowledge Base Question Answering\n(KBQA), but few current models have numerical reasoning skills and thus\nstruggle to answer ordinal constrained questions. This paper proposes a new\nembedding-based KBQA framework which particularly takes numerical reasoning\ninto account. We present NumericalTransformer on top of NSM, a state-of-the-art\nembedding-based KBQA model, to create NT-NSM. To enable better training, we\npropose two pre-training tasks with explicit numerical-oriented loss functions\non two generated training datasets and a template-based data augmentation\nmethod for enriching ordinal constrained QA dataset. Extensive experiments on\nKBQA benchmarks demonstrate that with the help of our training algorithm,\nNT-NSM is empowered with numerical reasoning skills and substantially\noutperforms the baselines in answering ordinal constrained questions.", "published": "2021-12-12 01:30:29", "link": "http://arxiv.org/abs/2112.06109v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Communication-Efficient Federated Learning for Neural Machine\n  Translation", "abstract": "Training neural machine translation (NMT) models in federated learning (FL)\nsettings could be inefficient both computationally and communication-wise, due\nto the large size of translation engines as well as the multiple rounds of\nupdates required to train clients and a central server. In this paper, we\nexplore how to efficiently build NMT models in an FL setup by proposing a novel\nsolution. In order to reduce the communication overhead, out of all neural\nlayers we only exchange what we term \"Controller\" layers. Controllers are a\nsmall number of additional neural components connected to our pre-trained\narchitectures. These new components are placed in between original layers. They\nact as liaisons to communicate with the central server and learn minimal\ninformation that is sufficient enough to update clients.\n  We evaluated the performance of our models on five datasets from different\ndomains to translate from German into English. We noted that the models\nequipped with Controllers preform on par with those trained in a central and\nnon-FL setting. In addition, we observed a substantial reduction in the\ncommunication traffic of the FL pipeline, which is a direct consequence of\nusing Controllers. Based on our experiments, Controller-based models are ~6\ntimes less expensive than their other peers. This reduction is significantly\nimportant when we consider the number of parameters in large models and it\nbecomes even more critical when such parameters need to be exchanged for\nmultiple rounds in FL settings.", "published": "2021-12-12 03:16:03", "link": "http://arxiv.org/abs/2112.06135v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topic Detection and Tracking with Time-Aware Document Embeddings", "abstract": "The time at which a message is communicated is a vital piece of metadata in\nmany real-world natural language processing tasks such as Topic Detection and\nTracking (TDT). TDT systems aim to cluster a corpus of news articles by event,\nand in that context, stories that describe the same event are likely to have\nbeen written at around the same time. Prior work on time modeling for TDT takes\nthis into account, but does not well capture how time interacts with the\nsemantic nature of the event. For example, stories about a tropical storm are\nlikely to be written within a short time interval, while stories about a movie\nrelease may appear over weeks or months. In our work, we design a neural method\nthat fuses temporal and textual information into a single representation of\nnews documents for event detection. We fine-tune these time-aware document\nembeddings with a triplet loss architecture, integrate the model into\ndownstream TDT systems, and evaluate the systems on two benchmark TDT data sets\nin English. In the retrospective setting, we apply clustering algorithms to the\ntime-aware embeddings and show substantial improvements over baselines on the\nNews2013 data set. In the online streaming setting, we add our document encoder\nto an existing state-of-the-art TDT pipeline and demonstrate that it can\nbenefit the overall performance. We conduct ablation studies on the time\nrepresentation and fusion algorithm strategies, showing that our proposed model\noutperforms alternative strategies. Finally, we probe the model to examine how\nit handles recurring events more effectively than previous TDT systems.", "published": "2021-12-12 06:25:15", "link": "http://arxiv.org/abs/2112.06166v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-Shot Out-of-Domain Transfer Learning of Natural Language\n  Explanations in a Label-Abundant Setup", "abstract": "Training a model to provide natural language explanations (NLEs) for its\npredictions usually requires the acquisition of task-specific NLEs, which is\ntime- and resource-consuming. A potential solution is the few-shot\nout-of-domain transfer of NLEs from a parent task with many NLEs to a child\ntask. In this work, we examine the setup in which the child task has few NLEs\nbut abundant labels. We establish four few-shot transfer learning methods that\ncover the possible fine-tuning combinations of the labels and NLEs for the\nparent and child tasks. We transfer explainability from a large natural\nlanguage inference dataset (e-SNLI) separately to two child tasks: (1) hard\ncases of pronoun resolution, where we introduce the small-e-WinoGrande dataset\nof NLEs on top of the WinoGrande dataset, and (2)~commonsense validation\n(ComVE). Our results demonstrate that the parent task helps with NLE generation\nand we establish the best methods for this setup.", "published": "2021-12-12 11:10:39", "link": "http://arxiv.org/abs/2112.06204v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "ASCEND: A Spontaneous Chinese-English Dataset for Code-switching in\n  Multi-turn Conversation", "abstract": "Code-switching is a speech phenomenon occurring when a speaker switches\nlanguage during a conversation. Despite the spontaneous nature of\ncode-switching in conversational spoken language, most existing works collect\ncode-switching data from read speech instead of spontaneous speech. ASCEND (A\nSpontaneous Chinese-English Dataset) is a high-quality Mandarin Chinese-English\ncode-switching corpus built on spontaneous multi-turn conversational dialogue\nsources collected in Hong Kong. We report ASCEND's design and procedure for\ncollecting the speech data, including annotations. ASCEND consists of 10.62\nhours of clean speech, collected from 23 bilingual speakers of Chinese and\nEnglish. Furthermore, we conduct baseline experiments using pre-trained wav2vec\n2.0 models, achieving a best performance of 22.69\\% character error rate and\n27.05% mixed error rate.", "published": "2021-12-12 12:59:20", "link": "http://arxiv.org/abs/2112.06223v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Logical-Level Natural Language Generation with\n  Topic-Conditioned Data Augmentation and Logical Form Generation", "abstract": "Logical Natural Language Generation, i.e., generating textual descriptions\nthat can be logically entailed by a structured table, has been a challenge due\nto the low fidelity of the generation. \\citet{chen2020logic2text} have\naddressed this problem by annotating interim logical programs to control the\ngeneration contents and semantics, and presented the task of table-aware\nlogical form to text (Logic2text) generation. However, although table instances\nare abundant in the real world, logical forms paired with textual descriptions\nrequire costly human annotation work, which limits the performance of neural\nmodels. To mitigate this, we propose topic-conditioned data augmentation\n(TopicDA), which utilizes GPT-2 to generate unpaired logical forms and textual\ndescriptions directly from tables. We further introduce logical form generation\n(LG), a dual task of Logic2text that requires generating a valid logical form\nbased on a text description of a table. We also propose a semi-supervised\nlearning approach to jointly train a Logic2text and an LG model with both\nlabeled and augmented data. The two models benefit from each other by providing\nextra supervision signals through back-translation. Experimental results on the\nLogic2text dataset and the LG task demonstrate that our approach can\neffectively utilize the augmented data and outperform supervised baselines by a\nsubstantial margin.", "published": "2021-12-12 13:50:18", "link": "http://arxiv.org/abs/2112.06240v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards More Efficient Insertion Transformer with Fractional Positional\n  Encoding", "abstract": "Auto-regressive neural sequence models have been shown to be effective across\ntext generation tasks. However, their left-to-right decoding order prevents\ngeneration from being parallelized. Insertion Transformer (Stern et al., 2019)\nis an attractive alternative that allows outputting multiple tokens in a single\ngeneration step. Nevertheless, due to the incompatibility between absolute\npositional encoding and insertion-based generation schemes, it needs to refresh\nthe encoding of every token in the generated partial hypothesis at each step,\nwhich could be costly. We design a novel reusable positional encoding scheme\nfor Insertion Transformers called Fractional Positional Encoding (FPE), which\nallows reusing representations calculated in previous steps. Empirical studies\non various text generation tasks demonstrate the effectiveness of FPE, which\nleads to floating-point operation reduction and latency improvements on batched\ndecoding.", "published": "2021-12-12 18:38:27", "link": "http://arxiv.org/abs/2112.06295v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reading Task Classification Using EEG and Eye-Tracking Data", "abstract": "The Zurich Cognitive Language Processing Corpus (ZuCo) provides eye-tracking\nand EEG signals from two reading paradigms, normal reading and task-specific\nreading. We analyze whether machine learning methods are able to classify these\ntwo tasks using eye-tracking and EEG features. We implement models with\naggregated sentence-level features as well as fine-grained word-level features.\nWe test the models in within-subject and cross-subject evaluation scenarios.\nAll models are tested on the ZuCo 1.0 and ZuCo 2.0 data subsets, which are\ncharacterized by differing recording procedures and thus allow for different\nlevels of generalizability. Finally, we provide a series of control experiments\nto analyze the results in more detail.", "published": "2021-12-12 19:57:11", "link": "http://arxiv.org/abs/2112.06310v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextualized Scene Imagination for Generative Commonsense Reasoning", "abstract": "Humans use natural language to compose common concepts from their environment\ninto plausible, day-to-day scene descriptions. However, such generative\ncommonsense reasoning (GCSR) skills are lacking in state-of-the-art text\ngeneration methods. Descriptive sentences about arbitrary concepts generated by\nneural text generation models (e.g., pre-trained text-to-text Transformers) are\noften grammatically fluent but may not correspond to human common sense,\nlargely due to their lack of mechanisms to capture concept relations, to\nidentify implicit concepts, and to perform generalizable reasoning about unseen\nconcept compositions. In this paper, we propose an Imagine-and-Verbalize (I&V)\nmethod, which learns to imagine a relational scene knowledge graph (SKG) with\nrelations between the input concepts, and leverage the SKG as a constraint when\ngenerating a plausible scene description. We collect and harmonize a set of\nknowledge resources from different domains and modalities, providing a rich\nauxiliary supervision signal for I&V. The experiments demonstrate the\neffectiveness of I&V in improving language models on both concept-to-sentence\nand concept-to-story generation tasks, while enabling the model to learn well\nfrom fewer task examples and generate SKGs that make common sense to human\nannotators.", "published": "2021-12-12 20:38:08", "link": "http://arxiv.org/abs/2112.06318v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Code-switching Language Modeling with Artificially Generated\n  Texts using Cycle-consistent Adversarial Networks", "abstract": "This paper presents our latest effort on improving Code-switching language\nmodels that suffer from data scarcity. We investigate methods to augment\nCode-switching training text data by artificially generating them. Concretely,\nwe propose a cycle-consistent adversarial networks based framework to transfer\nmonolingual text into Code-switching text, considering Code-switching as a\nspeaking style. Our experimental results on the SEAME corpus show that\nutilising artificially generated Code-switching text data improves consistently\nthe language model as well as the automatic speech recognition performance.", "published": "2021-12-12 21:27:32", "link": "http://arxiv.org/abs/2112.06327v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting Above-Sentence Discourse Structure using Distant Supervision\n  from Topic Segmentation", "abstract": "RST-style discourse parsing plays a vital role in many NLP tasks, revealing\nthe underlying semantic/pragmatic structure of potentially complex and diverse\ndocuments. Despite its importance, one of the most prevailing limitations in\nmodern day discourse parsing is the lack of large-scale datasets. To overcome\nthe data sparsity issue, distantly supervised approaches from tasks like\nsentiment analysis and summarization have been recently proposed. Here, we\nextend this line of research by exploiting distant supervision from topic\nsegmentation, which can arguably provide a strong and oftentimes complementary\nsignal for high-level discourse structures. Experiments on two human-annotated\ndiscourse treebanks confirm that our proposal generates accurate tree\nstructures on sentence and paragraph level, consistently outperforming previous\ndistantly supervised models on the sentence-to-document task and occasionally\nreaching even higher scores on the sentence-to-paragraph level.", "published": "2021-12-12 10:16:45", "link": "http://arxiv.org/abs/2112.06196v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph-based hierarchical record clustering for unsupervised entity\n  resolution", "abstract": "Here we study the problem of matched record clustering in unsupervised entity\nresolution. We build upon a state-of-the-art probabilistic framework named the\nData Washing Machine (DWM). We introduce a graph-based hierarchical 2-step\nrecord clustering method (GDWM) that first identifies large, connected\ncomponents or, as we call them, soft clusters in the matched record pairs using\na graph-based transitive closure algorithm utilized in the DWM. That is\nfollowed by breaking down the discovered soft clusters into more precise entity\nclusters in a hierarchical manner using an adapted graph-based modularity\noptimization method. Our approach provides several advantages over the original\nimplementation of the DWM, mainly a significant speed-up, increased precision,\nand overall increased F1 scores. We demonstrate the efficacy of our approach\nusing experiments on multiple synthetic datasets. Our results also provide\nevidence of the utility of graph theory-based algorithms despite their sparsity\nin the literature on unsupervised entity resolution.", "published": "2021-12-12 21:58:07", "link": "http://arxiv.org/abs/2112.06331v1", "categories": ["cs.DB", "cs.CL"], "primary_category": "cs.DB"}
{"title": "ValueNet: A New Dataset for Human Value Driven Dialogue System", "abstract": "Building a socially intelligent agent involves many challenges, one of which\nis to teach the agent to speak guided by its value like a human. However,\nvalue-driven chatbots are still understudied in the area of dialogue systems.\nMost existing datasets focus on commonsense reasoning or social norm modeling.\nIn this work, we present a new large-scale human value dataset called ValueNet,\nwhich contains human attitudes on 21,374 text scenarios. The dataset is\norganized in ten dimensions that conform to the basic human value theory in\nintercultural research. We further develop a Transformer-based value regression\nmodel on ValueNet to learn the utility distribution. Comprehensive empirical\nresults show that the learned value model could benefit a wide range of\ndialogue tasks. For example, by teaching a generative agent with reinforcement\nlearning and the rewards from the value model, our method attains\nstate-of-the-art performance on the personalized dialog generation dataset:\nPersona-Chat. With values as additional features, existing emotion recognition\nmodels enable capturing rich human emotions in the context, which further\nimproves the empathetic response generation performance in the\nEmpatheticDialogues dataset. To the best of our knowledge, ValueNet is the\nfirst large-scale text dataset for human value modeling, and we are the first\none trying to incorporate a value model into emotionally intelligent dialogue\nsystems. The dataset is available at https://liang-qiu.github.io/ValueNet/.", "published": "2021-12-12 23:02:52", "link": "http://arxiv.org/abs/2112.06346v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Nigerian accent embeddings from speech: preliminary results\n  based on SautiDB-Naija corpus", "abstract": "This paper describes foundational efforts with SautiDB-Naija, a novel corpus\nof non-native (L2) Nigerian English speech. We describe how the corpus was\ncreated and curated as well as preliminary experiments with accent\nclassification and learning Nigerian accent embeddings. The initial version of\nthe corpus includes over 900 recordings from L2 English speakers of Nigerian\nlanguages, such as Yoruba, Igbo, Edo, Efik-Ibibio, and Igala. We further\ndemonstrate how fine-tuning on a pre-trained model like wav2vec can yield\nrepresentations suitable for related speech tasks such as accent\nclassification. SautiDB-Naija has been published to Zenodo for general use\nunder a flexible Creative Commons License.", "published": "2021-12-12 10:50:01", "link": "http://arxiv.org/abs/2112.06199v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Improving Speech Recognition on Noisy Speech via Speech Enhancement with\n  Multi-Discriminators CycleGAN", "abstract": "This paper presents our latest investigations on improving automatic speech\nrecognition for noisy speech via speech enhancement. We propose a novel method\nnamed Multi-discriminators CycleGAN to reduce noise of input speech and\ntherefore improve the automatic speech recognition performance. Our proposed\nmethod leverages the CycleGAN framework for speech enhancement without any\nparallel data and improve it by introducing multiple discriminators that check\ndifferent frequency areas. Furthermore, we show that training multiple\ngenerators on homogeneous subset of the training data is better than training\none generator on all the training data. We evaluate our method on CHiME-3 data\nset and observe up to 10.03% relatively WER improvement on the development set\nand up to 14.09% on the evaluation set.", "published": "2021-12-12 19:56:34", "link": "http://arxiv.org/abs/2112.06309v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised Text-to-SQL Parsing through Question Decomposition", "abstract": "Text-to-SQL parsers are crucial in enabling non-experts to effortlessly query\nrelational data. Training such parsers, by contrast, generally requires\nexpertise in annotating natural language (NL) utterances with corresponding SQL\nqueries. In this work, we propose a weak supervision approach for training\ntext-to-SQL parsers. We take advantage of the recently proposed question\nmeaning representation called QDMR, an intermediate between NL and formal query\nlanguages. Given questions, their QDMR structures (annotated by non-experts or\nautomatically predicted), and the answers, we are able to automatically\nsynthesize SQL queries that are used to train text-to-SQL models. We test our\napproach by experimenting on five benchmark datasets. Our results show that the\nweakly supervised models perform competitively with those trained on annotated\nNL-SQL data. Overall, we effectively train text-to-SQL parsers, while using\nzero SQL annotations.", "published": "2021-12-12 20:02:42", "link": "http://arxiv.org/abs/2112.06311v4", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Visualising and Explaining Deep Learning Models for Speech Quality\n  Prediction", "abstract": "Estimating quality of transmitted speech is known to be a non-trivial task.\nWhile traditionally, test participants are asked to rate the quality of\nsamples; nowadays, automated methods are available. These methods can be\ndivided into: 1) intrusive models, which use both, the original and the\ndegraded signals, and 2) non-intrusive models, which only require the degraded\nsignal. Recently, non-intrusive models based on neural networks showed to\noutperform signal processing based models. However, the advantages of deep\nlearning based models come with the cost of being more challenging to\ninterpret. To get more insight into the prediction models the non-intrusive\nspeech quality prediction model NISQA is analyzed in this paper. NISQA is\ncomposed of a convolutional neural network (CNN) and a recurrent neural network\n(RNN). The task of the CNN is to compute relevant features for the speech\nquality prediction on a frame level, while the RNN models time-dependencies\nbetween the individual speech frames. Different explanation algorithms are used\nto understand the automatically learned features of the CNN. In this way,\nseveral interpretable features could be identified, such as the sensitivity to\nnoise or strong interruptions. On the other hand, it was found that multiple\nfeatures carry redundant information.", "published": "2021-12-12 12:50:03", "link": "http://arxiv.org/abs/2112.06219v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "I.2.7"], "primary_category": "cs.SD"}
