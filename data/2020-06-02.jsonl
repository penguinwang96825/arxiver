{"title": "A Survey of Neural Networks and Formal Languages", "abstract": "This report is a survey of the relationships between various state-of-the-art\nneural network architectures and formal languages as, for example, structured\nby the Chomsky Language Hierarchy. Of particular interest are the abilities of\na neural architecture to represent, recognize and generate words from a\nspecific language by learning from samples of the language.", "published": "2020-06-02 01:46:04", "link": "http://arxiv.org/abs/2006.01338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embeddings of Label Components for Sequence Labeling: A Case Study of\n  Fine-grained Named Entity Recognition", "abstract": "In general, the labels used in sequence labeling consist of different types\nof elements. For example, IOB-format entity labels, such as B-Person and\nI-Person, can be decomposed into span (B and I) and type information (Person).\nHowever, while most sequence labeling models do not consider such label\ncomponents, the shared components across labels, such as Person, can be\nbeneficial for label prediction. In this work, we propose to integrate label\ncomponent information as embeddings into models. Through experiments on English\nand Japanese fine-grained named entity recognition, we demonstrate that the\nproposed method improves performance, especially for instances with\nlow-frequency labels.", "published": "2020-06-02 03:47:19", "link": "http://arxiv.org/abs/2006.01372v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERT Based Multilingual Machine Comprehension in English and Hindi", "abstract": "Multilingual Machine Comprehension (MMC) is a Question-Answering (QA)\nsub-task that involves quoting the answer for a question from a given snippet,\nwhere the question and the snippet can be in different languages. Recently\nreleased multilingual variant of BERT (m-BERT), pre-trained with 104 languages,\nhas performed well in both zero-shot and fine-tuned settings for multilingual\ntasks; however, it has not been used for English-Hindi MMC yet. We, therefore,\npresent in this article, our experiments with m-BERT for MMC in zero-shot,\nmono-lingual (e.g. Hindi Question-Hindi Snippet) and cross-lingual (e.g.\nEnglish QuestionHindi Snippet) fine-tune setups. These model variants are\nevaluated on all possible multilingual settings and results are compared\nagainst the current state-of-the-art sequential QA system for these languages.\nExperiments show that m-BERT, with fine-tuning, improves performance on all\nevaluation settings across both the datasets used by the prior model, therefore\nestablishing m-BERT based MMC as the new state-of-the-art for English and\nHindi. We also publish our results on an extended version of the recently\nreleased XQuAD dataset, which we propose to use as the evaluation benchmark for\nfuture research.", "published": "2020-06-02 07:36:49", "link": "http://arxiv.org/abs/2006.01432v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Contextual Hierarchical Attention Network with Adaptive Objective for\n  Dialogue State Tracking", "abstract": "Recent studies in dialogue state tracking (DST) leverage historical\ninformation to determine states which are generally represented as slot-value\npairs. However, most of them have limitations to efficiently exploit relevant\ncontext due to the lack of a powerful mechanism for modeling interactions\nbetween the slot and the dialogue history. Besides, existing methods usually\nignore the slot imbalance problem and treat all slots indiscriminately, which\nlimits the learning of hard slots and eventually hurts overall performance. In\nthis paper, we propose to enhance the DST through employing a contextual\nhierarchical attention network to not only discern relevant information at both\nword level and turn level but also learn contextual representations. We further\npropose an adaptive objective to alleviate the slot imbalance problem by\ndynamically adjust weights of different slots during training. Experimental\nresults show that our approach reaches 52.68% and 58.55% joint accuracy on\nMultiWOZ 2.0 and MultiWOZ 2.1 datasets respectively and achieves new\nstate-of-the-art performance with considerable improvements (+1.24% and\n+5.98%).", "published": "2020-06-02 12:25:44", "link": "http://arxiv.org/abs/2006.01554v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Cross-sentence Contexts for Named Entity Recognition with BERT", "abstract": "Named entity recognition (NER) is frequently addressed as a sequence\nclassification task where each input consists of one sentence of text. It is\nnevertheless clear that useful information for the task can often be found\noutside of the scope of a single-sentence context. Recently proposed\nself-attention models such as BERT can both efficiently capture long-distance\nrelationships in input as well as represent inputs consisting of several\nsentences, creating new opportunitites for approaches that incorporate\ncross-sentence information in natural language processing tasks. In this paper,\nwe present a systematic study exploring the use of cross-sentence information\nfor NER using BERT models in five languages. We find that adding context in the\nform of additional sentences to BERT input systematically increases NER\nperformance on all of the tested languages and models. Including multiple\nsentences in each input also allows us to study the predictions of the same\nsentences in different contexts. We propose a straightforward method,\nContextual Majority Voting (CMV), to combine different predictions for\nsentences and demonstrate this to further increase NER performance with BERT.\nOur approach does not require any changes to the underlying BERT architecture,\nrather relying on restructuring examples for training and prediction.\nEvaluation on established datasets, including the CoNLL'02 and CoNLL'03 NER\nbenchmarks, demonstrates that our proposed approach can improve on the\nstate-of-the-art NER results on English, Dutch, and Finnish, achieves the best\nreported BERT-based results on German, and is on par with performance reported\nwith other BERT-based approaches in Spanish. We release all methods implemented\nin this work under open licenses.", "published": "2020-06-02 12:34:52", "link": "http://arxiv.org/abs/2006.01563v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Unified Dual-view Model for Review Summarization and Sentiment\n  Classification with Inconsistency Loss", "abstract": "Acquiring accurate summarization and sentiment from user reviews is an\nessential component of modern e-commerce platforms. Review summarization aims\nat generating a concise summary that describes the key opinions and sentiment\nof a review, while sentiment classification aims to predict a sentiment label\nindicating the sentiment attitude of a review. To effectively leverage the\nshared sentiment information in both review summarization and sentiment\nclassification tasks, we propose a novel dual-view model that jointly improves\nthe performance of these two tasks. In our model, an encoder first learns a\ncontext representation for the review, then a summary decoder generates a\nreview summary word by word. After that, a source-view sentiment classifier\nuses the encoded context representation to predict a sentiment label for the\nreview, while a summary-view sentiment classifier uses the decoder hidden\nstates to predict a sentiment label for the generated summary. During training,\nwe introduce an inconsistency loss to penalize the disagreement between these\ntwo classifiers. It helps the decoder to generate a summary to have a\nconsistent sentiment tendency with the review and also helps the two sentiment\nclassifiers learn from each other. Experiment results on four real-world\ndatasets from different domains demonstrate the effectiveness of our model.", "published": "2020-06-02 13:34:11", "link": "http://arxiv.org/abs/2006.01592v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiscSense: Automated Semantic Analysis of Discourse Markers", "abstract": "Discourse markers ({\\it by contrast}, {\\it happily}, etc.) are words or\nphrases that are used to signal semantic and/or pragmatic relationships between\nclauses or sentences. Recent work has fruitfully explored the prediction of\ndiscourse markers between sentence pairs in order to learn accurate sentence\nrepresentations, that are useful in various classification tasks. In this work,\nwe take another perspective: using a model trained to predict discourse markers\nbetween sentence pairs, we predict plausible markers between sentence pairs\nwith a known semantic relation (provided by existing classification datasets).\nThese predictions allow us to study the link between discourse markers and the\nsemantic relations annotated in classification datasets. Handcrafted mappings\nhave been proposed between markers and discourse relations on a limited set of\nmarkers and a limited set of categories, but there exist hundreds of discourse\nmarkers expressing a wide variety of relations, and there is no consensus on\nthe taxonomy of relations between competing discourse theories (which are\nlargely built in a top-down fashion). By using an automatic rediction method\nover existing semantically annotated datasets, we provide a bottom-up\ncharacterization of discourse markers in English. The resulting dataset, named\nDiscSense, is publicly available.", "published": "2020-06-02 13:39:53", "link": "http://arxiv.org/abs/2006.01603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Web Document Categorization Using Naive Bayes Classifier and Latent\n  Semantic Analysis", "abstract": "A rapid growth of web documents due to heavy use of World Wide Web\nnecessitates efficient techniques to efficiently classify the document on the\nweb. It is thus produced High volumes of data per second with high diversity.\nAutomatically classification of these growing amounts of web document is One of\nthe biggest challenges facing us today. Probabilistic classification algorithms\nsuch as Naive Bayes have become commonly used for web document classification.\nThis problem is mainly because of the irrelatively high classification accuracy\non plenty application areas as well as their lack of support to handle high\ndimensional and sparse data which is the exclusive characteristics of textual\ndata representation. also it is common to Lack of attention and support the\nsemantic relation between words using traditional feature selection method When\ndealing with the big data and large-scale web documents. In order to solve the\nproblem, we proposed a method for web document classification that uses LSA to\nincrease similarity of documents under the same class and improve the\nclassification precision. Using this approach, we designed a faster and much\naccurate classifier for Web Documents. Experimental results have shown that\nusing the mentioned preprocessing can improve accuracy and speed of Naive Bayes\navailably, the precision and recall metrics have indicated the improvement.", "published": "2020-06-02 15:35:05", "link": "http://arxiv.org/abs/2006.01715v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Predictive Power of Neural Language Models for Human Real-Time\n  Comprehension Behavior", "abstract": "Human reading behavior is tuned to the statistics of natural language: the\ntime it takes human subjects to read a word can be predicted from estimates of\nthe word's probability in context. However, it remains an open question what\ncomputational architecture best characterizes the expectations deployed in real\ntime by humans that determine the behavioral signatures of reading. Here we\ntest over two dozen models, independently manipulating computational\narchitecture and training dataset size, on how well their next-word\nexpectations predict human reading time behavior on naturalistic text corpora.\nWe find that across model architectures and training dataset sizes the\nrelationship between word log-probability and reading time is (near-)linear. We\nnext evaluate how features of these models determine their psychometric\npredictive power, or ability to predict human reading behavior. In general, the\nbetter a model's next-word expectations, the better its psychometric predictive\npower. However, we find nontrivial differences across model architectures. For\nany given perplexity, deep Transformer models and n-gram models generally show\nsuperior psychometric predictive power over LSTM or structurally supervised\nneural models, especially for eye movement data. Finally, we compare models'\npsychometric predictive power to the depth of their syntactic knowledge, as\nmeasured by a battery of syntactic generalization tests developed using methods\nfrom controlled psycholinguistic experiments. Once perplexity is controlled\nfor, we find no significant relationship between syntactic knowledge and\npredictive power. These results suggest that different approaches may be\nrequired to best model human real-time language comprehension behavior in\nnaturalistic reading versus behavior for controlled linguistic materials\ndesigned for targeted probing of syntactic knowledge.", "published": "2020-06-02 19:47:01", "link": "http://arxiv.org/abs/2006.01912v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Typology of Polysemy: A Multilingual Distributional Framework", "abstract": "Lexical semantic typology has identified important cross-linguistic\ngeneralizations about the variation and commonalities in polysemy\npatterns---how languages package up meanings into words. Recent computational\nresearch has enabled investigation of lexical semantics at a much larger scale,\nbut little work has explored lexical typology across semantic domains, nor the\nfactors that influence cross-linguistic similarities. We present a novel\ncomputational framework that quantifies semantic affinity, the cross-linguistic\nsimilarity of lexical semantics for a concept. Our approach defines a common\nmultilingual semantic space that enables a direct comparison of the lexical\nexpression of concepts across languages. We validate our framework against\nempirical findings on lexical semantic typology at both the concept and domain\nlevels. Our results reveal an intricate interaction between semantic domains\nand extra-linguistic factors, beyond language phylogeny, that co-shape the\ntypology of polysemy across languages.", "published": "2020-06-02 22:31:40", "link": "http://arxiv.org/abs/2006.01966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open-Domain Question Answering with Pre-Constructed Question Spaces", "abstract": "Open-domain question answering aims at solving the task of locating the\nanswers to user-generated questions in massive collections of documents. There\nare two families of solutions available: retriever-readers, and\nknowledge-graph-based approaches. A retriever-reader usually first uses\ninformation retrieval methods like TF-IDF to locate some documents or\nparagraphs that are likely to be relevant to the question, and then feeds the\nretrieved text to a neural network reader to extract the answer. Alternatively,\nknowledge graphs can be constructed from the corpus and be queried against to\nanswer user questions. We propose a novel algorithm with a reader-retriever\nstructure that differs from both families. Our reader-retriever first uses an\noffline reader to read the corpus and generate collections of all answerable\nquestions associated with their answers, and then uses an online retriever to\nrespond to user queries by searching the pre-constructed question spaces for\nanswers that are most likely to be asked in the given way. We further combine\nretriever-reader and reader-retriever results into one single answer by\nexamining the consistency between the two components. We claim that our\nalgorithm solves some bottlenecks in existing work, and demonstrate that it\nachieves superior accuracy on real-world datasets.", "published": "2020-06-02 04:31:09", "link": "http://arxiv.org/abs/2006.08337v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subjective Question Answering: Deciphering the inner workings of\n  Transformers in the realm of subjectivity", "abstract": "Understanding subjectivity demands reasoning skills beyond the realm of\ncommon knowledge. It requires a machine learning model to process sentiment and\nto perform opinion mining. In this work, I've exploited a recently released\ndataset for span-selection Question Answering, namely SubjQA. SubjQA is the\nfirst QA dataset that contains questions that ask for subjective opinions\ncorresponding to review paragraphs from six different domains. Hence, to answer\nthese subjective questions, a learner must extract opinions and process\nsentiment for various domains, and additionally, align the knowledge extracted\nfrom a paragraph with the natural language utterances in the corresponding\nquestion, which together enhance the difficulty of a QA task. The primary goal\nof this thesis was to investigate the inner workings (i.e., latent\nrepresentations) of a Transformer-based architecture to contribute to a better\nunderstanding of these not yet well understood \"black-box\" models.\nTransformer's hidden representations, concerning the true answer span, are\nclustered more closely in vector space than those representations corresponding\nto erroneous predictions. This observation holds across the top three\nTransformer layers for both objective and subjective questions and generally\nincreases as a function of layer dimensions. Moreover, the probability to\nachieve a high cosine similarity among hidden representations in latent space\nconcerning the true answer span tokens is significantly higher for correct\ncompared to incorrect answer span predictions. These results have decisive\nimplications for down-stream applications, where it is crucial to know about\nwhy a neural network made mistakes, and in which point, in space and time the\nmistake has happened (e.g., to automatically predict correctness of an answer\nspan prediction without the necessity of labeled data).", "published": "2020-06-02 13:48:14", "link": "http://arxiv.org/abs/2006.08342v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Pairwise Probe for Understanding BERT Fine-Tuning on Machine Reading\n  Comprehension", "abstract": "Pre-trained models have brought significant improvements to many NLP tasks\nand have been extensively analyzed. But little is known about the effect of\nfine-tuning on specific tasks. Intuitively, people may agree that a pre-trained\nmodel already learns semantic representations of words (e.g. synonyms are\ncloser to each other) and fine-tuning further improves its capabilities which\nrequire more complicated reasoning (e.g. coreference resolution, entity\nboundary detection, etc). However, how to verify these arguments analytically\nand quantitatively is a challenging task and there are few works focus on this\ntopic. In this paper, inspired by the observation that most probing tasks\ninvolve identifying matched pairs of phrases (e.g. coreference requires\nmatching an entity and a pronoun), we propose a pairwise probe to understand\nBERT fine-tuning on the machine reading comprehension (MRC) task. Specifically,\nwe identify five phenomena in MRC. According to pairwise probing tasks, we\ncompare the performance of each layer's hidden representation of pre-trained\nand fine-tuned BERT. The proposed pairwise probe alleviates the problem of\ndistraction from inaccurate model training and makes a robust and quantitative\ncomparison. Our experimental analysis leads to highly confident conclusions:\n(1) Fine-tuning has little effect on the fundamental and low-level information\nand general semantic tasks. (2) For specific abilities required for downstream\ntasks, fine-tuned BERT is better than pre-trained BERT and such gaps are\nobvious after the fifth layer.", "published": "2020-06-02 02:12:19", "link": "http://arxiv.org/abs/2006.01346v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Enhanced Universal Dependency Parsing with Second-Order Inference and\n  Mixture of Training Data", "abstract": "This paper presents the system used in our submission to the \\textit{IWPT\n2020 Shared Task}. Our system is a graph-based parser with second-order\ninference. For the low-resource Tamil corpus, we specially mixed the training\ndata of Tamil with other languages and significantly improved the performance\nof Tamil. Due to our misunderstanding of the submission requirements, we\nsubmitted graphs that are not connected, which makes our system only rank\n\\textbf{6th} over 10 teams. However, after we fixed this problem, our system is\n0.6 ELAS higher than the team that ranked \\textbf{1st} in the official results.", "published": "2020-06-02 06:42:22", "link": "http://arxiv.org/abs/2006.01414v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WikiBERT models: deep transfer learning for many languages", "abstract": "Deep neural language models such as BERT have enabled substantial recent\nadvances in many natural language processing tasks. Due to the effort and\ncomputational cost involved in their pre-training, language-specific models are\ntypically introduced only for a small number of high-resource languages such as\nEnglish. While multilingual models covering large numbers of languages are\navailable, recent work suggests monolingual training can produce better models,\nand our understanding of the tradeoffs between mono- and multilingual training\nis incomplete. In this paper, we introduce a simple, fully automated pipeline\nfor creating language-specific BERT models from Wikipedia data and introduce 42\nnew such models, most for languages up to now lacking dedicated deep neural\nlanguage models. We assess the merits of these models using the\nstate-of-the-art UDify parser on Universal Dependencies data, contrasting\nperformance with results using the multilingual BERT model. We find that UDify\nusing WikiBERT models outperforms the parser using mBERT on average, with the\nlanguage-specific models showing substantially improved performance for some\nlanguages, yet limited improvement or a decrease in performance for others. We\nalso present preliminary results as first steps toward an understanding of the\nconditions under which language-specific models are most beneficial. All of the\nmethods and models introduced in this work are available under open licenses\nfrom https://github.com/turkunlp/wikibert.", "published": "2020-06-02 11:57:53", "link": "http://arxiv.org/abs/2006.01538v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Event Arguments Extraction via Dilate Gated Convolutional Neural Network\n  with Enhanced Local Features", "abstract": "Event Extraction plays an important role in information-extraction to\nunderstand the world. Event extraction could be split into two subtasks: one is\nevent trigger extraction, the other is event arguments extraction. However, the\nF-Score of event arguments extraction is much lower than that of event trigger\nextraction, i.e. in the most recent work, event trigger extraction achieves\n80.7%, while event arguments extraction achieves only 58%. In pipelined\nstructures, the difficulty of event arguments extraction lies in its lack of\nclassification feature, and the much higher computation consumption. In this\nwork, we proposed a novel Event Extraction approach based on multi-layer Dilate\nGated Convolutional Neural Network (EE-DGCNN) which has fewer parameters. In\naddition, enhanced local information is incorporated into word features, to\nassign event arguments roles for triggers predicted by the first subtask. The\nnumerical experiments demonstrated significant performance improvement beyond\nstate-of-art event extraction approaches on real-world datasets. Further\nanalysis of extraction procedure is presented, as well as experiments are\nconducted to analyze impact factors related to the performance improvement.", "published": "2020-06-02 18:05:34", "link": "http://arxiv.org/abs/2006.01854v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Nurse is Closer to Woman than Surgeon? Mitigating Gender-Biased\n  Proximities in Word Embeddings", "abstract": "Word embeddings are the standard model for semantic and syntactic\nrepresentations of words. Unfortunately, these models have been shown to\nexhibit undesirable word associations resulting from gender, racial, and\nreligious biases. Existing post-processing methods for debiasing word\nembeddings are unable to mitigate gender bias hidden in the spatial arrangement\nof word vectors. In this paper, we propose RAN-Debias, a novel gender debiasing\nmethodology which not only eliminates the bias present in a word vector but\nalso alters the spatial distribution of its neighbouring vectors, achieving a\nbias-free setting while maintaining minimal semantic offset. We also propose a\nnew bias evaluation metric - Gender-based Illicit Proximity Estimate (GIPE),\nwhich measures the extent of undue proximity in word vectors resulting from the\npresence of gender-based predilections. Experiments based on a suite of\nevaluation metrics show that RAN-Debias significantly outperforms the\nstate-of-the-art in reducing proximity bias (GIPE) by at least 42.02%. It also\nreduces direct bias, adding minimal semantic disturbance, and achieves the best\nperformance in a downstream application task (coreference resolution).", "published": "2020-06-02 20:50:43", "link": "http://arxiv.org/abs/2006.01938v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "REL: An Entity Linker Standing on the Shoulders of Giants", "abstract": "Entity linking is a standard component in modern retrieval system that is\noften performed by third-party toolkits. Despite the plethora of open source\noptions, it is difficult to find a single system that has a modular\narchitecture where certain components may be replaced, does not depend on\nexternal sources, can easily be updated to newer Wikipedia versions, and, most\nimportant of all, has state-of-the-art performance. The REL system presented in\nthis paper aims to fill that gap. Building on state-of-the-art neural\ncomponents from natural language processing research, it is provided as a\nPython package as well as a web API. We also report on an experimental\ncomparison against both well-established systems and the current\nstate-of-the-art on standard entity linking benchmarks.", "published": "2020-06-02 22:51:17", "link": "http://arxiv.org/abs/2006.01969v1", "categories": ["cs.IR", "cs.CL", "H.3"], "primary_category": "cs.IR"}
{"title": "Graph-Stega: Semantic Controllable Steganographic Text Generation Guided\n  by Knowledge Graph", "abstract": "Most of the existing text generative steganographic methods are based on\ncoding the conditional probability distribution of each word during the\ngeneration process, and then selecting specific words according to the secret\ninformation, so as to achieve information hiding. Such methods have their\nlimitations which may bring potential security risks. Firstly, with the\nincrease of embedding rate, these models will choose words with lower\nconditional probability, which will reduce the quality of the generated\nsteganographic texts; secondly, they can not control the semantic expression of\nthe final generated steganographic text. This paper proposes a new text\ngenerative steganography method which is quietly different from the existing\nmodels. We use a Knowledge Graph (KG) to guide the generation of steganographic\nsentences. On the one hand, we hide the secret information by coding the path\nin the knowledge graph, but not the conditional probability of each generated\nword; on the other hand, we can control the semantic expression of the\ngenerated steganographic text to a certain extent. The experimental results\nshow that the proposed model can guarantee both the quality of the generated\ntext and its semantic expression, which is a supplement and improvement to the\ncurrent text generation steganography.", "published": "2020-06-02 06:53:21", "link": "http://arxiv.org/abs/2006.08339v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Analyzing the Quality and Stability of a Streaming End-to-End On-Device\n  Speech Recognizer", "abstract": "The demand for fast and accurate incremental speech recognition increases as\nthe applications of automatic speech recognition (ASR) proliferate. Incremental\nspeech recognizers output chunks of partially recognized words while the user\nis still talking. Partial results can be revised before the ASR finalizes its\nhypothesis, causing instability issues. We analyze the quality and stability of\non-device streaming end-to-end (E2E) ASR models. We first introduce a novel set\nof metrics that quantify the instability at word and segment levels. We study\nthe impact of several model training techniques that improve E2E model\nqualities but degrade model stability. We categorize the causes of instability\nand explore various solutions to mitigate them in a streaming E2E ASR system.\nIndex Terms: ASR, stability, end-to-end, text normalization,on-device, RNN-T", "published": "2020-06-02 06:47:27", "link": "http://arxiv.org/abs/2006.01416v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "An Empirical Methodology for Detecting and Prioritizing Needs during\n  Crisis Events", "abstract": "In times of crisis, identifying the essential needs is a crucial step to\nproviding appropriate resources and services to affected entities. Social media\nplatforms such as Twitter contain vast amount of information about the general\npublic's needs. However, the sparsity of the information as well as the amount\nof noisy content present a challenge to practitioners to effectively identify\nshared information on these platforms. In this study, we propose two novel\nmethods for two distinct but related needs detection tasks: the identification\nof 1) a list of resources needed ranked by priority, and 2) sentences that\nspecify who-needs-what resources. We evaluated our methods on a set of tweets\nabout the COVID-19 crisis. For task 1 (detecting top needs), we compared our\nresults against two given lists of resources and achieved 64% precision. For\ntask 2 (detecting who-needs-what), we compared our results on a set of 1,000\nannotated tweets and achieved a 68% F1-score.", "published": "2020-06-02 08:02:29", "link": "http://arxiv.org/abs/2006.01439v1", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Situated and Interactive Multimodal Conversations", "abstract": "Next generation virtual assistants are envisioned to handle multimodal inputs\n(e.g., vision, memories of previous interactions, in addition to the user's\nutterances), and perform multimodal actions (e.g., displaying a route in\naddition to generating the system's utterance). We introduce Situated\nInteractive MultiModal Conversations (SIMMC) as a new direction aimed at\ntraining agents that take multimodal actions grounded in a co-evolving\nmultimodal input context in addition to the dialog history. We provide two\nSIMMC datasets totalling ~13K human-human dialogs (~169K utterances) using a\nmultimodal Wizard-of-Oz (WoZ) setup, on two shopping domains: (a) furniture\n(grounded in a shared virtual environment) and, (b) fashion (grounded in an\nevolving set of images). We also provide logs of the items appearing in each\nscene, and contextual NLU and coreference annotations, using a novel and\nunified framework of SIMMC conversational acts for both user and assistant\nutterances. Finally, we present several tasks within SIMMC as objective\nevaluation protocols, such as Structural API Prediction and Response\nGeneration. We benchmark a collection of existing models on these SIMMC tasks\nas strong baselines, and demonstrate rich multimodal conversational\ninteractions. Our data, annotations, code, and models are publicly available.", "published": "2020-06-02 09:02:23", "link": "http://arxiv.org/abs/2006.01460v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Question Answering on Scholarly Knowledge Graphs", "abstract": "Answering questions on scholarly knowledge comprising text and other\nartifacts is a vital part of any research life cycle. Querying scholarly\nknowledge and retrieving suitable answers is currently hardly possible due to\nthe following primary reason: machine inactionable, ambiguous and unstructured\ncontent in publications. We present JarvisQA, a BERT based system to answer\nquestions on tabular views of scholarly knowledge graphs. Such tables can be\nfound in a variety of shapes in the scholarly literature (e.g., surveys,\ncomparisons or results). Our system can retrieve direct answers to a variety of\ndifferent questions asked on tabular data in articles. Furthermore, we present\na preliminary dataset of related tables and a corresponding set of natural\nlanguage questions. This dataset is used as a benchmark for our system and can\nbe reused by others. Additionally, JarvisQA is evaluated on two datasets\nagainst other baselines and shows an improvement of two to three folds in\nperformance compared to related methods.", "published": "2020-06-02 11:24:02", "link": "http://arxiv.org/abs/2006.01527v1", "categories": ["cs.IR", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Relational Learning Analysis of Social Politics using Knowledge Graph\n  Embedding", "abstract": "Knowledge Graphs (KGs) have gained considerable attention recently from both\nacademia and industry. In fact, incorporating graph technology and the copious\nof various graph datasets have led the research community to build\nsophisticated graph analytics tools. Therefore, the application of KGs has\nextended to tackle a plethora of real-life problems in dissimilar domains.\nDespite the abundance of the currently proliferated generic KGs, there is a\nvital need to construct domain-specific KGs. Further, quality and credibility\nshould be assimilated in the process of constructing and augmenting KGs,\nparticularly those propagated from mixed-quality resources such as social media\ndata. This paper presents a novel credibility domain-based KG Embedding\nframework. This framework involves capturing a fusion of data obtained from\nheterogeneous resources into a formal KG representation depicted by a domain\nontology. The proposed approach makes use of various knowledge-based\nrepositories to enrich the semantics of the textual contents, thereby\nfacilitating the interoperability of information. The proposed framework also\nembodies a credibility module to ensure data quality and trustworthiness. The\nconstructed KG is then embedded in a low-dimension semantically-continuous\nspace using several embedding techniques. The utility of the constructed KG and\nits embeddings is demonstrated and substantiated on link prediction,\nclustering, and visualisation tasks.", "published": "2020-06-02 14:10:28", "link": "http://arxiv.org/abs/2006.01626v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Neural Speaker Diarization with Speaker-Wise Chain Rule", "abstract": "Speaker diarization is an essential step for processing multi-speaker audio.\nAlthough an end-to-end neural diarization (EEND) method achieved\nstate-of-the-art performance, it is limited to a fixed number of speakers. In\nthis paper, we solve this fixed number of speaker issue by a novel speaker-wise\nconditional inference method based on the probabilistic chain rule. In the\nproposed method, each speaker's speech activity is regarded as a single random\nvariable, and is estimated sequentially conditioned on previously estimated\nother speakers' speech activities. Similar to other sequence-to-sequence\nmodels, the proposed method produces a variable number of speakers with a stop\nsequence condition. We evaluated the proposed method on multi-speaker audio\nrecordings of a variable number of speakers. Experimental results show that the\nproposed method can correctly produce diarization results with a variable\nnumber of speakers and outperforms the state-of-the-art end-to-end speaker\ndiarization methods in terms of diarization error rate.", "published": "2020-06-02 17:28:12", "link": "http://arxiv.org/abs/2006.01796v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improved acoustic word embeddings for zero-resource languages using\n  multilingual transfer", "abstract": "Acoustic word embeddings are fixed-dimensional representations of\nvariable-length speech segments. Such embeddings can form the basis for speech\nsearch, indexing and discovery systems when conventional speech recognition is\nnot possible. In zero-resource settings where unlabelled speech is the only\navailable resource, we need a method that gives robust embeddings on an\narbitrary language. Here we explore multilingual transfer: we train a single\nsupervised embedding model on labelled data from multiple well-resourced\nlanguages and then apply it to unseen zero-resource languages. We consider\nthree multilingual recurrent neural network (RNN) models: a classifier trained\non the joint vocabularies of all training languages; a Siamese RNN trained to\ndiscriminate between same and different words from multiple languages; and a\ncorrespondence autoencoder (CAE) RNN trained to reconstruct word pairs. In a\nword discrimination task on six target languages, all of these models\noutperform state-of-the-art unsupervised models trained on the zero-resource\nlanguages themselves, giving relative improvements of more than 30% in average\nprecision. When using only a few training languages, the multilingual CAE\nperforms better, but with more training languages the other multilingual models\nperform similarly. Using more training languages is generally beneficial, but\nimprovements are marginal on some languages. We present probing experiments\nwhich show that the CAE encodes more phonetic, word duration, language identity\nand speaker information than the other multilingual models.", "published": "2020-06-02 12:28:34", "link": "http://arxiv.org/abs/2006.02295v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Position Masking for Language Models", "abstract": "Masked language modeling (MLM) pre-training models such as BERT corrupt the\ninput by replacing some tokens with [MASK] and then train a model to\nreconstruct the original tokens. This is an effective technique which has led\nto good results on all NLP benchmarks. We propose to expand upon this idea by\nmasking the positions of some tokens along with the masked input token ids. We\nfollow the same standard approach as BERT masking a percentage of the tokens\npositions and then predicting their original values using an additional fully\nconnected classifier stage. This approach has shown good performance gains\n(.3\\% improvement) for the SQUAD additional improvement in convergence times.\nFor the Graphcore IPU the convergence of BERT Base with position masking\nrequires only 50\\% of the tokens from the original BERT paper.", "published": "2020-06-02 23:40:41", "link": "http://arxiv.org/abs/2006.05676v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "An ASR Guided Speech Intelligibility Measure for TTS Model Selection", "abstract": "The perceptual quality of neural text-to-speech (TTS) is highly dependent on\nthe choice of the model during training. Selecting the model using a\ntraining-objective metric such as the least mean squared error does not always\ncorrelate with human perception. In this paper, we propose an objective metric\nbased on the phone error rate (PER) to select the TTS model with the best\nspeech intelligibility. The PER is computed between the input text to the TTS\nmodel, and the text decoded from the synthesized speech using an automatic\nspeech recognition (ASR) model, which is trained on the same data as the TTS\nmodel. With the help of subjective studies, we show that the TTS model chosen\nwith the least PER on validation split has significantly higher speech\nintelligibility compared to the model with the least training-objective metric\nloss. Finally, using the proposed PER and subjective evaluation, we show that\nthe choice of best TTS model depends on the genre of the target domain text.\nAll our experiments are conducted on a Hindi language dataset. However, the\nproposed model selection method is language independent.", "published": "2020-06-02 09:06:41", "link": "http://arxiv.org/abs/2006.01463v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Dataset of Reverberant Spatial Sound Scenes with Moving Sources for\n  Sound Event Localization and Detection", "abstract": "This report presents the dataset and the evaluation setup of the Sound Event\nLocalization & Detection (SELD) task for the DCASE 2020 Challenge. The SELD\ntask refers to the problem of trying to simultaneously classify a known set of\nsound event classes, detect their temporal activations, and estimate their\nspatial directions or locations while they are active. To train and test SELD\nsystems, datasets of diverse sound events occurring under realistic acoustic\nconditions are needed. Compared to the previous challenge, a significantly more\ncomplex dataset was created for DCASE 2020. The two key differences are a more\ndiverse range of acoustical conditions, and dynamic conditions, i.e. moving\nsources. The spatial sound scenes are created using real room impulse responses\ncaptured in a continuous manner with a slowly moving excitation source. Both\nstatic and moving sound events are synthesized from them. Ambient noise\nrecorded on location is added to complete the generation of scene recordings. A\nbaseline SELD method accompanies the dataset, based on a convolutional\nrecurrent neural network, to provide benchmark scores for the task. The\nbaseline is an updated version of the one used in the previous challenge, with\ninput features and training modifications to improve its performance.", "published": "2020-06-02 20:01:25", "link": "http://arxiv.org/abs/2006.01919v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Cross entropy as objective function for music generative models", "abstract": "The election of the function to optimize when training a machine learning\nmodel is very important since this is which lets the model learn. It is not\ntrivial since there are many options, each for different purposes. In the case\nof sequence generation of text, cross entropy is a common option because of its\ncapability to quantify the predictive behavior of the model. In this paper, we\ntest the validity of cross entropy for a music generator model with an\nexperiment that aims to correlate improvements in the loss value with the\nreduction of randomness and the ability to keep consistent melodies. We also\nanalyze the relationship between these two aspects which respectively relate to\nshort and long term memory and how they behave and are learned differently.", "published": "2020-06-02 16:11:04", "link": "http://arxiv.org/abs/2006.02217v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dilated U-net based approach for multichannel speech enhancement from\n  First-Order Ambisonics recordings", "abstract": "We present a CNN architecture for speech enhancement from multichannel\nfirst-order Ambisonics mixtures. The data-dependent spatial filters, deduced\nfrom a mask-based approach, are used to help an automatic speech recognition\nengine to face adverse conditions of reverberation and competitive speakers.\nThe mask predictions are provided by a neural network, fed with rough\nestimations of speech and noise amplitude spectra, under the assumption of\nknown directions of arrival. This study evaluates the replacing of the\nrecurrent LSTM network previously investigated by a convolutive U-net under\nmore stressing conditions with an additional second competitive speaker. We\nshow that, due to more accurate short-term masks prediction, the U-net\narchitecture brings some improvements in terms of word error rate. Moreover,\nresults indicate that the use of dilated convolutive layers is beneficial in\ndifficult situations with two interfering speakers, and/or where the target and\ninterferences are close to each other in terms of the angular distance.\nMoreover, these results come with a two-fold reduction in the number of\nparameters.", "published": "2020-06-02 15:26:07", "link": "http://arxiv.org/abs/2006.01708v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Quantifying the Effects of Prosody Modulation on User Engagement and\n  Satisfaction in Conversational Systems", "abstract": "As voice-based assistants such as Alexa, Siri, and Google Assistant become\nubiquitous, users increasingly expect to maintain natural and informative\nconversations with such systems. However, for an open-domain conversational\nsystem to be coherent and engaging, it must be able to maintain the user's\ninterest for extended periods, without sounding boring or annoying. In this\npaper, we investigate one natural approach to this problem, of modulating\nresponse prosody, i.e., changing the pitch and cadence of the response to\nindicate delight, sadness or other common emotions, as well as using\npre-recorded interjections. Intuitively, this approach should improve the\nnaturalness of the conversation, but attempts to quantify the effects of\nprosodic modulation on user satisfaction and engagement remain challenging. To\naccomplish this, we report results obtained from a large-scale empirical study\nthat measures the effects of prosodic modulation on user behavior and\nengagement across multiple conversation domains, both immediately after each\nturn, and at the overall conversation level. Our results indicate that the\nprosody modulation significantly increases both immediate and overall user\nsatisfaction. However, since the effects vary across different domains, we\nverify that prosody modulations do not substitute for coherent, informative\ncontent of the responses. Together, our results provide useful tools and\ninsights for improving the naturalness of responses in conversational systems.", "published": "2020-06-02 19:53:13", "link": "http://arxiv.org/abs/2006.01916v1", "categories": ["cs.HC", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Detecting Audio Attacks on ASR Systems with Dropout Uncertainty", "abstract": "Various adversarial audio attacks have recently been developed to fool\nautomatic speech recognition (ASR) systems. We here propose a defense against\nsuch attacks based on the uncertainty introduced by dropout in neural networks.\nWe show that our defense is able to detect attacks created through optimized\nperturbations and frequency masking on a state-of-the-art end-to-end ASR\nsystem. Furthermore, the defense can be made robust against attacks that are\nimmune to noise reduction. We test our defense on Mozilla's CommonVoice\ndataset, the UrbanSound dataset, and an excerpt of the LibriSpeech dataset,\nshowing that it achieves high detection accuracy in a wide range of scenarios.", "published": "2020-06-02 19:40:38", "link": "http://arxiv.org/abs/2006.01906v2", "categories": ["eess.AS", "cs.CR", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
