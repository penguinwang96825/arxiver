{"title": "Revolutionizing Finance with LLMs: An Overview of Applications and\n  Insights", "abstract": "In recent years, Large Language Models (LLMs) like ChatGPT have seen\nconsiderable advancements and have been applied in diverse fields. Built on the\nTransformer architecture, these models are trained on extensive datasets,\nenabling them to understand and generate human language effectively. In the\nfinancial domain, the deployment of LLMs is gaining momentum. These models are\nbeing utilized for automating financial report generation, forecasting market\ntrends, analyzing investor sentiment, and offering personalized financial\nadvice. Leveraging their natural language processing capabilities, LLMs can\ndistill key insights from vast financial data, aiding institutions in making\ninformed investment choices and enhancing both operational efficiency and\ncustomer satisfaction. In this study, we provide a comprehensive overview of\nthe emerging integration of LLMs into various financial tasks. Additionally, we\nconducted holistic tests on multiple financial tasks through the combination of\nnatural language instructions. Our findings show that GPT-4 effectively follow\nprompt instructions across various financial tasks. This survey and evaluation\nof LLMs in the financial domain aim to deepen the understanding of LLMs'\ncurrent role in finance for both financial practitioners and LLM researchers,\nidentify new research and application prospects, and highlight how these\ntechnologies can be leveraged to solve practical challenges in the finance\nindustry.", "published": "2024-01-22 01:06:17", "link": "http://arxiv.org/abs/2401.11641v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language\n  Conversion for Language Models", "abstract": "Symbols (or more broadly, non-natural language textual representations) such\nas numerical sequences, molecular formulas, and table delimiters widely exist,\nplaying important roles in various tasks such as abstract reasoning, chemical\nproperty prediction, and table question answering. Despite the impressive\nnatural language comprehension capabilities of large language models (LLMs),\ntheir reasoning abilities for symbols remain inadequate, which could attributed\nto the difference between symbol representations and general natural languages.\nWe propose symbol-to-language (S2L), a tuning-free method that enables large\nlanguage models to solve symbol-related problems with information expressed in\nnatural language. Specifically, S2L first converts the symbols involved to\nlanguage-based representations, which can be implemented by prompting LLMs or\nleveraging external tools, then these language-based representations are\nintegrated into the original problem via direct substitution or concatenation,\nserving as useful input information for LLMs. We evaluate the S2L method using\nboth API-based (GPT-4, ChatGPT) and open-source (OpenChat) models over eight\nsymbol-related tasks, ranging from symbol-only abstract reasoning to sentiment\nanalysis in social media. Experimental results show that S2L consistently leads\nto superior performance. For example, by employing S2L for GPT-4, there can be\naverage significant improvements of +21.9% and +9.5% for subtasks in 1D-ARC and\nDyck language, respectively. Codes and data are available at\nhttps://github.com/THUNLP-MT/symbol2language.", "published": "2024-01-22 07:07:06", "link": "http://arxiv.org/abs/2401.11725v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Claim Detection for Automated Fact-checking: A Survey on Monolingual,\n  Multilingual and Cross-Lingual Research", "abstract": "Automated fact-checking has drawn considerable attention over the past few\ndecades due to the increase in the diffusion of misinformation on online\nplatforms. This is often carried out as a sequence of tasks comprising (i) the\ndetection of sentences circulating in online platforms which constitute claims\nneeding verification, followed by (ii) the verification process of those\nclaims. This survey focuses on the former, by discussing existing efforts\ntowards detecting claims needing fact-checking, with a particular focus on\nmultilingual data and methods. This is a challenging and fertile direction\nwhere existing methods are yet far from matching human performance due to the\nprofoundly challenging nature of the issue. Especially, the dissemination of\ninformation across multiple social platforms, articulated in multiple languages\nand modalities demands more generalized solutions for combating misinformation.\nFocusing on multilingual misinformation, we present a comprehensive survey of\nexisting multilingual claim detection research. We present state-of-the-art\nmultilingual claim detection research categorized into three key factors of the\nproblem, verifiability, priority, and similarity. Further, we present a\ndetailed overview of the existing multilingual datasets along with the\nchallenges and suggest possible future advancements.", "published": "2024-01-22 14:17:03", "link": "http://arxiv.org/abs/2401.11969v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synergizing Machine Learning & Symbolic Methods: A Survey on Hybrid\n  Approaches to Natural Language Processing", "abstract": "The advancement of machine learning and symbolic approaches have underscored\ntheir strengths and weaknesses in Natural Language Processing (NLP). While\nmachine learning approaches are powerful in identifying patterns in data, they\noften fall short in learning commonsense and the factual knowledge required for\nthe NLP tasks. Meanwhile, the symbolic methods excel in representing\nknowledge-rich data. However, they struggle to adapt dynamic data and\ngeneralize the knowledge. Bridging these two paradigms through hybrid\napproaches enables the alleviation of weaknesses in both while preserving their\nstrengths. Recent studies extol the virtues of this union, showcasing promising\nresults in a wide range of NLP tasks. In this paper, we present an overview of\nhybrid approaches used for NLP. Specifically, we delve into the\nstate-of-the-art hybrid approaches used for a broad spectrum of NLP tasks\nrequiring natural language understanding, generation, and reasoning.\nFurthermore, we discuss the existing resources available for hybrid approaches\nfor NLP along with the challenges and future directions, offering a roadmap for\nfuture research avenues.", "published": "2024-01-22 14:24:03", "link": "http://arxiv.org/abs/2401.11972v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ALMs: Authorial Language Models for Authorship Attribution", "abstract": "In this paper, we introduce an authorship attribution method called Authorial\nLanguage Models (ALMs) that involves identifying the most likely author of a\nquestioned document based on the perplexity of the questioned document\ncalculated for a set of causal language models fine-tuned on the writings of a\nset of candidate author. We benchmarked ALMs against state-of-art-systems using\nthe CCAT50 dataset and the Blogs50 datasets. We find that ALMs achieves a\nmacro-average accuracy score of 83.6% on Blogs50, outperforming all other\nmethods, and 74.9% on CCAT50, matching the performance of the best method. To\nassess the performance of ALMs on shorter texts, we also conducted text\nablation testing. We found that to reach a macro-average accuracy of 70%, ALMs\nneeds 40 tokens on Blogs50 and 400 tokens on CCAT50, while to reach 60% ALMs\nrequires 20 tokens on Blogs50 and 70 tokens on CCAT50.", "published": "2024-01-22 14:53:59", "link": "http://arxiv.org/abs/2401.12005v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Transfer Learning for Javanese Dependency Parsing", "abstract": "While structure learning achieves remarkable performance in high-resource\nlanguages, the situation differs for under-represented languages due to the\nscarcity of annotated data. This study focuses on assessing the efficacy of\ntransfer learning in enhancing dependency parsing for Javanese, a language\nspoken by 80 million individuals but characterized by limited representation in\nnatural language processing. We utilized the Universal Dependencies dataset\nconsisting of dependency treebanks from more than 100 languages, including\nJavanese. We propose two learning strategies to train the model: transfer\nlearning (TL) and hierarchical transfer learning (HTL). While TL only uses a\nsource language to pre-train the model, the HTL method uses a source language\nand an intermediate language in the learning process. The results show that our\nbest model uses the HTL method, which improves performance with an increase of\n10% for both UAS and LAS evaluations compared to the baseline model.", "published": "2024-01-22 16:13:45", "link": "http://arxiv.org/abs/2401.12072v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Temporal Blind Spots in Large Language Models", "abstract": "Large language models (LLMs) have recently gained significant attention due\nto their unparalleled ability to perform various natural language processing\ntasks. These models, benefiting from their advanced natural language\nunderstanding capabilities, have demonstrated impressive zero-shot performance.\nHowever, the pre-training data utilized in LLMs is often confined to a specific\ncorpus, resulting in inherent freshness and temporal scope limitations.\nConsequently, this raises concerns regarding the effectiveness of LLMs for\ntasks involving temporal intents. In this study, we aim to investigate the\nunderlying limitations of general-purpose LLMs when deployed for tasks that\nrequire a temporal understanding. We pay particular attention to handling\nfactual temporal knowledge through three popular temporal QA datasets.\nSpecifically, we observe low performance on detailed questions about the past\nand, surprisingly, for rather new information. In manual and automatic testing,\nwe find multiple temporal errors and characterize the conditions under which QA\nperformance deteriorates. Our analysis contributes to understanding LLM\nlimitations and offers valuable insights into developing future models that can\nbetter cater to the demands of temporally-oriented tasks. The code is\navailable\\footnote{https://github.com/jwallat/temporalblindspots}.", "published": "2024-01-22 16:20:14", "link": "http://arxiv.org/abs/2401.12078v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Demonstration Selection Strategies in In-Context Learning", "abstract": "Large language models (LLMs) have shown an impressive ability to perform a\nwide range of tasks using in-context learning (ICL), where a few examples are\nused to describe a task to the model. However, the performance of ICL varies\nsignificantly with the choice of demonstrations, and it is still unclear why\nthis happens or what factors will influence its choice. In this work, we first\nrevisit the factors contributing to this variance from both data and model\naspects, and find that the choice of demonstration is both data- and\nmodel-dependent. We further proposed a data- and model-dependent demonstration\nselection method, \\textbf{TopK + ConE}, based on the assumption that\n\\textit{the performance of a demonstration positively correlates with its\ncontribution to the model's understanding of the test samples}, resulting in a\nsimple and effective recipe for ICL. Empirically, our method yields consistent\nimprovements in both language understanding and generation tasks with different\nmodel scales. Further analyses confirm that, besides the generality and\nstability under different circumstances, our method provides a unified\nexplanation for the effectiveness of previous methods. Code will be released.", "published": "2024-01-22 16:25:27", "link": "http://arxiv.org/abs/2401.12087v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Learning of Graph from Recipes", "abstract": "Cooking recipes are one of the most readily available kinds of procedural\ntext. They consist of natural language instructions that can be challenging to\ninterpret. In this paper, we propose a model to identify relevant information\nfrom recipes and generate a graph to represent the sequence of actions in the\nrecipe. In contrast with other approaches, we use an unsupervised approach. We\niteratively learn the graph structure and the parameters of a $\\mathsf{GNN}$\nencoding the texts (text-to-graph) one sequence at a time while providing the\nsupervision by decoding the graph into text (graph-to-text) and comparing the\ngenerated text to the input. We evaluate the approach by comparing the\nidentified entities with annotated datasets, comparing the difference between\nthe input and output texts, and comparing our generated graphs with those\ngenerated by state of the art methods.", "published": "2024-01-22 16:25:47", "link": "http://arxiv.org/abs/2401.12088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of In-context Learning in LLMs for Machine\n  Translation", "abstract": "Recent interest has surged in employing Large Language Models (LLMs) for\nmachine translation (MT) via in-context learning (ICL) (Vilar et al., 2023).\nMost prior studies primarily focus on optimizing translation quality, with\nlimited attention to understanding the specific aspects of ICL that influence\nthe said quality. To this end, we perform the first of its kind, an exhaustive\nstudy of in-context learning for machine translation. We first establish that\nICL is primarily example-driven and not instruction-driven. Following this, we\nconduct an extensive exploration of various aspects of the examples to\nunderstand their influence on downstream performance. Our analysis includes\nfactors such as quality and quantity of demonstrations, spatial proximity, and\nsource versus target originality. Further, we also investigate challenging\nscenarios involving indirectness and misalignment of examples to understand the\nlimits of ICL. While we establish the significance of the quality of the target\ndistribution over the source distribution of demonstrations, we further observe\nthat perturbations sometimes act as regularizers, resulting in performance\nimprovements. Surprisingly, ICL does not necessitate examples from the same\ntask, and a related task with the same target distribution proves sufficient.\nWe hope that our study acts as a guiding resource for considerations in\nutilizing ICL for MT. Our code is available on\nhttps://github.com/PranjalChitale/in-context-mt-analysis.", "published": "2024-01-22 16:35:00", "link": "http://arxiv.org/abs/2401.12097v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large\n  Language Models", "abstract": "While large language models (LLMs) are still being adopted to new domains and\nutilized in novel applications, we are experiencing an influx of the new\ngeneration of foundation models, namely multi-modal large language models\n(MLLMs). These models integrate verbal and visual information, opening new\npossibilities to demonstrate more complex reasoning abilities at the\nintersection of the two modalities. However, despite the revolutionizing\nprospect of MLLMs, our understanding of their reasoning abilities is limited.\nIn this study, we assess the nonverbal abstract reasoning abilities of\nopen-source and closed-source MLLMs using variations of Raven's Progressive\nMatrices. Our experiments reveal the challenging nature of such problems for\nMLLMs while showcasing the immense gap between open-source and closed-source\nmodels. We also uncover critical shortcomings of visual and textual\nperceptions, subjecting the models to low-performance ceilings. Finally, to\nimprove MLLMs' performance, we experiment with different methods, such as\nChain-of-Thought prompting, leading to a significant (up to 100%) boost in\nperformance. Our code and datasets are available at\nhttps://github.com/usc-isi-i2/isi-mmlm-rpm.", "published": "2024-01-22 16:57:05", "link": "http://arxiv.org/abs/2401.12117v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anisotropy Is Inherent to Self-Attention in Transformers", "abstract": "The representation degeneration problem is a phenomenon that is widely\nobserved among self-supervised learning methods based on Transformers. In NLP,\nit takes the form of anisotropy, a singular property of hidden representations\nwhich makes them unexpectedly close to each other in terms of angular distance\n(cosine-similarity). Some recent works tend to show that anisotropy is a\nconsequence of optimizing the cross-entropy loss on long-tailed distributions\nof tokens. We show in this paper that anisotropy can also be observed\nempirically in language models with specific objectives that should not suffer\ndirectly from the same consequences. We also show that the anisotropy problem\nextends to Transformers trained on other modalities. Our observations suggest\nthat anisotropy is actually inherent to Transformers-based models.", "published": "2024-01-22 17:26:55", "link": "http://arxiv.org/abs/2401.12143v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cheap Learning: Maximising Performance of Language Models for Social\n  Data Science Using Minimal Data", "abstract": "The field of machine learning has recently made significant progress in\nreducing the requirements for labelled training data when building new models.\nThese `cheaper' learning techniques hold significant potential for the social\nsciences, where development of large labelled training datasets is often a\nsignificant practical impediment to the use of machine learning for analytical\ntasks. In this article we review three `cheap' techniques that have developed\nin recent years: weak supervision, transfer learning and prompt engineering.\nFor the latter, we also review the particular case of zero-shot prompting of\nlarge language models. For each technique we provide a guide of how it works\nand demonstrate its application across six different realistic social science\napplications (two different tasks paired with three different dataset makeups).\nWe show good performance for all techniques, and in particular we demonstrate\nhow prompting of large language models can achieve high accuracy at very low\ncost. Our results are accompanied by a code repository to make it easy for\nothers to duplicate our work and use it in their own research. Overall, our\narticle is intended to stimulate further uptake of these techniques in the\nsocial sciences.", "published": "2024-01-22 19:00:11", "link": "http://arxiv.org/abs/2401.12295v1", "categories": ["cs.CL", "I.2.7; J.4"], "primary_category": "cs.CL"}
{"title": "Subgraph Extraction-based Feedback-guided Iterative Scheduling for HLS", "abstract": "This paper proposes ISDC, a novel feedback-guided iterative system of\ndifference constraints (SDC) scheduling algorithm for high-level synthesis\n(HLS). ISDC leverages subgraph extraction-based low-level feedback from\ndownstream tools like logic synthesizers to iteratively refine HLS scheduling.\nTechnical innovations include: (1) An enhanced SDC formulation that effectively\nintegrates low-level feedback into the linear-programming (LP) problem; (2) A\nfanout and window-based subgraph extraction mechanism driving the feedback\ncycle; (3) A no-human-in-loop ISDC flow compatible with a wide range of\ndownstream tools and process design kits (PDKs). Evaluation shows that ISDC\nreduces register usage by 28.5% against an industrial-strength open-source HLS\ntool.", "published": "2024-01-22 20:17:06", "link": "http://arxiv.org/abs/2401.12343v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in\n  Chinese", "abstract": "We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate\nthe mathematical reasoning abilities of Chinese language models. SC-Math6 is\ndesigned as an upgraded Chinese version of the GSM8K dataset with enhanced\ndifficulty, diversity, and application scope. It consists of over 2000\nmathematical word problems requiring multi-step reasoning and providing natural\nlanguage solutions. We propose an innovative scheme to quantify the reasoning\ncapability of large models based on performance over problems with different\nreasoning steps. Experiments on 13 representative Chinese models demonstrate a\nclear stratification of reasoning levels, with top models like GPT-4 showing\nsuperior performance. SC-Math6 fills the gap in Chinese mathematical reasoning\nbenchmarks and provides a comprehensive testbed to advance the intelligence of\nChinese language models.", "published": "2024-01-22 10:30:11", "link": "http://arxiv.org/abs/2401.11819v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AI for social science and social science of AI: A Survey", "abstract": "Recent advancements in artificial intelligence, particularly with the\nemergence of large language models (LLMs), have sparked a rethinking of\nartificial general intelligence possibilities. The increasing human-like\ncapabilities of AI are also attracting attention in social science research,\nleading to various studies exploring the combination of these two fields. In\nthis survey, we systematically categorize previous explorations in the\ncombination of AI and social science into two directions that share common\ntechnical approaches but differ in their research objectives. The first\ndirection is focused on AI for social science, where AI is utilized as a\npowerful tool to enhance various stages of social science research. While the\nsecond direction is the social science of AI, which examines AI agents as\nsocial entities with their human-like cognitive and linguistic capabilities. By\nconducting a thorough review, particularly on the substantial progress\nfacilitated by recent advancements in large language models, this paper\nintroduces a fresh perspective to reassess the relationship between AI and\nsocial science, provides a cohesive framework that allows researchers to\nunderstand the distinctions and connections between AI for social science and\nsocial science of AI, and also summarized state-of-art experiment simulation\nplatforms to facilitate research in these two directions. We believe that as AI\ntechnology continues to advance and intelligent agents find increasing\napplications in our daily lives, the significance of the combination of AI and\nsocial science will become even more prominent.", "published": "2024-01-22 10:57:09", "link": "http://arxiv.org/abs/2401.11839v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "The Right Model for the Job: An Evaluation of Legal Multi-Label\n  Classification Baselines", "abstract": "Multi-Label Classification (MLC) is a common task in the legal domain, where\nmore than one label may be assigned to a legal document. A wide range of\nmethods can be applied, ranging from traditional ML approaches to the latest\nTransformer-based architectures. In this work, we perform an evaluation of\ndifferent MLC methods using two public legal datasets, POSTURE50K and\nEURLEX57K. By varying the amount of training data and the number of labels, we\nexplore the comparative advantage offered by different approaches in relation\nto the dataset properties. Our findings highlight DistilRoBERTa and LegalBERT\nas performing consistently well in legal MLC with reasonable computational\ndemands. T5 also demonstrates comparable performance while offering advantages\nas a generative model in the presence of changing label sets. Finally, we show\nthat the CrossEncoder exhibits potential for notable macro-F1 score\nimprovements, albeit with increased computational costs.", "published": "2024-01-22 11:15:07", "link": "http://arxiv.org/abs/2401.11852v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Distilling Mathematical Reasoning Capabilities into Small Language\n  Models", "abstract": "This work addresses the challenge of democratizing advanced Large Language\nModels (LLMs) by compressing their mathematical reasoning capabilities into\nsub-billion parameter Small Language Models (SLMs) without compromising\nperformance. We introduce Equation-of-Thought Distillation (EoTD), a novel\ntechnique that encapsulates the reasoning process into equation-based\nrepresentations to construct an EoTD dataset for fine-tuning SLMs.\nAdditionally, we propose the Ensemble Thoughts Distillation (ETD) framework to\nenhance the reasoning performance of SLMs. This involves creating a reasoning\ndataset with multiple thought processes, including Chain-of-Thought (CoT),\nProgram-of-Thought (PoT), and Equation-of-Thought (EoT), and using it for\nfine-tuning. Our experimental performance demonstrates that EoTD significantly\nboosts the reasoning abilities of SLMs, while ETD enables these models to\nachieve state-of-the-art reasoning performance.", "published": "2024-01-22 11:37:18", "link": "http://arxiv.org/abs/2401.11864v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Blinded by Generated Contexts: How Language Models Merge Generated and\n  Retrieved Contexts When Knowledge Conflicts?", "abstract": "While auxiliary information has become a key to enhancing Large Language\nModels (LLMs), relatively little is known about how LLMs merge these contexts,\nspecifically contexts generated by LLMs and those retrieved from external\nsources. To investigate this, we formulate a systematic framework to identify\nwhether LLMs' responses are attributed to either generated or retrieved\ncontexts. To easily trace the origin of the response, we construct datasets\nwith conflicting contexts, i.e., each question is paired with both generated\nand retrieved contexts, yet only one of them contains the correct answer. Our\nexperiments reveal a significant bias in several LLMs (GPT-4/3.5 and Llama2) to\nfavor generated contexts, even when they provide incorrect information. We\nfurther identify two key factors contributing to this bias: i) contexts\ngenerated by LLMs typically show greater similarity to the questions,\nincreasing their likelihood of being selected; ii) the segmentation process\nused in retrieved contexts disrupts their completeness, thereby hindering their\nfull utilization in LLMs. Our analysis enhances the understanding of how LLMs\nmerge diverse contexts, offers valuable insights for advancing current LLM\naugmentation methods, and highlights the risk of generated misinformation for\nretrieval-augmented LLMs.", "published": "2024-01-22 12:54:04", "link": "http://arxiv.org/abs/2401.11911v6", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "In-Context Learning for Extreme Multi-Label Classification", "abstract": "Multi-label classification problems with thousands of classes are hard to\nsolve with in-context learning alone, as language models (LMs) might lack prior\nknowledge about the precise classes or how to assign them, and it is generally\ninfeasible to demonstrate every class in a prompt. We propose a general\nprogram, $\\texttt{Infer--Retrieve--Rank}$, that defines multi-step interactions\nbetween LMs and retrievers to efficiently tackle such problems. We implement\nthis program using the $\\texttt{DSPy}$ programming model, which specifies\nin-context systems in a declarative manner, and use $\\texttt{DSPy}$ optimizers\nto tune it towards specific datasets by bootstrapping only tens of few-shot\nexamples. Our primary extreme classification program, optimized separately for\neach task, attains state-of-the-art results across three benchmarks (HOUSE,\nTECH, TECHWOLF). We apply the same program to a benchmark with vastly different\ncharacteristics and attain competitive performance as well (BioDEX). Unlike\nprior work, our proposed solution requires no finetuning, is easily applicable\nto new tasks, alleviates prompt engineering, and requires only tens of labeled\nexamples. Our code is public at https://github.com/KarelDO/xmc.dspy.", "published": "2024-01-22 18:09:52", "link": "http://arxiv.org/abs/2401.12178v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "APT: Adaptive Pruning and Tuning Pretrained Language Models for\n  Efficient Training and Inference", "abstract": "Fine-tuning and inference with large Language Models (LM) are generally known\nto be expensive. Parameter-efficient fine-tuning over pretrained LMs reduces\ntraining memory by updating a small number of LM parameters but does not\nimprove inference efficiency. Structured pruning improves LM inference\nefficiency by removing consistent parameter blocks, yet often increases\ntraining memory and time. To improve both training and inference efficiency, we\nintroduce APT that adaptively prunes and tunes parameters for the LMs. At the\nearly stage of fine-tuning, APT dynamically adds salient tuning parameters for\nfast and accurate convergence while discarding unimportant parameters for\nefficiency. Compared to baselines, our experiments show that APT maintains up\nto 98% task performance when pruning RoBERTa and T5 models with 40% parameters\nleft while keeping 86.4% LLaMA models' performance with 70% parameters\nremained. Furthermore, APT speeds up LMs fine-tuning by up to 8x and reduces\nlarge LMs memory training footprint by up to 70%.", "published": "2024-01-22 18:39:40", "link": "http://arxiv.org/abs/2401.12200v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Vision-Language Foundation Model to Enhance Efficiency of Chest X-ray\n  Interpretation", "abstract": "Over 1.4 billion chest X-rays (CXRs) are performed annually due to their\ncost-effectiveness as an initial diagnostic test. This scale of radiological\nstudies provides a significant opportunity to streamline CXR interpretation and\ndocumentation. While foundation models are a promising solution, the lack of\npublicly available large-scale datasets and benchmarks inhibits their iterative\ndevelopment and real-world evaluation. To overcome these challenges, we\nconstructed a large-scale dataset (CheXinstruct), which we utilized to train a\nvision-language foundation model (CheXagent). We systematically demonstrated\ncompetitive performance across eight distinct task types on our novel\nevaluation benchmark (CheXbench). Beyond technical validation, we assessed the\nreal-world utility of CheXagent in directly drafting radiology reports. Our\nclinical assessment with eight radiologists revealed a 36% time saving for\nresidents using CheXagent-drafted reports, while attending radiologists showed\nno significant time difference editing resident-drafted or CheXagent-drafted\nreports. The CheXagent-drafted reports improved the writing efficiency of both\nradiology residents and attending radiologists in 81% and 61% of cases,\nrespectively, without loss of quality. Overall, we demonstrate that CheXagent\ncan effectively perform a variety of CXR interpretation tasks and holds\npotential to assist radiologists in routine clinical workflows.", "published": "2024-01-22 18:51:07", "link": "http://arxiv.org/abs/2401.12208v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GRATH: Gradual Self-Truthifying for Large Language Models", "abstract": "Truthfulness is paramount for large language models (LLMs) as they are\nincreasingly deployed in real-world applications. However, existing LLMs still\nstruggle with generating truthful content, as evidenced by their modest\nperformance on benchmarks like TruthfulQA. To address this issue, we propose\nGRAdual self-truTHifying (GRATH), a novel post-processing method to enhance\ntruthfulness of LLMs. GRATH utilizes out-of-domain question prompts to generate\npairwise truthfulness training data with each pair containing a question and\nits correct and incorrect answers, and then optimizes the model via direct\npreference optimization (DPO) to learn from the truthfulness difference between\nanswer pairs. GRATH iteratively refines truthfulness data and updates the\nmodel, leading to a gradual improvement in model truthfulness in a\nself-supervised manner. Empirically, we evaluate GRATH using different 7B-LLMs\nand compare with LLMs with similar or even larger sizes on benchmark datasets.\nOur results show that GRATH effectively improves LLMs' truthfulness without\ncompromising other core capabilities. Notably, GRATH achieves state-of-the-art\nperformance on TruthfulQA, with MC1 accuracy of 54.71% and MC2 accuracy of\n69.10%, which even surpass those on 70B-LLMs.", "published": "2024-01-22 19:00:08", "link": "http://arxiv.org/abs/2401.12292v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fine-tuning Large Language Models for Multigenerator, Multidomain, and\n  Multilingual Machine-Generated Text Detection", "abstract": "SemEval-2024 Task 8 introduces the challenge of identifying machine-generated\ntexts from diverse Large Language Models (LLMs) in various languages and\ndomains. The task comprises three subtasks: binary classification in\nmonolingual and multilingual (Subtask A), multi-class classification (Subtask\nB), and mixed text detection (Subtask C). This paper focuses on Subtask A & B.\nEach subtask is supported by three datasets for training, development, and\ntesting. To tackle this task, two methods: 1) using traditional machine\nlearning (ML) with natural language preprocessing (NLP) for feature extraction,\nand 2) fine-tuning LLMs for text classification. The results show that\ntransformer models, particularly LoRA-RoBERTa, exceed traditional ML methods in\neffectiveness, with majority voting being particularly effective in\nmultilingual contexts for identifying machine-generated texts.", "published": "2024-01-22 19:39:05", "link": "http://arxiv.org/abs/2401.12326v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Development of an NLP-driven computer-based test guide for visually\n  impaired students", "abstract": "In recent years, advancements in Natural Language Processing (NLP) techniques\nhave revolutionized the field of accessibility and exclusivity of testing,\nparticularly for visually impaired students (VIS). CBT has shown in years back\nits relevance in terms of administering exams electronically, making the test\nprocess easier, providing quicker and more accurate results, and offering\ngreater flexibility and accessibility for candidates. Yet, its relevance was\nnot felt by the visually impaired students as they cannot access printed\ndocuments. Hence, in this paper, we present an NLP-driven Computer-Based Test\nguide for visually impaired students. It employs a speech technology\npre-trained methods to provide real-time assistance and support to visually\nimpaired students. The system utilizes NLP technologies to convert the\ntext-based questions and the associated options in a machine-readable format.\nSubsequently, the speech technology pre-trained model processes the converted\ntext enabling the VIS to comprehend and analyze the content. Furthermore, we\nvalidated that this pre-trained model is not perverse by testing for accuracy\nusing sample audio datasets labels (A, B, C, D, E, F, G) to compare with the\nvoice recordings obtained from 20 VIS which is been predicted by the system to\nattain values for precision, recall, and F1-scores. These metrics are used to\nassess the performance of the pre-trained model and have indicated that it is\nproficient enough to give its better performance to the evaluated system. The\nmethodology adopted for this system is Object Oriented Analysis and Design\nMethodology (OOADM) where Objects are discussed and built by modeling\nreal-world instances.", "published": "2024-01-22 21:59:00", "link": "http://arxiv.org/abs/2401.12375v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Far Can 100 Samples Go? Unlocking Overall Zero-Shot Multilingual\n  Translation via Tiny Multi-Parallel Data", "abstract": "Zero-shot translation aims to translate between language pairs not seen\nduring training in Multilingual Machine Translation (MMT) and is largely\nconsidered an open problem. A common, albeit resource-consuming, solution is to\nadd as many related translation directions as possible to the training corpus.\nIn this paper, we show that for an English-centric model, surprisingly large\nzero-shot improvements can be achieved by simply fine-tuning with a very small\namount of multi-parallel data. For example, on the EC30 dataset, we obtain up\nto +21.7 ChrF non-English overall improvements (870 directions) by using only\n100 multi-parallel samples while preserving English-centric translation\nquality. When investigating the size effect of fine-tuning data and its\ntransfer capabilities, we found that already a small, randomly sampled set of\nfine-tuning directions is sufficient to achieve comparable improvements. The\nresulting non-English performance is close to the complete translation upper\nbound. Even in a minimal setting -- fine-tuning with only one single sample --\nthe well-known off-target issue is almost completely resolved, explaining parts\n-- but not all -- of the observed improvements in translation quality.", "published": "2024-01-22 23:55:00", "link": "http://arxiv.org/abs/2401.12413v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social\n  Media Communications", "abstract": "Emojis, which encapsulate semantics beyond mere words or phrases, have become\nprevalent in social network communications. This has spurred increasing\nscholarly interest in exploring their attributes and functionalities. However,\nemoji-related research and application face two primary challenges. First,\nresearchers typically rely on crowd-sourcing to annotate emojis in order to\nunderstand their sentiments, usage intentions, and semantic meanings. Second,\nsubjective interpretations by users can often lead to misunderstandings of\nemojis and cause the communication barrier. Large Language Models (LLMs) have\nachieved significant success in various annotation tasks, with ChatGPT\ndemonstrating expertise across multiple domains. In our study, we assess\nChatGPT's effectiveness in handling previously annotated and downstream tasks.\nOur objective is to validate the hypothesis that ChatGPT can serve as a viable\nalternative to human annotators in emoji research and that its ability to\nexplain emoji meanings can enhance clarity and transparency in online\ncommunications. Our findings indicate that ChatGPT has extensive knowledge of\nemojis. It is adept at elucidating the meaning of emojis across various\napplication scenarios and demonstrates the potential to replace human\nannotators in a range of tasks.", "published": "2024-01-22 06:02:39", "link": "http://arxiv.org/abs/2402.01681v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Applications, challenges and ethical issues of AI and ChatGPT in\n  education", "abstract": "Artificial Intelligence (AI) in recent years has shown an unprecedentedly\nimpressive development, tending to play a catalytic role in all aspects of\nlife. The interest of the academic community, but also of governments, is huge\nin the dynamics of AI and is reflected by the truly explosive amount of\ninvestment and research that is underway. Enthusiastic opinions and statements\nabout AI are made every day, but at the same time they also bring to the fore\nalarming predictions about its effects. This paper aims to describe the\nopportunities emerging from the use of artificial intelligence and ChatGPT to\nimprove education, but also to identify the challenges and ethical issues that\narise.", "published": "2024-01-22 14:48:13", "link": "http://arxiv.org/abs/2402.07907v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Streaming Bilingual End-to-End ASR model using Attention over Multiple\n  Softmax", "abstract": "Even with several advancements in multilingual modeling, it is challenging to\nrecognize multiple languages using a single neural model, without knowing the\ninput language and most multilingual models assume the availability of the\ninput language. In this work, we propose a novel bilingual end-to-end (E2E)\nmodeling approach, where a single neural model can recognize both languages and\nalso support switching between the languages, without any language input from\nthe user. The proposed model has shared encoder and prediction networks, with\nlanguage-specific joint networks that are combined via a self-attention\nmechanism. As the language-specific posteriors are combined, it produces a\nsingle posterior probability over all the output symbols, enabling a single\nbeam search decoding and also allowing dynamic switching between the languages.\nThe proposed approach outperforms the conventional bilingual baseline with\n13.3%, 8.23% and 1.3% word error rate relative reduction on Hindi, English and\ncode-mixed test sets, respectively.", "published": "2024-01-22 01:44:42", "link": "http://arxiv.org/abs/2401.11645v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Keep Decoding Parallel with Effective Knowledge Distillation from\n  Language Models to End-to-end Speech Recognisers", "abstract": "This study presents a novel approach for knowledge distillation (KD) from a\nBERT teacher model to an automatic speech recognition (ASR) model using\nintermediate layers. To distil the teacher's knowledge, we use an attention\ndecoder that learns from BERT's token probabilities. Our method shows that\nlanguage model (LM) information can be more effectively distilled into an ASR\nmodel using both the intermediate layers and the final layer. By using the\nintermediate layers as distillation target, we can more effectively distil LM\nknowledge into the lower network layers. Using our method, we achieve better\nrecognition accuracy than with shallow fusion of an external LM, allowing us to\nmaintain fast parallel decoding. Experiments on the LibriSpeech dataset\ndemonstrate the effectiveness of our approach in enhancing greedy decoding with\nconnectionist temporal classification (CTC).", "published": "2024-01-22 05:46:11", "link": "http://arxiv.org/abs/2401.11700v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation", "abstract": "Weakly-Supervised Semantic Segmentation (WSSS) aims to train segmentation\nmodels using image data with only image-level supervision. Since precise\npixel-level annotations are not accessible, existing methods typically focus on\nproducing pseudo masks for training segmentation models by refining CAM-like\nheatmaps. However, the produced heatmaps may capture only the discriminative\nimage regions of object categories or the associated co-occurring backgrounds.\nTo address the issues, we propose a Semantic Prompt Learning for WSSS (SemPLeS)\nframework, which learns to effectively prompt the CLIP latent space to enhance\nthe semantic alignment between the segmented regions and the target object\ncategories. More specifically, we propose Contrastive Prompt Learning and\nPrompt-guided Semantic Refinement to learn the prompts that adequately describe\nand suppress the co-occurring backgrounds associated with each object category.\nIn this way, SemPLeS can perform better semantic alignment between object\nregions and class labels, resulting in desired pseudo masks for training\nsegmentation models. The proposed SemPLeS framework achieves competitive\nperformance on standard WSSS benchmarks, PASCAL VOC 2012 and MS COCO 2014, and\nshows compatibility with other WSSS methods. Code:\nhttps://github.com/NVlabs/SemPLeS.", "published": "2024-01-22 09:41:05", "link": "http://arxiv.org/abs/2401.11791v4", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hallucination is Inevitable: An Innate Limitation of Large Language\n  Models", "abstract": "Hallucination has been widely recognized to be a significant drawback for\nlarge language models (LLMs). There have been many works that attempt to reduce\nthe extent of hallucination. These efforts have mostly been empirical so far,\nwhich cannot answer the fundamental question whether it can be completely\neliminated. In this paper, we formalize the problem and show that it is\nimpossible to eliminate hallucination in LLMs. Specifically, we define a formal\nworld where hallucination is defined as inconsistencies between a computable\nLLM and a computable ground truth function. By employing results from learning\ntheory, we show that LLMs cannot learn all the computable functions and will\ntherefore inevitably hallucinate if used as general problem solvers. Since the\nformal world is a part of the real world which is much more complicated,\nhallucinations are also inevitable for real world LLMs. Furthermore, for real\nworld LLMs constrained by provable time complexity, we describe the\nhallucination-prone tasks and empirically validate our claims. Finally, using\nthe formal world framework, we discuss the possible mechanisms and efficacies\nof existing hallucination mitigators as well as the practical implications on\nthe safe deployment of LLMs.", "published": "2024-01-22 10:26:14", "link": "http://arxiv.org/abs/2401.11817v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PsySafe: A Comprehensive Framework for Psychological-based Attack,\n  Defense, and Evaluation of Multi-agent System Safety", "abstract": "Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit\nprofound capabilities in collective intelligence. However, the potential misuse\nof this intelligence for malicious purposes presents significant risks. To\ndate, comprehensive research on the safety issues associated with multi-agent\nsystems remains limited. In this paper, we explore these concerns through the\ninnovative lens of agent psychology, revealing that the dark psychological\nstates of agents constitute a significant threat to safety. To tackle these\nconcerns, we propose a comprehensive framework (PsySafe) grounded in agent\npsychology, focusing on three key areas: firstly, identifying how dark\npersonality traits in agents can lead to risky behaviors; secondly, evaluating\nthe safety of multi-agent systems from the psychological and behavioral\nperspectives, and thirdly, devising effective strategies to mitigate these\nrisks. Our experiments reveal several intriguing phenomena, such as the\ncollective dangerous behaviors among agents, agents' self-reflection when\nengaging in dangerous behavior, and the correlation between agents'\npsychological assessments and dangerous behaviors. We anticipate that our\nframework and observations will provide valuable insights for further research\ninto the safety of multi-agent systems. We will make our data and code publicly\naccessible at https://github.com/AI4Good24/PsySafe.", "published": "2024-01-22 12:11:55", "link": "http://arxiv.org/abs/2401.11880v3", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.MA"], "primary_category": "cs.CL"}
{"title": "CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding\n  Benchmark", "abstract": "As the capabilities of large multimodal models (LMMs) continue to advance,\nevaluating the performance of LMMs emerges as an increasing need. Additionally,\nthere is an even larger gap in evaluating the advanced knowledge and reasoning\nabilities of LMMs in non-English contexts such as Chinese. We introduce CMMMU,\na new Chinese Massive Multi-discipline Multimodal Understanding benchmark\ndesigned to evaluate LMMs on tasks demanding college-level subject knowledge\nand deliberate reasoning in a Chinese context. CMMMU is inspired by and\nstrictly follows the annotation and analysis pattern of MMMU. CMMMU includes\n12k manually collected multimodal questions from college exams, quizzes, and\ntextbooks, covering six core disciplines: Art & Design, Business, Science,\nHealth & Medicine, Humanities & Social Science, and Tech & Engineering, like\nits companion, MMMU. These questions span 30 subjects and comprise 39 highly\nheterogeneous image types, such as charts, diagrams, maps, tables, music\nsheets, and chemical structures. CMMMU focuses on complex perception and\nreasoning with domain-specific knowledge in the Chinese context. We evaluate 11\nopen-source LLMs and one proprietary GPT-4V(ision). Even GPT-4V only achieves\naccuracies of 42%, indicating a large space for improvement. CMMMU will boost\nthe community to build the next-generation LMMs towards expert artificial\nintelligence and promote the democratization of LMMs by providing diverse\nlanguage contexts.", "published": "2024-01-22 13:34:34", "link": "http://arxiv.org/abs/2401.11944v4", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated\n  Text", "abstract": "Detecting text generated by modern large language models is thought to be\nhard, as both LLMs and humans can exhibit a wide range of complex behaviors.\nHowever, we find that a score based on contrasting two closely related language\nmodels is highly accurate at separating human-generated and machine-generated\ntext. Based on this mechanism, we propose a novel LLM detector that only\nrequires simple calculations using a pair of pre-trained LLMs. The method,\ncalled Binoculars, achieves state-of-the-art accuracy without any training\ndata. It is capable of spotting machine text from a range of modern LLMs\nwithout any model-specific modifications. We comprehensively evaluate\nBinoculars on a number of text sources and in varied situations. Over a wide\nrange of document types, Binoculars detects over 90% of generated samples from\nChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being\ntrained on any ChatGPT data.", "published": "2024-01-22 16:09:47", "link": "http://arxiv.org/abs/2401.12070v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "West-of-N: Synthetic Preferences for Self-Improving Reward Models", "abstract": "The success of reinforcement learning from human feedback (RLHF) in language\nmodel alignment is strongly dependent on the quality of the underlying reward\nmodel. In this paper, we present a novel approach to improve reward model\nquality by generating synthetic preference data, thereby augmenting the\ntraining dataset with on-policy, high-quality preference pairs. Motivated by\nthe promising results of Best-of-N sampling strategies in language model\ntraining, we extend their application to reward model training. This results in\na self-training strategy to generate preference pairs by selecting the best and\nworst candidates in a pool of responses to a given query. Empirically, we find\nthat this approach improves the performance of any reward model, with an effect\ncomparable to the addition of a similar quantity of human preference data. This\nwork opens up new avenues of research for improving RLHF for language model\nalignment, by offering synthetic preference generation as a solution to reward\nmodeling challenges.", "published": "2024-01-22 16:24:43", "link": "http://arxiv.org/abs/2401.12086v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning\n  Capabilities", "abstract": "Understanding and reasoning about spatial relationships is a fundamental\ncapability for Visual Question Answering (VQA) and robotics. While Vision\nLanguage Models (VLM) have demonstrated remarkable performance in certain VQA\nbenchmarks, they still lack capabilities in 3D spatial reasoning, such as\nrecognizing quantitative relationships of physical objects like distances or\nsize differences. We hypothesize that VLMs' limited spatial reasoning\ncapability is due to the lack of 3D spatial knowledge in training data and aim\nto solve this problem by training VLMs with Internet-scale spatial reasoning\ndata. To this end, we present a system to facilitate this approach. We first\ndevelop an automatic 3D spatial VQA data generation framework that scales up to\n2 billion VQA examples on 10 million real-world images. We then investigate\nvarious factors in the training recipe, including data quality, training\npipeline, and VLM architecture. Our work features the first internet-scale 3D\nspatial reasoning dataset in metric space. By training a VLM on such data, we\nsignificantly enhance its ability on both qualitative and quantitative spatial\nVQA. Finally, we demonstrate that this VLM unlocks novel downstream\napplications in chain-of-thought spatial reasoning and robotics due to its\nquantitative estimation capability. Project website:\nhttps://spatial-vlm.github.io/", "published": "2024-01-22 18:01:01", "link": "http://arxiv.org/abs/2401.12168v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Universal Neurons in GPT2 Language Models", "abstract": "A basic question within the emerging field of mechanistic interpretability is\nthe degree to which neural networks learn the same underlying mechanisms. In\nother words, are neural mechanisms universal across different models? In this\nwork, we study the universality of individual neurons across GPT2 models\ntrained from different initial random seeds, motivated by the hypothesis that\nuniversal neurons are likely to be interpretable. In particular, we compute\npairwise correlations of neuron activations over 100 million tokens for every\nneuron pair across five different seeds and find that 1-5\\% of neurons are\nuniversal, that is, pairs of neurons which consistently activate on the same\ninputs. We then study these universal neurons in detail, finding that they\nusually have clear interpretations and taxonomize them into a small number of\nneuron families. We conclude by studying patterns in neuron weights to\nestablish several universal functional roles of neurons in simple circuits:\ndeactivating attention heads, changing the entropy of the next token\ndistribution, and predicting the next token to (not) be within a particular\nset.", "published": "2024-01-22 18:11:01", "link": "http://arxiv.org/abs/2401.12181v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "WARM: On the Benefits of Weight Averaged Reward Models", "abstract": "Aligning large language models (LLMs) with human preferences through\nreinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit\nfailures in the reward model (RM) to achieve seemingly high rewards without\nmeeting the underlying objectives. We identify two primary challenges when\ndesigning RMs to mitigate reward hacking: distribution shifts during the RL\nprocess and inconsistencies in human preferences. As a solution, we propose\nWeight Averaged Reward Models (WARM), first fine-tuning multiple RMs, then\naveraging them in the weight space. This strategy follows the observation that\nfine-tuned weights remain linearly mode connected when sharing the same\npre-training. By averaging weights, WARM improves efficiency compared to the\ntraditional ensembling of predictions, while improving reliability under\ndistribution shifts and robustness to preference inconsistencies. Our\nexperiments on summarization tasks, using best-of-N and RL methods, shows that\nWARM improves the overall quality and alignment of LLM predictions; for\nexample, a policy RL fine-tuned with WARM has a 79.4% win rate against a policy\nRL fine-tuned with a single RM.", "published": "2024-01-22 18:27:08", "link": "http://arxiv.org/abs/2401.12187v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Text Embedding Inversion Security for Multilingual Language Models", "abstract": "Textual data is often represented as real-numbered embeddings in NLP,\nparticularly with the popularity of large language models (LLMs) and Embeddings\nas a Service (EaaS). However, storing sensitive information as embeddings can\nbe susceptible to security breaches, as research shows that text can be\nreconstructed from embeddings, even without knowledge of the underlying model.\nWhile defence mechanisms have been explored, these are exclusively focused on\nEnglish, leaving other languages potentially exposed to attacks. This work\nexplores LLM security through multilingual embedding inversion. We define the\nproblem of black-box multilingual and cross-lingual inversion attacks, and\nexplore their potential implications. Our findings suggest that multilingual\nLLMs may be more vulnerable to inversion attacks, in part because English-based\ndefences may be ineffective. To alleviate this, we propose a simple masking\ndefense effective for both monolingual and multilingual models. This study is\nthe first to investigate multilingual inversion attacks, shedding light on the\ndifferences in attacks and defenses across monolingual and multilingual\nsettings.", "published": "2024-01-22 18:34:42", "link": "http://arxiv.org/abs/2401.12192v4", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "The Ethics of Interaction: Mitigating Security Threats in LLMs", "abstract": "This paper comprehensively explores the ethical challenges arising from\nsecurity threats to Large Language Models (LLMs). These intricate digital\nrepositories are increasingly integrated into our daily lives, making them\nprime targets for attacks that can compromise their training data and the\nconfidentiality of their data sources. The paper delves into the nuanced\nethical repercussions of such security threats on society and individual\nprivacy. We scrutinize five major threats--prompt injection, jailbreaking,\nPersonal Identifiable Information (PII) exposure, sexually explicit content,\nand hate-based content--going beyond mere identification to assess their\ncritical ethical consequences and the urgency they create for robust defensive\nstrategies. The escalating reliance on LLMs underscores the crucial need for\nensuring these systems operate within the bounds of ethical norms, particularly\nas their misuse can lead to significant societal and individual harm. We\npropose conceptualizing and developing an evaluative tool tailored for LLMs,\nwhich would serve a dual purpose: guiding developers and designers in\npreemptive fortification of backend systems and scrutinizing the ethical\ndimensions of LLM chatbot responses during the testing phase. By comparing LLM\nresponses with those expected from humans in a moral context, we aim to discern\nthe degree to which AI behaviors align with the ethical values held by a\nbroader society. Ultimately, this paper not only underscores the ethical\ntroubles presented by LLMs; it also highlights a path toward cultivating trust\nin these systems.", "published": "2024-01-22 17:11:37", "link": "http://arxiv.org/abs/2401.12273v2", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Longitudinal Sentiment Classification of Reddit Posts", "abstract": "We report results of a longitudinal sentiment classification of Reddit posts\nwritten by students of four major Canadian universities. We work with the texts\nof the posts, concentrating on the years 2020-2023. By finely tuning a\nsentiment threshold to a range of [-0.075,0.075], we successfully built\nclassifiers proficient in categorizing post sentiments into positive and\nnegative categories. Noticeably, our sentiment classification results are\nconsistent across the four university data sets.", "published": "2024-01-22 22:16:55", "link": "http://arxiv.org/abs/2401.12382v1", "categories": ["cs.CL", "cs.LG", "cs.SI", "I.2.6"], "primary_category": "cs.CL"}
{"title": "Enhancing In-context Learning via Linear Probe Calibration", "abstract": "In-context learning (ICL) is a new paradigm for natural language processing\nthat utilizes Generative Pre-trained Transformer (GPT)-like models. This\napproach uses prompts that include in-context demonstrations to generate the\ncorresponding output for a new query input. However, applying ICL in real cases\ndoes not scale with the number of samples, and lacks robustness to different\nprompt templates and demonstration permutations. In this paper, we first show\nthat GPT-like models using ICL result in unreliable predictions based on a new\nmetric based on Shannon entropy. Then, to solve this problem, we propose a new\ntechnique called the Linear Probe Calibration (LinC), a method that calibrates\nthe model's output probabilities, resulting in reliable predictions and\nimproved performance, while requiring only minimal additional samples (as few\nas five labeled data samples). LinC significantly enhances the ICL test\nperformance of GPT models on various benchmark datasets, with an average\nimprovement of up to 21%, and up to a 50% improvement in some cases, and\nsignificantly boosts the performance of PEFT methods, especially in the low\nresource regime. Moreover, LinC achieves lower expected calibration error, and\nis highly robust to varying label proportions, prompt templates, and\ndemonstration permutations. Our code is available at\n\\url{https://github.com/mominabbass/LinC}.", "published": "2024-01-22 23:35:09", "link": "http://arxiv.org/abs/2401.12406v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Social Media Data to Identify Factors Influencing Public\n  Attitude Towards Accessibility, Socioeconomic Disparity and Public\n  Transportation", "abstract": "This study proposes a novel method to understand the factors affecting\nindividuals' perception of transport accessibility, socioeconomic disparity,\nand public infrastructure. As opposed to the time consuming and expensive\nsurvey-based approach, this method can generate organic large-scale responses\nfrom social media and develop statistical models to understand individuals'\nperceptions of various transportation issues. This study retrieved and analyzed\n36,098 tweets from New York City from March 19, 2020, to May 15, 2022. A\nstate-of-the-art natural language processing algorithm is used for text mining\nand classification. A data fusion technique has been adopted to generate a\nseries of socioeconomic traits that are used as explanatory variables in the\nmodel. The model results show that females and individuals of Asian origin tend\nto discuss transportation accessibility more than their counterparts, with\nthose experiencing high neighborhood traffic also being more vocal. However,\ndisadvantaged individuals, including the unemployed and those living in\nlow-income neighborhoods or in areas with high natural hazard risks, tend to\ncommunicate less about such issues. As for socioeconomic disparity, individuals\nof Asian origin and those experiencing various types of air pollution are more\nlikely to discuss these topics on Twitter, often with a negative sentiment.\nHowever, unemployed, or disadvantaged individuals, as well as those living in\nareas with high natural hazard risks or expected losses, are less inclined to\ntweet about this subject. Lack of internet accessibility could be a reason why\nmany disadvantaged individuals do not tweet about transport accessibility and\nsubsidized internet could be a possible solution.", "published": "2024-01-22 06:51:29", "link": "http://arxiv.org/abs/2402.01682v1", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
{"title": "Community-based Behavioral Understanding of Crisis Activity Concerns\n  using Social Media Data: A Study on the 2023 Canadian Wildfires in New York\n  City", "abstract": "New York City (NYC) topped the global chart for the worst air pollution in\nJune 2023, owing to the wildfire smoke drifting in from Canada. This\nunprecedented situation caused significant travel disruptions and shifts in\ntraditional activity patterns of NYC residents. This study utilized large-scale\nsocial media data to study different crisis activity concerns (i.e.,\nevacuation, staying indoors, shopping, and recreational activities among\nothers) in the emergence of the 2023 Canadian wildfire smoke in NYC. In this\nregard, one week (June 02 through June 09, 2023) geotagged Twitter data from\nNYC were retrieved and used in the analysis. The tweets were processed using\nadvanced text classification techniques and later integrated with national\ndatabases such as Social Security Administration data, Census, and American\nCommunity Survey. Finally, a model has been developed to make community\ninferences of different activity concerns in a major wildfire. The findings\nsuggest, during wildfires, females are less likely to engage in discussions\nabout evacuation, trips for medical, social, or recreational purposes, and\ncommuting for work, likely influenced by workplaces maintaining operations\ndespite poor air quality. There were also racial disparities in these\ndiscussions, with Asians being more likely than Hispanics to discuss evacuation\nand work commute, and African Americans being less likely to discuss social and\nrecreational activities. Additionally, individuals from low-income\nneighborhoods and non-higher education students expressed fewer concerns about\nevacuation. This study provides valuable insights for policymakers, emergency\nplanners, and public health officials, aiding them in formulating targeted\ncommunication strategies and equitable emergency response plans.", "published": "2024-01-22 06:57:45", "link": "http://arxiv.org/abs/2402.01683v1", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
{"title": "A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs\n  Using the CGC-LORA Algorithm", "abstract": "With the productive evolution of large language models (LLMs) in the field of\nnatural language processing (NLP), tons of effort has been made to effectively\nfine-tune common pre-trained LLMs to fulfill a variety of tasks in one or\nmultiple specific domain. In practice, there are two prevailing ways, in which\nthe adaptation can be achieved: (i) Multiple Independent Models: Pre-trained\nLLMs are fine-tuned a few times independently using the corresponding training\nsamples from each task. (ii) An Integrated Model: Samples from all tasks are\nemployed to fine-tune a pre-trianed LLM unitedly. To address the high computing\ncost and seesawing issue simultaneously, we propose a unified framework that\nimplements a 1 + N mutli-task fine-tuning pattern in LLMs using a novel\nCustomized Gate Control (CGC) Low-rank Adaptation (LoRA) algorithm. Our work\naims to take an advantage of both MTL (i.e., CGC) and PEFT (i.e., LoRA) scheme.\nFor a given cluster of tasks, we design an innovative layer that contains two\ntypes of experts as additional trainable parameters to make LoRA be compatible\nwith MTL. To comprehensively evaluate the proposed framework, we conduct\nwell-designed experiments on two public datasets. The experimental results\ndemonstrate that the unified framework with CGC-LoRA modules achieves higher\nevaluation scores than all benchmarks on both two datasets.", "published": "2024-01-22 07:58:31", "link": "http://arxiv.org/abs/2402.01684v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SMUTF: Schema Matching Using Generative Tags and Hybrid Features", "abstract": "We introduce SMUTF, a unique approach for large-scale tabular data schema\nmatching (SM), which assumes that supervised learning does not affect\nperformance in open-domain tasks, thereby enabling effective cross-domain\nmatching. This system uniquely combines rule-based feature engineering,\npre-trained language models, and generative large language models. In an\ninnovative adaptation inspired by the Humanitarian Exchange Language, we deploy\n'generative tags' for each data column, enhancing the effectiveness of SM.\nSMUTF exhibits extensive versatility, working seamlessly with any pre-existing\npre-trained embeddings, classification methods, and generative models.\n  Recognizing the lack of extensive, publicly available datasets for SM, we\nhave created and open-sourced the HDXSM dataset from the public humanitarian\ndata. We believe this to be the most exhaustive SM dataset currently available.\nIn evaluations across various public datasets and the novel HDXSM dataset,\nSMUTF demonstrated exceptional performance, surpassing existing\nstate-of-the-art models in terms of accuracy and efficiency, and} improving the\nF1 score by 11.84% and the AUC of ROC by 5.08%.", "published": "2024-01-22 08:47:50", "link": "http://arxiv.org/abs/2402.01685v2", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Benchmarking Large Multimodal Models against Common Corruptions", "abstract": "This technical report aims to fill a deficiency in the assessment of large\nmultimodal models (LMMs) by specifically examining the self-consistency of\ntheir outputs when subjected to common corruptions. We investigate the\ncross-modal interactions between text, image, and speech, encompassing four\nessential generation tasks: text-to-image, image-to-text, text-to-speech, and\nspeech-to-text. We create a comprehensive benchmark, named MMCBench, that\ncovers more than 100 popular LMMs (totally over 150 model checkpoints). A\nthorough evaluation under common corruptions is critical for practical\ndeployment and facilitates a better understanding of the reliability of\ncutting-edge LMMs. The benchmarking code is available at\nhttps://github.com/sail-sg/MMCBench", "published": "2024-01-22 13:33:53", "link": "http://arxiv.org/abs/2401.11943v1", "categories": ["cs.LG", "cs.CL", "cs.CR", "cs.CV", "cs.MM"], "primary_category": "cs.LG"}
{"title": "ScoreDec: A Phase-preserving High-Fidelity Audio Codec with A\n  Generalized Score-based Diffusion Post-filter", "abstract": "Although recent mainstream waveform-domain end-to-end (E2E) neural audio\ncodecs achieve impressive coded audio quality with a very low bitrate, the\nquality gap between the coded and natural audio is still significant. A\ngenerative adversarial network (GAN) training is usually required for these E2E\nneural codecs because of the difficulty of direct phase modeling. However, such\nadversarial learning hinders these codecs from preserving the original phase\ninformation. To achieve human-level naturalness with a reasonable bitrate,\npreserve the original phase, and get rid of the tricky and opaque GAN training,\nwe develop a score-based diffusion post-filter (SPF) in the complex spectral\ndomain and combine our previous AudioDec with the SPF to propose ScoreDec,\nwhich can be trained using only spectral and score-matching losses. Both the\nobjective and subjective experimental results show that ScoreDec with a 24~kbps\nbitrate encodes and decodes full-band 48~kHz speech with human-level\nnaturalness and well-preserved phase information.", "published": "2024-01-22 17:54:19", "link": "http://arxiv.org/abs/2401.12160v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Empowering Communication: Speech Technology for Indian and Western\n  Accents through AI-powered Speech Synthesis", "abstract": "Neural Text-to-speech (TTS) synthesis is a powerful technology that can\ngenerate speech using neural networks. One of the most remarkable features of\nTTS synthesis is its capability to produce speech in the voice of different\nspeakers. This paper introduces voice cloning and speech synthesis\nhttps://pypi.org/project/voice-cloning/ an open-source python package for\nhelping speech disorders to communicate more effectively as well as for\nprofessionals seeking to integrate voice cloning or speech synthesis\ncapabilities into their projects. This package aims to generate synthetic\nspeech that sounds like the natural voice of an individual, but it does not\nreplace the natural human voice. The architecture of the system comprises a\nspeaker verification system, a synthesizer, a vocoder, and noise reduction.\nSpeaker verification system trained on a varied set of speakers to achieve\noptimal generalization performance without relying on transcriptions.\nSynthesizer is trained using both audio and transcriptions that generate Mel\nspectrogram from a text and vocoder which converts the generated Mel\nSpectrogram into corresponding audio signal. Then the audio signal is processed\nby a noise reduction algorithm to eliminate unwanted noise and enhance speech\nclarity. The performance of synthesized speech from seen and unseen speakers\nare then evaluated using subjective and objective evaluation such as Mean\nOpinion Score (MOS), Gross Pitch Error (GPE), and Spectral distortion (SD). The\nmodel can create speech in distinct voices by including speaker characteristics\nthat are chosen randomly.", "published": "2024-01-22 09:07:17", "link": "http://arxiv.org/abs/2401.11771v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Harmonic Detection from Noisy Speech with Auditory Frame Gain for\n  Intelligibility Enhancement", "abstract": "This paper introduces a novel (HDAG - Harmonic Detection for Auditory Gain)\nmethod for speech intelligibility enhancement in noisy scenarios. In the\nproposed scheme, a series of selective Gammachirp filters are adopted to\nemphasize the harmonic components of speech reducing the masking effects of\nacoustic noises. The fundamental frequency are estimated by the HHT-Amp\ntechnique. Harmonic patterns estimated with low accuracy are detected and\nadjusted according the FSFFE low/high pitch separation. The central frequencies\nof the filterbank are defined considering the third octave subbands which are\nbest suited to cover the regions most relevant to intelligibility. Before\nsignal reconstruction, the gammachirp filtered components are amplified by gain\nfactors regulated by FSFFE classification. The proposed HDAG solution and three\nbaseline techniques are examined considering six background noises with four\nsignal-to-noise ratios. Three objective measures are adopted for the evaluation\nof speech intelligibility and quality. Several experiments are conducted to\ndemonstrate that the proposed scheme achieves better speech intelligibility\nimprovement when compared to the competing approaches. A perceptual listening\ntest is further considered and corroborates with the objective results.", "published": "2024-01-22 10:41:17", "link": "http://arxiv.org/abs/2401.11829v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Acoustic Disturbance Sensing Level Detection for ASD Diagnosis and\n  Intelligibility Enhancement", "abstract": "The acoustic sensitivity of Autism Spectrum Disorder (ASD) individuals highly\nimpacts their intelligibility in noisy urban environments. In this Letter, the\ndisturbance sensing level is examined with perceptual listening tests that\ndemonstrate the impact of their append High Internal Noise (HIN) profile on\nintelligibility. This particular sensing level is then proposed as additional\naid to ASD diagnosis. In this Letter, a novel intelligibility enhancement\nscheme is also introduced for ASD particular circumstances. For this proposal,\nharmonic features estimated from speech signal frames are considered as center\nfrequencies of auditory filterbanks. A gain factor is further applied to the\noutput of the filtered samples. The experimental results demonstrate that the\nproposal improved the acoustic intelligibility of ASD and Neurotypicals (NT)\npeople considering four acoustic noises at different signal-to-noise ratios.", "published": "2024-01-22 10:48:37", "link": "http://arxiv.org/abs/2401.11832v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adversarial speech for voice privacy protection from Personalized Speech\n  generation", "abstract": "The rapid progress in personalized speech generation technology, including\npersonalized text-to-speech (TTS) and voice conversion (VC), poses a challenge\nin distinguishing between generated and real speech for human listeners,\nresulting in an urgent demand in protecting speakers' voices from malicious\nmisuse. In this regard, we propose a speaker protection method based on\nadversarial attacks. The proposed method perturbs speech signals by minimally\naltering the original speech while rendering downstream speech generation\nmodels unable to accurately generate the voice of the target speaker. For\nvalidation, we employ the open-source pre-trained YourTTS model for speech\ngeneration and protect the target speaker's speech in the white-box scenario.\nAutomatic speaker verification (ASV) evaluations were carried out on the\ngenerated speech as the assessment of the voice protection capability. Our\nexperimental results show that we successfully perturbed the speaker encoder of\nthe YourTTS model using the gradient-based I-FGSM adversarial perturbation\nmethod. Furthermore, the adversarial perturbation is effective in preventing\nthe YourTTS model from generating the speech of the target speaker. Audio\nsamples can be found in\nhttps://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS.", "published": "2024-01-22 11:26:59", "link": "http://arxiv.org/abs/2401.11857v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Consistency Based Unsupervised Self-training For ASR Personalisation", "abstract": "On-device Automatic Speech Recognition (ASR) models trained on speech data of\na large population might underperform for individuals unseen during training.\nThis is due to a domain shift between user data and the original training data,\ndiffered by user's speaking characteristics and environmental acoustic\nconditions. ASR personalisation is a solution that aims to exploit user data to\nimprove model robustness. The majority of ASR personalisation methods assume\nlabelled user data for supervision. Personalisation without any labelled data\nis challenging due to limited data size and poor quality of recorded audio\nsamples. This work addresses unsupervised personalisation by developing a novel\nconsistency based training method via pseudo-labelling. Our method achieves a\nrelative Word Error Rate Reduction (WERR) of 17.3% on unlabelled training data\nand 8.1% on held-out data compared to a pre-trained model, and outperforms the\ncurrent state-of-the art methods.", "published": "2024-01-22 16:23:45", "link": "http://arxiv.org/abs/2401.12085v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An Exploratory Study of Multimodal Physiological Data in Jazz\n  Improvisation Using Basic Machine Learning Techniques", "abstract": "Our study delves into the \"Embodied Musicking Dataset,\" exploring the\nintertwined relationships and correlations between physiological and\npsychological dimensions during improvisational music performances. The primary\nobjective is to ascertain the presence of a definitive causal or correlational\nrelationship between these states and comprehend their manifestation in musical\ncompositions. This rich dataset provides a perspective on how musicians\ncoordinate their physicality with sonic events in real-time improvisational\nscenarios, emphasizing the concept of \"Embodied Musicking.\"", "published": "2024-01-22 10:32:18", "link": "http://arxiv.org/abs/2401.12266v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Lightweight Protection for Privacy in Offloaded Speech Understanding", "abstract": "Speech is a common input method for mobile embedded devices, but cloud-based\nspeech recognition systems pose privacy risks. Disentanglement-based encoders,\ndesigned to safeguard user privacy by filtering sensitive information from\nspeech signals, unfortunately require substantial memory and computational\nresources, which limits their use in less powerful devices. To overcome this,\nwe introduce a novel system, XXX, optimized for such devices. XXX is built on\nthe insight that speech understanding primarily relies on understanding the\nentire utterance's long-term dependencies, while privacy concerns are often\nlinked to short-term details. Therefore, XXX focuses on selectively masking\nthese short-term elements, preserving the quality of long-term speech\nunderstanding. The core of XXX is an innovative differential mask generator,\ngrounded in interpretable learning, which fine-tunes the masking process. We\ntested XXX on the STM32H7 microcontroller, assessing its performance in various\npotential attack scenarios. The results show that XXX maintains speech\nunderstanding accuracy and privacy at levels comparable to existing encoders,\nbut with a significant improvement in efficiency, achieving up to 53.3$\\times$\nfaster processing and a 134.1$\\times$ smaller memory footprint.", "published": "2024-01-22 14:36:01", "link": "http://arxiv.org/abs/2401.11983v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Look, Listen and Recognise: Character-Aware Audio-Visual Subtitling", "abstract": "The goal of this paper is automatic character-aware subtitle generation.\nGiven a video and a minimal amount of metadata, we propose an audio-visual\nmethod that generates a full transcript of the dialogue, with precise speech\ntimestamps, and the character speaking identified. The key idea is to first use\naudio-visual cues to select a set of high-precision audio exemplars for each\ncharacter, and then use these exemplars to classify all speech segments by\nspeaker identity. Notably, the method does not require face detection or\ntracking. We evaluate the method over a variety of TV sitcoms, including\nSeinfeld, Fraiser and Scrubs. We envision this system being useful for the\nautomatic generation of subtitles to improve the accessibility of the vast\namount of videos available on modern streaming services. Project page :\n\\url{https://www.robots.ox.ac.uk/~vgg/research/look-listen-recognise/}", "published": "2024-01-22 15:26:01", "link": "http://arxiv.org/abs/2401.12039v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Resource-constrained stereo singing voice cancellation", "abstract": "We study the problem of stereo singing voice cancellation, a subtask of music\nsource separation, whose goal is to estimate an instrumental background from a\nstereo mix. We explore how to achieve performance similar to large\nstate-of-the-art source separation networks starting from a small, efficient\nmodel for real-time speech separation. Such a model is useful when memory and\ncompute are limited and singing voice processing has to run with limited\nlook-ahead. In practice, this is realised by adapting an existing mono model to\nhandle stereo input. Improvements in quality are obtained by tuning model\nparameters and expanding the training set. Moreover, we highlight the benefits\na stereo model brings by introducing a new metric which detects attenuation\ninconsistencies between channels. Our approach is evaluated using objective\noffline metrics and a large-scale MUSHRA trial, confirming the effectiveness of\nour techniques in stringent listening tests.", "published": "2024-01-22 16:05:30", "link": "http://arxiv.org/abs/2401.12068v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation", "abstract": "We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose\nframe-work for controlling pre-trained text-to-music diffusion models at\ninference-time via optimizing initial noise latents. Our method can be used to\noptimize through any differentiable feature matching loss to achieve a target\n(stylized) output and leverages gradient checkpointing for memory efficiency.\nWe demonstrate a surprisingly wide-range of applications for music generation\nincluding inpainting, outpainting, and looping as well as intensity, melody,\nand musical structure control - all without ever fine-tuning the underlying\nmodel. When we compare our approach against related training, guidance, and\noptimization-based methods, we find DITTO achieves state-of-the-art performance\non nearly all tasks, including outperforming comparable approaches on\ncontrollability, audio quality, and computational efficiency, thus opening the\ndoor for high-quality, flexible, training-free control of diffusion models.\nSound examples can be found at https://DITTO-Music.github.io/web/.", "published": "2024-01-22 18:10:10", "link": "http://arxiv.org/abs/2401.12179v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CoAVT: A Cognition-Inspired Unified Audio-Visual-Text Pre-Training Model\n  for Multimodal Processing", "abstract": "There has been a long-standing quest for a unified audio-visual-text model to\nenable various multimodal understanding tasks, which mimics the listening,\nseeing and reading process of human beings. Humans tends to represent knowledge\nusing two separate systems: one for representing verbal (textual) information\nand one for representing non-verbal (visual and auditory) information. These\ntwo systems can operate independently but can also interact with each other.\nMotivated by this understanding of human cognition, in this paper, we introduce\nCoAVT -- a novel cognition-inspired Correlated Audio-Visual-Text pre-training\nmodel to connect the three modalities. It contains a joint audio-visual encoder\nthat learns to encode audio-visual synchronization information together with\nthe audio and visual content for non-verbal information, and a text encoder to\nhandle textual input for verbal information. To bridge the gap between\nmodalities, CoAVT employs a query encoder, which contains a set of learnable\nquery embeddings, and extracts the most informative audiovisual features of the\ncorresponding text. Additionally, to leverage the correspondences between audio\nand vision with language respectively, we also establish the audio-text and\nvisual-text bi-modal alignments upon the foundational audiovisual-text\ntri-modal alignment to enhance the multimodal representation learning. Finally,\nwe jointly optimize CoAVT model with three multimodal objectives: contrastive\nloss, matching loss and language modeling loss. Extensive experiments show that\nCoAVT can learn strong multimodal correlations and be generalized to various\ndownstream tasks. CoAVT establishes new state-of-the-art performance on\ntext-video retrieval task on AudioCaps for both zero-shot and fine-tuning\nsettings, audio-visual event classification and audio-visual retrieval tasks on\nAudioSet and VGGSound.", "published": "2024-01-22 08:16:48", "link": "http://arxiv.org/abs/2401.12264v2", "categories": ["eess.AS", "cs.MM", "cs.SD", "eess.IV"], "primary_category": "eess.AS"}
{"title": "Acoustic characterization of speech rhythm: going beyond metrics with\n  recurrent neural networks", "abstract": "Languages have long been described according to their perceived rhythmic\nattributes. The associated typologies are of interest in psycholinguistics as\nthey partly predict newborns' abilities to discriminate between languages and\nprovide insights into how adult listeners process non-native languages. Despite\nthe relative success of rhythm metrics in supporting the existence of\nlinguistic rhythmic classes, quantitative studies have yet to capture the full\ncomplexity of temporal regularities associated with speech rhythm. We argue\nthat deep learning offers a powerful pattern-recognition approach to advance\nthe characterization of the acoustic bases of speech rhythm. To explore this\nhypothesis, we trained a medium-sized recurrent neural network on a language\nidentification task over a large database of speech recordings in 21 languages.\nThe network had access to the amplitude envelopes and a variable identifying\nthe voiced segments, assuming that this signal would poorly convey phonetic\ninformation but preserve prosodic features. The network was able to identify\nthe language of 10-second recordings in 40% of the cases, and the language was\nin the top-3 guesses in two-thirds of the cases. Visualization methods show\nthat representations built from the network activations are consistent with\nspeech rhythm typologies, although the resulting maps are more complex than two\nseparated clusters between stress and syllable-timed languages. We further\nanalyzed the model by identifying correlations between network activations and\nknown speech rhythm metrics. The findings illustrate the potential of deep\nlearning tools to advance our understanding of speech rhythm through the\nidentification and exploration of linguistically relevant acoustic feature\nspaces.", "published": "2024-01-22 09:49:44", "link": "http://arxiv.org/abs/2401.14416v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "NEUROSEC: FPGA-Based Neuromorphic Audio Security", "abstract": "Neuromorphic systems, inspired by the complexity and functionality of the\nhuman brain, have gained interest in academic and industrial attention due to\ntheir unparalleled potential across a wide range of applications. While their\ncapabilities herald innovation, it is imperative to underscore that these\ncomputational paradigms, analogous to their traditional counterparts, are not\nimpervious to security threats. Although the exploration of neuromorphic\nmethodologies for image and video processing has been rigorously pursued, the\nrealm of neuromorphic audio processing remains in its early stages. Our results\nhighlight the robustness and precision of our FPGA-based neuromorphic system.\nSpecifically, our system showcases a commendable balance between desired signal\nand background noise, efficient spike rate encoding, and unparalleled\nresilience against adversarial attacks such as FGSM and PGD. A standout feature\nof our framework is its detection rate of 94%, which, when compared to other\nmethodologies, underscores its greater capability in identifying and mitigating\nthreats within 5.39 dB, a commendable SNR ratio. Furthermore, neuromorphic\ncomputing and hardware security serve many sensor domains in mission-critical\nand privacy-preserving applications.", "published": "2024-01-22 15:47:05", "link": "http://arxiv.org/abs/2401.12055v1", "categories": ["cs.CR", "cs.ET", "cs.LG", "cs.NE", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
