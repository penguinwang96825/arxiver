{"title": "Ethereum Data Structures", "abstract": "Ethereum platform operates with rich spectrum of data structures and hashing\nand coding functions. The main source describing them is the Yellow paper,\ncomplemented by a lot of informal blogs. These sources are somehow limited. In\nparticular, the Yellow paper does not ideally balance brevity and detail, in\nsome parts it is very detail, while too shallow elsewhere. The blogs on the\nother hand are often too vague and in certain cases contain incorrect\ninformation. As a solution, we provide this document, which summarises data\nstructures used in Ethereum. The goal is to provide sufficient detail while\nkeeping brevity. Sufficiently detailed formal view is enriched with examples to\nextend on clarity.", "published": "2021-08-12 03:22:33", "link": "http://arxiv.org/abs/2108.05513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMMUS : A Survey of Transformer-based Pretrained Models in Natural\n  Language Processing", "abstract": "Transformer-based pretrained language models (T-PTLMs) have achieved great\nsuccess in almost every NLP task. The evolution of these models started with\nGPT and BERT. These models are built on the top of transformers,\nself-supervised learning and transfer learning. Transformed-based PTLMs learn\nuniversal language representations from large volumes of text data using\nself-supervised learning and transfer this knowledge to downstream tasks. These\nmodels provide good background knowledge to downstream tasks which avoids\ntraining of downstream models from scratch. In this comprehensive survey paper,\nwe initially give a brief overview of self-supervised learning. Next, we\nexplain various core concepts like pretraining, pretraining methods,\npretraining tasks, embeddings and downstream adaptation methods. Next, we\npresent a new taxonomy of T-PTLMs and then give brief overview of various\nbenchmarks including both intrinsic and extrinsic. We present a summary of\nvarious useful libraries to work with T-PTLMs. Finally, we highlight some of\nthe future research directions which will further improve these models. We\nstrongly believe that this comprehensive survey paper will serve as a good\nreference to learn the core concepts as well as to stay updated with the recent\nhappenings in T-PTLMs.", "published": "2021-08-12 05:32:18", "link": "http://arxiv.org/abs/2108.05542v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Kicktionary-LOME: A Domain-Specific Multilingual Frame Semantic Parsing\n  Model for Football Language", "abstract": "This technical report introduces an adapted version of the LOME frame\nsemantic parsing model (Xia et al., EACL 2021) which is capable of\nautomatically annotating texts according to the \"Kicktionary\" domain-specific\nframenet resource. Several methods for training a model even with limited\navailable training data are proposed. While there are some challenges for\nevaluation related to the nature of the available annotations, preliminary\nresults are very promising, with the best model reaching F1-scores of 0.83\n(frame prediction) and 0.81 (semantic role prediction).", "published": "2021-08-12 07:47:13", "link": "http://arxiv.org/abs/2108.05575v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generation Challenges: Results of the Accuracy Evaluation Shared Task", "abstract": "The Shared Task on Evaluating Accuracy focused on techniques (both manual and\nautomatic) for evaluating the factual accuracy of texts produced by neural NLG\nsystems, in a sports-reporting domain. Four teams submitted evaluation\ntechniques for this task, using very different approaches and techniques. The\nbest-performing submissions did encouragingly well at this difficult task.\nHowever, all automatic submissions struggled to detect factual errors which are\nsemantically or pragmatically complex (for example, based on incorrect\ncomputation or inference).", "published": "2021-08-12 10:24:34", "link": "http://arxiv.org/abs/2108.05644v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Diverse Descriptions from Semantic Graphs", "abstract": "Text generation from semantic graphs is traditionally performed with\ndeterministic methods, which generate a unique description given an input\ngraph. However, the generation problem admits a range of acceptable textual\noutputs, exhibiting lexical, syntactic and semantic variation. To address this\ndisconnect, we present two main contributions. First, we propose a stochastic\ngraph-to-text model, incorporating a latent variable in an encoder-decoder\nmodel, and its use in an ensemble. Second, to assess the diversity of the\ngenerated sentences, we propose a new automatic evaluation metric which jointly\nevaluates output diversity and quality in a multi-reference setting. We\nevaluate the models on WebNLG datasets in English and Russian, and show an\nensemble of stochastic models produces diverse sets of generated sentences,\nwhile retaining similar quality to state-of-the-art models.", "published": "2021-08-12 11:00:09", "link": "http://arxiv.org/abs/2108.05659v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "(Un)solving Morphological Inflection: Lemma Overlap Artificially\n  Inflates Models' Performance", "abstract": "In the domain of Morphology, Inflection is a fundamental and important task\nthat gained a lot of traction in recent years, mostly via SIGMORPHON's\nshared-tasks. With average accuracy above 0.9 over the scores of all languages,\nthe task is considered mostly solved using relatively generic neural seq2seq\nmodels, even with little data provided. In this work, we propose to re-evaluate\nmorphological inflection models by employing harder train-test splits that will\nchallenge the generalization capacity of the models. In particular, as opposed\nto the na{\\\"i}ve split-by-form, we propose a split-by-lemma method to challenge\nthe performance on existing benchmarks. Our experiments with the three\ntop-ranked systems on the SIGMORPHON's 2020 shared-task show that the\nlemma-split presents an average drop of 30 percentage points in macro-average\nfor the 90 languages included. The effect is most significant for low-resourced\nlanguages with a drop as high as 95 points, but even high-resourced languages\nlose about 10 points on average. Our results clearly show that generalizing\ninflection to unseen lemmas is far from being solved, presenting a simple yet\neffective means to promote more sophisticated models.", "published": "2021-08-12 12:06:47", "link": "http://arxiv.org/abs/2108.05682v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining (second-order) graph-based and headed-span-based projective\n  dependency parsing", "abstract": "Graph-based methods, which decompose the score of a dependency tree into\nscores of dependency arcs, are popular in dependency parsing for decades.\nRecently, \\citet{Yang2022Span} propose a headed-span-based method that\ndecomposes the score of a dependency tree into scores of headed spans. They\nshow improvement over first-order graph-based methods. However, their method\ndoes not score dependency arcs at all, and dependency arcs are implicitly\ninduced by their cubic-time algorithm, which is possibly sub-optimal since\nmodeling dependency arcs is intuitively useful. In this work, we aim to combine\ngraph-based and headed-span-based methods, incorporating both arc scores and\nheaded span scores into our model. First, we show a direct way to combine with\n$O(n^4)$ parsing complexity. To decrease complexity, inspired by the classical\nhead-splitting trick, we show two $O(n^3)$ dynamic programming algorithms to\ncombine first- and second-order graph-based and headed-span-based methods. Our\nexperiments on PTB, CTB, and UD show that combining first-order graph-based and\nheaded-span-based methods is effective. We also confirm the effectiveness of\nsecond-order graph-based parsing in the deep learning age, however, we observe\nmarginal or no improvement when combining second-order graph-based and\nheaded-span-based methods. Our code is publicly available at\n\\url{https://github.com/sustcsonglin/span-based-dependency-parsing}.", "published": "2021-08-12 16:42:00", "link": "http://arxiv.org/abs/2108.05838v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Optimal is Greedy Decoding for Extractive Question Answering?", "abstract": "Fine-tuned language models use greedy decoding to answer reading\ncomprehension questions with relative success. However, this approach does not\nensure that the answer is a span in the given passage, nor does it guarantee\nthat it is the most probable one. Does greedy decoding actually perform worse\nthan an algorithm that does adhere to these properties? To study the\nperformance and optimality of greedy decoding, we present exact-extract, a\ndecoding algorithm that efficiently finds the most probable answer span in the\ncontext. We compare the performance of T5 with both decoding algorithms on\nzero-shot and few-shot extractive question answering. When no training examples\nare available, exact-extract significantly outperforms greedy decoding.\nHowever, greedy decoding quickly converges towards the performance of\nexact-extract with the introduction of a few training examples, becoming more\nextractive and increasingly likelier to generate the most probable span as the\ntraining set grows. We also show that self-supervised training can bias the\nmodel towards extractive behavior, increasing performance in the zero-shot\nsetting without resorting to annotated examples. Overall, our results suggest\nthat pretrained language models are so good at adapting to extractive question\nanswering, that it is often enough to fine-tune on a small training set for the\ngreedy algorithm to emulate the optimal decoding strategy.", "published": "2021-08-12 17:07:31", "link": "http://arxiv.org/abs/2108.05857v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax Matters! Syntax-Controlled in Text Style Transfer", "abstract": "Existing text style transfer (TST) methods rely on style classifiers to\ndisentangle the text's content and style attributes for text style transfer.\nWhile the style classifier plays a critical role in existing TST methods, there\nis no known investigation on its effect on the TST methods. In this paper, we\nconduct an empirical study on the limitations of the style classifiers used in\nexisting TST methods. We demonstrate that the existing style classifiers cannot\nlearn sentence syntax effectively and ultimately worsen existing TST models'\nperformance. To address this issue, we propose a novel Syntax-Aware\nControllable Generation (SACG) model, which includes a syntax-aware style\nclassifier that ensures learned style latent representations effectively\ncapture the syntax information for TST. Through extensive experiments on two\npopular TST tasks, we show that our proposed method significantly outperforms\nthe state-of-the-art methods. Our case studies have also demonstrated SACG's\nability to generate fluent target-style sentences that preserved the original\ncontent.", "published": "2021-08-12 17:35:23", "link": "http://arxiv.org/abs/2108.05869v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attacks against Ranking Algorithms with Text Embeddings: a Case Study on\n  Recruitment Algorithms", "abstract": "Recently, some studies have shown that text classification tasks are\nvulnerable to poisoning and evasion attacks. However, little work has\ninvestigated attacks against decision making algorithms that use text\nembeddings, and their output is a ranking. In this paper, we focus on ranking\nalgorithms for recruitment process, that employ text embeddings for ranking\napplicants resumes when compared to a job description. We demonstrate both\nwhite box and black box attacks that identify text items, that based on their\nlocation in embedding space, have significant contribution in increasing the\nsimilarity score between a resume and a job description. The adversary then\nuses these text items to improve the ranking of their resume among others. We\ntested recruitment algorithms that use the similarity scores obtained from\nUniversal Sentence Encoder (USE) and Term Frequency Inverse Document Frequency\n(TF IDF) vectors. Our results show that in both adversarial settings, on\naverage the attacker is successful. We also found that attacks against TF IDF\nis more successful compared to USE.", "published": "2021-08-12 01:41:21", "link": "http://arxiv.org/abs/2108.05490v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Corpus Aware Language Model Pre-training for Dense Passage\n  Retrieval", "abstract": "Recent research demonstrates the effectiveness of using fine-tuned language\nmodels~(LM) for dense retrieval. However, dense retrievers are hard to train,\ntypically requiring heavily engineered fine-tuning pipelines to realize their\nfull potential. In this paper, we identify and address two underlying problems\nof dense retrievers: i)~fragility to training data noise and ii)~requiring\nlarge batches to robustly learn the embedding space. We use the recently\nproposed Condenser pre-training architecture, which learns to condense\ninformation into the dense vector through LM pre-training. On top of it, we\npropose coCondenser, which adds an unsupervised corpus-level contrastive loss\nto warm up the passage embedding space. Retrieval experiments on MS-MARCO,\nNatural Question, and Trivia QA datasets show that coCondenser removes the need\nfor heavy data engineering such as augmentation, synthesis, or filtering, as\nwell as the need for large batch training. It shows comparable performance to\nRocketQA, a state-of-the-art, heavily engineered system, using simple small\nbatch fine-tuning.", "published": "2021-08-12 05:20:27", "link": "http://arxiv.org/abs/2108.05540v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Modeling Relevance Ranking under the Pre-training and Fine-tuning\n  Paradigm", "abstract": "Recently, pre-trained language models such as BERT have been applied to\ndocument ranking for information retrieval, which first pre-train a general\nlanguage model on an unlabeled large corpus and then conduct ranking-specific\nfine-tuning on expert-labeled relevance datasets. Ideally, an IR system would\nmodel relevance from a user-system dualism: the user's view and the system's\nview. User's view judges the relevance based on the activities of \"real users\"\nwhile the system's view focuses on the relevance signals from the system side,\ne.g., from the experts or algorithms, etc. Inspired by the user-system\nrelevance views and the success of pre-trained language models, in this paper\nwe propose a novel ranking framework called Pre-Rank that takes both user's\nview and system's view into consideration, under the pre-training and\nfine-tuning paradigm. Specifically, to model the user's view of relevance,\nPre-Rank pre-trains the initial query-document representations based on\nlarge-scale user activities data such as the click log. To model the system's\nview of relevance, Pre-Rank further fine-tunes the model on expert-labeled\nrelevance data. More importantly, the pre-trained representations, are\nfine-tuned together with handcrafted learning-to-rank features under a wide and\ndeep network architecture. In this way, Pre-Rank can model the relevance by\nincorporating the relevant knowledge and signals from both real search users\nand the IR experts. To verify the effectiveness of Pre-Rank, we showed two\nimplementations by using BERT and SetRank as the underlying ranking model,\nrespectively. Experimental results base on three publicly available benchmarks\nshowed that in both of the implementations, Pre-Rank can respectively\noutperform the underlying ranking models and achieved state-of-the-art\nperformances.", "published": "2021-08-12 10:37:12", "link": "http://arxiv.org/abs/2108.05652v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Scalable pragmatic communication via self-supervision", "abstract": "Models of context-sensitive communication often use the Rational Speech Act\nframework (RSA; Frank & Goodman, 2012), which formulates listeners and speakers\nin a cooperative reasoning process. However, the standard RSA formulation can\nonly be applied to small domains, and large-scale applications have relied on\nimitating human behavior. Here, we propose a new approach to scalable\npragmatics, building upon recent theoretical results (Zaslavsky et al., 2020)\nthat characterize pragmatic reasoning in terms of general information-theoretic\nprinciples. Specifically, we propose an architecture and learning process in\nwhich agents acquire pragmatic policies via self-supervision instead of\nimitating human data. This work suggests a new principled approach for\nequipping artificial agents with pragmatic skills via self-supervision, which\nis grounded both in pragmatic theory and in information theory.", "published": "2021-08-12 15:28:30", "link": "http://arxiv.org/abs/2108.05799v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hatemoji: A Test Suite and Adversarially-Generated Dataset for\n  Benchmarking and Detecting Emoji-based Hate", "abstract": "Detecting online hate is a complex task, and low-performing models have\nharmful consequences when used for sensitive applications such as content\nmoderation. Emoji-based hate is an emerging challenge for automated detection.\nWe present HatemojiCheck, a test suite of 3,930 short-form statements that\nallows us to evaluate performance on hateful language expressed with emoji.\nUsing the test suite, we expose weaknesses in existing hate detection models.\nTo address these weaknesses, we create the HatemojiBuild dataset using a\nhuman-and-model-in-the-loop approach. Models built with these 5,912 adversarial\nexamples perform substantially better at detecting emoji-based hate, while\nretaining strong performance on text-only hate. Both HatemojiCheck and\nHatemojiBuild are made publicly available. See our Github Repository\n(https://github.com/HannahKirk/Hatemoji). HatemojiCheck, HatemojiBuild, and the\nfinal Hatemoji Model are also available on HuggingFace\n(https://huggingface.co/datasets/HannahRoseKirk/).", "published": "2021-08-12 18:42:06", "link": "http://arxiv.org/abs/2108.05921v3", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Overview of the HASOC track at FIRE 2020: Hate Speech and Offensive\n  Content Identification in Indo-European Languages", "abstract": "With the growth of social media, the spread of hate speech is also increasing\nrapidly. Social media are widely used in many countries. Also Hate Speech is\nspreading in these countries. This brings a need for multilingual Hate Speech\ndetection algorithms. Much research in this area is dedicated to English at the\nmoment. The HASOC track intends to provide a platform to develop and optimize\nHate Speech detection algorithms for Hindi, German and English. The dataset is\ncollected from a Twitter archive and pre-classified by a machine learning\nsystem. HASOC has two sub-task for all three languages: task A is a binary\nclassification problem (Hate and Not Offensive) while task B is a fine-grained\nclassification problem for three classes (HATE) Hate speech, OFFENSIVE and\nPROFANITY. Overall, 252 runs were submitted by 40 teams. The performance of the\nbest classification algorithms for task A are F1 measures of 0.51, 0.53 and\n0.52 for English, Hindi, and German, respectively. For task B, the best\nclassification algorithms achieved F1 measures of 0.26, 0.33 and 0.29 for\nEnglish, Hindi, and German, respectively. This article presents the tasks and\nthe data development as well as the results. The best performing algorithms\nwere mainly variants of the transformer architecture BERT. However, also other\nsystems were applied with good success", "published": "2021-08-12 19:02:53", "link": "http://arxiv.org/abs/2108.05927v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Bursting Scientific Filter Bubbles: Boosting Innovation via Novel Author\n  Discovery", "abstract": "Isolated silos of scientific research and the growing challenge of\ninformation overload limit awareness across the literature and hinder\ninnovation. Algorithmic curation and recommendation, which often prioritize\nrelevance, can further reinforce these informational \"filter bubbles.\" In\nresponse, we describe Bridger, a system for facilitating discovery of scholars\nand their work. We construct a faceted representation of authors with\ninformation gleaned from their papers and inferred author personas, and use it\nto develop an approach that locates commonalities and contrasts between\nscientists to balance relevance and novelty. In studies with computer science\nresearchers, this approach helps users discover authors considered useful for\ngenerating novel research directions. We also demonstrate an approach for\ndisplaying information about authors, boosting the ability to understand the\nwork of new, unfamiliar scholars. Our analysis reveals that Bridger connects\nauthors who have different citation profiles and publish in different venues,\nraising the prospect of bridging diverse scientific communities.", "published": "2021-08-12 11:24:23", "link": "http://arxiv.org/abs/2108.05669v3", "categories": ["cs.DL", "cs.CL", "cs.HC", "cs.IR"], "primary_category": "cs.DL"}
{"title": "HopfE: Knowledge Graph Representation Learning using Inverse Hopf\n  Fibrations", "abstract": "Recently, several Knowledge Graph Embedding (KGE) approaches have been\ndevised to represent entities and relations in dense vector space and employed\nin downstream tasks such as link prediction. A few KGE techniques address\ninterpretability, i.e., mapping the connectivity patterns of the relations\n(i.e., symmetric/asymmetric, inverse, and composition) to a geometric\ninterpretation such as rotations. Other approaches model the representations in\nhigher dimensional space such as four-dimensional space (4D) to enhance the\nability to infer the connectivity patterns (i.e., expressiveness). However,\nmodeling relation and entity in a 4D space often comes at the cost of\ninterpretability. This paper proposes HopfE, a novel KGE approach aiming to\nachieve the interpretability of inferred relations in the four-dimensional\nspace. We first model the structural embeddings in 3D Euclidean space and view\nthe relation operator as an SO(3) rotation. Next, we map the entity embedding\nvector from a 3D space to a 4D hypersphere using the inverse Hopf Fibration, in\nwhich we embed the semantic information from the KG ontology. Thus, HopfE\nconsiders the structural and semantic properties of the entities without losing\nexpressivity and interpretability. Our empirical results on four well-known\nbenchmarks achieve state-of-the-art performance for the KG completion task.", "published": "2021-08-12 14:34:02", "link": "http://arxiv.org/abs/2108.05774v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "The paradox of the compositionality of natural language: a neural\n  machine translation case study", "abstract": "Obtaining human-like performance in NLP is often argued to require\ncompositional generalisation. Whether neural networks exhibit this ability is\nusually studied by training models on highly compositional synthetic data.\nHowever, compositionality in natural language is much more complex than the\nrigid, arithmetic-like version such data adheres to, and artificial\ncompositionality tests thus do not allow us to determine how neural models deal\nwith more realistic forms of compositionality. In this work, we re-instantiate\nthree compositionality tests from the literature and reformulate them for\nneural machine translation (NMT). Our results highlight that: i) unfavourably,\nmodels trained on more data are more compositional; ii) models are sometimes\nless compositional than expected, but sometimes more, exemplifying that\ndifferent levels of compositionality are required, and models are not always\nable to modulate between them correctly; iii) some of the non-compositional\nbehaviours are mistakes, whereas others reflect the natural variation in data.\nApart from an empirical study, our work is a call to action: we should rethink\nthe evaluation of compositionality in neural networks and develop benchmarks\nusing real data to evaluate compositionality on natural language, where\ncomposing meaning is not as straightforward as doing the math.", "published": "2021-08-12 17:57:23", "link": "http://arxiv.org/abs/2108.05885v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VTLayout: Fusion of Visual and Text Features for Document Layout\n  Analysis", "abstract": "Documents often contain complex physical structures, which make the Document\nLayout Analysis (DLA) task challenging. As a pre-processing step for content\nextraction, DLA has the potential to capture rich information in historical or\nscientific documents on a large scale. Although many deep-learning-based\nmethods from computer vision have already achieved excellent performance in\ndetecting \\emph{Figure} from documents, they are still unsatisfactory in\nrecognizing the \\emph{List}, \\emph{Table}, \\emph{Text} and \\emph{Title}\ncategory blocks in DLA. This paper proposes a VTLayout model fusing the\ndocuments' deep visual, shallow visual, and text features to localize and\nidentify different category blocks. The model mainly includes two stages, and\nthe three feature extractors are built in the second stage. In the first stage,\nthe Cascade Mask R-CNN model is applied directly to localize all category\nblocks of the documents. In the second stage, the deep visual, shallow visual,\nand text features are extracted for fusion to identify the category blocks of\ndocuments. As a result, we strengthen the classification power of different\ncategory blocks based on the existing localization technique. The experimental\nresults show that the identification capability of the VTLayout is superior to\nthe most advanced method of DLA based on the PubLayNet dataset, and the F1\nscore is as high as 0.9599.", "published": "2021-08-12 17:12:11", "link": "http://arxiv.org/abs/2108.13297v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Joint Spatio-Temporal Discretisation of Nonlinear Active Cochlear Models", "abstract": "Biologically inspired auditory models play an important role in developing\neffective audio representations that can be tightly integrated into speech and\naudio processing systems. Current computational models of the cochlea are\ntypically expressed in terms of systems of differential equations and do not\ndirectly lend themselves for use in computational speech processing systems.\nSpecifically, these models are spatially discrete and temporally continuous.\nThis paper presents a jointly discretised (spatially and temporally discrete)\nmodel of the cochlea which allows for processing at fixed time intervals suited\nto discrete time speech and audio processing systems. The proposed model takes\ninto account the active feedback mechanism in the cochlea, a core\ncharacteristic lacking in traditional speech processing front-ends, which\nendows it with significant dynamic range compression capability. This model is\nderived by jointly discretising an established semi-discretised (spatially\ndiscrete and temporally continuous) cochlear model in a state space form. We\nthen demonstrate that the proposed jointly discretised implementation matches\nthe semi-discrete model in terms of its characteristics and finally present\nstability analyses of the proposed model.", "published": "2021-08-12 23:03:13", "link": "http://arxiv.org/abs/2108.05993v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Masked Acoustic Unit for Mispronunciation Detection and Correction", "abstract": "Computer-Assisted Pronunciation Training (CAPT) plays an important role in\nlanguage learning. Conventional ASR-based CAPT methods require expensive\nannotation of the ground truth pronunciation for the supervised training.\nMeanwhile, certain undefined non-native phonemes cannot be correctly classified\ninto standard phonemes, making the annotation process challenging and\nsubjective. On the other hand, ASR-based CAPT methods only give the learner\ntext-based feedback about the mispronunciation, but cannot teach the learner\nhow to pronounce the sentence correctly. To solve these limitations, we propose\nto use the acoustic unit (AU) as the intermediary feature for both\nmispronunciation detection and correction. The proposed method uses the masked\nAU sequence and the target phonemes to detect the error AU and then corrects\nit. This method can give the learner speech-based self-imitating feedback,\nmaking our CAPT powerful for education.", "published": "2021-08-12 03:44:27", "link": "http://arxiv.org/abs/2108.05517v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Neural Network Voice Activity Detector for Downsampled Audio Data:\n  An Experiment Report", "abstract": "Sociometric badges are an emerging technology for study how teams interact in\nphysical places. Audio data recorded by sociometric badges is often downsampled\nto not record discussions of the sociometric badges holders. To gain more\ninformation about interactions inside teams with sociometric badges a Voice\nActivity Detector (VAD) is deployed to measure verbal activity of the\ninteraction. Detecting voice activity from downsampled audio data is\nchallenging because down-sampling destroys information from the data. We\ndeveloped a VAD using deep learning techniques that achieves only moderate\naccuracy in a low noise meeting setting and in across variable noise levels\ndespite excellent validation performance. Experiences and lessons learned while\ndeveloping the VAD are discussed.", "published": "2021-08-12 06:16:40", "link": "http://arxiv.org/abs/2108.05553v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Xi-Vector Embedding for Speaker Recognition", "abstract": "We present a Bayesian formulation for deep speaker embedding, wherein the\nxi-vector is the Bayesian counterpart of the x-vector, taking into account the\nuncertainty estimate. On the technology front, we offer a simple and\nstraightforward extension to the now widely used x-vector. It consists of an\nauxiliary neural net predicting the frame-wise uncertainty of the input\nsequence. We show that the proposed extension leads to substantial improvement\nacross all operating points, with a significant reduction in error rates and\ndetection cost. On the theoretical front, our proposal integrates the Bayesian\nformulation of linear Gaussian model to speaker-embedding neural networks via\nthe pooling layer. In one sense, our proposal integrates the Bayesian\nformulation of the i-vector to that of the x-vector. Hence, we refer to the\nembedding as the xi-vector, which is pronounced as /zai/ vector. Experimental\nresults on the SITW evaluation set show a consistent improvement of over 17.5%\nin equal-error-rate and 10.9% in minimum detection cost.", "published": "2021-08-12 11:54:56", "link": "http://arxiv.org/abs/2108.05679v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Parameter Tuning of Time-Frequency Masking Algorithms for Reverberant\n  Artifact Removal within the Cochlear Implant Stimulus", "abstract": "Cochlear implant users struggle to understand speech in reverberant\nenvironments. To restore speech perception, artifacts dominated by reverberant\nreflections can be removed from the cochlear implant stimulus. Artifacts can be\nidentified and removed by applying a matrix of gain values, a technique\nreferred to as time-frequency masking. Gain values are determined by an oracle\nalgorithm that uses knowledge of the undistorted signal to minimize retention\nof the signal components dominated by reverberant reflections. In practice,\ngain values are estimated from the distorted signal, with the oracle algorithm\nproviding the estimation objective. Different oracle techniques exist for\ndetermining gain values, and each technique must be parameterized to set the\namount of signal retention. This work assesses which oracle masking strategies\nand parameterizations lead to the best improvements in speech intelligibility\nfor cochlear implant users in reverberant conditions using online speech\nintelligibility testing of normal-hearing individuals with vocoding.", "published": "2021-08-12 19:08:27", "link": "http://arxiv.org/abs/2108.05929v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dereverberation of Autoregressive Envelopes for Far-field Speech\n  Recognition", "abstract": "The task of speech recognition in far-field environments is adversely\naffected by the reverberant artifacts that elicit as the temporal smearing of\nthe sub-band envelopes. In this paper, we develop a neural model for speech\ndereverberation using the long-term sub-band envelopes of speech. The sub-band\nenvelopes are derived using frequency domain linear prediction (FDLP) which\nperforms an autoregressive estimation of the Hilbert envelopes. The neural\ndereverberation model estimates the envelope gain which when applied to\nreverberant signals suppresses the late reflection components in the far-field\nsignal. The dereverberated envelopes are used for feature extraction in speech\nrecognition. Further, the sequence of steps involved in envelope\ndereverberation, feature extraction and acoustic modeling for ASR can be\nimplemented as a single neural processing pipeline which allows the joint\nlearning of the dereverberation network and the acoustic model. Several\nexperiments are performed on the REVERB challenge dataset, CHiME-3 dataset and\nVOiCES dataset. In these experiments, the joint learning of envelope\ndereverberation and acoustic model yields significant performance improvements\nover the baseline ASR system based on log-mel spectrogram as well as other past\napproaches for dereverberation (average relative improvements of 10-24% over\nthe baseline system). A detailed analysis on the choice of hyper-parameters and\nthe cost function involved in envelope dereverberation is also provided.", "published": "2021-08-12 04:05:38", "link": "http://arxiv.org/abs/2108.05520v2", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "RW-Resnet: A Novel Speech Anti-Spoofing Model Using Raw Waveform", "abstract": "In recent years, synthetic speech generated by advanced text-to-speech (TTS)\nand voice conversion (VC) systems has caused great harms to automatic speaker\nverification (ASV) systems, urging us to design a synthetic speech detection\nsystem to protect ASV systems. In this paper, we propose a new speech\nanti-spoofing model named ResWavegram-Resnet (RW-Resnet). The model contains\ntwo parts, Conv1D Resblocks and backbone Resnet34. The Conv1D Resblock is based\non the Conv1D block with a residual connection. For the first part, we use the\nraw waveform as input and feed it to the stacked Conv1D Resblocks to get the\nResWavegram. Compared with traditional methods, ResWavegram keeps all the\ninformation from the audio signal and has a stronger ability in extracting\nfeatures. For the second part, the extracted features are fed to the backbone\nResnet34 for the spoofed or bonafide decision. The ASVspoof2019 logical access\n(LA) corpus is used to evaluate our proposed RW-Resnet. Experimental results\nshow that the RW-Resnet achieves better performance than other state-of-the-art\nanti-spoofing models, which illustrates its effectiveness in detecting\nsynthetic speech attacks.", "published": "2021-08-12 12:09:26", "link": "http://arxiv.org/abs/2108.05684v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
