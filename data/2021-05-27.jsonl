{"title": "How Does Distilled Data Complexity Impact the Quality and Confidence of\n  Non-Autoregressive Machine Translation?", "abstract": "While non-autoregressive (NAR) models are showing great promise for machine\ntranslation, their use is limited by their dependence on knowledge distillation\nfrom autoregressive models. To address this issue, we seek to understand why\ndistillation is so effective. Prior work suggests that distilled training data\nis less complex than manual translations. Based on experiments with the\nLevenshtein Transformer and the Mask-Predict NAR models on the WMT14\nGerman-English task, this paper shows that different types of complexity have\ndifferent impacts: while reducing lexical diversity and decreasing reordering\ncomplexity both help NAR learn better alignment between source and target, and\nthus improve translation quality, lexical diversity is the main reason why\ndistillation increases model confidence, which affects the calibration of\ndifferent NAR models differently.", "published": "2021-05-27 01:19:11", "link": "http://arxiv.org/abs/2105.12900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Directed Acyclic Graph Network for Conversational Emotion Recognition", "abstract": "The modeling of conversational context plays a vital role in emotion\nrecognition from conversation (ERC). In this paper, we put forward a novel idea\nof encoding the utterances with a directed acyclic graph (DAG) to better model\nthe intrinsic structure within a conversation, and design a directed acyclic\nneural network, namely DAG-ERC, to implement this idea. In an attempt to\ncombine the strengths of conventional graph-based neural models and\nrecurrence-based neural models, DAG-ERC provides a more intuitive way to model\nthe information flow between long-distance conversation background and nearby\ncontext. Extensive experiments are conducted on four ERC benchmarks with\nstate-of-the-art models employed as baselines for comparison. The empirical\nresults demonstrate the superiority of this new model and confirm the\nmotivation of the directed acyclic graph architecture for ERC.", "published": "2021-05-27 01:51:37", "link": "http://arxiv.org/abs/2105.12907v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Corpus-Level Evaluation for Event QA: The IndiaPoliceEvents Corpus\n  Covering the 2002 Gujarat Violence", "abstract": "Automated event extraction in social science applications often requires\ncorpus-level evaluations: for example, aggregating text predictions across\nmetadata and unbiased estimates of recall. We combine corpus-level evaluation\nrequirements with a real-world, social science setting and introduce the\nIndiaPoliceEvents corpus--all 21,391 sentences from 1,257 English-language\nTimes of India articles about events in the state of Gujarat during March 2002.\nOur trained annotators read and label every document for mentions of police\nactivity events, allowing for unbiased recall evaluations. In contrast to other\ndatasets with structured event representations, we gather annotations by posing\nnatural questions, and evaluate off-the-shelf models for three different tasks:\nsentence classification, document ranking, and temporal aggregation of target\nevents. We present baseline results from zero-shot BERT-based models fine-tuned\non natural language inference and passage retrieval tasks. Our novel\ncorpus-level evaluations and annotation approach can guide creation of similar\nsocial-science-oriented resources in the future.", "published": "2021-05-27 04:15:44", "link": "http://arxiv.org/abs/2105.12936v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improve Query Focused Abstractive Summarization by Incorporating Answer\n  Relevance", "abstract": "Query focused summarization (QFS) models aim to generate summaries from\nsource documents that can answer the given query. Most previous work on QFS\nonly considers the query relevance criterion when producing the summary.\nHowever, studying the effect of answer relevance in the summary generating\nprocess is also important. In this paper, we propose QFS-BART, a model that\nincorporates the explicit answer relevance of the source documents given the\nquery via a question answering model, to generate coherent and answer-related\nsummaries. Furthermore, our model can take advantage of large pre-trained\nmodels which improve the summarization performance significantly. Empirical\nresults on the Debatepedia dataset show that the proposed model achieves the\nnew state-of-the-art performance.", "published": "2021-05-27 06:58:42", "link": "http://arxiv.org/abs/2105.12969v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating label suggestions for opinion mining in German Covid-19\n  social media", "abstract": "This work investigates the use of interactively updated label suggestions to\nimprove upon the efficiency of gathering annotations on the task of opinion\nmining in German Covid-19 social media data. We develop guidelines to conduct a\ncontrolled annotation study with social science students and find that\nsuggestions from a model trained on a small, expert-annotated dataset already\nlead to a substantial improvement - in terms of inter-annotator agreement(+.14\nFleiss' $\\kappa$) and annotation quality - compared to students that do not\nreceive any label suggestions. We further find that label suggestions from\ninteractively trained models do not lead to an improvement over suggestions\nfrom a static model. Nonetheless, our analysis of suggestion bias shows that\nannotators remain capable of reflecting upon the suggested label in general.\nFinally, we confirm the quality of the annotated data in transfer learning\nexperiments between different annotator groups. To facilitate further research\nin opinion mining on social media data, we release our collected data\nconsisting of 200 expert and 2,785 student annotations.", "published": "2021-05-27 07:47:53", "link": "http://arxiv.org/abs/2105.12980v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptive Nearest Neighbor Machine Translation", "abstract": "kNN-MT, recently proposed by Khandelwal et al. (2020a), successfully combines\npre-trained neural machine translation (NMT) model with token-level\nk-nearest-neighbor (kNN) retrieval to improve the translation accuracy.\nHowever, the traditional kNN algorithm used in kNN-MT simply retrieves a same\nnumber of nearest neighbors for each target token, which may cause prediction\nerrors when the retrieved neighbors include noises. In this paper, we propose\nAdaptive kNN-MT to dynamically determine the number of k for each target token.\nWe achieve this by introducing a light-weight Meta-k Network, which can be\nefficiently trained with only a few training samples. On four benchmark machine\ntranslation datasets, we demonstrate that the proposed method is able to\neffectively filter out the noises in retrieval results and significantly\noutperforms the vanilla kNN-MT model. Even more noteworthy is that the Meta-k\nNetwork learned on one domain could be directly applied to other domains and\nobtain consistent improvements, illustrating the generality of our method. Our\nimplementation is open-sourced at https://github.com/zhengxxn/adaptive-knn-mt.", "published": "2021-05-27 09:27:42", "link": "http://arxiv.org/abs/2105.13022v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extremely low-resource machine translation for closely related languages", "abstract": "An effective method to improve extremely low-resource neural machine\ntranslation is multilingual training, which can be improved by leveraging\nmonolingual data to create synthetic bilingual corpora using the\nback-translation method. This work focuses on closely related languages from\nthe Uralic language family: from Estonian and Finnish geographical regions. We\nfind that multilingual learning and synthetic corpora increase the translation\nquality in every language pair for which we have data. We show that transfer\nlearning and fine-tuning are very effective for doing low-resource machine\ntranslation and achieve the best results. We collected new parallel data for\nV\\~oro, North and South Saami and present first results of neural machine\ntranslation for these languages.", "published": "2021-05-27 11:27:06", "link": "http://arxiv.org/abs/2105.13065v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TranSmart: A Practical Interactive Machine Translation System", "abstract": "Automatic machine translation is super efficient to produce translations yet\ntheir quality is not guaranteed. This technique report introduces TranSmart, a\npractical human-machine interactive translation system that is able to trade\noff translation quality and efficiency. Compared to existing publicly available\ninteractive translation systems, TranSmart supports three key features,\nword-level autocompletion, sentence-level autocompletion and translation\nmemory. By word-level and sentence-level autocompletion, TranSmart allows users\nto interactively translate words in their own manners rather than the strict\nmanner from left to right. In addition, TranSmart has the potential to avoid\nsimilar translation mistakes by using translated sentences in history as its\nmemory. This report presents major functions of TranSmart, algorithms for\nachieving these functions, how to use the TranSmart APIs, and evaluation\nresults of some key functions. TranSmart is publicly available at its homepage\n(https://transmart.qq.com).", "published": "2021-05-27 11:40:29", "link": "http://arxiv.org/abs/2105.13072v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAW-C: Relatedness of Ambiguous Words--in Context (A New Lexical\n  Resource for English)", "abstract": "Most words are ambiguous--i.e., they convey distinct meanings in different\ncontexts--and even the meanings of unambiguous words are context-dependent.\nBoth phenomena present a challenge for NLP. Recently, the advent of\ncontextualized word embeddings has led to success on tasks involving lexical\nambiguity, such as Word Sense Disambiguation. However, there are few tasks that\ndirectly evaluate how well these contextualized embeddings accommodate the more\ncontinuous, dynamic nature of word meaning--particularly in a way that matches\nhuman intuitions. We introduce RAW-C, a dataset of graded, human relatedness\njudgments for 112 ambiguous words in context (with 672 sentence pairs total),\nas well as human estimates of sense dominance. The average inter-annotator\nagreement (assessed using a leave-one-annotator-out method) was 0.79. We then\nshow that a measure of cosine distance, computed using contextualized\nembeddings from BERT and ELMo, correlates with human judgments, but that cosine\ndistance also systematically underestimates how similar humans find uses of the\nsame sense of a word to be, and systematically overestimates how similar humans\nfind uses of different-sense homonyms. Finally, we propose a synthesis between\npsycholinguistic theories of the mental lexicon and computational models of\nlexical semantics.", "published": "2021-05-27 16:07:13", "link": "http://arxiv.org/abs/2105.13266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthetic Data Generation for Grammatical Error Correction with Tagged\n  Corruption Models", "abstract": "Synthetic data generation is widely known to boost the accuracy of neural\ngrammatical error correction (GEC) systems, but existing methods often lack\ndiversity or are too simplistic to generate the broad range of grammatical\nerrors made by human writers. In this work, we use error type tags from\nautomatic annotation tools such as ERRANT to guide synthetic data generation.\nWe compare several models that can produce an ungrammatical sentence given a\nclean sentence and an error type tag. We use these models to build a new, large\nsynthetic pre-training data set with error tag frequency distributions matching\na given development set. Our synthetic data set yields large and consistent\ngains, improving the state-of-the-art on the BEA-19 and CoNLL-14 test sets. We\nalso show that our approach is particularly effective in adapting a GEC system,\ntrained on mixed native and non-native English, to a native English test set,\neven surpassing real training data consisting of high-quality sentence pairs.", "published": "2021-05-27 17:17:21", "link": "http://arxiv.org/abs/2105.13318v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Adversarial Imitation Learning for Empathy-based AI", "abstract": "Generative adversarial imitation learning (GAIL) is a model-free algorithm\nthat has been shown to provide strong results in imitating complex behaviors in\nhigh-dimensional environments. In this paper, we utilize the GAIL model for\ntext generation to develop empathy-based context-aware conversational AI. Our\nmodel uses an expert trajectory of empathetic prompt-response dialogues which\ncan accurately exhibit the correct empathetic emotion when generating a\nresponse. The Generator of the GAIL model uses the GPT-2 sequential pre-trained\nlanguage model trained on 117 million parameters from 40 GB of internet data.\nWe propose a novel application of an approach used in transfer learning to fine\ntune the GPT-2 model in order to generate concise, user-specific empathetic\nresponses validated against the Discriminator. Our novel GAIL model utilizes a\nsentiment analysis history-based reinforcement learning approach to\nempathetically respond to human interactions in a personalized manner. We find\nthat our model's response scores on various human-generated prompts collected\nfrom the Facebook Empathetic Dialogues dataset outperform baseline\ncounterparts. Moreover, our model improves upon various history-based\nconversational AI models developed recently, as our model's performance over a\nsustained conversation of 3 or more interactions outperform similar\nconversational AI models.", "published": "2021-05-27 17:37:37", "link": "http://arxiv.org/abs/2105.13328v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Online Learning Meets Machine Translation Evaluation: Finding the Best\n  Systems with the Least Human Effort", "abstract": "In Machine Translation, assessing the quality of a large amount of automatic\ntranslations can be challenging. Automatic metrics are not reliable when it\ncomes to high performing systems. In addition, resorting to human evaluators\ncan be expensive, especially when evaluating multiple systems. To overcome the\nlatter challenge, we propose a novel application of online learning that, given\nan ensemble of Machine Translation systems, dynamically converges to the best\nsystems, by taking advantage of the human feedback available. Our experiments\non WMT'19 datasets show that our online approach quickly converges to the top-3\nranked systems for the language pairs considered, despite the lack of human\nfeedback for many translations.", "published": "2021-05-27 18:19:39", "link": "http://arxiv.org/abs/2105.13385v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relational Gating for \"What If\" Reasoning", "abstract": "This paper addresses the challenge of learning to do procedural reasoning\nover text to answer \"What if...\" questions. We propose a novel relational\ngating network that learns to filter the key entities and relationships and\nlearns contextual and cross representations of both procedure and question for\nfinding the answer. Our relational gating network contains an entity gating\nmodule, relation gating module, and contextual interaction module. These\nmodules help in solving the \"What if...\" reasoning problem. We show that\nmodeling pairwise relationships helps to capture higher-order relations and\nfind the line of reasoning for causes and effects in the procedural\ndescriptions. Our proposed approach achieves the state-of-the-art results on\nthe WIQA dataset.", "published": "2021-05-27 21:07:30", "link": "http://arxiv.org/abs/2105.13449v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced\n  Collective Inference", "abstract": "Compared to the general news domain, information extraction (IE) from\nbiomedical text requires much broader domain knowledge. However, many previous\nIE methods do not utilize any external knowledge during inference. Due to the\nexponential growth of biomedical publications, models that do not go beyond\ntheir fixed set of parameters will likely fall behind. Inspired by how humans\nlook up relevant information to comprehend a scientific text, we present a\nnovel framework that utilizes external knowledge for joint entity and relation\nextraction named KECI (Knowledge-Enhanced Collective Inference). Given an input\ntext, KECI first constructs an initial span graph representing its initial\nunderstanding of the text. It then uses an entity linker to form a knowledge\ngraph containing relevant background knowledge for the the entity mentions in\nthe text. To make the final predictions, KECI fuses the initial span graph and\nthe knowledge graph into a more refined graph using an attention mechanism.\nKECI takes a collective approach to link mention spans to entities by\nintegrating global relational information into local representations using\ngraph convolutional networks. Our experimental results show that the framework\nis highly effective, achieving new state-of-the-art results in two different\nbenchmark datasets: BioRelEx (binding interaction detection) and ADE (adverse\ndrug event extraction). For example, KECI achieves absolute improvements of\n4.59% and 4.91% in F1 scores over the state-of-the-art on the BioRelEx entity\nand relation extraction tasks.", "published": "2021-05-27 21:33:34", "link": "http://arxiv.org/abs/2105.13456v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Verb Sense Clustering using Contextualized Word Representations for\n  Semantic Frame Induction", "abstract": "Contextualized word representations have proven useful for various natural\nlanguage processing tasks. However, it remains unclear to what extent these\nrepresentations can cover hand-coded semantic information such as semantic\nframes, which specify the semantic role of the arguments associated with a\npredicate. In this paper, we focus on verbs that evoke different frames\ndepending on the context, and we investigate how well contextualized word\nrepresentations can recognize the difference of frames that the same verb\nevokes. We also explore which types of representation are suitable for semantic\nframe induction. In our experiments, we compare seven different contextualized\nword representations for two English frame-semantic resources, FrameNet and\nPropBank. We demonstrate that several contextualized word representations,\nespecially BERT and its variants, are considerably informative for semantic\nframe induction. Furthermore, we examine the extent to which the contextualized\nrepresentation of a verb can estimate the number of frames that the verb can\nevoke.", "published": "2021-05-27 21:53:40", "link": "http://arxiv.org/abs/2105.13465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Frame Induction using Masked Word Embeddings and Two-Step\n  Clustering", "abstract": "Recent studies on semantic frame induction show that relatively high\nperformance has been achieved by using clustering-based methods with\ncontextualized word embeddings. However, there are two potential drawbacks to\nthese methods: one is that they focus too much on the superficial information\nof the frame-evoking verb and the other is that they tend to divide the\ninstances of the same verb into too many different frame clusters. To overcome\nthese drawbacks, we propose a semantic frame induction method using masked word\nembeddings and two-step clustering. Through experiments on the English FrameNet\ndata, we demonstrate that using the masked word embeddings is effective for\navoiding too much reliance on the surface information of frame-evoking verbs\nand that two-step clustering can improve the number of resulting frame clusters\nfor the instances of the same verb.", "published": "2021-05-27 22:00:33", "link": "http://arxiv.org/abs/2105.13466v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Linguistic Coordination in Reranking N-Best Candidates For\n  End-to-End Response Selection Using BERT", "abstract": "Retrieval-based dialogue systems select the best response from many\ncandidates. Although many state-of-the-art models have shown promising\nperformance in dialogue response selection tasks, there is still quite a gap\nbetween R@1 and R@10 performance. To address this, we propose to leverage\nlinguistic coordination (a phenomenon that individuals tend to develop similar\nlinguistic behaviors in conversation) to rerank the N-best candidates produced\nby BERT, a state-of-the-art pre-trained language model. Our results show an\nimprovement in R@1 compared to BERT baselines, demonstrating the utility of\nrepairing machine-generated outputs by leveraging a linguistic theory.", "published": "2021-05-27 22:23:17", "link": "http://arxiv.org/abs/2105.13479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diagnosing Transformers in Task-Oriented Semantic Parsing", "abstract": "Modern task-oriented semantic parsing approaches typically use seq2seq\ntransformers to map textual utterances to semantic frames comprised of intents\nand slots. While these models are empirically strong, their specific strengths\nand weaknesses have largely remained unexplored. In this work, we study BART\nand XLM-R, two state-of-the-art parsers, across both monolingual and\nmultilingual settings. Our experiments yield several key results:\ntransformer-based parsers struggle not only with disambiguating intents/slots,\nbut surprisingly also with producing syntactically-valid frames. Though\npre-training imbues transformers with syntactic inductive biases, we find the\nambiguity of copying utterance spans into frames often leads to tree\ninvalidity, indicating span extraction is a major bottleneck for current\nparsers. However, as a silver lining, we show transformer-based parsers give\nsufficient indicators for whether a frame is likely to be correct or incorrect,\nmaking them easier to deploy in production settings.", "published": "2021-05-27 23:08:53", "link": "http://arxiv.org/abs/2105.13496v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neighborhood Rough Set based Multi-document Summarization", "abstract": "This research paper proposes a novel Neighbourhood Rough Set based approach\nfor supervised Multi-document Text Summarization (MDTS) with analysis and\nimpact on the summarization results for MDTS. Here, Rough Set based LERS\nalgorithm is improved using Neighborhood Rough Set which is itself a novel\ncombination called Neighborhood-LERS to be experimented for evaluations of\nefficacy and efficiency. In this paper, we shall apply and evaluate the\nproposed Neighborhood-LERS for Multi-document Summarization which here is\nproved experimentally to be superior to the base LERS technique for MDTS.", "published": "2021-05-27 00:43:20", "link": "http://arxiv.org/abs/2106.07338v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-turn Dialog System on Single-turn Data in Medical Domain", "abstract": "Recently there has been a huge interest in dialog systems. This interest has\nalso been developed in the field of the medical domain where researchers are\nfocusing on building a dialog system in the medical domain. This research is\nfocused on the multi-turn dialog system trained on the multi-turn dialog data.\nIt is difficult to gather a huge amount of multi-turn conversational data in\nthe medical domain that is verified by professionals and can be trusted.\nHowever, there are several frequently asked questions (FAQs) or single-turn QA\npairs that have information that is verified by the experts and can be used to\nbuild a multi-turn dialog system.", "published": "2021-05-27 00:42:11", "link": "http://arxiv.org/abs/2105.12887v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contrastive Fine-tuning Improves Robustness for Neural Rankers", "abstract": "The performance of state-of-the-art neural rankers can deteriorate\nsubstantially when exposed to noisy inputs or applied to a new domain. In this\npaper, we present a novel method for fine-tuning neural rankers that can\nsignificantly improve their robustness to out-of-domain data and query\nperturbations. Specifically, a contrastive loss that compares data points in\nthe representation space is combined with the standard ranking loss during\nfine-tuning. We use relevance labels to denote similar/dissimilar pairs, which\nallows the model to learn the underlying matching semantics across different\nquery-document pairs and leads to improved robustness. In experiments with four\npassage ranking datasets, the proposed contrastive fine-tuning method obtains\nimprovements on robustness to query reformulations, noise perturbations, and\nzero-shot transfer for both BERT and BART based rankers. Additionally, our\nexperiments show that contrastive fine-tuning outperforms data augmentation for\nrobustifying neural rankers.", "published": "2021-05-27 04:00:22", "link": "http://arxiv.org/abs/2105.12932v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Selective Knowledge Distillation for Neural Machine Translation", "abstract": "Neural Machine Translation (NMT) models achieve state-of-the-art performance\non many translation benchmarks. As an active research field in NMT, knowledge\ndistillation is widely applied to enhance the model's performance by\ntransferring teacher model's knowledge on each training sample. However,\nprevious work rarely discusses the different impacts and connections among\nthese samples, which serve as the medium for transferring teacher knowledge. In\nthis paper, we design a novel protocol that can effectively analyze the\ndifferent impacts of samples by comparing various samples' partitions. Based on\nabove protocol, we conduct extensive experiments and find that the teacher's\nknowledge is not the more, the better. Knowledge over specific samples may even\nhurt the whole performance of knowledge distillation. Finally, to address these\nissues, we propose two simple yet effective strategies, i.e., batch-level and\nglobal-level selections, to pick suitable samples for distillation. We evaluate\nour approaches on two large-scale machine translation tasks, WMT'14\nEnglish->German and WMT'19 Chinese->English. Experimental results show that our\napproaches yield up to +1.28 and +0.89 BLEU points improvements over the\nTransformer baseline, respectively.", "published": "2021-05-27 06:54:12", "link": "http://arxiv.org/abs/2105.12967v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Put your money where your mouth is: Using deep learning to identify\n  consumer tribes from word usage", "abstract": "Internet and social media offer firms novel ways of managing their marketing\nstrategy and gain competitive advantage. The groups of users expressing\nthemselves on the Internet about a particular topic, product, or brand are\nfrequently called a virtual tribe or E-tribe. However, there are no automatic\ntools for identifying and studying the characteristics of these virtual tribes.\nTowards this aim, this paper presents Tribefinder, a system to reveal Twitter\nusers' tribal affiliations, by analyzing their tweets and language use. To show\nthe potential of this instrument, we provide an example considering three\nspecific tribal macro-categories: alternative realities, lifestyle, and\nrecreation. In addition, we discuss the different characteristics of each\nidentified tribe, in terms of use of language and social interaction metrics.\nTribefinder illustrates the importance of adopting a new lens for studying\nvirtual tribes, which is crucial for firms to properly design their marketing\nstrategy, and for scholars to extend prior marketing research.", "published": "2021-05-27 10:06:56", "link": "http://arxiv.org/abs/2105.13036v1", "categories": ["cs.CL", "cs.LG", "I.2.7; H.4.0; H.0; J.4"], "primary_category": "cs.CL"}
{"title": "Maria: A Visual Experience Powered Conversational Agent", "abstract": "Arguably, the visual perception of conversational agents to the physical\nworld is a key way for them to exhibit the human-like intelligence.\nImage-grounded conversation is thus proposed to address this challenge.\nExisting works focus on exploring the multimodal dialog models that ground the\nconversation on a given image. In this paper, we take a step further to study\nimage-grounded conversation under a fully open-ended setting where no paired\ndialog and image are assumed available. Specifically, we present Maria, a\nneural conversation agent powered by the visual world experiences which are\nretrieved from a large-scale image index. Maria consists of three flexible\ncomponents, i.e., text-to-image retriever, visual concept detector and\nvisual-knowledge-grounded response generator. The retriever aims to retrieve a\ncorrelated image to the dialog from an image index, while the visual concept\ndetector extracts rich visual knowledge from the image. Then, the response\ngenerator is grounded on the extracted visual knowledge and dialog context to\ngenerate the target response. Extensive experiments demonstrate Maria\noutperforms previous state-of-the-art methods on automatic metrics and human\nevaluation, and can generate informative responses that have some visual\ncommonsense of the physical world.", "published": "2021-05-27 11:45:29", "link": "http://arxiv.org/abs/2105.13073v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Path-based knowledge reasoning with textual semantic information for\n  medical knowledge graph completion", "abstract": "Background Knowledge graphs (KGs), especially medical knowledge graphs, are\noften significantly incomplete, so it necessitating a demand for medical\nknowledge graph completion (MedKGC). MedKGC can find new facts based on the\nexited knowledge in the KGs. The path-based knowledge reasoning algorithm is\none of the most important approaches to this task. This type of method has\nreceived great attention in recent years because of its high performance and\ninterpretability. In fact, traditional methods such as path ranking algorithm\n(PRA) take the paths between an entity pair as atomic features. However, the\nmedical KGs are very sparse, which makes it difficult to model effective\nsemantic representation for extremely sparse path features. The sparsity in the\nmedical KGs is mainly reflected in the long-tailed distribution of entities and\npaths. Previous methods merely consider the context structure in the paths of\nthe knowledge graph and ignore the textual semantics of the symbols in the\npath. Therefore, their performance cannot be further improved due to the two\naspects of entity sparseness and path sparseness. To address the above issues,\nthis paper proposes two novel path-based reasoning methods to solve the\nsparsity issues of entity and path respectively, which adopts the textual\nsemantic information of entities and paths for MedKGC. By using the pre-trained\nmodel BERT, combining the textual semantic representations of the entities and\nthe relationships, we model the task of symbolic reasoning in the medical KG as\na numerical computing issue in textual semantic representation.", "published": "2021-05-27 11:45:59", "link": "http://arxiv.org/abs/2105.13074v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Neural Entity Recognition with Gazetteer based Fusion", "abstract": "Incorporating external knowledge into Named Entity Recognition (NER) systems\nhas been widely studied in the generic domain. In this paper, we focus on\nclinical domain where only limited data is accessible and interpretability is\nimportant. Recent advancement in technology and the acceleration of clinical\ntrials has resulted in the discovery of new drugs, procedures as well as\nmedical conditions. These factors motivate towards building robust zero-shot\nNER systems which can quickly adapt to new medical terminology. We propose an\nauxiliary gazetteer model and fuse it with an NER system, which results in\nbetter robustness and interpretability across different clinical datasets. Our\ngazetteer based fusion model is data efficient, achieving +1.7 micro-F1 gains\non the i2b2 dataset using 20% training data, and brings + 4.7 micro-F1 gains on\nnovel entity mentions never presented during training. Moreover, our fusion\nmodel is able to quickly adapt to new mentions in gazetteers without\nre-training and the gains from the proposed fusion model are transferable to\nrelated datasets.", "published": "2021-05-27 15:14:15", "link": "http://arxiv.org/abs/2105.13225v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CoSQA: 20,000+ Web Queries for Code Search and Question Answering", "abstract": "Finding codes given natural language query isb eneficial to the productivity\nof software developers. Future progress towards better semantic matching\nbetween query and code requires richer supervised training resources. To remedy\nthis, we introduce the CoSQA dataset.It includes 20,604 labels for pairs of\nnatural language queries and codes, each annotated by at least 3 human\nannotators. We further introduce a contrastive learning method dubbed CoCLR to\nenhance query-code matching, which works as a data augmenter to bring more\nartificially generated training instances. We show that evaluated on CodeXGLUE\nwith the same CodeBERT model, training on CoSQA improves the accuracy of code\nquestion answering by 5.1%, and incorporating CoCLR brings a further\nimprovement of 10.5%.", "published": "2021-05-27 15:37:21", "link": "http://arxiv.org/abs/2105.13239v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Measuring Fine-Grained Domain Relevance of Terms: A Hierarchical\n  Core-Fringe Approach", "abstract": "We propose to measure fine-grained domain relevance - the degree that a term\nis relevant to a broad (e.g., computer science) or narrow (e.g., deep learning)\ndomain. Such measurement is crucial for many downstream tasks in natural\nlanguage processing. To handle long-tail terms, we build a core-anchored\nsemantic graph, which uses core terms with rich description information to\nbridge the vast remaining fringe terms semantically. To support a fine-grained\ndomain without relying on a matching corpus for supervision, we develop\nhierarchical core-fringe learning, which learns core and fringe terms jointly\nin a semi-supervised manner contextualized in the hierarchy of the domain. To\nreduce expensive human efforts, we employ automatic annotation and hierarchical\npositive-unlabeled learning. Our approach applies to big or small domains,\ncovers head or tail terms, and requires little human effort. Extensive\nexperiments demonstrate that our methods outperform strong baselines and even\nsurpass professional human performance.", "published": "2021-05-27 15:52:34", "link": "http://arxiv.org/abs/2105.13255v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hailstorm : A Statically-Typed, Purely Functional Language for IoT\n  Applications", "abstract": "With the growing ubiquity of Internet of Things(IoT), more complex logic is\nbeing programmed on resource-constrained IoT devices, almost exclusively using\nthe C programming language. While C provides low-level control over memory, it\nlacks a number of high-level programming abstractions such as higher-order\nfunctions, polymorphism, strong static typing, memory safety, and automatic\nmemory management.\n  We present Hailstorm, a statically-typed, purely functional programming\nlanguage that attempts to address the above problem. It is a high-level\nprogramming language with a strict typing discipline. It supports features like\nhigher-order functions, tail-recursion, and automatic memory management, to\nprogram IoT devices in a declarative manner. Applications running on these\ndevices tend to be heavily dominated by I/O. Hailstorm tracks side effects\nlikeI/O in its type system using resource types. This choice allowed us to\nexplore the design of a purely functional standalone language, in an area where\nit is more common to embed a functional core in an imperative shell. The\nlanguage borrows the combinators of arrowized FRP, but has discrete-time\nsemantics. The design of the full set of combinators is work in progress,\ndriven by examples. So far, we have evaluated Hailstorm by writing standard\nexamples from the literature (earthquake detection, a railway crossing system\nand various other clocked systems), and also running examples on the GRiSP\nembedded systems board, through generation of Erlang.", "published": "2021-05-27 22:09:15", "link": "http://arxiv.org/abs/2105.13468v1", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "Inspecting the concept knowledge graph encoded by modern language models", "abstract": "The field of natural language understanding has experienced exponential\nprogress in the last few years, with impressive results in several tasks. This\nsuccess has motivated researchers to study the underlying knowledge encoded by\nthese models. Despite this, attempts to understand their semantic capabilities\nhave not been successful, often leading to non-conclusive, or contradictory\nconclusions among different works. Via a probing classifier, we extract the\nunderlying knowledge graph of nine of the most influential language models of\nthe last years, including word embeddings, text generators, and context\nencoders. This probe is based on concept relatedness, grounded on WordNet. Our\nresults reveal that all the models encode this knowledge, but suffer from\nseveral inaccuracies. Furthermore, we show that the different architectures and\ntraining strategies lead to different model biases. We conduct a systematic\nevaluation to discover specific factors that explain why some concepts are\nchallenging. We hope our insights will motivate the development of models that\ncapture concepts more precisely.", "published": "2021-05-27 22:19:19", "link": "http://arxiv.org/abs/2105.13471v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ProtAugment: Unsupervised diverse short-texts paraphrasing for intent\n  detection meta-learning", "abstract": "Recent research considers few-shot intent detection as a meta-learning\nproblem: the model is learning to learn from a consecutive set of small tasks\nnamed episodes. In this work, we propose ProtAugment, a meta-learning algorithm\nfor short texts classification (the intent detection task). ProtAugment is a\nnovel extension of Prototypical Networks, that limits overfitting on the bias\nintroduced by the few-shots classification objective at each episode. It relies\non diverse paraphrasing: a conditional language model is first fine-tuned for\nparaphrasing, and diversity is later introduced at the decoding stage at each\nmeta-learning episode. The diverse paraphrasing is unsupervised as it is\napplied to unlabelled data, and then fueled to the Prototypical Network\ntraining objective as a consistency loss. ProtAugment is the state-of-the-art\nmethod for intent detection meta-learning, at no extra labeling efforts and\nwithout the need to fine-tune a conditional language model on a given\napplication domain.", "published": "2021-05-27 08:31:27", "link": "http://arxiv.org/abs/2105.12995v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Finding top performers through email patterns analysis", "abstract": "In the information economy, individuals' work performance is closely\nassociated with their digital communication strategies. This study combines\nsocial network and semantic analysis to develop a method to identify top\nperformers based on email communication. By reviewing existing literature, we\nidentified the indicators that quantify email communication into measurable\ndimensions. To empirically examine the predictive power of the proposed\nindicators, we collected 2 million email archive of 578 executives in an\ninternational service company. Panel regression was employed to derive\ninterpretable association between email indicators and top performance. The\nresults suggest that top performers tend to assume central network positions\nand have high responsiveness to emails. In email contents, top performers use\nmore positive and complex language, with low emotionality, but rich in\ninfluential words that are probably reused by co-workers. To better explore the\npredictive power of the email indicators, we employed AdaBoost machine learning\nmodels, which achieved 83.56% accuracy in identifying top performers. With\ncluster analysis, we further find three categories of top performers,\n\"networkers\" with central network positions, \"influencers\" with influential\nideas and \"positivists\" with positive sentiments. The findings suggest that top\nperformers have distinctive email communication patterns, laying the foundation\nfor grounding email communication competence in theory. The proposed email\nanalysis method also provides a tool to evaluate the different types of\nindividual communication styles.", "published": "2021-05-27 09:45:02", "link": "http://arxiv.org/abs/2105.13025v1", "categories": ["cs.SI", "cs.CL", "physics.soc-ph", "J.4; I.2.7; H.4.0"], "primary_category": "cs.SI"}
{"title": "Self-Supervised Multimodal Opinion Summarization", "abstract": "Recently, opinion summarization, which is the generation of a summary from\nmultiple reviews, has been conducted in a self-supervised manner by considering\na sampled review as a pseudo summary. However, non-text data such as image and\nmetadata related to reviews have been considered less often. To use the\nabundant information contained in non-text data, we propose a self-supervised\nmultimodal opinion summarization framework called MultimodalSum. Our framework\nobtains a representation of each modality using a separate encoder for each\nmodality, and the text decoder generates a summary. To resolve the inherent\nheterogeneity of multimodal data, we propose a multimodal training pipeline. We\nfirst pretrain the text encoder--decoder based solely on text modality data.\nSubsequently, we pretrain the non-text modality encoders by considering the\npretrained text decoder as a pivot for the homogeneous representation of\nmultimodal data. Finally, to fuse multimodal representations, we train the\nentire framework in an end-to-end manner. We demonstrate the superiority of\nMultimodalSum by conducting experiments on Yelp and Amazon datasets.", "published": "2021-05-27 13:29:05", "link": "http://arxiv.org/abs/2105.13135v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Privacy and Confidentiality of Communications in Organizational\n  Graphs", "abstract": "Machine learned models trained on organizational communication data, such as\nemails in an enterprise, carry unique risks of breaching confidentiality, even\nif the model is intended only for internal use. This work shows how\nconfidentiality is distinct from privacy in an enterprise context, and aims to\nformulate an approach to preserving confidentiality while leveraging principles\nfrom differential privacy. The goal is to perform machine learning tasks, such\nas learning a language model or performing topic analysis, using interpersonal\ncommunications in the organization, while not learning about confidential\ninformation shared in the organization. Works that apply differential privacy\ntechniques to natural language processing tasks usually assume independently\ndistributed data, and overlook potential correlation among the records.\nIgnoring this correlation results in a fictional promise of privacy. Naively\nextending differential privacy techniques to focus on group privacy instead of\nrecord-level privacy is a straightforward approach to mitigate this issue. This\napproach, although providing a more realistic privacy-guarantee, is\nover-cautious and severely impacts model utility. We show this gap between\nthese two extreme measures of privacy over two language tasks, and introduce a\nmiddle-ground solution. We propose a model that captures the correlation in the\nsocial network graph, and incorporates this correlation in the privacy\ncalculations through Pufferfish privacy principles.", "published": "2021-05-27 19:45:56", "link": "http://arxiv.org/abs/2105.13418v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "An Improved Measure of Musical Noise Based on Spectral Kurtosis", "abstract": "Audio processing methods operating on a time-frequency representation of the\nsignal can introduce unpleasant sounding artifacts known as musical noise.\nThese artifacts are observed in the context of audio coding, speech\nenhancement, and source separation. The change in kurtosis of the power\nspectrum introduced during the processing was shown to correlate with the human\nperception of musical noise in the context of speech enhancement, leading to\nthe proposal of measures based on it. These baseline measures are here shown to\ncorrelate with human perception only in a limited manner. As ground truth for\nthe human perception, the results from two listening tests are considered: one\ninvolving audio coding and one involving source separation. Simple but\neffective perceptually motivated improvements are proposed and the resulting\nnew measure is shown to clearly outperform the baselines in terms of\ncorrelation with the results of both listening tests. Moreover, with respect to\nthe listening test on musical noise in audio coding, the exhibited correlation\nis nearly as good as the one exhibited by the Artifact-related Perceptual Score\n(APS), which was found to be the best objective measure for this task. The APS\nis however computationally very expensive. The proposed measure is easily\ncomputed, requiring only a fraction of the computational cost of the APS.", "published": "2021-05-27 12:03:52", "link": "http://arxiv.org/abs/2105.13079v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Phone-Level Prosody Modelling with GMM-Based MDN for Diverse and\n  Controllable Speech Synthesis", "abstract": "Generating natural speech with a diverse and smooth prosody pattern is a\nchallenging task. Although random sampling with phone-level prosody\ndistribution has been investigated to generate different prosody patterns, the\ndiversity of the generated speech is still very limited and far from what can\nbe achieved by humans. This is largely due to the use of uni-modal\ndistribution, such as single Gaussian, in the prior works of phone-level\nprosody modelling. In this work, we propose a novel approach that models\nphone-level prosodies with a GMM-based mixture density network(MDN) and then\nextend it for multi-speaker TTS using speaker adaptation transforms of Gaussian\nmeans and variances. Furthermore, we show that we can clone the prosodies from\na reference speech by sampling prosodies from the Gaussian components that\nproduce the reference prosodies. Our experiments on LJSpeech and LibriTTS\ndataset show that the proposed method with GMM-based MDN not only achieves\nsignificantly better diversity than using a single Gaussian in both\nsingle-speaker and multi-speaker TTS, but also provides better naturalness. The\nprosody cloning experiments demonstrate that the prosody similarity of the\nproposed method with GMM-based MDN is comparable to recent proposed\nfine-grained VAE while the target speaker similarity is better.", "published": "2021-05-27 12:16:42", "link": "http://arxiv.org/abs/2105.13086v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Learning for Depression Recognition with Audiovisual Cues: A Review", "abstract": "With the acceleration of the pace of work and life, people have to face more\nand more pressure, which increases the possibility of suffering from\ndepression. However, many patients may fail to get a timely diagnosis due to\nthe serious imbalance in the doctor-patient ratio in the world. Promisingly,\nphysiological and psychological studies have indicated some differences in\nspeech and facial expression between patients with depression and healthy\nindividuals. Consequently, to improve current medical care, many scholars have\nused deep learning to extract a representation of depression cues in audio and\nvideo for automatic depression detection. To sort out and summarize these\nworks, this review introduces the databases and describes objective markers for\nautomatic depression estimation (ADE). Furthermore, we review the deep learning\nmethods for automatic depression detection to extract the representation of\ndepression from audio and video. Finally, this paper discusses challenges and\npromising directions related to automatic diagnosing of depression using deep\nlearning technologies.", "published": "2021-05-27 15:48:31", "link": "http://arxiv.org/abs/2106.00610v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Evaluation of concept drift adaptation for acoustic scene classifier\n  based on Kernel Density Drift Detection and Combine Merge Gaussian Mixture\n  Model", "abstract": "Based on the experimental results, all concepts drift types have their\nrespective hyperparameter configurations. Simple and gradual concept drift have\nsimilar pattern which requires a smaller {\\alpha} value than recurring concept\ndrift because, in this type of drift, a new concept appear continuously, so it\nneeds a high-frequency model adaptation. However, in recurring concepts, the\nnew concept may repeat in the future, so the lower frequency adaptation is\nbetter. Furthermore, high-frequency model adaptation could lead to an\noverfitting problem. Implementing CMGMM component pruning mechanism help to\ncontrol the number of the active component and improve model performance.", "published": "2021-05-27 15:09:24", "link": "http://arxiv.org/abs/2105.13220v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Cross-Referencing Self-Training Network for Sound Event Detection in\n  Audio Mixtures", "abstract": "Sound event detection is an important facet of audio tagging that aims to\nidentify sounds of interest and define both the sound category and time\nboundaries for each sound event in a continuous recording. With advances in\ndeep neural networks, there has been tremendous improvement in the performance\nof sound event detection systems, although at the expense of costly data\ncollection and labeling efforts. In fact, current state-of-the-art methods\nemploy supervised training methods that leverage large amounts of data samples\nand corresponding labels in order to facilitate identification of sound\ncategory and time stamps of events. As an alternative, the current study\nproposes a semi-supervised method for generating pseudo-labels from\nunsupervised data using a student-teacher scheme that balances self-training\nand cross-training. Additionally, this paper explores post-processing which\nextracts sound intervals from network prediction, for further improvement in\nsound event detection performance. The proposed approach is evaluated on sound\nevent detection task for the DCASE2020 challenge. The results of these methods\non both \"validation\" and \"public evaluation\" sets of DESED database show\nsignificant improvement compared to the state-of-the art systems in\nsemi-supervised learning.", "published": "2021-05-27 18:46:59", "link": "http://arxiv.org/abs/2105.13392v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
