{"title": "Freezing Subnetworks to Analyze Domain Adaptation in Neural Machine\n  Translation", "abstract": "To better understand the effectiveness of continued training, we analyze the\nmajor components of a neural machine translation system (the encoder, decoder,\nand each embedding space) and consider each component's contribution to, and\ncapacity for, domain adaptation. We find that freezing any single component\nduring continued training has minimal impact on performance, and that\nperformance is surprisingly good when a single component is adapted while\nholding the rest of the model fixed. We also find that continued training does\nnot move the model very far from the out-of-domain model, compared to a\nsensitivity analysis metric, suggesting that the out-of-domain model can\nprovide a good generic initialization for the new domain.", "published": "2018-09-14 01:42:21", "link": "http://arxiv.org/abs/1809.05218v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Catchphrase Extraction from Legal Case Documents via Scoring\n  using Deep Neural Networks", "abstract": "In this paper, we present a method of automatic catchphrase extracting from\nlegal case documents. We utilize deep neural networks for constructing scoring\nmodel of our extraction system. We achieve comparable performance with systems\nusing corpus-wide and citation information which we do not use in our system.", "published": "2018-09-14 01:48:46", "link": "http://arxiv.org/abs/1809.05219v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Abstractive Sentence Summarization using Length Controlled\n  Variational Autoencoder", "abstract": "In this work we present an unsupervised approach to summarize sentences in\nabstractive way using Variational Autoencoder (VAE). VAE are known to learn a\nsemantically rich latent variable, representing high dimensional input. VAEs\nare trained by learning to reconstruct the input from the probabilistic latent\nvariable. Explicitly providing the information about output length during\ntraining influences the VAE to not encode this information and thus can be\nmanipulated during inference. Instructing the decoder to produce a shorter\noutput sequence leads to expressing the input sentence with fewer words. We\nshow on different summarization data sets, that these shorter sentences can not\nbeat a simple baseline but yield higher ROUGE scores than trying to reconstruct\nthe whole sentence.", "published": "2018-09-14 02:52:02", "link": "http://arxiv.org/abs/1809.05233v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Supervised Machine Learning for Extractive Query Based Summarisation of\n  Biomedical Data", "abstract": "The automation of text summarisation of biomedical publications is a pressing\nneed due to the plethora of information available on-line. This paper explores\nthe impact of several supervised machine learning approaches for extracting\nmulti-document summaries for given queries. In particular, we compare\nclassification and regression approaches for query-based extractive\nsummarisation using data provided by the BioASQ Challenge. We tackled the\nproblem of annotating sentences for training classification systems and show\nthat a simple annotation approach outperforms regression-based summarisation.", "published": "2018-09-14 06:27:38", "link": "http://arxiv.org/abs/1809.05268v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Macquarie University at BioASQ 6b: Deep learning and deep reinforcement\n  learning for query-based multi-document summarisation", "abstract": "This paper describes Macquarie University's contribution to the BioASQ\nChallenge (BioASQ 6b, Phase B). We focused on the extraction of the ideal\nanswers, and the task was approached as an instance of query-based\nmulti-document summarisation. In particular, this paper focuses on the\nexperiments related to the deep learning and reinforcement learning approaches\nused in the submitted runs. The best run used a deep learning model under a\nregression-based framework. The deep learning architecture used features\nderived from the output of LSTM chains on word embeddings, plus features based\non similarity with the query, and sentence position. The reinforcement learning\napproach was a proof-of-concept prototype that trained a global policy using\nREINFORCE. The global policy was implemented as a neural network that used\n$tf.idf$ features encoding the candidate sentence, question, and context.", "published": "2018-09-14 07:26:31", "link": "http://arxiv.org/abs/1809.05283v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Characterizing Variation in Crowd-Sourced Data for Training Neural\n  Language Generators to Produce Stylistically Varied Outputs", "abstract": "One of the biggest challenges of end-to-end language generation from meaning\nrepresentations in dialogue systems is making the outputs more natural and\nvaried. Here we take a large corpus of 50K crowd-sourced utterances in the\nrestaurant domain and develop text analysis methods that systematically\ncharacterize types of sentences in the training data. We then automatically\nlabel the training data to allow us to conduct two kinds of experiments with a\nneural generator. First, we test the effect of training the system with\ndifferent stylistic partitions and quantify the effect of smaller, but more\nstylistically controlled training data. Second, we propose a method of labeling\nthe style variants during training, and show that we can modify the style of\nthe generated utterances using our stylistic labels. We contrast and compare\nthese methods that can be used with any existing large corpus, showing how they\nvary in terms of semantic quality and stylistic control.", "published": "2018-09-14 07:51:19", "link": "http://arxiv.org/abs/1809.05288v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory", "abstract": "For dialogue response generation, traditional generative models generate\nresponses solely from input queries. Such models rely on insufficient\ninformation for generating a specific response since a certain query could be\nanswered in multiple ways. Consequentially, those models tend to output generic\nand dull responses, impeding the generation of informative utterances.\nRecently, researchers have attempted to fill the information gap by exploiting\ninformation retrieval techniques. When generating a response for a current\nquery, similar dialogues retrieved from the entire training data are considered\nas an additional knowledge source. While this may harvest massive information,\nthe generative models could be overwhelmed, leading to undesirable performance.\nIn this paper, we propose a new framework which exploits retrieval results via\na skeleton-then-response paradigm. At first, a skeleton is generated by\nrevising the retrieved responses. Then, a novel generative model uses both the\ngenerated skeleton and the original query for response generation. Experimental\nresults show that our approaches significantly improve the diversity and\ninformativeness of the generated responses.", "published": "2018-09-14 08:07:54", "link": "http://arxiv.org/abs/1809.05296v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Numeral Understanding in Financial Tweets for Fine-grained Crowd-based\n  Forecasting", "abstract": "Numerals that contain much information in financial documents are crucial for\nfinancial decision making. They play different roles in financial analysis\nprocesses. This paper is aimed at understanding the meanings of numerals in\nfinancial tweets for fine-grained crowd-based forecasting. We propose a\ntaxonomy that classifies the numerals in financial tweets into 7 categories,\nand further extend some of these categories into several subcategories. Neural\nnetwork-based models with word and character-level encoders are proposed for\n7-way classification and 17-way classification. We perform backtest to confirm\nthe effectiveness of the numeric opinions made by the crowd. This work is the\nfirst attempt to understand numerals in financial social media data, and we\nprovide the first comparison of fine-grained opinion of individual investors\nand analysts based on their forecast price. The numeral corpus used in our\nexperiments, called FinNum 1.0 , is available for research purposes.", "published": "2018-09-14 11:11:37", "link": "http://arxiv.org/abs/1809.05356v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ground Truth for training OCR engines on historical documents in German\n  Fraktur and Early Modern Latin", "abstract": "In this paper we describe a dataset of German and Latin \\textit{ground truth}\n(GT) for historical OCR in the form of printed text line images paired with\ntheir transcription. This dataset, called \\textit{GT4HistOCR}, consists of\n313,173 line pairs covering a wide period of printing dates from incunabula\nfrom the 15th century to 19th century books printed in Fraktur types and is\nopenly available under a CC-BY 4.0 license. The special form of GT as line\nimage/transcription pairs makes it directly usable to train state-of-the-art\nrecognition models for OCR software employing recurring neural networks in LSTM\narchitecture such as Tesseract 4 or OCRopus. We also provide some pretrained\nOCRopus models for subcorpora of our dataset yielding between 95\\% (early\nprintings) and 98\\% (19th century Fraktur printings) character accuracy rates\non unseen test cases, a Perl script to harmonize GT produced by different\ntranscription rules, and give hints on how to construct GT for OCR purposes\nwhich has requirements that may differ from linguistically motivated\ntranscriptions.", "published": "2018-09-14 16:52:12", "link": "http://arxiv.org/abs/1809.05501v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Events Beyond ACE: Curated Training for Events", "abstract": "We explore a human-driven approach to annotation, curated training (CT), in\nwhich annotation is framed as teaching the system by using interactive search\nto identify informative snippets of text to annotate, unlike traditional\napproaches which either annotate preselected text or use active learning. A\ntrained annotator performed 80 hours of CT for the thirty event types of the\nNIST TAC KBP Event Argument Extraction evaluation. Combining this annotation\nwith ACE results in a 6% reduction in error and the learning curve of CT\nplateaus more slowly than for full-document annotation. 3 NLP researchers\nperformed CT for one event type and showed much sharper learning curves with\nall three exceeding ACE performance in less than ninety minutes, suggesting\nthat CT can provide further benefits when the annotator deeply understands the\nsystem.", "published": "2018-09-14 20:37:38", "link": "http://arxiv.org/abs/1809.05576v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SQL-to-Text Generation with Graph-to-Sequence Model", "abstract": "Previous work approaches the SQL-to-text generation task using vanilla\nSeq2Seq models, which may not fully capture the inherent graph-structured\ninformation in SQL query. In this paper, we first introduce a strategy to\nrepresent the SQL query as a directed graph and then employ a graph-to-sequence\nmodel to encode the global structure information into node embeddings. This\nmodel can effectively learn the correlation between the SQL query pattern and\nits interpretation. Experimental results on the WikiSQL dataset and\nStackoverflow dataset show that our model significantly outperforms the Seq2Seq\nand Tree2Seq baselines, achieving the state-of-the-art performance.", "published": "2018-09-14 05:00:40", "link": "http://arxiv.org/abs/1809.05255v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extending Neural Generative Conversational Model using External\n  Knowledge Sources", "abstract": "The use of connectionist approaches in conversational agents has been\nprogressing rapidly due to the availability of large corpora. However current\ngenerative dialogue models often lack coherence and are content poor. This work\nproposes an architecture to incorporate unstructured knowledge sources to\nenhance the next utterance prediction in chit-chat type of generative dialogue\nmodels. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents\ntrained with the Reddit News dataset, and consider incorporating external\nknowledge from Wikipedia summaries as well as from the NELL knowledge base. Our\nexperiments show faster training time and improved perplexity when leveraging\nexternal knowledge.", "published": "2018-09-14 17:53:53", "link": "http://arxiv.org/abs/1809.05524v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Fingerprint the Latent Structure in Question Articulation", "abstract": "Abstract Machine understanding of questions is tightly related to recognition\nof articulation in the context of the computational capabilities of an\nunderlying processing algorithm. In this paper a mathematical model to capture\nand distinguish the latent structure in the articulation of questions is\npresented. We propose an objective-driven approach to represent this latent\nstructure and show that such an approach is beneficial when examples of\ncomplementary objectives are not available. We show that the latent structure\ncan be represented as a system that maximizes a cost function related to the\nunderlying objective. Further, we show that the optimization formulation can be\napproximated to building a memory of patterns represented as a trained neural\nauto-encoder. Experimental evaluation using many clusters of questions, each\nrelated to an objective, shows 80% recognition accuracy and negligible false\npositive across these clusters of questions. We then extend the same memory to\na related task where the goal is to iteratively refine a dataset of questions\nbased on the latent articulation. We also demonstrate a refinement scheme\ncalled K-fingerprints, that achieves nearly 100% recognition with negligible\nfalse positive across the different clusters of questions.", "published": "2018-09-14 06:51:01", "link": "http://arxiv.org/abs/1809.05275v1", "categories": ["cs.AI", "cs.CL", "cs.NE", "I.2.7; I.2.6; I.5.0"], "primary_category": "cs.AI"}
{"title": "Visual Speech Language Models", "abstract": "Language models (LM) are very powerful in lipreading systems. Language models\nbuilt upon the ground truth utterances of datasets learn grammar and structure\nrules of words and sentences (the latter in the case of continuous speech).\nHowever, visual co-articulation effects in visual speech signals damage the\nperformance of visual speech LM's as visually, people do not utter what the\nlanguage model expects. These models are commonplace but while higher-order\nN-gram LM's may improve classification rates, the cost of this model is\ndisproportionate to the common goal of developing more accurate classifiers. So\nwe compare which unit would best optimize a lipreading (visual speech) LM to\nobserve their limitations. We compare three units; visemes (visual speech\nunits) \\cite{lan2010improving}, phonemes (audible speech units), and words.", "published": "2018-09-14 11:07:32", "link": "http://arxiv.org/abs/1809.06800v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Multi-Stage Algorithm for Acoustic Physical Model Parameters\n  Estimation", "abstract": "One of the challenges in computational acoustics is the identification of\nmodels that can simulate and predict the physical behavior of a system\ngenerating an acoustic signal. Whenever such models are used for commercial\napplications an additional constraint is the time-to-market, making automation\nof the sound design process desirable. In previous works, a computational sound\ndesign approach has been proposed for the parameter estimation problem\ninvolving timbre matching by deep learning, which was applied to the synthesis\nof pipe organ tones. In this work we refine previous results by introducing the\nformer approach in a multi-stage algorithm that also adds heuristics and a\nstochastic optimization method operating on objective cost functions based on\npsychoacoustics. The optimization method shows to be able to refine the first\nestimate given by the deep learning approach and substantially improve the\nobjective metrics, with the additional benefit of reducing the sound design\nprocess time. Subjective listening tests are also conducted to gather\nadditional insights on the results.", "published": "2018-09-14 16:05:51", "link": "http://arxiv.org/abs/1809.05483v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
