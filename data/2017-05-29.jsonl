{"title": "Supervised Complementary Entity Recognition with Augmented Key-value\n  Pairs of Knowledge", "abstract": "Extracting opinion targets is an important task in sentiment analysis on\nproduct reviews and complementary entities (products) are one important type of\nopinion targets that may work together with the reviewed product. In this\npaper, we address the problem of Complementary Entity Recognition (CER) as a\nsupervised sequence labeling with the capability of expanding domain knowledge\nas key-value pairs from unlabeled reviews, by automatically learning and\nenhancing knowledge-based features. We use Conditional Random Field (CRF) as\nthe base learner and augment CRF with knowledge-based features (called the\nKnowledge-based CRF or KCRF for short). We conduct experiments to show that\nKCRF effectively improves the performance of supervised CER task.", "published": "2017-05-29 03:45:25", "link": "http://arxiv.org/abs/1705.10030v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamics of core of language vocabulary", "abstract": "Studies of the overall structure of vocabulary and its dynamics became\npossible due to creation of diachronic text corpora, especially Google Books\nNgram. This article discusses the question of core change rate and the degree\nto which the core words cover the texts. Different periods of the last three\ncenturies and six main European languages presented in Google Books Ngram are\ncompared. The main result is high stability of core change rate, which is\nanalogous to stability of the Swadesh list.", "published": "2017-05-29 10:51:20", "link": "http://arxiv.org/abs/1705.10112v1", "categories": ["cs.CL", "91F20", "I.2.7; J.5"], "primary_category": "cs.CL"}
{"title": "An Automatic Contextual Analysis and Clustering Classifiers Ensemble\n  approach to Sentiment Analysis", "abstract": "Products reviews are one of the major resources to determine the public\nsentiment. The existing literature on reviews sentiment analysis mainly\nutilizes supervised paradigm, which needs labeled data to be trained on and\nsuffers from domain-dependency. This article addresses these issues by\ndescribes a completely automatic approach for sentiment analysis based on\nunsupervised ensemble learning. The method consists of two phases. The first\nphase is contextual analysis, which has five processes, namely (1) data\npreparation; (2) spelling correction; (3) intensifier handling; (4) negation\nhandling and (5) contrast handling. The second phase comprises the unsupervised\nlearning approach, which is an ensemble of clustering classifiers using a\nmajority voting mechanism with different weight schemes. The base classifier of\nthe ensemble method is a modified k-means algorithm. The base classifier is\nmodified by extracting initial centroids from the feature set via using\nSentWordNet (SWN). We also introduce new sentiment analysis problems of\nAustralian airlines and home builders which offer potential benchmark problems\nin the sentiment analysis field. Our experiments on datasets from different\ndomains show that contextual analysis and the ensemble phases improve the\nclustering performance in term of accuracy, stability and generalization\nability.", "published": "2017-05-29 11:37:58", "link": "http://arxiv.org/abs/1705.10130v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Who's to say what's funny? A computer using Language Models and Deep\n  Learning, That's Who!", "abstract": "Humor is a defining characteristic of human beings. Our goal is to develop\nmethods that automatically detect humorous statements and rank them on a\ncontinuous scale. In this paper we report on results using a Language Model\napproach, and outline our plans for using methods from Deep Learning.", "published": "2017-05-29 16:20:21", "link": "http://arxiv.org/abs/1705.10272v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the \"Calligraphy\" of Books", "abstract": "Authorship attribution is a natural language processing task that has been\nwidely studied, often by considering small order statistics. In this paper, we\nexplore a complex network approach to assign the authorship of texts based on\ntheir mesoscopic representation, in an attempt to capture the flow of the\nnarrative. Indeed, as reported in this work, such an approach allowed the\nidentification of the dominant narrative structure of the studied authors. This\nhas been achieved due to the ability of the mesoscopic approach to take into\naccount relationships between different, not necessarily adjacent, parts of the\ntext, which is able to capture the story flow. The potential of the proposed\napproach has been illustrated through principal component analysis, a\ncomparison with the chance baseline method, and network visualization. Such\nvisualizations reveal individual characteristics of the authors, which can be\nunderstood as a kind of calligraphy.", "published": "2017-05-29 23:34:03", "link": "http://arxiv.org/abs/1705.10415v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Importance of Automatic Syntactic Features in Vietnamese Named\n  Entity Recognition", "abstract": "This paper presents a state-of-the-art system for Vietnamese Named Entity\nRecognition (NER). By incorporating automatic syntactic features with word\nembeddings as input for bidirectional Long Short-Term Memory (Bi-LSTM), our\nsystem, although simpler than some deep learning architectures, achieves a much\nbetter result for Vietnamese NER. The proposed method achieves an overall F1\nscore of 92.05% on the test set of an evaluation campaign, organized in late\n2016 by the Vietnamese Language and Speech Processing (VLSP) community. Our\nnamed entity recognition system outperforms the best previous systems for\nVietnamese NER by a large margin.", "published": "2017-05-29 08:10:15", "link": "http://arxiv.org/abs/1705.10610v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Character-Based Text Classification using Top Down Semantic Model for\n  Sentence Representation", "abstract": "Despite the success of deep learning on many fronts especially image and\nspeech, its application in text classification often is still not as good as a\nsimple linear SVM on n-gram TF-IDF representation especially for smaller\ndatasets. Deep learning tends to emphasize on sentence level semantics when\nlearning a representation with models like recurrent neural network or\nrecursive neural network, however from the success of TF-IDF representation, it\nseems a bag-of-words type of representation has its strength. Taking advantage\nof both representions, we present a model known as TDSM (Top Down Semantic\nModel) for extracting a sentence representation that considers both the\nword-level semantics by linearly combining the words with attention weights and\nthe sentence-level semantics with BiLSTM and use it on text classification. We\napply the model on characters and our results show that our model is better\nthan all the other character-based and word-based convolutional neural network\nmodels by \\cite{zhang15} across seven different datasets with only 1\\% of their\nparameters. We also demonstrate that this model beats traditional linear models\non TF-IDF vectors on small and polished datasets like news article in which\ntypically deep learning models surrender.", "published": "2017-05-29 15:53:00", "link": "http://arxiv.org/abs/1705.10586v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Multilingual Training of Neural Dependency Parsers", "abstract": "We show that a recently proposed neural dependency parser can be improved by\njoint training on multiple languages from the same family. The parser is\nimplemented as a deep neural network whose only input is orthographic\nrepresentations of words. In order to successfully parse, the network has to\ndiscover how linguistically relevant concepts can be inferred from word\nspellings. We analyze the representations of characters and words that are\nlearned by the network to establish which properties of languages were\naccounted for. In particular we show that the parser has approximately learned\nto associate Latin characters with their Cyrillic counterparts and that it can\ngroup Polish and Russian words that have a similar grammatical function.\nFinally, we evaluate the parser on selected languages from the Universal\nDependencies dataset and show that it is competitive with other recently\nproposed state-of-the art methods, while having a simple structure.", "published": "2017-05-29 14:24:08", "link": "http://arxiv.org/abs/1705.10209v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Latent Intention Dialogue Models", "abstract": "Developing a dialogue agent that is capable of making autonomous decisions\nand communicating by natural language is one of the long-term goals of machine\nlearning research. Traditional approaches either rely on hand-crafting a small\nstate-action set for applying reinforcement learning that is not scalable or\nconstructing deterministic models for learning dialogue sentences that fail to\ncapture natural conversational variability. In this paper, we propose a Latent\nIntention Dialogue Model (LIDM) that employs a discrete latent variable to\nlearn underlying dialogue intentions in the framework of neural variational\ninference. In a goal-oriented dialogue scenario, these latent intentions can be\ninterpreted as actions guiding the generation of machine responses, which can\nbe further refined autonomously by reinforcement learning. The experimental\nevaluation of LIDM shows that the model out-performs published benchmarks for\nboth corpus-based and human evaluation, demonstrating the effectiveness of\ndiscrete latent variable models for learning goal-oriented dialogues.", "published": "2017-05-29 15:01:44", "link": "http://arxiv.org/abs/1705.10229v1", "categories": ["cs.CL", "cs.LG", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Emergent Communication in a Multi-Modal, Multi-Step Referential Game", "abstract": "Inspired by previous work on emergent communication in referential games, we\npropose a novel multi-modal, multi-step referential game, where the sender and\nreceiver have access to distinct modalities of an object, and their information\nexchange is bidirectional and of arbitrary duration. The multi-modal multi-step\nsetting allows agents to develop an internal communication significantly closer\nto natural language, in that they share a single set of messages, and that the\nlength of the conversation may vary according to the difficulty of the task. We\nexamine these properties empirically using a dataset consisting of images and\ntextual descriptions of mammals, where the agents are tasked with identifying\nthe correct object. Our experiments indicate that a robust and efficient\ncommunication protocol emerges, where gradual information exchange informs\nbetter predictions and higher communication bandwidth improves generalization.", "published": "2017-05-29 19:25:49", "link": "http://arxiv.org/abs/1705.10369v4", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.IT", "cs.MA", "math.IT"], "primary_category": "cs.LG"}
