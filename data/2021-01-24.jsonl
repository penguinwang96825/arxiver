{"title": "WangchanBERTa: Pretraining transformer-based Thai Language Models", "abstract": "Transformer-based language models, more specifically BERT-based architectures\nhave achieved state-of-the-art performance in many downstream tasks. However,\nfor a relatively low-resource language such as Thai, the choices of models are\nlimited to training a BERT-based model based on a much smaller dataset or\nfinetuning multi-lingual models, both of which yield suboptimal downstream\nperformance. Moreover, large-scale multi-lingual pretraining does not take into\naccount language-specific features for Thai. To overcome these limitations, we\npretrain a language model based on RoBERTa-base architecture on a large,\ndeduplicated, cleaned training set (78GB in total size), curated from diverse\ndomains of social media posts, news articles and other publicly available\ndatasets. We apply text processing rules that are specific to Thai most\nimportantly preserving spaces, which are important chunk and sentence\nboundaries in Thai before subword tokenization. We also experiment with\nword-level, syllable-level and SentencePiece tokenization with a smaller\ndataset to explore the effects on tokenization on downstream performance. Our\nmodel wangchanberta-base-att-spm-uncased trained on the 78.5GB dataset\noutperforms strong baselines (NBSVM, CRF and ULMFit) and multi-lingual models\n(XLMR and mBERT) on both sequence classification and token classification tasks\nin human-annotated, mono-lingual contexts.", "published": "2021-01-24 03:06:34", "link": "http://arxiv.org/abs/2101.09635v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Dialog Length matter for Next Response Selection task? An Empirical\n  Study", "abstract": "In the last few years, the release of BERT, a multilingual transformer based\nmodel, has taken the NLP community by storm. BERT-based models have achieved\nstate-of-the-art results on various NLP tasks, including dialog tasks. One of\nthe limitation of BERT is the lack of ability to handle long text sequence. By\ndefault, BERT has a maximum wordpiece token sequence length of 512. Recently,\nthere has been renewed interest to tackle the BERT limitation to handle long\ntext sequences with the addition of new self-attention based architectures.\nHowever, there has been little to no research on the impact of this limitation\nwith respect to dialog tasks. Dialog tasks are inherently different from other\nNLP tasks due to: a) the presence of multiple utterances from multiple\nspeakers, which may be interlinked to each other across different turns and b)\nlonger length of dialogs. In this work, we empirically evaluate the impact of\ndialog length on the performance of BERT model for the Next Response Selection\ndialog task on four publicly available and one internal multi-turn dialog\ndatasets. We observe that there is little impact on performance with long\ndialogs and even the simplest approach of truncating input works really well.", "published": "2021-01-24 05:39:36", "link": "http://arxiv.org/abs/2101.09647v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Novel Two-stage Framework for Extracting Opinionated Sentences from\n  News Articles", "abstract": "This paper presents a novel two-stage framework to extract opinionated\nsentences from a given news article. In the first stage, Naive Bayes classifier\nby utilizing the local features assigns a score to each sentence - the score\nsignifies the probability of the sentence to be opinionated. In the second\nstage, we use this prior within the HITS (Hyperlink-Induced Topic Search)\nschema to exploit the global structure of the article and relation between the\nsentences. In the HITS schema, the opinionated sentences are treated as Hubs\nand the facts around these opinions are treated as the Authorities. The\nalgorithm is implemented and evaluated against a set of manually marked data.\nWe show that using HITS significantly improves the precision over the baseline\nNaive Bayes classifier. We also argue that the proposed method actually\ndiscovers the underlying structure of the article, thus extracting various\nopinions, grouped with supporting facts as well as other supporting opinions\nfrom the article.", "published": "2021-01-24 16:24:20", "link": "http://arxiv.org/abs/2101.09743v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RomeBERT: Robust Training of Multi-Exit BERT", "abstract": "BERT has achieved superior performances on Natural Language Understanding\n(NLU) tasks. However, BERT possesses a large number of parameters and demands\ncertain resources to deploy. For acceleration, Dynamic Early Exiting for BERT\n(DeeBERT) has been proposed recently, which incorporates multiple exits and\nadopts a dynamic early-exit mechanism to ensure efficient inference. While\nobtaining an efficiency-performance tradeoff, the performances of early exits\nin multi-exit BERT are significantly worse than late exits. In this paper, we\nleverage gradient regularized self-distillation for RObust training of\nMulti-Exit BERT (RomeBERT), which can effectively solve the performance\nimbalance problem between early and late exits. Moreover, the proposed RomeBERT\nadopts a one-stage joint training strategy for multi-exits and the BERT\nbackbone while DeeBERT needs two stages that require more training time.\nExtensive experiments on GLUE datasets are performed to demonstrate the\nsuperiority of our approach. Our code is available at\nhttps://github.com/romebert/RomeBERT.", "published": "2021-01-24 17:03:57", "link": "http://arxiv.org/abs/2101.09755v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Models of Robust Word Recognition with Serial Reproduction", "abstract": "Spoken communication occurs in a \"noisy channel\" characterized by high levels\nof environmental noise, variability within and between speakers, and lexical\nand syntactic ambiguity. Given these properties of the received linguistic\ninput, robust spoken word recognition -- and language processing more generally\n-- relies heavily on listeners' prior knowledge to evaluate whether candidate\ninterpretations of that input are more or less likely. Here we compare several\nbroad-coverage probabilistic generative language models in their ability to\ncapture human linguistic expectations. Serial reproduction, an experimental\nparadigm where spoken utterances are reproduced by successive participants\nsimilar to the children's game of \"Telephone,\" is used to elicit a sample that\nreflects the linguistic expectations of English-speaking adults. When we\nevaluate a suite of probabilistic generative language models against the\nyielded chains of utterances, we find that those models that make use of\nabstract representations of preceding linguistic context (i.e., phrase\nstructure) best predict the changes made by people in the course of serial\nreproduction. A logistic regression model predicting which words in an\nutterance are most likely to be lost or changed in the course of spoken\ntransmission corroborates this result. We interpret these findings in light of\nresearch highlighting the interaction of memory-based constraints and\nrepresentations in language processing.", "published": "2021-01-24 20:16:12", "link": "http://arxiv.org/abs/2101.09788v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FakeFlow: Fake News Detection by Modeling the Flow of Affective\n  Information", "abstract": "Fake news articles often stir the readers' attention by means of emotional\nappeals that arouse their feelings. Unlike in short news texts, authors of\nlonger articles can exploit such affective factors to manipulate readers by\nadding exaggerations or fabricating events, in order to affect the readers'\nemotions. To capture this, we propose in this paper to model the flow of\naffective information in fake news articles using a neural architecture. The\nproposed model, FakeFlow, learns this flow by combining topic and affective\ninformation extracted from text. We evaluate the model's performance with\nseveral experiments on four real-world datasets. The results show that FakeFlow\nachieves superior results when compared against state-of-the-art methods, thus\nconfirming the importance of capturing the flow of the affective information in\nnews articles.", "published": "2021-01-24 21:55:28", "link": "http://arxiv.org/abs/2101.09810v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Head Label Help for Long-Tailed Multi-Label Text Classification", "abstract": "Multi-label text classification (MLTC) aims to annotate documents with the\nmost relevant labels from a number of candidate labels. In real applications,\nthe distribution of label frequency often exhibits a long tail, i.e., a few\nlabels are associated with a large number of documents (a.k.a. head labels),\nwhile a large fraction of labels are associated with a small number of\ndocuments (a.k.a. tail labels). To address the challenge of insufficient\ntraining data on tail label classification, we propose a Head-to-Tail Network\n(HTTN) to transfer the meta-knowledge from the data-rich head labels to\ndata-poor tail labels. The meta-knowledge is the mapping from few-shot network\nparameters to many-shot network parameters, which aims to promote the\ngeneralizability of tail classifiers. Extensive experimental results on three\nbenchmark datasets demonstrate that HTTN consistently outperforms the\nstate-of-the-art methods. The code and hyper-parameter settings are released\nfor reproducibility", "published": "2021-01-24 12:31:39", "link": "http://arxiv.org/abs/2101.09704v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Belief-based Generation of Argumentative Claims", "abstract": "When engaging in argumentative discourse, skilled human debaters tailor\nclaims to the beliefs of the audience, to construct effective arguments.\nRecently, the field of computational argumentation witnessed extensive effort\nto address the automatic generation of arguments. However, existing approaches\ndo not perform any audience-specific adaptation. In this work, we aim to bridge\nthis gap by studying the task of belief-based claim generation: Given a\ncontroversial topic and a set of beliefs, generate an argumentative claim\ntailored to the beliefs. To tackle this task, we model the people's prior\nbeliefs through their stances on controversial topics and extend\nstate-of-the-art text generation models to generate claims conditioned on the\nbeliefs. Our automatic evaluation confirms the ability of our approach to adapt\nclaims to a set of given beliefs. In a manual study, we additionally evaluate\nthe generated claims in terms of informativeness and their likelihood to be\nuttered by someone with a respective belief. Our results reveal the limitations\nof modeling users' beliefs based on their stances, but demonstrate the\npotential of encoding beliefs into argumentative texts, laying the ground for\nfuture exploration of audience reach.", "published": "2021-01-24 18:07:02", "link": "http://arxiv.org/abs/2101.09765v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge Grounded Conversational Symptom Detection with Graph Memory\n  Networks", "abstract": "In this work, we propose a novel goal-oriented dialog task, automatic symptom\ndetection. We build a system that can interact with patients through dialog to\ndetect and collect clinical symptoms automatically, which can save a doctor's\ntime interviewing the patient. Given a set of explicit symptoms provided by the\npatient to initiate a dialog for diagnosing, the system is trained to collect\nimplicit symptoms by asking questions, in order to collect more information for\nmaking an accurate diagnosis. After getting the reply from the patient for each\nquestion, the system also decides whether current information is enough for a\nhuman doctor to make a diagnosis. To achieve this goal, we propose two neural\nmodels and a training pipeline for the multi-step reasoning task. We also build\na knowledge graph as additional inputs to further improve model performance.\nExperiments show that our model significantly outperforms the baseline by 4%,\ndiscovering 67% of implicit symptoms on average with a limited number of\nquestions.", "published": "2021-01-24 18:50:16", "link": "http://arxiv.org/abs/2101.09773v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Review of Speaker Diarization: Recent Advances with Deep Learning", "abstract": "Speaker diarization is a task to label audio or video recordings with classes\nthat correspond to speaker identity, or in short, a task to identify \"who spoke\nwhen\". In the early years, speaker diarization algorithms were developed for\nspeech recognition on multispeaker audio recordings to enable speaker adaptive\nprocessing. These algorithms also gained their own value as a standalone\napplication over time to provide speaker-specific metainformation for\ndownstream tasks such as audio retrieval. More recently, with the emergence of\ndeep learning technology, which has driven revolutionary changes in research\nand practices across speech application domains, rapid advancements have been\nmade for speaker diarization. In this paper, we review not only the historical\ndevelopment of speaker diarization technology but also the recent advancements\nin neural speaker diarization approaches. Furthermore, we discuss how speaker\ndiarization systems have been integrated with speech recognition applications\nand how the recent surge of deep learning is leading the way of jointly\nmodeling these two components to be complementary to each other. By considering\nsuch exciting technical trends, we believe that this paper is a valuable\ncontribution to the community to provide a survey work by consolidating the\nrecent developments with neural methods and thus facilitating further progress\ntoward a more efficient speaker diarization.", "published": "2021-01-24 01:28:05", "link": "http://arxiv.org/abs/2101.09624v4", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Explanation as a Defense of Recommendation", "abstract": "Textual explanations have proved to help improve user satisfaction on\nmachine-made recommendations. However, current mainstream solutions loosely\nconnect the learning of explanation with the learning of recommendation: for\nexample, they are often separately modeled as rating prediction and content\ngeneration tasks. In this work, we propose to strengthen their connection by\nenforcing the idea of sentiment alignment between a recommendation and its\ncorresponding explanation. At training time, the two learning tasks are joined\nby a latent sentiment vector, which is encoded by the recommendation module and\nused to make word choices for explanation generation. At both training and\ninference time, the explanation module is required to generate explanation text\nthat matches sentiment predicted by the recommendation module. Extensive\nexperiments demonstrate our solution outperforms a rich set of baselines in\nboth recommendation and explanation tasks, especially on the improved quality\nof its generated explanations. More importantly, our user studies confirm our\ngenerated explanations help users better recognize the differences between\nrecommended items and understand why an item is recommended.", "published": "2021-01-24 06:34:36", "link": "http://arxiv.org/abs/2101.09656v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Automatic Monitoring Social Dynamics During Big Incidences: A Case Study\n  of COVID-19 in Bangladesh", "abstract": "Newspapers are trustworthy media where people get the most reliable and\ncredible information compared with other sources. On the other hand, social\nmedia often spread rumors and misleading news to get more traffic and\nattention. Careful characterization, evaluation, and interpretation of\nnewspaper data can provide insight into intrigue and passionate social issues\nto monitor any big social incidence. This study analyzed a large set of\nspatio-temporal Bangladeshi newspaper data related to the COVID-19 pandemic.\nThe methodology included volume analysis, topic analysis, automated\nclassification, and sentiment analysis of news articles to get insight into the\nCOVID-19 pandemic in different sectors and regions in Bangladesh over a period\nof time. This analysis will help the government and other organizations to\nfigure out the challenges that have arisen in society due to this pandemic,\nwhat steps should be taken immediately and in the post-pandemic period, how the\ngovernment and its allies can come together to address the crisis in the\nfuture, keeping these problems in mind.", "published": "2021-01-24 07:46:17", "link": "http://arxiv.org/abs/2101.09667v2", "categories": ["cs.CY", "cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CY"}
{"title": "Stereotype and Skew: Quantifying Gender Bias in Pre-trained and\n  Fine-tuned Language Models", "abstract": "This paper proposes two intuitive metrics, skew and stereotype, that quantify\nand analyse the gender bias present in contextual language models when tackling\nthe WinoBias pronoun resolution task. We find evidence that gender stereotype\ncorrelates approximately negatively with gender skew in out-of-the-box models,\nsuggesting that there is a trade-off between these two forms of bias. We\ninvestigate two methods to mitigate bias. The first approach is an online\nmethod which is effective at removing skew at the expense of stereotype. The\nsecond, inspired by previous work on ELMo, involves the fine-tuning of BERT\nusing an augmented gender-balanced dataset. We show that this reduces both skew\nand stereotype relative to its unaugmented fine-tuned counterpart. However, we\nfind that existing gender bias benchmarks do not fully probe professional bias\nas pronoun resolution may be obfuscated by cross-correlations from other\nmanifestations of gender prejudice. Our code is available online, at\nhttps://github.com/12kleingordon34/NLP_masters_project.", "published": "2021-01-24 10:57:59", "link": "http://arxiv.org/abs/2101.09688v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "A2P-MANN: Adaptive Attention Inference Hops Pruned Memory-Augmented\n  Neural Networks", "abstract": "In this work, to limit the number of required attention inference hops in\nmemory-augmented neural networks, we propose an online adaptive approach called\nA2P-MANN. By exploiting a small neural network classifier, an adequate number\nof attention inference hops for the input query is determined. The technique\nresults in elimination of a large number of unnecessary computations in\nextracting the correct answer. In addition, to further lower computations in\nA2P-MANN, we suggest pruning weights of the final FC (fully-connected) layers.\nTo this end, two pruning approaches, one with negligible accuracy loss and the\nother with controllable loss on the final accuracy, are developed. The efficacy\nof the technique is assessed by using the twenty question-answering (QA) tasks\nof bAbI dataset. The analytical assessment reveals, on average, more than 42%\nfewer computations compared to the baseline MANN at the cost of less than 1%\naccuracy loss. In addition, when used along with the previously published\nzero-skipping technique, a computation count reduction of up to 68% is\nachieved. Finally, when the proposed approach (without zero-skipping) is\nimplemented on the CPU and GPU platforms, up to 43% runtime reduction is\nachieved.", "published": "2021-01-24 12:02:12", "link": "http://arxiv.org/abs/2101.09693v2", "categories": ["cs.CL", "cs.CC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fast Sequence Generation with Multi-Agent Reinforcement Learning", "abstract": "Autoregressive sequence Generation models have achieved state-of-the-art\nperformance in areas like machine translation and image captioning. These\nmodels are autoregressive in that they generate each word by conditioning on\npreviously generated words, which leads to heavy latency during inference.\nRecently, non-autoregressive decoding has been proposed in machine translation\nto speed up the inference time by generating all words in parallel. Typically,\nthese models use the word-level cross-entropy loss to optimize each word\nindependently. However, such a learning process fails to consider the\nsentence-level consistency, thus resulting in inferior generation quality of\nthese non-autoregressive models. In this paper, we propose a simple and\nefficient model for Non-Autoregressive sequence Generation (NAG) with a novel\ntraining paradigm: Counterfactuals-critical Multi-Agent Learning (CMAL). CMAL\nformulates NAG as a multi-agent reinforcement learning system where element\npositions in the target sequence are viewed as agents that learn to\ncooperatively maximize a sentence-level reward. On MSCOCO image captioning\nbenchmark, our NAG method achieves a performance comparable to state-of-the-art\nautoregressive models, while brings 13.9x decoding speedup. On WMT14 EN-DE\nmachine translation dataset, our method outperforms cross-entropy trained\nbaseline by 6.0 BLEU points while achieves the greatest decoding speedup of\n17.46x.", "published": "2021-01-24 12:16:45", "link": "http://arxiv.org/abs/2101.09698v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Analysing the Noise Model Error for Realistic Noisy Label Data", "abstract": "Distant and weak supervision allow to obtain large amounts of labeled\ntraining data quickly and cheaply, but these automatic annotations tend to\ncontain a high amount of errors. A popular technique to overcome the negative\neffects of these noisy labels is noise modelling where the underlying noise\nprocess is modelled. In this work, we study the quality of these estimated\nnoise models from the theoretical side by deriving the expected error of the\nnoise model. Apart from evaluating the theoretical results on commonly used\nsynthetic noise, we also publish NoisyNER, a new noisy label dataset from the\nNLP domain that was obtained through a realistic distant supervision technique.\nIt provides seven sets of labels with differing noise patterns to evaluate\ndifferent noise levels on the same instances. Parallel, clean labels are\navailable making it possible to study scenarios where a small amount of\ngold-standard data can be leveraged. Our theoretical results and the\ncorresponding experiments give insights into the factors that influence the\nnoise model estimation like the noise distribution and the sampling technique.", "published": "2021-01-24 17:45:15", "link": "http://arxiv.org/abs/2101.09763v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Separating Stimulus-Induced and Background Components of Dynamic\n  Functional Connectivity in Naturalistic fMRI", "abstract": "We consider the challenges in extracting stimulus-related neural dynamics\nfrom other intrinsic processes and noise in naturalistic functional magnetic\nresonance imaging (fMRI). Most studies rely on inter-subject correlations (ISC)\nof low-level regional activity and neglect varying responses in individuals. We\npropose a novel, data-driven approach based on low-rank plus sparse (L+S)\ndecomposition to isolate stimulus-driven dynamic changes in brain functional\nconnectivity (FC) from the background noise, by exploiting shared network\nstructure among subjects receiving the same naturalistic stimuli. The\ntime-resolved multi-subject FC matrices are modeled as a sum of a low-rank\ncomponent of correlated FC patterns across subjects, and a sparse component of\nsubject-specific, idiosyncratic background activities. To recover the shared\nlow-rank subspace, we introduce a fused version of principal component pursuit\n(PCP) by adding a fusion-type penalty on the differences between the rows of\nthe low-rank matrix. The method improves the detection of stimulus-induced\ngroup-level homogeneity in the FC profile while capturing inter-subject\nvariability. We develop an efficient algorithm via a linearized alternating\ndirection method of multipliers to solve the fused-PCP. Simulations show\naccurate recovery by the fused-PCP even when a large fraction of FC edges are\nseverely corrupted. When applied to natural fMRI data, our method reveals FC\nchanges that were time-locked to auditory processing during movie watching,\nwith dynamic engagement of sensorimotor systems for speech-in-noise. It also\nprovides a better mapping to auditory content in the movie than ISC.", "published": "2021-01-24 11:35:39", "link": "http://arxiv.org/abs/2102.10331v1", "categories": ["q-bio.NC", "cs.LG", "cs.SD", "eess.AS", "eess.IV", "eess.SP", "stat.AP"], "primary_category": "q-bio.NC"}
