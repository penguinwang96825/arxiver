{"title": "Non-Linguistic Supervision for Contrastive Learning of Sentence\n  Embeddings", "abstract": "Semantic representation learning for sentences is an important and\nwell-studied problem in NLP. The current trend for this task involves training\na Transformer-based sentence encoder through a contrastive objective with text,\ni.e., clustering sentences with semantically similar meanings and scattering\nothers. In this work, we find the performance of Transformer models as sentence\nencoders can be improved by training with multi-modal multi-task losses, using\nunpaired examples from another modality (e.g., sentences and unrelated\nimage/audio data). In particular, besides learning by the contrastive loss on\ntext, our model clusters examples from a non-linguistic domain (e.g.,\nvisual/audio) with a similar contrastive loss at the same time. The reliance of\nour framework on unpaired non-linguistic data makes it language-agnostic,\nenabling it to be widely applicable beyond English NLP. Experiments on 7\nsemantic textual similarity benchmarks reveal that models trained with the\nadditional non-linguistic (images/audio) contrastive objective lead to higher\nquality sentence embeddings. This indicates that Transformer models are able to\ngeneralize better by doing a similar task (i.e., clustering) with unpaired\nexamples from different modalities in a multi-task fashion.", "published": "2022-09-20 03:01:45", "link": "http://arxiv.org/abs/2209.09433v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vega-MT: The JD Explore Academy Translation System for WMT22", "abstract": "We describe the JD Explore Academy's submission of the WMT 2022 shared\ngeneral translation task. We participated in all high-resource tracks and one\nmedium-resource track, including Chinese-English, German-English,\nCzech-English, Russian-English, and Japanese-English. We push the limit of our\nprevious work -- bidirectional training for translation by scaling up two main\nfactors, i.e. language pairs and model sizes, namely the \\textbf{Vega-MT}\nsystem. As for language pairs, we scale the \"bidirectional\" up to the\n\"multidirectional\" settings, covering all participating languages, to exploit\nthe common knowledge across languages, and transfer them to the downstream\nbilingual tasks. As for model sizes, we scale the Transformer-Big up to the\nextremely large model that owns nearly 4.7 Billion parameters, to fully enhance\nthe model capacity for our Vega-MT. Also, we adopt the data augmentation\nstrategies, e.g. cycle translation for monolingual data, and bidirectional\nself-training for bilingual and monolingual data, to comprehensively exploit\nthe bilingual and monolingual data. To adapt our Vega-MT to the general domain\ntest set, generalization tuning is designed. Based on the official automatic\nscores of constrained systems, in terms of the sacreBLEU shown in Figure-1, we\ngot the 1st place on {Zh-En (33.5), En-Zh (49.7), De-En (33.7), En-De (37.8),\nCs-En (54.9), En-Cs (41.4) and En-Ru (32.7)}, 2nd place on {Ru-En (45.1) and\nJa-En (25.6)}, and 3rd place on {En-Ja(41.5)}, respectively; W.R.T the COMET,\nwe got the 1st place on {Zh-En (45.1), En-Zh (61.7), De-En (58.0), En-De\n(63.2), Cs-En (74.7), Ru-En (64.9), En-Ru (69.6) and En-Ja (65.1)}, 2nd place\non {En-Cs (95.3) and Ja-En (40.6)}, respectively.", "published": "2022-09-20 03:45:24", "link": "http://arxiv.org/abs/2209.09444v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Few-shot Approach to Resume Information Extraction via Prompts", "abstract": "Prompt learning's fine-tune performance on text classification tasks has\nattracted the NLP community. This paper applies it to resume information\nextraction, improving existing methods for this task. We created manual\ntemplates and verbalizers tailored to resume texts and compared the performance\nof Masked Language Model (MLM) and Seq2Seq PLMs. Also, we enhanced the\nverbalizer design for Knowledgeable Prompt-tuning, contributing to prompt\ntemplate design across NLP tasks. We present the Manual Knowledgeable\nVerbalizer (MKV), a rule for constructing verbalizers for specific\napplications. Our tests show that MKV rules yield more effective, robust\ntemplates and verbalizers than existing methods. Our MKV approach resolved\nsample imbalance, surpassing current automatic prompt methods. This study\nunderscores the value of tailored prompt learning for resume extraction,\nstressing the importance of custom-designed templates and verbalizers.", "published": "2022-09-20 04:01:46", "link": "http://arxiv.org/abs/2209.09450v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalizing through Forgetting -- Domain Generalization for Symptom\n  Event Extraction in Clinical Notes", "abstract": "Symptom information is primarily documented in free-text clinical notes and\nis not directly accessible for downstream applications. To address this\nchallenge, information extraction approaches that can handle clinical language\nvariation across different institutions and specialties are needed. In this\npaper, we present domain generalization for symptom extraction using\npretraining and fine-tuning data that differs from the target domain in terms\nof institution and/or specialty and patient population. We extract symptom\nevents using a transformer-based joint entity and relation extraction method.\nTo reduce reliance on domain-specific features, we propose a domain\ngeneralization method that dynamically masks frequent symptoms words in the\nsource domain. Additionally, we pretrain the transformer language model (LM) on\ntask-related unlabeled texts for better representation. Our experiments\nindicate that masking and adaptive pretraining methods can significantly\nimprove performance when the source domain is more distant from the target\ndomain.", "published": "2022-09-20 05:53:22", "link": "http://arxiv.org/abs/2209.09485v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Yet Another Format of Universal Dependencies for Korean", "abstract": "In this study, we propose a morpheme-based scheme for Korean dependency\nparsing and adopt the proposed scheme to Universal Dependencies. We present the\nlinguistic rationale that illustrates the motivation and the necessity of\nadopting the morpheme-based format, and develop scripts that convert between\nthe original format used by Universal Dependencies and the proposed\nmorpheme-based format automatically. The effectiveness of the proposed format\nfor Korean dependency parsing is then testified by both statistical and neural\nmodels, including UDPipe and Stanza, with our carefully constructed\nmorpheme-based word embedding for Korean. morphUD outperforms parsing results\nfor all Korean UD treebanks, and we also present detailed error analyses.", "published": "2022-09-20 14:21:00", "link": "http://arxiv.org/abs/2209.09742v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Target-Guided Open-Domain Conversation Planning", "abstract": "Prior studies addressing target-oriented conversational tasks lack a crucial\nnotion that has been intensively studied in the context of goal-oriented\nartificial intelligence agents, namely, planning. In this study, we propose the\ntask of Target-Guided Open-Domain Conversation Planning (TGCP) task to evaluate\nwhether neural conversational agents have goal-oriented conversation planning\nabilities. Using the TGCP task, we investigate the conversation planning\nabilities of existing retrieval models and recent strong generative models. The\nexperimental results reveal the challenges facing current technology.", "published": "2022-09-20 14:22:33", "link": "http://arxiv.org/abs/2209.09746v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Varieties of Italy: Technology Challenges and Opportunities", "abstract": "Italy is characterized by a one-of-a-kind linguistic diversity landscape in\nEurope, which implicitly encodes local knowledge, cultural traditions, artistic\nexpressions and history of its speakers. However, most local languages and\ndialects in Italy are at risk of disappearing within few generations. The NLP\ncommunity has recently begun to engage with endangered languages, including\nthose of Italy. Yet, most efforts assume that these varieties are\nunder-resourced language monoliths with an established written form and\nhomogeneous functions and needs, and thus highly interchangeable with each\nother and with high-resource, standardized languages. In this paper, we\nintroduce the linguistic context of Italy and challenge the default\nmachine-centric assumptions of NLP for Italy's language varieties. We advocate\nfor a shift in the paradigm from machine-centric to speaker-centric NLP, and\nprovide recommendations and opportunities for work that prioritizes languages\nand their speakers over technological advances. To facilitate the process, we\nfinally propose building a local community towards responsible, participatory\nefforts aimed at supporting vitality of languages and dialects of Italy.", "published": "2022-09-20 14:39:12", "link": "http://arxiv.org/abs/2209.09757v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Efficient End-to-End Transformer with Progressive Tri-modal Attention\n  for Multi-modal Emotion Recognition", "abstract": "Recent works on multi-modal emotion recognition move towards end-to-end\nmodels, which can extract the task-specific features supervised by the target\ntask compared with the two-phase pipeline. However, previous methods only model\nthe feature interactions between the textual and either acoustic and visual\nmodalities, ignoring capturing the feature interactions between the acoustic\nand visual modalities. In this paper, we propose the multi-modal end-to-end\ntransformer (ME2ET), which can effectively model the tri-modal features\ninteraction among the textual, acoustic, and visual modalities at the low-level\nand high-level. At the low-level, we propose the progressive tri-modal\nattention, which can model the tri-modal feature interactions by adopting a\ntwo-pass strategy and can further leverage such interactions to significantly\nreduce the computation and memory complexity through reducing the input token\nlength. At the high-level, we introduce the tri-modal feature fusion layer to\nexplicitly aggregate the semantic representations of three modalities. The\nexperimental results on the CMU-MOSEI and IEMOCAP datasets show that ME2ET\nachieves the state-of-the-art performance. The further in-depth analysis\ndemonstrates the effectiveness, efficiency, and interpretability of the\nproposed progressive tri-modal attention, which can help our model to achieve\nbetter performance while significantly reducing the computation and memory\ncost. Our code will be publicly available.", "published": "2022-09-20 14:51:38", "link": "http://arxiv.org/abs/2209.09768v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Register Variation Remains Stable Across 60 Languages", "abstract": "This paper measures the stability of cross-linguistic register variation. A\nregister is a variety of a language that is associated with extra-linguistic\ncontext. The relationship between a register and its context is functional: the\nlinguistic features that make up a register are motivated by the needs and\nconstraints of the communicative situation. This view hypothesizes that\nregister should be universal, so that we expect a stable relationship between\nthe extra-linguistic context that defines a register and the sets of linguistic\nfeatures which the register contains. In this paper, the universality and\nrobustness of register variation is tested by comparing variation within vs.\nbetween register-specific corpora in 60 languages using corpora produced in\ncomparable communicative situations: tweets and Wikipedia articles. Our\nfindings confirm the prediction that register variation is, in fact, universal.", "published": "2022-09-20 16:02:15", "link": "http://arxiv.org/abs/2209.09813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Twitter Topic Classification", "abstract": "Social media platforms host discussions about a wide variety of topics that\narise everyday. Making sense of all the content and organising it into\ncategories is an arduous task. A common way to deal with this issue is relying\non topic modeling, but topics discovered using this technique are difficult to\ninterpret and can differ from corpus to corpus. In this paper, we present a new\ntask based on tweet topic classification and release two associated datasets.\nGiven a wide range of topics covering the most important discussion points in\nsocial media, we provide training and testing data from recent time periods\nthat can be used to evaluate tweet classification models. Moreover, we perform\na quantitative evaluation and analysis of current general- and domain-specific\nlanguage models on the task, which provide more insights on the challenges and\nnature of the task.", "published": "2022-09-20 16:13:52", "link": "http://arxiv.org/abs/2209.09824v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Relevance Graph Network for Knowledge-Aware Question Answering", "abstract": "This work investigates the challenge of learning and reasoning for\nCommonsense Question Answering given an external source of knowledge in the\nform of a knowledge graph (KG). We propose a novel graph neural network\narchitecture, called Dynamic Relevance Graph Network (DRGN). DRGN operates on a\ngiven KG subgraph based on the question and answers entities and uses the\nrelevance scores between the nodes to establish new edges dynamically for\nlearning node representations in the graph network. This explicit usage of\nrelevance as graph edges has the following advantages, a) the model can exploit\nthe existing relationships, re-scale the node weights, and influence the way\nthe neighborhood nodes' representations are aggregated in the KG subgraph, b)\nIt potentially recovers the missing edges in KG that are needed for reasoning.\nMoreover, as a byproduct, our model improves handling the negative questions\ndue to considering the relevance between the question node and the graph\nentities. Our proposed approach shows competitive performance on two QA\nbenchmarks, CommonsenseQA and OpenbookQA, compared to the state-of-the-art\npublished results.", "published": "2022-09-20 18:52:05", "link": "http://arxiv.org/abs/2209.09947v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Optimal Granularity for Extractive Summarization of\n  Unstructured Health Records: Analysis of the Largest Multi-Institutional\n  Archive of Health Records in Japan", "abstract": "Automated summarization of clinical texts can reduce the burden of medical\nprofessionals. \"Discharge summaries\" are one promising application of the\nsummarization, because they can be generated from daily inpatient records. Our\npreliminary experiment suggests that 20-31% of the descriptions in discharge\nsummaries overlap with the content of the inpatient records. However, it\nremains unclear how the summaries should be generated from the unstructured\nsource. To decompose the physician's summarization process, this study aimed to\nidentify the optimal granularity in summarization. We first defined three types\nof summarization units with different granularities to compare the performance\nof the discharge summary generation: whole sentences, clinical segments, and\nclauses. We defined clinical segments in this study, aiming to express the\nsmallest medically meaningful concepts. To obtain the clinical segments, it was\nnecessary to automatically split the texts in the first stage of the pipeline.\nAccordingly, we compared rule-based methods and a machine learning method, and\nthe latter outperformed the formers with an F1 score of 0.846 in the splitting\ntask. Next, we experimentally measured the accuracy of extractive summarization\nusing the three types of units, based on the ROUGE-1 metric, on a\nmulti-institutional national archive of health records in Japan. The measured\naccuracies of extractive summarization using whole sentences, clinical\nsegments, and clauses were 31.91, 36.15, and 25.18, respectively. We found that\nthe clinical segments yielded higher accuracy than sentences and clauses. This\nresult indicates that summarization of inpatient records demands finer\ngranularity than sentence-oriented processing. Although we used only Japanese\nhealth records, it can be interpreted as follows: physicians extract \"concepts\nof medical significance\" from patient records and recombine them ...", "published": "2022-09-20 23:26:02", "link": "http://arxiv.org/abs/2209.10041v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Label Sequence Generation for Prompting Sequence-to-sequence\n  Models", "abstract": "Prompting, which casts downstream applications as language modeling tasks,\nhas shown to be sample efficient compared to standard fine-tuning with\npre-trained models. However, one pitfall of prompting is the need of\nmanually-designed patterns, whose outcome can be unintuitive and requires large\nvalidation sets to tune. To tackle the challenge, we propose AutoSeq, a fully\nautomatic prompting method: (1) We adopt natural language prompts on\nsequence-to-sequence models, enabling free-form generation and larger label\nsearch space; (2) We propose label sequences -- phrases with indefinite lengths\nto verbalize the labels -- which eliminate the need of manual templates and are\nmore expressive than single label words; (3) We use beam search to\nautomatically generate a large amount of label sequence candidates and propose\ncontrastive re-ranking to get the best combinations. AutoSeq significantly\noutperforms other no-manual-design methods, such as soft prompt tuning, adapter\ntuning, and automatic search on single label words; the generated label\nsequences are even better than curated manual ones on a variety of tasks. Our\nmethod reveals the potential of sequence-to-sequence models in few-shot\nlearning and sheds light on a path to generic and automatic prompting. The\nsource code of this paper can be obtained from\nhttps://github.com/thunlp/Seq2Seq-Prompt.", "published": "2022-09-20 01:35:04", "link": "http://arxiv.org/abs/2209.09401v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weak Disambiguation for Partial Structured Output Learning", "abstract": "Existing disambiguation strategies for partial structured output learning\njust cannot generalize well to solve the problem that there are some candidates\nwhich can be false positive or similar to the ground-truth label. In this\npaper, we propose a novel weak disambiguation for partial structured output\nlearning (WD-PSL). First, a piecewise large margin formulation is generalized\nto partial structured output learning, which effectively avoids handling large\nnumber of candidate structured outputs for complex structures. Second, in the\nproposed weak disambiguation strategy, each candidate label is assigned with a\nconfidence value indicating how likely it is the true label, which aims to\nreduce the negative effects of wrong ground-truth label assignment in the\nlearning process. Then two large margins are formulated to combine two types of\nconstraints which are the disambiguation between candidates and non-candidates,\nand the weak disambiguation for candidates. In the framework of alternating\noptimization, a new 2n-slack variables cutting plane algorithm is developed to\naccelerate each iteration of optimization. The experimental results on several\nsequence labeling tasks of Natural Language Processing show the effectiveness\nof the proposed model.", "published": "2022-09-20 02:12:31", "link": "http://arxiv.org/abs/2209.09410v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "One-to-Many Semantic Communication Systems: Design, Implementation,\n  Performance Evaluation", "abstract": "Semantic communication in the 6G era has been deemed a promising\ncommunication paradigm to break through the bottleneck of traditional\ncommunications. However, its applications for the multi-user scenario,\nespecially the broadcasting case, remain under-explored. To effectively exploit\nthe benefits enabled by semantic communication, in this paper, we propose a\none-to-many semantic communication system. Specifically, we propose a deep\nneural network (DNN) enabled semantic communication system called MR\\_DeepSC.\nBy leveraging semantic features for different users, a semantic recognizer\nbased on the pre-trained model, i.e., DistilBERT, is built to distinguish\ndifferent users. Furthermore, the transfer learning is adopted to speed up the\ntraining of new receiver networks. Simulation results demonstrate that the\nproposed MR\\_DeepSC can achieve the best performance in terms of BLEU score\nthan the other benchmarks under different channel conditions, especially in the\nlow signal-to-noise ratio (SNR) regime.", "published": "2022-09-20 02:48:34", "link": "http://arxiv.org/abs/2209.09425v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Modeling sequential annotations for sequence labeling with crowds", "abstract": "Crowd sequential annotations can be an efficient and cost-effective way to\nbuild large datasets for sequence labeling. Different from tagging independent\ninstances, for crowd sequential annotations the quality of label sequence\nrelies on the expertise level of annotators in capturing internal dependencies\nfor each token in the sequence. In this paper, we propose Modeling sequential\nannotation for sequence labeling with crowds (SA-SLC). First, a conditional\nprobabilistic model is developed to jointly model sequential data and\nannotators' expertise, in which categorical distribution is introduced to\nestimate the reliability of each annotator in capturing local and non-local\nlabel dependency for sequential annotation. To accelerate the marginalization\nof the proposed model, a valid label sequence inference (VLSE) method is\nproposed to derive the valid ground-truth label sequences from crowd sequential\nannotations. VLSE derives possible ground-truth labels from the token-wise\nlevel and further prunes sub-paths in the forward inference for label sequence\ndecoding. VLSE reduces the number of candidate label sequences and improves the\nquality of possible ground-truth label sequences. The experimental results on\nseveral sequence labeling tasks of Natural Language Processing show the\neffectiveness of the proposed model.", "published": "2022-09-20 02:51:23", "link": "http://arxiv.org/abs/2209.09430v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CofeNet: Context and Former-Label Enhanced Net for Complicated Quotation\n  Extraction", "abstract": "Quotation extraction aims to extract quotations from written text. There are\nthree components in a quotation: source refers to the holder of the quotation,\ncue is the trigger word(s), and content is the main body. Existing solutions\nfor quotation extraction mainly utilize rule-based approaches and sequence\nlabeling models. While rule-based approaches often lead to low recalls,\nsequence labeling models cannot well handle quotations with complicated\nstructures. In this paper, we propose the Context and Former-Label Enhanced Net\n(CofeNet) for quotation extraction. CofeNet is able to extract complicated\nquotations with components of variable lengths and complicated structures. On\ntwo public datasets (i.e., PolNeAR and Riqua) and one proprietary dataset\n(i.e., PoliticsZH), we show that our CofeNet achieves state-of-the-art\nperformance on complicated quotation extraction.", "published": "2022-09-20 03:00:24", "link": "http://arxiv.org/abs/2209.09432v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Incorporating Causal Analysis into Diversified and Logical Response\n  Generation", "abstract": "Although the Conditional Variational AutoEncoder (CVAE) model can generate\nmore diversified responses than the traditional Seq2Seq model, the responses\noften have low relevance with the input words or are illogical with the\nquestion. A causal analysis is carried out to study the reasons behind, and a\nmethodology of searching for the mediators and mitigating the confounding bias\nin dialogues is provided. Specifically, we propose to predict the mediators to\npreserve relevant information and auto-regressively incorporate the mediators\ninto generating process. Besides, a dynamic topic graph guided conditional\nvariational autoencoder (TGG-CVAE) model is utilized to complement the semantic\nspace and reduce the confounding bias in responses. Extensive experiments\ndemonstrate that the proposed model is able to generate both relevant and\ninformative responses, and outperforms the state-of-the-art in terms of\nautomatic metrics and human evaluations.", "published": "2022-09-20 05:51:11", "link": "http://arxiv.org/abs/2209.09482v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generating Persuasive Responses to Customer Reviews with Multi-Source\n  Prior Knowledge in E-commerce", "abstract": "Customer reviews usually contain much information about one's online shopping\nexperience. While positive reviews are beneficial to the stores, negative ones\nwill largely influence consumers' decision and may lead to a decline in sales.\nTherefore, it is of vital importance to carefully and persuasively reply to\neach negative review and minimize its disadvantageous effect. Recent studies\nconsider leveraging generation models to help the sellers respond. However,\nthis problem is not well-addressed as the reviews may contain multiple aspects\nof issues which should be resolved accordingly and persuasively. In this work,\nwe propose a Multi-Source Multi-Aspect Attentive Generation model for\npersuasive response generation. Various sources of information are\nappropriately obtained and leveraged by the proposed model for generating more\ninformative and persuasive responses. A multi-aspect attentive network is\nproposed to automatically attend to different aspects in a review and ensure\nmost of the issues are tackled. Extensive experiments on two real-world\ndatasets, demonstrate that our approach outperforms the state-of-the-art\nmethods and online tests prove that our deployed system significantly enhances\nthe efficiency of the stores' dealing with negative reviews.", "published": "2022-09-20 06:20:45", "link": "http://arxiv.org/abs/2209.09497v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EffEval: A Comprehensive Evaluation of Efficiency for MT Evaluation\n  Metrics", "abstract": "Efficiency is a key property to foster inclusiveness and reduce environmental\ncosts, especially in an era of LLMs. In this work, we provide a comprehensive\nevaluation of efficiency for MT evaluation metrics. Our approach involves\nreplacing computation-intensive transformers with lighter alternatives and\nemploying linear and quadratic approximations for alignment algorithms on top\nof LLM representations. We evaluate six (reference-free and reference-based)\nmetrics across three MT datasets and examine 16 lightweight transformers. In\naddition, we look into the training efficiency of metrics like COMET by\nutilizing adapters. Our results indicate that (a) TinyBERT provides the optimal\nbalance between quality and efficiency, (b) CPU speed-ups are more substantial\nthan those on GPU; (c) WMD approximations yield no efficiency gains while\nreducing quality and (d) adapters enhance training efficiency (regarding\nbackward pass speed and memory requirements) as well as, in some cases, metric\nquality. These findings can help to strike a balance between evaluation speed\nand quality, which is essential for effective NLG systems. Furthermore, our\nresearch contributes to the ongoing efforts to optimize NLG evaluation metrics\nwith minimal impact on performance. To our knowledge, ours is the most\ncomprehensive analysis of different aspects of efficiency for MT metrics\nconducted so far.", "published": "2022-09-20 10:12:07", "link": "http://arxiv.org/abs/2209.09593v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Simple Temporal Information Matching Mechanism for Entity Alignment\n  Between Temporal Knowledge Graphs", "abstract": "Entity alignment (EA) aims to find entities in different knowledge graphs\n(KGs) that refer to the same object in the real world. Recent studies\nincorporate temporal information to augment the representations of KGs. The\nexisting methods for EA between temporal KGs (TKGs) utilize a time-aware\nattention mechanism to incorporate relational and temporal information into\nentity embeddings. The approaches outperform the previous methods by using\ntemporal information. However, we believe that it is not necessary to learn the\nembeddings of temporal information in KGs since most TKGs have uniform temporal\nrepresentations. Therefore, we propose a simple graph neural network (GNN)\nmodel combined with a temporal information matching mechanism, which achieves\nbetter performance with less time and fewer parameters. Furthermore, since\nalignment seeds are difficult to label in real-world applications, we also\npropose a method to generate unsupervised alignment seeds via the temporal\ninformation of TKG. Extensive experiments on public datasets indicate that our\nsupervised method significantly outperforms the previous methods and the\nunsupervised one has competitive performance.", "published": "2022-09-20 12:27:34", "link": "http://arxiv.org/abs/2209.09677v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Knowledge-Aware Bayesian Deep Topic Model", "abstract": "We propose a Bayesian generative model for incorporating prior domain\nknowledge into hierarchical topic modeling. Although embedded topic models\n(ETMs) and its variants have gained promising performance in text analysis,\nthey mainly focus on mining word co-occurrence patterns, ignoring potentially\neasy-to-obtain prior topic hierarchies that could help enhance topic coherence.\nWhile several knowledge-based topic models have recently been proposed, they\nare either only applicable to shallow hierarchies or sensitive to the quality\nof the provided prior knowledge. To this end, we develop a novel deep ETM that\njointly models the documents and the given prior knowledge by embedding the\nwords and topics into the same space. Guided by the provided knowledge, the\nproposed model tends to discover topic hierarchies that are organized into\ninterpretable taxonomies. Besides, with a technique for adapting a given graph,\nour extended version allows the provided prior topic structure to be finetuned\nto match the target corpus. Extensive experiments show that our proposed model\nefficiently integrates the prior knowledge and improves both hierarchical topic\ndiscovery and document representation.", "published": "2022-09-20 09:16:05", "link": "http://arxiv.org/abs/2209.14228v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Early Exit in DNNs with Multiple Exits", "abstract": "Deep Neural Networks (DNNs) are generally designed as sequentially cascaded\ndifferentiable blocks/layers with a prediction module connected only to its\nlast layer. DNNs can be attached with prediction modules at multiple points\nalong the backbone where inference can stop at an intermediary stage without\npassing through all the modules. The last exit point may offer a better\nprediction error but also involves more computational resources and latency. An\nexit point that is `optimal' in terms of both prediction error and cost is\ndesirable. The optimal exit point may depend on the latent distribution of the\ntasks and may change from one task type to another. During neural inference,\nthe ground truth of instances may not be available and error rates at each exit\npoint cannot be estimated. Hence one is faced with the problem of selecting the\noptimal exit in an unsupervised setting. Prior works tackled this problem in an\noffline supervised setting assuming that enough labeled data is available to\nestimate the error rate at each exit point and tune the parameters for better\naccuracy. However, pre-trained DNNs are often deployed in new domains for which\na large amount of ground truth may not be available. We model the problem of\nexit selection as an unsupervised online learning problem and use bandit theory\nto identify the optimal exit point. Specifically, we focus on Elastic BERT, a\npre-trained multi-exit DNN to demonstrate that it `nearly' satisfies the Strong\nDominance (SD) property making it possible to learn the optimal exit in an\nonline setup without knowing the ground truth labels. We develop upper\nconfidence bound (UCB) based algorithm named UEE-UCB that provably achieves\nsub-linear regret under the SD property. Thus our method provides a means to\nadaptively learn domain-specific optimal exit points in multi-exit DNNs. We\nempirically validate our algorithm on IMDb and Yelp datasets.", "published": "2022-09-20 05:35:54", "link": "http://arxiv.org/abs/2209.09480v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The language and social behavior of innovators", "abstract": "Innovators are creative people who can conjure the ground-breaking ideas that\nrepresent the main engine of innovative organizations. Past research has\nextensively investigated who innovators are and how they behave in work-related\nactivities. In this paper, we suggest that it is necessary to analyze how\ninnovators behave in other contexts, such as in informal communication spaces,\nwhere knowledge is shared without formal structure, rules, and work\nobligations. Drawing on communication and network theory, we analyze about\n38,000 posts available in the intranet forum of a large multinational company.\nFrom this, we explain how innovators differ from other employees in terms of\nsocial network behavior and language characteristics. Through text mining, we\nfind that innovators write more, use a more complex language, introduce new\nconcepts/ideas, and use positive but factual-based language. Understanding how\ninnovators behave and communicate can support the decision-making processes of\nmanagers who want to foster innovation.", "published": "2022-09-20 07:01:25", "link": "http://arxiv.org/abs/2209.09511v1", "categories": ["cs.CL", "cs.SI", "physics.soc-ph", "I.2.7; J.4; H.4.0"], "primary_category": "cs.CL"}
{"title": "Relaxed Attention for Transformer Models", "abstract": "The powerful modeling capabilities of all-attention-based transformer\narchitectures often cause overfitting and - for natural language processing\ntasks - lead to an implicitly learned internal language model in the\nautoregressive transformer decoder complicating the integration of external\nlanguage models. In this paper, we explore relaxed attention, a simple and\neasy-to-implement smoothing of the attention weights, yielding a two-fold\nimprovement to the general transformer architecture: First, relaxed attention\nprovides regularization when applied to the self-attention layers in the\nencoder. Second, we show that it naturally supports the integration of an\nexternal language model as it suppresses the implicitly learned internal\nlanguage model by relaxing the cross attention in the decoder. We demonstrate\nthe benefit of relaxed attention across several tasks with clear improvement in\ncombination with recent benchmark approaches. Specifically, we exceed the\nformer state-of-the-art performance of 26.90% word error rate on the largest\npublic lip-reading LRS3 benchmark with a word error rate of 26.31%, as well as\nwe achieve a top-performing BLEU score of 37.67 on the IWSLT14\n(DE$\\rightarrow$EN) machine translation task without external language models\nand virtually no additional model parameters. Code and models will be made\npublicly available.", "published": "2022-09-20 14:10:28", "link": "http://arxiv.org/abs/2209.09735v1", "categories": ["cs.LG", "cs.CL", "eess.AS", "eess.IV"], "primary_category": "cs.LG"}
{"title": "Spillover of Antisocial Behavior from Fringe Platforms: The Unintended\n  Consequences of Community Banning", "abstract": "Online platforms face pressure to keep their communities civil and\nrespectful. Thus, the bannings of problematic online communities from\nmainstream platforms like Reddit and Facebook are often met with enthusiastic\npublic reactions. However, this policy can lead users to migrate to alternative\nfringe platforms with lower moderation standards and where antisocial behaviors\nlike trolling and harassment are widely accepted. As users of these communities\noften remain co-active across mainstream and fringe platforms, antisocial\nbehaviors may spill over onto the mainstream platform. We study this possible\nspillover by analyzing around 70,000 users from three banned communities that\nmigrated to fringe platforms: r/The_Donald, r/GenderCritical, and r/Incels.\nUsing a difference-in-differences design, we contrast co-active users with\nmatched counterparts to estimate the causal effect of fringe platform\nparticipation on users' antisocial behavior on Reddit. Our results show that\nparticipating in the fringe communities increases users' toxicity on Reddit (as\nmeasured by Perspective API) and involvement with subreddits similar to the\nbanned community -- which often also breach platform norms. The effect\nintensifies with time and exposure to the fringe platform. In short, we find\nevidence for a spillover of antisocial behavior from fringe platforms onto\nReddit via co-participation.", "published": "2022-09-20 15:48:27", "link": "http://arxiv.org/abs/2209.09803v2", "categories": ["cs.SI", "cs.CL", "physics.soc-ph"], "primary_category": "cs.SI"}
{"title": "LINGUIST: Language Model Instruction Tuning to Generate Annotated\n  Utterances for Intent Classification and Slot Tagging", "abstract": "We present LINGUIST, a method for generating annotated data for Intent\nClassification and Slot Tagging (IC+ST), via fine-tuning AlexaTM 5B, a\n5-billion-parameter multilingual sequence-to-sequence (seq2seq) model, on a\nflexible instruction prompt. In a 10-shot novel intent setting for the SNIPS\ndataset, LINGUIST surpasses state-of-the-art approaches (Back-Translation and\nExample Extrapolation) by a wide margin, showing absolute improvement for the\ntarget intents of +1.9 points on IC Recall and +2.5 points on ST F1 Score. In\nthe zero-shot cross-lingual setting of the mATIS++ dataset, LINGUIST\nout-performs a strong baseline of Machine Translation with Slot Alignment by\n+4.14 points absolute on ST F1 Score across 6 languages, while matching\nperformance on IC. Finally, we verify our results on an internal large-scale\nmultilingual dataset for conversational agent IC+ST and show significant\nimprovements over a baseline which uses Back-Translation, Paraphrasing and Slot\nCatalog Resampling. To our knowledge, we are the first to demonstrate\ninstruction fine-tuning of a large-scale seq2seq model to control the outputs\nof multilingual intent- and slot-labeled data generation.", "published": "2022-09-20 17:59:08", "link": "http://arxiv.org/abs/2209.09900v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science\n  Question Answering", "abstract": "When answering a question, humans utilize the information available across\ndifferent modalities to synthesize a consistent and complete chain of thought\n(CoT). This process is normally a black box in the case of deep learning models\nlike large-scale language models. Recently, science question benchmarks have\nbeen used to diagnose the multi-hop reasoning ability and interpretability of\nan AI system. However, existing datasets fail to provide annotations for the\nanswers, or are restricted to the textual-only modality, small scales, and\nlimited domain diversity. To this end, we present Science Question Answering\n(ScienceQA), a new benchmark that consists of ~21k multimodal multiple choice\nquestions with a diverse set of science topics and annotations of their answers\nwith corresponding lectures and explanations. We further design language models\nto learn to generate lectures and explanations as the chain of thought (CoT) to\nmimic the multi-hop reasoning process when answering ScienceQA questions.\nScienceQA demonstrates the utility of CoT in language models, as CoT improves\nthe question answering performance by 1.20% in few-shot GPT-3 and 3.99% in\nfine-tuned UnifiedQA. We also explore the upper bound for models to leverage\nexplanations by feeding those in the input; we observe that it improves the\nfew-shot performance of GPT-3 by 18.96%. Our analysis further shows that\nlanguage models, similar to humans, benefit from explanations to learn from\nfewer data and achieve the same performance with just 40% of the data. The data\nand code are available at https://scienceqa.github.io.", "published": "2022-09-20 07:04:24", "link": "http://arxiv.org/abs/2209.09513v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Setting the rhythm scene: deep learning-based drum loop generation from\n  arbitrary language cues", "abstract": "Generative artificial intelligence models can be a valuable aid to music\ncomposition and live performance, both to aid the professional musician and to\nhelp democratize the music creation process for hobbyists. Here we present a\nnovel method that, given an English word or phrase, generates 2 compasses of a\n4-piece drum pattern that embodies the \"mood\" of the given language cue, or\nthat could be used for an audiovisual scene described by the language cue. We\nenvision this tool as composition aid for electronic music and audiovisual\nsoundtrack production, or an improvisation tool for live performance. In order\nto produce the training samples for this model, besides manual annotation of\nthe \"scene\" or \"mood\" terms, we have designed a novel method to extract the\nconsensus drum track of any song. This consists of a 2-bar, 4-piece drum\npattern that represents the main percussive motif of a song, which could be\nimported into any music loop device or live looping software. These two key\ncomponents (drum pattern generation from a generalizable input, and consensus\npercussion extraction) present a novel approach to computer-aided composition\nand provide a stepping stone for more comprehensive rhythm generation.", "published": "2022-09-20 21:53:35", "link": "http://arxiv.org/abs/2209.10016v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.IR", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PromptCast: A New Prompt-based Learning Paradigm for Time Series\n  Forecasting", "abstract": "This paper presents a new perspective on time series forecasting. In existing\ntime series forecasting methods, the models take a sequence of numerical values\nas input and yield numerical values as output. The existing SOTA models are\nlargely based on the Transformer architecture, modified with multiple encoding\nmechanisms to incorporate the context and semantics around the historical data.\nInspired by the successes of pre-trained language foundation models, we pose a\nquestion about whether these models can also be adapted to solve time-series\nforecasting. Thus, we propose a new forecasting paradigm: prompt-based time\nseries forecasting (PromptCast). In this novel task, the numerical input and\noutput are transformed into prompts and the forecasting task is framed in a\nsentence-to-sentence manner, making it possible to directly apply language\nmodels for forecasting purposes. To support and facilitate the research of this\ntask, we also present a large-scale dataset (PISA) that includes three\nreal-world forecasting scenarios. We evaluate different SOTA numerical-based\nforecasting methods and language generation models. The benchmark results with\nvarious forecasting settings demonstrate the proposed PromptCast with language\ngeneration models is a promising research direction. Additionally, in\ncomparison to conventional numerical-based forecasting, PromptCast shows a much\nbetter generalization ability under the zero-shot setting.", "published": "2022-09-20 10:15:35", "link": "http://arxiv.org/abs/2210.08964v5", "categories": ["stat.ME", "cs.AI", "cs.CL", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ME"}
{"title": "ESPnet-ONNX: Bridging a Gap Between Research and Production", "abstract": "In the field of deep learning, researchers often focus on inventing novel\nneural network models and improving benchmarks. In contrast, application\ndevelopers are interested in making models suitable for actual products, which\ninvolves optimizing a model for faster inference and adapting a model to\nvarious platforms (e.g., C++ and Python). In this work, to fill the gap between\nthe two, we establish an effective procedure for optimizing a PyTorch-based\nresearch-oriented model for deployment, taking ESPnet, a widely used toolkit\nfor speech processing, as an instance. We introduce different techniques to\nESPnet, including converting a model into an ONNX format, fusing nodes in a\ngraph, and quantizing parameters, which lead to approximately 1.3-2$\\times$\nspeedup in various tasks (i.e., ASR, TTS, speech translation, and spoken\nlanguage understanding) while keeping its performance without any additional\ntraining. Our ESPnet-ONNX will be publicly available at\nhttps://github.com/espnet/espnet_onnx", "published": "2022-09-20 14:37:38", "link": "http://arxiv.org/abs/2209.09756v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Combined Model for Noise Reduction of Lung Sound Signals Based on\n  Empirical Mode Decomposition and Artificial Neural Network", "abstract": "Computer analysis of Lung Sound (LS) signals has been proposed in recent\nyears as a tool to analyze the lungs' status but there have always been main\nchallenges, including the contamination of LS with environmental noises, which\ncome from different sources of unlike intensities. One of the common methods in\nnoise reduction of LS signals is based on thresholding on Discrete Wavelet\nTransform (DWT) coefficients or Empirical Mode Decomposition (EMD) of the\nsignal, however, in these methods, it is necessary to calculate the SNR value\nto determine the appropriate threshold for noise removal. To solve this\nproblem, a combined model based on EMD and Artificial Neural Network (ANN)\ntrained with different SNRs (0, 5, 10, 15, and 20dB) is proposed in this\nresearch. The model can denoise white and pink noises in the range of -2 to\n20dB without thresholding or even estimating SNR, and at the same time, keep\nthe main content of the LS signal well. The proposed method is also compared\nwith the EMD-custom method, and the results obtained from the SNR, and fit\ncriteria indicate the absolute superiority of the proposed method. For example,\nat SNR = 0dB, the combined method can improve the SNR by 9.41 and 8.23dB for\nwhite and pink noises, respectively, while the corresponding values are\nrespectively 5.89 and 4.31dB for the EMD-Custom method.", "published": "2022-09-20 07:04:23", "link": "http://arxiv.org/abs/2209.09512v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "The BUCEA Speaker Diarization System for the VoxCeleb Speaker\n  Recognition Challenge 2022", "abstract": "This paper describes the BUCEA speaker diarization system for the 2022\nVoxCeleb Speaker Recognition Challenge. Voxsrc-22 provides the development set\nand test set of VoxConverse, and we mainly use the test set of VoxConverse for\nparameter adjustment. Our system consists of several modules, including speech\nactivity detection (VAD), speaker embedding extractor, clustering methods,\noverlapping speech detection (OSD), and result fusion. Without considering\noverlap, the Dover-LAP (short for Diarization Output Voting Error Reduction)\nmethod was applied to system fusion, and overlapping speech detection and\nprocessing were finally carried out. Our best system achieves a diarization\nerror rate (DER) of 5.48% and a Jaccard error rate (JER) of 32.1% on the VoxSRC\n2022 evaluation set respectively.", "published": "2022-09-20 11:33:58", "link": "http://arxiv.org/abs/2209.09635v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Meta-Learning for Adaptive Filters with Higher-Order Frequency\n  Dependencies", "abstract": "Adaptive filters are applicable to many signal processing tasks including\nacoustic echo cancellation, beamforming, and more. Adaptive filters are\ntypically controlled using algorithms such as least-mean squares(LMS),\nrecursive least squares(RLS), or Kalman filter updates. Such models are often\napplied in the frequency domain, assume frequency independent processing, and\ndo not exploit higher-order frequency dependencies, for simplicity. Recent work\non meta-adaptive filters, however, has shown that we can control filter\nadaptation using neural networks without manual derivation, motivating new work\nto exploit such information. In this work, we present higher-order\nmeta-adaptive filters, a key improvement to meta-adaptive filters that\nincorporates higher-order frequency dependencies. We demonstrate our approach\non acoustic echo cancellation and develop a family of filters that yield\nmulti-dB improvements over competitive baselines, and are at least an\norder-of-magnitude less complex. Moreover, we show our improvements hold with\nor without a downstream speech enhancer.", "published": "2022-09-20 19:22:24", "link": "http://arxiv.org/abs/2209.09955v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Language-based Audio Retrieval Task in DCASE 2022 Challenge", "abstract": "Language-based audio retrieval is a task, where natural language textual\ncaptions are used as queries to retrieve audio signals from a dataset. It has\nbeen first introduced into DCASE 2022 Challenge as Subtask 6B of task 6, which\naims at developing computational systems to model relationships between audio\nsignals and free-form textual descriptions. Compared with audio captioning\n(Subtask 6A), which is about generating audio captions for audio signals,\nlanguage-based audio retrieval (Subtask 6B) focuses on ranking audio signals\naccording to their relevance to natural language textual captions. In DCASE\n2022 Challenge, the provided baseline system for Subtask 6B was significantly\noutperformed, with top performance being 0.276 in mAP@10. This paper presents\nthe outcome of Subtask 6B in terms of submitted systems' performance and\nanalysis.", "published": "2022-09-20 19:51:53", "link": "http://arxiv.org/abs/2209.09967v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
