{"title": "NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods", "abstract": "Knowledge graph completion (KGC) aims to discover missing relations of query\nentities. Current text-based models utilize the entity name and description to\ninfer the tail entity given the head entity and a certain relation. Existing\napproaches also consider the neighborhood of the head entity. However, these\nmethods tend to model the neighborhood using a flat structure and are only\nrestricted to 1-hop neighbors. In this work, we propose a node\nneighborhood-enhanced framework for knowledge graph completion. It models the\nhead entity neighborhood from multiple hops using graph neural networks to\nenrich the head node information. Moreover, we introduce an additional edge\nlink prediction task to improve KGC. Evaluation on two public datasets shows\nthat this framework is simple yet effective. The case study also shows that the\nmodel is able to predict explainable predictions.", "published": "2023-02-13 06:38:25", "link": "http://arxiv.org/abs/2302.06132v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation of Word Embeddings for the Social Sciences", "abstract": "Word embeddings are an essential instrument in many NLP tasks. Most available\nresources are trained on general language from Web corpora or Wikipedia dumps.\nHowever, word embeddings for domain-specific language are rare, in particular\nfor the social science domain. Therefore, in this work, we describe the\ncreation and evaluation of word embedding models based on 37,604 open-access\nsocial science research papers. In the evaluation, we compare domain-specific\nand general language models for (i) language coverage, (ii) diversity, and\n(iii) semantic relationships. We found that the created domain-specific model,\neven with a relatively small vocabulary size, covers a large part of social\nscience concepts, their neighborhoods are diverse in comparison to more general\nmodels. Across all relation types, we found a more extensive coverage of\nsemantic relationships.", "published": "2023-02-13 08:23:03", "link": "http://arxiv.org/abs/2302.06174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distinguishability Calibration to In-Context Learning", "abstract": "Recent years have witnessed increasing interests in prompt-based learning in\nwhich models can be trained on only a few annotated instances, making them\nsuitable in low-resource settings. When using prompt-based learning for text\nclassification, the goal is to use a pre-trained language model (PLM) to\npredict a missing token in a pre-defined template given an input text, which\ncan be mapped to a class label. However, PLMs built on the transformer\narchitecture tend to generate similar output embeddings, making it difficult to\ndiscriminate between different class labels. The problem is further exacerbated\nwhen dealing with classification tasks involving many fine-grained class\nlabels. In this work, we alleviate this information diffusion issue, i.e.,\ndifferent tokens share a large proportion of similar information after going\nthrough stacked multiple self-attention layers in a transformer, by proposing a\ncalibration method built on feature transformations through rotation and\nscaling to map a PLM-encoded embedding into a new metric space to guarantee the\ndistinguishability of the resulting embeddings. Furthermore, we take the\nadvantage of hyperbolic embeddings to capture the hierarchical relations among\nfine-grained class-associated token embedding by a coarse-to-fine metric\nlearning strategy to enhance the distinguishability of the learned output\nembeddings. Extensive experiments on the three datasets under various settings\ndemonstrate the effectiveness of our approach. Our code can be found at\nhttps://github.com/donttal/TARA.", "published": "2023-02-13 09:15:00", "link": "http://arxiv.org/abs/2302.06198v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition", "abstract": "Despite the recent success achieved by several two-stage prototypical\nnetworks in few-shot named entity recognition (NER) task, the overdetected\nfalse spans at the span detection stage and the inaccurate and unstable\nprototypes at the type classification stage remain to be challenging problems.\nIn this paper, we propose a novel Type-Aware Decomposed framework, namely\nTadNER, to solve these problems. We first present a type-aware span filtering\nstrategy to filter out false spans by removing those semantically far away from\ntype names. We then present a type-aware contrastive learning strategy to\nconstruct more accurate and stable prototypes by jointly exploiting support\nsamples and type names as references. Extensive experiments on various\nbenchmarks prove that our proposed TadNER framework yields a new\nstate-of-the-art performance. Our code and data will be available at\nhttps://github.com/NLPWM-WHU/TadNER.", "published": "2023-02-13 14:36:21", "link": "http://arxiv.org/abs/2302.06397v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Encoding Sentence Position in Context-Aware Neural Machine Translation\n  with Concatenation", "abstract": "Context-aware translation can be achieved by processing a concatenation of\nconsecutive sentences with the standard Transformer architecture. This paper\ninvestigates the intuitive idea of providing the model with explicit\ninformation about the position of the sentences contained in the concatenation\nwindow. We compare various methods to encode sentence positions into token\nrepresentations, including novel methods. Our results show that the Transformer\nbenefits from certain sentence position encoding methods on English to Russian\ntranslation if trained with a context-discounted loss (Lupo et al., 2022).\nHowever, the same benefits are not observed in English to German. Further\nempirical efforts are necessary to define the conditions under which the\nproposed approach is beneficial.", "published": "2023-02-13 15:39:08", "link": "http://arxiv.org/abs/2302.06459v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why Can't Discourse Parsing Generalize? A Thorough Investigation of the\n  Impact of Data Diversity", "abstract": "Recent advances in discourse parsing performance create the impression that,\nas in other NLP tasks, performance for high-resource languages such as English\nis finally becoming reliable. In this paper we demonstrate that this is not the\ncase, and thoroughly investigate the impact of data diversity on RST parsing\nstability. We show that state-of-the-art architectures trained on the standard\nEnglish newswire benchmark do not generalize well, even within the news domain.\nUsing the two largest RST corpora of English with text from multiple genres, we\nquantify the impact of genre diversity in training data for achieving\ngeneralization to text types unseen during training. Our results show that a\nheterogeneous training regime is critical for stable and generalizable models,\nacross parser architectures. We also provide error analyses of model outputs\nand out-of-domain performance. To our knowledge, this study is the first to\nfully evaluate cross-corpus RST parsing generalizability on complete trees,\nexamine between-genre degradation within an RST corpus, and investigate the\nimpact of genre diversity in training data composition.", "published": "2023-02-13 16:11:58", "link": "http://arxiv.org/abs/2302.06488v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Agile Text Classifiers for Everyone", "abstract": "Text-based safety classifiers are widely used for content moderation and\nincreasingly to tune generative language model behavior - a topic of growing\nconcern for the safety of digital assistants and chatbots. However, different\npolicies require different classifiers, and safety policies themselves improve\nfrom iteration and adaptation. This paper introduces and evaluates methods for\nagile text classification, whereby classifiers are trained using small,\ntargeted datasets that can be quickly developed for a particular policy.\nExperimenting with 7 datasets from three safety-related domains, comprising 15\nannotation schemes, led to our key finding: prompt-tuning large language\nmodels, like PaLM 62B, with a labeled dataset of as few as 80 examples can\nachieve state-of-the-art performance. We argue that this enables a paradigm\nshift for text classification, especially for models supporting safer online\ndiscourse. Instead of collecting millions of examples to attempt to create\nuniversal safety classifiers over months or years, classifiers could be tuned\nusing small datasets, created by individuals or small organizations, tailored\nfor specific use cases, and iterated on and adapted in the time-span of a day.", "published": "2023-02-13 17:34:13", "link": "http://arxiv.org/abs/2302.06541v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AbLit: A Resource for Analyzing and Generating Abridged Versions of\n  English Literature", "abstract": "Creating an abridged version of a text involves shortening it while\nmaintaining its linguistic qualities. In this paper, we examine this task from\nan NLP perspective for the first time. We present a new resource, AbLit, which\nis derived from abridged versions of English literature books. The dataset\ncaptures passage-level alignments between the original and abridged texts. We\ncharacterize the linguistic relations of these alignments, and create automated\nmodels to predict these relations as well as to generate abridgements for new\ntexts. Our findings establish abridgement as a challenging task, motivating\nfuture resources and research. The dataset is available at\ngithub.com/roemmele/AbLit.", "published": "2023-02-13 18:33:26", "link": "http://arxiv.org/abs/2302.06579v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gradient-Based Automated Iterative Recovery for Parameter-Efficient\n  Tuning", "abstract": "Pretrained large language models (LLMs) are able to solve a wide variety of\ntasks through transfer learning. Various explainability methods have been\ndeveloped to investigate their decision making process. TracIn (Pruthi et al.,\n2020) is one such gradient-based method which explains model inferences based\non the influence of training examples. In this paper, we explore the use of\nTracIn to improve model performance in the parameter-efficient tuning (PET)\nsetting. We develop conversational safety classifiers via the prompt-tuning PET\nmethod and show how the unique characteristics of the PET regime enable TracIn\nto identify the cause for certain misclassifications by LLMs. We develop a new\nmethodology for using gradient-based explainability techniques to improve model\nperformance, G-BAIR: gradient-based automated iterative recovery. We show that\nG-BAIR can recover LLM performance on benchmarks after manually corrupting\ntraining labels. This suggests that influence methods like TracIn can be used\nto automatically perform data cleaning, and introduces the potential for\ninteractive debugging and relabeling for PET-based transfer learning methods.", "published": "2023-02-13 18:54:58", "link": "http://arxiv.org/abs/2302.06598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emotion Detection in Unfix-length-Context Conversation", "abstract": "We leverage different context windows when predicting the emotion of\ndifferent utterances. New modules are included to realize variable-length\ncontext: 1) two speaker-aware units, which explicitly model inner- and\ninter-speaker dependencies to form distilled conversational context, and 2) a\ntop-k normalization layer, which determines the most proper context windows\nfrom the conversational context to predict emotion. Experiments and ablation\nstudies show that our approach outperforms several strong baselines on three\npublic datasets.", "published": "2023-02-13 00:06:47", "link": "http://arxiv.org/abs/2302.06029v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NYCU-TWO at Memotion 3: Good Foundation, Good Teacher, then you have\n  Good Meme Analysis", "abstract": "This paper presents a robust solution to the Memotion 3.0 Shared Task. The\ngoal of this task is to classify the emotion and the corresponding intensity\nexpressed by memes, which are usually in the form of images with short captions\non social media. Understanding the multi-modal features of the given memes will\nbe the key to solving the task. In this work, we use CLIP to extract aligned\nimage-text features and propose a novel meme sentiment analysis framework,\nconsisting of a Cooperative Teaching Model (CTM) for Task A and a Cascaded\nEmotion Classifier (CEC) for Tasks B&C. CTM is based on the idea of knowledge\ndistillation, and can better predict the sentiment of a given meme in Task A;\nCEC can leverage the emotion intensity suggestion from the prediction of Task C\nto classify the emotion more precisely in Task B. Experiments show that we\nachieved the 2nd place ranking for both Task A and Task B and the 4th place\nranking for Task C, with weighted F1-scores of 0.342, 0.784, and 0.535\nrespectively. The results show the robustness and effectiveness of our\nframework. Our code is released at github.", "published": "2023-02-13 03:25:37", "link": "http://arxiv.org/abs/2302.06078v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Can GPT-3 Perform Statutory Reasoning?", "abstract": "Statutory reasoning is the task of reasoning with facts and statutes, which\nare rules written in natural language by a legislature. It is a basic legal\nskill. In this paper we explore the capabilities of the most capable GPT-3\nmodel, text-davinci-003, on an established statutory-reasoning dataset called\nSARA. We consider a variety of approaches, including dynamic few-shot\nprompting, chain-of-thought prompting, and zero-shot prompting. While we\nachieve results with GPT-3 that are better than the previous best published\nresults, we also identify several types of clear errors it makes. We\ninvestigate why these errors happen. We discover that GPT-3 has imperfect prior\nknowledge of the actual U.S. statutes on which SARA is based. More importantly,\nwe create simple synthetic statutes, which GPT-3 is guaranteed not to have seen\nduring training. We find GPT-3 performs poorly at answering straightforward\nquestions about these simple synthetic statutes.", "published": "2023-02-13 04:56:11", "link": "http://arxiv.org/abs/2302.06100v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Identifying Semantically Difficult Samples to Improve Text\n  Classification", "abstract": "In this paper, we investigate the effect of addressing difficult samples from\na given text dataset on the downstream text classification task. We define\ndifficult samples as being non-obvious cases for text classification by\nanalysing them in the semantic embedding space; specifically - (i) semantically\nsimilar samples that belong to different classes and (ii) semantically\ndissimilar samples that belong to the same class. We propose a penalty function\nto measure the overall difficulty score of every sample in the dataset. We\nconduct exhaustive experiments on 13 standard datasets to show a consistent\nimprovement of up to 9% and discuss qualitative results to show effectiveness\nof our approach in identifying difficult samples for a text classification\nmodel.", "published": "2023-02-13 07:33:46", "link": "http://arxiv.org/abs/2302.06155v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Parameter-efficient Modularised Bias Mitigation via AdapterFusion", "abstract": "Large pre-trained language models contain societal biases and carry along\nthese biases to downstream tasks. Current in-processing bias mitigation\napproaches (like adversarial training) impose debiasing by updating a model's\nparameters, effectively transferring the model to a new, irreversible debiased\nstate. In this work, we propose a novel approach to develop stand-alone\ndebiasing functionalities separate from the model, which can be integrated into\nthe model on-demand, while keeping the core model untouched. Drawing from the\nconcept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing\nwith Adapter Modules) - a debiasing approach to first encapsulate arbitrary\nbias mitigation functionalities into separate adapters, and then add them to\nthe model on-demand in order to deliver fairness qualities. We conduct a large\nset of experiments on three classification tasks with gender, race, and age as\nprotected attributes. Our results show that DAM improves or maintains the\neffectiveness of bias mitigation, avoids catastrophic forgetting in a\nmulti-attribute scenario, and maintains on-par task performance, while granting\nparameter-efficiency and easy switching between the original and debiased\nmodels.", "published": "2023-02-13 12:39:45", "link": "http://arxiv.org/abs/2302.06321v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Linguistic ambiguity analysis in ChatGPT", "abstract": "Linguistic ambiguity is and has always been one of the main challenges in\nNatural Language Processing (NLP) systems. Modern Transformer architectures\nlike BERT, T5 or more recently InstructGPT have achieved some impressive\nimprovements in many NLP fields, but there is still plenty of work to do.\nMotivated by the uproar caused by ChatGPT, in this paper we provide an\nintroduction to linguistic ambiguity, its varieties and their relevance in\nmodern NLP, and perform an extensive empiric analysis. ChatGPT strengths and\nweaknesses are revealed, as well as strategies to get the most of this model.", "published": "2023-02-13 15:03:07", "link": "http://arxiv.org/abs/2302.06426v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Joint Span Segmentation and Rhetorical Role Labeling with Data\n  Augmentation for Legal Documents", "abstract": "Segmentation and Rhetorical Role Labeling of legal judgements play a crucial\nrole in retrieval and adjacent tasks, including case summarization, semantic\nsearch, argument mining etc. Previous approaches have formulated this task\neither as independent classification or sequence labeling of sentences. In this\nwork, we reformulate the task at span level as identifying spans of multiple\nconsecutive sentences that share the same rhetorical role label to be assigned\nvia classification. We employ semi-Markov Conditional Random Fields (CRF) to\njointly learn span segmentation and span label assignment. We further explore\nthree data augmentation strategies to mitigate the data scarcity in the\nspecialized domain of law where individual documents tend to be very long and\nannotation cost is high. Our experiments demonstrate improvement of span-level\nprediction metrics with a semi-Markov CRF model over a CRF baseline. This\nbenefit is contingent on the presence of multi sentence spans in the document.", "published": "2023-02-13 15:28:02", "link": "http://arxiv.org/abs/2302.06448v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Large Scale Multi-Lingual Multi-Modal Summarization Dataset", "abstract": "Significant developments in techniques such as encoder-decoder models have\nenabled us to represent information comprising multiple modalities. This\ninformation can further enhance many downstream tasks in the field of\ninformation retrieval and natural language processing; however, improvements in\nmulti-modal techniques and their performance evaluation require large-scale\nmulti-modal data which offers sufficient diversity. Multi-lingual modeling for\na variety of tasks like multi-modal summarization, text generation, and\ntranslation leverages information derived from high-quality multi-lingual\nannotated data. In this work, we present the current largest multi-lingual\nmulti-modal summarization dataset (M3LS), and it consists of over a million\ninstances of document-image pairs along with a professionally annotated\nmulti-modal summary for each pair. It is derived from news articles published\nby British Broadcasting Corporation(BBC) over a decade and spans 20 languages,\ntargeting diversity across five language roots, it is also the largest\nsummarization dataset for 13 languages and consists of cross-lingual\nsummarization data for 2 languages. We formally define the multi-lingual\nmulti-modal summarization task utilizing our dataset and report baseline scores\nfrom various state-of-the-art summarization techniques in a multi-lingual\nsetting. We also compare it with many similar datasets to analyze the\nuniqueness and difficulty of M3LS.", "published": "2023-02-13 18:00:23", "link": "http://arxiv.org/abs/2302.06560v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Improving Out-of-Distribution Generalization of Neural Rerankers with\n  Contextualized Late Interaction", "abstract": "Recent progress in information retrieval finds that embedding query and\ndocument representation into multi-vector yields a robust bi-encoder retriever\non out-of-distribution datasets. In this paper, we explore whether late\ninteraction, the simplest form of multi-vector, is also helpful to neural\nrerankers that only use the [CLS] vector to compute the similarity score.\nAlthough intuitively, the attention mechanism of rerankers at the previous\nlayers already gathers the token-level information, we find adding late\ninteraction still brings an extra 5% improvement in average on\nout-of-distribution datasets, with little increase in latency and no\ndegradation in in-domain effectiveness. Through extensive experiments and\nanalysis, we show that the finding is consistent across different model sizes\nand first-stage retrievers of diverse natures and that the improvement is more\nprominent on longer queries.", "published": "2023-02-13 18:42:17", "link": "http://arxiv.org/abs/2302.06589v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Task-Specific Skill Localization in Fine-tuned Language Models", "abstract": "Pre-trained language models can be fine-tuned to solve diverse NLP tasks,\nincluding in few-shot settings. Thus fine-tuning allows the model to quickly\npick up task-specific ``skills,'' but there has been limited study of where\nthese newly-learnt skills reside inside the massive model. This paper\nintroduces the term skill localization for this problem and proposes a\nsolution. Given the downstream task and a model fine-tuned on that task, a\nsimple optimization is used to identify a very small subset of parameters\n($\\sim0.01$% of model parameters) responsible for ($>95$%) of the model's\nperformance, in the sense that grafting the fine-tuned values for just this\ntiny subset onto the pre-trained model gives performance almost as well as the\nfine-tuned model. While reminiscent of recent works on parameter-efficient\nfine-tuning, the novel aspects here are that: (i) No further re-training is\nneeded on the subset (unlike, say, with lottery tickets). (ii) Notable\nimprovements are seen over vanilla fine-tuning with respect to calibration of\npredictions in-distribution ($40$-$90$% error reduction) as well as the quality\nof predictions out-of-distribution (OOD). In models trained on multiple tasks,\na stronger notion of skill localization is observed, where the sparse regions\ncorresponding to different tasks are almost disjoint, and their overlap (when\nit happens) is a proxy for task similarity. Experiments suggest that\nlocalization via grafting can assist certain forms of continual learning.", "published": "2023-02-13 18:55:52", "link": "http://arxiv.org/abs/2302.06600v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UniAdapter: Unified Parameter-Efficient Transfer Learning for\n  Cross-modal Modeling", "abstract": "Large-scale vision-language pre-trained models have shown promising\ntransferability to various downstream tasks. As the size of these foundation\nmodels and the number of downstream tasks grow, the standard full fine-tuning\nparadigm becomes unsustainable due to heavy computational and storage costs.\nThis paper proposes UniAdapter, which unifies unimodal and multimodal adapters\nfor parameter-efficient cross-modal adaptation on pre-trained vision-language\nmodels. Specifically, adapters are distributed to different modalities and\ntheir interactions, with the total number of tunable parameters reduced by\npartial weight sharing. The unified and knowledge-sharing design enables\npowerful cross-modal representations that can benefit various downstream tasks,\nrequiring only 1.0%-2.0% tunable parameters of the pre-trained model. Extensive\nexperiments on 6 cross-modal downstream benchmarks (including video-text\nretrieval, image-text retrieval, VideoQA, and VQA) show that in most cases,\nUniAdapter not only outperforms the state-of-the-arts, but even beats the full\nfine-tuning strategy. Particularly, on the MSRVTT retrieval task, UniAdapter\nachieves 49.7% recall@1 with 2.2% model parameters, outperforming the latest\ncompetitors by 2.0%. The code and models are available at\nhttps://github.com/RERV/UniAdapter.", "published": "2023-02-13 18:59:10", "link": "http://arxiv.org/abs/2302.06605v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded\n  Dialogue", "abstract": "Identifying relevant persona or knowledge for conversational systems is\ncritical to grounded dialogue response generation. However, each grounding has\nbeen mostly researched in isolation with more practical multi-context dialogue\ntasks introduced in recent works. We define Persona and Knowledge Dual Context\nIdentification as the task to identify persona and knowledge jointly for a\ngiven dialogue, which could be of elevated importance in complex multi-context\ndialogue settings. We develop a novel grounding retrieval method that utilizes\nall contexts of dialogue simultaneously. Our method requires less computational\npower via utilizing neural QA retrieval models. We further introduce our novel\nnull-positive rank test which measures ranking performance on semantically\ndissimilar samples (i.e. hard negatives) in relation to data augmentation.", "published": "2023-02-13 20:27:26", "link": "http://arxiv.org/abs/2302.06674v4", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Bag of Tricks for In-Distribution Calibration of Pretrained Transformers", "abstract": "While pre-trained language models (PLMs) have become a de-facto standard\npromoting the accuracy of text classification tasks, recent studies find that\nPLMs often predict over-confidently. Although various calibration methods have\nbeen proposed, such as ensemble learning and data augmentation, most of the\nmethods have been verified in computer vision benchmarks rather than in\nPLM-based text classification tasks. In this paper, we present an empirical\nstudy on confidence calibration for PLMs, addressing three categories,\nincluding confidence penalty losses, data augmentations, and ensemble methods.\nWe find that the ensemble model overfitted to the training set shows sub-par\ncalibration performance and also observe that PLMs trained with confidence\npenalty loss have a trade-off between calibration and accuracy. Building on\nthese observations, we propose the Calibrated PLM (CALL), a combination of\ncalibration techniques. The CALL complements the drawbacks that may occur when\nutilizing a calibration method individually and boosts both classification and\ncalibration accuracy. Design choices in CALL's training procedures are\nextensively studied, and we provide a detailed analysis of how calibration\ntechniques affect the calibration performance of PLMs.", "published": "2023-02-13 21:11:52", "link": "http://arxiv.org/abs/2302.06690v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "STREET: A Multi-Task Structured Reasoning and Explanation Benchmark", "abstract": "We introduce STREET, a unified multi-task and multi-domain natural language\nreasoning and explanation benchmark. Unlike most existing question-answering\n(QA) datasets, we expect models to not only answer questions, but also produce\nstep-by-step structured explanations describing how premises in the question\nare used to produce intermediate conclusions that can prove the correctness of\na certain answer. We perform extensive evaluation with popular language models\nsuch as few-shot prompting GPT-3 and fine-tuned T5. We find that these models\nstill lag behind human performance when producing such structured reasoning\nsteps. We believe this work will provide a way for the community to better\ntrain and test systems on multi-step reasoning and explanations in natural\nlanguage.", "published": "2023-02-13 22:34:02", "link": "http://arxiv.org/abs/2302.06729v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Knowledge Enhanced Semantic Communication Receiver", "abstract": "In recent years, with the rapid development of deep learning and natural\nlanguage processing technologies, semantic communication has become a topic of\ngreat interest in the field of communication. Although existing deep\nlearning-based semantic communication approaches have shown many advantages,\nthey still do not make sufficient use of prior knowledge. Moreover, most\nexisting semantic communication methods focus on the semantic encoding at the\ntransmitter side, while we believe that the semantic decoding capability of the\nreceiver should also be concerned. In this paper, we propose a knowledge\nenhanced semantic communication framework in which the receiver can more\nactively utilize the facts in the knowledge base for semantic reasoning and\ndecoding, on the basis of only affecting the parameters rather than the\nstructure of the neural networks at the transmitter side. Specifically, we\ndesign a transformer-based knowledge extractor to find relevant factual triples\nfor the received noisy signal. Extensive simulation results on the WebNLG\ndataset demonstrate that the proposed receiver yields superior performance on\ntop of the knowledge graph enhanced decoding.", "published": "2023-02-13 01:49:51", "link": "http://arxiv.org/abs/2302.07727v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning from Noisy Crowd Labels with Logics", "abstract": "This paper explores the integration of symbolic logic knowledge into deep\nneural networks for learning from noisy crowd labels. We introduce Logic-guided\nLearning from Noisy Crowd Labels (Logic-LNCL), an EM-alike iterative logic\nknowledge distillation framework that learns from both noisy labeled data and\nlogic rules of interest. Unlike traditional EM methods, our framework contains\na ``pseudo-E-step'' that distills from the logic rules a new type of learning\ntarget, which is then used in the ``pseudo-M-step'' for training the\nclassifier. Extensive evaluations on two real-world datasets for text sentiment\nclassification and named entity recognition demonstrate that the proposed\nframework improves the state-of-the-art and provides a new solution to learning\nfrom noisy crowd labels.", "published": "2023-02-13 13:14:23", "link": "http://arxiv.org/abs/2302.06337v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Text2shape Deep Retrieval Model: Generating Initial Cases for Mechanical\n  Part Redesign under the Context of Case-Based Reasoning", "abstract": "Retrieving the similar solutions from the historical case base for new design\nrequirements is the first step in mechanical part redesign under the context of\ncase-based reasoning. However, the manual retrieving method has the problem of\nlow efficiency when the case base is large. Additionally, it is difficult for\nsimple reasoning algorithms (e.g., rule-based reasoning, decision tree) to\ncover all the features in complicated design solutions. In this regard, a\ntext2shape deep retrieval model is established in order to support text\ndescription-based mechanical part shapes retrieval, where the texts are for\ndescribing the structural features of the target mechanical parts. More\nspecifically, feature engineering is applied to identify the key structural\nfeatures of the target mechanical parts. Based on the identified key structural\nfeatures, a training set of 1000 samples was constructed, where each sample\nconsisted of a paragraph of text description of a group of structural features\nand the corresponding 3D shape of the structural features. RNN and 3D CNN\nalgorithms were customized to build the text2shape deep retrieval model.\nOrthogonal experiments were used for modeling turning. Eventually, the highest\naccuracy of the model was 0.98; therefore, the model can be effective for\nretrieving initial cases for mechanical part redesign.", "published": "2023-02-13 13:24:11", "link": "http://arxiv.org/abs/2302.06341v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "A Study on ReLU and Softmax in Transformer", "abstract": "The Transformer architecture consists of self-attention and feed-forward\nnetworks (FFNs) which can be viewed as key-value memories according to previous\nworks. However, FFN and traditional memory utilize different activation\nfunctions (i.e., ReLU and Softmax respectively), which makes them not\nequivalent. In this paper, we first rebuild the connections between FFN and\nkey-value memory by conducting extensive studies on ReLU and Softmax, and find\nthey are equivalent when adding an additional layer normalization module on\nSoftmax. In addition, ReLU outperforms Softmax on both FFN and key-value memory\nwhen the number of value slots is large. We analyze the reasons and then\nexplore this good property of ReLU on the self-attention network where the\noriginal Softmax activation performs poorly on long input sequences. We then\npropose a full ReLU architecture named ReLUFormer which performs better than\nthe baseline Transformer on long sequence tasks such as document translation.\nThis paper sheds light on the following points: 1) Softmax and ReLU use\ndifferent normalization methods over elements which lead to different variances\nof results, and ReLU is good at dealing with a large number of key-value slots;\n2) FFN and key-value memory are equivalent, and thus the Transformer can be\nviewed as a memory network where FFNs and self-attention networks are both\nkey-value memories.", "published": "2023-02-13 15:41:20", "link": "http://arxiv.org/abs/2302.06461v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do Vision and Language Models Share Concepts? A Vector Space Alignment\n  Study", "abstract": "Large-scale pretrained language models (LMs) are said to ``lack the ability\nto connect utterances to the world'' (Bender and Koller, 2020), because they do\nnot have ``mental models of the world' '(Mitchell and Krakauer, 2023). If so,\none would expect LM representations to be unrelated to representations induced\nby vision models. We present an empirical evaluation across four families of\nLMs (BERT, GPT-2, OPT and LLaMA-2) and three vision model architectures\n(ResNet, SegFormer, and MAE). Our experiments show that LMs partially converge\ntowards representations isomorphic to those of vision models, subject to\ndispersion, polysemy and frequency. This has important implications for both\nmulti-modal processing and the LM understanding debate (Mitchell and Krakauer,\n2023).", "published": "2023-02-13 17:55:54", "link": "http://arxiv.org/abs/2302.06555v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Guiding Pretraining in Reinforcement Learning with Large Language Models", "abstract": "Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.", "published": "2023-02-13 21:16:03", "link": "http://arxiv.org/abs/2302.06692v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "On the Planning Abilities of Large Language Models (A Critical\n  Investigation with a Proposed Benchmark)", "abstract": "Intrigued by the claims of emergent reasoning capabilities in LLMs trained on\ngeneral web corpora, in this paper, we set out to investigate their planning\ncapabilities. We aim to evaluate (1) how good LLMs are by themselves in\ngenerating and validating simple plans in commonsense planning tasks (of the\ntype that humans are generally quite good at) and (2) how good LLMs are in\nbeing a source of heuristic guidance for other agents--either AI planners or\nhuman planners--in their planning tasks. To investigate these questions in a\nsystematic rather than anecdotal manner, we start by developing a benchmark\nsuite based on the kinds of domains employed in the International Planning\nCompetition. On this benchmark, we evaluate LLMs in three modes: autonomous,\nheuristic and human-in-the-loop. Our results show that LLM's ability to\nautonomously generate executable plans is quite meager, averaging only about 3%\nsuccess rate. The heuristic and human-in-the-loop modes show slightly more\npromise. In addition to these results, we also make our benchmark and\nevaluation tools available to support investigations by research community.", "published": "2023-02-13 21:37:41", "link": "http://arxiv.org/abs/2302.06706v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Machine Learning Model Attribution Challenge", "abstract": "We present the findings of the Machine Learning Model Attribution Challenge.\nFine-tuned machine learning models may derive from other trained models without\nobvious attribution characteristics. In this challenge, participants identify\nthe publicly-available base models that underlie a set of anonymous, fine-tuned\nlarge language models (LLMs) using only textual output of the models.\nContestants aim to correctly attribute the most fine-tuned models, with ties\nbroken in the favor of contestants whose solutions use fewer calls to the\nfine-tuned models' API. The most successful approaches were manual, as\nparticipants observed similarities between model outputs and developed\nattribution heuristics based on public documentation of the base models, though\nseveral teams also submitted automated, statistical solutions.", "published": "2023-02-13 22:05:27", "link": "http://arxiv.org/abs/2302.06716v3", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Diminished Diversity-of-Thought in a Standard Large Language Model", "abstract": "We test whether Large Language Models (LLMs) can be used to simulate human\nparticipants in social-science studies. To do this, we run replications of 14\nstudies from the Many Labs 2 replication project with OpenAI's text-davinci-003\nmodel, colloquially known as GPT3.5. Based on our pre-registered analyses, we\nfind that among the eight studies we could analyse, our GPT sample replicated\n37.5% of the original results and 37.5% of the Many Labs 2 results. However, we\nwere unable to analyse the remaining six studies due to an unexpected\nphenomenon we call the \"correct answer\" effect. Different runs of GPT3.5\nanswered nuanced questions probing political orientation, economic preference,\njudgement, and moral philosophy with zero or near-zero variation in responses:\nwith the supposedly \"correct answer.\" In one exploratory follow-up study, we\nfound that a \"correct answer\" was robust to changing the demographic details\nthat precede the prompt. In another, we found that most but not all \"correct\nanswers\" were robust to changing the order of answer choices. One of our most\nstriking findings occurred in our replication of the Moral Foundations Theory\nsurvey results, where we found GPT3.5 identifying as a political conservative\nin 99.6% of the cases, and as a liberal in 99.3% of the cases in the\nreverse-order condition. However, both self-reported 'GPT conservatives' and\n'GPT liberals' showed right-leaning moral foundations. Our results cast doubts\non the validity of using LLMs as a general replacement for human participants\nin the social sciences. Our results also raise concerns that a hypothetical\nAI-led future may be subject to a diminished diversity-of-thought.", "published": "2023-02-13 17:57:50", "link": "http://arxiv.org/abs/2302.07267v6", "categories": ["cs.HC", "cs.AI", "cs.CL", "68T50", "I.2.7"], "primary_category": "cs.HC"}
{"title": "Targeted Attack on GPT-Neo for the SATML Language Model Data Extraction\n  Challenge", "abstract": "Previous work has shown that Large Language Models are susceptible to\nso-called data extraction attacks. This allows an attacker to extract a sample\nthat was contained in the training data, which has massive privacy\nimplications. The construction of data extraction attacks is challenging,\ncurrent attacks are quite inefficient, and there exists a significant gap in\nthe extraction capabilities of untargeted attacks and memorization. Thus,\ntargeted attacks are proposed, which identify if a given sample from the\ntraining data, is extractable from a model. In this work, we apply a targeted\ndata extraction attack to the SATML2023 Language Model Training Data Extraction\nChallenge. We apply a two-step approach. In the first step, we maximise the\nrecall of the model and are able to extract the suffix for 69% of the samples.\nIn the second step, we use a classifier-based Membership Inference Attack on\nthe generations. Our AutoSklearn classifier achieves a precision of 0.841. The\nfull approach reaches a score of 0.405 recall at a 10% false positive rate,\nwhich is an improvement of 34% over the baseline of 0.301.", "published": "2023-02-13 18:00:44", "link": "http://arxiv.org/abs/2302.07735v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Paparazzi: A Deep Dive into the Capabilities of Language and Vision\n  Models for Grounding Viewpoint Descriptions", "abstract": "Existing language and vision models achieve impressive performance in\nimage-text understanding. Yet, it is an open question to what extent they can\nbe used for language understanding in 3D environments and whether they\nimplicitly acquire 3D object knowledge, e.g. about different views of an\nobject. In this paper, we investigate whether a state-of-the-art language and\nvision model, CLIP, is able to ground perspective descriptions of a 3D object\nand identify canonical views of common objects based on text queries. We\npresent an evaluation framework that uses a circling camera around a 3D object\nto generate images from different viewpoints and evaluate them in terms of\ntheir similarity to natural language descriptions. We find that a pre-trained\nCLIP model performs poorly on most canonical views and that fine-tuning using\nhard negative sampling and random contrasting yields good results even under\nconditions with little available training data.", "published": "2023-02-13 15:18:27", "link": "http://arxiv.org/abs/2302.10282v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Symbolic Discovery of Optimization Algorithms", "abstract": "We present a method to formulate algorithm discovery as program search, and\napply it to discover optimization algorithms for deep neural network training.\nWe leverage efficient search techniques to explore an infinite and sparse\nprogram space. To bridge the large generalization gap between proxy and target\ntasks, we also introduce program selection and simplification strategies. Our\nmethod discovers a simple and effective optimization algorithm, $\\textbf{Lion}$\n($\\textit{Evo$\\textbf{L}$ved S$\\textbf{i}$gn M$\\textbf{o}$me$\\textbf{n}$tum}$).\nIt is more memory-efficient than Adam as it only keeps track of the momentum.\nDifferent from adaptive optimizers, its update has the same magnitude for each\nparameter calculated through the sign operation. We compare Lion with widely\nused optimizers, such as Adam and Adafactor, for training a variety of models\non different tasks. On image classification, Lion boosts the accuracy of ViT by\nup to 2% on ImageNet and saves up to 5x the pre-training compute on JFT. On\nvision-language contrastive learning, we achieve 88.3% $\\textit{zero-shot}$ and\n91.1% $\\textit{fine-tuning}$ accuracy on ImageNet, surpassing the previous best\nresults by 2% and 0.1%, respectively. On diffusion models, Lion outperforms\nAdam by achieving a better FID score and reducing the training compute by up to\n2.3x. For autoregressive, masked language modeling, and fine-tuning, Lion\nexhibits a similar or better performance compared to Adam. Our analysis of Lion\nreveals that its performance gain grows with the training batch size. It also\nrequires a smaller learning rate than Adam due to the larger norm of the update\nproduced by the sign function. Additionally, we examine the limitations of Lion\nand identify scenarios where its improvements are small or not statistically\nsignificant. Lion is also successfully deployed in production systems such as\nGoogle search ads CTR model.", "published": "2023-02-13 20:27:30", "link": "http://arxiv.org/abs/2302.06675v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Fast and small footprint Hybrid HMM-HiFiGAN based system for speech\n  synthesis in Indian languages", "abstract": "Hidden-Markov-model (HMM) based text-to-speech (HTS) offers flexibility in\nspeaking styles along with fast training and synthesis while being\ncomputationally less intense. HTS performs well even in low-resource scenarios.\nThe primary drawback is that the voice quality is poor compared to that of E2E\nsystems. A hybrid approach combining HMM-based feature generation and\nneural-network-based HiFi-GAN vocoder to improve HTS synthesis quality is\nproposed. HTS is trained on high-resolution mel-spectrograms instead of\nconventional mel generalized coefficients (MGC), and the output mel-spectrogram\ncorresponding to the input text is used in a HiFi-GAN vocoder trained on Indic\nlanguages, to produce naturalness that is equivalent to that of E2E systems, as\nevidenced from the DMOS and PC tests.", "published": "2023-02-13 10:01:43", "link": "http://arxiv.org/abs/2302.06227v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
