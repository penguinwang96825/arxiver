{"title": "Token-Scaled Logit Distillation for Ternary Weight Generative Language\n  Models", "abstract": "Generative Language Models (GLMs) have shown impressive performance in tasks\nsuch as text generation, understanding, and reasoning. However, the large model\nsize poses challenges for practical deployment. To solve this problem,\nQuantization-Aware Training (QAT) has become increasingly popular. However,\ncurrent QAT methods for generative models have resulted in a noticeable loss of\naccuracy. To counteract this issue, we propose a novel knowledge distillation\nmethod specifically designed for GLMs. Our method, called token-scaled logit\ndistillation, prevents overfitting and provides superior learning from the\nteacher model and ground truth. This research marks the first evaluation of\nternary weight quantization-aware training of large-scale GLMs with less than\n1.0 degradation in perplexity and achieves enhanced accuracy in tasks like\ncommon-sense QA and arithmetic reasoning as well as natural language\nunderstanding. Our code is available at https://github.com/aiha-lab/TSLD.", "published": "2023-08-13 11:07:55", "link": "http://arxiv.org/abs/2308.06744v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Infidelity: When Faithfulness Measures on Masked Language Models\n  Are Misleading", "abstract": "A common approach to quantifying neural text classifier interpretability is\nto calculate faithfulness metrics based on iteratively masking salient input\ntokens and measuring changes in the model prediction. We propose that this\nproperty is better described as \"sensitivity to iterative masking\", and\nhighlight pitfalls in using this measure for comparing text classifier\ninterpretability. We show that iterative masking produces large variation in\nfaithfulness scores between otherwise comparable Transformer encoder text\nclassifiers. We then demonstrate that iteratively masked samples produce\nembeddings outside the distribution seen during training, resulting in\nunpredictable behaviour. We further explore task-specific considerations that\nundermine principled comparison of interpretability using iterative masking,\nsuch as an underlying similarity to salience-based adversarial attacks. Our\nfindings give insight into how these behaviours affect neural text classifiers,\nand provide guidance on how sensitivity to iterative masking should be\ninterpreted.", "published": "2023-08-13 15:44:39", "link": "http://arxiv.org/abs/2308.06795v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Building Trust in Conversational AI: A Comprehensive Review and Solution\n  Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge\n  Graph", "abstract": "Conversational AI systems have emerged as key enablers of human-like\ninteractions across diverse sectors. Nevertheless, the balance between\nlinguistic nuance and factual accuracy has proven elusive. In this paper, we\nfirst introduce LLMXplorer, a comprehensive tool that provides an in-depth\nreview of over 150 Large Language Models (LLMs), elucidating their myriad\nimplications ranging from social and ethical to regulatory, as well as their\napplicability across industries. Building on this foundation, we propose a\nnovel functional architecture that seamlessly integrates the structured\ndynamics of Knowledge Graphs with the linguistic capabilities of LLMs.\nValidated using real-world AI news data, our architecture adeptly blends\nlinguistic sophistication with factual rigour and further strengthens data\nsecurity through Role-Based Access Control. This research provides insights\ninto the evolving landscape of conversational AI, emphasizing the imperative\nfor systems that are efficient, transparent, and trustworthy.", "published": "2023-08-13 22:47:51", "link": "http://arxiv.org/abs/2308.13534v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MACO: A Modality Adversarial and Contrastive Framework for\n  Modality-missing Multi-modal Knowledge Graph Completion", "abstract": "Recent years have seen significant advancements in multi-modal knowledge\ngraph completion (MMKGC). MMKGC enhances knowledge graph completion (KGC) by\nintegrating multi-modal entity information, thereby facilitating the discovery\nof unobserved triples in the large-scale knowledge graphs (KGs). Nevertheless,\nexisting methods emphasize the design of elegant KGC models to facilitate\nmodality interaction, neglecting the real-life problem of missing modalities in\nKGs. The missing modality information impedes modal interaction, consequently\nundermining the model's performance. In this paper, we propose a modality\nadversarial and contrastive framework (MACO) to solve the modality-missing\nproblem in MMKGC. MACO trains a generator and discriminator adversarially to\ngenerate missing modality features that can be incorporated into the MMKGC\nmodel. Meanwhile, we design a cross-modal contrastive loss to improve the\nperformance of the generator. Experiments on public benchmarks with further\nexplorations demonstrate that MACO could achieve state-of-the-art results and\nserve as a versatile framework to bolster various MMKGC models. Our code and\nbenchmark data are available at https://github.com/zjukg/MACO.", "published": "2023-08-13 06:29:38", "link": "http://arxiv.org/abs/2308.06696v1", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Modeling the Dashboard Provenance", "abstract": "Organizations of all kinds, whether public or private, profit-driven or\nnon-profit, and across various industries and sectors, rely on dashboards for\neffective data visualization. However, the reliability and efficacy of these\ndashboards rely on the quality of the visual and data they present. Studies\nshow that less than a quarter of dashboards provide information about their\nsources, which is just one of the expected metadata when provenance is\nseriously considered. Provenance is a record that describes people,\norganizations, entities, and activities that had a role in the production,\ninfluence, or delivery of a piece of data or an object. This paper aims to\nprovide a provenance representation model, that entitles standardization,\nmodeling, generation, capture, and visualization, specifically designed for\ndashboards and its visual and data components. The proposed model will offer a\ncomprehensive set of essential provenance metadata that enables users to\nevaluate the quality, consistency, and reliability of the information presented\non dashboards. This will allow a clear and precise understanding of the context\nin which a specific dashboard was developed, ultimately leading to better\ndecision-making.", "published": "2023-08-13 15:03:31", "link": "http://arxiv.org/abs/2308.06788v2", "categories": ["cs.HC", "cs.CL", "cs.DB", "cs.GR"], "primary_category": "cs.HC"}
{"title": "An Ensemble Approach to Question Classification: Integrating Electra\n  Transformer, GloVe, and LSTM", "abstract": "Natural Language Processing (NLP) has emerged as a crucial technology for\nunderstanding and generating human language, playing an essential role in tasks\nsuch as machine translation, sentiment analysis, and more pertinently, question\nclassification. As a subfield within NLP, question classification focuses on\ndetermining the type of information being sought, a fundamental step for\ndownstream applications like question answering systems. This study presents an\ninnovative ensemble approach for question classification, combining the\nstrengths of Electra, GloVe, and LSTM models. Rigorously tested on the\nwell-regarded TREC dataset, the model demonstrates how the integration of these\ndisparate technologies can lead to superior results. Electra brings in its\ntransformer-based capabilities for complex language understanding, GloVe offers\nglobal vector representations for capturing word-level semantics, and LSTM\ncontributes its sequence learning abilities to model long-term dependencies. By\nfusing these elements strategically, our ensemble model delivers a robust and\nefficient solution for the complex task of question classification. Through\nrigorous comparisons with well-known models like BERT, RoBERTa, and DistilBERT,\nthe ensemble approach verifies its effectiveness by attaining an 80% accuracy\nscore on the test dataset.", "published": "2023-08-13 18:14:10", "link": "http://arxiv.org/abs/2308.06828v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Diagnostic Reasoning Prompts Reveal the Potential for Large Language\n  Model Interpretability in Medicine", "abstract": "One of the major barriers to using large language models (LLMs) in medicine\nis the perception they use uninterpretable methods to make clinical decisions\nthat are inherently different from the cognitive processes of clinicians. In\nthis manuscript we develop novel diagnostic reasoning prompts to study whether\nLLMs can perform clinical reasoning to accurately form a diagnosis. We find\nthat GPT4 can be prompted to mimic the common clinical reasoning processes of\nclinicians without sacrificing diagnostic accuracy. This is significant because\nan LLM that can use clinical reasoning to provide an interpretable rationale\noffers physicians a means to evaluate whether LLMs can be trusted for patient\ncare. Novel prompting methods have the potential to expose the black box of\nLLMs, bringing them one step closer to safe and effective use in medicine.", "published": "2023-08-13 19:04:07", "link": "http://arxiv.org/abs/2308.06834v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Transforming Sentiment Analysis in the Financial Domain with ChatGPT", "abstract": "Financial sentiment analysis plays a crucial role in decoding market trends\nand guiding strategic trading decisions. Despite the deployment of advanced\ndeep learning techniques and language models to refine sentiment analysis in\nfinance, this study breaks new ground by investigating the potential of large\nlanguage models, particularly ChatGPT 3.5, in financial sentiment analysis,\nwith a strong emphasis on the foreign exchange market (forex). Employing a\nzero-shot prompting approach, we examine multiple ChatGPT prompts on a\nmeticulously curated dataset of forex-related news headlines, measuring\nperformance using metrics such as precision, recall, f1-score, and Mean\nAbsolute Error (MAE) of the sentiment class. Additionally, we probe the\ncorrelation between predicted sentiment and market returns as an additional\nevaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment\nanalysis model for financial texts, exhibited approximately 35\\% enhanced\nperformance in sentiment classification and a 36\\% higher correlation with\nmarket returns. By underlining the significance of prompt engineering,\nparticularly in zero-shot contexts, this study spotlights ChatGPT's potential\nto substantially boost sentiment analysis in financial applications. By sharing\nthe utilized dataset, our intention is to stimulate further research and\nadvancements in the field of financial services.", "published": "2023-08-13 09:20:47", "link": "http://arxiv.org/abs/2308.07935v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.IR", "68T01, 68T50, 91B28, 91B30"], "primary_category": "cs.CL"}
