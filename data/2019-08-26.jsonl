{"title": "Transductive Data-Selection Algorithms for Fine-Tuning Neural Machine\n  Translation", "abstract": "Machine Translation models are trained to translate a variety of documents\nfrom one language into another. However, models specifically trained for a\nparticular characteristics of the documents tend to perform better. Fine-tuning\nis a technique for adapting an NMT model to some domain. In this work, we want\nto use this technique to adapt the model to a given test set. In particular, we\nare using transductive data selection algorithms which take advantage the\ninformation of the test set to retrieve sentences from a larger parallel set.\n  In cases where the model is available at translation time (when the test set\nis provided), it can be adapted with a small subset of data, thereby achieving\nbetter performance than a generic model or a domain-adapted model.", "published": "2019-08-26 08:55:00", "link": "http://arxiv.org/abs/1908.09532v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Attribute Representation and Injection for Sentiment\n  Classification", "abstract": "Text attributes, such as user and product information in product reviews,\nhave been used to improve the performance of sentiment classification models.\nThe de facto standard method is to incorporate them as additional biases in the\nattention mechanism, and more performance gains are achieved by extending the\nmodel architecture. In this paper, we show that the above method is the least\neffective way to represent and inject attributes. To demonstrate this\nhypothesis, unlike previous models with complicated architectures, we limit our\nbase model to a simple BiLSTM with attention classifier, and instead focus on\nhow and where the attributes should be incorporated in the model. We propose to\nrepresent attributes as chunk-wise importance weight matrices and consider four\nlocations in the model (i.e., embedding, encoding, attention, classifier) to\ninject attributes. Experiments show that our proposed method achieves\nsignificant improvements over the standard approach and that attention\nmechanism is the worst location to inject attributes, contradicting prior work.\nWe also outperform the state-of-the-art despite our use of a simple base model.\nFinally, we show that these representations transfer well to other tasks. Model\nimplementation and datasets are released here:\nhttps://github.com/rktamplayo/CHIM.", "published": "2019-08-26 10:55:42", "link": "http://arxiv.org/abs/1908.09590v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Patent Claim Generation by Span Relevancy", "abstract": "Our goal of patent claim generation is to realize \"augmented inventing\" for\ninventors by leveraging latest Deep Learning techniques. We envision the\npossibility of building an \"auto-complete\" function for inventors to conceive\nbetter inventions in the era of artificial intelligence. In order to generate\npatent claims with good quality, a fundamental question is how to measure it.\nWe tackle the problem from a perspective of claim span relevancy. Patent claim\nlanguage was rarely explored in the NLP field. It is unique in its own way and\ncontains rich explicit and implicit human annotations. In this work, we propose\na span-based approach and a generic framework to measure patent claim\ngeneration quantitatively. In order to study the effectiveness of patent claim\ngeneration, we define a metric to measure whether two consecutive spans in a\ngenerated patent claims are relevant. We treat such relevancy measurement as a\nspan-pair classification problem, following the concept of natural language\ninference. Technically, the span-pair classifier is implemented by fine-tuning\na pre-trained language model. The patent claim generation is implemented by\nfine-tuning the other pre-trained model. Specifically, we fine-tune a\npre-trained Google BERT model to measure the patent claim spans generated by a\nfine-tuned OpenAI GPT-2 model. In this way, we re-use two of the\nstate-of-the-art pre-trained models in the NLP field. Our result shows the\neffectiveness of the span-pair classifier after fine-tuning the pre-trained\nmodel. It further validates the quantitative metric of span relevancy in patent\nclaim generation. Particularly, we found that the span relevancy ratio measured\nby BERT becomes lower when the diversity in GPT-2 text generation becomes\nhigher.", "published": "2019-08-26 10:59:55", "link": "http://arxiv.org/abs/1908.09591v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Simple Domain Adaptation Methods in Unsupervised Neural\n  Machine Translation", "abstract": "Domain adaptation has been well-studied in supervised neural machine\ntranslation (SNMT). However, it has not been well-studied for unsupervised\nneural machine translation (UNMT), although UNMT has recently achieved\nremarkable results in several domain-specific language pairs. Besides the\ninconsistent domains between training data and test data for SNMT, there\nsometimes exists an inconsistent domain between two monolingual training data\nfor UNMT. In this work, we empirically show different scenarios for\nunsupervised neural machine translation. Based on these scenarios, we revisit\nthe effect of the existing domain adaptation methods including batch weighting\nand fine tuning methods in UNMT. Finally, we propose modified methods to\nimprove the performances of domain-specific UNMT systems.", "published": "2019-08-26 11:36:16", "link": "http://arxiv.org/abs/1908.09605v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low-Resource Name Tagging Learned with Weakly Labeled Data", "abstract": "Name tagging in low-resource languages or domains suffers from inadequate\ntraining data. Existing work heavily relies on additional information, while\nleaving those noisy annotations unexplored that extensively exist on the web.\nIn this paper, we propose a novel neural model for name tagging solely based on\nweakly labeled (WL) data, so that it can be applied in any low-resource\nsettings. To take the best advantage of all WL sentences, we split them into\nhigh-quality and noisy portions for two modules, respectively: (1) a\nclassification module focusing on the large portion of noisy data can\nefficiently and robustly pretrain the tag classifier by capturing textual\ncontext semantics; and (2) a costly sequence labeling module focusing on\nhigh-quality data utilizes Partial-CRFs with non-entity sampling to achieve\nglobal optimum. Two modules are combined via shared parameters. Extensive\nexperiments involving five low-resource languages and fine-grained food domain\ndemonstrate our superior performance (6% and 7.8% F1 gains on average) as well\nas efficiency.", "published": "2019-08-26 13:09:37", "link": "http://arxiv.org/abs/1908.09659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "uniblock: Scoring and Filtering Corpus with Unicode Block Information", "abstract": "The preprocessing pipelines in Natural Language Processing usually involve a\nstep of removing sentences consisted of illegal characters. The definition of\nillegal characters and the specific removal strategy depend on the task,\nlanguage, domain, etc, which often lead to tiresome and repetitive scripting of\nrules. In this paper, we introduce a simple statistical method, uniblock, to\novercome this problem. For each sentence, uniblock generates a fixed-size\nfeature vector using Unicode block information of the characters. A Gaussian\nmixture model is then estimated on some clean corpus using variational\ninference. The learned model can then be used to score sentences and filter\ncorpus. We present experimental results on Sentiment Analysis, Language\nModeling and Machine Translation, and show the simplicity and effectiveness of\nour method.", "published": "2019-08-26 14:55:03", "link": "http://arxiv.org/abs/1908.09716v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does BERT agree? Evaluating knowledge of structure dependence through\n  agreement relations", "abstract": "Learning representations that accurately model semantics is an important goal\nof natural language processing research. Many semantic phenomena depend on\nsyntactic structure. Recent work examines the extent to which state-of-the-art\nmodels for pre-training representations, such as BERT, capture such\nstructure-dependent phenomena, but is largely restricted to one phenomenon in\nEnglish: number agreement between subjects and verbs. We evaluate BERT's\nsensitivity to four types of structure-dependent agreement relations in a new\nsemi-automatically curated dataset across 26 languages. We show that both the\nsingle-language and multilingual BERT models capture syntax-sensitive agreement\npatterns well in general, but we also highlight the specific linguistic\ncontexts in which their performance degrades.", "published": "2019-08-26 19:56:08", "link": "http://arxiv.org/abs/1908.09892v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Channel Graph Neural Network for Entity Alignment", "abstract": "Entity alignment typically suffers from the issues of structural\nheterogeneity and limited seed alignments. In this paper, we propose a novel\nMulti-channel Graph Neural Network model (MuGNN) to learn alignment-oriented\nknowledge graph (KG) embeddings by robustly encoding two KGs via multiple\nchannels. Each channel encodes KGs via different relation weighting schemes\nwith respect to self-attention towards KG completion and cross-KG attention for\npruning exclusive entities respectively, which are further combined via pooling\ntechniques. Moreover, we also infer and transfer rule knowledge for completing\ntwo KGs consistently. MuGNN is expected to reconcile the structural differences\nof two KGs, and thus make better use of seed alignments. Extensive experiments\non five publicly available datasets demonstrate our superior performance (5%\nHits@1 up on average).", "published": "2019-08-26 20:05:37", "link": "http://arxiv.org/abs/1908.09898v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Partially-supervised Mention Detection", "abstract": "Learning to detect entity mentions without using syntactic information can be\nuseful for integration and joint optimization with other tasks. However, it is\ncommon to have partially annotated data for this problem. Here, we investigate\ntwo approaches to deal with partial annotation of mentions: weighted loss and\nsoft-target classification. We also propose two neural mention detection\napproaches: a sequence tagging, and an exhaustive search. We evaluate our\nmethods with coreference resolution as a downstream task, using multitask\nlearning. The results show that the recall and F1 score improve for all\nmethods.", "published": "2019-08-26 07:40:33", "link": "http://arxiv.org/abs/1908.09507v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Thinking Globally, Acting Locally: Distantly Supervised Global-to-Local\n  Knowledge Selection for Background Based Conversation", "abstract": "Background Based Conversations (BBCs) have been introduced to help\nconversational systems avoid generating overly generic responses. In a BBC, the\nconversation is grounded in a knowledge source. A key challenge in BBCs is\nKnowledge Selection (KS): given a conversational context, try to find the\nappropriate background knowledge (a text fragment containing related facts or\ncomments, etc.) based on which to generate the next response. Previous work\naddresses KS by employing attention and/or pointer mechanisms. These mechanisms\nuse a local perspective, i.e., they select a token at a time based solely on\nthe current decoding state. We argue for the adoption of a global perspective,\ni.e., pre-selecting some text fragments from the background knowledge that\ncould help determine the topic of the next response. We enhance KS in BBCs by\nintroducing a Global-to-Local Knowledge Selection (GLKS) mechanism. Given a\nconversational context and background knowledge, we first learn a topic\ntransition vector to encode the most likely text fragments to be used in the\nnext response, which is then used to guide the local KS at each decoding\ntimestamp. In order to effectively learn the topic transition vector, we\npropose a distantly supervised learning schema. Experimental results show that\nthe GLKS model significantly outperforms state-of-the-art methods in terms of\nboth automatic and human evaluation. More importantly, GLKS achieves this\nwithout requiring any extra annotations, which demonstrates its high degree of\nscalability.", "published": "2019-08-26 08:52:33", "link": "http://arxiv.org/abs/1908.09528v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Detecting Toxicity in News Articles: Application to Bulgarian", "abstract": "Online media aim for reaching ever bigger audience and for attracting ever\nlonger attention span. This competition creates an environment that rewards\nsensational, fake, and toxic news. To help limit their spread and impact, we\npropose and develop a news toxicity detector that can recognize various types\nof toxic content. While previous research primarily focused on English, here we\ntarget Bulgarian. We created a new dataset by crawling a website that for five\nyears has been collecting Bulgarian news articles that were manually\ncategorized into eight toxicity groups. Then we trained a multi-class\nclassifier with nine categories: eight toxic and one non-toxic. We experimented\nwith different representations based on ElMo, BERT, and XLM, as well as with a\nvariety of domain-specific features. Due to the small size of our dataset, we\ncreated a separate model for each feature type, and we ultimately combined\nthese models into a meta-classifier. The evaluation results show an accuracy of\n59.0% and a macro-F1 score of 39.7%, which represent sizable improvements over\nthe majority-class baseline (Acc=30.3%, macro-F1=5.2%).", "published": "2019-08-26 16:37:03", "link": "http://arxiv.org/abs/1908.09785v1", "categories": ["cs.CL", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News", "abstract": "Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.", "published": "2019-08-26 17:23:22", "link": "http://arxiv.org/abs/1908.09805v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Don't paraphrase, detect! Rapid and Effective Data Collection for\n  Semantic Parsing", "abstract": "A major hurdle on the road to conversational interfaces is the difficulty in\ncollecting data that maps language utterances to logical forms. One prominent\napproach for data collection has been to automatically generate pseudo-language\npaired with logical forms, and paraphrase the pseudo-language to natural\nlanguage through crowdsourcing (Wang et al., 2015). However, this data\ncollection procedure often leads to low performance on real data, due to a\nmismatch between the true distribution of examples and the distribution induced\nby the data collection procedure. In this paper, we thoroughly analyze two\nsources of mismatch in this process: the mismatch in logical form distribution\nand the mismatch in language distribution between the true and induced\ndistributions. We quantify the effects of these mismatches, and propose a new\ndata collection approach that mitigates them. Assuming access to unlabeled\nutterances from the true distribution, we combine crowdsourcing with a\nparaphrase model to detect correct logical forms for the unlabeled utterances.\nOn two datasets, our method leads to 70.6 accuracy on average on the true\ndistribution, compared to 51.3 in paraphrasing-based data collection.", "published": "2019-08-26 22:15:55", "link": "http://arxiv.org/abs/1908.09940v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Neural Story Generation by Targeted Common Sense Grounding", "abstract": "Stories generated with neural language models have shown promise in\ngrammatical and stylistic consistency. However, the generated stories are still\nlacking in common sense reasoning, e.g., they often contain sentences deprived\nof world knowledge. We propose a simple multi-task learning scheme to achieve\nquantitatively better common sense reasoning in language models by leveraging\nauxiliary training signals from datasets designed to provide common sense\ngrounding. When combined with our two-stage fine-tuning pipeline, our method\nachieves improved common sense reasoning and state-of-the-art perplexity on the\nWriting Prompts (Fan et al., 2018) story generation dataset.", "published": "2019-08-26 03:29:21", "link": "http://arxiv.org/abs/1908.09451v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Semi-supervised Learning for Word Sense Disambiguation", "abstract": "This work is a study of the impact of multiple aspects in a classic\nunsupervised word sense disambiguation algorithm. We identify relevant factors\nin a decision rule algorithm, including the initial labeling of examples, the\nformalization of the rule confidence, and the criteria for accepting a decision\nrule. Some of these factors are only implicitly considered in the original\nliterature. We then propose a lightly supervised version of the algorithm, and\nemploy a pseudo-word-based strategy to evaluate the impact of these factors.\nThe obtained performances are comparable with those of highly optimized\nformulations of the word sense disambiguation method.", "published": "2019-08-26 12:35:28", "link": "http://arxiv.org/abs/1908.09641v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Ensemble approach for natural language question answering problem", "abstract": "Machine comprehension, answering a question depending on a given context\nparagraph is a typical task of Natural Language Understanding. It requires to\nmodel complex dependencies existing between the question and the context\nparagraph. There are many neural network models attempting to solve the problem\nof question answering. The best models have been selected, studied and compared\nwith each other. All the selected models are based on the neural attention\nmechanism concept. Additionally, studies on a SQUAD dataset were performed. The\nsubsets of queries were extracted and then each model was analyzed how it deals\nwith specific group of queries. Based on these three model ensemble model was\ncreated and tested on SQUAD dataset. It outperforms the best Mnemonic Reader\nmodel.", "published": "2019-08-26 15:01:24", "link": "http://arxiv.org/abs/1908.09720v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Connecting and Comparing Language Model Interpolation Techniques", "abstract": "In this work, we uncover a theoretical connection between two language model\ninterpolation techniques, count merging and Bayesian interpolation. We compare\nthese techniques as well as linear interpolation in three scenarios with\nabundant training data per component model. Consistent with prior work, we show\nthat both count merging and Bayesian interpolation outperform linear\ninterpolation. We include the first (to our knowledge) published comparison of\ncount merging and Bayesian interpolation, showing that the two techniques\nperform similarly. Finally, we argue that other considerations will make\nBayesian interpolation the preferred approach in most circumstances.", "published": "2019-08-26 15:32:44", "link": "http://arxiv.org/abs/1908.09738v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Differentiable Product Quantization for End-to-End Embedding Compression", "abstract": "Embedding layers are commonly used to map discrete symbols into continuous\nembedding vectors that reflect their semantic meanings. Despite their\neffectiveness, the number of parameters in an embedding layer increases\nlinearly with the number of symbols and poses a critical challenge on memory\nand storage constraints. In this work, we propose a generic and end-to-end\nlearnable compression framework termed differentiable product quantization\n(DPQ). We present two instantiations of DPQ that leverage different\napproximation techniques to enable differentiability in end-to-end learning.\nOur method can readily serve as a drop-in alternative for any existing\nembedding layer. Empirically, DPQ offers significant compression ratios\n(14-238$\\times$) at negligible or no performance cost on 10 datasets across\nthree different language tasks.", "published": "2019-08-26 15:56:10", "link": "http://arxiv.org/abs/1908.09756v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Granularity Representations of Dialog", "abstract": "Neural models of dialog rely on generalized latent representations of\nlanguage. This paper introduces a novel training procedure which explicitly\nlearns multiple representations of language at several levels of granularity.\nThe multi-granularity training algorithm modifies the mechanism by which\nnegative candidate responses are sampled in order to control the granularity of\nlearned latent representations. Strong performance gains are observed on the\nnext utterance retrieval task using both the MultiWOZ dataset and the Ubuntu\ndialog corpus. Analysis significantly demonstrates that multiple granularities\nof representation are being learned, and that multi-granularity training\nfacilitates better transfer to downstream tasks.", "published": "2019-08-26 19:41:21", "link": "http://arxiv.org/abs/1908.09890v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging External Knowledge for Out-Of-Vocabulary Entity Labeling", "abstract": "Dealing with previously unseen slots is a challenging problem in a real-world\nmulti-domain dialogue state tracking task. Other approaches rely on predefined\nmappings to generate candidate slot keys, as well as their associated values.\nThis, however, may fail when the key, the value, or both, are not seen during\ntraining. To address this problem we introduce a neural network that leverages\nexternal knowledge bases (KBs) to better classify out-of-vocabulary slot keys\nand values. This network projects the slot into an attribute space derived from\nthe KB, and, by leveraging similarities in this space, we propose candidate\nslot keys and values to the dialogue state tracker. We provide extensive\nexperiments that demonstrate that our stratagem can improve upon a previous\napproach, which relies on predefined candidate mappings. In particular, we\nevaluate this approach by training a state-of-the-art model with candidates\ngenerated from our network, and obtained relative increases of 57.7% and 82.7%\nin F1 score and accuracy, respectively, for the aforementioned model, when\ncompared to the current candidate generation strategy.", "published": "2019-08-26 22:08:55", "link": "http://arxiv.org/abs/1908.09936v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Emotional Analysis of False Information in Social Media and News\n  Articles", "abstract": "Fake news is risky since it has been created to manipulate the readers'\nopinions and beliefs. In this work, we compared the language of false news to\nthe real one of real news from an emotional perspective, considering a set of\nfalse information types (propaganda, hoax, clickbait, and satire) from social\nmedia and online news articles sources. Our experiments showed that false\ninformation has different emotional patterns in each of its types, and emotions\nplay a key role in deceiving the reader. Based on that, we proposed a LSTM\nneural network model that is emotionally-infused to detect false news.", "published": "2019-08-26 22:49:35", "link": "http://arxiv.org/abs/1908.09951v1", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Using LSTMs to Model the Java Programming Language", "abstract": "Recurrent neural networks (RNNs), specifically long-short term memory\nnetworks (LSTMs), can model natural language effectively. This research\ninvestigates the ability for these same LSTMs to perform next \"word\" prediction\non the Java programming language. Java source code from four different\nrepositories undergoes a transformation that preserves the logical structure of\nthe source code and removes the code's various specificities such as variable\nnames and literal values. Such datasets and an additional English language\ncorpus are used to train and test standard LSTMs' ability to predict the next\nelement in a sequence. Results suggest that LSTMs can effectively model Java\ncode achieving perplexities under 22 and accuracies above 0.47, which is an\nimprovement over LSTM's performance on the English language which demonstrated\na perplexity of 85 and an accuracy of 0.27. This research can have\napplicability in other areas such as syntactic template suggestion and\nautomated bug patching.", "published": "2019-08-26 00:43:32", "link": "http://arxiv.org/abs/1908.11685v1", "categories": ["cs.SE", "cs.CL", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Nearest Neighbor Search-Based Bitwise Source Separation Using\n  Discriminant Winner-Take-All Hashing", "abstract": "We propose an iteration-free source separation algorithm based on\nWinner-Take-All (WTA) hash codes, which is a faster, yet accurate alternative\nto a complex machine learning model for single-channel source separation in a\nresource-constrained environment. We first generate random permutations with\nWTA hashing to encode the shape of the multidimensional audio spectrum to a\nreduced bitstring representation. A nearest neighbor search on the hash codes\nof an incoming noisy spectrum as the query string results in the closest\nmatches among the hashed mixture spectra. Using the indices of the matching\nframes, we obtain the corresponding ideal binary mask vectors for denoising.\nSince both the training data and the search operation are bitwise, the\nprocedure can be done efficiently in hardware implementations. Experimental\nresults show that the WTA hash codes are discriminant and provide an affordable\ndictionary search mechanism that leads to a competent performance compared to a\ncomprehensive model and oracle masking.", "published": "2019-08-26 16:58:50", "link": "http://arxiv.org/abs/1908.09799v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Improving Automatic Jazz Melody Generation by Transfer Learning\n  Techniques", "abstract": "In this paper, we tackle the problem of transfer learning for Jazz automatic\ngeneration. Jazz is one of representative types of music, but the lack of Jazz\ndata in the MIDI format hinders the construction of a generative model for\nJazz. Transfer learning is an approach aiming to solve the problem of data\ninsufficiency, so as to transfer the common feature from one domain to another.\nIn view of its success in other machine learning problems, we investigate\nwhether, and how much, it can help improve automatic music generation for\nunder-resourced musical genres. Specifically, we use a recurrent variational\nautoencoder as the generative model, and use a genre-unspecified dataset as the\nsource dataset and a Jazz-only dataset as the target dataset. Two transfer\nlearning methods are evaluated using six levels of source-to-target data\nratios. The first method is to train the model on the source dataset, and then\nfine-tune the resulting model parameters on the target dataset. The second\nmethod is to train the model on both the source and target datasets at the same\ntime, but add genre labels to the latent vectors and use a genre classifier to\nimprove Jazz generation. The evaluation results show that the second method\nseems to perform better overall, but it cannot take full advantage of the\ngenre-unspecified dataset.", "published": "2019-08-26 05:57:21", "link": "http://arxiv.org/abs/1908.09484v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
