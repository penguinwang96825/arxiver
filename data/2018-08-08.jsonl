{"title": "Adversarial Domain Adaptation for Variational Neural Language Generation\n  in Dialogue Systems", "abstract": "Domain Adaptation arises when we aim at learning from source domain a model\nthat can per- form acceptably well on a different target domain. It is\nespecially crucial for Natural Language Generation (NLG) in Spoken Dialogue\nSystems when there are sufficient annotated data in the source domain, but\nthere is a limited labeled data in the target domain. How to effectively\nutilize as much of existing abilities from source domains is a crucial issue in\ndomain adaptation. In this paper, we propose an adversarial training procedure\nto train a Variational encoder-decoder based language generator via multiple\nadaptation steps. In this procedure, a model is first trained on a source\ndomain data and then fine-tuned on a small set of target domain utterances\nunder the guidance of two proposed critics. Experimental results show that the\nproposed method can effec- tively leverage the existing knowledge in the source\ndomain to adapt to another related domain by using only a small amount of\nin-domain data.", "published": "2018-08-08 00:02:18", "link": "http://arxiv.org/abs/1808.02586v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Write Notes in Electronic Health Records", "abstract": "Clinicians spend a significant amount of time inputting free-form textual\nnotes into Electronic Health Records (EHR) systems. Much of this documentation\nwork is seen as a burden, reducing time spent with patients and contributing to\nclinician burnout. With the aspiration of AI-assisted note-writing, we propose\na new language modeling task predicting the content of notes conditioned on\npast data from a patient's medical record, including patient demographics,\nlabs, medications, and past notes. We train generative models using the public,\nde-identified MIMIC-III dataset and compare generated notes with those in the\ndataset on multiple measures. We find that much of the content can be\npredicted, and that many common templates found in notes can be learned. We\ndiscuss how such models can be useful in supporting assistive note-writing\nfeatures such as error-detection and auto-complete.", "published": "2018-08-08 04:49:41", "link": "http://arxiv.org/abs/1808.02622v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Focus when Ranking Answers", "abstract": "One of the main challenges in ranking is embedding the query and document\npairs into a joint feature space, which can then be fed to a learning-to-rank\nalgorithm. To achieve this representation, the conventional state of the art\napproaches perform extensive feature engineering that encode the similarity of\nthe query-answer pair. Recently, deep-learning solutions have shown that it is\npossible to achieve comparable performance, in some settings, by learning the\nsimilarity representation directly from data. Unfortunately, previous models\nperform poorly on longer texts, or on texts with significant portion of\nirrelevant information, or which are grammatically incorrect. To overcome these\nlimitations, we propose a novel ranking algorithm for question answering,\nQARAT, which uses an attention mechanism to learn on which words and phrases to\nfocus when building the mutual representation. We demonstrate superior ranking\nperformance on several real-world question-answer ranking datasets, and provide\nvisualization of the attention mechanism to otter more insights into how our\nmodels of attention could benefit ranking for difficult question answering\nchallenges.", "published": "2018-08-08 11:06:15", "link": "http://arxiv.org/abs/1808.02724v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Debugging Neural Machine Translations", "abstract": "In this paper, we describe a tool for debugging the output and attention\nweights of neural machine translation (NMT) systems and for improved\nestimations of confidence about the output based on the attention. The purpose\nof the tool is to help researchers and developers find weak and faulty example\ntranslations that their NMT systems produce without the need for reference\ntranslations. Our tool also includes an option to directly compare translation\noutputs from two different NMT engines or experiments. In addition, we present\na demo website of our tool with examples of good and bad translations:\nhttp://attention.lielakeda.lv", "published": "2018-08-08 11:55:36", "link": "http://arxiv.org/abs/1808.02733v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Generation by Hierarchical Decoding with Linguistic\n  Patterns", "abstract": "Natural language generation (NLG) is a critical component in spoken dialogue\nsystems. Classic NLG can be divided into two phases: (1) sentence planning:\ndeciding on the overall sentence structure, (2) surface realization:\ndetermining specific word forms and flattening the sentence structure into a\nstring. Many simple NLG models are based on recurrent neural networks (RNN) and\nsequence-to-sequence (seq2seq) model, which basically contains an\nencoder-decoder structure; these NLG models generate sentences from scratch by\njointly optimizing sentence planning and surface realization using a simple\ncross entropy loss training criterion. However, the simple encoder-decoder\narchitecture usually suffers from generating complex and long sentences,\nbecause the decoder has to learn all grammar and diction knowledge. This paper\nintroduces a hierarchical decoding NLG model based on linguistic patterns in\ndifferent levels, and shows that the proposed method outperforms the\ntraditional one with a smaller model size. Furthermore, the design of the\nhierarchical decoding is flexible and easily-extensible in various NLG systems.", "published": "2018-08-08 13:12:10", "link": "http://arxiv.org/abs/1808.02747v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Debunking Fake News One Feature at a Time", "abstract": "Identifying the stance of a news article body with respect to a certain\nheadline is the first step to automated fake news detection. In this paper, we\nintroduce a 2-stage ensemble model to solve the stance detection task. By using\nonly hand-crafted features as input to a gradient boosting classifier, we are\nable to achieve a score of 9161.5 out of 11651.25 (78.63%) on the official Fake\nNews Challenge (Stage 1) dataset. We identify the most useful features for\ndetecting fake news and discuss how sampling techniques can be used to improve\nrecall accuracy on a highly imbalanced dataset.", "published": "2018-08-08 15:45:06", "link": "http://arxiv.org/abs/1808.02831v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Effective Representations for Chinese Sentiment Analysis\n  Using a Multi-Channel Convolutional Neural Network", "abstract": "Effective representation of a text is critical for various natural language\nprocessing tasks. For the particular task of Chinese sentiment analysis, it is\nimportant to understand and choose an effective representation of a text from\ndifferent forms of Chinese representations such as word, character and pinyin.\nThis paper presents a systematic study of the effect of these representations\nfor Chinese sentiment analysis by proposing a multi-channel convolutional\nneural network (MCCNN), where each channel corresponds to a representation.\nExperimental results show that: (1) Word wins on the dataset of low OOV rate\nwhile character wins otherwise; (2) Using these representations in combination\ngenerally improves the performance; (3) The representations based on MCCNN\noutperform conventional ngram features using SVM; (4) The proposed MCCNN model\nachieves the competitive performance against the state-of-the-art model\nfastText for Chinese sentiment analysis.", "published": "2018-08-08 23:06:12", "link": "http://arxiv.org/abs/1808.02961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of the CLEF-2018 CheckThat! Lab on Automatic Identification and\n  Verification of Political Claims. Task 1: Check-Worthiness", "abstract": "We present an overview of the CLEF-2018 CheckThat! Lab on Automatic\nIdentification and Verification of Political Claims, with focus on Task 1:\nCheck-Worthiness. The task asks to predict which claims in a political debate\nshould be prioritized for fact-checking. In particular, given a debate or a\npolitical speech, the goal was to produce a ranked list of its sentences based\non their worthiness for fact checking. We offered the task in both English and\nArabic, based on debates from the 2016 US Presidential Campaign, as well as on\nsome speeches during and after the campaign. A total of 30 teams registered to\nparticipate in the Lab and seven teams actually submitted systems for Task~1.\nThe most successful approaches used by the participants relied on recurrent and\nmulti-layer neural networks, as well as on combinations of distributional\nrepresentations, on matchings claims' vocabulary against lexicons, and on\nmeasures of syntactic dependency. The best systems achieved mean average\nprecision of 0.18 and 0.15 on the English and on the Arabic test datasets,\nrespectively. This leaves large room for further improvement, and thus we\nrelease all datasets and the scoring scripts, which should enable further\nresearch in check-worthiness estimation.", "published": "2018-08-08 12:51:21", "link": "http://arxiv.org/abs/1808.05542v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "End-to-end Speech Recognition with Word-based RNN Language Models", "abstract": "This paper investigates the impact of word-based RNN language models\n(RNN-LMs) on the performance of end-to-end automatic speech recognition (ASR).\nIn our prior work, we have proposed a multi-level LM, in which character-based\nand word-based RNN-LMs are combined in hybrid CTC/attention-based ASR. Although\nthis multi-level approach achieves significant error reduction in the Wall\nStreet Journal (WSJ) task, two different LMs need to be trained and used for\ndecoding, which increase the computational cost and memory usage. In this\npaper, we further propose a novel word-based RNN-LM, which allows us to decode\nwith only the word-based LM, where it provides look-ahead word probabilities to\npredict next characters instead of the character-based LM, leading competitive\naccuracy with less computation compared to the multi-level LM. We demonstrate\nthe efficacy of the word-based RNN-LMs using a larger corpus, LibriSpeech, in\naddition to WSJ we used in the prior work. Furthermore, we show that the\nproposed model achieves 5.1 %WER for WSJ Eval'92 test set when the vocabulary\nsize is increased, which is the best WER reported for end-to-end ASR systems on\nthis benchmark.", "published": "2018-08-08 03:05:11", "link": "http://arxiv.org/abs/1808.02608v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cognitive system to achieve human-level accuracy in automated assignment\n  of helpdesk email tickets", "abstract": "Ticket assignment/dispatch is a crucial part of service delivery business\nwith lot of scope for automation and optimization. In this paper, we present an\nend-to-end automated helpdesk email ticket assignment system, which is also\noffered as a service. The objective of the system is to determine the nature of\nthe problem mentioned in an incoming email ticket and then automatically\ndispatch it to an appropriate resolver group (or team) for resolution.\n  The proposed system uses an ensemble classifier augmented with a configurable\nrule engine. While design of classifier that is accurate is one of the main\nchallenges, we also need to address the need of designing a system that is\nrobust and adaptive to changing business needs. We discuss some of the main\ndesign challenges associated with email ticket assignment automation and how we\nsolve them. The design decisions for our system are driven by high accuracy,\ncoverage, business continuity, scalability and optimal usage of computational\nresources.\n  Our system has been deployed in production of three major service providers\nand currently assigning over 40,000 emails per month, on an average, with an\naccuracy close to 90% and covering at least 90% of email tickets. This\ntranslates to achieving human-level accuracy and results in a net saving of\nabout 23000 man-hours of effort per annum.", "published": "2018-08-08 06:04:35", "link": "http://arxiv.org/abs/1808.02636v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Question-Guided Hybrid Convolution for Visual Question Answering", "abstract": "In this paper, we propose a novel Question-Guided Hybrid Convolution (QGHC)\nnetwork for Visual Question Answering (VQA). Most state-of-the-art VQA methods\nfuse the high-level textual and visual features from the neural network and\nabandon the visual spatial information when learning multi-modal features.To\naddress these problems, question-guided kernels generated from the input\nquestion are designed to convolute with visual features for capturing the\ntextual and visual relationship in the early stage. The question-guided\nconvolution can tightly couple the textual and visual information but also\nintroduce more parameters when learning kernels. We apply the group\nconvolution, which consists of question-independent kernels and\nquestion-dependent kernels, to reduce the parameter size and alleviate\nover-fitting. The hybrid convolution can generate discriminative multi-modal\nfeatures with fewer parameters. The proposed approach is also complementary to\nexisting bilinear pooling fusion and attention based VQA methods. By\nintegrating with them, our method could further boost the performance.\nExtensive experiments on public VQA datasets validate the effectiveness of\nQGHC.", "published": "2018-08-08 05:39:00", "link": "http://arxiv.org/abs/1808.02632v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Towards Learning Fine-Grained Disentangled Representations from Speech", "abstract": "Learning disentangled representations of high-dimensional data is currently\nan active research area. However, compared to the field of computer vision,\nless work has been done for speech processing. In this paper, we provide a\nreview of two representative efforts on this topic and propose the novel\nconcept of fine-grained disentangled speech representation learning.", "published": "2018-08-08 20:59:26", "link": "http://arxiv.org/abs/1808.02939v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neural Machine Translation Inspired Binary Code Similarity Comparison\n  beyond Function Pairs", "abstract": "Binary code analysis allows analyzing binary code without having access to\nthe corresponding source code. A binary, after disassembly, is expressed in an\nassembly language. This inspires us to approach binary analysis by leveraging\nideas and techniques from Natural Language Processing (NLP), a rich area\nfocused on processing text of various natural languages. We notice that binary\ncode analysis and NLP share a lot of analogical topics, such as semantics\nextraction, summarization, and classification. This work utilizes these ideas\nto address two important code similarity comparison problems. (I) Given a pair\nof basic blocks for different instruction set architectures (ISAs), determining\nwhether their semantics is similar or not; and (II) given a piece of code of\ninterest, determining if it is contained in another piece of assembly code for\na different ISA. The solutions to these two problems have many applications,\nsuch as cross-architecture vulnerability discovery and code plagiarism\ndetection. We implement a prototype system INNEREYE and perform a comprehensive\nevaluation. A comparison between our approach and existing approaches to\nProblem I shows that our system outperforms them in terms of accuracy,\nefficiency and scalability. And the case studies utilizing the system\ndemonstrate that our solution to Problem II is effective. Moreover, this\nresearch showcases how to apply ideas and techniques from NLP to large-scale\nbinary code analysis.", "published": "2018-08-08 22:26:08", "link": "http://arxiv.org/abs/1808.04706v2", "categories": ["cs.SE", "cs.CL", "cs.CR", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Affect Estimation in 3D Space Using Multi-Task Active Learning for\n  Regression", "abstract": "Acquisition of labeled training samples for affective computing is usually\ncostly and time-consuming, as affects are intrinsically subjective, subtle and\nuncertain, and hence multiple human assessors are needed to evaluate each\naffective sample. Particularly, for affect estimation in the 3D space of\nvalence, arousal and dominance, each assessor has to perform the evaluations in\nthree dimensions, which makes the labeling problem even more challenging. Many\nsophisticated machine learning approaches have been proposed to reduce the data\nlabeling requirement in various other domains, but so far few have considered\naffective computing. This paper proposes two multi-task active learning for\nregression approaches, which select the most beneficial samples to label, by\nconsidering the three affect primitives simultaneously. Experimental results on\nthe VAM corpus demonstrated that our optimal sample selection approaches can\nresult in better estimation performance than random selection and several\ntraditional single-task active learning approaches. Thus, they can help\nalleviate the data labeling problem in affective computing, i.e., better\nestimation performance can be obtained from fewer labeling queries.", "published": "2018-08-08 22:39:46", "link": "http://arxiv.org/abs/1808.04244v2", "categories": ["cs.LG", "cs.HC", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
