{"title": "Natural Language Processing for Dialects of a Language: A Survey", "abstract": "State-of-the-art natural language processing (NLP) models are trained on\nmassive training corpora, and report a superlative performance on evaluation\ndatasets. This survey delves into an important attribute of these datasets: the\ndialect of a language. Motivated by the performance degradation of NLP models\nfor dialectal datasets and its implications for the equity of language\ntechnologies, we survey past research in NLP for dialects in terms of datasets,\nand approaches. We describe a wide range of NLP tasks in terms of two\ncategories: natural language understanding (NLU) (for tasks such as dialect\nclassification, sentiment analysis, parsing, and NLU benchmarks) and natural\nlanguage generation (NLG) (for summarisation, machine translation, and dialogue\nsystems). The survey is also broad in its coverage of languages which include\nEnglish, Arabic, German, among others. We observe that past work in NLP\nconcerning dialects goes deeper than mere dialect classification, and extends\nto several NLU and NLG tasks. For these tasks, we describe classical machine\nlearning using statistical models, along with the recent deep learning-based\napproaches based on pre-trained language models. We expect that this survey\nwill be useful to NLP researchers interested in building equitable language\ntechnologies by rethinking LLM benchmarks and model architectures.", "published": "2024-01-11 03:04:38", "link": "http://arxiv.org/abs/2401.05632v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Context-aware Detection of Cherry-picking in News Reporting", "abstract": "Cherry-picking refers to the deliberate selection of evidence or facts that\nfavor a particular viewpoint while ignoring or distorting evidence that\nsupports an opposing perspective. Manually identifying cherry-picked statements\nin news stories can be challenging. In this study, we introduce a novel\napproach to detecting cherry-picked statements by identifying missing important\nstatements in a target news story using language models and contextual\ninformation from other news sources. Furthermore, this research introduces a\nnovel dataset specifically designed for training and evaluating cherry-picking\ndetection models. Our best performing model achieves an F-1 score of about 89%\nin detecting important statements. Moreover, results show the effectiveness of\nincorporating external knowledge from alternative narratives when assessing\nstatement importance.", "published": "2024-01-11 04:03:35", "link": "http://arxiv.org/abs/2401.05650v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unveiling the Tapestry of Automated Essay Scoring: A Comprehensive\n  Investigation of Accuracy, Fairness, and Generalizability", "abstract": "Automatic Essay Scoring (AES) is a well-established educational pursuit that\nemploys machine learning to evaluate student-authored essays. While much effort\nhas been made in this area, current research primarily focuses on either (i)\nboosting the predictive accuracy of an AES model for a specific prompt (i.e.,\ndeveloping prompt-specific models), which often heavily relies on the use of\nthe labeled data from the same target prompt; or (ii) assessing the\napplicability of AES models developed on non-target prompts to the intended\ntarget prompt (i.e., developing the AES models in a cross-prompt setting).\nGiven the inherent bias in machine learning and its potential impact on\nmarginalized groups, it is imperative to investigate whether such bias exists\nin current AES methods and, if identified, how it intervenes with an AES\nmodel's accuracy and generalizability. Thus, our study aimed to uncover the\nintricate relationship between an AES model's accuracy, fairness, and\ngeneralizability, contributing practical insights for developing effective AES\nmodels in real-world education. To this end, we meticulously selected nine\nprominent AES methods and evaluated their performance using seven metrics on an\nopen-sourced dataset, which contains over 25,000 essays and various demographic\ninformation about students such as gender, English language learner status, and\neconomic status. Through extensive evaluations, we demonstrated that: (1)\nprompt-specific models tend to outperform their cross-prompt counterparts in\nterms of predictive accuracy; (2) prompt-specific models frequently exhibit a\ngreater bias towards students of different economic statuses compared to\ncross-prompt models; (3) in the pursuit of generalizability, traditional\nmachine learning models coupled with carefully engineered features hold greater\npotential for achieving both high accuracy and fairness than complex neural\nnetwork models.", "published": "2024-01-11 04:28:02", "link": "http://arxiv.org/abs/2401.05655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConcEPT: Concept-Enhanced Pre-Training for Language Models", "abstract": "Pre-trained language models (PLMs) have been prevailing in state-of-the-art\nmethods for natural language processing, and knowledge-enhanced PLMs are\nfurther proposed to promote model performance in knowledge-intensive tasks.\nHowever, conceptual knowledge, one essential kind of knowledge for human\ncognition, still remains understudied in this line of research. This limits\nPLMs' performance in scenarios requiring human-like cognition, such as\nunderstanding long-tail entities with concepts. In this paper, we propose\nConcEPT, which stands for Concept-Enhanced Pre-Training for language models, to\ninfuse conceptual knowledge into PLMs. ConcEPT exploits external taxonomies\nwith entity concept prediction, a novel pre-training objective to predict the\nconcepts of entities mentioned in the pre-training contexts. Unlike previous\nconcept-enhanced methods, ConcEPT can be readily adapted to various downstream\napplications without entity linking or concept mapping. Results of extensive\nexperiments show the effectiveness of ConcEPT in four tasks such as entity\ntyping, which validates that our model gains improved conceptual knowledge with\nconcept-enhanced pre-training.", "published": "2024-01-11 05:05:01", "link": "http://arxiv.org/abs/2401.05669v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Physician Diagnostic Logic into Large Language Models:\n  Preference Learning from Process Feedback", "abstract": "The use of large language models in medical dialogue generation has garnered\nsignificant attention, with a focus on improving response quality and fluency.\nWhile previous studies have made progress in optimizing model performance for\nsingle-round medical Q&A tasks, there is a need to enhance the model's\ncapability for multi-round conversations to avoid logical inconsistencies. To\naddress this, we propose an approach called preference learning from process\nfeedback~(PLPF), which integrates the doctor's diagnostic logic into LLMs. PLPF\ninvolves rule modeling, preference data generation, and preference alignment to\ntrain the model to adhere to the diagnostic process. Experimental results using\nStandardized Patient Testing show that PLPF enhances the diagnostic accuracy of\nthe baseline model in medical conversations by 17.6%, outperforming traditional\nreinforcement learning from human feedback. Additionally, PLPF demonstrates\neffectiveness in both multi-round and single-round dialogue tasks, showcasing\nits potential for improving medical dialogue generation.", "published": "2024-01-11 06:42:45", "link": "http://arxiv.org/abs/2401.05695v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAT-LLM: Prompting Large Language Models with Text Style Definition for\n  Chinese Article-style Transfer", "abstract": "Text style transfer is increasingly prominent in online entertainment and\nsocial media. However, existing research mainly concentrates on style transfer\nwithin individual English sentences, while ignoring the complexity of long\nChinese texts, which limits the wider applicability of style transfer in\ndigital media realm. To bridge this gap, we propose a Chinese Article-style\nTransfer framework (CAT-LLM), leveraging the capabilities of Large Language\nModels (LLMs). CAT-LLM incorporates a bespoke, pluggable Text Style Definition\n(TSD) module aimed at comprehensively analyzing text features in articles,\nprompting LLMs to efficiently transfer Chinese article-style. The TSD module\nintegrates a series of machine learning algorithms to analyze article-style\nfrom both words and sentences levels, thereby aiding LLMs thoroughly grasp the\ntarget style without compromising the integrity of the original text. In\naddition, this module supports dynamic expansion of internal style trees,\nshowcasing robust compatibility and allowing flexible optimization in\nsubsequent research. Moreover, we select five Chinese articles with distinct\nstyles and create five parallel datasets using ChatGPT, enhancing the models'\nperformance evaluation accuracy and establishing a novel paradigm for\nevaluating subsequent research on article-style transfer. Extensive\nexperimental results affirm that CAT-LLM outperforms current research in terms\nof transfer accuracy and content preservation, and has remarkable applicability\nto various types of LLMs.", "published": "2024-01-11 07:18:46", "link": "http://arxiv.org/abs/2401.05707v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero Resource Cross-Lingual Part Of Speech Tagging", "abstract": "Part of speech tagging in zero-resource settings can be an effective approach\nfor low-resource languages when no labeled training data is available. Existing\nsystems use two main techniques for POS tagging i.e. pretrained multilingual\nlarge language models(LLM) or project the source language labels into the zero\nresource target language and train a sequence labeling model on it. We explore\nthe latter approach using the off-the-shelf alignment module and train a hidden\nMarkov model(HMM) to predict the POS tags. We evaluate transfer learning setup\nwith English as a source language and French, German, and Spanish as target\nlanguages for part-of-speech tagging. Our conclusion is that projected\nalignment data in zero-resource language can be beneficial to predict POS tags.", "published": "2024-01-11 08:12:47", "link": "http://arxiv.org/abs/2401.05727v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Proficient Are Large Language Models in Formal Languages? An\n  In-Depth Insight for Knowledge Base Question Answering", "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural language\nquestions based on facts in knowledge bases. A typical approach to KBQA is\nsemantic parsing, which translates a question into an executable logical form\nin a formal language. Recent works leverage the capabilities of large language\nmodels (LLMs) for logical form generation to improve performance. However,\nalthough it is validated that LLMs are capable of solving some KBQA problems,\nthere has been little discussion on the differences in LLMs' proficiency in\nformal languages used in semantic parsing. In this work, we propose to evaluate\nthe understanding and generation ability of LLMs to deal with differently\nstructured logical forms by examining the inter-conversion of natural and\nformal language through in-context learning of LLMs. Extensive experiments with\nmodels of different sizes show that state-of-the-art LLMs can understand formal\nlanguages as well as humans, but generating correct logical forms given a few\nexamples remains a challenge. Most importantly, our results also indicate that\nLLMs exhibit considerable sensitivity. In general, the formal language with a\nlower formalization level, i.e., the more similar it is to natural language, is\nmore friendly to LLMs.", "published": "2024-01-11 09:27:50", "link": "http://arxiv.org/abs/2401.05777v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain of Evidences and Evidence to Generate: Prompting for Context\n  Grounded and Retrieval Augmented Reasoning", "abstract": "While chain-of-thoughts (CoT) prompting has revolutionized how LLMs perform\nreasoning tasks, its current methods and variations (e.g, Self-consistency,\nReACT, Reflexion, Tree-of-Thoughts (ToT), Cumulative Reasoning (CR) etc.,)\nsuffer from limitations like limited context grounding,\nhallucination/inconsistent output generation, and iterative sluggishness. To\novercome these challenges, we introduce a novel mono/dual-step zero-shot\nprompting framework built upon two unique strategies Chain of Evidences (CoE)}\nand Evidence to Generate (E2G). Instead of unverified reasoning claims, our\ninnovative approaches leverage the power of \"evidence for decision making\" by\nfirst focusing exclusively on the thought sequences explicitly mentioned in the\ncontext which then serve as extracted evidence, guiding the LLM's output\ngeneration process with greater precision and efficiency. This simple yet\npotent approach unlocks the full potential of chain-of-thoughts prompting,\nfacilitating faster, more reliable, and contextually aware reasoning in LLMs.\nOur framework consistently achieves remarkable results across various\nknowledge-intensive reasoning and generation tasks, surpassing baseline\napproaches with state-of-the-art LLMs. For instance, (i) on the LogiQA\nbenchmark using GPT-4, CoE achieves a new state-of-the-art accuracy of 53.8%,\nsurpassing CoT by 18%, ToT by 11%, and CR by 9%; (ii) CoE with PaLM-2\noutperforms the variable-shot performance of Gemini Ultra by 0.9 F1 points,\nachieving an F1 score of 83.3 on DROP. We release our prompts and outputs on\nthese benchmarks as a new instruction tuning dataset for future research at\nhttps://huggingface.co/datasets/kagnlp/Chain-of-Evidences/.", "published": "2024-01-11 09:49:15", "link": "http://arxiv.org/abs/2401.05787v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Boosting Many-to-Many Multilingual Machine Translation with\n  Large Language Models", "abstract": "The training paradigm for machine translation has gradually shifted, from\nlearning neural machine translation (NMT) models with extensive parallel\ncorpora to instruction finetuning on multilingual large language models (LLMs)\nwith high-quality translation pairs. In this paper, we focus on boosting\nmany-to-many multilingual translation of LLMs with an emphasis on zero-shot\ntranslation directions. We demonstrate that prompt strategies adopted during\nfinetuning are crucial to zero-shot translation and introduce a cross-lingual\nconsistency regularization, XConST, to bridge the representation gap among\ndifferent languages and improve zero-shot translation performance. XConST is\nnot a new method, but a version of CrossConST (Gao et al., 2023a) adapted for\ntranslation instruction finetuning with LLMs. Experimental results on ALMA (Xu\net al., 2023), Tower (Team, 2024), and LLaMA-2 (Touvron et al., 2023) show that\nour approach consistently improves translation performance. Our implementations\nare available at https://github.com/gpengzhi/CrossConST-LLM.", "published": "2024-01-11 12:11:30", "link": "http://arxiv.org/abs/2401.05861v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Personality Recognition in Dialogue by Data Augmentation and\n  Heterogeneous Conversational Graph Networks", "abstract": "Personality recognition is useful for enhancing robots' ability to tailor\nuser-adaptive responses, thus fostering rich human-robot interactions. One of\nthe challenges in this task is a limited number of speakers in existing\ndialogue corpora, which hampers the development of robust, speaker-independent\npersonality recognition models. Additionally, accurately modeling both the\ninterdependencies among interlocutors and the intra-dependencies within the\nspeaker in dialogues remains a significant issue. To address the first\nchallenge, we introduce personality trait interpolation for speaker data\naugmentation. For the second, we propose heterogeneous conversational graph\nnetworks to independently capture both contextual influences and inherent\npersonality traits. Evaluations on the RealPersonaChat corpus demonstrate our\nmethod's significant improvements over existing baselines.", "published": "2024-01-11 12:27:33", "link": "http://arxiv.org/abs/2401.05871v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Deduplication For Socia Media Data Selection", "abstract": "Social media data exhibits severe redundancy caused by its noisy nature. It\nleads to increased training time and model bias in its processing. To address\nthis issue, we propose a novel Generative Deduplication framework for social\nmedia data selection by removing semantically duplicate data. While related\nwork involves data selection in task-specific training, our model acts as an\nefficient pre-processing method to universally enhance social media NLP\npipelines. Specifically, we train a generative model via self-supervised\nlearning to predict a keyword to capture the semantics of noisy social media\ntext for deduplication. Meanwhile, time-dimensional Gaussian noise is added to\nimprove training complexity and avoid learning trivial features. Extensive\nexperiments suggest that our model can better reduce training samples while\nimproving performance than baselines. The results show our model's potential to\nbroadly advance social media language understanding in effectiveness and\nefficiency.", "published": "2024-01-11 12:43:26", "link": "http://arxiv.org/abs/2401.05883v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-based mental health screening from social media text", "abstract": "This article presents a method for prompt-based mental health screening from\na large and noisy dataset of social media text. Our method uses GPT 3.5.\nprompting to distinguish publications that may be more relevant to the task,\nand then uses a straightforward bag-of-words text classifier to predict actual\nuser labels. Results are found to be on pair with a BERT mixture of experts\nclassifier, and incurring only a fraction of its training costs.", "published": "2024-01-11 13:44:28", "link": "http://arxiv.org/abs/2401.05912v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Unhelpfulness in Emotional Support Conversations with\n  Multifaceted AI Feedback", "abstract": "An emotional support conversation system aims to alleviate users' emotional\ndistress and assist them in addressing their challenges. To generate supportive\nresponses, it is critical to consider multiple factors such as empathy, support\nstrategies, and response coherence, as established in prior methods.\nNonetheless, previous models occasionally generate unhelpful responses, which\nintend to provide support but display counterproductive effects. According to\npsychology and communication theories, poor performance in just one\ncontributing factor might cause a response to be unhelpful. From the model\ntraining perspective, since these models have not been exposed to unhelpful\nresponses during their training phase, they are unable to distinguish if the\ntokens they generate might result in unhelpful responses during inference. To\naddress this issue, we introduce a novel model-agnostic framework named\nmitigating unhelpfulness with multifaceted AI feedback for emotional support\n(Muffin). Specifically, Muffin employs a multifaceted AI feedback module to\nassess the helpfulness of responses generated by a specific model with\nconsideration of multiple factors. Using contrastive learning, it then reduces\nthe likelihood of the model generating unhelpful responses compared to the\nhelpful ones. Experimental results demonstrate that Muffin effectively\nmitigates the generation of unhelpful responses while slightly increasing\nresponse fluency and relevance.", "published": "2024-01-11 14:07:47", "link": "http://arxiv.org/abs/2401.05928v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be\n  Detected?", "abstract": "With the rapid development and widespread application of Large Language\nModels (LLMs), the use of Machine-Generated Text (MGT) has become increasingly\ncommon, bringing with it potential risks, especially in terms of quality and\nintegrity in fields like news, education, and science. Current research mainly\nfocuses on purely MGT detection without adequately addressing mixed scenarios,\nincluding AI-revised Human-Written Text (HWT) or human-revised MGT. To tackle\nthis challenge, we define mixtext, a form of mixed text involving both AI and\nhuman-generated content. Then, we introduce MixSet, the first dataset dedicated\nto studying these mixtext scenarios. Leveraging MixSet, we executed\ncomprehensive experiments to assess the efficacy of prevalent MGT detectors in\nhandling mixtext situations, evaluating their performance in terms of\neffectiveness, robustness, and generalization. Our findings reveal that\nexisting detectors struggle to identify mixtext, particularly in dealing with\nsubtle modifications and style adaptability. This research underscores the\nurgent need for more fine-grain detectors tailored for mixtext, offering\nvaluable insights for future research. Code and Models are available at\nhttps://github.com/Dongping-Chen/MixSet.", "published": "2024-01-11 14:44:08", "link": "http://arxiv.org/abs/2401.05952v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LinguAlchemy: Fusing Typological and Geographical Elements for Unseen\n  Language Generalization", "abstract": "Pretrained language models (PLMs) have become remarkably adept at task and\nlanguage generalization. Nonetheless, they often fail when faced with unseen\nlanguages. In this work, we present LinguAlchemy, a regularization method that\nincorporates various linguistic information covering typological, geographical,\nand phylogenetic features to align PLMs representation to the corresponding\nlinguistic information on each language. Our LinguAlchemy significantly\nimproves the performance of mBERT and XLM-R on low-resource languages in\nmultiple downstream tasks such as intent classification, news classification,\nand semantic relatedness compared to fully finetuned models and displaying a\nhigh degree of unseen language generalization. We further introduce\nAlchemyScale and AlchemyTune, extension of LinguAlchemy which adjusts the\nlinguistic regularization weights automatically, alleviating the need for\nhyperparameter search.", "published": "2024-01-11 16:48:00", "link": "http://arxiv.org/abs/2401.06034v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeepSeekMoE: Towards Ultimate Expert Specialization in\n  Mixture-of-Experts Language Models", "abstract": "In the era of large language models, Mixture-of-Experts (MoE) is a promising\narchitecture for managing computational costs when scaling up model parameters.\nHowever, conventional MoE architectures like GShard, which activate the top-$K$\nout of $N$ experts, face challenges in ensuring expert specialization, i.e.\neach expert acquires non-overlapping and focused knowledge. In response, we\npropose the DeepSeekMoE architecture towards ultimate expert specialization. It\ninvolves two principal strategies: (1) finely segmenting the experts into $mN$\nones and activating $mK$ from them, allowing for a more flexible combination of\nactivated experts; (2) isolating $K_s$ experts as shared ones, aiming at\ncapturing common knowledge and mitigating redundancy in routed experts.\nStarting from a modest scale with 2B parameters, we demonstrate that\nDeepSeekMoE 2B achieves comparable performance with GShard 2.9B, which has 1.5\ntimes the expert parameters and computation. In addition, DeepSeekMoE 2B nearly\napproaches the performance of its dense counterpart with the same number of\ntotal parameters, which set the upper bound of MoE models. Subsequently, we\nscale up DeepSeekMoE to 16B parameters and show that it achieves comparable\nperformance with LLaMA2 7B, with only about 40% of computations. Further, our\npreliminary efforts to scale up DeepSeekMoE to 145B parameters consistently\nvalidate its substantial advantages over the GShard architecture, and show its\nperformance comparable with DeepSeek 67B, using only 28.5% (maybe even 18.2%)\nof computations.", "published": "2024-01-11 17:31:42", "link": "http://arxiv.org/abs/2401.06066v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Large Language Models via Fine-grained Reinforcement Learning\n  with Minimum Editing Constraint", "abstract": "Reinforcement learning (RL) has been widely used in training large language\nmodels (LLMs) for preventing unexpected outputs, eg reducing harmfulness and\nerrors. However, existing RL methods mostly adopt the instance-level reward,\nwhich is unable to provide fine-grained supervision for complex reasoning\ntasks, and can not focus on the few key tokens that lead to the incorrectness.\nTo address it, we propose a new RL method named RLMEC that incorporates a\ngenerative model as the reward model, which is trained by the erroneous\nsolution rewriting task under the minimum editing constraint, and can produce\ntoken-level rewards for RL training. Based on the generative reward model, we\ndesign the token-level RL objective for training and an imitation-based\nregularization for stabilizing RL process. And the both objectives focus on the\nlearning of the key tokens for the erroneous solution, reducing the effect of\nother unimportant tokens. The experiment results on mathematical tasks and\nquestion-answering tasks have demonstrated the effectiveness of our approach.\nOur code and data are available at https://github.com/RUCAIBox/RLMEC.", "published": "2024-01-11 17:58:41", "link": "http://arxiv.org/abs/2401.06081v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformers are Multi-State RNNs", "abstract": "Transformers are considered conceptually different from the previous\ngeneration of state-of-the-art NLP models - recurrent neural networks (RNNs).\nIn this work, we demonstrate that decoder-only transformers can in fact be\nconceptualized as unbounded multi-state RNNs - an RNN variant with unlimited\nhidden state size. We further show that transformers can be converted into\n$\\textit{bounded}$ multi-state RNNs by fixing the size of their hidden state,\neffectively compressing their key-value cache. We introduce a novel,\ntraining-free compression policy - $\\textbf{T}$oken $\\textbf{O}$mission\n$\\textbf{V}$ia $\\textbf{A}$ttention (TOVA). Our experiments with four long\nrange tasks and several LLMs show that TOVA outperforms several baseline\ncompression policies. Particularly, our results are nearly on par with the full\nmodel, using in some cases only $\\frac{1}{8}$ of the original cache size, which\ntranslates to 4.8X higher throughput. Our results shed light on the connection\nbetween transformers and RNNs, and help mitigate one of LLMs' most painful\ncomputational bottlenecks - the size of their key-value cache. We publicly\nrelease our code at https://github.com/schwartz-lab-NLP/TOVA", "published": "2024-01-11 18:35:26", "link": "http://arxiv.org/abs/2401.06104v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed\n  Embeddings", "abstract": "Word embedding is one of the most important components in natural language\nprocessing, but interpreting high-dimensional embeddings remains a challenging\nproblem. To address this problem, Independent Component Analysis (ICA) is\nidentified as an effective solution. ICA-transformed word embeddings reveal\ninterpretable semantic axes; however, the order of these axes are arbitrary. In\nthis study, we focus on this property and propose a novel method, Axis Tour,\nwhich optimizes the order of the axes. Inspired by Word Tour, a one-dimensional\nword embedding method, we aim to improve the clarity of the word embedding\nspace by maximizing the semantic continuity of the axes. Furthermore, we show\nthrough experiments on downstream tasks that Axis Tour yields better or\ncomparable low-dimensional embeddings compared to both PCA and ICA.", "published": "2024-01-11 18:46:12", "link": "http://arxiv.org/abs/2401.06112v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction", "abstract": "To address intricate real-world tasks, there has been a rising interest in\ntool utilization in applications of large language models (LLMs). To develop\nLLM-based agents, it usually requires LLMs to understand many tool functions\nfrom different tool documentation. But these documentations could be diverse,\nredundant or incomplete, which immensely affects the capability of LLMs in\nusing tools. To solve this, we introduce EASYTOOL, a framework transforming\ndiverse and lengthy tool documentation into a unified and concise tool\ninstruction for easier tool usage. EasyTool purifies essential information from\nextensive tool documentation of different sources, and elaborates a unified\ninterface (i.e., tool instruction) to offer standardized tool descriptions and\nfunctionalities for LLM-based agents. Extensive experiments on multiple\ndifferent tasks demonstrate that EasyTool can significantly reduce token\nconsumption and improve the performance of tool utilization in real-world\nscenarios. Our code will be available at\n\\url{https://github.com/microsoft/JARVIS/} in the future.", "published": "2024-01-11 15:45:11", "link": "http://arxiv.org/abs/2401.06201v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LEGOBench: Scientific Leaderboard Generation Benchmark", "abstract": "The ever-increasing volume of paper submissions makes it difficult to stay\ninformed about the latest state-of-the-art research. To address this challenge,\nwe introduce LEGOBench, a benchmark for evaluating systems that generate\nscientific leaderboards. LEGOBench is curated from 22 years of preprint\nsubmission data on arXiv and more than 11k machine learning leaderboards on the\nPapersWithCode portal. We present four graph-based and two language model-based\nleaderboard generation task configurations. We evaluate popular encoder-only\nscientific language models as well as decoder-only large language models across\nthese task configurations. State-of-the-art models showcase significant\nperformance gaps in automatic leaderboard generation on LEGOBench. The code is\navailable on GitHub ( https://github.com/lingo-iitgn/LEGOBench ) and the\ndataset is hosted on OSF (\nhttps://osf.io/9v2py/?view_only=6f91b0b510df498ba01595f8f278f94c ).", "published": "2024-01-11 19:20:27", "link": "http://arxiv.org/abs/2401.06233v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey of Text Classification Techniques and Their\n  Research Applications: Observational and Experimental Insights", "abstract": "The exponential growth of textual data presents substantial challenges in\nmanagement and analysis, notably due to high storage and processing costs. Text\nclassification, a vital aspect of text mining, provides robust solutions by\nenabling efficient categorization and organization of text data. These\ntechniques allow individuals, researchers, and businesses to derive meaningful\npatterns and insights from large volumes of text. This survey paper introduces\na comprehensive taxonomy specifically designed for text classification based on\nresearch fields. The taxonomy is structured into hierarchical levels: research\nfield-based category, research field-based sub-category, methodology-based\ntechnique, methodology sub-technique, and research field applications. We\nemploy a dual evaluation approach: empirical and experimental. Empirically, we\nassess text classification techniques across four critical criteria.\nExperimentally, we compare and rank the methodology sub-techniques within the\nsame methodology technique and within the same overall research field\nsub-category. This structured taxonomy, coupled with thorough evaluations,\nprovides a detailed and nuanced understanding of text classification algorithms\nand their applications, empowering researchers to make informed decisions based\non precise, field-specific insights.", "published": "2024-01-11 08:17:42", "link": "http://arxiv.org/abs/2401.12982v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource\n  Unsupervised Neural Machine Translation", "abstract": "Low-resource languages (LRLs) face challenges in supervised neural machine\ntranslation due to limited parallel data, prompting research into unsupervised\nmethods. Unsupervised neural machine translation (UNMT) methods, including\nback-translation, transfer learning, and pivot-based translation, offer\npractical solutions for LRL translation, but they are hindered by issues like\nsynthetic data noise, language bias, and error propagation, which can\npotentially be mitigated by Large Language Models (LLMs). LLMs have advanced\nNMT with in-context learning (ICL) and supervised fine-tuning methods, but\ninsufficient training data results in poor performance in LRLs. We argue that\nLLMs can mitigate the linguistic noise with auxiliary languages to improve\ntranslations in LRLs. In this paper, we propose Probability-driven Meta-graph\nPrompter (POMP), a novel approach employing a dynamic, sampling-based graph of\nmultiple auxiliary languages to enhance LLMs' translation capabilities for\nLRLs. POMP involves constructing a directed acyclic meta-graph for each source\nlanguage, from which we dynamically sample multiple paths to prompt LLMs to\nmitigate the linguistic noise and improve translations during training. We use\nthe BLEURT metric to evaluate the translations and back-propagate rewards,\nestimated by scores, to update the probabilities of auxiliary languages in the\npaths. Our experiments show significant improvements in the translation quality\nof three LRLs, demonstrating the effectiveness of our approach.", "published": "2024-01-11 00:03:36", "link": "http://arxiv.org/abs/2401.05596v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scaling Laws for Forgetting When Fine-Tuning Large Language Models", "abstract": "We study and quantify the problem of forgetting when fine-tuning pre-trained\nlarge language models (LLMs) on a downstream task. We find that\nparameter-efficient fine-tuning (PEFT) strategies, such as Low-Rank Adapters\n(LoRA), still suffer from catastrophic forgetting. In particular, we identify a\nstrong inverse linear relationship between the fine-tuning performance and the\namount of forgetting when fine-tuning LLMs with LoRA. We further obtain precise\nscaling laws that show forgetting increases as a shifted power law in the\nnumber of parameters fine-tuned and the number of update steps. We also examine\nthe impact of forgetting on knowledge, reasoning, and the safety guardrails\ntrained into Llama 2 7B chat. Our study suggests that forgetting cannot be\navoided through early stopping or by varying the number of parameters\nfine-tuned. We believe this opens up an important safety-critical direction for\nfuture research to evaluate and develop fine-tuning schemes which mitigate\nforgetting", "published": "2024-01-11 00:44:25", "link": "http://arxiv.org/abs/2401.05605v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "The Benefits of a Concise Chain of Thought on Problem-Solving in Large\n  Language Models", "abstract": "In this paper, we introduce Concise Chain-of-Thought (CCoT) prompting. We\ncompared standard CoT and CCoT prompts to see how conciseness impacts response\nlength and correct-answer accuracy. We evaluated this using GPT-3.5 and GPT-4\nwith a multiple-choice question-and-answer (MCQA) benchmark. CCoT reduced\naverage response length by 48.70% for both GPT-3.5 and GPT-4 while having a\nnegligible impact on problem-solving performance. However, on math problems,\nGPT-3.5 with CCoT incurs a performance penalty of 27.69%. Overall, CCoT leads\nto an average per-token cost reduction of 22.67%. All code, data, and\nsupplemental materials are available on GitHub at\nhttps://github.com/matthewrenze/jhu-concise-cot", "published": "2024-01-11 01:52:25", "link": "http://arxiv.org/abs/2401.05618v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "R-BI: Regularized Batched Inputs enhance Incremental Decoding Framework\n  for Low-Latency Simultaneous Speech Translation", "abstract": "Incremental Decoding is an effective framework that enables the use of an\noffline model in a simultaneous setting without modifying the original model,\nmaking it suitable for Low-Latency Simultaneous Speech Translation. However,\nthis framework may introduce errors when the system outputs from incomplete\ninput. To reduce these output errors, several strategies such as Hold-$n$,\nLA-$n$, and SP-$n$ can be employed, but the hyper-parameter $n$ needs to be\ncarefully selected for optimal performance. Moreover, these strategies are more\nsuitable for end-to-end systems than cascade systems. In our paper, we propose\na new adaptable and efficient policy named \"Regularized Batched Inputs\". Our\nmethod stands out by enhancing input diversity to mitigate output errors. We\nsuggest particular regularization techniques for both end-to-end and cascade\nsystems. We conducted experiments on IWSLT Simultaneous Speech Translation\n(SimulST) tasks, which demonstrate that our approach achieves low latency while\nmaintaining no more than 2 BLEU points loss compared to offline systems.\nFurthermore, our SimulST systems attained several new state-of-the-art results\nin various language directions.", "published": "2024-01-11 07:05:02", "link": "http://arxiv.org/abs/2401.05700v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-modal Retrieval for Knowledge-based Visual Question Answering", "abstract": "Knowledge-based Visual Question Answering about Named Entities is a\nchallenging task that requires retrieving information from a multimodal\nKnowledge Base. Named entities have diverse visual representations and are\ntherefore difficult to recognize. We argue that cross-modal retrieval may help\nbridge the semantic gap between an entity and its depictions, and is foremost\ncomplementary with mono-modal retrieval. We provide empirical evidence through\nexperiments with a multimodal dual encoder, namely CLIP, on the recent ViQuAE,\nInfoSeek, and Encyclopedic-VQA datasets. Additionally, we study three different\nstrategies to fine-tune such a model: mono-modal, cross-modal, or joint\ntraining. Our method, which combines mono-and cross-modal retrieval, is\ncompetitive with billion-parameter models on the three datasets, while being\nconceptually simpler and computationally cheaper.", "published": "2024-01-11 08:40:16", "link": "http://arxiv.org/abs/2401.05736v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Shocking Amount of the Web is Machine Translated: Insights from\n  Multi-Way Parallelism", "abstract": "We show that content on the web is often translated into many languages, and\nthe low quality of these multi-way translations indicates they were likely\ncreated using Machine Translation (MT). Multi-way parallel, machine generated\ncontent not only dominates the translations in lower resource languages; it\nalso constitutes a large fraction of the total web content in those languages.\nWe also find evidence of a selection bias in the type of content which is\ntranslated into many languages, consistent with low quality English content\nbeing translated en masse into many lower resource languages, via MT. Our work\nraises serious concerns about training models such as multilingual large\nlanguage models on both monolingual and bilingual data scraped from the web.", "published": "2024-01-11 08:56:13", "link": "http://arxiv.org/abs/2401.05749v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language\n  Model Systems", "abstract": "Large language models (LLMs) have strong capabilities in solving diverse\nnatural language processing tasks. However, the safety and security issues of\nLLM systems have become the major obstacle to their widespread application.\nMany studies have extensively investigated risks in LLM systems and developed\nthe corresponding mitigation strategies. Leading-edge enterprises such as\nOpenAI, Google, Meta, and Anthropic have also made lots of efforts on\nresponsible LLMs. Therefore, there is a growing need to organize the existing\nstudies and establish comprehensive taxonomies for the community. In this\npaper, we delve into four essential modules of an LLM system, including an\ninput module for receiving prompts, a language model trained on extensive\ncorpora, a toolchain module for development and deployment, and an output\nmodule for exporting LLM-generated content. Based on this, we propose a\ncomprehensive taxonomy, which systematically analyzes potential risks\nassociated with each module of an LLM system and discusses the corresponding\nmitigation strategies. Furthermore, we review prevalent benchmarks, aiming to\nfacilitate the risk assessment of LLM systems. We hope that this paper can help\nLLM participants embrace a systematic perspective to build their responsible\nLLM systems.", "published": "2024-01-11 09:29:56", "link": "http://arxiv.org/abs/2401.05778v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Discovering Low-rank Subspaces for Language-agnostic Multilingual\n  Representations", "abstract": "Large pretrained multilingual language models (ML-LMs) have shown remarkable\ncapabilities of zero-shot cross-lingual transfer, without direct cross-lingual\nsupervision. While these results are promising, follow-up works found that,\nwithin the multilingual embedding spaces, there exists strong language identity\ninformation which hinders the expression of linguistic factors shared across\nlanguages. For semantic tasks like cross-lingual sentence retrieval, it is\ndesired to remove such language identity signals to fully leverage semantic\ninformation. In this work, we provide a novel view of projecting away\nlanguage-specific factors from a multilingual embedding space. Specifically, we\ndiscover that there exists a low-rank subspace that primarily encodes\ninformation irrelevant to semantics (e.g., syntactic information). To identify\nthis subspace, we present a simple but effective unsupervised method based on\nsingular value decomposition with multiple monolingual corpora as input. Once\nthe subspace is found, we can directly project the original embeddings into the\nnull space to boost language agnosticism without finetuning. We systematically\nevaluate our method on various tasks including the challenging\nlanguage-agnostic QA retrieval task. Empirical results show that applying our\nmethod consistently leads to improvements over commonly used ML-LMs.", "published": "2024-01-11 09:54:11", "link": "http://arxiv.org/abs/2401.05792v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tuning LLMs with Contrastive Alignment Instructions for Machine\n  Translation in Unseen, Low-resource Languages", "abstract": "This article introduces contrastive alignment instructions (AlignInstruct) to\naddress two challenges in machine translation (MT) on large language models\n(LLMs). One is the expansion of supported languages to previously unseen ones.\nThe second relates to the lack of data in low-resource languages. Model\nfine-tuning through MT instructions (MTInstruct) is a straightforward approach\nto the first challenge. However, MTInstruct is limited by weak cross-lingual\nsignals inherent in the second challenge. AlignInstruct emphasizes\ncross-lingual supervision via a cross-lingual discriminator built using\nstatistical word alignments. Our results based on fine-tuning the BLOOMZ models\n(1b1, 3b, and 7b1) in up to 24 unseen languages showed that: (1) LLMs can\neffectively translate unseen languages using MTInstruct; (2) AlignInstruct led\nto consistent improvements in translation quality across 48 translation\ndirections involving English; (3) Discriminator-based instructions outperformed\ntheir generative counterparts as cross-lingual instructions; (4) AlignInstruct\nimproved performance in 30 zero-shot directions.", "published": "2024-01-11 10:28:17", "link": "http://arxiv.org/abs/2401.05811v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Goal-Oriented Agents for Evolving Problems Observed via\n  Conversation", "abstract": "The objective of this work is to train a chatbot capable of solving evolving\nproblems through conversing with a user about a problem the chatbot cannot\ndirectly observe. The system consists of a virtual problem (in this case a\nsimple game), a simulated user capable of answering natural language questions\nthat can observe and perform actions on the problem, and a Deep Q-Network\n(DQN)-based chatbot architecture. The chatbot is trained with the goal of\nsolving the problem through dialogue with the simulated user using\nreinforcement learning. The contributions of this paper are as follows: a\nproposed architecture to apply a conversational DQN-based agent to evolving\nproblems, an exploration of training methods such as curriculum learning on\nmodel performance and the effect of modified reward functions in the case of\nincreasing environment complexity.", "published": "2024-01-11 10:38:43", "link": "http://arxiv.org/abs/2401.05822v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with\n  Epilepsy Medical Knowledge", "abstract": "With large training datasets and massive amounts of computing sources, large\nlanguage models (LLMs) achieve remarkable performance in comprehensive and\ngenerative ability. Based on those powerful LLMs, the model fine-tuned with\ndomain-specific datasets posseses more specialized knowledge and thus is more\npractical like medical LLMs. However, the existing fine-tuned medical LLMs are\nlimited to general medical knowledge with English language. For\ndisease-specific problems, the model's response is inaccurate and sometimes\neven completely irrelevant, especially when using a language other than\nEnglish. In this work, we focus on the particular disease of Epilepsy with\nJapanese language and introduce a customized LLM termed as EpilepsyLLM. Our\nmodel is trained from the pre-trained LLM by fine-tuning technique using\ndatasets from the epilepsy domain. The datasets contain knowledge of basic\ninformation about disease, common treatment methods and drugs, and important\nnotes in life and work. The experimental results demonstrate that EpilepsyLLM\ncan provide more reliable and specialized medical knowledge responses.", "published": "2024-01-11 13:39:00", "link": "http://arxiv.org/abs/2401.05908v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Teachers Can Use Large Language Models and Bloom's Taxonomy to\n  Create Educational Quizzes", "abstract": "Question generation (QG) is a natural language processing task with an\nabundance of potential benefits and use cases in the educational domain. In\norder for this potential to be realized, QG systems must be designed and\nvalidated with pedagogical needs in mind. However, little research has assessed\nor designed QG approaches with the input from real teachers or students. This\npaper applies a large language model-based QG approach where questions are\ngenerated with learning goals derived from Bloom's taxonomy. The automatically\ngenerated questions are used in multiple experiments designed to assess how\nteachers use them in practice. The results demonstrate that teachers prefer to\nwrite quizzes with automatically generated questions, and that such quizzes\nhave no loss in quality compared to handwritten versions. Further, several\nmetrics indicate that automatically generated questions can even improve the\nquality of the quizzes created, showing the promise for large scale use of QG\nin the classroom setting.", "published": "2024-01-11 13:47:13", "link": "http://arxiv.org/abs/2401.05914v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully", "abstract": "Large language models (LLMs) demonstrate great performance in text\ngeneration. However, LLMs are still suffering from hallucinations. In this\nwork, we propose an inference-time method, Self-Highlighted Hesitation (SH2),\nto help LLMs decode more truthfully. SH2 is based on a simple fact rooted in\ninformation theory that for an LLM, the tokens predicted with lower\nprobabilities are prone to be more informative than others. Our analysis shows\nthat the tokens assigned with lower probabilities by an LLM are more likely to\nbe closely related to factual information, such as nouns, proper nouns, and\nadjectives. Therefore, we propose to ''highlight'' the factual information by\nselecting the tokens with the lowest probabilities and concatenating them to\nthe original context, thus forcing the model to repeatedly read and hesitate on\nthese tokens before generation. During decoding, we also adopt contrastive\ndecoding to emphasize the difference in the output probabilities brought by the\nhesitation. Experimental results demonstrate that our SH2, requiring no\nadditional data or models, can effectively help LLMs elicit factual knowledge\nand distinguish hallucinated contexts. Significant and consistent improvements\nare achieved by SH2 for LLaMA-7b, LLaMA2-7b and Mistral-7b on multiple\nhallucination tasks.", "published": "2024-01-11 14:09:09", "link": "http://arxiv.org/abs/2401.05930v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph\n  Embedding", "abstract": "The primary aim of Knowledge Graph embeddings (KGE) is to learn\nlow-dimensional representations of entities and relations for predicting\nmissing facts. While rotation-based methods like RotatE and QuatE perform well\nin KGE, they face two challenges: limited model flexibility requiring\nproportional increases in relation size with entity dimension, and difficulties\nin generalizing the model for higher-dimensional rotations. To address these\nissues, we introduce OrthogonalE, a novel KGE model employing matrices for\nentities and block-diagonal orthogonal matrices with Riemannian optimization\nfor relations. This approach enhances the generality and flexibility of KGE\nmodels. The experimental results indicate that our new KGE model, OrthogonalE,\nis both general and flexible, significantly outperforming state-of-the-art KGE\nmodels while substantially reducing the number of relation parameters.", "published": "2024-01-11 15:13:00", "link": "http://arxiv.org/abs/2401.05967v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Combating Adversarial Attacks with Multi-Agent Debate", "abstract": "While state-of-the-art language models have achieved impressive results, they\nremain susceptible to inference-time adversarial attacks, such as adversarial\nprompts generated by red teams arXiv:2209.07858. One approach proposed to\nimprove the general quality of language model generations is multi-agent\ndebate, where language models self-evaluate through discussion and feedback\narXiv:2305.14325. We implement multi-agent debate between current\nstate-of-the-art language models and evaluate models' susceptibility to red\nteam attacks in both single- and multi-agent settings. We find that multi-agent\ndebate can reduce model toxicity when jailbroken or less capable models are\nforced to debate with non-jailbroken or more capable models. We also find\nmarginal improvements through the general usage of multi-agent interactions. We\nfurther perform adversarial prompt content classification via embedding\nclustering, and analyze the susceptibility of different models to different\ntypes of attack topics.", "published": "2024-01-11 15:57:38", "link": "http://arxiv.org/abs/2401.05998v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GroundingGPT:Language Enhanced Multi-modal Grounding Model", "abstract": "Multi-modal large language models have demonstrated impressive performance\nacross various tasks in different modalities. However, existing multi-modal\nmodels primarily emphasize capturing global information within each modality\nwhile neglecting the importance of perceiving local information across\nmodalities. Consequently, these models lack the ability to effectively\nunderstand the fine-grained details of input data, limiting their performance\nin tasks that require a more nuanced understanding. To address this limitation,\nthere is a compelling need to develop models that enable fine-grained\nunderstanding across multiple modalities, thereby enhancing their applicability\nto a wide range of tasks. In this paper, we propose GroundingGPT, a language\nenhanced multi-modal grounding model. Beyond capturing global information like\nother multi-modal models, our proposed model excels at tasks demanding a\ndetailed understanding of local information within the input. It demonstrates\nprecise identification and localization of specific regions in images or\nmoments in videos. To achieve this objective, we design a diversified dataset\nconstruction pipeline, resulting in a multi-modal, multi-granularity dataset\nfor model training. The code, dataset, and demo of our model can be found at\nhttps: //github.com/lzw-lzw/GroundingGPT.", "published": "2024-01-11 17:41:57", "link": "http://arxiv.org/abs/2401.06071v5", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Chain of History: Learning and Forecasting with LLMs for Temporal\n  Knowledge Graph Completion", "abstract": "Temporal Knowledge Graph Completion (TKGC) is a complex task involving the\nprediction of missing event links at future timestamps by leveraging\nestablished temporal structural knowledge. This paper aims to provide a\ncomprehensive perspective on harnessing the advantages of Large Language Models\n(LLMs) for reasoning in temporal knowledge graphs, presenting an easily\ntransferable pipeline. In terms of graph modality, we underscore the LLMs'\nprowess in discerning the structural information of pivotal nodes within the\nhistorical chain. As for the generation mode of the LLMs utilized for\ninference, we conduct an exhaustive exploration into the variances induced by a\nrange of inherent factors in LLMs, with particular attention to the challenges\nin comprehending reverse logic. We adopt a parameter-efficient fine-tuning\nstrategy to harmonize the LLMs with the task requirements, facilitating the\nlearning of the key knowledge highlighted earlier. Comprehensive experiments\nare undertaken on several widely recognized datasets, revealing that our\nframework exceeds or parallels existing methods across numerous popular\nmetrics. Additionally, we execute a substantial range of ablation experiments\nand draw comparisons with several advanced commercial LLMs, to investigate the\ncrucial factors influencing LLMs' performance in structured temporal knowledge\ninference tasks.", "published": "2024-01-11 17:42:47", "link": "http://arxiv.org/abs/2401.06072v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Extreme Compression of Large Language Models via Additive Quantization", "abstract": "The emergence of accurate open large language models (LLMs) has led to a race\ntowards performant quantization techniques which can enable their execution on\nend-user devices. In this paper, we revisit the problem of \"extreme\" LLM\ncompression-defined as targeting extremely low bit counts, such as 2 to 3 bits\nper parameter-from the point of view of classic methods in Multi-Codebook\nQuantization (MCQ). Our algorithm, called AQLM, generalizes the classic\nAdditive Quantization (AQ) approach for information retrieval to advance the\nstate-of-the-art in LLM compression, via two innovations: 1) learned additive\nquantization of weight matrices in input-adaptive fashion, and 2) joint\noptimization of codebook parameters across each transformer blocks. Broadly,\nAQLM is the first scheme that is Pareto optimal in terms of\naccuracy-vs-model-size when compressing to less than 3 bits per parameter, and\nsignificantly improves upon all known schemes in the extreme compression (2bit)\nregime. In addition, AQLM is practical: we provide fast GPU and CPU\nimplementations of AQLM for token generation, which enable us to match or\noutperform optimized FP16 implementations for speed, while executing in a much\nsmaller memory footprint.", "published": "2024-01-11 18:54:44", "link": "http://arxiv.org/abs/2401.06118v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "TOFU: A Task of Fictitious Unlearning for LLMs", "abstract": "Large language models trained on massive corpora of data from the web can\nmemorize and reproduce sensitive or private data raising both legal and ethical\nconcerns. Unlearning, or tuning models to forget information present in their\ntraining data, provides us with a way to protect private data after training.\nAlthough several methods exist for such unlearning, it is unclear to what\nextent they result in models equivalent to those where the data to be forgotten\nwas never learned in the first place. To address this challenge, we present\nTOFU, a Task of Fictitious Unlearning, as a benchmark aimed at helping deepen\nour understanding of unlearning. We offer a dataset of 200 diverse synthetic\nauthor profiles, each consisting of 20 question-answer pairs, and a subset of\nthese profiles called the forget set that serves as the target for unlearning.\nWe compile a suite of metrics that work together to provide a holistic picture\nof unlearning efficacy. Finally, we provide a set of baseline results from\nexisting unlearning algorithms. Importantly, none of the baselines we consider\nshow effective unlearning motivating continued efforts to develop approaches\nfor unlearning that effectively tune models so that they truly behave as if\nthey were never trained on the forget data at all.", "published": "2024-01-11 18:57:12", "link": "http://arxiv.org/abs/2401.06121v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Analyzing Regional Impacts of Climate Change using Natural Language\n  Processing Techniques", "abstract": "Understanding the multifaceted effects of climate change across diverse\ngeographic locations is crucial for timely adaptation and the development of\neffective mitigation strategies. As the volume of scientific literature on this\ntopic continues to grow exponentially, manually reviewing these documents has\nbecome an immensely challenging task. Utilizing Natural Language Processing\n(NLP) techniques to analyze this wealth of information presents an efficient\nand scalable solution. By gathering extensive amounts of peer-reviewed articles\nand studies, we can extract and process critical information about the effects\nof climate change in specific regions. We employ BERT (Bidirectional Encoder\nRepresentations from Transformers) for Named Entity Recognition (NER), which\nenables us to efficiently identify specific geographies within the climate\nliterature. This, in turn, facilitates location-specific analyses. We conduct\nregion-specific climate trend analyses to pinpoint the predominant themes or\nconcerns related to climate change within a particular area, trace the temporal\nprogression of these identified issues, and evaluate their frequency, severity,\nand potential development over time. These in-depth examinations of\nlocation-specific climate data enable the creation of more customized\npolicy-making, adaptation, and mitigation strategies, addressing each region's\nunique challenges and providing more effective solutions rooted in data-driven\ninsights. This approach, founded on a thorough exploration of scientific texts,\noffers actionable insights to a wide range of stakeholders, from policymakers\nto engineers to environmentalists. By proactively understanding these impacts,\nsocieties are better positioned to prepare, allocate resources wisely, and\ndesign tailored strategies to cope with future climate conditions, ensuring a\nmore resilient future for all.", "published": "2024-01-11 16:44:59", "link": "http://arxiv.org/abs/2401.06817v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "REBUS: A Robust Evaluation Benchmark of Understanding Symbols", "abstract": "We propose a new benchmark evaluating the performance of multimodal large\nlanguage models on rebus puzzles. The dataset covers 333 original examples of\nimage-based wordplay, cluing 13 categories such as movies, composers, major\ncities, and food. To achieve good performance on the benchmark of identifying\nthe clued word or phrase, models must combine image recognition and string\nmanipulation with hypothesis testing, multi-step reasoning, and an\nunderstanding of human cognition, making for a complex, multimodal evaluation\nof capabilities. We find that GPT-4o significantly outperforms all other\nmodels, followed by proprietary models outperforming all other evaluated\nmodels. However, even the best model has a final accuracy of only 42\\%, which\ngoes down to just 7\\% on hard puzzles, highlighting the need for substantial\nimprovements in reasoning. Further, models rarely understand all parts of a\npuzzle, and are almost always incapable of retroactively explaining the correct\nanswer. Our benchmark can therefore be used to identify major shortcomings in\nthe knowledge and reasoning of multimodal large language models.", "published": "2024-01-11 00:30:28", "link": "http://arxiv.org/abs/2401.05604v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Towards Conversational Diagnostic AI", "abstract": "At the heart of medicine lies the physician-patient dialogue, where skillful\nhistory-taking paves the way for accurate diagnosis, effective management, and\nenduring trust. Artificial Intelligence (AI) systems capable of diagnostic\ndialogue could increase accessibility, consistency, and quality of care.\nHowever, approximating clinicians' expertise is an outstanding grand challenge.\nHere, we introduce AMIE (Articulate Medical Intelligence Explorer), a Large\nLanguage Model (LLM) based AI system optimized for diagnostic dialogue.\n  AMIE uses a novel self-play based simulated environment with automated\nfeedback mechanisms for scaling learning across diverse disease conditions,\nspecialties, and contexts. We designed a framework for evaluating\nclinically-meaningful axes of performance including history-taking, diagnostic\naccuracy, management reasoning, communication skills, and empathy. We compared\nAMIE's performance to that of primary care physicians (PCPs) in a randomized,\ndouble-blind crossover study of text-based consultations with validated patient\nactors in the style of an Objective Structured Clinical Examination (OSCE). The\nstudy included 149 case scenarios from clinical providers in Canada, the UK,\nand India, 20 PCPs for comparison with AMIE, and evaluations by specialist\nphysicians and patient actors. AMIE demonstrated greater diagnostic accuracy\nand superior performance on 28 of 32 axes according to specialist physicians\nand 24 of 26 axes according to patient actors. Our research has several\nlimitations and should be interpreted with appropriate caution. Clinicians were\nlimited to unfamiliar synchronous text-chat which permits large-scale\nLLM-patient interactions but is not representative of usual clinical practice.\nWhile further research is required before AMIE could be translated to\nreal-world settings, the results represent a milestone towards conversational\ndiagnostic AI.", "published": "2024-01-11 04:25:06", "link": "http://arxiv.org/abs/2401.05654v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "UCorrect: An Unsupervised Framework for Automatic Speech Recognition\n  Error Correction", "abstract": "Error correction techniques have been used to refine the output sentences\nfrom automatic speech recognition (ASR) models and achieve a lower word error\nrate (WER). Previous works usually adopt end-to-end models and has strong\ndependency on Pseudo Paired Data and Original Paired Data. But when only\npre-training on Pseudo Paired Data, previous models have negative effect on\ncorrection. While fine-tuning on Original Paired Data, the source side data\nmust be transcribed by a well-trained ASR model, which takes a lot of time and\nnot universal. In this paper, we propose UCorrect, an unsupervised\nDetector-Generator-Selector framework for ASR Error Correction. UCorrect has no\ndependency on the training data mentioned before. The whole procedure is first\nto detect whether the character is erroneous, then to generate some candidate\ncharacters and finally to select the most confident one to replace the error\ncharacter. Experiments on the public AISHELL-1 dataset and WenetSpeech dataset\nshow the effectiveness of UCorrect for ASR error correction: 1) it achieves\nsignificant WER reduction, achieves 6.83\\% even without fine-tuning and 14.29\\%\nafter fine-tuning; 2) it outperforms the popular NAR correction models by a\nlarge margin with a competitive low latency; and 3) it is an universal method,\nas it reduces all WERs of the ASR model with different decoding strategies and\nreduces all WERs of ASR models trained on different scale datasets.", "published": "2024-01-11 06:30:07", "link": "http://arxiv.org/abs/2401.05689v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis", "abstract": "Large language models (LLMs) have drastically changed the possible ways to\ndesign intelligent systems, shifting the focuses from massive data acquisition\nand new modeling training to human alignment and strategical elicitation of the\nfull potential of existing pre-trained models. This paradigm shift, however, is\nnot fully realized in financial sentiment analysis (FSA), due to the\ndiscriminative nature of this task and a lack of prescriptive knowledge of how\nto leverage generative models in such a context. This study investigates the\neffectiveness of the new paradigm, i.e., using LLMs without fine-tuning for\nFSA. Rooted in Minsky's theory of mind and emotions, a design framework with\nheterogeneous LLM agents is proposed. The framework instantiates specialized\nagents using prior domain knowledge of the types of FSA errors and reasons on\nthe aggregated agent discussions. Comprehensive evaluation on FSA datasets show\nthat the framework yields better accuracies, especially when the discussions\nare substantial. This study contributes to the design foundations and paves new\navenues for LLMs-based FSA. Implications on business and management are also\ndiscussed.", "published": "2024-01-11 10:06:42", "link": "http://arxiv.org/abs/2401.05799v1", "categories": ["cs.CL", "cs.AI", "cs.MA", "q-fin.GN"], "primary_category": "cs.CL"}
{"title": "Hallucination Benchmark in Medical Visual Question Answering", "abstract": "The recent success of large language and vision models (LLVMs) on vision\nquestion answering (VQA), particularly their applications in medicine\n(Med-VQA), has shown a great potential of realizing effective visual assistants\nfor healthcare. However, these models are not extensively tested on the\nhallucination phenomenon in clinical settings. Here, we created a hallucination\nbenchmark of medical images paired with question-answer sets and conducted a\ncomprehensive evaluation of the state-of-the-art models. The study provides an\nin-depth analysis of current models' limitations and reveals the effectiveness\nof various prompting strategies.", "published": "2024-01-11 10:52:17", "link": "http://arxiv.org/abs/2401.05827v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Inferring Intentions to Speak Using Accelerometer Data In-the-Wild", "abstract": "Humans have good natural intuition to recognize when another person has\nsomething to say. It would be interesting if an AI can also recognize\nintentions to speak. Especially in scenarios when an AI is guiding a group\ndiscussion, this can be a useful skill. This work studies the inference of\nsuccessful and unsuccessful intentions to speak from accelerometer data. This\nis chosen because it is privacy-preserving and feasible for in-the-wild\nsettings since it can be placed in a smart badge. Data from a real-life social\nnetworking event is used to train a machine-learning model that aims to infer\nintentions to speak. A subset of unsuccessful intention-to-speak cases in the\ndata is annotated. The model is trained on the successful intentions to speak\nand evaluated on both the successful and unsuccessful cases. In conclusion,\nthere is useful information in accelerometer data, but not enough to reliably\ncapture intentions to speak. For example, posture shifts are correlated with\nintentions to speak, but people also often shift posture without having an\nintention to speak, or have an intention to speak without shifting their\nposture. More modalities are likely needed to reliably infer intentions to\nspeak.", "published": "2024-01-11 11:38:21", "link": "http://arxiv.org/abs/2401.05849v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC", "I.5.5; I.2.6"], "primary_category": "cs.LG"}
{"title": "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for\n  In-context Learning", "abstract": "In-context learning, a paradigm bridging the gap between pre-training and\nfine-tuning, has demonstrated high efficacy in several NLP tasks, especially in\nfew-shot settings. Despite being widely applied, in-context learning is\nvulnerable to malicious attacks. In this work, we raise security concerns\nregarding this paradigm. Our studies demonstrate that an attacker can\nmanipulate the behavior of large language models by poisoning the demonstration\ncontext, without the need for fine-tuning the model. Specifically, we design a\nnew backdoor attack method, named ICLAttack, to target large language models\nbased on in-context learning. Our method encompasses two types of attacks:\npoisoning demonstration examples and poisoning demonstration prompts, which can\nmake models behave in alignment with predefined intentions. ICLAttack does not\nrequire additional fine-tuning to implant a backdoor, thus preserving the\nmodel's generality. Furthermore, the poisoned examples are correctly labeled,\nenhancing the natural stealth of our attack method. Extensive experimental\nresults across several language models, ranging in size from 1.3B to 180B\nparameters, demonstrate the effectiveness of our attack method, exemplified by\na high average attack success rate of 95.0% across the three datasets on OPT\nmodels.", "published": "2024-01-11 14:38:19", "link": "http://arxiv.org/abs/2401.05949v6", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Investigating Data Contamination for Pre-training Language Models", "abstract": "Language models pre-trained on web-scale corpora demonstrate impressive\ncapabilities on diverse downstream tasks. However, there is increasing concern\nwhether such capabilities might arise from evaluation datasets being included\nin the pre-training corpus -- a phenomenon known as \\textit{data contamination}\n-- in a manner that artificially increases performance. There has been little\nunderstanding of how this potential contamination might influence LMs'\nperformance on downstream tasks. In this paper, we explore the impact of data\ncontamination at the pre-training stage by pre-training a series of GPT-2\nmodels \\textit{from scratch}. We highlight the effect of both text\ncontamination (\\textit{i.e.}\\ input text of the evaluation samples) and\nground-truth contamination (\\textit{i.e.}\\ the prompts asked on the input and\nthe desired outputs) from evaluation data. We also investigate the effects of\nrepeating contamination for various downstream tasks. Additionally, we examine\nthe prevailing n-gram-based definitions of contamination within current LLM\nreports, pinpointing their limitations and inadequacy. Our findings offer new\ninsights into data contamination's effects on language model capabilities and\nunderscore the need for independent, comprehensive contamination assessments in\nLLM studies.", "published": "2024-01-11 17:24:49", "link": "http://arxiv.org/abs/2401.06059v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Autocompletion of Chief Complaints in the Electronic Health Records\n  using Large Language Models", "abstract": "The Chief Complaint (CC) is a crucial component of a patient's medical record\nas it describes the main reason or concern for seeking medical care. It\nprovides critical information for healthcare providers to make informed\ndecisions about patient care. However, documenting CCs can be time-consuming\nfor healthcare providers, especially in busy emergency departments. To address\nthis issue, an autocompletion tool that suggests accurate and well-formatted\nphrases or sentences for clinical notes can be a valuable resource for triage\nnurses. In this study, we utilized text generation techniques to develop\nmachine learning models using CC data. In our proposed work, we train a Long\nShort-Term Memory (LSTM) model and fine-tune three different variants of\nBiomedical Generative Pretrained Transformers (BioGPT), namely\nmicrosoft/biogpt, microsoft/BioGPT-Large, and microsoft/BioGPT-Large-PubMedQA.\nAdditionally, we tune a prompt by incorporating exemplar CC sentences,\nutilizing the OpenAI API of GPT-4. We evaluate the models' performance based on\nthe perplexity score, modified BERTScore, and cosine similarity score. The\nresults show that BioGPT-Large exhibits superior performance compared to the\nother models. It consistently achieves a remarkably low perplexity score of\n1.65 when generating CC, whereas the baseline LSTM model achieves the best\nperplexity score of 170. Further, we evaluate and assess the proposed models'\nperformance and the outcome of GPT-4.0. Our study demonstrates that utilizing\nLLMs such as BioGPT, leads to the development of an effective autocompletion\ntool for generating CC documentation in healthcare settings.", "published": "2024-01-11 18:06:30", "link": "http://arxiv.org/abs/2401.06088v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Patchscopes: A Unifying Framework for Inspecting Hidden Representations\n  of Language Models", "abstract": "Understanding the internal representations of large language models (LLMs)\ncan help explain models' behavior and verify their alignment with human values.\nGiven the capabilities of LLMs in generating human-understandable text, we\npropose leveraging the model itself to explain its internal representations in\nnatural language. We introduce a framework called Patchscopes and show how it\ncan be used to answer a wide range of questions about an LLM's computation. We\nshow that many prior interpretability methods based on projecting\nrepresentations into the vocabulary space and intervening on the LLM\ncomputation can be viewed as instances of this framework. Moreover, several of\ntheir shortcomings such as failure in inspecting early layers or lack of\nexpressivity can be mitigated by Patchscopes. Beyond unifying prior inspection\ntechniques, Patchscopes also opens up new possibilities such as using a more\ncapable model to explain the representations of a smaller model, and multihop\nreasoning error correction.", "published": "2024-01-11 18:33:48", "link": "http://arxiv.org/abs/2401.06102v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PALP: Prompt Aligned Personalization of Text-to-Image Models", "abstract": "Content creators often aim to create personalized images using personal\nsubjects that go beyond the capabilities of conventional text-to-image models.\nAdditionally, they may want the resulting image to encompass a specific\nlocation, style, ambiance, and more. Existing personalization methods may\ncompromise personalization ability or the alignment to complex textual prompts.\nThis trade-off can impede the fulfillment of user prompts and subject fidelity.\nWe propose a new approach focusing on personalization methods for a\n\\emph{single} prompt to address this issue. We term our approach prompt-aligned\npersonalization. While this may seem restrictive, our method excels in\nimproving text alignment, enabling the creation of images with complex and\nintricate prompts, which may pose a challenge for current techniques. In\nparticular, our method keeps the personalized model aligned with a target\nprompt using an additional score distillation sampling term. We demonstrate the\nversatility of our method in multi- and single-shot settings and further show\nthat it can compose multiple subjects or use inspiration from reference images,\nsuch as artworks. We compare our approach quantitatively and qualitatively with\nexisting baselines and state-of-the-art techniques.", "published": "2024-01-11 18:35:33", "link": "http://arxiv.org/abs/2401.06105v1", "categories": ["cs.CV", "cs.CL", "cs.GR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "End to end Hindi to English speech conversion using Bark, mBART and a\n  finetuned XLSR Wav2Vec2", "abstract": "Speech has long been a barrier to effective communication and connection,\npersisting as a challenge in our increasingly interconnected world. This\nresearch paper introduces a transformative solution to this persistent obstacle\nan end-to-end speech conversion framework tailored for Hindi-to-English\ntranslation, culminating in the synthesis of English audio. By integrating\ncutting-edge technologies such as XLSR Wav2Vec2 for automatic speech\nrecognition (ASR), mBART for neural machine translation (NMT), and a\nText-to-Speech (TTS) synthesis component, this framework offers a unified and\nseamless approach to cross-lingual communication. We delve into the intricate\ndetails of each component, elucidating their individual contributions and\nexploring the synergies that enable a fluid transition from spoken Hindi to\nsynthesized English audio.", "published": "2024-01-11 04:26:21", "link": "http://arxiv.org/abs/2401.06183v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "CrisisKAN: Knowledge-infused and Explainable Multimodal Attention\n  Network for Crisis Event Classification", "abstract": "Pervasive use of social media has become the emerging source for real-time\ninformation (like images, text, or both) to identify various events. Despite\nthe rapid growth of image and text-based event classification, the\nstate-of-the-art (SOTA) models find it challenging to bridge the semantic gap\nbetween features of image and text modalities due to inconsistent encoding.\nAlso, the black-box nature of models fails to explain the model's outcomes for\nbuilding trust in high-stakes situations such as disasters, pandemic.\nAdditionally, the word limit imposed on social media posts can potentially\nintroduce bias towards specific events. To address these issues, we proposed\nCrisisKAN, a novel Knowledge-infused and Explainable Multimodal Attention\nNetwork that entails images and texts in conjunction with external knowledge\nfrom Wikipedia to classify crisis events. To enrich the context-specific\nunderstanding of textual information, we integrated Wikipedia knowledge using\nproposed wiki extraction algorithm. Along with this, a guided cross-attention\nmodule is implemented to fill the semantic gap in integrating visual and\ntextual data. In order to ensure reliability, we employ a model-specific\napproach called Gradient-weighted Class Activation Mapping (Grad-CAM) that\nprovides a robust explanation of the predictions of the proposed model. The\ncomprehensive experiments conducted on the CrisisMMD dataset yield in-depth\nanalysis across various crisis-specific tasks and settings. As a result,\nCrisisKAN outperforms existing SOTA methodologies and provides a novel view in\nthe domain of explainable multimodal event classification.", "published": "2024-01-11 13:22:38", "link": "http://arxiv.org/abs/2401.06194v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning Unsupervised Semantic Document Representation for Fine-grained\n  Aspect-based Sentiment Analysis", "abstract": "Document representation is the core of many NLP tasks on machine\nunderstanding. A general representation learned in an unsupervised manner\nreserves generality and can be used for various applications. In practice,\nsentiment analysis (SA) has been a challenging task that is regarded to be\ndeeply semantic-related and is often used to assess general representations.\nExisting methods on unsupervised document representation learning can be\nseparated into two families: sequential ones, which explicitly take the\nordering of words into consideration, and non-sequential ones, which do not\nexplicitly do so. However, both of them suffer from their own weaknesses. In\nthis paper, we propose a model that overcomes difficulties encountered by both\nfamilies of methods. Experiments show that our model outperforms\nstate-of-the-art methods on popular SA datasets and a fine-grained aspect-based\nSA by a large margin.", "published": "2024-01-11 18:59:52", "link": "http://arxiv.org/abs/2401.06210v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "UniRQR: A Unified Model for Retrieval Decision, Query, and Response\n  Generation in Internet-Based Knowledge Dialogue Systems", "abstract": "Knowledge-based dialogue systems with internet retrieval have recently\nattracted considerable attention from researchers. The dialogue systems\novercome a major limitation of traditional knowledge dialogue systems, where\nthe timeliness of knowledge cannot be assured, hence providing greater\npractical application value. Knowledge-based dialogue systems with internet\nretrieval can be typically segmented into three tasks: Retrieval Decision,\nQuery Generation, and Response Generation. However, many of studies assumed\nthat all conversations require external knowledge to continue, neglecting the\ncritical step of determining when retrieval is necessary. This assumption often\nleads to an over-dependence on external knowledge, even when it may not be\nrequired. Our work addresses this oversight by employing a single unified model\nfacilitated by prompt and multi-task learning approaches. This model not only\ndecides whether retrieval is necessary but also generates retrieval queries and\nresponses. By integrating these functions, our system leverages the full\npotential of pre-trained models and reduces the complexity and costs associated\nwith deploying multiple models. We conducted extensive experiments to\ninvestigate the mutual enhancement among the three tasks in our system. What is\nmore, the experiment results on the Wizint and Dusinc datasets not only\ndemonstrate that our unified model surpasses the baseline performance for\nindividual tasks, but also reveal that it achieves comparable results when\ncontrasted with SOTA systems that deploy separate, specialized models for each\ntask.", "published": "2024-01-11 06:09:15", "link": "http://arxiv.org/abs/2401.06811v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "When ChatGPT is gone: Creativity reverts and homogeneity persists", "abstract": "ChatGPT has been evidenced to enhance human performance in creative tasks.\nYet, it is still unclear if this boosting effect sustains with and without\nChatGPT. In a pre-registered seven-day lab experiment and a follow-up survey\nafter 30 days of experiment completion, we examined the impacts of ChatGPT\npresence and absence on sustained creativity using a text dataset of 3302\ncreative ideas and 427 creative solutions from 61 college students.\nParticipants in the treatment group used ChatGPT in creative tasks, while those\nin the control group completed the tasks by themselves. The findings show that\nalthough the boosting effect of ChatGPT was consistently observed over a\nfive-day creative journey, human creative performance reverted to baseline when\nChatGPT was down on the 7th and the 30th day. More critically, the use of\nChatGPT in creative tasks resulted in increasingly homogenized contents, and\nthis homogenization effect persisted even when ChatGPT was absence. These\nfindings pose a challenge to the prevailing argument that ChatGPT can enhance\nhuman creativity. In fact, generative AI like ChatGPT lends to human with a\ntemporary rise in creative performance but boxes human creative capability in\nthe long run, highlighting the imperative for cautious generative AI\nintegration in creative endeavors.", "published": "2024-01-11 16:34:09", "link": "http://arxiv.org/abs/2401.06816v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "DrawTalking: Building Interactive Worlds by Sketching and Speaking", "abstract": "We introduce DrawTalking, an approach to building and controlling interactive\nworlds by sketching and speaking while telling stories. It emphasizes user\ncontrol and flexibility, and gives programming-like capability without\nrequiring code. An early open-ended study with our prototype shows that the\nmechanics resonate and are applicable to many creative-exploratory use cases,\nwith the potential to inspire and inform research in future natural interfaces\nfor creative exploration and authoring.", "published": "2024-01-11 03:02:17", "link": "http://arxiv.org/abs/2401.05631v4", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.ET", "cs.GR", "H.5.2; D.2.2; I.2.7; D.1.7; H.5.1"], "primary_category": "cs.HC"}
{"title": "Localizing Acoustic Energy in Sound Field Synthesis by Directionally\n  Weighted Exterior Radiation Suppression", "abstract": "A method for synthesizing the desired sound field while suppressing the\nexterior radiation power with directional weighting is proposed. The exterior\nradiation from the loudspeakers in sound field synthesis systems can be\nproblematic in practical situations. Although several methods to suppress the\nexterior radiation have been proposed, suppression in all outward directions is\ngenerally difficult, especially when the number of loudspeakers is not\nsufficiently large. We propose the directionally weighted exterior radiation\nrepresentation to prioritize the suppression directions by incorporating it\ninto the optimization problem of sound field synthesis. By using the proposed\nrepresentation, the exterior radiation in the prioritized directions can be\nsignificantly reduced while maintaining high interior synthesis accuracy, owing\nto the relaxed constraint on the exterior radiation. Its performance is\nevaluated with the application of the proposed representation to amplitude\nmatching in numerical experiments.", "published": "2024-01-11 10:21:47", "link": "http://arxiv.org/abs/2401.05809v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Contrastive Loss Based Frame-wise Feature disentanglement for Polyphonic\n  Sound Event Detection", "abstract": "Overlapping sound events are ubiquitous in real-world environments, but\nexisting end-to-end sound event detection (SED) methods still struggle to\ndetect them effectively. A critical reason is that these methods represent\noverlapping events using shared and entangled frame-wise features, which\ndegrades the feature discrimination. To solve the problem, we propose a\ndisentangled feature learning framework to learn a category-specific\nrepresentation. Specifically, we employ different projectors to learn the\nframe-wise features for each category. To ensure that these feature does not\ncontain information of other categories, we maximize the common information\nbetween frame-wise features within the same category and propose a frame-wise\ncontrastive loss. In addition, considering that the labeled data used by the\nproposed method is limited, we propose a semi-supervised frame-wise contrastive\nloss that can leverage large amounts of unlabeled data to achieve feature\ndisentanglement. The experimental results demonstrate the effectiveness of our\nmethod.", "published": "2024-01-11 11:39:21", "link": "http://arxiv.org/abs/2401.05850v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neural Ambisonics encoding for compact irregular microphone arrays", "abstract": "Ambisonics encoding of microphone array signals can enable various spatial\naudio applications, such as virtual reality or telepresence, but it is\ntypically designed for uniformly-spaced spherical microphone arrays. This paper\nproposes a method for Ambisonics encoding that uses a deep neural network (DNN)\nto estimate a signal transform from microphone inputs to Ambisonics signals.\nThe approach uses a DNN consisting of a U-Net structure with a learnable\npreprocessing as well as a loss function consisting of mean average error,\nspatial correlation, and energy preservation components. The method is\nvalidated on two microphone arrays with regular and irregular shapes having\nfour microphones, on simulated reverberant scenes with multiple sources. The\nresults of the validation show that the proposed method can meet or exceed the\nperformance of a conventional signal-independent Ambisonics encoder on a number\nof error metrics.", "published": "2024-01-11 13:49:54", "link": "http://arxiv.org/abs/2401.05916v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sub-band and Full-band Interactive U-Net with DPRNN for Demixing\n  Cross-talk Stereo Music", "abstract": "This paper presents a detailed description of our proposed methods for the\nICASSP 2024 Cadenza Challenge. Experimental results show that the proposed\nsystem can achieve better performance than official baselines.", "published": "2024-01-11 02:57:37", "link": "http://arxiv.org/abs/2401.08678v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Revisiting proximity effect using broadband signals", "abstract": "Experiments studying mainly proximity effect are presented. Pink noise and\nmusic were used as stimuli and a combo guitar amplifier as source to test\nseveral microphones: omnidirectional and directional. We plot in-axis levels\nand spectral balances as functions of x, the distance to the source. Proximity\neffect was found for omnidirectional microphones. In-axis level curves show\nthat 1/x law seems poorly valid. Spectral balance evolutions depend on\nmicrophones and moreover on stimuli: bigger decreases of low frequencies with\npink noise; larger increases of other frequencies with music. For a naked\nloudspeaker, we found similar in-axis level curves under and above the cut-off\nfrequency and propose an explanation. Listening equalized music recordings will\nhelp to demonstrate proximity effect for tested microphones.Paper 7106\npresented at the 122th Convention of the Audio Engineering Society, Wien, 2007", "published": "2024-01-11 08:42:23", "link": "http://arxiv.org/abs/2401.14410v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Self-Attention and Hybrid Features for Replay and Deep-Fake Audio\n  Detection", "abstract": "Due to the successful application of deep learning, audio spoofing detection\nhas made significant progress. Spoofed audio with speech synthesis or voice\nconversion can be well detected by many countermeasures. However, an automatic\nspeaker verification system is still vulnerable to spoofing attacks such as\nreplay or Deep-Fake audio. Deep-Fake audio means that the spoofed utterances\nare generated using text-to-speech (TTS) and voice conversion (VC) algorithms.\nHere, we propose a novel framework based on hybrid features with the\nself-attention mechanism. It is expected that hybrid features can be used to\nget more discrimination capacity. Firstly, instead of only one type of\nconventional feature, deep learning features and Mel-spectrogram features will\nbe extracted by two parallel paths: convolution neural networks and a\nshort-time Fourier transform (STFT) followed by Mel-frequency. Secondly,\nfeatures will be concatenated by a max-pooling layer. Thirdly, there is a\nSelf-attention mechanism for focusing on essential elements. Finally, ResNet\nand a linear layer are built to get the results. Experimental results reveal\nthat the hybrid features, compared with conventional features, can cover more\ndetails of an utterance. We achieve the best Equal Error Rate (EER) of 9.67\\%\nin the physical access (PA) scenario and 8.94\\% in the Deep fake task on the\nASVspoof 2021 dataset. Compared with the best baseline system, the proposed\napproach improves by 74.60\\% and 60.05\\%, respectively.", "published": "2024-01-11 01:41:16", "link": "http://arxiv.org/abs/2401.05614v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Intuitive Control of Scraping and Rubbing Through Audio-tactile\n  Synthesis", "abstract": "Intuitive control of synthesis processes is an ongoing challenge within the\ndomain of auditory perception and cognition. Previous works on sound modelling\ncombined with psychophysical tests have enabled our team to develop a\nsynthesizer that provides intuitive control of actions and objects based on\nsemantic descriptions for sound sources. In this demo we present an augmented\nversion of the synthesizer in which we added tactile stimulations to increase\nthe sensation of true continuous friction interactions (rubbing and scratching)\nwith the simulated objects. This is of interest for several reasons. Firstly,\nit enables to evaluate the realism of our sound model in presence of\nstimulations from other modalities. Secondly it enables to compare tactile and\nauditory signal structures linked to the same evocation, and thirdly it\nprovides a tool to investigate multimodal perception and how stimulations from\ndifferent modalities should be combined to provide realistic user interfaces.", "published": "2024-01-11 09:07:44", "link": "http://arxiv.org/abs/2401.05757v1", "categories": ["cs.SD", "eess.AS", "physics.class-ph"], "primary_category": "cs.SD"}
{"title": "Remixing Music for Hearing Aids Using Ensemble of Fine-Tuned Source\n  Separators", "abstract": "This paper introduces our system submission for the Cadenza ICASSP 2024 Grand\nChallenge, which presents the problem of remixing and enhancing music for\nhearing aid users. Our system placed first in the challenge, achieving the best\naverage Hearing-Aid Audio Quality Index (HAAQI) score on the evaluation data\nset. We describe the system, which uses an ensemble of deep learning music\nsource separators that are fine tuned on the challenge data. We demonstrate the\neffectiveness of our system through the challenge results and analyze the\nimportance of different system aspects through ablation studies.", "published": "2024-01-11 16:04:53", "link": "http://arxiv.org/abs/2401.06203v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "HiCMAE: Hierarchical Contrastive Masked Autoencoder for Self-Supervised\n  Audio-Visual Emotion Recognition", "abstract": "Audio-Visual Emotion Recognition (AVER) has garnered increasing attention in\nrecent years for its critical role in creating emotion-ware intelligent\nmachines. Previous efforts in this area are dominated by the supervised\nlearning paradigm. Despite significant progress, supervised learning is meeting\nits bottleneck due to the longstanding data scarcity issue in AVER. Motivated\nby recent advances in self-supervised learning, we propose Hierarchical\nContrastive Masked Autoencoder (HiCMAE), a novel self-supervised framework that\nleverages large-scale self-supervised pre-training on vast unlabeled\naudio-visual data to promote the advancement of AVER. Following prior arts in\nself-supervised audio-visual representation learning, HiCMAE adopts two primary\nforms of self-supervision for pre-training, namely masked data modeling and\ncontrastive learning. Unlike them which focus exclusively on top-layer\nrepresentations while neglecting explicit guidance of intermediate layers,\nHiCMAE develops a three-pronged strategy to foster hierarchical audio-visual\nfeature learning and improve the overall quality of learned representations. To\nverify the effectiveness of HiCMAE, we conduct extensive experiments on 9\ndatasets covering both categorical and dimensional AVER tasks. Experimental\nresults show that our method significantly outperforms state-of-the-art\nsupervised and self-supervised audio-visual methods, which indicates that\nHiCMAE is a powerful audio-visual emotion representation learner. Codes and\nmodels will be publicly available at https://github.com/sunlicai/HiCMAE.", "published": "2024-01-11 07:00:07", "link": "http://arxiv.org/abs/2401.05698v2", "categories": ["cs.CV", "cs.HC", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Segment Boundary Detection via Class Entropy Measurements in\n  Connectionist Phoneme Recognition", "abstract": "This article investigates the possibility to use the class entropy of the\noutput of a connectionist phoneme recogniser to predict time boundaries between\nphonetic classes. The rationale is that the value of the entropy should\nincrease in proximity of a transition between two segments that are well\nmodelled (known) by the recognition network since it is a measure of\nuncertainty. The advantage of this measure is its simplicity as the posterior\nprobabilities of each class are available in connectionist phoneme recognition.\nThe entropy and a number of measures based on differentiation of the entropy\nare used in isolation and in combination. The decision methods for predicting\nthe boundaries range from simple thresholds to neural network based procedure.\nThe different methods are compared with respect to their precision, measured in\nterms of the ratio between the number C of predicted boundaries within 10 or 20\nmsec of the reference and the total number of predicted boundaries, and recall,\nmeasured as the ratio between C and the total number of reference boundaries.", "published": "2024-01-11 07:47:10", "link": "http://arxiv.org/abs/2401.05717v2", "categories": ["eess.AS", "cs.IT", "cs.LG", "cs.SD", "math.IT", "I.5.0; I.2.7; E.4"], "primary_category": "eess.AS"}
