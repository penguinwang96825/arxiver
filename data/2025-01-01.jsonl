{"title": "Boosting the Accuracy of Stock Market Prediction via Multi-Layer Hybrid MTL Structure", "abstract": "Accurate stock market prediction provides great opportunities for informed\ndecision-making, yet existing methods struggle with financial data's\nnon-linear, high-dimensional, and volatile characteristics. Advanced predictive\nmodels are needed to effectively address these complexities. This paper\nproposes a novel multi-layer hybrid multi-task learning (MTL) framework aimed\nat achieving more efficient stock market predictions. It involves a Transformer\nencoder to extract complex correspondences between various input features, a\nBidirectional Gated Recurrent Unit (BiGRU) to capture long-term temporal\nrelationships, and a Kolmogorov-Arnold Network (KAN) to enhance the learning\nprocess. Experimental evaluations indicate that the proposed learning structure\nachieves great performance, with an MAE as low as 1.078, a MAPE as low as\n0.012, and an R^2 as high as 0.98, when compared with other competitive\nnetworks.", "published": "2025-01-01 17:47:45", "link": "http://arxiv.org/abs/2501.09760v1", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "LLM-Powered Multi-Agent System for Automated Crypto Portfolio Management", "abstract": "Cryptocurrency investment is inherently difficult due to its shorter history\ncompared to traditional assets, the need to integrate vast amounts of data from\nvarious modalities, and the requirement for complex reasoning. While deep\nlearning approaches have been applied to address these challenges, their\nblack-box nature raises concerns about trust and explainability. Recently,\nlarge language models (LLMs) have shown promise in financial applications due\nto their ability to understand multi-modal data and generate explainable\ndecisions. However, single LLM faces limitations in complex, comprehensive\ntasks such as asset investment. These limitations are even more pronounced in\ncryptocurrency investment, where LLMs have less domain-specific knowledge in\ntheir training corpora.\n  To overcome these challenges, we propose an explainable, multi-modal,\nmulti-agent framework for cryptocurrency investment. Our framework uses\nspecialized agents that collaborate within and across teams to handle subtasks\nsuch as data analysis, literature integration, and investment decision-making\nfor the top 30 cryptocurrencies by market capitalization. The expert training\nmodule fine-tunes agents using multi-modal historical data and professional\ninvestment literature, while the multi-agent investment module employs\nreal-time data to make informed cryptocurrency investment decisions. Unique\nintrateam and interteam collaboration mechanisms enhance prediction accuracy by\nadjusting final predictions based on confidence levels within agent teams and\nfacilitating information sharing between teams. Empirical evaluation using data\nfrom November 2023 to September 2024 demonstrates that our framework\noutperforms single-agent models and market benchmarks in classification, asset\npricing, portfolio, and explainability performance.", "published": "2025-01-01 13:08:17", "link": "http://arxiv.org/abs/2501.00826v2", "categories": ["q-fin.TR", "cs.AI"], "primary_category": "q-fin.TR"}
{"title": "PANDA -- Paired Anti-hate Narratives Dataset from Asia: Using an\n  LLM-as-a-Judge to Create the First Chinese Counterspeech Dataset", "abstract": "Despite the global prevalence of Modern Standard Chinese language,\ncounterspeech (CS) resources for Chinese remain virtually nonexistent. To\naddress this gap in East Asian counterspeech research we introduce the a corpus\nof Modern Standard Mandarin counterspeech that focuses on combating hate speech\nin Mainland China. This paper proposes a novel approach of generating CS by\nusing an LLM-as-a-Judge, simulated annealing, LLMs zero-shot CN generation and\na round-robin algorithm. This is followed by manual verification for quality\nand contextual relevance. This paper details the methodology for creating\neffective counterspeech in Chinese and other non-Eurocentric languages,\nincluding unique cultural patterns of which groups are maligned and linguistic\npatterns in what kinds of discourse markers are programmatically marked as hate\nspeech (HS). Analysis of the generated corpora, we provide strong evidence for\nthe lack of open-source, properly labeled Chinese hate speech data and the\nlimitations of using an LLM-as-Judge to score possible answers in Chinese.\nMoreover, the present corpus serves as the first East Asian language based CS\ncorpus and provides an essential resource for future research on counterspeech\ngeneration and evaluation.", "published": "2025-01-01 01:56:32", "link": "http://arxiv.org/abs/2501.00697v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CODEOFCONDUCT at Multilingual Counterspeech Generation: A Context-Aware\n  Model for Robust Counterspeech Generation in Low-Resource Languages", "abstract": "This paper introduces a context-aware model for robust counterspeech\ngeneration, which achieved significant success in the MCG-COLING-2025 shared\ntask. Our approach particularly excelled in low-resource language settings. By\nleveraging a simulated annealing algorithm fine-tuned on multilingual datasets,\nthe model generates factually accurate responses to hate speech.\n  We demonstrate state-of-the-art performance across four languages (Basque,\nEnglish, Italian, and Spanish), with our system ranking first for Basque,\nsecond for Italian, and third for both English and Spanish. Notably, our model\nswept all three top positions for Basque, highlighting its effectiveness in\nlow-resource scenarios.\n  Evaluation of the shared task employs both traditional metrics (BLEU, ROUGE,\nBERTScore, Novelty) and JudgeLM based on LLM. We present a detailed analysis of\nour results, including an empirical evaluation of the model performance and\ncomprehensive score distributions across evaluation metrics.\n  This work contributes to the growing body of research on multilingual\ncounterspeech generation, offering insights into developing robust models that\ncan adapt to diverse linguistic and cultural contexts in the fight against\nonline hate speech.", "published": "2025-01-01 03:36:31", "link": "http://arxiv.org/abs/2501.00713v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DIVE: Diversified Iterative Self-Improvement", "abstract": "Recent advances in large language models (LLMs) have demonstrated the\neffectiveness of Iterative Self-Improvement (ISI) techniques. However,\ncontinuous training on self-generated data leads to reduced output diversity, a\nlimitation particularly critical in reasoning tasks where diverse solution\npaths are essential. We present DIVE (Diversified Iterative Self-Improvement),\na novel framework that addresses this challenge through two key components:\nSample Pool Expansion for broader solution exploration, and Data Selection for\nbalancing diversity and quality in preference pairs. Experiments on MATH and\nGSM8k datasets show that DIVE achieves a 10% to 45% relative increase in output\ndiversity metrics while maintaining performance quality compared to vanilla\nISI. Our ablation studies confirm both components' significance in achieving\nthese improvements. Code is available at https://github.com/qinyiwei/DIVE.", "published": "2025-01-01 06:33:45", "link": "http://arxiv.org/abs/2501.00747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Read/Write Policy-Makers for Simultaneous\n  Generation", "abstract": "Simultaneous generation models write generation results while reading\nstreaming inputs, necessitating a policy-maker to determine the appropriate\noutput timing. Existing simultaneous generation methods generally adopt the\ntraditional encoder-decoder architecture and learn the generation and\npolicy-making capabilities through complex dynamic programming techniques.\nAlthough LLMs excel at text generation, they face challenges in taking on the\nrole of policy-makers through traditional training methods, limiting their\nexploration in simultaneous generation. To overcome these limitations, we\npropose a novel LLM-driven Simultaneous Generation (LSG) framework, which\nallows the off-the-shelf LLM to decide the generation timing and produce output\nconcurrently. Specifically, LSG selects the generation policy that minimizes\nlatency as the baseline policy. Referring to the baseline policy, LSG enables\nthe LLM to devise an improved generation policy that better balances latency\nand generation quality, and writes generation results accordingly. Experiments\non simultaneous translation and streaming automatic speech recognition tasks\nshow that our method can achieve state-of-the-art performance utilizing the\nopen-source LLMs and demonstrate practicality in real-world scenarios.", "published": "2025-01-01 15:20:35", "link": "http://arxiv.org/abs/2501.00868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TrustRAG: Enhancing Robustness and Trustworthiness in RAG", "abstract": "Retrieval-Augmented Generation (RAG) systems enhance large language models\n(LLMs) by integrating external knowledge sources, enabling more accurate and\ncontextually relevant responses tailored to user queries. However, these\nsystems remain vulnerable to corpus poisoning attacks that can significantly\ndegrade LLM performance through the injection of malicious content. To address\nthese challenges, we propose TrustRAG, a robust framework that systematically\nfilters compromised and irrelevant contents before they are retrieved for\ngeneration. Our approach implements a two-stage defense mechanism: At the first\nstage, it employs K-means clustering to identify potential attack patterns in\nretrieved documents using cosine similarity and ROUGE metrics as guidance,\neffectively isolating suspicious content. Secondly, it performs a\nself-assessment which detects malicious documents and resolves discrepancies\nbetween the model's internal knowledge and external information. TrustRAG\nfunctions as a plug-and-play, training-free module that integrates seamlessly\nwith any language model, whether open or closed-source. In addition, TrustRAG\nmaintains high contextual relevance while strengthening defenses against corpus\npoisoning attacks. Through extensive experimental validation, we demonstrate\nthat TrustRAG delivers substantial improvements in retrieval accuracy,\nefficiency, and attack resistance compared to existing approaches across\nmultiple model architectures and datasets. We have made TrustRAG available as\nopen-source software at \\url{https://github.com/HuichiZhou/TrustRAG}.", "published": "2025-01-01 15:57:34", "link": "http://arxiv.org/abs/2501.00879v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unfolding the Headline: Iterative Self-Questioning for News Retrieval\n  and Timeline Summarization", "abstract": "In the fast-changing realm of information, the capacity to construct coherent\ntimelines from extensive event-related content has become increasingly\nsignificant and challenging. The complexity arises in aggregating related\ndocuments to build a meaningful event graph around a central topic. This paper\nproposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline\nSummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective\non the integration of Large Language Models (LLMs) to tackle the task of\nTimeline Summarization (TLS). By iteratively reflecting on how events are\nlinked and posing new questions regarding a specific news topic to gather\ninformation online or from an offline knowledge base, LLMs produce and refresh\nchronological summaries based on documents retrieved in each round.\nFurthermore, we curate Open-TLS, a novel dataset of timelines on recent news\ntopics authored by professional journalists to evaluate open-domain TLS where\ninformation overload makes it impossible to find comprehensive relevant\ndocuments from the web. Our experiments indicate that CHRONOS is not only adept\nat open-domain timeline summarization, but it also rivals the performance of\nexisting state-of-the-art systems designed for closed-domain applications,\nwhere a related news corpus is provided for summarization.", "published": "2025-01-01 16:28:21", "link": "http://arxiv.org/abs/2501.00888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IGC: Integrating a Gated Calculator into an LLM to Solve Arithmetic\n  Tasks Reliably and Efficiently", "abstract": "Solving arithmetic tasks is a simple and fundamental skill, yet modern Large\nLanguage Models (LLMs) have great difficulty with them. We introduce the\nIntegrated Gated Calculator (IGC), a module that enables LLMs to perform\narithmetic by emulating a calculator on the GPU. We finetune a Llama model with\nour module and test it on the BigBench Arithmetic benchmark, where it beats the\nState of the Art, outperforming all models on the benchmark, including models\nalmost two orders of magnitude larger. Our approach takes only a single\niteration to run and requires no external tools. It performs arithmetic\noperations entirely inside the LLM without the need to produce intermediate\ntokens. It is computationally efficient, interpretable, and avoids side-effects\non tasks that do not require arithmetic operations. It reliably achieves 98\\%\nto 99\\% accuracy across multiple training runs and for all subtasks, including\nthe substantially harder subtask of multiplication, which was previously\nunsolved.", "published": "2025-01-01 00:01:27", "link": "http://arxiv.org/abs/2501.00684v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Labels Generated by Large Language Model Helps Measuring People's\n  Empathy in Vitro", "abstract": "Large language models (LLMs) have revolutionised numerous fields, with\nLLM-as-a-service (LLMSaaS) having a strong generalisation ability that offers\naccessible solutions directly without the need for costly training. In contrast\nto the widely studied prompt engineering for task solving directly (in vivo),\nthis paper explores its potential in in-vitro applications. These involve using\nLLM to generate labels to help the supervised training of mainstream models by\n(1) noisy label correction and (2) training data augmentation with\nLLM-generated labels. In this paper, we evaluate this approach in the emerging\nfield of empathy computing -- automating the prediction of psychological\nquestionnaire outcomes from inputs like text sequences. Specifically,\ncrowdsourced datasets in this domain often suffer from noisy labels that\nmisrepresent underlying empathy. By leveraging LLM-generated labels to train\npre-trained language models (PLMs) like RoBERTa, we achieve statistically\nsignificant accuracy improvements over baselines, achieving a state-of-the-art\nPearson correlation coefficient of 0.648 on NewsEmp benchmarks. In addition, we\nbring insightful discussions, including current challenges in empathy\ncomputing, data biases in training data and evaluation metric selection. Code\nand LLM-generated data are available at\nhttps://github.com/hasan-rakibul/LLMPathy (available once the paper is\naccepted).", "published": "2025-01-01 01:06:58", "link": "http://arxiv.org/abs/2501.00691v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rethinking Addressing in Language Models via Contexualized Equivariant\n  Positional Encoding", "abstract": "Transformers rely on both content-based and position-based addressing\nmechanisms to make predictions, but existing positional encoding techniques\noften diminish the effectiveness of position-based addressing. Many current\nmethods enforce rigid patterns in attention maps, limiting the ability to model\nlong-range dependencies and adapt to diverse tasks. Additionally, most\npositional encodings are learned as general biases, lacking the specialization\nrequired for different instances within a dataset. To address this, we propose\ncon$\\textbf{T}$extualized equivari$\\textbf{A}$nt $\\textbf{P}$osition\n$\\textbf{E}$mbedding ($\\textbf{TAPE}$), a novel framework that enhances\npositional embeddings by incorporating sequence content across layers. TAPE\nintroduces dynamic, context-aware positional encodings, overcoming the\nconstraints of traditional fixed patterns. By enforcing permutation and\northogonal equivariance, TAPE ensures the stability of positional encodings\nduring updates, improving robustness and adaptability. Our method can be easily\nintegrated into pre-trained transformers, offering parameter-efficient\nfine-tuning with minimal overhead. Extensive experiments shows that TAPE\nachieves superior performance in language modeling, arithmetic reasoning, and\nlong-context retrieval tasks compared to existing positional embedding\ntechniques.", "published": "2025-01-01 03:23:00", "link": "http://arxiv.org/abs/2501.00712v1", "categories": ["cs.CL", "cs.LG", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "eRevise+RF: A Writing Evaluation System for Assessing Student Essay\n  Revisions and Providing Formative Feedback", "abstract": "The ability to revise essays in response to feedback is important for\nstudents' writing success. An automated writing evaluation (AWE) system that\nsupports students in revising their essays is thus essential. We present\neRevise+RF, an enhanced AWE system for assessing student essay revisions (e.g.,\nchanges made to an essay to improve its quality in response to essay feedback)\nand providing revision feedback. We deployed the system with 6 teachers and 406\nstudents across 3 schools in Pennsylvania and Louisiana. The results confirmed\nits effectiveness in (1) assessing student essays in terms of evidence usage,\n(2) extracting evidence and reasoning revisions across essays, and (3)\ndetermining revision success in responding to feedback. The evaluation also\nsuggested eRevise+RF is a helpful system for young students to improve their\nargumentative writing skills through revision and formative feedback.", "published": "2025-01-01 03:49:48", "link": "http://arxiv.org/abs/2501.00715v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Importance of Layer Pruning for Smaller BERT Models and Low Resource\n  Languages", "abstract": "This study explores the effectiveness of layer pruning for developing more\nefficient BERT models tailored to specific downstream tasks in low-resource\nlanguages. Our primary objective is to evaluate whether pruned BERT models can\nmaintain high performance while reducing model size and complexity. We\nexperiment with several BERT variants, including MahaBERT-v2 and Google-Muril,\napplying different pruning strategies and comparing their performance to\nsmaller, scratch-trained models like MahaBERT-Small and MahaBERT-Smaller. We\nfine-tune these models on Marathi datasets, specifically Short Headlines\nClassification (SHC), Long Paragraph Classification (LPC) and Long Document\nClassification (LDC), to assess their classification accuracy. Our findings\ndemonstrate that pruned models, despite having fewer layers, achieve comparable\nperformance to their fully-layered counterparts while consistently\noutperforming scratch-trained models of similar size. Notably, pruning layers\nfrom the middle of the model proves to be the most effective strategy, offering\nperformance competitive with pruning from the top and bottom. However, there is\nno clear winner, as different pruning strategies perform better in different\nmodel and dataset combinations. Additionally, monolingual BERT models\noutperform multilingual ones in these experiments. This approach, which reduces\ncomputational demands, provides a faster and more efficient alternative to\ntraining smaller models from scratch, making advanced NLP models more\naccessible for low-resource languages without compromising classification\naccuracy.", "published": "2025-01-01 05:30:10", "link": "http://arxiv.org/abs/2501.00733v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Transformers for Generalizable First-Order Logical Entailment", "abstract": "Transformers, as a fundamental deep learning architecture, have demonstrated\nremarkable capabilities in reasoning. This paper investigates the generalizable\nfirst-order logical reasoning ability of transformers with their parameterized\nknowledge and explores ways to improve it. The first-order reasoning capability\nof transformers is assessed through their ability to perform first-order\nlogical entailment, which is quantitatively measured by their performance in\nanswering knowledge graph queries. We establish connections between (1) two\ntypes of distribution shifts studied in out-of-distribution generalization and\n(2) the unseen knowledge and query settings discussed in the task of knowledge\ngraph query answering, enabling a characterization of fine-grained\ngeneralizability. Results on our comprehensive dataset show that transformers\noutperform previous methods specifically designed for this task and provide\ndetailed empirical evidence on the impact of input query syntax, token\nembedding, and transformer architectures on the reasoning capability of\ntransformers. Interestingly, our findings reveal a mismatch between positional\nencoding and other design choices in transformer architectures employed in\nprior practices. This discovery motivates us to propose a more sophisticated,\nlogic-aware architecture, TEGA, to enhance the capability for generalizable\nfirst-order logical entailment in transformers.", "published": "2025-01-01 07:05:32", "link": "http://arxiv.org/abs/2501.00759v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FitCF: A Framework for Automatic Feature Importance-guided\n  Counterfactual Example Generation", "abstract": "Counterfactual examples are widely used in natural language processing (NLP)\nas valuable data to improve models, and in explainable artificial intelligence\n(XAI) to understand model behavior. The automated generation of counterfactual\nexamples remains a challenging task even for large language models (LLMs),\ndespite their impressive performance on many tasks. In this paper, we first\nintroduce ZeroCF, a faithful approach for leveraging important words derived\nfrom feature attribution methods to generate counterfactual examples in a\nzero-shot setting. Second, we present a new framework, FitCF, which further\nverifies aforementioned counterfactuals by label flip verification and then\ninserts them as demonstrations for few-shot prompting, outperforming two\nstate-of-the-art baselines. Through ablation studies, we identify the\nimportance of each of FitCF's core components in improving the quality of\ncounterfactuals, as assessed through flip rate, perplexity, and similarity\nmeasures. Furthermore, we show the effectiveness of LIME and Integrated\nGradients as backbone attribution methods for FitCF and find that the number of\ndemonstrations has the largest effect on performance. Finally, we reveal a\nstrong correlation between the faithfulness of feature attribution scores and\nthe quality of generated counterfactuals.", "published": "2025-01-01 09:00:10", "link": "http://arxiv.org/abs/2501.00777v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Decoding the Flow: CauseMotion for Emotional Causality Analysis in\n  Long-form Conversations", "abstract": "Long-sequence causal reasoning seeks to uncover causal relationships within\nextended time series data but is hindered by complex dependencies and the\nchallenges of validating causal links. To address the limitations of\nlarge-scale language models (e.g., GPT-4) in capturing intricate emotional\ncausality within extended dialogues, we propose CauseMotion, a long-sequence\nemotional causal reasoning framework grounded in Retrieval-Augmented Generation\n(RAG) and multimodal fusion. Unlike conventional methods relying only on\ntextual information, CauseMotion enriches semantic representations by\nincorporating audio-derived features-vocal emotion, emotional intensity, and\nspeech rate-into textual modalities. By integrating RAG with a sliding window\nmechanism, it effectively retrieves and leverages contextually relevant\ndialogue segments, thus enabling the inference of complex emotional causal\nchains spanning multiple conversational turns. To evaluate its effectiveness,\nwe constructed the first benchmark dataset dedicated to long-sequence emotional\ncausal reasoning, featuring dialogues with over 70 turns. Experimental results\ndemonstrate that the proposed RAG-based multimodal integrated approach, the\nefficacy of substantially enhances both the depth of emotional understanding\nand the causal inference capabilities of large-scale language models. A GLM-4\nintegrated with CauseMotion achieves an 8.7% improvement in causal accuracy\nover the original model and surpasses GPT-4o by 1.2%. Additionally, on the\npublicly available DiaASQ dataset, CauseMotion-GLM-4 achieves state-of-the-art\nresults in accuracy, F1 score, and causal reasoning accuracy.", "published": "2025-01-01 09:10:32", "link": "http://arxiv.org/abs/2501.00778v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Navigating Nuance: In Quest for Political Truth", "abstract": "This study investigates the several nuanced rationales for countering the\nrise of political bias. We evaluate the performance of the Llama-3 (70B)\nlanguage model on the Media Bias Identification Benchmark (MBIB), based on a\nnovel prompting technique that incorporates subtle reasons for identifying\npolitical leaning. Our findings underscore the challenges of detecting\npolitical bias and highlight the potential of transfer learning methods to\nenhance future models. Through our framework, we achieve a comparable\nperformance with the supervised and fully fine-tuned ConvBERT model, which is\nthe state-of-the-art model, performing best among other baseline models for the\npolitical bias task on MBIB. By demonstrating the effectiveness of our\napproach, we contribute to the development of more robust tools for mitigating\nthe spread of misinformation and polarization. Our codes and dataset are made\npublicly available in github.", "published": "2025-01-01 09:24:47", "link": "http://arxiv.org/abs/2501.00782v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Reasoning-Oriented and Analogy-Based Methods for Locating and Editing in\n  Zero-Shot Event-Relational Reasoning", "abstract": "Zero-shot event-relational reasoning is an important task in natural language\nprocessing, and existing methods jointly learn a variety of event-relational\nprefixes and inference-form prefixes to achieve such tasks. However, training\nprefixes consumes large computational resources and lacks interpretability.\nAdditionally, learning various relational and inferential knowledge\ninefficiently exploits the connections between tasks. Therefore, we first\npropose a method for Reasoning-Oriented Locating and Editing (ROLE), which\nlocates and edits the key modules of the language model for reasoning about\nevent relations, enhancing interpretability and also resource-efficiently\noptimizing the reasoning ability. Subsequently, we propose a method for\nAnalogy-Based Locating and Editing (ABLE), which efficiently exploits the\nsimilarities and differences between tasks to optimize the zero-shot reasoning\ncapability. Experimental results show that ROLE improves interpretability and\nreasoning performance with reduced computational cost. ABLE achieves SOTA\nresults in zero-shot reasoning.", "published": "2025-01-01 11:02:08", "link": "http://arxiv.org/abs/2501.00803v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Text Pronunciation Correlation Generation and Application for\n  Contextual Biasing", "abstract": "Effectively distinguishing the pronunciation correlations between different\nwritten texts is a significant issue in linguistic acoustics. Traditionally,\nsuch pronunciation correlations are obtained through manually designed\npronunciation lexicons. In this paper, we propose a data-driven method to\nautomatically acquire these pronunciation correlations, called automatic text\npronunciation correlation (ATPC). The supervision required for this method is\nconsistent with the supervision needed for training end-to-end automatic speech\nrecognition (E2E-ASR) systems, i.e., speech and corresponding text annotations.\nFirst, the iteratively-trained timestamp estimator (ITSE) algorithm is employed\nto align the speech with their corresponding annotated text symbols. Then, a\nspeech encoder is used to convert the speech into speech embeddings. Finally,\nwe compare the speech embeddings distances of different text symbols to obtain\nATPC. Experimental results on Mandarin show that ATPC enhances E2E-ASR\nperformance in contextual biasing and holds promise for dialects or languages\nlacking artificial pronunciation lexicons.", "published": "2025-01-01 11:10:46", "link": "http://arxiv.org/abs/2501.00804v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Embedding Style Beyond Topics: Analyzing Dispersion Effects Across\n  Different Language Models", "abstract": "This paper analyzes how writing style affects the dispersion of embedding\nvectors across multiple, state-of-the-art language models. While early\ntransformer models primarily aligned with topic modeling, this study examines\nthe role of writing style in shaping embedding spaces. Using a literary corpus\nthat alternates between topics and styles, we compare the sensitivity of\nlanguage models across French and English. By analyzing the particular impact\nof style on embedding dispersion, we aim to better understand how language\nmodels process stylistic information, contributing to their overall\ninterpretability.", "published": "2025-01-01 13:17:16", "link": "http://arxiv.org/abs/2501.00828v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLM+AL: Bridging Large Language Models and Action Languages for Complex\n  Reasoning about Actions", "abstract": "Large Language Models (LLMs) have made significant strides in various\nintelligent tasks but still struggle with complex action reasoning tasks that\nrequire systematic search. To address this limitation, we propose a method that\nbridges the natural language understanding capabilities of LLMs with the\nsymbolic reasoning strengths of action languages. Our approach, termed\n\"LLM+AL,\" leverages the LLM's strengths in semantic parsing and commonsense\nknowledge generation alongside the action language's proficiency in automated\nreasoning based on encoded knowledge. We compare LLM+AL against\nstate-of-the-art LLMs, including ChatGPT-4, Claude 3 Opus, Gemini Ultra 1.0,\nand o1-preview, using benchmarks for complex reasoning about actions. Our\nfindings indicate that, although all methods exhibit errors, LLM+AL, with\nrelatively minimal human corrections, consistently leads to correct answers,\nwhereas standalone LLMs fail to improve even with human feedback. LLM+AL also\ncontributes to automated generation of action languages.", "published": "2025-01-01 13:20:01", "link": "http://arxiv.org/abs/2501.00830v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Negative to Positive Co-learning with Aggressive Modality Dropout", "abstract": "This paper aims to document an effective way to improve multimodal\nco-learning by using aggressive modality dropout. We find that by using\naggressive modality dropout we are able to reverse negative co-learning (NCL)\nto positive co-learning (PCL). Aggressive modality dropout can be used to\n\"prep\" a multimodal model for unimodal deployment, and dramatically increases\nmodel performance during negative co-learning, where during some experiments we\nsaw a 20% gain in accuracy. We also benchmark our modality dropout technique\nagainst PCL to show that our modality drop out technique improves co-learning\nduring PCL, although it does not have as much as an substantial effect as it\ndoes during NCL. Github: https://github.com/nmagal/modality_drop_for_colearning", "published": "2025-01-01 15:18:23", "link": "http://arxiv.org/abs/2501.00865v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LUSIFER: Language Universal Space Integration for Enhanced Multilingual\n  Embeddings with Large Language Models", "abstract": "Recent advancements in large language models (LLMs) based embedding models\nhave established new state-of-the-art benchmarks for text embedding tasks,\nparticularly in dense vector-based retrieval. However, these models\npredominantly focus on English, leaving multilingual embedding capabilities\nlargely unexplored. To address this limitation, we present LUSIFER, a novel\nzero-shot approach that adapts LLM-based embedding models for multilingual\ntasks without requiring multilingual supervision. LUSIFER's architecture\ncombines a multilingual encoder, serving as a language-universal learner, with\nan LLM-based embedding model optimized for embedding-specific tasks. These\ncomponents are seamlessly integrated through a minimal set of trainable\nparameters that act as a connector, effectively transferring the multilingual\nencoder's language understanding capabilities to the specialized embedding\nmodel. Additionally, to comprehensively evaluate multilingual embedding\nperformance, we introduce a new benchmark encompassing 5 primary embedding\ntasks, 123 diverse datasets, and coverage across 14 languages. Extensive\nexperimental results demonstrate that LUSIFER significantly enhances the\nmultilingual performance across various embedding tasks, particularly for\nmedium and low-resource languages, without requiring explicit multilingual\ntraining data.", "published": "2025-01-01 15:43:07", "link": "http://arxiv.org/abs/2501.00874v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "AutoPresent: Designing Structured Visuals from Scratch", "abstract": "Designing structured visuals such as presentation slides is essential for\ncommunicative needs, necessitating both content creation and visual planning\nskills. In this work, we tackle the challenge of automated slide generation,\nwhere models produce slide presentations from natural language (NL)\ninstructions. We first introduce the SlidesBench benchmark, the first benchmark\nfor slide generation with 7k training and 585 testing examples derived from 310\nslide decks across 10 domains. SlidesBench supports evaluations that are\n(i)reference-based to measure similarity to a target slide, and\n(ii)reference-free to measure the design quality of generated slides alone. We\nbenchmark end-to-end image generation and program generation methods with a\nvariety of models, and find that programmatic methods produce higher-quality\nslides in user-interactable formats. Built on the success of program\ngeneration, we create AutoPresent, an 8B Llama-based model trained on 7k pairs\nof instructions paired with code for slide generation, and achieve results\ncomparable to the closed-source model GPT-4o. We further explore iterative\ndesign refinement where the model is tasked to self-refine its own output, and\nwe found that this process improves the slide's quality. We hope that our work\nwill provide a basis for future work on generating structured visuals.", "published": "2025-01-01 18:09:32", "link": "http://arxiv.org/abs/2501.00912v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Aligning Netlist to Source Code using SynAlign", "abstract": "In current chip design processes, using multiple tools to obtain a gate-level\nnetlist often results in the loss of source code correlation. SynAlign\naddresses this challenge by automating the alignment process, simplifying\niterative design, reducing overhead, and maintaining correlation across various\ntools. This enhances the efficiency and effectiveness of chip design workflows.\n  Improving characteristics such as frequency through iterative design is\nessential for enhancing accelerators and chip designs. While synthesis tools\nproduce netlists with critical path information, designers often lack the tools\nto trace these netlist cells back to their original source code. Mapping\nnetlist components to source code provides early feedback on timing and power\nfor frontend designers.\n  SynAlign automatically aligns post-optimized netlists with the original\nsource code without altering compilers or synthesis processes. Its alignment\nstrategy relies on the consistent design structure throughout the chip design\ncycle, even with changes in compiler flow. This consistency allows engineers to\nmaintain a correlation between modified designs and the original source code\nacross various tools. Remarkably, SynAlign can tolerate up to 61\\% design net\nchanges without impacting alignment accuracy.", "published": "2025-01-01 18:40:05", "link": "http://arxiv.org/abs/2501.00921v1", "categories": ["cs.AR", "cs.CL"], "primary_category": "cs.AR"}
{"title": "Prior Lessons of Incremental Dialogue and Robot Action Management for\n  the Age of Language Models", "abstract": "Efforts towards endowing robots with the ability to speak have benefited from\nrecent advancements in natural language processing, in particular large\nlanguage models. However, current language models are not fully incremental, as\ntheir processing is inherently monotonic and thus lack the ability to revise\ntheir interpretations or output in light of newer observations. This\nmonotonicity has important implications for the development of dialogue systems\nfor human--robot interaction. In this paper, we review the literature on\ninteractive systems that operate incrementally (i.e., at the word level or\nbelow it). We motivate the need for incremental systems, survey incremental\nmodeling of important aspects of dialogue like speech recognition and language\ngeneration. Primary focus is on the part of the system that makes decisions,\nknown as the dialogue manager. We find that there is very little research on\nincremental dialogue management, offer some requirements for practical\nincremental dialogue management, and the implications of incremental dialogue\nfor embodied, robotic platforms in the age of large language models.", "published": "2025-01-01 20:58:03", "link": "http://arxiv.org/abs/2501.00953v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adjoint sharding for very long context training of state space models", "abstract": "Despite very fast progress, efficiently training large language models (LLMs)\nin very long contexts remains challenging. Existing methods fall back to\ntraining LLMs with short contexts (a maximum of a few thousands tokens in\ntraining) and use inference time techniques when evaluating on long contexts\n(above 1M tokens context window at inference). As opposed to\nlong-context-inference, training on very long context input prompts is quickly\nlimited by GPU memory availability and by the prohibitively long training times\nit requires on state-of-the-art hardware. Meanwhile, many real-life\napplications require not only inference but also training/fine-tuning with long\ncontext on specific tasks. Such applications include, for example, augmenting\nthe context with various sources of raw reference information for fact\nextraction, fact summarization, or fact reconciliation tasks. We propose\nadjoint sharding, a novel technique that comprises sharding gradient\ncalculation during training to reduce memory requirements by orders of\nmagnitude, making training on very long context computationally tractable.\nAdjoint sharding is based on the adjoint method and computes equivalent\ngradients to backpropagation. We also propose truncated adjoint sharding to\nspeed up the algorithm while maintaining performance. We provide a distributed\nversion, and a paralleled version of adjoint sharding to further speed up\ntraining. Empirical results show the proposed adjoint sharding algorithm\nreduces memory usage by up to 3X with a 1.27B parameter large language model on\n1M context length training. This allows to increase the maximum context length\nduring training or fine-tuning of a 1.27B parameter model from 35K tokens to\nabove 100K tokens on a training infrastructure composed of five AWS P4\ninstances.", "published": "2025-01-01 01:10:59", "link": "http://arxiv.org/abs/2501.00692v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SLIDE: Integrating Speech Language Model with LLM for Spontaneous Spoken\n  Dialogue Generation", "abstract": "Recently, ``textless\" speech language models (SLMs) based on speech units\nhave made huge progress in generating naturalistic speech, including non-verbal\nvocalizations. However, the generated speech samples often lack semantic\ncoherence. In this paper, we propose SLM and LLM Integration for spontaneous\nspoken Dialogue gEneration (SLIDE). Specifically, we first utilize an LLM to\ngenerate the textual content of spoken dialogue. Next, we convert the textual\ndialogues into phoneme sequences and use a two-tower transformer-based duration\npredictor to predict the duration of each phoneme. Finally, an SLM conditioned\non the spoken phoneme sequences is used to vocalize the textual dialogue.\nExperimental results on the Fisher dataset demonstrate that our system can\ngenerate naturalistic spoken dialogue while maintaining high semantic\ncoherence.", "published": "2025-01-01 11:11:07", "link": "http://arxiv.org/abs/2501.00805v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Decoupling Knowledge and Reasoning in Transformers: A Modular\n  Architecture with Generalized Cross-Attention", "abstract": "Transformers have achieved remarkable success across diverse domains, but\ntheir monolithic architecture presents challenges in interpretability,\nadaptability, and scalability. This paper introduces a novel modular\nTransformer architecture that explicitly decouples knowledge and reasoning\nthrough a generalized cross-attention mechanism to a globally shared knowledge\nbase with layer-specific transformations, specifically designed for effective\nknowledge retrieval. Critically, we provide a rigorous mathematical derivation\ndemonstrating that the Feed-Forward Network (FFN) in a standard Transformer is\na specialized case (a closure) of this generalized cross-attention, revealing\nits role in implicit knowledge retrieval and validating our design. This\ntheoretical framework provides a new lens for understanding FFNs and lays the\nfoundation for future research exploring enhanced interpretability,\nadaptability, and scalability, enabling richer interplay with external\nknowledge bases and other systems.", "published": "2025-01-01 12:55:57", "link": "http://arxiv.org/abs/2501.00823v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DiffETM: Diffusion Process Enhanced Embedded Topic Model", "abstract": "The embedded topic model (ETM) is a widely used approach that assumes the\nsampled document-topic distribution conforms to the logistic normal\ndistribution for easier optimization. However, this assumption oversimplifies\nthe real document-topic distribution, limiting the model's performance. In\nresponse, we propose a novel method that introduces the diffusion process into\nthe sampling process of document-topic distribution to overcome this limitation\nand maintain an easy optimization process. We validate our method through\nextensive experiments on two mainstream datasets, proving its effectiveness in\nimproving topic modeling performance.", "published": "2025-01-01 15:15:39", "link": "http://arxiv.org/abs/2501.00862v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Representation in large language models", "abstract": "The extraordinary success of recent Large Language Models (LLMs) on a diverse\narray of tasks has led to an explosion of scientific and philosophical\ntheorizing aimed at explaining how they do what they do. Unfortunately,\ndisagreement over fundamental theoretical issues has led to stalemate, with\nentrenched camps of LLM optimists and pessimists often committed to very\ndifferent views of how these systems work. Overcoming stalemate requires\nagreement on fundamental questions, and the goal of this paper is to address\none such question, namely: is LLM behavior driven partly by\nrepresentation-based information processing of the sort implicated in\nbiological cognition, or is it driven entirely by processes of memorization and\nstochastic table look-up? This is a question about what kind of algorithm LLMs\nimplement, and the answer carries serious implications for higher level\nquestions about whether these systems have beliefs, intentions, concepts,\nknowledge, and understanding. I argue that LLM behavior is partially driven by\nrepresentation-based information processing, and then I describe and defend a\nseries of practical techniques for investigating these representations and\ndeveloping explanations on their basis. The resulting account provides a\ngroundwork for future theorizing about language models and their successors.", "published": "2025-01-01 16:19:48", "link": "http://arxiv.org/abs/2501.00885v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "U-GIFT: Uncertainty-Guided Firewall for Toxic Speech in Few-Shot\n  Scenario", "abstract": "With the widespread use of social media, user-generated content has surged on\nonline platforms. When such content includes hateful, abusive, offensive, or\ncyberbullying behavior, it is classified as toxic speech, posing a significant\nthreat to the online ecosystem's integrity and safety. While manual content\nmoderation is still prevalent, the overwhelming volume of content and the\npsychological strain on human moderators underscore the need for automated\ntoxic speech detection. Previously proposed detection methods often rely on\nlarge annotated datasets; however, acquiring such datasets is both costly and\nchallenging in practice. To address this issue, we propose an\nuncertainty-guided firewall for toxic speech in few-shot scenarios, U-GIFT,\nthat utilizes self-training to enhance detection performance even when labeled\ndata is limited. Specifically, U-GIFT combines active learning with Bayesian\nNeural Networks (BNNs) to automatically identify high-quality samples from\nunlabeled data, prioritizing the selection of pseudo-labels with higher\nconfidence for training based on uncertainty estimates derived from model\npredictions. Extensive experiments demonstrate that U-GIFT significantly\noutperforms competitive baselines in few-shot detection scenarios. In the\n5-shot setting, it achieves a 14.92\\% performance improvement over the basic\nmodel. Importantly, U-GIFT is user-friendly and adaptable to various\npre-trained language models (PLMs). It also exhibits robust performance in\nscenarios with sample imbalance and cross-domain settings, while showcasing\nstrong generalization across various language applications. We believe that\nU-GIFT provides an efficient solution for few-shot toxic speech detection,\noffering substantial support for automated content moderation in cyberspace,\nthereby acting as a firewall to promote advancements in cybersecurity.", "published": "2025-01-01 17:47:22", "link": "http://arxiv.org/abs/2501.00907v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "2.5 Years in Class: A Multimodal Textbook for Vision-Language\n  Pretraining", "abstract": "Compared to image-text pair data, interleaved corpora enable Vision-Language\nModels (VLMs) to understand the world more naturally like humans. However, such\nexisting datasets are crawled from webpage, facing challenges like low\nknowledge density, loose image-text relations, and poor logical coherence\nbetween images. On the other hand, the internet hosts vast instructional videos\n(e.g., online geometry courses) that are widely used by humans to learn\nfoundational subjects, yet these valuable resources remain underexplored in VLM\ntraining. In this paper, we introduce a high-quality \\textbf{multimodal\ntextbook} corpus with richer foundational knowledge for VLM pretraining. It\ncollects over 2.5 years of instructional videos, totaling 22,000 class hours.\nWe first use an LLM-proposed taxonomy to systematically gather instructional\nvideos. Then we progressively extract and refine visual (keyframes), audio\n(ASR), and textual knowledge (OCR) from the videos, and organize as an\nimage-text interleaved corpus based on temporal order. Compared to its\ncounterparts, our video-centric textbook offers more coherent context, richer\nknowledge, and better image-text alignment. Experiments demonstrate its superb\npretraining performance, particularly in knowledge- and reasoning-intensive\ntasks like ScienceQA and MathVista. Moreover, VLMs pre-trained on our textbook\nexhibit outstanding interleaved context awareness, leveraging visual and\ntextual cues in their few-shot context for task solving. Our code are available\nat https://github.com/DAMO-NLP-SG/multimodal_textbook.", "published": "2025-01-01 21:29:37", "link": "http://arxiv.org/abs/2501.00958v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Breaking Through the Spike: Spike Window Decoding for Accelerated and\n  Precise Automatic Speech Recognition", "abstract": "Recently, end-to-end automatic speech recognition has become the mainstream\napproach in both industry and academia. To optimize system performance in\nspecific scenarios, the Weighted Finite-State Transducer (WFST) is extensively\nused to integrate acoustic and language models, leveraging its capacity to\nimplicitly fuse language models within static graphs, thereby ensuring robust\nrecognition while also facilitating rapid error correction. However, WFST\nnecessitates a frame-by-frame search of CTC posterior probabilities through\nautoregression, which significantly hampers inference speed. In this work, we\nthoroughly investigate the spike property of CTC outputs and further propose\nthe conjecture that adjacent frames to non-blank spikes carry semantic\ninformation beneficial to the model. Building on this, we propose the Spike\nWindow Decoding algorithm, which greatly improves the inference speed by making\nthe number of frames decoded in WFST linearly related to the number of spiking\nframes in the CTC output, while guaranteeing the recognition performance. Our\nmethod achieves SOTA recognition accuracy with significantly accelerates\ndecoding speed, proven across both AISHELL-1 and large-scale In-House datasets,\nestablishing a pioneering approach for integrating CTC output with WFST.", "published": "2025-01-01 12:20:07", "link": "http://arxiv.org/abs/2501.03257v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Dynamics of Adversarial Attacks on Large Language Model-Based Search\n  Engines", "abstract": "The increasing integration of Large Language Model (LLM) based search engines\nhas transformed the landscape of information retrieval. However, these systems\nare vulnerable to adversarial attacks, especially ranking manipulation attacks,\nwhere attackers craft webpage content to manipulate the LLM's ranking and\npromote specific content, gaining an unfair advantage over competitors. In this\npaper, we study the dynamics of ranking manipulation attacks. We frame this\nproblem as an Infinitely Repeated Prisoners' Dilemma, where multiple players\nstrategically decide whether to cooperate or attack. We analyze the conditions\nunder which cooperation can be sustained, identifying key factors such as\nattack costs, discount rates, attack success rates, and trigger strategies that\ninfluence player behavior. We identify tipping points in the system dynamics,\ndemonstrating that cooperation is more likely to be sustained when players are\nforward-looking. However, from a defense perspective, we find that simply\nreducing attack success probabilities can, paradoxically, incentivize attacks\nunder certain conditions. Furthermore, defensive measures to cap the upper\nbound of attack success rates may prove futile in some scenarios. These\ninsights highlight the complexity of securing LLM-based systems. Our work\nprovides a theoretical foundation and practical insights for understanding and\nmitigating their vulnerabilities, while emphasizing the importance of adaptive\nsecurity strategies and thoughtful ecosystem design.", "published": "2025-01-01 06:23:26", "link": "http://arxiv.org/abs/2501.00745v1", "categories": ["cs.CL", "cs.AI", "cs.GT", "cs.IR", "econ.TH"], "primary_category": "cs.CL"}
{"title": "VoiceRestore: Flow-Matching Transformers for Speech Recording Quality\n  Restoration", "abstract": "We present VoiceRestore, a novel approach to restoring the quality of speech\nrecordings using flow-matching Transformers trained in a self-supervised manner\non synthetic data. Our method tackles a wide range of degradations frequently\nfound in both short and long-form speech recordings, including background\nnoise, reverberation, compression artifacts, and bandwidth limitations - all\nwithin a single, unified model. Leveraging conditional flow matching and\nclassifier free guidance, the model learns to map degraded speech to high\nquality recordings without requiring paired clean and degraded datasets. We\ndescribe the training process, the conditional flow matching framework, and the\nmodel's architecture. We also demonstrate the model's generalization to\nreal-world speech restoration tasks, including both short utterances and\nextended monologues or dialogues. Qualitative and quantitative evaluations show\nthat our approach provides a flexible and effective solution for enhancing the\nquality of speech recordings across varying lengths and degradation types.", "published": "2025-01-01 10:13:19", "link": "http://arxiv.org/abs/2501.00794v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
