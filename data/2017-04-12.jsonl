{"title": "Trainable Referring Expression Generation using Overspecification\n  Preferences", "abstract": "Referring expression generation (REG) models that use speaker-dependent\ninformation require a considerable amount of training data produced by every\nindividual speaker, or may otherwise perform poorly. In this work we present a\nsimple REG experiment that allows the use of larger training data sets by\ngrouping speakers according to their overspecification preferences. Intrinsic\nevaluation shows that this method generally outperforms the personalised method\nfound in previous work.", "published": "2017-04-12 10:47:10", "link": "http://arxiv.org/abs/1704.03693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representation Stability as a Regularizer for Improved Text Analytics\n  Transfer Learning", "abstract": "Although neural networks are well suited for sequential transfer learning\ntasks, the catastrophic forgetting problem hinders proper integration of prior\nknowledge. In this work, we propose a solution to this problem by using a\nmulti-task objective based on the idea of distillation and a mechanism that\ndirectly penalizes forgetting at the shared representation layer during the\nknowledge integration phase of training. We demonstrate our approach on a\nTwitter domain sentiment analysis task with sequential knowledge transfer from\nfour related tasks. We show that our technique outperforms networks fine-tuned\nto the target task. Additionally, we show both through empirical evidence and\nexamples that it does not forget useful knowledge from the source task that is\nforgotten during standard fine-tuning. Surprisingly, we find that first\ndistilling a human made rule based sentiment engine into a recurrent neural\nnetwork and then integrating the knowledge with the target task data leads to a\nsubstantial gain in generalization performance. Our experiments demonstrate the\npower of multi-source transfer techniques in practical text analytics problems\nwhen paired with distillation. In particular, for the SemEval 2016 Task 4\nSubtask A (Nakov et al., 2016) dataset we surpass the state of the art\nestablished during the competition with a comparatively simple model\narchitecture that is not even competitive when trained on only the labeled task\nspecific data.", "published": "2017-04-12 04:38:18", "link": "http://arxiv.org/abs/1704.03617v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PACRR: A Position-Aware Neural IR Model for Relevance Matching", "abstract": "In order to adopt deep learning for information retrieval, models are needed\nthat can capture all relevant information required to assess the relevance of a\ndocument to a given user query. While previous works have successfully captured\nunigram term matches, how to fully employ position-dependent information such\nas proximity and term dependencies has been insufficiently explored. In this\nwork, we propose a novel neural IR model named PACRR aiming at better modeling\nposition-dependent interactions between a query and a document. Extensive\nexperiments on six years' TREC Web Track data confirm that the proposed model\nyields better results under multiple benchmarks.", "published": "2017-04-12 21:56:59", "link": "http://arxiv.org/abs/1704.03940v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Real-time On-Demand Crowd-powered Entity Extraction", "abstract": "Output-agreement mechanisms such as ESP Game have been widely used in human\ncomputation to obtain reliable human-generated labels. In this paper, we argue\nthat a \"time-limited\" output-agreement mechanism can be used to create a fast\nand robust crowd-powered component in interactive systems, particularly\ndialogue systems, to extract key information from user utterances on the fly.\nOur experiments on Amazon Mechanical Turk using the Airline Travel Information\nSystem (ATIS) dataset showed that the proposed approach achieves high-quality\nresults with an average response time shorter than 9 seconds.", "published": "2017-04-12 05:48:18", "link": "http://arxiv.org/abs/1704.03627v2", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "A Neural Parametric Singing Synthesizer", "abstract": "We present a new model for singing synthesis based on a modified version of\nthe WaveNet architecture. Instead of modeling raw waveform, we model features\nproduced by a parametric vocoder that separates the influence of pitch and\ntimbre. This allows conveniently modifying pitch to match any target melody,\nfacilitates training on more modest dataset sizes, and significantly reduces\ntraining and generation times. Our model makes frame-wise predictions using\nmixture density outputs rather than categorical outputs in order to reduce the\nrequired parameter count. As we found overfitting to be an issue with the\nrelatively small datasets used in our experiments, we propose a method to\nregularize the model and make the autoregressive generation process more robust\nto prediction errors. Using a simple multi-stream architecture, harmonic,\naperiodic and voiced/unvoiced components can all be predicted in a coherent\nmanner. We compare our method to existing parametric statistical and\nstate-of-the-art concatenative methods using quantitative metrics and a\nlistening test. While naive implementations of the autoregressive generation\nalgorithm tend to be inefficient, using a smart algorithm we can greatly speed\nup the process and obtain a system that's competitive in both speed and\nquality.", "published": "2017-04-12 15:57:08", "link": "http://arxiv.org/abs/1704.03809v3", "categories": ["cs.SD", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
